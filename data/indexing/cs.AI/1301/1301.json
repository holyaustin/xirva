[{"id": "1301.0173", "submitter": "Doreswamy", "authors": "Doreswamy", "title": "Knowledge Discovery System For Fiber Reinforced Polymer Matrix Composite\n  Laminate", "comments": "International Journal of Computing, Vol. 2, Issue 7, pp. 121-130,\n  July 2010. (ISSN 2151-9617)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper Knowledge Discovery System (KDS) is proposed and implemented\nfor the extraction of knowledge-mean stiffness of a polymer composite material\nin which when fibers are placed at different orientations. Cosine amplitude\nmethod is implemented for retrieving compatible polymer matrix and\nreinforcement fiber which is coming under predicted fiber class, from the\npolymer and reinforcement database respectively, based on the design\nrequirements. Fuzzy classification rules to classify fibers into short, medium\nand long fiber classes are derived based on the fiber length and the computed\nor derive critical length of fiber. Longitudinal and Transverse module of\nPolymer Matrix Composite consisting of seven layers with different fiber volume\nfractions and different fibers orientations at 0,15,30,45,60,75 and 90 degrees\nare analyzed through Rule-of Mixture material design model. The analysis\nresults are represented in different graphical steps and have been measured\nwith statistical parameters. This data mining application implemented here has\nfocused the mechanical problems of material design and analysis. Therefore,\nthis system is an expert decision support system for optimizing the materials\nperformance for designing light-weight and strong, and cost effective polymer\ncomposite materials.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2013 06:47:45 GMT"}], "update_date": "2013-01-03", "authors_parsed": [["Doreswamy", "", ""]]}, {"id": "1301.0176", "submitter": "Doreswamy", "authors": "Doreswamy, M.N.Vanajakshi", "title": "Similarity Measuring Approuch for Engineering Materials Selection", "comments": "International Journal of Computational Intelligence Systems (IJCIS),\n  Vol.3, Issue 1, April 2010, pp.115-122. (ISSN: 1875-6883)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced engineering materials design involves the exploration of massive\nmultidimensional feature spaces, the correlation of materials properties and\nthe processing parameters derived from disparate sources. The search for\nalternative materials or processing property strategies, whether through\nanalytical, experimental or simulation approaches, has been a slow and arduous\ntask, punctuated by infrequent and often expected discoveries. A few systematic\nefforts have been made to analyze the trends in data as a basis for\nclassifications and predictions. This is particularly due to the lack of large\namounts of organized data and more importantly the challenging of shifting\nthrough them in a timely and efficient manner. The application of recent\nadvances in Data Mining on materials informatics is the state of art of\ncomputational and experimental approaches for materials discovery. In this\npaper similarity based engineering materials selection model is proposed and\nimplemented to select engineering materials based on the composite materials\nconstraints. The result reviewed from this model is sustainable for effective\ndecision making in advanced engineering materials design applications.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2013 07:07:20 GMT"}], "update_date": "2013-01-03", "authors_parsed": [["Doreswamy", "", ""], ["Vanajakshi", "M. N.", ""]]}, {"id": "1301.0216", "submitter": "Jan Hrncir", "authors": "Jan Hrn\\v{c}\\'i\\v{r} and Michael Rovatsos", "title": "Applying Strategic Multiagent Planning to Real-World Travel Sharing\n  Problems", "comments": "7th International Workshop on Agents in Traffic and Transportation,\n  AAMAS, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Travel sharing, i.e., the problem of finding parts of routes which can be\nshared by several travellers with different points of departure and\ndestinations, is a complex multiagent problem that requires taking into account\nindividual agents' preferences to come up with mutually acceptable joint plans.\nIn this paper, we apply state-of-the-art planning techniques to real-world\npublic transportation data to evaluate the feasibility of multiagent planning\ntechniques in this domain. The potential application value of improving travel\nsharing technology has great application value due to its ability to reduce the\nenvironmental impact of travelling while providing benefits to travellers at\nthe same time. We propose a three-phase algorithm that utilises performant\nsingle-agent planners to find individual plans in a simplified domain first,\nthen merges them using a best-response planner which ensures resulting\nsolutions are individually rational, and then maps the resulting plan onto the\nfull temporal planning domain to schedule actual journeys. The evaluation of\nour algorithm on real-world, multi-modal public transportation data for the\nUnited Kingdom shows linear scalability both in the scenario size and in the\nnumber of agents, where trade-offs have to be made between total cost\nimprovement, the percentage of feasible timetables identified for journeys, and\nthe prolongation of these journeys. Our system constitutes the first\nimplementation of strategic multiagent planning algorithms in large-scale\ndomains and provides insights into the engineering process of translating\ngeneral domain-independent multiagent planning algorithms to real-world\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2013 12:06:59 GMT"}], "update_date": "2013-01-03", "authors_parsed": [["Hrn\u010d\u00ed\u0159", "Jan", ""], ["Rovatsos", "Michael", ""]]}, {"id": "1301.0302", "submitter": "Paulo Shakarian", "authors": "Paulo Shakarian, Gerardo I. Simari, Robert Schroeder", "title": "MANCaLog: A Logic for Multi-Attribute Network Cascades (Technical\n  Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.MA cs.SI physics.soc-ph", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  The modeling of cascade processes in multi-agent systems in the form of\ncomplex networks has in recent years become an important topic of study due to\nits many applications: the adoption of commercial products, spread of disease,\nthe diffusion of an idea, etc. In this paper, we begin by identifying a\ndesiderata of seven properties that a framework for modeling such processes\nshould satisfy: the ability to represent attributes of both nodes and edges, an\nexplicit representation of time, the ability to represent non-Markovian\ntemporal relationships, representation of uncertain information, the ability to\nrepresent competing cascades, allowance of non-monotonic diffusion, and\ncomputational tractability. We then present the MANCaLog language, a formalism\nbased on logic programming that satisfies all these desiderata, and focus on\nalgorithms for finding minimal models (from which the outcome of cascades can\nbe obtained) as well as how this formalism can be applied in real world\nscenarios. We are not aware of any other formalism in the literature that meets\nall of the above requirements.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2013 20:01:04 GMT"}, {"version": "v2", "created": "Sat, 19 Jan 2013 01:54:12 GMT"}], "update_date": "2013-01-22", "authors_parsed": [["Shakarian", "Paulo", ""], ["Simari", "Gerardo I.", ""], ["Schroeder", "Robert", ""]]}, {"id": "1301.0550", "submitter": "Ayesha R. Ali", "authors": "Ayesha R. Ali, Thomas S. Richardson", "title": "Markov Equivalence Classes for Maximal Ancestral Graphs", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-1-9", "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ancestral graphs are a class of graphs that encode conditional independence\nrelations arising in DAG models with latent and selection variables,\ncorresponding to marginalization and conditioning. However, for any ancestral\ngraph, there may be several other graphs to which it is Markov equivalent. We\nintroduce a simple representation of a Markov equivalence class of ancestral\ngraphs, thereby facilitating model search. \\ More specifically, we define a\njoin operation on ancestral graphs which will associate a unique graph with a\nMarkov equivalence class. We also extend the separation criterion for ancestral\ngraphs (which is an extension of d-separation) and provide a proof of the\npairwise Markov property for joined ancestral graphs.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:55:00 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Ali", "Ayesha R.", ""], ["Richardson", "Thomas S.", ""]]}, {"id": "1301.0552", "submitter": "Ionut Aron", "authors": "Ionut Aron, Pascal Van Hentenryck", "title": "A constraint satisfaction approach to the robust spanning tree problem\n  with interval data", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-18-25", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust optimization is one of the fundamental approaches to deal with\nuncertainty in combinatorial optimization. This paper considers the robust\nspanning tree problem with interval data, which arises in a variety of\ntelecommunication applications. It proposes a constraint satisfaction approach\nusing a combinatorial lower bound, a pruning component that removes infeasible\nand suboptimal edges, as well as a search strategy exploring the most uncertain\nedges first. The resulting algorithm is shown to produce very dramatic\nimprovements over the mathematical programming approach of Yaman et al. and to\nenlarge considerably the class of problems amenable to effective solutions\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:55:09 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Aron", "Ionut", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "1301.0553", "submitter": "Vincent Auvray", "authors": "Vincent Auvray, Louis Wehenkel", "title": "On the Construction of the Inclusion Boundary Neighbourhood for Markov\n  Equivalence Classes of Bayesian Network Structures", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-26-35", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of learning Markov equivalence classes of Bayesian network\nstructures may be solved by searching for the maximum of a scoring metric in a\nspace of these classes. This paper deals with the definition and analysis of\none such search space. We use a theoretically motivated neighbourhood, the\ninclusion boundary, and represent equivalence classes by essential graphs. We\nshow that this search space is connected and that the score of the neighbours\ncan be evaluated incrementally. We devise a practical way of building this\nneighbourhood for an essential graph that is purely graphical and does not\nexplicitely refer to the underlying independences. We find that its size can be\nintractable, depending on the complexity of the essential graph of the\nequivalence class. The emphasis is put on the potential use of this space with\ngreedy hill -climbing search\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:55:13 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Auvray", "Vincent", ""], ["Wehenkel", "Louis", ""]]}, {"id": "1301.0555", "submitter": "Salem Benferhat", "authors": "Salem Benferhat, Didier Dubois, Souhila Kaci, Henri Prade", "title": "Bipolar Possibilistic Representations", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-45-52", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, it has been emphasized that the possibility theory framework allows\nus to distinguish between i) what is possible because it is not ruled out by\nthe available knowledge, and ii) what is possible for sure. This distinction\nmay be useful when representing knowledge, for modelling values which are not\nimpossible because they are consistent with the available knowledge on the one\nhand, and values guaranteed to be possible because reported from observations\non the other hand. It is also of interest when expressing preferences, to point\nout values which are positively desired among those which are not rejected.\nThis distinction can be encoded by two types of constraints expressed in terms\nof necessity measures and in terms of guaranteed possibility functions, which\ninduce a pair of possibility distributions at the semantic level. A consistency\ncondition should ensure that what is claimed to be guaranteed as possible is\nindeed not impossible. The present paper investigates the representation of\nthis bipolar view, including the case when it is stated by means of conditional\nmeasures, or by means of comparative context-dependent constraints. The\ninterest of this bipolar framework, which has been recently stressed for\nexpressing preferences, is also pointed out in the representation of diagnostic\nknowledge.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:55:21 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Benferhat", "Salem", ""], ["Dubois", "Didier", ""], ["Kaci", "Souhila", ""], ["Prade", "Henri", ""]]}, {"id": "1301.0557", "submitter": "Blai Bonet", "authors": "Blai Bonet, Judea Pearl", "title": "Qualitative MDPs and POMDPs: An Order-Of-Magnitude Approximation", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-61-68", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a qualitative theory of Markov Decision Processes (MDPs) and\nPartially Observable MDPs that can be used to model sequential decision making\ntasks when only qualitative information is available. Our approach is based\nupon an order-of-magnitude approximation of both probabilities and utilities,\nsimilar to epsilon-semantics. The result is a qualitative theory that has close\nties with the standard maximum-expected-utility theory and is amenable to\ngeneral planning techniques.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:55:30 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Bonet", "Blai", ""], ["Pearl", "Judea", ""]]}, {"id": "1301.0558", "submitter": "Ronen I. Brafman", "authors": "Ronen I. Brafman, Carmel Domshlak", "title": "Introducing Variable Importance Tradeoffs into CP-Nets", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-69-76", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to make decisions and to assess potential courses of action is a\ncorner-stone of many AI applications, and usually this requires explicit\ninformation about the decision-maker s preferences. IN many applications,\npreference elicitation IS a serious bottleneck.The USER either does NOT have\nthe time, the knowledge, OR the expert support required TO specify complex\nmulti - attribute utility functions. IN such cases, a method that IS based ON\nintuitive, yet expressive, preference statements IS required. IN this paper we\nsuggest the USE OF TCP - nets, an enhancement OF CP - nets, AS a tool FOR\nrepresenting, AND reasoning about qualitative preference statements.We present\nAND motivate this framework, define its semantics, AND show how it can be used\nTO perform constrained optimization.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:55:33 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Brafman", "Ronen I.", ""], ["Domshlak", "Carmel", ""]]}, {"id": "1301.0559", "submitter": "John Bresina", "authors": "John Bresina, Richard Dearden, Nicolas Meuleau, Sailesh Ramkrishnan,\n  David Smith, Richard Washington", "title": "Planning under Continuous Time and Resource Uncertainty: A Challenge for\n  AI", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-77-84", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We outline a class of problems, typical of Mars rover operations, that are\nproblematic for current methods of planning under uncertainty. The existing\nmethods fail because they suffer from one or more of the following limitations:\n1) they rely on very simple models of actions and time, 2) they assume that\nuncertainty is manifested in discrete action outcomes, 3) they are only\npractical for very small problems. For many real world problems, these\nassumptions fail to hold. In particular, when planning the activities for a\nMars rover, none of the above assumptions is valid: 1) actions can be\nconcurrent and have differing durations, 2) there is uncertainty concerning\naction durations and consumption of continuous resources like power, and 3)\ntypical daily plans involve on the order of a hundred actions. This class of\nproblems may be of particular interest to the UAI community because both\nclassical and decision-theoretic planning techniques may be useful in solving\nit. We describe the rover problem, discuss previous work on planning under\nuncertainty, and present a detailed, but very small, example illustrating some\nof the difficulties of finding good plans.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:55:37 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Bresina", "John", ""], ["Dearden", "Richard", ""], ["Meuleau", "Nicolas", ""], ["Ramkrishnan", "Sailesh", ""], ["Smith", "David", ""], ["Washington", "Richard", ""]]}, {"id": "1301.0560", "submitter": "Carlos Brito", "authors": "Carlos Brito, Judea Pearl", "title": "Generalized Instrumental Variables", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-85-93", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns the assessment of direct causal effects from a\ncombination of: (i) non-experimental data, and (ii) qualitative domain\nknowledge. Domain knowledge is encoded in the form of a directed acyclic graph\n(DAG), in which all interactions are assumed linear, and some variables are\npresumed to be unobserved. We provide a generalization of the well-known method\nof Instrumental Variables, which allows its application to models with few\nconditional independeces.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:55:41 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Brito", "Carlos", ""], ["Pearl", "Judea", ""]]}, {"id": "1301.0561", "submitter": "David Maxwell Chickering", "authors": "David Maxwell Chickering, Christopher Meek", "title": "Finding Optimal Bayesian Networks", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-94-102", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we derive optimality results for greedy Bayesian-network\nsearch algorithms that perform single-edge modifications at each step and use\nasymptotically consistent scoring criteria. Our results extend those of Meek\n(1997) and Chickering (2002), who demonstrate that in the limit of large\ndatasets, if the generative distribution is perfect with respect to a DAG\ndefined over the observable variables, such search algorithms will identify\nthis optimal (i.e. generative) DAG model. We relax their assumption about the\ngenerative distribution, and assume only that this distribution satisfies the\n{em composition property} over the observable variables, which is a more\nrealistic assumption for real domains. Under this assumption, we guarantee that\nthe search algorithms identify an {em inclusion-optimal} model; that is, a\nmodel that (1) contains the generative distribution and (2) has no sub-model\nthat contains this distribution. In addition, we show that the composition\nproperty is guaranteed to hold whenever the dependence relationships in the\ngenerative distribution can be characterized by paths between singleton\nelements in some generative graphical model (e.g. a DAG, a chain graph, or a\nMarkov network) even when the generative model includes unobserved variables,\nand even when the observed data is subject to selection bias.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:55:46 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Chickering", "David Maxwell", ""], ["Meek", "Christopher", ""]]}, {"id": "1301.0563", "submitter": "Scott Davies", "authors": "Scott Davies, Andrew Moore", "title": "Interpolating Conditional Density Trees", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-119-127", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint distributions over many variables are frequently modeled by decomposing\nthem into products of simpler, lower-dimensional conditional distributions,\nsuch as in sparsely connected Bayesian networks. However, automatically\nlearning such models can be very computationally expensive when there are many\ndatapoints and many continuous variables with complex nonlinear relationships,\nparticularly when no good ways of decomposing the joint distribution are known\na priori. In such situations, previous research has generally focused on the\nuse of discretization techniques in which each continuous variable has a single\ndiscretization that is used throughout the entire network. \\ In this paper, we\npresent and compare a wide variety of tree-based algorithms for learning and\nevaluating conditional density estimates over continuous variables. These trees\ncan be thought of as discretizations that vary according to the particular\ninteractions being modeled; however, the density within a given leaf of the\ntree need not be assumed constant, and we show that such nonuniform leaf\ndensities lead to more accurate density estimation. We have developed Bayesian\nnetwork structure-learning algorithms that employ these tree-based conditional\ndensity representations, and we show that they can be used to practically learn\ncomplex joint probability models over dozens of continuous variables from\nthousands of datapoints. We focus on finding models that are simultaneously\naccurate, fast to learn, and fast to evaluate once they are learned.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:55:54 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Davies", "Scott", ""], ["Moore", "Andrew", ""]]}, {"id": "1301.0564", "submitter": "Rina Dechter", "authors": "Rina Dechter, Kalev Kask, Robert Mateescu", "title": "Iterative Join-Graph Propagation", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-128-136", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents an iterative version of join-tree clustering that applies\nthe message passing of join-tree clustering algorithm to join-graphs rather\nthan to join-trees, iteratively. It is inspired by the success of Pearl's\nbelief propagation algorithm as an iterative approximation scheme on one hand,\nand by a recently introduced mini-clustering i. success as an anytime\napproximation method, on the other. The proposed Iterative Join-graph\nPropagation IJGP belongs to the class of generalized belief propagation\nmethods, recently proposed using analogy with algorithms in statistical\nphysics. Empirical evaluation of this approach on a number of problem classes\ndemonstrates that even the most time-efficient variant is almost always\nsuperior to IBP and MC i, and is sometimes more accurate by as much as several\norders of magnitude.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:55:58 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Dechter", "Rina", ""], ["Kask", "Kalev", ""], ["Mateescu", "Robert", ""]]}, {"id": "1301.0566", "submitter": "Thomas Eiter", "authors": "Thomas Eiter, Thomas Lukasiewicz", "title": "Causes and Explanations in the Structural-Model Approach: Tractable\n  Cases", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-146-153", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we continue our research on the algorithmic aspects of Halpern\nand Pearl's causes and explanations in the structural-model approach. To this\nend, we present new characterizations of weak causes for certain classes of\ncausal models, which show that under suitable restrictions deciding causes and\nexplanations is tractable. To our knowledge, these are the first explicit\ntractability results for the structural-model approach.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:56:06 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Eiter", "Thomas", ""], ["Lukasiewicz", "Thomas", ""]]}, {"id": "1301.0567", "submitter": "Sarah Finney", "authors": "Sarah Finney, Natalia Gardiol, Leslie Pack Kaelbling, Tim Oates", "title": "The Thing That We Tried Didn't Work Very Well : Deictic Representation\n  in Reinforcement Learning", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-154-161", "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most reinforcement learning methods operate on propositional representations\nof the world state. Such representations are often intractably large and\ngeneralize poorly. Using a deictic representation is believed to be a viable\nalternative: they promise generalization while allowing the use of existing\nreinforcement-learning methods. Yet, there are few experiments on learning with\ndeictic representations reported in the literature. In this paper we explore\nthe effectiveness of two forms of deictic representation and a na\\\"{i}ve\npropositional representation in a simple blocks-world domain. We find,\nempirically, that the deictic representations actually worsen learning\nperformance. We conclude with a discussion of possible causes of these results\nand strategies for more effective learning in domains with objects.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:56:10 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Finney", "Sarah", ""], ["Gardiol", "Natalia", ""], ["Kaelbling", "Leslie Pack", ""], ["Oates", "Tim", ""]]}, {"id": "1301.0568", "submitter": "Dan Geiger", "authors": "Dan Geiger, Christopher Meek, Bernd Sturmfels", "title": "Factorization of Discrete Probability Distributions", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-162-169", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate necessary and sufficient conditions for an arbitrary discrete\nprobability distribution to factor according to an undirected graphical model,\nor a log-linear model, or other more general exponential models. This result\ngeneralizes the well known Hammersley-Clifford Theorem.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:56:14 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Geiger", "Dan", ""], ["Meek", "Christopher", ""], ["Sturmfels", "Bernd", ""]]}, {"id": "1301.0569", "submitter": "Phan H. Giang", "authors": "Phan H. Giang, Prakash P. Shenoy", "title": "Statistical Decisions Using Likelihood Information Without Prior\n  Probabilities", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-170-178", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a decision-theoretic approach to statistical inference\nthat satisfies the likelihood principle (LP) without using prior information.\nUnlike the Bayesian approach, which also satisfies LP, we do not assume\nknowledge of the prior distribution of the unknown parameter. With respect to\ninformation that can be obtained from an experiment, our solution is more\nefficient than Wald's minimax solution.However, with respect to information\nassumed to be known before the experiment, our solution demands less input than\nthe Bayesian solution.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:56:18 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Giang", "Phan H.", ""], ["Shenoy", "Prakash P.", ""]]}, {"id": "1301.0570", "submitter": "Joshua Goodman", "authors": "Joshua Goodman", "title": "Reduction of Maximum Entropy Models to Hidden Markov Models", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-179-186", "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that maximum entropy (maxent) models can be modeled with certain\nkinds of HMMs, allowing us to construct maxent models with hidden variables,\nhidden state sequences, or other characteristics. The models can be trained\nusing the forward-backward algorithm. While the results are primarily of\ntheoretical interest, unifying apparently unrelated concepts, we also give\nexperimental results for a maxent model with a hidden variable on a word\ndisambiguation task; the model outperforms standard techniques.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:56:22 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Goodman", "Joshua", ""]]}, {"id": "1301.0571", "submitter": "Carlos E. Guestrin", "authors": "Carlos E. Guestrin, Geoffrey Gordon", "title": "Distributed Planning in Hierarchical Factored MDPs", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-197-206", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a principled and efficient planning algorithm for collaborative\nmultiagent dynamical systems. All computation, during both the planning and the\nexecution phases, is distributed among the agents; each agent only needs to\nmodel and plan for a small part of the system. Each of these local subsystems\nis small, but once they are combined they can represent an exponentially larger\nproblem. The subsystems are connected through a subsystem hierarchy.\nCoordination and communication between the agents is not imposed, but derived\ndirectly from the structure of this hierarchy. A globally consistent plan is\nachieved by a message passing algorithm, where messages correspond to natural\nlocal reward functions and are computed by local linear programs; another\nmessage passing algorithm allows us to execute the resulting policy. When two\nportions of the hierarchy share the same structure, our algorithm can reuse\nplans and messages to speed up computation.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:56:27 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Guestrin", "Carlos E.", ""], ["Gordon", "Geoffrey", ""]]}, {"id": "1301.0572", "submitter": "Tom Heskes", "authors": "Tom Heskes, Onno Zoeter", "title": "Expectation Propogation for approximate inference in dynamic Bayesian\n  networks", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-216-223", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe expectation propagation for approximate inference in dynamic\nBayesian networks as a natural extension of Pearl s exact belief\npropagation.Expectation propagation IS a greedy algorithm, converges IN many\npractical cases, but NOT always.We derive a DOUBLE - loop algorithm, guaranteed\nTO converge TO a local minimum OF a Bethe free energy.Furthermore, we show that\nstable fixed points OF (damped) expectation propagation correspond TO local\nminima OF this free energy, but that the converse need NOT be the CASE .We\nillustrate the algorithms BY applying them TO switching linear dynamical\nsystems AND discuss implications FOR approximate inference IN general Bayesian\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:56:30 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Heskes", "Tom", ""], ["Zoeter", "Onno", ""]]}, {"id": "1301.0573", "submitter": "Eric J. Horvitz", "authors": "Eric J. Horvitz, Paul Koch, Carl Kadie, Andy Jacobs", "title": "Coordinates: Probabilistic Forecasting of Presence and Availability", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-224-233", "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present methods employed in Coordinate, a prototype service that supports\ncollaboration and communication by learning predictive models that provide\nforecasts of users s AND availability.We describe how data IS collected about\nUSER activity AND proximity FROM multiple devices, IN addition TO analysis OF\nthe content OF users, the time of day, and day of week. We review applications\nof presence forecasting embedded in the Priorities application and then present\ndetails of the Coordinate service that was informed by the earlier efforts.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:56:34 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Horvitz", "Eric J.", ""], ["Koch", "Paul", ""], ["Kadie", "Carl", ""], ["Jacobs", "Andy", ""]]}, {"id": "1301.0574", "submitter": "Finn Verner Jensen", "authors": "Finn Verner Jensen, Marta Vomlelova", "title": "Unconstrained Influence Diagrams", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-234-241", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the language of influence diagrams to cope with decision scenarios\nwhere the order of decisions and observations is not determined. As the\nordering of decisions is dependent on the evidence, a step-strategy of such a\nscenario is a sequence of dependent choices of the next action. A strategy is a\nstep-strategy together with selection functions for decision actions. The\nstructure of a step-strategy can be represented as a DAG with nodes labeled\nwith action variables. We introduce the concept of GS-DAG: a DAG incorporating\nan optimal step-strategy for any instantiation. We give a method for\nconstructing GS-DAGs, and we show how to use a GS-DAG for determining an\noptimal strategy. Finally we discuss how analysis of relevant past can be used\nto reduce the size of the GS-DAG.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:56:38 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Jensen", "Finn Verner", ""], ["Vomlelova", "Marta", ""]]}, {"id": "1301.0575", "submitter": "Carl Kadie", "authors": "Carl Kadie, Christopher Meek, David Heckerman", "title": "CFW: A Collaborative Filtering System Using Posteriors Over Weights Of\n  Evidence", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-242-250", "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe CFW, a computationally efficient algorithm for collaborative\nfiltering that uses posteriors over weights of evidence. In experiments on real\ndata, we show that this method predicts as well or better than other methods in\nsituations where the size of the user query is small. The new approach works\nparticularly well when the user s query CONTAINS low frequency(unpopular)\nitems.The approach complements that OF dependency networks which perform well\nWHEN the size OF the query IS large.Also IN this paper, we argue that the USE\nOF posteriors OVER weights OF evidence IS a natural way TO recommend similar\nitems collaborative - filtering task.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:56:42 GMT"}, {"version": "v2", "created": "Sat, 16 May 2015 23:04:17 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Kadie", "Carl", ""], ["Meek", "Christopher", ""], ["Heckerman", "David", ""]]}, {"id": "1301.0576", "submitter": "Mehmet Kayaalp", "authors": "Mehmet Kayaalp, Gregory F. Cooper", "title": "A Bayesian Network Scoring Metric That Is Based On Globally Uniform\n  Parameter Priors", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-251-258", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new Bayesian network (BN) scoring metric called the Global\nUniform (GU) metric. This metric is based on a particular type of default\nparameter prior. Such priors may be useful when a BN developer is not willing\nor able to specify domain-specific parameter priors. The GU parameter prior\nspecifies that every prior joint probability distribution P consistent with a\nBN structure S is considered to be equally likely. Distribution P is consistent\nwith S if P includes just the set of independence relations defined by S. We\nshow that the GU metric addresses some undesirable behavior of the BDeu and K2\nBayesian network scoring metrics, which also use particular forms of default\nparameter priors. A closed form formula for computing GU for special classes of\nBNs is derived. Efficiently computing GU for an arbitrary BN remains an open\nproblem.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:56:46 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Kayaalp", "Mehmet", ""], ["Cooper", "Gregory F.", ""]]}, {"id": "1301.0577", "submitter": "Michael Kearns", "authors": "Michael Kearns, Yishay Mansour", "title": "Efficient Nash Computation in Large Population Games with Bounded\n  Influence", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-259-266", "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a general representation of large-population games in which each\nplayer s influence ON the others IS centralized AND limited, but may otherwise\nbe arbitrary.This representation significantly generalizes the class known AS\ncongestion games IN a natural way.Our main results are provably correct AND\nefficient algorithms FOR computing AND learning approximate Nash equilibria IN\nthis general framework.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:56:50 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Kearns", "Michael", ""], ["Mansour", "Yishay", ""]]}, {"id": "1301.0580", "submitter": "Michail Lagoudakis", "authors": "Michail Lagoudakis, Ron Parr", "title": "Value Function Approximation in Zero-Sum Markov Games", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-283-292", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates value function approximation in the context of\nzero-sum Markov games, which can be viewed as a generalization of the Markov\ndecision process (MDP) framework to the two-agent case. We generalize error\nbounds from MDPs to Markov games and describe generalizations of reinforcement\nlearning algorithms to Markov games. We present a generalization of the optimal\nstopping problem to a two-player simultaneous move Markov game. For this\nspecial problem, we provide stronger bounds and can guarantee convergence for\nLSTD and temporal difference learning with linear value function approximation.\nWe demonstrate the viability of value function approximation for Markov games\nby using the Least squares policy iteration (LSPI) algorithm to learn good\npolicies for a soccer domain and a flow control problem.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:57:02 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Lagoudakis", "Michail", ""], ["Parr", "Ron", ""]]}, {"id": "1301.0582", "submitter": "Uri Lerner", "authors": "Uri Lerner, Brooks Moses, Maricia Scott, Sheila McIlraith, Daphne\n  Koller", "title": "Monitoring a Complez Physical System using a Hybrid Dynamic Bayes Net", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-301-310", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Reverse Water Gas Shift system (RWGS) is a complex physical system\ndesigned to produce oxygen from the carbon dioxide atmosphere on Mars. If sent\nto Mars, it would operate without human supervision, thus requiring a reliable\nautomated system for monitoring and control. The RWGS presents many challenges\ntypical of real-world systems, including: noisy and biased sensors, nonlinear\nbehavior, effects that are manifested over different time granularities, and\nunobservability of many important quantities. In this paper we model the RWGS\nusing a hybrid (discrete/continuous) Dynamic Bayesian Network (DBN), where the\nstate at each time slice contains 33 discrete and 184 continuous variables. We\nshow how the system state can be tracked using probabilistic inference over the\nmodel. We discuss how to deal with the various challenges presented by the\nRWGS, providing a suite of techniques that are likely to be useful in a wide\nrange of applications. In particular, we describe a general framework for\ndealing with nonlinear behavior using numerical integration techniques,\nextending the successful Unscented Filter. We also show how to use a\nfixed-point computation to deal with effects that develop at different time\nscales, specifically rapid changes occurring during slowly changing processes.\nWe test our model using real data collected from the RWGS, demonstrating the\nfeasibility of hybrid DBNs for monitoring complex real-world physical systems.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:57:11 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Lerner", "Uri", ""], ["Moses", "Brooks", ""], ["Scott", "Maricia", ""], ["McIlraith", "Sheila", ""], ["Koller", "Daphne", ""]]}, {"id": "1301.0583", "submitter": "Omid Madani", "authors": "Omid Madani", "title": "Polynomial Value Iteration Algorithms for Detrerminstic MDPs", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-311-318", "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value iteration is a commonly used and empirically competitive method in\nsolving many Markov decision process problems. However, it is known that value\niteration has only pseudo-polynomial complexity in general. We establish a\nsomewhat surprising polynomial bound for value iteration on deterministic\nMarkov decision (DMDP) problems. We show that the basic value iteration\nprocedure converges to the highest average reward cycle on a DMDP problem in\nheta(n^2) iterations, or heta(mn^2) total time, where n denotes the number of\nstates, and m the number of edges. We give two extensions of value iteration\nthat solve the DMDP in heta(mn) time. We explore the analysis of policy\niteration algorithms and report on an empirical study of value iteration\nshowing that its convergence is much faster on random sparse graphs.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:57:15 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Madani", "Omid", ""]]}, {"id": "1301.0584", "submitter": "Bhaskara Marthi", "authors": "Bhaskara Marthi, Hanna Pasula, Stuart Russell, Yuval Peres", "title": "Decayed MCMC Filtering", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-319-326", "categories": "cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Filtering---estimating the state of a partially observable Markov process\nfrom a sequence of observations---is one of the most widely studied problems in\ncontrol theory, AI, and computational statistics. Exact computation of the\nposterior distribution is generally intractable for large discrete systems and\nfor nonlinear continuous systems, so a good deal of effort has gone into\ndeveloping robust approximation algorithms. This paper describes a simple\nstochastic approximation algorithm for filtering called {em decayed MCMC}. The\nalgorithm applies Markov chain Monte Carlo sampling to the space of state\ntrajectories using a proposal distribution that favours flips of more recent\nstate variables. The formal analysis of the algorithm involves a generalization\nof standard coupling arguments for MCMC convergence. We prove that for any\nergodic underlying Markov process, the convergence time of decayed MCMC with\ninverse-polynomial decay remains bounded as the length of the observation\nsequence grows. We show experimentally that decayed MCMC is at least\ncompetitive with other approximation algorithms such as particle filtering.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:57:19 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Marthi", "Bhaskara", ""], ["Pasula", "Hanna", ""], ["Russell", "Stuart", ""], ["Peres", "Yuval", ""]]}, {"id": "1301.0585", "submitter": "Peter McBurney", "authors": "Peter McBurney, Simon Parsons", "title": "Formalizing Scenario Analysis", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-327-334", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a formal treatment of scenarios in the context of a dialectical\nargumentation formalism for qualitative reasoning about uncertain propositions.\nOur formalism extends prior work in which arguments for and against uncertain\npropositions were presented and compared in interaction spaces called Agoras.\nWe now define the notion of a scenario in this framework and use it to define a\nset of qualitative uncertainty labels for propositions across a collection of\nscenarios. This work is intended to lead to a formal theory of scenarios and\nscenario analysis.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:57:23 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["McBurney", "Peter", ""], ["Parsons", "Simon", ""]]}, {"id": "1301.0589", "submitter": "Andrew Moore", "authors": "Andrew Moore, Jeff Schneider", "title": "Real-valued All-Dimensions search: Low-overhead rapid searching over\n  subsets of attributes", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-360-369", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is about searching the combinatorial space of contingency tables\nduring the inner loop of a nonlinear statistical optimization. Examples of this\noperation in various data analytic communities include searching for nonlinear\ncombinations of attributes that contribute significantly to a regression\n(Statistics), searching for items to include in a decision list (machine\nlearning) and association rule hunting (Data Mining).\n  This paper investigates a new, efficient approach to this class of problems,\ncalled RADSEARCH (Real-valued All-Dimensions-tree Search). RADSEARCH finds the\nglobal optimum, and this gives us the opportunity to empirically evaluate the\nquestion: apart from algorithmic elegance what does this attention to\noptimality buy us?\n  We compare RADSEARCH with other recent successful search algorithms such as\nCN2, PRIM, APriori, OPUS and DenseMiner. Finally, we introduce RADREG, a new\nregression algorithm for learning real-valued outputs based on RADSEARCHing for\nhigh-order interactions.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:57:39 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Moore", "Andrew", ""], ["Schneider", "Jeff", ""]]}, {"id": "1301.0590", "submitter": "Brenda Ng", "authors": "Brenda Ng, Leonid Peshkin, Avi Pfeffer", "title": "Factored Particles for Scalable Monitoring", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-370-377", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exact monitoring in dynamic Bayesian networks is intractable, so approximate\nalgorithms are necessary. This paper presents a new family of approximate\nmonitoring algorithms that combine the best qualities of the particle filtering\nand Boyen-Koller methods. Our algorithms maintain an approximate representation\nthe belief state in the form of sets of factored particles, that correspond to\nsamples of clusters of state variables. Empirical results show that our\nalgorithms outperform both ordinary particle filtering and the Boyen-Koller\nalgorithm on large systems.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:57:43 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Ng", "Brenda", ""], ["Peshkin", "Leonid", ""], ["Pfeffer", "Avi", ""]]}, {"id": "1301.0591", "submitter": "Uri Nodelman", "authors": "Uri Nodelman, Christian R. Shelton, Daphne Koller", "title": "Continuous Time Bayesian Networks", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-378-387", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a language for finite state continuous time Bayesian\nnetworks (CTBNs), which describe structured stochastic processes that evolve\nover continuous time. The state of the system is decomposed into a set of local\nvariables whose values change over time. The dynamics of the system are\ndescribed by specifying the behavior of each local variable as a function of\nits parents in a directed (possibly cyclic) graph. The model specifies, at any\ngiven point in time, the distribution over two aspects: when a local variable\nchanges its value and the next value it takes. These distributions are\ndetermined by the variable s CURRENT value AND the CURRENT VALUES OF its\nparents IN the graph.More formally, each variable IS modelled AS a finite state\ncontinuous time Markov process whose transition intensities are functions OF\nits parents.We present a probabilistic semantics FOR the language IN terms OF\nthe generative model a CTBN defines OVER sequences OF events.We list types OF\nqueries one might ask OF a CTBN, discuss the conceptual AND computational\ndifficulties associated WITH exact inference, AND provide an algorithm FOR\napproximate inference which takes advantage OF the structure within the\nprocess.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:57:47 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Nodelman", "Uri", ""], ["Shelton", "Christian R.", ""], ["Koller", "Daphne", ""]]}, {"id": "1301.0592", "submitter": "James D. Park", "authors": "James D. Park", "title": "MAP Complexity Results and Approximation Methods", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-388-396", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MAP is the problem of finding a most probable instantiation of a set of\nnvariables in a Bayesian network, given some evidence. MAP appears to be a\nsignificantly harder problem than the related problems of computing the\nprobability of evidence Pr, or MPE a special case of MAP. Because of the\ncomplexity of MAP, and the lack of viable algorithms to approximate it,MAP\ncomputations are generally avoided by practitioners. This paper investigates\nthe complexity of MAP. We show that MAP is complete for NP. We also provide\nnegative complexity results for elimination based algorithms. It turns out that\nMAP remains hard even when MPE, and Pr are easy. We show that MAP is NPcomplete\nwhen the networks are restricted to polytrees, and even then can not be\neffectively approximated. Because there is no approximation algorithm with\nguaranteed results, we investigate best effort approximations. We introduce a\ngeneric MAP approximation framework. As one instantiation of it, we implement\nlocal search coupled with belief propagation BP to approximate MAP. We show how\nto extract approximate evidence retraction information from belief propagation\nwhich allows us to perform efficient local search. This allows MAP\napproximation even on networks that are too complex to even exactly solve the\neasier problems of computing Pr or MPE. Experimental results indicate that\nusing BP and local search provides accurate MAP estimates in many cases.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:57:50 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Park", "James D.", ""]]}, {"id": "1301.0594", "submitter": "David M Pennock", "authors": "David M Pennock, Sandip Debnath, Eric Glover, C. Lee Giles", "title": "Modelling Information Incorporation in Markets, with Application to\n  Detecting and Explaining Events", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-405-413", "categories": "cs.AI q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a model of how information flows into a market, and derive\nalgorithms for automatically detecting and explaining relevant events. We\nanalyze data from twenty-two \"political stock markets\" (i.e., betting markets\non political outcomes) on the Iowa Electronic Market (IEM). We prove that,\nunder certain efficiency assumptions, prices in such betting markets will on\naverage approach the correct outcomes over time, and show that IEM data\nconforms closely to the theory. We present a simple model of a betting market\nwhere information is revealed over time, and show a qualitative correspondence\nbetween the model and real market data. We also present an algorithm for\nautomatically detecting significant events and generating semantic explanations\nof their origin. The algorithm operates by discovering significant changes in\nvocabulary on online news sources (using expected entropy loss) that align with\nmajor price spikes in related betting markets.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:57:58 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Pennock", "David M", ""], ["Debnath", "Sandip", ""], ["Glover", "Eric", ""], ["Giles", "C. Lee", ""]]}, {"id": "1301.0596", "submitter": "Silja Renooij", "authors": "Silja Renooij, Linda C. van der Gaag", "title": "From Qualitative to Quantitative Probabilistic Networks", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-422-429", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantification is well known to be a major obstacle in the construction of a\nprobabilistic network, especially when relying on human experts for this\npurpose. The construction of a qualitative probabilistic network has been\nproposed as an initial step in a network s quantification, since the\nqualitative network can be used TO gain preliminary insight IN the projected\nnetworks reasoning behaviour. We extend on this idea and present a new type of\nnetwork in which both signs and numbers are specified; we further present an\nassociated algorithm for probabilistic inference. Building upon these\nsemi-qualitative networks, a probabilistic network can be quantified and\nstudied in a stepwise manner. As a result, modelling inadequacies can be\ndetected and amended at an early stage in the quantification process.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:58:05 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Renooij", "Silja", ""], ["van der Gaag", "Linda C.", ""]]}, {"id": "1301.0597", "submitter": "Jose Carlos Ferreira da Rocha", "authors": "Jose Carlos Ferreira da Rocha, Fabio Gagliardi Cozman", "title": "Inference with Seperately Specified Sets of Probabilities in Credal\n  Networks", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-430-437", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new algorithms for inference in credal networks --- directed\nacyclic graphs associated with sets of probabilities. Credal networks are here\ninterpreted as encoding strong independence relations among variables. We first\npresent a theory of credal networks based on separately specified sets of\nprobabilities. We also show that inference with polytrees is NP-hard in this\nsetting. We then introduce new techniques that reduce the computational effort\ndemanded by inference, particularly in polytrees, by exploring separability of\ncredal sets.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:58:09 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["da Rocha", "Jose Carlos Ferreira", ""], ["Cozman", "Fabio Gagliardi", ""]]}, {"id": "1301.0598", "submitter": "Dmitry Rusakov", "authors": "Dmitry Rusakov, Dan Geiger", "title": "Asymptotic Model Selection for Naive Bayesian Networks", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-438-445", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a closed form asymptotic formula to compute the marginal\nlikelihood of data given a naive Bayesian network model with two hidden states\nand binary features. This formula deviates from the standard BIC score. Our\nwork provides a concrete example that the BIC score is generally not valid for\nstatistical models that belong to a stratified exponential family. This stands\nin contrast to linear and curved exponential families, where the BIC score has\nbeen proven to provide a correct approximation for the marginal likelihood.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:58:13 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Rusakov", "Dmitry", ""], ["Geiger", "Dan", ""]]}, {"id": "1301.0600", "submitter": "Guy Shani", "authors": "Guy Shani, Ronen I. Brafman, David Heckerman", "title": "An MDP-based Recommender System", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-453-460", "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical Recommender systems adopt a static view of the recommendation process\nand treat it as a prediction problem. We argue that it is more appropriate to\nview the problem of generating recommendations as a sequential decision problem\nand, consequently, that Markov decision processes (MDP) provide a more\nappropriate model for Recommender systems. MDPs introduce two benefits: they\ntake into account the long-term effects of each recommendation, and they take\ninto account the expected value of each recommendation. To succeed in practice,\nan MDP-based Recommender system must employ a strong initial model; and the\nbulk of this paper is concerned with the generation of such a model. In\nparticular, we suggest the use of an n-gram predictive model for generating the\ninitial MDP. Our n-gram model induces a Markov-chain model of user behavior\nwhose predictive accuracy is greater than that of existing predictive models.\nWe describe our predictive model in detail and evaluate its performance on real\ndata. In addition, we show how the model can be used in an MDP-based\nRecommender system.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:58:21 GMT"}, {"version": "v2", "created": "Sat, 16 May 2015 23:00:34 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Shani", "Guy", ""], ["Brafman", "Ronen I.", ""], ["Heckerman", "David", ""]]}, {"id": "1301.0603", "submitter": "Masami Takikawa", "authors": "Masami Takikawa, Bruce D'Ambrosio, Ed Wright", "title": "Real-Time Inference with Large-Scale Temporal Bayes Nets", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-477-484", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of applications require real-time reasoning under\nuncertainty with streaming input. The temporal (dynamic) Bayes net formalism\nprovides a powerful representational framework for such applications. However,\nexisting exact inference algorithms for dynamic Bayes nets do not scale to the\nsize of models required for real world applications which often contain\nhundreds or even thousands of variables for each time slice. In addition,\nexisting algorithms were not developed with real-time processing in mind. We\nhave developed a new computational approach to support real-time exact\ninference in large temporal Bayes nets. Our approach tackles scalability by\nrecognizing that the complexity of the inference depends on the number of\ninterface nodes between time slices and by exploiting the distinction between\nstatic and dynamic nodes in order to reduce the number of interface nodes and\nto factorize their joint probability distribution. We approach the real-time\nissue by organizing temporal Bayes nets into static representations, and then\nusing the symbolic probabilistic inference algorithm to derive analytic\nexpressions for the static representations. The parts of these expressions that\ndo not change at each time step are pre-computed. The remaining parts are\ncompiled into efficient procedural code so that the memory and CPU resources\nrequired by the inference are small and fixed.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:58:34 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Takikawa", "Masami", ""], ["D'Ambrosio", "Bruce", ""], ["Wright", "Ed", ""]]}, {"id": "1301.0604", "submitter": "Ben Taskar", "authors": "Ben Taskar, Pieter Abbeel, Daphne Koller", "title": "Discriminative Probabilistic Models for Relational Data", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-485-492", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many supervised learning tasks, the entities to be labeled are related to\neach other in complex ways and their labels are not independent. For example,\nin hypertext classification, the labels of linked pages are highly correlated.\nA standard approach is to classify each entity independently, ignoring the\ncorrelations between them. Recently, Probabilistic Relational Models, a\nrelational version of Bayesian networks, were used to define a joint\nprobabilistic model for a collection of related entities. In this paper, we\npresent an alternative framework that builds on (conditional) Markov networks\nand addresses two limitations of the previous approach. First, undirected\nmodels do not impose the acyclicity constraint that hinders representation of\nmany important relational dependencies in directed models. Second, undirected\nmodels are well suited for discriminative training, where we optimize the\nconditional likelihood of the labels given the features, which generally\nimproves classification accuracy. We show how to train these models\neffectively, and how to use approximate probabilistic inference over the\nlearned model for collective classification of multiple related entities. We\nprovide experimental results on a webpage classification task, showing that\naccuracy can be significantly improved by modeling relational dependencies.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:58:38 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Taskar", "Ben", ""], ["Abbeel", "Pieter", ""], ["Koller", "Daphne", ""]]}, {"id": "1301.0605", "submitter": "Sekhar Tatikonda", "authors": "Sekhar Tatikonda, Michael I. Jordan", "title": "Loopy Belief Propogation and Gibbs Measures", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-493-500", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the question of convergence in the loopy belief propagation (LBP)\nalgorithm. Specifically, we relate convergence of LBP to the existence of a\nweak limit for a sequence of Gibbs measures defined on the LBP s associated\ncomputation tree.Using tools FROM the theory OF Gibbs measures we develop\neasily testable sufficient conditions FOR convergence.The failure OF\nconvergence OF LBP implies the existence OF multiple phases FOR the associated\nGibbs specification.These results give new insight INTO the mechanics OF the\nalgorithm.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:58:42 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Tatikonda", "Sekhar", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1301.0606", "submitter": "Sylvie Thiebaux", "authors": "Sylvie Thiebaux, Froduald Kabanza, John Slanley", "title": "Anytime State-Based Solution Methods for Decision Processes with\n  non-Markovian Rewards", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-501-510", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular approach to solving a decision process with non-Markovian rewards\n(NMRDP) is to exploit a compact representation of the reward function to\nautomatically translate the NMRDP into an equivalent Markov decision process\n(MDP) amenable to our favorite MDP solution method. The contribution of this\npaper is a representation of non-Markovian reward functions and a translation\ninto MDP aimed at making the best possible use of state-based anytime\nalgorithms as the solution method. By explicitly constructing and exploring\nonly parts of the state space, these algorithms are able to trade computation\ntime for policy quality, and have proven quite effective in dealing with large\nMDPs. Our representation extends future linear temporal logic (FLTL) to express\nrewards. Our translation has the effect of embedding model-checking in the\nsolution method. It results in an MDP of the minimal size achievable without\nstepping outside the anytime framework, and consequently in better policies by\nthe deadline.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:58:46 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Thiebaux", "Sylvie", ""], ["Kabanza", "Froduald", ""], ["Slanley", "John", ""]]}, {"id": "1301.0607", "submitter": "Sebastian Thrun", "authors": "Sebastian Thrun", "title": "Particle Filters in Robotics (Invited Talk)", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-511-518", "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This presentation will introduce the audience to a new, emerging body of\nresearch on sequential Monte Carlo techniques in robotics. In recent years,\nparticle filters have solved several hard perceptual robotic problems. Early\nsuccesses were limited to low-dimensional problems, such as the problem of\nrobot localization in environments with known maps. More recently, researchers\nhave begun exploiting structural properties of robotic domains that have led to\nsuccessful particle filter applications in spaces with as many as 100,000\ndimensions. The presentation will discuss specific tricks necessary to make\nthese techniques work in real - world domains,and also discuss open challenges\nfor researchers IN the UAI community.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:58:50 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Thrun", "Sebastian", ""]]}, {"id": "1301.0608", "submitter": "Jin Tian", "authors": "Jin Tian, Judea Pearl", "title": "On the Testable Implications of Causal Models with Hidden Variables", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-519-527", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The validity OF a causal model can be tested ONLY IF the model imposes\nconstraints ON the probability distribution that governs the generated data. IN\nthe presence OF unmeasured variables, causal models may impose two types OF\nconstraints : conditional independencies, AS READ through the d - separation\ncriterion, AND functional constraints, FOR which no general criterion IS\navailable.This paper offers a systematic way OF identifying functional\nconstraints AND, thus, facilitates the task OF testing causal models AS well AS\ninferring such models FROM data.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:58:54 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Tian", "Jin", ""], ["Pearl", "Judea", ""]]}, {"id": "1301.0609", "submitter": "Jirka Vomlel", "authors": "Jirka Vomlel", "title": "Exploiting Functional Dependence in Bayesian Network Inference", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-528-535", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an efficient method for Bayesian network inference in models with\nfunctional dependence. We generalize the multiplicative factorization method\noriginally designed by Takikawa and D Ambrosio(1999) FOR models WITH\nindependence OF causal influence.Using a hidden variable, we transform a\nprobability potential INTO a product OF two - dimensional potentials.The\nmultiplicative factorization yields more efficient inference. FOR example, IN\njunction tree propagation it helps TO avoid large cliques. IN ORDER TO keep\npotentials small, the number OF states OF the hidden variable should be\nminimized.We transform this problem INTO a combinatorial problem OF minimal\nbase IN a particular space.We present an example OF a computerized adaptive\ntest, IN which the factorization method IS significantly more efficient than\nprevious inference methods.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:58:58 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Vomlel", "Jirka", ""]]}, {"id": "1301.0611", "submitter": "Peter P. Wakker", "authors": "Peter P. Wakker", "title": "Decision Principles to justify Carnap's Updating Method and to Suggest\n  Corrections of Probability Judgments (Invited Talks)", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-544-551", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper uses decision-theoretic principles to obtain new insights into the\nassessment and updating of probabilities. First, a new foundation of\nBayesianism is given. It does not require infinite atomless uncertainties as\ndid Savage s classical result, AND can therefore be applied TO ANY finite\nBayesian network.It neither requires linear utility AS did de Finetti s\nclassical result, AND r ntherefore allows FOR the empirically AND normatively\ndesirable risk r naversion.Finally, BY identifying AND fixing utility IN an\nelementary r nmanner, our result can readily be applied TO identify methods OF\nr nprobability updating.Thus, a decision - theoretic foundation IS given r nto\nthe computationally efficient method OF inductive reasoning r ndeveloped BY\nRudolf Carnap.Finally, recent empirical findings ON r nprobability assessments\nare discussed.It leads TO suggestions FOR r ncorrecting biases IN probability\nassessments, AND FOR an alternative r nto the Dempster - Shafer belief\nfunctions that avoids the reduction TO r ndegeneracy after multiple updatings.r\nn\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:59:06 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Wakker", "Peter P.", ""]]}, {"id": "1301.0613", "submitter": "Wim Wiegerinck", "authors": "Wim Wiegerinck, Tom Heskes", "title": "IPF for Discrete Chain Factor Graphs", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-560-567", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Iterative Proportional Fitting (IPF), combined with EM, is commonly used as\nan algorithm for likelihood maximization in undirected graphical models. In\nthis paper, we present two iterative algorithms that generalize upon IPF. The\nfirst one is for likelihood maximization in discrete chain factor graphs, which\nwe define as a wide class of discrete variable models including undirected\ngraphical models and Bayesian networks, but also chain graphs and sigmoid\nbelief networks. The second one is for conditional likelihood maximization in\nstandard undirected models and Bayesian networks. In both algorithms, the\niteration steps are expressed in closed form. Numerical simulations show that\nthe algorithms are competitive with state of the art methods.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:59:15 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Wiegerinck", "Wim", ""], ["Heskes", "Tom", ""]]}, {"id": "1301.0614", "submitter": "Sung Wook Yoon", "authors": "Sung Wook Yoon, Alan Fern, Robert Givan", "title": "Inductive Policy Selection for First-Order MDPs", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-568-576", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We select policies for large Markov Decision Processes (MDPs) with compact\nfirst-order representations. We find policies that generalize well as the\nnumber of objects in the domain grows, potentially without bound. Existing\ndynamic-programming approaches based on flat, propositional, or first-order\nrepresentations either are impractical here or do not naturally scale as the\nnumber of objects grows without bound. We implement and evaluate an alternative\napproach that induces first-order policies using training data constructed by\nsolving small problem instances using PGraphplan (Blum & Langford, 1999). Our\npolicies are represented as ensembles of decision lists, using a taxonomic\nconcept language. This approach extends the work of Martin and Geffner (2000)\nto stochastic domains, ensemble learning, and a wider variety of problems.\nEmpirically, we find \"good\" policies for several stochastic first-order MDPs\nthat are beyond the scope of previous approaches. We also discuss the\napplication of this work to the relational reinforcement-learning problem.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:59:19 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Yoon", "Sung Wook", ""], ["Fern", "Alan", ""], ["Givan", "Robert", ""]]}, {"id": "1301.0701", "submitter": "Rajendra Prasath Dr", "authors": "R.Rajendra Prasath and Pinar \\\"Ozt\\\"urk", "title": "Similarity Assessment through blocking and affordance assignment in\n  Textual CBR", "comments": "10 pages, 3 figures, WebCBR 2010, Alessandria, Italy", "journal-ref": "in: Proc. of the Reasoning from Experiences on the Web (WebCBR\n  2010), pp. 151-160, July 2010", "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been conceived that children learn new objects through their\naffordances, that is, the actions that can be taken on them. We suggest that\nweb pages also have affordances defined in terms of the users' information need\nthey meet. An assumption of the proposed approach is that different parts of a\ntext may not be equally important / relevant to a given query. Judgment on the\nrelevance of a web document requires, therefore, a thorough look into its\nparts, rather than treating it as a monolithic content. We propose a method to\nextract and assign affordances to texts and then use these affordances to\nretrieve the corresponding web pages. The overall approach presented in the\npaper relies on case-based representations that bridge the queries to the\naffordances of web documents. We tested our method on the tourism domain and\nthe results are promising.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2013 10:36:34 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Prasath", "R. Rajendra", ""], ["\u00d6zt\u00fcrk", "Pinar", ""]]}, {"id": "1301.0932", "submitter": "Mahyuddin K. M.  Nasution", "authors": "Sufianto Mahfudz, Mahyuddin K. M. Nasution, and Sawaluddin Nasution", "title": "Knowledge Sharing: A Model", "comments": "5 pages, a draf for ICOCSIM 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We know anything because we learn about it, there is anything we ever share\nabout it, but now a lot of media that can represent how it happened as\ninfrastructure of the knowledge sharing. This paper aims to introduce a model\nfor understanding a problem in knowledge sharing based on interaction.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2013 19:28:42 GMT"}], "update_date": "2013-01-08", "authors_parsed": [["Mahfudz", "Sufianto", ""], ["Nasution", "Mahyuddin K. M.", ""], ["Nasution", "Sawaluddin", ""]]}, {"id": "1301.0958", "submitter": "Giuseppe Sanfilippo", "authors": "Angelo Gilio and Giuseppe Sanfilippo", "title": "Probabilistic entailment in the setting of coherence: The role of quasi\n  conjunction and inclusion relation", "comments": null, "journal-ref": "International Journal of Approximate Reasoning, vol. 54, no. 4,\n  pp. 513-525, 2013, http://dx.doi.org/10.1016/j.ijar.2012.11.001", "doi": "10.1016/j.ijar.2012.11.001", "report-no": null, "categories": "math.PR cs.AI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, by adopting a coherence-based probabilistic approach to\ndefault reasoning, we focus the study on the logical operation of quasi\nconjunction and the Goodman-Nguyen inclusion relation for conditional events.\nWe recall that quasi conjunction is a basic notion for defining consistency of\nconditional knowledge bases. By deepening some results given in a previous\npaper we show that, given any finite family of conditional events F and any\nnonempty subset S of F, the family F p-entails the quasi conjunction C(S);\nthen, given any conditional event E|H, we analyze the equivalence between\np-entailment of E|H from F and p-entailment of E|H from C(S), where S is some\nnonempty subset of F. We also illustrate some alternative theorems related with\np-consistency and p-entailment. Finally, we deepen the study of the connections\nbetween the notions of p-entailment and inclusion relation by introducing for a\npair (F,E|H) the (possibly empty) class K of the subsets S of F such that C(S)\nimplies E|H. We show that the class K satisfies many properties; in particular\nK is additive and has a greatest element which can be determined by applying a\nsuitable algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2013 01:04:50 GMT"}], "update_date": "2013-03-18", "authors_parsed": [["Gilio", "Angelo", ""], ["Sanfilippo", "Giuseppe", ""]]}, {"id": "1301.1299", "submitter": "Th\\'eophane  Weber", "authors": "David Wingate, Theophane Weber", "title": "Automated Variational Inference in Probabilistic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We present a new algorithm for approximate inference in probabilistic\nprograms, based on a stochastic gradient for variational programs. This method\nis efficient without restrictions on the probabilistic program; it is\nparticularly practical for distributions which are not analytically tractable,\nincluding highly structured distributions that arise in probabilistic programs.\nWe show how to automatically derive mean-field probabilistic programs and\noptimize them, and demonstrate that our perspective improves inference\nefficiency over other algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2013 18:48:02 GMT"}], "update_date": "2013-01-08", "authors_parsed": [["Wingate", "David", ""], ["Weber", "Theophane", ""]]}, {"id": "1301.1332", "submitter": "Daniel Ritter", "authors": "Daniel Ritter", "title": "A Logic Programming Approach to Integration Network Inference", "comments": "15 pages, The 26th Workshop on Logic Programming (WLP), Bonn, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discovery, representation and reconstruction of (technical) integration\nnetworks from Network Mining (NM) raw data is a difficult problem for\nenterprises. This is due to large and complex IT landscapes within and across\nenterprise boundaries, heterogeneous technology stacks, and fragmented data. To\nremain competitive, visibility into the enterprise and partner IT networks on\ndifferent, interrelated abstraction levels is desirable.\n  We present an approach to represent and reconstruct the integration networks\nfrom NM raw data using logic programming based on first-order logic. The raw\ndata expressed as integration network model is represented as facts, on which\nrules are applied to reconstruct the network. We have built a system that is\nused to apply this approach to real-world enterprise landscapes and we report\non our experience with this system.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2013 20:52:40 GMT"}, {"version": "v2", "created": "Tue, 8 Jan 2013 16:24:10 GMT"}], "update_date": "2013-01-09", "authors_parsed": [["Ritter", "Daniel", ""]]}, {"id": "1301.1385", "submitter": "Michael Fink", "authors": "Mario Alviano and Wolfgang Faber", "title": "Translating NP-SPEC into ASP", "comments": "Proceedings of Answer Set Programming and Other Computing Paradigms\n  (ASPOCP 2012), 5th International Workshop, September 4, 2012, Budapest,\n  Hungary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NP-SPEC is a language for specifying problems in NP in a declarative way.\nDespite the fact that the semantics of the language was given by referring to\nDatalog with circumscription, which is very close to ASP, so far the only\nexisting implementations are by means of ECLiPSe Prolog and via Boolean\nsatisfiability solvers. In this paper, we present translations from NP-SPEC\ninto various forms of ASP and analyze them. We also argue that it might be\nuseful to incorporate certain language constructs of NP-SPEC into mainstream\nASP.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 02:28:49 GMT"}], "update_date": "2013-01-09", "authors_parsed": [["Alviano", "Mario", ""], ["Faber", "Wolfgang", ""]]}, {"id": "1301.1386", "submitter": "Michael Fink", "authors": "Evgenii Balai, Michael Gelfond, and Yuanlin Zhang", "title": "SPARC - Sorted ASP with Consistency Restoring Rules", "comments": "Proceedings of Answer Set Programming and Other Computing Paradigms\n  (ASPOCP 2012), 5th International Workshop, September 4, 2012, Budapest,\n  Hungary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a preliminary report on the work aimed at making CR-Prolog -- a\nversion of ASP with consistency restoring rules -- more suitable for use in\nteaching and large applications. First we describe a sorted version of\nCR-Prolog called SPARC. Second, we translate a basic version of the CR-Prolog\ninto the language of DLV and compare the performance with the state of the art\nCR-Prolog solver. The results form the foundation for future more efficient and\nuser friendly implementation of SPARC and shed some light on the relationship\nbetween two useful knowledge representation constructs: consistency restoring\nrules and weak constraints of DLV.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 02:29:00 GMT"}], "update_date": "2013-01-09", "authors_parsed": [["Balai", "Evgenii", ""], ["Gelfond", "Michael", ""], ["Zhang", "Yuanlin", ""]]}, {"id": "1301.1387", "submitter": "Michael Fink", "authors": "Marcello Balduccini and Michael Gelfond", "title": "Language ASP{f} with Arithmetic Expressions and Consistency-Restoring\n  Rules", "comments": "Proceedings of Answer Set Programming and Other Computing Paradigms\n  (ASPOCP 2012), 5th International Workshop, September 4, 2012, Budapest,\n  Hungary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we continue the work on our extension of Answer Set Programming\nby non-Herbrand functions and add to the language support for arithmetic\nexpressions and various inequality relations over non-Herbrand functions, as\nwell as consistency-restoring rules from CR-Prolog. We demonstrate the use of\nthis latest version of the language in the representation of important kinds of\nknowledge.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 02:29:05 GMT"}], "update_date": "2013-01-09", "authors_parsed": [["Balduccini", "Marcello", ""], ["Gelfond", "Michael", ""]]}, {"id": "1301.1388", "submitter": "Michael Fink", "authors": "G\\\"unther Charwat, Johannes Peter Wallner, and Stefan Woltran", "title": "Utilizing ASP for Generating and Visualizing Argumentation Frameworks", "comments": "Proceedings of Answer Set Programming and Other Computing Paradigms\n  (ASPOCP 2012), 5th International Workshop, September 4, 2012, Budapest,\n  Hungary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the area of computational models of argumentation, the\ninstantiation-based approach is gaining more and more attention, not at least\nbecause meaningful input for Dung's abstract frameworks is provided in that\nway. In a nutshell, the aim of instantiation-based argumentation is to form,\nfrom a given knowledge base, a set of arguments and to identify the conflicts\nbetween them. The resulting network is then evaluated by means of\nextension-based semantics on an abstract level, i.e. on the resulting graph.\nWhile several systems are nowadays available for the latter step, the\nautomation of the instantiation process itself has received less attention. In\nthis work, we provide a novel approach to construct and visualize an\nargumentation framework from a given knowledge base. The system we propose\nrelies on Answer-Set Programming and follows a two-step approach. A first\nprogram yields the logic-based arguments as its answer-sets; a second program\nis then used to specify the relations between arguments based on the\nanswer-sets of the first program. As it turns out, this approach not only\nallows for a flexible and extensible tool for instantiation-based\nargumentation, but also provides a new method for answer-set visualization in\ngeneral.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 02:29:11 GMT"}], "update_date": "2013-01-09", "authors_parsed": [["Charwat", "G\u00fcnther", ""], ["Wallner", "Johannes Peter", ""], ["Woltran", "Stefan", ""]]}, {"id": "1301.1389", "submitter": "Michael Fink", "authors": "Sandeep Chintabathina", "title": "Planning and Scheduling in Hybrid Domains Using Answer Set Programming", "comments": "Proceedings of Answer Set Programming and Other Computing Paradigms\n  (ASPOCP 2012), 5th International Workshop, September 4, 2012, Budapest,\n  Hungary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an Action Language-Answer Set Programming based\napproach to solving planning and scheduling problems in hybrid domains -\ndomains that exhibit both discrete and continuous behavior. We use action\nlanguage H to represent the domain and then translate the resulting theory into\nan A-Prolog program. In this way, we reduce the problem of finding solutions to\nplanning and scheduling problems to computing answer sets of A-Prolog programs.\nWe cite a planning and scheduling example from the literature and show how to\nmodel it in H. We show how to translate the resulting H theory into an\nequivalent A-Prolog program. We compute the answer sets of the resulting\nprogram using a hybrid solver called EZCSP which loosely integrates a\nconstraint solver with an answer set solver. The solver allows us reason about\nconstraints over reals and compute solutions to complex planning and scheduling\nproblems. Results have shown that our approach can be applied to any planning\nand scheduling problem in hybrid domains.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 02:29:17 GMT"}], "update_date": "2013-01-09", "authors_parsed": [["Chintabathina", "Sandeep", ""]]}, {"id": "1301.1390", "submitter": "Michael Fink", "authors": "Thomas Eiter, Michael Fink, Thomas Krennwallner, Christoph Redl, and\n  Peter Sch\\\"uller", "title": "Eliminating Unfounded Set Checking for HEX-Programs", "comments": "Proceedings of Answer Set Programming and Other Computing Paradigms\n  (ASPOCP 2012), 5th International Workshop, September 4, 2012, Budapest,\n  Hungary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  HEX-programs are an extension of the Answer Set Programming (ASP) paradigm\nincorporating external means of computation into the declarative programming\nlanguage through so-called external atoms. Their semantics is defined in terms\nof minimal models of the Faber-Leone-Pfeifer (FLP) reduct. Developing native\nsolvers for HEX-programs based on an appropriate notion of unfounded sets has\nbeen subject to recent research for reasons of efficiency. Although this has\nlead to an improvement over naive minimality checking using the FLP reduct,\ntesting for foundedness remains a computationally expensive task. In this work\nwe improve on HEX-program evaluation in this respect by identifying a syntactic\nclass of programs, that can be efficiently recognized and allows to entirely\nskip the foundedness check. Moreover, we develop criteria for decomposing a\nprogram into components, such that the search for unfounded sets can be\nrestricted. Observing that our results apply to many HEX-program applications\nprovides analytic evidence for the significance and effectiveness of our\napproach, which is complemented by a brief discussion of preliminary\nexperimental validation.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 02:29:22 GMT"}], "update_date": "2013-01-09", "authors_parsed": [["Eiter", "Thomas", ""], ["Fink", "Michael", ""], ["Krennwallner", "Thomas", ""], ["Redl", "Christoph", ""], ["Sch\u00fcller", "Peter", ""]]}, {"id": "1301.1391", "submitter": "Johannes Klaus Fichte", "authors": "Johannes Klaus Fichte and Stefan Szeider", "title": "Backdoors to Normality for Disjunctive Logic Programs", "comments": "A short version will appear in the Proceedings of the Proceedings of\n  the 27th AAAI Conference on Artificial Intelligence (AAAI'13). A preliminary\n  version of the paper was presented on the workshop Answer Set Programming and\n  Other Computing Paradigms (ASPOCP 2012), 5th International Workshop,\n  September 4, 2012, Budapest, Hungary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last two decades, propositional satisfiability (SAT) has become one\nof the most successful and widely applied techniques for the solution of\nNP-complete problems. The aim of this paper is to investigate theoretically how\nSat can be utilized for the efficient solution of problems that are harder than\nNP or co-NP. In particular, we consider the fundamental reasoning problems in\npropositional disjunctive answer set programming (ASP), Brave Reasoning and\nSkeptical Reasoning, which ask whether a given atom is contained in at least\none or in all answer sets, respectively. Both problems are located at the\nsecond level of the Polynomial Hierarchy and thus assumed to be harder than NP\nor co-NP. One cannot transform these two reasoning problems into SAT in\npolynomial time, unless the Polynomial Hierarchy collapses. We show that\ncertain structural aspects of disjunctive logic programs can be utilized to\nbreak through this complexity barrier, using new techniques from Parameterized\nComplexity. In particular, we exhibit transformations from Brave and Skeptical\nReasoning to SAT that run in time O(2^k n^2) where k is a structural parameter\nof the instance and n the input size. In other words, the reduction is\nfixed-parameter tractable for parameter k. As the parameter k we take the size\nof a smallest backdoor with respect to the class of normal (i.e.,\ndisjunction-free) programs. Such a backdoor is a set of atoms that when deleted\nmakes the program normal. In consequence, the combinatorial explosion, which is\nexpected when transforming a problem from the second level of the Polynomial\nHierarchy to the first level, can now be confined to the parameter k, while the\nrunning time of the reduction is polynomial in the input size n, where the\norder of the polynomial is independent of k.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 02:29:37 GMT"}, {"version": "v2", "created": "Thu, 2 May 2013 17:17:43 GMT"}], "update_date": "2013-05-06", "authors_parsed": [["Fichte", "Johannes Klaus", ""], ["Szeider", "Stefan", ""]]}, {"id": "1301.1392", "submitter": "Michael Fink", "authors": "Martin Gebser, Torsten Grote, Roland Kaminski, Philipp Obermeier,\n  Orkunt Sabuncu, and Torsten Schaub", "title": "Answer Set Programming for Stream Reasoning", "comments": "Proceedings of Answer Set Programming and Other Computing Paradigms\n  (ASPOCP 2012), 5th International Workshop, September 4, 2012, Budapest,\n  Hungary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advance of Internet and Sensor technology has brought about new\nchallenges evoked by the emergence of continuous data streams. Beyond rapid\ndata processing, application areas like ambient assisted living, robotics, or\ndynamic scheduling involve complex reasoning tasks. We address such scenarios\nand elaborate upon approaches to knowledge-intense stream reasoning, based on\nAnswer Set Programming (ASP). While traditional ASP methods are devised for\nsingular problem solving, we develop new techniques to formulate and process\nproblems dealing with emerging as well as expiring data in a seamless way.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 02:29:44 GMT"}], "update_date": "2013-01-09", "authors_parsed": [["Gebser", "Martin", ""], ["Grote", "Torsten", ""], ["Kaminski", "Roland", ""], ["Obermeier", "Philipp", ""], ["Sabuncu", "Orkunt", ""], ["Schaub", "Torsten", ""]]}, {"id": "1301.1393", "submitter": "Michael Fink", "authors": "Joohyung Lee and Yunsong Meng", "title": "Two New Definitions of Stable Models of Logic Programs with Generalized\n  Quantifiers", "comments": "Proceedings of Answer Set Programming and Other Computing Paradigms\n  (ASPOCP 2012), 5th International Workshop, September 4, 2012, Budapest,\n  Hungary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present alternative definitions of the first-order stable model semantics\nand its extension to incorporate generalized quantifiers by referring to the\nfamiliar notion of a reduct instead of referring to the SM operator in the\noriginal definitions. Also, we extend the FLP stable model semantics to allow\ngeneralized quantifiers by referring to an operator that is similar to the\n$\\sm$ operator. For a reasonable syntactic class of logic programs, we show\nthat the two stable model semantics of generalized quantifiers are\ninterchangeable.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 02:29:49 GMT"}], "update_date": "2013-01-09", "authors_parsed": [["Lee", "Joohyung", ""], ["Meng", "Yunsong", ""]]}, {"id": "1301.1394", "submitter": "Michael Fink", "authors": "Vladimir Lifschitz and Fangkai Yang", "title": "Lloyd-Topor Completion and General Stable Models", "comments": "Proceedings of Answer Set Programming and Other Computing Paradigms\n  (ASPOCP 2012), 5th International Workshop, September 4, 2012, Budapest,\n  Hungary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the relationship between the generalization of program\ncompletion defined in 1984 by Lloyd and Topor and the generalization of the\nstable model semantics introduced recently by Ferraris et al. The main theorem\ncan be used to characterize, in some cases, the general stable models of a\nlogic program by a first-order formula. The proof uses Truszczynski's stable\nmodel semantics of infinitary propositional formulas.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 02:29:55 GMT"}], "update_date": "2013-01-09", "authors_parsed": [["Lifschitz", "Vladimir", ""], ["Yang", "Fangkai", ""]]}, {"id": "1301.1395", "submitter": "Michael Fink", "authors": "Joost Vennekens and Marc Denecker", "title": "Extending FO(ID) with Knowledge Producing Definitions: Preliminary\n  Results", "comments": "Proceedings of Answer Set Programming and Other Computing Paradigms\n  (ASPOCP 2012), 5th International Workshop, September 4, 2012, Budapest,\n  Hungary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous research into the relation between ASP and classical logic has\nidentified at least two different ways in which the former extends the latter.\nFirst, ASP program typically contain sets of rules that can be naturally\ninterpreted as inductive definitions, and the language FO(ID) has shown that\nsuch inductive definitions can elegantly be added to classical logic in a\nmodular way. Second, there is of course also the well-known epistemic component\nof ASP, which was mainly emphasized in the early papers on stable model\nsemantics. To investigate whether this kind of knowledge can also, and in a\nsimilarly modular way, be added to classical logic, the language of Ordered\nEpistemic Logic was presented in recent work. However, this logic views the\nepistemic component as entirely separate from the inductive definition\ncomponent, thus ignoring any possible interplay between the two. In this paper,\nwe present a language that extends the inductive definition construct found in\nFO(ID) with an epistemic component, making such interplay possible. The\neventual goal of this work is to discover whether it is really appropriate to\nview the epistemic component and the inductive definition component of ASP as\ntwo separate extensions of classical logic, or whether there is also something\nof importance in the combination of the two.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 02:30:01 GMT"}], "update_date": "2013-01-09", "authors_parsed": [["Vennekens", "Joost", ""], ["Denecker", "Marc", ""]]}, {"id": "1301.1444", "submitter": "Julia Mortera", "authors": "Julia Mortera, Paola Vicard, Cecilia Vergari", "title": "Object-oriented Bayesian networks for a decision support system for\n  antitrust enforcement", "comments": "Published in at http://dx.doi.org/10.1214/12-AOAS625 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2013, Vol. 7, No. 2, 714-738", "doi": "10.1214/12-AOAS625", "report-no": "IMS-AOAS-AOAS625", "categories": "cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an economic decision problem where the actors are two firms and the\nAntitrust Authority whose main task is to monitor and prevent firms' potential\nanti-competitive behaviour and its effect on the market. The Antitrust\nAuthority's decision process is modelled using a Bayesian network where both\nthe relational structure and the parameters of the model are estimated from a\ndata set provided by the Authority itself. A number of economic variables that\ninfluence this decision process are also included in the model. We analyse how\nmonitoring by the Antitrust Authority affects firms' strategies about\ncooperation. Firms' strategies are modelled as a repeated prisoner's dilemma\nusing object-oriented Bayesian networks. We show how the integration of firms'\ndecision process and external market information can be modelled in this way.\nVarious decision scenarios and strategies are illustrated.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 08:54:26 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2013 10:03:42 GMT"}], "update_date": "2013-12-09", "authors_parsed": [["Mortera", "Julia", ""], ["Vicard", "Paola", ""], ["Vergari", "Cecilia", ""]]}, {"id": "1301.1502", "submitter": "Hannah Inbarani", "authors": "N. Kalaiselvi, H. Hannah Inbarani", "title": "Fuzzy Soft Set Based Classification for Gene Expression Data", "comments": "7 pages, IJSER Vol.3 Issue: 10 Oct 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification is one of the major issues in Data Mining Research fields. The\nclassification problems in medical area often classify medical dataset based on\nthe result of medical diagnosis or description of medical treatment by the\nmedical practitioner. This research work discusses the classification process\nof Gene Expression data for three different cancers which are breast cancer,\nlung cancer and leukemia cancer with two classes which are cancerous stage and\nnon cancerous stage. We have applied a fuzzy soft set similarity based\nclassifier to enhance the accuracy to predict the stages among cancer genes and\nthe informative genes are selected by using Entopy filtering.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 11:48:49 GMT"}], "update_date": "2013-01-09", "authors_parsed": [["Kalaiselvi", "N.", ""], ["Inbarani", "H. Hannah", ""]]}, {"id": "1301.1753", "submitter": "Vaibhav Godbole", "authors": "Vaibhav Godbole", "title": "FCA - An Approach On LEACH Protocol Of Wireless Sensor Networks Using\n  Fuzzy Logic", "comments": "This paper is withdrawn due to mistakes in the figure captions", "journal-ref": "International Journal of Computer Communications and Networks\n  (IJCCN),Vol.2, No.3, pp.1-13, December 2012", "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to gather information more efficiently, wireless sensor networks are\npartitioned into clusters. The most of the proposed clustering algorithms do\nnot consider the location of the base station. This situation causes hot spots\nproblem in multi-hop wireless sensor networks. In this paper, we propose a\nfuzzy clustering algorithm (FCA) which aims to prolong the lifetime of wireless\nsensor networks. FCA adjusts the cluster-head radius considering the residual\nenergy and the distance to the base station parameters of the sensor nodes.\nThis helps decreasing the intra-cluster work of the sensor nodes which are\ncloser to the base station or have lower battery level. We utilize fuzzy logic\nfor handling the uncertainties in cluster-head radius estimation. We compare\nour algorithm with LEACH according to first node dies, half of the nodes alive\nand energy-efficiency metrics. Our simulation results show that FCA performs\nbetter than other algorithms in most of the cases. Therefore, our proposed\nalgorithm is a stable and energy-efficient clustering algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2013 05:27:34 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2013 14:23:09 GMT"}], "update_date": "2013-01-17", "authors_parsed": [["Godbole", "Vaibhav", ""]]}, {"id": "1301.1932", "submitter": "P. Mahesha", "authors": "P. Mahesha and D. S. Vinod", "title": "An Approach for Classification of Dysfluent and Fluent Speech Using K-NN\n  And SVM", "comments": "10 pages,4 figures; International Journal of Computer Science,\n  Engineering and Applications (IJCSEA) Vol.2, No.6, December 2012", "journal-ref": null, "doi": "10.5121/ijcsea.2012.2603", "report-no": null, "categories": "cs.SD cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new approach for classification of dysfluent and fluent\nspeech using Mel-Frequency Cepstral Coefficient (MFCC). The speech is fluent\nwhen person's speech flows easily and smoothly. Sounds combine into syllable,\nsyllables mix together into words and words link into sentences with little\neffort. When someone's speech is dysfluent, it is irregular and does not flow\neffortlessly. Therefore, a dysfluency is a break in the smooth, meaningful flow\nof speech. Stuttering is one such disorder in which the fluent flow of speech\nis disrupted by occurrences of dysfluencies such as repetitions, prolongations,\ninterjections and so on. In this work we have considered three types of\ndysfluencies such as repetition, prolongation and interjection to characterize\ndysfluent speech. After obtaining dysfluent and fluent speech, the speech\nsignals are analyzed in order to extract MFCC features. The k-Nearest Neighbor\n(k-NN) and Support Vector Machine (SVM) classifiers are used to classify the\nspeech as dysfluent and fluent speech. The 80% of the data is used for training\nand 20% for testing. The average accuracy of 86.67% and 93.34% is obtained for\ndysfluent and fluent speech respectively.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2013 17:42:59 GMT"}], "update_date": "2013-01-10", "authors_parsed": [["Mahesha", "P.", ""], ["Vinod", "D. S.", ""]]}, {"id": "1301.1950", "submitter": "Bogdan Patrut", "authors": "Bogdan Patrut", "title": "Syntactic Analysis Based on Morphological Characteristic Features of the\n  Romanian Language", "comments": "13 pages, 3 figures, DIASEXP, International Journal on Natural\n  Language Computing, 2012, Volume 1, Number 4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper refers to the syntactic analysis of phrases in Romanian, as an\nimportant process of natural language processing. We will suggest a real-time\nsolution, based on the idea of using some words or groups of words that\nindicate grammatical category; and some specific endings of some parts of\nsentence. Our idea is based on some characteristics of the Romanian language,\nwhere some prepositions, adverbs or some specific endings can provide a lot of\ninformation about the structure of a complex sentence. Such characteristics can\nbe found in other languages, too, such as French. Using a special grammar, we\ndeveloped a system (DIASEXP) that can perform a dialogue in natural language\nwith assertive and interogative sentences about a \"story\" (a set of sentences\ndescribing some events from the real life).\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2013 19:17:31 GMT"}], "update_date": "2013-01-10", "authors_parsed": [["Patrut", "Bogdan", ""]]}, {"id": "1301.2005", "submitter": "Xiaowang Zhang", "authors": "Xiaowang Zhang and Kewen Wang and Zhe Wang and Yue Ma and Guilin Qi", "title": "A Distance-based Paraconsistent Semantics for DL-Lite", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DL-Lite is an important family of description logics. Recently, there is an\nincreasing interest in handling inconsistency in DL-Lite as the constraint\nimposed by a TBox can be easily violated by assertions in ABox in DL-Lite. In\nthis paper, we present a distance-based paraconsistent semantics based on the\nnotion of feature in DL-Lite, which provides a novel way to rationally draw\nmeaningful conclusions even from an inconsistent knowledge base. Finally, we\ninvestigate several important logical properties of this entailment relation\nbased on the new semantics and show its promising advantages in non-monotonic\nreasoning for DL-Lite.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2013 23:02:34 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2013 14:57:25 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2015 07:03:58 GMT"}], "update_date": "2015-06-04", "authors_parsed": [["Zhang", "Xiaowang", ""], ["Wang", "Kewen", ""], ["Wang", "Zhe", ""], ["Ma", "Yue", ""], ["Qi", "Guilin", ""]]}, {"id": "1301.2137", "submitter": "Xiaowang Zhang", "authors": "Dai Xu and Xiaowang Zhang and Zuoquan Lin", "title": "A Forgetting-based Approach to Merging Knowledge Bases", "comments": "5 pages", "journal-ref": "2010 International Conference on Progress in Informatics and\n  Computing, IEEE Computer Society, vol 1, pp. 321-325", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach based on variable forgetting, which is a\nuseful tool in resolving contradictory by filtering some given variables, to\nmerging multiple knowledge bases. This paper first builds a relationship\nbetween belief merging and variable forgetting by using dilation. Variable\nforgetting is applied to capture belief merging operation. Finally, some new\nmerging operators are developed by modifying candidate variables to amend the\nshortage of traditional merging operators. Different from model selection of\ntraditional merging operators, as an alternative approach, variable selection\nin those new operators could provide intuitive information about an atom\nvariable among whole knowledge bases.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 14:41:52 GMT"}], "update_date": "2013-01-11", "authors_parsed": [["Xu", "Dai", ""], ["Zhang", "Xiaowang", ""], ["Lin", "Zuoquan", ""]]}, {"id": "1301.2146", "submitter": "Xiaowang Zhang", "authors": "Xiaowang Zhang and Guohui Xiao and Zuoquan Lin", "title": "A Paraconsistent Tableau Algorithm Based on Sign Transformation in\n  Semantic Web", "comments": "11 pages, in Chinese; the 4th Chinese Semantic Web Symposium (CSWS\n  2010), Beijing, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an open, constantly changing and collaborative environment like the\nforthcoming Semantic Web, it is reasonable to expect that knowledge sources\nwill contain noise and inaccuracies. It is well known, as the logical\nfoundation of the Semantic Web, description logic is lack of the ability of\ntolerating inconsistent or incomplete data. Recently, the ability of\nparaconsistent approaches in Semantic Web is weaker in this paper, we present a\ntableau algorithm based on sign transformation in Semantic Web which holds the\nstronger ability of reasoning. We prove that the tableau algorithm is decidable\nwhich hold the same function of classical tableau algorithm for consistent\nknowledge bases.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 15:07:22 GMT"}], "update_date": "2013-01-11", "authors_parsed": [["Zhang", "Xiaowang", ""], ["Xiao", "Guohui", ""], ["Lin", "Zuoquan", ""]]}, {"id": "1301.2158", "submitter": "Casey Bennett", "authors": "Casey C. Bennett, Kris Hauser", "title": "Artificial Intelligence Framework for Simulating Clinical\n  Decision-Making: A Markov Decision Process Approach", "comments": "Keywords: Markov Decision Process; Dynamic Decision Network;\n  Multi-Agent System; Clinical Artificial Intelligence; Medical Decision\n  Making; Chronic Illness; (2013) Artificial Intelligence in Medicine", "journal-ref": "Artificial Intelligence in Medicine. 57(1): 9-19. (2013)", "doi": "10.1016/j.artmed.2012.12.003", "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the modern healthcare system, rapidly expanding costs/complexity, the\ngrowing myriad of treatment options, and exploding information streams that\noften do not effectively reach the front lines hinder the ability to choose\noptimal treatment decisions over time. The goal in this paper is to develop a\ngeneral purpose (non-disease-specific) computational/artificial intelligence\n(AI) framework to address these challenges. This serves two potential\nfunctions: 1) a simulation environment for exploring various healthcare\npolicies, payment methodologies, etc., and 2) the basis for clinical artificial\nintelligence - an AI that can think like a doctor. This approach combines\nMarkov decision processes and dynamic decision networks to learn from clinical\ndata and develop complex plans via simulation of alternative sequential\ndecision paths while capturing the sometimes conflicting, sometimes synergistic\ninteractions of various components in the healthcare system. It can operate in\npartially observable environments (in the case of missing observations or data)\nby maintaining belief states about patient health status and functions as an\nonline agent that plans and re-plans. This framework was evaluated using real\npatient data from an electronic health record. Such an AI framework easily\noutperforms the current treatment-as-usual (TAU) case-rate/fee-for-service\nmodels of healthcare (Cost per Unit Change: $189 vs. $497) while obtaining a\n30-35% increase in patient outcomes. Tweaking certain model parameters further\nenhances this advantage, obtaining roughly 50% more improvement for roughly\nhalf the costs. Given careful design and problem formulation, an AI simulation\nframework can approximate optimal decisions even in complex and uncertain\nenvironments. Future work is described that outlines potential lines of\nresearch and integration of machine learning algorithms for personalized\nmedicine.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 15:29:59 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Bennett", "Casey C.", ""], ["Hauser", "Kris", ""]]}, {"id": "1301.2215", "submitter": "Michael Fink", "authors": "Michael Fink and Yuliya Lierler", "title": "Proceedings of Answer Set Programming and Other Computing Paradigms\n  (ASPOCP 2012), 5th International Workshop, September 4, 2012, Budapest,\n  Hungary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the papers presented at the fifth workshop on Answer Set\nProgramming and Other Computing Paradigms (ASPOCP 2012) held on September 4th,\n2012 in Budapest, co-located with the 28th International Conference on Logic\nProgramming (ICLP 2012). It thus continues a series of previous events\nco-located with ICLP, aiming at facilitating the discussion about crossing the\nboundaries of current ASP techniques in theory, solving, and applications, in\ncombination with or inspired by other computing paradigms.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 18:52:32 GMT"}], "update_date": "2013-01-11", "authors_parsed": [["Fink", "Michael", ""], ["Lierler", "Yuliya", ""]]}, {"id": "1301.2253", "submitter": "Eyal Amir", "authors": "Eyal Amir", "title": "Efficient Approximation for Triangulation of Minimum Treewidth", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-7-15", "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present four novel approximation algorithms for finding triangulation of\nminimum treewidth. Two of the algorithms improve on the running times of\nalgorithms by Robertson and Seymour, and Becker and Geiger that approximate the\noptimum by factors of 4 and 3 2/3, respectively. A third algorithm is faster\nthan those but gives an approximation factor of 4 1/2. The last algorithm is\nyet faster, producing factor-O(lg/k) approximations in polynomial time. Finding\ntriangulations of minimum treewidth for graphs is central to many problems in\ncomputer science. Real-world problems in artificial intelligence, VLSI design\nand databases are efficiently solvable if we have an efficient approximation\nalgorithm for them. We report on experimental results confirming the\neffectiveness of our algorithms for large graphs associated with real-world\nproblems.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:22:23 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Amir", "Eyal", ""]]}, {"id": "1301.2254", "submitter": "Nicos Angelopoulos", "authors": "Nicos Angelopoulos, James Cussens", "title": "Markov Chain Monte Carlo using Tree-Based Priors on Model Structure", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-16-23", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general framework for defining priors on model structure and\nsampling from the posterior using the Metropolis-Hastings algorithm. The key\nidea is that structure priors are defined via a probability tree and that the\nproposal mechanism for the Metropolis-Hastings algorithm operates by traversing\nthis tree, thereby defining a cheaply computable acceptance probability. We\nhave applied this approach to Bayesian net structure learning using a number of\npriors and tree traversal strategies. Our results show that these must be\nchosen appropriately for this approach to be successful.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:22:27 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Angelopoulos", "Nicos", ""], ["Cussens", "James", ""]]}, {"id": "1301.2255", "submitter": "Salem Benferhat", "authors": "Salem Benferhat, Didier Dubois, Souhila Kaci, Henri Prade", "title": "Graphical readings of possibilistic logic bases", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-24-31", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Possibility theory offers either a qualitive, or a numerical framework for\nrepresenting uncertainty, in terms of dual measures of possibility and\nnecessity. This leads to the existence of two kinds of possibilistic causal\ngraphs where the conditioning is either based on the minimum, or the product\noperator. Benferhat et al. (1999) have investigated the connections between\nmin-based graphs and possibilistic logic bases (made of classical formulas\nweighted in terms of certainty). This paper deals with a more difficult issue :\nthe product-based graphical representations of possibilistic bases, which\nprovides an easy structural reading of possibilistic bases. Moreover, this\npaper also provides another reading of possibilistic bases in terms of\ncomparative preferences of the form \"in the context p, q is preferred to not\nq\". This enables us to explicit preferences underlying a set of goals with\ndifferent levels of priority.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:22:32 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Benferhat", "Salem", ""], ["Dubois", "Didier", ""], ["Kaci", "Souhila", ""], ["Prade", "Henri", ""]]}, {"id": "1301.2256", "submitter": "Hans L. Bodlaender", "authors": "Hans L. Bodlaender, Arie M.C.A. Koster, Frank van den Eijkhof, Linda\n  C. van der Gaag", "title": "Pre-processing for Triangulation of Probabilistic Networks", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-32-39", "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The currently most efficient algorithm for inference with a probabilistic\nnetwork builds upon a triangulation of a network's graph. In this paper, we\nshow that pre-processing can help in finding good triangulations\nforprobabilistic networks, that is, triangulations with a minimal maximum\nclique size. We provide a set of rules for stepwise reducing a graph, without\nlosing optimality. This reduction allows us to solve the triangulation problem\non a smaller graph. From the smaller graph's triangulation, a triangulation of\nthe original graph is obtained by reversing the reduction steps. Our\nexperimental results show that the graphs of some well-known real-life\nprobabilistic networks can be triangulated optimally just by preprocessing; for\nother networks, huge reductions in their graph's size are obtained.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:22:36 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Bodlaender", "Hans L.", ""], ["Koster", "Arie M. C. A.", ""], ["Eijkhof", "Frank van den", ""], ["van der Gaag", "Linda C.", ""]]}, {"id": "1301.2257", "submitter": "Blai Bonet", "authors": "Blai Bonet", "title": "A Calculus for Causal Relevance", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-40-47", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a sound and completecalculus for causal relevance, based\nonPearl's functional models semantics.The calculus consists of axioms and\nrulesof inference for reasoning about causalrelevance relationships.We extend\nthe set of known axioms for causalrelevance with three new axioms, andintroduce\ntwo new rules of inference forreasoning about specific subclasses\nofmodels.These subclasses give a more refinedcharacterization of causal models\nthan the one given in Halpern's axiomatizationof counterfactual\nreasoning.Finally, we show how the calculus for causalrelevance can be used in\nthe task ofidentifying causal structure from non-observational data.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:22:40 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Bonet", "Blai", ""]]}, {"id": "1301.2258", "submitter": "Blai Bonet", "authors": "Blai Bonet", "title": "Instrumentality Tests Revisited", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-48-55", "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An instrument is a random variable thatallows the identification of\nparameters inlinear models when the error terms arenot uncorrelated.It is a\npopular method used in economicsand the social sciences that reduces theproblem\nof identification to the problemof finding the appropriate instruments.Few\nyears ago, Pearl introduced a necessarytest for instruments that allows the\nresearcher to discard those candidatesthat fail the test.In this paper, we make\na detailed study of Pearl's test and the general model forinstruments. The\nresults of this studyinclude a novel interpretation of Pearl'stest, a general\ntheory of instrumentaltests, and an affirmative answer to aprevious conjecture.\nWe also presentnew instrumentality tests for the casesof discrete and\ncontinuous variables.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:22:44 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Bonet", "Blai", ""]]}, {"id": "1301.2259", "submitter": "Craig Boutilier", "authors": "Craig Boutilier, Fahiem Bacchus, Ronen I. Brafman", "title": "UCP-Networks: A Directed Graphical Representation of Conditional\n  Utilities", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-56-64", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new directed graphical representation of utility functions,\ncalled UCP-networks, that combines aspects of two existing graphical models:\ngeneralized additive models and CP-networks. The network decomposes a utility\nfunction into a number of additive factors, with the directionality of the arcs\nreflecting conditional dependence of preference statements - in the underlying\n(qualitative) preference ordering - under a {em ceteris paribus} (all else\nbeing equal) interpretation. This representation is arguably natural in many\nsettings. Furthermore, the strong CP-semantics ensures that computation of\noptimization and dominance queries is very efficient. We also demonstrate the\nvalue of this representation in decision making. Finally, we describe an\ninteractive elicitation procedure that takes advantage of the linear nature of\nthe constraints on \"`tradeoff weights\" imposed by a UCP-network. This procedure\nallows the network to be refined until the regret of the decision with minimax\nregret (with respect to the incompletely specified utility function) falls\nbelow a specified threshold (e.g., the cost of further questioning.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:22:49 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Boutilier", "Craig", ""], ["Bacchus", "Fahiem", ""], ["Brafman", "Ronen I.", ""]]}, {"id": "1301.2260", "submitter": "Jian Cheng", "authors": "Jian Cheng, Marek J. Druzdzel", "title": "Confidence Inference in Bayesian Networks", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-75-82", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two sampling algorithms for probabilistic confidence inference in\nBayesian networks. These two algorithms (we call them AIS-BN-mu and\nAIS-BN-sigma algorithms) guarantee that estimates of posterior probabilities\nare with a given probability within a desired precision bound. Our algorithms\nare based on recent advances in sampling algorithms for (1) estimating the mean\nof bounded random variables and (2) adaptive importance sampling in Bayesian\nnetworks. In addition to a simple stopping rule for sampling that they provide,\nthe AIS-BN-mu and AIS-BN-sigma algorithms are capable of guiding the learning\nprocess in the AIS-BN algorithm. An empirical evaluation of the proposed\nalgorithms shows excellent performance, even for very unlikely evidence.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:22:53 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Cheng", "Jian", ""], ["Druzdzel", "Marek J.", ""]]}, {"id": "1301.2261", "submitter": "Tianjiao Chu", "authors": "Tianjiao Chu, Richard Scheines, Peter L. Spirtes", "title": "Semi-Instrumental Variables: A Test for Instrument Admissibility", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-83-90", "categories": "stat.ME cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a causal graphical model, an instrument for a variable X and its effect Y\nis a random variable that is a cause of X and independent of all the causes of\nY except X. (Pearl (1995), Spirtes et al (2000)). Instrumental variables can be\nused to estimate how the distribution of an effect will respond to a\nmanipulation of its causes, even in the presence of unmeasured common causes\n(confounders). In typical instrumental variable estimation, instruments are\nchosen based on domain knowledge. There is currently no statistical test for\nvalidating a variable as an instrument. In this paper, we introduce the concept\nof semi-instrument, which generalizes the concept of instrument. We show that\nin the framework of additive models, under certain conditions, we can test\nwhether a variable is semi-instrumental. Moreover, adding some distribution\nassumptions, we can test whether two semi-instruments are instrumental. We give\nalgorithms to estimate the p-value that a random variable is semi-instrumental,\nand the p-value that two semi-instruments are both instrumental. These\nalgorithms can be used to test the experts' choice of instruments, or to\nidentify instruments automatically.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:22:57 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Chu", "Tianjiao", ""], ["Scheines", "Richard", ""], ["Spirtes", "Peter L.", ""]]}, {"id": "1301.2262", "submitter": "Robert G. Cowell", "authors": "Robert G. Cowell", "title": "Conditions Under Which Conditional Independence and Scoring Methods Lead\n  to Identical Selection of Bayesian Network Models", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-91-97", "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is often stated in papers tackling the task of inferring Bayesian network\nstructures from data that there are these two distinct approaches: (i) Apply\nconditional independence tests when testing for the presence or otherwise of\nedges; (ii) Search the model space using a scoring metric. Here I argue that\nfor complete data and a given node ordering this division is a myth, by showing\nthat cross entropy methods for checking conditional independence are\nmathematically identical to methods based upon discriminating between models by\ntheir overall goodness-of-fit logarithmic scores.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:23:01 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Cowell", "Robert G.", ""]]}, {"id": "1301.2263", "submitter": "David Danks", "authors": "David Danks, Clark Glymour", "title": "Linearity Properties of Bayes Nets with Binary Variables", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-98-104", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is \"well known\" that in linear models: (1) testable constraints on the\nmarginal distribution of observed variables distinguish certain cases in which\nan unobserved cause jointly influences several observed variables; (2) the\ntechnique of \"instrumental variables\" sometimes permits an estimation of the\ninfluence of one variable on another even when the association between the\nvariables may be confounded by unobserved common causes; (3) the association\n(or conditional probability distribution of one variable given another) of two\nvariables connected by a path or trek can be computed directly from the\nparameter values associated with each edge in the path or trek; (4) the\nassociation of two variables produced by multiple treks can be computed from\nthe parameters associated with each trek; and (5) the independence of two\nvariables conditional on a third implies the corresponding independence of the\nsums of the variables over all units conditional on the sums over all units of\neach of the original conditioning variables.These properties are exploited in\nsearch procedures. It is also known that properties (2)-(5) do not hold for all\nBayes nets with binary variables. We show that (1) holds for all Bayes nets\nwith binary variables and (5) holds for all singly trek-connected Bayes nets of\nthat kind. We further show that all five properties hold for Bayes nets with\nany DAG and binary variables parameterized with noisy-or and noisy-and gates.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:23:05 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Danks", "David", ""], ["Glymour", "Clark", ""]]}, {"id": "1301.2264", "submitter": "Gary A. Davis", "authors": "Gary A. Davis", "title": "Using Bayesian Networks to Identify the Causal Effect of Speeding in\n  Individual Vehicle/Pedestrian Collisions", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-105-111", "categories": "cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On roads showing significant violations of posted speed limits, one measure\nof the safety effect of speeding is the difference between the road's actual\naccident count and the count that would have occurred if the posted speed limit\nhad been strictly obeyed. An estimate of this accident reduction can be had by\ncomputing the probability that speeding was a necessary condition for each of\nset of accidents. This is an instance of assessing individual probabilities of\ncausation, which is generally not possible absent prior knowledge of causal\nstructure. For traffic accidents such prior knowledge is often available and\nthis paper illustrates how, for a commonly occurring class of\nvehicle/pedestrian accidents, approaches to uncertainty and causal analyses\nappearing in the accident reconstruction literature can be unified using\nBayesian networks. Measured skidmarks, pedestrian throw distances, and\npedestrian injury severity are treated as evidence, and using the Gibbs\nSampling routine BUGS, the posterior probability distribution over exogenous\nvariables, such as the vehicle's initial speed, location, and driver reaction\ntime, is computed. This posterior distribution is then used to compute the\n\"probability of necessity\" for speeding.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:23:09 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Davis", "Gary A.", ""]]}, {"id": "1301.2265", "submitter": "Rina Dechter", "authors": "Rina Dechter, David Ephraim Larkin", "title": "Hybrid Processing of Beliefs and Constraints", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-112-119", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores algorithms for processing probabilistic and deterministic\ninformation when the former is represented as a belief network and the latter\nas a set of boolean clauses. The motivating tasks are 1. evaluating beliefs\nnetworks having a large number of deterministic relationships and2. evaluating\nprobabilities of complex boolean querie over a belief network. We propose a\nparameterized family of variable elimination algorithms that exploit both types\nof information, and that allows varying levels of constraint propagation\ninferences. The complexity of the scheme is controlled by the induced-width of\nthe graph {em augmented} by the dependencies introduced by the boolean\nconstraints. Preliminary empirical evaluation demonstrate the effect of\nconstraint propagation on probabilistic computation.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:23:13 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Dechter", "Rina", ""], ["Larkin", "David Ephraim", ""]]}, {"id": "1301.2267", "submitter": "Amol Deshpande", "authors": "Amol Deshpande, Minos Garofalakis, Michael I. Jordan", "title": "Efficient Stepwise Selection in Decomposable Models", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-128-135", "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an efficient way of performing stepwise selection\nin the class of decomposable models. The main contribution of the paper is a\nsimple characterization of the edges that canbe added to a decomposable model\nwhile keeping the resulting model decomposable and an efficient algorithm for\nenumerating all such edges for a given model in essentially O(1) time per edge.\nWe also discuss how backward selection can be performed efficiently using our\ndata structures.We also analyze the complexity of the complete stepwise\nselection procedure, including the complexity of choosing which of the eligible\ndges to add to (or delete from) the current model, with the aim ofminimizing\nthe Kullback-Leibler distance of the resulting model from the saturated model\nfor the data.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:23:22 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Deshpande", "Amol", ""], ["Garofalakis", "Minos", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1301.2268", "submitter": "Tal El-Hay", "authors": "Tal El-Hay, Nir Friedman", "title": "Incorporating Expressive Graphical Models in Variational Approximations:\n  Chain-Graphs and Hidden Variables", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-136-143", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global variational approximation methods in graphical models allow efficient\napproximate inference of complex posterior distributions by using a simpler\nmodel. The choice of the approximating model determines a tradeoff between the\ncomplexity of the approximation procedure and the quality of the approximation.\nIn this paper, we consider variational approximations based on two classes of\nmodels that are richer than standard Bayesian networks, Markov networks or\nmixture models. As such, these classes allow to find better tradeoffs in the\nspectrum of approximations. The first class of models are chain graphs, which\ncapture distributions that are partially directed. The second class of models\nare directed graphs (Bayesian networks) with additional latent variables. Both\nclasses allow representation of multi-variable dependencies that cannot be\neasily represented within a Bayesian network.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:23:26 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["El-Hay", "Tal", ""], ["Friedman", "Nir", ""]]}, {"id": "1301.2269", "submitter": "Gal Elidan", "authors": "Gal Elidan, Nir Friedman", "title": "Learning the Dimensionality of Hidden Variables", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-144-151", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A serious problem in learning probabilistic models is the presence of hidden\nvariables. These variables are not observed, yet interact with several of the\nobserved variables. Detecting hidden variables poses two problems: determining\nthe relations to other variables in the model and determining the number of\nstates of the hidden variable. In this paper, we address the latter problem in\nthe context of Bayesian networks. We describe an approach that utilizes a\nscore-based agglomerative state-clustering. As we show, this approach allows us\nto efficiently evaluate models with a range of cardinalities for the hidden\nvariable. We show how to extend this procedure to deal with multiple\ninteracting hidden variables. We demonstrate the effectiveness of this approach\nby evaluating it on synthetic and real-life data. We show that our approach\nlearns models with hidden variables that generalize better and have better\nstructure than previous approaches.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:23:30 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Elidan", "Gal", ""], ["Friedman", "Nir", ""]]}, {"id": "1301.2270", "submitter": "Nir Friedman", "authors": "Nir Friedman, Ori Mosenzon, Noam Slonim, Naftali Tishby", "title": "Multivariate Information Bottleneck", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-152-161", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Information bottleneck method is an unsupervised non-parametric data\norganization technique. Given a joint distribution P(A,B), this method\nconstructs a new variable T that extracts partitions, or clusters, over the\nvalues of A that are informative about B. The information bottleneck has\nalready been applied to document classification, gene expression, neural code,\nand spectral analysis. In this paper, we introduce a general principled\nframework for multivariate extensions of the information bottleneck method.\nThis allows us to consider multiple systems of data partitions that are\ninter-related. Our approach utilizes Bayesian networks for specifying the\nsystems of clusters and what information each captures. We show that this\nconstruction provides insight about bottleneck variations and enables us to\ncharacterize solutions of these variations. We also present a general framework\nfor iterative algorithms for constructing solutions, and apply it to several\nexamples.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:23:36 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Friedman", "Nir", ""], ["Mosenzon", "Ori", ""], ["Slonim", "Noam", ""], ["Tishby", "Naftali", ""]]}, {"id": "1301.2271", "submitter": "Phan H. Giang", "authors": "Phan H. Giang, Prakash P. Shenoy", "title": "A Comparison of Axiomatic Approaches to Qualitative Decision Making\n  Using Possibility Theory", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-162-170", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we analyze two recent axiomatic approaches proposed by Dubois\net al and by Giang and Shenoy to qualitative decision making where uncertainty\nis described by possibility theory. Both axiomtizations are inspired by von\nNeumann and Morgenstern's system of axioms for the case of probability theory.\nWe show that our approach naturally unifies two axiomatic systems that\ncorrespond respectively to pessimistic and optimistic decision criteria\nproposed by Dubois et al. The simplifying unification is achieved by (i)\nreplacing axioms that are supposed to reflect two informational attitudes\n(uncertainty aversion and uncertainty attraction) by an axiom that imposes\norder on set of standard lotteries and (ii) using a binary utility scale in\nwhich each utility level is represented by a pair of numbers.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:23:40 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Giang", "Phan H.", ""], ["Shenoy", "Prakash P.", ""]]}, {"id": "1301.2272", "submitter": "Steven B. Gillispie", "authors": "Steven B. Gillispie, Michael D. Perlman", "title": "Enumerating Markov Equivalence Classes of Acyclic Digraph Models", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-171-177", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphical Markov models determined by acyclic digraphs (ADGs), also called\ndirected acyclic graphs (DAGs), are widely studied in statistics, computer\nscience (as Bayesian networks), operations research (as influence diagrams),\nand many related fields. Because different ADGs may determine the same Markov\nequivalence class, it long has been of interest to determine the efficiency\ngained in model specification and search by working directly with Markov\nequivalence classes of ADGs rather than with ADGs themselves. A computer\nprogram was written to enumerate the equivalence classes of ADG models as\nspecified by Pearl & Verma's equivalence criterion. The program counted\nequivalence classes for models up to and including 10 vertices. The ratio of\nnumber of classes to ADGs appears to approach an asymptote of about 0.267.\nClasses were analyzed according to number of edges and class size. By edges,\nthe distribution of number of classes approaches a Gaussian shape. By class\nsize, classes of size 1 are most common, with the proportions for larger sizes\ninitially decreasing but then following a more irregular pattern. The maximum\nnumber of classes generated by any undirected graph was found to increase\napproximately factorially. The program also includes a new variation of orderly\nalgorithm for generating undirected graphs.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:23:44 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Gillispie", "Steven B.", ""], ["Perlman", "Michael D.", ""]]}, {"id": "1301.2273", "submitter": "Carlos E. Guestrin", "authors": "Carlos E. Guestrin, Dirk Ormoneit", "title": "Robust Combination of Local Controllers", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-178-185", "categories": "cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning problems are hard, motion planning, for example, isPSPACE-hard. Such\nproblems are even more difficult in the presence of uncertainty. Although,\nMarkov Decision Processes (MDPs) provide a formal framework for such problems,\nfinding solutions to high dimensional continuous MDPs is usually difficult,\nespecially when the actions and time measurements are continuous. Fortunately,\nproblem-specific knowledge allows us to design controllers that are good\nlocally, though having no global guarantees. We propose a method of\nnonparametrically combining local controllers to obtain globally good\nsolutions. We apply this formulation to two types of problems : motion planning\n(stochastic shortest path) and discounted MDPs. For motion planning, we argue\nthat usual MDP optimality criterion (expected cost) may not be practically\nrelevant. Wepropose an alternative: finding the minimum cost path,subject to\nthe constraint that the robot must reach the goal withhigh probability. For\nthis problem, we prove that a polynomial number of samples is sufficient to\nobtain a high probability path. For discounted MDPs, we propose a formulation\nthat explicitly deals with model uncertainty, i.e., the problem introduced when\ntransition probabilities are not known exactly. We formulate the problem as a\nrobust linear program which directly incorporates this type of uncertainty.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:23:48 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Guestrin", "Carlos E.", ""], ["Ormoneit", "Dirk", ""]]}, {"id": "1301.2274", "submitter": "Vu A. Ha", "authors": "Vu A. Ha, Peter Haddawy, John Miyamoto", "title": "Similarity Measures on Preference Structures, Part II: Utility Functions", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-186-193", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In previous work cite{Ha98:Towards} we presented a case-based approach to\neliciting and reasoning with preferences. A key issue in this approach is the\ndefinition of similarity between user preferences. We introduced the\nprobabilistic distance as a measure of similarity on user preferences, and\nprovided an algorithm to compute the distance between two partially specified\n{em value} functions. This is for the case of decision making under {em\ncertainty}. In this paper we address the more challenging issue of computing\nthe probabilistic distance in the case of decision making under{em\nuncertainty}. We provide an algorithm to compute the probabilistic distance\nbetween two partially specified {em utility} functions. We demonstrate the use\nof this algorithm with a medical data set of partially specified patient\npreferences,where none of the other existing distancemeasures appear definable.\nUsing this data set, we also demonstrate that the case-based approach to\npreference elicitation isapplicable in domains with uncertainty. Finally, we\nprovide a comprehensive analytical comparison of the probabilistic distance\nwith some existing distance measures on preferences.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:23:53 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Ha", "Vu A.", ""], ["Haddawy", "Peter", ""], ["Miyamoto", "John", ""]]}, {"id": "1301.2275", "submitter": "Joseph Y. Halpern", "authors": "Joseph Y. Halpern, Judea Pearl", "title": "Causes and Explanations: A Structural-Model Approach --- Part 1: Causes", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001), later extended version is\n  arXiv:cs/0011012", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-194-202", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new definition of actual causes, using structural equations to\nmodel counterfactuals.We show that the definitions yield a plausible and\nelegant account ofcausation that handles well examples which have caused\nproblems forother definitions and resolves major difficulties in the\ntraditionalaccount. In a companion paper, we show how the definition of\ncausality can beused to give an elegant definition of (causal) explanation.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:23:57 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Halpern", "Joseph Y.", ""], ["Pearl", "Judea", ""]]}, {"id": "1301.2277", "submitter": "Milos Hauskrecht", "authors": "Milos Hauskrecht, Eli Upfal", "title": "A Clustering Approach to Solving Large Stochastic Matching Problems", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-219-226", "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we focus on efficient heuristics for solving a class of\nstochastic planning problems that arise in a variety of business, investment,\nand industrial applications. The problem is best described in terms of future\nbuy and sell contracts. By buying less reliable, but less expensive, buy\n(supply) contracts, a company or a trader can cover a position of more reliable\nand more expensive sell contracts. The goal is to maximize the expected net\ngain (profit) by constructing a dose to optimum portfolio out of the available\nbuy and sell contracts. This stochastic planning problem can be formulated as a\ntwo-stage stochastic linear programming problem with recourse. However, this\nformalization leads to solutions that are exponential in the number of possible\nfailure combinations. Thus, this approach is not feasible for large scale\nproblems. In this work we investigate heuristic approximation techniques\nalleviating the efficiency problem. We primarily focus on the clustering\napproach and devise heuristics for finding clusterings leading to good\napproximations. We illustrate the quality and feasibility of the approach\nthrough experimental data.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:24:06 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Hauskrecht", "Milos", ""], ["Upfal", "Eli", ""]]}, {"id": "1301.2279", "submitter": "Eric J. Horvitz", "authors": "Eric J. Horvitz, Yongshao Ruan, Carla P. Gomes, Henry Kautz, Bart\n  Selman, David Maxwell Chickering", "title": "A Bayesian Approach to Tackling Hard Computational Problems", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-235-244", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are developing a general framework for using learned Bayesian models for\ndecision-theoretic control of search and reasoningalgorithms. We illustrate the\napproach on the specific task of controlling both general and domain-specific\nsolvers on a hard class of structured constraint satisfaction problems. A\nsuccessful strategyfor reducing the high (and even infinite) variance in\nrunning time typically exhibited by backtracking search algorithms is to cut\noff and restart the search if a solution is not found within a certainamount of\ntime. Previous work on restart strategies have employed fixed cut off values.\nWe show how to create a dynamic cut off strategy by learning a Bayesian model\nthat predicts the ultimate length of a trial based on observing the early\nbehavior of the search algorithm. Furthermore, we describe the general\nconditions under which a dynamic restart strategy can outperform the\ntheoretically optimal fixed strategy.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:24:15 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Horvitz", "Eric J.", ""], ["Ruan", "Yongshao", ""], ["Gomes", "Carla P.", ""], ["Kautz", "Henry", ""], ["Selman", "Bart", ""], ["Chickering", "David Maxwell", ""]]}, {"id": "1301.2280", "submitter": "Geoff A. Jarrad", "authors": "Geoff A. Jarrad", "title": "Estimating Well-Performing Bayesian Networks using Bernoulli Mixtures", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-245-252", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel method for estimating Bayesian network (BN) parameters from data is\npresented which provides improved performance on test data. Previous research\nhas shown the value of representing conditional probability distributions\n(CPDs) via neural networks(Neal 1992), noisy-OR gates (Neal 1992, Diez 1993)and\ndecision trees (Friedman and Goldszmidt 1996).The Bernoulli mixture network\n(BMN) explicitly represents the CPDs of discrete BN nodes as mixtures of local\ndistributions,each having a different set of parents.This increases the space\nof possible structures which can be considered,enabling the CPDs to have\nfiner-grained dependencies.The resulting estimation procedure induces a\nmodelthat is better able to emulate the underlying interactions occurring in\nthe data than conventional conditional Bernoulli network models.The results for\nartificially generated data indicate that overfitting is best reduced by\nrestricting the complexity of candidate mixture substructures local to each\nnode. Furthermore, mixtures of very simple substructures can perform almost as\nwell as more complex ones.The BMN is also applied to data collected from an\nonline adventure game with an application to keyhole plan recognition. The\nresults show that the BMN-based model brings a dramatic improvement in\nperformance over a conventional BN model.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:24:19 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Jarrad", "Geoff A.", ""]]}, {"id": "1301.2281", "submitter": "Michael Kearns", "authors": "Michael Kearns, Michael L. Littman, Satinder Singh", "title": "Graphical Models for Game Theory", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-253-260", "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce graphical modelsfor multi-player game theory, and\ngive powerful algorithms for computing their Nash equilibria in certain cases.\nAn n-player game is given by an undirected graph on n nodes and a set of n\nlocal matrices. The interpretation is that the payoff to player i is determined\nentirely by the actions of player i and his neighbors in the graph, and thus\nthe payoff matrix to player i is indexed only by these players. We thus view\nthe global n-player game as being composed of interacting local games, each\ninvolving many fewer players. Each player's action may have global impact, but\nit occurs through the propagation of local influences.Our main technical result\nis an efficient algorithm for computing Nash equilibria when the underlying\ngraph is a tree (or can be turned into a tree with few node mergings). The\nalgorithm runs in time polynomial in the size of the representation (the graph\nand theassociated local game matrices), and comes in two related but distinct\nflavors. The first version involves an approximation step, and computes a\nrepresentation of all approximate Nash equilibria (of which there may be an\nexponential number in general). The second version allows the exact computation\nof Nash equilibria at the expense of weakened complexity bounds. The algorithm\nrequires only local message-passing between nodes (and thus can be implemented\nby the players themselves in a distributed manner). Despite an analogy to\ninference in Bayes nets that we develop, the analysis of our algorithm is more\ninvolved than that for the polytree algorithm in, owing partially to the fact\nthat we must either compute, or select from, an exponential number of potential\nsolutions. We discuss a number of extensions, such as the computation of\nequilibria with desirable global properties (e.g. maximizing global return),\nand directions for further research.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:24:24 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2015 01:31:51 GMT"}], "update_date": "2015-03-10", "authors_parsed": [["Kearns", "Michael", ""], ["Littman", "Michael L.", ""], ["Singh", "Satinder", ""]]}, {"id": "1301.2282", "submitter": "Tomas Kocka", "authors": "Tomas Kocka, Remco R. Bouckaert, Milan Studeny", "title": "On characterizing Inclusion of Bayesian Networks", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-261-268", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every directed acyclic graph (DAG) over a finite non-empty set of variables\n(= nodes) N induces an independence model over N, which is a list of\nconditional independence statements over N.The inclusion problem is how to\ncharacterize (in graphical terms) whether all independence statements in the\nmodel induced by a DAG K are in the model induced by a second DAG L. Meek\n(1997) conjectured that this inclusion holds iff there exists a sequence of\nDAGs from L to K such that only certain 'legal' arrow reversal and 'legal'\narrow adding operations are performed to get the next DAG in the sequence.In\nthis paper we give several characterizations of inclusion of DAG models and\nverify Meek's conjecture in the case that the DAGs K and L differ in at most\none adjacency. As a warming up a rigorous proof of well-known graphical\ncharacterizations of equivalence of DAGs, which is a highly related problem, is\ngiven.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:24:28 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Kocka", "Tomas", ""], ["Bouckaert", "Remco R.", ""], ["Studeny", "Milan", ""]]}, {"id": "1301.2283", "submitter": "Tomas Kocka", "authors": "Tomas Kocka, Robert Castelo", "title": "Improved learning of Bayesian networks", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-269-276", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The search space of Bayesian Network structures is usually defined as Acyclic\nDirected Graphs (DAGs) and the search is done by local transformations of DAGs.\nBut the space of Bayesian Networks is ordered by DAG Markov model inclusion and\nit is natural to consider that a good search policy should take this into\naccount. First attempt to do this (Chickering 1996) was using equivalence\nclasses of DAGs instead of DAGs itself. This approach produces better results\nbut it is significantly slower. We present a compromise between these two\napproaches. It uses DAGs to search the space in such a way that the ordering by\ninclusion is taken into account. This is achieved by repetitive usage of local\nmoves within the equivalence class of DAGs. We show that this new approach\nproduces better results than the original DAGs approach without substantial\nchange in time complexity. We present empirical results, within the framework\nof heuristic search and Markov Chain Monte Carlo, provided through the Alarm\ndataset.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:24:32 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Kocka", "Tomas", ""], ["Castelo", "Robert", ""]]}, {"id": "1301.2285", "submitter": "Jerome Lang", "authors": "Jerome Lang, Philippe Muller", "title": "Plausible reasoning from spatial observations", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-285-292", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article deals with plausible reasoning from incomplete knowledge about\nlarge-scale spatial properties. The availableinformation, consisting of a set\nof pointwise observations,is extrapolated to neighbour points. We make use of\nbelief functions to represent the influence of the knowledge at a given point\nto another point; the quantitative strength of this influence decreases when\nthe distance between both points increases. These influences arethen aggregated\nusing a variant of Dempster's rule of combination which takes into account the\nrelative dependence between observations.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:24:41 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Lang", "Jerome", ""], ["Muller", "Philippe", ""]]}, {"id": "1301.2287", "submitter": "Kathryn Blackmond Laskey", "authors": "Kathryn Blackmond Laskey, Suzanne M. Mahoney, Ed Wright", "title": "Hypothesis Management in Situation-Specific Network Construction", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-301-309", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of knowledge-based model construction in the\npresence of uncertainty about the association of domain entities to random\nvariables. Multi-entity Bayesian networks (MEBNs) are defined as a\nrepresentation for knowledge in domains characterized by uncertainty in the\nnumber of relevant entities, their interrelationships, and their association\nwith observables. An MEBN implicitly specifies a probability distribution in\nterms of a hierarchically structured collection of Bayesian network fragments\nthat together encode a joint probability distribution over arbitrarily many\ninterrelated hypotheses. Although a finite query-complete model can always be\nconstructed, association uncertainty typically makes exact model construction\nand evaluation intractable. The objective of hypothesis management is to\nbalance tractability against accuracy. We describe an application to the\nproblem of using intelligence reports to infer the organization and activities\nof groups of military vehicles. Our approach is compared to related work in the\ntracking and fusion literature.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:24:50 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Laskey", "Kathryn Blackmond", ""], ["Mahoney", "Suzanne M.", ""], ["Wright", "Ed", ""]]}, {"id": "1301.2288", "submitter": "Uri Lerner", "authors": "Uri Lerner, Ron Parr", "title": "Inference in Hybrid Networks: Theoretical Limits and Practical\n  Algorithms", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-310-318", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important subclass of hybrid Bayesian networks are those that represent\nConditional Linear Gaussian (CLG) distributions --- a distribution with a\nmultivariate Gaussian component for each instantiation of the discrete\nvariables. In this paper we explore the problem of inference in CLGs. We show\nthat inference in CLGs can be significantly harder than inference in Bayes\nNets. In particular, we prove that even if the CLG is restricted to an\nextremely simple structure of a polytree in which every continuous node has at\nmost one discrete ancestor, the inference task is NP-hard.To deal with the\noften prohibitive computational cost of the exact inference algorithm for CLGs,\nwe explore several approximate inference algorithms. These algorithms try to\nfind a small subset of Gaussians which are a good approximation to the full\nmixture distribution. We consider two Monte Carlo approaches and a novel\napproach that enumerates mixture components in order of prior probability. We\ncompare these methods on a variety of problems and show that our novel\nalgorithm is very promising for large, hybrid diagnosis problems.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:24:54 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Lerner", "Uri", ""], ["Parr", "Ron", ""]]}, {"id": "1301.2289", "submitter": "Uri Lerner", "authors": "Uri Lerner, Eran Segal, Daphne Koller", "title": "Exact Inference in Networks with Discrete Children of Continuous Parents", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-319-328", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real life domains contain a mixture of discrete and continuous variables\nand can be modeled as hybrid Bayesian Networks. Animportant subclass of hybrid\nBNs are conditional linear Gaussian (CLG) networks, where the conditional\ndistribution of the continuous variables given an assignment to the discrete\nvariables is a multivariate Gaussian. Lauritzen's extension to the clique tree\nalgorithm can be used for exact inference in CLG networks. However, many\ndomains also include discrete variables that depend on continuous ones, and CLG\nnetworks do not allow such dependencies to berepresented. No exact inference\nalgorithm has been proposed for these enhanced CLG networks. In this paper, we\ngeneralize Lauritzen's algorithm, providing the first \"exact\" inference\nalgorithm for augmented CLG networks - networks where continuous nodes are\nconditional linear Gaussians but that also allow discrete children ofcontinuous\nparents. Our algorithm is exact in the sense that it computes the exact\ndistributions over the discrete nodes, and the exact first and second moments\nof the continuous ones, up to the accuracy obtained by numerical integration\nused within thealgorithm. When the discrete children are modeled with softmax\nCPDs (as is the case in many real world domains) the approximation of the\ncontinuous distributions using the first two moments is particularly accurate.\nOur algorithm is simple to implement and often comparable in its complexity to\nLauritzen's algorithm. We show empirically that it achieves substantially\nhigher accuracy than previous approximate algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:24:58 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Lerner", "Uri", ""], ["Segal", "Eran", ""], ["Koller", "Daphne", ""]]}, {"id": "1301.2290", "submitter": "Thomas Lukasiewicz", "authors": "Thomas Lukasiewicz", "title": "Probabilistic Logic Programming under Inheritance with Overriding", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-329-336", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present probabilistic logic programming under inheritance with overriding.\nThis approach is based on new notions of entailment for reasoning with\nconditional constraints, which are obtained from the classical notion of\nlogical entailment by adding the principle of inheritance with overriding. This\nis done by using recent approaches to probabilistic default reasoning with\nconditional constraints. We analyze the semantic properties of the new\nentailment relations. We also present algorithms for probabilistic logic\nprogramming under inheritance with overriding, and program transformations for\nan increased efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:25:03 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Lukasiewicz", "Thomas", ""]]}, {"id": "1301.2291", "submitter": "Anders L. Madsen", "authors": "Anders L. Madsen, Dennis Nilsson", "title": "Solving Influence Diagrams using HUGIN, Shafer-Shenoy and Lazy\n  Propagation", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-337-345", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we compare three different architectures for the evaluation of\ninfluence diagrams: HUGIN, Shafer-Shenoy, and Lazy Evaluation architecture. The\ncomputational complexity of the architectures are compared on the LImited\nMemory Influence Diagram (LIMID): a diagram where only the requiste information\nfor the computation of the optimal policies are depicted. Because the requsite\ninformation is explicitly represented in the LIMID the evaluation can take\nadvantage of it, and significant savings in computational can be obtained. In\nthis paper we show how the obtained savings is considerably increased when the\ncomputations performed on the LIMID is according to the Lazy Evaluation scheme.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:25:07 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Madsen", "Anders L.", ""], ["Nilsson", "Dennis", ""]]}, {"id": "1301.2292", "submitter": "Dimitris Margaritis", "authors": "Dimitris Margaritis, Sebastian Thrun", "title": "A Bayesian Multiresolution Independence Test for Continuous Variables", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-346-353", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a method ofcomputing the posterior probability\nofconditional independence of two or morecontinuous variables from\ndata,examined at several resolutions. Ourapproach is motivated by\ntheobservation that the appearance ofcontinuous data varies widely atvarious\nresolutions, producing verydifferent independence estimatesbetween the\nvariablesinvolved. Therefore, it is difficultto ascertain independence\nwithoutexamining data at several carefullyselected resolutions. In our paper,\nweaccomplish this using the exactcomputation of the posteriorprobability of\nindependence, calculatedanalytically given a resolution. Ateach examined\nresolution, we assume amultinomial distribution with Dirichletpriors for the\ndiscretized tableparameters, and compute the posteriorusing Bayesian\nintegration. Acrossresolutions, we use a search procedureto approximate the\nBayesian integral ofprobability over an exponential numberof possible\nhistograms. Our methodgeneralizes to an arbitrary numbervariables in a\nstraightforward manner.The test is suitable for Bayesiannetwork learning\nalgorithms that useindependence tests to infer the networkstructure, in domains\nthat contain anymix of continuous, ordinal andcategorical variables.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:25:12 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Margaritis", "Dimitris", ""], ["Thrun", "Sebastian", ""]]}, {"id": "1301.2293", "submitter": "Pedrito Maynard-Reid II", "authors": "Pedrito Maynard-Reid II, Urszula Chajewska", "title": "Aggregating Learned Probabilistic Beliefs", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-354-361", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of aggregating beliefs of severalexperts. We assume that\nthese beliefs are represented as probabilitydistributions. We argue that the\nevaluation of any aggregationtechnique depends on the semantic context of this\ntask. We propose aframework, in which we assume that nature generates samples\nfrom a`true' distribution and different experts form their beliefs based onthe\nsubsets of the data they have a chance to observe. Naturally, theideal\naggregate distribution would be the one learned from thecombined sample sets.\nSuch a formulation leads to a natural way tomeasure the accuracy of the\naggregation mechanism.We show that the well-known aggregation operator LinOP is\nideallysuited for that task. We propose a LinOP-based learning\nalgorithm,inspired by the techniques developed for Bayesian learning,\nwhichaggregates the experts' distributions represented as Bayesiannetworks. Our\npreliminary experiments show that this algorithmperforms well in practice.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:25:16 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Maynard-Reid", "Pedrito", "II"], ["Chajewska", "Urszula", ""]]}, {"id": "1301.2294", "submitter": "Thomas P. Minka", "authors": "Thomas P. Minka", "title": "Expectation Propagation for approximate Bayesian inference", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-362-369", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new deterministic approximation technique in Bayesian\nnetworks. This method, \"Expectation Propagation\", unifies two previous\ntechniques: assumed-density filtering, an extension of the Kalman filter, and\nloopy belief propagation, an extension of belief propagation in Bayesian\nnetworks. All three algorithms try to recover an approximate distribution which\nis close in KL divergence to the true distribution. Loopy belief propagation,\nbecause it propagates exact belief states, is useful for a limited class of\nbelief networks, such as those which are purely discrete. Expectation\nPropagation approximates the belief states by only retaining certain\nexpectations, such as mean and variance, and iterates until these expectations\nare consistent throughout the network. This makes it applicable to hybrid\nnetworks with discrete and continuous nodes. Expectation Propagation also\nextends belief propagation in the opposite direction - it can propagate richer\nbelief states that incorporate correlations between nodes. Experiments with\nGaussian mixture models show Expectation Propagation to be convincingly better\nthan methods with similar computational cost: Laplace's method, variational\nBayes, and Monte Carlo. Expectation Propagation also provides an efficient\nalgorithm for training Bayes point machine classifiers.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:25:20 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Minka", "Thomas P.", ""]]}, {"id": "1301.2295", "submitter": "Quaid Morris", "authors": "Quaid Morris", "title": "Recognition Networks for Approximate Inference in BN20 Networks", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-370-377", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose using recognition networks for approximate inference inBayesian\nnetworks (BNs). A recognition network is a multilayerperception (MLP) trained\nto predict posterior marginals given observedevidence in a particular BN. The\ninput to the MLP is a vector of thestates of the evidential nodes. The activity\nof an output unit isinterpreted as a prediction of the posterior marginal of\nthecorresponding variable. The MLP is trained using samples generated fromthe\ncorresponding BN.We evaluate a recognition network that was trained to do\ninference ina large Bayesian network, similar in structure and complexity to\ntheQuick Medical Reference, Decision Theoretic (QMR-DT). Our networkis a\nbinary, two-layer, noisy-OR network containing over 4000 potentially observable\nnodes and over 600 unobservable, hidden nodes. Inreal medical diagnosis, most\nobservables are unavailable, and there isa complex and unknown bias that\nselects which ones are provided. Weincorporate a very basic type of selection\nbias in our network: a knownpreference that available observables are positive\nrather than negative.Even this simple bias has a significant effect on the\nposterior. We compare the performance of our recognition network\ntostate-of-the-art approximate inference algorithms on a large set oftest\ncases. In order to evaluate the effect of our simplistic modelof the selection\nbias, we evaluate algorithms using a variety ofincorrectly modeled observation\nbiases. Recognition networks performwell using both correct and incorrect\nobservation biases.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:25:25 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Morris", "Quaid", ""]]}, {"id": "1301.2296", "submitter": "Kevin Murphy", "authors": "Kevin Murphy, Yair Weiss", "title": "The Factored Frontier Algorithm for Approximate Inference in DBNs", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-378-385", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Factored Frontier (FF) algorithm is a simple approximate\ninferencealgorithm for Dynamic Bayesian Networks (DBNs). It is very similar\ntothe fully factorized version of the Boyen-Koller (BK) algorithm, butinstead\nof doing an exact update at every step followed bymarginalisation (projection),\nit always works with factoreddistributions. Hence it can be applied to models\nfor which the exactupdate step is intractable. We show that FF is equivalent to\n(oneiteration of) loopy belief propagation (LBP) on the original DBN, andthat\nBK is equivalent (to one iteration of) LBP on a DBN where wecluster some of the\nnodes. We then show empirically that byiterating, LBP can improve on the\naccuracy of both FF and BK. Wecompare these algorithms on two real-world DBNs:\nthe first is a modelof a water treatment plant, and the second is a coupled\nHMM, used tomodel freeway traffic.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:25:29 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Murphy", "Kevin", ""], ["Weiss", "Yair", ""]]}, {"id": "1301.2297", "submitter": "Ann Nicholson", "authors": "Ann Nicholson, Tal Boneh, Tim Wilkin, Kaye Stacey, Liz Sonenberg,\n  Vicki Steinle", "title": "A Case Study in Knowledge Discovery and Elicitation in an Intelligent\n  Tutoring Application", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-386-394", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most successful Bayesian network (BN) applications to datehave been built\nthrough knowledge elicitation from experts.This is difficult and time\nconsuming, which has lead to recentinterest in automated methods for learning\nBNs from data. We present a case study in the construction of a BN in\nanintelligent tutoring application, specifically decimal misconceptions.\nWedescribe the BN construction using expert elicitation and then investigate\nhow certainexisting automated knowledge discovery methods might support the BN\nknowledge engineering process.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:25:34 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Nicholson", "Ann", ""], ["Boneh", "Tal", ""], ["Wilkin", "Tim", ""], ["Stacey", "Kaye", ""], ["Sonenberg", "Liz", ""], ["Steinle", "Vicki", ""]]}, {"id": "1301.2298", "submitter": "Dirk Ormoneit", "authors": "Dirk Ormoneit, Christiane Lemieux, David J. Fleet", "title": "Lattice Particle Filters", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-395-402", "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A standard approach to approximate inference in state-space models isto apply\na particle filter, e.g., the Condensation Algorithm.However, the performance of\nparticle filters often varies significantlydue to their stochastic nature.We\npresent a class of algorithms, called lattice particle filters, thatcircumvent\nthis difficulty by placing the particles deterministicallyaccording to a\nQuasi-Monte Carlo integration rule.We describe a practical realization of this\nidea, discuss itstheoretical properties, and its efficiency.Experimental\nresults with a synthetic 2D tracking problem show that thelattice particle\nfilter is equivalent to a conventional particle filterthat has between 10 and\n60% more particles, depending ontheir \"sparsity\" in the state-space.We also\npresent results on inferring 3D human motion frommoving light displays.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:25:38 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Ormoneit", "Dirk", ""], ["Lemieux", "Christiane", ""], ["Fleet", "David J.", ""]]}, {"id": "1301.2299", "submitter": "James D. Park", "authors": "James D. Park, Adnan Darwiche", "title": "Approximating MAP using Local Search", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-403-410", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MAP is the problem of finding a most probable instantiation of a set of\nvariables in a Bayesian network, given evidence. Unlike computing marginals,\nposteriors, and MPE (a special case of MAP), the time and space complexity of\nMAP is not only exponential in the network treewidth, but also in a larger\nparameter known as the \"constrained\" treewidth. In practice, this means that\ncomputing MAP can be orders of magnitude more expensive than\ncomputingposteriors or MPE. Thus, practitioners generally avoid MAP\ncomputations, resorting instead to approximating them by the most likely value\nfor each MAP variableseparately, or by MPE.We present a method for\napproximating MAP using local search. This method has space complexity which is\nexponential onlyin the treewidth, as is the complexity of each search step. We\ninvestigate the effectiveness of different local searchmethods and several\ninitialization strategies and compare them to otherapproximation\nschemes.Experimental results show that local search provides a much more\naccurate approximation of MAP, while requiring few search steps.Practically,\nthis means that the complexity of local search is often exponential only in\ntreewidth as opposed to the constrained treewidth, making approximating MAP as\nefficient as other computations.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:25:42 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Park", "James D.", ""], ["Darwiche", "Adnan", ""]]}, {"id": "1301.2300", "submitter": "Judea Pearl", "authors": "Judea Pearl", "title": "Direct and Indirect Effects", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-411-420", "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The direct effect of one eventon another can be defined and measured\nbyholding constant all intermediate variables between the two.Indirect effects\npresent conceptual andpractical difficulties (in nonlinear models), because\nthey cannot be isolated by holding certain variablesconstant. This paper shows\na way of defining any path-specific effectthat does not invoke blocking the\nremainingpaths.This permits the assessment of a more naturaltype of direct and\nindirect effects, one thatis applicable in both linear and nonlinear models.\nThe paper establishesconditions under which such assessments can be estimated\nconsistentlyfrom experimental and nonexperimental data,and thus extends\npath-analytic techniques tononlinear and nonparametric models.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:25:47 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Pearl", "Judea", ""]]}, {"id": "1301.2301", "submitter": "Avi Pfeffer", "authors": "Avi Pfeffer", "title": "Sufficiency, Separability and Temporal Probabilistic Models", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-421-428", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose we are given the conditional probability of one variable given some\nother variables.Normally the full joint distribution over the conditioning\nvariablesis required to determine the probability of the conditioned\nvariable.Under what circumstances are the marginal distributions over the\nconditioning variables sufficient to determine the probability ofthe\nconditioned variable?Sufficiency in this sense is equivalent to additive\nseparability ofthe conditional probability distribution.Such separability\nstructure is natural and can be exploited forefficient inference.Separability\nhas a natural generalization to conditional separability.Separability provides\na precise notion of weaklyinteracting subsystems in temporal probabilistic\nmodels.Given a system that is decomposed into separable subsystems,\nexactmarginal probabilities over subsystems at future points in time can\nbecomputed by propagating marginal subsystem probabilities, rather thancomplete\nsystem joint probabilities.Thus, separability can make exact prediction\ntractable.However, observations can break separability,so exact monitoring of\ndynamic systems remains hard.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:25:51 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Pfeffer", "Avi", ""]]}, {"id": "1301.2302", "submitter": "Daniel Pless", "authors": "Daniel Pless, George Luger", "title": "Toward General Analysis of Recursive Probability Models", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-429-436", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is increasing interest within the research community in the design and\nuse of recursive probability models. Although there still remains concern about\ncomputational complexity costs and the fact that computing exact solutions can\nbe intractable for many nonrecursive models and impossible in the general case\nfor recursive problems, several research groups are actively developing\ncomputational techniques for recursive stochastic languages. We have developed\nan extension to the traditional lambda-calculus as a framework for families of\nTuring complete stochastic languages. We have also developed a class of exact\ninference algorithms based on the traditional reductions of the\nlambda-calculus. We further propose that using the deBruijn notation (a\nlambda-calculus notation with nameless dummies) supports effective caching in\nsuch systems (caching being an essential component of efficient computation).\nFinally, our extension to the lambda-calculus offers a foundation and general\ntheory for the construction of recursive stochastic modeling languages as well\nas promise for effective caching and efficient approximation algorithms for\ninference.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:25:55 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Pless", "Daniel", ""], ["Luger", "George", ""]]}, {"id": "1301.2304", "submitter": "Pascal Poupart", "authors": "Pascal Poupart, Craig Boutilier", "title": "Vector-space Analysis of Belief-state Approximation for POMDPs", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-445-452", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach to value-directed belief state approximation for\nPOMDPs. The value-directed model allows one to choose approximation methods for\nbelief state monitoring that have a small impact on decision quality. Using a\nvector space analysis of the problem, we devise two new search procedures for\nselecting an approximation scheme that have much better computational\nproperties than existing methods. Though these provide looser error bounds, we\nshow empirically that they have a similar impact on decision quality in\npractice, and run up to two orders of magnitude more quickly.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:26:03 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Poupart", "Pascal", ""], ["Boutilier", "Craig", ""]]}, {"id": "1301.2305", "submitter": "Pascal Poupart", "authors": "Pascal Poupart, Luis E. Ortiz, Craig Boutilier", "title": "Value-Directed Sampling Methods for POMDPs", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-453-461", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of approximate belief-state monitoring using particle\nfiltering for the purposes of implementing a policy for a partially-observable\nMarkov decision process (POMDP). While particle filtering has become a\nwidely-used tool in AI for monitoring dynamical systems, rather scant attention\nhas been paid to their use in the context of decision making. Assuming the\nexistence of a value function, we derive error bounds on decision quality\nassociated with filtering using importance sampling. We also describe an\nadaptive procedure that can be used to dynamically determine the number of\nsamples required to meet specific error bounds. Empirical evidence is offered\nsupporting this technique as a profitable means of directing sampling effort\nwhere it is needed to distinguish policies.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:26:08 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Poupart", "Pascal", ""], ["Ortiz", "Luis E.", ""], ["Boutilier", "Craig", ""]]}, {"id": "1301.2306", "submitter": "Christopher S Raphael", "authors": "Christopher S Raphael", "title": "A Mixed Graphical Model for Rhythmic Parsing", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-462-471", "categories": "cs.AI cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method is presented for the rhythmic parsing problem: Given a sequence of\nobserved musical note onset times, we estimate the corresponding notated rhythm\nand tempo process. A graphical model is developed that represents the\nsimultaneous evolution of tempo and rhythm and relates these hidden quantities\nto observations. The rhythm variables are discrete and the tempo and\nobservation variables are continuous. We show how to compute the globally most\nlikely configuration of the tempo and rhythm variables given an observation of\nnote onset times. Preliminary experiments are presented on a small data set. A\ngeneralization to arbitrary conditional Gaussian distributions is outlined.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:26:12 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Raphael", "Christopher S", ""]]}, {"id": "1301.2307", "submitter": "Khashayar Rohanimanesh", "authors": "Khashayar Rohanimanesh, Sridhar Mahadevan", "title": "Decision-Theoretic Planning with Concurrent Temporally Extended Actions", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-472-479", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a model for planning under uncertainty with temporallyextended\nactions, where multiple actions can be taken concurrently at each decision\nepoch. Our model is based on the options framework, and combines it with\nfactored state space models,where the set of options can be partitioned into\nclasses that affectdisjoint state variables. We show that the set of\ndecisionepochs for concurrent options defines a semi-Markov decisionprocess, if\nthe underlying temporally extended actions being parallelized arerestricted to\nMarkov options. This property allows us to use SMDPalgorithms for computing the\nvalue function over concurrentoptions. The concurrent options model allows\noverlapping execution ofoptions in order to achieve higher performance or in\norder to performa complex task. We describe a simple experiment using a\nnavigationtask which illustrates how concurrent options results in a faster\nplanwhen compared to the case when only one option is taken at a time.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:26:17 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Rohanimanesh", "Khashayar", ""], ["Mahadevan", "Sridhar", ""]]}, {"id": "1301.2308", "submitter": "Paat Rusmevichientong", "authors": "Paat Rusmevichientong, Benjamin van Roy", "title": "A Tractable POMDP for a Class of Sequencing Problems", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-480-487", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a partially observable Markov decision problem (POMDP) that\nmodels a class of sequencing problems. Although POMDPs are typically\nintractable, our formulation admits tractable solution. Instead of maintaining\na value function over a high-dimensional set of belief states, we reduce the\nstate space to one of smaller dimension, in which grid-based dynamic\nprogramming techniques are effective. We develop an error bound for the\nresulting approximation, and discuss an application of the model to a problem\nin targeted advertising.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:26:22 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Rusmevichientong", "Paat", ""], ["van Roy", "Benjamin", ""]]}, {"id": "1301.2310", "submitter": "Christian R. Shelton", "authors": "Christian R. Shelton", "title": "Policy Improvement for POMDPs Using Normalized Importance Sampling", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-496-503", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for estimating the expected return of a POMDP from\nexperience. The method does not assume any knowledge of the POMDP and allows\nthe experience to be gathered from an arbitrary sequence of policies. The\nreturn is estimated for any new policy of the POMDP. We motivate the estimator\nfrom function-approximation and importance sampling points-of-view and derive\nits theoretical properties. Although the estimator is biased, it has low\nvariance and the bias is often irrelevant when the estimator is used for\npair-wise comparisons. We conclude by extending the estimator to policies with\nmemory and compare its performance in a greedy search algorithm to REINFORCE\nalgorithms showing an order of magnitude reduction in the number of trials\nrequired.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:26:30 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Shelton", "Christian R.", ""]]}, {"id": "1301.2311", "submitter": "Nathan Srebro", "authors": "Nathan Srebro", "title": "Maximum Likelihood Bounded Tree-Width Markov Networks", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-504-511", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chow and Liu (1968) studied the problem of learning a maximumlikelihood\nMarkov tree. We generalize their work to more complexMarkov networks by\nconsidering the problem of learning a maximumlikelihood Markov network of\nbounded complexity. We discuss howtree-width is in many ways the appropriate\nmeasure of complexity andthus analyze the problem of learning a maximum\nlikelihood Markovnetwork of bounded tree-width.Similar to the work of Chow and\nLiu, we are able to formalize thelearning problem as a combinatorial\noptimization problem on graphs. Weshow that learning a maximum likelihood\nMarkov network of boundedtree-width is equivalent to finding a maximum weight\nhypertree. Thisequivalence gives rise to global, integer-programming\nbased,approximation algorithms with provable performance guarantees, for\nthelearning problem. This contrasts with heuristic local-searchalgorithms which\nwere previously suggested (e.g. by Malvestuto 1991).The equivalence also allows\nus to study the computational hardness ofthe learning problem. We show that\nlearning a maximum likelihoodMarkov network of bounded tree-width is NP-hard,\nand discuss thehardness of approximation.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:26:35 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Srebro", "Nathan", ""]]}, {"id": "1301.2312", "submitter": "Jin Tian", "authors": "Jin Tian, Judea Pearl", "title": "Causal Discovery from Changes", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-512-521", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method of discovering causal structures, based on the\ndetection of local, spontaneous changes in the underlying data-generating\nmodel. We analyze the classes of structures that are equivalent relative to a\nstream of distributions produced by local changes, and devise algorithms that\noutput graphical representations of these equivalence classes. We present\nexperimental results, using simulated data, and examine the errors associated\nwith detection of changes and recovery of structures.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:26:39 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Tian", "Jin", ""], ["Pearl", "Judea", ""]]}, {"id": "1301.2313", "submitter": "Tim Van Allen", "authors": "Tim Van Allen, Russell Greiner, Peter Hooper", "title": "Bayesian Error-Bars for Belief Net Inference", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-522-529", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Bayesian Belief Network (BN) is a model of a joint distribution over a\nsetof n variables, with a DAG structure to represent the immediate\ndependenciesbetween the variables, and a set of parameters (aka CPTables) to\nrepresent thelocal conditional probabilities of a node, given each assignment\nto itsparents. In many situations, these parameters are themselves random\nvariables - this may reflect the uncertainty of the domain expert, or may come\nfrom atraining sample used to estimate the parameter values. The distribution\noverthese \"CPtable variables\" induces a distribution over the response the\nBNwill return to any \"What is Pr(H | E)?\" query. This paper investigates\nthevariance of this response, showing first that it is asymptotically\nnormal,then providing its mean and asymptotical variance. We then present\naneffective general algorithm for computing this variance, which has the\nsamecomplexity as simply computing the (mean value of) the response itself -\nie,O(n 2^w), where n is the number of variables and w is the effective\ntreewidth. Finally, we provide empirical evidence that this algorithm,\nwhichincorporates assumptions and approximations, works effectively in\npractice,given only small samples.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:26:44 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Van Allen", "Tim", ""], ["Greiner", "Russell", ""], ["Hooper", "Peter", ""]]}, {"id": "1301.2314", "submitter": "Linda C. van der Gaag", "authors": "Linda C. van der Gaag, Silja Renooij", "title": "Analysing Sensitivity Data from Probabilistic Networks", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-530-537", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advance of efficient analytical methods for sensitivity analysis\nofprobabilistic networks, the interest in the sensitivities revealed by\nreal-life networks is rekindled. As the amount of data resulting from a\nsensitivity analysis of even a moderately-sized network is alreadyoverwhelming,\nmethods for extracting relevant information are called for. One such methodis\nto study the derivative of the sensitivity functions yielded for a network's\nparameters. We further propose to build upon the concept of admissible\ndeviation, that is, the extent to which a parameter can deviate from the true\nvalue without inducing a change in the most likely outcome. We illustrate these\nconcepts by means of a sensitivity analysis of a real-life probabilistic\nnetwork in oncology.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:26:48 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["van der Gaag", "Linda C.", ""], ["Renooij", "Silja", ""]]}, {"id": "1301.2315", "submitter": "Lex Weaver", "authors": "Lex Weaver, Nigel Tao", "title": "The Optimal Reward Baseline for Gradient-Based Reinforcement Learning", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-538-545", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There exist a number of reinforcement learning algorithms which learnby\nclimbing the gradient of expected reward. Their long-runconvergence has been\nproved, even in partially observableenvironments with non-deterministic\nactions, and without the need fora system model. However, the variance of the\ngradient estimator hasbeen found to be a significant practical problem. Recent\napproacheshave discounted future rewards, introducing a bias-variance\ntrade-offinto the gradient estimate. We incorporate a reward baseline into\nthelearning system, and show that it affects variance without\nintroducingfurther bias. In particular, as we approach the\nzero-bias,high-variance parameterization, the optimal (or variance\nminimizing)constant reward baseline is equal to the long-term average\nexpectedreward. Modified policy-gradient algorithms are presented, and anumber\nof experiments demonstrate their improvement over previous work.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:26:53 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Weaver", "Lex", ""], ["Tao", "Nigel", ""]]}, {"id": "1301.2317", "submitter": "Max Welling", "authors": "Max Welling, Yee Whye Teh", "title": "Belief Optimization for Binary Networks: A Stable Alternative to Loopy\n  Belief Propagation", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-554-561", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel inference algorithm for arbitrary, binary, undirected\ngraphs. Unlike loopy belief propagation, which iterates fixed point equations,\nwe directly descend on the Bethe free energy. The algorithm consists of two\nphases, first we update the pairwise probabilities, given the marginal\nprobabilities at each unit,using an analytic expression. Next, we update the\nmarginal probabilities, given the pairwise probabilities by following the\nnegative gradient of the Bethe free energy. Both steps are guaranteed to\ndecrease the Bethe free energy, and since it is lower bounded, the algorithm is\nguaranteed to converge to a local minimum. We also show that the Bethe free\nenergy is equal to the TAP free energy up to second order in the weights. In\nexperiments we confirm that when belief propagation converges it usually finds\nidentical solutions as our belief optimization method. However, in cases where\nbelief propagation fails to converge, belief optimization continues to converge\nto reasonable beliefs. The stable nature of belief optimization makes it\nideally suited for learning graphical models from data.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:27:02 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Welling", "Max", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1301.2318", "submitter": "Steve Young", "authors": "Steve Young", "title": "Statistical Modeling in Continuous Speech Recognition (CSR)(Invited\n  Talk)", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-562-571", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic continuous speech recognition (CSR) is sufficiently mature that a\nvariety of real world applications are now possible including large vocabulary\ntranscription and interactive spoken dialogues. This paper reviews the\nevolution of the statistical modelling techniques which underlie current-day\nsystems, specifically hidden Markov models (HMMs) and N-grams. Starting from a\ndescription of the speech signal and its parameterisation, the various\nmodelling assumptions and their consequences are discussed. It then describes\nvarious techniques by which the effects of these assumptions can be mitigated.\nDespite the progress that has been made, the limitations of current modelling\ntechniques are still evident. The paper therefore concludes with a brief review\nof some of the more fundamental modelling work now in progress.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:27:07 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Young", "Steve", ""]]}, {"id": "1301.2319", "submitter": "Bo Zhang", "authors": "Bo Zhang, Qingsheng Cai, Jianfeng Mao, Baining Guo", "title": "Planning and Acting under Uncertainty: A New Model for Spoken Dialogue\n  Systems", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-572-579", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty plays a central role in spoken dialogue systems. Some stochastic\nmodels like Markov decision process (MDP) are used to model the dialogue\nmanager. But the partially observable system state and user intention hinder\nthe natural representation of the dialogue state. MDP-based system degrades\nfast when uncertainty about a user's intention increases. We propose a novel\ndialogue model based on the partially observable Markov decision process\n(POMDP). We use hidden system states and user intentions as the state set,\nparser results and low-level information as the observation set, domain actions\nand dialogue repair actions as the action set. Here the low-level information\nis extracted from different input modals, including speech, keyboard, mouse,\netc., using Bayesian networks. Because of the limitation of the exact\nalgorithms, we focus on heuristic approximation algorithms and their\napplicability in POMDP for dialogue management. We also propose two methods for\ngrid point selection in grid-based approximation algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:27:11 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Zhang", "Bo", ""], ["Cai", "Qingsheng", ""], ["Mao", "Jianfeng", ""], ["Guo", "Baining", ""]]}, {"id": "1301.2320", "submitter": "Andrew Zimdars", "authors": "Andrew Zimdars, David Maxwell Chickering, Christopher Meek", "title": "Using Temporal Data for Making Recommendations", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-580-588", "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We treat collaborative filtering as a univariate time series estimation\nproblem: given a user's previous votes, predict the next vote. We describe two\nfamilies of methods for transforming data to encode time order in ways amenable\nto off-the-shelf classification and density estimation tools, and examine the\nresults of using these approaches on several real-world data sets. The\nimprovements in predictive accuracy we realize recommend the use of other\npredictive algorithms that exploit the temporal order of data.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:27:15 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Zimdars", "Andrew", ""], ["Chickering", "David Maxwell", ""], ["Meek", "Christopher", ""]]}, {"id": "1301.2343", "submitter": "Harm van Seijen", "authors": "Harm van Seijen and Richard S. Sutton", "title": "Planning by Prioritized Sweeping with Small Backups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient planning plays a crucial role in model-based reinforcement\nlearning. Traditionally, the main planning operation is a full backup based on\nthe current estimates of the successor states. Consequently, its computation\ntime is proportional to the number of successor states. In this paper, we\nintroduce a new planning backup that uses only the current value of a single\nsuccessor state and has a computation time independent of the number of\nsuccessor states. This new backup, which we call a small backup, opens the door\nto a new class of model-based reinforcement learning methods that exhibit much\nfiner control over their planning process than traditional methods. We\nempirically demonstrate that this increased flexibility allows for more\nefficient planning by showing that an implementation of prioritized sweeping\nbased on small backups achieves a substantial performance improvement over\nclassical implementations.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 21:54:42 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["van Seijen", "Harm", ""], ["Sutton", "Richard S.", ""]]}, {"id": "1301.2678", "submitter": "Fabio Patrizi", "authors": "Francesco Belardinelli, Alessio Lomuscio, Fabio Patrizi", "title": "Verification of Agent-Based Artifact Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artifact systems are a novel paradigm for specifying and implementing\nbusiness processes described in terms of interacting modules called artifacts.\nArtifacts consist of data and lifecycles, accounting respectively for the\nrelational structure of the artifacts' states and their possible evolutions\nover time. In this paper we put forward artifact-centric multi-agent systems, a\nnovel formalisation of artifact systems in the context of multi-agent systems\noperating on them. Differently from the usual process-based models of services,\nthe semantics we give explicitly accounts for the data structures on which\nartifact systems are defined. We study the model checking problem for\nartifact-centric multi-agent systems against specifications written in a\nquantified version of temporal-epistemic logic expressing the knowledge of the\nagents in the exchange. We begin by noting that the problem is undecidable in\ngeneral. We then identify two noteworthy restrictions, one syntactical and one\nsemantical, that enable us to find bisimilar finite abstractions and therefore\nreduce the model checking problem to the instance on finite models. Under these\nassumptions we show that the model checking problem for these systems is\nEXPSPACE-complete. We then introduce artifact-centric programs, compact and\ndeclarative representations of the programs governing both the artifact system\nand the agents. We show that, while these in principle generate infinite-state\nsystems, under natural conditions their verification problem can be solved on\nfinite abstractions that can be effectively computed from the programs. Finally\nwe exemplify the theoretical results of the paper through a mainstream\nprocurement scenario from the artifact systems literature.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2013 11:45:54 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2013 09:22:30 GMT"}], "update_date": "2013-01-23", "authors_parsed": [["Belardinelli", "Francesco", ""], ["Lomuscio", "Alessio", ""], ["Patrizi", "Fabio", ""]]}, {"id": "1301.2683", "submitter": "Josef Urban", "authors": "Josef Urban", "title": "BliStr: The Blind Strategymaker", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BliStr is a system that automatically develops strategies for E prover on a\nlarge set of problems. The main idea is to interleave (i) iterated\nlow-timelimit local search for new strategies on small sets of similar easy\nproblems with (ii) higher-timelimit evaluation of the new strategies on all\nproblems. The accumulated results of the global higher-timelimit runs are used\nto define and evolve the notion of \"similar easy problems\", and to control the\nselection of the next strategy to be improved. The technique was used to\nsignificantly strengthen the set of E strategies used by the MaLARea, PS-E,\nE-MaLeS, and E systems in the CASC@Turing 2012 competition, particularly in the\nMizar division. Similar improvement was obtained on the problems created from\nthe Flyspeck corpus.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2013 13:02:21 GMT"}, {"version": "v2", "created": "Wed, 28 May 2014 12:54:41 GMT"}], "update_date": "2014-05-29", "authors_parsed": [["Urban", "Josef", ""]]}, {"id": "1301.2774", "submitter": "Jafar Muhammadi", "authors": "Jafar Muhammadi, Hamid Reza Rabiee and Abbas Hosseini", "title": "Crowd Labeling: a survey", "comments": "Under consideration for publication in Knowledge and Information\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been a burst in the number of research projects on human\ncomputation via crowdsourcing. Multiple choice (or labeling) questions could be\nreferred to as a common type of problem which is solved by this approach. As an\napplication, crowd labeling is applied to find true labels for large machine\nlearning datasets. Since crowds are not necessarily experts, the labels they\nprovide are rather noisy and erroneous. This challenge is usually resolved by\ncollecting multiple labels for each sample, and then aggregating them to\nestimate the true label. Although the mechanism leads to high-quality labels,\nit is not actually cost-effective. As a result, efforts are currently made to\nmaximize the accuracy in estimating true labels, while fixing the number of\nacquired labels.\n  This paper surveys methods to aggregate redundant crowd labels in order to\nestimate unknown true labels. It presents a unified statistical latent model\nwhere the differences among popular methods in the field correspond to\ndifferent choices for the parameters of the model. Afterwards, algorithms to\nmake inference on these models will be surveyed. Moreover, adaptive methods\nwhich iteratively collect labels based on the previously collected labels and\nestimated models will be discussed. In addition, this paper compares the\ndistinguished methods, and provides guidelines for future work required to\naddress the current open issues.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jan 2013 14:12:53 GMT"}, {"version": "v2", "created": "Tue, 8 Apr 2014 05:59:49 GMT"}, {"version": "v3", "created": "Wed, 3 Sep 2014 06:37:23 GMT"}], "update_date": "2014-09-04", "authors_parsed": [["Muhammadi", "Jafar", ""], ["Rabiee", "Hamid Reza", ""], ["Hosseini", "Abbas", ""]]}, {"id": "1301.2811", "submitter": "Christian Scheible", "authors": "Christian Scheible and Hinrich Schuetze", "title": "Cutting Recursive Autoencoder Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning models enjoy considerable success in Natural Language\nProcessing. While deep architectures produce useful representations that lead\nto improvements in various tasks, they are often difficult to interpret. This\nmakes the analysis of learned structures particularly difficult. In this paper,\nwe rely on empirical tests to see whether a particular structure makes sense.\nWe present an analysis of the Semi-Supervised Recursive Autoencoder, a\nwell-known model that produces structural representations of text. We show that\nfor certain tasks, the structure of the autoencoder can be significantly\nreduced without loss of classification accuracy and we evaluate the produced\nstructures using human judgment.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jan 2013 19:33:31 GMT"}, {"version": "v2", "created": "Sun, 20 Jan 2013 09:09:08 GMT"}, {"version": "v3", "created": "Fri, 26 Apr 2013 12:33:50 GMT"}], "update_date": "2013-04-29", "authors_parsed": [["Scheible", "Christian", ""], ["Schuetze", "Hinrich", ""]]}, {"id": "1301.3535", "submitter": "Sang Hyun Kim", "authors": "Sang Hyun Kim, Eric Feron, John-Paul Clarke, Aude Marzuoli, Daniel\n  Delahaye", "title": "Airport Gate Scheduling for Passengers, Aircraft, and Operation", "comments": "This paper is submitted to the tenth USA/Europe ATM 2013 seminar", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Passengers' experience is becoming a key metric to evaluate the air\ntransportation system's performance. Efficient and robust tools to handle\nairport operations are needed along with a better understanding of passengers'\ninterests and concerns. Among various airport operations, this paper studies\nairport gate scheduling for improved passengers' experience. Three objectives\naccounting for passengers, aircraft, and operation are presented. Trade-offs\nbetween these objectives are analyzed, and a balancing objective function is\nproposed. The results show that the balanced objective can improve the\nefficiency of traffic flow in passenger terminals and on ramps, as well as the\nrobustness of gate operations.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 00:28:26 GMT"}], "update_date": "2013-01-17", "authors_parsed": [["Kim", "Sang Hyun", ""], ["Feron", "Eric", ""], ["Clarke", "John-Paul", ""], ["Marzuoli", "Aude", ""], ["Delahaye", "Daniel", ""]]}, {"id": "1301.3537", "submitter": "Joan Bruna", "authors": "Joan Bruna, Arthur Szlam, Yann LeCun", "title": "Learning Stable Group Invariant Representations with Convolutional\n  Networks", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformation groups, such as translations or rotations, effectively express\npart of the variability observed in many recognition problems. The group\nstructure enables the construction of invariant signal representations with\nappealing mathematical properties, where convolutions, together with pooling\noperators, bring stability to additive and geometric perturbations of the\ninput. Whereas physical transformation groups are ubiquitous in image and audio\napplications, they do not account for all the variability of complex signal\nclasses.\n  We show that the invariance properties built by deep convolutional networks\ncan be cast as a form of stable group invariance. The network wiring\narchitecture determines the invariance group, while the trainable filter\ncoefficients characterize the group action. We give explanatory examples which\nillustrate how the network architecture controls the resulting invariance\ngroup. We also explore the principle by which additional convolutional layers\ninduce a group factorization enabling more abstract, powerful invariant\nrepresentations.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 00:49:38 GMT"}], "update_date": "2013-01-17", "authors_parsed": [["Bruna", "Joan", ""], ["Szlam", "Arthur", ""], ["LeCun", "Yann", ""]]}, {"id": "1301.3720", "submitter": "Federico Schl\\\"uter", "authors": "Federico Schl\\\"uter and Facundo Bromberg and Alejandro Edera", "title": "The IBMAP approach for Markov networks structure learning", "comments": null, "journal-ref": null, "doi": "10.1007/s10472-014-9419-5", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we consider the problem of learning the structure of Markov\nnetworks from data. We present an approach for tackling this problem called\nIBMAP, together with an efficient instantiation of the approach: the IBMAP-HC\nalgorithm, designed for avoiding important limitations of existing\nindependence-based algorithms. These algorithms proceed by performing\nstatistical independence tests on data, trusting completely the outcome of each\ntest. In practice tests may be incorrect, resulting in potential cascading\nerrors and the consequent reduction in the quality of the structures learned.\nIBMAP contemplates this uncertainty in the outcome of the tests through a\nprobabilistic maximum-a-posteriori approach. The approach is instantiated in\nthe IBMAP-HC algorithm, a structure selection strategy that performs a\npolynomial heuristic local search in the space of possible structures. We\npresent an extensive empirical evaluation on synthetic and real data, showing\nthat our algorithm outperforms significantly the current independence-based\nalgorithms, in terms of data efficiency and quality of learned structures, with\nequivalent computational complexities. We also show the performance of IBMAP-HC\nin a real-world application of knowledge discovery: EDAs, which are\nevolutionary algorithms that use structure learning on each generation for\nmodeling the distribution of populations. The experiments show that when\nIBMAP-HC is used to learn the structure, EDAs improve the convergence to the\noptimum.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:21:19 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2014 17:32:50 GMT"}], "update_date": "2014-08-10", "authors_parsed": [["Schl\u00fcter", "Federico", ""], ["Bromberg", "Facundo", ""], ["Edera", "Alejandro", ""]]}, {"id": "1301.3764", "submitter": "Tom Schaul", "authors": "Tom Schaul, Yann LeCun", "title": "Adaptive learning rates and parallelization for stochastic, sparse,\n  non-smooth gradients", "comments": "Published at the First International Conference on Learning\n  Representations (ICLR-2013). Public reviews are available at\n  http://openreview.net/document/c14f2204-fd66-4d91-bed4-153523694041#c14f2204-fd66-4d91-bed4-153523694041", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has established an empirically successful framework for adapting\nlearning rates for stochastic gradient descent (SGD). This effectively removes\nall needs for tuning, while automatically reducing learning rates over time on\nstationary problems, and permitting learning rates to grow appropriately in\nnon-stationary tasks. Here, we extend the idea in three directions, addressing\nproper minibatch parallelization, including reweighted updates for sparse or\northogonal gradients, improving robustness on non-smooth loss functions, in the\nprocess replacing the diagonal Hessian estimation procedure that may not always\nbe available by a robust finite-difference approximation. The final algorithm\nintegrates all these components, has linear complexity and is hyper-parameter\nfree.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 17:48:38 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2013 18:30:41 GMT"}], "update_date": "2013-03-28", "authors_parsed": [["Schaul", "Tom", ""], ["LeCun", "Yann", ""]]}, {"id": "1301.3832", "submitter": "Teresa Alsinet", "authors": "Teresa Alsinet, Lluis Godo", "title": "A Complete Calculus for Possibilistic Logic Programming with Fuzzy\n  Propositional Variables", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-1-10", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a propositional logic programming language for\nreasoning under possibilistic uncertainty and representing vague knowledge.\nFormulas are represented by pairs (A, c), where A is a many-valued proposition\nand c is value in the unit interval [0,1] which denotes a lower bound on the\nbelief on A in terms of necessity measures. Belief states are modeled by\npossibility distributions on the set of all many-valued interpretations. In\nthis framework, (i) we define a syntax and a semantics of the general\nunderlying uncertainty logic; (ii) we provide a modus ponens-style calculus for\na sublanguage of Horn-rules and we prove that it is complete for determining\nthe maximum degree of possibilistic belief with which a fuzzy propositional\nvariable can be entailed from a set of formulas; and finally, (iii) we show how\nthe computation of a partial matching between fuzzy propositional variables, in\nterms of necessity measures for fuzzy sets, can be included in our logic\nprogramming system.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:48:38 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Alsinet", "Teresa", ""], ["Godo", "Lluis", ""]]}, {"id": "1301.3834", "submitter": "Ann Becker", "authors": "Ann Becker, Dan Geiger, Christopher Meek", "title": "Perfect Tree-Like Markovian Distributions", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-19-23", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that if a strictly positive joint probability distribution for a set\nof binary random variables factors according to a tree, then vertex separation\nrepresents all and only the independence relations enclosed in the\ndistribution. The same result is shown to hold also for multivariate strictly\npositive normal distributions. Our proof uses a new property of conditional\nindependence that holds for these two classes of probability distributions.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:48:48 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Becker", "Ann", ""], ["Geiger", "Dan", ""], ["Meek", "Christopher", ""]]}, {"id": "1301.3835", "submitter": "Salem Benferhat", "authors": "Salem Benferhat, Didier Dubois, Souhila Kaci, Henri Prade", "title": "A Principled Analysis of Merging Operations in Possibilistic Logic", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-24-31", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Possibilistic logic offers a qualitative framework for representing pieces of\ninformation associated with levels of uncertainty of priority. The fusion of\nmultiple sources information is discussed in this setting. Different classes of\nmerging operators are considered including conjunctive, disjunctive,\nreinforcement, adaptive and averaging operators. Then we propose to analyse\nthese classes in terms of postulates. This is done by first extending the\npostulate for merging classical bases to the case where priorites are avaialbe.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:48:52 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Benferhat", "Salem", ""], ["Dubois", "Didier", ""], ["Kaci", "Souhila", ""], ["Prade", "Henri", ""]]}, {"id": "1301.3836", "submitter": "Daniel S Bernstein", "authors": "Daniel S Bernstein, Shlomo Zilberstein, Neil Immerman", "title": "The Complexity of Decentralized Control of Markov Decision Processes", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-32-37", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning for distributed agents with partial state information is considered\nfrom a decision- theoretic perspective. We describe generalizations of both the\nMDP and POMDP models that allow for decentralized control. For even a small\nnumber of agents, the finite-horizon problems corresponding to both of our\nmodels are complete for nondeterministic exponential time. These complexity\nresults illustrate a fundamental difference between centralized and\ndecentralized control of Markov processes. In contrast to the MDP and POMDP\nproblems, the problems we consider provably do not admit polynomial-time\nalgorithms and most likely require doubly exponential time to solve in the\nworst case. We have thus provided mathematical evidence corresponding to the\nintuition that decentralized planning problems cannot easily be reduced to\ncentralized problems and solved exactly using established techniques.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:48:55 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Bernstein", "Daniel S", ""], ["Zilberstein", "Shlomo", ""], ["Immerman", "Neil", ""]]}, {"id": "1301.3837", "submitter": "Jeff A. Bilmes", "authors": "Jeff A. Bilmes", "title": "Dynamic Bayesian Multinets", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-38-45", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, dynamic Bayesian multinets are introduced where a Markov chain\nstate at time t determines conditional independence patterns between random\nvariables lying within a local time window surrounding t. It is shown how\ninformation-theoretic criterion functions can be used to induce sparse,\ndiscriminative, and class-conditional network structures that yield an optimal\napproximation to the class posterior probability, and therefore are useful for\nthe classification task. Using a new structure learning heuristic, the\nresulting models are tested on a medium-vocabulary isolated-word speech\nrecognition task. It is demonstrated that these discriminatively structured\ndynamic Bayesian multinets, when trained in a maximum likelihood setting using\nEM, can outperform both HMMs and other dynamic Bayesian networks with a similar\nnumber of parameters.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:48:59 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Bilmes", "Jeff A.", ""]]}, {"id": "1301.3839", "submitter": "Craig Boutilier", "authors": "Craig Boutilier", "title": "Approximately Optimal Monitoring of Plan Preconditions", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-54-62", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring plan preconditions can allow for replanning when a precondition\nfails, generally far in advance of the point in the plan where the precondition\nis relevant. However, monitoring is generally costly, and some precondition\nfailures have a very small impact on plan quality. We formulate a model for\noptimal precondition monitoring, using partially-observable Markov decisions\nprocesses, and describe methods for solving this model efficitively, though\napproximately. Specifically, we show that the single-precondition monitoring\nproblem is generally tractable, and the multiple-precondition monitoring\npolicies can be efficitively approximated using single-precondition soultions.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:49:07 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Boutilier", "Craig", ""]]}, {"id": "1301.3840", "submitter": "Urszula Chajewska", "authors": "Urszula Chajewska, Daphne Koller", "title": "Utilities as Random Variables: Density Estimation and Structure\n  Discovery", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-63-71", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision theory does not traditionally include uncertainty over utility\nfunctions. We argue that the a person's utility value for a given outcome can\nbe treated as we treat other domain attributes: as a random variable with a\ndensity function over its possible values. We show that we can apply\nstatistical density estimation techniques to learn such a density function from\na database of partially elicited utility functions. In particular, we define a\nBayesian learning framework for this problem, assuming the distribution over\nutilities is a mixture of Gaussians, where the mixture components represent\nstatistically coherent subpopulations. We can also extend our techniques to the\nproblem of discovering generalized additivity structure in the utility\nfunctions in the population. We define a Bayesian model selection criterion for\nutility function structure and a search procedure over structures. The\nfactorization of the utilities in the learned model, and the generalization\nobtained from density estimation, allows us to provide robust estimates of\nutilities using a significantly smaller number of utility elicitation\nquestions. We experiment with our technique on synthetic utility data and on a\nreal database of utility functions in the domain of prenatal diagnosis.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:49:11 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Chajewska", "Urszula", ""], ["Koller", "Daphne", ""]]}, {"id": "1301.3841", "submitter": "Jian Cheng", "authors": "Jian Cheng, Marek J. Druzdzel", "title": "Computational Investigation of Low-Discrepancy Sequences in Simulation\n  Algorithms for Bayesian Networks", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-72-81", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo sampling has become a major vehicle for approximate inference in\nBayesian networks. In this paper, we investigate a family of related simulation\napproaches, known collectively as quasi-Monte Carlo methods based on\ndeterministic low-discrepancy sequences. We first outline several theoretical\naspects of deterministic low-discrepancy sequences, show three examples of such\nsequences, and then discuss practical issues related to applying them to belief\nupdating in Bayesian networks. We propose an algorithm for selecting direction\nnumbers for Sobol sequence. Our experimental results show that low-discrepancy\nsequences (especially Sobol sequence) significantly improve the performance of\nsimulation algorithms in Bayesian networks compared to Monte Carlo sampling.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:49:15 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Cheng", "Jian", ""], ["Druzdzel", "Marek J.", ""]]}, {"id": "1301.3842", "submitter": "David Maxwell Chickering", "authors": "David Maxwell Chickering, David Heckerman", "title": "A Decision Theoretic Approach to Targeted Advertising", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-82-88", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A simple advertising strategy that can be used to help increase sales of a\nproduct is to mail out special offers to selected potential customers. Because\nthere is a cost associated with sending each offer, the optimal mailing\nstrategy depends on both the benefit obtained from a purchase and how the offer\naffects the buying behavior of the customers. In this paper, we describe two\nmethods for partitioning the potential customers into groups, and show how to\nperform a simple cost-benefit analysis to decide which, if any, of the groups\nshould be targeted. In particular, we consider two decision-tree learning\nalgorithms. The first is an \"off the shelf\" algorithm used to model the\nprobability that groups of customers will buy the product. The second is a new\nalgorithm that is similar to the first, except that for each group, it\nexplicitly models the probability of purchase under the two mailing scenarios:\n(1) the mail is sent to members of that group and (2) the mail is not sent to\nmembers of that group. Using data from a real-world advertising experiment, we\ncompare the algorithms to each other and to a naive mail-to-all strategy.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:49:19 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Chickering", "David Maxwell", ""], ["Heckerman", "David", ""]]}, {"id": "1301.3844", "submitter": "Gregory F. Cooper", "authors": "Gregory F. Cooper", "title": "A Bayesian Method for Causal Modeling and Discovery Under Selection", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-98-106", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a Bayesian method for learning causal networks using\nsamples that were selected in a non-random manner from a population of\ninterest. Examples of data obtained by non-random sampling include convenience\nsamples and case-control data in which a fixed number of samples with and\nwithout some condition is collected; such data are not uncommon. The paper\ndescribes a method for combining data under selection with prior beliefs in\norder to derive a posterior probability for a model of the causal processes\nthat are generating the data in the population of interest. The priors include\nbeliefs about the nature of the non-random sampling procedure. Although exact\napplication of the method would be computationally intractable for most\nrealistic datasets, efficient special-case and approximation methods are\ndiscussed. Finally, the paper describes how to combine learning under selection\nwith previous methods for learning from observational and experimental data\nthat are obtained on random samples of the population of interest. The net\nresult is a Bayesian methodology that supports causal modeling and discovery\nfrom a rich mixture of different types of data.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:49:26 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Cooper", "Gregory F.", ""]]}, {"id": "1301.3845", "submitter": "Fabio Gagliardi Cozman", "authors": "Fabio Gagliardi Cozman", "title": "Separation Properties of Sets of Probability Measures", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-107-114", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes independence concepts for sets of probability measures\nassociated with directed acyclic graphs. The paper shows that epistemic\nindependence and the standard Markov condition violate desirable separation\nproperties. The adoption of a contraction condition leads to d-separation but\nstill fails to guarantee a belief separation property. To overcome this\nunsatisfactory situation, a strong Markov condition is proposed, based on\nepistemic independence. The main result is that the strong Markov condition\nleads to strong independence and does enforce separation properties; this\nresult implies that (1) separation properties of Bayesian networks do extend to\nepistemic independence and sets of probability measures, and (2) strong\nindependence has a clear justification based on epistemic independence and the\nstrong Markov condition.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:49:30 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Cozman", "Fabio Gagliardi", ""]]}, {"id": "1301.3846", "submitter": "James Cussens", "authors": "James Cussens", "title": "Stochastic Logic Programs: Sampling, Inference and Applications", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-115-122", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms for exact and approximate inference in stochastic logic programs\n(SLPs) are presented, based respectively, on variable elimination and\nimportance sampling. We then show how SLPs can be used to represent prior\ndistributions for machine learning, using (i) logic programs and (ii) Bayes net\nstructures as examples. Drawing on existing work in statistics, we apply the\nMetropolis-Hasting algorithm to construct a Markov chain which samples from the\nposterior distribution. A Prolog implementation for this is described. We also\ndiscuss the possibility of constructing explicit representations of the\nposterior.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:49:34 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Cussens", "James", ""]]}, {"id": "1301.3847", "submitter": "Adnan Darwiche", "authors": "Adnan Darwiche", "title": "A Differential Approach to Inference in Bayesian Networks", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-123-132", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach for inference in Bayesian networks, which is mainly\nbased on partial differentiation. According to this approach, one compiles a\nBayesian network into a multivariate polynomial and then computes the partial\nderivatives of this polynomial with respect to each variable. We show that once\nsuch derivatives are made available, one can compute in constant-time answers\nto a large class of probabilistic queries, which are central to classical\ninference, parameter estimation, model validation and sensitivity analysis. We\npresent a number of complexity results relating to the compilation of such\npolynomials and to the computation of their partial derivatives. We argue that\nthe combined simplicity, comprehensiveness and computational complexity of the\npresented framework is unique among existing frameworks for inference in\nBayesian networks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:49:38 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Darwiche", "Adnan", ""]]}, {"id": "1301.3848", "submitter": "Adnan Darwiche", "authors": "Adnan Darwiche", "title": "Any-Space Probabilistic Inference", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-133-142", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have recently introduced an any-space algorithm for exact inference in\nBayesian networks, called Recursive Conditioning, RC, which allows one to trade\nspace with time at increments of X-bytes, where X is the number of bytes needed\nto cache a floating point number. In this paper, we present three key\nextensions of RC. First, we modify the algorithm so it applies to more general\nfactorization of probability distributions, including (but not limited to)\nBayesian network factorizations. Second, we present a forgetting mechanism\nwhich reduces the space requirements of RC considerably and then compare such\nrequirmenets with those of variable elimination on a number of realistic\nnetworks, showing orders of magnitude improvements in certain cases. Third, we\npresent a version of RC for computing maximum a posteriori hypotheses (MAP),\nwhich turns out to be the first MAP algorithm allowing a smooth time-space\ntradeoff. A key advantage of presented MAP algorithm is that it does not have\nto start from scratch each time a new query is presented, but can reuse some of\nits computations across multiple queries, leading to significant savings in\nceratain cases.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:49:42 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Darwiche", "Adnan", ""]]}, {"id": "1301.3852", "submitter": "Scott Davies", "authors": "Scott Davies, Andrew Moore", "title": "Mix-nets: Factored Mixtures of Gaussians in Bayesian Networks With Mixed\n  Continuous And Discrete Variables", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-168-175", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently developed techniques have made it possible to quickly learn accurate\nprobability density functions from data in low-dimensional continuous space. In\nparticular, mixtures of Gaussians can be fitted to data very quickly using an\naccelerated EM algorithm that employs multiresolution kd-trees (Moore, 1999).\nIn this paper, we propose a kind of Bayesian networks in which low-dimensional\nmixtures of Gaussians over different subsets of the domain's variables are\ncombined into a coherent joint probability model over the entire domain. The\nnetwork is also capable of modeling complex dependencies between discrete\nvariables and continuous variables without requiring discretization of the\ncontinuous variables. We present efficient heuristic algorithms for\nautomatically learning these networks from data, and perform comparative\nexperiments illustrated how well these networks model real scientific data and\nsynthetic data. We also briefly discuss some possible improvements to the\nnetworks, as well as possible applications.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:49:57 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Davies", "Scott", ""], ["Moore", "Andrew", ""]]}, {"id": "1301.3853", "submitter": "Arnaud Doucet", "authors": "Arnaud Doucet, Nando de Freitas, Kevin Murphy, Stuart Russell", "title": "Rao-Blackwellised Particle Filtering for Dynamic Bayesian Networks", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-176-183", "categories": "cs.LG cs.AI stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle filters (PFs) are powerful sampling-based inference/learning\nalgorithms for dynamic Bayesian networks (DBNs). They allow us to treat, in a\nprincipled way, any type of probability distribution, nonlinearity and\nnon-stationarity. They have appeared in several fields under such names as\n\"condensation\", \"sequential Monte Carlo\" and \"survival of the fittest\". In this\npaper, we show how we can exploit the structure of the DBN to increase the\nefficiency of particle filtering, using a technique known as\nRao-Blackwellisation. Essentially, this samples some of the variables, and\nmarginalizes out the rest exactly, using the Kalman filter, HMM filter,\njunction tree algorithm, or any other finite dimensional optimal filter. We\nshow that Rao-Blackwellised particle filters (RBPFs) lead to more accurate\nestimates than standard PFs. We demonstrate RBPFs on two problems, namely\nnon-stationary online regression with radial basis function networks and robot\nlocalization and map building. We also discuss other potential application\nareas and provide references to some finite dimensional optimal filters.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:50:01 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Doucet", "Arnaud", ""], ["de Freitas", "Nando", ""], ["Murphy", "Kevin", ""], ["Russell", "Stuart", ""]]}, {"id": "1301.3855", "submitter": "Nir Friedman", "authors": "Nir Friedman, Dan Geiger, Noam Lotner", "title": "Likelihood Computations Using Value Abstractions", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-192-200", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we use evidence-specific value abstraction for speeding\nBayesian networks inference. This is done by grouping variable values and\ntreating the combined values as a single entity. As we show, such abstractions\ncan exploit regularities in conditional probability distributions and also the\nspecific values of observed variables. To formally justify value abstraction,\nwe define the notion of safe value abstraction and devise inference algorithms\nthat use it to reduce the cost of inference. Our procedure is particularly\nuseful for learning complex networks with many hidden variables. In such cases,\nrepeated likelihood computations are required for EM or other parameter\noptimization techniques. Since these computations are repeated with respect to\nthe same evidence set, our methods can provide significant speedup to the\nlearning procedure. We demonstrate the algorithm on genetic linkage problems\nwhere the use of value abstraction sometimes differentiates between a feasible\nand non-feasible solution.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:50:10 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Friedman", "Nir", ""], ["Geiger", "Dan", ""], ["Lotner", "Noam", ""]]}, {"id": "1301.3856", "submitter": "Nir Friedman", "authors": "Nir Friedman, Daphne Koller", "title": "Being Bayesian about Network Structure", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-201-210", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many domains, we are interested in analyzing the structure of the\nunderlying distribution, e.g., whether one variable is a direct parent of the\nother. Bayesian model-selection attempts to find the MAP model and use its\nstructure to answer these questions. However, when the amount of available data\nis modest, there might be many models that have non-negligible posterior. Thus,\nwe want compute the Bayesian posterior of a feature, i.e., the total posterior\nprobability of all models that contain it. In this paper, we propose a new\napproach for this task. We first show how to efficiently compute a sum over the\nexponential number of networks that are consistent with a fixed ordering over\nnetwork variables. This allows us to compute, for a given ordering, both the\nmarginal probability of the data and the posterior of a feature. We then use\nthis result as the basis for an algorithm that approximates the Bayesian\nposterior of a feature. Our approach uses a Markov Chain Monte Carlo (MCMC)\nmethod, but over orderings rather than over network structures. The space of\norderings is much smaller and more regular than the space of structures, and\nhas a smoother posterior `landscape'. We present empirical results on synthetic\nand real-life datasets that compare our approach to full model averaging (when\npossible), to MCMC over network structures, and to a non-Bayesian bootstrap\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:50:14 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Friedman", "Nir", ""], ["Koller", "Daphne", ""]]}, {"id": "1301.3857", "submitter": "Nir Friedman", "authors": "Nir Friedman, Iftach Nachman", "title": "Gaussian Process Networks", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-211-219", "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the problem of learning the structure of a Bayesian\nnetwork in domains with continuous variables. This task requires a procedure\nfor comparing different candidate structures. In the Bayesian framework, this\nis done by evaluating the {em marginal likelihood/} of the data given a\ncandidate structure. This term can be computed in closed-form for standard\nparametric families (e.g., Gaussians), and can be approximated, at some\ncomputational cost, for some semi-parametric families (e.g., mixtures of\nGaussians).\n  We present a new family of continuous variable probabilistic networks that\nare based on {em Gaussian Process/} priors. These priors are semi-parametric in\nnature and can learn almost arbitrary noisy functional relations. Using these\npriors, we can directly compute marginal likelihoods for structure learning.\nThe resulting method can discover a wide range of functional dependencies in\nmultivariate data. We develop the Bayesian score of Gaussian Process Networks\nand describe how to learn them from data. We present empirical results on\nartificial data as well as on real-life domains with non-linear dependencies.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:50:18 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Friedman", "Nir", ""], ["Nachman", "Iftach", ""]]}, {"id": "1301.3858", "submitter": "Phan H. Giang", "authors": "Phan H. Giang, Prakash P. Shenoy", "title": "A Qualitative Linear Utility Theory for Spohn's Theory of Epistemic\n  Beliefs", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-220-229", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we formulate a qualitative \"linear\" utility theory for\nlotteries in which uncertainty is expressed qualitatively using a Spohnian\ndisbelief function. We argue that a rational decision maker facing an uncertain\ndecision problem in which the uncertainty is expressed qualitatively should\nbehave so as to maximize \"qualitative expected utility.\" Our axiomatization of\nthe qualitative utility is similar to the axiomatization developed by von\nNeumann and Morgenstern for probabilistic lotteries. We compare our results\nwith other recent results in qualitative decision making.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:50:22 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Giang", "Phan H.", ""], ["Shenoy", "Prakash P.", ""]]}, {"id": "1301.3859", "submitter": "Peter J Gorniak", "authors": "Peter J. Gorniak, David L. Poole", "title": "Building a Stochastic Dynamic Model of Application Use", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-230-237", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many intelligent user interfaces employ application and user models to\ndetermine the user's preferences, goals and likely future actions. Such models\nrequire application analysis, adaptation and expansion. Building and\nmaintaining such models adds a substantial amount of time and labour to the\napplication development cycle. We present a system that observes the interface\nof an unmodified application and records users' interactions with the\napplication. From a history of such observations we build a coarse state space\nof observed interface states and actions between them. To refine the space, we\nhypothesize sub-states based upon the histories that led users to a given\nstate. We evaluate the information gain of possible state splits, varying the\nlength of the histories considered in such splits. In this way, we\nautomatically produce a stochastic dynamic model of the application and of how\nit is used. To evaluate our approach, we present models derived from real-world\napplication usage data.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:50:26 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Gorniak", "Peter J.", ""], ["Poole", "David L.", ""]]}, {"id": "1301.3860", "submitter": "Peter D Grunwald", "authors": "Peter D. Grunwald", "title": "Maximum Entropy and the Glasses You Are Looking Through", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-238-246", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an interpretation of the Maximum Entropy (MaxEnt) Principle in\ngame-theoretic terms. Based on this interpretation, we make a formal\ndistinction between different ways of {em applying/} Maximum Entropy\ndistributions. MaxEnt has frequently been criticized on the grounds that it\nleads to highly representation dependent results. Our distinction allows us to\navoid this problem in many cases.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:50:30 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Grunwald", "Peter D.", ""]]}, {"id": "1301.3861", "submitter": "Michael Harvey", "authors": "Michael Harvey, Radford M. Neal", "title": "Inference for Belief Networks Using Coupling From the Past", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-256-263", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference for belief networks using Gibbs sampling produces a distribution\nfor unobserved variables that differs from the correct distribution by a\n(usually) unknown error, since convergence to the right distribution occurs\nonly asymptotically. The method of \"coupling from the past\" samples from\nexactly the correct distribution by (conceptually) running dependent Gibbs\nsampling simulations from every possible starting state from a time far enough\nin the past that all runs reach the same state at time t=0. Explicitly\nconsidering every possible state is intractable for large networks, however. We\npropose a method for layered noisy-or networks that uses a compact, but often\nimprecise, summary of a set of states. This method samples from exactly the\ncorrect distribution, and requires only about twice the time per step as\nordinary Gibbs sampling, but it may require more simulation steps than would be\nneeded if chains were tracked exactly.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:50:34 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Harvey", "Michael", ""], ["Neal", "Radford M.", ""]]}, {"id": "1301.3862", "submitter": "David Heckerman", "authors": "David Heckerman, David Maxwell Chickering, Christopher Meek, Robert\n  Rounthwaite, Carl Kadie", "title": "Dependency Networks for Collaborative Filtering and Data Visualization", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-264-273", "categories": "cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a graphical model for probabilistic relationships---an\nalternative to the Bayesian network---called a dependency network. The graph of\na dependency network, unlike a Bayesian network, is potentially cyclic. The\nprobability component of a dependency network, like a Bayesian network, is a\nset of conditional distributions, one for each node given its parents. We\nidentify several basic properties of this representation and describe a\ncomputationally efficient procedure for learning the graph and probability\ncomponents from data. We describe the application of this representation to\nprobabilistic inference, collaborative filtering (the task of predicting\npreferences), and the visualization of acausal predictive relationships.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:50:38 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Heckerman", "David", ""], ["Chickering", "David Maxwell", ""], ["Meek", "Christopher", ""], ["Rounthwaite", "Robert", ""], ["Kadie", "Carl", ""]]}, {"id": "1301.3863", "submitter": "Soren Hojsgaard", "authors": "Soren Hojsgaard", "title": "YGGDRASIL - A Statistical Package for Learning Split Models", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-274-281", "categories": "cs.AI cs.MS stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are two main objectives of this paper. The first is to present a\nstatistical framework for models with context specific independence structures,\ni.e., conditional independences holding only for sepcific values of the\nconditioning variables. This framework is constituted by the class of split\nmodels. Split models are extension of graphical models for contigency tables\nand allow for a more sophisticiated modelling than graphical models. The\ntreatment of split models include estimation, representation and a Markov\nproperty for reading off those independencies holding in a specific context.\nThe second objective is to present a software package named YGGDRASIL which is\ndesigned for statistical inference in split models, i.e., for learning such\nmodels on the basis of data.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:50:42 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Hojsgaard", "Soren", ""]]}, {"id": "1301.3864", "submitter": "Michael C. Horsch", "authors": "Michael C. Horsch, Bill Havens", "title": "Probabilistic Arc Consistency: A Connection between Constraint Reasoning\n  and Probabilistic Reasoning", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-282-290", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We document a connection between constraint reasoning and probabilistic\nreasoning. We present an algorithm, called {em probabilistic arc consistency},\nwhich is both a generalization of a well known algorithm for arc consistency\nused in constraint reasoning, and a specialization of the belief updating\nalgorithm for singly-connected networks. Our algorithm is exact for singly-\nconnected constraint problems, but can work well as an approximation for\narbitrary problems. We briefly discuss some empirical results, and related\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:50:46 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Horsch", "Michael C.", ""], ["Havens", "Bill", ""]]}, {"id": "1301.3866", "submitter": "Radim Jirousek", "authors": "Radim Jirousek", "title": "Marginalization in Composed Probabilistic Models", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-301-308", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Composition of low-dimensional distributions, whose foundations were laid in\nthe papaer published in the Proceeding of UAI'97 (Jirousek 1997), appeared to\nbe an alternative apparatus to describe multidimensional probabilistic models.\nIn contrast to Graphical Markov Models, which define multidomensinoal\ndistributions in a declarative way, this approach is rather procedural.\nOrdering of low-dimensional distributions into a proper sequence fully defines\nthe resepctive computational procedure; therefore, a stury of different type of\ngenerating sequences is one fo the central problems in this field. Thus, it\nappears that an important role is played by special sequences that are called\nperfect. Their main characterization theorems are presetned in this paper.\nHowever, the main result of this paper is a solution to the problem of\nmargnialization for general sequences. The main theorem describes a way to\nobtain a generating sequence that defines the model corresponding to the\nmarginal of the distribution defined by an arbitrary genearting sequence. From\nthis theorem the reader can see to what extent these comutations are local;\ni.e., the sequence consists of marginal distributions whose computation must be\nmade by summing up over the values of the variable eliminated (the paper deals\nwith finite model).\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:50:54 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Jirousek", "Radim", ""]]}, {"id": "1301.3867", "submitter": "Michael Kearns", "authors": "Michael Kearns, Yishay Mansour, Satinder Singh", "title": "Fast Planning in Stochastic Games", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-309-316", "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic games generalize Markov decision processes (MDPs) to a multiagent\nsetting by allowing the state transitions to depend jointly on all player\nactions, and having rewards determined by multiplayer matrix games at each\nstate. We consider the problem of computing Nash equilibria in stochastic\ngames, the analogue of planning in MDPs. We begin by providing a generalization\nof finite-horizon value iteration that computes a Nash strategy for each player\nin generalsum stochastic games. The algorithm takes an arbitrary Nash selection\nfunction as input, which allows the translation of local choices between\nmultiple Nash equilibria into the selection of a single global Nash\nequilibrium.\n  Our main technical result is an algorithm for computing near-Nash equilibria\nin large or infinite state spaces. This algorithm builds on our finite-horizon\nvalue iteration algorithm, and adapts the sparse sampling methods of Kearns,\nMansour and Ng (1999) to stochastic games. We conclude by descrbing a\ncounterexample showing that infinite-horizon discounted value iteration, which\nwas shown by shaplely to converge in the zero-sum case (a result we give extend\nslightly here), does not converge in the general-sum case.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:50:58 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Kearns", "Michael", ""], ["Mansour", "Yishay", ""], ["Singh", "Satinder", ""]]}, {"id": "1301.3868", "submitter": "Uffe Kj{\\ae}rulff", "authors": "Uffe Kj{\\ae}rulff, Linda C. van der Gaag", "title": "Making Sensitivity Analysis Computationally Efficient", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-317-325", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To investigate the robustness of the output probabilities of a Bayesian\nnetwork, a sensitivity analysis can be performed. A one-way sensitivity\nanalysis establishes, for each of the probability parameters of a network, a\nfunction expressing a posterior marginal probability of interest in terms of\nthe parameter. Current methods for computing the coefficients in such a\nfunction rely on a large number of network evaluations. In this paper, we\npresent a method that requires just a single outward propagation in a junction\ntree for establishing the coefficients in the functions for all possible\nparameters; in addition, an inward propagation is required for processing\nevidence. Conversely, the method requires a single outward propagation for\ncomputing the coefficients in the functions expressing all possible posterior\nmarginals in terms of a single parameter. We extend these results to an n-way\nsensitivity analysis in which sets of parameters are studied.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:51:02 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Kj\u00e6rulff", "Uffe", ""], ["van der Gaag", "Linda C.", ""]]}, {"id": "1301.3869", "submitter": "Daphne Koller", "authors": "Daphne Koller, Ron Parr", "title": "Policy Iteration for Factored MDPs", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-326-334", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many large MDPs can be represented compactly using a dynamic Bayesian\nnetwork. Although the structure of the value function does not retain the\nstructure of the process, recent work has shown that value functions in\nfactored MDPs can often be approximated well using a decomposed value function:\na linear combination of <I>restricted</I> basis functions, each of which refers\nonly to a small subset of variables. An approximate value function for a\nparticular policy can be computed using approximate dynamic programming, but\nthis approach (and others) can only produce an approximation relative to a\ndistance metric which is weighted by the stationary distribution of the current\npolicy. This type of weighted projection is ill-suited to policy improvement.\nWe present a new approach to value determination, that uses a simple\nclosed-form computation to directly compute a least-squares decomposed\napproximation to the value function <I>for any weights</I>. We then use this\nvalue determination algorithm as a subroutine in a policy iteration process. We\nshow that, under reasonable restrictions, the policies induced by a factored\nvalue function are compactly represented, and can be manipulated efficiently in\na policy iteration process. We also present a method for computing error bounds\nfor decomposed value functions using a variable-elimination algorithm for\nfunction optimization. The complexity of all of our algorithms depends on the\nfactorization of system dynamics and of the approximate value function.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:51:06 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Koller", "Daphne", ""], ["Parr", "Ron", ""]]}, {"id": "1301.3870", "submitter": "Pierfrancesco La Mura", "authors": "Pierfrancesco La Mura", "title": "Game Networks", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-335-342", "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Game networks (G nets), a novel representation for multi-agent\ndecision problems. Compared to other game-theoretic representations, such as\nstrategic or extensive forms, G nets are more structured and more compact; more\nfundamentally, G nets constitute a computationally advantageous framework for\nstrategic inference, as both probability and utility independencies are\ncaptured in the structure of the network and can be exploited in order to\nsimplify the inference process. An important aspect of multi-agent reasoning is\nthe identification of some or all of the strategic equilibria in a game; we\npresent original convergence methods for strategic equilibrium which can take\nadvantage of strategic separabilities in the G net structure in order to\nsimplify the computations. Specifically, we describe a method which identifies\na unique equilibrium as a function of the game payoffs, and one which\nidentifies all equilibria.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:51:10 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["La Mura", "Pierfrancesco", ""]]}, {"id": "1301.3871", "submitter": "Pedro Larra\\~naga", "authors": "Pedro Larra\\~naga, Ramon Etxeberria, Jose A. Lozano, Jose M. Pena", "title": "Combinatorial Optimization by Learning and Simulation of Bayesian\n  Networks", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-343-352", "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows how the Bayesian network paradigm can be used in order to\nsolve combinatorial optimization problems. To do it some methods of structure\nlearning from data and simulation of Bayesian networks are inserted inside\nEstimation of Distribution Algorithms (EDA). EDA are a new tool for\nevolutionary computation in which populations of individuals are created by\nestimation and simulation of the joint probability distribution of the selected\nindividuals. We propose new approaches to EDA for combinatorial optimization\nbased on the theory of probabilistic graphical models. Experimental results are\nalso presented.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:51:14 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Larra\u00f1aga", "Pedro", ""], ["Etxeberria", "Ramon", ""], ["Lozano", "Jose A.", ""], ["Pena", "Jose M.", ""]]}, {"id": "1301.3872", "submitter": "Tsai-Ching Lu", "authors": "Tsai-Ching Lu, Marek J. Druzdzel, Tze-Yun Leong", "title": "Causal Mechanism-based Model Construction", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-353-362", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for building graphical causal model that is based on\nthe concept of causal mechanisms. Causal models are intuitive for human users\nand, more importantly, support the prediction of the effect of manipulation. We\ndescribe an implementation of the proposed framework as an interactive model\nconstruction module, ImaGeNIe, in SMILE (Structural Modeling, Inference, and\nLearning Engine) and in GeNIe (SMILE's Windows user interface).\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:51:18 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Lu", "Tsai-Ching", ""], ["Druzdzel", "Marek J.", ""], ["Leong", "Tze-Yun", ""]]}, {"id": "1301.3873", "submitter": "Thomas Lukasiewicz", "authors": "Thomas Lukasiewicz", "title": "Credal Networks under Maximum Entropy", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-363-370", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply the principle of maximum entropy to select a unique joint\nprobability distribution from the set of all joint probability distributions\nspecified by a credal network. In detail, we start by showing that the unique\njoint distribution of a Bayesian tree coincides with the maximum entropy model\nof its conditional distributions. This result, however, does not hold anymore\nfor general Bayesian networks. We thus present a new kind of maximum entropy\nmodels, which are computed sequentially. We then show that for all general\nBayesian networks, the sequential maximum entropy model coincides with the\nunique joint distribution. Moreover, we apply the new principle of sequential\nmaximum entropy to interval Bayesian networks and more generally to credal\nnetworks. We especially show that this application is equivalent to a number of\nsmall local entropy maximizations.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:51:22 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Lukasiewicz", "Thomas", ""]]}, {"id": "1301.3874", "submitter": "Peter McBurney", "authors": "Peter McBurney, Simon Parsons", "title": "Risk Agoras: Dialectical Argumentation for Scientific Reasoning", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-371-379", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a formal framework for intelligent systems which can reason about\nscientific domains, in particular about the carcinogenicity of chemicals, and\nwe study its properties. Our framework is grounded in a philosophy of\nscientific enquiry and discourse, and uses a model of dialectical\nargumentation. The formalism enables representation of scientific uncertainty\nand conflict in a manner suitable for qualitative reasoning about the domain.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:51:26 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["McBurney", "Peter", ""], ["Parsons", "Simon", ""]]}, {"id": "1301.3875", "submitter": "Marina Meila", "authors": "Marina Meila, Tommi S. Jaakkola", "title": "Tractable Bayesian Learning of Tree Belief Networks", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-380-388", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present decomposable priors, a family of priors over\nstructure and parameters of tree belief nets for which Bayesian learning with\ncomplete observations is tractable, in the sense that the posterior is also\ndecomposable and can be completely determined analytically in polynomial time.\nThis follows from two main results: First, we show that factored distributions\nover spanning trees in a graph can be integrated in closed form. Second, we\nexamine priors over tree parameters and show that a set of assumptions similar\nto (Heckerman and al. 1995) constrain the tree parameter priors to be a\ncompactly parameterized product of Dirichlet distributions. Beside allowing for\nexact Bayesian learning, these results permit us to formulate a new class of\ntractable latent variable models in which the likelihood of a data point is\ncomputed through an ensemble average over tree structures.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:51:30 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Meila", "Marina", ""], ["Jaakkola", "Tommi S.", ""]]}, {"id": "1301.3876", "submitter": "Brian Milch", "authors": "Brian Milch, Daphne Koller", "title": "Probabilistic Models for Agents' Beliefs and Decisions", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-389-396", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications of intelligent systems require reasoning about the mental\nstates of agents in the domain. We may want to reason about an agent's beliefs,\nincluding beliefs about other agents; we may also want to reason about an\nagent's preferences, and how his beliefs and preferences relate to his\nbehavior. We define a probabilistic epistemic logic (PEL) in which belief\nstatements are given a formal semantics, and provide an algorithm for asserting\nand querying PEL formulas in Bayesian networks. We then show how to reason\nabout an agent's behavior by modeling his decision process as an influence\ndiagram and assuming that he behaves rationally. PEL can then be used for\nreasoning from an agent's observed actions to conclusions about other aspects\nof the domain, including unobserved domain variables and the agent's mental\nstates.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:51:34 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Milch", "Brian", ""], ["Koller", "Daphne", ""]]}, {"id": "1301.3878", "submitter": "Andrew Y. Ng", "authors": "Andrew Y. Ng, Michael I. Jordan", "title": "PEGASUS: A Policy Search Method for Large MDPs and POMDPs", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-406-415", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach to the problem of searching a space of policies for\na Markov decision process (MDP) or a partially observable Markov decision\nprocess (POMDP), given a model. Our approach is based on the following\nobservation: Any (PO)MDP can be transformed into an \"equivalent\" POMDP in which\nall state transitions (given the current state and action) are deterministic.\nThis reduces the general problem of policy search to one in which we need only\nconsider POMDPs with deterministic transitions. We give a natural way of\nestimating the value of all policies in these transformed POMDPs. Policy search\nis then simply performed by searching for a policy with high estimated value.\nWe also establish conditions under which our value estimates will be good,\nrecovering theoretical results similar to those of Kearns, Mansour and Ng\n(1999), but with \"sample complexity\" bounds that have only a polynomial rather\nthan exponential dependence on the horizon time. Our method applies to\narbitrary POMDPs, including ones with infinite state and action spaces. We also\npresent empirical results for our approach on a small discrete problem, and on\na complex continuous state/continuous action problem involving learning to ride\na bicycle.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:51:42 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Ng", "Andrew Y.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1301.3879", "submitter": "Thomas D. Nielsen", "authors": "Thomas D. Nielsen, Finn Verner Jensen", "title": "Representing and Solving Asymmetric Bayesian Decision Problems", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-416-425", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the representation and solution of asymmetric Bayesian\ndecision problems. We present a formal framework, termed asymmetric influence\ndiagrams, that is based on the influence diagram and allows an efficient\nrepresentation of asymmetric decision problems. As opposed to existing\nframeworks, the asymmetric influece diagram primarily encodes asymmetry at the\nqualitative level and it can therefore be read directly from the model. We give\nan algorithm for solving asymmetric influence diagrams. The algorithm initially\ndecomposes the asymmetric decision problem into a structure of symmetric\nsubproblems organized as a tree. A solution to the decision problem can then be\nfound by propagating from the leaves toward the root using existing evaluation\nmethods to solve the sub-problems.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:51:46 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Nielsen", "Thomas D.", ""], ["Jensen", "Finn Verner", ""]]}, {"id": "1301.3880", "submitter": "Thomas D. Nielsen", "authors": "Thomas D. Nielsen, Pierre-Henri Wuillemin, Finn Verner Jensen, Uffe\n  Kj{\\ae}rulff", "title": "Using ROBDDs for Inference in Bayesian Networks with Troubleshooting as\n  an Example", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-426-435", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When using Bayesian networks for modelling the behavior of man-made\nmachinery, it usually happens that a large part of the model is deterministic.\nFor such Bayesian networks deterministic part of the model can be represented\nas a Boolean function, and a central part of belief updating reduces to the\ntask of calculating the number of satisfying configurations in a Boolean\nfunction. In this paper we explore how advances in the calculation of Boolean\nfunctions can be adopted for belief updating, in particular within the context\nof troubleshooting. We present experimental results indicating a substantial\nspeed-up compared to traditional junction tree propagation.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:51:50 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Nielsen", "Thomas D.", ""], ["Wuillemin", "Pierre-Henri", ""], ["Jensen", "Finn Verner", ""], ["Kj\u00e6rulff", "Uffe", ""]]}, {"id": "1301.3881", "submitter": "Dennis Nilsson", "authors": "Dennis Nilsson, Steffen L. Lauritzen", "title": "Evaluating Influence Diagrams using LIMIDs", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-436-445", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach to the solution of decision problems formulated as\ninfluence diagrams. The approach converts the influence diagram into a simpler\nstructure, the LImited Memory Influence Diagram (LIMID), where only the\nrequisite information for the computation of optimal policies is depicted.\nBecause the requisite information is explicitly represented in the diagram, the\nevaluation procedure can take advantage of it. In this paper we show how to\nconvert an influence diagram to a LIMID and describe the procedure for finding\nan optimal strategy. Our approach can yield significant savings of memory and\ncomputational time when compared to traditional methods.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:51:54 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Nilsson", "Dennis", ""], ["Lauritzen", "Steffen L.", ""]]}, {"id": "1301.3882", "submitter": "Luis E. Ortiz", "authors": "Luis E. Ortiz, Leslie Pack Kaelbling", "title": "Adaptive Importance Sampling for Estimation in Structured Domains", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-446-454", "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sampling is an important tool for estimating large, complex sums and\nintegrals over high dimensional spaces. For instance, important sampling has\nbeen used as an alternative to exact methods for inference in belief networks.\nIdeally, we want to have a sampling distribution that provides optimal-variance\nestimators. In this paper, we present methods that improve the sampling\ndistribution by systematically adapting it as we obtain information from the\nsamples. We present a stochastic-gradient-descent method for sequentially\nupdating the sampling distribution based on the direct minization of the\nvariance. We also present other stochastic-gradient-descent methods based on\nthe minimizationof typical notions of distance between the current sampling\ndistribution and approximations of the target, optimal distribution. We finally\nvalidate and compare the different methods empirically by applying them to the\nproblem of action evaluation in influence diagrams.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:51:58 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Ortiz", "Luis E.", ""], ["Kaelbling", "Leslie Pack", ""]]}, {"id": "1301.3883", "submitter": "Tim Paek", "authors": "Tim Paek, Eric J. Horvitz", "title": "Conversation as Action Under Uncertainty", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-455-464", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversations abound with uncetainties of various kinds. Treating\nconversation as inference and decision making under uncertainty, we propose a\ntask independent, multimodal architecture for supporting robust continuous\nspoken dialog called Quartet. We introduce four interdependent levels of\nanalysis, and describe representations, inference procedures, and decision\nstrategies for managing uncertainties within and between the levels. We\nhighlight the approach by reviewing interactions between a user and two spoken\ndialog systems developed using the Quartet architecture: Prsenter, a prototype\nsystem for navigating Microsoft PowerPoint presentations, and the Bayesian\nReceptionist, a prototype system for dealing with tasks typically handled by\nfront desk receptionists at the Microsoft corporate campus.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:52:02 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Paek", "Tim", ""], ["Horvitz", "Eric J.", ""]]}, {"id": "1301.3884", "submitter": "Dmitry Y. Pavlov", "authors": "Dmitry Y. Pavlov, Heikki Mannila, Padhraic Smyth", "title": "Probabilistic Models for Query Approximation with Large Sparse Binary\n  Datasets", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-465-472", "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large sparse sets of binary transaction data with millions of records and\nthousands of attributes occur in various domains: customers purchasing\nproducts, users visiting web pages, and documents containing words are just\nthree typical examples. Real-time query selectivity estimation (the problem of\nestimating the number of rows in the data satisfying a given predicate) is an\nimportant practical problem for such databases.\n  We investigate the application of probabilistic models to this problem. In\nparticular, we study a Markov random field (MRF) approach based on frequent\nsets and maximum entropy, and compare it to the independence model and the\nChow-Liu tree model. We find that the MRF model provides substantially more\naccurate probability estimates than the other methods but is more expensive\nfrom a computational and memory viewpoint. To alleviate the computational\nrequirements we show how one can apply bucket elimination and clique tree\napproaches to take advantage of structure in the models and in the queries. We\nprovide experimental results on two large real-world transaction datasets.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:52:06 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Pavlov", "Dmitry Y.", ""], ["Mannila", "Heikki", ""], ["Smyth", "Padhraic", ""]]}, {"id": "1301.3887", "submitter": "Pascal Poupart", "authors": "Pascal Poupart, Craig Boutilier", "title": "Value-Directed Belief State Approximation for POMDPs", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-497-506", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem belief-state monitoring for the purposes of\nimplementing a policy for a partially-observable Markov decision process\n(POMDP), specifically how one might approximate the belief state. Other schemes\nfor belief-state approximation (e.g., based on minimixing a measures such as\nKL-diveregence between the true and estimated state) are not necessarily\nappropriate for POMDPs. Instead we propose a framework for analyzing\nvalue-directed approximation schemes, where approximation quality is determined\nby the expected error in utility rather than by the error in the belief state\nitself. We propose heuristic methods for finding good projection schemes for\nbelief state estimation - exhibiting anytime characteristics - given a POMDP\nvalue fucntion. We also describe several algorithms for constructing bounds on\nthe error in decision quality (expected utility) associated with acting in\naccordance with a given belief state approximation.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:52:18 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Poupart", "Pascal", ""], ["Boutilier", "Craig", ""]]}, {"id": "1301.3888", "submitter": "David V. Pynadath", "authors": "David V. Pynadath, Michael P. Wellman", "title": "Probabilistic State-Dependent Grammars for Plan Recognition", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-507-514", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Techniques for plan recognition under uncertainty require a stochastic model\nof the plan-generation process. We introduce Probabilistic State-Dependent\nGrammars (PSDGs) to represent an agent's plan-generation process. The PSDG\nlanguage model extends probabilistic context-free grammars (PCFGs) by allowing\nproduction probabilities to depend on an explicit model of the planning agent's\ninternal and external state. Given a PSDG description of the plan-generation\nprocess, we can then use inference algorithms that exploit the particular\nindependence properties of the PSDG language to efficiently answer\nplan-recognition queries. The combination of the PSDG language model and\ninference algorithms extends the range of plan-recognition domains for which\npractical probabilistic inference is possible, as illustrated by applications\nin traffic monitoring and air combat.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:52:22 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Pynadath", "David V.", ""], ["Wellman", "Michael P.", ""]]}, {"id": "1301.3889", "submitter": "Silja Renooij", "authors": "Silja Renooij, Linda C. van der Gaag, Simon Parsons, Shaw Green", "title": "Pivotal Pruning of Trade-offs in QPNs", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-515-522", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Qualitative probabilistic networks have been designed for probabilistic\nreasoning in a qualitative way. Due to their coarse level of representation\ndetail, qualitative probabilistic networks do not provide for resolving\ntrade-offs and typically yield ambiguous results upon inference. We present an\nalgorithm for computing more insightful results for unresolved trade-offs. The\nalgorithm builds upon the idea of using pivots to zoom in on the trade-offs and\nidentifying the information that would serve to resolve them.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:52:25 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Renooij", "Silja", ""], ["van der Gaag", "Linda C.", ""], ["Parsons", "Simon", ""], ["Green", "Shaw", ""]]}, {"id": "1301.3893", "submitter": "Claus Skaanning", "authors": "Claus Skaanning", "title": "A Knowledge Acquisition Tool for Bayesian-Network Troubleshooters", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-549-557", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a domain-specific knowledge acquisition tool for\nintelligent automated troubleshooters based on Bayesian networks. No Bayesian\nnetwork knowledge is required to use the tool, and troubleshooting information\ncan be specified as natural and intuitive as possible. Probabilities can be\nspecified in the direction that is most natural to the domain expert. Thus, the\nknowledge acquisition efficiently removes the traditional knowledge acquisition\nbottleneck of Bayesian networks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:52:41 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Skaanning", "Claus", ""]]}, {"id": "1301.3894", "submitter": "Harald Steck", "authors": "Harald Steck", "title": "On the Use of Skeletons when Learning in Bayesian Networks", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-558-565", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a heuristic operator which aims at simultaneously\noptimizing the orientations of all the edges in an intermediate Bayesian\nnetwork structure during the search process. This is done by alternating\nbetween the space of directed acyclic graphs (DAGs) and the space of skeletons.\nThe found orientations of the edges are based on a scoring function rather than\non induced conditional independences. This operator can be used as an extension\nto commonly employed search strategies. It is evaluated in experiments with\nartificial and real-world data.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:52:45 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Steck", "Harald", ""]]}, {"id": "1301.3895", "submitter": "Amos J. Storkey", "authors": "Amos J. Storkey", "title": "Dynamic Trees: A Structured Variational Method Giving Efficient\n  Propagation Rules", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-566-573", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic trees are mixtures of tree structured belief networks. They solve\nsome of the problems of fixed tree networks at the cost of making exact\ninference intractable. For this reason approximate methods such as sampling or\nmean field approaches have been used. However, mean field approximations assume\na factorized distribution over node states. Such a distribution seems unlickely\nin the posterior, as nodes are highly correlated in the prior. Here a\nstructured variational approach is used, where the posterior distribution over\nthe non-evidential nodes is itself approximated by a dynamic tree. It turns out\nthat this form can be used tractably and efficiently. The result is a set of\nupdate rules which can propagate information through the network to obtain both\na full variational approximation, and the relevant marginals. The progagtion\nrules are more efficient than the mean field approach and give noticeable\nquantitative and qualitative improvement in the inference. The marginals\ncalculated give better approximations to the posterior than loopy propagation\non a small toy problem.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:52:49 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Storkey", "Amos J.", ""]]}, {"id": "1301.3897", "submitter": "Jin Tian", "authors": "Jin Tian", "title": "A Branch-and-Bound Algorithm for MDL Learning Bayesian Networks", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-580-588", "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends the work in [Suzuki, 1996] and presents an efficient\ndepth-first branch-and-bound algorithm for learning Bayesian network\nstructures, based on the minimum description length (MDL) principle, for a\ngiven (consistent) variable ordering. The algorithm exhaustively searches\nthrough all network structures and guarantees to find the network with the best\nMDL score. Preliminary experiments show that the algorithm is efficient, and\nthat the time complexity grows slowly with the sample size. The algorithm is\nuseful for empirically studying both the performance of suboptimal heuristic\nsearch algorithms and the adequacy of the MDL principle in learning Bayesian\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:52:56 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Tian", "Jin", ""]]}, {"id": "1301.3898", "submitter": "Jin Tian", "authors": "Jin Tian, Judea Pearl", "title": "Probabilities of Causation: Bounds and Identification", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-589-598", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the problem of estimating the probability that one\nevent was a cause of another in a given scenario. Using structural-semantical\ndefinitions of the probabilities of necessary or sufficient causation (or\nboth), we show how to optimally bound these quantities from data obtained in\nexperimental and observational studies, making minimal assumptions concerning\nthe data-generating process. In particular, we strengthen the results of Pearl\n(1999) by weakening the data-generation assumptions and deriving theoretically\nsharp bounds on the probabilities of causation. These results delineate\nprecisely how empirical data can be used both in settling questions of\nattribution and in solving attribution-related problems of decision making.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:53:00 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Tian", "Jin", ""], ["Pearl", "Judea", ""]]}, {"id": "1301.3899", "submitter": "Shivakumar Vaithyanathan", "authors": "Shivakumar Vaithyanathan, Byron E Dom", "title": "Model-Based Hierarchical Clustering", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-599-608", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to model-based hierarchical clustering by formulating\nan objective function based on a Bayesian analysis. This model organizes the\ndata into a cluster hierarchy while specifying a complex feature-set\npartitioning that is a key component of our model. Features can have either a\nunique distribution in every cluster or a common distribution over some (or\neven all) of the clusters. The cluster subsets over which these features have\nsuch a common distribution correspond to the nodes (clusters) of the tree\nrepresenting the hierarchy. We apply this general model to the problem of\ndocument clustering for which we use a multinomial likelihood function and\nDirichlet priors. Our algorithm consists of a two-stage process wherein we\nfirst perform a flat clustering followed by a modified hierarchical\nagglomerative merging process that includes determining the features that will\nhave common distributions over the merged clusters. The regularization induced\nby using the marginal likelihood automatically determines the optimal model\nstructure including number of clusters, the depth of the tree and the subset of\nfeatures to be modeled as having a common distribution at each node. We present\nexperimental results on both synthetic data and a real document collection.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:53:05 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Vaithyanathan", "Shivakumar", ""], ["Dom", "Byron E", ""]]}, {"id": "1301.3900", "submitter": "Jirina Vejnarova", "authors": "Jirina Vejnarova", "title": "Conditional Independence and Markov Properties in Possibility Theory", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-609-616", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional independence and Markov properties are powerful tools allowing\nexpression of multidimensional probability distributions by means of\nlow-dimensional ones. As multidimensional possibilistic models have been\nstudied for several years, the demand for analogous tools in possibility theory\nseems to be quite natural. This paper is intended to be a promotion of de\nCooman's measure-theoretic approcah to possibility theory, as this approach\nallows us to find analogies to many important results obtained in probabilistic\nframework. First, we recall semi-graphoid properties of conditional\npossibilistic independence, parameterized by a continuous t-norm, and find\nsufficient conditions for a class of Archimedean t-norms to have the graphoid\nproperty. Then we introduce Markov properties and factorization of possibility\ndistrubtions (again parameterized by a continuous t-norm) and find the\nrelationships between them. These results are accompanied by a number of\nconterexamples, which show that the assumptions of specific theorems are\nsubstantial.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:53:09 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Vejnarova", "Jirina", ""]]}, {"id": "1301.3901", "submitter": "Wim Wiegerinck", "authors": "Wim Wiegerinck", "title": "Variational Approximations between Mean Field Theory and the Junction\n  Tree Algorithm", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-626-633", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, variational approximations such as the mean field approximation\nhave received much interest. We extend the standard mean field method by using\nan approximating distribution that factorises into cluster potentials. This\nincludes undirected graphs, directed acyclic graphs and junction trees. We\nderive generalized mean field equations to optimize the cluster potentials. We\nshow that the method bridges the gap between the standard mean field\napproximation and the exact junction tree algorithm. In addition, we address\nthe problem of how to choose the graphical structure of the approximating\ndistribution. From the generalised mean field equations we derive rules to\nsimplify the structure of the approximating distribution in advance without\naffecting the quality of the approximation. We also show how the method fits\ninto some other variational approximations that are currently popular.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:53:17 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Wiegerinck", "Wim", ""]]}, {"id": "1301.3902", "submitter": "David M Williamson", "authors": "David M. Williamson, Russell Almond, Robert Mislevy", "title": "Model Criticism of Bayesian Networks with Latent Variables", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-634-643", "categories": "cs.AI stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of Bayesian networks (BNs) to cognitive assessment and\nintelligent tutoring systems poses new challenges for model construction. When\ncognitive task analyses suggest constructing a BN with several latent\nvariables, empirical model criticism of the latent structure becomes both\ncritical and complex. This paper introduces a methodology for criticizing\nmodels both globally (a BN in its entirety) and locally (observable nodes), and\nexplores its value in identifying several kinds of misfit: node errors, edge\nerrors, state errors, and prior probability errors in the latent structure. The\nresults suggest the indices have potential for detecting model misfit and\nassisting in locating problematic components of the model.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:53:20 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Williamson", "David M.", ""], ["Almond", "Russell", ""], ["Mislevy", "Robert", ""]]}, {"id": "1301.3903", "submitter": "Frank Wittig", "authors": "Frank Wittig, Anthony Jameson", "title": "Exploiting Qualitative Knowledge in the Learning of Conditional\n  Probabilities of Bayesian Networks", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-644-652", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms for learning the conditional probabilities of Bayesian networks\nwith hidden variables typically operate within a high-dimensional search space\nand yield only locally optimal solutions. One way of limiting the search space\nand avoiding local optima is to impose qualitative constraints that are based\non background knowledge concerning the domain. We present a method for\nintegrating formal statements of qualitative constraints into two learning\nalgorithms, APN and EM. In our experiments with synthetic data, this method\nyielded networks that satisfied the constraints almost perfectly. The accuracy\nof the learned networks was consistently superior to that of corresponding\nnetworks learned without constraints. The exploitation of qualitative\nconstraints therefore appears to be a promising way to increase both the\ninterpretability and the accuracy of learned Bayesian networks with known\nstructure.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:53:24 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Wittig", "Frank", ""], ["Jameson", "Anthony", ""]]}, {"id": "1301.4137", "submitter": "Emanuel Diamant", "authors": "Emanuel Diamant", "title": "When you talk about \"Information processing\" what actually do you have\n  in mind?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Information Processing\" is a recently launched buzzword whose meaning is\nvague and obscure even for the majority of its users. The reason for this is\nthe lack of a suitable definition for the term \"information\". In my attempt to\namend this bizarre situation, I have realized that, following the insights of\nKolmogorov's Complexity theory, information can be defined as a description of\nstructures observable in a given data set. Two types of structures could be\neasily distinguished in every data set - in this regard, two types of\ninformation (information descriptions) should be designated: physical\ninformation and semantic information. Kolmogorov's theory also posits that the\ninformation descriptions should be provided as a linguistic text structure.\nThis inevitably leads us to an assertion that information processing has to be\nseen as a kind of text processing. The idea is not new - inspired by the\nobservation that human information processing is deeply rooted in natural\nlanguage handling customs, Lotfi Zadeh and his followers have introduced the\nso-called \"Computing With Words\" paradigm. Despite of promotional efforts, the\nidea is not taking off yet. The reason - a lack of a coherent understanding of\nwhat should be called \"information\", and, as a result, misleading research\nroadmaps and objectives. I hope my humble attempt to clarify these issues would\nbe helpful in avoiding common traps and pitfalls.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2012 05:37:04 GMT"}], "update_date": "2013-03-12", "authors_parsed": [["Diamant", "Emanuel", ""]]}, {"id": "1301.4272", "submitter": "Marco Correia", "authors": "Marco Correia and Pedro Barahona", "title": "View-based propagation of decomposable constraints", "comments": "The final publication is available at link.springer.com", "journal-ref": null, "doi": "10.1007/s10601-013-9140-8", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraints that may be obtained by composition from simpler constraints are\npresent, in some way or another, in almost every constraint program. The\ndecomposition of such constraints is a standard technique for obtaining an\nadequate propagation algorithm from a combination of propagators designed for\nsimpler constraints. The decomposition approach is appealing in several ways.\nFirstly because creating a specific propagator for every constraint is clearly\ninfeasible since the number of constraints is infinite. Secondly, because\ndesigning a propagation algorithm for complex constraints can be very\nchallenging. Finally, reusing existing propagators allows to reduce the size of\ncode to be developed and maintained. Traditionally, constraint solvers\nautomatically decompose constraints into simpler ones using additional\nauxiliary variables and propagators, or expect the users to perform such\ndecomposition themselves, eventually leading to the same propagation model. In\nthis paper we explore views, an alternative way to create efficient propagators\nfor such constraints in a modular, simple and correct way, which avoids the\nintroduction of auxiliary variables and propagators.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2013 23:37:47 GMT"}], "update_date": "2013-01-21", "authors_parsed": [["Correia", "Marco", ""], ["Barahona", "Pedro", ""]]}, {"id": "1301.4351", "submitter": "Djallel Bouneffouf", "authors": "Djallel Bouneffouf", "title": "Applying machine learning techniques to improve user acceptance on\n  ubiquitous environement", "comments": null, "journal-ref": null, "doi": null, "report-no": "urn:nbn:de:0074-731-7 Vol-731", "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ubiquitous information access becomes more and more important nowadays and\nresearch is aimed at making it adapted to users. Our work consists in applying\nmachine learning techniques in order to adapt the information access provided\nby ubiquitous systems to users when the system only knows the user social\ngroup, without knowing anything about the user interest. The adaptation\nprocedures associate actions to perceived situations of the user. Associations\nare based on feedback given by the user as a reaction to the behavior of the\nsystem. Our method brings a solution to some of the problems concerning the\nacceptance of the system by users when applying machine learning techniques to\nsystems at the beginning of the interaction between the system and the user.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2013 11:26:54 GMT"}], "update_date": "2013-02-05", "authors_parsed": [["Bouneffouf", "Djallel", ""]]}, {"id": "1301.4430", "submitter": "Haiqin Wang", "authors": "Haiqin Wang, Marek J. Druzdzel", "title": "User Interface Tools for Navigation in Conditional Probability Tables\n  and Elicitation of Probabilities in Bayesian Networks", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-617-625", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Elicitation of probabilities is one of the most laborious tasks in building\ndecision-theoretic models, and one that has so far received only moderate\nattention in decision-theoretic systems. We propose a set of user interface\ntools for graphical probabilistic models, focusing on two aspects of\nprobability elicitation: (1) navigation through conditional probability tables\nand (2) interactive graphical assessment of discrete probability distributions.\nWe propose two new graphical views that aid navigation in very large\nconditional probability tables: the CPTree (Conditional Probability Tree) and\nthe SCPT (shrinkable Conditional Probability Table). Based on what is known\nabout graphical presentation of quantitative data to humans, we offer several\nuseful enhancements to probability wheel and bar graph, including different\nchart styles and options that can be adapted to user preferences and needs. We\npresent the results of a simple usability study that proves the value of the\nproposed tools.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2013 16:50:44 GMT"}], "update_date": "2013-01-21", "authors_parsed": [["Wang", "Haiqin", ""], ["Druzdzel", "Marek J.", ""]]}, {"id": "1301.4604", "submitter": "Nando de Freitas", "authors": "Nando de Freitas and Kevin Murphy", "title": "Proceedings of the Twenty-Eighth Conference on Uncertainty in Artificial\n  Intelligence (2012)", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI2012", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the Twenty-Eighth Conference on Uncertainty in\nArtificial Intelligence, which was held on Catalina Island, CA August 14-18\n2012.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2013 22:32:52 GMT"}, {"version": "v2", "created": "Thu, 28 Aug 2014 04:31:38 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["de Freitas", "Nando", ""], ["Murphy", "Kevin", ""]]}, {"id": "1301.4606", "submitter": "Christopher Meek", "authors": "Christopher Meek and Uffe Kjaerulff", "title": "Proceedings of the Nineteenth Conference on Uncertainty in Artificial\n  Intelligence (2003)", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI2003", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the Nineteenth Conference on Uncertainty in\nArtificial Intelligence, which was held in Acapulco, Mexico, August 7-10 2003\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2013 23:12:33 GMT"}, {"version": "v2", "created": "Thu, 28 Aug 2014 04:18:59 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["Meek", "Christopher", ""], ["Kjaerulff", "Uffe", ""]]}, {"id": "1301.4607", "submitter": "John Breese", "authors": "John Breese and Daphne Koller", "title": "Proceedings of the Seventeenth Conference on Uncertainty in Artificial\n  Intelligence (2001)", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI2001", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the Seventeenth Conference on Uncertainty in\nArtificial Intelligence, which was held in Seattle, WA, August 2-5 2001\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2013 23:16:59 GMT"}, {"version": "v2", "created": "Thu, 28 Aug 2014 04:16:28 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["Breese", "John", ""], ["Koller", "Daphne", ""]]}, {"id": "1301.4608", "submitter": "Adnan Darwiche", "authors": "Adnan Darwiche and Nir Friedman", "title": "Proceedings of the Eighteenth Conference on Uncertainty in Artificial\n  Intelligence (2002)", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI2002", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the Eighteenth Conference on Uncertainty in\nArtificial Intelligence, which was held in Alberta, Canada, August 1-4 2002\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2013 23:17:26 GMT"}, {"version": "v2", "created": "Thu, 28 Aug 2014 04:17:50 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["Darwiche", "Adnan", ""], ["Friedman", "Nir", ""]]}, {"id": "1301.4659", "submitter": "Firoj Parwej Dr.", "authors": "Firoj Parwej", "title": "English Sentence Recognition using Artificial Neural Network through\n  Mouse-based Gestures", "comments": "6 Pages, 7 Figures. arXiv admin note: text overlap with\n  arXiv:1007.0627 by other authors without attribution", "journal-ref": "International Journal of Computer Applications (IJCA)USA, Volume\n  61, No.17, January 2013 ISSN 0975 - 8887, http://www.ijcaonline.org,\n  http://www.ijcaonline.org/archives/volume61/number17/10023-4998", "doi": "10.5120/10023-4998", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Handwriting is one of the most important means of daily communication.\nAlthough the problem of handwriting recognition has been considered for more\nthan 60 years there are still many open issues, especially in the task of\nunconstrained handwritten sentence recognition. This paper focuses on the\nautomatic system that recognizes continuous English sentence through a\nmouse-based gestures in real-time based on Artificial Neural Network. The\nproposed Artificial Neural Network is trained using the traditional\nbackpropagation algorithm for self supervised neural network which provides the\nsystem with great learning ability and thus has proven highly successful in\ntraining for feed-forward Artificial Neural Network. The designed algorithm is\nnot only capable of translating discrete gesture moves, but also continuous\ngestures through the mouse. In this paper we are using the efficient neural\nnetwork approach for recognizing English sentence drawn by mouse. This approach\nshows an efficient way of extracting the boundary of the English Sentence and\nspecifies the area of the recognition English sentence where it has been drawn\nin an image and then used Artificial Neural Network to recognize the English\nsentence. The proposed approach English sentence recognition (ESR) system is\ndesigned and tested successfully. Experimental results show that the higher\nspeed and accuracy were examined.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2013 14:13:22 GMT"}], "update_date": "2013-01-22", "authors_parsed": [["Parwej", "Firoj", ""]]}, {"id": "1301.4753", "submitter": "Nikzad Babaii-Rizvandi", "authors": "Nikzad Babaii Rizvandi, Javid Taheri, Albert Y.Zomaya", "title": "Pattern Matching for Self- Tuning of MapReduce Jobs", "comments": "7 pages, previously published as \"On Using Pattern Matching\n  Algorithms in MapReduce Applications\" at ISPA 2011. arXiv admin note:\n  substantial text overlap with arXiv:1112.5505", "journal-ref": null, "doi": "10.1109/ISPA.2011.24", "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study CPU utilization time patterns of several MapReduce\napplications. After extracting running patterns of several applications, they\nare saved in a reference database to be later used to tweak system parameters\nto efficiently execute unknown applications in future. To achieve this goal,\nCPU utilization patterns of new applications are compared with the already\nknown ones in the reference database to find/predict their most probable\nexecution patterns. Because of different patterns lengths, the Dynamic Time\nWarping (DTW) is utilized for such comparison; a correlation analysis is then\napplied to DTWs outcomes to produce feasible similarity patterns. Three real\napplications (WordCount, Exim Mainlog parsing and Terasort) are used to\nevaluate our hypothesis in tweaking system parameters in executing similar\napplications. Results were very promising and showed effectiveness of our\napproach on pseudo-distributed MapReduce platforms.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 04:57:05 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Rizvandi", "Nikzad Babaii", ""], ["Taheri", "Javid", ""], ["Zomaya", "Albert Y.", ""]]}, {"id": "1301.4780", "submitter": "Christophe Cruz", "authors": "Helmi Ben Hmida (i3mainz), Christophe Cruz (Le2i), Frank Boochs\n  (i3mainz), Christophe Nicolle (Le2i)", "title": "From Quantitative Spatial Operator to Qualitative Spatial Relation Using\n  Constructive Solid Geometry, Logic Rules and Optimized 9-IM Model, A Semantic\n  Based Approach", "comments": null, "journal-ref": "IEEE International Conference on Computer Science and Automation\n  Engineering (CSAE),, Zhangjiajie : China (2012)", "doi": "10.1109/CSAE.2012.6272992", "report-no": null, "categories": "cs.CG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Constructive Solid Geometry (CSG) is a data model providing a set of\nbinary Boolean operators such as Union, Difference and Intersection. In this\nwork, these operators are used to compute topological relations between objects\ndefined by the constraints of the nine Intersection Model (9-IM) from\nEgenhofer. With the help of these constraints, we define a procedure to compute\nthe topological relations on CSG objects. These topological relations are\nDisjoint, Contains, Inside, Covers, CoveredBy, Equals and Overlaps, and are\ndefined in a top-level ontology with a specific semantic definition on relation\nsuch as Transitive, Symmetric, Asymmetric, Functional, Reflexive, and\nIrreflexive. The results of topological relations computation are stored in the\nontology allowing after what to infer on these topological relationships. In\naddition, logic rules based on the Semantic Web Language allows the definition\nof logic programs that define which topological relationships have to be\ncomputed on which kind of objects. For instance, a \"Building\" that overlaps a\n\"Railway\" is a \"RailStation\".\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 08:13:54 GMT"}], "update_date": "2013-01-22", "authors_parsed": [["Hmida", "Helmi Ben", "", "i3mainz"], ["Cruz", "Christophe", "", "Le2i"], ["Boochs", "Frank", "", "i3mainz"], ["Nicolle", "Christophe", "", "Le2i"]]}, {"id": "1301.4783", "submitter": "Christophe Cruz", "authors": "Helmi Ben Hmida (i3mainz), Christophe Cruz (Le2i), Frank Boochs\n  (i3mainz), Christophe Nicolle (Le2i)", "title": "From 3D Point Clouds To Semantic Objects An Ontology-Based Detection\n  Approach", "comments": null, "journal-ref": "International Conference on Knowledge Engineering and Ontology\n  Development, Paris : France (2011)", "doi": null, "report-no": null, "categories": "cs.CG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a knowledge-based detection of objects approach using the\nOWL ontology language, the Semantic Web Rule Language, and 3D processing\nbuilt-ins aiming at combining geometrical analysis of 3D point clouds and\nspecialist's knowledge. This combination allows the detection and the\nannotation of objects contained in point clouds. The context of the study is\nthe detection of railway objects such as signals, technical cupboards, electric\npoles, etc. Thus, the resulting enriched and populated ontology, that contains\nthe annotations of objects in the point clouds, is used to feed a GIS systems\nor an IFC file for architecture purposes.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 08:16:53 GMT"}], "update_date": "2013-01-22", "authors_parsed": [["Hmida", "Helmi Ben", "", "i3mainz"], ["Cruz", "Christophe", "", "Le2i"], ["Boochs", "Frank", "", "i3mainz"], ["Nicolle", "Christophe", "", "Le2i"]]}, {"id": "1301.4848", "submitter": "Christophe Cruz", "authors": "Frank Boochs (i3mainz), Andreas Marbs (i3mainz), Hung Truong (i3mainz,\n  Le2i), Helmi Ben Hmida (i3mainz), Ashish Karmacharya (i3mainz, Le2i),\n  Christophe Cruz (Le2i), Adlane Habed (Le2i), Yvon Voisin (Le2i), Christophe\n  Nicolle (Le2i)", "title": "Integration of knowledge to support automatic object reconstruction from\n  images and 3D data", "comments": null, "journal-ref": "Systems, Signals and Devices (SSD), 2011 8th International\n  Multi-Conference on, Chemnitz : Germany (2011)", "doi": "10.1109/SSD.2011.5993558", "report-no": null, "categories": "cs.CG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object reconstruction is an important task in many fields of application as\nit allows to generate digital representations of our physical world used as\nbase for analysis, planning, construction, visualization or other aims. A\nreconstruction itself normally is based on reliable data (images, 3D point\nclouds for example) expressing the object in his complete extent. This data\nthen has to be compiled and analyzed in order to extract all necessary\ngeometrical elements, which represent the object and form a digital copy of it.\nTraditional strategies are largely based on manual interaction and\ninterpretation, because with increasing complexity of objects human\nunderstanding is inevitable to achieve acceptable and reliable results. But\nhuman interaction is time consuming and expensive, why many researches has\nalready been invested to use algorithmic support, what allows to speed up the\nprocess and to reduce manual work load. Presently most of such supporting\nalgorithms are data-driven and concentate on specific features of the objects,\nbeing accessible to numerical models. By means of these models, which normally\nwill represent geometrical (flatness, roughness, for example) or physical\nfeatures (color, texture), the data is classified and analyzed. This is\nsuccessful for objects with low complexity, but gets to its limits with\nincreasing complexness of objects. Then purely numerical strategies are not\nable to sufficiently model the reality. Therefore, the intention of our\napproach is to take human cognitive strategy as an example, and to simulate\nextraction processes based on available human defined knowledge for the objects\nof interest. Such processes will introduce a semantic structure for the objects\nand guide the algorithms used to detect and recognize objects, which will yield\na higher effectiveness. Hence, our research proposes an approach using\nknowledge to guide the algorithms in 3D point cloud and image processing.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 12:42:54 GMT"}], "update_date": "2013-01-22", "authors_parsed": [["Boochs", "Frank", "", "i3mainz"], ["Marbs", "Andreas", "", "i3mainz"], ["Truong", "Hung", "", "i3mainz,\n  Le2i"], ["Hmida", "Helmi Ben", "", "i3mainz"], ["Karmacharya", "Ashish", "", "i3mainz, Le2i"], ["Cruz", "Christophe", "", "Le2i"], ["Habed", "Adlane", "", "Le2i"], ["Voisin", "Yvon", "", "Le2i"], ["Nicolle", "Christophe", "", "Le2i"]]}, {"id": "1301.4862", "submitter": "Pierre-Yves Oudeyer", "authors": "Adrien Baranes and Pierre-Yves Oudeyer", "title": "Active Learning of Inverse Models with Intrinsically Motivated Goal\n  Exploration in Robots", "comments": null, "journal-ref": "Baranes, A., Oudeyer, P-Y. (2013) Active Learning of Inverse\n  Models with Intrinsically Motivated Goal Exploration in Robots, Robotics and\n  Autonomous Systems, 61(1), pp. 49-73", "doi": "10.1016/j.robot.2012.05.008", "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Self-Adaptive Goal Generation - Robust Intelligent Adaptive\nCuriosity (SAGG-RIAC) architecture as an intrinsi- cally motivated goal\nexploration mechanism which allows active learning of inverse models in\nhigh-dimensional redundant robots. This allows a robot to efficiently and\nactively learn distributions of parameterized motor skills/policies that solve\na corresponding distribution of parameterized tasks/goals. The architecture\nmakes the robot sample actively novel parameterized tasks in the task space,\nbased on a measure of competence progress, each of which triggers low-level\ngoal-directed learning of the motor policy pa- rameters that allow to solve it.\nFor both learning and generalization, the system leverages regression\ntechniques which allow to infer the motor policy parameters corresponding to a\ngiven novel parameterized task, and based on the previously learnt\ncorrespondences between policy and task parameters. We present experiments with\nhigh-dimensional continuous sensorimotor spaces in three different robotic\nsetups: 1) learning the inverse kinematics in a highly-redundant robotic arm,\n2) learning omnidirectional locomotion with motor primitives in a quadruped\nrobot, 3) an arm learning to control a fishing rod with a flexible wire. We\nshow that 1) exploration in the task space can be a lot faster than exploration\nin the actuator space for learning inverse models in redundant robots; 2)\nselecting goals maximizing competence progress creates developmental\ntrajectories driving the robot to progressively focus on tasks of increasing\ncomplexity and is statistically significantly more efficient than selecting\ntasks randomly, as well as more efficient than different standard active motor\nbabbling methods; 3) this architecture allows the robot to actively discover\nwhich parts of its task space it can learn to reach and which part it cannot.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 13:26:07 GMT"}], "update_date": "2013-01-23", "authors_parsed": [["Baranes", "Adrien", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1301.4910", "submitter": "M\\'ario S. Alvim", "authors": "M\\'ario S. Alvim", "title": "Computational Aspects of the Calculus of Structure", "comments": "Thesis presented by M\\'ario S. Alvim as part of the requirements for\n  the degree or Master of Science in Computer Science granted by the\n  Universidade Federal de Minas Gerais. April, 04th, 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logic is the science of correct inferences and a logical system is a tool to\nprove assertions in a certain logic in a correct way. There are many logical\nsystems, and many ways of formalizing them, e.g., using natural deduction or\nsequent calculus. Calculus of structures (CoS) is a new formalism proposed by\nAlessio Guglielmi in 2004 that generalizes sequent calculus in the sense that\ninference rules can be applied at any depth inside a formula, rather than only\nto the main connective. With this feature, proofs in CoS are shorter than in\nany other formalism supporting analytical proofs. Although it is great to have\nthe freedom and expressiveness of CoS, under the point of view of proof search\nmore freedom means a larger search space. And that should be restricted when\nlooking for complete automation of deductive systems. Some efforts were made to\nreduce this non-determinism, but they are all basically operational approaches,\nand no solid theoretical result regarding the computational behaviour of CoS\nhas been achieved so far. The main focus of this thesis is to discuss ways to\npropose a proof search strategy for CoS suitable to implementation. This\nstrategy should be theoretical instead of purely operational. We introduce the\nconcept of incoherence number of substructures inside structures and we use\nthis concept to achieve our main result: there is an algorithm that, according\nto our conjecture, corresponds to a proof search strategy to every provable\nstructure in the subsystem of FBV (the multiplicative linear logic MLL plus the\nrule mix) containing only pairwise distinct atoms. Our algorithm is implemented\nand we believe our strategy is a good starting point to exploit the\ncomputational aspects of CoS in more general systems, like BV itself.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 16:19:00 GMT"}], "update_date": "2013-01-22", "authors_parsed": [["Alvim", "M\u00e1rio S.", ""]]}, {"id": "1301.4991", "submitter": "Christophe Cruz", "authors": "Helmi Ben Hmida (i3mainz), Christophe Cruz (Le2i), Frank Boochs\n  (i3mainz), Christophe Nicolle (Le2i)", "title": "Knowledge Base Approach for 3D Objects Detection in Point Clouds Using\n  3D Processing and Specialists Knowledge", "comments": "ISSN: 1942-2679. arXiv admin note: text overlap with arXiv:1301.4783", "journal-ref": "International Journal On Advances in Intelligent Systems 5, 1 et 2\n  (2012) 1-14", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a knowledge-based detection of objects approach using the\nOWL ontology language, the Semantic Web Rule Language, and 3D processing\nbuilt-ins aiming at combining geometrical analysis of 3D point clouds and\nspecialist's knowledge. Here, we share our experience regarding the creation of\n3D semantic facility model out of unorganized 3D point clouds. Thus, a\nknowledge-based detection approach of objects using the OWL ontology language\nis presented. This knowledge is used to define SWRL detection rules. In\naddition, the combination of 3D processing built-ins and topological Built-Ins\nin SWRL rules allows a more flexible and intelligent detection, and the\nannotation of objects contained in 3D point clouds. The created WiDOP prototype\ntakes a set of 3D point clouds as input, and produces as output a populated\nontology corresponding to an indexed scene visualized within VRML language. The\ncontext of the study is the detection of railway objects materialized within\nthe Deutsche Bahn scene such as signals, technical cupboards, electric poles,\netc. Thus, the resulting enriched and populated ontology, that contains the\nannotations of objects in the point clouds, is used to feed a GIS system or an\nIFC file for architecture purposes.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 12:42:17 GMT"}], "update_date": "2013-01-23", "authors_parsed": [["Hmida", "Helmi Ben", "", "i3mainz"], ["Cruz", "Christophe", "", "Le2i"], ["Boochs", "Frank", "", "i3mainz"], ["Nicolle", "Christophe", "", "Le2i"]]}, {"id": "1301.4992", "submitter": "Christophe Cruz", "authors": "Helmi Ben Hmida (i3mainz), Christophe Cruz (Le2i), Frank Boochs\n  (i3mainz), Christophe Nicolle (Le2i)", "title": "From 9-IM Topological Operators to Qualitative Spatial Relations using\n  3D Selective Nef Complexes and Logic Rules for bodies", "comments": "arXiv admin note: substantial text overlap with arXiv:1301.4780", "journal-ref": "International Conference on Knowledge Engineering and Ontology\n  Development, Barcelone : Spain (2012)", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a method to compute automatically topological relations\nusing SWRL rules. The calculation of these rules is based on the definition of\na Selective Nef Complexes Nef Polyhedra structure generated from standard\nPolyhedron. The Selective Nef Complexes is a data model providing a set of\nbinary Boolean operators such as Union, Difference, Intersection and Symmetric\ndifference, and unary operators such as Interior, Closure and Boundary. In this\nwork, these operators are used to compute topological relations between objects\ndefined by the constraints of the 9 Intersection Model (9-IM) from Egenhofer.\nWith the help of these constraints, we defined a procedure to compute the\ntopological relations on Nef polyhedra. These topological relationships are\nDisjoint, Meets, Contains, Inside, Covers, CoveredBy, Equals and Overlaps, and\ndefined in a top-level ontology with a specific semantic definition on relation\nsuch as Transitive, Symmetric, Asymmetric, Functional, Reflexive, and\nIrreflexive. The results of the computation of topological relationships are\nstored in an OWL-DL ontology allowing after what to infer on these new\nrelationships between objects. In addition, logic rules based on the Semantic\nWeb Rule Language allows the definition of logic programs that define which\ntopological relationships have to be computed on which kind of objects with\nspecific attributes. For instance, a \"Building\" that overlaps a \"Railway\" is a\n\"RailStation\".\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 12:43:38 GMT"}], "update_date": "2013-01-23", "authors_parsed": [["Hmida", "Helmi Ben", "", "i3mainz"], ["Cruz", "Christophe", "", "Le2i"], ["Boochs", "Frank", "", "i3mainz"], ["Nicolle", "Christophe", "", "Le2i"]]}, {"id": "1301.5022", "submitter": "Vicen\\c{c} Torra", "authors": "Vicen\\c{c} Torra and Klara Stokes", "title": "A formalization of re-identification in terms of compatible\n  probabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Re-identification algorithms are used in data privacy to measure disclosure\nrisk. They model the situation in which an adversary attacks a published\ndatabase by means of linking the information of this adversary with the\ndatabase.\n  In this paper we formalize this type of algorithm in terms of true\nprobabilities and compatible belief functions. The purpose of this work is to\nleave aside as re-identification algorithms those algorithms that do not\nsatisfy a minimum requirement.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 21:53:56 GMT"}], "update_date": "2013-01-23", "authors_parsed": [["Torra", "Vicen\u00e7", ""], ["Stokes", "Klara", ""]]}, {"id": "1301.5154", "submitter": "Radhakrishnan Delhibabu", "authors": "Radhakrishnan Delhibabu, Gerhard Lakemeyer", "title": "A Rational and Efficient Algorithm for View Revision in Databases", "comments": null, "journal-ref": "Applied Mathematics & Information Sciences, Volume 7, No. 3\n  (2013), PP:843-856", "doi": "10.12785/amis/070302", "report-no": null, "categories": "cs.LO cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dynamics of belief and knowledge is one of the major components of any\nautonomous system that should be able to incorporate new pieces of information.\nIn this paper, we argue that to apply rationality result of belief dynamics\ntheory to various practical problems, it should be generalized in two respects:\nfirst of all, it should allow a certain part of belief to be declared as\nimmutable; and second, the belief state need not be deductively closed. Such a\ngeneralization of belief dynamics, referred to as base dynamics, is presented,\nalong with the concept of a generalized revision algorithm for Horn knowledge\nbases. We show that Horn knowledge base dynamics has interesting connection\nwith kernel change and abduction. Finally, we also show that both variants are\nrational in the sense that they satisfy certain rationality postulates stemming\nfrom philosophical works on belief dynamics.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2013 11:30:37 GMT"}], "update_date": "2014-07-22", "authors_parsed": [["Delhibabu", "Radhakrishnan", ""], ["Lakemeyer", "Gerhard", ""]]}, {"id": "1301.5349", "submitter": "Christophe Cruz", "authors": "Helmi Ben Hmida (i3mainz), Christophe Cruz (Le2i), Christophe Nicolle\n  (Le2i), Frank Boochs (i3mainz)", "title": "Toward the Automatic Generation of a Semantic VRML Model from\n  Unorganized 3D Point Clouds", "comments": "arXiv admin note: substantial text overlap with arXiv:1301.4991,\n  arXiv:1301.4783", "journal-ref": "The Fifth International Conference on Advances in Semantic\n  Processing, Lisbon : Portugal (2011)", "doi": null, "report-no": null, "categories": "cs.CG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents our experience regarding the creation of 3D semantic\nfacility model out of unorganized 3D point clouds. Thus, a knowledge-based\ndetection approach of objects using the OWL ontology language is presented.\nThis knowledge is used to define SWRL detection rules. In addition, the\ncombination of 3D processing built-ins and topological Built-Ins in SWRL rules\naims at combining geometrical analysis of 3D point clouds and specialist's\nknowledge. This combination allows more flexible and intelligent detection and\nthe annotation of objects contained in 3D point clouds. The created WiDOP\nprototype takes a set of 3D point clouds as input, and produces an indexed\nscene of colored objects visualized within VRML language as output. The context\nof the study is the detection of railway objects materialized within the\nDeutsche Bahn scene such as signals, technical cupboards, electric poles, etc.\nTherefore, the resulting enriched and populated domain ontology, that contains\nthe annotations of objects in the point clouds, is used to feed a GIS system.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 08:17:15 GMT"}], "update_date": "2013-01-24", "authors_parsed": [["Hmida", "Helmi Ben", "", "i3mainz"], ["Cruz", "Christophe", "", "Le2i"], ["Nicolle", "Christophe", "", "Le2i"], ["Boochs", "Frank", "", "i3mainz"]]}, {"id": "1301.5488", "submitter": "Manuel Lopes", "authors": "Francisco Melo and Manuel Lopes", "title": "Multi-class Generalized Binary Search for Active Inverse Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of learning a task from demonstration. We\nadopt the framework of inverse reinforcement learning, where tasks are\nrepresented in the form of a reward function. Our contribution is a novel\nactive learning algorithm that enables the learning agent to query the expert\nfor more informative demonstrations, thus leading to more sample-efficient\nlearning. For this novel algorithm (Generalized Binary Search for Inverse\nReinforcement Learning, or GBS-IRL), we provide a theoretical bound on sample\ncomplexity and illustrate its applicability on several different tasks. To our\nknowledge, GBS-IRL is the first active IRL algorithm with provable sample\ncomplexity bounds. We also discuss our method in light of other existing\nmethods in the literature and its general applicability in multi-class\nclassification problems. Finally, motivated by recent work on learning from\ndemonstration in robots, we also discuss how different forms of human feedback\ncan be integrated in a transparent manner in our learning framework.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 12:54:09 GMT"}], "update_date": "2013-01-24", "authors_parsed": [["Melo", "Francisco", ""], ["Lopes", "Manuel", ""]]}, {"id": "1301.5943", "submitter": "Lu\\'is Filipe Te\\'ofilo", "authors": "Lu\\'is Filipe Te\\'ofilo, Luis Paulo Reis", "title": "Identifying Player\\'s Strategies in No Limit Texas Hold\\'em Poker\n  through the Analysis of Individual Moves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of competitive artificial Poker playing agents has proven to\nbe a challenge, because agents must deal with unreliable information and\ndeception which make it essential to model the opponents in order to achieve\ngood results. This paper presents a methodology to develop opponent modeling\ntechniques for Poker agents. The approach is based on applying clustering\nalgorithms to a Poker game database in order to identify player types based on\ntheir actions. First, common game moves were identified by clustering all\nplayers\\' moves. Then, player types were defined by calculating the frequency\nwith which the players perform each type of movement. With the given dataset, 7\ndifferent types of players were identified with each one having at least one\ntactic that characterizes him. The identification of player types may improve\nthe overall performance of Poker agents, because it helps the agents to predict\nthe opponent\\'s moves, by associating each opponent to a distinct cluster.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2013 01:49:15 GMT"}], "update_date": "2013-01-28", "authors_parsed": [["Te\u00f3filo", "Lu\u00eds Filipe", ""], ["Reis", "Luis Paulo", ""]]}, {"id": "1301.5946", "submitter": "Lu\\'is Filipe Te\\'ofilo", "authors": "Lu\\'is Filipe Te\\'ofilo, Lu\\'is Paulo Reis, Henrique Lopes Cardoso,\n  Dinis F\\'elix, Rui S\\^eca, Jo\\~ao Ferreira, Pedro Mendes, Nuno Cruz, Vitor\n  Pereira, Nuno Passos", "title": "Computer Poker Research at LIACC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer Poker's unique characteristics present a well-suited challenge for\nresearch in artificial intelligence. For that reason, and due to the Poker's\nmarket increase in popularity in Portugal since 2008, several members of LIACC\nhave researched in this field. Several works were published as papers and\nmaster theses and more recently a member of LIACC engaged on a research in this\narea as a Ph.D. thesis in order to develop a more extensive and in-depth work.\nThis paper describes the existing research in LIACC about Computer Poker, with\nspecial emphasis on the completed master's theses and plans for future work.\nThis paper means to present a summary of the lab's work to the research\ncommunity in order to encourage the exchange of ideas with other labs /\nindividuals. LIACC hopes this will improve research in this area so as to reach\nthe goal of creating an agent that surpasses the best human players.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2013 01:56:03 GMT"}], "update_date": "2013-01-28", "authors_parsed": [["Te\u00f3filo", "Lu\u00eds Filipe", ""], ["Reis", "Lu\u00eds Paulo", ""], ["Cardoso", "Henrique Lopes", ""], ["F\u00e9lix", "Dinis", ""], ["S\u00eaca", "Rui", ""], ["Ferreira", "Jo\u00e3o", ""], ["Mendes", "Pedro", ""], ["Cruz", "Nuno", ""], ["Pereira", "Vitor", ""], ["Passos", "Nuno", ""]]}, {"id": "1301.6011", "submitter": "D P Acharjya Ph.D", "authors": "B.K.Tripathy, D.P.Acharjya and V.Cynthya", "title": "A Framework for Intelligent Medical Diagnosis using Rough Set with\n  Formal Concept Analysis", "comments": "22 pages", "journal-ref": "International Journal of Artificial Intelligence & Applications\n  (IJAIA), Vol.2, No.2, April 2011", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical diagnosis process vary in the degree to which they attempt to deal\nwith different complicating aspects of diagnosis such as relative importance of\nsymptoms, varied symptom pattern and the relation between diseases them selves.\nBased on decision theory, in the past many mathematical models such as crisp\nset, probability distribution, fuzzy set, intuitionistic fuzzy set were\ndeveloped to deal with complicating aspects of diagnosis. But, many such models\nare failed to include important aspects of the expert decisions. Therefore, an\neffort has been made to process inconsistencies in data being considered by\nPawlak with the introduction of rough set theory. Though rough set has major\nadvantages over the other methods, but it generates too many rules that create\nmany difficulties while taking decisions. Therefore, it is essential to\nminimize the decision rules. In this paper, we use two processes such as pre\nprocess and post process to mine suitable rules and to explore the relationship\namong the attributes. In pre process we use rough set theory to mine suitable\nrules, whereas in post process we use formal concept analysis from these\nsuitable rules to explore better knowledge and most important factors affecting\nthe decision making.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2013 11:24:05 GMT"}], "update_date": "2013-01-28", "authors_parsed": [["Tripathy", "B. K.", ""], ["Acharjya", "D. P.", ""], ["Cynthya", "V.", ""]]}, {"id": "1301.6039", "submitter": "Jonathan Heras", "authors": "J\\'onathan Heras and Ekaterina Komendantskaya", "title": "Recycling Proof Patterns in Coq: Case Studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Development of Interactive Theorem Provers has led to the creation of big\nlibraries and varied infrastructures for formal proofs. However, despite (or\nperhaps due to) their sophistication, the re-use of libraries by non-experts or\nacross domains is a challenge. In this paper, we provide detailed case studies\nand evaluate the machine-learning tool ML4PG built to interactively data-mine\nthe electronic libraries of proofs, and to provide user guidance on the basis\nof proof patterns found in the existing libraries.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2013 13:29:29 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2013 14:04:45 GMT"}, {"version": "v3", "created": "Mon, 3 Feb 2014 10:39:54 GMT"}, {"version": "v4", "created": "Fri, 7 Mar 2014 12:30:49 GMT"}], "update_date": "2014-03-10", "authors_parsed": [["Heras", "J\u00f3nathan", ""], ["Komendantskaya", "Ekaterina", ""]]}, {"id": "1301.6262", "submitter": "Sim-Hui Tee", "authors": "Sim-Hui Tee", "title": "Developing Parallel Dependency Graph In Improving Game Balancing", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dependency graph is a data architecture that models all the dependencies\nbetween the different types of assets in the game. It depicts the\ndependency-based relationships between the assets of a game. For example, a\nplayer must construct an arsenal before he can build weapons. It is vital that\nthe dependency graph of a game is designed logically to ensure a logical\nsequence of game play. However, a mere logical dependency graph is not\nsufficient in sustaining the players' enduring interests in a game, which\nbrings the problem of game balancing into picture. The issue of game balancing\narises when the players do not feel the chances of winning the game over their\nAI opponents who are more skillful in the game play. At the current state of\nresearch, the architecture of dependency graph is monolithic for the players.\nThe sequence of asset possession is always foreseeable because there is only a\nsingle dependency graph. Game balancing is impossible when the assets of AI\nplayers are overwhelmingly outnumbering that of human players. This paper\nproposes a parallel architecture of dependency graph for the AI players and\nhuman players. Instead of having a single dependency graph, a parallel\narchitecture is proposed where the dependency graph of AI player is adjustable\nwith that of human player using a support dependency as a game balancing\nmechanism. This paper exhibits that the parallel dependency graph helps to\nimprove game balancing.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2013 14:41:03 GMT"}], "update_date": "2013-01-29", "authors_parsed": [["Tee", "Sim-Hui", ""]]}, {"id": "1301.6359", "submitter": "Alexander Serov", "authors": "Alexander Serov", "title": "Subjective Reality and Strong Artificial Intelligence", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main prospective aim of modern research related to Artificial\nIntelligence is the creation of technical systems that implement the idea of\nStrong Intelligence. According our point of view the path to the development of\nsuch systems comes through the research in the field related to perceptions.\nHere we formulate the model of the perception of external world which may be\nused for the description of perceptual activity of intelligent beings. We\nconsider a number of issues related to the development of the set of patterns\nwhich will be used by the intelligent system when interacting with environment.\nThe key idea of the presented perception model is the idea of subjective\nreality. The principle of the relativity of perceived world is formulated. It\nis shown that this principle is the immediate consequence of the idea of\nsubjective reality. In this paper we show how the methodology of subjective\nreality may be used for the creation of different types of Strong AI systems.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2013 14:29:04 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2013 17:32:23 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Serov", "Alexander", ""]]}, {"id": "1301.6479", "submitter": "Carsten Lutz", "authors": "Meghyn Bienvenu, Balder ten Cate, Carsten Lutz, Frank Wolter", "title": "Ontology-based Data Access: A Study through Disjunctive Datalog, CSP,\n  and MMSNP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontology-based data access is concerned with querying incomplete data sources\nin the presence of domain-specific knowledge provided by an ontology. A central\nnotion in this setting is that of an ontology-mediated query, which is a\ndatabase query coupled with an ontology. In this paper, we study several\nclasses of ontology-mediated queries, where the database queries are given as\nsome form of conjunctive query and the ontologies are formulated in description\nlogics or other relevant fragments of first-order logic, such as the guarded\nfragment and the unary-negation fragment. The contributions of the paper are\nthree-fold. First, we characterize the expressive power of ontology-mediated\nqueries in terms of fragments of disjunctive datalog. Second, we establish\nintimate connections between ontology-mediated queries and constraint\nsatisfaction problems (CSPs) and their logical generalization, MMSNP formulas.\nThird, we exploit these connections to obtain new results regarding (i)\nfirst-order rewritability and datalog-rewritability of ontology-mediated\nqueries, (ii) P/NP dichotomies for ontology-mediated queries, and (iii) the\nquery containment problem for ontology-mediated queries.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2013 09:11:54 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2013 12:52:59 GMT"}], "update_date": "2013-06-07", "authors_parsed": [["Bienvenu", "Meghyn", ""], ["Cate", "Balder ten", ""], ["Lutz", "Carsten", ""], ["Wolter", "Frank", ""]]}, {"id": "1301.6675", "submitter": "Gustavo Arroyo-Figueroa", "authors": "Gustavo Arroyo-Figueroa, Luis Enrique Sucar", "title": "A Temporal Bayesian Network for Diagnosis and Prediction", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-13-20", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diagnosis and prediction in some domains, like medical and industrial\ndiagnosis, require a representation that combines uncertainty management and\ntemporal reasoning. Based on the fact that in many cases there are few state\nchanges in the temporal range of interest, we propose a novel representation\ncalled Temporal Nodes Bayesian Networks (TNBN). In a TNBN each node represents\nan event or state change of a variable, and an arc corresponds to a\ncausal-temporal relationship. The temporal intervals can differ in number and\nsize for each temporal node, so this allows multiple granularity. Our approach\nis contrasted with a dynamic Bayesian network for a simple medical example. An\nempirical evaluation is presented for a more complex problem, a subsystem of a\nfossil power plant, in which this approach is used for fault diagnosis and\nprediction with good results.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:56:38 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Arroyo-Figueroa", "Gustavo", ""], ["Sucar", "Luis Enrique", ""]]}, {"id": "1301.6678", "submitter": "Philip S. Barry", "authors": "Philip S. Barry, Kathryn Blackmond Laskey", "title": "An Application of Uncertain Reasoning to Requirements Engineering", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-41-48", "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines the use of Bayesian Networks to tackle one of the tougher\nproblems in requirements engineering, translating user requirements into system\nrequirements. The approach taken is to model domain knowledge as Bayesian\nNetwork fragments that are glued together to form a complete view of the domain\nspecific system requirements. User requirements are introduced as evidence and\nthe propagation of belief is used to determine what are the appropriate system\nrequirements as indicated by user requirements. This concept has been\ndemonstrated in the development of a system specification and the results are\npresented here.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:56:51 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Barry", "Philip S.", ""], ["Laskey", "Kathryn Blackmond", ""]]}, {"id": "1301.6679", "submitter": "Salem Benferhat", "authors": "Salem Benferhat, Didier Dubois, Laurent Garcia, Henri Prade", "title": "Possibilistic logic bases and possibilistic graphs", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-57-64", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Possibilistic logic bases and possibilistic graphs are two different\nframeworks of interest for representing knowledge. The former stratifies the\npieces of knowledge (expressed by logical formulas) according to their level of\ncertainty, while the latter exhibits relationships between variables. The two\ntypes of representations are semantically equivalent when they lead to the same\npossibility distribution (which rank-orders the possible interpretations). A\npossibility distribution can be decomposed using a chain rule which may be\nbased on two different kinds of conditioning which exist in possibility theory\n(one based on product in a numerical setting, one based on minimum operation in\na qualitative setting). These two types of conditioning induce two kinds of\npossibilistic graphs. In both cases, a translation of these graphs into\npossibilistic bases is provided. The converse translation from a possibilistic\nknowledge base into a min-based graph is also described.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:56:55 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Benferhat", "Salem", ""], ["Dubois", "Didier", ""], ["Garcia", "Laurent", ""], ["Prade", "Henri", ""]]}, {"id": "1301.6680", "submitter": "Magnus Boman", "authors": "Magnus Boman, Paul Davidsson, Hakan L. Younes", "title": "Artificial Decision Making Under Uncertainty in Intelligent Buildings", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-65-70", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our hypothesis is that by equipping certain agents in a multi-agent system\ncontrolling an intelligent building with automated decision support, two\nimportant factors will be increased. The first is energy saving in the\nbuilding. The second is customer value---how the people in the building\nexperience the effects of the actions of the agents. We give evidence for the\ntruth of this hypothesis through experimental findings related to tools for\nartificial decision making. A number of assumptions related to agent control,\nthrough monitoring and delegation of tasks to other kinds of agents, of rooms\nat a test site are relaxed. Each assumption controls at least one uncertainty\nthat complicates considerably the procedures for selecting actions part of each\nsuch agent. We show that in realistic decision situations, room-controlling\nagents can make bounded rational decisions even under dynamic real-time\nconstraints. This result can be, and has been, generalized to other domains\nwith even harsher time constraints.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:56:59 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Boman", "Magnus", ""], ["Davidsson", "Paul", ""], ["Younes", "Hakan L.", ""]]}, {"id": "1301.6681", "submitter": "Craig Boutilier", "authors": "Craig Boutilier, Ronen I. Brafman, Holger H. Hoos, David L. Poole", "title": "Reasoning With Conditional Ceteris Paribus Preference Statem", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-71-80", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many domains it is desirable to assess the preferences of users in a\nqualitative rather than quantitative way. Such representations of qualitative\npreference orderings form an importnat component of automated decision tools.\nWe propose a graphical representation of preferences that reflects conditional\ndependence and independence of preference statements under a ceteris paribus\n(all else being equal) interpretation. Such a representation is ofetn compact\nand arguably natural. We describe several search algorithms for dominance\ntesting based on this representation; these algorithms are quite effective,\nespecially in specific network topologies, such as chain-and tree- structured\nnetworks, as well as polytrees.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:57:03 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Boutilier", "Craig", ""], ["Brafman", "Ronen I.", ""], ["Hoos", "Holger H.", ""], ["Poole", "David L.", ""]]}, {"id": "1301.6682", "submitter": "Craig Boutilier", "authors": "Craig Boutilier, Moises Goldszmidt, Bikash Sabata", "title": "Continuous Value Function Approximation for Sequential Bidding Policies", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-81-90", "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Market-based mechanisms such as auctions are being studied as an appropriate\nmeans for resource allocation in distributed and mulitagent decision problems.\nWhen agents value resources in combination rather than in isolation, they must\noften deliberate about appropriate bidding strategies for a sequence of\nauctions offering resources of interest. We briefly describe a discrete dynamic\nprogramming model for constructing appropriate bidding policies for resources\nexhibiting both complementarities and substitutability. We then introduce a\ncontinuous approximation of this model, assuming that money (or the numeraire\ngood) is infinitely divisible. Though this has the potential to reduce the\ncomputational cost of computing policies, value functions in the transformed\nproblem do not have a convenient closed form representation. We develop {em\ngrid-based} approximation for such value functions, representing value\nfunctions using piecewise linear approximations. We show that these methods can\noffer significant computational savings with relatively small cost in solution\nquality.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:57:07 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Boutilier", "Craig", ""], ["Goldszmidt", "Moises", ""], ["Sabata", "Bikash", ""]]}, {"id": "1301.6683", "submitter": "Xavier Boyen", "authors": "Xavier Boyen, Nir Friedman, Daphne Koller", "title": "Discovering the Hidden Structure of Complex Dynamic Systems", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-91-100", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Bayesian networks provide a compact and natural representation for\ncomplex dynamic systems. However, in many cases, there is no expert available\nfrom whom a model can be elicited. Learning provides an alternative approach\nfor constructing models of dynamic systems. In this paper, we address some of\nthe crucial computational aspects of learning the structure of dynamic systems,\nparticularly those where some relevant variables are partially observed or even\nentirely unknown. Our approach is based on the Structural Expectation\nMaximization (SEM) algorithm. The main computational cost of the SEM algorithm\nis the gathering of expected sufficient statistics. We propose a novel\napproximation scheme that allows these sufficient statistics to be computed\nefficiently. We also investigate the fundamental problem of discovering the\nexistence of hidden variables without exhaustive and expensive search. Our\napproach is based on the observation that, in dynamic systems, ignoring a\nhidden variable typically results in a violation of the Markov property. Thus,\nour algorithm searches for such violations in the data, and introduces hidden\nvariables to explain them. We provide empirical results showing that the\nalgorithm is able to learn the dynamics of complex systems in a computationally\ntractable way.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:57:10 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Boyen", "Xavier", ""], ["Friedman", "Nir", ""], ["Koller", "Daphne", ""]]}, {"id": "1301.6684", "submitter": "Jie Cheng", "authors": "Jie Cheng, Russell Greiner", "title": "Comparing Bayesian Network Classifiers", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-101-108", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we empirically evaluate algorithms for learning four types of\nBayesian network (BN) classifiers - Naive-Bayes, tree augmented Naive-Bayes, BN\naugmented Naive-Bayes and general BNs, where the latter two are learned using\ntwo variants of a conditional-independence (CI) based BN-learning algorithm.\nExperimental results show the obtained classifiers, learned using the CI based\nalgorithms, are competitive with (or superior to) the best known classifiers,\nbased on both Bayesian networks and other formalisms; and that the\ncomputational time for learning and using these classifiers is relatively\nsmall. Moreover, these results also suggest a way to learn yet more effective\nclassifiers; we demonstrate empirically that this new algorithm does work as\nexpected. Collectively, these results argue that BN classifiers deserve more\nattention in machine learning and data mining communities.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:57:14 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Cheng", "Jie", ""], ["Greiner", "Russell", ""]]}, {"id": "1301.6686", "submitter": "Gregory F. Cooper", "authors": "Gregory F. Cooper, Changwon Yoo", "title": "Causal Discovery from a Mixture of Experimental and Observational Data", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-116-125", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a Bayesian method for combining an arbitrary mixture of\nobservational and experimental data in order to learn causal Bayesian networks.\nObservational data are passively observed. Experimental data, such as that\nproduced by randomized controlled trials, result from the experimenter\nmanipulating one or more variables (typically randomly) and observing the\nstates of other variables. The paper presents a Bayesian method for learning\nthe causal structure and parameters of the underlying causal process that is\ngenerating the data, given that (1) the data contains a mixture of\nobservational and experimental case records, and (2) the causal process is\nmodeled as a causal Bayesian network. This learning method was applied using as\ninput various mixtures of experimental and observational data that were\ngenerated from the ALARM causal Bayesian network. In these experiments, the\nabsolute and relative quantities of experimental and observational data were\nvaried systematically. For each of these training datasets, the learning method\nwas applied to predict the causal structure and to estimate the causal\nparameters that exist among randomly selected pairs of nodes in ALARM that are\nnot confounded. The paper reports how these structure predictions and parameter\nestimates compare with the true causal structures and parameters as given by\nthe ALARM network.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:57:22 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Cooper", "Gregory F.", ""], ["Yoo", "Changwon", ""]]}, {"id": "1301.6687", "submitter": "James Cussens", "authors": "James Cussens", "title": "Loglinear models for first-order probabilistic reasoning", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-126-133", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on loglinear models in probabilistic constraint logic programming\nis applied to first-order probabilistic reasoning. Probabilities are defined\ndirectly on the proofs of atomic formulae, and by marginalisation on the atomic\nformulae themselves. We use Stochastic Logic Programs (SLPs) composed of\nlabelled and unlabelled definite clauses to define the proof probabilities. We\nhave a conservative extension of first-order reasoning, so that, for example,\nthere is a one-one mapping between logical and random variables. We show how,\nin this framework, Inductive Logic Programming (ILP) can be used to induce the\nfeatures of a loglinear model from data. We also compare the presented\nframework with other approaches to first-order probabilistic reasoning.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:57:26 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Cussens", "James", ""]]}, {"id": "1301.6688", "submitter": "Sanjoy Dasgupta", "authors": "Sanjoy Dasgupta", "title": "Learning Polytrees", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-134-141", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of learning the maximum-likelihood polytree from data.\nOur first result is a performance guarantee establishing that the optimal\nbranching (or Chow-Liu tree), which can be computed very easily, constitutes a\ngood approximation to the best polytree. We then show that it is not possible\nto do very much better, since the learning problem is NP-hard even to\napproximately solve within some constant factor.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:57:30 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Dasgupta", "Sanjoy", ""]]}, {"id": "1301.6689", "submitter": "Denver Dash", "authors": "Denver Dash, Marek J. Druzdzel", "title": "A Hybrid Anytime Algorithm for the Constructiion of Causal Models From\n  Sparse Data", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-142-149", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a hybrid constraint-based/Bayesian algorithm for learning causal\nnetworks in the presence of sparse data. The algorithm searches the space of\nequivalence classes of models (essential graphs) using a heuristic based on\nconventional constraint-based techniques. Each essential graph is then\nconverted into a directed acyclic graph and scored using a Bayesian scoring\nmetric. Two variants of the algorithm are developed and tested using data from\nrandomly generated networks of sizes from 15 to 45 nodes with data sizes\nranging from 250 to 2000 records. Both variations are compared to, and found to\nconsistently outperform two variations of greedy search with restarts.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:57:34 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Dash", "Denver", ""], ["Druzdzel", "Marek J.", ""]]}, {"id": "1301.6690", "submitter": "Richard Dearden", "authors": "Richard Dearden, Nir Friedman, David Andre", "title": "Model-Based Bayesian Exploration", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-150-159", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning systems are often concerned with balancing exploration\nof untested actions against exploitation of actions that are known to be good.\nThe benefit of exploration can be estimated using the classical notion of Value\nof Information - the expected improvement in future decision quality arising\nfrom the information acquired by exploration. Estimating this quantity requires\nan assessment of the agent's uncertainty about its current value estimates for\nstates. In this paper we investigate ways of representing and reasoning about\nthis uncertainty in algorithms where the system attempts to learn a model of\nits environment. We explicitly represent uncertainty about the parameters of\nthe model and build probability distributions over Q-values based on these.\nThese distributions are used to compute a myopic approximation to the value of\ninformation for each action and hence to select the action that best balances\nexploration and exploitation.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:57:38 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Dearden", "Richard", ""], ["Friedman", "Nir", ""], ["Andre", "David", ""]]}, {"id": "1301.6691", "submitter": "Michael I. Dekhtyar", "authors": "Michael I. Dekhtyar, Alex Dekhtyar, V. S. Subrahmanian", "title": "Hybrid Probabilistic Programs: Algorithms and Complexity", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-160-169", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybrid Probabilistic Programs (HPPs) are logic programs that allow the\nprogrammer to explicitly encode his knowledge of the dependencies between\nevents being described in the program. In this paper, we classify HPPs into\nthree classes called HPP_1,HPP_2 and HPP_r,r>= 3. For these classes, we provide\nthree types of results for HPPs. First, we develop algorithms to compute the\nset of all ground consequences of an HPP. Then we provide algorithms and\ncomplexity results for the problems of entailment (\"Given an HPP P and a query\nQ as input, is Q a logical consequence of P?\") and consistency (\"Given an HPP P\nas input, is P consistent?\"). Our results provide a fine characterization of\nwhen polynomial algorithms exist for the above problems, and when these\nproblems become intractable.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:57:43 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Dekhtyar", "Michael I.", ""], ["Dekhtyar", "Alex", ""], ["Subrahmanian", "V. S.", ""]]}, {"id": "1301.6692", "submitter": "Didier Dubois", "authors": "Didier Dubois, Michel Grabisch, Henri Prade, Philippe Smets", "title": "Assessing the value of a candidate. Comparing belief function and\n  possibility theories", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-170-177", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of assessing the value of a candidate is viewed here as a\nmultiple combination problem. On the one hand a candidate can be evaluated\naccording to different criteria, and on the other hand several experts are\nsupposed to assess the value of candidates according to each criterion.\nCriteria are not equally important, experts are not equally competent or\nreliable. Moreover levels of satisfaction of criteria, or levels of confidence\nare only assumed to take their values in qualitative scales which are just\nlinearly ordered. The problem is discussed within two frameworks, the\ntransferable belief model and the qualitative possibility theory. They\nrespectively offer a quantitative and a qualitative setting for handling the\nproblem, providing thus a way to compare the nature of the underlying\nassumptions.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:57:47 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Dubois", "Didier", ""], ["Grabisch", "Michel", ""], ["Prade", "Henri", ""], ["Smets", "Philippe", ""]]}, {"id": "1301.6694", "submitter": "Helene Fargier", "authors": "Helene Fargier, Patrice Perny", "title": "Qualitative Models for Decision Under Uncertainty without the\n  Commensurability Assumption", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-188-195", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates a purely qualitative version of Savage's theory for\ndecision making under uncertainty. Until now, most representation theorems for\npreference over acts rely on a numerical representation of utility and\nuncertainty where utility and uncertainty are commensurate. Disrupting the\ntradition, we relax this assumption and introduce a purely ordinal axiom\nrequiring that the Decision Maker (DM) preference between two acts only depends\non the relative position of their consequences for each state. Within this\nqualitative framework, we determine the only possible form of the decision rule\nand investigate some instances compatible with the transitivity of the strict\npreference. Finally we propose a mild relaxation of our ordinality axiom,\nleaving room for a new family of qualitative decision rules compatible with\ntransitivity.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:57:55 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Fargier", "Helene", ""], ["Perny", "Patrice", ""]]}, {"id": "1301.6695", "submitter": "Nir Friedman", "authors": "Nir Friedman, Moises Goldszmidt, Abraham Wyner", "title": "Data Analysis with Bayesian Networks: A Bootstrap Approach", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-196-205", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years there has been significant progress in algorithms and methods\nfor inducing Bayesian networks from data. However, in complex data analysis\nproblems, we need to go beyond being satisfied with inducing networks with high\nscores. We need to provide confidence measures on features of these networks:\nIs the existence of an edge between two nodes warranted? Is the Markov blanket\nof a given node robust? Can we say something about the ordering of the\nvariables? We should be able to address these questions, even when the amount\nof data is not enough to induce a high scoring network. In this paper we\npropose Efron's Bootstrap as a computationally efficient approach for answering\nthese questions. In addition, we propose to use these confidence measures to\ninduce better structures from the data, and to detect the presence of latent\nvariables.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:58:00 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Friedman", "Nir", ""], ["Goldszmidt", "Moises", ""], ["Wyner", "Abraham", ""]]}, {"id": "1301.6696", "submitter": "Nir Friedman", "authors": "Nir Friedman, Iftach Nachman, Dana Pe'er", "title": "Learning Bayesian Network Structure from Massive Datasets: The \"Sparse\n  Candidate\" Algorithm", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-206-215", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning Bayesian networks is often cast as an optimization problem, where\nthe computational task is to find a structure that maximizes a statistically\nmotivated score. By and large, existing learning tools address this\noptimization problem using standard heuristic search techniques. Since the\nsearch space is extremely large, such search procedures can spend most of the\ntime examining candidates that are extremely unreasonable. This problem becomes\ncritical when we deal with data sets that are large either in the number of\ninstances, or the number of attributes. In this paper, we introduce an\nalgorithm that achieves faster learning by restricting the search space. This\niterative algorithm restricts the parents of each variable to belong to a small\nsubset of candidates. We then search for a network that satisfies these\nconstraints. The learned network is then used for selecting better candidates\nfor the next iteration. We evaluate this algorithm both on synthetic and\nreal-life data. Our results show that it is significantly faster than\nalternative search procedures without loss of quality in the learned\nstructures.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:58:05 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Friedman", "Nir", ""], ["Nachman", "Iftach", ""], ["Pe'er", "Dana", ""]]}, {"id": "1301.6698", "submitter": "Dan Geiger", "authors": "Dan Geiger, Christopher Meek", "title": "Quantifier Elimination for Statistical Problems", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-226-235", "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent improvement on Tarski's procedure for quantifier elimination in the\nfirst order theory of real numbers makes it feasible to solve small instances\nof the following problems completely automatically: 1. listing all equality and\ninequality constraints implied by a graphical model with hidden variables. 2.\nComparing graphyical models with hidden variables (i.e., model equivalence,\ninclusion, and overlap). 3. Answering questions about the identification of a\nmodel or portion of a model, and about bounds on quantities derived from a\nmodel. 4. Determing whether a given set of independence assertions. We discuss\nthe foundation of quantifier elimination and demonstrate its application to\nthese problems.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:58:14 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Geiger", "Dan", ""], ["Meek", "Christopher", ""]]}, {"id": "1301.6699", "submitter": "Phan H. Giang", "authors": "Phan H. Giang, Prakash P. Shenoy", "title": "On Transformations between Probability and Spohnian Disbelief Functions", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-236-244", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze the relationship between probability and Spohn's\ntheory for representation of uncertain beliefs. Using the intuitive idea that\nthe more probable a proposition is, the more believable it is, we study\ntransformations from probability to Sphonian disbelief and vice-versa. The\ntransformations described in this paper are different from those described in\nthe literature. In particular, the former satisfies the principles of ordinal\ncongruence while the latter does not. Such transformations between probability\nand Spohn's calculi can contribute to (1) a clarification of the semantics of\nnonprobabilistic degree of uncertain belief, and (2) to a construction of a\ndecision theory for such calculi. In practice, the transformations will allow a\nmeaningful combination of more than one calculus in different stages of using\nan expert system such as knowledge acquisition, inference, and interpretation\nof results.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:58:18 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Giang", "Phan H.", ""], ["Shenoy", "Prakash P.", ""]]}, {"id": "1301.6700", "submitter": "Robert P. Goldman", "authors": "Robert P. Goldman, Christopher W. Geib, Christopher A. Miller", "title": "A New Model of Plan Recognition", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-245-254", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new abductive, probabilistic theory of plan recognition. This\nmodel differs from previous plan recognition theories in being centered around\na model of plan execution: most previous methods have been based on plans as\nformal objects or on rules describing the recognition process. We show that our\nnew model accounts for phenomena omitted from most previous plan recognition\ntheories: notably the cumulative effect of a sequence of observations of\npartially-ordered, interleaved plans and the effect of context on plan\nadoption. The model also supports inferences about the evolution of plan\nexecution in situations where another agent intervenes in plan execution. This\nfacility provides support for using plan recognition to build systems that will\nintelligently assist a user.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:58:22 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Goldman", "Robert P.", ""], ["Geib", "Christopher W.", ""], ["Miller", "Christopher A.", ""]]}, {"id": "1301.6701", "submitter": "Dominique Gruyer", "authors": "Dominique Gruyer, Veronique Berge-Cherfaoui", "title": "Multi-objects association in perception of dynamical situation", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-255-262", "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In current perception systems applied to the rebuilding of the environment\nfor intelligent vehicles, the part reserved to object association for the\ntracking is increasingly significant. This allows firstly to follow the objects\ntemporal evolution and secondly to increase the reliability of environment\nperception. We propose in this communication the development of a multi-objects\nassociation algorithm with ambiguity removal entering into the design of such a\ndynamic perception system for intelligent vehicles. This algorithm uses the\nbelief theory and data modelling with fuzzy mathematics in order to be able to\nhandle inaccurate as well as uncertain information due to imperfect sensors.\nThese theories also allow the fusion of numerical as well as symbolic data. We\ndevelop in this article the problem of matching between known and perceived\nobjects. This makes it possible to update a dynamic environment map for a\nvehicle. The belief theory will enable us to quantify the belief in the\nassociation of each perceived object with each known object. Conflicts can\nappear in the case of object appearance or disappearance, or in the case of a\nconfused situation or bad perception. These conflicts are removed or solved\nusing an assignment algorithm, giving a solution called the \" best \" and so\nensuring the tracking of some objects present in our environment.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:58:26 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Gruyer", "Dominique", ""], ["Berge-Cherfaoui", "Veronique", ""]]}, {"id": "1301.6702", "submitter": "Vu A. Ha", "authors": "Vu A. Ha, Peter Haddawy", "title": "A Hybrid Approach to Reasoning with Partially Elicited Preference Models", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-263-270", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical Decision Theory provides a normative framework for representing and\nreasoning about complex preferences. Straightforward application of this theory\nto automate decision making is difficult due to high elicitation cost. In\nresponse to this problem, researchers have recently developed a number of\nqualitative, logic-oriented approaches for representing and reasoning about\nreferences. While effectively addressing some expressiveness issues, these\nlogics have not proven powerful enough for building practical automated\ndecision making systems. In this paper we present a hybrid approach to\npreference elicitation and decision making that is grounded in classical\nmulti-attribute utility theory, but can make effective use of the expressive\npower of qualitative approaches. Specifically, assuming a partially specified\nmultilinear utility function, we show how comparative statements about classes\nof decision alternatives can be used to further constrain the utility function\nand thus identify sup-optimal alternatives. This work demonstrates that\nquantitative and qualitative approaches can be synergistically integrated to\nprovide effective and flexible decision support.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:58:30 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Ha", "Vu A.", ""], ["Haddawy", "Peter", ""]]}, {"id": "1301.6703", "submitter": "David Harmanec", "authors": "David Harmanec", "title": "Faithful Approximations of Belief Functions", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-271-278", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A conceptual foundation for approximation of belief functions is proposed and\ninvestigated. It is based on the requirements of consistency and closeness. An\noptimal approximation is studied. Unfortunately, the computation of the optimal\napproximation turns out to be intractable. Hence, various heuristic methods are\nproposed and experimantally evaluated both in terms of their accuracy and in\nterms of the speed of computation. These methods are compared to the earlier\nproposed approximations of belief functions.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:58:34 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Harmanec", "David", ""]]}, {"id": "1301.6704", "submitter": "Jesse Hoey", "authors": "Jesse Hoey, Robert St-Aubin, Alan Hu, Craig Boutilier", "title": "SPUDD: Stochastic Planning using Decision Diagrams", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-279-288", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov decisions processes (MDPs) are becoming increasing popular as models\nof decision theoretic planning. While traditional dynamic programming methods\nperform well for problems with small state spaces, structured methods are\nneeded for large problems. We propose and examine a value iteration algorithm\nfor MDPs that uses algebraic decision diagrams(ADDs) to represent value\nfunctions and policies. An MDP is represented using Bayesian networks and ADDs\nand dynamic programming is applied directly to these ADDs. We demonstrate our\nmethod on large MDPs (up to 63 million states) and show that significant gains\ncan be had when compared to tree-structured representations (with up to a\nthirty-fold reduction in the number of nodes required to represent optimal\nvalue functions).\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:58:38 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Hoey", "Jesse", ""], ["St-Aubin", "Robert", ""], ["Hu", "Alan", ""], ["Boutilier", "Craig", ""]]}, {"id": "1301.6706", "submitter": "Michael C. Horsch", "authors": "Michael C. Horsch, David L. Poole", "title": "Estimating the Value of Computation in Flexible Information Refinement", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-297-304", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We outline a method to estimate the value of computation for a flexible\nalgorithm using empirical data. To determine a reasonable trade-off between\ncost and value, we build an empirical model of the value obtained through\ncomputation, and apply this model to estimate the value of computation for\nquite different problems. In particular, we investigate this trade-off for the\nproblem of constructing policies for decision problems represented as influence\ndiagrams. We show how two features of our anytime algorithm provide reasonable\nestimates of the value of computation in this domain.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:58:47 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Horsch", "Michael C.", ""], ["Poole", "David L.", ""]]}, {"id": "1301.6707", "submitter": "Eric J. Horvitz", "authors": "Eric J. Horvitz, Andy Jacobs, David Hovel", "title": "Attention-Sensitive Alerting", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-305-313", "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce utility-directed procedures for mediating the flow of\npotentially distracting alerts and communications to computer users. We present\nmodels and inference procedures that balance the context-sensitive costs of\ndeferring alerts with the cost of interruption. We describe the challenge of\nreasoning about such costs under uncertainty via an analysis of user activity\nand the content of notifications. After introducing principles of\nattention-sensitive alerting, we focus on the problem of guiding alerts about\nemail messages. We dwell on the problem of inferring the expected criticality\nof email and discuss work on the Priorities system, centering on prioritizing\nemail by criticality and modulating the communication of notifications to users\nabout the presence and nature of incoming email.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:58:51 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Horvitz", "Eric J.", ""], ["Jacobs", "Andy", ""], ["Hovel", "David", ""]]}, {"id": "1301.6708", "submitter": "Kalev Kask", "authors": "Kalev Kask, Rina Dechter", "title": "Mini-Bucket Heuristics for Improved Search", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-314-323", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper is a second in a series of two papers evaluating the power of a new\nscheme that generates search heuristics mechanically. The heuristics are\nextracted from an approximation scheme called mini-bucket elimination that was\nrecently introduced. The first paper introduced the idea and evaluated it\nwithin Branch-and-Bound search. In the current paper the idea is further\nextended and evaluated within Best-First search. The resulting algorithms are\ncompared on coding and medical diagnosis problems, using varying strength of\nthe mini-bucket heuristics.\n  Our results demonstrate an effective search scheme that permits controlled\ntradeoff between preprocessing (for heuristic generation) and search.\nBest-first search is shown to outperform Branch-and-Bound, when supplied with\ngood heuristics, and sufficient memory space.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:58:54 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Kask", "Kalev", ""], ["Dechter", "Rina", ""]]}, {"id": "1301.6709", "submitter": "Daphne Koller", "authors": "Daphne Koller, Uri Lerner, Dragomir Anguelov", "title": "A General Algorithm for Approximate Inference and its Application to\n  Hybrid Bayes Nets", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-324-333", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The clique tree algorithm is the standard method for doing inference in\nBayesian networks. It works by manipulating clique potentials - distributions\nover the variables in a clique. While this approach works well for many\nnetworks, it is limited by the need to maintain an exact representation of the\nclique potentials. This paper presents a new unified approach that combines\napproximate inference and the clique tree algorithm, thereby circumventing this\nlimitation. Many known approximate inference algorithms can be viewed as\ninstances of this approach. The algorithm essentially does clique tree\npropagation, using approximate inference to estimate the densities in each\nclique. In many settings, the computation of the approximate clique potential\ncan be done easily using statistical importance sampling. Iterations are used\nto gradually improve the quality of the estimation.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:58:59 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Koller", "Daphne", ""], ["Lerner", "Uri", ""], ["Anguelov", "Dragomir", ""]]}, {"id": "1301.6711", "submitter": "Kevin B. Korb", "authors": "Kevin B. Korb, Ann Nicholson, Nathalie Jitnah", "title": "Bayesian Poker", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-343-350", "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poker is ideal for testing automated reasoning under uncertainty. It\nintroduces uncertainty both by physical randomization and by incomplete\ninformation about opponents hands.Another source OF uncertainty IS the limited\ninformation available TO construct psychological models OF opponents, their\ntendencies TO bluff, play conservatively, reveal weakness, etc. AND the\nrelation BETWEEN their hand strengths AND betting behaviour. ALL OF these\nuncertainties must be assessed accurately AND combined effectively FOR ANY\nreasonable LEVEL OF skill IN the game TO be achieved, since good decision\nmaking IS highly sensitive TO those tasks.We describe our Bayesian Poker\nProgram(BPP), which uses a Bayesian network TO model the programs poker hand,\nthe opponents hand AND the opponents playing behaviour conditioned upon the\nhand, and betting curves which govern play given a probability of winning. The\nhistory of play with opponents is used to improve BPPs understanding OF their\nbehaviour.We compare BPP experimentally WITH : a simple RULE - based system; a\nprogram which depends exclusively ON hand probabilities(i.e., without opponent\nmodeling); AND WITH human players.BPP has shown itself TO be an effective\nplayer against ALL these opponents, barring the better humans.We also sketch\nout SOME likely ways OF improving play.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:59:06 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Korb", "Kevin B.", ""], ["Nicholson", "Ann", ""], ["Jitnah", "Nathalie", ""]]}, {"id": "1301.6712", "submitter": "Ryszard Kowalczyk", "authors": "Ryszard Kowalczyk", "title": "On Quantified Linguistic Approximation", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-351-358", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most fuzzy systems including fuzzy decision support and fuzzy control systems\nprovide out-puts in the form of fuzzy sets that represent the inferred\nconclusions. Linguistic interpretation of such outputs often involves the use\nof linguistic approximation that assigns a linguistic label to a fuzzy set\nbased on the predefined primary terms, linguistic modifiers and linguistic\nconnectives. More generally, linguistic approximation can be formalized in the\nterms of the re-translation rules that correspond to the translation rules in\nex-plicitation (e.g. simple, modifier, composite, quantification and\nqualification rules) in com-puting with words [Zadeh 1996]. However most\nexisting methods of linguistic approximation use the simple, modifier and\ncomposite re-translation rules only. Although these methods can provide a\nsufficient approximation of simple fuzzy sets the approximation of more complex\nones that are typical in many practical applications of fuzzy systems may be\nless satisfactory. Therefore the question arises why not use in linguistic\nap-proximation also other re-translation rules corre-sponding to the\ntranslation rules in explicitation to advantage. In particular linguistic\nquantifica-tion may be desirable in situations where the conclusions\ninterpreted as quantified linguistic propositions can be more informative and\nnatu-ral. This paper presents some aspects of linguis-tic approximation in the\ncontext of the re-translation rules and proposes an approach to linguistic\napproximation with the use of quantifi-cation rules, i.e. quantified linguistic\napproxima-tion. Two methods of the quantified linguistic approximation are\nconsidered with the use of lin-guistic quantifiers based on the concepts of the\nnon-fuzzy and fuzzy cardinalities of fuzzy sets. A number of examples are\nprovided to illustrate the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:59:10 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Kowalczyk", "Ryszard", ""]]}, {"id": "1301.6713", "submitter": "Henry E. Kyburg Jr.", "authors": "Henry E. Kyburg Jr., Choh Man Teng", "title": "Choosing Among Interpretations of Probability", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-359-365", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is available an ever-increasing variety of procedures for managing\nuncertainty. These methods are discussed in the literature of artificial\nintelligence, as well as in the literature of philosophy of science. Heretofore\nthese methods have been evaluated by intuition, discussion, and the general\nphilosophical method of argument and counterexample. Almost any method of\nuncertainty management will have the property that in the long run it will\ndeliver numbers approaching the relative frequency of the kinds of events at\nissue. To find a measure that will provide a meaningful evaluation of these\ntreatments of uncertainty, we must look, not at the long run, but at the short\nor intermediate run. Our project attempts to develop such a measure in terms of\nshort or intermediate length performance. We represent the effects of practical\nchoices by the outcomes of bets offered to agents characterized by two\nuncertainty management approaches: the subjective Bayesian approach and the\nClassical confidence interval approach. Experimental evaluation suggests that\nthe confidence interval approach can outperform the subjective approach in the\nrelatively short run.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:59:14 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Kyburg", "Henry E.", "Jr."], ["Teng", "Choh Man", ""]]}, {"id": "1301.6714", "submitter": "Pierfrancesco La Mura", "authors": "Pierfrancesco La Mura, Yoav Shoham", "title": "Expected Utility Networks", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-366-373", "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new class of graphical representations, expected utility\nnetworks (EUNs), and discuss some of its properties and potential applications\nto artificial intelligence and economic theory. In EUNs not only probabilities,\nbut also utilities enjoy a modular representation. EUNs are undirected graphs\nwith two types of arc, representing probability and utility dependencies\nrespectively. The representation of utilities is based on a novel notion of\nconditional utility independence, which we introduce and discuss in the context\nof other existing proposals. Just as probabilistic inference involves the\ncomputation of conditional probabilities, strategic inference involves the\ncomputation of conditional expected utilities for alternative plans of action.\nWe define a new notion of conditional expected utility (EU) independence, and\nshow that in EUNs node separation with respect to the probability and utility\nsubgraphs implies conditional EU independence.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:59:18 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["La Mura", "Pierfrancesco", ""], ["Shoham", "Yoav", ""]]}, {"id": "1301.6715", "submitter": "Christopher Lusena", "authors": "Christopher Lusena, Tong Li, Shelia Sittinger, Chris Wells, Judy\n  Goldsmith", "title": "My Brain is Full: When More Memory Helps", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-374-381", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding good finite-horizon policies for POMDPs\nunder the expected reward metric. The policies considered are {em free\nfinite-memory policies with limited memory}; a policy is a mapping from the\nspace of observation-memory pairs to the space of action-memeory pairs (the\npolicy updates the memory as it goes), and the number of possible memory states\nis a parameter of the input to the policy-finding algorithms. The algorithms\nconsidered here are preliminary implementations of three search heuristics:\nlocal search, simulated annealing, and genetic algorithms. We compare their\noutcomes to each other and to the optimal policies for each instance. We\ncompare run times of each policy and of a dynamic programming algorithm for\nPOMDPs developed by Hansen that iteratively improves a finite-state controller\n--- the previous state of the art for finite memory policies. The value of the\nbest policy can only improve as the amount of memory increases, up to the\namount needed for an optimal finite-memory policy. Our most surprising finding\nis that more memory helps in another way: given more memory than is needed for\nan optimal policy, the algorithms are more likely to converge to optimal-valued\npolicies.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:59:22 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Lusena", "Christopher", ""], ["Li", "Tong", ""], ["Sittinger", "Shelia", ""], ["Wells", "Chris", ""], ["Goldsmith", "Judy", ""]]}, {"id": "1301.6716", "submitter": "Anders L. Madsen", "authors": "Anders L. Madsen, Finn Verner Jensen", "title": "Lazy Evaluation of Symmetric Bayesian Decision Problems", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-382-390", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving symmetric Bayesian decision problems is a computationally intensive\ntask to perform regardless of the algorithm used. In this paper we propose a\nmethod for improving the efficiency of algorithms for solving Bayesian decision\nproblems. The method is based on the principle of lazy evaluation - a principle\nrecently shown to improve the efficiency of inference in Bayesian networks. The\nbasic idea is to maintain decompositions of potentials and to postpone\ncomputations for as long as possible. The efficiency improvements obtained with\nthe lazy evaluation based method is emphasized through examples. Finally, the\nlazy evaluation based method is compared with the hugin and valuation-based\nsystems architectures for solving symmetric Bayesian decision problems.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:59:26 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Madsen", "Anders L.", ""], ["Jensen", "Finn Verner", ""]]}, {"id": "1301.6717", "submitter": "Suzanne M. Mahoney", "authors": "Suzanne M. Mahoney, Kathryn Blackmond Laskey", "title": "Representing and Combining Partially Specified CPTs", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-391-400", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends previous work with network fragments and\nsituation-specific network construction. We formally define the asymmetry\nnetwork, an alternative representation for a conditional probability table. We\nalso present an object-oriented representation for partially specified\nasymmetry networks. We show that the representation is parsimonious. We define\nan algebra for the elements of the representation that allows us to 'factor'\nany CPT and to soundly combine the partially specified asymmetry networks.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:59:31 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Mahoney", "Suzanne M.", ""], ["Laskey", "Kathryn Blackmond", ""]]}, {"id": "1301.6718", "submitter": "Yishay Mansour", "authors": "Yishay Mansour, Satinder Singh", "title": "On the Complexity of Policy Iteration", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-401-408", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision-making problems in uncertain or stochastic domains are often\nformulated as Markov decision processes (MDPs). Policy iteration (PI) is a\npopular algorithm for searching over policy-space, the size of which is\nexponential in the number of states. We are interested in bounds on the\ncomplexity of PI that do not depend on the value of the discount factor. In\nthis paper we prove the first such non-trivial, worst-case, upper bounds on the\nnumber of iterations required by PI to converge to the optimal policy. Our\nanalysis also sheds new light on the manner in which PI progresses through the\nspace of policies.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:59:34 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Mansour", "Yishay", ""], ["Singh", "Satinder", ""]]}, {"id": "1301.6719", "submitter": "David A. McAllester", "authors": "David A. McAllester, Satinder Singh", "title": "Approximate Planning for Factored POMDPs using Belief State\n  Simplification", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-409-416", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in the problem of planning for factored POMDPs. Building on\nthe recent results of Kearns, Mansour and Ng, we provide a planning algorithm\nfor factored POMDPs that exploits the accuracy-efficiency tradeoff in the\nbelief state simplification introduced by Boyen and Koller.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:59:38 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["McAllester", "David A.", ""], ["Singh", "Satinder", ""]]}, {"id": "1301.6720", "submitter": "Nicolas Meuleau", "authors": "Nicolas Meuleau, Kee-Eung Kim, Leslie Pack Kaelbling, Anthony R.\n  Cassandra", "title": "Solving POMDPs by Searching the Space of Finite Policies", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-417-426", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving partially observable Markov decision processes (POMDPs) is highly\nintractable in general, at least in part because the optimal policy may be\ninfinitely large. In this paper, we explore the problem of finding the optimal\npolicy from a restricted set of policies, represented as finite state automata\nof a given size. This problem is also intractable, but we show that the\ncomplexity can be greatly reduced when the POMDP and/or policy are further\nconstrained. We demonstrate good empirical results with a branch-and-bound\nmethod for finding globally optimal deterministic policies, and a\ngradient-ascent method for finding locally optimal stochastic policies.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:59:42 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Meuleau", "Nicolas", ""], ["Kim", "Kee-Eung", ""], ["Kaelbling", "Leslie Pack", ""], ["Cassandra", "Anthony R.", ""]]}, {"id": "1301.6721", "submitter": "Nicolas Meuleau", "authors": "Nicolas Meuleau, Leonid Peshkin, Kee-Eung Kim, Leslie Pack Kaelbling", "title": "Learning Finite-State Controllers for Partially Observable Environments", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-427-436", "categories": "cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reactive (memoryless) policies are sufficient in completely observable Markov\ndecision processes (MDPs), but some kind of memory is usually necessary for\noptimal control of a partially observable MDP. Policies with finite memory can\nbe represented as finite-state automata. In this paper, we extend Baird and\nMoore's VAPS algorithm to the problem of learning general finite-state\nautomata. Because it performs stochastic gradient descent, this algorithm can\nbe shown to converge to a locally optimal finite-state controller. We provide\nthe details of the algorithm and then consider the question of under what\nconditions stochastic gradient descent will outperform exact gradient descent.\nWe conclude with empirical results comparing the performance of stochastic and\nexact gradient descent, and showing the ability of our algorithm to extract the\nuseful information contained in the sequence of past observations to compensate\nfor the lack of observability at each time-step.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:59:46 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Meuleau", "Nicolas", ""], ["Peshkin", "Leonid", ""], ["Kim", "Kee-Eung", ""], ["Kaelbling", "Leslie Pack", ""]]}, {"id": "1301.6722", "submitter": "Robert Mislevy", "authors": "Robert Mislevy, Russell Almond, Duanli Yan, Linda S. Steinberg", "title": "Bayes Nets in Educational Assessment: Where Do the Numbers Come From?", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-437-446", "categories": "cs.AI cs.CY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As observations and student models become complex, educational assessments\nthat exploit advances in technology and cognitive psychology can outstrip\nfamiliar testing models and analytic methods. Within the Portal conceptual\nframework for assessment design, Bayesian inference networks (BINs) record\nbeliefs about students' knowledge and skills, in light of what they say and do.\nJoining evidence model BIN fragments- which contain observable variables and\npointers to student model variables - to the student model allows one to update\nbelief about knowledge and skills as observations arrive. Markov Chain Monte\nCarlo (MCMC) techniques can estimate the required conditional probabilities\nfrom empirical data, supplemented by expert judgment or substantive theory.\nDetails for the special cases of item response theory (IRT) and multivariate\nlatent class modeling are given, with a numerical example of the latter.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:59:50 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Mislevy", "Robert", ""], ["Almond", "Russell", ""], ["Yan", "Duanli", ""], ["Steinberg", "Linda S.", ""]]}, {"id": "1301.6723", "submitter": "Stefano Monti", "authors": "Stefano Monti, Gregory F. Cooper", "title": "A Bayesian Network Classifier that Combines a Finite Mixture Model and a\n  Naive Bayes Model", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-447-456", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a new Bayesian network model for classification that\ncombines the naive-Bayes (NB) classifier and the finite-mixture (FM)\nclassifier. The resulting classifier aims at relaxing the strong assumptions on\nwhich the two component models are based, in an attempt to improve on their\nclassification performance, both in terms of accuracy and in terms of\ncalibration of the estimated probabilities. The proposed classifier is obtained\nby superimposing a finite mixture model on the set of feature variables of a\nnaive Bayes model. We present experimental results that compare the predictive\nperformance on real datasets of the new classifier with the predictive\nperformance of the NB classifier and the FM classifier.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:59:54 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Monti", "Stefano", ""], ["Cooper", "Gregory F.", ""]]}, {"id": "1301.6724", "submitter": "Kevin Murphy", "authors": "Kevin Murphy", "title": "A Variational Approximation for Bayesian Networks with Discrete and\n  Continuous Latent Variables", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-457-466", "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to use a variational approximation to the logistic function to\nperform approximate inference in Bayesian networks containing discrete nodes\nwith continuous parents. Essentially, we convert the logistic function to a\nGaussian, which facilitates exact inference, and then iteratively adjust the\nvariational parameters to improve the quality of the approximation. We\ndemonstrate experimentally that this approximation is faster and potentially\nmore accurate than sampling. We also introduce a simple new technique for\nhandling evidence, which allows us to handle arbitrary distributions on\nobserved nodes, as well as achieving a significant speedup in networks with\ndiscrete variables of large cardinality.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:59:58 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Murphy", "Kevin", ""]]}, {"id": "1301.6725", "submitter": "Kevin Murphy", "authors": "Kevin Murphy, Yair Weiss, Michael I. Jordan", "title": "Loopy Belief Propagation for Approximate Inference: An Empirical Study", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-467-476", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, researchers have demonstrated that loopy belief propagation - the\nuse of Pearls polytree algorithm IN a Bayesian network WITH loops OF error-\ncorrecting codes.The most dramatic instance OF this IS the near Shannon - limit\nperformance OF Turbo Codes codes whose decoding algorithm IS equivalent TO\nloopy belief propagation IN a chain - structured Bayesian network. IN this\npaper we ask : IS there something special about the error - correcting code\ncontext, OR does loopy propagation WORK AS an approximate inference schemeIN a\nmore general setting? We compare the marginals computed using loopy propagation\nTO the exact ones IN four Bayesian network architectures, including two real -\nworld networks : ALARM AND QMR.We find that the loopy beliefs often converge\nAND WHEN they do, they give a good approximation TO the correct\nmarginals.However,ON the QMR network, the loopy beliefs oscillated AND had no\nobvious relationship TO the correct posteriors. We present SOME initial\ninvestigations INTO the cause OF these oscillations, AND show that SOME simple\nmethods OF preventing them lead TO the wrong results.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:00:02 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Murphy", "Kevin", ""], ["Weiss", "Yair", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1301.6726", "submitter": "James W. Myers", "authors": "James W. Myers, Kathryn Blackmond Laskey, Tod S. Levitt", "title": "Learning Bayesian Networks from Incomplete Data with Stochastic Search\n  Algorithms", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-476-485", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes stochastic search approaches, including a new stochastic\nalgorithm and an adaptive mutation operator, for learning Bayesian networks\nfrom incomplete data. This problem is characterized by a huge solution space\nwith a highly multimodal landscape. State-of-the-art approaches all involve\nusing deterministic approaches such as the expectation-maximization algorithm.\nThese approaches are guaranteed to find local maxima, but do not explore the\nlandscape for other modes. Our approach evolves structure and the missing data.\nWe compare our stochastic algorithms and show they all produce accurate\nresults.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:00:06 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Myers", "James W.", ""], ["Laskey", "Kathryn Blackmond", ""], ["Levitt", "Tod S.", ""]]}, {"id": "1301.6727", "submitter": "Julian R. Neil", "authors": "Julian R. Neil, Chris S. Wallace, Kevin B. Korb", "title": "Learning Bayesian Networks with Restricted Causal Interactions", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-486-493", "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major problem for the learning of Bayesian networks (BNs) is the\nexponential number of parameters needed for conditional probability tables.\nRecent research reduces this complexity by modeling local structure in the\nprobability tables. We examine the use of log-linear local models. While\nlog-linear models in this context are not new (Whittaker, 1990; Buntine, 1991;\nNeal, 1992; Heckerman and Meek, 1997), for structure learning they are\ngenerally subsumed under a naive Bayes model. We describe an alternative\ninterpretation, and use a Minimum Message Length (MML) (Wallace, 1987) metric\nfor structure learning of networks exhibiting causal independence, which we\nterm first-order networks (FONs). We also investigate local model selection on\na node-by-node basis.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:00:10 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Neil", "Julian R.", ""], ["Wallace", "Chris S.", ""], ["Korb", "Kevin B.", ""]]}, {"id": "1301.6728", "submitter": "Hien Nguyen", "authors": "Hien Nguyen, Peter Haddawy", "title": "The Decision-Theoretic Interactive Video Advisor", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-494-501", "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need to help people choose among large numbers of items and to filter\nthrough large amounts of information has led to a flood of research in\nconstruction of personal recommendation agents. One of the central issues in\nconstructing such agents is the representation and elicitation of user\npreferences or interests. This topic has long been studied in Decision Theory,\nbut surprisingly little work in the area of recommender systems has made use of\nformal decision-theoretic techniques. This paper describes DIVA, a\ndecision-theoretic agent for recommending movies that contains a number of\nnovel features. DIVA represents user preferences using pairwise comparisons\namong items, rather than numeric ratings. It uses a novel similarity measure\nbased on the concept of the probability of conflict between two orderings of\nitems. The system has a rich representation of preference, distinguishing\nbetween a user's general taste in movies and his immediate interests. It takes\nan incremental approach to preference elicitation in which the user can provide\nfeedback if not satisfied with the recommendation list. We empirically evaluate\nthe performance of the system using the EachMovie collaborative filtering\ndatabase.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:00:14 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Nguyen", "Hien", ""], ["Haddawy", "Peter", ""]]}, {"id": "1301.6729", "submitter": "Thomas D. Nielsen", "authors": "Thomas D. Nielsen, Finn Verner Jensen", "title": "Welldefined Decision Scenarios", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-502-511", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Influence diagrams serve as a powerful tool for modelling symmetric decision\nproblems. When solving an influence diagram we determine a set of strategies\nfor the decisions involved. A strategy for a decision variable is in principle\na function over its past. However, some of the past may be irrelevant for the\ndecision, and for computational reasons it is important not to deal with\nredundant variables in the strategies. We show that current methods (e.g. the\n\"Decision Bayes-ball\" algorithm by Shachter UAI98) do not determine the\nrelevant past, and we present a complete algorithm.\n  Actually, this paper takes a more general outset: When formulating a decision\nscenario as an influence diagram, a linear temporal ordering of the decisions\nvariables is required. This constraint ensures that the decision scenario is\nwelldefined. However, the structure of a decision scenario often yields certain\ndecisions conditionally independent, and it is therefore unnecessary to impose\na linear temporal ordering on the decisions. In this paper we deal with partial\ninfluence diagrams i.e. influence diagrams with only a partial temporal\nordering specified. We present a set of conditions which are necessary and\nsufficient to ensure that a partial influence diagram is welldefined. These\nconditions are used as a basis for the construction of an algorithm for\ndetermining whether or not a partial influence diagram is welldefined.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:00:18 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Nielsen", "Thomas D.", ""], ["Jensen", "Finn Verner", ""]]}, {"id": "1301.6732", "submitter": "David M Pennock", "authors": "David M. Pennock, Michael P. Wellman", "title": "Graphical Representations of Consensus Belief", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-531-540", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphical models based on conditional independence support concise encodings\nof the subjective belief of a single agent. A natural question is whether the\nconsensus belief of a group of agents can be represented with equal parsimony.\nWe prove, under relatively mild assumptions, that even if everyone agrees on a\ncommon graph topology, no method of combining beliefs can maintain that\nstructure. Even weaker conditions rule out local aggregation within conditional\nprobability tables. On a more positive note, we show that if probabilities are\ncombined with the logarithmic opinion pool (LogOP), then commonly held Markov\nindependencies are maintained. This suggests a straightforward procedure for\nconstructing a consensus Markov network. We describe an algorithm for computing\nthe LogOP with time complexity comparable to that of exact Bayesian inference.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:00:29 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Pennock", "David M.", ""], ["Wellman", "Michael P.", ""]]}, {"id": "1301.6733", "submitter": "Avi Pfeffer", "authors": "Avi Pfeffer, Daphne Koller, Brian Milch, Ken T. Takusagawa", "title": "SPOOK: A System for Probabilistic Object-Oriented Knowledge\n  Representation", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-541-550", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In previous work, we pointed out the limitations of standard Bayesian\nnetworks as a modeling framework for large, complex domains. We proposed a new,\nrichly structured modeling language, {em Object-oriented Bayesian Netorks},\nthat we argued would be able to deal with such domains. However, it turns out\nthat OOBNs are not expressive enough to model many interesting aspects of\ncomplex domains: the existence of specific named objects, arbitrary relations\nbetween objects, and uncertainty over domain structure. These aspects are\ncrucial in real-world domains such as battlefield awareness. In this paper, we\npresent SPOOK, an implemented system that addresses these limitations. SPOOK\nimplements a more expressive language that allows it to represent the\nbattlespace domain naturally and compactly. We present a new inference\nalgorithm that utilizes the model structure in a fundamental way, and show\nempirically that it achieves orders of magnitude speedup over existing\napproaches.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:00:32 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Pfeffer", "Avi", ""], ["Koller", "Daphne", ""], ["Milch", "Brian", ""], ["Takusagawa", "Ken T.", ""]]}, {"id": "1301.6734", "submitter": "Luigi Portinale", "authors": "Luigi Portinale, Andrea Bobbio", "title": "Bayesian Networks for Dependability Analysis: an Application to Digital\n  Control Reliability", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-551-558", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Networks (BN) provide robust probabilistic methods of reasoning\nunder uncertainty, but despite their formal grounds are strictly based on the\nnotion of conditional dependence, not much attention has been paid so far to\ntheir use in dependability analysis. The aim of this paper is to propose BN as\na suitable tool for dependability analysis, by challenging the formalism with\nbasic issues arising in dependability tasks. We will discuss how both modeling\nand analysis issues can be naturally dealt with by BN. Moreover, we will show\nhow some limitations intrinsic to combinatorial dependability methods such as\nFault Trees can be overcome using BN. This will be pursued through the study of\na real-world example concerning the reliability analysis of a redundant digital\nProgrammable Logic Controller (PLC) with majority voting 2:3\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:00:36 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Portinale", "Luigi", ""], ["Bobbio", "Andrea", ""]]}, {"id": "1301.6735", "submitter": "Silja Renooij", "authors": "Silja Renooij, Linda C. van der Gaag", "title": "Enhancing QPNs for Trade-off Resolution", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-559-566", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Qualitative probabilistic networks have been introduced as qualitative\nabstractions of Bayesian belief networks. One of the major drawbacks of these\nqualitative networks is their coarse level of detail, which may lead to\nunresolved trade-offs during inference. We present an enhanced formalism for\nqualitative networks with a finer level of detail. An enhanced qualitative\nprobabilistic network differs from a regular qualitative network in that it\ndistinguishes between strong and weak influences. Enhanced qualitative\nprobabilistic networks are purely qualitative in nature, as regular qualitative\nnetworks are, yet allow for efficiently resolving trade-offs during inference.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:00:40 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Renooij", "Silja", ""], ["van der Gaag", "Linda C.", ""]]}, {"id": "1301.6736", "submitter": "Regis Sabbadin", "authors": "Regis Sabbadin", "title": "A Possibilistic Model for Qualitative Sequential Decision Problems under\n  Uncertainty in Partially Observable Environments", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-567-574", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we propose a qualitative (ordinal) counterpart for the\nPartially Observable Markov Decision Processes model (POMDP) in which the\nuncertainty, as well as the preferences of the agent, are modeled by\npossibility distributions. This qualitative counterpart of the POMDP model\nrelies on a possibilistic theory of decision under uncertainty, recently\ndeveloped. One advantage of such a qualitative framework is its ability to\nescape from the classical obstacle of stochastic POMDPs, in which even with a\nfinite state space, the obtained belief state space of the POMDP is infinite.\nInstead, in the possibilistic framework even if exponentially larger than the\nstate space, the belief state space remains finite.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:00:44 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Sabbadin", "Regis", ""]]}, {"id": "1301.6737", "submitter": "David A. Schum", "authors": "David A. Schum", "title": "Inference Networks and the Evaluation of Evidence: Alternative Analyses", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-575-584", "categories": "cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference networks have a variety of important uses and are constructed by\npersons having quite different standpoints. Discussed in this paper are three\ndifferent but complementary methods for generating and analyzing probabilistic\ninference networks. The first method, though over eighty years old, is very\nuseful for knowledge representation in the task of constructing probabilistic\narguments. It is also useful as a heuristic device in generating new forms of\nevidence. The other two methods are formally equivalent ways for combining\nprobabilities in the analysis of inference networks. The use of these three\nmethods is illustrated in an analysis of a mass of evidence in a celebrated\nAmerican law case.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:00:48 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Schum", "David A.", ""]]}, {"id": "1301.6739", "submitter": "Ross D. Shachter", "authors": "Ross D. Shachter", "title": "Efficient Value of Information Computation", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-594-601", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most useful sensitivity analysis techniques of decision analysis\nis the computation of value of information (or clairvoyance), the difference in\nvalue obtained by changing the decisions by which some of the uncertainties are\nobserved. In this paper, some simple but powerful extensions to previous\nalgorithms are introduced which allow an efficient value of information\ncalculation on the rooted cluster tree (or strong junction tree) used to solve\nthe original decision problem.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:00:56 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Shachter", "Ross D.", ""]]}, {"id": "1301.6740", "submitter": "Hagit Shatkay", "authors": "Hagit Shatkay", "title": "Learning Hidden Markov Models with Geometrical Constraints", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-602-611", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hidden Markov models (HMMs) and partially observable Markov decision\nprocesses (POMDPs) form a useful tool for modeling dynamical systems. They are\nparticularly useful for representing environments such as road networks and\noffice buildings, which are typical for robot navigation and planning. The work\npresented here is concerned with acquiring such models. We demonstrate how\ndomain-specific information and constraints can be incorporated into the\nstatistical estimation process, greatly improving the learned models in terms\nof the model quality, the number of iterations required for convergence and\nrobustness to reduction in the amount of available data. We present new\ninitialization heuristics which can be used even when the data suffers from\ncumulative rotational error, new update rules for the model parameters, as an\ninstance of generalized EM, and a strategy for enforcing complete geometrical\nconsistency in the model. Experimental results demonstrate the effectiveness of\nour approach for both simulated and real robot data, in traditionally\nhard-to-learn environments.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:01:01 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Shatkay", "Hagit", ""]]}, {"id": "1301.6741", "submitter": "Philippe Smets", "authors": "Philippe Smets", "title": "Practical Uses of Belief Functions", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-612-621", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present examples where the use of belief functions provided sound and\nelegant solutions to real life problems. These are essentially characterized by\n?missing' information. The examples deal with 1) discriminant analysis using a\nlearning set where classes are only partially known; 2) an information\nretrieval systems handling inter-documents relationships; 3) the combination of\ndata from sensors competent on partially overlapping frames; 4) the\ndetermination of the number of sources in a multi-sensor environment by\nstudying the inter-sensors contradiction. The purpose of the paper is to report\non such applications where the use of belief functions provides a convenient\ntool to handle ?messy' data problems.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:01:05 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Smets", "Philippe", ""]]}, {"id": "1301.6742", "submitter": "Masami Takikawa", "authors": "Masami Takikawa, Bruce D'Ambrosio", "title": "Multiplicative Factorization of Noisy-Max", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-622-630", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The noisy-or and its generalization noisy-max have been utilized to reduce\nthe complexity of knowledge acquisition. In this paper, we present a new\nrepresentation of noisy-max that allows for efficient inference in general\nBayesian networks. Empirical studies show that our method is capable of\ncomputing queries in well-known large medical networks, QMR-DT and CPCS, for\nwhich no previous exact inference method has been shown to perform well.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:01:09 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Takikawa", "Masami", ""], ["D'Ambrosio", "Bruce", ""]]}, {"id": "1301.6743", "submitter": "Leendert van der Torre", "authors": "Leendert van der Torre, Yao-Hua Tan", "title": "An Update Semantics for Defeasible Obligations", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-631-638", "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deontic logic DUS is a Deontic Update Semantics for prescriptive\nobligations based on the update semantics of Veltman. In DUS the definition of\nlogical validity of obligations is not based on static truth values but on\ndynamic action transitions. In this paper prescriptive defeasible obligations\nare formalized in update semantics and the diagnostic problem of defeasible\ndeontic logic is discussed. Assume a defeasible obligation `normally A ought to\nbe (done)' together withthe fact `A is not (done).' Is this an exception of the\nnormality claim, or is it a violation of the obligation? In this paper we\nformalize the heuristic principle that it is a violation, unless there is a\nmore specific overriding obligation. The underlying motivation from legal\nreasoning is that criminals should have as little opportunities as possible to\nexcuse themselves by claiming that their behavior was exceptional rather than\ncriminal.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:01:14 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["van der Torre", "Leendert", ""], ["Tan", "Yao-Hua", ""]]}, {"id": "1301.6744", "submitter": "Volker Tresp", "authors": "Volker Tresp, Michael Haft, Reimar Hofmann", "title": "Mixture Approximations to Bayesian Networks", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-639-646", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structure and parameters in a Bayesian network uniquely specify the\nprobability distribution of the modeled domain. The locality of both structure\nand probabilistic information are the great benefits of Bayesian networks and\nrequire the modeler to only specify local information. On the other hand this\nlocality of information might prevent the modeler - and even more any other\nperson - from obtaining a general overview of the important relationships\nwithin the domain. The goal of the work presented in this paper is to provide\nan \"alternative\" view on the knowledge encoded in a Bayesian network which\nmight sometimes be very helpful for providing insights into the underlying\ndomain. The basic idea is to calculate a mixture approximation to the\nprobability distribution represented by the Bayesian network. The mixture\ncomponent densities can be thought of as representing typical scenarios implied\nby the Bayesian model, providing intuition about the basic relationships. As an\nadditional benefit, performing inference in the approximate model is very\nsimple and intuitive and can provide additional insights. The computational\ncomplexity for the calculation of the mixture approximations criticaly depends\non the measure which defines the distance between the probability distribution\nrepresented by the Bayesian network and the approximate distribution. Both the\nKL-divergence and the backward KL-divergence lead to inefficient algorithms.\nIncidentally, the latter is used in recent work on mixtures of mean field\nsolutions to which the work presented here is closely related. We show,\nhowever, that using a mean squared error cost function leads to update\nequations which can be solved using the junction tree algorithm. We conclude\nthat the mean squared error cost function can be used for Bayesian networks in\nwhich inference based on the junction tree is tractable. For large networks,\nhowever, one may have to rely on mean field approximations.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:01:18 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Tresp", "Volker", ""], ["Haft", "Michael", ""], ["Hofmann", "Reimar", ""]]}, {"id": "1301.6745", "submitter": "Linda C. van der Gaag", "authors": "Linda C. van der Gaag, Silja Renooij, Cilia L. M. Witteman, Berthe M.\n  P. Aleman, Babs G. Taal", "title": "How to Elicit Many Probabilities", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-647-654", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In building Bayesian belief networks, the elicitation of all probabilities\nrequired can be a major obstacle. We learned the extent of this often-cited\nobservation in the construction of the probabilistic part of a complex\ninfluence diagram in the field of cancer treatment. Based upon our negative\nexperiences with existing methods, we designed a new method for probability\nelicitation from domain experts. The method combines various ideas, among which\nare the ideas of transcribing probabilities and of using a scale with both\nnumerical and verbal anchors for marking assessments. In the construction of\nthe probabilistic part of our influence diagram, the method proved to allow for\nthe elicitation of many probabilities in little time.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:01:22 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["van der Gaag", "Linda C.", ""], ["Renooij", "Silja", ""], ["Witteman", "Cilia L. M.", ""], ["Aleman", "Berthe M. P.", ""], ["Taal", "Babs G.", ""]]}, {"id": "1301.6746", "submitter": "Frans Voorbraak", "authors": "Frans Voorbraak", "title": "Probabilistic Belief Change: Expansion, Conditioning and Constraining", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-655-662", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The AGM theory of belief revision has become an important paradigm for\ninvestigating rational belief changes. Unfortunately, researchers working in\nthis paradigm have restricted much of their attention to rather simple\nrepresentations of belief states, namely logically closed sets of propositional\nsentences. In our opinion, this has resulted in a too abstract categorisation\nof belief change operations: expansion, revision, or contraction. Occasionally,\nin the AGM paradigm, also probabilistic belief changes have been considered,\nand it is widely accepted that the probabilistic version of expansion is\nconditioning. However, we argue that it may be more correct to view\nconditioning and expansion as two essentially different kinds of belief change,\nand that what we call constraining is a better candidate for being considered\nprobabilistic expansion.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:01:26 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Voorbraak", "Frans", ""]]}, {"id": "1301.6747", "submitter": "Robert L. Welch", "authors": "Robert L. Welch, Clayton Smith", "title": "Bayesian Control for Concentrating Mixed Nuclear Waste", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-663-669", "categories": "cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A control algorithm for batch processing of mixed waste is proposed based on\nconditional Gaussian Bayesian networks. The network is compiled during batch\nstaging for real-time response to sensor input.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:01:29 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Welch", "Robert L.", ""], ["Smith", "Clayton", ""]]}, {"id": "1301.6748", "submitter": "Michael S. K. M. Wong", "authors": "Michael S. K. M. Wong, C. J. Butz", "title": "Contextual Weak Independence in Bayesian Networks", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-670-679", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that the notion of (strong) conditional independence (CI) is\ntoo restrictive to capture independencies that only hold in certain contexts.\nThis kind of contextual independency, called context-strong independence (CSI),\ncan be used to facilitate the acquisition, representation, and inference of\nprobabilistic knowledge. In this paper, we suggest the use of contextual weak\nindependence (CWI) in Bayesian networks. It should be emphasized that the\nnotion of CWI is a more general form of contextual independence than CSI.\nFurthermore, if the contextual strong independence holds for all contexts, then\nthe notion of CSI becomes strong CI. On the other hand, if the weak contextual\nindependence holds for all contexts, then the notion of CWI becomes weak\nindependence (WI) nwhich is a more general noncontextual independency than\nstrong CI. More importantly, complete axiomatizations are studied for both the\nclass of WI and the class of CI and WI together. Finally, the interesting\nproperty of WI being a necessary and sufficient condition for ensuring\nconsistency in granular probabilistic networks is shown.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:01:33 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Wong", "Michael S. K. M.", ""], ["Butz", "C. J.", ""]]}, {"id": "1301.6749", "submitter": "Yanping Xiang", "authors": "Yanping Xiang, Finn Verner Jensen", "title": "Inference in Multiply Sectioned Bayesian Networks with Extended\n  Shafer-Shenoy and Lazy Propagation", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-680-687", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Bayesian networks are applied to larger and more complex problem domains,\nsearch for flexible modeling and more efficient inference methods is an ongoing\neffort. Multiply sectioned Bayesian networks (MSBNs) extend the HUGIN inference\nfor Bayesian networks into a coherent framework for flexible modeling and\ndistributed inference.Lazy propagation extends the Shafer-Shenoy and HUGIN\ninference methods with reduced space complexity. We apply the Shafer-Shenoy and\nlazy propagation to inference in MSBNs. The combination of the MSBN framework\nand lazy propagation provides a better framework for modeling and inference in\nvery large domains. It retains the modeling flexibility of MSBNs and reduces\nthe runtime space complexity, allowing exact inference in much larger domains\ngiven the same computational resources.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:01:37 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Xiang", "Yanping", ""], ["Jensen", "Finn Verner", ""]]}, {"id": "1301.6750", "submitter": "Yanping Xiang", "authors": "Yanping Xiang, Kim-Leng Poh", "title": "Time-Critical Dynamic Decision Making", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-688-695", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent interests in dynamic decision modeling have led to the development of\nseveral representation and inference methods. These methods however, have\nlimited application under time critical conditions where a trade-off between\nmodel quality and computational tractability is essential. This paper presents\nan approach to time-critical dynamic decision modeling. A knowledge\nrepresentation and modeling method called the time-critical dynamic influence\ndiagram is proposed. The formalism has two forms. The condensed form is used\nfor modeling and model abstraction, while the deployed form which can be\nconverted from the condensed form is used for inference purposes. The proposed\napproach has the ability to represent space-temporal abstraction within the\nmodel. A knowledge-based meta-reasoning approach is proposed for the purpose of\nselecting the best abstracted model that provide the optimal trade-off between\nmodel quality and model tractability. An outline of the knowledge-based model\nconstruction algorithm is also provided.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:01:41 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Xiang", "Yanping", ""], ["Poh", "Kim-Leng", ""]]}, {"id": "1301.6751", "submitter": "Nevin Lianwen Zhang", "authors": "Nevin Lianwen Zhang, Stephen S. Lee, Weihong Zhang", "title": "A Method for Speeding Up Value Iteration in Partially Observable Markov\n  Decision Processes", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-696-703", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a technique for speeding up the convergence of value iteration for\npartially observable Markov decisions processes (POMDPs). The underlying idea\nis similar to that behind modified policy iteration for fully observable Markov\ndecision processes (MDPs). The technique can be easily incorporated into any\nexisting POMDP value iteration algorithms. Experiments have been conducted on\nseveral test problems with one POMDP value iteration algorithm called\nincremental pruning. We find that the technique can make incremental pruning\nrun several orders of magnitude faster.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:01:45 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Zhang", "Nevin Lianwen", ""], ["Lee", "Stephen S.", ""], ["Zhang", "Weihong", ""]]}, {"id": "1301.6789", "submitter": "D P Acharjya Ph.D", "authors": "B.K.Tripathy and D.P.Acharjya", "title": "Approximation of Classification and Measures of Uncertainty in Rough Set\n  on Two Universal Sets", "comments": "14 pages, International Journal of Advanced Science and Technology\n  Vol. 40, March, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of rough set captures indiscernibility of elements in a set. But,\nin many real life situations, an information system establishes the relation\nbetween different universes. This gave the extension of rough set on single\nuniversal set to rough set on two universal sets. In this paper, we introduce\napproximation of classifications and measures of uncertainty basing upon rough\nset on two universal sets employing the knowledge due to binary relations.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2013 11:58:23 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Tripathy", "B. K.", ""], ["Acharjya", "D. P.", ""]]}, {"id": "1301.6905", "submitter": "Robert Kowalski", "authors": "Robert Kowalski, Fariba Sadri", "title": "Towards a Logic-Based Unifying Framework for Computing", "comments": "An improved version of this paper will be published in the journal,\n  New Generation Computing, with the title \"Reactive Computing as Model\n  Generation\". In the meanwhile, a copy of the revised paper can be found on\n  http://www.doc.ic.ac.uk/~rak/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DB cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a logic-based, framework inspired by artificial\nintelligence, but scaled down for practical database and programming\napplications. Computation in the framework is viewed as the task of generating\na sequence of state transitions, with the purpose of making an agent's goals\nall true. States are represented by sets of atomic sentences (or facts),\nrepresenting the values of program variables, tuples in a coordination\nlanguage, facts in relational databases, or Herbrand models.\n  In the model-theoretic semantics, the entire sequence of states and events\nare combined into a single model-theoretic structure, by associating timestamps\nwith facts and events. But in the operational semantics, facts are updated\ndestructively, without timestamps. We show that the model generated by\ndestructive updates is identical to the model generated by reasoning with facts\ncontaining timestamps. We also extend the model with intentional predicates and\ncomposite event predicates defined by logic programs containing conditions in\nfirst-order logic, which query the current state.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2013 12:23:26 GMT"}, {"version": "v2", "created": "Thu, 24 Apr 2014 07:25:29 GMT"}], "update_date": "2014-04-25", "authors_parsed": [["Kowalski", "Robert", ""], ["Sadri", "Fariba", ""]]}, {"id": "1301.6975", "submitter": "Keyan Zahedi", "authors": "Keyan Zahedi and Nihat Ay", "title": "Quantifying Morphological Computation", "comments": null, "journal-ref": "Entropy. 2013; 15(5):1887-1915", "doi": "10.3390/e15051887", "report-no": null, "categories": "cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of embodied intelligence emphasises the importance of the\nmorphology and environment with respect to the behaviour of a cognitive system.\nThe contribution of the morphology to the behaviour, commonly known as\nmorphological computation, is well-recognised in this community. We believe\nthat the field would benefit from a formalisation of this concept as we would\nlike to ask how much the morphology and the environment contribute to an\nembodied agent's behaviour, or how an embodied agent can maximise the\nexploitation of its morphology within its environment. In this work we derive\ntwo concepts of measuring morphological computation, and we discuss their\nrelation to the Information Bottleneck Method. The first concepts asks how much\nthe world contributes to the overall behaviour and the second concept asks how\nmuch the agent's action contributes to a behaviour. Various measures are\nderived from the concepts and validated in two experiments which highlight\ntheir strengths and weaknesses.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2013 16:39:18 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2013 10:35:13 GMT"}], "update_date": "2013-06-21", "authors_parsed": [["Zahedi", "Keyan", ""], ["Ay", "Nihat", ""]]}, {"id": "1301.7189", "submitter": "Jose M. Pe\\~na", "authors": "Jose M. Pe\\~na", "title": "Approximate Counting of Graphical Models Via MCMC Revisited", "comments": "In Proceedings of the 15th Conference of the Spanish Association for\n  Artificial Intelligence (CAEPIA 2013). Lecture Notes in Artificial\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Pe\\~na (2007), MCMC sampling is applied to approximately calculate the\nratio of essential graphs (EGs) to directed acyclic graphs (DAGs) for up to 20\nnodes. In the present paper, we extend that work from 20 to 31 nodes. We also\nextend that work by computing the approximate ratio of connected EGs to\nconnected DAGs, of connected EGs to EGs, and of connected DAGs to DAGs.\nFurthermore, we prove that the latter ratio is asymptotically 1. We also\ndiscuss the implications of these results for learning DAGs from data.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 10:40:07 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2013 20:30:47 GMT"}], "update_date": "2013-07-04", "authors_parsed": [["Pe\u00f1a", "Jose M.", ""]]}, {"id": "1301.7251", "submitter": "Teresa Alsinet", "authors": "Teresa Alsinet, Lluis Godo, Sandra Sandri", "title": "On the Semantics and Automated Deduction for PLFC, a Logic of\n  Possibilistic Uncertainty and Fuzziness", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-3-12", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Possibilistic logic is a well-known graded logic of uncertainty suitable to\nreason under incomplete information and partially inconsistent knowledge, which\nis built upon classical first order logic. There exists for Possibilistic logic\na proof procedure based on a refutation complete resolution-style calculus.\nRecently, a syntactical extension of first order Possibilistic logic (called\nPLFC) dealing with fuzzy constants and fuzzily restricted quantifiers has been\nproposed. Our aim is to present steps towards both the formalization of PLFC\nitself and an automated deduction system for it by (i) providing a formal\nsemantics; (ii) defining a sound resolution-style calculus by refutation; and\n(iii) describing a first-order proof procedure for PLFC clauses based on (ii)\nand on a novel notion of most general substitution of two literals in a\nresolution step. In contrast to standard Possibilistic logic semantics,\ntruth-evaluation of formulas with fuzzy constants are many-valued instead of\nboolean, and consequently an extended notion of possibilistic uncertainty is\nalso needed.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 14:58:40 GMT"}], "update_date": "2013-01-31", "authors_parsed": [["Alsinet", "Teresa", ""], ["Godo", "Lluis", ""], ["Sandri", "Sandra", ""]]}, {"id": "1301.7358", "submitter": "Leila Amgoud", "authors": "Leila Amgoud, Claudette Cayrol", "title": "On the Acceptability of Arguments in Preference-Based Argumentation", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-1-7", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Argumentation is a promising model for reasoning with uncertain knowledge.\nThe key concept of acceptability enables to differentiate arguments and\ncounterarguments: The certainty of a proposition can then be evaluated through\nthe most acceptable arguments for that proposition. In this paper, we\ninvestigate different complementary points of view: - an acceptability based on\nthe existence of direct counterarguments, - an acceptability based on the\nexistence of defenders. Pursuing previous work on preference-based\nargumentation principles, we enforce both points of view by taking into account\npreference orderings for comparing arguments. Our approach is illustrated in\nthe context of reasoning with stratified knowldge bases.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:02:19 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Amgoud", "Leila", ""], ["Cayrol", "Claudette", ""]]}, {"id": "1301.7359", "submitter": "Salem Benferhat", "authors": "Salem Benferhat, Claudio Sossai", "title": "Merging Uncertain Knowledge Bases in a Possibilistic Logic Framework", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-8-15", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of merging uncertain information in the\nframework of possibilistic logic. It presents several syntactic combination\nrules to merge possibilistic knowledge bases, provided by different sources,\ninto a new possibilistic knowledge base. These combination rules are first\ndescribed at the meta-level outside the language of possibilistic logic. Next,\nan extension of possibilistic logic, where the combination rules are inside the\nlanguage, is proposed. A proof system in a sequent form, which is sound and\ncomplete with respect to the possibilistic logic semantics, is given.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:02:23 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Benferhat", "Salem", ""], ["Sossai", "Claudio", ""]]}, {"id": "1301.7360", "submitter": "Mark Bloemeke", "authors": "Mark Bloemeke, Marco Valtorta", "title": "A Hybrid Algorithm to Compute Marginal and Joint Beliefs in Bayesian\n  Networks and Its Complexity", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-16-23", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There exist two general forms of exact algorithms for updating probabilities\nin Bayesian Networks. The first approach involves using a structure, usually a\nclique tree, and performing local message based calculation to extract the\nbelief in each variable. The second general class of algorithm involves the use\nof non-serial dynamic programming techniques to extract the belief in some\ndesired group of variables. In this paper we present a hybrid algorithm based\non the latter approach yet possessing the ability to retrieve the belief in all\nsingle variables. The technique is advantageous in that it saves a NP-hard\ncomputation step over using one algorithm of each type. Furthermore, this\ntechnique re-enforces a conjecture of Jensen and Jensen [JJ94] in that it still\nrequires a single NP-hard step to set up the structure on which inference is\nperformed, as we show by confirming Li and D'Ambrosio's [LD94] conjectured\nNP-hardness of OFP.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:02:29 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Bloemeke", "Mark", ""], ["Valtorta", "Marco", ""]]}, {"id": "1301.7361", "submitter": "Craig Boutilier", "authors": "Craig Boutilier, Ronen I. Brafman, Christopher W. Geib", "title": "Structured Reachability Analysis for Markov Decision Processes", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-24-32", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research in decision theoretic planning has focussed on making the\nsolution of Markov decision processes (MDPs) more feasible. We develop a family\nof algorithms for structured reachability analysis of MDPs that are suitable\nwhen an initial state (or set of states) is known. Using compact, structured\nrepresentations of MDPs (e.g., Bayesian networks), our methods, which vary in\nthe tradeoff between complexity and accuracy, produce structured descriptions\nof (estimated) reachable states that can be used to eliminate variables or\nvariable values from the problem description, reducing the size of the MDP and\nmaking it easier to solve. One contribution of our work is the extension of\nideas from GRAPHPLAN to deal with the distributed nature of action\nrepresentations typically embodied within Bayes nets and the problem of\ncorrelated action effects. We also demonstrate that our algorithm can be made\nmore complete by using k-ary constraints instead of binary constraints. Another\ncontribution is the illustration of how the compact representation of\nreachability constraints can be exploited by several existing (exact and\napproximate) abstraction algorithms for MDPs.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:02:33 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2013 15:58:57 GMT"}], "update_date": "2013-04-24", "authors_parsed": [["Boutilier", "Craig", ""], ["Brafman", "Ronen I.", ""], ["Geib", "Christopher W.", ""]]}, {"id": "1301.7362", "submitter": "Xavier Boyen", "authors": "Xavier Boyen, Daphne Koller", "title": "Tractable Inference for Complex Stochastic Processes", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-33-42", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The monitoring and control of any dynamic system depends crucially on the\nability to reason about its current status and its future trajectory. In the\ncase of a stochastic system, these tasks typically involve the use of a belief\nstate- a probability distribution over the state of the process at a given\npoint in time. Unfortunately, the state spaces of complex processes are very\nlarge, making an explicit representation of a belief state intractable. Even in\ndynamic Bayesian networks (DBNs), where the process itself can be represented\ncompactly, the representation of the belief state is intractable. We\ninvestigate the idea of maintaining a compact approximation to the true belief\nstate, and analyze the conditions under which the errors due to the\napproximations taken over the lifetime of the process do not accumulate to make\nour answers completely irrelevant. We show that the error in a belief state\ncontracts exponentially as the process evolves. Thus, even with multiple\napproximations, the error in our process remains bounded indefinitely. We show\nhow the additional structure of a DBN can be used to design our approximation\nscheme, improving its performance significantly. We demonstrate the\napplicability of our ideas in the context of a monitoring task, showing that\norders of magnitude faster inference can be achieved with only a small\ndegradation in accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:02:39 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Boyen", "Xavier", ""], ["Koller", "Daphne", ""]]}, {"id": "1301.7364", "submitter": "Luis M. de Campos", "authors": "Luis M. de Campos, Juan M. Fernandez-Luna, Juan F. Huete", "title": "Query Expansion in Information Retrieval Systems using a Bayesian\n  Network-Based Thesaurus", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-53-60", "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information Retrieval (IR) is concerned with the identification of documents\nin a collection that are relevant to a given information need, usually\nrepresented as a query containing terms or keywords, which are supposed to be a\ngood description of what the user is looking for. IR systems may improve their\neffectiveness (i.e., increasing the number of relevant documents retrieved) by\nusing a process of query expansion, which automatically adds new terms to the\noriginal query posed by an user. In this paper we develop a method of query\nexpansion based on Bayesian networks. Using a learning algorithm, we construct\na Bayesian network that represents some of the relationships among the terms\nappearing in a given document collection; this network is then used as a\nthesaurus (specific for that collection). We also report the results obtained\nby our method on three standard test collections.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:02:49 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["de Campos", "Luis M.", ""], ["Fernandez-Luna", "Juan M.", ""], ["Huete", "Juan F.", ""]]}, {"id": "1301.7365", "submitter": "Charles Castel", "authors": "Charles Castel, Corine Cossart, Catherine Tessier", "title": "Dealing with Uncertainty in Situation Assessment: towards a Symbolic\n  Approach", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-61-68", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The situation assessment problem is considered, in terms of object,\ncondition, activity, and plan recognition, based on data coming from the\nreal-word {em via} various sensors. It is shown that uncertainty issues are\nlinked both to the models and to the matching algorithm. Three different types\nof uncertainties are identified, and within each one, the numerical and the\nsymbolic cases are distinguished. The emphasis is then put on purely symbolic\nuncertainties: it is shown that they can be dealt with within a purely symbolic\nframework resulting from a transposition of classical numerical estimation\ntools.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:02:54 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Castel", "Charles", ""], ["Cossart", "Corine", ""], ["Tessier", "Catherine", ""]]}, {"id": "1301.7366", "submitter": "Enrique F. Castillo", "authors": "Enrique F. Castillo, Juan Ferr\\'andiz, Pilar Sanmartin", "title": "Marginalizing in Undirected Graph and Hypergraph Models", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-69-78", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an undirected graph G or hypergraph X model for a given set of\nvariables V, we introduce two marginalization operators for obtaining the\nundirected graph GA or hypergraph HA associated with a given subset A c V such\nthat the marginal distribution of A factorizes according to GA or HA,\nrespectively. Finally, we illustrate the method by its application to some\npractical examples. With them we show that hypergraph models allow defining a\nfiner factorization or performing a more precise conditional independence\nanalysis than undirected graph models.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:02:59 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Castillo", "Enrique F.", ""], ["Ferr\u00e1ndiz", "Juan", ""], ["Sanmartin", "Pilar", ""]]}, {"id": "1301.7367", "submitter": "Urszula Chajewska", "authors": "Urszula Chajewska, Lise Getoor, Joseph Norman, Yuval Shahar", "title": "Utility Elicitation as a Classification Problem", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-79-88", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the application of classification techniques to utility\nelicitation. In a decision problem, two sets of parameters must generally be\nelicited: the probabilities and the utilities. While the prior and conditional\nprobabilities in the model do not change from user to user, the utility models\ndo. Thus it is necessary to elicit a utility model separately for each new\nuser. Elicitation is long and tedious, particularly if the outcome space is\nlarge and not decomposable. There are two common approaches to utility function\nelicitation. The first is to base the determination of the users utility\nfunction solely ON elicitation OF qualitative preferences.The second makes\nassumptions about the form AND decomposability OF the utility function.Here we\ntake a different approach: we attempt TO identify the new USERs utility\nfunction based on classification relative to a database of previously collected\nutility functions. We do this by identifying clusters of utility functions that\nminimize an appropriate distance measure. Having identified the clusters, we\ndevelop a classification scheme that requires many fewer and simpler\nassessments than full utility elicitation and is more robust than utility\nelicitation based solely on preferences. We have tested our algorithm on a\nsmall database of utility functions in a prenatal diagnosis domain and the\nresults are quite promising.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:03:05 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Chajewska", "Urszula", ""], ["Getoor", "Lise", ""], ["Norman", "Joseph", ""], ["Shahar", "Yuval", ""]]}, {"id": "1301.7368", "submitter": "Fabio Gagliardi Cozman", "authors": "Fabio Gagliardi Cozman", "title": "Irrelevance and Independence Relations in Quasi-Bayesian Networks", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-89-96", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes irrelevance and independence relations in graphical\nmodels associated with convex sets of probability distributions (called\nQuasi-Bayesian networks). The basic question in Quasi-Bayesian networks is, How\ncan irrelevance/independence relations in Quasi-Bayesian networks be detected,\nenforced and exploited? This paper addresses these questions through Walley's\ndefinitions of irrelevance and independence. Novel algorithms and results are\npresented for inferences with the so-called natural extensions using fractional\nlinear programming, and the properties of the so-called type-1 extensions are\nclarified through a new generalization of d-separation.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:03:11 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Cozman", "Fabio Gagliardi", ""]]}, {"id": "1301.7369", "submitter": "Adnan Darwiche", "authors": "Adnan Darwiche", "title": "Dynamic Jointrees", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-97-104", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that one can ignore parts of a belief network when computing\nanswers to certain probabilistic queries. It is also well known that the\nignorable parts (if any) depend on the specific query of interest and,\ntherefore, may change as the query changes. Algorithms based on jointrees,\nhowever, do not seem to take computational advantage of these facts given that\nthey typically construct jointrees for worst-case queries; that is, queries for\nwhich every part of the belief network is considered relevant. To address this\nlimitation, we propose in this paper a method for reconfiguring jointrees\ndynamically as the query changes. The reconfiguration process aims at\nmaintaining a jointree which corresponds to the underlying belief network after\nit has been pruned given the current query. Our reconfiguration method is\nmarked by three characteristics: (a) it is based on a non-classical definition\nof jointrees; (b) it is relatively efficient; and (c) it can reuse some of the\ncomputations performed before a jointree is reconfigured. We present\npreliminary experimental results which demonstrate significant savings over\nusing static jointrees when query changes are considerable.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:03:15 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Darwiche", "Adnan", ""]]}, {"id": "1301.7370", "submitter": "Benoit Desjardins", "authors": "Benoit Desjardins", "title": "On the Semi-Markov Equivalence of Causal Models", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-105-112", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The variability of structure in a finite Markov equivalence class of causally\nsufficient models represented by directed acyclic graphs has been fully\ncharacterized. Without causal sufficiency, an infinite semi-Markov equivalence\nclass of models has only been characterized by the fact that each model in the\nequivalence class entails the same marginal statistical dependencies. In this\npaper, we study the variability of structure of causal models within a\nsemi-Markov equivalence class and propose a systematic approach to construct\nmodels entailing any specific marginal statistical dependencies.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:03:20 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Desjardins", "Benoit", ""]]}, {"id": "1301.7371", "submitter": "Didier Dubois", "authors": "Didier Dubois, Helene Fargier, Henri Prade", "title": "Comparative Uncertainty, Belief Functions and Accepted Beliefs", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-113-120", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper relates comparative belief structures and a general view of belief\nmanagement in the setting of deductively closed logical representations of\naccepted beliefs. We show that the range of compatibility between the classical\ndeductive closure and uncertain reasoning covers precisely the nonmonotonic\n'preferential' inference system of Kraus, Lehmann and Magidor and nothing else.\nIn terms of uncertain reasoning any possibility or necessity measure gives\nbirth to a structure of accepted beliefs. The classes of probability functions\nand of Shafer's belief functions which yield belief sets prove to be very\nspecial ones.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:03:26 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Dubois", "Didier", ""], ["Fargier", "Helene", ""], ["Prade", "Henri", ""]]}, {"id": "1301.7372", "submitter": "Didier Dubois", "authors": "Didier Dubois, Henri Prade, Regis Sabbadin", "title": "Qualitative Decision Theory with Sugeno Integrals", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-121-128", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an axiomatic framework for qualitative decision under\nuncertainty in a finite setting. The corresponding utility is expressed by a\nsup-min expression, called Sugeno (or fuzzy) integral. Technically speaking,\nSugeno integral is a median, which is indeed a qualitative counterpart to the\naveraging operation underlying expected utility. The axiomatic justification of\nSugeno integral-based utility is expressed in terms of preference between acts\nas in Savage decision theory. Pessimistic and optimistic qualitative utilities,\nbased on necessity and possibility measures, previously introduced by two of\nthe authors, can be retrieved in this setting by adding appropriate axioms.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:03:31 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Dubois", "Didier", ""], ["Prade", "Henri", ""], ["Sabbadin", "Regis", ""]]}, {"id": "1301.7373", "submitter": "Nir Friedman", "authors": "Nir Friedman", "title": "The Bayesian Structural EM Algorithm", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-129-138", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years there has been a flurry of works on learning Bayesian\nnetworks from data. One of the hard problems in this area is how to effectively\nlearn the structure of a belief network from incomplete data- that is, in the\npresence of missing values or hidden variables. In a recent paper, I introduced\nan algorithm called Structural EM that combines the standard Expectation\nMaximization (EM) algorithm, which optimizes parameters, with structure search\nfor model selection. That algorithm learns networks based on penalized\nlikelihood scores, which include the BIC/MDL score and various approximations\nto the Bayesian score. In this paper, I extend Structural EM to deal directly\nwith Bayesian model selection. I prove the convergence of the resulting\nalgorithm and show how to apply it for learning a large class of probabilistic\nmodels, including Bayesian networks and some variants thereof.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:03:37 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Friedman", "Nir", ""]]}, {"id": "1301.7374", "submitter": "Nir Friedman", "authors": "Nir Friedman, Kevin Murphy, Stuart Russell", "title": "Learning the Structure of Dynamic Probabilistic Networks", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-139-147", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic probabilistic networks are a compact representation of complex\nstochastic processes. In this paper we examine how to learn the structure of a\nDPN from data. We extend structure scoring rules for standard probabilistic\nnetworks to the dynamic case, and show how to search for structure when some of\nthe variables are hidden. Finally, we examine two applications where such a\ntechnology might be useful: predicting and classifying dynamic behaviors, and\nlearning causal orderings in biological processes. We provide empirical results\nthat demonstrate the applicability of our methods in both domains.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:03:42 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Friedman", "Nir", ""], ["Murphy", "Kevin", ""], ["Russell", "Stuart", ""]]}, {"id": "1301.7377", "submitter": "Clark Glymour", "authors": "Clark Glymour", "title": "Psychological and Normative Theories of Causal Power and the\n  Probabilities of Causes", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-166-172", "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper (1)shows that the best supported current psychological theory\n(Cheng, 1997) of how human subjects judge the causal power or influence of\nvariations in presence or absence of one feature on another, given data on\ntheir covariation, tacitly uses a Bayes network which is either a noisy or gate\n(for causes that promote the effect) or a noisy and gate (for causes that\ninhibit the effect); (2)generalizes Chengs theory to arbitrary acyclic networks\nof noisy or and noisy and gates; (3)gives various sufficient conditions for the\nestimation of the parameters in such networks when there are independent,\nunobserved causes; (4)distinguishes direct causal influence of one feature on\nanother (influence along a path with one edge) from total influence (influence\nalong all paths from one variable to another) and gives sufficient conditions\nfor estimating each when there are unobserved causes of the outcome variable;\n(5)describes the relation between Cheng models and a simplified version of the\nRubin framework for representing causal relations.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:03:57 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Glymour", "Clark", ""]]}, {"id": "1301.7379", "submitter": "Vu A. Ha", "authors": "Vu A. Ha, Peter Haddawy", "title": "Towards Case-Based Preference Elicitation: Similarity Measures on\n  Preference Structures", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-193-201", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While decision theory provides an appealing normative framework for\nrepresenting rich preference structures, eliciting utility or value functions\ntypically incurs a large cost. For many applications involving interactive\nsystems this overhead precludes the use of formal decision-theoretic models of\npreference. Instead of performing elicitation in a vacuum, it would be useful\nif we could augment directly elicited preferences with some appropriate default\ninformation. In this paper we propose a case-based approach to alleviating the\npreference elicitation bottleneck. Assuming the existence of a population of\nusers from whom we have elicited complete or incomplete preference structures,\nwe propose eliciting the preferences of a new user interactively and\nincrementally, using the closest existing preference structures as potential\ndefaults. Since a notion of closeness demands a measure of distance among\npreference structures, this paper takes the first step of studying various\ndistance measures over fully and partially specified preference structures. We\nexplore the use of Euclidean distance, Spearmans footrule, and define a new\nmeasure, the probabilistic distance. We provide computational techniques for\nall three measures.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:04:06 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Ha", "Vu A.", ""], ["Haddawy", "Peter", ""]]}, {"id": "1301.7380", "submitter": "Eric A. Hansen", "authors": "Eric A. Hansen", "title": "Solving POMDPs by Searching in Policy Space", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-211-219", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most algorithms for solving POMDPs iteratively improve a value function that\nimplicitly represents a policy and are said to search in value function space.\nThis paper presents an approach to solving POMDPs that represents a policy\nexplicitly as a finite-state controller and iteratively improves the controller\nby search in policy space. Two related algorithms illustrate this approach. The\nfirst is a policy iteration algorithm that can outperform value iteration in\nsolving infinitehorizon POMDPs. It provides the foundation for a new heuristic\nsearch algorithm that promises further speedup by focusing computational effort\non regions of the problem space that are reachable, or likely to be reached,\nfrom a start state.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:04:11 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Hansen", "Eric A.", ""]]}, {"id": "1301.7381", "submitter": "Milos Hauskrecht", "authors": "Milos Hauskrecht, Nicolas Meuleau, Leslie Pack Kaelbling, Thomas L.\n  Dean, Craig Boutilier", "title": "Hierarchical Solution of Markov Decision Processes using Macro-actions", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-220-229", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the use of temporally abstract actions, or macro-actions, in\nthe solution of Markov decision processes. Unlike current models that combine\nboth primitive actions and macro-actions and leave the state space unchanged,\nwe propose a hierarchical model (using an abstract MDP) that works with\nmacro-actions only, and that significantly reduces the size of the state space.\nThis is achieved by treating macroactions as local policies that act in certain\nregions of state space, and by restricting states in the abstract MDP to those\nat the boundaries of regions. The abstract MDP approximates the original and\ncan be solved more efficiently. We discuss several ways in which macro-actions\ncan be generated to ensure good solution quality. Finally, we consider ways in\nwhich macro-actions can be reused to solve multiple, related MDPs; and we show\nthat this can justify the computational overhead of macro-action generation.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:04:16 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Hauskrecht", "Milos", ""], ["Meuleau", "Nicolas", ""], ["Kaelbling", "Leslie Pack", ""], ["Dean", "Thomas L.", ""], ["Boutilier", "Craig", ""]]}, {"id": "1301.7382", "submitter": "David Heckerman", "authors": "David Heckerman, Eric J. Horvitz", "title": "Inferring Informational Goals from Free-Text Queries: A Bayesian\n  Approach", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-230-237", "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People using consumer software applications typically do not use technical\njargon when querying an online database of help topics. Rather, they attempt to\ncommunicate their goals with common words and phrases that describe software\nfunctionality in terms of structure and objects they understand. We describe a\nBayesian approach to modeling the relationship between words in a user's query\nfor assistance and the informational goals of the user. After reviewing the\ngeneral method, we describe several extensions that center on integrating\nadditional distinctions and structure about language usage and user goals into\nthe Bayesian models.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:04:21 GMT"}, {"version": "v2", "created": "Sat, 16 May 2015 23:11:26 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Heckerman", "David", ""], ["Horvitz", "Eric J.", ""]]}, {"id": "1301.7383", "submitter": "Holger H. Hoos", "authors": "Holger H. Hoos, Thomas Stutzle", "title": "Evaluating Las Vegas Algorithms - Pitfalls and Remedies", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-238-245", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic search algorithms are among the most sucessful approaches for\nsolving hard combinatorial problems. A large class of stochastic search\napproaches can be cast into the framework of Las Vegas Algorithms (LVAs). As\nthe run-time behavior of LVAs is characterized by random variables, the\ndetailed knowledge of run-time distributions provides important information for\nthe analysis of these algorithms. In this paper we propose a novel methodology\nfor evaluating the performance of LVAs, based on the identification of\nempirical run-time distributions. We exemplify our approach by applying it to\nStochastic Local Search (SLS) algorithms for the satisfiability problem (SAT)\nin propositional logic. We point out pitfalls arising from the use of improper\nempirical methods and discuss the benefits of the proposed methodology for\nevaluating and comparing LVAs.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:04:26 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Hoos", "Holger H.", ""], ["Stutzle", "Thomas", ""]]}, {"id": "1301.7384", "submitter": "Michael C. Horsch", "authors": "Michael C. Horsch, David L. Poole", "title": "An Anytime Algorithm for Decision Making under Uncertainty", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-246-255", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an anytime algorithm which computes policies for decision problems\nrepresented as multi-stage influence diagrams. Our algorithm constructs\npolicies incrementally, starting from a policy which makes no use of the\navailable information. The incremental process constructs policies which\nincludes more of the information available to the decision maker at each step.\nWhile the process converges to the optimal policy, our approach is designed for\nsituations in which computing the optimal policy is infeasible. We provide\nexamples of the process on several large decision problems, showing that, for\nthese examples, the process constructs valuable (but sub-optimal) policies\nbefore the optimal policy would be available by traditional methods.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:04:31 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Horsch", "Michael C.", ""], ["Poole", "David L.", ""]]}, {"id": "1301.7385", "submitter": "Eric J. Horvitz", "authors": "Eric J. Horvitz, John S. Breese, David Heckerman, David Hovel, Koos\n  Rommelse", "title": "The Lumiere Project: Bayesian User Modeling for Inferring the Goals and\n  Needs of Software Users", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-256-265", "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lumiere Project centers on harnessing probability and utility to provide\nassistance to computer software users. We review work on Bayesian user models\nthat can be employed to infer a users needs by considering a user's background,\nactions, and queries. Several problems were tackled in Lumiere research,\nincluding (1) the construction of Bayesian models for reasoning about the\ntime-varying goals of computer users from their observed actions and queries,\n(2) gaining access to a stream of events from software applications, (3)\ndeveloping a language for transforming system events into observational\nvariables represented in Bayesian user models, (4) developing persistent\nprofiles to capture changes in a user expertise, and (5) the development of an\noverall architecture for an intelligent user interface. Lumiere prototypes\nserved as the basis for the Office Assistant in the Microsoft Office '97 suite\nof productivity applications.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:04:36 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Horvitz", "Eric J.", ""], ["Breese", "John S.", ""], ["Heckerman", "David", ""], ["Hovel", "David", ""], ["Rommelse", "Koos", ""]]}, {"id": "1301.7386", "submitter": "Pablo H. Ibarguengoytia", "authors": "Pablo H. Ibarguengoytia, Luis Enrique Sucar, Sunil Vadera", "title": "Any Time Probabilistic Reasoning for Sensor Validation", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-266-273", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many real time applications, it is important to validate the information\nreceived from the sensors before entering higher levels of reasoning. This\npaper presents an any time probabilistic algorithm for validating the\ninformation provided by sensors. The system consists of two Bayesian network\nmodels. The first one is a model of the dependencies between sensors and it is\nused to validate each sensor. It provides a list of potentially faulty sensors.\nTo isolate the real faults, a second Bayesian network is used, which relates\nthe potential faults with the real faults. This second model is also used to\nmake the validation algorithm any time, by validating first the sensors that\nprovide more information. To select the next sensor to validate, and measure\nthe quality of the results at each stage, an entropy function is used. This\nfunction captures in a single quantity both the certainty and specificity\nmeasures of any time algorithms. Together, both models constitute a mechanism\nfor validating sensors in an any time fashion, providing at each step the\nprobability of correct/faulty for each sensor, and the total quality of the\nresults. The algorithm has been tested in the validation of temperature sensors\nof a power plant.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:04:41 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Ibarguengoytia", "Pablo H.", ""], ["Sucar", "Luis Enrique", ""], ["Vadera", "Sunil", ""]]}, {"id": "1301.7387", "submitter": "Manfred Jaeger", "authors": "Manfred Jaeger", "title": "Measure Selection: Notions of Rationality and Representation\n  Independence", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-274-281", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We take another look at the general problem of selecting a preferred\nprobability measure among those that comply with some given constraints. The\ndominant role that entropy maximization has obtained in this context is\nquestioned by arguing that the minimum information principle on which it is\nbased could be supplanted by an at least as plausible \"likelihood of evidence\"\nprinciple. We then review a method for turning given selection functions into\nrepresentation independent variants, and discuss the tradeoffs involved in this\ntransformation.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:04:45 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Jaeger", "Manfred", ""]]}, {"id": "1301.7388", "submitter": "Jean-Yves Jaffray", "authors": "Jean-Yves Jaffray", "title": "Implementing Resolute Choice Under Uncertainty", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-282-288", "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adaptation to situations of sequential choice under uncertainty of\ndecision criteria which deviate from (subjective) expected utility raises the\nproblem of ensuring the selection of a nondominated strategy. In particular,\nwhen following the suggestion of Machina and McClennen of giving up\nseparability (also known as consequentialism), which requires the choice of a\nsubstrategy in a subtree to depend only on data relevant to that subtree, one\nmust renounce to the use of dynamic programming, since Bellman's principle is\nno longer valid. An interpretation of McClennen's resolute choice, based on\ncooperation between the successive Selves of the decision maker, is proposed.\nImplementations of resolute choice which prevent Money Pumps negative prices of\ninformation or, more generally, choices of dominated strategies, while\nremaining computationally tractable, are proposed.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:04:50 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Jaffray", "Jean-Yves", ""]]}, {"id": "1301.7389", "submitter": "Iman Jarkass", "authors": "Iman Jarkass, Michele Rombaut", "title": "Dealing with Uncertainty on the Initial State of a Petri Net", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-289-295", "categories": "cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a method to find the actual state of a complex dynamic\nsystem from information coming from the sensors on the system himself, or on\nits environment. The nominal evolution of the system is a priori known and can\nbe modeled (by an expert, for example), by different methods. In this paper,\nthe Petri nets have been chosen. Contrary to the usual use of the Petri nets,\nthe initial state of the system is unknown. So a degree of belief is bound to\neach places, or set of places. The theory used to model this uncertainty is the\nDempster-Shafer's one which is well adapted to this type of problems. From the\ngiven Petri net characterizing the nominal evolution of the dynamic system, and\nfrom the observation inputs, the proposed method allows to determine according\nto the reliability of the model and the inputs, the state of the system at any\ntime.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:04:54 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Jarkass", "Iman", ""], ["Rombaut", "Michele", ""]]}, {"id": "1301.7391", "submitter": "Michael Kearns", "authors": "Michael Kearns, Yishay Mansour", "title": "Exact Inference of Hidden Structure from Sample Data in Noisy-OR\n  Networks", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-304-310", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the literature on graphical models, there has been increased attention\npaid to the problems of learning hidden structure (see Heckerman [H96] for\nsurvey) and causal mechanisms from sample data [H96, P88, S93, P95, F98]. In\nmost settings we should expect the former to be difficult, and the latter\npotentially impossible without experimental intervention. In this work, we\nexamine some restricted settings in which perfectly reconstruct the hidden\nstructure solely on the basis of observed sample data.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:05:04 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Kearns", "Michael", ""], ["Mansour", "Yishay", ""]]}, {"id": "1301.7394", "submitter": "Vasilica Lepar", "authors": "Vasilica Lepar, Prakash P. Shenoy", "title": "A Comparison of Lauritzen-Spiegelhalter, Hugin, and Shenoy-Shafer\n  Architectures for Computing Marginals of Probability Distributions", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-328-337", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, several architectures have been proposed for exact\ncomputation of marginals using local computation. In this paper, we compare\nthree architectures - Lauritzen-Spiegelhalter, Hugin, and Shenoy-Shafer - from\nthe perspective of graphical structure for message propagation, message-passing\nscheme, computational efficiency, and storage efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:05:20 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Lepar", "Vasilica", ""], ["Shenoy", "Prakash P.", ""]]}, {"id": "1301.7395", "submitter": "Chao-Lin Liu", "authors": "Chao-Lin Liu, Michael P. Wellman", "title": "Incremental Tradeoff Resolution in Qualitative Probabilistic Networks", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-338-345", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Qualitative probabilistic reasoning in a Bayesian network often reveals\ntradeoffs: relationships that are ambiguous due to competing qualitative\ninfluences. We present two techniques that combine qualitative and numeric\nprobabilistic reasoning to resolve such tradeoffs, inferring the qualitative\nrelationship between nodes in a Bayesian network. The first approach\nincrementally marginalizes nodes that contribute to the ambiguous qualitative\nrelationships. The second approach evaluates approximate Bayesian networks for\nbounds of probability distributions, and uses these bounds to determinate\nqualitative relationships in question. This approach is also incremental in\nthat the algorithm refines the state spaces of random variables for tighter\nbounds until the qualitative relationships are resolved. Both approaches\nprovide systematic methods for tradeoff resolution at potentially lower\ncomputational cost than application of purely numeric methods.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:05:25 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Liu", "Chao-Lin", ""], ["Wellman", "Michael P.", ""]]}, {"id": "1301.7396", "submitter": "Chao-Lin Liu", "authors": "Chao-Lin Liu, Michael P. Wellman", "title": "Using Qualitative Relationships for Bounding Probability Distributions", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-346-353", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We exploit qualitative probabilistic relationships among variables for\ncomputing bounds of conditional probability distributions of interest in\nBayesian networks. Using the signs of qualitative relationships, we can\nimplement abstraction operations that are guaranteed to bound the distributions\nof interest in the desired direction. By evaluating incrementally improved\napproximate networks, our algorithm obtains monotonically tightening bounds\nthat converge to exact distributions. For supermodular utility functions, the\ntightening bounds monotonically reduce the set of admissible decision\nalternatives as well.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:05:30 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Liu", "Chao-Lin", ""], ["Wellman", "Michael P.", ""]]}, {"id": "1301.7397", "submitter": "Thomas Lukasiewicz", "authors": "Thomas Lukasiewicz", "title": "Magic Inference Rules for Probabilistic Deduction under Taxonomic\n  Knowledge", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-354-361", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present locally complete inference rules for probabilistic deduction from\ntaxonomic and probabilistic knowledge-bases over conjunctive events. Crucially,\nin contrast to similar inference rules in the literature, our inference rules\nare locally complete for conjunctive events and under additional taxonomic\nknowledge. We discover that our inference rules are extremely complex and that\nit is at first glance not clear at all where the deduced tightest bounds come\nfrom. Moreover, analyzing the global completeness of our inference rules, we\nfind examples of globally very incomplete probabilistic deductions. More\ngenerally, we even show that all systems of inference rules for taxonomic and\nprobabilistic knowledge-bases over conjunctive events are globally incomplete.\nWe conclude that probabilistic deduction by the iterative application of\ninference rules on interval restrictions for conditional probabilities, even\nthough considered very promising in the literature so far, seems very limited\nin its field of application.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:05:34 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Lukasiewicz", "Thomas", ""]]}, {"id": "1301.7398", "submitter": "Anders L. Madsen", "authors": "Anders L. Madsen, Finn Verner Jensen", "title": "Lazy Propagation in Junction Trees", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-362-369", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The efficiency of algorithms using secondary structures for probabilistic\ninference in Bayesian networks can be improved by exploiting independence\nrelations induced by evidence and the direction of the links in the original\nnetwork. In this paper we present an algorithm that on-line exploits\nindependence relations induced by evidence and the direction of the links in\nthe original network to reduce both time and space costs. Instead of\nmultiplying the conditional probability distributions for the various cliques,\nwe determine on-line which potentials to multiply when a message is to be\nproduced. The performance improvement of the algorithm is emphasized through\nempirical evaluations involving large real world Bayesian networks, and we\ncompare the method with the HUGIN and Shafer-Shenoy inference algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:05:39 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Madsen", "Anders L.", ""], ["Jensen", "Finn Verner", ""]]}, {"id": "1301.7399", "submitter": "Suzanne M. Mahoney", "authors": "Suzanne M. Mahoney, Kathryn Blackmond Laskey", "title": "Constructing Situation Specific Belief Networks", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-370-378", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a process for constructing situation-specific belief\nnetworks from a knowledge base of network fragments. A situation-specific\nnetwork is a minimal query complete network constructed from a knowledge base\nin response to a query for the probability distribution on a set of target\nvariables given evidence and context variables. We present definitions of query\ncompleteness and situation-specific networks. We describe conditions on the\nknowledge base that guarantee query completeness. The relationship of our work\nto earlier work on KBMC is also discussed.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:05:44 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Mahoney", "Suzanne M.", ""], ["Laskey", "Kathryn Blackmond", ""]]}, {"id": "1301.7402", "submitter": "Paul-Andre Monney", "authors": "Paul-Andre Monney", "title": "From Likelihood to Plausibility", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-396-403", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several authors have explained that the likelihood ratio measures the\nstrength of the evidence represented by observations in statistical problems.\nThis idea works fine when the goal is to evaluate the strength of the available\nevidence for a simple hypothesis versus another simple hypothesis. However, the\napplicability of this idea is limited to simple hypotheses because the\nlikelihood function is primarily defined on points (simple hypotheses) of the\nparameter space. In this paper we define a general weight of evidence that is\napplicable to both simple and composite hypotheses. It is based on the\nDempster-Shafer concept of plausibility and is shown to be a generalization of\nthe likelihood ratio. Functional models are of a fundamental importance for the\ngeneral weight of evidence proposed in this paper. The relevant concepts and\nideas are explained by means of a familiar urn problem and the general analysis\nof a real-world medical problem is presented.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:06:00 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Monney", "Paul-Andre", ""]]}, {"id": "1301.7403", "submitter": "Stefano Monti", "authors": "Stefano Monti, Gregory F. Cooper", "title": "A Multivariate Discretization Method for Learning Bayesian Networks from\n  Mixed Data", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-404-413", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the problem of discretization in the context of\nlearning Bayesian networks (BNs) from data containing both continuous and\ndiscrete variables. We describe a new technique for <EM>multivariate</EM>\ndiscretization, whereby each continuous variable is discretized while taking\ninto account its interaction with the other variables. The technique is based\non the use of a Bayesian scoring metric that scores the discretization policy\nfor a continuous variable given a BN structure and the observed data. Since the\nmetric is relative to the BN structure currently being evaluated, the\ndiscretization of a variable needs to be dynamically adjusted as the BN\nstructure changes.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:06:05 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Monti", "Stefano", ""], ["Cooper", "Gregory F.", ""]]}, {"id": "1301.7404", "submitter": "Benson Hin Kwong Ng", "authors": "Benson Hin Kwong Ng, Kam-Fai Wong, Boon-Toh Low", "title": "Resolving Conflicting Arguments under Uncertainties", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-414-421", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed knowledge based applications in open domain rely on common sense\ninformation which is bound to be uncertain and incomplete. To draw the useful\nconclusions from ambiguous data, one must address uncertainties and conflicts\nincurred in a holistic view. No integrated frameworks are viable without an\nin-depth analysis of conflicts incurred by uncertainties. In this paper, we\ngive such an analysis and based on the result, propose an integrated framework.\nOur framework extends definite argumentation theory to model uncertainty. It\nsupports three views over conflicting and uncertain knowledge. Thus, knowledge\nengineers can draw different conclusions depending on the application context\n(i.e. view). We also give an illustrative example on strategical decision\nsupport to show the practical usefulness of our framework.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:06:09 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Ng", "Benson Hin Kwong", ""], ["Wong", "Kam-Fai", ""], ["Low", "Boon-Toh", ""]]}, {"id": "1301.7405", "submitter": "Ron Parr", "authors": "Ron Parr", "title": "Flexible Decomposition Algorithms for Weakly Coupled Markov Decision\n  Problems", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-422-430", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents two new approaches to decomposing and solving large\nMarkov decision problems (MDPs), a partial decoupling method and a complete\ndecoupling method. In these approaches, a large, stochastic decision problem is\ndivided into smaller pieces. The first approach builds a cache of policies for\neach part of the problem independently, and then combines the pieces in a\nseparate, light-weight step. A second approach also divides the problem into\nsmaller pieces, but information is communicated between the different problem\npieces, allowing intelligent decisions to be made about which piece requires\nthe most attention. Both approaches can be used to find optimal policies or\napproximately optimal policies with provable bounds. These algorithms also\nprovide a framework for the efficient transfer of knowledge across problems\nthat share similar structure.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:06:15 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Parr", "Ron", ""]]}, {"id": "1301.7406", "submitter": "David M Pennock", "authors": "David M. Pennock", "title": "Logarithmic Time Parallel Bayesian Inference", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-431-438", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I present a parallel algorithm for exact probabilistic inference in Bayesian\nnetworks. For polytree networks with n variables, the worst-case time\ncomplexity is O(log n) on a CREW PRAM (concurrent-read, exclusive-write\nparallel random-access machine) with n processors, for any constant number of\nevidence variables. For arbitrary networks, the time complexity is O(r^{3w}*log\nn) for n processors, or O(w*log n) for r^{3w}*n processors, where r is the\nmaximum range of any variable, and w is the induced width (the maximum clique\nsize), after moralizing and triangulating the network.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:06:20 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Pennock", "David M.", ""]]}, {"id": "1301.7407", "submitter": "Mark Alan Peot", "authors": "Mark Alan Peot, Ross D. Shachter", "title": "Learning From What You Don't Observe", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-439-446", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The process of diagnosis involves learning about the state of a system from\nvarious observations of symptoms or findings about the system. Sophisticated\nBayesian (and other) algorithms have been developed to revise and maintain\nbeliefs about the system as observations are made. Nonetheless, diagnostic\nmodels have tended to ignore some common sense reasoning exploited by human\ndiagnosticians; In particular, one can learn from which observations have not\nbeen made, in the spirit of conversational implicature. There are two concepts\nthat we describe to extract information from the observations not made. First,\nsome symptoms, if present, are more likely to be reported before others.\nSecond, most human diagnosticians and expert systems are economical in their\ndata-gathering, searching first where they are more likely to find symptoms\npresent. Thus, there is a desirable bias toward reporting symptoms that are\npresent. We develop a simple model for these concepts that can significantly\nimprove diagnostic inference.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:06:25 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Peot", "Mark Alan", ""], ["Shachter", "Ross D.", ""]]}, {"id": "1301.7408", "submitter": "David L Poole", "authors": "David L. Poole", "title": "Context-Specific Approximation in Probabilistic Inference", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-447-454", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is evidence that the numbers in probabilistic inference don't really\nmatter. This paper considers the idea that we can make a probabilistic model\nsimpler by making fewer distinctions. Unfortunately, the level of a Bayesian\nnetwork seems too coarse; it is unlikely that a parent will make little\ndifference for all values of the other parents. In this paper we consider an\napproximation scheme where distinctions can be ignored in some contexts, but\nnot in other contexts. We elaborate on a notion of a parent context that allows\na structured context-specific decomposition of a probability distribution and\nthe associated probabilistic inference scheme called probabilistic partial\nevaluation (Poole 1997). This paper shows a way to simplify a probabilistic\nmodel by ignoring distinctions which have similar probabilities, a method to\nexploit the simpler model, a bound on the resulting errors, and some\npreliminary empirical results on simple networks.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:06:30 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Poole", "David L.", ""]]}, {"id": "1301.7409", "submitter": "Irina Rish", "authors": "Irina Rish, Kalev Kask, Rina Dechter", "title": "Empirical Evaluation of Approximation Algorithms for Probabilistic\n  Decoding", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-455-463", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It was recently shown that the problem of decoding messages transmitted\nthrough a noisy channel can be formulated as a belief updating task over a\nprobabilistic network [McEliece]. Moreover, it was observed that iterative\napplication of the (linear time) Pearl's belief propagation algorithm designed\nfor polytrees outperformed state of the art decoding algorithms, even though\nthe corresponding networks may have many cycles. This paper demonstrates\nempirically that an approximation algorithm approx-mpe for solving the most\nprobable explanation (MPE) problem, developed within the recently proposed\nmini-bucket elimination framework [Dechter96], outperforms iterative belief\npropagation on classes of coding networks that have bounded induced width. Our\nexperiments suggest that approximate MPE decoders can be good competitors to\nthe approximate belief updating decoders.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:06:34 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Rish", "Irina", ""], ["Kask", "Kalev", ""], ["Dechter", "Rina", ""]]}, {"id": "1301.7410", "submitter": "Paola Sebastiani", "authors": "Paola Sebastiani, Marco Ramoni", "title": "Decision Theoretic Foundations of Graphical Model Selection", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-464-471", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a decision theoretic formulation of learning the\ngraphical structure of a Bayesian Belief Network from data. This framework\nsubsumes the standard Bayesian approach of choosing the model with the largest\nposterior probability as the solution of a decision problem with a 0-1 loss\nfunction and allows the use of more general loss functions able to trade-off\nthe complexity of the selected model and the error of choosing an\noversimplified model. A new class of loss functions, called disintegrable, is\nintroduced, to allow the decision problem to match the decomposability of the\ngraphical model. With this class of loss functions, the optimal solution to the\ndecision problem can be found using an efficient bottom-up search strategy.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:06:39 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Sebastiani", "Paola", ""], ["Ramoni", "Marco", ""]]}, {"id": "1301.7412", "submitter": "Ross D. Shachter", "authors": "Ross D. Shachter", "title": "Bayes-Ball: The Rational Pastime (for Determining Irrelevance and\n  Requisite Information in Belief Networks and Influence Diagrams)", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-480-487", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the benefits of belief networks and influence diagrams is that so much\nknowledge is captured in the graphical structure. In particular, statements of\nconditional irrelevance (or independence) can be verified in time linear in the\nsize of the graph. To resolve a particular inference query or decision problem,\nonly some of the possible states and probability distributions must be\nspecified, the \"requisite information.\"\n  This paper presents a new, simple, and efficient \"Bayes-ball\" algorithm which\nis well-suited to both new students of belief networks and state of the art\nimplementations. The Bayes-ball algorithm determines irrelevant sets and\nrequisite information more efficiently than existing methods, and is linear in\nthe size of the graph for belief networks and influence diagrams.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:06:48 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Shachter", "Ross D.", ""]]}, {"id": "1301.7413", "submitter": "Yoram Singer", "authors": "Yoram Singer", "title": "Switching Portfolios", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-488-495", "categories": "q-fin.PM cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A constant rebalanced portfolio is an asset allocation algorithm which keeps\nthe same distribution of wealth among a set of assets along a period of time.\nRecently, there has been work on on-line portfolio selection algorithms which\nare competitive with the best constant rebalanced portfolio determined in\nhindsight. By their nature, these algorithms employ the assumption that high\nreturns can be achieved using a fixed asset allocation strategy. However, stock\nmarkets are far from being stationary and in many cases the wealth achieved by\na constant rebalanced portfolio is much smaller than the wealth achieved by an\nad-hoc investment strategy that adapts to changes in the market. In this paper\nwe present an efficient Bayesian portfolio selection algorithm that is able to\ntrack a changing market. We also describe a simple extension of the algorithm\nfor the case of a general transaction cost, including the transactions cost\nmodels recently investigated by Blum and kalai. We provide a simple analysis of\nthe competitiveness of the algorithm and check its performance on real stock\ndata from the New York Stock Exchange accumulated during a 22-year period.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:06:52 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Singer", "Yoram", ""]]}, {"id": "1301.7414", "submitter": "Milan Studeny", "authors": "Milan Studeny", "title": "Bayesian Networks from the Point of View of Chain Graphs", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-496-503", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AThe paper gives a few arguments in favour of the use of chain graphs for\ndescription of probabilistic conditional independence structures. Every\nBayesian network model can be equivalently introduced by means of a\nfactorization formula with respect to a chain graph which is Markov equivalent\nto the Bayesian network. A graphical characterization of such graphs is given.\nThe class of equivalent graphs can be represented by a distinguished graph\nwhich is called the largest chain graph. The factorization formula with respect\nto the largest chain graph is a basis of a proposal of how to represent the\ncorresponding (discrete) probability distribution in a computer (i.e.\nparametrize it). This way does not depend on the choice of a particular\nBayesian network from the class of equivalent networks and seems to be the most\nefficient way from the point of view of memory demands. A separation criterion\nfor reading independency statements from a chain graph is formulated in a\nsimpler way. It resembles the well-known d-separation criterion for Bayesian\nnetworks and can be implemented locally.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:06:56 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Studeny", "Milan", ""]]}, {"id": "1301.7415", "submitter": "Bo Thiesson", "authors": "Bo Thiesson, Christopher Meek, David Maxwell Chickering, David\n  Heckerman", "title": "Learning Mixtures of DAG Models", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-504-513", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe computationally efficient methods for learning mixtures in which\neach component is a directed acyclic graphical model (mixtures of DAGs or\nMDAGs). We argue that simple search-and-score algorithms are infeasible for a\nvariety of problems, and introduce a feasible approach in which parameter and\nstructure search is interleaved and expected data is treated as real data. Our\napproach can be viewed as a combination of (1) the Cheeseman--Stutz asymptotic\napproximation for model posterior probability and (2) the\nExpectation--Maximization algorithm. We evaluate our procedure for selecting\namong MDAGs on synthetic and real examples.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:07:02 GMT"}, {"version": "v2", "created": "Sat, 16 May 2015 23:27:23 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Thiesson", "Bo", ""], ["Meek", "Christopher", ""], ["Chickering", "David Maxwell", ""], ["Heckerman", "David", ""]]}, {"id": "1301.7416", "submitter": "Nevin Lianwen Zhang", "authors": "Nevin Lianwen Zhang", "title": "Probabilistic Inference in Influence Diagrams", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-514-522", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is about reducing influence diagram (ID) evaluation into Bayesian\nnetwork (BN) inference problems. Such reduction is interesting because it\nenables one to readily use one's favorite BN inference algorithm to efficiently\nevaluate IDs. Two such reduction methods have been proposed previously (Cooper\n1988, Shachter and Peot 1992). This paper proposes a new method. The BN\ninference problems induced by the mew method are much easier to solve than\nthose induced by the two previous methods.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:07:07 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Zhang", "Nevin Lianwen", ""]]}, {"id": "1301.7417", "submitter": "Nevin Lianwen Zhang", "authors": "Nevin Lianwen Zhang, Stephen S. Lee", "title": "Planning with Partially Observable Markov Decision Processes: Advances\n  in Exact Solution Method", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-523-530", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is much interest in using partially observable Markov decision\nprocesses (POMDPs) as a formal model for planning in stochastic domains. This\npaper is concerned with finding optimal policies for POMDPs. We propose several\nimprovements to incremental pruning, presently the most efficient exact\nalgorithm for solving POMDPs.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:07:12 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Zhang", "Nevin Lianwen", ""], ["Lee", "Stephen S.", ""]]}, {"id": "1301.7418", "submitter": "Weixiong Zhang", "authors": "Weixiong Zhang", "title": "Flexible and Approximate Computation through State-Space Reduction", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-531-538", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the real world, insufficient information, limited computation resources,\nand complex problem structures often force an autonomous agent to make a\ndecision in time less than that required to solve the problem at hand\ncompletely. Flexible and approximate computations are two approaches to\ndecision making under limited computation resources. Flexible computation helps\nan agent to flexibly allocate limited computation resources so that the overall\nsystem utility is maximized. Approximate computation enables an agent to find\nthe best satisfactory solution within a deadline. In this paper, we present two\nstate-space reduction methods for flexible and approximate computation:\nquantitative reduction to deal with inaccurate heuristic information, and\nstructural reduction to handle complex problem structures. These two methods\ncan be applied successively to continuously improve solution quality if more\ncomputation is available. Our results show that these reduction methods are\neffective and efficient, finding better solutions with less computation than\nsome existing well-known methods.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:07:19 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Zhang", "Weixiong", ""]]}, {"id": "1301.7673", "submitter": "Nicos Angelopoulos", "authors": "Neng-Fa Zhou and Jonathan Fruhman", "title": "Toward a Dynamic Programming Solution for the 4-peg Tower of Hanoi\n  Problem with Configurations", "comments": "Appeared in CICLOPS 2012. 15 Pages, 2 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Frame-Stewart algorithm for the 4-peg variant of the Tower of Hanoi,\nintroduced in 1941, partitions disks into intermediate towers before moving the\nremaining disks to their destination. Algorithms that partition the disks have\nnot been proven to be optimal, although they have been verified for up to 30\ndisks. This paper presents a dynamic programming approach to this algorithm,\nusing tabling in B-Prolog. This study uses a variation of the problem,\ninvolving configurations of disks, in order to contrast the tabling approach\nwith the approaches utilized by other solvers. A comparison of different\npartitioning locations for the Frame-Stewart algorithm indicates that, although\ncertain partitions are optimal for the classic problem, they need to be\nmodified for certain configurations, and that random configurations might\nrequire an entirely new algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2013 16:37:28 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Zhou", "Neng-Fa", ""], ["Fruhman", "Jonathan", ""]]}, {"id": "1301.7676", "submitter": "Nicos Angelopoulos", "authors": "Anthony Monnet and Roger Villemaire", "title": "Efficient Partial Order CDCL Using Assertion Level Choice Heuristics", "comments": "Appeared in CICLOPS 2012. 15 Pages, 1 Figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We previously designed Partial Order Conflict Driven Clause Learning\n(PO-CDCL), a variation of the satisfiability solving CDCL algorithm with a\npartial order on decision levels, and showed that it can speed up the solving\non problems with a high independence between decision levels. In this paper, we\nmore thoroughly analyze the reasons of the efficiency of PO-CDCL. Of particular\nimportance is that the partial order introduces several candidates for the\nassertion level. By evaluating different heuristics for this choice, we show\nthat the assertion level selection has an important impact on solving and that\na carefully designed heuristic can significantly improve performances on\nrelevant benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2013 16:45:01 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Monnet", "Anthony", ""], ["Villemaire", "Roger", ""]]}]