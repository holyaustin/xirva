[{"id": "1103.0127", "submitter": "Shobha Shankar", "authors": "Shobha Shankar, Dr. T. Ananthapadmanabha", "title": "Fuzzy Approach to Critical Bus Ranking under Normal and Line Outage\n  Contingencies", "comments": "12 pages, 7 figures, CCSIT Conference", "journal-ref": "Advanced Computing, CCSIT Proceedings, Part III, pp. 400-406, Jan\n  2011", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identification of critical or weak buses for a given operating condition is\nan important task in the load dispatch centre. It has become more vital in view\nof the threat of voltage instability leading to voltage collapse. This paper\npresents a fuzzy approach for ranking critical buses in a power system under\nnormal and network contingencies based on Line Flow index and voltage profiles\nat load buses. The Line Flow index determines the maximum load that is possible\nto be connected to a bus in order to maintain stability before the system\nreaches its bifurcation point. Line Flow index (LF index) along with voltage\nprofiles at the load buses are represented in Fuzzy Set notation. Further they\nare evaluated using fuzzy rules to compute Criticality Index. Based on this\nindex, critical buses are ranked. The bus with highest rank is the weakest bus\nas it can withstand a small amount of load before causing voltage collapse. The\nproposed method is tested on Five Bus Test System.\n", "versions": [{"version": "v1", "created": "Tue, 1 Mar 2011 10:35:44 GMT"}], "update_date": "2011-03-02", "authors_parsed": [["Shankar", "Shobha", ""], ["Ananthapadmanabha", "Dr. T.", ""]]}, {"id": "1103.0605", "submitter": "Yusuke Watanabe", "authors": "Yusuke Watanabe and Kenji Fukumizu", "title": "Loopy Belief Propagation, Bethe Free Energy and Graph Zeta Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach to the theoretical analysis of Loopy Belief\nPropagation (LBP) and the Bethe free energy (BFE) by establishing a formula to\nconnect LBP and BFE with a graph zeta function. The proposed approach is\napplicable to a wide class of models including multinomial and Gaussian types.\nThe connection derives a number of new theoretical results on LBP and BFE. This\npaper focuses two of such topics. One is the analysis of the region where the\nHessian of the Bethe free energy is positive definite, which derives the\nnon-convexity of BFE for graphs with multiple cycles, and a condition of\nconvexity on a restricted set. This analysis also gives a new condition for the\nuniqueness of the LBP fixed point. The other result is to clarify the relation\nbetween the local stability of a fixed point of LBP and local minima of the\nBFE, which implies, for example, that a locally stable fixed point of the\nGaussian LBP is a local minimum of the Gaussian Bethe free energy.\n", "versions": [{"version": "v1", "created": "Thu, 3 Mar 2011 04:40:19 GMT"}], "update_date": "2011-03-04", "authors_parsed": [["Watanabe", "Yusuke", ""], ["Fukumizu", "Kenji", ""]]}, {"id": "1103.0632", "submitter": "Hioual Ouassila", "authors": "Hioual Ouassila and Boufaida Zizette", "title": "An Agent Based Architecture (Using Planning) for Dynamic and Semantic\n  Web Services Composition in an EBXML Context", "comments": "22 pages, 11 figures, 1 table", "journal-ref": "International Journal of Database Management Systems ( IJDMS ),\n  Vol.3, No.1, February 2011 110-131", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The process-based semantic composition of Web Services is gaining a\nconsiderable momentum as an approach for the effective integration of\ndistributed, heterogeneous, and autonomous applications. To compose Web\nServices semantically, we need an ontology. There are several ways of inserting\nsemantics in Web Services. One of them consists of using description languages\nlike OWL-S. In this paper, we introduce our work which consists in the\nproposition of a new model and the use of semantic matching technology for\nsemantic and dynamic composition of ebXML business processes.\n", "versions": [{"version": "v1", "created": "Thu, 3 Mar 2011 09:44:06 GMT"}], "update_date": "2015-06-01", "authors_parsed": [["Ouassila", "Hioual", ""], ["Zizette", "Boufaida", ""]]}, {"id": "1103.0697", "submitter": "Adrian Walker", "authors": "Adrian Walker", "title": "A Wiki for Business Rules in Open Vocabulary, Executable English", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of business-IT alignment is of widespread economic concern.\n  As one way of addressing the problem, this paper describes an online system\nthat functions as a kind of Wiki -- one that supports the collaborative writing\nand running of business and scientific applications, as rules in open\nvocabulary, executable English, using a browser.\n  Since the rules are in English, they are indexed by Google and other search\nengines. This is useful when looking for rules for a task that one has in mind.\n  The design of the system integrates the semantics of data, with a semantics\nof an inference method, and also with the meanings of English sentences. As\nsuch, the system has functionality that may be useful for the Rules, Logic,\nProof and Trust requirements of the Semantic Web.\n  The system accepts rules, and small numbers of facts, typed or copy-pasted\ndirectly into a browser. One can then run the rules, again using a browser. For\nlarger amounts of data, the system uses information in the rules to\nautomatically generate and run SQL over networked databases. From a few highly\ndeclarative rules, the system typically generates SQL that would be too\ncomplicated to write reliably by hand. However, the system can explain its\nresults in step-by-step hypertexted English, at the business or scientific\nlevel\n  As befits a Wiki, shared use of the system is free.\n", "versions": [{"version": "v1", "created": "Thu, 3 Mar 2011 14:31:32 GMT"}], "update_date": "2011-03-04", "authors_parsed": [["Walker", "Adrian", ""]]}, {"id": "1103.1003", "submitter": "Eray Ozkural", "authors": "Eray \\\"Ozkural", "title": "Teraflop-scale Incremental Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a long-term memory design for artificial general intelligence\nbased on Solomonoff's incremental machine learning methods. We use R5RS Scheme\nand its standard library with a few omissions as the reference machine. We\nintroduce a Levin Search variant based on Stochastic Context Free Grammar\ntogether with four synergistic update algorithms that use the same grammar as a\nguiding probability distribution of programs. The update algorithms include\nadjusting production probabilities, re-using previous solutions, learning\nprogramming idioms and discovery of frequent subprograms. Experiments with two\ntraining sequences demonstrate that our approach to incremental learning is\neffective.\n", "versions": [{"version": "v1", "created": "Sat, 5 Mar 2011 03:41:30 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["\u00d6zkural", "Eray", ""]]}, {"id": "1103.1156", "submitter": "Farnood Merrikh-Bayat", "authors": "Farnood Merrikh-Bayat and Saeed Bagheri-Shouraki", "title": "Efficient neuro-fuzzy system and its Memristor Crossbar-based Hardware\n  Implementation", "comments": "34 pages, 14 figures, Submitted to IEEE Transactions on Fuzzy Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a novel neuro-fuzzy system is proposed where its learning is\nbased on the creation of fuzzy relations by using new implication method\nwithout utilizing any exact mathematical techniques. Then, a simple memristor\ncrossbar-based analog circuit is designed to implement this neuro-fuzzy system\nwhich offers very interesting properties. In addition to high connectivity\nbetween neurons and being fault-tolerant, all synaptic weights in our proposed\nmethod are always non-negative and there is no need to precisely adjust them.\nFinally, this structure is hierarchically expandable and can compute operations\nin real time since it is implemented through analog circuits. Simulation\nresults show the efficiency and applicability of our neuro-fuzzy computing\nsystem. They also indicate that this system can be a good candidate to be used\nfor creating artificial brain.\n", "versions": [{"version": "v1", "created": "Sun, 6 Mar 2011 18:52:05 GMT"}], "update_date": "2011-03-08", "authors_parsed": [["Merrikh-Bayat", "Farnood", ""], ["Bagheri-Shouraki", "Saeed", ""]]}, {"id": "1103.1157", "submitter": "Nicola Di Mauro", "authors": "Nicola Di Mauro, Teresa M.A. Basile, Stefano Ferilli, Floriana\n  Esposito", "title": "GRASP and path-relinking for Coalition Structure Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Artificial Intelligence with Coalition Structure Generation (CSG) one\nrefers to those cooperative complex problems that require to find an optimal\npartition, maximising a social welfare, of a set of entities involved in a\nsystem into exhaustive and disjoint coalitions. The solution of the CSG problem\nfinds applications in many fields such as Machine Learning (covering machines,\nclustering), Data Mining (decision tree, discretization), Graph Theory, Natural\nLanguage Processing (aggregation), Semantic Web (service composition), and\nBioinformatics. The problem of finding the optimal coalition structure is\nNP-complete. In this paper we present a greedy adaptive search procedure\n(GRASP) with path-relinking to efficiently search the space of coalition\nstructures. Experiments and comparisons to other algorithms prove the validity\nof the proposed method in solving this hard combinatorial problem.\n", "versions": [{"version": "v1", "created": "Sun, 6 Mar 2011 18:54:04 GMT"}, {"version": "v2", "created": "Wed, 9 Mar 2011 10:55:28 GMT"}], "update_date": "2011-03-10", "authors_parsed": [["Di Mauro", "Nicola", ""], ["Basile", "Teresa M. A.", ""], ["Ferilli", "Stefano", ""], ["Esposito", "Floriana", ""]]}, {"id": "1103.1205", "submitter": "Minal Tomar", "authors": "Minal Tomar and Pratibha Singh", "title": "A Directional Feature with Energy based Offline Signature Verification\n  Network", "comments": "10 pages, 6 figures", "journal-ref": "International Journal on Soft Computing ( IJSC ), Vol.2, No.1,\n  February 2011", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signature used as a biometric is implemented in various systems as well as\nevery signature signed by each person is distinct at the same time. So, it is\nvery important to have a computerized signature verification system. In offline\nsignature verification system dynamic features are not available obviously, but\none can use a signature as an image and apply image processing techniques to\nmake an effective offline signature verification system. Author proposes a\nintelligent network used directional feature and energy density both as inputs\nto the same network and classifies the signature. Neural network is used as a\nclassifier for this system. The results are compared with both the very basic\nenergy density method and a simple directional feature method of offline\nsignature verification system and this proposed new network is found very\neffective as compared to the above two methods, specially for less number of\ntraining samples, which can be implemented practically.\n", "versions": [{"version": "v1", "created": "Mon, 7 Mar 2011 07:17:13 GMT"}], "update_date": "2011-03-08", "authors_parsed": [["Tomar", "Minal", ""], ["Singh", "Pratibha", ""]]}, {"id": "1103.1252", "submitter": "Emilio Ferrara", "authors": "Emilio Ferrara and Robert Baumgartner", "title": "Automatic Wrapper Adaptation by Tree Edit Distance Matching", "comments": "7 pages, 3 figures, In Proceedings of the 2nd International Workshop\n  on Combinations of Intelligent Methods and Applications (CIMA 2010)", "journal-ref": "Combinations of Intelligent Methods and Applications Smart\n  Innovation, Systems and Technologies Volume 8, 2011, pp 41-54", "doi": "10.1007/978-3-642-19618-8_3", "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information distributed through the Web keeps growing faster day by day, and\nfor this reason, several techniques for extracting Web data have been suggested\nduring last years. Often, extraction tasks are performed through so called\nwrappers, procedures extracting information from Web pages, e.g. implementing\nlogic-based techniques. Many fields of application today require a strong\ndegree of robustness of wrappers, in order not to compromise assets of\ninformation or reliability of data extracted. Unfortunately, wrappers may fail\nin the task of extracting data from a Web page, if its structure changes,\nsometimes even slightly, thus requiring the exploiting of new techniques to be\nautomatically held so as to adapt the wrapper to the new structure of the page,\nin case of failure. In this work we present a novel approach of automatic\nwrapper adaptation based on the measurement of similarity of trees through\nimproved tree edit distance matching techniques.\n", "versions": [{"version": "v1", "created": "Mon, 7 Mar 2011 11:27:30 GMT"}], "update_date": "2013-06-06", "authors_parsed": [["Ferrara", "Emilio", ""], ["Baumgartner", "Robert", ""]]}, {"id": "1103.1254", "submitter": "Emilio Ferrara", "authors": "Emilio Ferrara and Robert Baumgartner", "title": "Design of Automatically Adaptable Web Wrappers", "comments": "7 pages, 2 figures, In Proceedings of the 3rd International\n  Conference on Agents and Artificial Intelligence (ICAART 2011)", "journal-ref": "Proceedings of the 3rd International Conference on Agents and\n  Artificial Intelligence, pp 211-216, 2011", "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the huge amount of information distributed through the Web\nmotivates studying techniques to be adopted in order to extract relevant data\nin an efficient and reliable way. Both academia and enterprises developed\nseveral approaches of Web data extraction, for example using techniques of\nartificial intelligence or machine learning. Some commonly adopted procedures,\nnamely wrappers, ensure a high degree of precision of information extracted\nfrom Web pages, and, at the same time, have to prove robustness in order not to\ncompromise quality and reliability of data themselves. In this paper we focus\non some experimental aspects related to the robustness of the data extraction\nprocess and the possibility of automatically adapting wrappers. We discuss the\nimplementation of algorithms for finding similarities between two different\nversion of a Web page, in order to handle modifications, avoiding the failure\nof data extraction tasks and ensuring reliability of information extracted. Our\npurpose is to evaluate performances, advantages and draw-backs of our novel\nsystem of automatic wrapper adaptation.\n", "versions": [{"version": "v1", "created": "Mon, 7 Mar 2011 11:41:25 GMT"}], "update_date": "2013-06-06", "authors_parsed": [["Ferrara", "Emilio", ""], ["Baumgartner", "Robert", ""]]}, {"id": "1103.1516", "submitter": "Pierre Lopez", "authors": "Asma Lahimer (LAAS), Pierre Lopez (LAAS), Mohamed Haouari", "title": "Climbing depth-bounded adjacent discrepancy search for solving hybrid\n  flow shop scheduling problems with multiprocessor tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers multiprocessor task scheduling in a multistage hybrid\nflow-shop environment. The problem even in its simplest form is NP-hard in the\nstrong sense. The great deal of interest for this problem, besides its\ntheoretical complexity, is animated by needs of various manufacturing and\ncomputing systems. We propose a new approach based on limited discrepancy\nsearch to solve the problem. Our method is tested with reference to a proposed\nlower bound as well as the best-known solutions in literature. Computational\nresults show that the developed approach is efficient in particular for\nlarge-size problems.\n", "versions": [{"version": "v1", "created": "Tue, 8 Mar 2011 12:57:29 GMT"}], "update_date": "2011-03-09", "authors_parsed": [["Lahimer", "Asma", "", "LAAS"], ["Lopez", "Pierre", "", "LAAS"], ["Haouari", "Mohamed", ""]]}, {"id": "1103.1530", "submitter": "Mark Levene", "authors": "Trevor Fenner, Mark Levene, and George Loizou", "title": "A Discrete Evolutionary Model for Chess Players' Ratings", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Elo system for rating chess players, also used in other games and sports,\nwas adopted by the World Chess Federation over four decades ago. Although not\nwithout controversy, it is accepted as generally reliable and provides a method\nfor assessing players' strengths and ranking them in official tournaments.\n  It is generally accepted that the distribution of players' rating data is\napproximately normal but, to date, no stochastic model of how the distribution\nmight have arisen has been proposed. We propose such an evolutionary stochastic\nmodel, which models the arrival of players into the rating pool, the games they\nplay against each other, and how the results of these games affect their\nratings. Using a continuous approximation to the discrete model, we derive the\ndistribution for players' ratings at time $t$ as a normal distribution, where\nthe variance increases in time as a logarithmic function of $t$. We validate\nthe model using published rating data from 2007 to 2010, showing that the\nparameters obtained from the data can be recovered through simulations of the\nstochastic model.\n  The distribution of players' ratings is only approximately normal and has\nbeen shown to have a small negative skew. We show how to modify our\nevolutionary stochastic model to take this skewness into account, and we\nvalidate the modified model using the published official rating data.\n", "versions": [{"version": "v1", "created": "Tue, 8 Mar 2011 13:51:46 GMT"}, {"version": "v2", "created": "Wed, 30 Mar 2011 07:45:53 GMT"}], "update_date": "2011-03-31", "authors_parsed": [["Fenner", "Trevor", ""], ["Levene", "Mark", ""], ["Loizou", "George", ""]]}, {"id": "1103.1542", "submitter": "P\\'aid\\'i Creed", "authors": "David A. Cohen, Martin C. Cooper, P\\'aid\\'i Creed, Andr\\'as Z. Salamon", "title": "The tractability of CSP classes defined by forbidden patterns", "comments": null, "journal-ref": "Journal Of Artificial Intelligence Research, Volume 45, pages\n  47-78, 2012", "doi": "10.1613/jair.3651", "report-no": null, "categories": "cs.AI cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The constraint satisfaction problem (CSP) is a general problem central to\ncomputer science and artificial intelligence. Although the CSP is NP-hard in\ngeneral, considerable effort has been spent on identifying tractable\nsubclasses. The main two approaches consider structural properties\n(restrictions on the hypergraph of constraint scopes) and relational properties\n(restrictions on the language of constraint relations). Recently, some authors\nhave considered hybrid properties that restrict the constraint hypergraph and\nthe relations simultaneously.\n  Our key contribution is the novel concept of a CSP pattern and classes of\nproblems defined by forbidden patterns (which can be viewed as forbidding\ngeneric subproblems). We describe the theoretical framework which can be used\nto reason about classes of problems defined by forbidden patterns. We show that\nthis framework generalises relational properties and allows us to capture known\nhybrid tractable classes.\n  Although we are not close to obtaining a dichotomy concerning the\ntractability of general forbidden patterns, we are able to make some progress\nin a special case: classes of problems that arise when we can only forbid\nbinary negative patterns (generic subproblems in which only inconsistent tuples\nare specified). In this case we are able to characterise very large classes of\ntractable and NP-hard forbidden patterns. This leaves the complexity of just\none case unresolved and we conjecture that this last case is tractable.\n", "versions": [{"version": "v1", "created": "Tue, 8 Mar 2011 14:43:17 GMT"}, {"version": "v2", "created": "Tue, 8 Jul 2014 17:38:33 GMT"}], "update_date": "2014-07-09", "authors_parsed": [["Cohen", "David A.", ""], ["Cooper", "Martin C.", ""], ["Creed", "P\u00e1id\u00ed", ""], ["Salamon", "Andr\u00e1s Z.", ""]]}, {"id": "1103.1604", "submitter": "Georg Gottlob", "authors": "Georg Gottlob", "title": "On Minimal Constraint Networks", "comments": "Preprint - to appear in Artificial Intelligence. (Full version of the\n  CP'2011 paper with same title)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a minimal binary constraint network, every tuple of a constraint relation\ncan be extended to a solution. The tractability or intractability of computing\na solution to such a minimal network was a long standing open question. Dechter\nconjectured this computation problem to be NP-hard. We prove this conjecture.\nWe also prove a conjecture by Dechter and Pearl stating that for k\\geq2 it is\nNP-hard to decide whether a single constraint can be decomposed into an\nequivalent k-ary constraint network. We show that this holds even in case of\nbi-valued constraints where k\\geq3, which proves another conjecture of Dechter\nand Pearl. Finally, we establish the tractability frontier for this problem\nwith respect to the domain cardinality and the parameter k.\n", "versions": [{"version": "v1", "created": "Tue, 8 Mar 2011 19:02:33 GMT"}, {"version": "v2", "created": "Mon, 25 Apr 2011 23:04:43 GMT"}, {"version": "v3", "created": "Wed, 27 Apr 2011 10:00:57 GMT"}, {"version": "v4", "created": "Mon, 20 Jun 2011 15:15:25 GMT"}, {"version": "v5", "created": "Sat, 12 May 2012 00:10:11 GMT"}, {"version": "v6", "created": "Wed, 25 Jul 2012 13:48:03 GMT"}], "update_date": "2012-07-26", "authors_parsed": [["Gottlob", "Georg", ""]]}, {"id": "1103.1711", "submitter": "D. Bryce", "authors": "D. Bryce, S. Kambhampati, D. E. Smith", "title": "Planning Graph Heuristics for Belief Space Search", "comments": null, "journal-ref": "Journal Of Artificial Intelligence Research, Volume 26, pages\n  35-99, 2006", "doi": "10.1613/jair.1869", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some recent works in conditional planning have proposed reachability\nheuristics to improve planner scalability, but many lack a formal description\nof the properties of their distance estimates. To place previous work in\ncontext and extend work on heuristics for conditional planning, we provide a\nformal basis for distance estimates between belief states. We give a definition\nfor the distance between belief states that relies on aggregating underlying\nstate distance measures. We give several techniques to aggregate state\ndistances and their associated properties. Many existing heuristics exhibit a\nsubset of the properties, but in order to provide a standardized comparison we\npresent several generalizations of planning graph heuristics that are used in a\nsingle planner. We compliment our belief state distance estimate framework by\nalso investigating efficient planning graph data structures that incorporate\nBDDs to compute the most effective heuristics.\n  We developed two planners to serve as test-beds for our investigation. The\nfirst, CAltAlt, is a conformant regression planner that uses A* search. The\nsecond, POND, is a conditional progression planner that uses AO* search. We\nshow the relative effectiveness of our heuristic techniques within these\nplanners. We also compare the performance of these planners with several state\nof the art approaches in conditional planning.\n", "versions": [{"version": "v1", "created": "Wed, 9 Mar 2011 06:43:55 GMT"}], "update_date": "2011-05-13", "authors_parsed": [["Bryce", "D.", ""], ["Kambhampati", "S.", ""], ["Smith", "D. E.", ""]]}, {"id": "1103.1791", "submitter": "Chris Adami", "authors": "Jeffrey Edlund, Nicolas Chaumont, Arend Hintze, Christof Koch, Giulio\n  Tononi, and Christoph Adami", "title": "Integrated information increases with fitness in the evolution of\n  animats", "comments": "27 pages, 8 figures, one supplementary figure. Three supplementary\n  video files available on request. Version commensurate with published text in\n  PLoS Comput. Biol", "journal-ref": "PLoS Computational Biology 7 (2001) e1002236", "doi": "10.1371/journal.pcbi.1002236", "report-no": null, "categories": "q-bio.PE cs.AI nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the hallmarks of biological organisms is their ability to integrate\ndisparate information sources to optimize their behavior in complex\nenvironments. How this capability can be quantified and related to the\nfunctional complexity of an organism remains a challenging problem, in\nparticular since organismal functional complexity is not well-defined. We\npresent here several candidate measures that quantify information and\nintegration, and study their dependence on fitness as an artificial agent\n(\"animat\") evolves over thousands of generations to solve a navigation task in\na simple, simulated environment. We compare the ability of these measures to\npredict high fitness with more conventional information-theoretic processing\nmeasures. As the animat adapts by increasing its \"fit\" to the world,\ninformation integration and processing increase commensurately along the\nevolutionary line of descent. We suggest that the correlation of fitness with\ninformation integration and with processing measures implies that high fitness\nrequires both information processing as well as integration, but that\ninformation integration may be a better measure when the task requires memory.\nA correlation of measures of information integration (but also information\nprocessing) and fitness strongly suggests that these measures reflect the\nfunctional complexity of the animat, and that such measures can be used to\nquantify functional complexity even in the absence of fitness data.\n", "versions": [{"version": "v1", "created": "Wed, 9 Mar 2011 14:33:21 GMT"}, {"version": "v2", "created": "Mon, 3 Oct 2011 16:59:02 GMT"}], "update_date": "2011-11-08", "authors_parsed": [["Edlund", "Jeffrey", ""], ["Chaumont", "Nicolas", ""], ["Hintze", "Arend", ""], ["Koch", "Christof", ""], ["Tononi", "Giulio", ""], ["Adami", "Christoph", ""]]}, {"id": "1103.2091", "submitter": "Tejbanta Singh Chingtham Mr", "authors": "Tejbanta Singh Chingtham, G. Sahoo and M.K. Ghose", "title": "An Artificial Immune System Model for Multi-Agents Resource Sharing in\n  Distributed Environments", "comments": null, "journal-ref": "International Journal on Computer Science and Engineering (IJCSE),\n  Vol. 02, No. 05, 2010, pp 1813-1818", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural Immune system plays a vital role in the survival of the all living\nbeing. It provides a mechanism to defend itself from external predates making\nit consistent systems, capable of adapting itself for survival incase of\nchanges. The human immune system has motivated scientists and engineers for\nfinding powerful information processing algorithms that has solved complex\nengineering tasks. This paper explores one of the various possibilities for\nsolving problem in a Multiagent scenario wherein multiple robots are deployed\nto achieve a goal collectively. The final goal is dependent on the performance\nof individual robot and its survival without having to lose its energy beyond a\npredetermined threshold value by deploying an evolutionary computational\ntechnique otherwise called the artificial immune system that imitates the\nbiological immune system.\n", "versions": [{"version": "v1", "created": "Thu, 24 Feb 2011 09:12:17 GMT"}], "update_date": "2011-03-11", "authors_parsed": [["Chingtham", "Tejbanta Singh", ""], ["Sahoo", "G.", ""], ["Ghose", "M. K.", ""]]}, {"id": "1103.2110", "submitter": "Martin Aruldoss Mr", "authors": "A.Martin, V.Gayathri, G.Saranya, P.Gayathri, Prasanna Venkatesan", "title": "A hybrid model for bankruptcy prediction using genetic algorithm, fuzzy\n  c-means and mars", "comments": "Bankruptcy prediction, financial ratio models, Genetic Algorithm,\n  Fuzzy c-means Clustering, MARS", "journal-ref": "International Journal on Soft Computing (IJSC), Vol.2, No.1,\n  February 2011", "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bankruptcy prediction is very important for all the organization since it\naffects the economy and rise many social problems with high costs. There are\nlarge number of techniques have been developed to predict the bankruptcy, which\nhelps the decision makers such as investors and financial analysts. One of the\nbankruptcy prediction models is the hybrid model using Fuzzy C-means clustering\nand MARS, which uses static ratios taken from the bank financial statements for\nprediction, which has its own theoretical advantages. The performance of\nexisting bankruptcy model can be improved by selecting the best features\ndynamically depend on the nature of the firm. This dynamic selection can be\naccomplished by Genetic Algorithm and it improves the performance of prediction\nmodel.\n", "versions": [{"version": "v1", "created": "Tue, 1 Mar 2011 09:57:25 GMT"}], "update_date": "2011-03-11", "authors_parsed": [["Martin", "A.", ""], ["Gayathri", "V.", ""], ["Saranya", "G.", ""], ["Gayathri", "P.", ""], ["Venkatesan", "Prasanna", ""]]}, {"id": "1103.2325", "submitter": "Tsvi Tlusty", "authors": "David Levary, Jean-Pierre Eckmann, Elisha Moses and Tsvi Tlusty", "title": "Self reference in word definitions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dictionaries are inherently circular in nature. A given word is linked to a\nset of alternative words (the definition) which in turn point to further\ndescendants. Iterating through definitions in this way, one typically finds\nthat definitions loop back upon themselves. The graph formed by such\ndefinitional relations is our object of study. By eliminating those links which\nare not in loops, we arrive at a core subgraph of highly connected nodes.\n  We observe that definitional loops are conveniently classified by length,\nwith longer loops usually emerging from semantic misinterpretation. By breaking\nthe long loops in the graph of the dictionary, we arrive at a set of\ndisconnected clusters. We find that the words in these clusters constitute\nsemantic units, and moreover tend to have been introduced into the English\nlanguage at similar times, suggesting a possible mechanism for language\nevolution.\n", "versions": [{"version": "v1", "created": "Fri, 11 Mar 2011 17:57:16 GMT"}], "update_date": "2011-03-14", "authors_parsed": [["Levary", "David", ""], ["Eckmann", "Jean-Pierre", ""], ["Moses", "Elisha", ""], ["Tlusty", "Tsvi", ""]]}, {"id": "1103.2342", "submitter": "Tiago Silva", "authors": "Tiago Silva and In\\^es Dutra", "title": "SPPAM - Statistical PreProcessing AlgorithM", "comments": "Submited to IJCAI11 conference on January 25, 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most machine learning tools work with a single table where each row is an\ninstance and each column is an attribute. Each cell of the table contains an\nattribute value for an instance. This representation prevents one important\nform of learning, which is, classification based on groups of correlated\nrecords, such as multiple exams of a single patient, internet customer\npreferences, weather forecast or prediction of sea conditions for a given day.\nTo some extent, relational learning methods, such as inductive logic\nprogramming, can capture this correlation through the use of intensional\npredicates added to the background knowledge. In this work, we propose SPPAM,\nan algorithm that aggregates past observations in one single record. We show\nthat applying SPPAM to the original correlated data, before the learning task,\ncan produce classifiers that are better than the ones trained using all\nrecords.\n", "versions": [{"version": "v1", "created": "Fri, 11 Mar 2011 18:58:40 GMT"}], "update_date": "2011-03-14", "authors_parsed": [["Silva", "Tiago", ""], ["Dutra", "In\u00eas", ""]]}, {"id": "1103.2376", "submitter": "Leonid Perlovsky", "authors": "Leonid Perlovsky (Harvard University and the AFRL)", "title": "Language, Emotions, and Cultures: Emotional Sapir-Whorf Hypothesis", "comments": "16p, 2 figs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An emotional version of Sapir-Whorf hypothesis suggests that differences in\nlanguage emotionalities influence differences among cultures no less than\nconceptual differences. Conceptual contents of languages and cultures to\nsignificant extent are determined by words and their semantic differences;\nthese could be borrowed among languages and exchanged among cultures. Emotional\ndifferences, as suggested in the paper, are related to grammar and mostly\ncannot be borrowed. Conceptual and emotional mechanisms of languages are\nconsidered here along with their functions in the mind and cultural evolution.\nA fundamental contradiction in human mind is considered: language evolution\nrequires reduced emotionality, but \"too low\" emotionality makes language\n\"irrelevant to life,\" disconnected from sensory-motor experience. Neural\nmechanisms of these processes are suggested as well as their mathematical\nmodels: the knowledge instinct, the language instinct, the dual model\nconnecting language and cognition, dynamic logic, neural modeling fields.\nMathematical results are related to cognitive science, linguistics, and\npsychology. Experimental evidence and theoretical arguments are discussed.\nApproximate equations for evolution of human minds and cultures are obtained.\nTheir solutions identify three types of cultures: \"conceptual\"-pragmatic\ncultures, in which emotionality of language is reduced and differentiation\novertakes synthesis resulting in fast evolution at the price of uncertainty of\nvalues, self doubts, and internal crises; \"traditional-emotional\" cultures\nwhere differentiation lags behind synthesis, resulting in cultural stability at\nthe price of stagnation; and \"multi-cultural\" societies combining fast cultural\nevolution and stability. Unsolved problems and future theoretical and\nexperimental directions are discussed.\n", "versions": [{"version": "v1", "created": "Fri, 11 Mar 2011 21:13:38 GMT"}], "update_date": "2011-03-15", "authors_parsed": [["Perlovsky", "Leonid", "", "Harvard University and the AFRL"]]}, {"id": "1103.3123", "submitter": "Yong Lai", "authors": "Yong Lai, Dayou Liu, Shengsheng Wang", "title": "Reduced Ordered Binary Decision Diagram with Implied Literals: A New\n  knowledge Compilation Approach", "comments": "18 pages, 13 figures", "journal-ref": null, "doi": "10.1007/s10115-012-0525-6", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge compilation is an approach to tackle the computational\nintractability of general reasoning problems. According to this approach,\nknowledge bases are converted off-line into a target compilation language which\nis tractable for on-line querying. Reduced ordered binary decision diagram\n(ROBDD) is one of the most influential target languages. We generalize ROBDD by\nassociating some implied literals in each node and the new language is called\nreduced ordered binary decision diagram with implied literals (ROBDD-L). Then\nwe discuss a kind of subsets of ROBDD-L called ROBDD-i with precisely i implied\nliterals (0 \\leq i \\leq \\infty). In particular, ROBDD-0 is isomorphic to ROBDD;\nROBDD-\\infty requires that each node should be associated by the implied\nliterals as many as possible. We show that ROBDD-i has uniqueness over some\nspecific variables order, and ROBDD-\\infty is the most succinct subset in\nROBDD-L and can meet most of the querying requirements involved in the\nknowledge compilation map. Finally, we propose an ROBDD-i compilation algorithm\nfor any i and a ROBDD-\\infty compilation algorithm. Based on them, we implement\na ROBDD-L package called BDDjLu and then get some conclusions from preliminary\nexperimental results: ROBDD-\\infty is obviously smaller than ROBDD for all\nbenchmarks; ROBDD-\\infty is smaller than the d-DNNF the benchmarks whose\ncompilation results are relatively small; it seems that it is better to\ntransform ROBDDs-\\infty into FBDDs and ROBDDs rather than straight compile the\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Mar 2011 08:12:05 GMT"}, {"version": "v2", "created": "Thu, 24 Mar 2011 04:23:05 GMT"}], "update_date": "2013-05-14", "authors_parsed": [["Lai", "Yong", ""], ["Liu", "Dayou", ""], ["Wang", "Shengsheng", ""]]}, {"id": "1103.3223", "submitter": "Piero Giacomelli", "authors": "Piero Giacomelli, Giulia Munaro and Roberto Rosso", "title": "Using Soft Computer Techniques on Smart Devices for Monitoring Chronic\n  Diseases: the CHRONIOUS case", "comments": "presented at \"The Third International Conference on eHealth,\n  Telemedicine, and Social Medicine (eTELEMED 2011)\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CHRONIOUS is an Open, Ubiquitous and Adaptive Chronic Disease Management\nPlatform for Chronic Obstructive Pulmonary Disease(COPD) Chronic Kidney Disease\n(CKD) and Renal Insufficiency. It consists of several modules: an ontology\nbased literature search engine, a rule based decision support system, remote\nsensors interacting with lifestyle interfaces (PDA, monitor touchscreen) and a\nmachine learning module. All these modules interact each other to allow the\nmonitoring of two types of chronic diseases and to help clinician in taking\ndecision for cure purpose. This paper illustrates how some machine learning\nalgorithms and a rule based decision support system can be used in smart\ndevices, to monitor chronic patient. We will analyse how a set of machine\nlearning algorithms can be used in smart devices to alert the clinician in case\nof a patient health condition worsening trend.\n", "versions": [{"version": "v1", "created": "Wed, 16 Mar 2011 16:28:00 GMT"}], "update_date": "2011-03-17", "authors_parsed": [["Giacomelli", "Piero", ""], ["Munaro", "Giulia", ""], ["Rosso", "Roberto", ""]]}, {"id": "1103.3240", "submitter": "Ken Duffy", "authors": "K. R. Duffy and C. Bordenave and D. J. Leith", "title": "Decentralized Constraint Satisfaction", "comments": null, "journal-ref": "IEEE/ACM Transactions on Networking, 21 (4), 1298-1308, 2013", "doi": "10.1109/TNET.2012.2222923", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that several important resource allocation problems in wireless\nnetworks fit within the common framework of Constraint Satisfaction Problems\n(CSPs). Inspired by the requirements of these applications, where variables are\nlocated at distinct network devices that may not be able to communicate but may\ninterfere, we define natural criteria that a CSP solver must possess in order\nto be practical. We term these algorithms decentralized CSP solvers. The best\nknown CSP solvers were designed for centralized problems and do not meet these\ncriteria. We introduce a stochastic decentralized CSP solver and prove that it\nwill find a solution in almost surely finite time, should one exist, also\nshowing it has many practically desirable properties. We benchmark the\nalgorithm's performance on a well-studied class of CSPs, random k-SAT,\nillustrating that the time the algorithm takes to find a satisfying assignment\nis competitive with stochastic centralized solvers on problems with order a\nthousand variables despite its decentralized nature. We demonstrate the\nsolver's practical utility for the problems that motivated its introduction by\nusing it to find a non-interfering channel allocation for a network formed from\ndata from downtown Manhattan.\n", "versions": [{"version": "v1", "created": "Wed, 2 Mar 2011 15:00:09 GMT"}, {"version": "v2", "created": "Mon, 25 Jul 2011 14:44:16 GMT"}, {"version": "v3", "created": "Wed, 7 Sep 2011 11:00:47 GMT"}, {"version": "v4", "created": "Tue, 9 Oct 2012 07:46:22 GMT"}], "update_date": "2013-09-19", "authors_parsed": [["Duffy", "K. R.", ""], ["Bordenave", "C.", ""], ["Leith", "D. J.", ""]]}, {"id": "1103.3417", "submitter": "Andreas Baldi", "authors": "Hazim A. Farhan, Hussein H. Owaied, Suhaib I. Al-Ghazi", "title": "Finding Shortest Path for Developed Cognitive Map Using Medial Axis", "comments": "9 pages", "journal-ref": "World of Computer Science and Information Technology Journal\n  (WCSIT), ISSN: 2221-0741, Vol. 1, No. 2, 17-25, 2011", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  this paper presents an enhancement of the medial axis algorithm to be used\nfor finding the optimal shortest path for developed cognitive map. The\ncognitive map has been developed, based on the architectural blueprint maps.\nThe idea for using the medial-axis is to find main path central pixels; each\ncenter pixel represents the center distance between two side boarder pixels.\nThe need for these pixels in the algorithm comes from the need of building a\nnetwork of nodes for the path, where each node represents a turning in the real\nworld (left, right, critical left, critical right...). The algorithm also\nignores from finding the center pixels paths that are too small for intelligent\nrobot navigation. The Idea of this algorithm is to find the possible shortest\npath between start and end points. The goal of this research is to extract a\nsimple, robust representation of the shape of the cognitive map together with\nthe optimal shortest path between start and end points. The intelligent robot\nwill use this algorithm in order to decrease the time that is needed for\nsweeping the targeted building.\n", "versions": [{"version": "v1", "created": "Thu, 17 Mar 2011 14:02:50 GMT"}], "update_date": "2011-03-18", "authors_parsed": [["Farhan", "Hazim A.", ""], ["Owaied", "Hussein H.", ""], ["Al-Ghazi", "Suhaib I.", ""]]}, {"id": "1103.3420", "submitter": "Sofiene Haboubi", "authors": "Sofiene Haboubi and Samia Maddouri", "title": "Extraction of handwritten areas from colored image of bank checks by an\n  hybrid method", "comments": "International Conference on Machine Intelligence (ACIDCA-ICIM),\n  Tozeur, Tunisia, November 2005", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  One of the first step in the realization of an automatic system of check\nrecognition is the extraction of the handwritten area. We propose in this paper\nan hybrid method to extract these areas. This method is based on digit\nrecognition by Fourier descriptors and different steps of colored image\nprocessing . It requires the bank recognition of its code which is located in\nthe check marking band as well as the handwritten color recognition by the\nmethod of difference of histograms. The areas extraction is then carried out by\nthe use of some mathematical morphology tools.\n", "versions": [{"version": "v1", "created": "Thu, 17 Mar 2011 14:13:36 GMT"}], "update_date": "2011-03-18", "authors_parsed": [["Haboubi", "Sofiene", ""], ["Maddouri", "Samia", ""]]}, {"id": "1103.3430", "submitter": "Sofiene Haboubi", "authors": "Sofiene Haboubi, Samia Maddouri and Hamid Amiri", "title": "Identification of arabic word from bilingual text using character\n  features", "comments": "FAHR 2010 - the 1st International Workshop on Frontiers in Arabic\n  Handwriting Recognition", "journal-ref": "International Workshop on Frontiers in Arabic Handwriting\n  Recognition (2010) 50-54", "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  The identification of the language of the script is an important stage in the\nprocess of recognition of the writing. There are several works in this research\narea, which treat various languages. Most of the used methods are global or\nstatistical. In this present paper, we study the possibility of using the\nfeatures of scripts to identify the language. The identification of the\nlanguage of the script by characteristics returns the identification in the\ncase of multilingual documents less difficult. We present by this work, a study\non the possibility of using the structural features to identify the Arabic\nlanguage from an Arabic / Latin text.\n", "versions": [{"version": "v1", "created": "Thu, 17 Mar 2011 14:59:33 GMT"}], "update_date": "2012-04-05", "authors_parsed": [["Haboubi", "Sofiene", ""], ["Maddouri", "Samia", ""], ["Amiri", "Hamid", ""]]}, {"id": "1103.3687", "submitter": "Subbarao Kambhampati", "authors": "William Cushing and J. Benton and Subbarao Kambhampati", "title": "Cost Based Satisficing Search Considered Harmful", "comments": "Longer version of an extended abstract from SOCS 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, several researchers have found that cost-based satisficing search\nwith A* often runs into problems. Although some \"work arounds\" have been\nproposed to ameliorate the problem, there has not been any concerted effort to\npinpoint its origin. In this paper, we argue that the origins can be traced\nback to the wide variance in action costs that is observed in most planning\ndomains. We show that such cost variance misleads A* search, and that this is\nno trifling detail or accidental phenomenon, but a systemic weakness of the\nvery concept of \"cost-based evaluation functions + systematic search +\ncombinatorial graphs\". We show that satisficing search with sized-based\nevaluation functions is largely immune to this problem.\n", "versions": [{"version": "v1", "created": "Fri, 18 Mar 2011 18:57:46 GMT"}], "update_date": "2011-03-21", "authors_parsed": [["Cushing", "William", ""], ["Benton", "J.", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1103.3735", "submitter": "Lihong Li", "authors": "Taesup Moon and Wei Chu and Lihong Li and Zhaohui Zheng and Yi Chang", "title": "Refining Recency Search Results with User Click Feedback", "comments": "22 pages, 9 figures, 1 table. A preliminary and shorter version\n  presented at CIKM-2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional machine-learned ranking systems for web search are often trained\nto capture stationary relevance of documents to queries, which has limited\nability to track non-stationary user intention in a timely manner. In recency\nsearch, for instance, the relevance of documents to a query on breaking news\noften changes significantly over time, requiring effective adaptation to user\nintention. In this paper, we focus on recency search and study a number of\nalgorithms to improve ranking results by leveraging user click feedback. Our\ncontributions are three-fold. First, we use real search sessions collected in a\nrandom exploration bucket for \\emph{reliable} offline evaluation of these\nalgorithms, which provides an unbiased comparison across algorithms without\nonline bucket tests. Second, we propose a re-ranking approach to improve search\nresults for recency queries using user clicks. Third, our empirical comparison\nof a dozen algorithms on real-life search data suggests importance of a few\nalgorithmic choices in these applications, including generalization across\ndifferent query-document pairs, specialization to popular queries, and\nreal-time adaptation of user clicks.\n", "versions": [{"version": "v1", "created": "Sat, 19 Mar 2011 00:08:45 GMT"}], "update_date": "2011-03-22", "authors_parsed": [["Moon", "Taesup", ""], ["Chu", "Wei", ""], ["Li", "Lihong", ""], ["Zheng", "Zhaohui", ""], ["Chang", "Yi", ""]]}, {"id": "1103.3745", "submitter": "Nina Narodytska", "authors": "Christian Bessiere, Nina Narodytska, Claude-Guy Quimper, Toby Walsh", "title": "The AllDifferent Constraint with Precedences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose AllDiffPrecedence, a new global constraint that combines together\nan AllDifferent constraint with precedence constraints that strictly order\ngiven pairs of variables. We identify a number of applications for this global\nconstraint including instruction scheduling and symmetry breaking. We give an\nefficient propagation algorithm that enforces bounds consistency on this global\nconstraint. We show how to implement this propagator using a decomposition that\nextends the bounds consistency enforcing decomposition proposed for the\nAllDifferent constraint. Finally, we prove that enforcing domain consistency on\nthis global constraint is NP-hard in general.\n", "versions": [{"version": "v1", "created": "Sat, 19 Mar 2011 03:50:45 GMT"}], "update_date": "2011-03-22", "authors_parsed": [["Bessiere", "Christian", ""], ["Narodytska", "Nina", ""], ["Quimper", "Claude-Guy", ""], ["Walsh", "Toby", ""]]}, {"id": "1103.3904", "submitter": "Daniel Harabor D", "authors": "Daniel Harabor and Philip Kilby", "title": "Informed Heuristics for Guiding Stem-and-Cycle Ejection Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state of the art in local search for the Traveling Salesman Problem is\ndominated by ejection chain methods utilising the Stem-and-Cycle reference\nstructure. Though effective such algorithms employ very little information in\ntheir successor selection strategy, typically seeking only to minimise the cost\nof a move. We propose an alternative approach inspired from the AI literature\nand show how an admissible heuristic can be used to guide successor selection.\nWe undertake an empirical analysis and demonstrate that this technique often\nproduces better results than less informed strategies albeit at the cost of\nrunning in higher polynomial time.\n", "versions": [{"version": "v1", "created": "Mon, 21 Mar 2011 00:15:00 GMT"}], "update_date": "2011-03-22", "authors_parsed": [["Harabor", "Daniel", ""], ["Kilby", "Philip", ""]]}, {"id": "1103.3949", "submitter": "Ana Sofia Gomes", "authors": "Ana Sofia Gomes, Jose Julio Alferes, Terrance Swift", "title": "A Goal-Directed Implementation of Query Answering for Hybrid MKNF\n  Knowledge Bases", "comments": null, "journal-ref": "Theory and Practice of Logic Programming 14 (2014) 239-264", "doi": "10.1017/S1471068412000439", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontologies and rules are usually loosely coupled in knowledge representation\nformalisms. In fact, ontologies use open-world reasoning while the leading\nsemantics for rules use non-monotonic, closed-world reasoning. One exception is\nthe tightly-coupled framework of Minimal Knowledge and Negation as Failure\n(MKNF), which allows statements about individuals to be jointly derived via\nentailment from an ontology and inferences from rules. Nonetheless, the\npractical usefulness of MKNF has not always been clear, although recent work\nhas formalized a general resolution-based method for querying MKNF when rules\nare taken to have the well-founded semantics, and the ontology is modeled by a\ngeneral oracle. That work leaves open what algorithms should be used to relate\nthe entailments of the ontology and the inferences of rules. In this paper we\nprovide such algorithms, and describe the implementation of a query-driven\nsystem, CDF-Rules, for hybrid knowledge bases combining both (non-monotonic)\nrules under the well-founded semantics and a (monotonic) ontology, represented\nby a CDF Type-1 (ALQ) theory. To appear in Theory and Practice of Logic\nProgramming (TPLP)\n", "versions": [{"version": "v1", "created": "Mon, 21 Mar 2011 09:51:36 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2012 14:03:07 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Gomes", "Ana Sofia", ""], ["Alferes", "Jose Julio", ""], ["Swift", "Terrance", ""]]}, {"id": "1103.3954", "submitter": "Olivier Bailleux", "authors": "Olivier Bailleux", "title": "BoolVar/PB v1.0, a java library for translating pseudo-Boolean\n  constraints into CNF formulae", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BoolVar/PB is an open source java library dedicated to the translation of\npseudo-Boolean constraints into CNF formulae. Input constraints can be\ncategorized with tags. Several encoding schemes are implemented in a way that\neach input constraint can be translated using one or several encoders,\naccording to the related tags. The library can be easily extended by adding new\nencoders and / or new output formats.\n", "versions": [{"version": "v1", "created": "Mon, 21 Mar 2011 10:14:40 GMT"}], "update_date": "2011-03-22", "authors_parsed": [["Bailleux", "Olivier", ""]]}, {"id": "1103.4487", "submitter": "Dan Ciresan", "authors": "Dan C. Cire\\c{s}an, Ueli Meier, Luca M. Gambardella and J\\\"urgen\n  Schmidhuber", "title": "Handwritten Digit Recognition with a Committee of Deep Neural Nets on\n  GPUs", "comments": "9 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": "IDSIA-03-11", "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The competitive MNIST handwritten digit recognition benchmark has a long\nhistory of broken records since 1998. The most recent substantial improvement\nby others dates back 7 years (error rate 0.4%) . Recently we were able to\nsignificantly improve this result, using graphics cards to greatly speed up\ntraining of simple but deep MLPs, which achieved 0.35%, outperforming all the\nprevious more complex methods. Here we report another substantial improvement:\n0.31% obtained using a committee of MLPs.\n", "versions": [{"version": "v1", "created": "Wed, 23 Mar 2011 10:38:50 GMT"}], "update_date": "2011-03-24", "authors_parsed": [["Cire\u015fan", "Dan C.", ""], ["Meier", "Ueli", ""], ["Gambardella", "Luca M.", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1103.4558", "submitter": "Fangkai Yang", "authors": "Paolo Ferraris, Joohyung Lee, Yuliya Lierler, Vladimir Lifschitz and\n  Fangkai Yang", "title": "Representing First-Order Causal Theories by Logic Programs", "comments": "29 pages. To appear in Theory and Practice of Logic Programming\n  (TPLP); Theory and Practice of Logic Programming, May, 2011", "journal-ref": null, "doi": "10.1017/S1471068411000081", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonmonotonic causal logic, introduced by Norman McCain and Hudson Turner,\nbecame a basis for the semantics of several expressive action languages.\nMcCain's embedding of definite propositional causal theories into logic\nprogramming paved the way to the use of answer set solvers for answering\nqueries about actions described in such languages. In this paper we extend this\nembedding to nondefinite theories and to first-order causal logic.\n", "versions": [{"version": "v1", "created": "Wed, 23 Mar 2011 15:48:44 GMT"}], "update_date": "2011-06-03", "authors_parsed": [["Ferraris", "Paolo", ""], ["Lee", "Joohyung", ""], ["Lierler", "Yuliya", ""], ["Lifschitz", "Vladimir", ""], ["Yang", "Fangkai", ""]]}, {"id": "1103.4601", "submitter": "Lihong Li", "authors": "Miroslav Dudik and John Langford and Lihong Li", "title": "Doubly Robust Policy Evaluation and Learning", "comments": "Published at ICML 2011, 8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study decision making in environments where the reward is only partially\nobserved, but can be modeled as a function of an action and an observed\ncontext. This setting, known as contextual bandits, encompasses a wide variety\nof applications including health-care policy and Internet advertising. A\ncentral task is evaluation of a new policy given historic data consisting of\ncontexts, actions and received rewards. The key challenge is that the past data\ntypically does not faithfully represent proportions of actions taken by a new\npolicy. Previous approaches rely either on models of rewards or models of the\npast policy. The former are plagued by a large bias whereas the latter have a\nlarge variance.\n  In this work, we leverage the strength and overcome the weaknesses of the two\napproaches by applying the doubly robust technique to the problems of policy\nevaluation and optimization. We prove that this approach yields accurate value\nestimates when we have either a good (but not necessarily consistent) model of\nrewards or a good (but not necessarily consistent) model of past policy.\nExtensive empirical comparison demonstrates that the doubly robust approach\nuniformly improves over existing techniques, achieving both lower variance in\nvalue estimation and better policies. As such, we expect the doubly robust\napproach to become common practice.\n", "versions": [{"version": "v1", "created": "Wed, 23 Mar 2011 19:37:45 GMT"}, {"version": "v2", "created": "Fri, 6 May 2011 02:38:18 GMT"}], "update_date": "2011-05-09", "authors_parsed": [["Dudik", "Miroslav", ""], ["Langford", "John", ""], ["Li", "Lihong", ""]]}, {"id": "1103.4778", "submitter": "Jos\\'e L Balc\\'azar Navarro", "authors": "Jos\\'e L. Balc\\'azar", "title": "Formal and Computational Properties of the Confidence Boost of\n  Association Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some existing notions of redundancy among association rules allow for a\nlogical-style characterization and lead to irredundant bases of absolutely\nminimum size. One can push the intuition of redundancy further and find an\nintuitive notion of interest of an association rule, in terms of its \"novelty\"\nwith respect to other rules. Namely: an irredundant rule is so because its\nconfidence is higher than what the rest of the rules would suggest; then, one\ncan ask: how much higher? We propose to measure such a sort of \"novelty\"\nthrough the confidence boost of a rule, which encompasses two previous similar\nnotions (confidence width and rule blocking, of which the latter is closely\nrelated to the earlier measure \"improvement\"). Acting as a complement to\nconfidence and support, the confidence boost helps to obtain small and crisp\nsets of mined association rules, and solves the well-known problem that, in\ncertain cases, rules of negative correlation may pass the confidence bound. We\nanalyze the properties of two versions of the notion of confidence boost, one\nof them a natural generalization of the other. We develop efficient\nalgorithmics to filter rules according to their confidence boost, compare the\nconcept to some similar notions in the bibliography, and describe the results\nof some experimentation employing the new notions on standard benchmark\ndatasets. We describe an open-source association mining tool that embodies one\nof our variants of confidence boost in such a way that the data mining process\ndoes not require the user to select any value for any parameter.\n", "versions": [{"version": "v1", "created": "Thu, 24 Mar 2011 14:45:50 GMT"}], "update_date": "2011-03-25", "authors_parsed": [["Balc\u00e1zar", "Jos\u00e9 L.", ""]]}, {"id": "1103.4854", "submitter": "Vadas Gintautas", "authors": "Vadas Gintautas, Aric Hagberg, Luis M. A. Bettencourt", "title": "When is social computation better than the sum of its parts?", "comments": "5 pages, 1 figure; In H. Liu, J. J. Salerno, and M. J. Young,\n  editors, Social Computing, Behavior Modeling, and Prediction, 2009", "journal-ref": null, "doi": null, "report-no": "LA-UR 09-00432", "categories": "cs.IT cs.AI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social computation, whether in the form of searches performed by swarms of\nagents or collective predictions of markets, often supplies remarkably good\nsolutions to complex problems. In many examples, individuals trying to solve a\nproblem locally can aggregate their information and work together to arrive at\na superior global solution. This suggests that there may be general principles\nof information aggregation and coordination that can transcend particular\napplications. Here we show that the general structure of this problem can be\ncast in terms of information theory and derive mathematical conditions that\nlead to optimal multi-agent searches. Specifically, we illustrate the problem\nin terms of local search algorithms for autonomous agents looking for the\nspatial location of a stochastic source. We explore the types of search\nproblems, defined in terms of the statistical properties of the source and the\nnature of measurements at each agent, for which coordination among multiple\nsearchers yields an advantage beyond that gained by having the same number of\nindependent searchers. We show that effective coordination corresponds to\nsynergy and that ineffective coordination corresponds to independence as\ndefined using information theory. We classify explicit types of sources in\nterms of their potential for synergy. We show that sources that emit\nuncorrelated signals provide no opportunity for synergetic coordination while\nsources that emit signals that are correlated in some way, do allow for strong\nsynergy between searchers. These general considerations are crucial for\ndesigning optimal algorithms for particular search problems in real world\nsettings.\n", "versions": [{"version": "v1", "created": "Thu, 24 Mar 2011 19:47:51 GMT"}], "update_date": "2011-03-25", "authors_parsed": [["Gintautas", "Vadas", ""], ["Hagberg", "Aric", ""], ["Bettencourt", "Luis M. A.", ""]]}, {"id": "1103.4888", "submitter": "Vadas Gintautas", "authors": "Vadas Gintautas, Aric Hagberg, Luis M. A. Bettencourt", "title": "Cooperative searching for stochastic targets", "comments": "Journal of Intelligence Community Research and Development,\n  permanently available on Intelink, October 2010", "journal-ref": null, "doi": null, "report-no": "LA-UR 09-07676", "categories": "cs.IT cs.AI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial search problems abound in the real world, from locating hidden\nnuclear or chemical sources to finding skiers after an avalanche. We exemplify\nthe formalism and solution for spatial searches involving two agents that may\nor may not choose to share information during a search. For certain classes of\ntasks, sharing information between multiple searchers makes cooperative\nsearching advantageous. In some examples, agents are able to realize synergy by\naggregating information and moving based on local judgments about maximal\ninformation gathering expectations. We also explore one- and two-dimensional\nsimplified situations analytically and numerically to provide a framework for\nanalyzing more complex problems. These general considerations provide a guide\nfor designing optimal algorithms for real-world search problems.\n", "versions": [{"version": "v1", "created": "Fri, 25 Mar 2011 00:54:19 GMT"}], "update_date": "2011-03-28", "authors_parsed": [["Gintautas", "Vadas", ""], ["Hagberg", "Aric", ""], ["Bettencourt", "Luis M. A.", ""]]}, {"id": "1103.5002", "submitter": "David Vallet David Vallet", "authors": "Blaz Fortuna, Dunja Mladenic, Marko Grobelnik", "title": "User Modeling Combining Access Logs, Page Content and Semantics", "comments": "1st International Workshop on Usage Analysis and the Web of Data\n  (USEWOD2011) in the 20th International World Wide Web Conference (WWW2011),\n  Hyderabad, India, March 28th, 2011", "journal-ref": null, "doi": null, "report-no": "WWW2011USEWOD/2011/formlagro", "categories": "cs.IR cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper proposes an approach to modeling users of large Web sites based on\ncombining different data sources: access logs and content of the accessed pages\nare combined with semantic information about the Web pages, the users and the\naccesses of the users to the Web site. The assumption is that we are dealing\nwith a large Web site providing content to a large number of users accessing\nthe site. The proposed approach represents each user by a set of features\nderived from the different data sources, where some feature values may be\nmissing for some users. It further enables user modeling based on the provided\ncharacteristics of the targeted user subset. The approach is evaluated on\nreal-world data where we compare performance of the automatic assignment of a\nuser to a predefined user segment when different data sources are used to\nrepresent the users.\n", "versions": [{"version": "v1", "created": "Fri, 25 Mar 2011 15:49:03 GMT"}], "update_date": "2011-03-28", "authors_parsed": [["Fortuna", "Blaz", ""], ["Mladenic", "Dunja", ""], ["Grobelnik", "Marko", ""]]}, {"id": "1103.5034", "submitter": "Tong Chern", "authors": "Tong Chern", "title": "On Understanding and Machine Understanding", "comments": "due to some serious errors on page 2,3 and 5", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper, we try to propose a self-similar network theory for the\nbasic understanding. By extending the natural languages to a kind of so called\nidealy sufficient language, we can proceed a few steps to the investigation of\nthe language searching and the language understanding of AI.\n  Image understanding, and the familiarity of the brain to the surrounding\nenvironment are also discussed. Group effects are discussed by addressing the\nessense of the power of influences, and constructing the influence network of a\nsociety. We also give a discussion of inspirations.\n", "versions": [{"version": "v1", "created": "Thu, 24 Mar 2011 03:35:24 GMT"}, {"version": "v2", "created": "Thu, 1 Feb 2018 14:02:38 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Chern", "Tong", ""]]}, {"id": "1103.5043", "submitter": "David Vallet David Vallet", "authors": "Mario Arias, Javier D. Fern\\'andez, Miguel A. Mart\\'inez-Prieto, Pablo\n  de la Fuente", "title": "An Empirical Study of Real-World SPARQL Queries", "comments": "1st International Workshop on Usage Analysis and the Web of Data\n  (USEWOD2011) in the 20th International World Wide Web Conference (WWW2011),\n  Hyderabad, India, March 28th, 2011", "journal-ref": null, "doi": null, "report-no": "WWW2011USEWOD/2011/arifermarfue", "categories": "cs.IR cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding how users tailor their SPARQL queries is crucial when designing\nquery evaluation engines or fine-tuning RDF stores with performance in mind. In\nthis paper we analyze 3 million real-world SPARQL queries extracted from logs\nof the DBPedia and SWDF public endpoints. We aim at finding which are the most\nused language elements both from syntactical and structural perspectives,\npaying special attention to triple patterns and joins, since they are indeed\nsome of the most expensive SPARQL operations at evaluation phase. We have\ndetermined that most of the queries are simple and include few triple patterns\nand joins, being Subject-Subject, Subject-Object and Object-Object the most\ncommon join types. The graph patterns are usually star-shaped and despite\ntriple pattern chains exist, they are generally short.\n", "versions": [{"version": "v1", "created": "Fri, 25 Mar 2011 17:43:17 GMT"}], "update_date": "2011-03-28", "authors_parsed": [["Arias", "Mario", ""], ["Fern\u00e1ndez", "Javier D.", ""], ["Mart\u00ednez-Prieto", "Miguel A.", ""], ["de la Fuente", "Pablo", ""]]}, {"id": "1103.5044", "submitter": "David Vallet David Vallet", "authors": "Ashish Sureka", "title": "Mining User Comment Activity for Detecting Forum Spammers in YouTube", "comments": "1st International Workshop on Usage Analysis and the Web of Data\n  (USEWOD2011) in the 20th International World Wide Web Conference (WWW2011),\n  Hyderabad, India, March 28th, 2011", "journal-ref": null, "doi": null, "report-no": "WWW2011USEWOD/2011/sur", "categories": "cs.IR cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research shows that comment spamming (comments which are unsolicited,\nunrelated, abusive, hateful, commercial advertisements etc) in online\ndiscussion forums has become a common phenomenon in Web 2.0 applications and\nthere is a strong need to counter or combat comment spamming. We present a\nmethod to automatically detect comment spammer in YouTube (largest and a\npopular video sharing website) forums. The proposed technique is based on\nmining comment activity log of a user and extracting patterns (such as time\ninterval between subsequent comments, presence of exactly same comment across\nmultiple unrelated videos) indicating spam behavior. We perform empirical\nanalysis on data crawled from YouTube and demonstrate that the proposed method\nis effective for the task of comment spammer detection.\n", "versions": [{"version": "v1", "created": "Fri, 25 Mar 2011 17:45:46 GMT"}], "update_date": "2011-03-28", "authors_parsed": [["Sureka", "Ashish", ""]]}, {"id": "1103.5046", "submitter": "David Vallet David Vallet", "authors": "Markus Kirchberg, Ryan K L Ko, Bu Sung Lee", "title": "From Linked Data to Relevant Data -- Time is the Essence", "comments": "1st International Workshop on Usage Analysis and the Web of Data\n  (USEWOD2011) in the 20th International World Wide Web Conference (WWW2011),\n  Hyderabad, India, March 28th, 2011", "journal-ref": null, "doi": null, "report-no": "WWW2011USEWOD/2011/kirkolee", "categories": "cs.IR cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Semantic Web initiative puts emphasis not primarily on putting data on\nthe Web, but rather on creating links in a way that both humans and machines\ncan explore the Web of data. When such users access the Web, they leave a trail\nas Web servers maintain a history of requests. Web usage mining approaches have\nbeen studied since the beginning of the Web given the log's huge potential for\npurposes such as resource annotation, personalization, forecasting etc.\nHowever, the impact of any such efforts has not really gone beyond generating\nstatistics detailing who, when, and how Web pages maintained by a Web server\nwere visited.\n", "versions": [{"version": "v1", "created": "Fri, 25 Mar 2011 17:48:57 GMT"}], "update_date": "2011-04-07", "authors_parsed": [["Kirchberg", "Markus", ""], ["Ko", "Ryan K L", ""], ["Lee", "Bu Sung", ""]]}, {"id": "1103.5078", "submitter": "Miroslav Ciric", "authors": "Miroslav \\'Ciri\\'c, Jelena Ignjatovi\\'c, Ivana Jan\\v{c}i\\'c, Nada\n  Damljanovi\\'c", "title": "Algorithms for computing the greatest simulations and bisimulations\n  between fuzzy automata", "comments": "19 pages, submitted to a journal", "journal-ref": "Fuzzy Sets and Systems 208 (2012) 22-42", "doi": "10.1016/j.fss.2012.05.006", "report-no": null, "categories": "cs.FL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, two types of simulations (forward and backward simulations) and\nfour types of bisimulations (forward, backward, forward-backward, and\nbackward-forward bisimulations) between fuzzy automata have been introduced. If\nthere is at least one simulation/bisimulation of some of these types between\nthe given fuzzy automata, it has been proved that there is the greatest\nsimulation/bisimulation of this kind. In the present paper, for any of the\nabove-mentioned types of simulations/bisimulations we provide an effective\nalgorithm for deciding whether there is a simulation/bisimulation of this type\nbetween the given fuzzy automata, and for computing the greatest one, whenever\nit exists. The algorithms are based on the method developed in [J.\nIgnjatovi\\'c, M. \\'Ciri\\'c, S. Bogdanovi\\'c, On the greatest solutions to\ncertain systems of fuzzy relation inequalities and equations, Fuzzy Sets and\nSystems 161 (2010) 3081-3113], which comes down to the computing of the\ngreatest post-fixed point, contained in a given fuzzy relation, of an isotone\nfunction on the lattice of fuzzy relations.\n", "versions": [{"version": "v1", "created": "Fri, 25 Mar 2011 20:37:04 GMT"}], "update_date": "2014-04-01", "authors_parsed": [["\u0106iri\u0107", "Miroslav", ""], ["Ignjatovi\u0107", "Jelena", ""], ["Jan\u010di\u0107", "Ivana", ""], ["Damljanovi\u0107", "Nada", ""]]}, {"id": "1103.5708", "submitter": "Yi Sun", "authors": "Yi Sun, Faustino Gomez, Juergen Schmidhuber", "title": "Planning to Be Surprised: Optimal Bayesian Exploration in Dynamic\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  To maximize its success, an AGI typically needs to explore its initially\nunknown world. Is there an optimal way of doing so? Here we derive an\naffirmative answer for a broad class of environments.\n", "versions": [{"version": "v1", "created": "Tue, 29 Mar 2011 17:02:35 GMT"}], "update_date": "2011-03-30", "authors_parsed": [["Sun", "Yi", ""], ["Gomez", "Faustino", ""], ["Schmidhuber", "Juergen", ""]]}]