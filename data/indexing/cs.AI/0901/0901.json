[{"id": "0901.0317", "submitter": "Janardan Misra", "authors": "Janardan Misra", "title": "Design of a P System based Artificial Graph Chemistry", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Chemistries (ACs) are symbolic chemical metaphors for the\nexploration of Artificial Life, with specific focus on the origin of life. In\nthis work we define a P system based artificial graph chemistry to understand\nthe principles leading to the evolution of life-like structures in an AC set up\nand to develop a unified framework to characterize and classify symbolic\nartificial chemistries by devising appropriate formalism to capture semantic\nand organizational information. An extension of P system is considered by\nassociating probabilities with the rules providing the topological framework\nfor the evolution of a labeled undirected graph based molecular reaction\nsemantics.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jan 2009 17:35:49 GMT"}], "update_date": "2009-01-06", "authors_parsed": [["Misra", "Janardan", ""]]}, {"id": "0901.0318", "submitter": "Janardan Misra", "authors": "Janrdan Misra", "title": "Thoughts on an Unified Framework for Artificial Chemistries", "comments": "17 papges", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT math.IT nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Chemistries (ACs) are symbolic chemical metaphors for the\nexploration of Artificial Life, with specific focus on the problem of\nbiogenesis or the origin of life. This paper presents authors thoughts towards\ndefining a unified framework to characterize and classify symbolic artificial\nchemistries by devising appropriate formalism to capture semantic and\norganizational information. We identify three basic high level abstractions in\ninitial proposal for this framework viz., information, computation, and\ncommunication. We present an analysis of two important notions of information,\nnamely, Shannon's Entropy and Algorithmic Information, and discuss inductive\nand deductive approaches for defining the framework.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jan 2009 17:37:15 GMT"}], "update_date": "2009-01-06", "authors_parsed": [["Misra", "Janrdan", ""]]}, {"id": "0901.0597", "submitter": "Reza Rastegar", "authors": "Reza Rastegar", "title": "On the Optimal Convergence Probability of Univariate Estimation of\n  Distribution Algorithms", "comments": "evolutionary computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we obtain bounds on the probability of convergence to the\noptimal solution for the compact Genetic Algorithm (cGA) and the Population\nBased Incremental Learning (PBIL). We also give a sufficient condition for\nconvergence of these algorithms to the optimal solution and compute a range of\npossible values of the parameters of these algorithms for which they converge\nto the optimal solution with a confidence level.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jan 2009 06:36:54 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2009 18:27:38 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2009 13:34:45 GMT"}, {"version": "v4", "created": "Mon, 13 Sep 2010 12:40:44 GMT"}], "update_date": "2010-09-14", "authors_parsed": [["Rastegar", "Reza", ""]]}, {"id": "0901.0598", "submitter": "Reza Rastegar", "authors": "Reza Rastegar, Arash Hariri", "title": "A Step Forward in Studying the Compact Genetic Algorithm", "comments": "13 Pages", "journal-ref": "Evolutionary Computation (2006),Vol 14, No 3, 277-290", "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The compact Genetic Algorithm (cGA) is an Estimation of Distribution\nAlgorithm that generates offspring population according to the estimated\nprobabilistic model of the parent population instead of using traditional\nrecombination and mutation operators. The cGA only needs a small amount of\nmemory; therefore, it may be quite useful in memory-constrained applications.\nThis paper introduces a theoretical framework for studying the cGA from the\nconvergence point of view in which, we model the cGA by a Markov process and\napproximate its behavior using an Ordinary Differential Equation (ODE). Then,\nwe prove that the corresponding ODE converges to local optima and stays there.\nConsequently, we conclude that the cGA will converge to the local optima of the\nfunction to be optimized.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jan 2009 07:07:00 GMT"}], "update_date": "2009-01-07", "authors_parsed": [["Rastegar", "Reza", ""], ["Hariri", "Arash", ""]]}, {"id": "0901.0733", "submitter": "\\'Eric Martin", "authors": "\\'Eric A. Martin", "title": "Contextual hypotheses and semantics of logic programs", "comments": "To appear in Theory and Practice of Logic Programming (TPLP) 46\n  pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logic programming has developed as a rich field, built over a logical\nsubstratum whose main constituent is a nonclassical form of negation, sometimes\ncoexisting with classical negation. The field has seen the advent of a number\nof alternative semantics, with Kripke-Kleene semantics, the well-founded\nsemantics, the stable model semantics, and the answer-set semantics standing\nout as the most successful. We show that all aforementioned semantics are\nparticular cases of a generic semantics, in a framework where classical\nnegation is the unique form of negation and where the literals in the bodies of\nthe rules can be `marked' to indicate that they can be the targets of\nhypotheses. A particular semantics then amounts to choosing a particular\nmarking scheme and choosing a particular set of hypotheses. When a literal\nbelongs to the chosen set of hypotheses, all marked occurrences of that literal\nin the body of a rule are assumed to be true, whereas the occurrences of that\nliteral that have not been marked in the body of the rule are to be derived in\norder to contribute to the firing of the rule. Hence the notion of hypothetical\nreasoning that is presented in this framework is not based on making global\nassumptions, but more subtly on making local, contextual assumptions, taking\neffect as indicated by the chosen marking scheme on the basis of the chosen set\nof hypotheses. Our approach offers a unified view on the various semantics\nproposed in logic programming, classical in that only classical negation is\nused, and links the semantics of logic programs to mechanisms that endow\nrule-based systems with the power to harness hypothetical reasoning.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jan 2009 22:50:22 GMT"}, {"version": "v2", "created": "Fri, 6 May 2011 05:27:50 GMT"}], "update_date": "2011-05-09", "authors_parsed": [["Martin", "\u00c9ric A.", ""]]}, {"id": "0901.0786", "submitter": "Vicen\\c{c} G\\'omez Cerd\\`a", "authors": "V. G\\'omez, H. J. Kappen, M. Chertkov", "title": "Approximate inference on planar graphs using Loop Calculus and Belief\n  Propagation", "comments": "23 pages, 10 figures. Submitted to Journal of Machine Learning\n  Research. Proceedings version accepted for UAI 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce novel results for approximate inference on planar graphical\nmodels using the loop calculus framework. The loop calculus (Chertkov and\nChernyak, 2006) allows to express the exact partition function of a graphical\nmodel as a finite sum of terms that can be evaluated once the belief\npropagation (BP) solution is known. In general, full summation over all\ncorrection terms is intractable. We develop an algorithm for the approach\npresented in (Certkov et al., 2008) which represents an efficient truncation\nscheme on planar graphs and a new representation of the series in terms of\nPfaffians of matrices. We analyze the performance of the algorithm for the\npartition function approximation for models with binary variables and pairwise\ninteractions on grids and other planar graphs. We study in detail both the loop\nseries and the equivalent Pfaffian series and show that the first term of the\nPfaffian series for the general, intractable planar model, can provide very\naccurate approximations. The algorithm outperforms previous truncation schemes\nof the loop series and is competitive with other state-of-the-art methods for\napproximate inference.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jan 2009 09:21:47 GMT"}, {"version": "v2", "created": "Sun, 22 Feb 2009 14:42:14 GMT"}, {"version": "v3", "created": "Mon, 25 May 2009 14:29:00 GMT"}], "update_date": "2009-05-25", "authors_parsed": [["G\u00f3mez", "V.", ""], ["Kappen", "H. J.", ""], ["Chertkov", "M.", ""]]}, {"id": "0901.1152", "submitter": "Victor Eliashberg", "authors": "Victor Eliashberg", "title": "A nonclassical symbolic theory of working memory, mental computations,\n  and mental set", "comments": "29 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper tackles four basic questions associated with human brain as a\nlearning system. How can the brain learn to (1) mentally simulate different\nexternal memory aids, (2) perform, in principle, any mental computations using\nimaginary memory aids, (3) recall the real sensory and motor events and\nsynthesize a combinatorial number of imaginary events, (4) dynamically change\nits mental set to match a combinatorial number of contexts? We propose a\nuniform answer to (1)-(4) based on the general postulate that the human\nneocortex processes symbolic information in a \"nonclassical\" way. Instead of\nmanipulating symbols in a read/write memory, as the classical symbolic systems\ndo, it manipulates the states of dynamical memory representing different\ntemporary attributes of immovable symbolic structures stored in a long-term\nmemory. The approach is formalized as the concept of E-machine. Intuitively, an\nE-machine is a system that deals mainly with characteristic functions\nrepresenting subsets of memory pointers rather than the pointers themselves.\nThis nonclassical symbolic paradigm is Turing universal, and, unlike the\nclassical one, is efficiently implementable in homogeneous neural networks with\ntemporal modulation topologically resembling that of the neocortex.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jan 2009 23:42:45 GMT"}], "update_date": "2009-01-12", "authors_parsed": [["Eliashberg", "Victor", ""]]}, {"id": "0901.1230", "submitter": "Leslie De Koninck", "authors": "Leslie De Koninck", "title": "Logical Algorithms meets CHR: A meta-complexity result for Constraint\n  Handling Rules with rule priorities", "comments": "To appear in Theory and Practice of Logic Programming (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the relationship between the Logical Algorithms\nlanguage (LA) of Ganzinger and McAllester and Constraint Handling Rules (CHR).\nWe present a translation schema from LA to CHR-rp: CHR with rule priorities,\nand show that the meta-complexity theorem for LA can be applied to a subset of\nCHR-rp via inverse translation. Inspired by the high-level implementation\nproposal for Logical Algorithm by Ganzinger and McAllester and based on a new\nscheduling algorithm, we propose an alternative implementation for CHR-rp that\ngives strong complexity guarantees and results in a new and accurate\nmeta-complexity theorem for CHR-rp. It is furthermore shown that the\ntranslation from Logical Algorithms to CHR-rp combined with the new CHR-rp\nimplementation, satisfies the required complexity for the Logical Algorithms\nmeta-complexity result to hold.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2009 12:37:32 GMT"}], "update_date": "2009-01-12", "authors_parsed": [["De Koninck", "Leslie", ""]]}, {"id": "0901.1289", "submitter": "Florentin Smarandache", "authors": "Florentin Smarandache", "title": "N-norm and N-conorm in Neutrosophic Logic and Set, and the Neutrosophic\n  Topologies", "comments": "11 pages, 3 diagrams", "journal-ref": "In author's book A Unifying Field in Logics: Neutrosophic Logic;\n  Neutrosophic Set, Neutrosophic Probability and Statistics (fourth edition),\n  2005; Review of the Air Force Academy, No. 1 (14), pp. 05-11, 2009.", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the N-norms/N-conorms in neutrosophic logic and set\nas extensions of T-norms/T-conorms in fuzzy logic and set. Also, as an\nextension of the Intuitionistic Fuzzy Topology we present the Neutrosophic\nTopologies.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2009 17:58:39 GMT"}], "update_date": "2009-08-17", "authors_parsed": [["Smarandache", "Florentin", ""]]}, {"id": "0901.2130", "submitter": "Lenka Zdeborova", "authors": "Florent Krzakala and Lenka Zdeborov\\'a", "title": "Hiding Quiet Solutions in Random Constraint Satisfaction Problems", "comments": "4 pages, 3 figures", "journal-ref": "Phys. Rev. Lett. 102, 238701 (2009)", "doi": "10.1103/PhysRevLett.102.238701", "report-no": null, "categories": "cond-mat.stat-mech cond-mat.dis-nn cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study constraint satisfaction problems on the so-called 'planted' random\nensemble. We show that for a certain class of problems, e.g. graph coloring,\nmany of the properties of the usual random ensemble are quantitatively\nidentical in the planted random ensemble. We study the structural phase\ntransitions, and the easy/hard/easy pattern in the average computational\ncomplexity. We also discuss the finite temperature phase diagram, finding a\nclose connection with the liquid/glass/solid phenomenology.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jan 2009 21:47:05 GMT"}, {"version": "v2", "created": "Wed, 27 May 2009 18:32:00 GMT"}], "update_date": "2009-06-13", "authors_parsed": [["Krzakala", "Florent", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "0901.2850", "submitter": "Piero Bonatti", "authors": "Sabrina Baselice, Piero A. Bonatti, Giovanni Criscuolo", "title": "On finitely recursive programs", "comments": "26 pages, Preliminary version in Proc. of ICLP 2007, Best paper award", "journal-ref": "Theory and Practice of Logic Programming, 9(2), 213-238, 2009", "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disjunctive finitary programs are a class of logic programs admitting\nfunction symbols and hence infinite domains. They have very good computational\nproperties, for example ground queries are decidable while in the general case\nthe stable model semantics is highly undecidable. In this paper we prove that a\nlarger class of programs, called finitely recursive programs, preserves most of\nthe good properties of finitary programs under the stable model semantics,\nnamely: (i) finitely recursive programs enjoy a compactness property; (ii)\ninconsistency checking and skeptical reasoning are semidecidable; (iii)\nskeptical resolution is complete for normal finitely recursive programs.\nMoreover, we show how to check inconsistency and answer skeptical queries using\nfinite subsets of the ground program instantiation. We achieve this by\nextending the splitting sequence theorem by Lifschitz and Turner: We prove that\nif the input program P is finitely recursive, then the partial stable models\ndetermined by any smooth splitting omega-sequence converge to a stable model of\nP.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jan 2009 13:23:09 GMT"}], "update_date": "2009-05-25", "authors_parsed": [["Baselice", "Sabrina", ""], ["Bonatti", "Piero A.", ""], ["Criscuolo", "Giovanni", ""]]}, {"id": "0901.3574", "submitter": "Christoph Benzmueller", "authors": "Christoph Benzmueller", "title": "Automating Access Control Logics in Simple Type Theory with LEO-II", "comments": "ii + 20 pages", "journal-ref": "SEKI Report SR-2008-01 (ISSN 1437-4447), Saarland University, 2008", "doi": "10.1007/978-3-642-01244-0_34", "report-no": "SEKI Report SR-2008-01", "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Garg and Abadi recently proved that prominent access control logics can be\ntranslated in a sound and complete way into modal logic S4. We have previously\noutlined how normal multimodal logics, including monomodal logics K and S4, can\nbe embedded in simple type theory (which is also known as higher-order logic)\nand we have demonstrated that the higher-order theorem prover LEO-II can\nautomate reasoning in and about them. In this paper we combine these results\nand describe a sound and complete embedding of different access control logics\nin simple type theory. Employing this framework we show that the off the shelf\ntheorem prover LEO-II can be applied to automate reasoning in prominent access\ncontrol logics.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jan 2009 17:20:17 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2009 08:55:19 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Benzmueller", "Christoph", ""]]}, {"id": "0901.3585", "submitter": "Christoph Benzmueller", "authors": "Christoph Benzmueller, Volker Sorge", "title": "Resource Adaptive Agents in Interactive Theorem Proving", "comments": "13 pages", "journal-ref": "SEKI Report (ISSN 1437-4447), Saarland University, 1999", "doi": null, "report-no": "SR-99-02", "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a resource adaptive agent mechanism which supports the user in\ninteractive theorem proving. The mechanism uses a two layered architecture of\nagent societies to suggest appropriate commands together with possible command\nargument instantiations. Experiments with this approach show that its\neffectiveness can be further improved by introducing a resource concept. In\nthis paper we provide an abstract view on the overall mechanism, motivate the\nnecessity of an appropriate resource concept and discuss its realization within\nthe agent architecture.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jan 2009 05:29:09 GMT"}], "update_date": "2009-01-26", "authors_parsed": [["Benzmueller", "Christoph", ""], ["Sorge", "Volker", ""]]}, {"id": "0901.3608", "submitter": "Christoph Benzmueller", "authors": "Christoph Benzmueller", "title": "A remark on higher order RUE-resolution with EXTRUE", "comments": "3 pages", "journal-ref": "SEKI Report (ISSN 1437-4447), Saarland University, 1999", "doi": null, "report-no": "SR-02-05", "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that a prominent counterexample for the completeness of first order\nRUE-resolution does not apply to the higher order RUE-resolution approach\nEXTRUE.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jan 2009 06:18:30 GMT"}], "update_date": "2009-01-26", "authors_parsed": [["Benzmueller", "Christoph", ""]]}, {"id": "0901.3769", "submitter": "Sebastien Verel", "authors": "William Beaudoin (I3S), S\\'ebastien Verel (I3S), Philippe Collard\n  (I3S), Cathy Escazut (I3S)", "title": "Deceptiveness and Neutrality - the ND family of fitness landscapes", "comments": "Genetic And Evolutionary Computation Conference, Seatle :\n  \\'Etats-Unis d'Am\\'erique (2006)", "journal-ref": null, "doi": "10.1145/1143997.1144091", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a considerable number of mutations have no effects on fitness values,\nthe fitness landscape is said neutral. In order to study the interplay between\nneutrality, which exists in many real-world applications, and performances of\nmetaheuristics, it is useful to design landscapes which make it possible to\ntune precisely neutral degree distribution. Even though many neutral landscape\nmodels have already been designed, none of them are general enough to create\nlandscapes with specific neutral degree distributions. We propose three steps\nto design such landscapes: first using an algorithm we construct a landscape\nwhose distribution roughly fits the target one, then we use a simulated\nannealing heuristic to bring closer the two distributions and finally we affect\nfitness values to each neutral network. Then using this new family of fitness\nlandscapes we are able to highlight the interplay between deceptiveness and\nneutrality.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jan 2009 20:15:22 GMT"}], "update_date": "2009-01-26", "authors_parsed": [["Beaudoin", "William", "", "I3S"], ["Verel", "S\u00e9bastien", "", "I3S"], ["Collard", "Philippe", "", "I3S"], ["Escazut", "Cathy", "", "I3S"]]}, {"id": "0901.4004", "submitter": "Yannick Toussaint", "authors": "Alexander Estacio-Moreno, Yannick Toussaint, C\\'edric Bousquet", "title": "Mining for adverse drug events with formal concept analysis", "comments": null, "journal-ref": "Studies in health technology and informatics 136 (2008) 803-8", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pharmacovigilance databases consist of several case reports involving\ndrugs and adverse events (AEs). Some methods are applied consistently to\nhighlight all signals, i.e. all statistically significant associations between\na drug and an AE. These methods are appropriate for verification of more\ncomplex relationships involving one or several drug(s) and AE(s) (e.g;\nsyndromes or interactions) but do not address the identification of them. We\npropose a method for the extraction of these relationships based on Formal\nConcept Analysis (FCA) associated with disproportionality measures. This method\nidentifies all sets of drugs and AEs which are potential signals, syndromes or\ninteractions. Compared to a previous experience of disproportionality analysis\nwithout FCA, the addition of FCA was more efficient for identifying false\npositives related to concomitant drugs.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jan 2009 13:29:40 GMT"}], "update_date": "2009-01-27", "authors_parsed": [["Estacio-Moreno", "Alexander", ""], ["Toussaint", "Yannick", ""], ["Bousquet", "C\u00e9dric", ""]]}, {"id": "0901.4224", "submitter": "Pasquale Di Donato", "authors": "Pasquale Di Donato", "title": "Geospatial semantics: beyond ontologies, towards an enactive approach", "comments": "24 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current approaches to semantics in the geospatial domain are mainly based on\nontologies, but ontologies, since continue to build entirely on the symbolic\nmethodology, suffers from the classical problems, e.g. the symbol grounding\nproblem, affecting representational theories. We claim for an enactive approach\nto semantics, where meaning is considered to be an emergent feature arising\ncontext-dependently in action. Since representational theories are unable to\ndeal with context, a new formalism is required toward a contextual theory of\nconcepts. SCOP is considered a promising formalism in this sense and is briefly\ndescribed.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jan 2009 11:26:57 GMT"}], "update_date": "2009-01-28", "authors_parsed": [["Di Donato", "Pasquale", ""]]}, {"id": "0901.4761", "submitter": "Philippe Fournier-Viger", "authors": "P. Fournier-Viger, R. Nkambou and E. Mephu Nguifo", "title": "A Knowledge Discovery Framework for Learning Task Models from User\n  Interactions in Intelligent Tutoring Systems", "comments": "Proceedings of the 7th Mexican International Conference on Artificial\n  Intelligence (MICAI 2008), Springer, pp. 765-778", "journal-ref": null, "doi": "10.1007/978-3-540-88636-5", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain experts should provide relevant domain knowledge to an Intelligent\nTutoring System (ITS) so that it can guide a learner during problemsolving\nlearning activities. However, for many ill-defined domains, the domain\nknowledge is hard to define explicitly. In previous works, we showed how\nsequential pattern mining can be used to extract a partial problem space from\nlogged user interactions, and how it can support tutoring services during\nproblem-solving exercises. This article describes an extension of this approach\nto extract a problem space that is richer and more adapted for supporting\ntutoring services. We combined sequential pattern mining with (1) dimensional\npattern mining (2) time intervals, (3) the automatic clustering of valued\nactions and (4) closed sequences mining. Some tutoring services have been\nimplemented and an experiment has been conducted in a tutoring system.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jan 2009 19:58:09 GMT"}], "update_date": "2009-01-30", "authors_parsed": [["Fournier-Viger", "P.", ""], ["Nkambou", "R.", ""], ["Nguifo", "E. Mephu", ""]]}, {"id": "0901.4963", "submitter": "Usef Faghihi", "authors": "Usef Faghihi, Philippe Fournier-Viger, Roger Nkambou, Pierre Poirier,\n  Andre Mayers", "title": "How Emotional Mechanism Helps Episodic Learning in a Cognitive Agent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose the CTS (Concious Tutoring System) technology, a\nbiologically plausible cognitive agent based on human brain functions.This\nagent is capable of learning and remembering events and any related information\nsuch as corresponding procedures, stimuli and their emotional valences. Our\nproposed episodic memory and episodic learning mechanism are closer to the\ncurrent multiple-trace theory in neuroscience, because they are inspired by it\n[5] contrary to other mechanisms that are incorporated in cognitive agents.\nThis is because in our model emotions play a role in the encoding and\nremembering of events. This allows the agent to improve its behavior by\nremembering previously selected behaviors which are influenced by its emotional\nmechanism. Moreover, the architecture incorporates a realistic memory\nconsolidation process based on a data mining algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jan 2009 19:36:18 GMT"}], "update_date": "2009-02-02", "authors_parsed": [["Faghihi", "Usef", ""], ["Fournier-Viger", "Philippe", ""], ["Nkambou", "Roger", ""], ["Poirier", "Pierre", ""], ["Mayers", "Andre", ""]]}]