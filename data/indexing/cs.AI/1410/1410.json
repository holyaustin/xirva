[{"id": "1410.0083", "submitter": "Jie Fu", "authors": "Jie Fu and Ufuk Topcu", "title": "Integrating active sensing into reactive synthesis with temporal logic\n  constraints under partial observations", "comments": "7 pages, 2 figures, submitted to American Control Conference 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the notion of online reactive planning with sensing actions for\nsystems with temporal logic constraints in partially observable and dynamic\nenvironments. With incomplete information on the dynamic environment, reactive\ncontroller synthesis amounts to solving a two-player game with partial\nobservations, which has impractically computational complexity. To alleviate\nthe high computational burden, online replanning via sensing actions avoids\nsolving the strategy in the reactive system under partial observations.\nInstead, we only solve for a strategy that ensures a given temporal logic\nspecification can be satisfied had the system have complete observations of its\nenvironment. Such a strategy is then transformed into one which makes control\ndecisions based on the observed sequence of states (of the interacting system\nand its environment). When the system encounters a belief---a set including all\npossible hypotheses the system has for the current state---for which the\nobservation-based strategy is undefined, a sequence of sensing actions are\ntriggered, chosen by an active sensing strategy, to reduce the uncertainty in\nthe system's belief. We show that by alternating between the observation-based\nstrategy and the active sensing strategy, under a mild technical assumption of\nthe set of sensors in the system, the given temporal logic specification can be\nsatisfied with probability 1.\n", "versions": [{"version": "v1", "created": "Wed, 1 Oct 2014 01:05:01 GMT"}], "update_date": "2014-10-02", "authors_parsed": [["Fu", "Jie", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1410.0210", "submitter": "Mateusz Malinowski", "authors": "Mateusz Malinowski and Mario Fritz", "title": "A Multi-World Approach to Question Answering about Real-World Scenes\n  based on Uncertain Input", "comments": "Published in NIPS 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for automatically answering questions about images by\nbringing together recent advances from natural language processing and computer\nvision. We combine discrete reasoning with uncertain predictions by a\nmulti-world approach that represents uncertainty about the perceived world in a\nbayesian framework. Our approach can handle human questions of high complexity\nabout realistic scenes and replies with range of answer like counts, object\nclasses, instances and lists of them. The system is directly trained from\nquestion-answer pairs. We establish a first benchmark for this task that can be\nseen as a modern attempt at a visual turing test.\n", "versions": [{"version": "v1", "created": "Wed, 1 Oct 2014 12:59:16 GMT"}, {"version": "v2", "created": "Wed, 29 Oct 2014 16:29:44 GMT"}, {"version": "v3", "created": "Tue, 11 Nov 2014 12:13:18 GMT"}, {"version": "v4", "created": "Tue, 5 May 2015 17:39:10 GMT"}], "update_date": "2015-05-06", "authors_parsed": [["Malinowski", "Mateusz", ""], ["Fritz", "Mario", ""]]}, {"id": "1410.0281", "submitter": "Tom De Smedt", "authors": "Tom De Smedt", "title": "Modeling Creativity: Case Studies in Python", "comments": "p. 165, University Press Antwerp, ISBN 978-90-5718-260-0", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling Creativity (doctoral dissertation, 2013) explores how creativity can\nbe represented using computational approaches. Our aim is to construct computer\nmodels that exhibit creativity in an artistic context, that is, that are\ncapable of generating or evaluating an artwork (visual or linguistic), an\ninteresting new idea, a subjective opinion. The research was conducted in\n2008-2012 at the Computational Linguistics Research Group (CLiPS, University of\nAntwerp) under the supervision of Prof. Walter Daelemans. Prior research was\nalso conducted at the Experimental Media Research Group (EMRG, St. Lucas\nUniversity College of Art & Design Antwerp) under the supervision of Lucas\nNijs.\n  Modeling Creativity examines creativity in a number of different\nperspectives: from its origins in nature, which is essentially blind, to humans\nand machines, and from generating creative ideas to evaluating and learning\ntheir novelty and usefulness. We will use a hands-on approach with case studies\nand examples in the Python programming language.\n", "versions": [{"version": "v1", "created": "Sun, 10 Aug 2014 20:54:39 GMT"}], "update_date": "2014-10-02", "authors_parsed": [["De Smedt", "Tom", ""]]}, {"id": "1410.0369", "submitter": "Roman Yampolskiy", "authors": "Roman V. Yampolskiy", "title": "The Universe of Minds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper attempts to describe the space of possible mind designs by first\nequating all minds to software. Next it proves some interesting properties of\nthe mind design space such as infinitude of minds, size and representation\ncomplexity of minds. A survey of mind design taxonomies is followed by a\nproposal for a new field of investigation devoted to study of minds,\nintellectology, a list of open problems for this new field is presented.\n", "versions": [{"version": "v1", "created": "Wed, 1 Oct 2014 20:02:05 GMT"}], "update_date": "2014-10-03", "authors_parsed": [["Yampolskiy", "Roman V.", ""]]}, {"id": "1410.0413", "submitter": "Rafael Frongillo", "authors": "Rafael M. Frongillo, Mark D. Reid", "title": "Risk Dynamics in Trade Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new framework to model interactions among agents which seek to\ntrade to minimize their risk with respect to some future outcome. We quantify\nthis risk using the concept of risk measures from finance, and introduce a\nclass of trade dynamics which allow agents to trade contracts contingent upon\nthe future outcome. We then show that these trade dynamics exactly correspond\nto a variant of randomized coordinate descent. By extending the analysis of\nthese coordinate descent methods to account for our more organic setting, we\nare able to show convergence rates for very general trade dynamics, showing\nthat the market or network converges to a unique steady state. Applying these\nresults to prediction markets, we expand on recent results by adding\nconvergence rates and general aggregation properties. Finally, we illustrate\nthe generality of our framework by applying it to agent interactions on a\nscale-free network.\n", "versions": [{"version": "v1", "created": "Wed, 1 Oct 2014 23:26:59 GMT"}, {"version": "v2", "created": "Fri, 10 Oct 2014 01:40:36 GMT"}], "update_date": "2014-10-13", "authors_parsed": [["Frongillo", "Rafael M.", ""], ["Reid", "Mark D.", ""]]}, {"id": "1410.0471", "submitter": "Arto Klami", "authors": "Zakria Hussain, Arto Klami, Jussi Kujala, Alex P. Leung, Kitsuchart\n  Pasupa, Peter Auer, Samuel Kaski, Jorma Laaksonen and John Shawe-Taylor", "title": "PinView: Implicit Feedback in Content-Based Image Retrieval", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes PinView, a content-based image retrieval system that\nexploits implicit relevance feedback collected during a search session. PinView\ncontains several novel methods to infer the intent of the user. From relevance\nfeedback, such as eye movements or pointer clicks, and visual features of\nimages, PinView learns a similarity metric between images which depends on the\ncurrent interests of the user. It then retrieves images with a specialized\nonline learning algorithm that balances the tradeoff between exploring new\nimages and exploiting the already inferred interests of the user. We have\nintegrated PinView to the content-based image retrieval system PicSOM, which\nenables applying PinView to real-world image databases. With the new algorithms\nPinView outperforms the original PicSOM, and in online experiments with real\nusers the combination of implicit and explicit feedback gives the best results.\n", "versions": [{"version": "v1", "created": "Thu, 2 Oct 2014 08:05:19 GMT"}], "update_date": "2014-10-03", "authors_parsed": [["Hussain", "Zakria", ""], ["Klami", "Arto", ""], ["Kujala", "Jussi", ""], ["Leung", "Alex P.", ""], ["Pasupa", "Kitsuchart", ""], ["Auer", "Peter", ""], ["Kaski", "Samuel", ""], ["Laaksonen", "Jorma", ""], ["Shawe-Taylor", "John", ""]]}, {"id": "1410.0547", "submitter": "Richard Preen", "authors": "Richard J. Preen and Larry Bull", "title": "Design Mining Interacting Wind Turbines", "comments": null, "journal-ref": "Evolutionary Computation (2016), 24(1):89-111", "doi": "10.1162/EVCO_a_00144", "report-no": null, "categories": "cs.NE cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An initial study of surrogate-assisted evolutionary algorithms used to design\nvertical-axis wind turbines wherein candidate prototypes are evaluated under\nfan generated wind conditions after being physically instantiated by a 3D\nprinter has recently been presented. Unlike other approaches, such as\ncomputational fluid dynamics simulations, no mathematical formulations were\nused and no model assumptions were made. This paper extends that work by\nexploring alternative surrogate modelling and evolutionary techniques. The\naccuracy of various modelling algorithms used to estimate the fitness of\nevaluated individuals from the initial experiments is compared. The effect of\ntemporally windowing surrogate model training samples is explored. A\nsurrogate-assisted approach based on an enhanced local search is introduced;\nand alternative coevolution collaboration schemes are examined.\n", "versions": [{"version": "v1", "created": "Thu, 2 Oct 2014 13:32:59 GMT"}, {"version": "v2", "created": "Thu, 15 Jan 2015 14:20:23 GMT"}], "update_date": "2016-03-14", "authors_parsed": [["Preen", "Richard J.", ""], ["Bull", "Larry", ""]]}, {"id": "1410.0572", "submitter": "A. Mani", "authors": "A. Mani", "title": "Algebraic Semantics of Proto-Transitive Rough Sets", "comments": "90 pages, 2 figures, 1 table Pre-Publication Monograph, 1st edition", "journal-ref": "Transactions on Rough Sets Vol XX, LNCS, 2016", "doi": null, "report-no": null, "categories": "cs.AI math.LO math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rough sets over generalized transitive relations like proto-transitive ones\nhad been initiated by the present author in the year 2012. Subsequently,\napproximation of proto-transitive relations by other relations was investigated\nand the relation with rough approximations was developed towards constructing\nsemantics that can handle fragments of structure. It was also proved that\ndifference of approximations induced by some approximate relations need not\ninduce rough structures. In this research we develop different semantics of\nproto transitive rough sets (PRAX) after characterizing the structure of rough\nobjects and also develop a theory of dependence for general rough sets and use\nit to internalize the Nelson-algebra based approximate semantics developed\nearlier. The theory of rough dependence initiated later by the present author\nis extended in the process. This monograph is reasonably self-contained and\nincludes proofs and extensions of representation of objects that were not part\nof earlier papers.\n", "versions": [{"version": "v1", "created": "Thu, 2 Oct 2014 14:41:24 GMT"}, {"version": "v2", "created": "Fri, 3 Oct 2014 15:59:51 GMT"}, {"version": "v3", "created": "Mon, 6 Oct 2014 05:06:01 GMT"}], "update_date": "2016-04-25", "authors_parsed": [["Mani", "A.", ""]]}, {"id": "1410.0736", "submitter": "Zhicheng Yan", "authors": "Zhicheng Yan, Hao Zhang, Robinson Piramuthu, Vignesh Jagadeesh, Dennis\n  DeCoste, Wei Di, Yizhou Yu", "title": "HD-CNN: Hierarchical Deep Convolutional Neural Network for Large Scale\n  Visual Recognition", "comments": "Add new results on ImageNet using VGG-16-layer building block net", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In image classification, visual separability between different object\ncategories is highly uneven, and some categories are more difficult to\ndistinguish than others. Such difficult categories demand more dedicated\nclassifiers. However, existing deep convolutional neural networks (CNN) are\ntrained as flat N-way classifiers, and few efforts have been made to leverage\nthe hierarchical structure of categories. In this paper, we introduce\nhierarchical deep CNNs (HD-CNNs) by embedding deep CNNs into a category\nhierarchy. An HD-CNN separates easy classes using a coarse category classifier\nwhile distinguishing difficult classes using fine category classifiers. During\nHD-CNN training, component-wise pretraining is followed by global finetuning\nwith a multinomial logistic loss regularized by a coarse category consistency\nterm. In addition, conditional executions of fine category classifiers and\nlayer parameter compression make HD-CNNs scalable for large-scale visual\nrecognition. We achieve state-of-the-art results on both CIFAR100 and\nlarge-scale ImageNet 1000-class benchmark datasets. In our experiments, we\nbuild up three different HD-CNNs and they lower the top-1 error of the standard\nCNNs by 2.65%, 3.1% and 1.1%, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 3 Oct 2014 01:17:20 GMT"}, {"version": "v2", "created": "Fri, 19 Dec 2014 07:51:51 GMT"}, {"version": "v3", "created": "Sat, 28 Feb 2015 03:11:49 GMT"}, {"version": "v4", "created": "Sat, 16 May 2015 03:36:32 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Yan", "Zhicheng", ""], ["Zhang", "Hao", ""], ["Piramuthu", "Robinson", ""], ["Jagadeesh", "Vignesh", ""], ["DeCoste", "Dennis", ""], ["Di", "Wei", ""], ["Yu", "Yizhou", ""]]}, {"id": "1410.0949", "submitter": "Branislav Kveton", "authors": "Branislav Kveton, Zheng Wen, Azin Ashkan, and Csaba Szepesvari", "title": "Tight Regret Bounds for Stochastic Combinatorial Semi-Bandits", "comments": "Proceedings of the 18th International Conference on Artificial\n  Intelligence and Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A stochastic combinatorial semi-bandit is an online learning problem where at\neach step a learning agent chooses a subset of ground items subject to\nconstraints, and then observes stochastic weights of these items and receives\ntheir sum as a payoff. In this paper, we close the problem of computationally\nand sample efficient learning in stochastic combinatorial semi-bandits. In\nparticular, we analyze a UCB-like algorithm for solving the problem, which is\nknown to be computationally efficient; and prove $O(K L (1 / \\Delta) \\log n)$\nand $O(\\sqrt{K L n \\log n})$ upper bounds on its $n$-step regret, where $L$ is\nthe number of ground items, $K$ is the maximum number of chosen items, and\n$\\Delta$ is the gap between the expected returns of the optimal and best\nsuboptimal solutions. The gap-dependent bound is tight up to a constant factor\nand the gap-free bound is tight up to a polylogarithmic factor.\n", "versions": [{"version": "v1", "created": "Fri, 3 Oct 2014 19:38:16 GMT"}, {"version": "v2", "created": "Sun, 26 Oct 2014 04:30:17 GMT"}, {"version": "v3", "created": "Tue, 27 Jan 2015 05:15:20 GMT"}], "update_date": "2017-06-08", "authors_parsed": [["Kveton", "Branislav", ""], ["Wen", "Zheng", ""], ["Ashkan", "Azin", ""], ["Szepesvari", "Csaba", ""]]}, {"id": "1410.1068", "submitter": "Anirban Roychowdhury", "authors": "Anirban Roychowdhury, Brian Kulis", "title": "Gamma Processes, Stick-Breaking, and Variational Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While most Bayesian nonparametric models in machine learning have focused on\nthe Dirichlet process, the beta process, or their variants, the gamma process\nhas recently emerged as a useful nonparametric prior in its own right. Current\ninference schemes for models involving the gamma process are restricted to\nMCMC-based methods, which limits their scalability. In this paper, we present a\nvariational inference framework for models involving gamma process priors. Our\napproach is based on a novel stick-breaking constructive definition of the\ngamma process. We prove correctness of this stick-breaking process by using the\ncharacterization of the gamma process as a completely random measure (CRM), and\nwe explicitly derive the rate measure of our construction using Poisson process\nmachinery. We also derive error bounds on the truncation of the infinite\nprocess required for variational inference, similar to the truncation analyses\nfor other nonparametric models based on the Dirichlet and beta processes. Our\nrepresentation is then used to derive a variational inference algorithm for a\nparticular Bayesian nonparametric latent structure formulation known as the\ninfinite Gamma-Poisson model, where the latent variables are drawn from a gamma\nprocess prior with Poisson likelihoods. Finally, we present results for our\nalgorithms on nonnegative matrix factorization tasks on document corpora, and\nshow that we compare favorably to both sampling-based techniques and\nvariational approaches based on beta-Bernoulli priors.\n", "versions": [{"version": "v1", "created": "Sat, 4 Oct 2014 17:36:58 GMT"}], "update_date": "2017-04-17", "authors_parsed": [["Roychowdhury", "Anirban", ""], ["Kulis", "Brian", ""]]}, {"id": "1410.1141", "submitter": "Roi Livni", "authors": "Roi Livni and Shai Shalev-Shwartz and Ohad Shamir", "title": "On the Computational Efficiency of Training Neural Networks", "comments": "Section 2 is revised due to a mistake", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that neural networks are computationally hard to train. On\nthe other hand, in practice, modern day neural networks are trained efficiently\nusing SGD and a variety of tricks that include different activation functions\n(e.g. ReLU), over-specification (i.e., train networks which are larger than\nneeded), and regularization. In this paper we revisit the computational\ncomplexity of training neural networks from a modern perspective. We provide\nboth positive and negative results, some of them yield new provably efficient\nand practical algorithms for training certain types of neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 5 Oct 2014 10:54:07 GMT"}, {"version": "v2", "created": "Tue, 28 Oct 2014 19:14:37 GMT"}], "update_date": "2014-10-29", "authors_parsed": [["Livni", "Roi", ""], ["Shalev-Shwartz", "Shai", ""], ["Shamir", "Ohad", ""]]}, {"id": "1410.1231", "submitter": "Devavrat Shah", "authors": "Devavrat Shah and Kang Zhang", "title": "Bayesian regression and Bitcoin", "comments": "Preliminary version appeared in the Proceedings of 2014 Allerton\n  Conference on Communication, Control, and Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss the method of Bayesian regression and its efficacy\nfor predicting price variation of Bitcoin, a recently popularized virtual,\ncryptographic currency. Bayesian regression refers to utilizing empirical data\nas proxy to perform Bayesian inference. We utilize Bayesian regression for the\nso-called \"latent source model\". The Bayesian regression for \"latent source\nmodel\" was introduced and discussed by Chen, Nikolov and Shah (2013) and\nBresler, Chen and Shah (2014) for the purpose of binary classification. They\nestablished theoretical as well as empirical efficacy of the method for the\nsetting of binary classification.\n  In this paper, instead we utilize it for predicting real-valued quantity, the\nprice of Bitcoin. Based on this price prediction method, we devise a simple\nstrategy for trading Bitcoin. The strategy is able to nearly double the\ninvestment in less than 60 day period when run against real data trace.\n", "versions": [{"version": "v1", "created": "Mon, 6 Oct 2014 00:38:39 GMT"}], "update_date": "2014-10-07", "authors_parsed": [["Shah", "Devavrat", ""], ["Zhang", "Kang", ""]]}, {"id": "1410.1462", "submitter": "Zhi-Hua Zhou", "authors": "Nan Li and Rong Jin and Zhi-Hua Zhou", "title": "Top Rank Optimization in Linear Time", "comments": null, "journal-ref": "NIPS 2014", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bipartite ranking aims to learn a real-valued ranking function that orders\npositive instances before negative instances. Recent efforts of bipartite\nranking are focused on optimizing ranking accuracy at the top of the ranked\nlist. Most existing approaches are either to optimize task specific metrics or\nto extend the ranking loss by emphasizing more on the error associated with the\ntop ranked instances, leading to a high computational cost that is super-linear\nin the number of training instances. We propose a highly efficient approach,\ntitled TopPush, for optimizing accuracy at the top that has computational\ncomplexity linear in the number of training instances. We present a novel\nanalysis that bounds the generalization error for the top ranked instances for\nthe proposed approach. Empirical study shows that the proposed approach is\nhighly competitive to the state-of-the-art approaches and is 10-100 times\nfaster.\n", "versions": [{"version": "v1", "created": "Mon, 6 Oct 2014 17:10:23 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Li", "Nan", ""], ["Jin", "Rong", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1410.1776", "submitter": "Maurizio Proietti", "authors": "Fabrizio Smith, Maurizio Proietti", "title": "Ontology-based Representation and Reasoning on Process Models: A Logic\n  Programming Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework grounded in Logic Programming for representing and\nreasoning about business processes from both the procedural and ontological\npoint of views. In particular, our goal is threefold: (1) define a logical\nlanguage and a formal semantics for process models enriched with ontology-based\nannotations; (2) provide an effective inference mechanism that supports the\ncombination of reasoning services dealing with the structural definition of a\nprocess model, its behavior, and the domain knowledge related to the\nparticipating business entities; (3) implement such a theoretical framework\ninto a process modeling and reasoning platform. To this end we define a process\nontology coping with a relevant fragment of the popular BPMN modeling notation.\nThe behavioral semantics of a process is defined as a state transition system\nby following an approach similar to the Fluent Calculus, and allows us to\nspecify state change in terms of preconditions and effects of the enactment of\nactivities. Then we show how the procedural process knowledge can be seamlessly\nintegrated with the domain knowledge specified by using the OWL 2 RL rule-based\nontology language. Our framework provides a wide range of reasoning services,\nincluding CTL model checking, which can be performed by using standard Logic\nProgramming inference engines through a goal-oriented, efficient, sound and\ncomplete evaluation procedure. We also present a software environment\nimplementing the proposed framework, and we report on an experimental\nevaluation of the system, whose results are encouraging and show the viability\nof the approach.\n", "versions": [{"version": "v1", "created": "Tue, 7 Oct 2014 15:39:03 GMT"}], "update_date": "2014-10-08", "authors_parsed": [["Smith", "Fabrizio", ""], ["Proietti", "Maurizio", ""]]}, {"id": "1410.2056", "submitter": "Taymaz Rahkar Farshi", "authors": "Taymaz Rahkar-Farshi, Sara Behjat-Jamal, Mohammad-Reza Feizi-Derakhshi", "title": "An improved multimodal PSO method based on electrostatic interaction\n  using n- nearest-neighbor local search", "comments": "10 pages, 8 figures, International Journal of Artificial Intelligence\n  & Applications (IJAIA), Vol. 5, No. 5, September 2014", "journal-ref": null, "doi": "10.5121/ijaia.2014.5506", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  In this paper, an improved multimodal optimization (MMO) algorithm,called\nLSEPSO,has been proposed. LSEPSO combined Electrostatic Particle Swarm\nOptimization (EPSO) algorithm and a local search method and then made some\nmodification on them. It has been shown to improve global and local optima\nfinding ability of the algorithm. This algorithm useda modified local search to\nimprove particle's personal best, which used n-nearest-neighbour instead of\nnearest-neighbour. Then, by creating n new points among each particle and n\nnearest particles, it tried to find a point which could be the alternative of\nparticle's personal best. This method prevented particle's attenuation and\nfollowing a specific particle by its neighbours. The performed tests on a\nnumber of benchmark functions clearly demonstrated that the improved algorithm\nis able to solve MMO problems and outperform other tested algorithms in this\narticle.\n", "versions": [{"version": "v1", "created": "Wed, 8 Oct 2014 10:48:03 GMT"}], "update_date": "2014-10-09", "authors_parsed": [["Rahkar-Farshi", "Taymaz", ""], ["Behjat-Jamal", "Sara", ""], ["Feizi-Derakhshi", "Mohammad-Reza", ""]]}, {"id": "1410.2063", "submitter": "Stefania  Costantini", "authors": "Stefania Costantini", "title": "Committment-Based Data-Aware Multi-Agent-Contexts Systems", "comments": "Draft of a paper submitted to an International Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication and interaction among agents have been the subject of extensive\ninvestigation since many years. Commitment-based communication, where\ncommunicating agents are seen as a debtor agent who is committed to a creditor\nagent to bring about something (possibly under some conditions) is now very\nwell-established. The approach of DACMAS (Data-Aware Commitment-based MAS)\nlifts commitment-related approaches proposed in the literature from a\npropositional to a first-order setting via the adoption the DRL-Lite\nDescription Logic. Notably, DACMASs provide, beyond commitments, simple forms\nof inter-agent event-based communication. Yet, the aspect is missing of making\na MAS able to acquire knowledge from contexts which are not agents and which\nare external to the MAS. This topic is coped with in Managed MCSs (Managed\nMulti-Context Systems), where however exchanges are among knowledge bases and\nnot agents. In this paper, we propose the new approach of DACmMCMASs\n(Data-Aware Commitment-based managed Multi- Context MAS), so as to obtain a\ncommitment-based first-order agent system which is able to interact with\nheterogeneous external information sources. We show that DACmMCMASs retain the\nnice formal properties of the original approaches.\n", "versions": [{"version": "v1", "created": "Wed, 8 Oct 2014 11:11:13 GMT"}], "update_date": "2014-10-09", "authors_parsed": [["Costantini", "Stefania", ""]]}, {"id": "1410.2442", "submitter": "Steven Schockaert", "authors": "Steven Schockaert and Sanjiang Li", "title": "Realizing RCC8 networks using convex regions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RCC8 is a popular fragment of the region connection calculus, in which\nqualitative spatial relations between regions, such as adjacency, overlap and\nparthood, can be expressed. While RCC8 is essentially dimensionless, most\ncurrent applications are confined to reasoning about two-dimensional or\nthree-dimensional physical space. In this paper, however, we are mainly\ninterested in conceptual spaces, which typically are high-dimensional Euclidean\nspaces in which the meaning of natural language concepts can be represented\nusing convex regions. The aim of this paper is to analyze how the restriction\nto convex regions constrains the realizability of networks of RCC8 relations.\nFirst, we identify all ways in which the set of RCC8 base relations can be\nrestricted to guarantee that consistent networks can be convexly realized in\nrespectively 1D, 2D, 3D, and 4D. Most surprisingly, we find that if the\nrelation 'partially overlaps' is disallowed, all consistent atomic RCC8\nnetworks can be convexly realized in 4D. If instead refinements of the relation\n'part of' are disallowed, all consistent atomic RCC8 relations can be convexly\nrealized in 3D. We furthermore show, among others, that any consistent RCC8\nnetwork with 2n+1 variables can be realized using convex regions in the\nn-dimensional Euclidean space.\n", "versions": [{"version": "v1", "created": "Thu, 9 Oct 2014 12:54:08 GMT"}, {"version": "v2", "created": "Fri, 17 Oct 2014 10:14:17 GMT"}], "update_date": "2014-10-20", "authors_parsed": [["Schockaert", "Steven", ""], ["Li", "Sanjiang", ""]]}, {"id": "1410.3125", "submitter": "Martin Mladenov", "authors": "Kristian Kersting, Martin Mladenov, Pavel Tokmakov", "title": "Relational Linear Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.PL math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose relational linear programming, a simple framework for combing\nlinear programs (LPs) and logic programs. A relational linear program (RLP) is\na declarative LP template defining the objective and the constraints through\nthe logical concepts of objects, relations, and quantified variables. This\nallows one to express the LP objective and constraints relationally for a\nvarying number of individuals and relations among them without enumerating\nthem. Together with a logical knowledge base, effectively a logical program\nconsisting of logical facts and rules, it induces a ground LP. This ground LP\nis solved using lifted linear programming. That is, symmetries within the\nground LP are employed to reduce its dimensionality, if possible, and the\nreduced program is solved using any off-the-shelf LP solver. In contrast to\nmainstream LP template languages like AMPL, which features a mixture of\ndeclarative and imperative programming styles, RLP's relational nature allows a\nmore intuitive representation of optimization problems over relational domains.\nWe illustrate this empirically by experiments on approximate inference in\nMarkov logic networks using LP relaxations, on solving Markov decision\nprocesses, and on collective inference using LP support vector machines.\n", "versions": [{"version": "v1", "created": "Sun, 12 Oct 2014 18:06:07 GMT"}], "update_date": "2014-10-14", "authors_parsed": [["Kersting", "Kristian", ""], ["Mladenov", "Martin", ""], ["Tokmakov", "Pavel", ""]]}, {"id": "1410.3726", "submitter": "Chee Seng Chan", "authors": "Chern Hong Lim, Anhar Risnumawan and Chee Seng Chan", "title": "Scene Image is Non-Mutually Exclusive - A Fuzzy Qualitative Scene\n  Understanding", "comments": "Accepted in IEEE Transactions on Fuzzy Systems", "journal-ref": "IEEE Transactions on Fuzzy Systems, vol. 22(6), pp. 1541 - 1556,\n  2014", "doi": "10.1109/TFUZZ.2014.2298233", "report-no": null, "categories": "cs.CV cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ambiguity or uncertainty is a pervasive element of many real world decision\nmaking processes. Variation in decisions is a norm in this situation when the\nsame problem is posed to different subjects. Psychological and metaphysical\nresearch had proven that decision making by human is subjective. It is\ninfluenced by many factors such as experience, age, background, etc. Scene\nunderstanding is one of the computer vision problems that fall into this\ncategory. Conventional methods relax this problem by assuming scene images are\nmutually exclusive; and therefore, focus on developing different approaches to\nperform the binary classification tasks. In this paper, we show that scene\nimages are non-mutually exclusive, and propose the Fuzzy Qualitative Rank\nClassifier (FQRC) to tackle the aforementioned problems. The proposed FQRC\nprovides a ranking interpretation instead of binary decision. Evaluations in\nterm of qualitative and quantitative using large numbers and challenging public\nscene datasets have shown the effectiveness of our proposed method in modeling\nthe non-mutually exclusive scene images.\n", "versions": [{"version": "v1", "created": "Tue, 14 Oct 2014 15:19:43 GMT"}], "update_date": "2014-12-02", "authors_parsed": [["Lim", "Chern Hong", ""], ["Risnumawan", "Anhar", ""], ["Chan", "Chee Seng", ""]]}, {"id": "1410.3862", "submitter": "James Balhoff", "authors": "James P. Balhoff, T. Alexander Dececchi, Paula M. Mabee, Hilmar Lapp", "title": "Presence-absence reasoning for evolutionary phenotypes", "comments": "4 pages. Peer-reviewed submission presented to the Bio-ontologies SIG\n  Phenotype Day at ISMB 2014, Boston, Mass.\n  http://phenoday2014.bio-lark.org/pdf/11.pdf", "journal-ref": "James P. Balhoff, T. Alexander Dececchi, Paula M. Mabee, Hilmar\n  Lapp. 2014. Presence-absence reasoning for evolutionary phenotypes. In\n  proceedings of Phenotype Day of the Bio-ontologies SIG at ISMB 2014", "doi": null, "report-no": null, "categories": "cs.AI q-bio.QM", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Nearly invariably, phenotypes are reported in the scientific literature in\nmeticulous detail, utilizing the full expressivity of natural language. Often\nit is particularly these detailed observations (facts) that are of interest,\nand thus specific to the research questions that motivated observing and\nreporting them. However, research aiming to synthesize or integrate phenotype\ndata across many studies or even fields is often faced with the need to\nabstract from detailed observations so as to construct phenotypic concepts that\nare common across many datasets rather than specific to a few. Yet,\nobservations or facts that would fall under such abstracted concepts are\ntypically not directly asserted by the original authors, usually because they\nare \"obvious\" according to common domain knowledge, and thus asserting them\nwould be deemed redundant by anyone with sufficient domain knowledge. For\nexample, a phenotype describing the length of a manual digit for an organism\nimplicitly means that the organism must have had a hand, and thus a forelimb;\nthe presence or absence of a forelimb may have supporting data across a far\nwider range of taxa than the length of a particular manual digit. Here we\ndescribe how within the Phenoscape project we use a pipeline of OWL axiom\ngeneration and reasoning steps to infer taxon-specific presence/absence of\nanatomical entities from anatomical phenotypes. Although presence/absence is\nall but one, and a seemingly simple way to abstract phenotypes across data\nsources, it can nonetheless be powerful for linking genotype to phenotype, and\nit is particularly relevant for constructing synthetic morphological\nsupermatrices for comparative analysis; in fact presence/absence is one of the\nprevailing character observation types in published character matrices.\n", "versions": [{"version": "v1", "created": "Tue, 14 Oct 2014 20:40:28 GMT"}], "update_date": "2014-10-16", "authors_parsed": [["Balhoff", "James P.", ""], ["Dececchi", "T. Alexander", ""], ["Mabee", "Paula M.", ""], ["Lapp", "Hilmar", ""]]}, {"id": "1410.3916", "submitter": "Jason  Weston", "authors": "Jason Weston, Sumit Chopra, Antoine Bordes", "title": "Memory Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We describe a new class of learning models called memory networks. Memory\nnetworks reason with inference components combined with a long-term memory\ncomponent; they learn how to use these jointly. The long-term memory can be\nread and written to, with the goal of using it for prediction. We investigate\nthese models in the context of question answering (QA) where the long-term\nmemory effectively acts as a (dynamic) knowledge base, and the output is a\ntextual response. We evaluate them on a large-scale QA task, and a smaller, but\nmore complex, toy task generated from a simulated world. In the latter, we show\nthe reasoning power of such models by chaining multiple supporting sentences to\nanswer questions that require understanding the intension of verbs.\n", "versions": [{"version": "v1", "created": "Wed, 15 Oct 2014 03:13:18 GMT"}, {"version": "v10", "created": "Tue, 19 May 2015 21:48:30 GMT"}, {"version": "v11", "created": "Sun, 29 Nov 2015 07:00:41 GMT"}, {"version": "v2", "created": "Thu, 16 Oct 2014 16:33:51 GMT"}, {"version": "v3", "created": "Sat, 20 Dec 2014 03:53:26 GMT"}, {"version": "v4", "created": "Wed, 24 Dec 2014 21:56:07 GMT"}, {"version": "v5", "created": "Wed, 21 Jan 2015 07:26:45 GMT"}, {"version": "v6", "created": "Sat, 7 Feb 2015 01:25:50 GMT"}, {"version": "v7", "created": "Wed, 25 Feb 2015 04:08:49 GMT"}, {"version": "v8", "created": "Sat, 7 Mar 2015 15:29:16 GMT"}, {"version": "v9", "created": "Thu, 9 Apr 2015 20:45:05 GMT"}], "update_date": "2015-12-01", "authors_parsed": [["Weston", "Jason", ""], ["Chopra", "Sumit", ""], ["Bordes", "Antoine", ""]]}, {"id": "1410.4182", "submitter": "Biju Issac", "authors": "J. R. Modapothala, and B. Issac", "title": "Analysis of corporate environmental reports using statistical techniques\n  and data mining", "comments": "8 pages", "journal-ref": "Communications of the IBIMA, 10(6), 32-38. (2009)", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring the effectiveness of corporate environmental reports, it being\nhighly qualitative and less regulated, is often considered as a daunting task.\nThe task becomes more complex if comparisons are to be performed. This study is\nundertaken to overcome the physical verification problems by implementing data\nmining technique. It further explores on the effectiveness by performing\nexploratory analysis and structural equation model to bring out the significant\nlinkages between the selected 10 variables. Samples of five hundred and thirty\nnine reports across various countries are used from an international directory\nto perform the statistical analysis like: One way ANOVA (Analysis of Variance),\nMDA (Multivariate Discriminant Analysis) and SEM (Structural Equation\nModeling). The results indicate the significant differences among the various\ntypes of industries in their environmental reporting, and the exploratory\nfactors like stakeholder, organization strategy and industrial oriented\nfactors, proved significant. The major accomplishment is that the findings\ncorrelate with the conceptual frame work of GRI.\n", "versions": [{"version": "v1", "created": "Wed, 8 Oct 2014 09:23:43 GMT"}], "update_date": "2014-10-16", "authors_parsed": [["Modapothala", "J. R.", ""], ["Issac", "B.", ""]]}, {"id": "1410.4604", "submitter": "Marlos C. Machado", "authors": "Marlos C. Machado, Sriram Srinivasan and Michael Bowling", "title": "Domain-Independent Optimistic Initialization for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Reinforcement Learning (RL), it is common to use optimistic initialization\nof value functions to encourage exploration. However, such an approach\ngenerally depends on the domain, viz., the scale of the rewards must be known,\nand the feature representation must have a constant norm. We present a simple\napproach that performs optimistic initialization with less dependence on the\ndomain.\n", "versions": [{"version": "v1", "created": "Thu, 16 Oct 2014 23:30:08 GMT"}], "update_date": "2014-10-20", "authors_parsed": [["Machado", "Marlos C.", ""], ["Srinivasan", "Sriram", ""], ["Bowling", "Michael", ""]]}, {"id": "1410.4615", "submitter": "Wojciech Zaremba", "authors": "Wojciech Zaremba, Ilya Sutskever", "title": "Learning to Execute", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) with Long Short-Term Memory units (LSTM) are\nwidely used because they are expressive and are easy to train. Our interest\nlies in empirically evaluating the expressiveness and the learnability of LSTMs\nin the sequence-to-sequence regime by training them to evaluate short computer\nprograms, a domain that has traditionally been seen as too complex for neural\nnetworks. We consider a simple class of programs that can be evaluated with a\nsingle left-to-right pass using constant memory. Our main result is that LSTMs\ncan learn to map the character-level representations of such programs to their\ncorrect outputs. Notably, it was necessary to use curriculum learning, and\nwhile conventional curriculum learning proved ineffective, we developed a new\nvariant of curriculum learning that improved our networks' performance in all\nexperimental conditions. The improved curriculum had a dramatic impact on an\naddition problem, making it possible to train an LSTM to add two 9-digit\nnumbers with 99% accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 17 Oct 2014 01:35:12 GMT"}, {"version": "v2", "created": "Sun, 21 Dec 2014 03:46:49 GMT"}, {"version": "v3", "created": "Thu, 19 Feb 2015 15:33:35 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Zaremba", "Wojciech", ""], ["Sutskever", "Ilya", ""]]}, {"id": "1410.5078", "submitter": "Paolo Pareti Mr.", "authors": "Paolo Pareti and Ewan Klein", "title": "Learning Vague Concepts for the Semantic Web", "comments": "The 10th International Semantic Web Conference (ISWC 2011), Joint\n  Workshop on Knowledge Evolution and Ontology Dynamics. Bonn, Germany (2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Ontologies can be a powerful tool for structuring knowledge, and they are\ncurrently the subject of extensive research. Updating the contents of an\nontology or improving its interoperability with other ontologies is an\nimportant but difficult process. In this paper, we focus on the presence of\nvague concepts, which are pervasive in natural language, within the framework\nof formal ontologies. We will adopt a framework in which vagueness is captured\nvia numerical restrictions that can be automatically adjusted. Since updating\nvague concepts, either through ontology alignment or ontology evolution, can\nlead to inconsistent sets of axioms, we define and implement a method to\ndetecting and repairing such inconsistencies in a local fashion.\n", "versions": [{"version": "v1", "created": "Sun, 19 Oct 2014 14:34:23 GMT"}], "update_date": "2014-10-21", "authors_parsed": [["Pareti", "Paolo", ""], ["Klein", "Ewan", ""]]}, {"id": "1410.5215", "submitter": "Artem Revenko", "authors": "Sergei O. Kuznetsov and Artem Revenko", "title": "Interactive Error Correction in Implicative Theories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Errors in implicative theories coming from binary data are studied. First,\ntwo classes of errors that may affect implicative theories are singled out. Two\napproaches for finding errors of these classes are proposed, both of them based\non methods of Formal Concept Analysis. The first approach uses the cardinality\nminimal (canonical or Duquenne-Guigues) implication base. The construction of\nsuch a base is computationally intractable. Using an alternative approach one\nchecks possible errors on the fly in polynomial time via computing closures of\nsubsets of attributes. Both approaches are interactive, based on questions\nabout the validity of certain implications. Results of computer experiments are\npresented and discussed.\n", "versions": [{"version": "v1", "created": "Mon, 20 Oct 2014 10:04:39 GMT"}], "update_date": "2014-10-21", "authors_parsed": [["Kuznetsov", "Sergei O.", ""], ["Revenko", "Artem", ""]]}, {"id": "1410.5476", "submitter": "Josef Urban", "authors": "Cezary Kaliszyk, Josef Urban, Jiri Vyskocil", "title": "Certified Connection Tableaux Proofs for HOL Light and TPTP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent years, the Metis prover based on ordered paramodulation and\nmodel elimination has replaced the earlier built-in methods for general-purpose\nproof automation in HOL4 and Isabelle/HOL. In the annual CASC competition, the\nleanCoP system based on connection tableaux has however performed better than\nMetis. In this paper we show how the leanCoP's core algorithm can be\nimplemented inside HOLLight. leanCoP's flagship feature, namely its\nminimalistic core, results in a very simple proof system. This plays a crucial\nrole in extending the MESON proof reconstruction mechanism to connection\ntableaux proofs, providing an implementation of leanCoP that certifies its\nproofs. We discuss the differences between our direct implementation using an\nexplicit Prolog stack, to the continuation passing implementation of MESON\npresent in HOLLight and compare their performance on all core HOLLight goals.\nThe resulting prover can be also used as a general purpose TPTP prover. We\ncompare its performance against the resolution based Metis on TPTP and other\ninteresting datasets.\n", "versions": [{"version": "v1", "created": "Mon, 20 Oct 2014 21:36:47 GMT"}], "update_date": "2014-10-22", "authors_parsed": [["Kaliszyk", "Cezary", ""], ["Urban", "Josef", ""], ["Vyskocil", "Jiri", ""]]}, {"id": "1410.5557", "submitter": "Matthias Rolf", "authors": "Matthias Rolf and Minoru Asada", "title": "Where do goals come from? A Generic Approach to Autonomous Goal-System\n  Development", "comments": "Draft submitted to IEEE Transactions on Autonomous Mental Development\n  (TAMD)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goals express agents' intentions and allow them to organize their behavior\nbased on low-dimensional abstractions of high-dimensional world states. How can\nagents develop such goals autonomously? This paper proposes a detailed\nconceptual and computational account to this longstanding problem. We argue to\nconsider goals as high-level abstractions of lower-level intention mechanisms\nsuch as rewards and values, and point out that goals need to be considered\nalongside with a detection of the own actions' effects. We propose Latent Goal\nAnalysis as a computational learning formulation thereof, and show\nconstructively that any reward or value function can by explained by goals and\nsuch self-detection as latent mechanisms. We first show that learned goals\nprovide a highly effective dimensionality reduction in a practical\nreinforcement learning problem. Then, we investigate a developmental scenario\nin which entirely task-unspecific rewards induced by visual saliency lead to\nself and goal representations that constitute goal-directed reaching.\n", "versions": [{"version": "v1", "created": "Tue, 21 Oct 2014 07:24:03 GMT"}], "update_date": "2014-10-22", "authors_parsed": [["Rolf", "Matthias", ""], ["Asada", "Minoru", ""]]}, {"id": "1410.5614", "submitter": "Nick Bassiliades", "authors": "Thanos G. Stavropoulos, Stelios Andreadis, Nick Bassiliades, Dimitris\n  Vrakas and Ioannis Vlahavas", "title": "The Tomaco Hybrid Matching Framework for SAWSDL Semantic Web Services", "comments": "Under review. Keywords: Web Services Discovery, Intelligent Web\n  Services and Semantic Web, Internet reasoning services, Web-based services", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work aims to resolve issues related to Web Service retrieval, also known\nas Service Selection, Discovery or essentially Matching, in two directions.\nFirstly, a novel matching algorithm for SAWSDL is introduced. The algorithm is\nhybrid in nature, combining novel and known concepts, such as a logic-based\nstrategy and syntactic text-similarity measures on semantic annotations and\ntextual descriptions. A plugin for the S3 contest environment was developed, in\norder to position Tomaco amongst state-of-the-art in an objective, reproducible\nmanner. Evaluation showed that Tomaco ranks high amongst state of the art,\nespecially for early recall levels. Secondly, this work introduces the Tomaco\nweb application, which aims to accelerate the wide-spread adoption of Semantic\nWeb Service technologies and algorithms while targeting the lack of\nuser-friendly applications in this field. Tomaco integrates a variety of\nconfigurable matching algorithms proposed in this paper. It, finally, allows\ndiscovery of both existing and user-contributed service collections and\nontologies, serving also as a service registry.\n", "versions": [{"version": "v1", "created": "Tue, 21 Oct 2014 10:51:35 GMT"}], "update_date": "2014-10-22", "authors_parsed": [["Stavropoulos", "Thanos G.", ""], ["Andreadis", "Stelios", ""], ["Bassiliades", "Nick", ""], ["Vrakas", "Dimitris", ""], ["Vlahavas", "Ioannis", ""]]}, {"id": "1410.5738", "submitter": "Debdipta Goswami", "authors": "Debdipta Goswami and Heiko Hamann", "title": "Investigation of A Collective Decision Making System of Different\n  Neighbourhood-Size Based on Hyper-Geometric Distribution", "comments": "9 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of collective decision making system has become the central part of\nthe Swarm- Intelligence Related research in recent years. The most challenging\ntask of modelling a collec- tive decision making system is to develop the\nmacroscopic stochastic equation from its microscopic model. In this report we\nhave investigated the behaviour of a collective decision making system with\nspecified microscopic rules that resemble the chemical reaction and used\ndifferent group size. Then we ventured to derive a generalized analytical model\nof a collective-decision system using hyper-geometric distribution.\n  Index Terms-swarm; collective decision making; noise; group size;\nhyper-geometric distribution\n", "versions": [{"version": "v1", "created": "Tue, 21 Oct 2014 16:48:52 GMT"}], "update_date": "2014-10-22", "authors_parsed": [["Goswami", "Debdipta", ""], ["Hamann", "Heiko", ""]]}, {"id": "1410.5792", "submitter": "Andrey Bogomolov", "authors": "Andrey Bogomolov, Bruno Lepri, Fabio Pianesi", "title": "Generalized Compression Dictionary Distance as Universal Similarity\n  Measure", "comments": "2014 Conference on Big Data from Space (BiDS 14)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new similarity measure based on information theoretic measures\nwhich is superior than Normalized Compression Distance for clustering problems\nand inherits the useful properties of conditional Kolmogorov complexity. We\nshow that Normalized Compression Dictionary Size and Normalized Compression\nDictionary Entropy are computationally more efficient, as the need to perform\nthe compression itself is eliminated. Also they scale linearly with exponential\nvector size growth and are content independent. We show that normalized\ncompression dictionary distance is compressor independent, if limited to\nlossless compressors, which gives space for optimizations and implementation\nspeed improvement for real-time and big data applications. The introduced\nmeasure is applicable for machine learning tasks of parameter-free unsupervised\nclustering, supervised learning such as classification and regression, feature\nselection, and is applicable for big data problems with order of magnitude\nspeed increase.\n", "versions": [{"version": "v1", "created": "Tue, 21 Oct 2014 19:17:19 GMT"}], "update_date": "2014-10-22", "authors_parsed": [["Bogomolov", "Andrey", ""], ["Lepri", "Bruno", ""], ["Pianesi", "Fabio", ""]]}, {"id": "1410.5859", "submitter": "Ramanathan Guha", "authors": "Ramanathan Guha", "title": "Towards a Model Theory for Distributed Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed representations (such as those based on embeddings) and discrete\nrepresentations (such as those based on logic) have complementary strengths. We\nexplore one possible approach to combining these two kinds of representations.\nWe present a model theory/semantics for first order logic based on vectors of\nreals. We describe the model theory, discuss some interesting properties of\nsuch a system and present a simple approach to query answering.\n", "versions": [{"version": "v1", "created": "Tue, 21 Oct 2014 21:15:45 GMT"}, {"version": "v2", "created": "Thu, 30 Oct 2014 13:43:31 GMT"}, {"version": "v3", "created": "Thu, 5 Feb 2015 03:06:09 GMT"}], "update_date": "2015-02-06", "authors_parsed": [["Guha", "Ramanathan", ""]]}, {"id": "1410.5996", "submitter": "Vladimir V'yugin", "authors": "Vladimir V'yugin", "title": "Log-Optimal Portfolio Selection Using the Blackwell Approachability\n  Theorem", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for constructing the log-optimal portfolio using the\nwell-calibrated forecasts of market values. Dawid's notion of calibration and\nthe Blackwell approachability theorem are used for computing well-calibrated\nforecasts. We select a portfolio using this \"artificial\" probability\ndistribution of market values. Our portfolio performs asymptotically at least\nas well as any stationary portfolio that redistributes the investment at each\nround using a continuous function of side information. Unlike in classical\nmathematical finance theory, no stochastic assumptions are made about market\nvalues.\n", "versions": [{"version": "v1", "created": "Wed, 22 Oct 2014 11:05:17 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2015 11:25:49 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["V'yugin", "Vladimir", ""]]}, {"id": "1410.6142", "submitter": "Mark Riedl", "authors": "Mark O. Riedl", "title": "The Lovelace 2.0 Test of Artificial Creativity and Intelligence", "comments": "2 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Observing that the creation of certain types of artistic artifacts\nnecessitate intelligence, we present the Lovelace 2.0 Test of creativity as an\nalternative to the Turing Test as a means of determining whether an agent is\nintelligent. The Lovelace 2.0 Test builds off prior tests of creativity and\nadditionally provides a means of directly comparing the relative intelligence\nof different agents.\n", "versions": [{"version": "v1", "created": "Wed, 22 Oct 2014 18:59:31 GMT"}, {"version": "v2", "created": "Thu, 23 Oct 2014 15:09:53 GMT"}, {"version": "v3", "created": "Mon, 22 Dec 2014 03:24:06 GMT"}], "update_date": "2014-12-23", "authors_parsed": [["Riedl", "Mark O.", ""]]}, {"id": "1410.6414", "submitter": "Jingbo Shang", "authors": "Jingbo Shang, Tianqi Chen, Hang Li, Zhengdong Lu, Yong Yu", "title": "A Parallel and Efficient Algorithm for Learning to Match", "comments": "10 pages, short version was published in ICDM 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many tasks in data mining and related fields can be formalized as matching\nbetween objects in two heterogeneous domains, including collaborative\nfiltering, link prediction, image tagging, and web search. Machine learning\ntechniques, referred to as learning-to-match in this paper, have been\nsuccessfully applied to the problems. Among them, a class of state-of-the-art\nmethods, named feature-based matrix factorization, formalize the task as an\nextension to matrix factorization by incorporating auxiliary features into the\nmodel. Unfortunately, making those algorithms scale to real world problems is\nchallenging, and simple parallelization strategies fail due to the complex\ncross talking patterns between sub-tasks. In this paper, we tackle this\nchallenge with a novel parallel and efficient algorithm for feature-based\nmatrix factorization. Our algorithm, based on coordinate descent, can easily\nhandle hundreds of millions of instances and features on a single machine. The\nkey recipe of this algorithm is an iterative relaxation of the objective to\nfacilitate parallel updates of parameters, with guaranteed convergence on\nminimizing the original objective function. Experimental results demonstrate\nthat the proposed method is effective on a wide range of matching problems,\nwith efficiency significantly improved upon the baselines while accuracy\nretained unchanged.\n", "versions": [{"version": "v1", "created": "Wed, 22 Oct 2014 01:04:00 GMT"}], "update_date": "2014-10-24", "authors_parsed": [["Shang", "Jingbo", ""], ["Chen", "Tianqi", ""], ["Li", "Hang", ""], ["Lu", "Zhengdong", ""], ["Yu", "Yong", ""]]}, {"id": "1410.6519", "submitter": "David Tolpin", "authors": "David Tolpin", "title": "Justifying and Improving Meta-Agent Conflict-Based Search", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Meta-Agent Conflict-Based Search~(MA-CBS) is a recently proposed\nalgorithm for the multi-agent path finding problem. The algorithm is an\nextension of Conflict-Based Search~(CBS), which automatically merges\nconflicting agents into meta-agents if the number of conflicts exceeds a\ncertain threshold. However, the decision to merge agents is made according to\nan empirically chosen fixed threshold on the number of conflicts. The best\nthreshold depends both on the domain and on the number of agents, and the\nnature of the dependence is not clearly understood.\n  We suggest a justification for the use of a fixed threshold on the number of\nconflicts based on the analysis of a model problem. Following the suggested\njustification, we introduce new decision policies for the MA-CBS algorithm,\nwhich considerably improve the algorithm's performance. The improved variants\nof the algorithm are evaluated on several sets of problems, chosen to underline\ndifferent aspects of the algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 23 Oct 2014 22:50:35 GMT"}], "update_date": "2014-10-27", "authors_parsed": [["Tolpin", "David", ""]]}, {"id": "1410.6641", "submitter": "Paul Swoboda", "authors": "Paul Swoboda, Alexander Shekhovtsov, J\\\"org Hendrik Kappes, Christoph\n  Schn\\\"orr and Bogdan Savchynskyy", "title": "Partial Optimality by Pruning for MAP-Inference with General Graphical\n  Models", "comments": "16 pages, 4 tables and 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the energy minimization problem for undirected graphical models,\nalso known as MAP-inference problem for Markov random fields which is NP-hard\nin general. We propose a novel polynomial time algorithm to obtain a part of\nits optimal non-relaxed integral solution. Our algorithm is initialized with\nvariables taking integral values in the solution of a convex relaxation of the\nMAP-inference problem and iteratively prunes those, which do not satisfy our\ncriterion for partial optimality. We show that our pruning strategy is in a\ncertain sense theoretically optimal. Also empirically our method outperforms\nprevious approaches in terms of the number of persistently labelled variables.\nThe method is very general, as it is applicable to models with arbitrary\nfactors of an arbitrary order and can employ any solver for the considered\nrelaxed problem. Our method's runtime is determined by the runtime of the\nconvex relaxation solver for the MAP-inference problem.\n", "versions": [{"version": "v1", "created": "Fri, 24 Oct 2014 10:32:18 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2015 06:40:57 GMT"}], "update_date": "2015-08-19", "authors_parsed": [["Swoboda", "Paul", ""], ["Shekhovtsov", "Alexander", ""], ["Kappes", "J\u00f6rg Hendrik", ""], ["Schn\u00f6rr", "Christoph", ""], ["Savchynskyy", "Bogdan", ""]]}, {"id": "1410.6671", "submitter": "Yong Lai", "authors": "Yong Lai, Dayou Liu, Minghao Yin", "title": "Augmenting Ordered Binary Decision Diagrams with Conjunctive\n  Decomposition", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper augments OBDD with conjunctive decomposition to propose a\ngeneralization called OBDD[$\\wedge$]. By imposing reducedness and the finest\n$\\wedge$-decomposition bounded by integer $i$\n($\\wedge_{\\widehat{i}}$-decomposition) on OBDD[$\\wedge$], we identify a family\nof canonical languages called ROBDD[$\\wedge_{\\widehat{i}}$], where\nROBDD[$\\wedge_{\\widehat{0}}$] is equivalent to ROBDD. We show that the\nsuccinctness of ROBDD[$\\wedge_{\\widehat{i}}$] is strictly increasing when $i$\nincreases. We introduce a new time-efficiency criterion called rapidity which\nreflects that exponential operations may be preferable if the language can be\nexponentially more succinct, and show that: the rapidity of each operation on\nROBDD[$\\wedge_{\\widehat{i}}$] is increasing when $i$ increases; particularly,\nthe rapidity of some operations (e.g., conjoining) is strictly increasing.\nFinally, our empirical results show that: a) the size of\nROBDD[$\\wedge_{\\widehat{i}}$] is normally not larger than that of the\nequivalent \\ROBDDC{\\widehat{i+1}}; b) conjoining two\nROBDD[$\\wedge_{\\widehat{1}}$]s is more efficient than conjoining two\nROBDD[$\\wedge_{\\widehat{0}}$]s in most cases, where the former is NP-hard but\nthe latter is in P; and c) the space-efficiency of\nROBDD[$\\wedge_{\\widehat{\\infty}}$] is comparable with that of d-DNNF and that\nof another canonical generalization of \\ROBDD{} called SDD.\n", "versions": [{"version": "v1", "created": "Fri, 24 Oct 2014 13:07:53 GMT"}], "update_date": "2014-10-27", "authors_parsed": [["Lai", "Yong", ""], ["Liu", "Dayou", ""], ["Yin", "Minghao", ""]]}, {"id": "1410.6690", "submitter": "Emmanuel Lonca", "authors": "Daniel Le Berre and Emmanuel Lonca and Pierre Marquis", "title": "On the Complexity of Optimization Problems based on Compiled NNF\n  Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization is a key task in a number of applications. When the set of\nfeasible solutions under consideration is of combinatorial nature and described\nin an implicit way as a set of constraints, optimization is typically NP-hard.\nFortunately, in many problems, the set of feasible solutions does not often\nchange and is independent from the user's request. In such cases, compiling the\nset of constraints describing the set of feasible solutions during an off-line\nphase makes sense, if this compilation step renders computationally easier the\ngeneration of a non-dominated, yet feasible solution matching the user's\nrequirements and preferences (which are only known at the on-line step). In\nthis article, we focus on propositional constraints. The subsets L of the NNF\nlanguage analyzed in Darwiche and Marquis' knowledge compilation map are\nconsidered. A number of families F of representations of objective functions\nover propositional variables, including linear pseudo-Boolean functions and\nmore sophisticated ones, are considered. For each language L and each family F,\nthe complexity of generating an optimal solution when the constraints are\ncompiled into L and optimality is to be considered w.r.t. a function from F is\nidentified.\n", "versions": [{"version": "v1", "created": "Fri, 24 Oct 2014 14:26:04 GMT"}], "update_date": "2014-10-27", "authors_parsed": [["Berre", "Daniel Le", ""], ["Lonca", "Emmanuel", ""], ["Marquis", "Pierre", ""]]}, {"id": "1410.6854", "submitter": "Diederik Aerts", "authors": "Diederik Aerts, Sandro Sozzo and Tomas Veloz", "title": "The Quantum Nature of Identity in Human Thought: Bose-Einstein\n  Statistics for Conceptual Indistinguishability", "comments": "12 pages", "journal-ref": "International Journal of Theoretical Physics, 54, pp 4430-4443,\n  2015", "doi": "10.1007/s10773-015-2620-4", "report-no": null, "categories": "cs.AI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing experimental evidence shows that humans combine concepts in a way\nthat violates the rules of classical logic and probability theory. On the other\nhand, mathematical models inspired by the formalism of quantum theory are in\naccordance with data on concepts and their combinations. In this paper, we\ninvestigate a novel type of concept combination were a number is combined with\na noun, e.g., `Eleven Animals. Our aim is to study 'conceptual identity' and\nthe effects of 'indistinguishability' - in the combination 'Eleven Animals',\nthe 'animals' are identical and indistinguishable - on the mechanisms of\nconceptual combination. We perform experiments on human subjects and find\nsignificant evidence of deviation from the predictions of classical statistical\ntheories, more specifically deviations with respect to Maxwell-Boltzmann\nstatistics. This deviation is of the 'same type' of the deviation of quantum\nmechanical from classical mechanical statistics, due to indistinguishability of\nmicroscopic quantum particles, i.e we find convincing evidence of the presence\nof Bose-Einstein statistics. We also present preliminary promising evidence of\nthis phenomenon in a web-based study.\n", "versions": [{"version": "v1", "created": "Fri, 24 Oct 2014 23:51:41 GMT"}], "update_date": "2015-12-31", "authors_parsed": [["Aerts", "Diederik", ""], ["Sozzo", "Sandro", ""], ["Veloz", "Tomas", ""]]}, {"id": "1410.6960", "submitter": "Vilem Vychodil", "authors": "Vilem Vychodil", "title": "Parameterizing the semantics of fuzzy attribute implications by systems\n  of isotone Galois connections", "comments": null, "journal-ref": "IEEE Trans. Fuzzy Systems 24(3): 645-660 (2016)", "doi": "10.1109/TFUZZ.2015.2470530", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the semantics of fuzzy if-then rules called fuzzy attribute\nimplications parameterized by systems of isotone Galois connections. The rules\nexpress dependencies between fuzzy attributes in object-attribute incidence\ndata. The proposed parameterizations are general and include as special cases\nthe parameterizations by linguistic hedges used in earlier approaches. We\nformalize the general parameterizations, propose bivalent and graded notions of\nsemantic entailment of fuzzy attribute implications, show their\ncharacterization in terms of least models and complete axiomatization, and\nprovide characterization of bases of fuzzy attribute implications derived from\ndata.\n", "versions": [{"version": "v1", "created": "Sat, 25 Oct 2014 20:53:10 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Vychodil", "Vilem", ""]]}, {"id": "1410.7063", "submitter": "Sander Beckers", "authors": "Sander Beckers and Joost Vennekens", "title": "Towards a General Framework for Actual Causation Using CP-logic", "comments": "http://ceur-ws.org/Vol-1413/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since Pearl's seminal work on providing a formal language for causality, the\nsubject has garnered a lot of interest among philosophers and researchers in\nartificial intelligence alike. One of the most debated topics in this context\nregards the notion of actual causation, which concerns itself with specific -\nas opposed to general - causal claims. The search for a proper formal\ndefinition of actual causation has evolved into a controversial debate, that is\npervaded with ambiguities and confusion. The goal of our research is twofold.\nFirst, we wish to provide a clear way to compare competing definitions. Second,\nwe also want to improve upon these definitions so they can be applied to a more\ndiverse range of instances, including non-deterministic ones. To achieve these\ngoals we will provide a general, abstract definition of actual causation,\nformulated in the context of the expressive language of CP-logic (Causal\nProbabilistic logic). We will then show that three recent definitions by Ned\nHall (originally formulated for structural models) and a definition of our own\n(formulated for CP-logic directly) can be viewed and directly compared as\ninstantiations of this abstract definition, which allows them to deal with a\nbroader range of examples.\n", "versions": [{"version": "v1", "created": "Sun, 26 Oct 2014 17:30:36 GMT"}, {"version": "v2", "created": "Thu, 27 Nov 2014 15:57:58 GMT"}, {"version": "v3", "created": "Thu, 29 Oct 2015 14:05:54 GMT"}], "update_date": "2015-10-30", "authors_parsed": [["Beckers", "Sander", ""], ["Vennekens", "Joost", ""]]}, {"id": "1410.7100", "submitter": "Harris Georgiou", "authors": "Harris V. Georgiou", "title": "Estimating the intrinsic dimension in fMRI space via dataset fractal\n  analysis - Counting the `cpu cores' of the human brain", "comments": "27 pages, 10 figures, 2 tables, 47 references", "journal-ref": null, "doi": null, "report-no": "HG/AI.1014.27v1 (draft/preprint)", "categories": "cs.AI cs.CV q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Functional Magnetic Resonance Imaging (fMRI) is a powerful non-invasive tool\nfor localizing and analyzing brain activity. This study focuses on one very\nimportant aspect of the functional properties of human brain, specifically the\nestimation of the level of parallelism when performing complex cognitive tasks.\nUsing fMRI as the main modality, the human brain activity is investigated\nthrough a purely data-driven signal processing and dimensionality analysis\napproach. Specifically, the fMRI signal is treated as a multi-dimensional data\nspace and its intrinsic `complexity' is studied via dataset fractal analysis\nand blind-source separation (BSS) methods. One simulated and two real fMRI\ndatasets are used in combination with Independent Component Analysis (ICA) and\nfractal analysis for estimating the intrinsic (true) dimensionality, in order\nto provide data-driven experimental evidence on the number of independent brain\nprocesses that run in parallel when visual or visuo-motor tasks are performed.\nAlthough this number is can not be defined as a strict threshold but rather as\na continuous range, when a specific activation level is defined, a\ncorresponding number of parallel processes or the casual equivalent of `cpu\ncores' can be detected in normal human brain activity.\n", "versions": [{"version": "v1", "created": "Mon, 27 Oct 2014 00:25:24 GMT"}], "update_date": "2014-10-28", "authors_parsed": [["Georgiou", "Harris V.", ""]]}, {"id": "1410.7223", "submitter": "Felix Diaz Hermida", "authors": "Felix Diaz-Hermida, Alberto Bugarin, David E. Losada", "title": "The probatilistic Quantifier Fuzzification Mechanism FA: A theoretical\n  analysis", "comments": "58 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main goal of this work is to analyze the behaviour of the FA quantifier\nfuzzification mechanism. As we prove in the paper, this model has a very solid\ntheorethical behaviour, superior to most of the models defined in the\nliterature. Moreover, we show that the underlying probabilistic interpretation\nhas very interesting consequences.\n", "versions": [{"version": "v1", "created": "Mon, 27 Oct 2014 13:12:43 GMT"}], "update_date": "2014-10-28", "authors_parsed": [["Diaz-Hermida", "Felix", ""], ["Bugarin", "Alberto", ""], ["Losada", "David E.", ""]]}, {"id": "1410.7265", "submitter": "Balint Antal", "authors": "Balint Antal, Bence Remenyik, Andras Hajdu", "title": "An Unsupervised Ensemble-based Markov Random Field Approach to\n  Microscope Cell Image Segmentation", "comments": null, "journal-ref": "Proceeingds of the 10th International Conference on Signal\n  Processing and Multimedia Applications (SIGMAP 2013), Reykjavik, Iceland,\n  2013, pp. 94-99", "doi": "10.5220/0004612900940099", "report-no": null, "categories": "cs.CV cs.AI q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an approach to the unsupervised segmentation of\nimages using Markov Random Field. The proposed approach is based on the idea of\nBit Plane Slicing. We use the planes as initial labellings for an ensemble of\nsegmentations. With pixelwise voting, a robust segmentation approach can be\nachieved, which we demonstrate on microscope cell images. We tested our\napproach on a publicly available database, where it proven to be competitive\nwith other methods and manual segmentation.\n", "versions": [{"version": "v1", "created": "Mon, 27 Oct 2014 14:58:28 GMT"}], "update_date": "2014-10-29", "authors_parsed": [["Antal", "Balint", ""], ["Remenyik", "Bence", ""], ["Hajdu", "Andras", ""]]}, {"id": "1410.7452", "submitter": "Varun Jampani", "authors": "Varun Jampani, S. M. Ali Eslami, Daniel Tarlow, Pushmeet Kohli and\n  John Winn", "title": "Consensus Message Passing for Layered Graphical Models", "comments": "Appearing in Proceedings of the 18th International Conference on\n  Artificial Intelligence and Statistics (AISTATS) 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Generative models provide a powerful framework for probabilistic reasoning.\nHowever, in many domains their use has been hampered by the practical\ndifficulties of inference. This is particularly the case in computer vision,\nwhere models of the imaging process tend to be large, loopy and layered. For\nthis reason bottom-up conditional models have traditionally dominated in such\ndomains. We find that widely-used, general-purpose message passing inference\nalgorithms such as Expectation Propagation (EP) and Variational Message Passing\n(VMP) fail on the simplest of vision models. With these models in mind, we\nintroduce a modification to message passing that learns to exploit their\nlayered structure by passing 'consensus' messages that guide inference towards\ngood solutions. Experiments on a variety of problems show that the proposed\ntechnique leads to significantly more accurate inference results, not only when\ncompared to standard EP and VMP, but also when compared to competitive\nbottom-up conditional models.\n", "versions": [{"version": "v1", "created": "Mon, 27 Oct 2014 22:40:52 GMT"}, {"version": "v2", "created": "Mon, 26 Jan 2015 21:36:36 GMT"}], "update_date": "2015-01-28", "authors_parsed": [["Jampani", "Varun", ""], ["Eslami", "S. M. Ali", ""], ["Tarlow", "Daniel", ""], ["Kohli", "Pushmeet", ""], ["Winn", "John", ""]]}, {"id": "1410.7690", "submitter": "Yu-Xiang Wang", "authors": "Yu-Xiang Wang, James Sharpnack, Alex Smola, Ryan J. Tibshirani", "title": "Trend Filtering on Graphs", "comments": "A short version appeared in AISTATS'2015", "journal-ref": "Journal of Machine Learning Research Volume (2016) Volume 17\n  Article 15-147", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a family of adaptive estimators on graphs, based on penalizing\nthe $\\ell_1$ norm of discrete graph differences. This generalizes the idea of\ntrend filtering [Kim et al. (2009), Tibshirani (2014)], used for univariate\nnonparametric regression, to graphs. Analogous to the univariate case, graph\ntrend filtering exhibits a level of local adaptivity unmatched by the usual\n$\\ell_2$-based graph smoothers. It is also defined by a convex minimization\nproblem that is readily solved (e.g., by fast ADMM or Newton algorithms). We\ndemonstrate the merits of graph trend filtering through examples and theory.\n", "versions": [{"version": "v1", "created": "Tue, 28 Oct 2014 16:22:32 GMT"}, {"version": "v2", "created": "Wed, 12 Nov 2014 01:21:54 GMT"}, {"version": "v3", "created": "Fri, 24 Apr 2015 06:16:02 GMT"}, {"version": "v4", "created": "Wed, 12 Aug 2015 00:42:15 GMT"}, {"version": "v5", "created": "Sat, 4 Jun 2016 17:03:24 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Wang", "Yu-Xiang", ""], ["Sharpnack", "James", ""], ["Smola", "Alex", ""], ["Tibshirani", "Ryan J.", ""]]}, {"id": "1410.7827", "submitter": "Yanshuai Cao", "authors": "Yanshuai Cao, David J. Fleet", "title": "Generalized Product of Experts for Automatic and Principled Fusion of\n  Gaussian Process Predictions", "comments": "Modern Nonparametrics 3: Automating the Learning Pipeline workshop at\n  NIPS 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a generalized product of experts (gPoE) framework\nfor combining the predictions of multiple probabilistic models. We identify\nfour desirable properties that are important for scalability, expressiveness\nand robustness, when learning and inferring with a combination of multiple\nmodels. Through analysis and experiments, we show that gPoE of Gaussian\nprocesses (GP) have these qualities, while no other existing combination\nschemes satisfy all of them at the same time. The resulting GP-gPoE is highly\nscalable as individual GP experts can be independently learned in parallel;\nvery expressive as the way experts are combined depends on the input rather\nthan fixed; the combined prediction is still a valid probabilistic model with\nnatural interpretation; and finally robust to unreliable predictions from\nindividual experts.\n", "versions": [{"version": "v1", "created": "Tue, 28 Oct 2014 22:04:30 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2015 03:12:57 GMT"}], "update_date": "2015-11-25", "authors_parsed": [["Cao", "Yanshuai", ""], ["Fleet", "David J.", ""]]}, {"id": "1410.7849", "submitter": "Andrew Connor", "authors": "A.M.Connor", "title": "A mutli-thread tabu search algorithm", "comments": null, "journal-ref": "Design Optimization: International Journal of Product and Process\n  Improvement, 1(3), 293-304, 1999", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a novel refinement to a Tabu search algorithm that has\nbeen implemented in an attempt to improve the robustness of the search when\napplied to particularly complex problems. In this approach, two Tabu searches\nare carried out in parallel. Each search thread is characterised by it's own\nshort term memory which forces that point out of local optima. However, the two\nsearch threads share an intermediate term memory so allowing a degree of\ninformation to be passed between them. Results are presented for both\nunconstrained and constrained numerical functions as well as a problem in the\nfield of hydraulic circuit optimization. Simulation of hydraulic circuit\nperformance is achieved by linking the optimization algorithm to the commercial\nsimulation package Bathfp.\n", "versions": [{"version": "v1", "created": "Wed, 29 Oct 2014 01:04:58 GMT"}], "update_date": "2014-10-30", "authors_parsed": [["Connor", "A. M.", ""]]}, {"id": "1410.7851", "submitter": "Andrew Connor", "authors": "Andy M. Connor, Keith A. Seffen, Geoffrey T. Parks and P. John\n  Clarkson", "title": "Efficient optimisation of structures using tabu search", "comments": null, "journal-ref": "Connor, A.M., Seffen, K.A., Clarkson, P.J. & Parks, G.T. (1999)\n  \"Efficient optimisation of structures using tabu search\" Proceedings of the\n  1st ASMO/ISSMO Conference on Engineering Design Optimization, 127-134", "doi": null, "report-no": null, "categories": "cs.CE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach to the optimisation of structures using\na Tabu search (TS) method. TS is a metaheuristic which is used to guide local\nsearch methods towards a globally optimal solution by using flexible memory\ncycles of differing time spans. Results are presented for the well established\nten bar truss problem and compared to results published in the literature. In\nthe first example a truss is optimised to minimise mass and the results\ncompared to results obtained using an alternative TS implementation. In the\nsecond example, the problem has multiple objectives that are compounded into a\nsingle objective function value using game theory. In general the results\ndemonstrate that the TS method is capable of solving structural optimisation\nproblems at least as efficiently as other numerical optimisation approaches.\n", "versions": [{"version": "v1", "created": "Wed, 29 Oct 2014 01:11:14 GMT"}], "update_date": "2014-10-30", "authors_parsed": [["Connor", "Andy M.", ""], ["Seffen", "Keith A.", ""], ["Parks", "Geoffrey T.", ""], ["Clarkson", "P. John", ""]]}, {"id": "1410.7856", "submitter": "Lirong Xia", "authors": "Hossein Azari Soufiani, David C. Parkes, Lirong Xia", "title": "A Statistical Decision-Theoretic Framework for Social Choice", "comments": "Full version of a NIPS-14 paper under the same title, fixed a typo in\n  Theorem 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we take a statistical decision-theoretic viewpoint on social\nchoice, putting a focus on the decision to be made on behalf of a system of\nagents. In our framework, we are given a statistical ranking model, a decision\nspace, and a loss function defined on (parameter, decision) pairs, and\nformulate social choice mechanisms as decision rules that minimize expected\nloss. This suggests a general framework for the design and analysis of new\nsocial choice mechanisms. We compare Bayesian estimators, which minimize\nBayesian expected loss, for the Mallows model and the Condorcet model\nrespectively, and the Kemeny rule. We consider various normative properties, in\naddition to computational complexity and asymptotic behavior. In particular, we\nshow that the Bayesian estimator for the Condorcet model satisfies some desired\nproperties such as anonymity, neutrality, and monotonicity, can be computed in\npolynomial time, and is asymptotically different from the other two rules when\nthe data are generated from the Condorcet model for some ground truth\nparameter.\n", "versions": [{"version": "v1", "created": "Wed, 29 Oct 2014 01:46:50 GMT"}, {"version": "v2", "created": "Sat, 12 Mar 2016 05:11:50 GMT"}], "update_date": "2016-03-15", "authors_parsed": [["Soufiani", "Hossein Azari", ""], ["Parkes", "David C.", ""], ["Xia", "Lirong", ""]]}, {"id": "1410.7942", "submitter": "Alexander Semenov", "authors": "Stepan Kochemazov, Alexander Semenov", "title": "Using synchronous Boolean networks to model several phenomena of\n  collective behavior", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0115156", "report-no": null, "categories": "cs.SI cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an approach for modeling and analysis of a number\nof phenomena of collective behavior. By collectives we mean multi-agent systems\nthat transition from one state to another at discrete moments of time. The\nbehavior of a member of a collective (agent) is called conforming if the\nopinion of this agent at current time moment conforms to the opinion of some\nother agents at the previous time moment. We presume that at each moment of\ntime every agent makes a decision by choosing from the set {0,1} (where\n1-decision corresponds to action and 0-decision corresponds to inaction). In\nour approach we model collective behavior with synchronous Boolean networks. We\npresume that in a network there can be agents that act at every moment of time.\nSuch agents are called instigators. Also there can be agents that never act.\nSuch agents are called loyalists. Agents that are neither instigators nor\nloyalists are called simple agents. We study two combinatorial problems. The\nfirst problem is to find a disposition of instigators that in several time\nmoments transforms a network from a state where a majority of simple agents are\ninactive to a state with a majority of active agents. The second problem is to\nfind a disposition of loyalists that returns the network to a state with a\nmajority of inactive agents. Similar problems are studied for networks in which\nsimple agents demonstrate the contrary to conforming behavior that we call\nanticonforming. We obtained several theoretical results regarding the behavior\nof collectives of agents with conforming or anticonforming behavior. In\ncomputational experiments we solved the described problems for randomly\ngenerated networks with several hundred vertices. We reduced corresponding\ncombinatorial problems to the Boolean satisfiability problem (SAT) and used\nmodern SAT solvers to solve the instances obtained.\n", "versions": [{"version": "v1", "created": "Wed, 29 Oct 2014 11:35:29 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Kochemazov", "Stepan", ""], ["Semenov", "Alexander", ""]]}, {"id": "1410.7953", "submitter": "Paula Severi", "authors": "Regina Motz, Edelweis Rohrer and Paula Severi", "title": "Reasoning for ALCQ extended with a flexible meta-modelling hierarchy", "comments": "This is the long version of the paper submitted to JIST2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This works is motivated by a real-world case study where it is necessary to\nintegrate and relate existing ontologies through meta- modelling. For this, we\nintroduce the Description Logic ALCQM which is obtained from ALCQ by adding\nstatements that equate individuals to concepts in a knowledge base. In this new\nextension, a concept can be an individual of another concept (called\nmeta-concept) which themselves can be individuals of yet another concept\n(called meta meta-concept) and so on. We define a tableau algorithm for\nchecking consistency of an ontology in ALCQM and prove its correctness.\n", "versions": [{"version": "v1", "created": "Wed, 29 Oct 2014 12:23:24 GMT"}], "update_date": "2014-10-30", "authors_parsed": [["Motz", "Regina", ""], ["Rohrer", "Edelweis", ""], ["Severi", "Paula", ""]]}, {"id": "1410.8027", "submitter": "Mateusz Malinowski", "authors": "Mateusz Malinowski and Mario Fritz", "title": "Towards a Visual Turing Challenge", "comments": "Published in the NIPS 2014 Workshop on Learning Semantics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.GL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As language and visual understanding by machines progresses rapidly, we are\nobserving an increasing interest in holistic architectures that tightly\ninterlink both modalities in a joint learning and inference process. This trend\nhas allowed the community to progress towards more challenging and open tasks\nand refueled the hope at achieving the old AI dream of building machines that\ncould pass a turing test in open domains. In order to steadily make progress\ntowards this goal, we realize that quantifying performance becomes increasingly\ndifficult. Therefore we ask how we can precisely define such challenges and how\nwe can evaluate different algorithms on this open tasks? In this paper, we\nsummarize and discuss such challenges as well as try to give answers where\nappropriate options are available in the literature. We exemplify some of the\nsolutions on a recently presented dataset of question-answering task based on\nreal-world indoor images that establishes a visual turing challenge. Finally,\nwe argue despite the success of unique ground-truth annotation, we likely have\nto step away from carefully curated dataset and rather rely on 'social\nconsensus' as the main driving force to create suitable benchmarks. Providing\ncoverage in this inherently ambiguous output space is an emerging challenge\nthat we face in order to make quantifiable progress in this area.\n", "versions": [{"version": "v1", "created": "Wed, 29 Oct 2014 15:38:29 GMT"}, {"version": "v2", "created": "Tue, 11 Nov 2014 12:09:53 GMT"}, {"version": "v3", "created": "Tue, 5 May 2015 18:03:56 GMT"}], "update_date": "2015-05-06", "authors_parsed": [["Malinowski", "Mateusz", ""], ["Fritz", "Mario", ""]]}, {"id": "1410.8233", "submitter": "Brian Tomasik", "authors": "Brian Tomasik", "title": "Do Artificial Reinforcement-Learning Agents Matter Morally?", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial reinforcement learning (RL) is a widely used technique in\nartificial intelligence that provides a general method for training agents to\nperform a wide variety of behaviours. RL as used in computer science has\nstriking parallels to reward and punishment learning in animal and human\nbrains. I argue that present-day artificial RL agents have a very small but\nnonzero degree of ethical importance. This is particularly plausible for views\naccording to which sentience comes in degrees based on the abilities and\ncomplexities of minds, but even binary views on consciousness should assign\nnonzero probability to RL programs having morally relevant experiences. While\nRL programs are not a top ethical priority today, they may become more\nsignificant in the coming decades as RL is increasingly applied to industry,\nrobotics, video games, and other areas. I encourage scientists, philosophers,\nand citizens to begin a conversation about our ethical duties to reduce the\nharm that we inflict on powerless, voiceless RL agents.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 02:34:48 GMT"}], "update_date": "2014-10-31", "authors_parsed": [["Tomasik", "Brian", ""]]}, {"id": "1410.8326", "submitter": "Nicholas H. Kirk", "authors": "Nicholas H. Kirk", "title": "Towards Learning Object Affordance Priors from Technical Texts", "comments": "\"Active Learning in Robotics\" Workshop, IEEE-RAS International\n  Conference on Humanoid Robots [accepted]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Everyday activities performed by artificial assistants can potentially be\nexecuted naively and dangerously given their lack of common sense knowledge.\nThis paper presents conceptual work towards obtaining prior knowledge on the\nusual modality (passive or active) of any given entity, and their affordance\nestimates, by extracting high-confidence ability modality semantic relations (X\ncan Y relationship) from non-figurative texts, by analyzing co-occurrence of\ngrammatical instances of subjects and verbs, and verbs and objects. The\ndiscussion includes an outline of the concept, potential and limitations, and\npossible feature and learning framework adoption.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 11:02:39 GMT"}], "update_date": "2014-10-31", "authors_parsed": [["Kirk", "Nicholas H.", ""]]}, {"id": "1410.8498", "submitter": "Emma Strubell", "authors": "Emma Strubell, Luke Vilnis, Andrew McCallum", "title": "Training for Fast Sequential Prediction Using Dynamic Feature Selection", "comments": "5 pages, NIPS Modern ML + NLP Workshop 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present paired learning and inference algorithms for significantly\nreducing computation and increasing speed of the vector dot products in the\nclassifiers that are at the heart of many NLP components. This is accomplished\nby partitioning the features into a sequence of templates which are ordered\nsuch that high confidence can often be reached using only a small fraction of\nall features. Parameter estimation is arranged to maximize accuracy and early\nconfidence in this sequence. We present experiments in left-to-right\npart-of-speech tagging on WSJ, demonstrating that we can preserve accuracy\nabove 97% with over a five-fold reduction in run-time.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 19:02:48 GMT"}, {"version": "v2", "created": "Fri, 19 Dec 2014 21:46:25 GMT"}], "update_date": "2014-12-23", "authors_parsed": [["Strubell", "Emma", ""], ["Vilnis", "Luke", ""], ["McCallum", "Andrew", ""]]}, {"id": "1410.8536", "submitter": "Yannis Tzitzikas", "authors": "Christina Lantzaki and Yannis Tzitzikas", "title": "Tasks that Require, or can Benefit from, Matching Blank Nodes", "comments": "19 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In various domains and cases, we observe the creation and usage of\ninformation elements which are unnamed. Such elements do not have a name, or\nmay have a name that is not externally referable (usually meaningless and not\npersistent over time). This paper discusses why we will never `escape' from the\nproblem of having to construct mappings between such unnamed elements in\ninformation systems. Since unnamed elements nowadays occur very often in the\nframework of the Semantic Web and Linked Data as blank nodes, the paper\ndescribes scenarios that can benefit from methods that compute mappings between\nthe unnamed elements. For each scenario, the corresponding bnode matching\nproblem is formally defined. Based on this analysis, we try to reach to more a\ngeneral formulation of the problem, which can be useful for guiding the\nrequired technological advances. To this end, the paper finally discusses\nmethods to realize blank node matching, the implementations that exist, and\nidentifies open issues and challenges.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 20:04:07 GMT"}], "update_date": "2014-11-03", "authors_parsed": [["Lantzaki", "Christina", ""], ["Tzitzikas", "Yannis", ""]]}, {"id": "1410.8577", "submitter": "Balint Antal", "authors": "Balint Antal, Andras Hajdu", "title": "An Ensemble-based System for Microaneurysm Detection and Diabetic\n  Retinopathy Grading", "comments": null, "journal-ref": "IEEE Transactions on Biomedical Engineering, vol.59, no.6, pp.\n  1720-1726, June 2012", "doi": "10.1109/TBME.2012.2193126", "report-no": null, "categories": "cs.CV cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliable microaneurysm detection in digital fundus images is still an open\nissue in medical image processing. We propose an ensemble-based framework to\nimprove microaneurysm detection. Unlike the well-known approach of considering\nthe output of multiple classifiers, we propose a combination of internal\ncomponents of microaneurysm detectors, namely preprocessing methods and\ncandidate extractors. We have evaluated our approach for microaneurysm\ndetection in an online competition, where this algorithm is currently ranked as\nfirst and also on two other databases. Since microaneurysm detection is\ndecisive in diabetic retinopathy grading, we also tested the proposed method\nfor this task on the publicly available Messidor database, where a promising\nAUC 0.90 with 0.01 uncertainty is achieved in a 'DR/non-DR'-type classification\nbased on the presence or absence of the microaneurysms.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 22:21:02 GMT"}], "update_date": "2014-11-03", "authors_parsed": [["Antal", "Balint", ""], ["Hajdu", "Andras", ""]]}, {"id": "1410.8620", "submitter": "Aaron Defazio Mr", "authors": "Aaron Defazio and Thore Graepel", "title": "A Comparison of learning algorithms on the Arcade Learning Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Reinforcement learning agents have traditionally been evaluated on small toy\nproblems. With advances in computing power and the advent of the Arcade\nLearning Environment, it is now possible to evaluate algorithms on diverse and\ndifficult problems within a consistent framework. We discuss some challenges\nposed by the arcade learning environment which do not manifest in simpler\nenvironments. We then provide a comparison of model-free, linear learning\nalgorithms on this challenging problem set.\n", "versions": [{"version": "v1", "created": "Fri, 31 Oct 2014 02:19:19 GMT"}], "update_date": "2014-11-03", "authors_parsed": [["Defazio", "Aaron", ""], ["Graepel", "Thore", ""]]}, {"id": "1410.8808", "submitter": "Paolo Pareti Mr.", "authors": "Paolo Pareti, Ewan Klein and Adam Barker", "title": "A Semantic Web of Know-How: Linked Data for Community-Centric Tasks", "comments": "6th International Workshop on Web Intelligence & Communities (WIC14),\n  Proceedings of the companion publication of the 23rd International Conference\n  on World Wide Web (WWW 2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper proposes a novel framework for representing community know-how on\nthe Semantic Web. Procedural knowledge generated by web communities typically\ntakes the form of natural language instructions or videos and is largely\nunstructured. The absence of semantic structure impedes the deployment of many\nuseful applications, in particular the ability to discover and integrate\nknow-how automatically. We discuss the characteristics of community know-how\nand argue that existing knowledge representation frameworks fail to represent\nit adequately. We present a novel framework for representing the semantic\nstructure of community know-how and demonstrate the feasibility of our approach\nby providing a concrete implementation which includes a method for\nautomatically acquiring procedural knowledge for real-world tasks.\n", "versions": [{"version": "v1", "created": "Wed, 29 Oct 2014 15:48:40 GMT"}], "update_date": "2014-11-03", "authors_parsed": [["Pareti", "Paolo", ""], ["Klein", "Ewan", ""], ["Barker", "Adam", ""]]}]