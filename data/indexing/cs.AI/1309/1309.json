[{"id": "1309.0085", "submitter": "Junaid  Qadir", "authors": "Junaid Qadir", "title": "Artificial Intelligence Based Cognitive Routing for Cognitive Radio\n  Networks", "comments": "28 pages, submitted to IEEE Communications Surveys and Tutorials", "journal-ref": "Artificial Intelligence Review pp 1-72 First online: 03 September\n  2015", "doi": "10.1007/s10462-015-9438-6", "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive radio networks (CRNs) are networks of nodes equipped with cognitive\nradios that can optimize performance by adapting to network conditions. While\ncognitive radio networks (CRN) are envisioned as intelligent networks,\nrelatively little research has focused on the network level functionality of\nCRNs. Although various routing protocols, incorporating varying degrees of\nadaptiveness, have been proposed for CRNs, it is imperative for the long term\nsuccess of CRNs that the design of cognitive routing protocols be pursued by\nthe research community. Cognitive routing protocols are envisioned as routing\nprotocols that fully and seamless incorporate AI-based techniques into their\ndesign. In this paper, we provide a self-contained tutorial on various AI and\nmachine-learning techniques that have been, or can be, used for developing\ncognitive routing protocols. We also survey the application of various classes\nof AI techniques to CRNs in general, and to the problem of routing in\nparticular. We discuss various decision making techniques and learning\ntechniques from AI and document their current and potential applications to the\nproblem of routing in CRNs. We also highlight the various inference, reasoning,\nmodeling, and learning sub tasks that a cognitive routing protocol must solve.\nFinally, open research issues and future directions of work are identified.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2013 09:34:48 GMT"}], "update_date": "2015-11-06", "authors_parsed": [["Qadir", "Junaid", ""]]}, {"id": "1309.0363", "submitter": "Florian Meyer", "authors": "Florian Meyer, Ondrej Hlinka, and Franz Hlawatsch", "title": "Sigma Point Belief Propagation", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sigma point (SP) filter, also known as unscented Kalman filter, is an\nattractive alternative to the extended Kalman filter and the particle filter.\nHere, we extend the SP filter to nonsequential Bayesian inference corresponding\nto loopy factor graphs. We propose sigma point belief propagation (SPBP) as a\nlow-complexity approximation of the belief propagation (BP) message passing\nscheme. SPBP achieves approximate marginalizations of posterior distributions\ncorresponding to (generally) loopy factor graphs. It is well suited for\ndecentralized inference because of its low communication requirements. For a\ndecentralized, dynamic sensor localization problem, we demonstrate that SPBP\ncan outperform nonparametric (particle-based) BP while requiring significantly\nless computations and communications.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2013 10:59:38 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2013 12:42:10 GMT"}], "update_date": "2013-11-19", "authors_parsed": [["Meyer", "Florian", ""], ["Hlinka", "Ondrej", ""], ["Hlawatsch", "Franz", ""]]}, {"id": "1309.0659", "submitter": "Yi Zhou Dr.", "authors": "Yi Zhou", "title": "Majority Rule for Belief Evolution in Social Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study how an agent's belief is affected by her neighbors in\na social network. We first introduce a general framework, where every agent has\nan initial belief on a statement, and updates her belief according to her and\nher neighbors' current beliefs under some belief evolution functions, which,\narguably, should satisfy some basic properties. Then, we focus on the majority\nrule belief evolution function, that is, an agent will (dis)believe the\nstatement iff more than half of her neighbors (dis)believe it. We consider some\nfundamental issues about majority rule belief evolution, for instance, whether\nthe belief evolution process will eventually converge. The answer is no in\ngeneral. However, for random asynchronous belief evolution, this is indeed the\ncase.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2013 12:45:55 GMT"}], "update_date": "2013-09-04", "authors_parsed": [["Zhou", "Yi", ""]]}, {"id": "1309.0671", "submitter": "Ruben Martinez-Cantin", "authors": "Ruben Martinez-Cantin", "title": "BayesOpt: A Library for Bayesian optimization with Robotics Applications", "comments": "Robotics: Science and Systems, Workshop on Active Learning in\n  Robotics: Exploration, Curiosity, and Interaction", "journal-ref": "Journal of Machine Learning Research, 15(Nov), 3915-3919, 2014", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this paper is twofold. On one side, we present a general\nframework for Bayesian optimization and we compare it with some related fields\nin active learning and Bayesian numerical analysis. On the other hand, Bayesian\noptimization and related problems (bandits, sequential experimental design) are\nhighly dependent on the surrogate model that is selected. However, there is no\nclear standard in the literature. Thus, we present a fast and flexible toolbox\nthat allows to test and combine different models and criteria with little\neffort. It includes most of the state-of-the-art contributions, algorithms and\nmodels. Its speed also removes part of the stigma that Bayesian optimization\nmethods are only good for \"expensive functions\". The software is free and it\ncan be used in many operating systems and computer languages.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2013 13:38:05 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Martinez-Cantin", "Ruben", ""]]}, {"id": "1309.0866", "submitter": "EPTCS", "authors": "Ezio Bartocci (TU Wien, Austria), Luca Bortolussi (University of\n  Trieste, Italy), Laura Nenzi (IMT Lucca, Italy), Guido Sanguinetti\n  (University of Edinburgh, UK)", "title": "On the Robustness of Temporal Properties for Stochastic Models", "comments": "In Proceedings HSB 2013, arXiv:1308.5724", "journal-ref": "EPTCS 125, 2013, pp. 3-19", "doi": "10.4204/EPTCS.125.1", "report-no": null, "categories": "cs.LO cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic models such as Continuous-Time Markov Chains (CTMC) and Stochastic\nHybrid Automata (SHA) are powerful formalisms to model and to reason about the\ndynamics of biological systems, due to their ability to capture the\nstochasticity inherent in biological processes. A classical question in formal\nmodelling with clear relevance to biological modelling is the model checking\nproblem. i.e. calculate the probability that a behaviour, expressed for\ninstance in terms of a certain temporal logic formula, may occur in a given\nstochastic process. However, one may not only be interested in the notion of\nsatisfiability, but also in the capacity of a system to mantain a particular\nemergent behaviour unaffected by the perturbations, caused e.g. from extrinsic\nnoise, or by possible small changes in the model parameters. To address this\nissue, researchers from the verification community have recently proposed\nseveral notions of robustness for temporal logic providing suitable definitions\nof distance between a trajectory of a (deterministic) dynamical system and the\nboundaries of the set of trajectories satisfying the property of interest. The\ncontributions of this paper are twofold. First, we extend the notion of\nrobustness to stochastic systems, showing that this naturally leads to a\ndistribution of robustness scores. By discussing two examples, we show how to\napproximate the distribution of the robustness score and its key indicators:\nthe average robustness and the conditional average robustness. Secondly, we\nshow how to combine these indicators with the satisfaction probability to\naddress the system design problem, where the goal is to optimize some control\nparameters of a stochastic model in order to best maximize robustness of the\ndesired specifications.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2013 23:40:49 GMT"}], "update_date": "2013-09-05", "authors_parsed": [["Bartocci", "Ezio", "", "TU Wien, Austria"], ["Bortolussi", "Luca", "", "University of\n  Trieste, Italy"], ["Nenzi", "Laura", "", "IMT Lucca, Italy"], ["Sanguinetti", "Guido", "", "University of Edinburgh, UK"]]}, {"id": "1309.0962", "submitter": "Ehtibar Dzhafarov", "authors": "Ehtibar N. Dzhafarov and Janne V. Kujala", "title": "Random Variables Recorded under Mutually Exclusive Conditions:\n  Contextuality-by-Default", "comments": "In H. Liljenstr\\\"om (Ed.) Advances in Cognitive Neurodynamics IV (pp.\n  405-410) (2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI math.PR q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present general principles underlying analysis of the dependence of random\nvariables (outputs) on deterministic conditions (inputs). Random outputs\nrecorded under mutually exclusive input values are labeled by these values and\nconsidered stochastically unrelated, possessing no joint distribution. An input\nthat does not directly influence an output creates a context for the latter.\nAny constraint imposed on the dependence of random outputs on inputs can be\ncharacterized by considering all possible couplings (joint distributions)\nimposed on stochastically unrelated outputs. The target application of these\nprinciples is a quantum mechanical system of entangled particles, with\ndirections of spin measurements chosen for each particle being inputs and the\nspins recorded outputs. The sphere of applicability, however, spans systems\nacross physical, biological, and behavioral sciences.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2013 10:19:23 GMT"}, {"version": "v2", "created": "Fri, 23 Jan 2015 21:48:33 GMT"}], "update_date": "2015-01-27", "authors_parsed": [["Dzhafarov", "Ehtibar N.", ""], ["Kujala", "Janne V.", ""]]}, {"id": "1309.1226", "submitter": "Joseph Y. Halpern", "authors": "Joseph Y. Halpern and Christopher Hitchcock", "title": "Graded Causation and Defaults", "comments": "To appear, British Journal for the Philosophy of Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in psychology and experimental philosophy has shown that\njudgments of actual causation are often influenced by consideration of\ndefaults, typicality, and normality. A number of philosophers and computer\nscientists have also suggested that an appeal to such factors can help deal\nwith problems facing existing accounts of actual causation. This paper develops\na flexible formal framework for incorporating defaults, typicality, and\nnormality into an account of actual causation. The resulting account takes\nactual causation to be both graded and comparative. We then show how our\naccount would handle a number of standard cases.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2013 02:17:54 GMT"}], "update_date": "2013-09-06", "authors_parsed": [["Halpern", "Joseph Y.", ""], ["Hitchcock", "Christopher", ""]]}, {"id": "1309.1227", "submitter": "Joseph Y. Halpern", "authors": "Joseph Y. Halpern and Christopher Hitchcock", "title": "Compact Representations of Extended Causal Models", "comments": null, "journal-ref": "Cognitive Science 37:6, 2013, pp. 986-1010", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Judea Pearl was the first to propose a definition of actual causation using\ncausal models. A number of authors have suggested that an adequate account of\nactual causation must appeal not only to causal structure, but also to\nconsiderations of normality. In earlier work, we provided a definition of\nactual causation using extended causal models, which include information about\nboth causal structure and normality. Extended causal models are potentially\nvery complex. In this paper, we show how it is possible to achieve a compact\nrepresentation of extended causal models.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2013 02:26:44 GMT"}], "update_date": "2013-09-06", "authors_parsed": [["Halpern", "Joseph Y.", ""], ["Hitchcock", "Christopher", ""]]}, {"id": "1309.1228", "submitter": "Joseph Y. Halpern", "authors": "Joseph Y. Halpern", "title": "Weighted regret-based likelihood: a new approach to describing\n  uncertainty", "comments": "Appeared in 12th European Conference on Symbolic and Quantitative\n  Approaches to Reasoning with Uncertainty (ECSQARU)}, 2013, pp. 266--277", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Halpern and Leung suggested representing uncertainty by a weighted\nset of probability measures, and suggested a way of making decisions based on\nthis representation of uncertainty: maximizing weighted regret. Their paper\ndoes not answer an apparently simpler question: what it means, according to\nthis representation of uncertainty, for an event E to be more likely than an\nevent E'. In this paper, a notion of comparative likelihood when uncertainty is\nrepresented by a weighted set of probability measures is defined. It\ngeneralizes the ordering defined by probability (and by lower probability) in a\nnatural way; a generalization of upper probability can also be defined. A\ncomplete axiomatic characterization of this notion of regret-based likelihood\nis given.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2013 02:33:30 GMT"}], "update_date": "2013-09-06", "authors_parsed": [["Halpern", "Joseph Y.", ""]]}, {"id": "1309.1524", "submitter": "Oliver Obst", "authors": "Oliver Obst, Joschka Boedecker", "title": "Guided Self-Organization of Input-Driven Recurrent Neural Networks", "comments": "23 pages, to appear in M. Prokopenko (ed.), Guided Self-Organization:\n  Inception, Springer, 2014", "journal-ref": null, "doi": "10.1007/978-3-642-53734-9_11", "report-no": null, "categories": "cs.NE cs.AI nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review attempts that have been made towards understanding the\ncomputational properties and mechanisms of input-driven dynamical systems like\nRNNs, and reservoir computing networks in particular. We provide details on\nmethods that have been developed to give quantitative answers to the questions\nabove. Following this, we show how self-organization may be used to improve\nreservoirs for better performance, in some cases guided by the measures\npresented before. We also present a possible way to quantify task performance\nusing an information-theoretic approach, and finally discuss promising future\ndirections aimed at a better understanding of how these systems perform their\ncomputations and how to best guide self-organized processes for their\noptimization.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2013 03:03:03 GMT"}], "update_date": "2014-01-10", "authors_parsed": [["Obst", "Oliver", ""], ["Boedecker", "Joschka", ""]]}, {"id": "1309.1973", "submitter": "Feng Wu", "authors": "Feng Wu and Nicholas R. Jennings", "title": "Regret-Based Multi-Agent Coordination with Uncertain Task Rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many multi-agent coordination problems can be represented as DCOPs. Motivated\nby task allocation in disaster response, we extend standard DCOP models to\nconsider uncertain task rewards where the outcome of completing a task depends\non its current state, which is randomly drawn from unknown distributions. The\ngoal of solving this problem is to find a solution for all agents that\nminimizes the overall worst-case loss. This is a challenging problem for\ncentralized algorithms because the search space grows exponentially with the\nnumber of agents and is nontrivial for standard DCOP algorithms we have. To\naddress this, we propose a novel decentralized algorithm that incorporates\nMax-Sum with iterative constraint generation to solve the problem by passing\nmessages among agents. By so doing, our approach scales well and can solve\ninstances of the task allocation problem with hundreds of agents and tasks.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2013 16:20:06 GMT"}], "update_date": "2013-09-10", "authors_parsed": [["Wu", "Feng", ""], ["Jennings", "Nicholas R.", ""]]}, {"id": "1309.2080", "submitter": "Elena Bellodi", "authors": "Elena Bellodi, Fabrizio Riguzzi", "title": "Structure Learning of Probabilistic Logic Programs by Searching the\n  Clause Space", "comments": "44 pages, 12 figures", "journal-ref": "Theory and Practice of Logic Programming 15 (2015) 169-212", "doi": "10.1017/S1471068413000689", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning probabilistic logic programming languages is receiving an increasing\nattention and systems are available for learning the parameters (PRISM,\nLeProbLog, LFI-ProbLog and EMBLEM) or both the structure and the parameters\n(SEM-CP-logic and SLIPCASE) of these languages. In this paper we present the\nalgorithm SLIPCOVER for \"Structure LearnIng of Probabilistic logic programs by\nsearChing OVER the clause space\". It performs a beam search in the space of\nprobabilistic clauses and a greedy search in the space of theories, using the\nlog likelihood of the data as the guiding heuristics. To estimate the log\nlikelihood SLIPCOVER performs Expectation Maximization with EMBLEM. The\nalgorithm has been tested on five real world datasets and compared with\nSLIPCASE, SEM-CP-logic, Aleph and two algorithms for learning Markov Logic\nNetworks (Learning using Structural Motifs (LSM) and ALEPH++ExactL1). SLIPCOVER\nachieves higher areas under the precision-recall and ROC curves in most cases.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2013 09:24:44 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Bellodi", "Elena", ""], ["Riguzzi", "Fabrizio", ""]]}, {"id": "1309.2351", "submitter": "Rodrigo Lopez-Pablos", "authors": "Rodrigo Lopez-Pablos (Universidad Nacional de La Matanza y Universidad\n  Tecnol\\'ogica Nacional)", "title": "Elementos de ingenier\\'ia de explotaci\\'on de la informaci\\'on aplicados\n  a la investigaci\\'on tributaria fiscal", "comments": "30 pages, 7 figures, written in Castilian, Artificial Intelligence\n  (cs.AI), Computers and Society (cs.CY)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  By introducing elements of information mining to tax analysis, by means of\ndata mining software and advanced computational concepts of artificial\nintelligence, the problem of tax evader's crime against public property has\nbeen addressed. Through an empirical approach from a hypothetical case of use,\ninduction algorithms, neural networks and bayesian networks are applied to\ndetermine the feasibility of its heuristic application by the tax public\nadministrator. Different strategies are explored to facilitate the work of\nlocal and regional federal tax inspectors, considering their limited\ncomputational capabilities, but equally effective for those social scientist\ncommitted to handcrafting tax research.\n  -----\n  Apresentando a introdu\\c{c}\\~ao de elementos de explora\\c{c}\\~ao de\ninforma\\c{c}\\~oes para an\\'alise fiscal, por meio de software de\nminera\\c{c}\\~ao de dados e conceitos avan\\c{c}ados computacionais de\nintelig\\^encia artificial, foi abordado o problema do crime de sonegador fiscal\ncontra o patrim\\^onio p\\'ublico. Atrav\\'es de uma abordagem emp\\'irica a partir\nde um caso hipot\\'etico de uso, os algoritmos de indu\\c{c}\\~ao, redes neurais e\nredes bayesianas s\\~ao aplicados para determinar a viabilidade de sua\naplica\\c{c}\\~ao heur\\'istica pelo administrador p\\'ublico tribut\\'ario.\nDiferentes estrat\\'egias s\\~ao exploradas para facilitar o trabalho dos\ninspectores tribut\\'arios federais locais e regionais, tendo em conta as suas\ncapacidades computacionais limitados, mas igualmente eficaz para aqueles\ncientista social comprometido com a investiga\\c{c}\\~ao fiscal.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2013 00:42:05 GMT"}], "update_date": "2013-09-11", "authors_parsed": [["Lopez-Pablos", "Rodrigo", "", "Universidad Nacional de La Matanza y Universidad\n  Tecnol\u00f3gica Nacional"]]}, {"id": "1309.2693", "submitter": "Victor Pillac", "authors": "Victor Pillac and Pascal Van Henetenryck and Caroline Even", "title": "A Conflict-Based Path-Generation Heuristic for Evacuation Planning", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": "NICTA VRL-7393", "categories": "cs.AI math.OC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Evacuation planning and scheduling is a critical aspect of disaster\nmanagement and national security applications. This paper proposes a\nconflict-based path-generation approach for evacuation planning. Its key idea\nis to generate evacuation routes lazily for evacuated areas and to optimize the\nevacuation over these routes in a master problem. Each new path is generated to\nremedy conflicts in the evacuation and adds new columns and a new row in the\nmaster problem. The algorithm is applied to massive flood scenarios in the\nHawkesbury-Nepean river (West Sydney, Australia) which require evacuating in\nthe order of 70,000 persons. The proposed approach reduces the number of\nvariables from 4,500,000 in a Mixed Integer Programming (MIP) formulation to\n30,000 in the case study. With this approach, realistic evacuations scenarios\ncan be solved near-optimally in real time, supporting both evacuation planning\nin strategic, tactical, and operational environments.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2013 23:42:57 GMT"}], "update_date": "2013-09-12", "authors_parsed": [["Pillac", "Victor", ""], ["Van Henetenryck", "Pascal", ""], ["Even", "Caroline", ""]]}, {"id": "1309.2747", "submitter": "Junping Zhou", "authors": "Junping Zhou, Weihua Su, Minghao Yin", "title": "Approximate Counting CSP Solutions Using Partition Function", "comments": "14 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approximate method for counting the number of the solutions\nfor constraint satisfaction problem (CSP). The method derives from the\npartition function based on introducing the free energy and capturing the\nrelationship of probabilities of variables and constraints, which requires the\nmarginal probabilities. It firstly obtains the marginal probabilities using the\nbelief propagation, and then computes the number of solutions according to the\npartition function. This allows us to directly plug the marginal probabilities\ninto the partition function and efficiently count the number of solutions for\nCSP. The experimental results show that our method can solve both random\nproblems and structural problems efficiently.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2013 07:32:07 GMT"}], "update_date": "2013-09-12", "authors_parsed": [["Zhou", "Junping", ""], ["Su", "Weihua", ""], ["Yin", "Minghao", ""]]}, {"id": "1309.2796", "submitter": "Ferdinando Cicalese", "authors": "Ferdinando Cicalese and Eduardo Laber and Aline Medeiros Saettler", "title": "Decision Trees for Function Evaluation - Simultaneous Optimization of\n  Worst and Expected Cost", "comments": "A preliminary version of this paper was accepted for presentation at\n  ICML 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In several applications of automatic diagnosis and active learning a central\nproblem is the evaluation of a discrete function by adaptively querying the\nvalues of its variables until the values read uniquely determine the value of\nthe function. In general, the process of reading the value of a variable might\ninvolve some cost, computational or even a fee to be paid for the experiment\nrequired for obtaining the value. This cost should be taken into account when\ndeciding the next variable to read. The goal is to design a strategy for\nevaluating the function incurring little cost (in the worst case or in\nexpectation according to a prior distribution on the possible variables'\nassignments). Our algorithm builds a strategy (decision tree) which attains a\nlogarithmic approxima- tion simultaneously for the expected and worst cost\nspent. This is best possible under the assumption that $P \\neq NP.$\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2013 11:50:44 GMT"}, {"version": "v2", "created": "Sat, 26 Jul 2014 15:42:05 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Cicalese", "Ferdinando", ""], ["Laber", "Eduardo", ""], ["Saettler", "Aline Medeiros", ""]]}, {"id": "1309.3039", "submitter": "Azlan Iqbal", "authors": "Azlan Iqbal", "title": "How Relevant Are Chess Composition Conventions?", "comments": "10 pages, 3 tables, 2 figures. Accepted to the 23rd International\n  Joint Conference on Artificial Intelligence (IJCAI) Workshop on Computer\n  Games, Beijing, China, 3-5 August 2013. Published version:\n  http://link.springer.com/chapter/10.1007%2F978-3-319-05428-5_9", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Composition conventions are guidelines used by human composers in composing\nchess problems. They are particularly significant in composition tournaments.\nExamples include, not having any check in the first move of the solution and\nnot dressing up the board with unnecessary pieces. Conventions are often\nassociated or even directly conflated with the overall aesthetics or beauty of\na composition. Using an existing experimentally-validated computational\naesthetics model for three-move mate problems, we analyzed sets of\ncomputer-generated compositions adhering to at least 2, 3 and 4 comparable\nconventions to test if simply conforming to more conventions had a positive\neffect on their aesthetics, as is generally believed by human composers. We\nfound slight but statistically significant evidence that it does, but only to a\npoint. We also analyzed human judge scores of 145 three-move mate problems\ncomposed by humans to see if they had any positive correlation with the\ncomputational aesthetic scores of those problems. We found that they did not.\nThese seemingly conflicting findings suggest two main things. First, the right\namount of adherence to composition conventions in a composition has a positive\neffect on its perceived aesthetics. Second, human judges either do not look at\nthe same conventions related to aesthetics in the model used or emphasize\nothers that have less to do with beauty as perceived by the majority of\nplayers, even though they may mistakenly consider their judgements beautiful in\nthe traditional, non-esoteric sense. Human judges may also be relying\nsignificantly on personal tastes as we found no correlation between their\nindividual scores either.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2013 06:00:13 GMT"}, {"version": "v2", "created": "Wed, 21 Sep 2016 02:38:10 GMT"}], "update_date": "2016-09-22", "authors_parsed": [["Iqbal", "Azlan", ""]]}, {"id": "1309.3060", "submitter": "Oliver Kullmann", "authors": "Matthew Gwynne and Oliver Kullmann", "title": "On SAT representations of XOR constraints", "comments": "39 pages; 2nd v. improved handling of acyclic systems, free-standing\n  proof of the transformation from AC-representations to monotone circuits,\n  improved wording and literature review; 3rd v. updated literature,\n  strengthened treatment of monotonisation, improved discussions; 4th v. update\n  of literature, discussions and formulations, more details and examples;\n  conference v. to appear LATA 2014", "journal-ref": "LATA 2014: Language and Automata Theory and Applications, LNCS\n  8370, pages 409-420", "doi": "10.1007/978-3-319-04921-2_33", "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the representation of systems S of linear equations over the\ntwo-element field (aka xor- or parity-constraints) via conjunctive normal forms\nF (boolean clause-sets). First we consider the problem of finding an\n\"arc-consistent\" representation (\"AC\"), meaning that unit-clause propagation\nwill fix all forced assignments for all possible instantiations of the\nxor-variables. Our main negative result is that there is no polysize\nAC-representation in general. On the positive side we show that finding such an\nAC-representation is fixed-parameter tractable (fpt) in the number of\nequations. Then we turn to a stronger criterion of representation, namely\npropagation completeness (\"PC\") --- while AC only covers the variables of S,\nnow all the variables in F (the variables in S plus auxiliary variables) are\nconsidered for PC. We show that the standard translation actually yields a PC\nrepresentation for one equation, but fails so for two equations (in fact\narbitrarily badly). We show that with a more intelligent translation we can\nalso easily compute a translation to PC for two equations. We conjecture that\ncomputing a representation in PC is fpt in the number of equations.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2013 08:42:11 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2013 14:02:37 GMT"}, {"version": "v3", "created": "Mon, 11 Nov 2013 22:58:24 GMT"}, {"version": "v4", "created": "Thu, 19 Dec 2013 01:13:29 GMT"}], "update_date": "2014-06-24", "authors_parsed": [["Gwynne", "Matthew", ""], ["Kullmann", "Oliver", ""]]}, {"id": "1309.3187", "submitter": "Roberto As\\'in-Ach\\'a", "authors": "Roberto As\\'in, Juan Olate and Leo Ferres", "title": "Cache Performance Study of Portfolio-Based Parallel CDCL SAT Solvers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel SAT solvers are becoming mainstream. Their performance has made them\nwin the past two SAT competitions consecutively and are in the limelight of\nresearch and industry. The problem is that it is not known exactly what is\nneeded to make them perform even better; that is, how to make them solve more\nproblems in less time. Also, it is also not know how well they scale in massive\nmulti-core environments which, predictably, is the scenario of comming new\nhardware. In this paper we show that cache contention is a main culprit of a\nslowing down in scalability, and provide empirical results that for some type\nof searches, physically sharing the clause Database between threads is\nbeneficial.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2013 15:12:07 GMT"}], "update_date": "2013-09-13", "authors_parsed": [["As\u00edn", "Roberto", ""], ["Olate", "Juan", ""], ["Ferres", "Leo", ""]]}, {"id": "1309.3197", "submitter": "Arthur Carvalho", "authors": "Arthur Carvalho, Stanko Dimitrov, Kate Larson", "title": "Inducing Honest Reporting Without Observing Outcomes: An Application to\n  the Peer-Review Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.DL math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When eliciting opinions from a group of experts, traditional devices used to\npromote honest reporting assume that there is an observable future outcome. In\npractice, however, this assumption is not always reasonable. In this paper, we\npropose a scoring method built on strictly proper scoring rules to induce\nhonest reporting without assuming observable outcomes. Our method provides\nscores based on pairwise comparisons between the reports made by each pair of\nexperts in the group. For ease of exposition, we introduce our scoring method\nby illustrating its application to the peer-review process. In order to do so,\nwe start by modeling the peer-review process using a Bayesian model where the\nuncertainty regarding the quality of the manuscript is taken into account.\nThereafter, we introduce our scoring method to evaluate the reported reviews.\nUnder the assumptions that reviewers are Bayesian decision-makers and that they\ncannot influence the reviews of other reviewers, we show that risk-neutral\nreviewers strictly maximize their expected scores by honestly disclosing their\nreviews. We also show how the group's scores can be used to find a consensual\nreview. Experimental results show that encouraging honest reporting through the\nproposed scoring method creates more accurate reviews than the traditional\npeer-review process.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2013 15:34:21 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2013 13:39:51 GMT"}], "update_date": "2013-10-23", "authors_parsed": [["Carvalho", "Arthur", ""], ["Dimitrov", "Stanko", ""], ["Larson", "Kate", ""]]}, {"id": "1309.3242", "submitter": "Iman Esmaili Paeen Afrakoti", "authors": "Iman Esmaili Paeen Afrakoti, Saeed Bagheri Shouraki and Farnood\n  Merrikhbayat", "title": "Using memristor crossbar structure to implement a novel adaptive real\n  time fuzzy modeling algorithm", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although fuzzy techniques promise fast meanwhile accurate modeling and\ncontrol abilities for complicated systems, different difficulties have been\nre-vealed in real situation implementations. Usually there is no escape of\nit-erative optimization based on crisp domain algorithms. Recently memristor\nstructures appeared promising to implement neural network structures and fuzzy\nalgorithms. In this paper a novel adaptive real-time fuzzy modeling algorithm\nis proposed which uses active learning method concept to mimic recent\nunderstandings of right brain processing techniques. The developed method is\nbased on processing fuzzy numbers to provide the ability of being sensitive to\neach training data point to expand the knowledge tree leading to plasticity\nwhile used defuzzification technique guaranties enough stability. An\noutstanding characteristic of the proposed algorithm is its consistency to\nmemristor crossbar hardware processing concepts. An analog implemen-tation of\nthe proposed algorithm on memristor crossbars structure is also introduced in\nthis paper. The effectiveness of the proposed algorithm in modeling and pattern\nrecognition tasks is verified by means of computer simulations\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2013 19:02:00 GMT"}], "update_date": "2017-01-08", "authors_parsed": [["Afrakoti", "Iman Esmaili Paeen", ""], ["Shouraki", "Saeed Bagheri", ""], ["Merrikhbayat", "Farnood", ""]]}, {"id": "1309.3285", "submitter": "Salman Hooshmand", "authors": "Salman Hooshmand, Mehdi Behshameh and Omid Hamidi", "title": "A tabu search algorithm with efficient diversification strategy for high\n  school timetabling problem", "comments": null, "journal-ref": null, "doi": "10.5121/ijcsit.2013.5402", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The school timetabling problem can be described as scheduling a set of\nlessons (combination of classes, teachers, subjects and rooms) in a weekly\ntimetable. This paper presents a novel way to generate timetables for high\nschools. The algorithm has three phases. Pre-scheduling, initial phase and\noptimization through tabu search. In the first phase, a graph based algorithm\nused to create groups of lessons to be scheduled simultaneously; then an\ninitial solution is built by a sequential greedy heuristic. Finally, the\nsolution is optimized using tabu search algorithm based on frequency based\ndiversification. The algorithm has been tested on a set of real problems\ngathered from Iranian high schools. Experiments show that the proposed\nalgorithm can effectively build acceptable timetables.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2013 20:03:09 GMT"}], "update_date": "2013-09-16", "authors_parsed": [["Hooshmand", "Salman", ""], ["Behshameh", "Mehdi", ""], ["Hamidi", "Omid", ""]]}, {"id": "1309.3611", "submitter": "Fionn Murtagh", "authors": "Fionn Murtagh", "title": "Ultrametric Component Analysis with Application to Analysis of Text and\n  of Emotion", "comments": "49 pages, 15 figures, 52 citations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review the theory and practice of determining what parts of a data set are\nultrametric. It is assumed that the data set, to begin with, is endowed with a\nmetric, and we include discussion of how this can be brought about if a\ndissimilarity, only, holds. The basis for part of the metric-endowed data set\nbeing ultrametric is to consider triplets of the observables (vectors). We\ndevelop a novel consensus of hierarchical clusterings. We do this in order to\nhave a framework (including visualization and supporting interpretation) for\nthe parts of the data that are determined to be ultrametric. Furthermore a\nmajor objective is to determine locally ultrametric relationships as opposed to\nnon-local ultrametric relationships. As part of this work, we also study a\nparticular property of our ultrametricity coefficient, namely, it being a\nfunction of the difference of angles of the base angles of the isosceles\ntriangle. This work is completed by a review of related work, on consensus\nhierarchies, and of a major new application, namely quantifying and\ninterpreting the emotional content of narrative.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2013 00:12:13 GMT"}], "update_date": "2013-09-17", "authors_parsed": [["Murtagh", "Fionn", ""]]}, {"id": "1309.3699", "submitter": "Ravi Ganti", "authors": "Ravi Ganti and Alexander Gray", "title": "Local Support Vector Machines:Formulation and Analysis", "comments": "12 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a formulation for Local Support Vector Machines (LSVMs) that\ngeneralizes previous formulations, and brings out the explicit connections to\nlocal polynomial learning used in nonparametric estimation literature. We\ninvestigate the simplest type of LSVMs called Local Linear Support Vector\nMachines (LLSVMs). For the first time we establish conditions under which\nLLSVMs make Bayes consistent predictions at each test point $x_0$. We also\nestablish rates at which the local risk of LLSVMs converges to the minimum\nvalue of expected local risk at each point $x_0$. Using stability arguments we\nestablish generalization error bounds for LLSVMs.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2013 21:06:22 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Ganti", "Ravi", ""], ["Gray", "Alexander", ""]]}, {"id": "1309.3775", "submitter": "Jose Acacio de Barros", "authors": "J. Acacio de Barros", "title": "Beyond the quantum formalism: consequences of a neural-oscillator model\n  to quantum cognition", "comments": "4 pages; to appear in the Advances in Cognitive Neurodynamics,\n  Proceedings of the 4th International Conference on Cognitive Neurodynamics -\n  2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph cs.AI q-bio.NC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a neural oscillator model of stimulus response\ntheory that exhibits quantum-like behavior. We then show that without adding\nany additional assumptions, a quantum model constructed to fit observable\npairwise correlations has no predictive power over the unknown triple moment,\nobtainable through the activation of multiple oscillators. We compare this with\nthe results obtained in de Barros (2013), where a criteria of rationality gives\noptimal ranges for the triple moment.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2013 16:20:46 GMT"}, {"version": "v2", "created": "Fri, 4 Apr 2014 17:41:33 GMT"}], "update_date": "2014-04-07", "authors_parsed": [["de Barros", "J. Acacio", ""]]}, {"id": "1309.3917", "submitter": "Gaetan Marceau", "authors": "Ga\\'etan Marceau (INRIA Saclay - Ile de France, LRI), Pierre\n  Sav\\'eant, Marc Schoenauer (INRIA Saclay - Ile de France, LRI)", "title": "Strategic Planning in Air Traffic Control as a Multi-objective\n  Stochastic Optimization Problem", "comments": "ATM Seminar 2013 (2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the objective of handling the airspace sector congestion subject to\ncontinuously growing air traffic, we suggest to create a collaborative working\nplan during the strategic phase of air traffic control. The plan obtained via a\nnew decision support tool presented in this article consists in a schedule for\ncontrollers, which specifies time of overflight on the different waypoints of\nthe flight plans. In order to do it, we believe that the decision-support tool\nshall model directly the uncertainty at a trajectory level in order to\npropagate the uncertainty to the sector level. Then, the probability of\ncongestion for any sector in the airspace can be computed. Since air traffic\nregulations and sector congestion are antagonist, we designed and implemented a\nmulti-objective optimization algorithm for determining the best trade-off\nbetween these two criteria. The solution comes up as a set of alternatives for\nthe multi-sector planner where the severity of the congestion cost is\nadjustable. In this paper, the Non-dominated Sorting Genetic Algorithm\n(NSGA-II) was used to solve an artificial benchmark problem involving 24\naircraft and 11 sectors, and is able to provide a good approximation of the\nPareto front.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2013 11:52:07 GMT"}], "update_date": "2013-09-17", "authors_parsed": [["Marceau", "Ga\u00e9tan", "", "INRIA Saclay - Ile de France, LRI"], ["Sav\u00e9ant", "Pierre", "", "INRIA Saclay - Ile de France, LRI"], ["Schoenauer", "Marc", "", "INRIA Saclay - Ile de France, LRI"]]}, {"id": "1309.3921", "submitter": "Gaetan Marceau", "authors": "Ga\\'etan Marceau (INRIA Saclay - Ile de France, LRI), Pierre\n  Sav\\'eant, Marc Schoenauer (INRIA Saclay - Ile de France, LRI)", "title": "Computational Methods for Probabilistic Inference of Sector Congestion\n  in Air Traffic Management", "comments": "Interdisciplinary Science for Innovative Air Traffic Management\n  (2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article addresses the issue of computing the expected cost functions\nfrom a probabilistic model of the air traffic flow and capacity management. The\nClenshaw-Curtis quadrature is compared to Monte-Carlo algorithms defined\nspecifically for this problem. By tailoring the algorithms to this model, we\nreduce the computational burden in order to simulate real instances. The study\nshows that the Monte-Carlo algorithm is more sensible to the amount of\nuncertainty in the system, but has the advantage to return a result with the\nassociated accuracy on demand. The performances for both approaches are\ncomparable for the computation of the expected cost of delay and the expected\ncost of congestion. Finally, this study shows some evidences that the\nsimulation of the proposed probabilistic model is tractable for realistic\ninstances.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2013 11:55:27 GMT"}], "update_date": "2013-09-17", "authors_parsed": [["Marceau", "Ga\u00e9tan", "", "INRIA Saclay - Ile de France, LRI"], ["Sav\u00e9ant", "Pierre", "", "INRIA Saclay - Ile de France, LRI"], ["Schoenauer", "Marc", "", "INRIA Saclay - Ile de France, LRI"]]}, {"id": "1309.4035", "submitter": "Peter Turney", "authors": "Peter D. Turney", "title": "Domain and Function: A Dual-Space Model of Semantic Relations and\n  Compositions", "comments": null, "journal-ref": "Journal of Artificial Intelligence Research (JAIR), (2012), 44,\n  533-585", "doi": "10.1613/jair.3640", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given appropriate representations of the semantic relations between carpenter\nand wood and between mason and stone (for example, vectors in a vector space\nmodel), a suitable algorithm should be able to recognize that these relations\nare highly similar (carpenter is to wood as mason is to stone; the relations\nare analogous). Likewise, with representations of dog, house, and kennel, an\nalgorithm should be able to recognize that the semantic composition of dog and\nhouse, dog house, is highly similar to kennel (dog house and kennel are\nsynonymous). It seems that these two tasks, recognizing relations and\ncompositions, are closely connected. However, up to now, the best models for\nrelations are significantly different from the best models for compositions. In\nthis paper, we introduce a dual-space model that unifies these two tasks. This\nmodel matches the performance of the best previous models for relations and\ncompositions. The dual-space model consists of a space for measuring domain\nsimilarity and a space for measuring function similarity. Carpenter and wood\nshare the same domain, the domain of carpentry. Mason and stone share the same\ndomain, the domain of masonry. Carpenter and mason share the same function, the\nfunction of artisans. Wood and stone share the same function, the function of\nmaterials. In the composition dog house, kennel has some domain overlap with\nboth dog and house (the domains of pets and buildings). The function of kennel\nis similar to the function of house (the function of shelters). By combining\ndomain and function similarities in various ways, we can model relations,\ncompositions, and other aspects of semantics.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2013 16:51:02 GMT"}], "update_date": "2013-09-17", "authors_parsed": [["Turney", "Peter D.", ""]]}, {"id": "1309.4085", "submitter": "Gaetan Marceau", "authors": "Ga\\'etan Marceau (INRIA Saclay - Ile de France, LRI), Pierre\n  Sav\\'eant, Marc Schoenauer (INRIA Saclay - Ile de France, LRI)", "title": "Multiobjective Tactical Planning under Uncertainty for Air Traffic Flow\n  and Capacity Management", "comments": "IEEE Congress on Evolutionary Computation (2013). arXiv admin note:\n  substantial text overlap with arXiv:1309.3917", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a method to deal with congestion of sectors and delays in the\ntactical phase of air traffic flow and capacity management. It relies on\ntemporal objectives given for every point of the flight plans and shared among\nthe controllers in order to create a collaborative environment. This would\nenhance the transition from the network view of the flow management to the\nlocal view of air traffic control. Uncertainty is modeled at the trajectory\nlevel with temporal information on the boundary points of the crossed sectors\nand then, we infer the probabilistic occupancy count. Therefore, we can model\nthe accuracy of the trajectory prediction in the optimization process in order\nto fix some safety margins. On the one hand, more accurate is our prediction;\nmore efficient will be the proposed solutions, because of the tighter safety\nmargins. On the other hand, when uncertainty is not negligible, the proposed\nsolutions will be more robust to disruptions. Furthermore, a multiobjective\nalgorithm is used to find the tradeoff between the delays and congestion, which\nare antagonist in airspace with high traffic density. The flow management\nposition can choose manually, or automatically with a preference-based\nalgorithm, the adequate solution. This method is tested against two instances,\none with 10 flights and 5 sectors and one with 300 flights and 16 sectors.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2013 11:53:39 GMT"}], "update_date": "2013-09-18", "authors_parsed": [["Marceau", "Ga\u00e9tan", "", "INRIA Saclay - Ile de France, LRI"], ["Sav\u00e9ant", "Pierre", "", "INRIA Saclay - Ile de France, LRI"], ["Schoenauer", "Marc", "", "INRIA Saclay - Ile de France, LRI"]]}, {"id": "1309.4291", "submitter": "Edmund Collins", "authors": "E. J. Collins", "title": "Models and algorithms for skip-free Markov decision processes on trees", "comments": "v1: 20 pages Accepted for publication subject to minor changes by the\n  Journal of the Operational Research Society (JORS); v2: 22 pages, 1 figure,\n  revised title, example added", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a class of models for multidimensional control problems which we\ncall skip-free Markov decision processes on trees. We describe and analyse an\nalgorithm applicable to Markov decision processes of this type that are\nskip-free in the negative direction. Starting with the finite average cost\ncase, we show that the algorithm combines the advantages of both value\niteration and policy iteration -- it is guaranteed to converge to an optimal\npolicy and optimal value function after a finite number of iterations but the\ncomputational effort required for each iteration step is comparable with that\nfor value iteration. We show that the algorithm can also be used to solve\ndiscounted cost models and continuous time models, and that a suitably modified\nalgorithm can be used to solve communicating models.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2013 12:58:40 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2013 11:30:43 GMT"}], "update_date": "2013-11-11", "authors_parsed": [["Collins", "E. J.", ""]]}, {"id": "1309.4408", "submitter": "Percy Liang", "authors": "Percy Liang", "title": "Lambda Dependency-Based Compositional Semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short note presents a new formal language, lambda dependency-based\ncompositional semantics (lambda DCS) for representing logical forms in semantic\nparsing. By eliminating variables and making existential quantification\nimplicit, lambda DCS logical forms are generally more compact than those in\nlambda calculus.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2013 17:58:56 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2013 00:45:02 GMT"}], "update_date": "2013-09-19", "authors_parsed": [["Liang", "Percy", ""]]}, {"id": "1309.4501", "submitter": "Timothy Gowers", "authors": "M. Ganesalingam and W. T. Gowers", "title": "A fully automatic problem solver with human-style output", "comments": "41 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This paper describes a program that solves elementary mathematical problems,\nmostly in metric space theory, and presents solutions that are hard to\ndistinguish from solutions that might be written by human mathematicians. The\nprogram is part of a more general project, which we also discuss.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2013 22:56:06 GMT"}], "update_date": "2013-09-19", "authors_parsed": [["Ganesalingam", "M.", ""], ["Gowers", "W. T.", ""]]}, {"id": "1309.4714", "submitter": "Patrick M. Pilarski", "authors": "Ann L. Edwards, Alexandra Kearney, Michael Rory Dawson, Richard S.\n  Sutton, Patrick M. Pilarski", "title": "Temporal-Difference Learning to Assist Human Decision Making during the\n  Control of an Artificial Limb", "comments": "5 pages, 4 figures, This version to appear at The 1st\n  Multidisciplinary Conference on Reinforcement Learning and Decision Making,\n  Princeton, NJ, USA, Oct. 25-27, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we explore the use of reinforcement learning (RL) to help with\nhuman decision making, combining state-of-the-art RL algorithms with an\napplication to prosthetics. Managing human-machine interaction is a problem of\nconsiderable scope, and the simplification of human-robot interfaces is\nespecially important in the domains of biomedical technology and rehabilitation\nmedicine. For example, amputees who control artificial limbs are often required\nto quickly switch between a number of control actions or modes of operation in\norder to operate their devices. We suggest that by learning to anticipate\n(predict) a user's behaviour, artificial limbs could take on an active role in\na human's control decisions so as to reduce the burden on their users.\nRecently, we showed that RL in the form of general value functions (GVFs) could\nbe used to accurately detect a user's control intent prior to their explicit\ncontrol choices. In the present work, we explore the use of temporal-difference\nlearning and GVFs to predict when users will switch their control influence\nbetween the different motor functions of a robot arm. Experiments were\nperformed using a multi-function robot arm that was controlled by muscle\nsignals from a user's body (similar to conventional artificial limb control).\nOur approach was able to acquire and maintain forecasts about a user's\nswitching decisions in real time. It also provides an intuitive and reward-free\nway for users to correct or reinforce the decisions made by the machine\nlearning system. We expect that when a system is certain enough about its\npredictions, it can begin to take over switching decisions from the user to\nstreamline control and potentially decrease the time and effort needed to\ncomplete tasks. This preliminary study therefore suggests a way to naturally\nintegrate human- and machine-based decision making systems.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2013 17:29:03 GMT"}], "update_date": "2013-09-19", "authors_parsed": [["Edwards", "Ann L.", ""], ["Kearney", "Alexandra", ""], ["Dawson", "Michael Rory", ""], ["Sutton", "Richard S.", ""], ["Pilarski", "Patrick M.", ""]]}, {"id": "1309.4744", "submitter": "Liane Gabora", "authors": "Murad A. Mithani, Tomas Veloz, and Liane Gabora", "title": "Modeling the Role of Context Dependency in the Recognition and\n  Manifestation of Entrepreneurial Opportunity", "comments": "8 pages In: P. Bruza, W. Lawless, K. van Rijsbergen, D. Sofge, & D.\n  Widdows (Eds.) Proc Assoc Advance Artif Intel Fall Symposium: Quantum\n  Informatics for Cognitive, Social, and Semantic Processes. AAAI Press, 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper uses the SCOP theory of concepts to model the role of environmental\ncontext on three levels of entrepreneurial opportunity: idea generation, idea\ndevelopment, and entrepreneurial decision. The role of contextual-fit in the\ngeneration and development of ideas is modeled as the collapse of their\nsuperposition state into one of the potential states that composes this\nsuperposition. The projection of this collapsed state on the socio-economic\nbasis results in interference of the developed idea with the perceptions of the\nsupporting community, undergoing an eventual collapse for an entrepreneurial\ndecision that reflects the shared vision of its stakeholders. The developed\nidea may continue to evolve due to continuous or discontinuous changes in the\nenvironment. The model offers unique insights into the effects of external\ninfluences on entrepreneurial decisions.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2013 18:45:39 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 02:34:15 GMT"}, {"version": "v3", "created": "Fri, 5 Jul 2019 18:24:33 GMT"}, {"version": "v4", "created": "Tue, 9 Jul 2019 19:29:43 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Mithani", "Murad A.", ""], ["Veloz", "Tomas", ""], ["Gabora", "Liane", ""]]}, {"id": "1309.4927", "submitter": "Miika Hannula", "authors": "Miika Hannula and Juha Kontinen", "title": "A finite axiomatization of conditional independence and inclusion\n  dependencies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.AI cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a complete finite axiomatization of the unrestricted implication\nproblem for inclusion and conditional independence atoms in the context of\ndependence logic. For databases, our result implies a finite axiomatization of\nthe unrestricted implication problem for inclusion, functional, and embedded\nmultivalued dependencies in the unirelational case.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2013 10:59:05 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2013 07:58:30 GMT"}], "update_date": "2013-09-23", "authors_parsed": [["Hannula", "Miika", ""], ["Kontinen", "Juha", ""]]}, {"id": "1309.4962", "submitter": "Josef Urban", "authors": "Cezary Kaliszyk and Josef Urban", "title": "HOL(y)Hammer: Online ATP Service for HOL Light", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DL cs.LG cs.LO cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  HOL(y)Hammer is an online AI/ATP service for formal (computer-understandable)\nmathematics encoded in the HOL Light system. The service allows its users to\nupload and automatically process an arbitrary formal development (project)\nbased on HOL Light, and to attack arbitrary conjectures that use the concepts\ndefined in some of the uploaded projects. For that, the service uses several\nautomated reasoning systems combined with several premise selection methods\ntrained on all the project proofs. The projects that are readily available on\nthe server for such query answering include the recent versions of the\nFlyspeck, Multivariate Analysis and Complex Analysis libraries. The service\nruns on a 48-CPU server, currently employing in parallel for each task 7 AI/ATP\ncombinations and 4 decision procedures that contribute to its overall\nperformance. The system is also available for local installation by interested\nusers, who can customize it for their own proof development. An Emacs interface\nallowing parallel asynchronous queries to the service is also provided. The\noverall structure of the service is outlined, problems that arise and their\nsolutions are discussed, and an initial account of using the system is given.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2013 13:22:31 GMT"}], "update_date": "2013-09-20", "authors_parsed": [["Kaliszyk", "Cezary", ""], ["Urban", "Josef", ""]]}, {"id": "1309.5018", "submitter": "Naveen Ashish", "authors": "Ben Zamanzadeh, Naveen Ashish, Cartic Ramakrishnan and John Zimmerman", "title": "Semantic Advertising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the concept of Semantic Advertising which we see as the future of\nonline advertising. Semantic Advertising is online advertising powered by\nsemantic technology which essentially enables us to represent and reason with\nconcepts and the meaning of things. This paper aims to 1) Define semantic\nadvertising, 2) Place it in the context of broader and more widely used\nconcepts such as the Semantic Web and Semantic Search, 3) Provide a survey of\nwork in related areas such as context matching, and 4) Provide a perspective on\nsuccessful emerging technologies and areas of future work. We base our work on\nour experience as a company developing semantic technologies aimed at realizing\nthe full potential of online advertising.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2013 15:23:24 GMT"}], "update_date": "2013-09-20", "authors_parsed": [["Zamanzadeh", "Ben", ""], ["Ashish", "Naveen", ""], ["Ramakrishnan", "Cartic", ""], ["Zimmerman", "John", ""]]}, {"id": "1309.5110", "submitter": "Wilfredo Ariel G\\'omez Bueno WAGomez", "authors": "Edson Fl\\'orez, Wilfredo G\\'omez, Lola Bautista", "title": "An ant colony optimization algorithm for job shop scheduling problem", "comments": "http://www.airccse.org/journal/ijaia/current2013.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The nature has inspired several metaheuristics, outstanding among these is\nAnt Colony Optimization (ACO), which have proved to be very effective and\nefficient in problems of high complexity (NP-hard) in combinatorial\noptimization. This paper describes the implementation of an ACO model algorithm\nknown as Elitist Ant System (EAS), applied to a combinatorial optimization\nproblem called Job Shop Scheduling Problem (JSSP). We propose a method that\nseeks to reduce delays designating the operation immediately available, but\nconsidering the operations that lack little to be available and have a greater\namount of pheromone. The performance of the algorithm was evaluated for\nproblems of JSSP reference, comparing the quality of the solutions obtained\nregarding the best known solution of the most effective methods. The solutions\nwere of good quality and obtained with a remarkable efficiency by having to\nmake a very low number of objective function evaluations.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2013 22:05:35 GMT"}], "update_date": "2013-09-23", "authors_parsed": [["Fl\u00f3rez", "Edson", ""], ["G\u00f3mez", "Wilfredo", ""], ["Bautista", "Lola", ""]]}, {"id": "1309.5316", "submitter": "Brigitte Charnomordic", "authors": "Aur\\'elie Th\\'ebaut (MISTEA), Thibault Scholash, Brigitte Charnomordic\n  (MISTEA), Nadine Hilgert (MISTEA)", "title": "A modeling approach to design a software sensor and analyze agronomical\n  features - Application to sap flow and grape quality relationship", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a framework using temporal data and domain knowledge in\norder to analyze complex agronomical features. The expertise is first\nformalized in an ontology, under the form of concepts and relationships between\nthem, and then used in conjunction with raw data and mathematical models to\ndesign a software sensor. Next the software sensor outputs are put in relation\nto product quality, assessed by quantitative measurements. This requires the\nuse of advanced data analysis methods, such as functional regression. The\nmethodology is applied to a case study involving an experimental design in\nFrench vineyards. The temporal data consist of sap flow measurements, and the\ngoal is to explain fruit quality (sugar concentration and weight), using vine's\nwater courses through the various vine phenological stages. The results are\ndiscussed, as well as the method genericity and robustness.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2013 16:41:43 GMT"}], "update_date": "2013-09-23", "authors_parsed": [["Th\u00e9baut", "Aur\u00e9lie", "", "MISTEA"], ["Scholash", "Thibault", "", "MISTEA"], ["Charnomordic", "Brigitte", "", "MISTEA"], ["Hilgert", "Nadine", "", "MISTEA"]]}, {"id": "1309.5502", "submitter": "Washington Alves de Oliveira", "authors": "Washington Alves de Oliveira, Antonio Carlos Moretti and Ednei Felix\n  Reis", "title": "The multi-vehicle covering tour problem: building routes for urban\n  patrolling", "comments": "28 pages, 8 figures, 7 tables, Brazilian Operations Research Society;\n  Printed version ISSN 0101-7438 / Online version ISSN 1678-5142", "journal-ref": "Pesquisa Operacional (2015) 35(3): 617-644", "doi": "10.1590/0101-7438.2015.035.03.0617", "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study a particular aspect of the urban community policing:\nroutine patrol route planning. We seek routes that guarantee visibility, as\nthis has a sizable impact on the community perceived safety, allowing quick\nemergency responses and providing surveillance of selected sites (e.g.,\nhospitals, schools). The planning is restricted to the availability of vehicles\nand strives to achieve balanced routes. We study an adaptation of the model for\nthe multi-vehicle covering tour problem, in which a set of locations must be\nvisited, whereas another subset must be close enough to the planned routes. It\nconstitutes an NP-complete integer programming problem. Suboptimal solutions\nare obtained with several heuristics, some adapted from the literature and\nothers developed by us. We solve some adapted instances from TSPLIB and an\ninstance with real data, the former being compared with results from\nliterature, and latter being compared with empirical data.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2013 17:17:46 GMT"}, {"version": "v2", "created": "Wed, 14 Sep 2016 23:16:49 GMT"}], "update_date": "2016-09-16", "authors_parsed": [["de Oliveira", "Washington Alves", ""], ["Moretti", "Antonio Carlos", ""], ["Reis", "Ednei Felix", ""]]}, {"id": "1309.5655", "submitter": "Vladimir Kolmogorov", "authors": "Vladimir Kolmogorov", "title": "A new look at reweighted message passing", "comments": "TPAMI accepted version", "journal-ref": "TPAMI, 37(5):919-930 (May, 2015)", "doi": "10.1109/TPAMI.2014.2363465", "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new family of message passing techniques for MAP estimation in\ngraphical models which we call {\\em Sequential Reweighted Message Passing}\n(SRMP). Special cases include well-known techniques such as {\\em Min-Sum\nDiffusion} (MSD) and a faster {\\em Sequential Tree-Reweighted Message Passing}\n(TRW-S). Importantly, our derivation is simpler than the original derivation of\nTRW-S, and does not involve a decomposition into trees. This allows easy\ngeneralizations. We present such a generalization for the case of higher-order\ngraphical models, and test it on several real-world problems with promising\nresults.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2013 21:19:36 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2014 11:57:31 GMT"}, {"version": "v3", "created": "Thu, 19 Jan 2017 17:45:24 GMT"}], "update_date": "2017-01-20", "authors_parsed": [["Kolmogorov", "Vladimir", ""]]}, {"id": "1309.5984", "submitter": "Phillip Lord Dr", "authors": "Phillip Lord", "title": "An evolutionary approach to Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Background: Understanding the distinction between function and role is vexing\nand difficult. While it appears to be useful, in practice this distinction is\nhard to apply, particularly within biology.\n  Results: I take an evolutionary approach, considering a series of examples,\nto develop and generate definitions for these concepts. I test them in practice\nagainst the Ontology for Biomedical Investigations (OBI). Finally, I give an\naxiomatisation and discuss methods for applying these definitions in practice.\n  Conclusions: The definitions in this paper are applicable, formalizing\ncurrent practice. As such, they make a significant contribution to the use of\nthese concepts within biomedical ontologies.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2013 21:15:10 GMT"}], "update_date": "2013-09-25", "authors_parsed": [["Lord", "Phillip", ""]]}, {"id": "1309.6129", "submitter": "Kyomin Jung", "authors": "Vincent Blondel, Kyomin Jung, Pushmeet Kohli, Devavrat Shah", "title": "Partition-Merge: Distributed Inference and Modularity Optimization", "comments": "19 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel meta algorithm, Partition-Merge (PM), which takes\nexisting centralized algorithms for graph computation and makes them\ndistributed and faster. In a nutshell, PM divides the graph into small\nsubgraphs using our novel randomized partitioning scheme, runs the centralized\nalgorithm on each partition separately, and then stitches the resulting\nsolutions to produce a global solution. We demonstrate the efficiency of the PM\nalgorithm on two popular problems: computation of Maximum A Posteriori (MAP)\nassignment in an arbitrary pairwise Markov Random Field (MRF), and modularity\noptimization for community detection. We show that the resulting distributed\nalgorithms for these problems essentially run in time linear in the number of\nnodes in the graph, and perform as well -- or even better -- than the original\ncentralized algorithm as long as the graph has geometric structures. Here we\nsay a graph has geometric structures, or polynomial growth property, when the\nnumber of nodes within distance r of any given node grows no faster than a\npolynomial function of r. More precisely, if the centralized algorithm is a\nC-factor approximation with constant C \\ge 1, the resulting distributed\nalgorithm is a (C+\\delta)-factor approximation for any small \\delta>0; but if\nthe centralized algorithm is a non-constant (e.g. logarithmic) factor\napproximation, then the resulting distributed algorithm becomes a constant\nfactor approximation. For general graphs, we compute explicit bounds on the\nloss of performance of the resulting distributed algorithm with respect to the\ncentralized algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2013 12:32:34 GMT"}], "update_date": "2013-09-25", "authors_parsed": [["Blondel", "Vincent", ""], ["Jung", "Kyomin", ""], ["Kohli", "Pushmeet", ""], ["Shah", "Devavrat", ""]]}, {"id": "1309.6226", "submitter": "Claus-Peter Wirth", "authors": "J Strother Moore, Claus-Peter Wirth", "title": "Automation of Mathematical Induction as part of the History of Logic", "comments": "ii+107 pages", "journal-ref": "IfCoLog Journal of Logics and their Applications, Vol. 4, number\n  5, pp. 1505-1634 (2017)", "doi": null, "report-no": "SEKI-Report SR-2013-02. ISSN 1437--4447", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review the history of the automation of mathematical induction\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2013 15:51:43 GMT"}, {"version": "v2", "created": "Sun, 6 Oct 2013 18:40:28 GMT"}, {"version": "v3", "created": "Thu, 9 Jan 2014 19:30:52 GMT"}, {"version": "v4", "created": "Tue, 18 Mar 2014 20:04:26 GMT"}, {"version": "v5", "created": "Mon, 28 Jul 2014 19:20:22 GMT"}], "update_date": "2017-08-04", "authors_parsed": [["Moore", "J Strother", ""], ["Wirth", "Claus-Peter", ""]]}, {"id": "1309.6297", "submitter": "Esra Erdem", "authors": "Esra Erdem, Umut Oztok", "title": "Generating Explanations for Biomedical Queries", "comments": "42 pages, 14 figures, 4 tables, online appendix (proofs, 24 pages)", "journal-ref": "Theory and Practice of Logic Programming 15 (2015) 35-78", "doi": "10.1017/S1471068413000598", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce novel mathematical models and algorithms to generate (shortest\nor k different) explanations for biomedical queries, using answer set\nprogramming. We implement these algorithms and integrate them in BIOQUERY-ASP.\nWe illustrate the usefulness of these methods with some complex biomedical\nqueries related to drug discovery, over the biomedical knowledge resources\nPHARMGKB, DRUGBANK, BIOGRID, CTD, SIDER, DISEASE ONTOLOGY and ORPHADATA. To\nappear in Theory and Practice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2013 19:28:44 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Erdem", "Esra", ""], ["Oztok", "Umut", ""]]}, {"id": "1309.6433", "submitter": "Mohammad Bazmara", "authors": "Mohammad Bazmara, Shahram Jafari, Fatemeh Pasand", "title": "A Fuzzy expert system for goalkeeper quality recognition", "comments": "5 pages", "journal-ref": "IJCSI International Journal of Computer Science Issues, Vol. 9,\n  Issue 5, No 1, September 2012", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goalkeeper (GK) is an expert in soccer and goalkeeping is a complete\nprofessional job. In fact, achieving success seems impossible without a\nreliable GK. His effect in successes and failures is more dominant than other\nplayers. The most visible mistakes in a game are those of goalkeeper's. In this\npaper the expert fuzzy system is used as a suitable tool to study the quality\nof a goalkeeper and compare it with others. Previously done researches are used\nto find the goalkeepers' indexes in soccer. Soccer experts have found that a\nsuccessful GK should have some qualifications. A new pattern is offered here\nwhich is called \"Soccer goalkeeper quality recognition using fuzzy expert\nsystems\". This pattern has some important capabilities. Firstly, among some\ngoalkeepers the one with the best quality for the main team arrange can be\nchosen. Secondly, the need to expert coaches for choosing a GK using their\nsenses and experiences decreases a lot. Thirdly, in the survey of a GK,\nquantitative criteria can be included, and finally this pattern is simple and\neasy to understand.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2013 09:05:32 GMT"}], "update_date": "2013-09-26", "authors_parsed": [["Bazmara", "Mohammad", ""], ["Jafari", "Shahram", ""], ["Pasand", "Fatemeh", ""]]}, {"id": "1309.6449", "submitter": "German Terrazas", "authors": "German Terrazas, Hector Zenil, Natalio Krasnogor", "title": "Exploring Programmable Self-Assembly in Non-DNA based Molecular\n  Computing", "comments": null, "journal-ref": null, "doi": "10.1007/s11047-013-9397-2", "report-no": null, "categories": "cs.CC cs.AI cs.CE physics.comp-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-assembly is a phenomenon observed in nature at all scales where\nautonomous entities build complex structures, without external influences nor\ncentralised master plan. Modelling such entities and programming correct\ninteractions among them is crucial for controlling the manufacture of desired\ncomplex structures at the molecular and supramolecular scale. This work focuses\non a programmability model for non DNA-based molecules and complex behaviour\nanalysis of their self-assembled conformations. In particular, we look into\nmodelling, programming and simulation of porphyrin molecules self-assembly and\napply Kolgomorov complexity-based techniques to classify and assess simulation\nresults in terms of information content. The analysis focuses on phase\ntransition, clustering, variability and parameter discovery which as a whole\npave the way to the notion of complex systems programmability.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2013 10:00:18 GMT"}], "update_date": "2013-09-26", "authors_parsed": [["Terrazas", "German", ""], ["Zenil", "Hector", ""], ["Krasnogor", "Natalio", ""]]}, {"id": "1309.6815", "submitter": "Paul Beame", "authors": "Paul Beame, Jerry Li, Sudeepa Roy, Dan Suciu", "title": "Lower Bounds for Exact Model Counting and Applications in Probabilistic\n  Databases", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-52-61", "categories": "cs.DB cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The best current methods for exactly computing the number of satisfying\nassignments, or the satisfying probability, of Boolean formulas can be seen,\neither directly or indirectly, as building 'decision-DNNF' (decision\ndecomposable negation normal form) representations of the input Boolean\nformulas. Decision-DNNFs are a special case of 'd-DNNF's where 'd' stands for\n'deterministic'. We show that any decision-DNNF can be converted into an\nequivalent 'FBDD' (free binary decision diagram) -- also known as a 'read-once\nbranching program' (ROBP or 1-BP) -- with only a quasipolynomial increase in\nrepresentation size in general, and with only a polynomial increase in size in\nthe special case of monotone k-DNF formulas. Leveraging known exponential lower\nbounds for FBDDs, we then obtain similar exponential lower bounds for\ndecision-DNNFs which provide lower bounds for the recent algorithms. We also\nseparate the power of decision-DNNFs from d-DNNFs and a generalization of\ndecision-DNNFs known as AND-FBDDs. Finally we show how these imply exponential\nlower bounds for natural problems associated with probabilistic databases.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:29:56 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Beame", "Paul", ""], ["Li", "Jerry", ""], ["Roy", "Sudeepa", ""], ["Suciu", "Dan", ""]]}, {"id": "1309.6816", "submitter": "Vaishak Belle", "authors": "Vaishak Belle, Hector Levesque", "title": "Reasoning about Probabilities in Dynamic Systems using Goal Regression", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-62-71", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning about degrees of belief in uncertain dynamic worlds is fundamental\nto many applications, such as robotics and planning, where actions modify state\nproperties and sensors provide measurements, both of which are prone to noise.\nWith the exception of limited cases such as Gaussian processes over linear\nphenomena, belief state evolution can be complex and hard to reason with in a\ngeneral way. This paper proposes a framework with new results that allows the\nreduction of subjective probabilities after sensing and acting to questions\nabout the initial state only. We build on an expressive probabilistic\nfirst-order logical account by Bacchus, Halpern and Levesque, resulting in a\nmethodology that, in principle, can be coupled with a variety of existing\ninference solutions.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:30:21 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Belle", "Vaishak", ""], ["Levesque", "Hector", ""]]}, {"id": "1309.6817", "submitter": "Damien Bigot", "authors": "Damien Bigot, Bruno Zanuttini, Helene Fargier, Jerome Mengin", "title": "Probabilistic Conditional Preference Networks", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-72-81", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to represent the preferences of a group of individuals, we introduce\nProbabilistic CP-nets (PCP-nets). PCP-nets provide a compact language for\nrepresenting probability distributions over preference orderings. We argue that\nthey are useful for aggregating preferences or modelling noisy preferences.\nThen we give efficient algorithms for the main reasoning problems, namely for\ncomputing the probability that a given outcome is preferred to another one, and\nthe probability that a given outcome is optimal. As a by-product, we obtain an\nunexpected linear-time algorithm for checking dominance in a standard,\ntree-structured CP-net.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:34:49 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Bigot", "Damien", ""], ["Zanuttini", "Bruno", ""], ["Fargier", "Helene", ""], ["Mengin", "Jerome", ""]]}, {"id": "1309.6820", "submitter": "Eliot Brenner", "authors": "Eliot Brenner, David Sontag", "title": "SparsityBoost: A New Scoring Function for Learning Bayesian Network\n  Structure", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-112-121", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new consistent scoring function for structure learning of Bayesian\nnetworks. In contrast to traditional approaches to scorebased structure\nlearning, such as BDeu or MDL, the complexity penalty that we propose is\ndata-dependent and is given by the probability that a conditional independence\ntest correctly shows that an edge cannot exist. What really distinguishes this\nnew scoring function from earlier work is that it has the property of becoming\ncomputationally easier to maximize as the amount of data increases. We prove a\npolynomial sample complexity result, showing that maximizing this score is\nguaranteed to correctly learn a structure with no false edges and a\ndistribution close to the generating distribution, whenever there exists a\nBayesian network which is a perfect map for the data generating distribution.\nAlthough the new score can be used with any search algorithm, we give empirical\nresults showing that it is particularly effective when used together with a\nlinear programming relaxation approach to Bayesian network structure learning.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:35:41 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Brenner", "Eliot", ""], ["Sontag", "David", ""]]}, {"id": "1309.6822", "submitter": "Hung Bui", "authors": "Hung Bui, Tuyen Huynh, Sebastian Riedel", "title": "Automorphism Groups of Graphical Models and Lifted Variational Inference", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-132-141", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using the theory of group action, we first introduce the concept of the\nautomorphism group of an exponential family or a graphical model, thus\nformalizing the general notion of symmetry of a probabilistic model. This\nautomorphism group provides a precise mathematical framework for lifted\ninference in the general exponential family. Its group action partitions the\nset of random variables and feature functions into equivalent classes (called\norbits) having identical marginals and expectations. Then the inference problem\nis effectively reduced to that of computing marginals or expectations for each\nclass, thus avoiding the need to deal with each individual variable or feature.\nWe demonstrate the usefulness of this general framework in lifting two classes\nof variational approximation for maximum a posteriori (MAP) inference: local\nlinear programming (LP) relaxation and local LP relaxation with cycle\nconstraints; the latter yields the first lifted variational inference algorithm\nthat operates on a bound tighter than the local constraints.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:36:16 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Bui", "Hung", ""], ["Huynh", "Tuyen", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1309.6824", "submitter": "Tom Claassen", "authors": "Tom Claassen, Joris Mooij, Tom Heskes", "title": "Learning Sparse Causal Models is not NP-hard", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-172-181", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows that causal model discovery is not an NP-hard problem, in\nthe sense that for sparse graphs bounded by node degree k the sound and\ncomplete causal model can be obtained in worst case order N^{2(k+2)}\nindependence tests, even when latent variables and selection bias may be\npresent. We present a modification of the well-known FCI algorithm that\nimplements the method for an independence oracle, and suggest improvements for\nsample/real-world data versions. It does not contradict any known hardness\nresults, and does not solve an NP-hard problem: it just proves that sparse\ncausal discovery is perhaps more complicated, but not as hard as learning\nminimal Bayesian networks.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:36:47 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Claassen", "Tom", ""], ["Mooij", "Joris", ""], ["Heskes", "Tom", ""]]}, {"id": "1309.6825", "submitter": "James Cussens", "authors": "Mark Bartlett, James Cussens", "title": "Advances in Bayesian Network Learning using Integer Programming", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-182-191", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning Bayesian networks (BNs) from complete\ndiscrete data. This problem of discrete optimisation is formulated as an\ninteger program (IP). We describe the various steps we have taken to allow\nefficient solving of this IP. These are (i) efficient search for cutting\nplanes, (ii) a fast greedy algorithm to find high-scoring (perhaps not optimal)\nBNs and (iii) tightening the linear relaxation of the IP. After relating this\nBN learning problem to set covering and the multidimensional 0-1 knapsack\nproblem, we present our empirical results. These show improvements, sometimes\ndramatic, over earlier results.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:37:01 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2015 13:56:08 GMT"}], "update_date": "2015-03-24", "authors_parsed": [["Bartlett", "Mark", ""], ["Cussens", "James", ""]]}, {"id": "1309.6826", "submitter": "Nicolas Drougard", "authors": "Nicolas Drougard, Florent Teichteil-Konigsbuch, Jean-Loup Farges,\n  Didier Dubois", "title": "Qualitative Possibilistic Mixed-Observable MDPs", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-192-201", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Possibilistic and qualitative POMDPs (pi-POMDPs) are counterparts of POMDPs\nused to model situations where the agent's initial belief or observation\nprobabilities are imprecise due to lack of past experiences or insufficient\ndata collection. However, like probabilistic POMDPs, optimally solving\npi-POMDPs is intractable: the finite belief state space exponentially grows\nwith the number of system's states. In this paper, a possibilistic version of\nMixed-Observable MDPs is presented to get around this issue: the complexity of\nsolving pi-POMDPs, some state variables of which are fully observable, can be\nthen dramatically reduced. A value iteration algorithm for this new formulation\nunder infinite horizon is next proposed and the optimality of the returned\npolicy (for a specified criterion) is shown assuming the existence of a \"stay\"\naction in some goal states. Experimental work finally shows that this\npossibilistic model outperforms probabilistic POMDPs commonly used in robotics,\nfor a target recognition problem where the agent's observations are imprecise.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:37:15 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Drougard", "Nicolas", ""], ["Teichteil-Konigsbuch", "Florent", ""], ["Farges", "Jean-Loup", ""], ["Dubois", "Didier", ""]]}, {"id": "1309.6827", "submitter": "Stefano Ermon", "authors": "Stefano Ermon, Carla P. Gomes, Ashish Sabharwal, Bart Selman", "title": "Optimization With Parity Constraints: From Binary Codes to Discrete\n  Integration", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-202-211", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many probabilistic inference tasks involve summations over exponentially\nlarge sets. Recently, it has been shown that these problems can be reduced to\nsolving a polynomial number of MAP inference queries for a model augmented with\nrandomly generated parity constraints. By exploiting a connection with\nmax-likelihood decoding of binary codes, we show that these optimizations are\ncomputationally hard. Inspired by iterative message passing decoding\nalgorithms, we propose an Integer Linear Programming (ILP) formulation for the\nproblem, enhanced with new sparsification techniques to improve decoding\nperformance. By solving the ILP through a sequence of LP relaxations, we get\nboth lower and upper bounds on the partition function, which hold with high\nprobability and are much tighter than those obtained with variational methods.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:37:33 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Ermon", "Stefano", ""], ["Gomes", "Carla P.", ""], ["Sabharwal", "Ashish", ""], ["Selman", "Bart", ""]]}, {"id": "1309.6828", "submitter": "Zohar Feldman", "authors": "Zohar Feldman, Carmel Domshlak", "title": "Monte-Carlo Planning: Theoretically Fast Convergence Meets Practical\n  Efficiency", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-212-221", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Popular Monte-Carlo tree search (MCTS) algorithms for online planning, such\nas epsilon-greedy tree search and UCT, aim at rapidly identifying a reasonably\ngood action, but provide rather poor worst-case guarantees on performance\nimprovement over time. In contrast, a recently introduced MCTS algorithm BRUE\nguarantees exponential-rate improvement over time, yet it is not geared towards\nidentifying reasonably good choices right at the go. We take a stand on the\nindividual strengths of these two classes of algorithms, and show how they can\nbe effectively connected. We then rationalize a principle of \"selective tree\nexpansion\", and suggest a concrete implementation of this principle within\nMCTS. The resulting algorithm,s favorably compete with other MCTS algorithms\nunder short planning times, while preserving the attractive convergence\nproperties of BRUE.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:37:50 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Feldman", "Zohar", ""], ["Domshlak", "Carmel", ""]]}, {"id": "1309.6829", "submitter": "Qiang Fu", "authors": "Qiang Fu, Huahua Wang, Arindam Banerjee", "title": "Bethe-ADMM for Tree Decomposition based Parallel MAP Inference", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-222-231", "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of maximum a posteriori (MAP) inference in discrete\ngraphical models. We present a parallel MAP inference algorithm called\nBethe-ADMM based on two ideas: tree-decomposition of the graph and the\nalternating direction method of multipliers (ADMM). However, unlike the\nstandard ADMM, we use an inexact ADMM augmented with a Bethe-divergence based\nproximal function, which makes each subproblem in ADMM easy to solve in\nparallel using the sum-product algorithm. We rigorously prove global\nconvergence of Bethe-ADMM. The proposed algorithm is extensively evaluated on\nboth synthetic and real datasets to illustrate its effectiveness. Further, the\nparallel Bethe-ADMM is shown to scale almost linearly with increasing number of\ncores.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:38:09 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Fu", "Qiang", ""], ["Wang", "Huahua", ""], ["Banerjee", "Arindam", ""]]}, {"id": "1309.6832", "submitter": "Vibhav Gogate", "authors": "Vibhav Gogate, Pedro Domingos", "title": "Structured Message Passing", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-252-261", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present structured message passing (SMP), a unifying\nframework for approximate inference algorithms that take advantage of\nstructured representations such as algebraic decision diagrams and sparse hash\ntables. These representations can yield significant time and space savings over\nthe conventional tabular representation when the message has several identical\nvalues (context-specific independence) or zeros (determinism) or both in its\nrange. Therefore, in order to fully exploit the power of structured\nrepresentations, we propose to artificially introduce context-specific\nindependence and determinism in the messages. This yields a new class of\npowerful approximate inference algorithms which includes popular algorithms\nsuch as cluster-graph Belief propagation (BP), expectation propagation and\nparticle BP as special cases. We show that our new algorithms introduce several\ninteresting bias-variance trade-offs. We evaluate these trade-offs empirically\nand demonstrate that our new algorithms are more accurate and scalable than\nstate-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:39:56 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Gogate", "Vibhav", ""], ["Domingos", "Pedro", ""]]}, {"id": "1309.6836", "submitter": "Antti Hyttinen", "authors": "Antti Hyttinen, Patrik O. Hoyer, Frederick Eberhardt, Matti Jarvisalo", "title": "Discovering Cyclic Causal Models with Latent Variables: A General\n  SAT-Based Procedure", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-301-310", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a very general approach to learning the structure of causal models\nbased on d-separation constraints, obtained from any given set of overlapping\npassive observational or experimental data sets. The procedure allows for both\ndirected cycles (feedback loops) and the presence of latent variables. Our\napproach is based on a logical representation of causal pathways, which permits\nthe integration of quite general background knowledge, and inference is\nperformed using a Boolean satisfiability (SAT) solver. The procedure is\ncomplete in that it exhausts the available information on whether any given\nedge can be determined to be present or absent, and returns \"unknown\"\notherwise. Many existing constraint-based causal discovery algorithms can be\nseen as special cases, tailored to circumstances in which one or more\nrestricting assumptions apply. Simulations illustrate the effect of these\nassumptions on discovery and how the present algorithm scales.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:41:22 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Hyttinen", "Antti", ""], ["Hoyer", "Patrik O.", ""], ["Eberhardt", "Frederick", ""], ["Jarvisalo", "Matti", ""]]}, {"id": "1309.6839", "submitter": "Arindam Khaled", "authors": "Arindam Khaled, Eric A. Hansen, Changhe Yuan", "title": "Solving Limited-Memory Influence Diagrams Using Branch-and-Bound Search", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-331-340", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A limited-memory influence diagram (LIMID) generalizes a traditional\ninfluence diagram by relaxing the assumptions of regularity and no-forgetting,\nallowing a wider range of decision problems to be modeled. Algorithms for\nsolving traditional influence diagrams are not easily generalized to solve\nLIMIDs, however, and only recently have exact algorithms for solving LIMIDs\nbeen developed. In this paper, we introduce an exact algorithm for solving\nLIMIDs that is based on branch-and-bound search. Our approach is related to the\napproach of solving an influence diagram by converting it to an equivalent\ndecision tree, with the difference that the LIMID is converted to a much\nsmaller decision graph that can be searched more efficiently.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:41:55 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Khaled", "Arindam", ""], ["Hansen", "Eric A.", ""], ["Yuan", "Changhe", ""]]}, {"id": "1309.6842", "submitter": "Sanghack Lee", "authors": "Sanghack Lee, Vasant Honavar", "title": "Causal Transportability of Experiments on Controllable Subsets of\n  Variables: z-Transportability", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-361-370", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce z-transportability, the problem of estimating the causal effect\nof a set of variables X on another set of variables Y in a target domain from\nexperiments on any subset of controllable variables Z where Z is an arbitrary\nsubset of observable variables V in a source domain. z-Transportability\ngeneralizes z-identifiability, the problem of estimating in a given domain the\ncausal effect of X on Y from surrogate experiments on a set of variables Z such\nthat Z is disjoint from X;. z-Transportability also generalizes\ntransportability which requires that the causal effect of X on Y in the target\ndomain be estimable from experiments on any subset of all observable variables\nin the source domain. We first generalize z-identifiability to allow cases\nwhere Z is not necessarily disjoint from X. Then, we establish a necessary and\nsufficient condition for z-transportability in terms of generalized\nz-identifiability and transportability. We provide a correct and complete\nalgorithm that determines whether a causal effect is z-transportable; and if it\nis, produces a transport formula, that is, a recipe for estimating the causal\neffect of X on Y in the target domain using information elicited from the\nresults of experimental manipulations of Z in the source domain and\nobservational data from the target domain. Our results also show that\ndo-calculus is complete for z-transportability.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:42:52 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Lee", "Sanghack", ""], ["Honavar", "Vasant", ""]]}, {"id": "1309.6843", "submitter": "Marc Maier", "authors": "Marc Maier, Katerina Marazopoulou, David Arbour, David Jensen", "title": "A Sound and Complete Algorithm for Learning Causal Models from\n  Relational Data", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-371-380", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The PC algorithm learns maximally oriented causal Bayesian networks. However,\nthere is no equivalent complete algorithm for learning the structure of\nrelational models, a more expressive generalization of Bayesian networks.\nRecent developments in the theory and representation of relational models\nsupport lifted reasoning about conditional independence. This enables a\npowerful constraint for orienting bivariate dependencies and forms the basis of\na new algorithm for learning structure. We present the relational causal\ndiscovery (RCD) algorithm that learns causal relational models. We prove that\nRCD is sound and complete, and we present empirical results that demonstrate\neffectiveness.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:43:12 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Maier", "Marc", ""], ["Marazopoulou", "Katerina", ""], ["Arbour", "David", ""], ["Jensen", "David", ""]]}, {"id": "1309.6844", "submitter": "Brandon Malone", "authors": "Brandon Malone, Changhe Yuan", "title": "Evaluating Anytime Algorithms for Learning Optimal Bayesian Networks", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-381-390", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exact algorithms for learning Bayesian networks guarantee to find provably\noptimal networks. However, they may fail in difficult learning tasks due to\nlimited time or memory. In this research we adapt several anytime heuristic\nsearch-based algorithms to learn Bayesian networks. These algorithms find\nhigh-quality solutions quickly, and continually improve the incumbent solution\nor prove its optimality before resources are exhausted. Empirical results show\nthat the anytime window A* algorithm usually finds higher-quality, often\noptimal, networks more quickly than other approaches. The results also show\nthat, surprisingly, while generating networks with few parents per variable are\nstructurally simpler, they are harder to learn than complex generating networks\nwith more parents per variable.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:43:51 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Malone", "Brandon", ""], ["Yuan", "Changhe", ""]]}, {"id": "1309.6845", "submitter": "Denis D. Maua", "authors": "Denis D. Maua, Cassio Polpo de Campos, Alessio Benavoli, Alessandro\n  Antonucci", "title": "On the Complexity of Strong and Epistemic Credal Networks", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-391-400", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Credal networks are graph-based statistical models whose parameters take\nvalues in a set, instead of being sharply specified as in traditional\nstatistical models (e.g., Bayesian networks). The computational complexity of\ninferences on such models depends on the irrelevance/independence concept\nadopted. In this paper, we study inferential complexity under the concepts of\nepistemic irrelevance and strong independence. We show that inferences under\nstrong independence are NP-hard even in trees with ternary variables. We prove\nthat under epistemic irrelevance the polynomial time complexity of inferences\nin credal trees is not likely to extend to more general models (e.g. singly\nconnected networks). These results clearly distinguish networks that admit\nefficient inferences and those where inferences are most likely hard, and\nsettle several open questions regarding computational complexity.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:44:14 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Maua", "Denis D.", ""], ["de Campos", "Cassio Polpo", ""], ["Benavoli", "Alessio", ""], ["Antonucci", "Alessandro", ""]]}, {"id": "1309.6846", "submitter": "James McInerney", "authors": "James McInerney, Alex Rogers, Nicholas R. Jennings", "title": "Learning Periodic Human Behaviour Models from Sparse Data for\n  Crowdsourcing Aid Delivery in Developing Countries", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-401-410", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many developing countries, half the population lives in rural locations,\nwhere access to essentials such as school materials, mosquito nets, and medical\nsupplies is restricted. We propose an alternative method of distribution (to\nstandard road delivery) in which the existing mobility habits of a local\npopulation are leveraged to deliver aid, which raises two technical challenges\nin the areas optimisation and learning. For optimisation, a standard Markov\ndecision process applied to this problem is intractable, so we provide an exact\nformulation that takes advantage of the periodicities in human location\nbehaviour. To learn such behaviour models from sparse data (i.e., cell tower\nobservations), we develop a Bayesian model of human mobility. Using real cell\ntower data of the mobility behaviour of 50,000 individuals in Ivory Coast, we\nfind that our model outperforms the state of the art approaches in mobility\nprediction by at least 25% (in held-out data likelihood). Furthermore, when\nincorporating mobility prediction with our MDP approach, we find a 81.3%\nreduction in total delivery time versus routine planning that minimises just\nthe number of participants in the solution path.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:44:36 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["McInerney", "James", ""], ["Rogers", "Alex", ""], ["Jennings", "Nicholas R.", ""]]}, {"id": "1309.6848", "submitter": "Elad Mezuman", "authors": "Elad Mezuman, Daniel Tarlow, Amir Globerson, Yair Weiss", "title": "Tighter Linear Program Relaxations for High Order Graphical Models", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-421-430", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphical models with High Order Potentials (HOPs) have received considerable\ninterest in recent years. While there are a variety of approaches to inference\nin these models, nearly all of them amount to solving a linear program (LP)\nrelaxation with unary consistency constraints between the HOP and the\nindividual variables. In many cases, the resulting relaxations are loose, and\nin these cases the results of inference can be poor. It is thus desirable to\nlook for more accurate ways of performing inference in these models. In this\nwork, we study the LP relaxations that result from enforcing additional\nconsistency constraints between the HOP and the rest of the model. We address\ntheoretical questions about the strength of the resulting relaxations compared\nto the relaxations that arise in standard approaches, and we develop practical\nand efficient message passing algorithms for optimizing the LPs. Empirically,\nwe show that the LPs with additional consistency constraints lead to more\naccurate inference on some challenging problems that include a combination of\nlow order and high order terms.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:45:22 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Mezuman", "Elad", ""], ["Tarlow", "Daniel", ""], ["Globerson", "Amir", ""], ["Weiss", "Yair", ""]]}, {"id": "1309.6849", "submitter": "Joris Mooij", "authors": "Joris Mooij, Tom Heskes", "title": "Cyclic Causal Discovery from Continuous Equilibrium Data", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-431-439", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for learning cyclic causal models from a combination of\nobservational and interventional equilibrium data. Novel aspects of the\nproposed method are its ability to work with continuous data (without assuming\nlinearity) and to deal with feedback loops. Within the context of biochemical\nreactions, we also propose a novel way of modeling interventions that modify\nthe activity of compounds instead of their abundance. For computational\nreasons, we approximate the nonlinear causal mechanisms by (coupled) local\nlinearizations, one for each experimental condition. We apply the method to\nreconstruct a cellular signaling network from the flow cytometry data measured\nby Sachs et al. (2005). We show that our method finds evidence in the data for\nfeedback loops and that it gives a more accurate quantitative description of\nthe data at comparable model complexity.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:45:43 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Mooij", "Joris", ""], ["Heskes", "Tom", ""]]}, {"id": "1309.6851", "submitter": "Teppo Niinimaki", "authors": "Teppo Niinimaki, Mikko Koivisto", "title": "Treedy: A Heuristic for Counting and Sampling Subsets", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-469-477", "categories": "cs.DS cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a collection of weighted subsets of a ground set N. Given a query\nsubset Q of N, how fast can one (1) find the weighted sum over all subsets of\nQ, and (2) sample a subset of Q proportionally to the weights? We present a\ntree-based greedy heuristic, Treedy, that for a given positive tolerance d\nanswers such counting and sampling queries to within a guaranteed relative\nerror d and total variation distance d, respectively. Experimental results on\nartificial instances and in application to Bayesian structure discovery in\nBayesian networks show that approximations yield dramatic savings in running\ntime compared to exact computation, and that Treedy typically outperforms a\npreviously proposed sorting-based heuristic.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:46:13 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Niinimaki", "Teppo", ""], ["Koivisto", "Mikko", ""]]}, {"id": "1309.6855", "submitter": "Michael Pacer", "authors": "Michael Pacer, Joseph Williams, Xi Chen, Tania Lombrozo, Thomas\n  Griffiths", "title": "Evaluating computational models of explanation using human judgments", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-498-507", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluate four computational models of explanation in Bayesian networks by\ncomparing model predictions to human judgments. In two experiments, we present\nhuman participants with causal structures for which the models make divergent\npredictions and either solicit the best explanation for an observed event\n(Experiment 1) or have participants rate provided explanations for an observed\nevent (Experiment 2). Across two versions of two causal structures and across\nboth experiments, we find that the Causal Explanation Tree and Most Relevant\nExplanation models provide better fits to human data than either Most Probable\nExplanation or Explanation Tree models. We identify strengths and shortcomings\nof these models and what they can reveal about human explanation. We conclude\nby suggesting the value of pursuing computational and psychological\ninvestigations of explanation in parallel.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:47:15 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Pacer", "Michael", ""], ["Williams", "Joseph", ""], ["Chen", "Xi", ""], ["Lombrozo", "Tania", ""], ["Griffiths", "Thomas", ""]]}, {"id": "1309.6856", "submitter": "Patrice Perny", "authors": "Patrice Perny, Paul Weng, Judy Goldsmith, Josiah Hanna", "title": "Approximation of Lorenz-Optimal Solutions in Multiobjective Markov\n  Decision Processes", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-508-517", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is devoted to fair optimization in Multiobjective Markov Decision\nProcesses (MOMDPs). A MOMDP is an extension of the MDP model for planning under\nuncertainty while trying to optimize several reward functions simultaneously.\nThis applies to multiagent problems when rewards define individual utility\nfunctions, or in multicriteria problems when rewards refer to different\nfeatures. In this setting, we study the determination of policies leading to\nLorenz-non-dominated tradeoffs. Lorenz dominance is a refinement of Pareto\ndominance that was introduced in Social Choice for the measurement of\ninequalities. In this paper, we introduce methods to efficiently approximate\nthe sets of Lorenz-non-dominated solutions of infinite-horizon, discounted\nMOMDPs. The approximations are polynomial-sized subsets of those solutions.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:48:02 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Perny", "Patrice", ""], ["Weng", "Paul", ""], ["Goldsmith", "Judy", ""], ["Hanna", "Josiah", ""]]}, {"id": "1309.6857", "submitter": "Marek Petrik", "authors": "Marek Petrik, Dharmashankar Subramanian, Janusz Marecki", "title": "Solution Methods for Constrained Markov Decision Process with Continuous\n  Probability Modulation", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-518-526", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose solution methods for previously-unsolved constrained MDPs in which\nactions can continuously modify the transition probabilities within some\nacceptable sets. While many methods have been proposed to solve regular MDPs\nwith large state sets, there are few practical approaches for solving\nconstrained MDPs with large action sets. In particular, we show that the\ncontinuous action sets can be replaced by their extreme points when the rewards\nare linear in the modulation. We also develop a tractable optimization\nformulation for concave reward functions and, surprisingly, also extend it to\nnon- concave reward functions by using their concave envelopes. We evaluate the\neffectiveness of the approach on the problem of managing delinquencies in a\nportfolio of loans.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:48:47 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Petrik", "Marek", ""], ["Subramanian", "Dharmashankar", ""], ["Marecki", "Janusz", ""]]}, {"id": "1309.6860", "submitter": "Eleni Sgouritsa", "authors": "Eleni Sgouritsa, Dominik Janzing, Jonas Peters, Bernhard Schoelkopf", "title": "Identifying Finite Mixtures of Nonparametric Product Distributions and\n  Causal Inference of Confounders", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-556-565", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a kernel method to identify finite mixtures of nonparametric\nproduct distributions. It is based on a Hilbert space embedding of the joint\ndistribution. The rank of the constructed tensor is equal to the number of\nmixture components. We present an algorithm to recover the components by\npartitioning the data points into clusters such that the variables are jointly\nconditionally independent given the cluster. This method can be used to\nidentify finite confounders.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:49:46 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Sgouritsa", "Eleni", ""], ["Janzing", "Dominik", ""], ["Peters", "Jonas", ""], ["Schoelkopf", "Bernhard", ""]]}, {"id": "1309.6863", "submitter": "Ilya Shpitser", "authors": "Ilya Shpitser, Robin J. Evans, Thomas S. Richardson, James M. Robins", "title": "Sparse Nested Markov models with Log-linear Parameters", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-576-585", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hidden variables are ubiquitous in practical data analysis, and therefore\nmodeling marginal densities and doing inference with the resulting models is an\nimportant problem in statistics, machine learning, and causal inference.\nRecently, a new type of graphical model, called the nested Markov model, was\ndeveloped which captures equality constraints found in marginals of directed\nacyclic graph (DAG) models. Some of these constraints, such as the so called\n`Verma constraint', strictly generalize conditional independence. To make\nmodeling and inference with nested Markov models practical, it is necessary to\nlimit the number of parameters in the model, while still correctly capturing\nthe constraints in the marginal of a DAG model. Placing such limits is similar\nin spirit to sparsity methods for undirected graphical models, and regression\nmodels. In this paper, we give a log-linear parameterization which allows\nsparse modeling with nested Markov models. We illustrate the advantages of this\nparameterization with a simulation study.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:50:19 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Shpitser", "Ilya", ""], ["Evans", "Robin J.", ""], ["Richardson", "Thomas S.", ""], ["Robins", "James M.", ""]]}, {"id": "1309.6864", "submitter": "Hossein Azari Soufiani", "authors": "Hossein Azari Soufiani, David C. Parkes, Lirong Xia", "title": "Preference Elicitation For General Random Utility Models", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-596-605", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses {General Random Utility Models (GRUMs)}. These are a\nclass of parametric models that generate partial ranks over alternatives given\nattributes of agents and alternatives. We propose two preference elicitation\nscheme for GRUMs developed from principles in Bayesian experimental design, one\nfor social choice and the other for personalized choice. We couple this with a\ngeneral Monte-Carlo-Expectation-Maximization (MC-EM) based algorithm for MAP\ninference under GRUMs. We also prove uni-modality of the likelihood functions\nfor a class of GRUMs. We examine the performance of various criteria by\nexperimental studies, which show that the proposed elicitation scheme increases\nthe precision of estimation.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:50:37 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Soufiani", "Hossein Azari", ""], ["Parkes", "David C.", ""], ["Xia", "Lirong", ""]]}, {"id": "1309.6870", "submitter": "Deepak Venugopal", "authors": "Deepak Venugopal, Vibhav Gogate", "title": "Dynamic Blocking and Collapsing for Gibbs Sampling", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-664-673", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate combining blocking and collapsing -- two widely\nused strategies for improving the accuracy of Gibbs sampling -- in the context\nof probabilistic graphical models (PGMs). We show that combining them is not\nstraight-forward because collapsing (or eliminating variables) introduces new\ndependencies in the PGM and in computation-limited settings, this may adversely\naffect blocking. We therefore propose a principled approach for tackling this\nproblem. Specifically, we develop two scoring functions, one each for blocking\nand collapsing, and formulate the problem of partitioning the variables in the\nPGM into blocked and collapsed subsets as simultaneously maximizing both\nscoring functions (i.e., a multi-objective optimization problem). We propose a\ndynamic, greedy algorithm for approximately solving this intractable\noptimization problem. Our dynamic algorithm periodically updates the\npartitioning into blocked and collapsed variables by leveraging correlation\nstatistics gathered from the generated samples and enables rapid mixing by\nblocking together and collapsing highly correlated variables. We demonstrate\nexperimentally the clear benefit of our dynamic approach: as more samples are\ndrawn, our dynamic approach significantly outperforms static graph-based\napproaches by an order of magnitude in terms of accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:53:01 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Venugopal", "Deepak", ""], ["Gogate", "Vibhav", ""]]}, {"id": "1309.6871", "submitter": "Luis Gustavo Vianna", "authors": "Luis Gustavo Vianna, Scott Sanner, Leliane Nunes de Barros", "title": "Bounded Approximate Symbolic Dynamic Programming for Hybrid MDPs", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-674-683", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in symbolic dynamic programming (SDP) combined with the\nextended algebraic decision diagram (XADD) data structure have provided exact\nsolutions for mixed discrete and continuous (hybrid) MDPs with piecewise linear\ndynamics and continuous actions. Since XADD-based exact solutions may grow\nintractably large for many problems, we propose a bounded error compression\ntechnique for XADDs that involves the solution of a constrained bilinear saddle\npoint problem. Fortuitously, we show that given the special structure of this\nproblem, it can be expressed as a bilevel linear programming problem and solved\nto optimality in finite time via constraint generation, despite having an\ninfinite set of constraints. This solution permits the use of efficient linear\nprogram solvers for XADD compression and enables a novel class of bounded\napproximate SDP algorithms for hybrid MDPs that empirically offers\norder-of-magnitude speedups over the exact solution in exchange for a small\napproximation error.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:53:25 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Vianna", "Luis Gustavo", ""], ["Sanner", "Scott", ""], ["de Barros", "Leliane Nunes", ""]]}, {"id": "1309.6872", "submitter": "Adrian Weller", "authors": "Adrian Weller, Tony S. Jebara", "title": "On MAP Inference by MWSS on Perfect Graphs", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-684-693", "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the most likely (MAP) configuration of a Markov random field (MRF) is\nNP-hard in general. A promising, recent technique is to reduce the problem to\nfinding a maximum weight stable set (MWSS) on a derived weighted graph, which\nif perfect, allows inference in polynomial time. We derive new results for this\napproach, including a general decomposition theorem for MRFs of any order and\nnumber of labels, extensions of results for binary pairwise models with\nsubmodular cost functions to higher order, and an exact characterization of\nwhich binary pairwise MRFs can be efficiently solved with this method. This\ndefines the power of the approach on this class of models, improves our toolbox\nand expands the range of tractable models.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:53:41 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Weller", "Adrian", ""], ["Jebara", "Tony S.", ""]]}, {"id": "1309.6883", "submitter": "Broes De Cat", "authors": "Maurice Bruynooghe, Hendrik Blockeel, Bart Bogaerts, Broes De Cat,\n  Stef De Pooter, Joachim Jansen, Anthony Labarre, Jan Ramon, Marc Denecker and\n  Sicco Verwer", "title": "Predicate Logic as a Modeling Language: Modeling and Solving some\n  Machine Learning and Data Mining Problems with IDP3", "comments": "To appear in Theory and Practice of Logic Programming (TPLP)", "journal-ref": "Theory and Practice of Logic Programming 15 (2014) 783-817", "doi": "10.1017/S147106841400009X", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a gentle introduction to problem solving with the IDP3\nsystem. The core of IDP3 is a finite model generator that supports first order\nlogic enriched with types, inductive definitions, aggregates and partial\nfunctions. It offers its users a modeling language that is a slight extension\nof predicate logic and allows them to solve a wide range of search problems.\nApart from a small introductory example, applications are selected from\nproblems that arose within machine learning and data mining research. These\nresearch areas have recently shown a strong interest in declarative modeling\nand constraint solving as opposed to algorithmic approaches. The paper\nillustrates that the IDP3 system can be a valuable tool for researchers with\nsuch an interest.\n  The first problem is in the domain of stemmatology, a domain of philology\nconcerned with the relationship between surviving variant versions of text. The\nsecond problem is about a somewhat related problem within biology where\nphylogenetic trees are used to represent the evolution of species. The third\nand final problem concerns the classical problem of learning a minimal\nautomaton consistent with a given set of strings. For this last problem, we\nshow that the performance of our solution comes very close to that of a\nstate-of-the art solution. For each of these applications, we analyze the\nproblem, illustrate the development of a logic-based model and explore how\nalternatives can affect the performance.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 13:18:05 GMT"}, {"version": "v2", "created": "Fri, 28 Mar 2014 10:59:21 GMT"}], "update_date": "2015-10-07", "authors_parsed": [["Bruynooghe", "Maurice", ""], ["Blockeel", "Hendrik", ""], ["Bogaerts", "Bart", ""], ["De Cat", "Broes", ""], ["De Pooter", "Stef", ""], ["Jansen", "Joachim", ""], ["Labarre", "Anthony", ""], ["Ramon", "Jan", ""], ["Denecker", "Marc", ""], ["Verwer", "Sicco", ""]]}, {"id": "1309.6989", "submitter": "Keyan Zahedi", "authors": "Keyan Zahedi and Georg Martius and Nihat Ay", "title": "Linear combination of one-step predictive information with an external\n  reward in an episodic policy gradient setting: a critical analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main challenges in the field of embodied artificial intelligence\nis the open-ended autonomous learning of complex behaviours. Our approach is to\nuse task-independent, information-driven intrinsic motivation(s) to support\ntask-dependent learning. The work presented here is a preliminary step in which\nwe investigate the predictive information (the mutual information of the past\nand future of the sensor stream) as an intrinsic drive, ideally supporting any\nkind of task acquisition. Previous experiments have shown that the predictive\ninformation (PI) is a good candidate to support autonomous, open-ended learning\nof complex behaviours, because a maximisation of the PI corresponds to an\nexploration of morphology- and environment-dependent behavioural regularities.\nThe idea is that these regularities can then be exploited in order to solve any\ngiven task. Three different experiments are presented and their results lead to\nthe conclusion that the linear combination of the one-step PI with an external\nreward function is not generally recommended in an episodic policy gradient\nsetting. Only for hard tasks a great speed-up can be achieved at the cost of an\nasymptotic performance lost.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 17:44:59 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Zahedi", "Keyan", ""], ["Martius", "Georg", ""], ["Ay", "Nihat", ""]]}, {"id": "1309.7004", "submitter": "Peter L. Spirtes", "authors": "Peter L. Spirtes", "title": "Calculation of Entailed Rank Constraints in Partially Non-Linear and\n  Cyclic Models", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-606-615", "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Trek Separation Theorem (Sullivant et al. 2010) states necessary and\nsufficient conditions for a linear directed acyclic graphical model to entail\nfor all possible values of its linear coefficients that the rank of various\nsub-matrices of the covariance matrix is less than or equal to n, for any given\nn. In this paper, I extend the Trek Separation Theorem in two ways: I prove\nthat the same necessary and sufficient conditions apply even when the\ngenerating model is partially non-linear and contains some cycles. This\njustifies application of constraint-based causal search algorithms such as the\nBuildPureClusters algorithm (Silva et al. 2006) for discovering the causal\nstructure of latent variable models to data generated by a wider class of\ncausal models that may contain non-linear and cyclic relations among the latent\nvariables.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2013 13:26:01 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Spirtes", "Peter L.", ""]]}, {"id": "1309.7068", "submitter": "Farzad Ghafari Jouneghani", "authors": "Farzad Ghafari Jouneghani, Mohammad Babazadeh, Rogayeh Bayramzadeh,\n  Hossein Movla", "title": "Investigation of commuting Hamiltonian in quantum Markov network", "comments": "11 pages, 8 figures", "journal-ref": "IJTP, V 53, I 8, August 2014, P 2521-2530", "doi": "10.1007/s10773-014-2042-8", "report-no": null, "categories": "cs.AI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphical Models have various applications in science and engineering which\ninclude physics, bioinformatics, telecommunication and etc. Usage of graphical\nmodels needs complex computations in order to evaluation of marginal\nfunctions,so there are some powerful methods including mean field\napproximation, belief propagation algorithm and etc. Quantum graphical models\nhave been recently developed in context of quantum information and computation,\nand quantum statistical physics, which is possible by generalization of\nclassical probability theory to quantum theory. The main goal of this paper is\npreparing a primary generalization of Markov network, as a type of graphical\nmodels, to quantum case and applying in quantum statistical physics.We have\ninvestigated the Markov network and the role of commuting Hamiltonian terms in\nconditional independence with simple examples of quantum statistical physics.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2013 15:17:33 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2013 06:47:42 GMT"}, {"version": "v3", "created": "Mon, 20 Jan 2014 22:08:54 GMT"}, {"version": "v4", "created": "Wed, 22 Jan 2014 08:23:35 GMT"}, {"version": "v5", "created": "Sun, 15 Jun 2014 10:28:54 GMT"}], "update_date": "2014-09-23", "authors_parsed": [["Jouneghani", "Farzad Ghafari", ""], ["Babazadeh", "Mohammad", ""], ["Bayramzadeh", "Rogayeh", ""], ["Movla", "Hossein", ""]]}, {"id": "1309.7145", "submitter": "Pierre Flener", "authors": "Nicolas Beldiceanu, Pierre Flener, Justin Pearson, Pascal Van\n  Hentenryck", "title": "Propagating Regular Counting Constraints", "comments": "Includes a SICStus Prolog source file with the propagator", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraints over finite sequences of variables are ubiquitous in sequencing\nand timetabling. Moreover, the wide variety of such constraints in practical\napplications led to general modelling techniques and generic propagation\nalgorithms, often based on deterministic finite automata (DFA) and their\nextensions. We consider counter-DFAs (cDFA), which provide concise models for\nregular counting constraints, that is constraints over the number of times a\nregular-language pattern occurs in a sequence. We show how to enforce domain\nconsistency in polynomial time for atmost and atleast regular counting\nconstraints based on the frequent case of a cDFA with only accepting states and\na single counter that can be incremented by transitions. We also prove that the\nsatisfaction of exact regular counting constraints is NP-hard and indicate that\nan incomplete algorithm for exact regular counting constraints is faster and\nprovides more pruning than the existing propagator from [3]. Regular counting\nconstraints are closely related to the CostRegular constraint but contribute\nboth a natural abstraction and some computational advantages.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2013 08:23:52 GMT"}], "update_date": "2013-09-30", "authors_parsed": [["Beldiceanu", "Nicolas", ""], ["Flener", "Pierre", ""], ["Pearson", "Justin", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "1309.7173", "submitter": "Priyanka Manchanda", "authors": "Priyanka Manchanda", "title": "Analysis of Optimization Techniques to Improve User Response Time of Web\n  Applications and Their Implementation for MOODLE", "comments": "The original final publication will be available at\n  http://www.springerlink.com", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis of seven optimization techniques grouped under three categories\n(hardware, back-end, and front-end) is done to study the reduction in average\nuser response time for Modular Object Oriented Dynamic Learning Environment\n(Moodle), a Learning Management System which is scripted in PHP5, runs on\nApache web server and utilizes MySQL database software. Before the\nimplementation of these techniques, performance analysis of Moodle is performed\nfor varying number of concurrent users. The results obtained for each\noptimization technique are then reported in a tabular format. The maximum\nreduction in end user response time was achieved for hardware optimization\nwhich requires Moodle server and database to be installed on solid state disk.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2013 09:27:01 GMT"}, {"version": "v2", "created": "Wed, 25 Dec 2013 07:19:32 GMT"}], "update_date": "2014-01-06", "authors_parsed": [["Manchanda", "Priyanka", ""]]}, {"id": "1309.7393", "submitter": "Chuan Shi", "authors": "Chuan Shi, Xiangnan Kong, Yue Huang, Philip S. Yu, Bin Wu", "title": "HeteSim: A General Framework for Relevance Measure in Heterogeneous\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarity search is an important function in many applications, which\nusually focuses on measuring the similarity between objects with the same type.\nHowever, in many scenarios, we need to measure the relatedness between objects\nwith different types. With the surge of study on heterogeneous networks, the\nrelevance measure on objects with different types becomes increasingly\nimportant. In this paper, we study the relevance search problem in\nheterogeneous networks, where the task is to measure the relatedness of\nheterogeneous objects (including objects with the same type or different\ntypes). A novel measure HeteSim is proposed, which has the following\nattributes: (1) a uniform measure: it can measure the relatedness of objects\nwith the same or different types in a uniform framework; (2) a path-constrained\nmeasure: the relatedness of object pairs are defined based on the search path\nthat connect two objects through following a sequence of node types; (3) a\nsemi-metric measure: HeteSim has some good properties (e.g., self-maximum and\nsymmetric), that are crucial to many data mining tasks. Moreover, we analyze\nthe computation characteristics of HeteSim and propose the corresponding quick\ncomputation strategies. Empirical studies show that HeteSim can effectively and\nefficiently evaluate the relatedness of heterogeneous objects.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2013 00:31:30 GMT"}], "update_date": "2013-10-01", "authors_parsed": [["Shi", "Chuan", ""], ["Kong", "Xiangnan", ""], ["Huang", "Yue", ""], ["Yu", "Philip S.", ""], ["Wu", "Bin", ""]]}, {"id": "1309.7405", "submitter": "Liane Gabora", "authors": "Liane Gabora and Patrick Colgan", "title": "A Model of the Mechanisms Underlying Exploratory Behaviour", "comments": "17 pages", "journal-ref": "In S. Wilson & J. A. Meyer (Eds.), Proceedings of the First\n  International Conference on the Simulation of Adaptive Behavior (pp.\n  475-484). Cambridge, MA: MIT Press. (1990)", "doi": null, "report-no": null, "categories": "q-bio.PE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A model of the mechanisms underlying exploratory behaviour, based on\nempirical research and refined using a computer simulation, is presented. The\nbehaviour of killifish from two lakes, one with killifish predators and one\nwithout, was compared in the laboratory. Plotting average activity in a novel\nenvironment versus time resulted in an inverted-U-shaped curve for both groups;\nhowever, the curve for killifish from the lake without predators was (1)\nsteeper, (2) reached a peak value earlier, (S) reached a higher peak value, and\n(4) subsumed less area than the curve for killifish from the lake with\npredators. We hypothesize that the shape of the exploration curve reflects a\ncompetition between motivational subsystems that excite and inhibit exploratory\nbehaviour in a way that is tuned to match the affordance probabilities of the\nanimal's environment. A computer implementation of this model produced curves\nwhich differed along the same four dimensions as differentiate the two\nkillifish curves. All four differences were reproduced in the model by tuning a\nsingle parameter: the time-dependent component of the decay-rate of the\nexploration-inhibiting subsystem.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2013 01:57:54 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 20:09:19 GMT"}, {"version": "v3", "created": "Tue, 9 Jul 2019 20:01:08 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Gabora", "Liane", ""], ["Colgan", "Patrick", ""]]}, {"id": "1309.7407", "submitter": "Liane Gabora", "authors": "Liane Gabora and Kirsty Kitto", "title": "Concept Combination and the Origins of Complex Cognition", "comments": "24 pages. arXiv admin note: substantial text overlap with\n  arXiv:1308.5032", "journal-ref": "In E. Swan (Ed.), Origins of mind: Biosemiotics Series (pp.\n  361-382). Berlin: Springer. (2013)", "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the core of our uniquely human cognitive abilities is the capacity to see\nthings from different perspectives, or to place them in a new context. We\npropose that this was made possible by two cognitive transitions. First, the\nlarge brain of Homo erectus facilitated the onset of recursive recall: the\nability to string thoughts together into a stream of potentially abstract or\nimaginative thought. This hypothesis is supported by a set of computational\nmodels where an artificial society of agents evolved to generate more diverse\nand valuable cultural outputs under conditions of recursive recall. We propose\nthat the capacity to see things in context arose much later, following the\nappearance of anatomically modern humans. This second transition was brought on\nby the onset of contextual focus: the capacity to shift between a minimally\ncontextual analytic mode of thought, and a highly contextual associative mode\nof thought, conducive to combining concepts in new ways and 'breaking out of a\nrut'. When contextual focus is implemented in an art-generating computer\nprogram, the resulting artworks are seen as more creative and appealing. We\nsummarize how both transitions can be modeled using a theory of concepts which\nhighlights the manner in which different contexts can lead to modern humans\nattributing very different meanings to the interpretation of one concept.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2013 02:17:10 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 19:55:57 GMT"}, {"version": "v3", "created": "Tue, 9 Jul 2019 20:02:45 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Gabora", "Liane", ""], ["Kitto", "Kirsty", ""]]}, {"id": "1309.7971", "submitter": "Ann Nicholson", "authors": "Ann Nicholson and Padhriac Smyth", "title": "Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial\n  Intelligence (2013)", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI2013", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the Twenty-Ninth Conference on Uncertainty in\nArtificial Intelligence, which was held in Bellevue, WA, August 11-15, 2013\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2013 19:16:53 GMT"}, {"version": "v2", "created": "Thu, 28 Aug 2014 03:58:06 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["Nicholson", "Ann", ""], ["Smyth", "Padhriac", ""]]}]