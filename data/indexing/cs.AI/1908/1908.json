[{"id": "1908.00085", "submitter": "Ana Lucic", "authors": "Ana Lucic, Hinda Haned, Maarten de Rijke", "title": "Why Does My Model Fail? Contrastive Local Explanations for Retail\n  Forecasting", "comments": "To appear in ACM FAT* 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In various business settings, there is an interest in using more complex\nmachine learning techniques for sales forecasting. It is difficult to convince\nanalysts, along with their superiors, to adopt these techniques since the\nmodels are considered to be \"black boxes,\" even if they perform better than\ncurrent models in use. We examine the impact of contrastive explanations about\nlarge errors on users' attitudes towards a \"black-box'\" model. We propose an\nalgorithm, Monte Carlo Bounds for Reasonable Predictions. Given a large error,\nMC-BRP determines (1) feature values that would result in a reasonable\nprediction, and (2) general trends between each feature and the target, both\nbased on Monte Carlo simulations. We evaluate on a real dataset with real users\nby conducting a user study with 75 participants to determine if explanations\ngenerated by MC-BRP help users understand why a prediction results in a large\nerror, and if this promotes trust in an automatically-learned model. Our study\nshows that users are able to answer objective questions about the model's\npredictions with overall 81.1% accuracy when provided with these contrastive\nexplanations. We show that users who saw MC-BRP explanations understand why the\nmodel makes large errors in predictions significantly more than users in the\ncontrol group. We also conduct an in-depth analysis on the difference in\nattitudes between Practitioners and Researchers, and confirm that our results\nhold when conditioning on the users' background.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 12:57:06 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 14:51:52 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Lucic", "Ana", ""], ["Haned", "Hinda", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1908.00087", "submitter": "Thilo Spinner", "authors": "Thilo Spinner, Udo Schlegel, Hanna Sch\\\"afer and Mennatallah El-Assady", "title": "explAIner: A Visual Analytics Framework for Interactive and Explainable\n  Machine Learning", "comments": "9 pages paper, 2 pages references, 5 pages supplementary material\n  (ancillary files)", "journal-ref": "IEEE Transactions on Visualization and Computer Graphics (2019)", "doi": "10.1109/TVCG.2019.2934629", "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for interactive and explainable machine learning that\nenables users to (1) understand machine learning models; (2) diagnose model\nlimitations using different explainable AI methods; as well as (3) refine and\noptimize the models. Our framework combines an iterative XAI pipeline with\neight global monitoring and steering mechanisms, including quality monitoring,\nprovenance tracking, model comparison, and trust building. To operationalize\nthe framework, we present explAIner, a visual analytics system for interactive\nand explainable machine learning that instantiates all phases of the suggested\npipeline within the commonly used TensorBoard environment. We performed a\nuser-study with nine participants across different expertise levels to examine\ntheir perception of our workflow and to collect suggestions to fill the gap\nbetween our system and framework. The evaluation confirms that our tightly\nintegrated system leads to an informed machine learning process while\ndisclosing opportunities for further extensions.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 15:04:59 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 12:54:46 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Spinner", "Thilo", ""], ["Schlegel", "Udo", ""], ["Sch\u00e4fer", "Hanna", ""], ["El-Assady", "Mennatallah", ""]]}, {"id": "1908.00112", "submitter": "Jia-Huai You", "authors": "David Spies, Jia-Huai You, Ryan Hayward", "title": "Domain-Independent Cost-Optimal Planning in ASP", "comments": "Paper presented at the 35th International Conference on Logic\n  Programming (ICLP 2019), Las Cruces, New Mexico, USA, 20-25 September 2019,\n  16 pages", "journal-ref": "Theory and Practice of Logic Programming 19 (2019) 1124-1142", "doi": "10.1017/S1471068419000395", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of cost-optimal planning in ASP. Current ASP\nplanners can be trivially extended to a cost-optimal one by adding weak\nconstraints, but only for a given makespan (number of steps). It is desirable\nto have a planner that guarantees global optimality. In this paper, we present\ntwo approaches to addressing this problem. First, we show how to engineer a\ncost-optimal planner composed of two ASP programs running in parallel. Using\nlessons learned from this, we then develop an entirely new approach to\ncost-optimal planning, stepless planning, which is completely free of makespan.\nExperiments to compare the two approaches with the only known cost-optimal\nplanner in SAT reveal good potentials for stepless planning in ASP. The paper\nis under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 21:42:24 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Spies", "David", ""], ["You", "Jia-Huai", ""], ["Hayward", "Ryan", ""]]}, {"id": "1908.00177", "submitter": "Tommy Tram", "authors": "Tommy Tram, Ivo Batkovic, Mohammad Ali, Jonas Sj\\\"oberg", "title": "Learning When to Drive in Intersections by Combining Reinforcement\n  Learning and Model Predictive Control", "comments": "6 pages, 5 figures, 1 table, Accepted to IEEE Intelligent Transport\n  Systems Conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a decision making algorithm intended for automated\nvehicles that negotiate with other possibly non-automated vehicles in\nintersections. The decision algorithm is separated into two parts: a high-level\ndecision module based on reinforcement learning, and a low-level planning\nmodule based on model predictive control. Traffic is simulated with numerous\npredefined driver behaviors and intentions, and the performance of the proposed\ndecision algorithm was evaluated against another controller. The results show\nthat the proposed decision algorithm yields shorter training episodes and an\nincreased performance in success rate compared to the other controller.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 02:00:49 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Tram", "Tommy", ""], ["Batkovic", "Ivo", ""], ["Ali", "Mohammad", ""], ["Sj\u00f6berg", "Jonas", ""]]}, {"id": "1908.00181", "submitter": "Zhuochen Jin", "authors": "Zhuochen Jin, Nan Cao, Yang Shi, Hanghang Tong, Yingcai Wu", "title": "EcoLens: Visual Analysis of Urban Region Dynamics Using Traffic Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid development of urbanization during the past decades has\nsignificantly improved people's lives but also introduced new challenges on\neffective functional urban planning and transportation management. The\nfunctional regions defined based on a static boundary rarely reflect an\nindividual's daily experience of the space in which they live and visit for a\nvariety of purposes. Fortunately, the increasing availability of spatiotemporal\ndata provides unprecedented opportunities for understanding the structure of an\nurban area in terms of people's activity pattern and how they form the latent\nregions over time. These ecological regions, where people temporarily share a\nsimilar moving behavior during a short period of time, could provide insights\ninto urban planning and smart-city services. However, existing solutions are\nlimited in their capacity of capturing the evolutionary patterns of dynamic\nlatent regions within urban context. In this work, we introduce an interactive\nvisual analysis approach, EcoLens, that allows analysts to progressively\nexplore and analyze the complex dynamic segmentation patterns of a city using\ntraffic data. We propose an extended non-negative Matrix Factorization based\nalgorithm smoothed over both spatial and temporal dimensions to capture the\nspatiotemporal dynamics of the city. The algorithm also ensures the\northogonality of its result to facilitate the interpretation of different\npatterns. A suite of visualizations is designed to illustrate the dynamics of\ncity segmentation and the corresponding interactions are added to support the\nexploration of the segmentation patterns over time. We evaluate the\neffectiveness of our system via case studies using a real-world dataset and a\nqualitative interview with the domain expert.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 23:50:15 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Jin", "Zhuochen", ""], ["Cao", "Nan", ""], ["Shi", "Yang", ""], ["Tong", "Hanghang", ""], ["Wu", "Yingcai", ""]]}, {"id": "1908.00183", "submitter": "EPTCS", "authors": "Carmen Leticia Garc\\'ia-Mata (Tecnol\\'ogico Nacional de M\\'exico -\n  Tecnol\\'ogico de Chihuahua), Pedro Rafael M\\'arquez-Guti\\'errez\n  (Tecnol\\'ogico Nacional de M\\'exico - Tecnol\\'ogico de Chihuahua)", "title": "Solving a Flowshop Scheduling Problem with Answer Set Programming:\n  Exploiting the Problem to Reduce the Number of Combinations", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646", "journal-ref": "EPTCS 306, 2019, pp. 347-353", "doi": "10.4204/EPTCS.306.41", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning and scheduling have been a central theme of research in computer\nscience. In particular, the simplicity of the theoretical approach of a no-wait\nflowshop scheduling problem does not allow to perceive the problem complexity\nat first sight. In this paper the applicability of the Answer Set Programming\nlanguage is explored for the solution of the Automated Wet-etching scheduling\nproblem in Semiconductor Manufacturing Systems. A method based in ranges is\nproposed in order to reduce the huge number of combinations.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 02:25:34 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 08:25:46 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Garc\u00eda-Mata", "Carmen Leticia", "", "Tecnol\u00f3gico Nacional de M\u00e9xico -\n  Tecnol\u00f3gico de Chihuahua"], ["M\u00e1rquez-Guti\u00e9rrez", "Pedro Rafael", "", "Tecnol\u00f3gico Nacional de M\u00e9xico - Tecnol\u00f3gico de Chihuahua"]]}, {"id": "1908.00286", "submitter": "Floris Den Hengst", "authors": "Floris den Hengst, Mark Hoogendoorn, Frank van Harmelen, Joost Bosman", "title": "Reinforcement Learning for Personalized Dialogue Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.HC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Language systems have been of great interest to the research community and\nhave recently reached the mass market through various assistant platforms on\nthe web. Reinforcement Learning methods that optimize dialogue policies have\nseen successes in past years and have recently been extended into methods that\npersonalize the dialogue, e.g. take the personal context of users into account.\nThese works, however, are limited to personalization to a single user with whom\nthey require multiple interactions and do not generalize the usage of context\nacross users. This work introduces a problem where a generalized usage of\ncontext is relevant and proposes two Reinforcement Learning (RL)-based\napproaches to this problem. The first approach uses a single learner and\nextends the traditional POMDP formulation of dialogue state with features that\ndescribe the user context. The second approach segments users by context and\nthen employs a learner per context. We compare these approaches in a benchmark\nof existing non-RL and RL-based methods in three established and one novel\napplication domain of financial product recommendation. We compare the\ninfluence of context and training experiences on performance and find that\nlearning approaches generally outperform a handcrafted gold standard.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 09:19:27 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Hengst", "Floris den", ""], ["Hoogendoorn", "Mark", ""], ["van Harmelen", "Frank", ""], ["Bosman", "Joost", ""]]}, {"id": "1908.00381", "submitter": "Anton Vladzymyrskyy", "authors": "S.P. Morozov, A.V. Vladzymyrskyy, V.G. Klyashtornyy, A.E.\n  Andreychenko, N.S. Kulberg, V.A. Gombolevsky, K.A. Sergunova", "title": "Clinical acceptance of software based on artificial intelligence\n  technologies (radiology)", "comments": "For correspondence: info@npcmr.ru, npcmr@zdrav.mos.ru. 28/1,\n  Srednyaya Kalitnikovskaya st., Moscow, 109029, Russia +7 (495) 276-04-36", "journal-ref": null, "doi": null, "report-no": "Preprint No. CDT-2019-1", "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aim: provide a methodological framework for the process of clinical tests,\nclinical acceptance, and scientific assessment of algorithms and software based\non the artificial intelligence (AI) technologies. Clinical tests are considered\nas a preparation stage for the software registration as a medical product. The\nauthors propose approaches to evaluate accuracy and efficiency of the AI\nalgorithms for radiology.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 13:24:26 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 14:16:03 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Morozov", "S. P.", ""], ["Vladzymyrskyy", "A. V.", ""], ["Klyashtornyy", "V. G.", ""], ["Andreychenko", "A. E.", ""], ["Kulberg", "N. S.", ""], ["Gombolevsky", "V. A.", ""], ["Sergunova", "K. A.", ""]]}, {"id": "1908.00409", "submitter": "Holger Ingmar Meinhardt", "authors": "Holger I. Meinhardt", "title": "Deduction Theorem: The Problematic Nature of Common Practice in Game\n  Theory", "comments": "12 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Deduction Theorem that is used in the literature of game\ntheory to run a purported proof by contradiction. In the context of game\ntheory, it is stated that if we have a proof of $\\phi \\vdash \\varphi$, then we\nalso have a proof of $\\phi \\Rightarrow \\varphi$. Hence, the proof of $\\phi\n\\Rightarrow \\varphi$ is deduced from a previous known statement. However, we\nargue that one has to manage to prove that the clauses $\\phi$ and $\\varphi$\nexist, i.e., they are known true statements in order to establish that $\\phi\n\\vdash \\varphi$ is provable, and that therefore $\\phi \\Rightarrow \\varphi$ is\nprovable as well. Thus, we are only allowed to reason with known true\nstatements, i.e., we are not allowed to assume that $\\phi$ or $\\varphi$ exist.\nDoing so, leads immediately to a wrong conclusion. Apart from this, we stress\nto other facts why the Deduction Theorem is not applicable to run a proof by\ncontradiction. Finally, we present an example from industrial cooperation where\nthe Deduction Theorem is not correctly applied with the consequence that the\nobtained result contradicts the well-known aggregation issue.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 11:49:44 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Meinhardt", "Holger I.", ""]]}, {"id": "1908.00413", "submitter": "Hoyeop Lee", "authors": "Hoyeop Lee, Jinbae Im, Seongwon Jang, Hyunsouk Cho, Sehee Chung", "title": "MeLU: Meta-Learned User Preference Estimator for Cold-Start\n  Recommendation", "comments": "Accepted as a full paper at KDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper proposes a recommender system to alleviate the cold-start problem\nthat can estimate user preferences based on only a small number of items. To\nidentify a user's preference in the cold state, existing recommender systems,\nsuch as Netflix, initially provide items to a user; we call those items\nevidence candidates. Recommendations are then made based on the items selected\nby the user. Previous recommendation studies have two limitations: (1) the\nusers who consumed a few items have poor recommendations and (2) inadequate\nevidence candidates are used to identify user preferences. We propose a\nmeta-learning-based recommender system called MeLU to overcome these two\nlimitations. From meta-learning, which can rapidly adopt new task with a few\nexamples, MeLU can estimate new user's preferences with a few consumed items.\nIn addition, we provide an evidence candidate selection strategy that\ndetermines distinguishing items for customized preference estimation. We\nvalidate MeLU with two benchmark datasets, and the proposed model reduces at\nleast 5.92% mean absolute error than two comparative models on the datasets. We\nalso conduct a user study experiment to verify the evidence selection strategy.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 07:43:00 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Lee", "Hoyeop", ""], ["Im", "Jinbae", ""], ["Jang", "Seongwon", ""], ["Cho", "Hyunsouk", ""], ["Chung", "Sehee", ""]]}, {"id": "1908.00528", "submitter": "Dung Phan", "authors": "Dung T. Phan, Radu Grosu, Nils Jansen, Nicola Paoletti, Scott A.\n  Smolka, Scott D. Stoller", "title": "Neural Simplex Architecture", "comments": "12th NASA Formal Methods Symposium (NFM 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Neural Simplex Architecture (NSA), a new approach to runtime\nassurance that provides safety guarantees for neural controllers (obtained e.g.\nusing reinforcement learning) of autonomous and other complex systems without\nunduly sacrificing performance. NSA is inspired by the Simplex control\narchitecture of Sha et al., but with some significant differences. In the\ntraditional approach, the advanced controller (AC) is treated as a black box;\nwhen the decision module switches control to the baseline controller (BC), the\nBC remains in control forever. There is relatively little work on switching\ncontrol back to the AC, and there are no techniques for correcting the AC's\nbehavior after it generates a potentially unsafe control input that causes a\nfailover to the BC. Our NSA addresses both of these limitations. NSA not only\nprovides safety assurances in the presence of a possibly unsafe neural\ncontroller, but can also improve the safety of such a controller in an online\nsetting via retraining, without overly degrading its performance. To\ndemonstrate NSA's benefits, we have conducted several significant case studies\nin the continuous control domain. These include a target-seeking ground rover\nnavigating an obstacle field, and a neural controller for an artificial\npancreas system.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 17:39:18 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 19:11:09 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Phan", "Dung T.", ""], ["Grosu", "Radu", ""], ["Jansen", "Nils", ""], ["Paoletti", "Nicola", ""], ["Smolka", "Scott A.", ""], ["Stoller", "Scott D.", ""]]}, {"id": "1908.00648", "submitter": "Amine Trabelsi", "authors": "Amine Trabelsi and Osmar R. Zaiane", "title": "Contrastive Reasons Detection and Clustering from Online Polarized\n  Debate", "comments": "Best paper award in CICLing 2019: International Conference on\n  Computational Linguistics and Intelligent Text Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work tackles the problem of unsupervised modeling and extraction of the\nmain contrastive sentential reasons conveyed by divergent viewpoints on\npolarized issues. It proposes a pipeline approach centered around the detection\nand clustering of phrases, assimilated to argument facets using a novel Phrase\nAuthor Interaction Topic-Viewpoint model. The evaluation is based on the\ninformativeness, the relevance and the clustering accuracy of extracted\nreasons. The pipeline approach shows a significant improvement over\nstate-of-the-art methods in contrastive summarization on online debate\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 22:42:36 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Trabelsi", "Amine", ""], ["Zaiane", "Osmar R.", ""]]}, {"id": "1908.00688", "submitter": "Yuan-Fang Li", "authors": "Ying Yang, Michael Wybrow, Yuan-Fang Li, Tobias Czauderna, Yongqun He", "title": "OntoPlot: A Novel Visualisation for Non-hierarchical Associations in\n  Large Ontologies", "comments": "Accepted at IEEE InfoVis 2019", "journal-ref": null, "doi": "10.1109/TVCG.2019.2934557", "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ontologies are formal representations of concepts and complex relationships\namong them. They have been widely used to capture comprehensive domain\nknowledge in areas such as biology and medicine, where large and complex\nontologies can contain hundreds of thousands of concepts. Especially due to the\nlarge size of ontologies, visualisation is useful for authoring, exploring and\nunderstanding their underlying data. Existing ontology visualisation tools\ngenerally focus on the hierarchical structure, giving much less emphasis to\nnon-hierarchical associations. In this paper we present OntoPlot, a novel\nvisualisation specifically designed to facilitate the exploration of all\nconcept associations whilst still showing an ontology's large hierarchical\nstructure. This hybrid visualisation combines icicle plots, visual compression\ntechniques and interactivity, improving space-efficiency and reducing visual\nstructural complexity. We conducted a user study with domain experts to\nevaluate the usability of OntoPlot, comparing it with the de facto ontology\neditor Prot{\\'e}g{\\'e}. The results confirm that OntoPlot attains our design\ngoals for association-related tasks and is strongly favoured by domain experts.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 02:58:04 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 09:17:24 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Yang", "Ying", ""], ["Wybrow", "Michael", ""], ["Li", "Yuan-Fang", ""], ["Czauderna", "Tobias", ""], ["He", "Yongqun", ""]]}, {"id": "1908.00698", "submitter": "Robert M\\\"uller", "authors": "Robert M\\\"uller, Stefan Langer, Fabian Ritz, Christoph Roch, Steffen\n  Illium, Claudia Linnhoff-Popien", "title": "Soccer Team Vectors", "comments": "11 pages, 1 figure; This paper was presented at the 6th Workshop on\n  Machine Learning and Data Mining for Sports Analytics at ECML/PKDD 2019,\n  W\\\"urzburg, Germany, 2019", "journal-ref": "Machine Learning and Knowledge Discovery in Databases. ECML PKDD\n  2019. Communications in Computer and Information Science, vol 1168. Springer,\n  Cham", "doi": "10.1007/978-3-030-43887-6_19", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present STEVE - Soccer TEam VEctors, a principled approach\nfor learning real valued vectors for soccer teams where similar teams are close\nto each other in the resulting vector space. STEVE only relies on freely\navailable information about the matches teams played in the past. These vectors\ncan serve as input to various machine learning tasks. Evaluating on the task of\nteam market value estimation, STEVE outperforms all its competitors. Moreover,\nwe use STEVE for similarity search and to rank soccer teams.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 13:46:16 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 12:51:09 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["M\u00fcller", "Robert", ""], ["Langer", "Stefan", ""], ["Ritz", "Fabian", ""], ["Roch", "Christoph", ""], ["Illium", "Steffen", ""], ["Linnhoff-Popien", "Claudia", ""]]}, {"id": "1908.00722", "submitter": "Robin Strudel", "authors": "Robin Strudel, Alexander Pashevich, Igor Kalevatykh, Ivan Laptev,\n  Josef Sivic, Cordelia Schmid", "title": "Learning to combine primitive skills: A step towards versatile robotic\n  manipulation", "comments": "ICRA 2020. See the project webpage at\n  https://www.di.ens.fr/willow/research/rlbc/", "journal-ref": "IEEE ROBOTICS AND AUTOMATION LETTERS, JULY 2020. 4637-4643", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manipulation tasks such as preparing a meal or assembling furniture remain\nhighly challenging for robotics and vision. Traditional task and motion\nplanning (TAMP) methods can solve complex tasks but require full state\nobservability and are not adapted to dynamic scene changes. Recent learning\nmethods can operate directly on visual inputs but typically require many\ndemonstrations and/or task-specific reward engineering. In this work we aim to\novercome previous limitations and propose a reinforcement learning (RL)\napproach to task planning that learns to combine primitive skills. First,\ncompared to previous learning methods, our approach requires neither\nintermediate rewards nor complete task demonstrations during training. Second,\nwe demonstrate the versatility of our vision-based task planning in challenging\nsettings with temporary occlusions and dynamic scene changes. Third, we propose\nan efficient training of basic skills from few synthetic demonstrations by\nexploring recent CNN architectures and data augmentation. Notably, while all of\nour policies are learned on visual inputs in simulated environments, we\ndemonstrate the successful transfer and high success rates when applying such\npolicies to manipulation tasks on a real UR5 robotic arm.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 07:04:17 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 16:02:27 GMT"}, {"version": "v3", "created": "Sat, 20 Jun 2020 14:26:45 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Strudel", "Robin", ""], ["Pashevich", "Alexander", ""], ["Kalevatykh", "Igor", ""], ["Laptev", "Ivan", ""], ["Sivic", "Josef", ""], ["Schmid", "Cordelia", ""]]}, {"id": "1908.00735", "submitter": "Andr\\'e Artelt", "authors": "Andr\\'e Artelt, Barbara Hammer", "title": "Efficient computation of counterfactual explanations of LVQ models", "comments": "Short version accepted at ESANN-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing use of machine learning in practice and legal regulations like\nEU's GDPR cause the necessity to be able to explain the prediction and behavior\nof machine learning models. A prominent example of particularly intuitive\nexplanations of AI models in the context of decision making are counterfactual\nexplanations. Yet, it is still an open research problem how to efficiently\ncompute counterfactual explanations for many models.\n  We investigate how to efficiently compute counterfactual explanations for an\nimportant class of models, prototype-based classifiers such as learning vector\nquantization models. In particular, we derive specific convex and non-convex\nprograms depending on the used metric.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 07:51:37 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 09:47:49 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Artelt", "Andr\u00e9", ""], ["Hammer", "Barbara", ""]]}, {"id": "1908.00744", "submitter": "Pablo Barros", "authors": "Pablo Barros, Stefan Wermter, Alessandra Sciutti", "title": "Towards Learning How to Properly Play UNO with the iCub Robot", "comments": "Workshops on Naturalistic Non-Verbal and Affective Human-Robot\n  Interactions co-located with ICDL-EPIROB 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  While interacting with another person, our reactions and behavior are much\naffected by the emotional changes within the temporal context of the\ninteraction. Our intrinsic affective appraisal comprising perception,\nself-assessment, and the affective memories with similar social experiences\nwill drive specific, and in most cases addressed as proper, reactions within\nthe interaction. This paper proposes the roadmap for the development of\nmultimodal research which aims to empower a robot with the capability to\nprovide proper social responses in a Human-Robot Interaction (HRI) scenario.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 08:11:46 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Barros", "Pablo", ""], ["Wermter", "Stefan", ""], ["Sciutti", "Alessandra", ""]]}, {"id": "1908.00877", "submitter": "Andrea Celli", "authors": "Andrea Celli and Stefano Coniglio and Nicola Gatti", "title": "Bayesian Persuasion with Sequential Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an information-structure design problem (a.k.a. persuasion) with a\nsingle sender and multiple receivers with actions of a priori unknown types,\nindependently drawn from action-specific marginal distributions. As in the\nstandard Bayesian persuasion model, the sender has access to additional\ninformation regarding the action types, which she can exploit when committing\nto a (noisy) signaling scheme through which she sends a private signal to each\nreceiver. The novelty of our model is in considering the case where the\nreceivers interact in a sequential game with imperfect information, with\nutilities depending on the game outcome and the realized action types. After\nformalizing the notions of ex ante and ex interim persuasiveness (which differ\nin the time at which the receivers commit to following the sender's signaling\nscheme), we investigate the continuous optimization problem of computing a\nsignaling scheme which maximizes the sender's expected revenue. We show that\ncomputing an optimal ex ante persuasive signaling scheme is NP-hard when there\nare three or more receivers. In contrast with previous hardness results for ex\ninterim persuasion, we show that, for games with two receivers, an optimal ex\nante persuasive signaling scheme can be computed in polynomial time thanks to a\nnovel algorithm based on the ellipsoid method which we propose.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 14:21:14 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Celli", "Andrea", ""], ["Coniglio", "Stefano", ""], ["Gatti", "Nicola", ""]]}, {"id": "1908.01000", "submitter": "Fan-Yun Sun", "authors": "Fan-Yun Sun, Jordan Hoffmann, Vikas Verma, Jian Tang", "title": "InfoGraph: Unsupervised and Semi-supervised Graph-Level Representation\n  Learning via Mutual Information Maximization", "comments": "ICLR 2020 (spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies learning the representations of whole graphs in both\nunsupervised and semi-supervised scenarios. Graph-level representations are\ncritical in a variety of real-world applications such as predicting the\nproperties of molecules and community analysis in social networks. Traditional\ngraph kernel based methods are simple, yet effective for obtaining fixed-length\nrepresentations for graphs but they suffer from poor generalization due to\nhand-crafted designs. There are also some recent methods based on language\nmodels (e.g. graph2vec) but they tend to only consider certain substructures\n(e.g. subtrees) as graph representatives. Inspired by recent progress of\nunsupervised representation learning, in this paper we proposed a novel method\ncalled InfoGraph for learning graph-level representations. We maximize the\nmutual information between the graph-level representation and the\nrepresentations of substructures of different scales (e.g., nodes, edges,\ntriangles). By doing so, the graph-level representations encode aspects of the\ndata that are shared across different scales of substructures. Furthermore, we\nfurther propose InfoGraph*, an extension of InfoGraph for semi-supervised\nscenarios. InfoGraph* maximizes the mutual information between unsupervised\ngraph representations learned by InfoGraph and the representations learned by\nexisting supervised methods. As a result, the supervised encoder learns from\nunlabeled data while preserving the latent semantic space favored by the\ncurrent supervised task. Experimental results on the tasks of graph\nclassification and molecular property prediction show that InfoGraph is\nsuperior to state-of-the-art baselines and InfoGraph* can achieve performance\ncompetitive with state-of-the-art semi-supervised models.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 06:28:43 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 16:24:01 GMT"}, {"version": "v3", "created": "Fri, 17 Jan 2020 16:20:00 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Sun", "Fan-Yun", ""], ["Hoffmann", "Jordan", ""], ["Verma", "Vikas", ""], ["Tang", "Jian", ""]]}, {"id": "1908.01007", "submitter": "Spencer Frazier", "authors": "Spencer Frazier, Mark Riedl", "title": "Improving Deep Reinforcement Learning in Minecraft with Action Advice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep reinforcement learning agents complex behaviors in 3D virtual\nenvironments requires significant computational resources. This is especially\ntrue in environments with high degrees of aliasing, where many states share\nnearly identical visual features. Minecraft is an exemplar of such an\nenvironment. We hypothesize that interactive machine learning IML, wherein\nhuman teachers play a direct role in training through demonstrations, critique,\nor action advice, may alleviate agent susceptibility to aliasing. However,\ninteractive machine learning is only practical when the number of human\ninteractions is limited, requiring a balance between human teacher effort and\nagent performance. We conduct experiments with two reinforcement learning\nalgorithms which enable human teachers to give action advice, Feedback\nArbitration and Newtonian Action Advice, under visual aliasing conditions. To\nassess potential cognitive load per advice type, we vary the accuracy and\nfrequency of various human action advice techniques. Training efficiency,\nrobustness against infrequent and inaccurate advisor input, and sensitivity to\naliasing are examined.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 18:36:44 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Frazier", "Spencer", ""], ["Riedl", "Mark", ""]]}, {"id": "1908.01022", "submitter": "Ross Allen", "authors": "Ross E. Allen, Jayesh K. Gupta, Jaime Pena, Yutai Zhou, Javona White\n  Bear, Mykel J. Kochenderfer", "title": "Health-Informed Policy Gradients for Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a definition of system health in the context of multiple\nagents optimizing a joint reward function. We use this definition as a credit\nassignment term in a policy gradient algorithm to distinguish the contributions\nof individual agents to the global reward. The health-informed credit\nassignment is then extended to a multi-agent variant of the proximal policy\noptimization algorithm and demonstrated on particle and multiwalker robot\nenvironments that have characteristics such as system health, risk-taking,\nsemi-expendable agents, continuous action spaces, and partial observability. We\nshow significant improvement in learning performance compared to policy\ngradient methods that do not perform multi-agent credit assignment.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 19:20:29 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 16:12:54 GMT"}, {"version": "v3", "created": "Thu, 19 Mar 2020 20:44:39 GMT"}, {"version": "v4", "created": "Mon, 4 Jan 2021 20:16:46 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Allen", "Ross E.", ""], ["Gupta", "Jayesh K.", ""], ["Pena", "Jaime", ""], ["Zhou", "Yutai", ""], ["Bear", "Javona White", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1908.01024", "submitter": "Os Keyes", "authors": "Cynthia L. Bennett, Os Keyes", "title": "What is the Point of Fairness? Disability, AI and The Complexity of\n  Justice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Work integrating conversations around AI and Disability is vital and valued,\nparticularly when done through a lens of fairness. Yet at the same time,\nanalyzing the ethical implications of AI for disabled people solely through the\nlens of a singular idea of \"fairness\" risks reinforcing existing power\ndynamics, either through reinforcing the position of existing medical\ngatekeepers, or promoting tools and techniques that benefit\notherwise-privileged disabled people while harming those who are rendered\noutliers in multiple ways. In this paper we present two case studies from\nwithin computer vision - a subdiscipline of AI focused on training algorithms\nthat can \"see\" - of technologies putatively intended to help disabled people\nbut, through failures to consider structural injustices in their design, are\nlikely to result in harms not addressed by a \"fairness\" framing of ethics.\nDrawing on disability studies and critical data science, we call on researchers\ninto AI ethics and disability to move beyond simplistic notions of fairness,\nand towards notions of justice.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 19:25:57 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 21:54:56 GMT"}, {"version": "v3", "created": "Fri, 9 Aug 2019 23:17:52 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Bennett", "Cynthia L.", ""], ["Keyes", "Os", ""]]}, {"id": "1908.01031", "submitter": "Adam Gudy\\'s", "authors": "Adam Gudy\\'s, Marek Sikora, {\\L}ukasz Wr\\'obel", "title": "RuleKit: A Comprehensive Suite for Rule-Based Learning", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": "10.1016/j.knosys.2020.105480", "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rule-based models are often used for data analysis as they combine\ninterpretability with predictive power. We present RuleKit, a versatile tool\nfor rule learning. Based on a sequential covering induction algorithm, it is\nsuitable for classification, regression, and survival problems. The presence of\na user-guided induction facilitates verifying hypotheses concerning data\ndependencies which are expected or of interest. The powerful and flexible\nexperimental environment allows straightforward investigation of different\ninduction schemes. The analysis can be performed in batch mode, through\nRapidMiner plug-in, or R package. A documented Java API is also provided for\nconvenience. The software is publicly available at GitHub under GNU AGPL-3.0\nlicense.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 19:53:46 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Gudy\u015b", "Adam", ""], ["Sikora", "Marek", ""], ["Wr\u00f3bel", "\u0141ukasz", ""]]}, {"id": "1908.01046", "submitter": "Anthony Corso", "authors": "Anthony Corso, Peter Du, Katherine Driggs-Campbell, Mykel J.\n  Kochenderfer", "title": "Adaptive Stress Testing with Reward Augmentation for Autonomous Vehicle\n  Validation", "comments": "Appears in IEEE ITSC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining possible failure scenarios is a critical step in the evaluation\nof autonomous vehicle systems. Real-world vehicle testing is commonly employed\nfor autonomous vehicle validation, but the costs and time requirements are\nhigh. Consequently, simulation-driven methods such as Adaptive Stress Testing\n(AST) have been proposed to aid in validation. AST formulates the problem of\nfinding the most likely failure scenarios as a Markov decision process, which\ncan be solved using reinforcement learning. In practice, AST tends to find\nscenarios where failure is unavoidable and tends to repeatedly discover the\nsame types of failures of a system. This work addresses these issues by\nencoding domain relevant information into the search procedure. With this\nmodification, the AST method discovers a larger and more expressive subset of\nthe failure space when compared to the original AST formulation. We show that\nour approach is able to identify useful failure scenarios of an autonomous\nvehicle policy.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 20:39:59 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 18:27:43 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Corso", "Anthony", ""], ["Du", "Peter", ""], ["Driggs-Campbell", "Katherine", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1908.01089", "submitter": "Chirag Gupta", "authors": "Chirag Gupta, Sivaraman Balakrishnan, Aaditya Ramdas", "title": "Path Length Bounds for Gradient Descent and Flow", "comments": "55 pages. Accepted for publication at the Journal of Machine Learning\n  Research (JMLR, 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive bounds on the path length $\\zeta$ of gradient descent (GD) and\ngradient flow (GF) curves for various classes of smooth convex and nonconvex\nfunctions. Among other results, we prove that: (a) if the iterates are linearly\nconvergent with factor $(1-c)$, then $\\zeta$ is at most $\\mathcal{O}(1/c)$; (b)\nunder the Polyak-Kurdyka-Lojasiewicz (PKL) condition, $\\zeta$ is at most\n$\\mathcal{O}(\\sqrt{\\kappa})$, where $\\kappa$ is the condition number, and at\nleast $\\widetilde\\Omega(\\sqrt{d} \\wedge \\kappa^{1/4})$; (c) for quadratics,\n$\\zeta$ is $\\Theta(\\min\\{\\sqrt{d},\\sqrt{\\log \\kappa}\\})$ and in some cases can\nbe independent of $\\kappa$; (d) assuming just convexity, $\\zeta$ can be at most\n$2^{4d\\log d}$; (e) for separable quasiconvex functions, $\\zeta$ is\n${\\Theta}(\\sqrt{d})$. Thus, we advance current understanding of the properties\nof GD and GF curves beyond rates of convergence. We expect our techniques to\nfacilitate future studies for other algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 23:07:42 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 03:54:14 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2020 22:41:40 GMT"}, {"version": "v4", "created": "Fri, 19 Mar 2021 18:09:00 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Gupta", "Chirag", ""], ["Balakrishnan", "Sivaraman", ""], ["Ramdas", "Aaditya", ""]]}, {"id": "1908.01099", "submitter": "Yixin Su", "authors": "Yixin Su, Sarah Monazam Erfani, Rui Zhang", "title": "MMF: Attribute Interpretable Collaborative Filtering", "comments": "8 pages, IJCNN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering is one of the most popular techniques in designing\nrecommendation systems, and its most representative model, matrix\nfactorization, has been wildly used by researchers and the industry. However,\nthis model suffers from the lack of interpretability and the item cold-start\nproblem, which limit its reliability and practicability. In this paper, we\npropose an interpretable recommendation model called Multi-Matrix Factorization\n(MMF), which addresses these two limitations and achieves the state-of-the-art\nprediction accuracy by exploiting common attributes that are present in\ndifferent items. In the model, predicted item ratings are regarded as weighted\naggregations of attribute ratings generated by the inner product of the user\nlatent vectors and the attribute latent vectors. MMF provides more fine grained\nanalyses than matrix factorization in the following ways: attribute ratings\nwith weights allow the understanding of how much each attribute contributes to\nthe recommendation and hence provide interpretability; the common attributes\ncan act as a link between existing and new items, which solves the item\ncold-start problem when no rating exists on an item. We evaluate the\ninterpretability of MMF comprehensively, and conduct extensive experiments on\nreal datasets to show that MMF outperforms state-of-the-art baselines in terms\nof accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 01:10:41 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Su", "Yixin", ""], ["Erfani", "Sarah Monazam", ""], ["Zhang", "Rui", ""]]}, {"id": "1908.01275", "submitter": "Ameer Haj-Ali", "authors": "Ameer Haj-Ali, Nesreen K. Ahmed, Ted Willke, Joseph Gonzalez, Krste\n  Asanovic, Ion Stoica", "title": "A View on Deep Reinforcement Learning in System Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world systems problems require reasoning about the long term\nconsequences of actions taken to configure and manage the system. These\nproblems with delayed and often sequentially aggregated reward, are often\ninherently reinforcement learning problems and present the opportunity to\nleverage the recent substantial advances in deep reinforcement learning.\nHowever, in some cases, it is not clear why deep reinforcement learning is a\ngood fit for the problem. Sometimes, it does not perform better than the\nstate-of-the-art solutions. And in other cases, random search or greedy\nalgorithms could outperform deep reinforcement learning. In this paper, we\nreview, discuss, and evaluate the recent trends of using deep reinforcement\nlearning in system optimization. We propose a set of essential metrics to guide\nfuture works in evaluating the efficacy of using deep reinforcement learning in\nsystem optimization. Our evaluation includes challenges, the types of problems,\ntheir formulation in the deep reinforcement learning setting, embedding, the\nmodel used, efficiency, and robustness. We conclude with a discussion on open\nchallenges and potential directions for pushing further the integration of\nreinforcement learning in system optimization.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 05:55:56 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 01:52:21 GMT"}, {"version": "v3", "created": "Wed, 4 Sep 2019 23:13:04 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Haj-Ali", "Ameer", ""], ["Ahmed", "Nesreen K.", ""], ["Willke", "Ted", ""], ["Gonzalez", "Joseph", ""], ["Asanovic", "Krste", ""], ["Stoica", "Ion", ""]]}, {"id": "1908.01288", "submitter": "Md. Rezaul Karim", "authors": "Md. Rezaul Karim, Michael Cochez, Joao Bosco Jares, Mamtaz Uddin, Oya\n  Beyan, Stefan Decker", "title": "Drug-Drug Interaction Prediction Based on Knowledge Graph Embeddings and\n  Convolutional-LSTM Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interference between pharmacological substances can cause serious medical\ninjuries. Correctly predicting so-called drug-drug interactions (DDI) does not\nonly reduce these cases but can also result in a reduction of drug development\ncost. Presently, most drug-related knowledge is the result of clinical\nevaluations and post-marketing surveillance; resulting in a limited amount of\ninformation. Existing data-driven prediction approaches for DDIs typically rely\non a single source of information, while using information from multiple\nsources would help improve predictions. Machine learning (ML) techniques are\nused, but the techniques are often unable to deal with skewness in the data.\nHence, we propose a new ML approach for predicting DDIs based on multiple data\nsources. For this task, we use 12,000 drug features from DrugBank, PharmGKB,\nand KEGG drugs, which are integrated using Knowledge Graphs (KGs). To train our\nprediction model, we first embed the nodes in the graph using various embedding\napproaches. We found that the best performing combination was a ComplEx\nembedding method creating using PyTorch-BigGraph (PBG) with a\nConvolutional-LSTM network and classic machine learning-based prediction\nmodels. The model averaging ensemble method of three best classifiers yields up\nto 0.94, 0.92, 0.80 for AUPR, F1-score, and MCC, respectively during 5-fold\ncross-validation tests.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 07:19:21 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Karim", "Md. Rezaul", ""], ["Cochez", "Michael", ""], ["Jares", "Joao Bosco", ""], ["Uddin", "Mamtaz", ""], ["Beyan", "Oya", ""], ["Decker", "Stefan", ""]]}, {"id": "1908.01289", "submitter": "Ellen Novoseller", "authors": "Ellen R. Novoseller, Yibing Wei, Yanan Sui, Yisong Yue, and Joel W.\n  Burdick", "title": "Dueling Posterior Sampling for Preference-Based Reinforcement Learning", "comments": "To appear in Conference on Uncertainty in Artificial Intelligence\n  (UAI), 2020. 9 pages before references and appendix; 51 pages total; 7\n  figures; 4 tables. This replacement incorporates reviewer comments, and in\n  comparison to version 1, extends the theoretical and empirical analyses and\n  adds mathematical detail. Code:\n  https://github.com/ernovoseller/DuelingPosteriorSampling", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In preference-based reinforcement learning (RL), an agent interacts with the\nenvironment while receiving preferences instead of absolute feedback. While\nthere is increasing research activity in preference-based RL, the design of\nformal frameworks that admit tractable theoretical analysis remains an open\nchallenge. Building upon ideas from preference-based bandit learning and\nposterior sampling in RL, we present DUELING POSTERIOR SAMPLING (DPS), which\nemploys preference-based posterior sampling to learn both the system dynamics\nand the underlying utility function that governs the preference feedback. As\npreference feedback is provided on trajectories rather than individual\nstate-action pairs, we develop a Bayesian approach for the credit assignment\nproblem, translating preferences to a posterior distribution over state-action\nreward models. We prove an asymptotic Bayesian no-regret rate for DPS with a\nBayesian linear regression credit assignment model. This is the first regret\nguarantee for preference-based RL to our knowledge. We also discuss possible\navenues for extending the proof methodology to other credit assignment models.\nFinally, we evaluate the approach empirically, showing competitive performance\nagainst existing baselines.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 07:51:36 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 05:27:33 GMT"}, {"version": "v3", "created": "Sat, 30 May 2020 05:26:41 GMT"}, {"version": "v4", "created": "Mon, 29 Jun 2020 16:09:49 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Novoseller", "Ellen R.", ""], ["Wei", "Yibing", ""], ["Sui", "Yanan", ""], ["Yue", "Yisong", ""], ["Burdick", "Joel W.", ""]]}, {"id": "1908.01328", "submitter": "Georgi Karadzhov", "authors": "Pepa Atanasova, Preslav Nakov, Llu\\'is M\\`arquez, Alberto\n  Barr\\'on-Cede\\~no, Georgi Karadzhov, Tsvetomila Mihaylova, Mitra Mohtarami,\n  James Glass", "title": "Automatic Fact-Checking Using Context and Discourse Information", "comments": "JDIQ,Special Issue on Combating Digital Misinformation and\n  Disinformation", "journal-ref": "J. Data and Information Quality, Volume 11 Issue 3, July 2019,\n  Article No. 12", "doi": "10.1145/3297722", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of automatic fact-checking, paying special attention to\nthe impact of contextual and discourse information. We address two related\ntasks: (i) detecting check-worthy claims, and (ii) fact-checking claims. We\ndevelop supervised systems based on neural networks, kernel-based support\nvector machines, and combinations thereof, which make use of rich input\nrepresentations in terms of discourse cues and contextual features. For the\ncheck-worthiness estimation task, we focus on political debates, and we model\nthe target claim in the context of the full intervention of a participant and\nthe previous and the following turns in the debate, taking into account\ncontextual meta information. For the fact-checking task, we focus on answer\nverification in a community forum, and we model the veracity of the answer with\nrespect to the entire question--answer thread in which it occurs as well as\nwith respect to other related posts from the entire forum. We develop annotated\ndatasets for both tasks and we run extensive experimental evaluation,\nconfirming that both types of information ---but especially contextual\nfeatures--- play an important role.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 12:40:28 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Atanasova", "Pepa", ""], ["Nakov", "Preslav", ""], ["M\u00e0rquez", "Llu\u00eds", ""], ["Barr\u00f3n-Cede\u00f1o", "Alberto", ""], ["Karadzhov", "Georgi", ""], ["Mihaylova", "Tsvetomila", ""], ["Mohtarami", "Mitra", ""], ["Glass", "James", ""]]}, {"id": "1908.01362", "submitter": "Sam Toyer", "authors": "Sam Toyer, Felipe Trevizan, Sylvie Thi\\'ebaux, Lexing Xie", "title": "ASNets: Deep Learning for Generalised Planning", "comments": "Journal extension of AAAI'18 paper (arXiv:1709.04271)", "journal-ref": "Journal of Artificial Intelligence Research 68 (2020) 1-68", "doi": "10.1613/jair.1.11633", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we discuss the learning of generalised policies for\nprobabilistic and classical planning problems using Action Schema Networks\n(ASNets). The ASNet is a neural network architecture that exploits the\nrelational structure of (P)PDDL planning problems to learn a common set of\nweights that can be applied to any problem in a domain. By mimicking the\nactions chosen by a traditional, non-learning planner on a handful of small\nproblems in a domain, ASNets are able to learn a generalised reactive policy\nthat can quickly solve much larger instances from the domain. This work extends\nthe ASNet architecture to make it more expressive, while still remaining\ninvariant to a range of symmetries that exist in PPDDL problems. We also\npresent a thorough experimental evaluation of ASNets, including a comparison\nwith heuristic search planners on seven probabilistic and deterministic\ndomains, an extended evaluation on over 18,000 Blocksworld instances, and an\nablation study. Finally, we show that sparsity-inducing regularisation can\nproduce ASNets that are compact enough for humans to understand, yielding\ninsights into how the structure of ASNets allows them to generalise across a\ndomain.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 15:37:13 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 15:19:06 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Toyer", "Sam", ""], ["Trevizan", "Felipe", ""], ["Thi\u00e9baux", "Sylvie", ""], ["Xie", "Lexing", ""]]}, {"id": "1908.01417", "submitter": "Alexander Zook", "authors": "Alexander Zook, Eric Fruchter, Mark O. Riedl", "title": "Automatic Playtesting for Game Parameter Tuning via Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Game designers use human playtesting to gather feedback about game design\nelements when iteratively improving a game. Playtesting, however, is expensive:\nhuman testers must be recruited, playtest results must be aggregated and\ninterpreted, and changes to game designs must be extrapolated from these\nresults. Can automated methods reduce this expense? We show how active learning\ntechniques can formalize and automate a subset of playtesting goals.\nSpecifically, we focus on the low-level parameter tuning required to balance a\ngame once the mechanics have been chosen. Through a case study on a\nshoot-`em-up game we demonstrate the efficacy of active learning to reduce the\namount of playtesting needed to choose the optimal set of game parameters for\ntwo classes of (formal) design objectives. This work opens the potential for\nadditional methods to reduce the human burden of performing playtesting for a\nvariety of relevant design concerns.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 22:48:16 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Zook", "Alexander", ""], ["Fruchter", "Eric", ""], ["Riedl", "Mark O.", ""]]}, {"id": "1908.01420", "submitter": "Alexander Zook", "authors": "Alexander Zook and Mark O. Riedl", "title": "Automatic Game Design via Mechanic Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Game designs often center on the game mechanics---rules governing the logical\nevolution of the game. We seek to develop an intelligent system that generates\ncomputer games. As first steps towards this goal we present a composable and\ncross-domain representation for game mechanics that draws from AI planning\naction representations. We use a constraint solver to generate mechanics\nsubject to design requirements on the form of those mechanics---what they do in\nthe game. A planner takes a set of generated mechanics and tests whether those\nmechanics meet playability requirements---controlling how mechanics function in\na game to affect player behavior. We demonstrate our system by modeling and\ngenerating mechanics in a role-playing game, platformer game, and combined\nrole-playing-platformer game.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 23:12:16 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Zook", "Alexander", ""], ["Riedl", "Mark O.", ""]]}, {"id": "1908.01423", "submitter": "Alexander Zook", "authors": "Alexander Zook, Brent Harrison, Mark O. Riedl", "title": "Monte-Carlo Tree Search for Simulation-based Strategy Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Games are often designed to shape player behavior in a desired way; however,\nit can be unclear how design decisions affect the space of behaviors in a game.\nDesigners usually explore this space through human playtesting, which can be\ntime-consuming and of limited effectiveness in exhausting the space of possible\nbehaviors. In this paper, we propose the use of automated planning agents to\nsimulate humans of varying skill levels to generate game playthroughs. Metrics\ncan then be gathered from these playthroughs to evaluate the current game\ndesign and identify its potential flaws. We demonstrate this technique in two\ngames: the popular word game Scrabble and a collectible card game of our own\ndesign named Cardonomicon. Using these case studies, we show how using\nsimulated agents to model humans of varying skill levels allows us to extract\nmetrics to describe game balance (in the case of Scrabble) and highlight\npotential design flaws (in the case of Cardonomicon).\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 23:21:00 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Zook", "Alexander", ""], ["Harrison", "Brent", ""], ["Riedl", "Mark O.", ""]]}, {"id": "1908.01478", "submitter": "Yi-Hsiang Chang", "authors": "Yi-Hsiang Chang, Kuan-Yu Chang, Henry Kuo, Chun-Yi Lee", "title": "Reusability and Transferability of Macro Actions for Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional reinforcement learning (RL) typically determines an appropriate\nprimitive action at each timestep. However, by using a proper macro action,\ndefined as a sequence of primitive actions, an agent is able to bypass\nintermediate states to a farther state and facilitate its learning procedure.\nThe problem we would like to investigate is what associated beneficial\nproperties that macro actions may possess. In this paper, we unveil the\nproperties of reusability and transferability of macro actions. The first\nproperty, reusability, means that a macro action generated along with one RL\nmethod can be reused by another RL method for training, while the second one,\ntransferability, means that a macro action can be utilized for training agents\nin similar environments with different reward settings. In our experiments, we\nfirst generate macro actions along with RL methods. We then provide a set of\nanalyses to reveal the properties of reusability and transferability of the\ngenerated macro actions.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 05:59:40 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 06:04:26 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Chang", "Yi-Hsiang", ""], ["Chang", "Kuan-Yu", ""], ["Kuo", "Henry", ""], ["Lee", "Chun-Yi", ""]]}, {"id": "1908.01482", "submitter": "Juncheng Li", "authors": "Juncheng Li, Siliang Tang, Fei Wu, and Yueting Zhuang", "title": "Walking with MIND: Mental Imagery eNhanceD Embodied QA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The EmbodiedQA is a task of training an embodied agent by intelligently\nnavigating in a simulated environment and gathering visual information to\nanswer questions. Existing approaches fail to explicitly model the mental\nimagery function of the agent, while the mental imagery is crucial to embodied\ncognition, and has a close relation to many high-level meta-skills such as\ngeneralization and interpretation. In this paper, we propose a novel Mental\nImagery eNhanceD (MIND) module for the embodied agent, as well as a relevant\ndeep reinforcement framework for training. The MIND module can not only model\nthe dynamics of the environment (e.g. 'what might happen if the agent passes\nthrough a door') but also help the agent to create a better understanding of\nthe environment (e.g. 'The refrigerator is usually in the kitchen'). Such\nknowledge makes the agent a faster and better learner in locating a feasible\npolicy with only a few trails. Furthermore, the MIND module can generate mental\nimages that are treated as short-term subgoals by our proposed deep\nreinforcement framework. These mental images facilitate policy learning since\nshort-term subgoals are easy to achieve and reusable. This yields better\nplanning efficiency than other algorithms that learn a policy directly from\nprimitive actions. Finally, the mental images visualize the agent's intentions\nin a way that human can understand, and this endows our agent's actions with\nmore interpretability. The experimental results and further analysis prove that\nthe agent with the MIND module is superior to its counterparts not only in EQA\nperformance but in many other aspects such as route planning, behavioral\ninterpretation, and the ability to generalize from a few examples.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 06:17:03 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Li", "Juncheng", ""], ["Tang", "Siliang", ""], ["Wu", "Fei", ""], ["Zhuang", "Yueting", ""]]}, {"id": "1908.01618", "submitter": "Nusrah Hussain", "authors": "Nusrah Hussain, Engin Erzin, T. Metin Sezgin, and Yucel Yemez", "title": "Speech Driven Backchannel Generation using Deep Q-Network for Enhancing\n  Engagement in Human-Robot Interaction", "comments": "8 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method for training a social robot to generate\nbackchannels during human-robot interaction. We address the problem within an\noff-policy reinforcement learning framework, and show how a robot may learn to\nproduce non-verbal backchannels like laughs, when trained to maximize the\nengagement and attention of the user. A major contribution of this work is the\nformulation of the problem as a Markov decision process (MDP) with states\ndefined by the speech activity of the user and rewards generated by quantified\nengagement levels. The problem that we address falls into the class of\napplications where unlimited interaction with the environment is not possible\n(our environment being a human) because it may be time-consuming, costly,\nimpracticable or even dangerous in case a bad policy is executed. Therefore, we\nintroduce deep Q-network (DQN) in a batch reinforcement learning framework,\nwhere an optimal policy is learned from a batch data collected using a more\ncontrolled policy. We suggest the use of human-to-human dyadic interaction\ndatasets as a batch of trajectories to train an agent for engaging\ninteractions. Our experiments demonstrate the potential of our method to train\na robot for engaging behaviors in an offline manner.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 13:47:31 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Hussain", "Nusrah", ""], ["Erzin", "Engin", ""], ["Sezgin", "T. Metin", ""], ["Yemez", "Yucel", ""]]}, {"id": "1908.01695", "submitter": "Koen Holtman", "authors": "Koen Holtman", "title": "Corrigibility with Utility Preservation", "comments": "Version 2 has improvements to the presentation and fixes typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Corrigibility is a safety property for artificially intelligent agents. A\ncorrigible agent will not resist attempts by authorized parties to alter the\ngoals and constraints that were encoded in the agent when it was first started.\nThis paper shows how to construct a safety layer that adds corrigibility to\narbitrarily advanced utility maximizing agents, including possible future\nagents with Artificial General Intelligence (AGI). The layer counter-acts the\nemergent incentive of advanced agents to resist such alteration. A detailed\nmodel for agents which can reason about preserving their utility function is\ndeveloped, and used to prove that the corrigibility layer works as intended in\na large set of non-hostile universes. The corrigible agents have an emergent\nincentive to protect key elements of their corrigibility layer. However,\nhostile universes may contain forces strong enough to break safety features.\nSome open problems related to graceful degradation when an agent is\nsuccessfully attacked are identified. The results in this paper were obtained\nby concurrently developing an AGI agent simulator, an agent model, and proofs.\nThe simulator is available under an open source license. The paper contains\nsimulation results which illustrate the safety related properties of corrigible\nAGI agents in detail.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 15:40:45 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 09:50:09 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Holtman", "Koen", ""]]}, {"id": "1908.01763", "submitter": "Lun Wang", "authors": "Wenbo Guo, Lun Wang, Xinyu Xing, Min Du, Dawn Song", "title": "TABOR: A Highly Accurate Approach to Inspecting and Restoring Trojan\n  Backdoors in AI Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A trojan backdoor is a hidden pattern typically implanted in a deep neural\nnetwork. It could be activated and thus forces that infected model behaving\nabnormally only when an input data sample with a particular trigger present is\nfed to that model. As such, given a deep neural network model and clean input\nsamples, it is very challenging to inspect and determine the existence of a\ntrojan backdoor. Recently, researchers design and develop several pioneering\nsolutions to address this acute problem. They demonstrate the proposed\ntechniques have a great potential in trojan detection. However, we show that\nnone of these existing techniques completely address the problem. On the one\nhand, they mostly work under an unrealistic assumption (e.g. assuming\navailability of the contaminated training database). On the other hand, the\nproposed techniques cannot accurately detect the existence of trojan backdoors,\nnor restore high-fidelity trojan backdoor images, especially when the triggers\npertaining to the trojan vary in size, shape and position. In this work, we\npropose TABOR, a new trojan detection technique. Conceptually, it formalizes a\ntrojan detection task as a non-convex optimization problem, and the detection\nof a trojan backdoor as the task of resolving the optimization through an\nobjective function. Different from the existing technique also modeling trojan\ndetection as an optimization problem, TABOR designs a new objective\nfunction--under the guidance of explainable AI techniques as well as\nheuristics--that could guide optimization to identify a trojan backdoor in a\nmore effective fashion. In addition, TABOR defines a new metric to measure the\nquality of a trojan backdoor identified. Using an anomaly detection method, we\nshow the new metric could better facilitate TABOR to identify intentionally\ninjected triggers in an infected model and filter out false alarms......\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 22:46:03 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2019 22:59:45 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Guo", "Wenbo", ""], ["Wang", "Lun", ""], ["Xing", "Xinyu", ""], ["Du", "Min", ""], ["Song", "Dawn", ""]]}, {"id": "1908.01766", "submitter": "Pavel Kraikivski", "authors": "Pavel Kraikivski", "title": "Seeding the Singularity for A.I", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The singularity refers to an idea that once a machine having an artificial\nintelligence surpassing the human intelligence capacity is created, it will\ntrigger explosive technological and intelligence growth. I propose to test the\nhypothesis that machine intelligence capacity can grow autonomously starting\nwith an intelligence comparable to that of bacteria - microbial intelligence.\nThe goal will be to demonstrate that rapid growth in intelligence capacity can\nbe realized at all in artificial computing systems. I propose the following\nthree properties that may allow an artificial intelligence to exhibit a steady\ngrowth in its intelligence capacity: (i) learning with the ability to modify\nitself when exposed to more data, (ii) acquiring new functionalities (skills),\nand (iii) expanding or replicating itself. The algorithms must demonstrate a\nrapid growth in skills of dataprocessing and analysis and gain qualitatively\ndifferent functionalities, at least until the current computing technology\nsupports their scalable development. The existing algorithms that already\nencompass some of these or similar properties, as well as missing abilities\nthat must yet be implemented, will be reviewed in this work. Future\ncomputational tests could support or oppose the hypothesis that artificial\nintelligence can potentially grow to the level of superintelligence which\novercomes the limitations in hardware by producing necessary processing\nresources or by changing the physical realization of computation from using\nchip circuits to using quantum computing principles.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 16:47:56 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Kraikivski", "Pavel", ""]]}, {"id": "1908.01767", "submitter": "Suhas Gupta", "authors": "Suhas Gupta", "title": "Exploring Neural Net Augmentation to BERT for Question Answering on\n  SQUAD 2.0", "comments": "Code bug found", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enhancing machine capabilities to answer questions has been a topic of\nconsiderable focus in recent years of NLP research. Language models like\nEmbeddings from Language Models (ELMo)[1] and Bidirectional Encoder\nRepresentations from Transformers (BERT) [2] have been very successful in\ndeveloping general purpose language models that can be optimized for a large\nnumber of downstream language tasks. In this work, we focused on augmenting the\npre-trained BERT language model with different output neural net architectures\nand compared their performance on question answering task posed by the Stanford\nQuestion Answering Dataset 2.0 (SQUAD 2.0) [3]. Additionally, we also\nfine-tuned the pre-trained BERT model parameters to demonstrate its\neffectiveness in adapting to specialized language tasks. Our best output\nnetwork, is the contextualized CNN that performs on both the unanswerable and\nanswerable question answering tasks with F1 scores of 75.32 and 64.85\nrespectively.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 16:48:24 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 03:21:33 GMT"}, {"version": "v3", "created": "Sun, 8 Mar 2020 23:10:16 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Gupta", "Suhas", ""]]}, {"id": "1908.01798", "submitter": "Dar\\'io Garigliotti", "authors": "Dar\\'io Garigliotti and Dyaa Albakour and Miguel Martinez and\n  Krisztian Balog", "title": "Unsupervised Context Retrieval for Long-tail Entities", "comments": "Proceedings of the 2019 ACM International Conference on Theory of\n  Information Retrieval (ICTIR' 19)", "journal-ref": null, "doi": "10.1145/3341981.3344244", "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring entities in media streams often relies on rich entity\nrepresentations, like structured information available in a knowledge base\n(KB). For long-tail entities, such monitoring is highly challenging, due to\ntheir limited, if not entirely missing, representation in the reference KB. In\nthis paper, we address the problem of retrieving textual contexts for\nmonitoring long-tail entities. We propose an unsupervised method to overcome\nthe limited representation of long-tail entities by leveraging established\nentities and their contexts as support information. Evaluation on a\npurpose-built test collection shows the suitability of our approach and its\nrobustness for out-of-KB entities.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 18:28:09 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Garigliotti", "Dar\u00edo", ""], ["Albakour", "Dyaa", ""], ["Martinez", "Miguel", ""], ["Balog", "Krisztian", ""]]}, {"id": "1908.01801", "submitter": "Kushal Kafle", "authors": "Kushal Kafle, Robik Shrestha, Brian Price, Scott Cohen, Christopher\n  Kanan", "title": "Answering Questions about Data Visualizations using Efficient Bimodal\n  Fusion", "comments": "Presented at WACV, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chart question answering (CQA) is a newly proposed visual question answering\n(VQA) task where an algorithm must answer questions about data visualizations,\ne.g. bar charts, pie charts, and line graphs. CQA requires capabilities that\nnatural-image VQA algorithms lack: fine-grained measurements, optical character\nrecognition, and handling out-of-vocabulary words in both questions and\nanswers. Without modifications, state-of-the-art VQA algorithms perform poorly\non this task. Here, we propose a novel CQA algorithm called parallel recurrent\nfusion of image and language (PReFIL). PReFIL first learns bimodal embeddings\nby fusing question and image features and then intelligently aggregates these\nlearned embeddings to answer the given question. Despite its simplicity, PReFIL\ngreatly surpasses state-of-the art systems and human baselines on both the\nFigureQA and DVQA datasets. Additionally, we demonstrate that PReFIL can be\nused to reconstruct tables by asking a series of questions about a chart.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 18:47:30 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 15:10:29 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Kafle", "Kushal", ""], ["Shrestha", "Robik", ""], ["Price", "Brian", ""], ["Cohen", "Scott", ""], ["Kanan", "Christopher", ""]]}, {"id": "1908.01839", "submitter": "Ping Wang", "authors": "Ping Wang, Tian Shi, Chandan K. Reddy", "title": "Text-to-SQL Generation for Question Answering on Electronic Medical\n  Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic medical records (EMR) contain comprehensive patient information\nand are typically stored in a relational database with multiple tables.\nEffective and efficient patient information retrieval from EMR data is a\nchallenging task for medical experts. Question-to-SQL generation methods tackle\nthis problem by first predicting the SQL query for a given question about a\ndatabase, and then, executing the query on the database. However, most of the\nexisting approaches have not been adapted to the healthcare domain due to a\nlack of healthcare Question-to-SQL dataset for learning models specific to this\ndomain. In addition, wide use of the abbreviation of terminologies and possible\ntypos in questions introduce additional challenges for accurately generating\nthe corresponding SQL queries. In this paper, we tackle these challenges by\ndeveloping a deep learning based TRanslate-Edit Model for Question-to-SQL\n(TREQS) generation, which adapts the widely used sequence-to-sequence model to\ndirectly generate the SQL query for a given question, and further performs the\nrequired edits using an attentive-copying mechanism and task-specific look-up\ntables. Based on the widely used publicly available electronic medical\ndatabase, we create a new large-scale Question-SQL pair dataset, named\nMIMICSQL, in order to perform the Question-to-SQL generation task in healthcare\ndomain. An extensive set of experiments are conducted to evaluate the\nperformance of our proposed model on MIMICSQL. Both quantitative and\nqualitative experimental results indicate the flexibility and efficiency of our\nproposed method in predicting condition values and its robustness to random\nquestions with abbreviations and typos.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 21:04:05 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 04:20:44 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Wang", "Ping", ""], ["Shi", "Tian", ""], ["Reddy", "Chandan K.", ""]]}, {"id": "1908.01843", "submitter": "Jie Zhou", "authors": "Jie Zhou, Xu Han, Cheng Yang, Zhiyuan Liu, Lifeng Wang, Changcheng Li,\n  Maosong Sun", "title": "GEAR: Graph-based Evidence Aggregating and Reasoning for Fact\n  Verification", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fact verification (FV) is a challenging task which requires to retrieve\nrelevant evidence from plain text and use the evidence to verify given claims.\nMany claims require to simultaneously integrate and reason over several pieces\nof evidence for verification. However, previous work employs simple models to\nextract information from evidence without letting evidence communicate with\neach other, e.g., merely concatenate the evidence for processing. Therefore,\nthese methods are unable to grasp sufficient relational and logical information\namong the evidence. To alleviate this issue, we propose a graph-based evidence\naggregating and reasoning (GEAR) framework which enables information to\ntransfer on a fully-connected evidence graph and then utilizes different\naggregators to collect multi-evidence information. We further employ BERT, an\neffective pre-trained language representation model, to improve the\nperformance. Experimental results on a large-scale benchmark dataset FEVER have\ndemonstrated that GEAR could leverage multi-evidence information for FV and\nthus achieves the promising result with a test FEVER score of 67.10%. Our code\nis available at https://github.com/thunlp/GEAR.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 08:25:16 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Zhou", "Jie", ""], ["Han", "Xu", ""], ["Yang", "Cheng", ""], ["Liu", "Zhiyuan", ""], ["Wang", "Lifeng", ""], ["Li", "Changcheng", ""], ["Sun", "Maosong", ""]]}, {"id": "1908.01887", "submitter": "Yusuke Urakami", "authors": "Yusuke Urakami, Alec Hodgkinson, Casey Carlin, Randall Leu, Luca\n  Rigazio, Pieter Abbeel", "title": "DoorGym: A Scalable Door Opening Environment And Baseline Agent", "comments": "Full version (Real world transfer experiments result)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to practically implement the door opening task, a policy ought to be\nrobust to a wide distribution of door types and environment settings.\nReinforcement Learning (RL) with Domain Randomization (DR) is a promising\ntechnique to enforce policy generalization, however, there are only a few\naccessible training environments that are inherently designed to train agents\nin domain randomized environments. We introduce DoorGym, an open-source door\nopening simulation framework designed to utilize domain randomization to train\na stable policy. We intend for our environment to lie at the intersection of\ndomain transfer, practical tasks, and realism. We also provide baseline\nProximal Policy Optimization and Soft Actor-Critic implementations, which\nachieves success rates between 0% up to 95% for opening various types of doors\nin this environment. Moreover, the real-world transfer experiment shows the\ntrained policy is able to work in the real world. Environment kit available\nhere: https://github.com/PSVL/DoorGym/\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 22:20:32 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 17:21:36 GMT"}, {"version": "v3", "created": "Wed, 13 May 2020 07:56:55 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Urakami", "Yusuke", ""], ["Hodgkinson", "Alec", ""], ["Carlin", "Casey", ""], ["Leu", "Randall", ""], ["Rigazio", "Luca", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1908.01969", "submitter": "Haoran Zhang", "authors": "Haoran Zhang and Diane Litman", "title": "Word Embedding for Response-To-Text Assessment of Evidence", "comments": "Published in the ACL 2017, Student Research Workshop", "journal-ref": "Proceedings of ACL 2017, Student Research Workshop (2017) 75-81", "doi": "10.18653/v1/P17-3013", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manually grading the Response to Text Assessment (RTA) is labor intensive.\nTherefore, an automatic method is being developed for scoring analytical\nwriting when the RTA is administered in large numbers of classrooms. Our\nlong-term goal is to also use this scoring method to provide formative feedback\nto students and teachers about students' writing quality. As a first step\ntowards this goal, interpretable features for automatically scoring the\nevidence rubric of the RTA have been developed. In this paper, we present a\nsimple but promising method for improving evidence scoring by employing the\nword embedding model. We evaluate our method on corpora of responses written by\nupper elementary students.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 05:58:06 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Zhang", "Haoran", ""], ["Litman", "Diane", ""]]}, {"id": "1908.01992", "submitter": "Haoran Zhang", "authors": "Haoran Zhang, Ahmed Magooda, Diane Litman, Richard Correnti, Elaine\n  Wang, Lindsay Clare Matsumura, Emily Howe, Rafael Quintana", "title": "eRevise: Using Natural Language Processing to Provide Formative Feedback\n  on Text Evidence Usage in Student Writing", "comments": "Published in IAAI 19", "journal-ref": "Proceedings of the AAAI Conference on Artificial Intelligence\n  (2019) vol. 33, 9619-9625", "doi": "10.1609/aaai.v33i01.33019619", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Writing a good essay typically involves students revising an initial paper\ndraft after receiving feedback. We present eRevise, a web-based writing and\nrevising environment that uses natural language processing features generated\nfor rubric-based essay scoring to trigger formative feedback messages regarding\nstudents' use of evidence in response-to-text writing. By helping students\nunderstand the criteria for using text evidence during writing, eRevise\nempowers students to better revise their paper drafts. In a pilot deployment of\neRevise in 7 classrooms spanning grades 5 and 6, the quality of text evidence\nusage in writing improved after students received formative feedback then\nengaged in paper revision.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 07:24:14 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Zhang", "Haoran", ""], ["Magooda", "Ahmed", ""], ["Litman", "Diane", ""], ["Correnti", "Richard", ""], ["Wang", "Elaine", ""], ["Matsumura", "Lindsay Clare", ""], ["Howe", "Emily", ""], ["Quintana", "Rafael", ""]]}, {"id": "1908.01993", "submitter": "Haoran Zhang", "authors": "Haoran Zhang and Diane Litman", "title": "Co-Attention Based Neural Network for Source-Dependent Essay Scoring", "comments": "Published in BEA 13 workshop", "journal-ref": "Proceedings of the Thirteenth Workshop on Innovative Use of NLP\n  for Building Educational Applications (2018) 399-409", "doi": "10.18653/v1/W18-0549", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an investigation of using a co-attention based neural\nnetwork for source-dependent essay scoring. We use a co-attention mechanism to\nhelp the model learn the importance of each part of the essay more accurately.\nAlso, this paper shows that the co-attention based neural network model\nprovides reliable score prediction of source-dependent responses. We evaluate\nour model on two source-dependent response corpora. Results show that our model\noutperforms the baseline on both corpora. We also show that the attention of\nthe model is similar to the expert opinions with examples.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 07:28:43 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Zhang", "Haoran", ""], ["Litman", "Diane", ""]]}, {"id": "1908.02002", "submitter": "Elad Farhi", "authors": "Elad I. Farhi and Vadim Indelman", "title": "Bayesian Incremental Inference Update by Re-using Calculations from\n  Belief Space Planning: A New Paradigm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference and decision making under uncertainty are key processes in every\nautonomous system and numerous robotic problems. In recent years, the\nsimilarities between inference and decision making triggered much work, from\ndeveloping unified computational frameworks to pondering about the duality\nbetween the two. In spite of these efforts, inference and control, as well as\ninference and belief space planning (BSP) are still treated as two separate\nprocesses. In this paper we propose a paradigm shift, a novel approach which\ndeviates from conventional Bayesian inference and utilizes the similarities\nbetween inference and BSP. We make the key observation that inference can be\nefficiently updated using predictions made during the decision making stage,\neven in light of inconsistent data association between the two. We developed a\ntwo staged process that implements our novel approach and updates inference\nusing calculations from the precursory planning phase. Using autonomous\nnavigation in an unknown environment along with iSAM2 efficient methodologies\nas a test case, we benchmarked our novel approach against standard Bayesian\ninference, both with synthetic and real-world data (KITTI dataset). Results\nindicate that not only our approach improves running time by at least a factor\nof two while providing the same estimation accuracy, but it also alleviates the\ncomputational burden of state dimensionality and loop closures.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 08:06:06 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 12:53:21 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Farhi", "Elad I.", ""], ["Indelman", "Vadim", ""]]}, {"id": "1908.02037", "submitter": "Nusrah Hussain", "authors": "Nusrah Hussain, Engin Erzin, T. Metin Sezgin, and Yucel Yemez", "title": "Batch Recurrent Q-Learning for Backchannel Generation Towards Engaging\n  Agents", "comments": "8 pages, 4 figures. arXiv admin note: substantial text overlap with\n  arXiv:1908.01618", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to generate appropriate verbal and non-verbal backchannels by an\nagent during human-robot interaction greatly enhances the interaction\nexperience. Backchannels are particularly important in applications like\ntutoring and counseling, which require constant attention and engagement of the\nuser. We present here a method for training a robot for backchannel generation\nduring a human-robot interaction within the reinforcement learning (RL)\nframework, with the goal of maintaining high engagement level. Since online\nlearning by interaction with a human is highly time-consuming and impractical,\nwe take advantage of the recorded human-to-human dataset and approach our\nproblem as a batch reinforcement learning problem. The dataset is utilized as a\nbatch data acquired by some behavior policy. We perform experiments with laughs\nas a backchannel and train an agent with value-based techniques. In particular,\nwe demonstrate the effectiveness of recurrent layers in the approximate value\nfunction for this problem, that boosts the performance in partially observable\nenvironments. With off-policy policy evaluation, it is shown that the RL agents\nare expected to produce more engagement than an agent trained from imitation\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 09:25:51 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Hussain", "Nusrah", ""], ["Erzin", "Engin", ""], ["Sezgin", "T. Metin", ""], ["Yemez", "Yucel", ""]]}, {"id": "1908.02047", "submitter": "Xianfu Chen", "authors": "Xianfu Chen and Celimuge Wu and Tao Chen and Honggang Zhang and Zhi\n  Liu and Yan Zhang and Mehdi Bennis", "title": "Age of Information-Aware Radio Resource Management in Vehicular\n  Networks: A Proactive Deep Reinforcement Learning Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we investigate the problem of age of information (AoI)-aware\nradio resource management for expected long-term performance optimization in a\nManhattan grid vehicle-to-vehicle network. With the observation of global\nnetwork state at each scheduling slot, the roadside unit (RSU) allocates the\nfrequency bands and schedules packet transmissions for all vehicle user\nequipment-pairs (VUE-pairs). We model the stochastic decision-making procedure\nas a discrete-time single-agent Markov decision process (MDP). The technical\nchallenges in solving the optimal control policy originate from high spatial\nmobility and temporally varying traffic information arrivals of the VUE-pairs.\nTo make the problem solving tractable, we first decompose the original MDP into\na series of per-VUE-pair MDPs. Then we propose a proactive algorithm based on\nlong short-term memory and deep reinforcement learning techniques to address\nthe partial observability and the curse of high dimensionality in local network\nstate space faced by each VUE-pair. With the proposed algorithm, the RSU makes\nthe optimal frequency band allocation and packet scheduling decision at each\nscheduling slot in a decentralized way in accordance with the partial\nobservations of the global network state at the VUE-pairs. Numerical\nexperiments validate the theoretical analysis and demonstrate the significant\nperformance improvements from the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 10:06:42 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 08:59:37 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Chen", "Xianfu", ""], ["Wu", "Celimuge", ""], ["Chen", "Tao", ""], ["Zhang", "Honggang", ""], ["Liu", "Zhi", ""], ["Zhang", "Yan", ""], ["Bennis", "Mehdi", ""]]}, {"id": "1908.02138", "submitter": "Stevan Tomic", "authors": "Stevan Tomic, Federico Pecora and Alessandro Saffiotti", "title": "Robby is Not a Robber (anymore): On the Use of Institutions for Learning\n  Normative Behavior", "comments": "16 pages, 11 figures, Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future robots should follow human social norms in order to be useful and\naccepted in human society. In this paper, we leverage already existing social\nknowledge in human societies by capturing it in our framework through the\nnotion of social norms. We show how norms can be used to guide a reinforcement\nlearning agent towards achieving normative behavior and apply the same set of\nnorms over different domains. Thus, we are able to: (1) provide a way to\nintuitively encode social knowledge (through norms); (2) guide learning towards\nnormative behaviors (through an automatic norm reward system); and (3) achieve\na transfer of learning by abstracting policies; Finally, (4) the method is not\ndependent on a particular RL algorithm. We show how our approach can be seen as\na means to achieve abstract representation and learn procedural knowledge based\non the declarative semantics of norms and discuss possible implications of this\nin some areas of cognitive science.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 23:46:55 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Tomic", "Stevan", ""], ["Pecora", "Federico", ""], ["Saffiotti", "Alessandro", ""]]}, {"id": "1908.02149", "submitter": "Amir Nakib", "authors": "Leo Souquet, Amir Nakib", "title": "Multi-node environment strategy for Parallel Deterministic\n  Multi-Objective Fractal Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.CY cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new implementation of deterministic multiobjective (MO)\noptimization called Multiobjective Fractal Decomposition Algorithm (Mo-FDA).\nThe original algorithm was designed for mono-objective large scale continuous\noptimization problems. It is based on a divide and conquer strategy and a\ngeometric fractal decomposition of the search space using hyperspheres. Then,\nto deal with MO problems a scalarization approach is used. In this work, a new\napproach has been developed on a multi-node environment using containers. The\nperformance of Mo-FDA was compared to state of the art algorithms from the\nliterature on classical benchmark of multi-objective optimization\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 00:58:12 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Souquet", "Leo", ""], ["Nakib", "Amir", ""]]}, {"id": "1908.02239", "submitter": "Rawan Naous", "authors": "Rawan Naous, Lazar Supic, Yoonhwan Kang, Ranko Sredojevic, Anish\n  Singhani, and Vladimir Stojanovic", "title": "Tuning Algorithms and Generators for Efficient Edge Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A surge in artificial intelligence and autonomous technologies have increased\nthe demand toward enhanced edge-processing capabilities. Computational\ncomplexity and size of state-of-the-art Deep Neural Networks (DNNs) are rising\nexponentially with diverse network models and larger datasets. This growth\nlimits the performance scaling and energy-efficiency of both distributed and\nembedded inference platforms. Embedded designs at the edge are constrained by\nenergy and speed limitations of available processor substrates and processor to\nmemory communication required to fetch the model coefficients. While many\nhardware accelerator and network deployment frameworks have been in\ndevelopment, a framework is needed to allow the variety of existing\narchitectures, and those in development, to be expressed in critical parts of\nthe flow that perform various optimization steps. Moreover, premature\narchitecture-blind network selection and optimization diminish the\neffectiveness of schedule optimizations and hardware-specific mappings. In this\npaper, we address these issues by creating a cross-layer software-hardware\ndesign framework that encompasses network training and model compression that\nis aware of and tuned to the underlying hardware architecture. This approach\nleverages the available degrees of DNN structure and sparsity to create a\nconverged network that can be partitioned and efficiently scheduled on the\ntarget hardware platform, minimizing data movement, and improving the overall\nthroughput and energy. To further streamline the design, we leverage the\nhigh-level, flexible SoC generator platform based on RISC-V ROCC framework.\nThis integration allows seamless extensions of the RISC-V instruction set and\nChisel-based rapid generator design. Utilizing this approach, we implemented a\nsilicon prototype in a 16 nm TSMC process node achieving record processing\nefficiency of up to 18 TOPS/W.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 02:52:52 GMT"}, {"version": "v2", "created": "Sun, 10 May 2020 20:22:12 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Naous", "Rawan", ""], ["Supic", "Lazar", ""], ["Kang", "Yoonhwan", ""], ["Sredojevic", "Ranko", ""], ["Singhani", "Anish", ""], ["Stojanovic", "Vladimir", ""]]}, {"id": "1908.02270", "submitter": "Tianchi Huang", "authors": "Tianchi Huang, Chao Zhou, Rui-Xiao Zhang, Chenglei Wu, Xin Yao, Lifeng\n  Sun", "title": "Comyco: Quality-Aware Adaptive Video Streaming via Imitation Learning", "comments": "ACM Multimedia 2019", "journal-ref": null, "doi": "10.1145/3343031.3351014", "report-no": null, "categories": "cs.MM cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-based Adaptive Bit Rate~(ABR) method, aiming to learn outstanding\nstrategies without any presumptions, has become one of the research hotspots\nfor adaptive streaming. However, it typically suffers from several issues,\ni.e., low sample efficiency and lack of awareness of the video quality\ninformation. In this paper, we propose Comyco, a video quality-aware ABR\napproach that enormously improves the learning-based methods by tackling the\nabove issues. Comyco trains the policy via imitating expert trajectories given\nby the instant solver, which can not only avoid redundant exploration but also\nmake better use of the collected samples. Meanwhile, Comyco attempts to pick\nthe chunk with higher perceptual video qualities rather than video bitrates. To\nachieve this, we construct Comyco's neural network architecture, video datasets\nand QoE metrics with video quality features. Using trace-driven and real-world\nexperiments, we demonstrate significant improvements of Comyco's sample\nefficiency in comparison to prior work, with 1700x improvements in terms of the\nnumber of samples required and 16x improvements on training time required.\nMoreover, results illustrate that Comyco outperforms previously proposed\nmethods, with the improvements on average QoE of 7.5% - 16.79%. Especially,\nComyco also surpasses state-of-the-art approach Pensieve by 7.37% on average\nvideo quality under the same rebuffering time.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 17:48:46 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 07:54:23 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Huang", "Tianchi", ""], ["Zhou", "Chao", ""], ["Zhang", "Rui-Xiao", ""], ["Wu", "Chenglei", ""], ["Yao", "Xin", ""], ["Sun", "Lifeng", ""]]}, {"id": "1908.02282", "submitter": "Srijith Rajamohan", "authors": "Srijith Rajamohan, Alana Romanella, Amit Ramesh", "title": "A Weakly-Supervised Attention-based Visualization Tool for Assessing\n  Political Affiliation", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we seek to finetune a weakly-supervised expert-guided Deep\nNeural Network (DNN) for the purpose of determining political affiliations. In\nthis context, stance detection is used for determining political affiliation or\nideology which is framed in the form of relative proximities between entities\nin a low-dimensional space. An attention-based mechanism is used to provide\nmodel interpretability. A Deep Neural Network for Natural Language\nUnderstanding (NLU) using static and contextual embeddings is trained and\nevaluated. Various techniques to visualize the projections generated from the\nnetwork are evaluated for visualization efficiency. An overview of the pipeline\nfrom data ingestion, processing and generation of visualization is given here.\nA web-based framework created to faciliate this interaction and exploration is\npresented here. Preliminary results of this study are summarized and future\nwork is outlined.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 18:14:06 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Rajamohan", "Srijith", ""], ["Romanella", "Alana", ""], ["Ramesh", "Amit", ""]]}, {"id": "1908.02353", "submitter": "Flavio de Barros Vidal", "authors": "Lucas F. Porto, Laise N. Correia Lima, Ademir Franco, Donald M.\n  Pianto, Carlos Eduardo Machado Palhares, Donald M. Pianto and Flavio de\n  Barros Vidal", "title": "Estimating sex and age for forensic applications using machine learning\n  based on facial measurements from frontal cephalometric landmarks", "comments": "17 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial analysis permits many investigations some of the most important of\nwhich are craniofacial identification, facial recognition, and age and sex\nestimation. In forensics, photo-anthropometry describes the study of facial\ngrowth and allows the identification of patterns in facial skull development by\nusing a group of cephalometric landmarks to estimate anthropological\ninformation. In several areas, automation of manual procedures has achieved\nadvantages over and similar measurement confidence as a forensic expert. This\nmanuscript presents an approach using photo-anthropometric indexes, generated\nfrom frontal faces cephalometric landmarks, to create an artificial neural\nnetwork classifier that allows the estimation of anthropological information,\nin this specific case age and sex. The work is focused on four tasks: i) sex\nestimation over ages from 5 to 22 years old, evaluating the interference of age\non sex estimation; ii) age estimation from photo-anthropometric indexes for\nfour age intervals (1 year, 2 years, 4 years and 5 years); iii) age group\nestimation for thresholds of over 14 and over 18 years old; and; iv) the\nprovision of a new data set, available for academic purposes only, with a large\nand complete set of facial photo-anthropometric points marked and checked by\nforensic experts, measured from over 18,000 faces of individuals from Brazil\nover the last 4 years. The proposed classifier obtained significant results,\nusing this new data set, for the sex estimation of individuals over 14 years\nold, achieving accuracy values greater than 0.85 by the F_1 measure. For age\nestimation, the accuracy results are 0.72 for measure with an age interval of 5\nyears. For the age group estimation, the measures of accuracy are greater than\n0.93 and 0.83 for thresholds of 14 and 18 years, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 20:33:11 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Porto", "Lucas F.", ""], ["Lima", "Laise N. Correia", ""], ["Franco", "Ademir", ""], ["Pianto", "Donald M.", ""], ["Palhares", "Carlos Eduardo Machado", ""], ["Pianto", "Donald M.", ""], ["Vidal", "Flavio de Barros", ""]]}, {"id": "1908.02357", "submitter": "Kaiqing Zhang", "authors": "Kaiqing Zhang and Erik Miehling and Tamer Ba\\c{s}ar", "title": "Online Planning for Decentralized Stochastic Control with Partial\n  History Sharing", "comments": "Accepted to American Control Conference (ACC) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In decentralized stochastic control, standard approaches for sequential\ndecision-making, e.g. dynamic programming, quickly become intractable due to\nthe need to maintain a complex information state. Computational challenges are\nfurther compounded if agents do not possess complete model knowledge. In this\npaper, we take advantage of the fact that in many problems agents share some\ncommon information, or history, termed partial history sharing. Under this\ninformation structure the policy search space is greatly reduced. We propose a\nprovably convergent, online tree-search based algorithm that does not require a\nclosed-form model or explicit communication among agents. Interestingly, our\nalgorithm can be viewed as a generalization of several existing heuristic\nsolvers for decentralized partially observable Markov decision processes. To\ndemonstrate the applicability of the model, we propose a novel collaborative\nintrusion response model, where multiple agents (defenders) possessing\nasymmetric information aim to collaboratively defend a computer network.\nNumerical results demonstrate the performance of our algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 20:38:58 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Zhang", "Kaiqing", ""], ["Miehling", "Erik", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "1908.02367", "submitter": "Chaoyu Guan", "authors": "Chaoyu Guan, Yuhao Cheng, Hai Zhao", "title": "Semantic Role Labeling with Associated Memory Network", "comments": "Published at NAACL 2019; This is camera Ready version; Code is\n  available at https://github.com/Frozenmad/AMN_SRL", "journal-ref": null, "doi": "10.18653/v1/N19-1340", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic role labeling (SRL) is a task to recognize all the\npredicate-argument pairs of a sentence, which has been in a performance\nimprovement bottleneck after a series of latest works were presented. This\npaper proposes a novel syntax-agnostic SRL model enhanced by the proposed\nassociated memory network (AMN), which makes use of inter-sentence attention of\nlabel-known associated sentences as a kind of memory to further enhance\ndependency-based SRL. In detail, we use sentences and their labels from train\ndataset as an associated memory cue to help label the target sentence.\nFurthermore, we compare several associated sentences selecting strategies and\nlabel merging methods in AMN to find and utilize the label of associated\nsentences while attending them. By leveraging the attentive memory from known\ntraining data, Our full model reaches state-of-the-art on CoNLL-2009 benchmark\ndatasets for syntax-agnostic setting, showing a new effective research line of\nSRL enhancement other than exploiting external resources such as well\npre-trained language models.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 09:40:18 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Guan", "Chaoyu", ""], ["Cheng", "Yuhao", ""], ["Zhao", "Hai", ""]]}, {"id": "1908.02374", "submitter": "Youcheng Sun", "authors": "Youcheng Sun, Hana Chockler, Xiaowei Huang, Daniel Kroening", "title": "Explaining Image Classifiers using Statistical Fault Localization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The black-box nature of deep neural networks (DNNs) makes it impossible to\nunderstand why a particular output is produced, creating demand for\n\"Explainable AI\". In this paper, we show that statistical fault localization\n(SFL) techniques from software engineering deliver high quality explanations of\nthe outputs of DNNs, where we define an explanation as a minimal subset of\nfeatures sufficient for making the same decision as for the original input. We\npresent an algorithm and a tool called DeepCover, which synthesizes a ranking\nof the features of the inputs using SFL and constructs explanations for the\ndecisions of the DNN based on this ranking. We compare explanations produced by\nDeepCover with those of the state-of-the-art tools GradCAM, LIME, SHAP, RISE\nand Extremal and show that explanations generated by DeepCover are consistently\nbetter across a broad set of experiments. On a benchmark set with known ground\ntruth, DeepCover achieves 76.7% accuracy, which is 6% better than the second\nbest Extremal.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 21:44:48 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 15:10:20 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Sun", "Youcheng", ""], ["Chockler", "Hana", ""], ["Huang", "Xiaowei", ""], ["Kroening", "Daniel", ""]]}, {"id": "1908.02402", "submitter": "Lei Shu", "authors": "Lei Shu, Piero Molino, Mahdi Namazifar, Hu Xu, Bing Liu, Huaixiu\n  Zheng, Gokhan Tur", "title": "Flexibly-Structured Model for Task-Oriented Dialogues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel end-to-end architecture for task-oriented\ndialogue systems. It is based on a simple and practical yet very effective\nsequence-to-sequence approach, where language understanding and state tracking\ntasks are modeled jointly with a structured copy-augmented sequential decoder\nand a multi-label decoder for each slot. The policy engine and language\ngeneration tasks are modeled jointly following that. The copy-augmented\nsequential decoder deals with new or unknown values in the conversation, while\nthe multi-label decoder combined with the sequential decoder ensures the\nexplicit assignment of values to slots. On the generation part, slot binary\nclassifiers are used to improve performance. This architecture is scalable to\nreal-world scenarios and is shown through an empirical evaluation to achieve\nstate-of-the-art performance on both the Cambridge Restaurant dataset and the\nStanford in-car assistant dataset\\footnote{The code is available at\n\\url{https://github.com/uber-research/FSDM}}\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 23:56:25 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Shu", "Lei", ""], ["Molino", "Piero", ""], ["Namazifar", "Mahdi", ""], ["Xu", "Hu", ""], ["Liu", "Bing", ""], ["Zheng", "Huaixiu", ""], ["Tur", "Gokhan", ""]]}, {"id": "1908.02412", "submitter": "Bin Guo", "authors": "Bin Guo, Huihui Chen, Yan Liu, Chao Chen, Qi Han, Zhiwen Yu", "title": "From Crowdsourcing to Crowdmining: Using Implicit Human Intelligence for\n  Better Understanding of Crowdsourced Data", "comments": "12 pages, accepted by World Wide Web Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of mobile social networks, more and more crowdsourced\ndata are generated on the Web or collected from real-world sensing. The\nfragment, heterogeneous, and noisy nature of online/offline crowdsourced data,\nhowever, makes it difficult to be understood. Traditional content-based\nanalyzing methods suffer from potential issues such as computational\nintensiveness and poor performance. To address them, this paper presents\nCrowdMining. In particular, we observe that the knowledge hidden in the process\nof data generation, regarding individual/crowd behavior patterns (e.g.,\nmobility patterns, community contexts such as social ties and structure) and\ncrowd-object interaction patterns (flickering or tweeting patterns) are\nneglected in crowdsourced data mining. Therefore, a novel approach that\nleverages implicit human intelligence (implicit HI) for crowdsourced data\nmining and understanding is proposed. Two studies titled CrowdEvent and\nCrowdRoute are presented to showcase its usage, where implicit HIs are\nextracted either from online or offline crowdsourced data. A generic model for\nCrowdMining is further proposed based on a set of existing studies. Experiments\nbased on real-world datasets demonstrate the effectiveness of CrowdMining.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 01:09:17 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Guo", "Bin", ""], ["Chen", "Huihui", ""], ["Liu", "Yan", ""], ["Chen", "Chao", ""], ["Han", "Qi", ""], ["Yu", "Zhiwen", ""]]}, {"id": "1908.02511", "submitter": "Dmitry Nikulin", "authors": "Dmitry Nikulin, Anastasia Ianina, Vladimir Aliev, Sergey Nikolenko", "title": "Free-Lunch Saliency via Attention in Atari Agents", "comments": "2019 ICCV Workshop on Interpreting and Explaining Visual Artificial\n  Intelligence Models. 15 pages, 14 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach to visualize saliency maps for deep neural network\nmodels and apply it to deep reinforcement learning agents trained on Atari\nenvironments. Our method adds an attention module that we call FLS (Free Lunch\nSaliency) to the feature extractor from an established baseline (Mnih et al.,\n2015). This addition results in a trainable model that can produce saliency\nmaps, i.e., visualizations of the importance of different parts of the input\nfor the agent's current decision making. We show experimentally that a network\nwith an FLS module exhibits performance similar to the baseline (i.e., it is\n\"free\", with no performance cost) and can be used as a drop-in replacement for\nreinforcement learning agents. We also design another feature extractor that\nscores slightly lower but provides higher-fidelity visualizations. In addition\nto attained scores, we report saliency metrics evaluated on the Atari-HEAD\ndataset of human gameplay.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 10:10:45 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 17:42:50 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Nikulin", "Dmitry", ""], ["Ianina", "Anastasia", ""], ["Aliev", "Vladimir", ""], ["Nikolenko", "Sergey", ""]]}, {"id": "1908.02551", "submitter": "Renhao Cui", "authors": "Renhao Cui, Gagan Agrawal, Rajiv Ramnath", "title": "Tweets Can Tell: Activity Recognition using Hybrid Long Short-Term\n  Memory Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents techniques to detect the \"offline\" activity a person is\nengaged in when she is tweeting (such as dining, shopping or entertainment), in\norder to create a dynamic profile of the user, for uses such as better\ntargeting of advertisements. To this end, we propose a hybrid LSTM model for\nrich contextual learning, along with studies on the effects of applying and\ncombining multiple LSTM based methods with different contextual features. The\nhybrid model is shown to outperform a set of baselines and state-of-the-art\nmethods. Finally, this paper presents an orthogonal validation with a real-case\napplication. Our model generates an offline activity analysis for the followers\nof several well-known accounts, which is quite representative of the expected\ncharacteristics of these accounts.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 02:29:39 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Cui", "Renhao", ""], ["Agrawal", "Gagan", ""], ["Ramnath", "Rajiv", ""]]}, {"id": "1908.02571", "submitter": "Afshin Sadeghi", "authors": "Afshin Sadeghi and Jens Lehmann", "title": "Linking Physicians to Medical Research Results via Knowledge Graph\n  Embeddings and Twitter", "comments": "AI for Good, Data Science for Social Good, Machine learning for\n  Social Good, Twitter Data, Knowledge Graph Embeddings, Medical Research", "journal-ref": "ECML SOGOOD 2019", "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Informing professionals about the latest research results in their field is a\nparticularly important task in the field of health care, since any development\nin this field directly improves the health status of the patients. Meanwhile,\nsocial media is an infrastructure that allows public instant sharing of\ninformation, thus it has recently become popular in medical applications. In\nthis study, we apply Multi Distance Knowledge Graph Embeddings (MDE) to link\nphysicians and surgeons to the latest medical breakthroughs that are shared as\nthe research results on Twitter. Our study shows that using this method\nphysicians can be informed about the new findings in their field given that\nthey have an account dedicated to their profession.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 10:15:40 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 14:37:36 GMT"}, {"version": "v3", "created": "Fri, 21 Feb 2020 14:25:56 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Sadeghi", "Afshin", ""], ["Lehmann", "Jens", ""]]}, {"id": "1908.02607", "submitter": "Zihan Jiang", "authors": "Zihan Jiang, Wanling Gao, Lei Wang, Xingwang Xiong, Yuchen Zhang, Xu\n  Wen, Chunjie Luo, Hainan Ye, Yunquan Zhang, Shengzhong Feng, Kenli Li, Weijia\n  Xu, Jianfeng Zhan", "title": "HPC AI500: A Benchmark Suite for HPC AI Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, with the trend of applying deep learning (DL) in high\nperformance scientific computing, the unique characteristics of emerging DL\nworkloads in HPC raise great challenges in designing, implementing HPC AI\nsystems. The community needs a new yard stick for evaluating the future HPC\nsystems. In this paper, we propose HPC AI500 --- a benchmark suite for\nevaluating HPC systems that running scientific DL workloads. Covering the most\nrepresentative scientific fields, each workload from HPC AI500 is based on\nreal-world scientific DL applications. Currently, we choose 14 scientific DL\nbenchmarks from perspectives of application scenarios, data sets, and software\nstack. We propose a set of metrics for comprehensively evaluating the HPC AI\nsystems, considering both accuracy, performance as well as power and cost. We\nprovide a scalable reference implementation of HPC AI500. HPC AI500 is a part\nof the open-source AIBench project, the specification and source code are\npublicly available from \\url{http://www.benchcouncil.org/AIBench/index.html}.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 10:18:08 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 03:38:49 GMT"}, {"version": "v3", "created": "Fri, 8 Nov 2019 09:31:40 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Jiang", "Zihan", ""], ["Gao", "Wanling", ""], ["Wang", "Lei", ""], ["Xiong", "Xingwang", ""], ["Zhang", "Yuchen", ""], ["Wen", "Xu", ""], ["Luo", "Chunjie", ""], ["Ye", "Hainan", ""], ["Zhang", "Yunquan", ""], ["Feng", "Shengzhong", ""], ["Li", "Kenli", ""], ["Xu", "Weijia", ""], ["Zhan", "Jianfeng", ""]]}, {"id": "1908.02619", "submitter": "Vaishak Belle", "authors": "Drew Hemment, Ruth Aylett, Vaishak Belle, Dave Murray-Rust, Ewa Luger,\n  Jane Hillston, Michael Rovatsos, Frank Broz", "title": "Experiential AI", "comments": "To appear in AI Matters 5(1): 25-31 (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experiential AI is proposed as a new research agenda in which artists and\nscientists come together to dispel the mystery of algorithms and make their\nmechanisms vividly apparent. It addresses the challenge of finding novel ways\nof opening up the field of artificial intelligence to greater transparency and\ncollaboration between human and machine. The hypothesis is that art can mediate\nbetween computer code and human comprehension to overcome the limitations of\nexplanations in and for AI systems. Artists can make the boundaries of systems\nvisible and offer novel ways to make the reasoning of AI transparent and\ndecipherable. Beyond this, artistic practice can explore new configurations of\nhumans and algorithms, mapping the terrain of inter-agencies between people and\nmachines. This helps to viscerally understand the complex causal chains in\nenvironments with AI components, including questions about what data to collect\nor who to collect it about, how the algorithms are chosen, commissioned and\nconfigured or how humans are conditioned by their participation in algorithmic\nprocesses.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 12:56:17 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Hemment", "Drew", ""], ["Aylett", "Ruth", ""], ["Belle", "Vaishak", ""], ["Murray-Rust", "Dave", ""], ["Luger", "Ewa", ""], ["Hillston", "Jane", ""], ["Rovatsos", "Michael", ""], ["Broz", "Frank", ""]]}, {"id": "1908.02624", "submitter": "Yolanda Gil", "authors": "Yolanda Gil and Bart Selman", "title": "A 20-Year Community Roadmap for Artificial Intelligence Research in the\n  US", "comments": "A Computing Community Consortium (CCC) workshop report, 109 pages", "journal-ref": null, "doi": null, "report-no": "ccc2019report_3", "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Decades of research in artificial intelligence (AI) have produced formidable\ntechnologies that are providing immense benefit to industry, government, and\nsociety. AI systems can now translate across multiple languages, identify\nobjects in images and video, streamline manufacturing processes, and control\ncars. The deployment of AI systems has not only created a trillion-dollar\nindustry that is projected to quadruple in three years, but has also exposed\nthe need to make AI systems fair, explainable, trustworthy, and secure. Future\nAI systems will rightfully be expected to reason effectively about the world in\nwhich they (and people) operate, handling complex tasks and responsibilities\neffectively and ethically, engaging in meaningful communication, and improving\ntheir awareness through experience.\n  Achieving the full potential of AI technologies poses research challenges\nthat require a radical transformation of the AI research enterprise,\nfacilitated by significant and sustained investment. These are the major\nrecommendations of a recent community effort coordinated by the Computing\nCommunity Consortium and the Association for the Advancement of Artificial\nIntelligence to formulate a Roadmap for AI research and development over the\nnext two decades.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 13:24:36 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Gil", "Yolanda", ""], ["Selman", "Bart", ""]]}, {"id": "1908.02673", "submitter": "Jorge Laval", "authors": "Jorge A. Laval and Hao Zhou", "title": "Large-scale traffic signal control using machine learning: some traffic\n  flow considerations", "comments": "15 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper uses supervised learning, random search and deep reinforcement\nlearning (DRL) methods to control large signalized intersection networks. The\ntraffic model is Cellular Automaton rule 184, which has been shown to be a\nparameter-free representation of traffic flow, and is the most efficient\nimplementation of the Kinematic Wave model with triangular fundamental diagram.\nWe are interested in the steady-state performance of the system, both spatially\nand temporally: we consider a homogeneous grid network inscribed on a torus,\nwhich makes the network boundary-free, and drivers choose random routes. As a\nbenchmark we use the longest-queue-first (LQF) greedy algorithm. We find that:\n(i) a policy trained with supervised learning with only two examples\noutperforms LQF, (ii) random search is able to generate near-optimal policies,\n(iii) the prevailing average network occupancy during training is the major\ndeterminant of the effectiveness of DRL policies. When trained under free-flow\nconditions one obtains DRL policies that are optimal for all traffic\nconditions, but this performance deteriorates as the occupancy during training\nincreases. For occupancies > 75% during training, DRL policies perform very\npoorly for all traffic conditions, which means that DRL methods cannot learn\nunder highly congested conditions. We conjecture that DRL's inability to learn\nunder congestion might be explained by a property of urban networks found here,\nwhereby even a very bad policy produces an intersection throughput higher than\ndownstream capacity. This means that the actual throughput tends to be\nindependent of the policy. Our findings imply that it is advisable for current\nDRL methods in the literature to discard any congested data when training, and\nthat doing this will improve their performance under all traffic conditions.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 15:08:33 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Laval", "Jorge A.", ""], ["Zhou", "Hao", ""]]}, {"id": "1908.02784", "submitter": "Kai Chen", "authors": "Kai Chen, Zhongrui Lin, Jian Wan, Lei Xu, Chungen Xu", "title": "Multi-owner Secure Encrypted Search Using Searching Adversarial Networks", "comments": "The 18th International Conference on Cryptology and Network Security.\n  Fixed minor issues with the conference version, such as spelling errors and\n  ambiguities in the content description", "journal-ref": null, "doi": null, "report-no": "1908.02784", "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Searchable symmetric encryption (SSE) for multi-owner model draws much\nattention as it enables data users to perform searches over encrypted cloud\ndata outsourced by data owners. However, implementing secure and precise query,\nefficient search and flexible dynamic system maintenance at the same time in\nSSE remains a challenge. To address this, this paper proposes secure and\nefficient multi-keyword ranked search over encrypted cloud data for multi-owner\nmodel based on searching adversarial networks. We exploit searching adversarial\nnetworks to achieve optimal pseudo-keyword padding, and obtain the optimal game\nequilibrium for query precision and privacy protection strength. Maximum\nlikelihood search balanced tree is generated by probabilistic learning, which\nachieves efficient search and brings the computational complexity close to\n$\\mathcal{O}(\\log N)$. In addition, we enable flexible dynamic system\nmaintenance with balanced index forest that makes full use of distributed\ncomputing. Compared with previous works, our solution maintains query precision\nabove 95% while ensuring adequate privacy protection, and introduces low\noverhead on computation, communication and storage.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 18:17:33 GMT"}, {"version": "v2", "created": "Sun, 11 Aug 2019 13:58:07 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Chen", "Kai", ""], ["Lin", "Zhongrui", ""], ["Wan", "Jian", ""], ["Xu", "Lei", ""], ["Xu", "Chungen", ""]]}, {"id": "1908.02962", "submitter": "Difei Gao", "authors": "Difei Gao, Ruiping Wang, Shiguang Shan, Xilin Chen", "title": "From Two Graphs to N Questions: A VQA Dataset for Compositional\n  Reasoning on Vision and Commonsense", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Question Answering (VQA) is a challenging task for evaluating the\nability of comprehensive understanding of the world. Existing benchmarks\nusually focus on the reasoning abilities either only on the vision or mainly on\nthe knowledge with relatively simple abilities on vision. However, the ability\nof answering a question that requires alternatively inferring on the image\ncontent and the commonsense knowledge is crucial for an advanced VQA system. In\nthis paper, we introduce a VQA dataset that provides more challenging and\ngeneral questions about Compositional Reasoning on vIsion and Commonsense,\nwhich is named as CRIC. To create this dataset, we develop a powerful method to\nautomatically generate compositional questions and rich annotations from both\nthe scene graph of a given image and some external knowledge graph. Moreover,\nthis paper presents a new compositional model that is capable of implementing\nvarious types of reasoning functions on the image content and the knowledge\ngraph. Further, we analyze several baselines, state-of-the-art and our model on\nCRIC dataset. The experimental results show that the proposed task is\nchallenging, where state-of-the-art obtains 52.26% accuracy and our model\nobtains 58.38%.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 08:07:35 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 11:43:42 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Gao", "Difei", ""], ["Wang", "Ruiping", ""], ["Shan", "Shiguang", ""], ["Chen", "Xilin", ""]]}, {"id": "1908.03015", "submitter": "Felix Berkhahn", "authors": "Felix Berkhahn, Richard Keys, Wajih Ouertani, Nikhil Shetty, and\n  Dominik Gei{\\ss}ler", "title": "Augmenting Variational Autoencoders with Sparse Labels: A Unified\n  Framework for Unsupervised, Semi-(un)supervised, and Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present a new flavor of Variational Autoencoder (VAE) that interpolates\nseamlessly between unsupervised, semi-supervised and fully supervised learning\ndomains. We show that unlabeled datapoints not only boost unsupervised tasks,\nbut also the classification performance. Vice versa, every label not only\nimproves classification, but also unsupervised tasks. The proposed architecture\nis simple: A classification layer is connected to the topmost encoder layer,\nand then combined with the resampled latent layer for the decoder. The usual\nevidence lower bound (ELBO) loss is supplemented with a supervised loss target\non this classification layer that is only applied for labeled datapoints. This\nsimplicity allows for extending any existing VAE model to our proposed\nsemi-supervised framework with minimal effort. In the context of\nclassification, we found that this approach even outperforms a direct\nsupervised setup.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 11:07:22 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 13:58:00 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Berkhahn", "Felix", ""], ["Keys", "Richard", ""], ["Ouertani", "Wajih", ""], ["Shetty", "Nikhil", ""], ["Gei\u00dfler", "Dominik", ""]]}, {"id": "1908.03020", "submitter": "Adam White Dr", "authors": "Adam White and Artur d'Avila Garcez", "title": "Measurable Counterfactual Local Explanations for Any Classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel method for explaining the predictions of any classifier.\nIn our approach, local explanations are expected to explain both the outcome of\na prediction and how that prediction would change if 'things had been\ndifferent'. Furthermore, we argue that satisfactory explanations cannot be\ndissociated from a notion and measure of fidelity, as advocated in the early\ndays of neural networks' knowledge extraction. We introduce a definition of\nfidelity to the underlying classifier for local explanation models which is\nbased on distances to a target decision boundary. A system called CLEAR:\nCounterfactual Local Explanations via Regression, is introduced and evaluated.\nCLEAR generates w-counterfactual explanations that state minimum changes\nnecessary to flip a prediction's classification. CLEAR then builds local\nregression models, using the w-counterfactuals to measure and improve the\nfidelity of its regressions. By contrast, the popular LIME method, which also\nuses regression to generate local explanations, neither measures its own\nfidelity nor generates counterfactuals. CLEAR's regressions are found to have\nsignificantly higher fidelity than LIME's, averaging over 45% higher in this\npaper's four case studies.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 11:16:22 GMT"}, {"version": "v2", "created": "Sun, 24 Nov 2019 02:00:56 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["White", "Adam", ""], ["Garcez", "Artur d'Avila", ""]]}, {"id": "1908.03106", "submitter": "Jesse Hoey", "authors": "Jesse Hoey and Neil J. MacKinnon", "title": "\"Conservatives Overfit, Liberals Underfit\": The Social-Psychological\n  Control of Affect and Uncertainty", "comments": "This is an extended version of the paper presented at SE-THEMOS\n  workshop at ACII 2019 in Cambridge England. Version 2 and 3 of this article\n  added sections on reinforcement learning(2.6 and 5.6), and a section on\n  neuroscience and the relation between cognition and affect (2.4)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presence of artificial agents in human social networks is growing. From\nchatbots to robots, human experience in the developed world is moving towards a\nsocio-technical system in which agents can be technological or biological, with\nincreasingly blurred distinctions between. Given that emotion is a key element\nof human interaction, enabling artificial agents with the ability to reason\nabout affect is a key stepping stone towards a future in which technological\nagents and humans can work together. This paper presents work on building\nintelligent computational agents that integrate both emotion and cognition.\nThese agents are grounded in the well-established social-psychological Bayesian\nAffect Control Theory (BayesAct). The core idea of BayesAct is that humans are\nmotivated in their social interactions by affective alignment: they strive for\ntheir social experiences to be coherent at a deep, emotional level with their\nsense of identity and general world views as constructed through culturally\nshared symbols. This affective alignment creates cohesive bonds between group\nmembers, and is instrumental for collaborations to solidify as relational group\ncommitments. BayesAct agents are motivated in their social interactions by a\ncombination of affective alignment and decision theoretic reasoning, trading\nthe two off as a function of the uncertainty or unpredictability of the\nsituation. This paper provides a high-level view of dual process theories and\nadvances BayesAct as a plausible, computationally tractable model based in\nsocial-psychological theory. We introduce a revised BayesAct model that more\ndeeply integrates social-psychological theorising, and we demonstrate a\ncomponent of the model as being sufficient to account for cognitive biases\nabout fairness, dissonance and conformity. We show how the model can unify\ndifferent exploration strategies in reinforcement learning.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 15:04:52 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 01:19:23 GMT"}, {"version": "v3", "created": "Sun, 1 Sep 2019 11:21:51 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Hoey", "Jesse", ""], ["MacKinnon", "Neil J.", ""]]}, {"id": "1908.03143", "submitter": "Zulkarnaen Hatala", "authors": "Zulkarnaen Hatala, Victor Puturuhu", "title": "Viterbi Extraction tutorial with Hidden Markov Toolkit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An algorithm used to extract HMM parameters is revisited. Most parts of the\nextraction process are taken from implemented Hidden Markov Toolkit (HTK)\nprogram under name HInit. The algorithm itself shows a few variations compared\nto another domain of implementations. The HMM model is introduced briefly based\non the theory of Discrete Time Markov Chain. We schematically outline the\nViterbi method implemented in HTK. Iterative definition of the method which is\nready to be implemented in computer programs is reviewed. We also illustrate\nthe method calculation precisely using manual calculation and extensive\ngraphical illustration. The distribution of observation probability used is\nsimply independent Gaussians r.v.s. The purpose of the content is not to\njustify the performance or accuracy of the method applied in a specific area.\nThis writing merely to describe how the algorithm is performed. The whole\ncontent should enlighten the audience the insight of the Viterbi Extraction\nmethod used by HTK.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 03:38:22 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Hatala", "Zulkarnaen", ""], ["Puturuhu", "Victor", ""]]}, {"id": "1908.03171", "submitter": "Patrick Lambrix", "authors": "Patrick Lambrix", "title": "Completing and Debugging Ontologies: state of the art and challenges", "comments": "56 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As semantically-enabled applications require high-quality ontologies,\ndeveloping and maintaining ontologies that are as correct and complete as\npossible is an important although difficult task in ontology engineering. A key\nstep is ontology debugging and completion. In general, there are two steps:\ndetecting defects and repairing defects. In this paper we discuss the state of\nthe art regarding the repairing step. We do this by formalizing the repairing\nstep as an abduction problem and situating the state of the art with respect to\nthis framework. We show that there are still many open research problems and\nshow opportunities for further work and advancing the field.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 17:02:37 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 19:36:24 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Lambrix", "Patrick", ""]]}, {"id": "1908.03250", "submitter": "Fabrizio Ventola", "authors": "Fabrizio Ventola, Karl Stelzner, Alejandro Molina and Kristian\n  Kersting", "title": "Random Sum-Product Forests with Residual Links", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tractable yet expressive density estimators are a key building block of\nprobabilistic machine learning. While sum-product networks (SPNs) offer\nattractive inference capabilities, obtaining structures large enough to fit\ncomplex, high-dimensional data has proven challenging. In this paper, we\npresent random sum-product forests (RSPFs), an ensemble approach for mixing\nmultiple randomly generated SPNs. We also introduce residual links, which\nreference specialized substructures of other component SPNs in order to\nleverage the context-specific knowledge encoded within them. Our empirical\nevidence demonstrates that RSPFs provide better performance than their\nindividual components. Adding residual links improves the models further,\nallowing the resulting ResSPNs to be competitive with commonly used structure\nlearning methods.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 19:55:03 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Ventola", "Fabrizio", ""], ["Stelzner", "Karl", ""], ["Molina", "Alejandro", ""], ["Kersting", "Kristian", ""]]}, {"id": "1908.03343", "submitter": "Yuka Ariki", "authors": "Yuka Ariki and Takuya Narihira", "title": "Fully Convolutional Search Heuristic Learning for Rapid Path Planners", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Path-planning algorithms are an important part of a wide variety of robotic\napplications, such as mobile robot navigation and robot arm manipulation.\nHowever, in large search spaces in which local traps may exist, it remains\nchallenging to reliably find a path while satisfying real-time constraints.\nEfforts to speed up the path search have led to the development of many\npractical path-planning algorithms. These algorithms often define a search\nheuristic to guide the search towards the goal. The heuristics should be\ncarefully designed for each specific problem to ensure reliability in the\nvarious situations encountered in the problem. However, it is often difficult\nfor humans to craft such robust heuristics, and the search performance often\ndegrades under conditions that violate the heuristic assumption. Rather than\nmanually designing the heuristics, in this work, we propose a learning approach\nto acquire these search heuristics. Our method represents the environment\ncontaining the obstacles as an image, and this image is fed into fully\nconvolutional neural networks to produce a search heuristic image where every\npixel represents a heuristic value (cost-to-go value to a goal) in the form of\na vertex of a search graph. Training the heuristic is performed using\npreviously collected planning results. Our preliminary experiments (2D grid\nworld navigation experiments) demonstrate significant reduction in the search\ncosts relative to a hand-designed heuristic.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 07:27:28 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Ariki", "Yuka", ""], ["Narihira", "Takuya", ""]]}, {"id": "1908.03566", "submitter": "Shuang Song", "authors": "\\'Ulfar Erlingsson and Ilya Mironov and Ananth Raghunathan and Shuang\n  Song", "title": "That which we call private", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The guarantees of security and privacy defenses are often strengthened by\nrelaxing the assumptions made about attackers or the context in which defenses\nare deployed. Such relaxations can be a highly worthwhile topic of\nexploration---even though they typically entail assuming a weaker, less\npowerful adversary---because there may indeed be great variability in both\nattackers' powers and their context.\n  However, no weakening or contextual discounting of attackers' power is\nassumed for what some have called \"relaxed definitions\" in the analysis of\ndifferential-privacy guarantees. Instead, the definitions so named are the\nbasis of refinements and more advanced analyses of the worst-case implications\nof attackers---without any change assumed in attackers' powers.\n  Because they more precisely bound the worst-case privacy loss, these improved\nanalyses can greatly strengthen the differential-privacy upper-bound\nguarantees---sometimes lowering the differential-privacy epsilon by\norders-of-magnitude. As such, to the casual eye, these analyses may appear to\nimply a reduced privacy loss. This is a false perception: the privacy loss of\nany concrete mechanism cannot change with the choice of a worst-case-loss\nupper-bound analysis technique. Practitioners must be careful not to equate\nreal-world privacy with differential-privacy epsilon values, at least not\nwithout full consideration of the context.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 22:09:52 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 18:39:55 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Erlingsson", "\u00dalfar", ""], ["Mironov", "Ilya", ""], ["Raghunathan", "Ananth", ""], ["Song", "Shuang", ""]]}, {"id": "1908.03568", "submitter": "Ian Osband", "authors": "Ian Osband, Yotam Doron, Matteo Hessel, John Aslanides, Eren Sezener,\n  Andre Saraiva, Katrina McKinney, Tor Lattimore, Csaba Szepesvari, Satinder\n  Singh, Benjamin Van Roy, Richard Sutton, David Silver, Hado Van Hasselt", "title": "Behaviour Suite for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the Behaviour Suite for Reinforcement Learning, or\nbsuite for short. bsuite is a collection of carefully-designed experiments that\ninvestigate core capabilities of reinforcement learning (RL) agents with two\nobjectives. First, to collect clear, informative and scalable problems that\ncapture key issues in the design of general and efficient learning algorithms.\nSecond, to study agent behaviour through their performance on these shared\nbenchmarks. To complement this effort, we open source\ngithub.com/deepmind/bsuite, which automates evaluation and analysis of any\nagent on bsuite. This library facilitates reproducible and accessible research\non the core issues in RL, and ultimately the design of superior learning\nalgorithms. Our code is Python, and easy to use within existing projects. We\ninclude examples with OpenAI Baselines, Dopamine as well as new reference\nimplementations. Going forward, we hope to incorporate more excellent\nexperiments from the research community, and commit to a periodic review of\nbsuite from a committee of prominent researchers.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 08:34:08 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 12:48:44 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 15:18:17 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Osband", "Ian", ""], ["Doron", "Yotam", ""], ["Hessel", "Matteo", ""], ["Aslanides", "John", ""], ["Sezener", "Eren", ""], ["Saraiva", "Andre", ""], ["McKinney", "Katrina", ""], ["Lattimore", "Tor", ""], ["Szepesvari", "Csaba", ""], ["Singh", "Satinder", ""], ["Van Roy", "Benjamin", ""], ["Sutton", "Richard", ""], ["Silver", "David", ""], ["Van Hasselt", "Hado", ""]]}, {"id": "1908.03608", "submitter": "Jorge Calvo-Zaragoza", "authors": "Jorge Calvo-Zaragoza, Jan Haji\\v{c} Jr., Alexander Pacha", "title": "Understanding Optical Music Recognition", "comments": null, "journal-ref": "ACM Comput. Surv. 53, 4 (2020) Article 77", "doi": "10.1145/3397499", "report-no": null, "categories": "cs.CV cs.AI cs.IR cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For over 50 years, researchers have been trying to teach computers to read\nmusic notation, referred to as Optical Music Recognition (OMR). However, this\nfield is still difficult to access for new researchers, especially those\nwithout a significant musical background: few introductory materials are\navailable, and furthermore the field has struggled with defining itself and\nbuilding a shared terminology. In this tutorial, we address these shortcomings\nby (1) providing a robust definition of OMR and its relationship to related\nfields, (2) analyzing how OMR inverts the music encoding process to recover the\nmusical notation and the musical semantics from documents, (3) proposing a\ntaxonomy of OMR, with most notably a novel taxonomy of applications.\nAdditionally, we discuss how deep learning affects modern OMR research, as\nopposed to the traditional pipeline. Based on this work, the reader should be\nable to attain a basic understanding of OMR: its objectives, its inherent\nstructure, its relationship to other fields, the state of the art, and the\nresearch opportunities it affords.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 08:37:16 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 09:38:29 GMT"}, {"version": "v3", "created": "Wed, 29 Jul 2020 08:59:52 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Calvo-Zaragoza", "Jorge", ""], ["Haji\u010d", "Jan", "Jr."], ["Pacha", "Alexander", ""]]}, {"id": "1908.03627", "submitter": "Jon\\'a\\v{s} Kulh\\'anek", "authors": "Jon\\'a\\v{s} Kulh\\'anek and Erik Derner and Tim de Bruin and Robert\n  Babu\\v{s}ka", "title": "Vision-based Navigation Using Deep Reinforcement Learning", "comments": "ECMR 2019: European Conference on Mobile Robots", "journal-ref": "2019 European Conference on Mobile Robots (ECMR), 2019, p.1-8", "doi": "10.1109/ECMR.2019.8870964", "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) has been successfully applied to a variety\nof game-like environments. However, the application of deep RL to visual\nnavigation with realistic environments is a challenging task. We propose a\nnovel learning architecture capable of navigating an agent, e.g. a mobile\nrobot, to a target given by an image. To achieve this, we have extended the\nbatched A2C algorithm with auxiliary tasks designed to improve visual\nnavigation performance. We propose three additional auxiliary tasks: predicting\nthe segmentation of the observation image and of the target image and\npredicting the depth-map. These tasks enable the use of supervised learning to\npre-train a large part of the network and to reduce the number of training\nsteps substantially. The training performance has been further improved by\nincreasing the environment complexity gradually over time. An efficient neural\nnetwork structure is proposed, which is capable of learning for multiple\ntargets in multiple environments. Our method navigates in continuous state\nspaces and on the AI2-THOR environment simulator outperforms state-of-the-art\ngoal-oriented visual navigation methods from the literature.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 13:22:22 GMT"}, {"version": "v2", "created": "Sat, 9 Nov 2019 12:49:43 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Kulh\u00e1nek", "Jon\u00e1\u0161", ""], ["Derner", "Erik", ""], ["de Bruin", "Tim", ""], ["Babu\u0161ka", "Robert", ""]]}, {"id": "1908.03628", "submitter": "Yash Mehta", "authors": "Yash Mehta, Navonil Majumder, Alexander Gelbukh, Erik Cambria", "title": "Recent Trends in Deep Learning Based Personality Detection", "comments": null, "journal-ref": "Artif Intell Rev 53 (2020) 2313-2339", "doi": "10.1007/s10462-019-09770-z", "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the automatic prediction of personality traits has received a lot\nof attention. Specifically, personality trait prediction from multimodal data\nhas emerged as a hot topic within the field of affective computing. In this\npaper, we review significant machine learning models which have been employed\nfor personality detection, with an emphasis on deep learning-based methods.\nThis review paper provides an overview of the most popular approaches to\nautomated personality detection, various computational datasets, its industrial\napplications, and state-of-the-art machine learning models for personality\ndetection with specific focus on multimodal approaches. Personality detection\nis a very broad and diverse topic: this survey only focuses on computational\napproaches and leaves out psychological studies on personality detection.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 19:16:50 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 19:46:57 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Mehta", "Yash", ""], ["Majumder", "Navonil", ""], ["Gelbukh", "Alexander", ""], ["Cambria", "Erik", ""]]}, {"id": "1908.03629", "submitter": "Michael Cochez", "authors": "Andrei Ionita, Andr\\'e Pomp, Michael Cochez, Tobias Meisen and Stefan\n  Decker", "title": "Transferring knowledge from monitored to unmonitored areas for\n  forecasting parking spaces", "comments": "Preprint of an article to be published in Int J. on Artificial\n  Intelligence Tools (IJAIT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart cities around the world have begun monitoring parking areas in order to\nestimate available parking spots and help drivers looking for parking. The\ncurrent results are promising, indeed. However, existing approaches are limited\nby the high cost of sensors that need to be installed throughout the city in\norder to achieve an accurate estimation. This work investigates the extension\nof estimating parking information from areas equipped with sensors to areas\nwhere they are missing. To this end, the similarity between city neighborhoods\nis determined based on background data, i.e., from geographic information\nsystems. Using the derived similarity values, we analyze the adaptation of\noccupancy rates from monitored- to unmonitored parking areas.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 18:43:24 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Ionita", "Andrei", ""], ["Pomp", "Andr\u00e9", ""], ["Cochez", "Michael", ""], ["Meisen", "Tobias", ""], ["Decker", "Stefan", ""]]}, {"id": "1908.03645", "submitter": "Arindam Mitra", "authors": "Arindam Mitra and Chitta Baral and Aurgho Bhattacharjee and Ishan\n  Shrivastava", "title": "A Generate-Validate Approach to Answering Questions about Qualitative\n  Relationships", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Qualitative relationships describe how increasing or decreasing one property\n(e.g. altitude) affects another (e.g. temperature). They are an important\naspect of natural language question answering and are crucial for building\nchatbots or voice agents where one may enquire about qualitative relationships.\nRecently a dataset about question answering involving qualitative relationships\nhas been proposed, and a few approaches to answer such questions have been\nexplored, in the heart of which lies a semantic parser that converts the\nnatural language input to a suitable logical form. A problem with existing\nsemantic parsers is that they try to directly convert the input sentences to a\nlogical form. Since the output language varies with each application, it forces\nthe semantic parser to learn almost everything from scratch. In this paper, we\nshow that instead of using a semantic parser to produce the logical form, if we\napply the generate-validate framework i.e. generate a natural language\ndescription of the logical form and validate if the natural language\ndescription is followed from the input text, we get a better scope for transfer\nlearning and our method outperforms the state-of-the-art by a large margin of\n7.93%.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 22:06:06 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Mitra", "Arindam", ""], ["Baral", "Chitta", ""], ["Bhattacharjee", "Aurgho", ""], ["Shrivastava", "Ishan", ""]]}, {"id": "1908.03719", "submitter": "Esra Erdem", "authors": "Esra Erdem, Andrea Formisano, German Vidal, and Fangkai Yang", "title": "Introduction to the 35th International Conference on Logic Programming\n  Special Issue", "comments": "The 35th International Conference on Logic Programming (ICLP 2019),\n  Las Cruces, New Mexico, USA, September 20--25, 2019. 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are proud to introduce this special issue of Theory and Practice of Logic\nProgramming (TPLP), dedicated to the regular papers accepted for the 35th\nInternational Conference on Logic Programming (ICLP). The ICLP meetings started\nin Marseille in 1982 and since then constitute the main venue for presenting\nand discussing work in the area of logic programming. Under consideration for\nacceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 09:25:01 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Erdem", "Esra", ""], ["Formisano", "Andrea", ""], ["Vidal", "German", ""], ["Yang", "Fangkai", ""]]}, {"id": "1908.03731", "submitter": "Miroslav Bogdanovic", "authors": "Miroslav Bogdanovic, Ludovic Righetti", "title": "Learning to Explore in Motion and Interaction Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model free reinforcement learning suffers from the high sampling complexity\ninherent to robotic manipulation or locomotion tasks. Most successful\napproaches typically use random sampling strategies which leads to slow policy\nconvergence. In this paper we present a novel approach for efficient\nexploration that leverages previously learned tasks. We exploit the fact that\nthe same system is used across many tasks and build a generative model for\nexploration based on data from previously solved tasks to improve learning new\ntasks. The approach also enables continuous learning of improved exploration\nstrategies as novel tasks are learned. Extensive simulations on a robot\nmanipulator performing a variety of motion and contact interaction tasks\ndemonstrate the capabilities of the approach. In particular, our experiments\nsuggest that the exploration strategy can more than double learning speed,\nespecially when rewards are sparse. Moreover, the algorithm is robust to task\nvariations and parameter tuning, making it beneficial for complex robotic\nproblems.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 11:04:42 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Bogdanovic", "Miroslav", ""], ["Righetti", "Ludovic", ""]]}, {"id": "1908.03840", "submitter": "Dilini Rajapaksha", "authors": "Dilini Rajapaksha, Christoph Bergmeir, Wray Buntine", "title": "LoRMIkA: Local rule-based model interpretability with k-optimal\n  associations", "comments": "26 pages, 3 figures", "journal-ref": "journal={Information Sciences}, volume={540}, pages={221--241},\n  year={2020}, publisher={Elsevier}", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  As we rely more and more on machine learning models for real-life\ndecision-making, being able to understand and trust the predictions becomes\never more important. Local explainer models have recently been introduced to\nexplain the predictions of complex machine learning models at the instance\nlevel. In this paper, we propose Local Rule-based Model Interpretability with\nk-optimal Associations (LoRMIkA), a novel model-agnostic approach that obtains\nk-optimal association rules from a neighbourhood of the instance to be\nexplained. Compared with other rule-based approaches in the literature, we\nargue that the most predictive rules are not necessarily the rules that provide\nthe best explanations. Consequently, the LoRMIkA framework provides a flexible\nway to obtain predictive and interesting rules. It uses an efficient search\nalgorithm guaranteed to find the k-optimal rules with respect to objectives\nsuch as confidence, lift, leverage, coverage, and support. It also provides\nmultiple rules which explain the decision and counterfactual rules, which give\nindications for potential changes to obtain different outputs for given\ninstances. We compare our approach to other state-of-the-art approaches in\nlocal model interpretability on three different datasets and achieve\ncompetitive results in terms of local accuracy and interpretability.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 02:42:27 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 02:44:10 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Rajapaksha", "Dilini", ""], ["Bergmeir", "Christoph", ""], ["Buntine", "Wray", ""]]}, {"id": "1908.03963", "submitter": "Afshin Oroojlooy", "authors": "Afshin OroojlooyJadid and Davood Hajinezhad", "title": "A Review of Cooperative Multi-Agent Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning has made significant progress in multi-agent\nsystems in recent years. In this review article, we have focused on presenting\nrecent approaches on Multi-Agent Reinforcement Learning (MARL) algorithms. In\nparticular, we have focused on five common approaches on modeling and solving\ncooperative multi-agent reinforcement learning problems: (I) independent\nlearners, (II) fully observable critic, (III) value function factorization,\n(IV) consensus, and (IV) learn to communicate. First, we elaborate on each of\nthese methods, possible challenges, and how these challenges were mitigated in\nthe relevant papers. If applicable, we further make a connection among\ndifferent papers in each category. Next, we cover some new emerging research\nareas in MARL along with the relevant recent papers. Due to the recent success\nof MARL in real-world applications, we assign a section to provide a review of\nthese applications and corresponding articles.\n  Also, a list of available environments for MARL research is provided in this\nsurvey. Finally, the paper is concluded with proposals on the possible research\ndirections.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 21:40:11 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 02:59:54 GMT"}, {"version": "v3", "created": "Sun, 14 Jun 2020 03:06:48 GMT"}, {"version": "v4", "created": "Fri, 30 Apr 2021 04:14:28 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["OroojlooyJadid", "Afshin", ""], ["Hajinezhad", "Davood", ""]]}, {"id": "1908.04005", "submitter": "Sisi Li", "authors": "Sisi Li, Nan Li, Anouck Girard, and Ilya Kolmanovsky", "title": "Decision making in dynamic and interactive environments based on\n  cognitive hierarchy theory, Bayesian inference, and predictive control", "comments": "2019 IEEE Conference on Decision and Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe an integrated framework for autonomous decision\nmaking in a dynamic and interactive environment. We model the interactions\nbetween the ego agent and its operating environment as a two-player dynamic\ngame, and integrate cognitive behavioral models, Bayesian inference, and\nreceding-horizon optimal control to define a dynamically-evolving decision\nstrategy for the ego agent. Simulation examples representing autonomous vehicle\ncontrol in three traffic scenarios where the autonomous ego vehicle interacts\nwith a human-driven vehicle are reported.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 05:07:12 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 22:47:12 GMT"}, {"version": "v3", "created": "Wed, 18 Sep 2019 06:04:36 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Li", "Sisi", ""], ["Li", "Nan", ""], ["Girard", "Anouck", ""], ["Kolmanovsky", "Ilya", ""]]}, {"id": "1908.04264", "submitter": "Emanuela Merelli", "authors": "Emanuela Merelli, Anita Wasilewska", "title": "Topological Interpretation of Interactive Computation", "comments": "18 figures, 19 pages. Scott Smolka Festschrift", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is a great pleasure to write this tribute in honor of Scott A. Smolka on\nhis 65th birthday. We revisit Goldin, Smolka hypothesis that persistent Turing\nmachine (PTM) can capture the intuitive notion of sequential interaction\ncomputation. We propose a topological setting to model the abstract concept of\nenvironment. We use it to define a notion of a topological Turing machine (TTM)\nas a universal model for interactive computation and possible model for\nconcurrent computation.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 19:29:36 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Merelli", "Emanuela", ""], ["Wasilewska", "Anita", ""]]}, {"id": "1908.04265", "submitter": "Namolaru Mircea", "authors": "Mircea Namolaru and Thierry Goubier", "title": "Recursion, Probability, Convolution and Classification for Computations", "comments": "17 pages, revised version of a NIPS 2019 submission (with the same\n  title), combined with a revised (rejected) PLDI 2019 submission (with the\n  title \"Rubik's cube and Bayesian Networks\")", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main motivation of this work was practical, to offer computationally and\ntheoretical scalable ways to structuring large classes of computation. It\nstarted from attempts to optimize R code for machine learning/artificial\nintelligence algorithms for huge data sets, that due to their size, should be\nhandled into an incremental (online) fashion.\n  Our target are large classes of relational (attribute based), mathematical\n(index based) or graph computations. We wanted to use powerful computation\nrepresentations that emerged in AI (artificial intelligence)/ML (machine\nlearning) as BN (Bayesian networks) and CNN (convolution neural networks). For\nthe classes of computation addressed by us, and for our HPC (high performance\ncomputing) needs, the current solutions for translating computations into such\nrepresentation need to be extended.\n  Our results show that the classes of computation targeted by us, could be\ntree-structured, and a probability distribution (defining a DBN, i.e. Dynamic\nBayesian Network) associated with it. More ever, this DBN may be viewed as a\nrecursive CNN (Convolution Neural Network). Within this tree-like structure,\nclassification in classes with size bounded (by a parameterizable may be\nperformed.\n  These results are at the core of very powerful, yet highly practically\nalgorithms for restructuring and parallelizing the computations. The\nmathematical background required for an in depth presentation and exposing the\nfull generality of our approach) is the subject of a subsequent paper. In this\npaper, we work in an limited (but important) framework that could be understood\nwith rudiments of linear algebra and graph theory. The focus is in\napplicability, most of this paper discuss the usefulness of our approach for\nsolving hard compilation problems related to automatic parallelism.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 11:07:55 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Namolaru", "Mircea", ""], ["Goubier", "Thierry", ""]]}, {"id": "1908.04344", "submitter": "Sharmin Pathan", "authors": "Sharmin Pathan", "title": "Interior Object Detection and Color Harmonization", "comments": null, "journal-ref": "Frontiers in Artificial Intelligence and Machine Learning 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Confused about renovating your space? Choosing the perfect color for your\nwalls is always a challenging task. One does rounds of color consultation and\nseveral patch tests. This paper proposes an AI tool to pitch paint based on\nattributes of your room and other furniture, and visualize it on your walls. It\nmakes the color selection process easy. It takes in images of a room, detects\nfurniture objects using YOLO object detection. Once these objects have been\ndetected, the tool picks out color of the object. Later this object specific\ninformation gets appended to the room attributes (room_type, room_size,\npreferred_tone, etc) and a deep neural net is trained to make predictions for\ncolor/texture/wallpaper for the walls. Finally, these predictions are\nvisualized on the walls from the images provided. The idea is to take the\nknowledge of a color consultant and pitch colors that suit the walls and\nprovide a good contrast with the furniture and harmonize with different colors\nin the room. Transfer learning for YOLO object detection from the COCO dataset\nwas used as a starting point and the weights were later fine-tuned by training\non additional images. The model was trained on 1000 records listing the room\nand furniture attributes, to predict colors. Given the room image, this method\nfinds the best color scheme for the walls. These predictions are then\nvisualized on the walls in the image using image segmentation. The results are\nvisually appealing and automatically enhance the color look-and-feel.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 21:02:12 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 13:45:07 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Pathan", "Sharmin", ""]]}, {"id": "1908.04348", "submitter": "Francesco Ventura", "authors": "Francesco Ventura, Tania Cerquitelli", "title": "What's in the box? Explaining the black-box model through an evaluation\n  of its interpretable features", "comments": "5 pages, 5 images", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Algorithms are powerful and necessary tools behind a large part of the\ninformation we use every day. However, they may introduce new sources of bias,\ndiscrimination and other unfair practices that affect people who are unaware of\nit. Greater algorithm transparency is indispensable to provide more credible\nand reliable services. Moreover, requiring developers to design transparent\nalgorithm-driven applications allows them to keep the model accessible and\nhuman understandable, increasing the trust of end users. In this paper we\npresent EBAnO, a new engine able to produce prediction-local explanations for a\nblack-box model exploiting interpretable feature perturbations. EBAnO exploits\nthe hypercolumns representation together with the cluster analysis to identify\na set of interpretable features of images. Furthermore two indices have been\nproposed to measure the influence of input features on the final prediction\nmade by a CNN model. EBAnO has been preliminarily tested on a set of\nheterogeneous images. The results highlight the effectiveness of EBAnO in\nexplaining the CNN classification through the evaluation of interpretable\nfeatures influence.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 15:05:06 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Ventura", "Francesco", ""], ["Cerquitelli", "Tania", ""]]}, {"id": "1908.04381", "submitter": "Jeffrey M. Dudek", "authors": "Jeffrey M. Dudek, Leonardo Due\\~nas-Osorio, Moshe Y. Vardi", "title": "Efficient Contraction of Large Tensor Networks for Weighted Model\n  Counting through Graph Decompositions", "comments": "Submitted to AIJ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constrained counting is a fundamental problem in artificial intelligence. A\npromising new algebraic approach to constrained counting makes use of tensor\nnetworks, following a reduction from constrained counting to the problem of\ntensor-network contraction. Contracting a tensor network efficiently requires\ndetermining an efficient order to contract the tensors inside the network,\nwhich is itself a difficult problem.\n  In this work, we apply graph decompositions to find contraction orders for\ntensor networks. We prove that finding an efficient contraction order for a\ntensor network is equivalent to the well-known problem of finding an optimal\ncarving decomposition. Thus memory-optimal contraction orders for planar tensor\nnetworks can be found in cubic time. We show that tree decompositions can be\nused both to find carving decompositions and to factor tensor networks with\nhigh-rank, structured tensors.\n  We implement these algorithms on top of state-of-the-art solvers for tree\ndecompositions and show empirically that the resulting weighted model counter\nis quite effective and useful as part of a portfolio of counters.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 21:01:49 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 23:39:11 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Dudek", "Jeffrey M.", ""], ["Due\u00f1as-Osorio", "Leonardo", ""], ["Vardi", "Moshe Y.", ""]]}, {"id": "1908.04385", "submitter": "Zheng Liu", "authors": "Zheng Liu, Zidong Jiang, Wei Feng, Hui Feng", "title": "OD-GCN: Object Detection Boosted by Knowledge GCN", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical CNN based object detection methods only extract the objects' image\nfeatures, but do not consider the high-level relationship among objects in\ncontext. In this article, the graph convolutional networks (GCN) is integrated\ninto the object detection framework to exploit the benefit of category\nrelationship among objects, which is able to provide extra confidence for any\npre-trained object detection model in our framework. In experiments, we test\nseveral popular base detection models on COCO dataset. The results show\npromising improvement on mAP by 1-5pp. In addition, visualized analysis reveals\nthe benchmark improvement is quite reasonable in human's opinion.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 02:23:29 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 03:17:40 GMT"}, {"version": "v3", "created": "Mon, 11 Nov 2019 03:27:23 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Liu", "Zheng", ""], ["Jiang", "Zidong", ""], ["Feng", "Wei", ""], ["Feng", "Hui", ""]]}, {"id": "1908.04392", "submitter": "Amir Mosavi Prof", "authors": "Husein Perez, Joseph H. M. Tah, Amir Mosavi", "title": "Deep Learning for Detecting Building Defects Using Convolutional Neural\n  Networks", "comments": "29 pages, 11 figures", "journal-ref": null, "doi": "10.20944/preprints201908.0068.v1", "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Clients are increasingly looking for fast and effective means to quickly and\nfrequently survey and communicate the condition of their buildings so that\nessential repairs and maintenance work can be done in a proactive and timely\nmanner before it becomes too dangerous and expensive. Traditional methods for\nthis type of work commonly comprise of engaging building surveyors to undertake\na condition assessment which involves a lengthy site inspection to produce a\nsystematic recording of the physical condition of the building elements,\nincluding cost estimates of immediate and projected long-term costs of renewal,\nrepair and maintenance of the building. Current asset condition assessment\nprocedures are extensively time consuming, laborious, and expensive and pose\nhealth and safety threats to surveyors, particularly at height and roof levels\nwhich are difficult to access. This paper aims at evaluating the application of\nconvolutional neural networks (CNN) towards an automated detection and\nlocalisation of key building defects, e.g., mould, deterioration, and stain,\nfrom images. The proposed model is based on pre-trained CNN classifier of\nVGG-16 (later compaired with ResNet-50, and Inception models), with class\nactivation mapping (CAM) for object localisation. The challenges and\nlimitations of the model in real-life applications have been identified. The\nproposed model has proven to be robust and able to accurately detect and\nlocalise building defects. The approach is being developed with the potential\nto scale-up and further advance to support automated detection of defects and\ndeterioration of buildings in real-time using mobile devices and drones.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 16:21:10 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Perez", "Husein", ""], ["Tah", "Joseph H. M.", ""], ["Mosavi", "Amir", ""]]}, {"id": "1908.04436", "submitter": "Philip Bontrager", "authors": "Philip Bontrager, Ahmed Khalifa, Damien Anderson, Matthew Stephenson,\n  Christoph Salge, Julian Togelius", "title": "Superstition in the Network: Deep Reinforcement Learning Plays Deceptive\n  Games", "comments": "7 pages, 4 figures, Accepted at the 15th AAAI Conference on\n  Artificial Intelligence and Interactive Digital Entertainment (AIIDE 19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has learned to play many games well, but failed\non others. To better characterize the modes and reasons of failure of deep\nreinforcement learners, we test the widely used Asynchronous Actor-Critic (A2C)\nalgorithm on four deceptive games, which are specially designed to provide\nchallenges to game-playing agents. These games are implemented in the General\nVideo Game AI framework, which allows us to compare the behavior of\nreinforcement learning-based agents with planning agents based on tree search.\nWe find that several of these games reliably deceive deep reinforcement\nlearners, and that the resulting behavior highlights the shortcomings of the\nlearning algorithm. The particular ways in which agents fail differ from how\nplanning-based agents fail, further illuminating the character of these\nalgorithms. We propose an initial typology of deceptions which could help us\nbetter understand pitfalls and failure modes of (deep) reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 23:27:26 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Bontrager", "Philip", ""], ["Khalifa", "Ahmed", ""], ["Anderson", "Damien", ""], ["Stephenson", "Matthew", ""], ["Salge", "Christoph", ""], ["Togelius", "Julian", ""]]}, {"id": "1908.04473", "submitter": "Mohammad Shojafar", "authors": "Rahim Taheri, Reza Javidan, Mohammad Shojafar, Zahra Pooranian, Ali\n  Miri, Mauro Conti", "title": "On Defending Against Label Flipping Attacks on Malware Detection Systems", "comments": "21 pages, 6 figures, 4 tables, NCAA Springer Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Label manipulation attacks are a subclass of data poisoning attacks in\nadversarial machine learning used against different applications, such as\nmalware detection. These types of attacks represent a serious threat to\ndetection systems in environments having high noise rate or uncertainty, such\nas complex networks and Internet of Thing (IoT). Recent work in the literature\nhas suggested using the $K$-Nearest Neighboring (KNN) algorithm to defend\nagainst such attacks. However, such an approach can suffer from low to wrong\ndetection accuracy. In this paper, we design an architecture to tackle the\nAndroid malware detection problem in IoT systems. We develop an attack\nmechanism based on Silhouette clustering method, modified for mobile Android\nplatforms. We proposed two Convolutional Neural Network (CNN)-type deep\nlearning algorithms against this \\emph{Silhouette Clustering-based Label\nFlipping Attack (SCLFA)}. We show the effectiveness of these two defense\nalgorithms - \\emph{Label-based Semi-supervised Defense (LSD)} and\n\\emph{clustering-based Semi-supervised Defense (CSD)} - in correcting labels\nbeing attacked. We evaluate the performance of the proposed algorithms by\nvarying the various machine learning parameters on three Android datasets:\nDrebin, Contagio, and Genome and three types of features: API, intent, and\npermission. Our evaluation shows that using random forest feature selection and\nvarying ratios of features can result in an improvement of up to 19\\% accuracy\nwhen compared with the state-of-the-art method in the literature.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 03:31:33 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 13:19:50 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 08:35:34 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Taheri", "Rahim", ""], ["Javidan", "Reza", ""], ["Shojafar", "Mohammad", ""], ["Pooranian", "Zahra", ""], ["Miri", "Ali", ""], ["Conti", "Mauro", ""]]}, {"id": "1908.04484", "submitter": "C. H. Huck Yang", "authors": "Sheng-Chun Kao, Chao-Han Huck Yang, Pin-Yu Chen, Xiaoli Ma, Tushar\n  Krishna", "title": "Reinforcement Learning based Interconnection Routing for Adaptive\n  Traffic Optimization", "comments": null, "journal-ref": null, "doi": "10.1145/3313231.335236", "report-no": null, "categories": "cs.NI cs.AI cs.AR cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying Machine Learning (ML) techniques to design and optimize computer\narchitectures is a promising research direction. Optimizing the runtime\nperformance of a Network-on-Chip (NoC) necessitates a continuous learning\nframework. In this work, we demonstrate the promise of applying reinforcement\nlearning (RL) to optimize NoC runtime performance. We present three RL-based\nmethods for learning optimal routing algorithms. The experimental results show\nthe algorithms can successfully learn a near-optimal solution across different\nenvironment states. Reproducible Code:\ngithub.com/huckiyang/interconnect-routing-gym\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 04:35:40 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Kao", "Sheng-Chun", ""], ["Yang", "Chao-Han Huck", ""], ["Chen", "Pin-Yu", ""], ["Ma", "Xiaoli", ""], ["Krishna", "Tushar", ""]]}, {"id": "1908.04503", "submitter": "Ang Li", "authors": "Ang Li, Jianzhong Qi, Rui Zhang, Ramamohanarao Kotagiri", "title": "Boosted GAN with Semantically Interpretable Information for Image\n  Inpainting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image inpainting aims at restoring missing region of corrupted images, which\nhas many applications such as image restoration and object removal. However,\ncurrent GAN-based inpainting models fail to explicitly consider the semantic\nconsistency between restored images and original images. Forexample, given a\nmale image with image region of one eye missing, current models may restore it\nwith a female eye. This is due to the ambiguity of GAN-based inpainting models:\nthese models can generate many possible restorations given a missing region. To\naddress this limitation, our key insight is that semantically interpretable\ninformation (such as attribute and segmentation information) of input images\n(with missing regions) can provide essential guidance for the inpainting\nprocess. Based on this insight, we propose a boosted GAN with semantically\ninterpretable information for image inpainting that consists of an inpainting\nnetwork and a discriminative network. The inpainting network utilizes two\nauxiliary pretrained networks to discover the attribute and segmentation\ninformation of input images and incorporates them into the inpainting process\nto provide explicit semantic-level guidance. The discriminative network adopts\na multi-level design that can enforce regularizations not only on overall\nrealness but also on attribute and segmentation consistency with the original\nimages. Experimental results show that our proposed model can preserve\nconsistency on both attribute and segmentation level, and significantly\noutperforms the state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 06:05:24 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Li", "Ang", ""], ["Qi", "Jianzhong", ""], ["Zhang", "Rui", ""], ["Kotagiri", "Ramamohanarao", ""]]}, {"id": "1908.04537", "submitter": "Wenbo Gong", "authors": "Wenbo Gong, Sebastian Tschiatschek, Richard Turner, Sebastian Nowozin,\n  Jos\\'e Miguel Hern\\'andez-Lobato, Cheng Zhang", "title": "Icebreaker: Element-wise Active Information Acquisition with Bayesian\n  Deep Latent Gaussian Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce the ice-start problem, i.e., the challenge of\ndeploying machine learning models when only little or no training data is\ninitially available, and acquiring each feature element of data is associated\nwith costs. This setting is representative for the real-world machine learning\napplications. For instance, in the health-care domain, when training an AI\nsystem for predicting patient metrics from lab tests, obtaining every single\nmeasurement comes with a high cost. Active learning, where only the label is\nassociated with a cost does not apply to such problem, because performing all\npossible lab tests to acquire a new training datum would be costly, as well as\nunnecessary due to redundancy. We propose Icebreaker, a principled framework to\napproach the ice-start problem. Icebreaker uses a full Bayesian Deep Latent\nGaussian Model (BELGAM) with a novel inference method. Our proposed method\ncombines recent advances in amortized inference and stochastic gradient MCMC to\nenable fast and accurate posterior inference. By utilizing BELGAM's ability to\nfully quantify model uncertainty, we also propose two information acquisition\nfunctions for imputation and active prediction problems. We demonstrate that\nBELGAM performs significantly better than the previous VAE (Variational\nautoencoder) based models, when the data set size is small, using both machine\nlearning benchmarks and real-world recommender systems and health-care\napplications. Moreover, based on BELGAM, Icebreaker further improves the\nperformance and demonstrate the ability to use minimum amount of the training\ndata to obtain the highest test time performance.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 08:49:33 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 09:20:57 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Gong", "Wenbo", ""], ["Tschiatschek", "Sebastian", ""], ["Turner", "Richard", ""], ["Nowozin", "Sebastian", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""], ["Zhang", "Cheng", ""]]}, {"id": "1908.04573", "submitter": "Yue Wang", "authors": "Yue Wang, Yao Wan, Chenwei Zhang, Lixin Cui, Lu Bai, and Philip S. Yu", "title": "Competitive Multi-Agent Deep Reinforcement Learning with Counterfactual\n  Thinking", "comments": "This paper is accepted by ICDM'19 as a short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual thinking describes a psychological phenomenon that people\nre-infer the possible results with different solutions about things that have\nalready happened. It helps people to gain more experience from mistakes and\nthus to perform better in similar future tasks. This paper investigates the\ncounterfactual thinking for agents to find optimal decision-making strategies\nin multi-agent reinforcement learning environments. In particular, we propose a\nmulti-agent deep reinforcement learning model with a structure which mimics the\nhuman-psychological counterfactual thinking process to improve the competitive\nabilities for agents. To this end, our model generates several possible actions\n(intent actions) with a parallel policy structure and estimates the rewards and\nregrets for these intent actions based on its current understanding of the\nenvironment. Our model incorporates a scenario-based framework to link the\nestimated regrets with its inner policies. During the iterations, our model\nupdates the parallel policies and the corresponding scenario-based regrets for\nagents simultaneously. To verify the effectiveness of our proposed model, we\nconduct extensive experiments on two different environments with real-world\napplications. Experimental results show that counterfactual thinking can\nactually benefit the agents to obtain more accumulative rewards from the\nenvironments with fair information by comparing to their opponents while\nkeeping high performing efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 10:55:24 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 13:40:16 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Wang", "Yue", ""], ["Wan", "Yao", ""], ["Zhang", "Chenwei", ""], ["Cui", "Lixin", ""], ["Bai", "Lu", ""], ["Yu", "Philip S.", ""]]}, {"id": "1908.04621", "submitter": "Chien-Sheng Wu", "authors": "Chien-Sheng Wu, Andrea Madotto, Zhaojiang Lin, Peng Xu, Pascale Fung", "title": "Getting To Know You: User Attribute Extraction from Dialogues", "comments": "1st Workshop on NLP for Conversational AI @ ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User attributes provide rich and useful information for user understanding,\nyet structured and easy-to-use attributes are often sparsely populated. In this\npaper, we leverage dialogues with conversational agents, which contain strong\nsuggestions of user information, to automatically extract user attributes.\nSince no existing dataset is available for this purpose, we apply distant\nsupervision to train our proposed two-stage attribute extractor, which\nsurpasses several retrieval and generation baselines on human evaluation.\nMeanwhile, we discuss potential applications (e.g., personalized recommendation\nand dialogue systems) of such extracted user attributes, and point out current\nlimitations to cast light on future work.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 13:03:58 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Wu", "Chien-Sheng", ""], ["Madotto", "Andrea", ""], ["Lin", "Zhaojiang", ""], ["Xu", "Peng", ""], ["Fung", "Pascale", ""]]}, {"id": "1908.04629", "submitter": "Tiago Machado", "authors": "Tiago Machado, Daniel Gopstein, Oded Nov, Angela Wang, Andy Nealen,\n  Julian Togelius", "title": "Evaluation of a Recommender System for Assisting Novice Game Designers", "comments": "The 15th AAAI Conference on Artificial Intelligence and Interactive\n  Digital Entertainment (AIIDE 19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Game development is a complex task involving multiple disciplines and\ntechnologies. Developers and researchers alike have suggested that AI-driven\ngame design assistants may improve developer workflow. We present a recommender\nsystem for assisting humans in game design as well as a rigorous human subjects\nstudy to validate it. The AI-driven game design assistance system suggests game\nmechanics to designers based on characteristics of the game being developed. We\nbelieve this method can bring creative insights and increase users'\nproductivity. We conducted quantitative studies that showed the recommender\nsystem increases users' levels of accuracy and computational affect, and\ndecreases their levels of workload.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 13:22:51 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Machado", "Tiago", ""], ["Gopstein", "Daniel", ""], ["Nov", "Oded", ""], ["Wang", "Angela", ""], ["Nealen", "Andy", ""], ["Togelius", "Julian", ""]]}, {"id": "1908.04683", "submitter": "Marin Toromanoff", "authors": "Marin Toromanoff, Emilie Wirbel, Fabien Moutarde", "title": "Is Deep Reinforcement Learning Really Superhuman on Atari? Leveling the\n  playing field", "comments": "Paper currently in review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consistent and reproducible evaluation of Deep Reinforcement Learning (DRL)\nis not straightforward. In the Arcade Learning Environment (ALE), small changes\nin environment parameters such as stochasticity or the maximum allowed play\ntime can lead to very different performance. In this work, we discuss the\ndifficulties of comparing different agents trained on ALE. In order to take a\nstep further towards reproducible and comparable DRL, we introduce SABER, a\nStandardized Atari BEnchmark for general Reinforcement learning algorithms. Our\nmethodology extends previous recommendations and contains a complete set of\nenvironment parameters as well as train and test procedures. We then use SABER\nto evaluate the current state of the art, Rainbow. Furthermore, we introduce a\nhuman world records baseline, and argue that previous claims of expert or\nsuperhuman performance of DRL might not be accurate. Finally, we propose\nRainbow-IQN by extending Rainbow with Implicit Quantile Networks (IQN) leading\nto new state-of-the-art performance. Source code is available for\nreproducibility.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 14:55:09 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 09:17:13 GMT"}, {"version": "v3", "created": "Thu, 22 Aug 2019 10:04:58 GMT"}, {"version": "v4", "created": "Tue, 24 Sep 2019 15:13:32 GMT"}, {"version": "v5", "created": "Fri, 8 Nov 2019 10:37:59 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Toromanoff", "Marin", ""], ["Wirbel", "Emilie", ""], ["Moutarde", "Fabien", ""]]}, {"id": "1908.04696", "submitter": "Xaq Pitkow", "authors": "Saurabh Daptardar, Paul Schrater, Xaq Pitkow", "title": "Inverse Rational Control with Partially Observable Continuous Nonlinear\n  Dynamics", "comments": "8 pages plus references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Continuous control and planning remains a major challenge in robotics and\nmachine learning. Neuroscience offers the possibility of learning from animal\nbrains that implement highly successful controllers, but it is unclear how to\nrelate an animal's behavior to control principles. Animals may not always act\noptimally from the perspective of an external observer, but may still act\nrationally: we hypothesize that animals choose actions with highest expected\nfuture subjective value according to their own internal model of the world.\nTheir actions thus result from solving a different optimal control problem from\nthose on which they are evaluated in neuroscience experiments. With this\nassumption, we propose a novel framework of model-based inverse rational\ncontrol that learns the agent's internal model that best explains their actions\nin a task described as a partially observable Markov decision process (POMDP).\nIn this approach we first learn optimal policies generalized over the entire\nmodel space of dynamics and subjective rewards, using an extended Kalman filter\nto represent the belief space, a neural network in the actor-critic framework\nto optimize the policy, and a simplified basis for the parameter space. We then\ncompute the model that maximizes the likelihood of the experimentally\nobservable data comprising the agent's sensory observations and chosen actions.\nOur proposed method is able to recover the true model of simulated agents\nwithin theoretical error bounds given by limited data. We illustrate this\nmethod by applying it to a complex naturalistic task currently used in\nneuroscience experiments. This approach provides a foundation for interpreting\nthe behavioral and neural dynamics of highly adapted controllers in animal\nbrains.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 15:12:22 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Daptardar", "Saurabh", ""], ["Schrater", "Paul", ""], ["Pitkow", "Xaq", ""]]}, {"id": "1908.04698", "submitter": "Andreas Vogelsang", "authors": "Mathias Blumreiter, Joel Greenyer, Francisco Javier Chiyah Garcia,\n  Verena Kl\\\"os, Maike Schwammberger, Christoph Sommer, Andreas Vogelsang,\n  Andreas Wortmann", "title": "Towards Self-Explainable Cyber-Physical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing complexity of CPSs, their behavior and decisions become\nincreasingly difficult to understand and comprehend for users and other\nstakeholders. Our vision is to build self-explainable systems that can, at\nrun-time, answer questions about the system's past, current, and future\nbehavior. As hitherto no design methodology or reference framework exists for\nbuilding such systems, we propose the MAB-EX framework for building\nself-explainable systems that leverage requirements- and explainability models\nat run-time. The basic idea of MAB-EX is to first Monitor and Analyze a certain\nbehavior of a system, then Build an explanation from explanation models and\nconvey this EXplanation in a suitable way to a stakeholder. We also take into\naccount that new explanations can be learned, by updating the explanation\nmodels, should new and yet un-explainable behavior be detected by the system.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 15:17:13 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Blumreiter", "Mathias", ""], ["Greenyer", "Joel", ""], ["Garcia", "Francisco Javier Chiyah", ""], ["Kl\u00f6s", "Verena", ""], ["Schwammberger", "Maike", ""], ["Sommer", "Christoph", ""], ["Vogelsang", "Andreas", ""], ["Wortmann", "Andreas", ""]]}, {"id": "1908.04700", "submitter": "Emile Van Krieken", "authors": "Emile van Krieken, Erman Acar, Frank van Harmelen", "title": "Semi-Supervised Learning using Differentiable Reasoning", "comments": null, "journal-ref": "IFCoLog Journal of Logic and its Applications 6 (2019) 633-653", "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Differentiable Reasoning (DR), a novel semi-supervised learning\ntechnique which uses relational background knowledge to benefit from unlabeled\ndata. We apply it to the Semantic Image Interpretation (SII) task and show that\nbackground knowledge provides significant improvement. We find that there is a\nstrong but interesting imbalance between the contributions of updates from\nModus Ponens (MP) and its logical equivalent Modus Tollens (MT) to the learning\nprocess, suggesting that our approach is very sensitive to a phenomenon called\nthe Raven Paradox. We propose a solution to overcome this situation.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 15:21:37 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["van Krieken", "Emile", ""], ["Acar", "Erman", ""], ["van Harmelen", "Frank", ""]]}, {"id": "1908.04725", "submitter": "Theo Deprelle", "authors": "Theo Deprelle, Thibault Groueix, Matthew Fisher, Vladimir G. Kim,\n  Bryan C. Russell, Mathieu Aubry", "title": "Learning elementary structures for 3D shape generation and matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to represent shapes as the deformation and combination of\nlearnable elementary 3D structures, which are primitives resulting from\ntraining over a collection of shape. We demonstrate that the learned elementary\n3D structures lead to clear improvements in 3D shape generation and matching.\nMore precisely, we present two complementary approaches for learning elementary\nstructures: (i) patch deformation learning and (ii) point translation learning.\nBoth approaches can be extended to abstract structures of higher dimensions for\nimproved results. We evaluate our method on two tasks: reconstructing ShapeNet\nobjects and estimating dense correspondences between human scans (FAUST inter\nchallenge). We show 16% improvement over surface deformation approaches for\nshape reconstruction and outperform FAUST inter challenge state of the art by\n6%.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 16:36:51 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 17:30:02 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Deprelle", "Theo", ""], ["Groueix", "Thibault", ""], ["Fisher", "Matthew", ""], ["Kim", "Vladimir G.", ""], ["Russell", "Bryan C.", ""], ["Aubry", "Mathieu", ""]]}, {"id": "1908.04734", "submitter": "Tom Everitt", "authors": "Tom Everitt, Marcus Hutter, Ramana Kumar, Victoria Krakovna", "title": "Reward Tampering Problems and Solutions in Reinforcement Learning: A\n  Causal Influence Diagram Perspective", "comments": "Accepted to Synthese, March 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Can humans get arbitrarily capable reinforcement learning (RL) agents to do\ntheir bidding? Or will sufficiently capable RL agents always find ways to\nbypass their intended objectives by shortcutting their reward signal? This\nquestion impacts how far RL can be scaled, and whether alternative paradigms\nmust be developed in order to build safe artificial general intelligence. In\nthis paper, we study when an RL agent has an instrumental goal to tamper with\nits reward process, and describe design principles that prevent instrumental\ngoals for two different types of reward tampering (reward function tampering\nand RF-input tampering). Combined, the design principles can prevent both types\nof reward tampering from being instrumental goals. The analysis benefits from\ncausal influence diagrams to provide intuitive yet precise formalizations.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 16:50:00 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2019 17:04:39 GMT"}, {"version": "v3", "created": "Tue, 20 Aug 2019 15:47:55 GMT"}, {"version": "v4", "created": "Thu, 18 Feb 2021 17:55:25 GMT"}, {"version": "v5", "created": "Fri, 26 Mar 2021 11:13:59 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Everitt", "Tom", ""], ["Hutter", "Marcus", ""], ["Kumar", "Ramana", ""], ["Krakovna", "Victoria", ""]]}, {"id": "1908.04755", "submitter": "Yufang Hou", "authors": "Yufang Hou", "title": "Fine-grained Information Status Classification Using Discourse\n  Context-Aware Self-Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work on bridging anaphora recognition (Hou et al., 2013a) casts the\nproblem as a subtask of learning fine-grained information status (IS). However,\nthese systems heavily depend on many hand-crafted linguistic features. In this\npaper, we propose a discourse context-aware self-attention neural network model\nfor fine-grained IS classification. On the ISNotes corpus (Markert et al.,\n2012), our model with the contextually-encoded word representations (BERT)\n(Devlin et al., 2018) achieves new state-of-the-art performances on\nfine-grained IS classification, obtaining a 4.1% absolute overall accuracy\nimprovement compared to Hou et al. (2013a). More importantly, we also show an\nimprovement of 3.9% F1 for bridging anaphora recognition without using any\ncomplex hand-crafted semantic features designed for capturing the bridging\nphenomenon.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 17:20:51 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Hou", "Yufang", ""]]}, {"id": "1908.04766", "submitter": "Zhaohong Deng", "authors": "Zhaohong Deng, Ruixiu Liu, Te Zhang, Peng Xu, Kup-Sze Choi, Bin Qin,\n  Shitong Wang", "title": "Multi-view Clustering with the Cooperation of Visible and Hidden Views", "comments": "This paper has been submitted to IEEE TKDE in Jun. 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view data are becoming common in real-world modeling tasks and many\nmulti-view data clustering algorithms have thus been proposed. The existing\nalgorithms usually focus on the cooperation of different views in the original\nspace but neglect the influence of the hidden information among these different\nvisible views, or they only consider the hidden information between the views.\nThe algorithms are therefore not efficient since the available information is\nnot fully excavated, particularly the otherness information in different views\nand the consistency information between them. In practice, the otherness and\nconsistency information in multi-view data are both very useful for effective\nclustering analyses. In this study, a Multi-View clustering algorithm developed\nwith the Cooperation of Visible and Hidden views, i.e., MV-Co-VH, is proposed.\nThe MV-Co-VH algorithm first projects the multiple views from different visible\nspaces to the common hidden space by using the non-negative matrix\nfactorization (NMF) strategy to obtain the common hidden view data.\nCollaborative learning is then implemented in the clustering procedure based on\nthe visible views and the shared hidden view. The results of extensive\nexperiments on UCI multi-view datasets and real-world image multi-view datasets\nshow that the clustering performance of the proposed algorithm is competitive\nwith or even better than that of the existing algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 14:55:22 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Deng", "Zhaohong", ""], ["Liu", "Ruixiu", ""], ["Zhang", "Te", ""], ["Xu", "Peng", ""], ["Choi", "Kup-Sze", ""], ["Qin", "Bin", ""], ["Wang", "Shitong", ""]]}, {"id": "1908.04771", "submitter": "Zhaohong Deng", "authors": "Zhaohong Deng, Chen Cui, Peng Xu, Ling Liang, Haoran Chen, Te Zhang,\n  Shitong Wang", "title": "Multi-View Fuzzy Clustering with The Alternative Learning between Shared\n  Hidden Space and Partition", "comments": "This paper has been submitted to IEEE Transactions on Cybnetics in\n  Apr. 8th 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the multi-view data grows in the real world, multi-view clus-tering has\nbecome a prominent technique in data mining, pattern recognition, and machine\nlearning. How to exploit the relation-ship between different views effectively\nusing the characteristic of multi-view data has become a crucial challenge.\nAiming at this, a hidden space sharing multi-view fuzzy clustering (HSS-MVFC)\nmethod is proposed in the present study. This method is based on the classical\nfuzzy c-means clustering model, and obtains associ-ated information between\ndifferent views by introducing shared hidden space. Especially, the shared\nhidden space and the fuzzy partition can be learned alternatively and\ncontribute to each other. Meanwhile, the proposed method uses maximum entropy\nstrategy to control the weights of different views while learning the shared\nhidden space. The experimental result shows that the proposed multi-view\nclustering method has better performance than many related clustering methods.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 14:44:07 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Deng", "Zhaohong", ""], ["Cui", "Chen", ""], ["Xu", "Peng", ""], ["Liang", "Ling", ""], ["Chen", "Haoran", ""], ["Zhang", "Te", ""], ["Wang", "Shitong", ""]]}, {"id": "1908.04777", "submitter": "Xusen Yin", "authors": "Xusen Yin and Jonathan May", "title": "Learn How to Cook a New Recipe in a New House: Using Map\n  Familiarization, Curriculum Learning, and Bandit Feedback to Learn Families\n  of Text-Based Adventure Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of learning to play families of text-based computer\nadventure games, i.e., fully textual environments with a common theme (e.g.\ncooking) and goal (e.g. prepare a meal from a recipe) but with different\nspecifics; new instances of such games are relatively straightforward for\nhumans to master after a brief exposure to the genre but have been curiously\ndifficult for computer agents to learn. We find that the deep Q-learning\nstrategies that have been successfully leveraged for superhuman performance in\nsingle-instance action video games can be applied to learn families of text\nvideo games when adopting simple strategies that correlate with human-like\nlearning behavior. Specifically, we build agents that learn to tackle simple\nscenarios before more complex ones using curriculum learning, that familiarize\nthemselves in an unfamiliar environment by navigating before acting, and that\nexplore uncertain environments more thoroughly using contextual multi-armed\nbandit decision policies. We demonstrate improved task completion rates over\nreasonable baselines when evaluating on never-before-seen games of that theme.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 17:48:10 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 05:13:21 GMT"}, {"version": "v3", "created": "Mon, 20 Apr 2020 18:59:09 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Yin", "Xusen", ""], ["May", "Jonathan", ""]]}, {"id": "1908.04784", "submitter": "Jordan J. Bird", "authors": "Jordan J. Bird, Diego R. Faria, Luis J. Manso, Anik\\'o Ek\\'art,\n  Christopher D. Buckingham", "title": "A Deep Evolutionary Approach to Bioinspired Classifier Optimisation for\n  Brain-Machine Interaction", "comments": "14 pages, 12 figures", "journal-ref": null, "doi": "10.1155/2019/4316548", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study suggests a new approach to EEG data classification by exploring\nthe idea of using evolutionary computation to both select useful discriminative\nEEG features and optimise the topology of Artificial Neural Networks. An\nevolutionary algorithm is applied to select the most informative features from\nan initial set of 2550 EEG statistical features. Optimisation of a Multilayer\nPerceptron (MLP) is performed with an evolutionary approach before\nclassification to estimate the best hyperparameters of the network. Deep\nlearning and tuning with Long Short-Term Memory (LSTM) are also explored, and\nAdaptive Boosting of the two types of models is tested for each problem. Three\nexperiments are provided for comparison using different classifiers: one for\nattention state classification, one for emotional sentiment classification, and\na third experiment in which the goal is to guess the number a subject is\nthinking of. The obtained results show that an Adaptive Boosted LSTM can\nachieve an accuracy of 84.44%, 97.06%, and 9.94% on the attentional, emotional,\nand number datasets, respectively. An evolutionary-optimised MLP achieves\nresults close to the Adaptive Boosted LSTM for the two first experiments and\nsignificantly higher for the number-guessing experiment with an Adaptive\nBoosted DEvo MLP reaching 31.35%, while being significantly quicker to train\nand classify. In particular, the accuracy of the nonboosted DEvo MLP was of\n79.81%, 96.11%, and 27.07% in the same benchmarks. Two datasets for the\nexperiments were gathered using a Muse EEG headband with four electrodes\ncorresponding to TP9, AF7, AF8, and TP10 locations of the international EEG\nplacement standard. The EEG MindBigData digits dataset was gathered from the\nTP9, FP1, FP2, and TP10 locations.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 16:49:30 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Bird", "Jordan J.", ""], ["Faria", "Diego R.", ""], ["Manso", "Luis J.", ""], ["Ek\u00e1rt", "Anik\u00f3", ""], ["Buckingham", "Christopher D.", ""]]}, {"id": "1908.04839", "submitter": "Freddy Lecue", "authors": "Xochitl Watts and Freddy Lecue", "title": "Local Score Dependent Model Explanation for Time Dependent Covariates", "comments": "Work accepted as full paper for presentation at XAI (Explainable AI)\n  workshop at Twenty-Eighth International Joint Conference on Artificial\n  Intelligence (IJCAI) 2019 in Macao, China - August 10-16, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of deep neural networks to make high risk decisions creates a need\nfor global and local explanations so that users and experts have confidence in\nthe modeling algorithms. We introduce a novel technique to find global and\nlocal explanations for time series data used in binary classification machine\nlearning systems. We identify the most salient of the original features used by\na black box model to distinguish between classes. The explanation can be made\non categorical, continuous, and time series data and can be generalized to any\nbinary classification model. The analysis is conducted on time series data to\ntrain a long short-term memory deep neural network and uses the time dependent\nstructure of the underlying features in the explanation. The proposed technique\nattributes weights to features to explain an observations risk of belonging to\na class as a multiplicative factor of a base hazard rate. We use a variation of\nthe Cox Proportional Hazards regression, a Generalized Additive Model, to\nexplain the effect of variables upon the probability of an in-class response\nfor a score output from the black box model. The covariates incorporate time\ndependence structure in the features so the explanation is inclusive of the\nunderlying time series data structure.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 19:46:26 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Watts", "Xochitl", ""], ["Lecue", "Freddy", ""]]}, {"id": "1908.04895", "submitter": "Prodromos Kolyvakis Mr.", "authors": "Prodromos Kolyvakis, Alexandros Kalousis, Dimitris Kiritsis", "title": "HyperKG: Hyperbolic Knowledge Graph Embeddings for Knowledge Base\n  Completion", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning embeddings of entities and relations existing in knowledge bases\nallows the discovery of hidden patterns in data. In this work, we examine the\ngeometrical space's contribution to the task of knowledge base completion. We\nfocus on the family of translational models, whose performance has been\nlagging, and propose a model, dubbed HyperKG, which exploits the hyperbolic\nspace in order to better reflect the topological properties of knowledge bases.\nWe investigate the type of regularities that our model can capture and we show\nthat it is a prominent candidate for effectively representing a subset of\nDatalog rules. We empirically show, using a variety of link prediction\ndatasets, that hyperbolic space allows to narrow down significantly the\nperformance gap between translational and bilinear models.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 00:24:54 GMT"}, {"version": "v2", "created": "Sat, 17 Aug 2019 21:45:59 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Kolyvakis", "Prodromos", ""], ["Kalousis", "Alexandros", ""], ["Kiritsis", "Dimitris", ""]]}, {"id": "1908.04926", "submitter": "Daniel Khashabi Mr.", "authors": "Daniel Khashabi", "title": "Reasoning-Driven Question-Answering for Natural Language Understanding", "comments": "PhD Dissertation; Presented to Computer and Information Sciences\n  department, at the University of Pennsylvania", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Natural language understanding (NLU) of text is a fundamental challenge in\nAI, and it has received significant attention throughout the history of NLP\nresearch. This primary goal has been studied under different tasks, such as\nQuestion Answering (QA) and Textual Entailment (TE). In this thesis, we\ninvestigate the NLU problem through the QA task and focus on the aspects that\nmake it a challenge for the current state-of-the-art technology. This thesis is\norganized into three main parts:\n  In the first part, we explore multiple formalisms to improve existing machine\ncomprehension systems. We propose a formulation for abductive reasoning in\nnatural language and show its effectiveness, especially in domains with limited\ntraining data. Additionally, to help reasoning systems cope with irrelevant or\nredundant information, we create a supervised approach to learn and detect the\nessential terms in questions.\n  In the second part, we propose two new challenge datasets. In particular, we\ncreate two datasets of natural language questions where (i) the first one\nrequires reasoning over multiple sentences; (ii) the second one requires\ntemporal common sense reasoning. We hope that the two proposed datasets will\nmotivate the field to address more complex problems.\n  In the final part, we present the first formal framework for multi-step\nreasoning algorithms, in the presence of a few important properties of language\nuse, such as incompleteness, ambiguity, etc. We apply this framework to prove\nfundamental limitations for reasoning algorithms. These theoretical results\nprovide extra intuition into the existing empirical evidence in the field.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 02:07:02 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Khashabi", "Daniel", ""]]}, {"id": "1908.04950", "submitter": "C\\u{a}t\\u{a}lina Cangea", "authors": "C\\u{a}t\\u{a}lina Cangea, Eugene Belilovsky, Pietro Li\\`o, Aaron\n  Courville", "title": "VideoNavQA: Bridging the Gap between Visual and Embodied Question\n  Answering", "comments": "To appear at BMVC 2019. 15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embodied Question Answering (EQA) is a recently proposed task, where an agent\nis placed in a rich 3D environment and must act based solely on its egocentric\ninput to answer a given question. The desired outcome is that the agent learns\nto combine capabilities such as scene understanding, navigation and language\nunderstanding in order to perform complex reasoning in the visual world.\nHowever, initial advancements combining standard vision and language methods\nwith imitation and reinforcement learning algorithms have shown EQA might be\ntoo complex and challenging for these techniques. In order to investigate the\nfeasibility of EQA-type tasks, we build the VideoNavQA dataset that contains\npairs of questions and videos generated in the House3D environment. The goal of\nthis dataset is to assess question-answering performance from nearly-ideal\nnavigation paths, while considering a much more complete variety of questions\nthan current instantiations of the EQA task. We investigate several models,\nadapted from popular VQA methods, on this new benchmark. This establishes an\ninitial understanding of how well VQA-style methods can perform within this\nnovel EQA paradigm.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 04:44:26 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Cangea", "C\u0103t\u0103lina", ""], ["Belilovsky", "Eugene", ""], ["Li\u00f2", "Pietro", ""], ["Courville", "Aaron", ""]]}, {"id": "1908.05059", "submitter": "Senka Krivic", "authors": "Michael Cashmore, Anna Collins, Benjamin Krarup, Senka Krivic, Daniele\n  Magazzeni, David Smith", "title": "Towards Explainable AI Planning as a Service", "comments": "2nd ICAPS Workshop on Explainable Planning (XAIP-2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Explainable AI is an important area of research within which Explainable\nPlanning is an emerging topic. In this paper, we argue that Explainable\nPlanning can be designed as a service -- that is, as a wrapper around an\nexisting planning system that utilises the existing planner to assist in\nanswering contrastive questions. We introduce a prototype framework to\nfacilitate this, along with some examples of how a planner can be used to\naddress certain types of contrastive questions. We discuss the main advantages\nand limitations of such an approach and we identify open questions for\nExplainable Planning as a service that identify several possible research\ndirections.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 10:25:42 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Cashmore", "Michael", ""], ["Collins", "Anna", ""], ["Krarup", "Benjamin", ""], ["Krivic", "Senka", ""], ["Magazzeni", "Daniele", ""], ["Smith", "David", ""]]}, {"id": "1908.05103", "submitter": "Lucas May Petry", "authors": "Lucas May Petry, Amilcar Soares, Vania Bogorny, Stan Matwin", "title": "Unsupervised Behavior Change Detection in Multidimensional Data Streams\n  for Maritime Traffic Monitoring", "comments": "Extended abstract submitted to the 2019 Montreal Artificial\n  Intelligence Symposium (MAIS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The worldwide growth of maritime traffic and the development of the Automatic\nIdentification System (AIS) has led to advances in monitoring systems for\npreventing vessel accidents and detecting illegal activities. In this work, we\ndescribe research gaps and challenges in machine learning for vessel behavior\nchange and event detection, considering several constraints imposed by\nreal-time data streams and the maritime monitoring domain. As a starting point,\nwe investigate how unsupervised and semi-supervised change detection methods\nmay be employed for identifying shifts in vessel behavior, aiming to detect and\nlabel unusual events.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 12:53:20 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Petry", "Lucas May", ""], ["Soares", "Amilcar", ""], ["Bogorny", "Vania", ""], ["Matwin", "Stan", ""]]}, {"id": "1908.05117", "submitter": "Yi-Ting Yeh", "authors": "Yi-Ting Yeh, Yun-Nung Chen", "title": "FlowDelta: Modeling Flow Information Gain in Reasoning for\n  Conversational Machine Comprehension", "comments": "Accepted by the 2nd Workshop on Machine Reading for Question\n  Answering (MRQA), EMNLP 2019 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational machine comprehension requires deep understanding of the\ndialogue flow, and the prior work proposed FlowQA to implicitly model the\ncontext representations in reasoning for better understanding. This paper\nproposes to explicitly model the information gain through dialogue reasoning in\norder to allow the model to focus on more informative cues. The proposed model\nachieves state-of-the-art performance in a conversational QA dataset QuAC and\nsequential instruction understanding dataset SCONE, which shows the\neffectiveness of the proposed mechanism and demonstrates its capability of\ngeneralization to different QA models and tasks.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 13:34:40 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 13:17:04 GMT"}, {"version": "v3", "created": "Fri, 17 Jan 2020 08:47:23 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Yeh", "Yi-Ting", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "1908.05135", "submitter": "Elia Bruni", "authors": "Mathijs Mul, Diane Bouchacourt, Elia Bruni", "title": "Mastering emergent language: learning to guide in simulated navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To cooperate with humans effectively, virtual agents need to be able to\nunderstand and execute language instructions. A typical setup to achieve this\nis with a scripted teacher which guides a virtual agent using language\ninstructions. However, such setup has clear limitations in scalability and,\nmore importantly, it is not interactive. Here, we introduce an autonomous agent\nthat uses discrete communication to interactively guide other agents to\nnavigate and act on a simulated environment. The developed communication\nprotocol is trainable, emergent and requires no additional supervision. The\nemergent language speeds up learning of new agents, it generalizes across\nincrementally more difficult tasks and, contrary to most other emergent\nlanguages, it is highly interpretable. We demonstrate how the emitted messages\ncorrelate with particular actions and observations, and how new agents become\nless dependent on this guidance as training progresses. By exploiting the\ncorrelations identified in our analysis, we manage to successfully address the\nagents in their own language.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 14:10:21 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Mul", "Mathijs", ""], ["Bouchacourt", "Diane", ""], ["Bruni", "Elia", ""]]}, {"id": "1908.05145", "submitter": "Krishna Balajirao Manoorkar", "authors": "Sabine Frittella, Krishna Manoorkar, Alessandra Palmigiano, Apostolos\n  Tzimoulis, Nachoem M. Wijnberg", "title": "Toward a Dempster-Shafer theory of concepts", "comments": null, "journal-ref": null, "doi": "10.1016/j.ijar.2020.05.004", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we generalize the basic notions and results of Dempster-Shafer\ntheory from predicates to formal concepts. Results include the representation\nof conceptual belief functions as inner measures of suitable probability\nfunctions, and a Dempster-Shafer rule of combination on belief functions on\nformal concepts.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 14:27:00 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 15:19:00 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Frittella", "Sabine", ""], ["Manoorkar", "Krishna", ""], ["Palmigiano", "Alessandra", ""], ["Tzimoulis", "Apostolos", ""], ["Wijnberg", "Nachoem M.", ""]]}, {"id": "1908.05224", "submitter": "Ofir Nachum", "authors": "Ofir Nachum, Michael Ahn, Hugo Ponte, Shixiang Gu, Vikash Kumar", "title": "Multi-Agent Manipulation via Locomotion using Hierarchical Sim2Real", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manipulation and locomotion are closely related problems that are often\nstudied in isolation. In this work, we study the problem of coordinating\nmultiple mobile agents to exhibit manipulation behaviors using a reinforcement\nlearning (RL) approach. Our method hinges on the use of hierarchical sim2real\n-- a simulated environment is used to learn low-level goal-reaching skills,\nwhich are then used as the action space for a high-level RL controller, also\ntrained in simulation. The full hierarchical policy is then transferred to the\nreal world in a zero-shot fashion. The application of domain randomization\nduring training enables the learned behaviors to generalize to real-world\nsettings, while the use of hierarchy provides a modular paradigm for learning\nand transferring increasingly complex behaviors. We evaluate our method on a\nnumber of real-world tasks, including coordinated object manipulation in a\nmulti-agent setting. See videos at\nhttps://sites.google.com/view/manipulation-via-locomotion\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 15:12:02 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 21:26:34 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Nachum", "Ofir", ""], ["Ahn", "Michael", ""], ["Ponte", "Hugo", ""], ["Gu", "Shixiang", ""], ["Kumar", "Vikash", ""]]}, {"id": "1908.05256", "submitter": "Rodrigo P\\'erez Dattari", "authors": "Rodrigo P\\'erez-Dattari, Carlos Celemin, Javier Ruiz-del-Solar, Jens\n  Kober", "title": "Continuous Control for High-Dimensional State Spaces: An Interactive\n  Learning Approach", "comments": "7 pages, 8 figures, IEEE International Conference on Robotics and\n  Automation (ICRA 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) has become a powerful methodology to solve\ncomplex decision-making problems. However, DRL has several limitations when\nused in real-world problems (e.g., robotics applications). For instance, long\ntraining times are required and cannot be accelerated in contrast to simulated\nenvironments, and reward functions may be hard to specify/model and/or to\ncompute. Moreover, the transfer of policies learned in a simulator to the\nreal-world has limitations (reality gap). On the other hand, machine learning\nmethods that rely on the transfer of human knowledge to an agent have shown to\nbe time efficient for obtaining well performing policies and do not require a\nreward function. In this context, we analyze the use of human corrective\nfeedback during task execution to learn policies with high-dimensional state\nspaces, by using the D-COACH framework, and we propose new variants of this\nframework. D-COACH is a Deep Learning based extension of COACH (COrrective\nAdvice Communicated by Humans), where humans are able to shape policies through\ncorrective advice. The enhanced version of D-COACH, which is proposed in this\npaper, largely reduces the time and effort of a human for training a policy.\nExperimental results validate the efficiency of the D-COACH framework in three\ndifferent problems (simulated and with real robots), and show that its enhanced\nversion reduces the human training effort considerably, and makes it feasible\nto learn policies within periods of time in which a DRL agent do not reach any\nimprovement.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 17:36:33 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["P\u00e9rez-Dattari", "Rodrigo", ""], ["Celemin", "Carlos", ""], ["Ruiz-del-Solar", "Javier", ""], ["Kober", "Jens", ""]]}, {"id": "1908.05341", "submitter": "Ozge Yalcin N", "authors": "\\\"Ozge Nilay Yal\\c{c}{\\i}n", "title": "Evaluating Empathy in Artificial Agents", "comments": "This is a pre-print of an article accepted to ACII 2019 conference\n  (http://acii-conf.org/2019/). The final authenticated version will be\n  published on IEEExplore as proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The novel research area of computational empathy is in its infancy and moving\ntowards developing methods and standards. One major problem is the lack of\nagreement on the evaluation of empathy in artificial interactive systems. Even\nthough the existence of well-established methods from psychology, psychiatry\nand neuroscience, the translation between these methods and computational\nempathy is not straightforward. It requires a collective effort to develop\nmetrics that are more suitable for interactive artificial agents. This paper is\naimed as an attempt to initiate the dialogue on this important problem. We\nexamine the evaluation methods for empathy in humans and provide suggestions\nfor the development of better metrics to evaluate empathy in artificial agents.\nWe acknowledge the difficulty of arriving at a single solution in a vast\nvariety of interactive systems and propose a set of systematic approaches that\ncan be used with a variety of applications and systems.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 20:38:52 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Yal\u00e7\u0131n", "\u00d6zge Nilay", ""]]}, {"id": "1908.05348", "submitter": "Malte Schilling", "authors": "Malte Schilling, Helge Ritter, Frank W. Ohl", "title": "From Crystallized Adaptivity to Fluid Adaptivity in Deep Reinforcement\n  Learning -- Insights from Biological Systems on Adaptive Flexibility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in machine-learning algorithms have led to impressive\nperformance increases in many traditional application scenarios of artificial\nintelligence research. In the area of deep reinforcement learning, deep\nlearning functional architectures are combined with incremental learning\nschemes for sequential tasks that include interaction-based, but often delayed\nfeedback. Despite their impressive successes, modern machine-learning\napproaches, including deep reinforcement learning, still perform weakly when\ncompared to flexibly adaptive biological systems in certain naturally occurring\nscenarios. Such scenarios include transfers to environments different than the\nones in which the training took place or environments that dynamically change,\nboth of which are often mastered by biological systems through a capability\nthat we here term \"fluid adaptivity\" to contrast it from the much slower\nadaptivity (\"crystallized adaptivity\") of the prior learning from which the\nbehavior emerged. In this article, we derive and discuss research strategies,\nbased on analyzes of fluid adaptivity in biological systems and its neuronal\nmodeling, that might aid in equipping future artificially intelligent systems\nwith capabilities of fluid adaptivity more similar to those seen in some\nbiologically intelligent systems. A key component of this research strategy is\nthe dynamization of the problem space itself and the implementation of this\ndynamization by suitably designed flexibly interacting modules.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 07:28:41 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Schilling", "Malte", ""], ["Ritter", "Helge", ""], ["Ohl", "Frank W.", ""]]}, {"id": "1908.05441", "submitter": "Peter Jansen", "authors": "Dongfang Xu, Peter Jansen, Jaycie Martin, Zhengnan Xie, Vikas Yadav,\n  Harish Tayyar Madabushi, Oyvind Tafjord and Peter Clark", "title": "Multi-class Hierarchical Question Classification for Multiple Choice\n  Science Exams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior work has demonstrated that question classification (QC), recognizing\nthe problem domain of a question, can help answer it more accurately. However,\ndeveloping strong QC algorithms has been hindered by the limited size and\ncomplexity of annotated data available. To address this, we present the largest\nchallenge dataset for QC, containing 7,787 science exam questions paired with\ndetailed classification labels from a fine-grained hierarchical taxonomy of 406\nproblem domains. We then show that a BERT-based model trained on this dataset\nachieves a large (+0.12 MAP) gain compared with previous methods, while also\nachieving state-of-the-art performance on benchmark open-domain and biomedical\nQC datasets. Finally, we show that using this model's predictions of question\ntopic significantly improves the accuracy of a question answering system by\n+1.7% P@1, with substantial future gains possible as QC performance improves.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 07:00:16 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Xu", "Dongfang", ""], ["Jansen", "Peter", ""], ["Martin", "Jaycie", ""], ["Xie", "Zhengnan", ""], ["Yadav", "Vikas", ""], ["Madabushi", "Harish Tayyar", ""], ["Tafjord", "Oyvind", ""], ["Clark", "Peter", ""]]}, {"id": "1908.05472", "submitter": "Liudmyla Nechepurenko", "authors": "Viktor Voss, Liudmyla Nechepurenko, Dr. Rudi Schaefer and Steffen\n  Bauer", "title": "Playing a Strategy Game with Knowledge-Based Reinforcement Learning", "comments": "preprint", "journal-ref": null, "doi": "10.1007/s42979-020-0087-8", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Knowledge-Based Reinforcement Learning (KB-RL) as a\nmethod that combines a knowledge-based approach and a reinforcement learning\n(RL) technique into one method for intelligent problem solving. The proposed\napproach focuses on multi-expert knowledge acquisition, with the reinforcement\nlearning being applied as a conflict resolution strategy aimed at integrating\nthe knowledge of multiple exerts into one knowledge base.\n  The article describes the KB-RL approach in detail and applies the reported\nmethod to one of the most challenging problems of current Artificial\nIntelligence (AI) research, namely playing a strategy game. The results show\nthat the KB-RL system is able to play and complete the full FreeCiv game, and\nto win against the computer players in various game settings. Moreover, with\nmore games played, the system improves the gameplay by shortening the number of\nrounds that it takes to win the game.\n  Overall, the reported experiment supports the idea that, based on human\nknowledge and empowered by reinforcement learning, the KB-RL system can deliver\na strong solution to the complex, multi-strategic problems, and, mainly, to\nimprove the solution with increased experience.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 09:52:51 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Voss", "Viktor", ""], ["Nechepurenko", "Liudmyla", ""], ["Schaefer", "Dr. Rudi", ""], ["Bauer", "Steffen", ""]]}, {"id": "1908.05490", "submitter": "Meghdad Farahmand", "authors": "Meghdad Farahmand", "title": "A Multivariate Model for Representing Semantic Non-compositionality", "comments": "11 content pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantically non-compositional phrases constitute an intriguing research\ntopic in Natural Language Processing. Semantic non-compositionality --the\nsituation when the meaning of a phrase cannot be derived from the meaning of\nits components, is the main characteristic of such phrases, however, they bear\nother characteristics such as high statistical association and\nnon-substitutability. In this work, we present a model for identifying\nnon-compositional phrases that takes into account all of these characteristics.\nWe show that the presented model remarkably outperforms the existing models of\nidentifying non-compositional phrases that mostly focus only on one of these\ncharacteristics.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 10:58:57 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Farahmand", "Meghdad", ""]]}, {"id": "1908.05551", "submitter": "Yi Yu", "authors": "Yi Yu, Abhishek Srivastava, Simon Canales", "title": "Conditional LSTM-GAN for Melody Generation from Lyrics", "comments": null, "journal-ref": "ACM Transactions on Multimedia Computing, Communications, and\n  Applications, April 2021 Article No.: 35\n  https://dl.acm.org/doi/10.1145/3424116", "doi": "10.1145/3424116", "report-no": null, "categories": "cs.AI cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Melody generation from lyrics has been a challenging research issue in the\nfield of artificial intelligence and music, which enables to learn and discover\nlatent relationship between interesting lyrics and accompanying melody.\nUnfortunately, the limited availability of paired lyrics-melody dataset with\nalignment information has hindered the research progress. To address this\nproblem, we create a large dataset consisting of 12,197 MIDI songs each with\npaired lyrics and melody alignment through leveraging different music sources\nwhere alignment relationship between syllables and music attributes is\nextracted. Most importantly, we propose a novel deep generative model,\nconditional Long Short-Term Memory - Generative Adversarial Network (LSTM-GAN)\nfor melody generation from lyrics, which contains a deep LSTM generator and a\ndeep LSTM discriminator both conditioned on lyrics. In particular,\nlyrics-conditioned melody and alignment relationship between syllables of given\nlyrics and notes of predicted melody are generated simultaneously. Experimental\nresults have proved the effectiveness of our proposed lyrics-to-melody\ngenerative model, where plausible and tuneful sequences can be inferred from\nlyrics.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 14:03:58 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 01:05:35 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Yu", "Yi", ""], ["Srivastava", "Abhishek", ""], ["Canales", "Simon", ""]]}, {"id": "1908.05602", "submitter": "Heikki Arponen Dr", "authors": "Heikki Arponen, Tom E Bishop", "title": "SHREWD: Semantic Hierarchy-based Relational Embeddings for\n  Weakly-supervised Deep Hashing", "comments": "4 pages, Published in ICLR LLD Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CV cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using class labels to represent class similarity is a typical approach to\ntraining deep hashing systems for retrieval; samples from the same or different\nclasses take binary 1 or 0 similarity values. This similarity does not model\nthe full rich knowledge of semantic relations that may be present between data\npoints. In this work we build upon the idea of using semantic hierarchies to\nform distance metrics between all available sample labels; for example cat to\ndog has a smaller distance than cat to guitar. We combine this type of semantic\ndistance into a loss function to promote similar distances between the deep\nneural network embeddings. We also introduce an empirical Kullback-Leibler\ndivergence loss term to promote binarization and uniformity of the embeddings.\nWe test the resulting SHREWD method and demonstrate improvements in\nhierarchical retrieval scores using compact, binary hash codes instead of real\nvalued ones, and show that in a weakly supervised hashing setting we are able\nto learn competitively without explicitly relying on class labels, but instead\non similarities between labels.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 08:24:40 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Arponen", "Heikki", ""], ["Bishop", "Tom E", ""]]}, {"id": "1908.05604", "submitter": "Ye Liu", "authors": "Ye Liu, Chenwei Zhang, Xiaohui Yan, Yi Chang, Philip S. Yu", "title": "Generative Question Refinement with Deep Reinforcement Learning in\n  Retrieval-based QA System", "comments": "CIKM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world question-answering (QA) systems, ill-formed questions, such as\nwrong words, ill word order, and noisy expressions, are common and may prevent\nthe QA systems from understanding and answering them accurately. In order to\neliminate the effect of ill-formed questions, we approach the question\nrefinement task and propose a unified model, QREFINE, to refine the ill-formed\nquestions to well-formed question. The basic idea is to learn a Seq2Seq model\nto generate a new question from the original one. To improve the quality and\nretrieval performance of the generated questions, we make two major\nimprovements: 1) To better encode the semantics of ill-formed questions, we\nenrich the representation of questions with character embedding and the recent\nproposed contextual word embedding such as BERT, besides the traditional\ncontext-free word embeddings; 2) To make it capable to generate desired\nquestions, we train the model with deep reinforcement learning techniques that\nconsiders an appropriate wording of the generation as an immediate reward and\nthe correlation between generated question and answer as time-delayed long-term\nrewards. Experimental results on real-world datasets show that the proposed\nQREFINE method can generate refined questions with more readability but fewer\nmistakes than the original questions provided by users. Moreover, the refined\nquestions also significantly improve the accuracy of answer retrieval.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 05:06:42 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 04:03:05 GMT"}, {"version": "v3", "created": "Wed, 9 Oct 2019 04:38:34 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Liu", "Ye", ""], ["Zhang", "Chenwei", ""], ["Yan", "Xiaohui", ""], ["Chang", "Yi", ""], ["Yu", "Philip S.", ""]]}, {"id": "1908.05632", "submitter": "Santiago Ontanon", "authors": "Pavan Kantharaju, Katelyn Alderfer, Jichen Zhu, Bruce Char, Brian\n  Smith and Santiago Onta\\~n\\'on", "title": "Tracing Player Knowledge in a Parallel Programming Educational Game", "comments": "7 pages, 2 figures, published at AIIDE 2018 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on \"tracing player knowledge\" in educational games.\nSpecifically, given a set of concepts or skills required to master a game, the\ngoal is to estimate the likelihood with which the current player has mastery of\neach of those concepts or skills. The main contribution of the paper is an\napproach that integrates machine learning and domain knowledge rules to find\nwhen the player applied a certain skill and either succeeded or failed. This is\nthen given as input to a standard knowledge tracing module (such as those from\nIntelligent Tutoring Systems) to perform knowledge tracing. We evaluate our\napproach in the context of an educational game called \"Parallel\" to teach\nparallel and concurrent programming with data collected from real users,\nshowing our approach can predict students skills with a low mean-squared error.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 16:46:03 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Kantharaju", "Pavan", ""], ["Alderfer", "Katelyn", ""], ["Zhu", "Jichen", ""], ["Char", "Bruce", ""], ["Smith", "Brian", ""], ["Onta\u00f1\u00f3n", "Santiago", ""]]}, {"id": "1908.05656", "submitter": "Ross Girshick", "authors": "Anton Bakhtin, Laurens van der Maaten, Justin Johnson, Laura\n  Gustafson, Ross Girshick", "title": "PHYRE: A New Benchmark for Physical Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and reasoning about physics is an important ability of\nintelligent agents. We develop the PHYRE benchmark for physical reasoning that\ncontains a set of simple classical mechanics puzzles in a 2D physical\nenvironment. The benchmark is designed to encourage the development of learning\nalgorithms that are sample-efficient and generalize well across puzzles. We\ntest several modern learning algorithms on PHYRE and find that these algorithms\nfall short in solving the puzzles efficiently. We expect that PHYRE will\nencourage the development of novel sample-efficient agents that learn efficient\nbut useful models of physics. For code and to play PHYRE for yourself, please\nvisit https://player.phyre.ai.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 17:58:32 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Bakhtin", "Anton", ""], ["van der Maaten", "Laurens", ""], ["Johnson", "Justin", ""], ["Gustafson", "Laura", ""], ["Girshick", "Ross", ""]]}, {"id": "1908.05737", "submitter": "EPTCS", "authors": "Francesco Olivieri (Data61, CSIRO (Australia)), Guido Governatori\n  (Data61, CSIRO (Australia)), Claudio Tomazzoli (Department of Computer\n  Science, University of Verona), Matteo Cristani (Department of Computer\n  Science, University of Verona)", "title": "Applications of Linear Defeasible Logic: combining resource consumption\n  and exceptions to energy management and business processes", "comments": "In Proceedings DICE-FOPARA 2019, arXiv:1908.04478. arXiv admin note:\n  substantial text overlap with arXiv:1809.03656", "journal-ref": "EPTCS 298, 2019, pp. 1-14", "doi": "10.4204/EPTCS.298.1", "report-no": null, "categories": "cs.AI cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear Logic and Defeasible Logic have been adopted to formalise different\nfeatures of knowledge representation: consumption of resources, and non\nmonotonic reasoning in particular to represent exceptions. Recently, a\nframework to combine sub-structural features, corresponding to the consumption\nof resources, with defeasibility aspects to handle potentially conflicting\ninformation, has been discussed in literature, by some of the authors. Two\napplications emerged that are very relevant: energy management and business\nprocess management. We illustrate a set of guide lines to determine how to\napply linear defeasible logic to those contexts.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 01:57:11 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Olivieri", "Francesco", "", "Data61, CSIRO"], ["Governatori", "Guido", "", "Data61, CSIRO"], ["Tomazzoli", "Claudio", "", "Department of Computer\n  Science, University of Verona"], ["Cristani", "Matteo", "", "Department of Computer\n  Science, University of Verona"]]}, {"id": "1908.05751", "submitter": "Johannes G\\\"unther", "authors": "Johannes G\\\"unther, Nadia M. Ady, Alex Kearney, Michael R. Dawson,\n  Patrick M. Pilarski", "title": "Examining the Use of Temporal-Difference Incremental Delta-Bar-Delta for\n  Real-World Predictive Knowledge Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictions and predictive knowledge have seen recent success in improving\nnot only robot control but also other applications ranging from industrial\nprocess control to rehabilitation. A property that makes these predictive\napproaches well suited for robotics is that they can be learned online and\nincrementally through interaction with the environment. However, a remaining\nchallenge for many prediction-learning approaches is an appropriate choice of\nprediction-learning parameters, especially parameters that control the\nmagnitude of a learning machine's updates to its predictions (the learning rate\nor step size). To begin to address this challenge, we examine the use of online\nstep-size adaptation using a sensor-rich robotic arm. Our method of choice,\nTemporal-Difference Incremental Delta-Bar-Delta (TIDBD), learns and adapts step\nsizes on a feature level; importantly, TIDBD allows step-size tuning and\nrepresentation learning to occur at the same time. We show that TIDBD is a\npractical alternative for classic Temporal-Difference (TD) learning via an\nextensive parameter search. Both approaches perform comparably in terms of\npredicting future aspects of a robotic data stream. Furthermore, the use of a\nstep-size adaptation method like TIDBD appears to allow a system to\nautomatically detect and characterize common sensor failures in a robotic\napplication. Together, these results promise to improve the ability of robotic\ndevices to learn from interactions with their environments in a robust way,\nproviding key capabilities for autonomous agents and robots.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 20:42:19 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 18:45:15 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["G\u00fcnther", "Johannes", ""], ["Ady", "Nadia M.", ""], ["Kearney", "Alex", ""], ["Dawson", "Michael R.", ""], ["Pilarski", "Patrick M.", ""]]}, {"id": "1908.05758", "submitter": "Daniel Menezes", "authors": "Daniel Specht Menezes, Pedro Savarese, Ruy Luiz Milidi\\'u", "title": "Building a Massive Corpus for Named Entity Recognition using Free Open\n  Data Sources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent progress in machine learning, boosted by techniques such as\ndeep learning, many tasks can be successfully solved once a large enough\ndataset is available for training. Nonetheless, human-annotated datasets are\noften expensive to produce, especially when labels are fine-grained, as is the\ncase of Named Entity Recognition (NER), a task that operates with labels on a\nword-level.\n  In this paper, we propose a method to automatically generate labeled datasets\nfor NER from public data sources by exploiting links and structured data from\nDBpedia and Wikipedia. Due to the massive size of these data sources, the\nresulting dataset -- SESAME Available at https://sesame-pt.github.io -- is\ncomposed of millions of labeled sentences. We detail the method to generate the\ndataset, report relevant statistics, and design a baseline using a neural\nnetwork, showing that our dataset helps building better NER predictors.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 03:47:03 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Menezes", "Daniel Specht", ""], ["Savarese", "Pedro", ""], ["Milidi\u00fa", "Ruy Luiz", ""]]}, {"id": "1908.05780", "submitter": "Venet Osmani", "authors": "Seyedmostafa Sheikhalishahi, Riccardo Miotto, Joel T Dudley, Alberto\n  Lavelli, Fabio Rinaldi, Venet Osmani", "title": "Natural Language Processing of Clinical Notes on Chronic Diseases:\n  Systematic Review", "comments": "Supplementary material detailing articles reviewed, classification of\n  diseases and associated algorithms, can be found at:\n  http://venetosmani.com/research/publications.html", "journal-ref": "JMIR Medical Informatics 2019;7(2):e12239, PMID:31066697", "doi": "10.2196/12239", "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Of the 2652 articles considered, 106 met the inclusion criteria. Review of\nthe included papers resulted in identification of 43 chronic diseases, which\nwere then further classified into 10 disease categories using ICD-10. The\nmajority of studies focused on diseases of the circulatory system (n=38) while\nendocrine and metabolic diseases were fewest (n=14). This was due to the\nstructure of clinical records related to metabolic diseases, which typically\ncontain much more structured data, compared with medical records for diseases\nof the circulatory system, which focus more on unstructured data and\nconsequently have seen a stronger focus of NLP. The review has shown that there\nis a significant increase in the use of machine learning methods compared to\nrule-based approaches; however, deep learning methods remain emergent (n=3).\nConsequently, the majority of works focus on classification of disease\nphenotype with only a handful of papers addressing extraction of comorbidities\nfrom the free text or integration of clinical notes with structured data. There\nis a notable use of relatively simple methods, such as shallow classifiers (or\ncombination with rule-based methods), due to the interpretability of\npredictions, which still represents a significant issue for more complex\nmethods. Finally, scarcity of publicly available data may also have contributed\nto insufficient development of more advanced methods, such as extraction of\nword embeddings from clinical notes. Further efforts are still required to\nimprove (1) progression of clinical NLP methods from extraction toward\nunderstanding; (2) recognition of relations among entities rather than entities\nin isolation; (3) temporal extraction to understand past, current, and future\nclinical events; (4) exploitation of alternative sources of clinical knowledge;\nand (5) availability of large-scale, de-identified clinical corpora.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 21:54:06 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Sheikhalishahi", "Seyedmostafa", ""], ["Miotto", "Riccardo", ""], ["Dudley", "Joel T", ""], ["Lavelli", "Alberto", ""], ["Rinaldi", "Fabio", ""], ["Osmani", "Venet", ""]]}, {"id": "1908.05859", "submitter": "Jia-Chen Gu", "authors": "Jia-Chen Gu, Zhen-Hua Ling, Xiaodan Zhu, Quan Liu", "title": "Dually Interactive Matching Network for Personalized Response Selection\n  in Retrieval-Based Chatbots", "comments": "Accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a dually interactive matching network (DIM) for\npresenting the personalities of dialogue agents in retrieval-based chatbots.\nThis model develops from the interactive matching network (IMN) which models\nthe matching degree between a context composed of multiple utterances and a\nresponse candidate. Compared with previous persona fusion approaches which\nenhance the representation of a context by calculating its similarity with a\ngiven persona, the DIM model adopts a dual matching architecture, which\nperforms interactive matching between responses and contexts and between\nresponses and personas respectively for ranking response candidates.\nExperimental results on PERSONA-CHAT dataset show that the DIM model\noutperforms its baseline model, i.e., IMN with persona fusion, by a margin of\n14.5% and outperforms the current state-of-the-art model by a margin of 27.7%\nin terms of top-1 accuracy hits@1.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 06:15:18 GMT"}, {"version": "v2", "created": "Sat, 7 Sep 2019 10:50:40 GMT"}, {"version": "v3", "created": "Sat, 1 Feb 2020 21:21:16 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Gu", "Jia-Chen", ""], ["Ling", "Zhen-Hua", ""], ["Zhu", "Xiaodan", ""], ["Liu", "Quan", ""]]}, {"id": "1908.05907", "submitter": "Sven L\\\"offler", "authors": "Sven L\\\"offler, Ke Liu, and Petra Hofstedt", "title": "The Regularization of Small Sub-Constraint Satisfaction Problems", "comments": "Part of DECLARE 19 proceedings (arXiv:hep-lat/2795508)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new approach on optimization of constraint\nsatisfaction problems (CSPs) by means of substituting sub-CSPs with locally\nconsistent regular membership constraints. The purpose of this approach is to\nreduce the number of fails in the resolution process, to improve the inferences\nmade during search by the constraint solver by strengthening constraint\npropagation, and to maintain the level of propagation while reducing the cost\nof propagating the constraints. Our experimental results show improvements in\nterms of the resolution speed compared to the original CSPs and a\ncompetitiveness to the recent tabulation approach. Besides, our approach can be\nrealized in a preprocessing step, and therefore wouldn't collide with\nredundancy constraints or parallel computing if implemented.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 09:24:45 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["L\u00f6ffler", "Sven", ""], ["Liu", "Ke", ""], ["Hofstedt", "Petra", ""]]}, {"id": "1908.05959", "submitter": "Mauricio Orbes Arteaga", "authors": "Mauricio Orbes-Arteaga and Thomas Varsavsky and Carole H. Sudre and\n  Zach Eaton-Rosen and Lewis J. Haddow and Lauge S{\\o}rensen and Mads Nielsen\n  and Akshay Pai and S\\'ebastien Ourselin and Marc Modat and Parashkev Nachev\n  and M. Jorge Cardoso", "title": "Multi-Domain Adaptation in Brain MRI through Paired Consistency and\n  Adversarial Learning", "comments": "Accepted at 1st International Workshop on Domain Adaptation and\n  Representation Transfer held at MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning algorithms trained on medical images will often fail to\ngeneralize across changes in acquisition parameters. Recent work in domain\nadaptation addresses this challenge and successfully leverages labeled data in\na source domain to perform well on an unlabeled target domain. Inspired by\nrecent work in semi-supervised learning we introduce a novel method to adapt\nfrom one source domain to $n$ target domains (as long as there is paired data\ncovering all domains). Our multi-domain adaptation method utilises a\nconsistency loss combined with adversarial learning. We provide results on\nwhite matter lesion hyperintensity segmentation from brain MRIs using the\nMICCAI 2017 challenge data as the source domain and two target domains. The\nproposed method significantly outperforms other domain adaptation baselines.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 13:06:18 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 09:31:53 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Orbes-Arteaga", "Mauricio", ""], ["Varsavsky", "Thomas", ""], ["Sudre", "Carole H.", ""], ["Eaton-Rosen", "Zach", ""], ["Haddow", "Lewis J.", ""], ["S\u00f8rensen", "Lauge", ""], ["Nielsen", "Mads", ""], ["Pai", "Akshay", ""], ["Ourselin", "S\u00e9bastien", ""], ["Modat", "Marc", ""], ["Nachev", "Parashkev", ""], ["Cardoso", "M. Jorge", ""]]}, {"id": "1908.06003", "submitter": "Ke Liu", "authors": "Ke Liu, Sven L\\\"offler, and Petra Hofstedt", "title": "Exploring Properties of Icosoku by Constraint Satisfaction Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Icosoku is a challenging and interesting puzzle that exhibits highly\nsymmetrical and combinatorial nature. In this paper, we pose the questions\nderived from the puzzle, but with more difficulty and generality. In addition,\nwe also present a constraint programming model for the proposed questions,\nwhich can provide the answers to our first two questions. The purpose of this\npaper is to share our preliminary result and problems to encourage researchers\nin both group theory and constraint communities to consider this topic further.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 15:08:37 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Liu", "Ke", ""], ["L\u00f6ffler", "Sven", ""], ["Hofstedt", "Petra", ""]]}, {"id": "1908.06008", "submitter": "Soujanya Poria", "authors": "Navonil Majumder, Soujanya Poria, Gangeshwar Krishnamurthy, Niyati\n  Chhaya, Rada Mihalcea, Alexander Gelbukh", "title": "Variational Fusion for Multimodal Sentiment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Multimodal fusion is considered a key step in multimodal tasks such as\nsentiment analysis, emotion detection, question answering, and others. Most of\nthe recent work on multimodal fusion does not guarantee the fidelity of the\nmultimodal representation with respect to the unimodal representations. In this\npaper, we propose a variational autoencoder-based approach for modality fusion\nthat minimizes information loss between unimodal and multimodal\nrepresentations. We empirically show that this method outperforms the\nstate-of-the-art methods by a significant margin on several popular datasets.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 13:39:19 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Majumder", "Navonil", ""], ["Poria", "Soujanya", ""], ["Krishnamurthy", "Gangeshwar", ""], ["Chhaya", "Niyati", ""], ["Mihalcea", "Rada", ""], ["Gelbukh", "Alexander", ""]]}, {"id": "1908.06012", "submitter": "Zhang-Wei Hong", "authors": "Zhang-Wei Hong, Joni Pajarinen, Jan Peters", "title": "Model-based Lookahead Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based Reinforcement Learning (MBRL) allows data-efficient learning\nwhich is required in real world applications such as robotics. However, despite\nthe impressive data-efficiency, MBRL does not achieve the final performance of\nstate-of-the-art Model-free Reinforcement Learning (MFRL) methods. We leverage\nthe strengths of both realms and propose an approach that obtains high\nperformance with a small amount of data. In particular, we combine MFRL and\nModel Predictive Control (MPC). While MFRL's strength in exploration allows us\nto train a better forward dynamics model for MPC, MPC improves the performance\nof the MFRL policy by sampling-based planning. The experimental results in\nstandard continuous control benchmarks show that our approach can achieve\nMFRL`s level of performance while being as data-efficient as MBRL.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 04:10:13 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Hong", "Zhang-Wei", ""], ["Pajarinen", "Joni", ""], ["Peters", "Jan", ""]]}, {"id": "1908.06040", "submitter": "Felipe Moreno-Vera", "authors": "Felipe Moreno-Vera", "title": "Performing Deep Recurrent Double Q-Learning for Atari Games", "comments": "Accepted paper on LatinXinAI Workshop co-located with the\n  International Conference on Machine Learning (ICML) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, many applications in Machine Learning are based on define new\nmodels to extract more information about data, In this case Deep Reinforcement\nLearning with the most common application in video games like Atari, Mario, and\nothers causes an impact in how to computers can learning by himself with only\ninformation called rewards obtained from any action. There is a lot of\nalgorithms modeled and implemented based on Deep Recurrent Q-Learning proposed\nby DeepMind used in AlphaZero and Go. In this document, We proposed Deep\nRecurrent Double Q-Learning that is an implementation of Deep Reinforcement\nLearning using Double Q-Learning algorithms and Recurrent Networks like LSTM\nand DRQN.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 15:56:16 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 21:45:01 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Moreno-Vera", "Felipe", ""]]}, {"id": "1908.06132", "submitter": "Rodrigo Nogueira", "authors": "Rodrigo Nogueira", "title": "Learning Representations and Agents for Information Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A goal shared by artificial intelligence and information retrieval is to\ncreate an oracle, that is, a machine that can answer our questions, no matter\nhow difficult they are. A more limited, but still instrumental, version of this\noracle is a question-answering system, in which an open-ended question is given\nto the machine, and an answer is produced based on the knowledge it has access\nto. Such systems already exist and are increasingly capable of answering\ncomplicated questions. This progress can be partially attributed to the recent\nsuccess of machine learning and to the efficient methods for storing and\nretrieving information, most notably through web search engines. One can\nimagine that this general-purpose question-answering system can be built as a\nbillion-parameters neural network trained end-to-end with a large number of\npairs of questions and answers. We argue, however, that although this approach\nhas been very successful for tasks such as machine translation, storing the\nworld's knowledge as parameters of a learning machine can be very hard. A more\nefficient way is to train an artificial agent on how to use an external\nretrieval system to collect relevant information. This agent can leverage the\neffort that has been put into designing and running efficient storage and\nretrieval systems by learning how to best utilize them to accomplish a task.\n...\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 19:07:07 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Nogueira", "Rodrigo", ""]]}, {"id": "1908.06165", "submitter": "Timnit Gebru", "authors": "Timnit Gebru", "title": "Oxford Handbook on AI Ethics Book Chapter on Race and Gender", "comments": "Book chapter on Oxford Hanbook on AI Ethics. 27 pages with references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From massive face-recognition-based surveillance and machine-learning-based\ndecision systems predicting crime recidivism rates, to the move towards\nautomated health diagnostic systems, artificial intelligence (AI) is being used\nin scenarios that have serious consequences in people's lives. However, this\nrapid permeation of AI into society has not been accompanied by a thorough\ninvestigation of the sociopolitical issues that cause certain groups of people\nto be harmed rather than advantaged by it. For instance, recent studies have\nshown that commercial face recognition systems have much higher error rates for\ndark skinned women while having minimal errors on light skinned men. A 2016\nProPublica investigation uncovered that machine learning based tools that\nassess crime recidivism rates in the US are biased against African Americans.\nOther studies show that natural language processing tools trained on newspapers\nexhibit societal biases (e.g. finishing the analogy \"Man is to computer\nprogrammer as woman is to X\" by homemaker). At the same time, books such as\nWeapons of Math Destruction and Automated Inequality detail how people in lower\nsocioeconomic classes in the US are subjected to more automated decision making\ntools than those who are in the upper class. Thus, these tools are most often\nused on people towards whom they exhibit the most bias. While many technical\nsolutions have been proposed to alleviate bias in machine learning systems, we\nhave to take a holistic and multifaceted approach. This includes\nstandardization bodies determining what types of systems can be used in which\nscenarios, making sure that automated decision tools are created by people from\ndiverse backgrounds, and understanding the historical and political factors\nthat disadvantage certain groups who are subjected to these tools.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 15:35:23 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Gebru", "Timnit", ""]]}, {"id": "1908.06178", "submitter": "Sarthak Dash", "authors": "Sarthak Dash, Alfio Gliozzo", "title": "Distributional Negative Sampling for Knowledge Base Completion", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art approaches for Knowledge Base Completion (KBC) exploit deep\nneural networks trained with both false and true assertions: positive\nassertions are explicitly taken from the knowledge base, whereas negative ones\nare generated by random sampling of entities. In this paper, we argue that\nrandom sampling is not a good training strategy since it is highly likely to\ngenerate a huge number of nonsensical assertions during training, which does\nnot provide relevant training signal to the system. Hence, it slows down the\nlearning process and decreases accuracy. To address this issue, we propose an\nalternative approach called Distributional Negative Sampling that generates\nmeaningful negative examples which are highly likely to be false. Our approach\nachieves a significant improvement in Mean Reciprocal Rank values amongst two\ndifferent KBC algorithms in three standard academic benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 21:12:37 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Dash", "Sarthak", ""], ["Gliozzo", "Alfio", ""]]}, {"id": "1908.06180", "submitter": "Dongrui Wu", "authors": "Zhenhua Shi, Xiaomo Chen, Changming Zhao, He He, Veit Stuphorn and\n  Dongrui Wu", "title": "Multi-View Broad Learning System for Primate Oculomotor Decision\n  Decoding", "comments": null, "journal-ref": "IEEE Transactions on Neural Systems and Rehabilitation\n  Engineering, 2020", "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view learning improves the learning performance by utilizing multi-view\ndata: data collected from multiple sources, or feature sets extracted from the\nsame data source. This approach is suitable for primate brain state decoding\nusing cortical neural signals. This is because the complementary components of\nsimultaneously recorded neural signals, local field potentials (LFPs) and\naction potentials (spikes), can be treated as two views. In this paper, we\nextended broad learning system (BLS), a recently proposed wide neural network\narchitecture, from single-view learning to multi-view learning, and validated\nits performance in decoding monkeys' oculomotor decision from medial frontal\nLFPs and spikes. We demonstrated that medial frontal LFPs and spikes in\nnon-human primate do contain complementary information about the oculomotor\ndecision, and that the proposed multi-view BLS is a more effective approach for\ndecoding the oculomotor decision than several classical and state-of-the-art\nsingle-view and multi-view learning approaches.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 21:23:20 GMT"}, {"version": "v2", "created": "Sat, 4 Jan 2020 16:18:49 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 22:53:26 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Shi", "Zhenhua", ""], ["Chen", "Xiaomo", ""], ["Zhao", "Changming", ""], ["He", "He", ""], ["Stuphorn", "Veit", ""], ["Wu", "Dongrui", ""]]}, {"id": "1908.06183", "submitter": "Anthony Rhodes", "authors": "Anthony D. Rhodes", "title": "Search Algorithms for Mastermind", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  his paper presents two novel approaches to solving the classic board game\nmastermind, including a variant of simulated annealing (SA) and a technique we\nterm maximum expected reduction in consistency (MERC). In addition, we compare\nsearch results for these algorithms to two baseline search methods: a random,\nuninformed search and the method of minimizing maximum query partition sets as\noriginally developed by both Donald Knuth and Peter Norvig.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 21:26:14 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Rhodes", "Anthony D.", ""]]}, {"id": "1908.06335", "submitter": "Jurriaan Parie", "authors": "Frank Phillipson, Jurriaan Parie, Ron Weikamp", "title": "Prune Sampling: a MCMC inference technique for discrete and\n  deterministic Bayesian networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and characterise the performance of the Markov chain Monte Carlo\n(MCMC) inference method Prune Sampling for discrete and deterministic Bayesian\nnetworks (BNs). We developed a procedure to obtain the performance of a MCMC\nsampling method in the limit of infinite simulation time, extrapolated from\nrelatively short simulations. This approach was used to conduct a study to\ncompare the accuracy, rate of convergence and the time consumption of Prune\nSampling with two conventional MCMC sampling methods: Gibbs- and Metropolis\nsampling. We show that Markov chains created by Prune Sampling always converge\nto the desired posterior distribution, also for networks where conventional\nGibbs sampling fails. Beside this, we demonstrate that pruning outperforms\nGibbs sampling, at least for a certain class of BNs. Though, this tempting\nfeature comes at a price. In the first version of Prune Sampling, for large BNs\nthe procedure to choose the next iteration step uniformly is rather time\nintensive. Our conclusion is that Prune Sampling is a competitive method for\nall types of small and medium sized BNs, but (for now) standard methods still\nperform better for all types of large BNs.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 20:05:23 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Phillipson", "Frank", ""], ["Parie", "Jurriaan", ""], ["Weikamp", "Ron", ""]]}, {"id": "1908.06336", "submitter": "Alexander Kuhnle", "authors": "Alexander Kuhnle, Ann Copestake", "title": "What is needed for simple spatial language capabilities in VQA?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual question answering (VQA) comprises a variety of language capabilities.\nThe diagnostic benchmark dataset CLEVR has fueled progress by helping to better\nassess and distinguish models in basic abilities like counting, comparing and\nspatial reasoning in vitro. Following this approach, we focus on spatial\nlanguage capabilities and investigate the question: what are the key\ningredients to handle simple visual-spatial relations? We look at the SAN,\nRelNet, FiLM and MC models and evaluate their learning behavior on diagnostic\ndata which is solely focused on spatial relations. Via comparative analysis and\ntargeted model modification we identify what really is required to\nsubstantially improve upon the CNN-LSTM baseline.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 20:12:39 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 19:03:21 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Kuhnle", "Alexander", ""], ["Copestake", "Ann", ""]]}, {"id": "1908.06376", "submitter": "Denys Matthies", "authors": "Shamane Siriwardhana, Rivindu Weerasakera, Denys J.C. Matthies,\n  Suranga Nanayakkara", "title": "VUSFA:Variational Universal Successor Features Approximator to Improve\n  Transfer DRL for Target Driven Visual Navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show how novel transfer reinforcement learning techniques\ncan be applied to the complex task of target driven navigation using the\nphotorealistic AI2THOR simulator. Specifically, we build on the concept of\nUniversal Successor Features with an A3C agent. We introduce the novel\narchitectural contribution of a Successor Feature Dependant Policy (SFDP) and\nadopt the concept of Variational Information Bottlenecks to achieve state of\nthe art performance. VUSFA, our final architecture, is a straightforward\napproach that can be implemented using our open source repository. Our approach\nis generalizable, showed greater stability in training, and outperformed recent\napproaches in terms of transfer learning ability.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 04:24:08 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Siriwardhana", "Shamane", ""], ["Weerasakera", "Rivindu", ""], ["Matthies", "Denys J. C.", ""], ["Nanayakkara", "Suranga", ""]]}, {"id": "1908.06402", "submitter": "Evgeny Burnaev", "authors": "Anton Smerdov and Evgeny Burnaev and Andrey Somov", "title": "eSports Pro-Players Behavior During the Game Events: Statistical\n  Analysis of Data Obtained Using the Smart Chair", "comments": "8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's competition between the professional eSports teams is so strong that\nin-depth analysis of players' performance literally crucial for creating a\npowerful team. There are two main approaches to such an estimation: obtaining\nfeatures and metrics directly from the in-game data or collecting detailed\ninformation about the player including data on his/her physical training. While\nthe correlation between the player's skill and in-game data has already been\ncovered in many papers, there are very few works related to analysis of eSports\nathlete's skill through his/her physical behavior. We propose the smart chair\nplatform which is to collect data on the person's behavior on the chair using\nan integrated accelerometer, a gyroscope and a magnetometer. We extract the\nimportant game events to define the players' physical reactions to them. The\nobtained data are used for training machine learning models in order to\ndistinguish between the low-skilled and high-skilled players. We extract and\nfigure out the key features during the game and discuss the results.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 09:05:18 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Smerdov", "Anton", ""], ["Burnaev", "Evgeny", ""], ["Somov", "Andrey", ""]]}, {"id": "1908.06407", "submitter": "Evgeny Burnaev", "authors": "Anton Smerdov and Anastasia Kiskun and Rostislav Shaniiazov and Andrey\n  Somov and Evgeny Burnaev", "title": "Understanding Cyber Athletes Behaviour Through a Smart Chair: CS:GO and\n  Monolith Team Scenario", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  eSports is the rapidly developing multidisciplinary domain. However, research\nand experimentation in eSports are in the infancy. In this work, we propose a\nsmart chair platform - an unobtrusive approach to the collection of data on the\neSports athletes and data further processing with machine learning methods. The\nuse case scenario involves three groups of players: `cyber athletes' (Monolith\nteam), semi-professional players and newbies all playing CS:GO discipline. In\nparticular, we collect data from the accelerometer and gyroscope integrated in\nthe chair and apply machine learning algorithms for the data analysis. Our\nresults demonstrate that the professional athletes can be identified by their\nbehaviour on the chair while playing the game.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 09:29:50 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Smerdov", "Anton", ""], ["Kiskun", "Anastasia", ""], ["Shaniiazov", "Rostislav", ""], ["Somov", "Andrey", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1908.06449", "submitter": "Chuan Meng", "authors": "Chuan Meng, Pengjie Ren, Zhumin Chen, Christof Monz, Jun Ma, Maarten\n  de Rijke", "title": "RefNet: A Reference-aware Network for Background Based Conversation", "comments": "Accepted to AAAI 2020 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing conversational systems tend to generate generic responses. Recently,\nBackground Based Conversations (BBCs) have been introduced to address this\nissue. Here, the generated responses are grounded in some background\ninformation. The proposed methods for BBCs are able to generate more\ninformative responses, they either cannot generate natural responses or have\ndifficulty in locating the right background information. In this paper, we\npropose a Reference-aware Network (RefNet) to address the two issues. Unlike\nexisting methods that generate responses token by token, RefNet incorporates a\nnovel reference decoder that provides an alternative way to learn to directly\ncite a semantic unit (e.g., a span containing complete semantic information)\nfrom the background. Experimental results show that RefNet significantly\noutperforms state-of-the-art methods in terms of both automatic and human\nevaluations, indicating that RefNet can generate more appropriate and\nhuman-like responses.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 14:49:16 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 07:56:45 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Meng", "Chuan", ""], ["Ren", "Pengjie", ""], ["Chen", "Zhumin", ""], ["Monz", "Christof", ""], ["Ma", "Jun", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1908.06540", "submitter": "Valentin Robu PhD", "authors": "Xingyu Zhao, Valentin Robu, David Flynn, Kizito Salako, Lorenzo\n  Strigini", "title": "Assessing the Safety and Reliability of Autonomous Vehicles from Road\n  Testing", "comments": null, "journal-ref": "Proceedings of 30th IEEE International Symposium on Software\n  Reliability Engineering (ISSRE 2019)", "doi": "10.1109/ISSRE.2019.00012", "report-no": null, "categories": "cs.AI cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an urgent societal need to assess whether autonomous vehicles (AVs)\nare safe enough. From published quantitative safety and reliability assessments\nof AVs, we know that, given the goal of predicting very low rates of accidents,\nroad testing alone requires infeasible numbers of miles to be driven. However,\nprevious analyses do not consider any knowledge prior to road testing -\nknowledge which could bring substantial advantages if the AV design allows\nstrong expectations of safety before road testing. We present the advantages of\na new variant of Conservative Bayesian Inference (CBI), which uses prior\nknowledge while avoiding optimistic biases. We then study the trend of\ndisengagements (take-overs by human drivers) by applying Software Reliability\nGrowth Models (SRGMs) to data from Waymo's public road testing over 51 months,\nin view of the practice of software updates during this testing. Our approach\nis to not trust any specific SRGM, but to assess forecast accuracy and then\nimprove forecasts. We show that, coupled with accuracy assessment and\nrecalibration techniques, SRGMs could be a valuable test planning aid.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 00:10:37 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Zhao", "Xingyu", ""], ["Robu", "Valentin", ""], ["Flynn", "David", ""], ["Salako", "Kizito", ""], ["Strigini", "Lorenzo", ""]]}, {"id": "1908.06556", "submitter": "Prithviraj Ammanabrolu", "authors": "Prithviraj Ammanabrolu and Mark O. Riedl", "title": "Transfer in Deep Reinforcement Learning using Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text adventure games, in which players must make sense of the world through\ntext descriptions and declare actions through text descriptions, provide a\nstepping stone toward grounding action in language. Prior work has demonstrated\nthat using a knowledge graph as a state representation and question-answering\nto pre-train a deep Q-network facilitates faster control policy transfer. In\nthis paper, we explore the use of knowledge graphs as a representation for\ndomain knowledge transfer for training text-adventure playing reinforcement\nlearning agents. Our methods are tested across multiple computer generated and\nhuman authored games, varying in domain and complexity, and demonstrate that\nour transfer learning methods let us learn a higher-quality control policy\nfaster.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 01:52:00 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Ammanabrolu", "Prithviraj", ""], ["Riedl", "Mark O.", ""]]}, {"id": "1908.06660", "submitter": "Johannes Czech", "authors": "Johannes Czech, Moritz Willig, Alena Beyer, Kristian Kersting,\n  Johannes F\\\"urnkranz", "title": "Learning to play the Chess Variant Crazyhouse above World Champion Level\n  with Deep Neural Networks and Human Data", "comments": "35 pages, 19 figures, 14 tables", "journal-ref": "Frontiers in Artificial Intelligence, Machine Learning and\n  Artificial Intelligence, Volume 3 (2020)", "doi": "10.3389/frai.2020.00024", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been successfully applied in learning the board\ngames Go, chess and shogi without prior knowledge by making use of\nreinforcement learning. Although starting from zero knowledge has been shown to\nyield impressive results, it is associated with high computationally costs\nespecially for complex games. With this paper, we present CrazyAra which is a\nneural network based engine solely trained in supervised manner for the chess\nvariant crazyhouse. Crazyhouse is a game with a higher branching factor than\nchess and there is only limited data of lower quality available compared to\nAlphaGo. Therefore, we focus on improving efficiency in multiple aspects while\nrelying on low computational resources. These improvements include\nmodifications in the neural network design and training configuration, the\nintroduction of a data normalization step and a more sample efficient\nMonte-Carlo tree search which has a lower chance to blunder. After training on\n569,537 human games for 1.5 days we achieve a move prediction accuracy of\n60.4%. During development, versions of CrazyAra played professional human\nplayers. Most notably, CrazyAra achieved a four to one win over 2017 crazyhouse\nworld champion Justin Tan (aka LM Jann Lee) who is more than 400 Elo higher\nrated compared to the average player in our training set. Furthermore, we test\nthe playing strength of CrazyAra on CPU against all participants of the second\nCrazyhouse Computer Championships 2017, winning against twelve of the thirteen\nparticipants. Finally, for CrazyAraFish we continue training our model on\ngenerated engine games. In ten long-time control matches playing Stockfish 10,\nCrazyAraFish wins three games and draws one out of ten matches.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 09:31:47 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 15:56:56 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Czech", "Johannes", ""], ["Willig", "Moritz", ""], ["Beyer", "Alena", ""], ["Kersting", "Kristian", ""], ["F\u00fcrnkranz", "Johannes", ""]]}, {"id": "1908.06663", "submitter": "Chris Reinke", "authors": "Chris Reinke, Mayalen Etcheverry, Pierre-Yves Oudeyer", "title": "Intrinsically Motivated Discovery of Diverse Patterns in Self-Organizing\n  Systems", "comments": "29 pages, 19 figure, ICLR 2020 conference paper, associated website:\n  https://automated-discovery.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many complex dynamical systems, artificial or natural, one can observe\nself-organization of patterns emerging from local rules. Cellular automata,\nlike the Game of Life (GOL), have been widely used as abstract models enabling\nthe study of various aspects of self-organization and morphogenesis, such as\nthe emergence of spatially localized patterns. However, findings of\nself-organized patterns in such models have so far relied on manual tuning of\nparameters and initial states, and on the human eye to identify interesting\npatterns. In this paper, we formulate the problem of automated discovery of\ndiverse self-organized patterns in such high-dimensional complex dynamical\nsystems, as well as a framework for experimentation and evaluation. Using a\ncontinuous GOL as a testbed, we show that recent intrinsically-motivated\nmachine learning algorithms (POP-IMGEPs), initially developed for learning of\ninverse models in robotics, can be transposed and used in this novel\napplication area. These algorithms combine intrinsically-motivated goal\nexploration and unsupervised learning of goal space representations. Goal space\nrepresentations describe the interesting features of patterns for which diverse\nvariations should be discovered. In particular, we compare various approaches\nto define and learn goal space representations from the perspective of\ndiscovering diverse spatially localized patterns. Moreover, we introduce an\nextension of a state-of-the-art POP-IMGEP algorithm which incrementally learns\na goal representation using a deep auto-encoder, and the use of CPPN primitives\nfor generating initialization parameters. We show that it is more efficient\nthan several baselines and equally efficient as a system pre-trained on a\nhand-made database of patterns identified by human experts.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 09:32:46 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 16:40:53 GMT"}, {"version": "v3", "created": "Mon, 17 Feb 2020 14:43:54 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Reinke", "Chris", ""], ["Etcheverry", "Mayalen", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1908.06674", "submitter": "Marius Lindauer", "authors": "Marius Lindauer, Matthias Feurer, Katharina Eggensperger, Andr\\'e\n  Biedenkapp, Frank Hutter", "title": "Towards Assessing the Impact of Bayesian Optimization's Own\n  Hyperparameters", "comments": "Accepted at DSO workshop (as part of IJCAI'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Optimization (BO) is a common approach for hyperparameter\noptimization (HPO) in automated machine learning. Although it is well-accepted\nthat HPO is crucial to obtain well-performing machine learning models, tuning\nBO's own hyperparameters is often neglected. In this paper, we empirically\nstudy the impact of optimizing BO's own hyperparameters and the transferability\nof the found settings using a wide range of benchmarks, including artificial\nfunctions, HPO and HPO combined with neural architecture search. In particular,\nwe show (i) that tuning can improve the any-time performance of different BO\napproaches, that optimized BO settings also perform well (ii) on similar\nproblems and (iii) partially even on problems from other problem families, and\n(iv) which BO hyperparameters are most important.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 09:59:49 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Lindauer", "Marius", ""], ["Feurer", "Matthias", ""], ["Eggensperger", "Katharina", ""], ["Biedenkapp", "Andr\u00e9", ""], ["Hutter", "Frank", ""]]}, {"id": "1908.06756", "submitter": "Marius Lindauer", "authors": "Marius Lindauer, Katharina Eggensperger, Matthias Feurer, Andr\\'e\n  Biedenkapp, Joshua Marben, Philipp M\\\"uller and Frank Hutter", "title": "BOAH: A Tool Suite for Multi-Fidelity Bayesian Optimization & Analysis\n  of Hyperparameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperparameter optimization and neural architecture search can become\nprohibitively expensive for regular black-box Bayesian optimization because the\ntraining and evaluation of a single model can easily take several hours. To\novercome this, we introduce a comprehensive tool suite for effective\nmulti-fidelity Bayesian optimization and the analysis of its runs. The suite,\nwritten in Python, provides a simple way to specify complex design spaces, a\nrobust and efficient combination of Bayesian optimization and HyperBand, and a\ncomprehensive analysis of the optimization process and its outcomes.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 10:01:03 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Lindauer", "Marius", ""], ["Eggensperger", "Katharina", ""], ["Feurer", "Matthias", ""], ["Biedenkapp", "Andr\u00e9", ""], ["Marben", "Joshua", ""], ["M\u00fcller", "Philipp", ""], ["Hutter", "Frank", ""]]}, {"id": "1908.06758", "submitter": "Jiancheng Long", "authors": "Jiancheng Long, Hongming Zhang, Tianyang Yu, Bo Xu", "title": "Iterative Update and Unified Representation for Multi-Agent\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent systems have a wide range of applications in cooperative and\ncompetitive tasks. As the number of agents increases, nonstationarity gets more\nserious in multi-agent reinforcement learning (MARL), which brings great\ndifficulties to the learning process. Besides, current mainstream algorithms\nconfigure each agent an independent network,so that the memory usage increases\nlinearly with the number of agents which greatly slows down the interaction\nwith the environment. Inspired by Generative Adversarial Networks (GAN), this\npaper proposes an iterative update method (IU) to stabilize the nonstationary\nenvironment. Further, we add first-person perspective and represent all agents\nby only one network which can change agents' policies from sequential compute\nto batch compute. Similar to continual lifelong learning, we realize the\niterative update method in this unified representative network (IUUR). In this\nmethod, iterative update can greatly alleviate the nonstationarity of the\nenvironment, unified representation can speed up the interaction with\nenvironment and avoid the linear growth of memory usage. Besides, this method\ndoes not bother decentralized execution and distributed deployment. Experiments\nshow that compared with MADDPG, our algorithm achieves state-of-the-art\nperformance and saves wall-clock time by a large margin especially with more\nagents.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 07:39:59 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Long", "Jiancheng", ""], ["Zhang", "Hongming", ""], ["Yu", "Tianyang", ""], ["Xu", "Bo", ""]]}, {"id": "1908.06769", "submitter": "De-An Huang", "authors": "De-An Huang, Danfei Xu, Yuke Zhu, Animesh Garg, Silvio Savarese, Li\n  Fei-Fei, Juan Carlos Niebles", "title": "Continuous Relaxation of Symbolic Planner for One-Shot Imitation\n  Learning", "comments": "IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address one-shot imitation learning, where the goal is to execute a\npreviously unseen task based on a single demonstration. While there has been\nexciting progress in this direction, most of the approaches still require a few\nhundred tasks for meta-training, which limits the scalability of the\napproaches. Our main contribution is to formulate one-shot imitation learning\nas a symbolic planning problem along with the symbol grounding problem. This\nformulation disentangles the policy execution from the inter-task\ngeneralization and leads to better data efficiency. The key technical challenge\nis that the symbol grounding is prone to error with limited training data and\nleads to subsequent symbolic planning failures. We address this challenge by\nproposing a continuous relaxation of the discrete symbolic planner that\ndirectly plans on the probabilistic outputs of the symbol grounding model. Our\ncontinuous relaxation of the planner can still leverage the information\ncontained in the probabilistic symbol grounding and significantly improve over\nthe baseline planner for the one-shot imitation learning tasks without using\nlarge training data.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 16:28:12 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 02:58:19 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Huang", "De-An", ""], ["Xu", "Danfei", ""], ["Zhu", "Yuke", ""], ["Garg", "Animesh", ""], ["Savarese", "Silvio", ""], ["Fei-Fei", "Li", ""], ["Niebles", "Juan Carlos", ""]]}, {"id": "1908.06820", "submitter": "Weikang Wang", "authors": "Weikang Wang, Jiajun Zhang, Qian Li, Chengqing Zong and Zhifei Li", "title": "Are You for Real? Detecting Identity Fraud via Dialogue Interactions", "comments": "EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identity fraud detection is of great importance in many real-world scenarios\nsuch as the financial industry. However, few studies addressed this problem\nbefore. In this paper, we focus on identity fraud detection in loan\napplications and propose to solve this problem with a novel interactive\ndialogue system which consists of two modules. One is the knowledge graph (KG)\nconstructor organizing the personal information for each loan applicant. The\nother is structured dialogue management that can dynamically generate a series\nof questions based on the personal KG to ask the applicants and determine their\nidentity states. We also present a heuristic user simulator based on problem\nanalysis to evaluate our method. Experiments have shown that the trainable\ndialogue system can effectively detect fraudsters, and achieve higher\nrecognition accuracy compared with rule-based systems. Furthermore, our learned\ndialogue strategies are interpretable and flexible, which can help promote\nreal-world applications.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 14:13:24 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Wang", "Weikang", ""], ["Zhang", "Jiajun", ""], ["Li", "Qian", ""], ["Zong", "Chengqing", ""], ["Li", "Zhifei", ""]]}, {"id": "1908.06871", "submitter": "Steve Jeffrey Tueno Fotso", "authors": "Steve Tueno", "title": "Towards Linearization Machine Learning Algorithms", "comments": "Study report - 5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper is about a machine learning approach based on the multilinear\nprojection of an unknown function (or probability distribution) to be estimated\ntowards a linear (or multilinear) dimensional space E'. The proposal transforms\nthe problem of predicting the target of an observation x into a problem of\ndetermining a consensus among the k nearest neighbors of x's image within the\ndimensional space E'. The algorithms that concretize it allow both regression\nand binary classification. Implementations carried out using Scala/Spark and\nassessed on a dozen LIBSVM datasets have demonstrated improvements in\nprediction accuracies in comparison with other prediction algorithms\nimplemented within Spark MLLib such as multilayer perceptrons, logistic\nregression classifiers and random forests.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 12:01:46 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Tueno", "Steve", ""]]}, {"id": "1908.06874", "submitter": "Michael Rapp", "authors": "Yannik Klein, Michael Rapp and Eneldo Loza Menc\\'ia", "title": "Efficient Discovery of Expressive Multi-label Rules using Relaxed\n  Pruning", "comments": "Preprint version. To appear in Proceedings of the 22nd International\n  Conference on Discovery Science, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being able to model correlations between labels is considered crucial in\nmulti-label classification. Rule-based models enable to expose such\ndependencies, e.g., implications, subsumptions, or exclusions, in an\ninterpretable and human-comprehensible manner. Albeit the number of possible\nlabel combinations increases exponentially with the number of available labels,\nit has been shown that rules with multiple labels in their heads, which are a\nnatural form to model local label dependencies, can be induced efficiently by\nexploiting certain properties of rule evaluation measures and pruning the label\nsearch space accordingly. However, experiments have revealed that multi-label\nheads are unlikely to be learned by existing methods due to their\nrestrictiveness. To overcome this limitation, we propose a plug-in approach\nthat relaxes the search space pruning used by existing methods in order to\nintroduce a bias towards larger multi-label heads resulting in more expressive\nrules. We further demonstrate the effectiveness of our approach empirically and\nshow that it does not come with drawbacks in terms of training time or\npredictive performance.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 15:22:23 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Klein", "Yannik", ""], ["Rapp", "Michael", ""], ["Menc\u00eda", "Eneldo Loza", ""]]}, {"id": "1908.06884", "submitter": "Hyo-Sang Shin PhD", "authors": "Hyo-Sang Shin, Shaoming He and Antonios Tsourdos", "title": "A Domain-Knowledge-Aided Deep Reinforcement Learning Approach for Flight\n  Control Design", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to examine the potential of using the emerging deep\nreinforcement learning techniques in flight control. Instead of learning from\nscratch, we suggest to leverage domain knowledge available in learning to\nimprove learning efficiency and generalisability. More specifically, the\nproposed approach fixes the autopilot structure as typical three-loop autopilot\nand deep reinforcement learning is utilised to learn the autopilot gains. To\nsolve the flight control problem, we then formulate a Markovian decision\nprocess with a proper reward function that enable the application of\nreinforcement learning theory. Another type of domain knowledge is exploited\nfor defining the reward function, by shaping reference inputs in consideration\nof important control objectives and using the shaped reference inputs in the\nreward function. The state-of-the-art deep deterministic policy gradient\nalgorithm is utilised to learn an action policy that maps the observed states\nto the autopilot gains. Extensive empirical numerical simulations are performed\nto validate the proposed computational control algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 15:41:33 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 14:52:13 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Shin", "Hyo-Sang", ""], ["He", "Shaoming", ""], ["Tsourdos", "Antonios", ""]]}, {"id": "1908.06886", "submitter": "Anton Muravev", "authors": "Anton Muravev, Jenni Raitoharju and Moncef Gabbouj", "title": "Neural Architecture Search by Estimation of Network Structure\n  Distributions", "comments": "16 pages, 4 figures, 3 tables", "journal-ref": "in IEEE Access, vol. 9, pp. 15304-15319, 2021", "doi": "10.1109/ACCESS.2021.3052996", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The influence of deep learning is continuously expanding across different\ndomains, and its new applications are ubiquitous. The question of neural\nnetwork design thus increases in importance, as traditional empirical\napproaches are reaching their limits. Manual design of network architectures\nfrom scratch relies heavily on trial and error, while using existing pretrained\nmodels can introduce redundancies or vulnerabilities. Automated neural\narchitecture design is able to overcome these problems, but the most successful\nalgorithms operate on significantly constrained design spaces, assuming the\ntarget network to consist of identical repeating blocks. While such approach\nallows for faster search, it does so at the cost of expressivity. We instead\npropose an alternative probabilistic representation of a whole neural network\nstructure under the assumption of independence between layer types. Our matrix\nof probabilities is equivalent to the population of models, but allows for\ndiscovery of structural irregularities, while being simple to interpret and\nanalyze. We construct an architecture search algorithm, inspired by the\nestimation of distribution algorithms, to take advantage of this\nrepresentation. The probability matrix is tuned towards generating\nhigh-performance models by repeatedly sampling the architectures and evaluating\nthe corresponding networks, while gradually increasing the model depth. Our\nalgorithm is shown to discover non-regular models which cannot be expressed via\nblocks, but are competitive both in accuracy and computational cost, while not\nutilizing complex dataflows or advanced training techniques, as well as\nremaining conceptually simple and highly extensible.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 15:43:22 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 14:26:33 GMT"}, {"version": "v3", "created": "Thu, 28 Jan 2021 16:01:20 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Muravev", "Anton", ""], ["Raitoharju", "Jenni", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "1908.06900", "submitter": "Mehrdad Saadatmand", "authors": "Mahshid Helali Moghadam, Mehrdad Saadatmand, Markus Borg, Markus\n  Bohlin, Bj\\\"orn Lisper", "title": "An Autonomous Performance Testing Framework using Self-Adaptive Fuzzy\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Test automation brings the potential to reduce costs and human effort, but\nseveral aspects of software testing remain challenging to automate. One such\nexample is automated performance testing to find performance breaking points.\nCurrent approaches to tackle automated generation of performance test cases\nmainly involve using source code or system model analysis or use-case based\ntechniques. However, source code and system models might not always be\navailable at testing time. On the other hand, if the optimal performance\ntesting policy for the intended objective in a testing process instead could be\nlearned by the testing system, then test automation without advanced\nperformance models could be possible. Furthermore, the learned policy could\nlater be reused for similar software systems under test, thus leading to higher\ntest efficiency. We propose SaFReL, a self-adaptive fuzzy reinforcement\nlearning-based performance testing framework. SaFReL learns the optimal policy\nto generate performance test cases through an initial learning phase, then\nreuses it during a transfer learning phase, while keeping the learning running\nand updating the policy in the long term. Through multiple experiments on a\nsimulated environment, we demonstrate that our approach generates the target\nperformance test cases for different programs more efficiently than a typical\ntesting process, and performs adaptively without access to source code and\nperformance models.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 16:00:35 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 22:29:44 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Moghadam", "Mahshid Helali", ""], ["Saadatmand", "Mehrdad", ""], ["Borg", "Markus", ""], ["Bohlin", "Markus", ""], ["Lisper", "Bj\u00f6rn", ""]]}, {"id": "1908.06917", "submitter": "Svitlana Vakulenko", "authors": "Svitlana Vakulenko, Javier David Fernandez Garcia, Axel Polleres,\n  Maarten de Rijke, Michael Cochez", "title": "Message Passing for Complex Question Answering over Knowledge Graphs", "comments": "Accepted in CIKM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering over knowledge graphs (KGQA) has evolved from simple\nsingle-fact questions to complex questions that require graph traversal and\naggregation. We propose a novel approach for complex KGQA that uses\nunsupervised message passing, which propagates confidence scores obtained by\nparsing an input question and matching terms in the knowledge graph to a set of\npossible answers. First, we identify entity, relationship, and class names\nmentioned in a natural language question, and map these to their counterparts\nin the graph. Then, the confidence scores of these mappings propagate through\nthe graph structure to locate the answer entities. Finally, these are\naggregated depending on the identified question type. This approach can be\nefficiently implemented as a series of sparse matrix multiplications mimicking\njoins over small local subgraphs. Our evaluation results show that the proposed\napproach outperforms the state-of-the-art on the LC-QuAD benchmark. Moreover,\nwe show that the performance of the approach depends only on the quality of the\nquestion interpretation results, i.e., given a correct relevance score\ndistribution, our approach always produces a correct answer ranking. Our error\nanalysis reveals correct answers missing from the benchmark dataset and\ninconsistencies in the DBpedia knowledge graph. Finally, we provide a\ncomprehensive evaluation of the proposed approach accompanied with an ablation\nstudy and an error analysis, which showcase the pitfalls for each of the\nquestion answering components in more detail.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 16:31:29 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Vakulenko", "Svitlana", ""], ["Garcia", "Javier David Fernandez", ""], ["Polleres", "Axel", ""], ["de Rijke", "Maarten", ""], ["Cochez", "Michael", ""]]}, {"id": "1908.06969", "submitter": "Eita Nakamura", "authors": "Eita Nakamura and Kazuyoshi Yoshii", "title": "Musical Rhythm Transcription Based on Bayesian Piece-Specific Score\n  Models Capturing Repetitions", "comments": "Title changed; change in organizations of sections; appendix added;\n  some explanations added; 14 pages, 9 figures (supplemental material: 11\n  pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most work on musical score models (a.k.a. musical language models) for music\ntranscription has focused on describing the local sequential dependence of\nnotes in musical scores and failed to capture their global repetitive\nstructure, which can be a useful guide for transcribing music. Focusing on\nrhythm, we formulate several classes of Bayesian Markov models of musical\nscores that describe repetitions indirectly using the sparse transition\nprobabilities of notes or note patterns. This enables us to construct\npiece-specific models for unseen scores with an unfixed repetitive structure\nand to derive tractable inference algorithms. Moreover, to describe approximate\nrepetitions, we explicitly incorporate a process for modifying the repeated\nnotes/note patterns. We apply these models as prior musical score models for\nrhythm transcription, where piece-specific score models are inferred from\nperformed MIDI data by Bayesian learning, in contrast to the conventional\nsupervised construction of score models. Evaluations using the vocal melodies\nof popular music showed that the Bayesian models improved the transcription\naccuracy for most of the tested model types, indicating the universal efficacy\nof the proposed approach. Moreover, we found an effective data representation\nfor modelling rhythms that maximizes the transcription accuracy and\ncomputational efficiency.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 14:26:59 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 18:27:17 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Nakamura", "Eita", ""], ["Yoshii", "Kazuyoshi", ""]]}, {"id": "1908.06973", "submitter": "Yuxi Li", "authors": "Yuxi Li", "title": "Reinforcement Learning Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We start with a brief introduction to reinforcement learning (RL), about its\nsuccessful stories, basics, an example, issues, the ICML 2019 Workshop on RL\nfor Real Life, how to use it, study material and an outlook. Then we discuss a\nselection of RL applications, including recommender systems, computer systems,\nenergy, finance, healthcare, robotics, and transportation.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 09:47:22 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Li", "Yuxi", ""]]}, {"id": "1908.06976", "submitter": "Arthur Aubret", "authors": "Arthur Aubret, Laetitia Matignon, Salima Hassas", "title": "A survey on intrinsic motivation in reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reinforcement learning (RL) research area is very active, with an\nimportant number of new contributions; especially considering the emergent\nfield of deep RL (DRL). However a number of scientific and technical challenges\nstill need to be addressed, amongst which we can mention the ability to\nabstract actions or the difficulty to explore the environment which can be\naddressed by intrinsic motivation (IM). In this article, we provide a survey on\nthe role of intrinsic motivation in DRL. We categorize the different kinds of\nintrinsic motivations and detail for each category, its advantages and\nlimitations with respect to the mentioned challenges. Additionnally, we conduct\nan in-depth investigation of substantial current research questions, that are\ncurrently under study or not addressed at all in the considered research area\nof DRL. We choose to survey these research works, from the perspective of\nlearning how to achieve tasks. We suggest then, that solving current challenges\ncould lead to a larger developmental architecture which may tackle most of the\ntasks. We describe this developmental architecture on the basis of several\nbuilding blocks composed of a RL algorithm and an IM module compressing\ninformation.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 16:22:20 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 14:40:14 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Aubret", "Arthur", ""], ["Matignon", "Laetitia", ""], ["Hassas", "Salima", ""]]}, {"id": "1908.07031", "submitter": "Weipeng Huang", "authors": "Weipeng Huang, Guangyuan Piao, Raul Moreno, Neil J. Hurley", "title": "Partially Observable Markov Decision Process Modelling for Assessing\n  Hierarchies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical clustering has been shown to be valuable in many scenarios.\nDespite its usefulness to many situations, there is no agreed methodology on\nhow to properly evaluate the hierarchies produced from different techniques,\nparticularly in the case where ground-truth labels are unavailable. This\nmotivates us to propose a framework for assessing the quality of hierarchical\nclustering allocations which covers the case of no ground-truth information.\nThis measurement is useful, e.g., to assess the hierarchical structures used by\nonline retailer websites to display their product catalogues. Our framework is\none of the few attempts for the hierarchy evaluation from a decision-theoretic\nperspective. We model the process as a bot searching stochastically for items\nin the hierarchy and establish a measure representing the degree to which the\nhierarchy supports this search. We employ Partially Observable Markov Decision\nProcesses (POMDP) to model the uncertainty, the decision making, and the\ncognitive return for searchers in such a scenario.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 19:13:27 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 13:56:23 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 17:20:36 GMT"}, {"version": "v4", "created": "Tue, 30 Jun 2020 01:31:59 GMT"}, {"version": "v5", "created": "Tue, 13 Oct 2020 20:35:41 GMT"}, {"version": "v6", "created": "Wed, 4 Nov 2020 13:28:16 GMT"}, {"version": "v7", "created": "Tue, 8 Dec 2020 09:07:39 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Huang", "Weipeng", ""], ["Piao", "Guangyuan", ""], ["Moreno", "Raul", ""], ["Hurley", "Neil J.", ""]]}, {"id": "1908.07064", "submitter": "Praveen Kumar Bodigutla", "authors": "Praveen Kumar Bodigutla, Longshaokan Wang, Kate Ridgeway, Joshua Levy,\n  Swanand Joshi, Alborz Geramifard, Spyros Matsoukas", "title": "Domain-Independent turn-level Dialogue Quality Evaluation via User\n  Satisfaction Estimation", "comments": "Implications of Deep Learning for Dialog Modeling - Special session\n  at SIGdial 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An automated metric to evaluate dialogue quality is vital for optimizing data\ndriven dialogue management. The common approach of relying on explicit user\nfeedback during a conversation is intrusive and sparse. Current models to\nestimate user satisfaction use limited feature sets and rely on annotation\nschemes with low inter-rater reliability, limiting generalizability to\nconversations spanning multiple domains. To address these gaps, we created a\nnew Response Quality annotation scheme, based on which we developed turn-level\nUser Satisfaction metric. We introduced five new domain-independent feature\nsets and experimented with six machine learning models to estimate the new\nsatisfaction metric.\n  Using Response Quality annotation scheme, across randomly sampled single and\nmulti-turn conversations from 26 domains, we achieved high inter-annotator\nagreement (Spearman's rho 0.94). The Response Quality labels were highly\ncorrelated (0.76) with explicit turn-level user ratings. Gradient boosting\nregression achieved best correlation of ~0.79 between predicted and annotated\nuser satisfaction labels. Multi Layer Perceptron and Gradient Boosting\nregression models generalized to an unseen domain better (linear correlation\n0.67) than other models. Finally, our ablation study verified that our novel\nfeatures significantly improved model performance.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 20:58:24 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Bodigutla", "Praveen Kumar", ""], ["Wang", "Longshaokan", ""], ["Ridgeway", "Kate", ""], ["Levy", "Joshua", ""], ["Joshi", "Swanand", ""], ["Geramifard", "Alborz", ""], ["Matsoukas", "Spyros", ""]]}, {"id": "1908.07088", "submitter": "Ethan Gordon", "authors": "Ethan K. Gordon, Xiang Meng, Matt Barnes, Tapomayukh Bhattacharjee,\n  Siddhartha S. Srinivasa", "title": "Adaptive Robot-Assisted Feeding: An Online Learning Framework for\n  Acquiring Previously Unseen Food Items", "comments": "To appear in IROS 2020; 8 pages incl. references, 8 figures; Abstract\n  presented in IJCAI 2019 AIxFood Workshop; v3: Added simulation and\n  experimental results for conference submission; v4: Added extra results to\n  Experiment 2 for camera-ready submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A successful robot-assisted feeding system requires bite acquisition of a\nwide variety of food items. It must adapt to changing user food preferences\nunder uncertain visual and physical environments. Different food items in\ndifferent environmental conditions require different manipulation strategies\nfor successful bite acquisition. Therefore, a key challenge is how to handle\npreviously unseen food items with very different success rate distributions\nover strategy. Combining low-level controllers and planners into discrete\naction trajectories, we show that the problem can be represented using a linear\ncontextual bandit setting. We construct a simulated environment using a doubly\nrobust loss estimate from previously seen food items, which we use to tune the\nparameters of off-the-shelf contextual bandit algorithms. Finally, we\ndemonstrate empirically on a robot-assisted feeding system that, even starting\nwith a model trained on thousands of skewering attempts on dissimilar\npreviously seen food items, $\\epsilon$-greedy and LinUCB algorithms can quickly\nconverge to the most successful manipulation strategy.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 22:36:45 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 19:38:07 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 22:48:32 GMT"}, {"version": "v4", "created": "Sat, 1 Aug 2020 00:47:21 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Gordon", "Ethan K.", ""], ["Meng", "Xiang", ""], ["Barnes", "Matt", ""], ["Bhattacharjee", "Tapomayukh", ""], ["Srinivasa", "Siddhartha S.", ""]]}, {"id": "1908.07121", "submitter": "Chengchao Shen", "authors": "Chengchao Shen, Mengqi Xue, Xinchao Wang, Jie Song, Li Sun, Mingli\n  Song", "title": "Customizing Student Networks From Heterogeneous Teachers via Adaptive\n  Knowledge Amalgamation", "comments": "Accepted to ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A massive number of well-trained deep networks have been released by\ndevelopers online. These networks may focus on different tasks and in many\ncases are optimized for different datasets. In this paper, we study how to\nexploit such heterogeneous pre-trained networks, known as teachers, so as to\ntrain a customized student network that tackles a set of selective tasks\ndefined by the user. We assume no human annotations are available, and each\nteacher may be either single- or multi-task. To this end, we introduce a\ndual-step strategy that first extracts the task-specific knowledge from the\nheterogeneous teachers sharing the same sub-task, and then amalgamates the\nextracted knowledge to build the student network. To facilitate the training,\nwe employ a selective learning scheme where, for each unlabelled sample, the\nstudent learns adaptively from only the teacher with the least prediction\nambiguity. We evaluate the proposed approach on several datasets and\nexperimental results demonstrate that the student, learned by such adaptive\nknowledge amalgamation, achieves performances even better than those of the\nteachers.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 01:13:26 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Shen", "Chengchao", ""], ["Xue", "Mengqi", ""], ["Wang", "Xinchao", ""], ["Song", "Jie", ""], ["Sun", "Li", ""], ["Song", "Mingli", ""]]}, {"id": "1908.07137", "submitter": "Feng Ji", "authors": "Shuke Peng, Xinjing Huang, Zehao Lin, Feng Ji, Haiqing Chen and Yin\n  Zhang", "title": "Teacher-Student Framework Enhanced Multi-domain Dialogue Generation", "comments": "Official Version: arXiv:2005.10450", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue systems dealing with multi-domain tasks are highly required. How to\nrecord the state remains a key problem in a task-oriented dialogue system.\nNormally we use human-defined features as dialogue states and apply a state\ntracker to extract these features. However, the performance of such a system is\nlimited by the error propagation of a state tracker. In this paper, we propose\na dialogue generation model that needs no external state trackers and still\nbenefits from human-labeled semantic data. By using a teacher-student\nframework, several teacher models are firstly trained in their individual\ndomains, learn dialogue policies from labeled states. And then the learned\nknowledge and experience are merged and transferred to a universal student\nmodel, which takes raw utterance as its input. Experiments show that the\ndialogue system trained under our framework outperforms the one uses a belief\ntracker.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 02:59:37 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 11:18:18 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Peng", "Shuke", ""], ["Huang", "Xinjing", ""], ["Lin", "Zehao", ""], ["Ji", "Feng", ""], ["Chen", "Haiqing", ""], ["Zhang", "Yin", ""]]}, {"id": "1908.07141", "submitter": "Mojtaba Nayyeri", "authors": "Mojtaba Nayyeri, Chengjin Xu, Jens Lehmann, Hamed Shariat Yazdi", "title": "LogicENN: A Neural Based Knowledge Graphs Embedding Model with Logical\n  Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph embedding models have gained significant attention in AI\nresearch. Recent works have shown that the inclusion of background knowledge,\nsuch as logical rules, can improve the performance of embeddings in downstream\nmachine learning tasks. However, so far, most existing models do not allow the\ninclusion of rules. We address the challenge of including rules and present a\nnew neural based embedding model (LogicENN). We prove that LogicENN can learn\nevery ground truth of encoded rules in a knowledge graph. To the best of our\nknowledge, this has not been proved so far for the neural based family of\nembedding models. Moreover, we derive formulae for the inclusion of various\nrules, including (anti-)symmetric, inverse, irreflexive and transitive,\nimplication, composition, equivalence and negation. Our formulation allows to\navoid grounding for implication and equivalence relations. Our experiments show\nthat LogicENN outperforms the state-of-the-art models in link prediction.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 03:12:13 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Nayyeri", "Mojtaba", ""], ["Xu", "Chengjin", ""], ["Lehmann", "Jens", ""], ["Yazdi", "Hamed Shariat", ""]]}, {"id": "1908.07281", "submitter": "Sameh K. Mohamed", "authors": "Sameh K. Mohamed", "title": "Unsupervised Hierarchical Grouping of Knowledge Graph Entities", "comments": "10 pages - LASCAR@ESWC'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Knowledge graphs have attracted lots of attention in academic and industrial\nenvironments. Despite their usefulness, popular knowledge graphs suffer from\nincompleteness of information, especially in their type assertions. This has\nencouraged research in the automatic discovery of entity types. In this\ncontext, multiple works were developed to utilize logical inference on\nontologies and statistical machine learning methods to learn type assertion in\nknowledge graphs. However, these approaches suffer from limited performance on\nnoisy data, limited scalability and the dependence on labeled training samples.\nIn this work, we propose a new unsupervised approach that learns to categorize\nentities into a hierarchy of named groups. We show that our approach is able to\neffectively learn entity groups using a scalable procedure in noisy and sparse\ndatasets. We experiment our approach on a set of popular knowledge graph\nbenchmarking datasets, and we publish a collection of the outcome group\nhierarchies.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 11:40:16 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Mohamed", "Sameh K.", ""]]}, {"id": "1908.07319", "submitter": "Hassan Ismail Fawaz", "authors": "Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber, Lhassane\n  Idoumghar, Pierre-Alain Muller", "title": "Accurate and interpretable evaluation of surgical skills from kinematic\n  data using fully convolutional neural networks", "comments": "Accepted at IJCARS Special Issue for MICCAI 2018", "journal-ref": null, "doi": "10.1007/s11548-019-02039-4", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: Manual feedback from senior surgeons observing less experienced\ntrainees is a laborious task that is very expensive, time-consuming and prone\nto subjectivity. With the number of surgical procedures increasing annually,\nthere is an unprecedented need to provide an accurate, objective and automatic\nevaluation of trainees' surgical skills in order to improve surgical practice.\nMethods: In this paper, we designed a convolutional neural network (CNN) to\nclassify surgical skills by extracting latent patterns in the trainees' motions\nperformed during robotic surgery. The method is validated on the JIGSAWS\ndataset for two surgical skills evaluation tasks: classification and\nregression. Results: Our results show that deep neural networks constitute\nrobust machine learning models that are able to reach new competitive\nstate-of-the-art performance on the JIGSAWS dataset. While we leveraged from\nCNNs' efficiency, we were able to minimize its black-box effect using the class\nactivation map technique. Conclusions: This characteristic allowed our method\nto automatically pinpoint which parts of the surgery influenced the skill\nevaluation the most, thus allowing us to explain a surgical skill\nclassification and provide surgeons with a novel personalized feedback\ntechnique. We believe this type of interpretable machine learning model could\nintegrate within \"Operation Room 2.0\" and support novice surgeons in improving\ntheir skills to eventually become experts.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 13:04:05 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Fawaz", "Hassan Ismail", ""], ["Forestier", "Germain", ""], ["Weber", "Jonathan", ""], ["Idoumghar", "Lhassane", ""], ["Muller", "Pierre-Alain", ""]]}, {"id": "1908.07446", "submitter": "Alex Gomez-Marin", "authors": "Regina Zaghi-Lara, Miguel \\'Angel Gea, Jordi Cam\\'i, Luis M.\n  Mart\\'inez, Alex Gomez-Marin", "title": "Playing magic tricks to deep neural networks untangles human deception", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.CV", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Magic is the art of producing in the spectator an illusion of impossibility.\nAlthough the scientific study of magic is in its infancy, the advent of recent\ntracking algorithms based on deep learning allow now to quantify the skills of\nthe magician in naturalistic conditions at unprecedented resolution and\nrobustness. In this study, we deconstructed stage magic into purely motor\nmaneuvers and trained an artificial neural network (DeepLabCut) to follow coins\nas a professional magician made them appear and disappear in a series of\ntricks. Rather than using AI as a mere tracking tool, we conceived it as an\n\"artificial spectator\". When the coins were not visible, the algorithm was\ntrained to infer their location as a human spectator would (i.e. in the left\nfist). This created situations where the human was fooled while AI (as seen by\na human) was not, and vice versa. Magic from the perspective of the machine\nreveals our own cognitive biases.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 15:50:11 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Zaghi-Lara", "Regina", ""], ["Gea", "Miguel \u00c1ngel", ""], ["Cam\u00ed", "Jordi", ""], ["Mart\u00ednez", "Luis M.", ""], ["Gomez-Marin", "Alex", ""]]}, {"id": "1908.07587", "submitter": "Songwei Ge", "authors": "Songwei Ge, Austin Dill, Eunsu Kang, Chun-Liang Li, Lingyao Zhang,\n  Manzil Zaheer, Barnabas Poczos", "title": "Developing Creative AI to Generate Sculptural Objects", "comments": "In the Proceedings of International Symposium on Electronic Art (ISEA\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the intersection of human and machine creativity by generating\nsculptural objects through machine learning. This research raises questions\nabout both the technical details of automatic art generation and the\ninteraction between AI and people, as both artists and the audience of art. We\nintroduce two algorithms for generating 3D point clouds and then discuss their\nactualization as sculpture and incorporation into a holistic art installation.\nSpecifically, the Amalgamated DeepDream (ADD) algorithm solves the sparsity\nproblem caused by the naive DeepDream-inspired approach and generates creative\nand printable point clouds. The Partitioned DeepDream (PDD) algorithm further\nallows us to explore more diverse 3D object creation by combining point cloud\nclustering algorithms and ADD.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 20:00:25 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Ge", "Songwei", ""], ["Dill", "Austin", ""], ["Kang", "Eunsu", ""], ["Li", "Chun-Liang", ""], ["Zhang", "Lingyao", ""], ["Zaheer", "Manzil", ""], ["Poczos", "Barnabas", ""]]}, {"id": "1908.07613", "submitter": "Jaime Sevilla", "authors": "Jaime Sevilla and Pablo Moreno", "title": "Implications of Quantum Computing for Artificial Intelligence alignment\n  research", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We explain some key features of quantum computing via three heuristics and\napply them to argue that a deep understanding of quantum computing is unlikely\nto be helpful to address current bottlenecks in Artificial Intelligence\nAlignment. Our argument relies on the claims that Quantum Computing leads to\ncompute overhang instead of algorithmic overhang, and that the difficulties\nassociated with the measurement of quantum states do not invalidate any major\nassumptions of current Artificial Intelligence Alignment research agendas. We\nalso discuss tripwiring, adversarial blinding, informed oversight and side\neffects as possible exceptions.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 17:53:34 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 14:43:44 GMT"}, {"version": "v3", "created": "Sat, 24 Aug 2019 14:19:04 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Sevilla", "Jaime", ""], ["Moreno", "Pablo", ""]]}, {"id": "1908.07617", "submitter": "Mauricio Gonzalez-Soto", "authors": "Mauricio Gonzalez-Soto and Felipe Orihuela Espina", "title": "Reinforcement Learning is not a Causal problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use an analogy between non-isomorphic mathematical structures defined over\nthe same set and the algebras induced by associative and causal levels of\ninformation in order to argue that Reinforcement Learning, in its current\nformulation, is not a causal problem, independently if the motivation behind it\nhas to do with an agent taking actions.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 21:30:13 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 12:16:45 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Gonzalez-Soto", "Mauricio", ""], ["Espina", "Felipe Orihuela", ""]]}, {"id": "1908.07630", "submitter": "Parijat Dube", "authors": "Bishwaranjan Bhattacharjee, John R. Kender, Matthew Hill, Parijat\n  Dube, Siyu Huo, Michael R. Glass, Brian Belgodere, Sharath Pankanti, Noel\n  Codella, Patrick Watson", "title": "P2L: Predicting Transfer Learning for Images and Semantic Relations", "comments": "10 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning enhances learning across tasks, by leveraging previously\nlearned representations -- if they are properly chosen. We describe an\nefficient method to accurately estimate the appropriateness of a previously\ntrained model for use in a new learning task. We use this measure, which we\ncall \"Predict To Learn\" (\"P2L\"), in the two very different domains of images\nand semantic relations, where it predicts, from a set of \"source\" models, the\none model most likely to produce effective transfer for training a given\n\"target\" model. We validate our approach thoroughly, by assembling a collection\nof candidate source models, then fine-tuning each candidate to perform each of\na collection of target tasks, and finally measuring how well transfer has been\nenhanced. Across 95 tasks within multiple domains (images classification and\nsemantic relations), the P2L approach was able to select the best transfer\nlearning model on average, while the heuristic of choosing model trained with\nthe largest data set selected the best model in only 55 cases. These results\nsuggest that P2L captures important information in common between source and\ntarget tasks, and that this shared informational structure contributes to\nsuccessful transfer learning more than simple data size.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 22:09:40 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 20:08:59 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Bhattacharjee", "Bishwaranjan", ""], ["Kender", "John R.", ""], ["Hill", "Matthew", ""], ["Dube", "Parijat", ""], ["Huo", "Siyu", ""], ["Glass", "Michael R.", ""], ["Belgodere", "Brian", ""], ["Pankanti", "Sharath", ""], ["Codella", "Noel", ""], ["Watson", "Patrick", ""]]}, {"id": "1908.07651", "submitter": "Tajul Rosli Razak Mr", "authors": "Tajul Rosli Razak", "title": "An Expert System Approach for determine the stage of UiTM Perlis Palapes\n  Cadet Performance and Ranking Selection", "comments": null, "journal-ref": "Journal of Computer Science & Computational Mathematics (2012)", "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The palapes cadets are one of the uniform organizations in UiTM Perlis for\nextra-curricular activities. The palapes cadets arrange their organization in a\nhierarchy according to grade. Senior uniform officer (SUO) is the highest rank,\nfollowed by a junior uniform officer (JUO), sergeant, corporal, lance corporal,\nand lastly, cadet officer, which is the lowest rank. The palapes organization\nhas several methods to measure performance toward promotion to a higher rank,\nwhether individual performance or in a group. Cadets are selected for promotion\nbased on demonstrated leadership abilities, acquired skills, physical fitness,\nand comprehension of information as measured through standardized testing.\nHowever, this method is too complicated when manually assessed by a trainer or\ncoach. Therefore, this study will propose an expert system, which is one of the\nartificial intelligence techniques that can recognize the readiness and\nprogression of a palapes cadet.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 05:46:53 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Razak", "Tajul Rosli", ""]]}, {"id": "1908.07784", "submitter": "Carlo Taticchi", "authors": "Stafano Bistarelli, Francesco Faloci and Carlo Taticchi", "title": "Implementing Ranking-Based Semantics in ConArg: a Preliminary Report", "comments": "10 pages, 10 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ConArg is a suite of tools that offers a wide series of applications for\ndealing with argumentation problems. In this work, we present the advances we\nmade in implementing a ranking-based semantics, based on computational choice\npower indexes, within ConArg. Such kind of semantics represents a method for\nsorting the arguments of an abstract argumentation framework, according to some\npreference relation. The ranking-based semantics we implement relies on\nShapley, Banzhaf, Deegan-Packel and Johnston power index, transferring well\nknow properties from computational social choice to argumentation framework\nranking-based semantics.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 10:42:19 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 17:23:11 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Bistarelli", "Stafano", ""], ["Faloci", "Francesco", ""], ["Taticchi", "Carlo", ""]]}, {"id": "1908.07795", "submitter": "Yichun Yin", "authors": "Yichun Yin, Lifeng Shang, Xin Jiang, Xiao Chen, Qun Liu", "title": "Dialog State Tracking with Reinforced Data Augmentation", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural dialog state trackers are generally limited due to the lack of\nquantity and diversity of annotated training data. In this paper, we address\nthis difficulty by proposing a reinforcement learning (RL) based framework for\ndata augmentation that can generate high-quality data to improve the neural\nstate tracker. Specifically, we introduce a novel contextual bandit generator\nto learn fine-grained augmentation policies that can generate new effective\ninstances by choosing suitable replacements for the specific context. Moreover,\nby alternately learning between the generator and the state tracker, we can\nkeep refining the generative policies to generate more high-quality training\ndata for neural state tracker. Experimental results on the WoZ and MultiWoZ\n(restaurant) datasets demonstrate that the proposed framework significantly\nimproves the performance over the state-of-the-art models, especially with\nlimited training data.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 11:07:14 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 03:21:21 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Yin", "Yichun", ""], ["Shang", "Lifeng", ""], ["Jiang", "Xin", ""], ["Chen", "Xiao", ""], ["Liu", "Qun", ""]]}, {"id": "1908.07816", "submitter": "Yubo Xie", "authors": "Yubo Xie, Ekaterina Svikhnushina, Pearl Pu", "title": "A Multi-Turn Emotionally Engaging Dialog Model", "comments": "Accepted to IUI 2020 user2agent workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-domain dialog systems (also known as chatbots) have increasingly drawn\nattention in natural language processing. Some of the recent work aims at\nincorporating affect information into sequence-to-sequence neural dialog\nmodeling, making the response emotionally richer, while others use hand-crafted\nrules to determine the desired emotion response. However, they do not\nexplicitly learn the subtle emotional interactions captured in human dialogs.\nIn this paper, we propose a multi-turn dialog system aimed at learning and\ngenerating emotional responses that so far only humans know how to do. Compared\nwith two baseline models, offline experiments show that our method performs the\nbest in perplexity scores. Further human evaluations confirm that our chatbot\ncan keep track of the conversation context and generate emotionally more\nappropriate responses while performing equally well on grammar.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 12:52:53 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 17:00:07 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 16:30:45 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Xie", "Yubo", ""], ["Svikhnushina", "Ekaterina", ""], ["Pu", "Pearl", ""]]}, {"id": "1908.07822", "submitter": "Shining Liang", "authors": "Shining Liang, Wanli Zuo, Zhenkun Shi, Sen Wang, Junhu Wang, Xianglin\n  Zuo", "title": "A Multi-level Neural Network for Implicit Causality Detection in Web\n  Texts", "comments": "31 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Mining causality from text is a complex and crucial natural language\nunderstanding task corresponding to the human cognition. Existing studies at\nits solution can be grouped into two primary categories: feature engineering\nbased and neural model based methods. In this paper, we find that the former\nhas incomplete coverage and inherent errors but provide prior knowledge; while\nthe latter leverages context information but causal inference of which is\ninsufficiency. To handle the limitations, we propose a novel causality\ndetection model named MCDN to explicitly model causal reasoning process, and\nfurthermore, to exploit the advantages of both methods. Specifically, we adopt\nmulti-head self-attention to acquire semantic feature at word level and develop\nthe SCRN to infer causality at segment level. To the best of our knowledge,\nwith regards to the causality tasks, this is the first time that the Relation\nNetwork is applied. The experimental results show that: 1) the proposed\napproach performs prominent performance on causality detection; 2) further\nanalysis manifests the effectiveness and robustness of MCDN.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 10:34:59 GMT"}, {"version": "v2", "created": "Sun, 8 Sep 2019 02:29:09 GMT"}, {"version": "v3", "created": "Thu, 27 May 2021 16:33:15 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Liang", "Shining", ""], ["Zuo", "Wanli", ""], ["Shi", "Zhenkun", ""], ["Wang", "Sen", ""], ["Wang", "Junhu", ""], ["Zuo", "Xianglin", ""]]}, {"id": "1908.07827", "submitter": "Suttinee Sawadsitang", "authors": "Suttinee Sawadsitang, Dusit Niyato, Kongrath Suankaewmanee, Puay Siew\n  Tan", "title": "Re-route Package Pickup and Delivery Planning with Random Demands", "comments": "6 pages, 4 figures, 2 tables", "journal-ref": "2019 IEEE 90th Vehicular Technology Conference: VTC2019-Fall", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a higher competition in logistics business introduces new\nchallenges to the vehicle routing problem (VRP). Re-route planning, also known\nas dynamic VRP, is one of the important challenges. The re-route planning has\nto be performed when new customers request for deliveries while the delivery\nvehicles, i.e., trucks, are serving other customers. While the re-route\nplanning has been studied in the literature, most of the existing works do not\nconsider different uncertainties. Therefore, in this paper, we propose two\nsystems, i.e., (i) an offline package pickup and delivery planning with\nstochastic demands (PDPSD) and (ii) a re-route package pickup and delivery\nplanning with stochastic demands (Re-route PDPSD). Accordingly, we formulate\nthe PDPSD system as a two-stage stochastic optimization. We then extend the\nPDPSD system to the Re-route PDPSD system with a re-route algorithm.\nFurthermore, we evaluate performance of the proposed systems by using the\ndataset from Solomon Benchmark suite and a real data from a Singapore logistics\n1company. The results show that the PDPSD system can achieve the lower cost\nthan that of the baseline model. In addition, the Re-route PDPSD system can\nhelp the supplier efficiently and successfully to serve more customers while\nthe trucks are already on the road.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 05:40:00 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Sawadsitang", "Suttinee", ""], ["Niyato", "Dusit", ""], ["Suankaewmanee", "Kongrath", ""], ["Tan", "Puay Siew", ""]]}, {"id": "1908.07846", "submitter": "Stephen Petrie Dr", "authors": "Stephen M. Petrie and T'Mir D. Julius", "title": "Representing text as abstract images enables image classifiers to also\n  simultaneously classify text", "comments": "Minor changes in order to submit paper to a different conference\n  (e.g. made minor changes to writing in several places and added extra data to\n  Table 3 in order to make it clearer)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel method for converting text data into abstract image\nrepresentations, which allows image-based processing techniques (e.g. image\nclassification networks) to be applied to text-based comparison problems. We\napply the technique to entity disambiguation of inventor names in US patents.\nThe method involves converting text from each pairwise comparison between two\ninventor name records into a 2D RGB (stacked) image representation. We then\ntrain an image classification neural network to discriminate between such\npairwise comparison images, and use the trained network to label each pair of\nrecords as either matched (same inventor) or non-matched (different inventors),\nobtaining highly accurate results. Our new text-to-image representation method\ncould also be used more broadly for other NLP comparison problems, such as\ndisambiguation of academic publications, or for problems that require\nsimultaneous classification of both text and image datasets.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 17:28:29 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 08:39:41 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2020 07:28:03 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Petrie", "Stephen M.", ""], ["Julius", "T'Mir D.", ""]]}, {"id": "1908.07912", "submitter": "Preslav Nakov", "authors": "Slavena Vasileva, Pepa Atanasova, Llu\\'is M\\`arquez, Alberto\n  Barr\\'on-Cede\\~no, Preslav Nakov", "title": "It Takes Nine to Smell a Rat: Neural Multi-Task Learning for\n  Check-Worthiness Prediction", "comments": "Check-worthiness; Fact-Checking; Veracity; Multi-task Learning;\n  Neural Networks. arXiv admin note: text overlap with arXiv:1908.01328", "journal-ref": "RANLP-2019", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a multi-task deep-learning approach for estimating the\ncheck-worthiness of claims in political debates. Given a political debate, such\nas the 2016 US Presidential and Vice-Presidential ones, the task is to predict\nwhich statements in the debate should be prioritized for fact-checking. While\ndifferent fact-checking organizations would naturally make different choices\nwhen analyzing the same debate, we show that it pays to learn from multiple\nsources simultaneously (PolitiFact, FactCheck, ABC, CNN, NPR, NYT, Chicago\nTribune, The Guardian, and Washington Post) in a multi-task learning setup,\neven when a particular source is chosen as a target to imitate. Our evaluation\nshows state-of-the-art results on a standard dataset for the task of\ncheck-worthiness prediction.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 19:52:50 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Vasileva", "Slavena", ""], ["Atanasova", "Pepa", ""], ["M\u00e0rquez", "Llu\u00eds", ""], ["Barr\u00f3n-Cede\u00f1o", "Alberto", ""], ["Nakov", "Preslav", ""]]}, {"id": "1908.07931", "submitter": "Marko Ilievski", "authors": "Marko Ilievski, Sean Sedwards, Ashish Gaurav, Aravind Balakrishnan,\n  Atrisha Sarkar, Jaeyoung Lee, Fr\\'ed\\'eric Bouchard, Ryan De Iaco, and\n  Krzysztof Czarnecki", "title": "Design Space of Behaviour Planning for Autonomous Driving", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the complex design space of behaviour planning for autonomous\ndriving. Design choices that successfully address one aspect of behaviour\nplanning can critically constrain others. To aid the design process, in this\nwork we decompose the design space with respect to important choices arising\nfrom the current state of the art approaches, and describe the resulting\ntrade-offs. In doing this, we also identify interesting directions of future\nwork.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 15:39:51 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Ilievski", "Marko", ""], ["Sedwards", "Sean", ""], ["Gaurav", "Ashish", ""], ["Balakrishnan", "Aravind", ""], ["Sarkar", "Atrisha", ""], ["Lee", "Jaeyoung", ""], ["Bouchard", "Fr\u00e9d\u00e9ric", ""], ["De Iaco", "Ryan", ""], ["Czarnecki", "Krzysztof", ""]]}, {"id": "1908.07999", "submitter": "Raehyun Kim", "authors": "Raehyun Kim, Chan Ho So, Minbyul Jeong, Sanghoon Lee, Jinkyu Kim,\n  Jaewoo Kang", "title": "HATS: A Hierarchical Graph Attention Network for Stock Movement\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many researchers both in academia and industry have long been interested in\nthe stock market. Numerous approaches were developed to accurately predict\nfuture trends in stock prices. Recently, there has been a growing interest in\nutilizing graph-structured data in computer science research communities.\nMethods that use relational data for stock market prediction have been recently\nproposed, but they are still in their infancy. First, the quality of collected\ninformation from different types of relations can vary considerably. No\nexisting work has focused on the effect of using different types of relations\non stock market prediction or finding an effective way to selectively aggregate\ninformation on different relation types. Furthermore, existing works have\nfocused on only individual stock prediction which is similar to the node\nclassification task. To address this, we propose a hierarchical attention\nnetwork for stock prediction (HATS) which uses relational data for stock market\nprediction. Our HATS method selectively aggregates information on different\nrelation types and adds the information to the representations of each company.\nSpecifically, node representations are initialized with features extracted from\na feature extraction module. HATS is used as a relational modeling module with\ninitialized node representations. Then, node representations with the added\ninformation are fed into a task-specific layer. Our method is used for\npredicting not only individual stock prices but also market index movements,\nwhich is similar to the graph classification task. The experimental results\nshow that performance can change depending on the relational data used. HATS\nwhich can automatically select information outperformed all the existing\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 07:29:52 GMT"}, {"version": "v2", "created": "Sat, 24 Aug 2019 06:50:04 GMT"}, {"version": "v3", "created": "Tue, 12 Nov 2019 08:10:06 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Kim", "Raehyun", ""], ["So", "Chan Ho", ""], ["Jeong", "Minbyul", ""], ["Lee", "Sanghoon", ""], ["Kim", "Jinkyu", ""], ["Kang", "Jaewoo", ""]]}, {"id": "1908.08007", "submitter": "Aleem Akhtar Asif", "authors": "Aleem Akhtar", "title": "Evolution of Ant Colony Optimization Algorithm -- A Brief Literature\n  Review", "comments": "11 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ant Colony Optimization (ACO) is a metaheuristic proposed by Marco Dorigo in\n1991 based on behavior of biological ants. Pheromone laying and selection of\nshortest route with the help of pheromone inspired development of first ACO\nalgorithm. Since, presentation of first such algorithm, many researchers have\nworked and published their research in this field. Though initial results were\nnot so promising but recent developments have made this metaheuristic a\nsignificant algorithm in Swarm Intelligence. This research presents a brief\noverview of recent developments carried out in ACO algorithms in terms of both\napplications and algorithmic developments. For application developments,\nmulti-objective optimization, continuous optimization and time-varying NP-hard\nproblems have been presented. While to review articles based on algorithmic\ndevelopment, hybridization and parallel architectures have been investigated.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 07:42:49 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 14:54:21 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Akhtar", "Aleem", ""]]}, {"id": "1908.08018", "submitter": "Jesus L. Lobo", "authors": "Jesus L. Lobo, Izaskun Oregi, Albert Bifet, Javier Del Ser", "title": "Exploiting a Stimuli Encoding Scheme of Spiking Neural Networks for\n  Stream Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stream data processing has gained progressive momentum with the arriving of\nnew stream applications and big data scenarios. One of the most promising\ntechniques in stream learning is the Spiking Neural Network, and some of them\nuse an interesting population encoding scheme to transform the incoming stimuli\ninto spikes. This study sheds lights on the key issue of this encoding scheme,\nthe Gaussian receptive fields, and focuses on applying them as a pre-processing\ntechnique to any dataset in order to gain representativeness, and to boost the\npredictive performance of the stream learning methods. Experiments with\nsynthetic and real data sets are presented, and lead to confirm that our\napproach can be applied successfully as a general pre-processing technique in\nmany real cases.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 09:48:50 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Lobo", "Jesus L.", ""], ["Oregi", "Izaskun", ""], ["Bifet", "Albert", ""], ["Del Ser", "Javier", ""]]}, {"id": "1908.08019", "submitter": "Jesus L. Lobo", "authors": "Jesus L. Lobo, Javier Del Ser, Albert Bifet, Nikola Kasabov", "title": "Spiking Neural Networks and Online Learning: An Overview and\n  Perspectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications that generate huge amounts of data in the form of fast streams\nare becoming increasingly prevalent, being therefore necessary to learn in an\nonline manner. These conditions usually impose memory and processing time\nrestrictions, and they often turn into evolving environments where a change may\naffect the input data distribution. Such a change causes that predictive models\ntrained over these stream data become obsolete and do not adapt suitably to new\ndistributions. Specially in these non-stationary scenarios, there is a pressing\nneed for new algorithms that adapt to these changes as fast as possible, while\nmaintaining good performance scores. Unfortunately, most off-the-shelf\nclassification models need to be retrained if they are used in changing\nenvironments, and fail to scale properly. Spiking Neural Networks have revealed\nthemselves as one of the most successful approaches to model the behavior and\nlearning potential of the brain, and exploit them to undertake practical online\nlearning tasks. Besides, some specific flavors of Spiking Neural Networks can\novercome the necessity of retraining after a drift occurs. This work intends to\nmerge both fields by serving as a comprehensive overview, motivating further\ndevelopments that embrace Spiking Neural Networks for online learning\nscenarios, and being a friendly entry point for non-experts.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 09:18:28 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Lobo", "Jesus L.", ""], ["Del Ser", "Javier", ""], ["Bifet", "Albert", ""], ["Kasabov", "Nikola", ""]]}, {"id": "1908.08167", "submitter": "Zhiguo Wang", "authors": "Zhiguo Wang, Patrick Ng, Xiaofei Ma, Ramesh Nallapati, Bing Xiang", "title": "Multi-passage BERT: A Globally Normalized BERT Model for Open-domain\n  Question Answering", "comments": "To appear in EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  BERT model has been successfully applied to open-domain QA tasks. However,\nprevious work trains BERT by viewing passages corresponding to the same\nquestion as independent training instances, which may cause incomparable scores\nfor answers from different passages. To tackle this issue, we propose a\nmulti-passage BERT model to globally normalize answer scores across all\npassages of the same question, and this change enables our QA model find better\nanswers by utilizing more passages. In addition, we find that splitting\narticles into passages with the length of 100 words by sliding window improves\nperformance by 4%. By leveraging a passage ranker to select high-quality\npassages, multi-passage BERT gains additional 2%. Experiments on four standard\nbenchmarks showed that our multi-passage BERT outperforms all state-of-the-art\nmodels on all benchmarks. In particular, on the OpenSQuAD dataset, our model\ngains 21.4% EM and 21.5% $F_1$ over all non-BERT models, and 5.8% EM and 6.5%\n$F_1$ over BERT-based models.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 02:00:53 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 02:28:53 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Wang", "Zhiguo", ""], ["Ng", "Patrick", ""], ["Ma", "Xiaofei", ""], ["Nallapati", "Ramesh", ""], ["Xiang", "Bing", ""]]}, {"id": "1908.08184", "submitter": "Takahiro Kawamura Dr.", "authors": "Takahiro Kawamura, Shusaku Egami, Koutarou Tamura, Yasunori Hokazono,\n  Takanori Ugai, Yusuke Koyanagi, Fumihito Nishino, Seiji Okajima, Katsuhiko\n  Murakami, Kunihiko Takamatsu, Aoi Sugiura, Shun Shiramatsu, Shawn Zhang, and\n  Kouji Kozaki", "title": "Report on the First Knowledge Graph Reasoning Challenge 2018 -- Toward\n  the eXplainable AI System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A new challenge for knowledge graph reasoning started in 2018. Deep learning\nhas promoted the application of artificial intelligence (AI) techniques to a\nwide variety of social problems. Accordingly, being able to explain the reason\nfor an AI decision is becoming important to ensure the secure and safe use of\nAI techniques. Thus, we, the Special Interest Group on Semantic Web and\nOntology of the Japanese Society for AI, organized a challenge calling for\ntechniques that reason and/or estimate which characters are criminals while\nproviding a reasonable explanation based on an open knowledge graph of a\nwell-known Sherlock Holmes mystery story. This paper presents a summary report\nof the first challenge held in 2018, including the knowledge graph\nconstruction, the techniques proposed for reasoning and/or estimation, the\nevaluation metrics, and the results. The first prize went to an approach that\nformalized the problem as a constraint satisfaction problem and solved it using\na lightweight formal method; the second prize went to an approach that used\nSPARQL and rules; the best resource prize went to a submission that constructed\nword embedding of characters from all sentences of Sherlock Holmes novels; and\nthe best idea prize went to a discussion multi-agents model. We conclude this\npaper with the plans and issues for the next challenge in 2019.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 03:27:48 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Kawamura", "Takahiro", ""], ["Egami", "Shusaku", ""], ["Tamura", "Koutarou", ""], ["Hokazono", "Yasunori", ""], ["Ugai", "Takanori", ""], ["Koyanagi", "Yusuke", ""], ["Nishino", "Fumihito", ""], ["Okajima", "Seiji", ""], ["Murakami", "Katsuhiko", ""], ["Takamatsu", "Kunihiko", ""], ["Sugiura", "Aoi", ""], ["Shiramatsu", "Shun", ""], ["Zhang", "Shawn", ""], ["Kozaki", "Kouji", ""]]}, {"id": "1908.08328", "submitter": "Dietmar Jannach", "authors": "Dietmar Jannach and Michael Jugovac", "title": "Measuring the Business Value of Recommender Systems", "comments": null, "journal-ref": null, "doi": "10.1145/3370082", "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender Systems are nowadays successfully used by all major web sites\n(from e-commerce to social media) to filter content and make suggestions in a\npersonalized way. Academic research largely focuses on the value of\nrecommenders for consumers, e.g., in terms of reduced information overload. To\nwhat extent and in which ways recommender systems create business value is,\nhowever, much less clear, and the literature on the topic is scattered. In this\nresearch commentary, we review existing publications on field tests of\nrecommender systems and report which business-related performance measures were\nused in such real-world deployments. We summarize common challenges of\nmeasuring the business value in practice and critically discuss the value of\nalgorithmic improvements and offline experiments as commonly done in academic\nenvironments. Overall, our review indicates that various open questions remain\nboth regarding the realistic quantification of the business effects of\nrecommenders and the performance assessment of recommendation algorithms in\nacademia.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 11:52:09 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 12:05:24 GMT"}, {"version": "v3", "created": "Tue, 17 Dec 2019 17:37:30 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Jannach", "Dietmar", ""], ["Jugovac", "Michael", ""]]}, {"id": "1908.08342", "submitter": "Runzhe Yang", "authors": "Runzhe Yang, Xingyuan Sun, Karthik Narasimhan", "title": "A Generalized Algorithm for Multi-Objective Reinforcement Learning and\n  Policy Adaptation", "comments": "Accepted in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new algorithm for multi-objective reinforcement learning\n(MORL) with linear preferences, with the goal of enabling few-shot adaptation\nto new tasks. In MORL, the aim is to learn policies over multiple competing\nobjectives whose relative importance (preferences) is unknown to the agent.\nWhile this alleviates dependence on scalar reward design, the expected return\nof a policy can change significantly with varying preferences, making it\nchallenging to learn a single model to produce optimal policies under different\npreference conditions. We propose a generalized version of the Bellman equation\nto learn a single parametric representation for optimal policies over the space\nof all possible preferences. After an initial learning phase, our agent can\nexecute the optimal policy under any given preference, or automatically infer\nan underlying preference with very few samples. Experiments across four\ndifferent domains demonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 17:54:14 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 06:36:07 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Yang", "Runzhe", ""], ["Sun", "Xingyuan", ""], ["Narasimhan", "Karthik", ""]]}, {"id": "1908.08351", "submitter": "Dieuwke Hupkes", "authors": "Dieuwke Hupkes, Verna Dankers, Mathijs Mul, Elia Bruni", "title": "Compositionality decomposed: how do neural networks generalise?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite a multitude of empirical studies, little consensus exists on whether\nneural networks are able to generalise compositionally, a controversy that, in\npart, stems from a lack of agreement about what it means for a neural model to\nbe compositional. As a response to this controversy, we present a set of tests\nthat provide a bridge between, on the one hand, the vast amount of linguistic\nand philosophical theory about compositionality of language and, on the other,\nthe successful neural models of language. We collect different interpretations\nof compositionality and translate them into five theoretically grounded tests\nfor models that are formulated on a task-independent level. In particular, we\nprovide tests to investigate (i) if models systematically recombine known parts\nand rules (ii) if models can extend their predictions beyond the length they\nhave seen in the training data (iii) if models' composition operations are\nlocal or global (iv) if models' predictions are robust to synonym substitutions\nand (v) if models favour rules or exceptions during training. To demonstrate\nthe usefulness of this evaluation paradigm, we instantiate these five tests on\na highly compositional data set which we dub PCFG SET and apply the resulting\ntests to three popular sequence-to-sequence models: a recurrent, a\nconvolution-based and a transformer model. We provide an in-depth analysis of\nthe results, which uncover the strengths and weaknesses of these three\narchitectures and point to potential areas of improvement.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 13:08:26 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 15:42:10 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Hupkes", "Dieuwke", ""], ["Dankers", "Verna", ""], ["Mul", "Mathijs", ""], ["Bruni", "Elia", ""]]}, {"id": "1908.08406", "submitter": "Marcos Cramer", "authors": "Marcos Cramer and Leendert van der Torre", "title": "SCF2 -- an Argumentation Semantics for Rational Human Judgments on\n  Argument Acceptability: Technical Report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In abstract argumentation theory, many argumentation semantics have been\nproposed for evaluating argumentation frameworks. This paper is based on the\nfollowing research question: Which semantics corresponds well to what humans\nconsider a rational judgment on the acceptability of arguments? There are two\nsystematic ways to approach this research question: A normative perspective is\nprovided by the principle-based approach, in which semantics are evaluated\nbased on their satisfaction of various normatively desirable principles. A\ndescriptive perspective is provided by the empirical approach, in which\ncognitive studies are conducted to determine which semantics best predicts\nhuman judgments about arguments. In this paper, we combine both approaches to\nmotivate a new argumentation semantics called SCF2. For this purpose, we\nintroduce and motivate two new principles and show that no semantics from the\nliterature satisfies both of them. We define SCF2 and prove that it satisfies\nboth new principles. Furthermore, we discuss findings of a recent empirical\ncognitive study that provide additional support to SCF2.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 14:27:28 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Cramer", "Marcos", ""], ["van der Torre", "Leendert", ""]]}, {"id": "1908.08474", "submitter": "Mukund Sundararajan", "authors": "Mukund Sundararajan and Amir Najmi", "title": "The many Shapley values for model explanation", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Shapley value has become a popular method to attribute the prediction of\na machine-learning model on an input to its base features. The use of the\nShapley value is justified by citing [16] showing that it is the \\emph{unique}\nmethod that satisfies certain good properties (\\emph{axioms}).\n  There are, however, a multiplicity of ways in which the Shapley value is\noperationalized in the attribution problem. These differ in how they reference\nthe model, the training data, and the explanation context. These give very\ndifferent results, rendering the uniqueness result meaningless. Furthermore, we\nfind that previously proposed approaches can produce counterintuitive\nattributions in theory and in practice---for instance, they can assign non-zero\nattributions to features that are not even referenced by the model.\n  In this paper, we use the axiomatic approach to study the differences between\nsome of the many operationalizations of the Shapley value for attribution, and\npropose a technique called Baseline Shapley (BShap) that is backed by a proper\nuniqueness result. We also contrast BShap with Integrated Gradients, another\nextension of Shapley value to the continuous setting.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 16:13:10 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 17:43:11 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Sundararajan", "Mukund", ""], ["Najmi", "Amir", ""]]}, {"id": "1908.08485", "submitter": "Valery Vilisov", "authors": "V.Ya. Vilisov, B. Yu. Murashkin, A. I. Kulikov", "title": "Simulation Model of Two-Robot Cooperation in Common Operating\n  Environment", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CY cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article considers a simulation modelling problem related to the chess\ngame process occurring between two three-tier manipulators. The objective of\nthe game construction lies in developing the procedure of effective control of\nthe autonomous manipulator robots located in a common operating environment.\nThe simulation model is a preliminary stage of building a natural complex that\nwould provide cooperation of several manipulator robots within a common\noperating environment. The article addresses issues of training and research.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 16:40:55 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Vilisov", "V. Ya.", ""], ["Murashkin", "B. Yu.", ""], ["Kulikov", "A. I.", ""]]}, {"id": "1908.08494", "submitter": "Jonatas Chagas", "authors": "Jonatas B. C. Chagas, T\\'ulio A. M. Toffolo, Marcone J. F. Souza,\n  Manuel Iori", "title": "The double traveling salesman problem with partial last-in-first-out\n  loading constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the Double Traveling Salesman Problem with\nPartial Last-In-First-Out Loading Constraints (DTSPPL). It is a\npickup-and-delivery single-vehicle routing problem, where all pickup operations\nmust be performed before any delivery one because the pickup and delivery areas\nare geographically separated. The vehicle collects items in the pickup area and\nloads them into its container, a horizontal stack. After performing all pickup\noperations, the vehicle begins delivering the items in the delivery area.\nLoading and unloading operations must obey a partial Last-In-First-Out (LIFO)\npolicy, i.e., a version of the LIFO policy that may be violated within a given\nreloading depth. The objective of the DTSPPL is to minimize the total cost,\nwhich involves the total distance traveled by the vehicle and the number of\nitems that are unloaded and then reloaded due to violations of the standard\nLIFO policy. We formally describe the DTSPPL through two Integer Linear\nProgramming (ILP) formulations and propose a heuristic algorithm based on the\nBiased Random-Key Genetic Algorithm (BRKGA) to find high-quality solutions. The\nperformance of the proposed solution approaches is assessed over a broad set of\ninstances. Computational results have shown that both ILP formulations have\nbeen able to solve only the smaller instances, whereas the BRKGA obtained good\nquality solutions for almost all instances, requiring short computational\ntimes.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 17:02:13 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2020 15:10:39 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Chagas", "Jonatas B. C.", ""], ["Toffolo", "T\u00falio A. M.", ""], ["Souza", "Marcone J. F.", ""], ["Iori", "Manuel", ""]]}, {"id": "1908.08526", "submitter": "Nathan Kallus", "authors": "Nathan Kallus, Masatoshi Uehara", "title": "Double Reinforcement Learning for Efficient Off-Policy Evaluation in\n  Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy evaluation (OPE) in reinforcement learning allows one to evaluate\nnovel decision policies without needing to conduct exploration, which is often\ncostly or otherwise infeasible. We consider for the first time the\nsemiparametric efficiency limits of OPE in Markov decision processes (MDPs),\nwhere actions, rewards, and states are memoryless. We show existing OPE\nestimators may fail to be efficient in this setting. We develop a new estimator\nbased on cross-fold estimation of $q$-functions and marginalized density\nratios, which we term double reinforcement learning (DRL). We show that DRL is\nefficient when both components are estimated at fourth-root rates and is also\ndoubly robust when only one component is consistent. We investigate these\nproperties empirically and demonstrate the performance benefits due to\nharnessing memorylessness.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 17:57:19 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 07:59:07 GMT"}, {"version": "v3", "created": "Fri, 5 Jun 2020 09:58:10 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Kallus", "Nathan", ""], ["Uehara", "Masatoshi", ""]]}, {"id": "1908.08564", "submitter": "Saurav Manchanda", "authors": "Saurav Manchanda, Mohit Sharma and George Karypis", "title": "Intent term selection and refinement in e-commerce queries", "comments": "Extended version of paper \"Intent term weighing in e-commerce\n  queries\" to appear in CIKM'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In e-commerce, a user tends to search for the desired product by issuing a\nquery to the search engine and examining the retrieved results. If the search\nengine was successful in correctly understanding the user's query, it will\nreturn results that correspond to the products whose attributes match the terms\nin the query that are representative of the query's product intent. However,\nthe search engine may fail to retrieve results that satisfy the query's product\nintent and thus degrading user experience due to different issues in query\nprocessing: (i) when multiple terms are present in a query it may fail to\ndetermine the relevant terms that are representative of the query's product\nintent, and (ii) it may suffer from vocabulary gap between the terms in the\nquery and the product's description, i.e., terms used in the query are\nsemantically similar but different from the terms in the product description.\nHence, identifying the terms that describe the query's product intent and\npredicting additional terms that describe the query's product intent better\nthan the existing query terms to the search engine is an essential task in\ne-commerce search. In this paper, we leverage the historical query\nreformulation logs of a major e-commerce retailer to develop distant-supervised\napproaches to solve both these problems. Our approaches exploit the fact that\nthe significance of a term is dependent upon the context (other terms in the\nneighborhood) in which it is used in order to learn the importance of the term\ntowards the query's product intent. We show that identifying and emphasizing\nthe terms that define the query's product intent leads to a 3% improvement in\nranking. Moreover, for the tasks of identifying the important terms in a query\nand for predicting the additional terms that represent product intent,\nexperiments illustrate that our approaches outperform the non-contextual\nbaselines.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 19:04:24 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Manchanda", "Saurav", ""], ["Sharma", "Mohit", ""], ["Karypis", "George", ""]]}, {"id": "1908.08581", "submitter": "Carsten Eickhoff", "authors": "Carsten Eickhoff and Floran Gmehlin and Anu V. Patel and Jocelyn\n  Boullier and Hamish Fraser", "title": "DC3 -- A Diagnostic Case Challenge Collection for Clinical Decision\n  Support", "comments": null, "journal-ref": "The 2019 ACM SIGIR International Conference on the Theory of\n  Information Retrieval (ICTIR '19)", "doi": "10.1145/3341981.3344239", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In clinical care, obtaining a correct diagnosis is the first step towards\nsuccessful treatment and, ultimately, recovery. Depending on the complexity of\nthe case, the diagnostic phase can be lengthy and ridden with errors and\ndelays. Such errors have a high likelihood to cause patients severe harm or\neven lead to their death and are estimated to cost the U.S. healthcare system\nseveral hundred billion dollars each year.\n  To avoid diagnostic errors, physicians increasingly rely on diagnostic\ndecision support systems drawing from heuristics, historic cases, textbooks,\nclinical guidelines and scholarly biomedical literature. The evaluation of such\nsystems, however, is often conducted in an ad-hoc fashion, using\nnon-transparent methodology, and proprietary data.\n  This paper presents DC3, a collection of 31 extremely difficult diagnostic\ncase challenges, manually compiled and solved by clinical experts. For each\ncase, we present a number of temporally ordered physician-generated\nobservations alongside the eventually confirmed true diagnosis. We additionally\nprovide inferred dense relevance judgments for these cases among the PubMed\ncollection of 27 million scholarly biomedical articles.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 20:20:22 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Eickhoff", "Carsten", ""], ["Gmehlin", "Floran", ""], ["Patel", "Anu V.", ""], ["Boullier", "Jocelyn", ""], ["Fraser", "Hamish", ""]]}, {"id": "1908.08594", "submitter": "Matthias von Davier", "authors": "Matthias von Davier", "title": "Training Optimus Prime, M.D.: Generating Medical Certification Items by\n  Fine-Tuning OpenAI's gpt2 Transformer Model", "comments": "18 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes new results of an application using transformer-based\nlanguage models to automated item generation (AIG), an area of ongoing interest\nin the domain of certification testing as well as in educational measurement\nand psychological testing. OpenAI's gpt2 pre-trained 345M parameter language\nmodel was retrained using the public domain text mining set of PubMed articles\nand subsequently used to generate item stems (case vignettes) as well as\ndistractor proposals for multiple-choice items. This case study shows promise\nand produces draft text that can be used by human item writers as input for\nauthoring. Future experiments with more recent transformer models (such as\nGrover, TransformerXL) using existing item pools are expected to improve\nresults further and to facilitate the development of assessment materials.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 00:58:21 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 11:07:04 GMT"}, {"version": "v3", "created": "Thu, 29 Aug 2019 23:11:08 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["von Davier", "Matthias", ""]]}, {"id": "1908.08641", "submitter": "Matt Cooper", "authors": "Matt Cooper, Jun Ki Lee, Jacob Beck, Joshua D. Fishman, Michael\n  Gillett, Zo\\\"e Papakipos, Aaron Zhang, Jerome Ramos, Aansh Shah, and Michael\n  L. Littman", "title": "Stackelberg Punishment and Bully-Proofing Autonomous Vehicles", "comments": "10 pages, The 11th International Conference on Social Robotics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mutually beneficial behavior in repeated games can be enforced via the threat\nof punishment, as enshrined in game theory's well-known \"folk theorem.\" There\nis a cost, however, to a player for generating these disincentives. In this\nwork, we seek to minimize this cost by computing a \"Stackelberg punishment,\" in\nwhich the player selects a behavior that sufficiently punishes the other player\nwhile maximizing its own score under the assumption that the other player will\nadopt a best response. This idea generalizes the concept of a Stackelberg\nequilibrium. Known efficient algorithms for computing a Stackelberg equilibrium\ncan be adapted to efficiently produce a Stackelberg punishment. We demonstrate\nan application of this idea in an experiment involving a virtual autonomous\nvehicle and human participants. We find that a self-driving car with a\nStackelberg punishment policy discourages human drivers from bullying in a\ndriving scenario requiring social negotiation.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 02:29:17 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Cooper", "Matt", ""], ["Lee", "Jun Ki", ""], ["Beck", "Jacob", ""], ["Fishman", "Joshua D.", ""], ["Gillett", "Michael", ""], ["Papakipos", "Zo\u00eb", ""], ["Zhang", "Aaron", ""], ["Ramos", "Jerome", ""], ["Shah", "Aansh", ""], ["Littman", "Michael L.", ""]]}, {"id": "1908.08740", "submitter": "Maximilian Felde", "authors": "Maximilian Felde and Gerd Stumme", "title": "Interactive Collaborative Exploration using Incomplete Contexts", "comments": "38 pages (31 pages + 7 pages appendix), 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A well-known knowledge acquisition method in the field of Formal Concept\nAnalysis (FCA) is attribute exploration. It is used to reveal dependencies in a\nset of attributes with help of a domain expert. In most applications no single\nexpert is capable (time- and knowledge-wise) of exploring the knowledge domain\nalone. However, there is up to now no theory that models the interaction of\nmultiple experts for the task of attribute exploration with incomplete\nknowledge. To this end, we to develop a theoretical framework that allows\nmultiple experts to explore domains together. We use a representation of\nincomplete knowledge as three-valued contexts. We then adapt the corresponding\nversion of attribute exploration to fit the setting of multiple experts. We\nsuggest formalizations for key components like expert knowledge, interaction\nand collaboration strategy. In particular, we define an order that allows to\ncompare the results of different exploration strategies on the same task with\nrespect to their information completeness. Furthermore we discuss other ways of\ncomparing collaboration strategies and suggest avenues for future research.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 09:49:43 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 10:50:53 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Felde", "Maximilian", ""], ["Stumme", "Gerd", ""]]}, {"id": "1908.08796", "submitter": "Chao Yu", "authors": "Chao Yu, Jiming Liu and Shamim Nemati", "title": "Reinforcement Learning in Healthcare: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a subfield of machine learning, reinforcement learning (RL) aims at\nempowering one's capabilities in behavioural decision making by using\ninteraction experience with the world and an evaluative feedback. Unlike\ntraditional supervised learning methods that usually rely on one-shot,\nexhaustive and supervised reward signals, RL tackles with sequential decision\nmaking problems with sampled, evaluative and delayed feedback simultaneously.\nSuch distinctive features make RL technique a suitable candidate for developing\npowerful solutions in a variety of healthcare domains, where diagnosing\ndecisions or treatment regimes are usually characterized by a prolonged and\nsequential procedure. This survey discusses the broad applications of RL\ntechniques in healthcare domains, in order to provide the research community\nwith systematic understanding of theoretical foundations, enabling methods and\ntechniques, existing challenges, and new insights of this emerging paradigm. By\nfirst briefly examining theoretical foundations and key techniques in RL\nresearch from efficient and representational directions, we then provide an\noverview of RL applications in healthcare domains ranging from dynamic\ntreatment regimes in chronic diseases and critical care, automated medical\ndiagnosis from both unstructured and structured clinical data, as well as many\nother control or scheduling domains that have infiltrated many aspects of a\nhealthcare system. Finally, we summarize the challenges and open issues in\ncurrent research, and point out some potential solutions and directions for\nfuture research.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 08:32:49 GMT"}, {"version": "v2", "created": "Sun, 12 Apr 2020 10:48:59 GMT"}, {"version": "v3", "created": "Thu, 23 Apr 2020 14:47:41 GMT"}, {"version": "v4", "created": "Fri, 24 Apr 2020 14:45:14 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Yu", "Chao", ""], ["Liu", "Jiming", ""], ["Nemati", "Shamim", ""]]}, {"id": "1908.08843", "submitter": "Mengnan Du", "authors": "Mengnan Du, Fan Yang, Na Zou, Xia Hu", "title": "Fairness in Deep Learning: A Computational Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is increasingly being used in high-stake decision making\napplications that affect individual lives. However, deep learning models might\nexhibit algorithmic discrimination behaviors with respect to protected groups,\npotentially posing negative impacts on individuals and society. Therefore,\nfairness in deep learning has attracted tremendous attention recently. We\nprovide a review covering recent progresses to tackle algorithmic fairness\nproblems of deep learning from the computational perspective. Specifically, we\nshow that interpretability can serve as a useful ingredient to diagnose the\nreasons that lead to algorithmic discrimination. We also discuss fairness\nmitigation approaches categorized according to three stages of deep learning\nlife-cycle, aiming to push forward the area of fairness in deep learning and\nbuild genuinely fair and reliable deep learning systems.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 14:38:07 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 02:33:17 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Du", "Mengnan", ""], ["Yang", "Fan", ""], ["Zou", "Na", ""], ["Hu", "Xia", ""]]}, {"id": "1908.08939", "submitter": "Meredith Ringel Morris", "authors": "Meredith Ringel Morris", "title": "AI and Accessibility: A Discussion of Ethical Considerations", "comments": "Preprint of a \"Viewpoint\" column that was published in the\n  Communications of the ACM in May/June 2020", "journal-ref": null, "doi": "10.1145/3356727", "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to the World Health Organization, more than one billion people\nworldwide have disabilities. The field of disability studies defines disability\nthrough a social lens; people are disabled to the extent that society creates\naccessibility barriers. AI technologies offer the possibility of removing many\naccessibility barriers; for example, computer vision might help people who are\nblind better sense the visual world, speech recognition and translation\ntechnologies might offer real time captioning for people who are hard of\nhearing, and new robotic systems might augment the capabilities of people with\nlimited mobility. Considering the needs of users with disabilities can help\ntechnologists identify high-impact challenges whose solutions can advance the\nstate of AI for all users; however, ethical challenges such as inclusivity,\nbias, privacy, error, expectation setting, simulated data, and social\nacceptability must be considered.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 17:00:25 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 07:28:59 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 16:33:42 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Morris", "Meredith Ringel", ""]]}, {"id": "1908.08992", "submitter": "Anjana Wijekoon", "authors": "Anjana Wijekoon, Nirmalie Wiratunga, Kay Cooper", "title": "MEx: Multi-modal Exercises Dataset for Human Activity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MEx: Multi-modal Exercises Dataset is a multi-sensor, multi-modal dataset,\nimplemented to benchmark Human Activity Recognition(HAR) and Multi-modal Fusion\nalgorithms. Collection of this dataset was inspired by the need for recognising\nand evaluating quality of exercise performance to support patients with\nMusculoskeletal Disorders(MSD). We select 7 exercises regularly recommended for\nMSD patients by physiotherapists and collected data with four sensors a\npressure mat, a depth camera and two accelerometers. The dataset contains three\ndata modalities; numerical time-series data, video data and pressure sensor\ndata posing interesting research challenges when reasoning for HAR and Exercise\nQuality Assessment. This paper presents our evaluation of the dataset on number\nof standard classification algorithms for the HAR task by comparing different\nfeature representation algorithms for each sensor. These results set a\nreference performance for each individual sensor that expose their strengths\nand weaknesses for the future tasks. In addition we visualise pressure mat data\nto explore the potential of the sensor to capture exercise performance quality.\nWith the recent advancement in multi-modal fusion, we also believe MEx is a\nsuitable dataset to benchmark not only HAR algorithms, but also fusion\nalgorithms of heterogeneous data types in multiple application domains.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 16:09:53 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Wijekoon", "Anjana", ""], ["Wiratunga", "Nirmalie", ""], ["Cooper", "Kay", ""]]}, {"id": "1908.08998", "submitter": "Wanling Gao", "authors": "Wanling Gao, Fei Tang, Lei Wang, Jianfeng Zhan, Chunxin Lan, Chunjie\n  Luo, Yunyou Huang, Chen Zheng, Jiahui Dai, Zheng Cao, Daoyi Zheng, Haoning\n  Tang, Kunlin Zhan, Biao Wang, Defei Kong, Tong Wu, Minghe Yu, Chongkang Tan,\n  Huan Li, Xinhui Tian, Yatao Li, Junchao Shao, Zhenyu Wang, Xiaoyu Wang, and\n  Hainan Ye", "title": "AIBench: An Industry Standard Internet Service AI Benchmark Suite", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IR cs.PF cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's Internet Services are undergoing fundamental changes and shifting to\nan intelligent computing era where AI is widely employed to augment services.\nIn this context, many innovative AI algorithms, systems, and architectures are\nproposed, and thus the importance of benchmarking and evaluating them rises.\nHowever, modern Internet services adopt a microservice-based architecture and\nconsist of various modules. The diversity of these modules and complexity of\nexecution paths, the massive scale and complex hierarchy of datacenter\ninfrastructure, the confidential issues of data sets and workloads pose great\nchallenges to benchmarking. In this paper, we present the first\nindustry-standard Internet service AI benchmark suite---AIBench with seventeen\nindustry partners, including several top Internet service providers. AIBench\nprovides a highly extensible, configurable, and flexible benchmark framework\nthat contains loosely coupled modules. We identify sixteen prominent AI problem\ndomains like learning to rank, each of which forms an AI component benchmark,\nfrom three most important Internet service domains: search engine, social\nnetwork, and e-commerce, which is by far the most comprehensive AI benchmarking\neffort. On the basis of the AIBench framework, abstracting the real-world data\nsets and workloads from one of the top e-commerce providers, we design and\nimplement the first end-to-end Internet service AI benchmark, which contains\nthe primary modules in the critical paths of an industry scale application and\nis scalable to deploy on different cluster scales. The specifications, source\ncode, and performance numbers are publicly available from the benchmark council\nweb site http://www.benchcouncil.org/AIBench/index.html.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 10:15:39 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 14:39:47 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Gao", "Wanling", ""], ["Tang", "Fei", ""], ["Wang", "Lei", ""], ["Zhan", "Jianfeng", ""], ["Lan", "Chunxin", ""], ["Luo", "Chunjie", ""], ["Huang", "Yunyou", ""], ["Zheng", "Chen", ""], ["Dai", "Jiahui", ""], ["Cao", "Zheng", ""], ["Zheng", "Daoyi", ""], ["Tang", "Haoning", ""], ["Zhan", "Kunlin", ""], ["Wang", "Biao", ""], ["Kong", "Defei", ""], ["Wu", "Tong", ""], ["Yu", "Minghe", ""], ["Tan", "Chongkang", ""], ["Li", "Huan", ""], ["Tian", "Xinhui", ""], ["Li", "Yatao", ""], ["Shao", "Junchao", ""], ["Wang", "Zhenyu", ""], ["Wang", "Xiaoyu", ""], ["Ye", "Hainan", ""]]}, {"id": "1908.09001", "submitter": "Eduard Ramon", "authors": "Eduard Ramon, Guillermo Ruiz, Thomas Batard, Xavier Gir\\'o-i-Nieto", "title": "Hyperparameter-Free Losses for Model-Based Monocular Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes novel hyperparameter-free losses for single view 3D\nreconstruction with morphable models (3DMM). We dispense with the\nhyperparameters used in other works by exploiting geometry, so that the shape\nof the object and the camera pose are jointly optimized in a sole term\nexpression. This simplification reduces the optimization time and its\ncomplexity. Moreover, we propose a novel implicit regularization technique\nbased on random virtual projections that does not require additional 2D or 3D\nannotations. Our experiments suggest that minimizing a shape reprojection error\ntogether with the proposed implicit regularization is especially suitable for\napplications that require precise alignment between geometry and image spaces,\nsuch as augmented reality. We evaluate our losses on a large scale dataset with\n3D ground truth and publish our implementations to facilitate reproducibility\nand public benchmarking in this field.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 14:32:19 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Ramon", "Eduard", ""], ["Ruiz", "Guillermo", ""], ["Batard", "Thomas", ""], ["Gir\u00f3-i-Nieto", "Xavier", ""]]}, {"id": "1908.09067", "submitter": "Okyaz Eminaga", "authors": "Okyaz Eminaga, Mahmoud Abbas, Christian Kunder, Andreas M. Loening,\n  Jeanne Shen, James D. Brooks, Curtis P. Langlotz, and Daniel L. Rubin", "title": "Plexus Convolutional Neural Network (PlexusNet): A novel neural network\n  architecture for histologic image analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.AI cs.CV eess.IV q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different convolutional neural network (CNN) models have been tested for\ntheir application in histological image analyses. However, these models are\nprone to overfitting due to their large parameter capacity, requiring more data\nor valuable computational resources for model training. Given these\nlimitations, we introduced a novel architecture (termed PlexusNet). We utilized\n310 Hematoxylin and Eosin stained (H&E) annotated histological images of\nprostate cancer cases from TCGA-PRAD and Stanford University and 398 H&E whole\nslides images from the Camelyon 2016 challenge. PlexusNet-architecture -derived\nmodels were compared to models derived from several existing \"state of the art\"\narchitectures. We measured discrimination accuracy, calibration, and clinical\nutility. An ablation study was conducted to study the effect of each component\nof PlexusNet on model performance. A well-fitted PlexusNet-based model\ndelivered comparable classification performance (AUC: 0.963) in distinguishing\nprostate cancer from healthy tissues, although it was at least 23 times\nsmaller, had a better model calibration and clinical utility than the\ncomparison models. A separate smaller PlexusNet model accurately detected\nslides with breast cancer metastases (AUC: 0.978); it helped reduce the slide\nnumber to examine by 43.8% without consequences, although its parameter\ncapacity was 200 times smaller than ResNet18. We found that the partitioning of\nthe development set influences the model calibration for all models. However,\nwith PlexusNet architecture, we could achieve comparable well-calibrated models\ntrained on different partitions. In conclusion, PlexusNet represents a novel\nmodel architecture for histological image analysis that achieves classification\nperformance comparable to other models while providing orders-of-magnitude\nparameter reduction.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 01:29:34 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 04:43:21 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Eminaga", "Okyaz", ""], ["Abbas", "Mahmoud", ""], ["Kunder", "Christian", ""], ["Loening", "Andreas M.", ""], ["Shen", "Jeanne", ""], ["Brooks", "James D.", ""], ["Langlotz", "Curtis P.", ""], ["Rubin", "Daniel L.", ""]]}, {"id": "1908.09080", "submitter": "Mohammad Reza Besharati", "authors": "MohammadReza Besharati, Mohammad Izadi", "title": "DAST Model: Deciding About Semantic Complexity of a Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring text complexity is an essential task in several fields and\napplications (such as NLP, semantic web, smart education, etc.). The semantic\nlayer of text is more tacit than its syntactic structure and, as a result,\ncalculation of semantic complexity is more difficult than syntactic complexity.\nWhile there are famous and powerful academic and commercial syntactic\ncomplexity measures, the problem of measuring semantic complexity is still a\nchallenging one. In this paper, we introduce the DAST model, which stands for\nDeciding About Semantic Complexity of a Text. DAST proposes an intuitionistic\napproach to semantics that lets us have a well-defined model for the semantics\nof a text and its complexity: semantic is considered as a lattice of intuitions\nand, as a result, semantic complexity is defined as the result of a calculation\non this lattice. A set theoretic formal definition of semantic complexity, as a\n6-tuple formal system, is provided. By using this formal system, a method for\nmeasuring semantic complexity is presented. The evaluation of the proposed\napproach is done by a set of three human-judgment experiments. The results show\nthat DAST model is capable of deciding about semantic complexity of text.\nFurthermore, the analysis of the results leads us to introduce a Markovian\nmodel for the process of common-sense, multiple-steps and semantic-complexity\nreasoning in people. The results of Experiments demonstrate that our method\noutperforms the random baseline with improvement in better precision and\ncompetes with other methods by less error percentage.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 03:10:38 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 08:10:24 GMT"}, {"version": "v3", "created": "Mon, 7 Oct 2019 21:09:09 GMT"}, {"version": "v4", "created": "Fri, 15 Nov 2019 21:16:18 GMT"}, {"version": "v5", "created": "Sat, 30 Nov 2019 23:23:09 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Besharati", "MohammadReza", ""], ["Izadi", "Mohammad", ""]]}, {"id": "1908.09137", "submitter": "Seunghyun Yoon", "authors": "Seunghyun Yoon, Franck Dernoncourt, Doo Soon Kim, Trung Bui, Kyomin\n  Jung", "title": "Propagate-Selector: Detecting Supporting Sentences for Question\n  Answering via Graph Neural Networks", "comments": "8 pages, Accepted as a conference paper at LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we propose a novel graph neural network called\npropagate-selector (PS), which propagates information over sentences to\nunderstand information that cannot be inferred when considering sentences in\nisolation. First, we design a graph structure in which each node represents an\nindividual sentence, and some pairs of nodes are selectively connected based on\nthe text structure. Then, we develop an iterative attentive aggregation and a\nskip-combine method in which a node interacts with its neighborhood nodes to\naccumulate the necessary information. To evaluate the performance of the\nproposed approaches, we conduct experiments with the standard HotpotQA dataset.\nThe empirical results demonstrate the superiority of our proposed approach,\nwhich obtains the best performances, compared to the widely used\nanswer-selection models that do not consider the intersentential relationship.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 13:37:35 GMT"}, {"version": "v2", "created": "Sun, 16 Feb 2020 13:25:41 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Yoon", "Seunghyun", ""], ["Dernoncourt", "Franck", ""], ["Kim", "Doo Soon", ""], ["Bui", "Trung", ""], ["Jung", "Kyomin", ""]]}, {"id": "1908.09156", "submitter": "Armineh Nourbakhsh", "authors": "Armineh Nourbakhsh, Grace Bang", "title": "A framework for anomaly detection using language modeling, and its\n  applications to finance", "comments": "5 pages, 2 figures, presented at the 2nd KDD Workshop on Anomaly\n  Detection in Finance, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the finance sector, studies focused on anomaly detection are often\nassociated with time-series and transactional data analytics. In this paper, we\nlay out the opportunities for applying anomaly and deviation detection methods\nto text corpora and challenges associated with them. We argue that language\nmodels that use distributional semantics can play a significant role in\nadvancing these studies in novel directions, with new applications in risk\nidentification, predictive modeling, and trend analysis.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 15:52:57 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Nourbakhsh", "Armineh", ""], ["Bang", "Grace", ""]]}, {"id": "1908.09171", "submitter": "Michael Everett", "authors": "Michael Everett and Justin Miller and Jonathan P. How", "title": "Planning Beyond the Sensing Horizon Using a Learned Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Last-mile delivery systems commonly propose the use of autonomous robotic\nvehicles to increase scalability and efficiency. The economic inefficiency of\ncollecting accurate prior maps for navigation motivates the use of planning\nalgorithms that operate in unmapped environments. However, these algorithms\ntypically waste time exploring regions that are unlikely to contain the\ndelivery destination. Context is key information about structured environments\nthat could guide exploration toward the unknown goal location, but the abstract\nidea is difficult to quantify for use in a planning algorithm. Some approaches\nspecifically consider contextual relationships between objects, but would\nperform poorly in object-sparse environments like outdoors. Recent deep\nlearning-based approaches consider context too generally, making\ntraining/transferability difficult. Therefore, this work proposes a novel\nformulation of utilizing context for planning as an image-to-image translation\nproblem, which is shown to extract terrain context from semantic gridmaps, into\na metric that an exploration-based planner can use. The proposed framework has\nthe benefit of training on a static dataset instead of requiring a\ntime-consuming simulator. Across 42 test houses with layouts from satellite\nimages, the trained algorithm enables a robot to reach its goal 189\\% faster\nthan with a context-unaware planner, and within 63\\% of the optimal path\ncomputed with a prior map. The proposed algorithm is also implemented on a\nvehicle with a forward-facing camera in a high-fidelity, Unreal simulation of\nneighborhood houses.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 17:19:50 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2019 15:03:43 GMT"}, {"version": "v3", "created": "Mon, 1 Jun 2020 21:34:05 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Everett", "Michael", ""], ["Miller", "Justin", ""], ["How", "Jonathan P.", ""]]}, {"id": "1908.09203", "submitter": "Amanda Askell", "authors": "Irene Solaiman, Miles Brundage, Jack Clark, Amanda Askell, Ariel\n  Herbert-Voss, Jeff Wu, Alec Radford, Gretchen Krueger, Jong Wook Kim, Sarah\n  Kreps, Miles McCain, Alex Newhouse, Jason Blazakis, Kris McGuffie, Jasmine\n  Wang", "title": "Release Strategies and the Social Impacts of Language Models", "comments": "71 pages, report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large language models have a range of beneficial uses: they can assist in\nprose, poetry, and programming; analyze dataset biases; and more. However,\ntheir flexibility and generative capabilities also raise misuse concerns. This\nreport discusses OpenAI's work related to the release of its GPT-2 language\nmodel. It discusses staged release, which allows time between model releases to\nconduct risk and benefit analyses as model sizes increased. It also discusses\nongoing partnership-based research and provides recommendations for better\ncoordination and responsible publication in AI.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 20:41:40 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 03:54:12 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Solaiman", "Irene", ""], ["Brundage", "Miles", ""], ["Clark", "Jack", ""], ["Askell", "Amanda", ""], ["Herbert-Voss", "Ariel", ""], ["Wu", "Jeff", ""], ["Radford", "Alec", ""], ["Krueger", "Gretchen", ""], ["Kim", "Jong Wook", ""], ["Kreps", "Sarah", ""], ["McCain", "Miles", ""], ["Newhouse", "Alex", ""], ["Blazakis", "Jason", ""], ["McGuffie", "Kris", ""], ["Wang", "Jasmine", ""]]}, {"id": "1908.09236", "submitter": "Shohin Mukherjee", "authors": "Tushar Kusnur, Shohin Mukherjee, Dhruv Mauria Saxena, Tomoya Fukami,\n  Takayuki Koyama, Oren Salzman, and Maxim Likhachev", "title": "A Planning Framework for Persistent, Multi-UAV Coverage with Global\n  Deconfliction", "comments": "12th Conference on Field and Service Robotics, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning for multi-robot coverage seeks to determine collision-free paths for\na fleet of robots, enabling them to collectively observe points of interest in\nan environment. Persistent coverage is a variant of traditional coverage where\ncoverage-levels in the environment decay over time. Thus, robots have to\ncontinuously revisit parts of the environment to maintain a desired\ncoverage-level. Facilitating this in the real world demands we tackle numerous\nsubproblems. While there exist standard solutions to these subproblems, there\nis no complete framework that addresses all of their individual challenges as a\nwhole in a practical setting. We adapt and combine these solutions to present a\nplanning framework for persistent coverage with multiple unmanned aerial\nvehicles (UAVs). Specifically, we run a continuous loop of goal assignment and\nglobally deconflicting, kinodynamic path planning for multiple UAVs. We\nevaluate our framework in simulation as well as the real world. In particular,\nwe demonstrate that (i) our framework exhibits graceful coverage given\nsufficient resources, we maintain persistent coverage; if resources are\ninsufficient (e.g., having too few UAVs for a given size of the enviornment),\ncoverage-levels decay slowly and (ii) planning with global deconfliction in our\nframework incurs a negligibly higher price compared to other weaker, more local\ncollision-checking schemes. (Video: https://youtu.be/aqDs6Wymp5Q)\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 00:08:34 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 19:36:14 GMT"}, {"version": "v3", "created": "Wed, 16 Oct 2019 20:16:07 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Kusnur", "Tushar", ""], ["Mukherjee", "Shohin", ""], ["Saxena", "Dhruv Mauria", ""], ["Fukami", "Tomoya", ""], ["Koyama", "Takayuki", ""], ["Salzman", "Oren", ""], ["Likhachev", "Maxim", ""]]}, {"id": "1908.09296", "submitter": "Sun-Yu Gordon Chi", "authors": "Sun-Yu Gordon Chi", "title": "Exploring the Performance of Deep Residual Networks in Crazyhouse Chess", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crazyhouse is a chess variant that incorporates all of the classical chess\nrules, but allows users to drop pieces captured from the opponent as a normal\nmove. Until 2018, all competitive computer engines for this board game made use\nof an alpha-beta pruning algorithm with a hand-crafted evaluation function for\neach position. Previous machine learning-based algorithms for just regular\nchess, such as NeuroChess and Giraffe, took hand-crafted evaluation features as\ninput rather than a raw board representation. More recent projects, such as\nAlphaZero, reached massive success but required massive computational resources\nin order to reach its final strength.\n  This paper describes the development of SixtyFour, an engine designed to\ncompete in the chess variant of Crazyhouse with limited hardware. This specific\nvariant poses a multitude of significant challenges due to its large branching\nfactor, state-space complexity, and the multiple move types a player can make.\nWe propose the novel creation of a neural network-based evaluation function for\nCrazyhouse. More importantly, we evaluate the effectiveness of an ensemble\nmodel, which allows the training time and datasets to be easily distributed on\nregular CPU hardware commodity. Early versions of the network have attained a\nplaying level comparable to a strong amateur on online servers.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 10:18:02 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Chi", "Sun-Yu Gordon", ""]]}, {"id": "1908.09357", "submitter": "William Whitney", "authors": "William Whitney, Rajat Agarwal, Kyunghyun Cho, and Abhinav Gupta", "title": "Dynamics-aware Embeddings", "comments": "Published at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider self-supervised representation learning to improve\nsample efficiency in reinforcement learning (RL). We propose a forward\nprediction objective for simultaneously learning embeddings of states and\naction sequences. These embeddings capture the structure of the environment's\ndynamics, enabling efficient policy learning. We demonstrate that our action\nembeddings alone improve the sample efficiency and peak performance of\nmodel-free RL on control from low-dimensional states. By combining state and\naction embeddings, we achieve efficient learning of high-quality policies on\ngoal-conditioned continuous control from pixel observations in only 1-2 million\nenvironment steps.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 16:22:04 GMT"}, {"version": "v2", "created": "Sun, 1 Sep 2019 13:08:05 GMT"}, {"version": "v3", "created": "Tue, 14 Jan 2020 14:50:13 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Whitney", "William", ""], ["Agarwal", "Rajat", ""], ["Cho", "Kyunghyun", ""], ["Gupta", "Abhinav", ""]]}, {"id": "1908.09362", "submitter": "Ziyu Liu", "authors": "Ziyu Liu, Guolin Ke, Jiang Bian, Tieyan Liu", "title": "LightMC: A Dynamic and Efficient Multiclass Decomposition Algorithm", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiclass decomposition splits a multiclass classification problem into a\nseries of independent binary learners and recomposes them by combining their\noutputs to reconstruct the multiclass classification results. Three widely-used\nrealizations of such decomposition methods are One-Versus-All (OVA),\nOne-Versus-One (OVO), and Error-Correcting-Output-Code (ECOC). While OVA and\nOVO are quite simple, both of them assume all classes are orthogonal which\nneglect the latent correlation between classes in real-world.\nError-Correcting-Output-Code (ECOC) based decomposition methods, on the other\nhand, are more preferable due to its integration of the correlation among\nclasses. However, the performance of existing ECOC-based methods highly depends\non the design of coding matrix and decoding strategy. Unfortunately, it is\nquite uncertain and time-consuming to discover an effective coding matrix with\nappropriate decoding strategy. To address this problem, we propose LightMC, an\nefficient dynamic multiclass decomposition algorithm. Instead of using fixed\ncoding matrix and decoding strategy, LightMC uses a differentiable decoding\nstrategy, which enables it to dynamically optimize the coding matrix and\ndecoding strategy, toward increasing the overall accuracy of multiclass\nclassification, via back propagation jointly with the training of base learners\nin an iterative way. Empirical experimental results on several public\nlarge-scale multiclass classification datasets have demonstrated the\neffectiveness of LightMC in terms of both good accuracy and high efficiency.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 17:12:01 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Liu", "Ziyu", ""], ["Ke", "Guolin", ""], ["Bian", "Jiang", ""], ["Liu", "Tieyan", ""]]}, {"id": "1908.09381", "submitter": "Xudong Sun", "authors": "Xudong Sun and Bernd Bischl", "title": "Tutorial and Survey on Probabilistic Graphical Model and Variational\n  Inference in Deep Reinforcement Learning", "comments": "2019 IEEE Symposium on Computational Intelligence, Symposium on\n  Adaptive Dynamic Programming and Reinforcement Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Aiming at a comprehensive and concise tutorial survey, recap of variational\ninference and reinforcement learning with Probabilistic Graphical Models are\ngiven with detailed derivations. Reviews and comparisons on recent advances in\ndeep reinforcement learning are made from various aspects. We offer detailed\nderivations to a taxonomy of Probabilistic Graphical Model and Variational\nInference methods in deep reinforcement learning, which serves as a\ncomplementary material on top of the original contributions.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 19:36:36 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 20:10:41 GMT"}, {"version": "v3", "created": "Thu, 10 Oct 2019 21:33:38 GMT"}, {"version": "v4", "created": "Mon, 28 Oct 2019 23:28:17 GMT"}, {"version": "v5", "created": "Sun, 8 Dec 2019 11:44:35 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Sun", "Xudong", ""], ["Bischl", "Bernd", ""]]}, {"id": "1908.09453", "submitter": "Marc Lanctot", "authors": "Marc Lanctot, Edward Lockhart, Jean-Baptiste Lespiau, Vinicius\n  Zambaldi, Satyaki Upadhyay, Julien P\\'erolat, Sriram Srinivasan, Finbarr\n  Timbers, Karl Tuyls, Shayegan Omidshafiei, Daniel Hennes, Dustin Morrill,\n  Paul Muller, Timo Ewalds, Ryan Faulkner, J\\'anos Kram\\'ar, Bart De Vylder,\n  Brennan Saeta, James Bradbury, David Ding, Sebastian Borgeaud, Matthew Lai,\n  Julian Schrittwieser, Thomas Anthony, Edward Hughes, Ivo Danihelka, Jonah\n  Ryan-Davis", "title": "OpenSpiel: A Framework for Reinforcement Learning in Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OpenSpiel is a collection of environments and algorithms for research in\ngeneral reinforcement learning and search/planning in games. OpenSpiel supports\nn-player (single- and multi- agent) zero-sum, cooperative and general-sum,\none-shot and sequential, strictly turn-taking and simultaneous-move, perfect\nand imperfect information games, as well as traditional multiagent environments\nsuch as (partially- and fully- observable) grid worlds and social dilemmas.\nOpenSpiel also includes tools to analyze learning dynamics and other common\nevaluation metrics. This document serves both as an overview of the code base\nand an introduction to the terminology, core concepts, and algorithms across\nthe fields of reinforcement learning, computational game theory, and search.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 03:31:35 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 20:57:01 GMT"}, {"version": "v3", "created": "Thu, 12 Sep 2019 04:26:51 GMT"}, {"version": "v4", "created": "Thu, 10 Oct 2019 17:06:01 GMT"}, {"version": "v5", "created": "Tue, 31 Dec 2019 05:55:04 GMT"}, {"version": "v6", "created": "Sat, 26 Sep 2020 11:49:05 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Lanctot", "Marc", ""], ["Lockhart", "Edward", ""], ["Lespiau", "Jean-Baptiste", ""], ["Zambaldi", "Vinicius", ""], ["Upadhyay", "Satyaki", ""], ["P\u00e9rolat", "Julien", ""], ["Srinivasan", "Sriram", ""], ["Timbers", "Finbarr", ""], ["Tuyls", "Karl", ""], ["Omidshafiei", "Shayegan", ""], ["Hennes", "Daniel", ""], ["Morrill", "Dustin", ""], ["Muller", "Paul", ""], ["Ewalds", "Timo", ""], ["Faulkner", "Ryan", ""], ["Kram\u00e1r", "J\u00e1nos", ""], ["De Vylder", "Bart", ""], ["Saeta", "Brennan", ""], ["Bradbury", "James", ""], ["Ding", "David", ""], ["Borgeaud", "Sebastian", ""], ["Lai", "Matthew", ""], ["Schrittwieser", "Julian", ""], ["Anthony", "Thomas", ""], ["Hughes", "Edward", ""], ["Danihelka", "Ivo", ""], ["Ryan-Davis", "Jonah", ""]]}, {"id": "1908.09528", "submitter": "Pengjie Ren", "authors": "Pengjie Ren, Zhumin Chen, Christof Monz, Jun Ma, Maarten de Rijke", "title": "Thinking Globally, Acting Locally: Distantly Supervised Global-to-Local\n  Knowledge Selection for Background Based Conversation", "comments": "accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background Based Conversations (BBCs) have been introduced to help\nconversational systems avoid generating overly generic responses. In a BBC, the\nconversation is grounded in a knowledge source. A key challenge in BBCs is\nKnowledge Selection (KS): given a conversational context, try to find the\nappropriate background knowledge (a text fragment containing related facts or\ncomments, etc.) based on which to generate the next response. Previous work\naddresses KS by employing attention and/or pointer mechanisms. These mechanisms\nuse a local perspective, i.e., they select a token at a time based solely on\nthe current decoding state. We argue for the adoption of a global perspective,\ni.e., pre-selecting some text fragments from the background knowledge that\ncould help determine the topic of the next response. We enhance KS in BBCs by\nintroducing a Global-to-Local Knowledge Selection (GLKS) mechanism. Given a\nconversational context and background knowledge, we first learn a topic\ntransition vector to encode the most likely text fragments to be used in the\nnext response, which is then used to guide the local KS at each decoding\ntimestamp. In order to effectively learn the topic transition vector, we\npropose a distantly supervised learning schema. Experimental results show that\nthe GLKS model significantly outperforms state-of-the-art methods in terms of\nboth automatic and human evaluation. More importantly, GLKS achieves this\nwithout requiring any extra annotations, which demonstrates its high degree of\nscalability.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 08:52:33 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 09:15:00 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Ren", "Pengjie", ""], ["Chen", "Zhumin", ""], ["Monz", "Christof", ""], ["Ma", "Jun", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1908.09641", "submitter": "Dar\\'io Garigliotti", "authors": "Dar\\'io Garigliotti", "title": "Semi-supervised Learning for Word Sense Disambiguation", "comments": "This work was awarded the Third Place in the EST 2013 Contest (ISSN\n  1850-2946) at the 42nd JAIIO (Annals of 42nd JAIIO - Argentine Journals of\n  Informatics - ISSN 1850-2776)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is a study of the impact of multiple aspects in a classic\nunsupervised word sense disambiguation algorithm. We identify relevant factors\nin a decision rule algorithm, including the initial labeling of examples, the\nformalization of the rule confidence, and the criteria for accepting a decision\nrule. Some of these factors are only implicitly considered in the original\nliterature. We then propose a lightly supervised version of the algorithm, and\nemploy a pseudo-word-based strategy to evaluate the impact of these factors.\nThe obtained performances are comparable with those of highly optimized\nformulations of the word sense disambiguation method.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 12:35:28 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Garigliotti", "Dar\u00edo", ""]]}, {"id": "1908.09652", "submitter": "Thiago Miranda", "authors": "Thiago Zafalon Miranda, Diorge Brognara Sardinha, Ricardo Cerri", "title": "Preventing the Generation of Inconsistent Sets of Classification Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the interest in interpretable classification models has\ngrown. One of the proposed ways to improve the interpretability of a rule-based\nclassification model is to use sets (unordered collections) of rules, instead\nof lists (ordered collections) of rules. One of the problems associated with\nsets is that multiple rules may cover a single instance, but predict different\nclasses for it, thus requiring a conflict resolution strategy. In this work, we\npropose two algorithms capable of finding feature-space regions inside which\nany created rule would be consistent with the already existing rules,\npreventing inconsistencies from arising. Our algorithms do not generate\nclassification models, but are instead meant to enhance algorithms that do so,\nsuch as Learning Classifier Systems. Both algorithms are described and analyzed\nexclusively from a theoretical perspective, since we have not modified a\nmodel-generating algorithm to incorporate our proposed solutions yet. This work\npresents the novelty of using conflict avoidance strategies instead of conflict\nresolution strategies.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 17:26:35 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 13:04:17 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Miranda", "Thiago Zafalon", ""], ["Sardinha", "Diorge Brognara", ""], ["Cerri", "Ricardo", ""]]}, {"id": "1908.09720", "submitter": "Marcin Pietron", "authors": "Anna Aniol and Marcin Pietron", "title": "Ensemble approach for natural language question answering problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine comprehension, answering a question depending on a given context\nparagraph is a typical task of Natural Language Understanding. It requires to\nmodel complex dependencies existing between the question and the context\nparagraph. There are many neural network models attempting to solve the problem\nof question answering. The best models have been selected, studied and compared\nwith each other. All the selected models are based on the neural attention\nmechanism concept. Additionally, studies on a SQUAD dataset were performed. The\nsubsets of queries were extracted and then each model was analyzed how it deals\nwith specific group of queries. Based on these three model ensemble model was\ncreated and tested on SQUAD dataset. It outperforms the best Mnemonic Reader\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 15:01:24 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 10:14:45 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Aniol", "Anna", ""], ["Pietron", "Marcin", ""]]}, {"id": "1908.09756", "submitter": "Ting Chen", "authors": "Ting Chen and Lala Li and Yizhou Sun", "title": "Differentiable Product Quantization for End-to-End Embedding Compression", "comments": "ICML'2020. Code at\n  https://github.com/chentingpc/dpq_embedding_compression", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding layers are commonly used to map discrete symbols into continuous\nembedding vectors that reflect their semantic meanings. Despite their\neffectiveness, the number of parameters in an embedding layer increases\nlinearly with the number of symbols and poses a critical challenge on memory\nand storage constraints. In this work, we propose a generic and end-to-end\nlearnable compression framework termed differentiable product quantization\n(DPQ). We present two instantiations of DPQ that leverage different\napproximation techniques to enable differentiability in end-to-end learning.\nOur method can readily serve as a drop-in alternative for any existing\nembedding layer. Empirically, DPQ offers significant compression ratios\n(14-238$\\times$) at negligible or no performance cost on 10 datasets across\nthree different language tasks.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 15:56:10 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 03:23:48 GMT"}, {"version": "v3", "created": "Thu, 25 Jun 2020 23:36:28 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Chen", "Ting", ""], ["Li", "Lala", ""], ["Sun", "Yizhou", ""]]}, {"id": "1908.09799", "submitter": "Sunwoo Kim", "authors": "Sunwoo Kim, Minje Kim", "title": "Nearest Neighbor Search-Based Bitwise Source Separation Using\n  Discriminant Winner-Take-All Hashing", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an iteration-free source separation algorithm based on\nWinner-Take-All (WTA) hash codes, which is a faster, yet accurate alternative\nto a complex machine learning model for single-channel source separation in a\nresource-constrained environment. We first generate random permutations with\nWTA hashing to encode the shape of the multidimensional audio spectrum to a\nreduced bitstring representation. A nearest neighbor search on the hash codes\nof an incoming noisy spectrum as the query string results in the closest\nmatches among the hashed mixture spectra. Using the indices of the matching\nframes, we obtain the corresponding ideal binary mask vectors for denoising.\nSince both the training data and the search operation are bitwise, the\nprocedure can be done efficiently in hardware implementations. Experimental\nresults show that the WTA hash codes are discriminant and provide an affordable\ndictionary search mechanism that leads to a competent performance compared to a\ncomprehensive model and oracle masking.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 16:58:50 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Kim", "Sunwoo", ""], ["Kim", "Minje", ""]]}, {"id": "1908.09800", "submitter": "Hankz Hankui Zhuo", "authors": "Hankz Hankui Zhuo, Jing Peng, Subbarao Kambhampati", "title": "Learning Action Models from Disordered and Noisy Plan Traces", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  There is increasing awareness in the planning community that the burden of\nspecifying complete domain models is too high, which impedes the applicability\nof planning technology in many real-world domains. Although there have many\nlearning systems that help automatically learning domain models, most existing\nwork assumes that the input traces are completely correct. A more realistic\nsituation is that the plan traces are disordered and noisy, such as plan traces\ndescribed by natural language. In this paper we propose and evaluate an\napproach for doing this. Our approach takes as input a set of plan traces with\ndisordered actions and noise and outputs action models that can best explain\nthe plan traces. We use a MAX-SAT framework for learning, where the constraints\nare derived from the given plan traces. Unlike traditional action models\nlearners, the states in plan traces can be partially observable and noisy as\nwell as the actions in plan traces can be disordered and parallel. We\ndemonstrate the effectiveness of our approach through a systematic empirical\nevaluation with both IPC domains and the real-world dataset extracted from\nnatural language documents.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 17:00:32 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 08:09:00 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Zhuo", "Hankz Hankui", ""], ["Peng", "Jing", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1908.09890", "submitter": "Shikib Mehri", "authors": "Shikib Mehri and Maxine Eskenazi", "title": "Multi-Granularity Representations of Dialog", "comments": "Accepted as a long paper at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural models of dialog rely on generalized latent representations of\nlanguage. This paper introduces a novel training procedure which explicitly\nlearns multiple representations of language at several levels of granularity.\nThe multi-granularity training algorithm modifies the mechanism by which\nnegative candidate responses are sampled in order to control the granularity of\nlearned latent representations. Strong performance gains are observed on the\nnext utterance retrieval task using both the MultiWOZ dataset and the Ubuntu\ndialog corpus. Analysis significantly demonstrates that multiple granularities\nof representation are being learned, and that multi-granularity training\nfacilitates better transfer to downstream tasks.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 19:41:21 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Mehri", "Shikib", ""], ["Eskenazi", "Maxine", ""]]}, {"id": "1908.09893", "submitter": "Gabriele Farina", "authors": "Gabriele Farina and Tommaso Bianchi and Tuomas Sandholm", "title": "Coarse Correlation in Extensive-Form Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coarse correlation models strategic interactions of rational agents\ncomplemented by a correlation device, that is a mediator that can recommend\nbehavior but not enforce it. Despite being a classical concept in the theory of\nnormal-form games for more than forty years, not much is known about the merits\nof coarse correlation in extensive-form settings. In this paper, we consider\ntwo instantiations of the idea of coarse correlation in extensive-form games:\nnormal-form coarse-correlated equilibrium (NFCCE), already defined in the\nliterature, and extensive-form coarse-correlated equilibrium (EFCCE), which we\nintroduce for the first time. We show that EFCCE is a subset of NFCCE and a\nsuperset of the related extensive-form correlated equilibrium. We also show\nthat, in two-player extensive-form games, social-welfare-maximizing EFCCEs and\nNFCEEs are bilinear saddle points, and give new efficient algorithms for the\nspecial case of games with no chance moves. In our experiments, our proposed\nalgorithm for NFCCE is two to four orders of magnitude faster than the prior\nstate of the art.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 19:58:48 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Farina", "Gabriele", ""], ["Bianchi", "Tommaso", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "1908.09921", "submitter": "Maxime Amblard", "authors": "Maria-Andrea Cruz-Bland\\'on (IDMC), Gosse Minnema (IDMC), Aria\n  Nourbakhsh (IDMC), Maria Boritchev (ENS Lyon, LORIA, SEMAGRAMME), Maxime\n  Amblard (SEMAGRAMME, LORIA)", "title": "Toward Dialogue Modeling: A Semantic Annotation Scheme for Questions and\n  Answers", "comments": null, "journal-ref": "LAW XIII 2019 - Linguistic Annotation Workshop - ACL Workshop, Jul\n  2019, Florence, Italy", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present study proposes an annotation scheme for classifying the content\nand discourse contribution of question-answer pairs. We propose detailed\nguidelines for using the scheme and apply them to dialogues in English,\nSpanish, and Dutch. Finally, we report on initial machine learning experiments\nfor automatic annotation.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 11:04:48 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Cruz-Bland\u00f3n", "Maria-Andrea", "", "IDMC"], ["Minnema", "Gosse", "", "IDMC"], ["Nourbakhsh", "Aria", "", "IDMC"], ["Boritchev", "Maria", "", "ENS Lyon, LORIA, SEMAGRAMME"], ["Amblard", "Maxime", "", "SEMAGRAMME, LORIA"]]}, {"id": "1908.09940", "submitter": "Jonathan Herzig", "authors": "Jonathan Herzig, Jonathan Berant", "title": "Don't paraphrase, detect! Rapid and Effective Data Collection for\n  Semantic Parsing", "comments": "EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major hurdle on the road to conversational interfaces is the difficulty in\ncollecting data that maps language utterances to logical forms. One prominent\napproach for data collection has been to automatically generate pseudo-language\npaired with logical forms, and paraphrase the pseudo-language to natural\nlanguage through crowdsourcing (Wang et al., 2015). However, this data\ncollection procedure often leads to low performance on real data, due to a\nmismatch between the true distribution of examples and the distribution induced\nby the data collection procedure. In this paper, we thoroughly analyze two\nsources of mismatch in this process: the mismatch in logical form distribution\nand the mismatch in language distribution between the true and induced\ndistributions. We quantify the effects of these mismatches, and propose a new\ndata collection approach that mitigates them. Assuming access to unlabeled\nutterances from the true distribution, we combine crowdsourcing with a\nparaphrase model to detect correct logical forms for the unlabeled utterances.\nOn two datasets, our method leads to 70.6 accuracy on average on the true\ndistribution, compared to 51.3 in paraphrasing-based data collection.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 22:15:55 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 00:21:32 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Herzig", "Jonathan", ""], ["Berant", "Jonathan", ""]]}, {"id": "1908.10010", "submitter": "Peng Gao", "authors": "Zhencai Hu, Peng Gao, Fei Wang", "title": "Research on Autonomous Maneuvering Decision of UCAV based on Approximate\n  Dynamic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned aircraft systems can perform some more dangerous and difficult\nmissions than manned aircraft systems. In some highly complicated and\nchangeable tasks, such as air combat, the maneuvering decision mechanism is\nrequired to sense the combat situation accurately and make the optimal strategy\nin real-time. This paper presents a formulation of a 3-D one-on-one air combat\nmaneuvering problem and an approximate dynamic programming approach for\ncomputing an optimal policy on autonomous maneuvering decision making. The\naircraft learns combat strategies in a Reinforcement Leaning method, while\nsensing the environment, taking available maneuvering actions and getting\nfeedback reward signals. To solve the problem of dimensional explosion in the\nair combat, the proposed method is implemented through feature selection,\ntrajectory sampling, function approximation and Bellman backup operation in the\nair combat simulation environment. This approximate dynamic programming\napproach provides a fast response to a rapidly changing tactical situation,\nlearns in long-term planning, without any explicitly coded air combat rule\nbase.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 04:01:19 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 00:43:03 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Hu", "Zhencai", ""], ["Gao", "Peng", ""], ["Wang", "Fei", ""]]}, {"id": "1908.10122", "submitter": "Varun Ojha", "authors": "Varun Ojha, Ajith Abraham, Vaclav Snasel", "title": "Heuristic design of fuzzy inference systems: A review of three decades\n  of research", "comments": "53 pages, 16 figures", "journal-ref": null, "doi": "10.1016/j.engappai.2019.08.010", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides an in-depth review of the optimal design of type-1 and\ntype-2 fuzzy inference systems (FIS) using five well known computational\nframeworks: genetic-fuzzy systems (GFS), neuro-fuzzy systems (NFS),\nhierarchical fuzzy systems (HFS), evolving fuzzy systems (EFS), and\nmulti-objective fuzzy systems (MFS), which is in view that some of them are\nlinked to each other. The heuristic design of GFS uses evolutionary algorithms\nfor optimizing both Mamdani-type and Takagi-Sugeno-Kang-type fuzzy systems.\nWhereas, the NFS combines the FIS with neural network learning systems to\nimprove the approximation ability. An HFS combines two or more low-dimensional\nfuzzy logic units in a hierarchical design to overcome the curse of\ndimensionality. An EFS solves the data streaming issues by evolving the system\nincrementally, and an MFS solves the multi-objective trade-offs like the\nsimultaneous maximization of both interpretability and accuracy. This paper\noffers a synthesis of these dimensions and explores their potentials,\nchallenges, and opportunities in FIS research. This review also examines the\ncomplex relations among these dimensions and the possibilities of combining one\nor more computational frameworks adding another dimension: deep fuzzy systems.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 10:45:15 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Ojha", "Varun", ""], ["Abraham", "Ajith", ""], ["Snasel", "Vaclav", ""]]}, {"id": "1908.10125", "submitter": "Dimitri Ognibene", "authors": "Dimitri Ognibene, Lorenzo Mirante, Letizia Marchegiani", "title": "Proactive Intention Recognition for Joint Human-Robot Search and Rescue\n  Missions through Monte-Carlo Planning in POMDP Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proactively perceiving others' intentions is a crucial skill to effectively\ninteract in unstructured, dynamic and novel environments. This work proposes a\nfirst step towards embedding this skill in support robots for search and rescue\nmissions. Predicting the responders' intentions, indeed, will enable\nexploration approaches which will identify and prioritise areas that are more\nrelevant for the responder and, thus, for the task, leading to the development\nof safer, more robust and efficient joint exploration strategies. More\nspecifically, this paper presents an active intention recognition paradigm to\nperceive, even under sensory constraints, not only the target's position but\nalso the first responder's movements, which can provide information on his/her\nintentions (e.g. reaching the position where he/she expects the target to be).\nThis mechanism is implemented by employing an extension of Monte-Carlo-based\nplanning techniques for partially observable environments, where the reward\nfunction is augmented with an entropy reduction bonus. We test in simulation\nseveral configurations of reward augmentation, both information theoretic and\nnot, as well as belief state approximations and obtain substantial improvements\nover the basic approach.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 10:56:59 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Ognibene", "Dimitri", ""], ["Mirante", "Lorenzo", ""], ["Marchegiani", "Letizia", ""]]}, {"id": "1908.10127", "submitter": "Ke Chen", "authors": "Ke Chen", "title": "Learning-Based Video Game Development in MLP@UoM: An Overview", "comments": "8 pages, 15 figures Invited paper presented as a keynote speech,\n  ICEEIE'19 in Bali, Indonesia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In general, video games not only prevail in entertainment but also have\nbecome an alternative methodology for knowledge learning, skill acquisition and\nassistance for medical treatment as well as health care in education,\nvocational/military training and medicine. On the other hand, video games also\nprovide an ideal test bed for AI researches. To a large extent, however, video\ngame development is still a laborious yet costly process, and there are many\ntechnical challenges ranging from game generation to intelligent agent\ncreation. Unlike traditional methodologies, in Machine Learning and Perception\nLab at the University of Manchester (MLP@UoM), we advocate applying machine\nlearning to different tasks in video game development to address several\nchallenges systematically. In this paper, we overview the main progress made in\nMLP@UoM recently and have an outlook on the future research directions in\nlearning-based video game development arising from our works.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 11:05:15 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Chen", "Ke", ""]]}, {"id": "1908.10128", "submitter": "Erik Bryhn Myklebust", "authors": "Erik Bryhn Myklebust and Ernesto Jimenez-Ruiz and Jiaoyan Chen and\n  Raoul Wolf and Knut Erik Tollefsen", "title": "TERA: the Toxicological Effect and Risk Assessment Knowledge Graph", "comments": "Submitted to a conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ecological risk assessment requires large amounts of chemical effect data\nfrom laboratory experiments. Due to experimental effort and animal welfare\nconcerns it is desired to extrapolate data from existing sources. To cover the\nrequired chemical effect data several data sources need to be integrated to\nenable their interoperability. In this paper we introduce the Toxicological\nEffect and Risk Assessment (TERA) knowledge graph, which aims at providing such\nintegrated view, and the data preparation and steps followed to construct this\nknowledge graph.\n  We also present the applications of TERA for chemical effect prediction and\nthe potential applications within the Semantic Web community.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 11:05:40 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 12:28:25 GMT"}, {"version": "v3", "created": "Sat, 7 Sep 2019 17:35:47 GMT"}, {"version": "v4", "created": "Wed, 11 Sep 2019 10:53:35 GMT"}, {"version": "v5", "created": "Thu, 12 Dec 2019 06:22:06 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Myklebust", "Erik Bryhn", ""], ["Jimenez-Ruiz", "Ernesto", ""], ["Chen", "Jiaoyan", ""], ["Wolf", "Raoul", ""], ["Tollefsen", "Knut Erik", ""]]}, {"id": "1908.10177", "submitter": "Pan Hu", "authors": "Pan Hu, Jacopo Urbani, Boris Motik, Ian Horrocks", "title": "Datalog Reasoning over Compressed RDF Knowledge Bases", "comments": "CIKM 2019", "journal-ref": null, "doi": "10.1145/3357384.3358147", "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Materialisation is often used in RDF systems as a preprocessing step to\nderive all facts implied by given RDF triples and rules. Although widely used,\nmaterialisation considers all possible rule applications and can use a lot of\nmemory for storing the derived facts, which can hinder performance. We present\na novel materialisation technique that compresses the RDF triples so that the\nrules can sometimes be applied to multiple facts at once, and the derived facts\ncan be represented using structure sharing. Our technique can thus require less\nspace, as well as skip certain rule applications. Our experiments show that our\ntechnique can be very effective: when the rules are relatively simple, our\nsystem is both faster and requires less memory than prominent state-of-the-art\nRDF systems.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 13:12:21 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 12:02:43 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Hu", "Pan", ""], ["Urbani", "Jacopo", ""], ["Motik", "Boris", ""], ["Horrocks", "Ian", ""]]}, {"id": "1908.10227", "submitter": "Antony Thomas", "authors": "Antony Thomas and Sunny Amatya and Fulvio Mastrogiovanni and Marco\n  Baglietto", "title": "Task-assisted Motion Planning in Partially Observable Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an integrated Task-Motion Planning framework for robot navigation\nin belief space. Autonomous robots operating in real world complex scenarios\nrequire planning in the discrete (task) space and the continuous (motion)\nspace. To this end, we propose a framework for integrating belief space\nreasoning within a hybrid task planner. The expressive power of PDDL+ combined\nwith heuristic-driven semantic attachments performs the propagated and\nposterior belief estimates while planning. The underlying methodology for the\ndevelopment of the combined hybrid planner is discussed, providing suggestions\nfor improvements and future work. Furthermore we validate key aspects of our\napproach using a realistic scenario in simulation.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 14:22:56 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Thomas", "Antony", ""], ["Amatya", "Sunny", ""], ["Mastrogiovanni", "Fulvio", ""], ["Baglietto", "Marco", ""]]}, {"id": "1908.10255", "submitter": "Andreas Gerken", "authors": "Andreas Gerken, Michael Spranger", "title": "Continuous Value Iteration (CVI) Reinforcement Learning and Imaginary\n  Experience Replay (IER) for learning multi-goal, continuous action and state\n  space controllers", "comments": "Published in 2019 International Conference on Robotics and Automation\n  (ICRA) 20-24 May 2019", "journal-ref": null, "doi": "10.1109/ICRA.2019.8794347", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel model-free Reinforcement Learning algorithm for\nlearning behavior in continuous action, state, and goal spaces. The algorithm\napproximates optimal value functions using non-parametric estimators. It is\nable to efficiently learn to reach multiple arbitrary goals in deterministic\nand nondeterministic environments. To improve generalization in the goal space,\nwe propose a novel sample augmentation technique. Using these methods, robots\nlearn faster and overall better controllers. We benchmark the proposed\nalgorithms using simulation and a real-world voltage controlled robot that\nlearns to maneuver in a non-observable Cartesian task space.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 15:00:53 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Gerken", "Andreas", ""], ["Spranger", "Michael", ""]]}, {"id": "1908.10258", "submitter": "Naman Goel", "authors": "Naman Goel, Cyril van Schreven, Aris Filos-Ratsikas, Boi Faltings", "title": "Infochain: A Decentralized, Trustless and Transparent Oracle on\n  Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain based systems allow various kinds of financial transactions to be\nexecuted in a decentralized manner. However, these systems often rely on a\ntrusted third party (oracle) to get correct information about the real-world\nevents, which trigger the financial transactions. In this paper, we identify\ntwo biggest challenges in building decentralized, trustless and transparent\noracles. The first challenge is acquiring correct information about the\nreal-world events without relying on a trusted information provider. We show\nhow a peer-consistency incentive mechanism can be used to acquire truthful\ninformation from an untrusted and self-interested crowd, even when the crowd\nhas outside incentives to provide wrong information. The second is a system\ndesign and implementation challenge. For the first time, we show how to\nimplement a trustless and transparent oracle in Ethereum. We discuss various\nnon-trivial issues that arise in implementing peer-consistency mechanisms in\nEthereum, suggest several optimizations to reduce gas cost and provide\nempirical analysis.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 15:05:47 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2020 11:29:30 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Goel", "Naman", ""], ["van Schreven", "Cyril", ""], ["Filos-Ratsikas", "Aris", ""], ["Faltings", "Boi", ""]]}, {"id": "1908.10285", "submitter": "Sandro Pezzelle", "authors": "Sandro Pezzelle and Raquel Fern\\'andez", "title": "Is the Red Square Big? MALeViC: Modeling Adjectives Leveraging Visual\n  Contexts", "comments": "Accepted at EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work aims at modeling how the meaning of gradable adjectives of size\n(`big', `small') can be learned from visually-grounded contexts. Inspired by\ncognitive and linguistic evidence showing that the use of these expressions\nrelies on setting a threshold that is dependent on a specific context, we\ninvestigate the ability of multi-modal models in assessing whether an object is\n`big' or `small' in a given visual scene. In contrast with the standard\ncomputational approach that simplistically treats gradable adjectives as\n`fixed' attributes, we pose the problem as relational: to be successful, a\nmodel has to consider the full visual context. By means of four main tasks, we\nshow that state-of-the-art models (but not a relatively strong baseline) can\nlearn the function subtending the meaning of size adjectives, though their\nperformance is found to decrease while moving from simple to more complex\ntasks. Crucially, models fail in developing abstract representations of\ngradable adjectives that can be used compositionally.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 15:44:17 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Pezzelle", "Sandro", ""], ["Fern\u00e1ndez", "Raquel", ""]]}, {"id": "1908.10300", "submitter": "James Olds PhD", "authors": "J.L. Olds, M.S. Khan, M. Nayebpour and N. Koizumi", "title": "Explainable AI: A Neurally-Inspired Decision Stack Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  European Law now requires AI to be explainable in the context of adverse\ndecisions affecting European Union (EU) citizens. At the same time, it is\nexpected that there will be increasing instances of AI failure as it operates\non imperfect data. This paper puts forward a neurally-inspired framework called\ndecision stacks that can provide for a way forward in research aimed at\ndeveloping explainable AI. Leveraging findings from memory systems in\nbiological brains, the decision stack framework operationalizes the definition\nof explainability and then proposes a test that can potentially reveal how a\ngiven AI decision came to its conclusion.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 16:22:31 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Olds", "J. L.", ""], ["Khan", "M. S.", ""], ["Nayebpour", "M.", ""], ["Koizumi", "N.", ""]]}, {"id": "1908.10322", "submitter": "Dokook Choe", "authors": "Dokook Choe, Rami Al-Rfou, Mandy Guo, Heeyoung Lee, Noah Constant", "title": "Bridging the Gap for Tokenizer-Free Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purely character-based language models (LMs) have been lagging in quality on\nlarge scale datasets, and current state-of-the-art LMs rely on word\ntokenization. It has been assumed that injecting the prior knowledge of a\ntokenizer into the model is essential to achieving competitive results. In this\npaper, we show that contrary to this conventional wisdom, tokenizer-free LMs\nwith sufficient capacity can achieve competitive performance on a large scale\ndataset. We train a vanilla transformer network with 40 self-attention layers\non the One Billion Word (lm1b) benchmark and achieve a new state of the art for\ntokenizer-free LMs, pushing these models to be on par with their word-based\ncounterparts.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 16:53:59 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Choe", "Dokook", ""], ["Al-Rfou", "Rami", ""], ["Guo", "Mandy", ""], ["Lee", "Heeyoung", ""], ["Constant", "Noah", ""]]}, {"id": "1908.10331", "submitter": "Heriberto Cuay\\'ahuitl", "authors": "Heriberto Cuay\\'ahuitl, Donghyeon Lee, Seonghan Ryu, Sungja Choi,\n  Inchul Hwang, Jihie Kim", "title": "Deep Reinforcement Learning for Chatbots Using Clustered Actions and\n  Human-Likeness Rewards", "comments": "In International Joint Conference of Neural Networks (IJCNN), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training chatbots using the reinforcement learning paradigm is challenging\ndue to high-dimensional states, infinite action spaces and the difficulty in\nspecifying the reward function. We address such problems using clustered\nactions instead of infinite actions, and a simple but promising reward function\nbased on human-likeness scores derived from human-human dialogue data. We train\nDeep Reinforcement Learning (DRL) agents using chitchat data in raw\ntext---without any manual annotations. Experimental results using different\nsplits of training data report the following. First, that our agents learn\nreasonable policies in the environments they get familiarised with, but their\nperformance drops substantially when they are exposed to a test set of unseen\ndialogues. Second, that the choice of sentence embedding size between 100 and\n300 dimensions is not significantly different on test data. Third, that our\nproposed human-likeness rewards are reasonable for training chatbots as long as\nthey use lengthy dialogue histories of >=10 sentences.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 17:06:15 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Cuay\u00e1huitl", "Heriberto", ""], ["Lee", "Donghyeon", ""], ["Ryu", "Seonghan", ""], ["Choi", "Sungja", ""], ["Hwang", "Inchul", ""], ["Kim", "Jihie", ""]]}, {"id": "1908.10345", "submitter": "Yingjie Hu", "authors": "Yingjie Hu, Wenwen Li, Dawn Wright, Orhun Aydin, Daniel Wilson, Omar\n  Maher, Mansour Raad", "title": "Artificial Intelligence Approaches", "comments": "12 pages, 5 figures", "journal-ref": "Artificial Intelligence Approaches. The Geographic Information\n  Science & Technology Body of Knowledge (3rd Quarter 2019 Edition), John P.\n  Wilson (ed.)", "doi": "10.22224/gistbok/2019.3.4", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) has received tremendous attention from academia,\nindustry, and the general public in recent years. The integration of geography\nand AI, or GeoAI, provides novel approaches for addressing a variety of\nproblems in the natural environment and our human society. This entry briefly\nreviews the recent development of AI with a focus on machine learning and deep\nlearning approaches. We discuss the integration of AI with geography and\nparticularly geographic information science, and present a number of GeoAI\napplications and possible future directions.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 17:36:27 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Hu", "Yingjie", ""], ["Li", "Wenwen", ""], ["Wright", "Dawn", ""], ["Aydin", "Orhun", ""], ["Wilson", "Daniel", ""], ["Maher", "Omar", ""], ["Raad", "Mansour", ""]]}, {"id": "1908.10398", "submitter": "Heriberto Cuay\\'ahuitl", "authors": "Heriberto Cuay\\'ahuitl", "title": "A Data-Efficient Deep Learning Approach for Deployable Multimodal Social\n  Robots", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2018.09.104", "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deep supervised and reinforcement learning paradigms (among others) have\nthe potential to endow interactive multimodal social robots with the ability of\nacquiring skills autonomously. But it is still not very clear yet how they can\nbe best deployed in real world applications. As a step in this direction, we\npropose a deep learning-based approach for efficiently training a humanoid\nrobot to play multimodal games---and use the game of `Noughts & Crosses' with\ntwo variants as a case study. Its minimum requirements for learning to perceive\nand interact are based on a few hundred example images, a few example\nmultimodal dialogues and physical demonstrations of robot manipulation, and\nautomatic simulations. In addition, we propose novel algorithms for robust\nvisual game tracking and for competitive policy learning with high winning\nrates, which substantially outperform DQN-based baselines. While an automatic\nevaluation shows evidence that the proposed approach can be easily extended to\nnew games with competitive robot behaviours, a human evaluation with 130 humans\nplaying with the Pepper robot confirms that highly accurate visual perception\nis required for successful game play.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 18:30:49 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Cuay\u00e1huitl", "Heriberto", ""]]}, {"id": "1908.10405", "submitter": "Marcelo Finger", "authors": "Marcelo Finger", "title": "Extending Description Logic EL++ with Linear Constraints on the\n  Probability of Axioms", "comments": "An earlier version of this work has appeared at Franz Baader's\n  festschrift. Here we detail the column generation method and present a\n  detailed example", "journal-ref": "In Lecture Notes in Computer Science 11560, pp. 286--300. Springer\n  (2019)", "doi": "10.1007/978-3-030-22102-7", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main reasons to employ a description logic such as EL or EL++ is\nthe fact that it has efficient, polynomial-time algorithmic properties such as\ndeciding consistency and inferring subsumption. However, simply by adding\nnegation of concepts to it, we obtain the expressivity of description logics\nwhose decision procedure is {ExpTime}-complete. Similar complexity explosion\noccurs if we add probability assignments on concepts. To lower the resulting\ncomplexity, we instead concentrate on assigning probabilities to Axioms (GCIs).\nWe show that the consistency detection problem for such a probabilistic\ndescription logic is NP-complete, and present a linear algebraic deterministic\nalgorithm to solve it, using the column generation technique. We also examine\nand provide algorithms for the probabilistic extension problem, which consists\nof inferring the minimum and maximum probabilities for a new axiom, given a\nconsistent probabilistic knowledge base.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 18:38:44 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Finger", "Marcelo", ""]]}, {"id": "1908.10422", "submitter": "Heriberto Cuay\\'ahuitl", "authors": "Heriberto Cuay\\'ahuitl, Donghyeon Lee, Seonghan Ryu, Yongjin Cho,\n  Sungja Choi, Satish Indurthi, Seunghak Yu, Hyungtak Choi, Inchul Hwang, Jihie\n  Kim", "title": "Ensemble-Based Deep Reinforcement Learning for Chatbots", "comments": "arXiv admin note: text overlap with arXiv:1908.10331", "journal-ref": null, "doi": "10.1016/j.neucom.2019.08.007", "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trainable chatbots that exhibit fluent and human-like conversations remain a\nbig challenge in artificial intelligence. Deep Reinforcement Learning (DRL) is\npromising for addressing this challenge, but its successful application remains\nan open question. This article describes a novel ensemble-based approach\napplied to value-based DRL chatbots, which use finite action sets as a form of\nmeaning representation. In our approach, while dialogue actions are derived\nfrom sentence clustering, the training datasets in our ensemble are derived\nfrom dialogue clustering. The latter aim to induce specialised agents that\nlearn to interact in a particular style. In order to facilitate neural chatbot\ntraining using our proposed approach, we assume dialogue data in raw text only\n-- without any manually-labelled data. Experimental results using chitchat data\nreveal that (1) near human-like dialogue policies can be induced, (2)\ngeneralisation to unseen data is a difficult problem, and (3) training an\nensemble of chatbot agents is essential for improved performance over using a\nsingle agent. In addition to evaluations using held-out data, our results are\nfurther supported by a human evaluation that rated dialogues in terms of\nfluency, engagingness and consistency -- which revealed that our proposed\ndialogue rewards strongly correlate with human judgements.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 19:18:09 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Cuay\u00e1huitl", "Heriberto", ""], ["Lee", "Donghyeon", ""], ["Ryu", "Seonghan", ""], ["Cho", "Yongjin", ""], ["Choi", "Sungja", ""], ["Indurthi", "Satish", ""], ["Yu", "Seunghak", ""], ["Choi", "Hyungtak", ""], ["Hwang", "Inchul", ""], ["Kim", "Jihie", ""]]}, {"id": "1908.10577", "submitter": "Yanan Wang", "authors": "Yanan Wang, Tong Xu, Xin Niu, Chang Tan, Enhong Chen, Hui Xiong", "title": "STMARL: A Spatio-Temporal Multi-Agent Reinforcement Learning Approach\n  for Cooperative Traffic Light Control", "comments": "Accepted to IEEE Transactions on Mobile Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of intelligent traffic light control systems is essential for\nsmart transportation management. While some efforts have been made to optimize\nthe use of individual traffic lights in an isolated way, related studies have\nlargely ignored the fact that the use of multi-intersection traffic lights is\nspatially influenced and there is a temporal dependency of historical traffic\nstatus for current traffic light control. To that end, in this paper, we\npropose a novel SpatioTemporal Multi-Agent Reinforcement Learning (STMARL)\nframework for effectively capturing the spatio-temporal dependency of multiple\nrelated traffic lights and control these traffic lights in a coordinating way.\nSpecifically, we first construct the traffic light adjacency graph based on the\nspatial structure among traffic lights. Then, historical traffic records will\nbe integrated with current traffic status via Recurrent Neural Network\nstructure. Moreover, based on the temporally-dependent traffic information, we\ndesign a Graph Neural Network based model to represent relationships among\nmultiple traffic lights, and the decision for each traffic light will be made\nin a distributed way by the deep Q-learning method. Finally, the experimental\nresults on both synthetic and real-world data have demonstrated the\neffectiveness of our STMARL framework, which also provides an insightful\nunderstanding of the influence mechanism among multi-intersection traffic\nlights.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 07:16:39 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 11:45:35 GMT"}, {"version": "v3", "created": "Sun, 29 Nov 2020 16:39:47 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Wang", "Yanan", ""], ["Xu", "Tong", ""], ["Niu", "Xin", ""], ["Tan", "Chang", ""], ["Chen", "Enhong", ""], ["Xiong", "Hui", ""]]}, {"id": "1908.10620", "submitter": "Andrea Celli", "authors": "Matteo Castiglioni, Andrea Celli, Nicola Gatti", "title": "Persuading Voters: It's Easy to Whisper, It's Hard to Speak Loud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the following natural question: is it possible to influence the\noutcome of a voting process through the strategic provision of information to\nvoters who update their beliefs rationally? We investigate whether it is\ncomputationally tractable to design a signaling scheme maximizing the\nprobability with which the sender's preferred candidate is elected. We focus on\nthe model recently introduced by Arieli and Babichenko (2019) (i.e., without\ninter-agent externalities), and consider, as explanatory examples, $k$-voting\nrule and plurality voting. There is a sharp contrast between the case in which\nprivate signals are allowed and the more restrictive setting in which only\npublic signals are allowed. In the former, we show that an optimal signaling\nscheme can be computed efficiently both under a $k$-voting rule and plurality\nvoting. In establishing these results, we provide two general (i.e., applicable\nto settings beyond voting) contributions. Specifically, we extend a well known\nresult by Dughmi and Xu (2017) to more general settings, and prove that, when\nthe sender's utility function is anonymous, computing an optimal signaling\nscheme is fixed parameter tractable w.r.t. the number of receivers' actions. In\nthe public signaling case, we show that the sender's optimal expected return\ncannot be approximated to within any factor under a $k$-voting rule. This\nnegative result easily extends to plurality voting and problems where utility\nfunctions are anonymous.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 10:05:41 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 14:39:32 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Castiglioni", "Matteo", ""], ["Celli", "Andrea", ""], ["Gatti", "Nicola", ""]]}, {"id": "1908.10621", "submitter": "Chao-Lin Liu", "authors": "Chao-Lin Liu", "title": "Onto Word Segmentation of the Complete Tang Poems", "comments": "5 pages, 2 tables, presented at the 2019 International Conference on\n  Digital Humanities (ADHO)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim at segmenting words in the Complete Tang Poems (CTP). Although it is\npossible to do some research about CTP without doing full-scale word\nsegmentation, we must move forward to word-level analysis of CTP for conducting\nadvanced research topics. In November 2018 when we submitted the manuscript for\nDH 2019 (ADHO), we collected only 2433 poems that were segmented by trained\nexperts, and used the segmented poems to evaluate the segmenter that considered\ndomain knowledge of Chinese poetry. We trained pointwise mutual information\n(PMI) between Chinese characters based on the CTP poems (excluding the 2433\npoems, which were used exclusively only for testing) and the domain knowledge.\nThe segmenter relied on the PMI information to the recover 85.7% of words in\nthe test poems. We could segment a poem completely correct only 17.8% of the\ntime, however. When we presented our work at DH 2019, we have annotated more\nthan 20000 poems. With a much larger amount of data, we were able to apply\nbiLSTM models for this word segmentation task, and we segmented a poem\ncompletely correct above 20% of the time. In contrast, human annotators\ncompletely agreed on their annotations about 40% of the time.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 10:06:19 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Liu", "Chao-Lin", ""]]}, {"id": "1908.10623", "submitter": "Fasih Haider Dr", "authors": "Fasih Haider, Senja Pollak, Pierre Albert, Saturnino Luz", "title": "Emotion Recognition in Low-Resource Settings: An Evaluation of Automatic\n  Feature Selection Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in automatic affect recognition has seldom addressed the issue of\ncomputational resource utilization. With the advent of ambient intelligence\ntechnology which employs a variety of low-power, resource-constrained devices,\nthis issue is increasingly gaining interest. This is especially the case in the\ncontext of health and elderly care technologies, where interventions may rely\non monitoring of emotional status to provide support or alert carers as\nappropriate. This paper focuses on emotion recognition from speech data, in\nsettings where it is desirable to minimize memory and computational\nrequirements. Reducing the number of features for inductive inference is a\nroute towards this goal. In this study, we evaluate three different\nstate-of-the-art feature selection methods: Infinite Latent Feature Selection\n(ILFS), ReliefF and Fisher (generalized Fisher score), and compare them to our\nrecently proposed feature selection method named `Active Feature Selection'\n(AFS). The evaluation is performed on three emotion recognition data sets\n(EmoDB, SAVEE and EMOVO) using two standard acoustic paralinguistic feature\nsets (i.e. eGeMAPs and emobase). The results show that similar or better\naccuracy can be achieved using subsets of features substantially smaller than\nthe entire feature set. A machine learning model trained on a smaller feature\nset will reduce the memory and computational resources of an emotion\nrecognition system which can result in lowering the barriers for use of health\nmonitoring technology.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 10:14:20 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 14:39:09 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Haider", "Fasih", ""], ["Pollak", "Senja", ""], ["Albert", "Pierre", ""], ["Luz", "Saturnino", ""]]}, {"id": "1908.10705", "submitter": "\\'Italo Gomes Santana", "authors": "\\'Italo Gomes Santana", "title": "Improving a State-of-the-Art Heuristic for the Minimum Latency Problem\n  with Data Mining", "comments": "This document is a dissertation file", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, hybrid metaheuristics have become a trend in operations research. A\nsuccessful example combines the Greedy Randomized Adaptive Search Procedures\n(GRASP) and data mining techniques, where frequent patterns found in\nhigh-quality solutions can lead to an efficient exploration of the search\nspace, along with a significant reduction of computational time. In this work,\na GRASP-based state-of-the-art heuristic for the Minimum Latency Problem (MLP)\nis improved by means of data mining techniques for two MLP variants.\nComputational experiments showed that the approaches with data mining were able\nto match or improve the solution quality for a large number of instances,\ntogether with a substantial reduction of running time. In addition, 88 new cost\nvalues of solutions are introduced into the literature. To support our results,\ntests of statistical significance, impact of using mined patterns, equal time\ncomparisons and time-to-target plots are provided.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 13:12:30 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Santana", "\u00cdtalo Gomes", ""]]}, {"id": "1908.10731", "submitter": "Semih Yavuz", "authors": "Semih Yavuz, Abhinav Rastogi, Guan-Lin Chao, Dilek Hakkani-Tur", "title": "DeepCopy: Grounded Response Generation with Hierarchical Pointer\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances in neural sequence-to-sequence models have led to promising\nresults for several language generation-based tasks, including dialogue\nresponse generation, summarization, and machine translation. However, these\nmodels are known to have several problems, especially in the context of\nchit-chat based dialogue systems: they tend to generate short and dull\nresponses that are often too generic. Furthermore, these models do not ground\nconversational responses on knowledge and facts, resulting in turns that are\nnot accurate, informative and engaging for the users. In this paper, we propose\nand experiment with a series of response generation models that aim to serve in\nthe general scenario where in addition to the dialogue context, relevant\nunstructured external knowledge in the form of text is also assumed to be\navailable for models to harness. Our proposed approach extends\npointer-generator networks (See et al., 2017) by allowing the decoder to\nhierarchically attend and copy from external knowledge in addition to the\ndialogue context. We empirically show the effectiveness of the proposed model\ncompared to several baselines including (Ghazvininejad et al., 2018; Zhang et\nal., 2018) through both automatic evaluation metrics and human evaluation on\nCONVAI2 dataset.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 14:03:44 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Yavuz", "Semih", ""], ["Rastogi", "Abhinav", ""], ["Chao", "Guan-Lin", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "1908.10747", "submitter": "David Schlangen", "authors": "David Schlangen", "title": "Language Tasks and Language Games: On Methodology in Current Natural\n  Language Processing Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  \"This paper introduces a new task and a new dataset\", \"we improve the state\nof the art in X by Y\" -- it is rare to find a current natural language\nprocessing paper (or AI paper more generally) that does not contain such\nstatements. What is mostly left implicit, however, is the assumption that this\nnecessarily constitutes progress, and what it constitutes progress towards.\nHere, we make more precise the normally impressionistically used notions of\nlanguage task and language game and ask how a research programme built on these\nmight make progress towards the goal of modelling general language competence.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 14:29:13 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Schlangen", "David", ""]]}, {"id": "1908.10770", "submitter": "Su Zhu", "authors": "Zijian Zhao, Su Zhu and Kai Yu", "title": "Data Augmentation with Atomic Templates for Spoken Language\n  Understanding", "comments": "To appear in EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken Language Understanding (SLU) converts user utterances into structured\nsemantic representations. Data sparsity is one of the main obstacles of SLU due\nto the high cost of human annotation, especially when domain changes or a new\ndomain comes. In this work, we propose a data augmentation method with atomic\ntemplates for SLU, which involves minimum human efforts. The atomic templates\nproduce exemplars for fine-grained constituents of semantic representations. We\npropose an encoder-decoder model to generate the whole utterance from atomic\nexemplars. Moreover, the generator could be transferred from source domains to\nhelp a new domain which has little data. Experimental results show that our\nmethod achieves significant improvements on DSTC 2\\&3 dataset which is a domain\nadaptation setting of SLU.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 15:17:33 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Zhao", "Zijian", ""], ["Zhu", "Su", ""], ["Yu", "Kai", ""]]}, {"id": "1908.10784", "submitter": "Camille Roth", "authors": "Telmo Menezes and Camille Roth", "title": "Semantic Hypergraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approaches to Natural language processing (NLP) may be classified along a\ndouble dichotomy open/opaque - strict/adaptive. The former axis relates to the\npossibility of inspecting the underlying processing rules, the latter to the\nuse of fixed or adaptive rules. We argue that many techniques fall into either\nthe open-strict or opaque-adaptive categories. Our contribution takes steps in\nthe open-adaptive direction, which we suggest is likely to provide key\ninstruments for interdisciplinary research. The central idea of our approach is\nthe Semantic Hypergraph (SH), a novel knowledge representation model that is\nintrinsically recursive and accommodates the natural hierarchical richness of\nnatural language. The SH model is hybrid in two senses. First, it attempts to\ncombine the strengths of ML and symbolic approaches. Second, it is a formal\nlanguage representation that reduces but tolerates ambiguity and structural\nvariability. We will see that SH enables simple yet powerful methods of pattern\ndetection, and features a good compromise for intelligibility both for humans\nand machines. It also provides a semantically deep starting point (in terms of\nexplicit meaning) for further algorithms to operate and collaborate on. We show\nhow modern NLP ML-based building blocks can be used in combination with a\nrandom forest classifier and a simple search tree to parse NL to SH, and that\nthis parser can achieve high precision in a diversity of text categories. We\ndefine a pattern language representable in SH itself, and a process to discover\nknowledge inference rules. We then illustrate the efficiency of the SH\nframework in a variety of tasks, including conjunction decomposition, open\ninformation extraction, concept taxonomy inference and co-reference resolution,\nand an applied example of claim and conflict analysis in a news corpus.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 15:39:02 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 14:26:53 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Menezes", "Telmo", ""], ["Roth", "Camille", ""]]}, {"id": "1908.10993", "submitter": "Deyan Ginev", "authors": "Deyan Ginev, Bruce R. Miller", "title": "Scientific Statement Classification over arXiv.org", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We introduce a new classification task for scientific statements and release\na large-scale dataset for supervised learning. Our resource is derived from a\nmachine-readable representation of the arXiv.org collection of preprint\narticles. We explore fifty author-annotated categories and empirically motivate\na task design of grouping 10.5 million annotated paragraphs into thirteen\nclasses. We demonstrate that the task setup aligns with known success rates\nfrom the state of the art, peaking at a 0.91 F1-score via a BiLSTM\nencoder-decoder model. Additionally, we introduce a lexeme serialization for\nmathematical formulas, and observe that context-aware models could improve when\nalso trained on the symbolic modality. Finally, we discuss the limitations of\nboth data and task design, and outline potential directions towards\nincreasingly complex models of scientific discourse, beyond isolated\nstatements.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 00:25:38 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Ginev", "Deyan", ""], ["Miller", "Bruce R.", ""]]}, {"id": "1908.11033", "submitter": "Jinlong Chai", "authors": "Jinlong Chai, Jiangeng Chang, Yakun Zhao, Honggang Liu", "title": "An Auto-ML Framework Based on GBDT for Lifelong Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic Machine Learning (Auto-ML) has attracted more and more attention in\nrecent years, our work is to solve the problem of data drift, which means that\nthe distribution of data will gradually change with the acquisition process,\nresulting in a worse performance of the auto-ML model. We construct our model\nbased on GBDT, Incremental learning and full learning are used to handle with\ndrift problem. Experiments show that our method performs well on the five data\nsets. Which shows that our method can effectively solve the problem of data\ndrift and has robust performance.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 03:30:11 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Chai", "Jinlong", ""], ["Chang", "Jiangeng", ""], ["Zhao", "Yakun", ""], ["Liu", "Honggang", ""]]}, {"id": "1908.11053", "submitter": "Wei Hu", "authors": "Jiwei Ding and Wei Hu and Qixin Xu and Yuzhong Qu", "title": "Leveraging Frequent Query Substructures to Generate Formal Queries for\n  Complex Question Answering", "comments": "Accepted by the 2019 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal query generation aims to generate correct executable queries for\nquestion answering over knowledge bases (KBs), given entity and relation\nlinking results. Current approaches build universal paraphrasing or ranking\nmodels for the whole questions, which are likely to fail in generating queries\nfor complex, long-tail questions. In this paper, we propose SubQG, a new query\ngeneration approach based on frequent query substructures, which helps rank the\nexisting (but nonsignificant) query structures or build new query structures.\nOur experiments on two benchmark datasets show that our approach significantly\noutperforms the existing ones, especially for complex questions. Also, it\nachieves promising performance with limited training data and noisy\nentity/relation linking results.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 05:03:57 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Ding", "Jiwei", ""], ["Hu", "Wei", ""], ["Xu", "Qixin", ""], ["Qu", "Yuzhong", ""]]}, {"id": "1908.11135", "submitter": "Christoph Wernhard", "authors": "Jana Kittelmann and Christoph Wernhard", "title": "KBSET -- Knowledge-Based Support for Scholarly Editing and Text\n  Processing", "comments": "Part of DECLARE 19 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  KBSET supports a practical workflow for scholarly editing, based on using\nLaTeX with dedicated commands for semantics-oriented markup and a\nProlog-implemented core system. Prolog plays there various roles: as query\nlanguage and access mechanism for large Semantic Web fact bases, as data\nrepresentation of structured documents and as a workflow model for advanced\napplication tasks. The core system includes a LaTeX parser and a facility for\nthe identification of named entities. We also sketch future perspectives of\nthis approach to scholarly editing based on techniques of computational logic.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 10:14:40 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Kittelmann", "Jana", ""], ["Wernhard", "Christoph", ""]]}, {"id": "1908.11137", "submitter": "Christoph Wernhard", "authors": "Christoph Wernhard", "title": "PIE -- Proving, Interpolating and Eliminating on the Basis of\n  First-Order Logic", "comments": "Part of DECLARE 19 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PIE is a Prolog-embedded environment for automated reasoning on the basis of\nfirst-order logic. It includes a versatile formula macro system and supports\nthe creation of documents that intersperse macro definitions, reasoner\ninvocations and LaTeX-formatted natural language text. Invocation of various\nreasoners is supported: External provers as well as sub-systems of PIE, which\ninclude preprocessors, a Prolog-based first-order prover, methods for Craig\ninterpolation and methods for second-order quantifier elimination.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 10:17:35 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Wernhard", "Christoph", ""]]}, {"id": "1908.11216", "submitter": "Alexandre Garcia", "authors": "Alexandre Garcia, Pierre Colombo, Slim Essid, Florence d'Alch\\'e-Buc,\n  Chlo\\'e Clavel", "title": "From the Token to the Review: A Hierarchical Multimodal approach to\n  Opinion Mining", "comments": "Accepted to 2019 Conference on Empirical Methods in Natural Language\n  Processing (EMNLP) and 9th International Joint Conference on Natural Language\n  Processing (IJCNLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of predicting fine grained user opinion based on spontaneous spoken\nlanguage is a key problem arising in the development of Computational Agents as\nwell as in the development of social network based opinion miners.\nUnfortunately, gathering reliable data on which a model can be trained is\nnotoriously difficult and existing works rely only on coarsely labeled\nopinions. In this work we aim at bridging the gap separating fine grained\nopinion models already developed for written language and coarse grained models\ndeveloped for spontaneous multimodal opinion mining. We take advantage of the\nimplicit hierarchical structure of opinions to build a joint fine and coarse\ngrained opinion model that exploits different views of the opinion expression.\nThe resulting model shares some properties with attention-based models and is\nshown to provide competitive results on a recently released multimodal fine\ngrained annotated corpus.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 13:34:50 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 11:07:23 GMT"}, {"version": "v3", "created": "Tue, 10 Sep 2019 08:29:00 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Garcia", "Alexandre", ""], ["Colombo", "Pierre", ""], ["Essid", "Slim", ""], ["d'Alch\u00e9-Buc", "Florence", ""], ["Clavel", "Chlo\u00e9", ""]]}, {"id": "1908.11302", "submitter": "Denis Newman-Griffis", "authors": "Denis Newman-Griffis, Eric Fosler-Lussier", "title": "HARE: a Flexible Highlighting Annotator for Ranking and Exploration", "comments": "EMNLP 2019 Systems Demonstration. Online version including\n  supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration and analysis of potential data sources is a significant challenge\nin the application of NLP techniques to novel information domains. We describe\nHARE, a system for highlighting relevant information in document collections to\nsupport ranking and triage, which provides tools for post-processing and\nqualitative analysis for model development and tuning. We apply HARE to the use\ncase of narrative descriptions of mobility information in clinical data, and\ndemonstrate its utility in comparing candidate embedding features. We provide a\nweb-based interface for annotation visualization and document ranking, with a\nmodular backend to support interoperability with existing annotation tools. Our\nsystem is available online at https://github.com/OSU-slatelab/HARE.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 15:36:40 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Newman-Griffis", "Denis", ""], ["Fosler-Lussier", "Eric", ""]]}, {"id": "1908.11317", "submitter": "Hongxiao Bai", "authors": "Hongxiao Bai, Hai Zhao, Junhan Zhao", "title": "Memorizing All for Implicit Discourse Relation Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit discourse relation recognition is a challenging task due to the\nabsence of the necessary informative clue from explicit connectives. The\nprediction of relations requires a deep understanding of the semantic meanings\nof sentence pairs. As implicit discourse relation recognizer has to carefully\ntackle the semantic similarity of the given sentence pairs and the severe data\nsparsity issue exists in the meantime, it is supposed to be beneficial from\nmastering the entire training data. Thus in this paper, we propose a novel\nmemory mechanism to tackle the challenges for further performance improvement.\nThe memory mechanism is adequately memorizing information by pairing\nrepresentations and discourse relations of all training instances, which right\nfills the slot of the data-hungry issue in the current implicit discourse\nrelation recognizer. Our experiments show that our full model with memorizing\nthe entire training set reaches new state-of-the-art against strong baselines,\nwhich especially for the first time exceeds the milestone of 60% accuracy in\nthe 4-way task.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 16:00:25 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Bai", "Hongxiao", ""], ["Zhao", "Hai", ""], ["Zhao", "Junhan", ""]]}, {"id": "1908.11341", "submitter": "Sergei O. Kuznetsov", "authors": "Sergei O. Kuznetsov", "title": "Ordered Sets for Data Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This book dwells on mathematical and algorithmic issues of data analysis\nbased on generality order of descriptions and respective precision. To speak of\nthese topics correctly, we have to go some way getting acquainted with the\nimportant notions of relation and order theory. On the one hand, data often\nhave a complex structure with natural order on it. On the other hand, many\nsymbolic methods of data analysis and machine learning allow to compare the\nobtained classifiers w.r.t. their generality, which is also an order relation.\nEfficient algorithms are very important in data analysis, especially when one\ndeals with big data, so scalability is a real issue. That is why we analyze the\ncomputational complexity of algorithms and problems of data analysis. We start\nfrom the basic definitions and facts of algorithmic complexity theory and\nanalyze the complexity of various tools of data analysis we consider. The tools\nand methods of data analysis, like computing taxonomies, groups of similar\nobjects (concepts and n-clusters), dependencies in data, classification, etc.,\nare illustrated with applications in particular subject domains, from\nchemoinformatics to text mining and natural language processing.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 18:01:13 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Kuznetsov", "Sergei O.", ""]]}, {"id": "1908.11355", "submitter": "Piyawat Lertvittayakumjorn", "authors": "Piyawat Lertvittayakumjorn, Francesca Toni", "title": "Human-grounded Evaluations of Explanation Methods for Text\n  Classification", "comments": "17 pages including appendices; accepted to appear at EMNLP-IJCNLP\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the black-box nature of deep learning models, methods for explaining\nthe models' results are crucial to gain trust from humans and support\ncollaboration between AIs and humans. In this paper, we consider several\nmodel-agnostic and model-specific explanation methods for CNNs for text\nclassification and conduct three human-grounded evaluations, focusing on\ndifferent purposes of explanations: (1) revealing model behavior, (2)\njustifying model predictions, and (3) helping humans investigate uncertain\npredictions. The results highlight dissimilar qualities of the various\nexplanation methods we consider and show the degree to which these methods\ncould serve for each purpose.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 17:12:04 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Lertvittayakumjorn", "Piyawat", ""], ["Toni", "Francesca", ""]]}, {"id": "1908.11360", "submitter": "Tim Lyon", "authors": "Tim Lyon and Kees van Berkel", "title": "Automating Agential Reasoning: Proof-Calculi and Syntactic Decidability\n  for STIT Logics", "comments": "Included version of the paper \"Automating Agential Reasoning:\n  Proof-Calculi and Syntactic Decidability for STIT Logics\", accepted to the\n  22nd International Conference on Principles and Practice of Multi-Agent\n  Systems (PRIMA 2019)", "journal-ref": null, "doi": "10.1007/978-3-030-33792-6_13", "report-no": null, "categories": "cs.LO cs.AI cs.MA math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work provides proof-search algorithms and automated counter-model\nextraction for a class of STIT logics. With this, we answer an open problem\nconcerning syntactic decision procedures and cut-free calculi for STIT logics.\nA new class of cut-free complete labelled sequent calculi G3LdmL^m_n, for\nmulti-agent STIT with at most n-many choices, is introduced. We refine the\ncalculi G3LdmL^m_n through the use of propagation rules and demonstrate the\nadmissibility of their structural rules, resulting in auxiliary calculi\nLdm^m_nL. In the single-agent case, we show that the refined calculi Ldm^m_nL\nderive theorems within a restricted class of (forestlike) sequents, allowing us\nto provide proof-search algorithms that decide single-agent STIT logics. We\nprove that the proof-search algorithms are correct and terminate.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 17:33:37 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 13:48:33 GMT"}, {"version": "v3", "created": "Wed, 16 Oct 2019 17:16:02 GMT"}, {"version": "v4", "created": "Sat, 15 Feb 2020 08:29:26 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Lyon", "Tim", ""], ["van Berkel", "Kees", ""]]}, {"id": "1908.11406", "submitter": "Sercan Arik", "authors": "Linchao Zhu, Sercan O. Arik, Yi Yang and Tomas Pfister", "title": "Learning to Transfer Learn: Reinforcement Learning-Based Selection for\n  Adaptive Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel adaptive transfer learning framework, learning to transfer\nlearn (L2TL), to improve performance on a target dataset by careful extraction\nof the related information from a source dataset. Our framework considers\ncooperative optimization of shared weights between models for source and target\ntasks, and adjusts the constituent loss weights adaptively. The adaptation of\nthe weights is based on a reinforcement learning (RL) selection policy, guided\nwith a performance metric on the target validation set. We demonstrate that\nL2TL outperforms fine-tuning baselines and other adaptive transfer learning\nmethods on eight datasets. In the regimes of small-scale target datasets and\nsignificant label mismatch between source and target datasets, L2TL shows\nparticularly large benefits.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 18:16:24 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 15:39:01 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Zhu", "Linchao", ""], ["Arik", "Sercan O.", ""], ["Yang", "Yi", ""], ["Pfister", "Tomas", ""]]}, {"id": "1908.11451", "submitter": "Mahnaz Sadat Qafari", "authors": "Mahnaz Sadat Qafari and Wil van der Aalst", "title": "Fairness-Aware Process Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process mining is a multi-purpose tool enabling organizations to improve\ntheir processes. One of the primary purposes of process mining is finding the\nroot causes of performance or compliance problems in processes. The usual way\nof doing so is by gathering data from the process event log and other sources\nand then applying some data mining and machine learning techniques. However,\nthe results of applying such techniques are not always acceptable. In many\nsituations, this approach is prone to making obvious or unfair diagnoses and\napplying them may result in conclusions that are unsurprising or even\ndiscriminating (e.g., blaming overloaded employees for delays). In this paper,\nwe present a solution to this problem by creating a fair classifier for such\nsituations. The undesired effects are removed at the expense of reduction on\nthe accuracy of the resulting classifier. We have implemented this method as a\nplug-in in ProM. Using the implemented plug-in on two real event logs, we\ndecreased the discrimination caused by the classifier, while losing a small\nfraction of its accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 15:08:34 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Qafari", "Mahnaz Sadat", ""], ["van der Aalst", "Wil", ""]]}, {"id": "1908.11494", "submitter": "Xinyang Gu", "authors": "Jingbin Liu, Xinyang Gu, Shuai Liu", "title": "Reinforcement learning with world model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, model-free reinforcement learning algorithms have achieved\nremarkable performance on many decision making and control tasks, but high\nsample complexity and low sample efficiency still hinder the wide use of\nmodel-free reinforcement learning algorithms. In this paper, we argue that if\nwe intend to design an intelligent agent that learns fast and transfers well,\nthe agent must be able to reflect key elements of intelligence, like intuition,\nMemory, PredictionandCuriosity. We propose an agent framework that integrates\noff-policy reinforcement learning with world model learning, so as to embody\nthe important features of intelligence in our algorithm design. We adopt the\nstate-of-art model-free reinforcement learning algorithm, Soft Actor-Critic, as\nthe agent intuition, and world model learning through RNN to endow the agent\nwith memory, curiosity, and the ability to predict. We show that these ideas\ncan work collaboratively with each other and our agent (RMC) can give new\nstate-of-art results while maintaining sample efficiency and training\nstability. Moreover, our agent framework can be easily extended from MDP to\nPOMDP problems without performance loss.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 00:29:32 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 04:25:25 GMT"}, {"version": "v3", "created": "Wed, 11 Sep 2019 02:31:44 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 05:52:25 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Liu", "Jingbin", ""], ["Gu", "Xinyang", ""], ["Liu", "Shuai", ""]]}, {"id": "1908.11513", "submitter": "Xin Lv", "authors": "Xin Lv, Yuxian Gu, Xu Han, Lei Hou, Juanzi Li, Zhiyuan Liu", "title": "Adapting Meta Knowledge Graph Information for Multi-Hop Reasoning over\n  Few-Shot Relations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop knowledge graph (KG) reasoning is an effective and explainable\nmethod for predicting the target entity via reasoning paths in query answering\n(QA) task. Most previous methods assume that every relation in KGs has enough\ntraining triples, regardless of those few-shot relations which cannot provide\nsufficient triples for training robust reasoning models. In fact, the\nperformance of existing multi-hop reasoning methods drops significantly on\nfew-shot relations. In this paper, we propose a meta-based multi-hop reasoning\nmethod (Meta-KGR), which adopts meta-learning to learn effective meta\nparameters from high-frequency relations that could quickly adapt to few-shot\nrelations. We evaluate Meta-KGR on two public datasets sampled from Freebase\nand NELL, and the experimental results show that Meta-KGR outperforms the\ncurrent state-of-the-art methods in few-shot scenarios. Our code and datasets\ncan be obtained from https://github.com/ THU-KEG/MetaKGR.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 02:44:44 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Lv", "Xin", ""], ["Gu", "Yuxian", ""], ["Han", "Xu", ""], ["Hou", "Lei", ""], ["Li", "Juanzi", ""], ["Liu", "Zhiyuan", ""]]}, {"id": "1908.11521", "submitter": "Deng Cai", "authors": "Huajie Chen and Deng Cai and Wei Dai and Zehui Dai and Yadong Ding", "title": "Charge-Based Prison Term Prediction with Deep Gating Network", "comments": "EMNLP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Judgment prediction for legal cases has attracted much research efforts for\nits practice use, of which the ultimate goal is prison term prediction. While\nexisting work merely predicts the total prison term, in reality a defendant is\noften charged with multiple crimes. In this paper, we argue that charge-based\nprison term prediction (CPTP) not only better fits realistic needs, but also\nmakes the total prison term prediction more accurate and interpretable. We\ncollect the first large-scale structured data for CPTP and evaluate several\ncompetitive baselines. Based on the observation that fine-grained feature\nselection is the key to achieving good performance, we propose the Deep Gating\nNetwork (DGN) for charge-specific feature selection and aggregation.\nExperiments show that DGN achieves the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 03:44:10 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Chen", "Huajie", ""], ["Cai", "Deng", ""], ["Dai", "Wei", ""], ["Dai", "Zehui", ""], ["Ding", "Yadong", ""]]}, {"id": "1908.11566", "submitter": "Jessica McBroom", "authors": "Jessica McBroom, Irena Koprinska and Kalina Yacef", "title": "A Survey of Automated Programming Hint Generation -- The HINTS Framework", "comments": "26 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated tutoring systems offer the flexibility and scalability necessary to\nfacilitate the provision of high quality and universally accessible programming\neducation. In order to realise the full potential of these systems, recent work\nhas proposed a diverse range of techniques for automatically generating hints\nto assist students with programming exercises. This paper integrates these\napparently disparate approaches into a coherent whole. Specifically, it\nemphasises that all hint techniques can be understood as a series of simpler\ncomponents with similar properties. Using this insight, it presents a simple\nframework for describing such techniques, the Hint Iteration by Narrow-down and\nTransformation Steps (HINTS) framework, and it surveys recent work in the\ncontext of this framework. It discusses important implications of the survey\nand framework, including the need to further develop evaluation methods and the\nimportance of considering hint technique components when designing,\ncommunicating and evaluating hint systems. Ultimately, this paper is designed\nto facilitate future opportunities for the development, extension and\ncomparison of automated programming hint techniques in order to maximise their\neducational potential.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 07:06:28 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["McBroom", "Jessica", ""], ["Koprinska", "Irena", ""], ["Yacef", "Kalina", ""]]}, {"id": "1908.11598", "submitter": "Adam Richardson", "authors": "Adam Richardson, Aris Filos-Ratsikas, Boi Faltings", "title": "Rewarding High-Quality Data via Influence Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a crowdsourcing data acquisition scenario, such as federated\nlearning, where a Center collects data points from a set of rational Agents,\nwith the aim of training a model. For linear regression models, we show how a\npayment structure can be designed to incentivize the agents to provide\nhigh-quality data as early as possible, based on a characterization of the\ninfluence that data points have on the loss function of the model. Our\ncontributions can be summarized as follows: (a) we prove theoretically that\nthis scheme ensures truthful data reporting as a game-theoretic equilibrium and\nfurther demonstrate its robustness against mixtures of truthful and heuristic\ndata reports, (b) we design a procedure according to which the influence\ncomputation can be efficiently approximated and processed sequentially in\nbatches over time, (c) we develop a theory that allows correcting the\ndifference between the influence and the overall change in loss and (d) we\nevaluate our approach on real datasets, confirming our theoretical findings.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 08:57:18 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Richardson", "Adam", ""], ["Filos-Ratsikas", "Aris", ""], ["Faltings", "Boi", ""]]}, {"id": "1908.11706", "submitter": "Pablo Barros", "authors": "Pablo Barros, Nikhil Churamani, Angelica Lim, Stefan Wermter", "title": "The OMG-Empathy Dataset: Evaluating the Impact of Affective Behavior in\n  Storytelling", "comments": "2019 8th International Conference on Affective Computing and\n  Intelligent Interaction (ACII)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Processing human affective behavior is important for developing intelligent\nagents that interact with humans in complex interaction scenarios. A large\nnumber of current approaches that address this problem focus on classifying\nemotion expressions by grouping them into known categories. Such strategies\nneglect, among other aspects, the impact of the affective responses from an\nindividual on their interaction partner thus ignoring how people empathize\ntowards each other. This is also reflected in the datasets used to train models\nfor affective processing tasks. Most of the recent datasets, in particular, the\nones which capture natural interactions (\"in-the-wild\" datasets), are designed,\ncollected, and annotated based on the recognition of displayed affective\nreactions, ignoring how these displayed or expressed emotions are perceived. In\nthis paper, we propose a novel dataset composed of dyadic interactions\ndesigned, collected and annotated with a focus on measuring the affective\nimpact that eight different stories have on the listener. Each video of the\ndataset contains around 5 minutes of interaction where a speaker tells a story\nto a listener. After each interaction, the listener annotated, using a valence\nscale, how the story impacted their affective state, reflecting how they\nempathized with the speaker as well as the story. We also propose different\nevaluation protocols and a baseline that encourages participation in the\nadvancement of the field of artificial empathy and emotion contagion.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 12:53:51 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Barros", "Pablo", ""], ["Churamani", "Nikhil", ""], ["Lim", "Angelica", ""], ["Wermter", "Stefan", ""]]}, {"id": "1908.11722", "submitter": "Preslav Nakov", "authors": "Dimitrina Zlatkova, Preslav Nakov, Ivan Koychev", "title": "Fact-Checking Meets Fauxtography: Verifying Claims About Images", "comments": "Claims about Images; Fauxtography; Fact-Checking; Veracity; Fake News", "journal-ref": "EMNLP-2019", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent explosion of false claims in social media and on the Web in\ngeneral has given rise to a lot of manual fact-checking initiatives.\nUnfortunately, the number of claims that need to be fact-checked is several\norders of magnitude larger than what humans can handle manually. Thus, there\nhas been a lot of research aiming at automating the process. Interestingly,\nprevious work has largely ignored the growing number of claims about images.\nThis is despite the fact that visual imagery is more influential than text and\nnaturally appears alongside fake news. Here we aim at bridging this gap. In\nparticular, we create a new dataset for this problem, and we explore a variety\nof features modeling the claim, the image, and the relationship between the\nclaim and the image. The evaluation results show sizable improvements over the\nbaseline. We release our dataset, hoping to enable further research on\nfact-checking claims about images.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 13:12:21 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Zlatkova", "Dimitrina", ""], ["Nakov", "Preslav", ""], ["Koychev", "Ivan", ""]]}, {"id": "1908.11779", "submitter": "Eric Veith", "authors": "Eric M.S.P. Veith, Lars Fischer, Martin Tr\\\"oschel, Astrid Nie{\\ss}e", "title": "Analyzing Cyber-Physical Systems from the Perspective of Artificial\n  Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principles of modern cyber-physical system (CPS) analysis are based on\nanalytical methods that depend on whether safety or liveness requirements are\nconsidered. Complexity is abstracted through different techniques, ranging from\nstochastic modelling to contracts. However, both distributed heuristics and\nArtificial Intelligence (AI)-based approaches as well as the user perspective\nor unpredictable effects, such as accidents or the weather, introduce enough\nuncertainty to warrant reinforcement-learning-based approaches. This paper\ncompares traditional approaches in the domain of CPS modelling and analysis\nwith the AI researcher perspective to exploring unknown complex systems.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 20:57:27 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Veith", "Eric M. S. P.", ""], ["Fischer", "Lars", ""], ["Tr\u00f6schel", "Martin", ""], ["Nie\u00dfe", "Astrid", ""]]}, {"id": "1908.11782", "submitter": "Xuewen Yang", "authors": "Xuewen Yang, Yingru Liu, Dongliang Xie, Xin Wang, and Niranjan\n  Balasubramanian", "title": "Latent Part-of-Speech Sequences for Neural Machine Translation", "comments": "In proceedings of EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning target side syntactic structure has been shown to improve Neural\nMachine Translation (NMT). However, incorporating syntax through latent\nvariables introduces additional complexity in inference, as the models need to\nmarginalize over the latent syntactic structures. To avoid this, models often\nresort to greedy search which only allows them to explore a limited portion of\nthe latent space. In this work, we introduce a new latent variable model,\nLaSyn, that captures the co-dependence between syntax and semantics, while\nallowing for effective and efficient inference over the latent space. LaSyn\ndecouples direct dependence between successive latent variables, which allows\nits decoder to exhaustively search through the latent syntactic choices, while\nkeeping decoding speed proportional to the size of the latent variable\nvocabulary. We implement LaSyn by modifying a transformer-based NMT system and\ndesign a neural expectation maximization algorithm that we regularize with\npart-of-speech information as the latent sequences. Evaluations on four\ndifferent MT tasks show that incorporating target side syntax with LaSyn\nimproves both translation quality, and also provides an opportunity to improve\ndiversity.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 15:21:28 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Yang", "Xuewen", ""], ["Liu", "Yingru", ""], ["Xie", "Dongliang", ""], ["Wang", "Xin", ""], ["Balasubramanian", "Niranjan", ""]]}, {"id": "1908.11790", "submitter": "Dongyeop Kang", "authors": "Dongyeop Kang, Hiroaki Hayashi, Alan W Black, Eduard Hovy", "title": "Linguistic Versus Latent Relations for Modeling Coherent Flow in\n  Paragraphs", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating a long, coherent text such as a paragraph requires a high-level\ncontrol of different levels of relations between sentences (e.g., tense,\ncoreference). We call such a logical connection between sentences as a\n(paragraph) flow. In order to produce a coherent flow of text, we explore two\nforms of intersentential relations in a paragraph: one is a human-created\nlinguistical relation that forms a structure (e.g., discourse tree) and the\nother is a relation from latent representation learned from the sentences\nthemselves. Our two proposed models incorporate each form of relations into\ndocument-level language models: the former is a supervised model that jointly\nlearns a language model as well as discourse relation prediction, and the\nlatter is an unsupervised model that is hierarchically conditioned by a\nrecurrent neural network (RNN) over the latent information. Our proposed models\nwith both forms of relations outperform the baselines in partially conditioned\nparagraph generation task. Our codes and data are publicly available.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 15:30:11 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Kang", "Dongyeop", ""], ["Hayashi", "Hiroaki", ""], ["Black", "Alan W", ""], ["Hovy", "Eduard", ""]]}]