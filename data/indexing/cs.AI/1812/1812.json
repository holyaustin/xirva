[{"id": "1812.00025", "submitter": "Danijar Hafner", "authors": "Alexander Pashevich, Danijar Hafner, James Davidson, Rahul Sukthankar,\n  Cordelia Schmid", "title": "Modulated Policy Hierarchies", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving tasks with sparse rewards is a main challenge in reinforcement\nlearning. While hierarchical controllers are an intuitive approach to this\nproblem, current methods often require manual reward shaping, alternating\ntraining phases, or manually defined sub tasks. We introduce modulated policy\nhierarchies (MPH), that can learn end-to-end to solve tasks from sparse\nrewards. To achieve this, we study different modulation signals and exploration\nfor hierarchical controllers. Specifically, we find that communicating via\nbit-vectors is more efficient than selecting one out of multiple skills, as it\nenables mixing between them. To facilitate exploration, MPH uses its different\ntime scales for temporally extended intrinsic motivation at each level of the\nhierarchy. We evaluate MPH on the robotics tasks of pushing and sparse block\nstacking, where it outperforms recent baselines.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 19:12:18 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Pashevich", "Alexander", ""], ["Hafner", "Danijar", ""], ["Davidson", "James", ""], ["Sukthankar", "Rahul", ""], ["Schmid", "Cordelia", ""]]}, {"id": "1812.00045", "submitter": "Bilal Kartal", "authors": "Bilal Kartal, Pablo Hernandez-Leal, Matthew E. Taylor", "title": "Using Monte Carlo Tree Search as a Demonstrator within Asynchronous Deep\n  RL", "comments": "9 pages, 6 figures, To appear at AAAI-19 Workshop on Reinforcement\n  Learning in Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) has achieved great successes in recent\nyears with the help of novel methods and higher compute power. However, there\nare still several challenges to be addressed such as convergence to locally\noptimal policies and long training times. In this paper, firstly, we augment\nAsynchronous Advantage Actor-Critic (A3C) method with a novel self-supervised\nauxiliary task, i.e. \\emph{Terminal Prediction}, measuring temporal closeness\nto terminal states, namely A3C-TP. Secondly, we propose a new framework where\nplanning algorithms such as Monte Carlo tree search or other sources of\n(simulated) demonstrators can be integrated to asynchronous distributed DRL\nmethods. Compared to vanilla A3C, our proposed methods both learn faster and\nconverge to better policies on a two-player mini version of the Pommerman game.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 20:37:17 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Kartal", "Bilal", ""], ["Hernandez-Leal", "Pablo", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "1812.00054", "submitter": "Zeming Lin", "authors": "Gabriel Synnaeve, Zeming Lin, Jonas Gehring, Dan Gant, Vegard Mella,\n  Vasil Khalidov, Nicolas Carion, Nicolas Usunier", "title": "Forward Modeling for Partial Observation Strategy Games - A StarCraft\n  Defogger", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 31 (2018)\n  10759-10770", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate the problem of defogging as state estimation and future state\nprediction from previous, partial observations in the context of real-time\nstrategy games. We propose to employ encoder-decoder neural networks for this\ntask, and introduce proxy tasks and baselines for evaluation to assess their\nability of capturing basic game rules and high-level dynamics. By combining\nconvolutional neural networks and recurrent networks, we exploit spatial and\nsequential correlations and train well-performing models on a large dataset of\nhuman games of StarCraft: Brood War. Finally, we demonstrate the relevance of\nour models to downstream tasks by applying them for enemy unit prediction in a\nstate-of-the-art, rule-based StarCraft bot. We observe improvements in win\nrates against several strong community bots.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 20:48:31 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Synnaeve", "Gabriel", ""], ["Lin", "Zeming", ""], ["Gehring", "Jonas", ""], ["Gant", "Dan", ""], ["Mella", "Vegard", ""], ["Khalidov", "Vasil", ""], ["Carion", "Nicolas", ""], ["Usunier", "Nicolas", ""]]}, {"id": "1812.00076", "submitter": "Mark Weber", "authors": "Mark Weber, Jie Chen, Toyotaro Suzumura, Aldo Pareja, Tengfei Ma,\n  Hiroki Kanezashi, Tim Kaler, Charles E. Leiserson, Tao B. Schardl", "title": "Scalable Graph Learning for Anti-Money Laundering: A First Look", "comments": "NeurIPS 2018 Workshop on Challenges and Opportunities for AI in\n  Financial Services: the Impact of Fairness, Explainability, Accuracy, and\n  Privacy, Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Organized crime inflicts human suffering on a genocidal scale: the Mexican\ndrug cartels have murdered 150,000 people since 2006, upwards of 700,000 people\nper year are \"exported\" in a human trafficking industry enslaving an estimated\n40 million people. These nefarious industries rely on sophisticated money\nlaundering schemes to operate. Despite tremendous resources dedicated to\nanti-money laundering (AML) only a tiny fraction of illicit activity is\nprevented. The research community can help. In this brief paper, we map the\nstructural and behavioral dynamics driving the technical challenge. We review\nAML methods, current and emergent. We provide a first look at scalable graph\nconvolutional neural networks for forensic analysis of financial data, which is\nmassive, dense, and dynamic. We report preliminary experimental results using a\nlarge synthetic graph (1M nodes, 9M edges) generated by a data simulator we\ncreated called AMLSim. We consider opportunities for high performance\nefficiency, in terms of computation and memory, and we share results from a\nsimple graph compression experiment. Our results support our working hypothesis\nthat graph deep learning for AML bears great promise in the fight against\ncriminal financial activity.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 22:18:45 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Weber", "Mark", ""], ["Chen", "Jie", ""], ["Suzumura", "Toyotaro", ""], ["Pareja", "Aldo", ""], ["Ma", "Tengfei", ""], ["Kanezashi", "Hiroki", ""], ["Kaler", "Tim", ""], ["Leiserson", "Charles E.", ""], ["Schardl", "Tao B.", ""]]}, {"id": "1812.00091", "submitter": "Yixiu Zhao", "authors": "Yixiu Zhao, Ziyin Liu", "title": "BlockPuzzle - A Challenge in Physical Reasoning and Generalization for\n  Robot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a novel task framework under which a variety of\nphysical reasoning puzzles can be constructed using very simple rules. Under\nsparse reward settings, most of these tasks can be very challenging for a\nreinforcement learning agent to learn. We build several simple environments\nwith this task framework in Mujoco and OpenAI gym and attempt to solve them. We\nare able to solve the environments by designing curricula to guide the agent in\nlearning and using imitation learning methods to transfer knowledge from a\nsimpler environment. This is only a first step for the task framework, and\nfurther research on how to solve the harder tasks and transfer knowledge\nbetween tasks is needed.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 23:18:08 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Zhao", "Yixiu", ""], ["Liu", "Ziyin", ""]]}, {"id": "1812.00116", "submitter": "Honglei Liu", "authors": "Honglei Liu, Anuj Kumar, Wenhai Yang, Benoit Dumoulin", "title": "Explore-Exploit: A Framework for Interactive and Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive user interfaces need to continuously evolve based on the\ninteractions that a user has (or does not have) with the system. This may\nrequire constant exploration of various options that the system may have for\nthe user and obtaining signals of user preferences on those. However, such an\nexploration, especially when the set of available options itself can change\nfrequently, can lead to sub-optimal user experiences. We present\nExplore-Exploit: a framework designed to collect and utilize user feedback in\nan interactive and online setting that minimizes regressions in end-user\nexperience. This framework provides a suite of online learning operators for\nvarious tasks such as personalization ranking, candidate selection and active\nlearning. We demonstrate how to integrate this framework with run-time services\nto leverage online and interactive machine learning out-of-the-box. We also\npresent results demonstrating the efficiencies that can be achieved using the\nExplore-Exploit framework.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 01:16:24 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Liu", "Honglei", ""], ["Kumar", "Anuj", ""], ["Yang", "Wenhai", ""], ["Dumoulin", "Benoit", ""]]}, {"id": "1812.00136", "submitter": "Yujian Li", "authors": "Yujian Li", "title": "Theory of Cognitive Relativity: A Promising Paradigm for True AI", "comments": "38 pages (double spaced), 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of deep learning has brought artificial intelligence (AI) to the\nforefront. The ultimate goal of AI is to realize machines with human mind and\nconsciousness, but existing achievements mainly simulate intelligent behavior\non computer platforms. These achievements all belong to weak AI rather than\nstrong AI. How to achieve strong AI is not known yet in the field of\nintelligence science. Currently, this field is calling for a new paradigm,\nespecially Theory of Cognitive Relativity (TCR). The TCR aims to summarize a\nsimple and elegant set of first principles about the nature of intelligence, at\nleast including the Principle of World's Relativity and the Principle of\nSymbol's Relativity. The Principle of World's Relativity states that the\nsubjective world an intelligent agent can observe is strongly constrained by\nthe way it perceives the objective world. The Principle of Symbol's Relativity\nstates that an intelligent agent can use any physical symbol system to express\nwhat it observes in its subjective world. The two principles are derived from\nscientific facts and life experience. Thought experiments show that they are\nimportant to understand high-level intelligence and necessary to establish a\nscientific theory of mind and consciousness. Rather than brain-like\nintelligence, the TCR indeed advocates a promising change in direction to\nrealize true AI, i.e. artificial general intelligence or artificial\nconsciousness, particularly different from humans' and animals'. Furthermore, a\nTCR creed has been presented and extended to reveal the secrets of\nconsciousness and to guide realization of conscious machines. In the sense that\ntrue AI could be diversely implemented in a brain-different way, the TCR would\nprobably drive an intelligence revolution in combination with some additional\nfirst principles.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 04:01:03 GMT"}, {"version": "v2", "created": "Sun, 16 Dec 2018 14:11:42 GMT"}, {"version": "v3", "created": "Thu, 20 Dec 2018 06:59:22 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Li", "Yujian", ""]]}, {"id": "1812.00176", "submitter": "Zhouxing Shi", "authors": "Zhouxing Shi, Minlie Huang", "title": "A Deep Sequential Model for Discourse Parsing on Multi-Party Dialogues", "comments": "Accepted to AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discourse structures are beneficial for various NLP tasks such as dialogue\nunderstanding, question answering, sentiment analysis, and so on. This paper\npresents a deep sequential model for parsing discourse dependency structures of\nmulti-party dialogues. The proposed model aims to construct a discourse\ndependency tree by predicting dependency relations and constructing the\ndiscourse structure jointly and alternately. It makes a sequential scan of the\nElementary Discourse Units (EDUs) in a dialogue. For each EDU, the model\ndecides to which previous EDU the current one should link and what the\ncorresponding relation type is. The predicted link and relation type are then\nused to build the discourse structure incrementally with a structured encoder.\nDuring link prediction and relation classification, the model utilizes not only\nlocal information that represents the concerned EDUs, but also global\ninformation that encodes the EDU sequence and the discourse structure that is\nalready built at the current step. Experiments show that the proposed model\noutperforms all the state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 08:13:48 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Shi", "Zhouxing", ""], ["Huang", "Minlie", ""]]}, {"id": "1812.00190", "submitter": "Raja Naeem Akram", "authors": "Julia A. Meister, Raja Naeem Akram, Konstantinos Markantonakis", "title": "Deep Learning Application in Security and Privacy -- Theory and\n  Practice: A Position Paper", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technology is shaping our lives in a multitude of ways. This is fuelled by a\ntechnology infrastructure, both legacy and state of the art, composed of a\nheterogeneous group of hardware, software, services and organisations. Such\ninfrastructure faces a diverse range of challenges to its operations that\ninclude security, privacy, resilience, and quality of services. Among these,\ncybersecurity and privacy are taking the centre-stage, especially since the\nGeneral Data Protection Regulation (GDPR) came into effect. Traditional\nsecurity and privacy techniques are overstretched and adversarial actors have\nevolved to design exploitation techniques that circumvent protection. With the\never-increasing complexity of technology infrastructure, security and\nprivacy-preservation specialists have started to look for adaptable and\nflexible protection methods that can evolve (potentially autonomously) as the\nadversarial actor changes its techniques. For this, Artificial Intelligence\n(AI), Machine Learning (ML) and Deep Learning (DL) were put forward as\nsaviours. In this paper, we look at the promises of AI, ML, and DL stated in\nacademic and industrial literature and evaluate how realistic they are. We also\nput forward potential challenges a DL based security and privacy protection\ntechnique has to overcome. Finally, we conclude the paper with a discussion on\nwhat steps the DL and the security and privacy-preservation community have to\ntake to ensure that DL is not just going to be hype, but an opportunity to\nbuild a secure, reliable, and trusted technology infrastructure on which we can\nrely on for so much in our lives.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 11:30:23 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Meister", "Julia A.", ""], ["Akram", "Raja Naeem", ""], ["Markantonakis", "Konstantinos", ""]]}, {"id": "1812.00225", "submitter": "Harshavardhan Kamarthi", "authors": "Ameet Deshpande, Harshavardhan Kamarthi, Balaraman Ravindran", "title": "Discovering hierarchies using Imitation Learning from hierarchy aware\n  policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning options that allow agents to exhibit temporally higher order\nbehavior has proven to be useful in increasing exploration, reducing sample\ncomplexity and for various transfer scenarios. Deep Discovery of Options (DDO)\nis a generative algorithm that learns a hierarchical policy along with options\ndirectly from expert trajectories. We perform a qualitative and quantitative\nanalysis of options inferred from DDO in different domains. To this end, we\nsuggest different value metrics like option termination condition, hinge value\nfunction error and KL-Divergence based distance metric to compare different\nmethods. Analyzing the termination condition of the options and number of time\nsteps the options were run revealed that the options were terminating\nprematurely. We suggest modifications which can be incorporated easily and\nalleviates the problem of shorter options and a collapse of options to the same\nmode.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 16:39:21 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 10:47:54 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Deshpande", "Ameet", ""], ["Kamarthi", "Harshavardhan", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1812.00236", "submitter": "Juthika Mahanta Ms.", "authors": "Juthika Mahanta and Subhasis Panda", "title": "Fuzzy expert system for prediction of prostate cancer", "comments": "13 pages, 8 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fuzzy expert system (FES) for the prediction of prostate cancer (PC) is\nprescribed in this article. Age, prostate-specific antigen (PSA), prostate\nvolume (PV) and $\\%$ Free PSA ($\\%$FPSA) are fed as inputs into the FES and\nprostate cancer risk (PCR) is obtained as the output. Using knowledge based\nrules in Mamdani type inference method the output is calculated. If PCR $\\ge\n50\\%$, then the patient shall be advised to go for a biopsy test for\nconfirmation. The efficacy of the designed FES is tested against a clinical\ndata set. The true prediction for all the patients turns out to be $68.91\\%$\nwhereas only for positive biopsy cases it rises to $73.77\\%$. This simple yet\neffective FES can be used as supportive tool for decision making in medical\ndiagnosis.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 18:31:11 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Mahanta", "Juthika", ""], ["Panda", "Subhasis", ""]]}, {"id": "1812.00285", "submitter": "Sanmit Narvekar", "authors": "Sanmit Narvekar and Peter Stone", "title": "Learning Curriculum Policies for Reinforcement Learning", "comments": null, "journal-ref": "Proceedings of the 18th International Conference on Autonomous\n  Agents and Multiagent Systems (AAMAS 2019)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Curriculum learning in reinforcement learning is a training methodology that\nseeks to speed up learning of a difficult target task, by first training on a\nseries of simpler tasks and transferring the knowledge acquired to the target\ntask. Automatically choosing a sequence of such tasks (i.e. a curriculum) is an\nopen problem that has been the subject of much recent work in this area. In\nthis paper, we build upon a recent method for curriculum design, which\nformulates the curriculum sequencing problem as a Markov Decision Process. We\nextend this model to handle multiple transfer learning algorithms, and show for\nthe first time that a curriculum policy over this MDP can be learned from\nexperience. We explore various representations that make this possible, and\nevaluate our approach by learning curriculum policies for multiple agents in\ntwo different domains. The results show that our method produces curricula that\ncan train agents to perform on a target task as fast or faster than existing\nmethods.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 23:22:18 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Narvekar", "Sanmit", ""], ["Stone", "Peter", ""]]}, {"id": "1812.00301", "submitter": "Yantian Zha", "authors": "Yantian Zha, Yikang Li, Tianshu Yu, Subbarao Kambhampati, Baoxin Li", "title": "Plan-Recognition-Driven Attention Modeling for Visual Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human visual recognition of activities or external agents involves an\ninterplay between high-level plan recognition and low-level perception. Given\nthat, a natural question to ask is: can low-level perception be improved by\nhigh-level plan recognition? We formulate the problem of leveraging recognized\nplans to generate better top-down attention maps\n\\cite{gazzaniga2009,baluch2011} to improve the perception performance. We call\nthese top-down attention maps specifically as plan-recognition-driven attention\nmaps. To address this problem, we introduce the Pixel Dynamics Network. Pixel\nDynamics Network serves as an observation model, which predicts next states of\nobject points at each pixel location given observation of pixels and\npixel-level action feature. This is like internally learning a pixel-level\ndynamics model. Pixel Dynamics Network is a kind of Convolutional Neural\nNetwork (ConvNet), with specially-designed architecture. Therefore, Pixel\nDynamics Network could take the advantage of parallel computation of ConvNets,\nwhile learning the pixel-level dynamics model. We further prove the equivalence\nbetween Pixel Dynamics Network as an observation model, and the belief update\nin partially observable Markov decision process (POMDP) framework. We evaluate\nour Pixel Dynamics Network in event recognition tasks. We build an event\nrecognition system, ER-PRN, which takes Pixel Dynamics Network as a subroutine,\nto recognize events based on observations augmented by plan-recognition-driven\nattention.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 02:07:06 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Zha", "Yantian", ""], ["Li", "Yikang", ""], ["Yu", "Tianshu", ""], ["Kambhampati", "Subbarao", ""], ["Li", "Baoxin", ""]]}, {"id": "1812.00315", "submitter": "Xinyi Zhou", "authors": "Xinyi Zhou and Reza Zafarani", "title": "A Survey of Fake News: Fundamental Theories, Detection Methods, and\n  Opportunities", "comments": "ACM Computing Surveys (CSUR), 37 pages", "journal-ref": null, "doi": "10.1145/3395046", "report-no": null, "categories": "cs.CL cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The explosive growth in fake news and its erosion to democracy, justice, and\npublic trust has increased the demand for fake news detection and intervention.\nThis survey reviews and evaluates methods that can detect fake news from four\nperspectives: (1) the false knowledge it carries, (2) its writing style, (3)\nits propagation patterns, and (4) the credibility of its source. The survey\nalso highlights some potential research tasks based on the review. In\nparticular, we identify and detail related fundamental theories across various\ndisciplines to encourage interdisciplinary research on fake news. We hope this\nsurvey can facilitate collaborative efforts among experts in computer and\ninformation sciences, social sciences, political science, and journalism to\nresearch fake news, where such efforts can lead to fake news detection that is\nnot only efficient but more importantly, explainable.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 03:27:15 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 21:08:10 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Zhou", "Xinyi", ""], ["Zafarani", "Reza", ""]]}, {"id": "1812.00318", "submitter": "Richard Scalzo", "authors": "Richard Scalzo, David Kohn, Hugo Olierook, Gregory Houseman, Rohitash\n  Chandra, Mark Girolami, and Sally Cripps", "title": "Efficiency and robustness in Monte Carlo sampling of 3-D geophysical\n  inversions with Obsidian v0.1.2: Setting up for success", "comments": "17 pages, 5 figures, 1 table; submitted to Geoscientific Model\n  Development", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rigorous quantification of uncertainty in geophysical inversions is a\nchallenging problem. Inversions are often ill-posed and the likelihood surface\nmay be multi-modal; properties of any single mode become inadequate uncertainty\nmeasures, and sampling methods become inefficient for irregular posteriors or\nhigh-dimensional parameter spaces. We explore the influences of different\nchoices made by the practitioner on the efficiency and accuracy of Bayesian\ngeophysical inversion methods that rely on Markov chain Monte Carlo sampling to\nassess uncertainty, using a multi-sensor inversion of the three-dimensional\nstructure and composition of a region in the Cooper Basin of South Australia as\na case study. The inversion is performed using an updated version of the\nObsidian distributed inversion software. We find that the posterior for this\ninversion has complex local covariance structure, hindering the efficiency of\nadaptive sampling methods that adjust the proposal based on the chain history.\nWithin the context of a parallel-tempered Markov chain Monte Carlo scheme for\nexploring high-dimensional multi-modal posteriors, a preconditioned\nCrank-Nicholson proposal outperforms more conventional forms of random walk.\nAspects of the problem setup, such as priors on petrophysics or on 3-D\ngeological structure, affect the shape and separation of posterior modes,\ninfluencing sampling performance as well as the inversion results. Use of\nuninformative priors on sensor noise can improve inversion results by enabling\noptimal weighting among multiple sensors even if noise levels are uncertain.\nEfficiency could be further increased by using posterior gradient information\nwithin proposals, which Obsidian does not currently support, but which could be\nemulated using posterior surrogates.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 03:58:33 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Scalzo", "Richard", ""], ["Kohn", "David", ""], ["Olierook", "Hugo", ""], ["Houseman", "Gregory", ""], ["Chandra", "Rohitash", ""], ["Girolami", "Mark", ""], ["Cripps", "Sally", ""]]}, {"id": "1812.00336", "submitter": "Sijia Xu", "authors": "Sijia Xu, Hongyu Kuang, Zhi Zhuang, Renjie Hu, Yang Liu, Huyang Sun", "title": "Macro action selection with deep reinforcement learning in StarCraft", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  StarCraft (SC) is one of the most popular and successful Real Time Strategy\n(RTS) games. In recent years, SC is also widely accepted as a challenging\ntestbed for AI research because of its enormous state space, partially observed\ninformation, multi-agent collaboration, and so on. With the help of annual\nAIIDE and CIG competitions, a growing number of SC bots are proposed and\ncontinuously improved. However, a large gap remains between the top-level bot\nand the professional human player. One vital reason is that current SC bots\nmainly rely on predefined rules to select macro actions during their games.\nThese rules are not scalable and efficient enough to cope with the enormous yet\npartially observed state space in the game. In this paper, we propose a deep\nreinforcement learning (DRL) framework to improve the selection of macro\nactions. Our framework is based on the combination of the Ape-X DQN and the\nLong-Short-Term-Memory (LSTM). We use this framework to build our bot, named as\nLastOrder. Our evaluation, based on training against all bots from the AIIDE\n2017 StarCraft AI competition set, shows that LastOrder achieves an 83% winning\nrate, outperforming 26 bots in total 28 entrants.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 06:06:28 GMT"}, {"version": "v2", "created": "Sun, 3 Mar 2019 07:38:12 GMT"}, {"version": "v3", "created": "Sat, 12 Oct 2019 02:10:29 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Xu", "Sijia", ""], ["Kuang", "Hongyu", ""], ["Zhuang", "Zhi", ""], ["Hu", "Renjie", ""], ["Liu", "Yang", ""], ["Sun", "Huyang", ""]]}, {"id": "1812.00350", "submitter": "Heriberto Cuay\\'ahuitl", "authors": "Heriberto Cuay\\'ahuitl, Seonghan Ryu, Donghyeon Lee, Jihie Kim", "title": "A Study on Dialogue Reward Prediction for Open-Ended Conversational\n  Agents", "comments": "In NeurIPS Workshop on Conversational AI: \"Today's Practice and\n  Tomorrow's Potential\", December 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The amount of dialogue history to include in a conversational agent is often\nunderestimated and/or set in an empirical and thus possibly naive way. This\nsuggests that principled investigations into optimal context windows are\nurgently needed given that the amount of dialogue history and corresponding\nrepresentations can play an important role in the overall performance of a\nconversational system. This paper studies the amount of history required by\nconversational agents for reliably predicting dialogue rewards. The task of\ndialogue reward prediction is chosen for investigating the effects of varying\namounts of dialogue history and their impact on system performance.\nExperimental results using a dataset of 18K human-human dialogues report that\nlengthy dialogue histories of at least 10 sentences are preferred (25 sentences\nbeing the best in our experiments) over short ones, and that lengthy histories\nare useful for training dialogue reward predictors with strong positive\ncorrelations between target dialogue rewards and predicted ones.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 08:03:12 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Cuay\u00e1huitl", "Heriberto", ""], ["Ryu", "Seonghan", ""], ["Lee", "Donghyeon", ""], ["Kim", "Jihie", ""]]}, {"id": "1812.00456", "submitter": "Zhao Song", "authors": "Zhao Song and Ronald E. Parr and Lawrence Carin", "title": "Revisiting the Softmax Bellman Operator: New Benefits and New\n  Perspective", "comments": "To appear in ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The impact of softmax on the value function itself in reinforcement learning\n(RL) is often viewed as problematic because it leads to sub-optimal value (or\nQ) functions and interferes with the contraction properties of the Bellman\noperator. Surprisingly, despite these concerns, and independent of its effect\non exploration, the softmax Bellman operator when combined with Deep\nQ-learning, leads to Q-functions with superior policies in practice, even\noutperforming its double Q-learning counterpart. To better understand how and\nwhy this occurs, we revisit theoretical properties of the softmax Bellman\noperator, and prove that $(i)$ it converges to the standard Bellman operator\nexponentially fast in the inverse temperature parameter, and $(ii)$ the\ndistance of its Q function from the optimal one can be bounded. These alone do\nnot explain its superior performance, so we also show that the softmax operator\ncan reduce the overestimation error, which may give some insight into why a\nsub-optimal operator leads to better performance in the presence of value\nfunction approximation. A comparison among different Bellman operators is then\npresented, showing the trade-offs when selecting them.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 19:45:38 GMT"}, {"version": "v2", "created": "Sun, 19 May 2019 18:01:20 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Song", "Zhao", ""], ["Parr", "Ronald E.", ""], ["Carin", "Lawrence", ""]]}, {"id": "1812.00548", "submitter": "Joseph Bullock", "authors": "Joseph Bullock, Carolina Cuesta-Lazaro, Arnau Quera-Bofarull", "title": "XNet: A convolutional neural network (CNN) implementation for medical\n  X-Ray image segmentation suitable for small datasets", "comments": "11 pages, 5 figures, 2 tables", "journal-ref": "Proc. SPIE 10953, Medical Imaging 2019: Biomedical Applications in\n  Molecular, Structural, and Functional Imaging, 109531Z (15 March 2019)", "doi": "10.1117/12.2512451", "report-no": null, "categories": "cs.CV cs.AI physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  X-Ray image enhancement, along with many other medical image processing\napplications, requires the segmentation of images into bone, soft tissue, and\nopen beam regions. We apply a machine learning approach to this problem,\npresenting an end-to-end solution which results in robust and efficient\ninference. Since medical institutions frequently do not have the resources to\nprocess and label the large quantity of X-Ray images usually needed for neural\nnetwork training, we design an end-to-end solution for small datasets, while\nachieving state-of-the-art results. Our implementation produces an overall\naccuracy of 92%, F1 score of 0.92, and an AUC of 0.98, surpassing classical\nimage processing techniques, such as clustering and entropy based methods,\nwhile improving upon the output of existing neural networks used for\nsegmentation in non-medical contexts. The code used for this project is\navailable online.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 04:17:27 GMT"}, {"version": "v2", "created": "Sat, 20 Apr 2019 10:22:52 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Bullock", "Joseph", ""], ["Cuesta-Lazaro", "Carolina", ""], ["Quera-Bofarull", "Arnau", ""]]}, {"id": "1812.00555", "submitter": "Fang Liu", "authors": "Fang Liu", "title": "SUSAN: Segment Unannotated image Structure using Adversarial Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmentation of magnetic resonance (MR) images is a fundamental step in many\nmedical imaging-based applications. The recent implementation of deep\nconvolutional neural networks (CNNs) in image processing has been shown to have\nsignificant impacts on medical image segmentation. Network training of\nsegmentation CNNs typically requires images and paired annotation data\nrepresenting pixel-wise tissue labels referred to as masks. However, the\nsupervised training of highly efficient CNNs with deeper structure and more\nnetwork parameters requires a large number of training images and paired tissue\nmasks. Thus, there is great need to develop a generalized CNN-based\nsegmentation method which would be applicable for a wide variety of MR image\ndatasets with different tissue contrasts. The purpose of this study was to\ndevelop and evaluate a generalized CNN-based method for fully-automated\nsegmentation of different MR image datasets using a single set of annotated\ntraining data. A technique called cycle-consistent generative adversarial\nnetwork (CycleGAN) is applied as the core of the proposed method to perform\nimage-to-image translation between MR image datasets with different tissue\ncontrasts. A joint segmentation network is incorporated into the adversarial\nnetwork to obtain additional segmentation functionality. The proposed method\nwas evaluated for segmenting bone and cartilage on two clinical knee MR image\ndatasets acquired at our institution using only a single set of annotated data\nfrom a publicly available knee MR image dataset. The new technique may further\nimprove the applicability and efficiency of CNN-based segmentation of medical\nimages while eliminating the need for large amounts of annotated training data.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 05:00:07 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Liu", "Fang", ""]]}, {"id": "1812.00568", "submitter": "Frederik Ebert", "authors": "Frederik Ebert, Chelsea Finn, Sudeep Dasari, Annie Xie, Alex Lee,\n  Sergey Levine", "title": "Visual Foresight: Model-Based Deep Reinforcement Learning for\n  Vision-Based Robotic Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) algorithms can learn complex robotic skills\nfrom raw sensory inputs, but have yet to achieve the kind of broad\ngeneralization and applicability demonstrated by deep learning methods in\nsupervised domains. We present a deep RL method that is practical for\nreal-world robotics tasks, such as robotic manipulation, and generalizes\neffectively to never-before-seen tasks and objects. In these settings, ground\ntruth reward signals are typically unavailable, and we therefore propose a\nself-supervised model-based approach, where a predictive model learns to\ndirectly predict the future from raw sensory readings, such as camera images.\nAt test time, we explore three distinct goal specification methods: designated\npixels, where a user specifies desired object manipulation tasks by selecting\nparticular pixels in an image and corresponding goal positions, goal images,\nwhere the desired goal state is specified with an image, and image classifiers,\nwhich define spaces of goal states. Our deep predictive models are trained\nusing data collected autonomously and continuously by a robot interacting with\nhundreds of objects, without human supervision. We demonstrate that visual MPC\ncan generalize to never-before-seen objects---both rigid and deformable---and\nsolve a range of user-defined object manipulation tasks using the same model.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 06:06:25 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Ebert", "Frederik", ""], ["Finn", "Chelsea", ""], ["Dasari", "Sudeep", ""], ["Xie", "Annie", ""], ["Lee", "Alex", ""], ["Levine", "Sergey", ""]]}, {"id": "1812.00622", "submitter": "Jean-Philippe Fauvelle", "authors": "Jean-Philippe Fauvelle, Alexandre Dey, Sylvain Navers", "title": "Protection of an information system by artificial intelligence: a\n  three-phase approach based on behaviour analysis to detect a hostile scenario", "comments": "in French. European Cyber Week - C\\&ESAR Conference - Artificial\n  Intelligence and Cybersecurity, Nov 2018, Rennes, France. 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of the behaviour of individuals and entities (UEBA) is an area\nof artificial intelligence that detects hostile actions (e.g. attacks, fraud,\ninfluence, poisoning) due to the unusual nature of observed events, by affixing\nto a signature-based operation. A UEBA process usually involves two phases,\nlearning and inference. Intrusion detection systems (IDS) available still\nsuffer from bias, including over-simplification of problems, underexploitation\nof the AI potential, insufficient consideration of the temporality of events,\nand perfectible management of the memory cycle of behaviours. In addition,\nwhile an alert generated by a signature-based IDS can refer to the signature on\nwhich the detection is based, the IDS in the UEBA domain produce results, often\nassociated with a score, whose explainable character is less obvious. Our\nunsupervised approach is to enrich this process by adding a third phase to\ncorrelate events (incongruities, weak signals) that are presumed to be linked\ntogether, with the benefit of a reduction of false positives and negatives. We\nalso seek to avoid a so-called \"boiled frog\" bias inherent in continuous\nlearning. Our first results are interesting and have an explainable character,\nboth on synthetic and real data.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 09:29:03 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Fauvelle", "Jean-Philippe", ""], ["Dey", "Alexandre", ""], ["Navers", "Sylvain", ""]]}, {"id": "1812.00647", "submitter": "Shichao Li", "authors": "Shichao Li, Xin Yang and Tim Cheng", "title": "Deep Hierarchical Machine: a Flexible Divide-and-Conquer Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Deep Hierarchical Machine (DHM), a model inspired from the\ndivide-and-conquer strategy while emphasizing representation learning ability\nand flexibility. A stochastic routing framework as used by recent deep neural\ndecision/regression forests is incorporated, but we remove the need to evaluate\nunnecessary computation paths by utilizing a different topology and introducing\na probabilistic pruning technique. We also show a specified version of DHM\n(DSHM) for efficiency, which inherits the sparse feature extraction process as\nin traditional decision tree with pixel-difference feature. To achieve sparse\nfeature extraction, we propose to utilize sparse convolution operation in DSHM\nand show one possibility of introducing sparse convolution kernels by using\nlocal binary convolution layer. DHM can be applied to both classification and\nregression problems, and we validate it on standard image classification and\nface alignment tasks to show its advantages over past architectures.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 10:34:01 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Li", "Shichao", ""], ["Yang", "Xin", ""], ["Cheng", "Tim", ""]]}, {"id": "1812.00660", "submitter": "Chia-Che Chang", "authors": "Wei-Chun Chen, Chia-Che Chang, Chien-Yu Lu, and Che-Rung Lee", "title": "Knowledge Distillation with Feature Maps for Image Classification", "comments": "Knowledge Distillation, Model Compression, and Generative Adversarial\n  Network, ACCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The model reduction problem that eases the computation costs and latency of\ncomplex deep learning architectures has received an increasing number of\ninvestigations owing to its importance in model deployment. One promising\nmethod is knowledge distillation (KD), which creates a fast-to-execute student\nmodel to mimic a large teacher network. In this paper, we propose a method,\ncalled KDFM (Knowledge Distillation with Feature Maps), which improves the\neffectiveness of KD by learning the feature maps from the teacher network. Two\nmajor techniques used in KDFM are shared classifier and generative adversarial\nnetwork. Experimental results show that KDFM can use a four layers CNN to mimic\nDenseNet-40 and use MobileNet to mimic DenseNet-100. Both student networks have\nless than 1\\% accuracy loss comparing to their teacher models for CIFAR-100\ndatasets. The student networks are 2-6 times faster than their teacher models\nfor inference, and the model size of MobileNet is less than half of\nDenseNet-100's.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 11:03:04 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Chen", "Wei-Chun", ""], ["Chang", "Chia-Che", ""], ["Lu", "Chien-Yu", ""], ["Lee", "Che-Rung", ""]]}, {"id": "1812.00786", "submitter": "Bradley Gram-Hansen", "authors": "Patrick Helber, Bradley Gram-Hansen, Indhu Varatharajan, Faiza Azam,\n  Alejandro Coca-Castro, Veronika Kopackova, Piotr Bilinski", "title": "Generating Material Maps to Map Informal Settlements", "comments": "Appeared at the 32nd Conference on Neural Information Processing\n  Systems (NeurlPS 2018) Machine Learning for the Developing World (ML4DW)\n  Workshop", "journal-ref": "NeurlPS workshop on Machine Learning for the Developing World\n  (ML4DW), 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting and mapping informal settlements encompasses several of the United\nNations sustainable development goals. This is because informal settlements are\nhome to the most socially and economically vulnerable people on the planet.\nThus, understanding where these settlements are is of paramount importance to\nboth government and non-government organizations (NGOs), such as the United\nNations Children's Fund (UNICEF), who can use this information to deliver\neffective social and economic aid. We propose a method that detects and maps\nthe locations of informal settlements using only freely available, Sentinel-2\nlow-resolution satellite spectral data and socio-economic data. This is in\ncontrast to previous studies that only use costly very-high resolution (VHR)\nsatellite and aerial imagery. We show how we can detect informal settlements by\ncombining both domain knowledge and machine learning techniques, to build a\nclassifier that looks for known roofing materials used in informal settlements.\nPlease find additional material at\nhttps://frontierdevelopmentlab.github.io/informal-settlements/.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 09:09:41 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 12:19:50 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Helber", "Patrick", ""], ["Gram-Hansen", "Bradley", ""], ["Varatharajan", "Indhu", ""], ["Azam", "Faiza", ""], ["Coca-Castro", "Alejandro", ""], ["Kopackova", "Veronika", ""], ["Bilinski", "Piotr", ""]]}, {"id": "1812.00812", "submitter": "Patrick Helber", "authors": "Patrick Helber, Bradley Gram-Hansen, Indhu Varatharajan, Faiza Azam,\n  Alejandro Coca-Castro, Veronika Kopackova, Piotr Bilinski", "title": "Mapping Informal Settlements in Developing Countries with\n  Multi-resolution, Multi-spectral Data", "comments": "arXiv admin note: text overlap with arXiv:1812.00786", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting and mapping informal settlements encompasses several of the United\nNations sustainable development goals. This is because informal settlements are\nhome to the most socially and economically vulnerable people on the planet.\nThus, understanding where these settlements are is of paramount importance to\nboth government and non-government organizations (NGOs), such as the United\nNations Children's Fund (UNICEF), who can use this information to deliver\neffective social and economic aid. We propose two effective methods for\ndetecting and mapping the locations of informal settlements. One uses only\nlow-resolution (LR), freely available, Sentinel-2 multispectral satellite\nimagery with noisy annotations, whilst the other is a deep learning approach\nthat uses only costly very-high-resolution (VHR) satellite imagery. To our\nknowledge, we are the first to map informal settlements successfully with\nlow-resolution satellite imagery. We extensively evaluate and compare the\nproposed methods. Please find additional material at\nhttps://frontierdevelopmentlab.github.io/informal-settlements/.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 10:38:37 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Helber", "Patrick", ""], ["Gram-Hansen", "Bradley", ""], ["Varatharajan", "Indhu", ""], ["Azam", "Faiza", ""], ["Coca-Castro", "Alejandro", ""], ["Kopackova", "Veronika", ""], ["Bilinski", "Piotr", ""]]}, {"id": "1812.00825", "submitter": "Po-Hsuan Cameron Chen", "authors": "Po-Hsuan Cameron Chen, Krishna Gadepalli, Robert MacDonald, Yun Liu,\n  Kunal Nagpal, Timo Kohlberger, Jeffrey Dean, Greg S. Corrado, Jason D. Hipp,\n  Martin C. Stumpe", "title": "Microscope 2.0: An Augmented Reality Microscope with Real-time\n  Artificial Intelligence Integration", "comments": null, "journal-ref": "Nature Medicine (2019)", "doi": "10.1038/s41591-019-0539-7", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The brightfield microscope is instrumental in the visual examination of both\nbiological and physical samples at sub-millimeter scales. One key clinical\napplication has been in cancer histopathology, where the microscopic assessment\nof the tissue samples is used for the diagnosis and staging of cancer and thus\nguides clinical therapy. However, the interpretation of these samples is\ninherently subjective, resulting in significant diagnostic variability.\nMoreover, in many regions of the world, access to pathologists is severely\nlimited due to lack of trained personnel. In this regard, Artificial\nIntelligence (AI) based tools promise to improve the access and quality of\nhealthcare. However, despite significant advances in AI research, integration\nof these tools into real-world cancer diagnosis workflows remains challenging\nbecause of the costs of image digitization and difficulties in deploying AI\nsolutions. Here we propose a cost-effective solution to the integration of AI:\nthe Augmented Reality Microscope (ARM). The ARM overlays AI-based information\nonto the current view of the sample through the optical pathway in real-time,\nenabling seamless integration of AI into the regular microscopy workflow. We\ndemonstrate the utility of ARM in the detection of lymph node metastases in\nbreast cancer and the identification of prostate cancer with a latency that\nsupports real-time workflows. We anticipate that ARM will remove barriers\ntowards the use of AI in microscopic analysis and thus improve the accuracy and\nefficiency of cancer diagnosis. This approach is applicable to other microscopy\ntasks and AI algorithms in the life sciences and beyond.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 21:02:50 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 05:36:36 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Chen", "Po-Hsuan Cameron", ""], ["Gadepalli", "Krishna", ""], ["MacDonald", "Robert", ""], ["Liu", "Yun", ""], ["Nagpal", "Kunal", ""], ["Kohlberger", "Timo", ""], ["Dean", "Jeffrey", ""], ["Corrado", "Greg S.", ""], ["Hipp", "Jason D.", ""], ["Stumpe", "Martin C.", ""]]}, {"id": "1812.00843", "submitter": "Hengxuan Li", "authors": "Hengxuan Li, Collin F. Lynch, Tiffany Barnes", "title": "Early Prediction of Course Grades: Models and Feature Selection", "comments": null, "journal-ref": "The Proceedings of the 11th International Conference on\n  Educational Data Mining (EDM 2018). 492-495", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we compare predictive models for students' final performance\nin a blended course using a set of generic features collected from the first\nsix weeks of class. These features were extracted from students' online\nhomework submission logs as well as other online actions. We compare the\neffectiveness of 5 different ML algorithms (SVMs, Support Vector Regression,\nDecision Tree, Naive Bayes and K-Nearest Neighbor). We found that SVMs\noutperform other models and improve when compared to the baseline. This study\ndemonstrates feasible implementations for predictive models that rely on common\ndata from blended courses that can be used to monitor students' progress and to\ntailor instruction.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 15:37:13 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Li", "Hengxuan", ""], ["Lynch", "Collin F.", ""], ["Barnes", "Tiffany", ""]]}, {"id": "1812.00880", "submitter": "Jonathan P. Chen", "authors": "Jonathan P. Chen, Fritz Obermeyer, Vladimir Lyapunov, Lionel Gueguen,\n  Noah D. Goodman", "title": "Joint Mapping and Calibration via Differentiable Sensor Fusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We leverage automatic differentiation (AD) and probabilistic programming to\ndevelop an end-to-end optimization algorithm for batch triangulation of a large\nnumber of unknown objects. Given noisy detections extracted from noisily\ngeo-located street level imagery without depth information, we jointly estimate\nthe number and location of objects of different types, together with parameters\nfor sensor noise characteristics and prior distribution of objects conditioned\non side information. The entire algorithm is framed as nested stochastic\nvariational inference. An inner loop solves a soft data association problem via\nloopy belief propagation; a middle loop performs soft EM clustering using a\nregularized Newton solver (leveraging an AD framework); an outer loop\nbackpropagates through the inner loops to train global parameters. We place\npriors over sensor parameters for different traffic object types, and\ndemonstrate improvements with richer priors incorporating knowledge of the\nenvironment.\n  We test our algorithm on detections of road signs observed by cars with\nmounted cameras, though in practice this technique can be used for any\ngeo-tagged images. The detections were extracted by neural image detectors and\nclassifiers, and we independently triangulate each type of sign (e.g. stop,\ntraffic light). We find that our model is more robust to DNN misclassifications\nthan current methods, generalizes across sign types, and can use geometric\ninformation to increase precision. Our algorithm outperforms our current\nproduction baseline based on k-means clustering. We show that variational\ninference training allows generalization by learning sign-specific parameters.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 06:22:06 GMT"}, {"version": "v2", "created": "Thu, 20 Dec 2018 04:58:10 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Chen", "Jonathan P.", ""], ["Obermeyer", "Fritz", ""], ["Lyapunov", "Vladimir", ""], ["Gueguen", "Lionel", ""], ["Goodman", "Noah D.", ""]]}, {"id": "1812.00886", "submitter": "Wei Wei", "authors": "Wei Wei, Lingjie Xu, Lingling Jin, Wei Zhang, Tianjun Zhang", "title": "AI Matrix - Synthetic Benchmarks for DNN", "comments": "Accepted by SC' 18\n  https://sc18.supercomputing.org/proceedings/tech_poster/tech_poster_pages/post153.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network (DNN) architectures, such as convolutional neural\nnetworks (CNN), involve heavy computation and require hardware, such as CPU,\nGPU, and AI accelerators, to provide the massive computing power. With the many\nvarieties of AI hardware prevailing on the market, it is often hard to decide\nwhich one is the best to use. Thus, benchmarking AI hardware effectively\nbecomes important and is of great help to select and optimize AI hardware.\nUnfortunately, there are few AI benchmarks available in both academia and\nindustry. Examples are BenchNN[1], DeepBench[2], and Dawn Bench[3], which are\nusually a collection of typical real DNN applications. While these benchmarks\nprovide performance comparison across different AI hardware, they suffer from a\nnumber of drawbacks. First, they cannot adapt to the emerging changes of DNN\nalgorithms and are fixed once selected. Second, they contain tens to hundreds\nof applications and take very long time to finish running. Third, they are\nmainly selected from open sources, which are restricted by copyright and are\nnot representable to proprietary applications. In this work, a synthetic\nbenchmarks framework is firstly proposed to address the above drawbacks of AI\nbenchmarks. Instead of pre-selecting a set of open-sourced benchmarks and\nrunning all of them, the synthetic approach generates only a one or few\nbenchmarks that best represent a broad range of applications using profiled\nworkload characteristics data of these applications. Thus, it can adapt to\nemerging changes of new DNN algorithms by re-profiling new applications and\nupdating itself, greatly reduce benchmark count and running time, and strongly\nrepresent DNN applications of interests. The generated benchmarks are called AI\nMatrix, serving as a performance benchmarks matching the statistical workload\ncharacteristics of a combination of applications of interests.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 19:20:35 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Wei", "Wei", ""], ["Xu", "Lingjie", ""], ["Jin", "Lingling", ""], ["Zhang", "Wei", ""], ["Zhang", "Tianjun", ""]]}, {"id": "1812.00888", "submitter": "D Yoan L Mekontchou Yomba", "authors": "D Yoan L. Mekontchou Yomba", "title": "A Consolidated Approach to Convolutional Neural Networks and the\n  Kolmogorov Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to precisely quantify similarity between various entities has\nbeen a fundamental complication in various problem spaces specifically in the\nclassification of cellular images. Contemporary similarity measures applied in\nthe domain of image processing proposed by the scientific community are mainly\npursued in supervised settings. In this work, we will explore the innovative\nalgorithmic normalized compression distance metric based on the information\ntheoretic concept of Kolmogorov Complexity. Additionally we will observe its\npossible implementation in Convolutional Neural Networks to facilitate and\nautomate the classification of Retinal Pigment Epithelial cell cultures for use\nin Age Related Macular Degeneration Stem Cell therapy in an unsupervised\nsetting.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 01:58:39 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Yomba", "D Yoan L. Mekontchou", ""]]}, {"id": "1812.00912", "submitter": "Mohammad Akbari", "authors": "Mohammad Akbari, Kunal Relia, Anas Elghafari, Rumi Chunara", "title": "From the User to the Medium: Neural Profiling Across Web Communities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online communities provide a unique way for individuals to access information\nfrom those in similar circumstances, which can be critical for health\nconditions that require daily and personalized management. As these groups and\ntopics often arise organically, identifying the types of topics discussed is\nnecessary to understand their needs. As well, these communities and people in\nthem can be quite diverse, and existing community detection methods have not\nbeen extended towards evaluating these heterogeneities. This has been limited\nas community detection methodologies have not focused on community detection\nbased on semantic relations between textual features of the user-generated\ncontent. Thus here we develop an approach, NeuroCom, that optimally finds dense\ngroups of users as communities in a latent space inferred by neural\nrepresentation of published contents of users. By embedding of words and\nmessages, we show that NeuroCom demonstrates improved clustering and identifies\nmore nuanced discussion topics in contrast to other common unsupervised\nlearning approaches.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 17:12:23 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Akbari", "Mohammad", ""], ["Relia", "Kunal", ""], ["Elghafari", "Anas", ""], ["Chunara", "Rumi", ""]]}, {"id": "1812.00914", "submitter": "Minghan Li", "authors": "Minghan Li, Tanli Zuo, Ruicheng Li, Martha White, Weishi Zheng", "title": "Accelerating Large Scale Knowledge Distillation via Dynamic Importance\n  Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation is an effective technique that transfers knowledge\nfrom a large teacher model to a shallow student. However, just like massive\nclassification, large scale knowledge distillation also imposes heavy\ncomputational costs on training models of deep neural networks, as the softmax\nactivations at the last layer involve computing probabilities over numerous\nclasses. In this work, we apply the idea of importance sampling which is often\nused in Neural Machine Translation on large scale knowledge distillation. We\npresent a method called dynamic importance sampling, where ranked classes are\nsampled from a dynamic distribution derived from the interaction between the\nteacher and student in full distillation. We highlight the utility of our\nproposal prior which helps the student capture the main information in the loss\nfunction. Our approach manages to reduce the computational cost at training\ntime while maintaining the competitive performance on CIFAR-100 and Market-1501\nperson re-identification datasets.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 17:15:44 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Li", "Minghan", ""], ["Zuo", "Tanli", ""], ["Li", "Ruicheng", ""], ["White", "Martha", ""], ["Zheng", "Weishi", ""]]}, {"id": "1812.00950", "submitter": "Yijie Guo", "authors": "Yijie Guo, Junhyuk Oh, Satinder Singh, Honglak Lee", "title": "Generative Adversarial Self-Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores a simple regularizer for reinforcement learning by\nproposing Generative Adversarial Self-Imitation Learning (GASIL), which\nencourages the agent to imitate past good trajectories via generative\nadversarial imitation learning framework. Instead of directly maximizing\nrewards, GASIL focuses on reproducing past good trajectories, which can\npotentially make long-term credit assignment easier when rewards are sparse and\ndelayed. GASIL can be easily combined with any policy gradient objective by\nusing GASIL as a learned shaped reward function. Our experimental results show\nthat GASIL improves the performance of proximal policy optimization on 2D Point\nMass and MuJoCo environments with delayed reward and stochastic dynamics.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 18:21:18 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Guo", "Yijie", ""], ["Oh", "Junhyuk", ""], ["Singh", "Satinder", ""], ["Lee", "Honglak", ""]]}, {"id": "1812.00967", "submitter": "Yanjun Li", "authors": "Yanjun Li, Hengtong Kang, Ketian Ye, Shuyu Yin and Xiaolin Li", "title": "FoldingZero: Protein Folding from Scratch in Hydrophobic-Polar Model", "comments": "Deep Reinforcement Learning Workshop (Oral) of NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  De novo protein structure prediction from amino acid sequence is one of the\nmost challenging problems in computational biology. As one of the extensively\nexplored mathematical models for protein folding, Hydrophobic-Polar (HP) model\nenables thorough investigation of protein structure formation and evolution.\nAlthough HP model discretizes the conformational space and simplifies the\nfolding energy function, it has been proven to be an NP-complete problem. In\nthis paper, we propose a novel protein folding framework FoldingZero,\nself-folding a de novo protein 2D HP structure from scratch based on deep\nreinforcement learning. FoldingZero features the coupled approach of a two-head\n(policy and value heads) deep convolutional neural network (HPNet) and a\nregularized Upper Confidence Bounds for Trees (R-UCT). It is trained solely by\na reinforcement learning algorithm, which improves HPNet and R-UCT iteratively\nthrough iterative policy optimization. Without any supervision and domain\nknowledge, FoldingZero not only achieves comparable results, but also learns\nthe latent folding knowledge to stabilize the structure. Without exponential\ncomputation, FoldingZero shows promising potential to be adopted for real-world\nprotein properties prediction.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 18:43:27 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Li", "Yanjun", ""], ["Kang", "Hengtong", ""], ["Ye", "Ketian", ""], ["Yin", "Shuyu", ""], ["Li", "Xiaolin", ""]]}, {"id": "1812.00971", "submitter": "Roozbeh Mottaghi", "authors": "Mitchell Wortsman, Kiana Ehsani, Mohammad Rastegari, Ali Farhadi,\n  Roozbeh Mottaghi", "title": "Learning to Learn How to Learn: Self-Adaptive Visual Navigation Using\n  Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning is an inherently continuous phenomenon. When humans learn a new task\nthere is no explicit distinction between training and inference. As we learn a\ntask, we keep learning about it while performing the task. What we learn and\nhow we learn it varies during different stages of learning. Learning how to\nlearn and adapt is a key property that enables us to generalize effortlessly to\nnew settings. This is in contrast with conventional settings in machine\nlearning where a trained model is frozen during inference. In this paper we\nstudy the problem of learning to learn at both training and test time in the\ncontext of visual navigation. A fundamental challenge in navigation is\ngeneralization to unseen scenes. In this paper we propose a self-adaptive\nvisual navigation method (SAVN) which learns to adapt to new environments\nwithout any explicit supervision. Our solution is a meta-reinforcement learning\napproach where an agent learns a self-supervised interaction loss that\nencourages effective navigation. Our experiments, performed in the AI2-THOR\nframework, show major improvements in both success rate and SPL for visual\nnavigation in novel scenes. Our code and data are available at:\nhttps://github.com/allenai/savn .\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 18:46:02 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2019 23:55:19 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Wortsman", "Mitchell", ""], ["Ehsani", "Kiana", ""], ["Rastegari", "Mohammad", ""], ["Farhadi", "Ali", ""], ["Mottaghi", "Roozbeh", ""]]}, {"id": "1812.01032", "submitter": "Paul Knott PhD MPhys BSc", "authors": "Rosanna Nichols, Lana Mineh, Jes\\'us Rubio, Jonathan C. F. Matthews\n  and Paul A. Knott", "title": "Designing quantum experiments with a genetic algorithm", "comments": "11 pages + Appendix, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a genetic algorithm that designs quantum optics experiments for\nengineering quantum states with specific properties. Our algorithm is powerful\nand flexible, and can easily be modified to find methods of engineering states\nfor a range of applications. Here we focus on quantum metrology. First, we\nconsider the noise-free case, and use the algorithm to find quantum states with\na large quantum Fisher information (QFI). We find methods, which only involve\nexperimental elements that are available with current or near-future\ntechnology, for engineering quantum states with up to a 100-fold improvement\nover the best classical state, and a 20-fold improvement over the optimal\nGaussian state. Such states are a superposition of the vacuum with a large\nnumber of photons (around $80$), and can hence be seen as\nSchr\\\"odinger-cat-like states. We then apply the two most dominant noise\nsources in our setting -- photon loss and imperfect heralding -- and use the\nalgorithm to find quantum states that still improve over the optimal Gaussian\nstate with realistic levels of noise. This will open up experimental and\ntechnological work in using exotic non-Gaussian states for quantum-enhanced\nphase measurements. Finally, we use the Bayesian mean square error to look\nbeyond the regime of validity of the QFI, finding quantum states with precision\nenhancements over the alternatives even when the experiment operates in the\nregime of limited data.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 19:06:33 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 15:54:09 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Nichols", "Rosanna", ""], ["Mineh", "Lana", ""], ["Rubio", "Jes\u00fas", ""], ["Matthews", "Jonathan C. F.", ""], ["Knott", "Paul A.", ""]]}, {"id": "1812.01054", "submitter": "Sebastian Flennerhag", "authors": "Sebastian Flennerhag, Pablo G. Moreno, Neil D. Lawrence, Andreas\n  Damianou", "title": "Transferring Knowledge across Learning Processes", "comments": "Published as a conference paper at ICLR 2019; 23 pages, 8 figures, 6\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In complex transfer learning scenarios new tasks might not be tightly linked\nto previous tasks. Approaches that transfer information contained only in the\nfinal parameters of a source model will therefore struggle. Instead, transfer\nlearning at a higher level of abstraction is needed. We propose Leap, a\nframework that achieves this by transferring knowledge across learning\nprocesses. We associate each task with a manifold on which the training process\ntravels from initialization to final parameters and construct a meta-learning\nobjective that minimizes the expected length of this path. Our framework\nleverages only information obtained during training and can be computed on the\nfly at negligible cost. We demonstrate that our framework outperforms competing\nmethods, both in meta-learning and transfer learning, on a set of computer\nvision tasks. Finally, we demonstrate that Leap can transfer knowledge across\nlearning processes in demanding reinforcement learning environments (Atari)\nthat involve millions of gradient steps.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 19:43:16 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 16:28:01 GMT"}, {"version": "v3", "created": "Fri, 22 Mar 2019 13:44:59 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Flennerhag", "Sebastian", ""], ["Moreno", "Pablo G.", ""], ["Lawrence", "Neil D.", ""], ["Damianou", "Andreas", ""]]}, {"id": "1812.01063", "submitter": "Azin Asgarian", "authors": "Azin Asgarian, Parinaz Sobhani, Ji Chao Zhang, Madalin Mihailescu,\n  Ariel Sibilia, Ahmed Bilal Ashraf, Babak Taati", "title": "A Hybrid Instance-based Transfer Learning Method", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:cs/0101200", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/174", "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, supervised machine learning models have demonstrated\ntremendous success in a variety of application domains. Despite the promising\nresults, these successful models are data hungry and their performance relies\nheavily on the size of training data. However, in many healthcare applications\nit is difficult to collect sufficiently large training datasets. Transfer\nlearning can help overcome this issue by transferring the knowledge from\nreadily available datasets (source) to a new dataset (target). In this work, we\npropose a hybrid instance-based transfer learning method that outperforms a set\nof baselines including state-of-the-art instance-based transfer learning\napproaches. Our method uses a probabilistic weighting strategy to fuse\ninformation from the source domain to the model learned in the target domain.\nOur method is generic, applicable to multiple source domains, and robust with\nrespect to negative transfer. We demonstrate the effectiveness of our approach\nthrough extensive experiments for two different applications.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 20:15:05 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Asgarian", "Azin", ""], ["Sobhani", "Parinaz", ""], ["Zhang", "Ji Chao", ""], ["Mihailescu", "Madalin", ""], ["Sibilia", "Ariel", ""], ["Ashraf", "Ahmed Bilal", ""], ["Taati", "Babak", ""]]}, {"id": "1812.01070", "submitter": "Wengong Jin", "authors": "Wengong Jin, Kevin Yang, Regina Barzilay, Tommi Jaakkola", "title": "Learning Multimodal Graph-to-Graph Translation for Molecular\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We view molecular optimization as a graph-to-graph translation problem. The\ngoal is to learn to map from one molecular graph to another with better\nproperties based on an available corpus of paired molecules. Since molecules\ncan be optimized in different ways, there are multiple viable translations for\neach input graph. A key challenge is therefore to model diverse translation\noutputs. Our primary contributions include a junction tree encoder-decoder for\nlearning diverse graph translations along with a novel adversarial training\nmethod for aligning distributions of molecules. Diverse output distributions in\nour model are explicitly realized by low-dimensional latent vectors that\nmodulate the translation process. We evaluate our model on multiple molecular\noptimization tasks and show that our model outperforms previous\nstate-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 20:28:09 GMT"}, {"version": "v2", "created": "Mon, 7 Jan 2019 22:19:13 GMT"}, {"version": "v3", "created": "Mon, 28 Jan 2019 19:38:39 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Jin", "Wengong", ""], ["Yang", "Kevin", ""], ["Barzilay", "Regina", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "1812.01127", "submitter": "Holger Banzhaf", "authors": "Holger Banzhaf, Paul Sanzenbacher, Ulrich Baumann, J. Marius Z\\\"ollner", "title": "Learning to Predict Ego-Vehicle Poses for Sampling-Based Nonholonomic\n  Motion Planning", "comments": "Extended version of DOI 10.1109/LRA.2019.2893975, IEEE Robotics and\n  Automation Letters, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sampling-based motion planning is an effective tool to compute safe\ntrajectories for automated vehicles in complex environments. However, a fast\nconvergence to the optimal solution can only be ensured with the use of\nproblem-specific sampling distributions. Due to the large variety of driving\nsituations within the context of automated driving, it is very challenging to\nmanually design such distributions. This paper introduces therefore a\ndata-driven approach utilizing a deep convolutional neural network (CNN): Given\nthe current driving situation, future ego-vehicle poses can be directly\ngenerated from the output of the CNN allowing to guide the motion planner\nefficiently towards the optimal solution. A benchmark highlights that the CNN\npredicts future vehicle poses with a higher accuracy compared to uniform\nsampling and a state-of-the-art A*-based approach. Combining this CNN-guided\nsampling with the motion planner Bidirectional RRT* reduces the computation\ntime by up to an order of magnitude and yields a faster convergence to a lower\ncost as well as a success rate of 100 % in the tested scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 23:08:31 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 11:36:27 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Banzhaf", "Holger", ""], ["Sanzenbacher", "Paul", ""], ["Baumann", "Ulrich", ""], ["Z\u00f6llner", "J. Marius", ""]]}, {"id": "1812.01129", "submitter": "Dilip Arumugam", "authors": "Dilip Arumugam, David Abel, Kavosh Asadi, Nakul Gopalan, Christopher\n  Grimm, Jun Ki Lee, Lucas Lehnert, Michael L. Littman", "title": "Mitigating Planner Overfitting in Model-Based Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An agent with an inaccurate model of its environment faces a difficult\nchoice: it can ignore the errors in its model and act in the real world in\nwhatever way it determines is optimal with respect to its model. Alternatively,\nit can take a more conservative stance and eschew its model in favor of\noptimizing its behavior solely via real-world interaction. This latter approach\ncan be exceedingly slow to learn from experience, while the former can lead to\n\"planner overfitting\" - aspects of the agent's behavior are optimized to\nexploit errors in its model. This paper explores an intermediate position in\nwhich the planner seeks to avoid overfitting through a kind of regularization\nof the plans it considers. We present three different approaches that\ndemonstrably mitigate planner overfitting in reinforcement-learning\nenvironments.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 23:11:30 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 16:55:53 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Arumugam", "Dilip", ""], ["Abel", "David", ""], ["Asadi", "Kavosh", ""], ["Gopalan", "Nakul", ""], ["Grimm", "Christopher", ""], ["Lee", "Jun Ki", ""], ["Lehnert", "Lucas", ""], ["Littman", "Michael L.", ""]]}, {"id": "1812.01144", "submitter": "Philip Cohen", "authors": "Philip R Cohen", "title": "Back to the Future for Dialogue Research: A Position Paper", "comments": "AAAI Workshop 2019, Deep Dial", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short position paper is intended to provide a critique of current\napproaches to dialogue, as well as a roadmap for collaborative dialogue\nresearch. It is unapologetically opinionated, but informed by 40 years of\ndialogue re-search. No attempt is made to be comprehensive. The paper will\ndiscuss current research into building so-called \"chatbots\", slot-filling\ndialogue systems, and plan-based dialogue systems. For further discussion of\nsome of these issues, please see (Allen et al., in press).\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 00:41:51 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Cohen", "Philip R", ""]]}, {"id": "1812.01161", "submitter": "Aditya Ramesh", "authors": "Aditya Ramesh, Youngduck Choi, Yann LeCun", "title": "A Spectral Regularizer for Unsupervised Disentanglement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A generative model with a disentangled representation allows for independent\ncontrol over different aspects of the output. Learning disentangled\nrepresentations has been a recent topic of great interest, but it remains\npoorly understood. We show that even for GANs that do not possess disentangled\nrepresentations, one can find curved trajectories in latent space over which\nlocal disentanglement occurs. These trajectories are found by iteratively\nfollowing the leading right-singular vectors of the Jacobian of the generator\nwith respect to its input. Based on this insight, we describe an efficient\nregularizer that aligns these vectors with the coordinate axes, and show that\nit can be used to induce disentangled representations in GANs, in a completely\nunsupervised manner.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 01:35:40 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 02:23:54 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Ramesh", "Aditya", ""], ["Choi", "Youngduck", ""], ["LeCun", "Yann", ""]]}, {"id": "1812.01184", "submitter": "Jeffrey Krichmar", "authors": "Jeffrey L. Krichmar, William Severa, Salar M. Khan, James L. Olds", "title": "Making BREAD: Biomimetic strategies for Artificial Intelligence Now and\n  in the Future", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.ET", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Artificial Intelligence (AI) revolution foretold of during the 1960s is\nwell underway in the second decade of the 21st century. Its period of\nphenomenal growth likely lies ahead. Still, we believe, there are crucial\nlessons that biology can offer that will enable a prosperous future for AI. For\nmachines in general, and for AI's especially, operating over extended periods\nor in extreme environments will require energy usage orders of magnitudes more\nefficient than exists today. In many operational environments, energy sources\nwill be constrained. Any plans for AI devices operating in a challenging\nenvironment must begin with the question of how they are powered, where fuel is\nlocated, how energy is stored and made available to the machine, and how long\nthe machine can operate on specific energy units. Hence, the materials and\ntechnologies that provide the needed energy represent a critical challenge\ntowards future use-scenarios of AI and should be integrated into their design.\nHere we make four recommendations for stakeholders and especially decision\nmakers to facilitate a successful trajectory for this technology. First, that\nscientific societies and governments coordinate Biomimetic Research for\nEnergy-efficient, AI Designs (BREAD); a multinational initiative and a funding\nstrategy for investments in the future integrated design of energetics into AI.\nSecond, that biomimetic energetic solutions be central to design consideration\nfor future AI. Third, that a pre-competitive space be organized between\nstakeholder partners and fourth, that a trainee pipeline be established to\nensure the human capital required for success in this area.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 02:59:44 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Krichmar", "Jeffrey L.", ""], ["Severa", "William", ""], ["Khan", "Salar M.", ""], ["Olds", "James L.", ""]]}, {"id": "1812.01214", "submitter": "Sascha Saralajew", "authors": "Sascha Saralajew and Lars Holdijk and Maike Rees and Thomas Villmann", "title": "Prototype-based Neural Network Layers: Incorporating Vector Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks currently dominate the machine learning community and they do\nso for good reasons. Their accuracy on complex tasks such as image\nclassification is unrivaled at the moment and with recent improvements they are\nreasonably easy to train. Nevertheless, neural networks are lacking robustness\nand interpretability. Prototype-based vector quantization methods on the other\nhand are known for being robust and interpretable. For this reason, we propose\ntechniques and strategies to merge both approaches. This contribution will\nparticularly highlight the similarities between them and outline how to\nconstruct a prototype-based classification layer for multilayer networks.\nAdditionally, we provide an alternative, prototype-based, approach to the\nclassical convolution operation. Numerical results are not part of this report,\ninstead the focus lays on establishing a strong theoretical framework. By\npublishing our framework and the respective theoretical considerations and\njustifications before finalizing our numerical experiments we hope to\njump-start the incorporation of prototype-based learning in neural networks and\nvice versa.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 04:33:12 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 11:07:39 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Saralajew", "Sascha", ""], ["Holdijk", "Lars", ""], ["Rees", "Maike", ""], ["Villmann", "Thomas", ""]]}, {"id": "1812.01243", "submitter": "Zhuoran Shen", "authors": "Zhuoran Shen, Mingyuan Zhang, Haiyu Zhao, Shuai Yi, Hongsheng Li", "title": "Efficient Attention: Attention with Linear Complexities", "comments": "To appear at WACV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dot-product attention has wide applications in computer vision and natural\nlanguage processing. However, its memory and computational costs grow\nquadratically with the input size. Such growth prohibits its application on\nhigh-resolution inputs. To remedy this drawback, this paper proposes a novel\nefficient attention mechanism equivalent to dot-product attention but with\nsubstantially less memory and computational costs. Its resource efficiency\nallows more widespread and flexible integration of attention modules into a\nnetwork, which leads to better accuracies. Empirical evaluations demonstrated\nthe effectiveness of its advantages. Efficient attention modules brought\nsignificant performance boosts to object detectors and instance segmenters on\nMS-COCO 2017. Further, the resource efficiency democratizes attention to\ncomplex models, where high costs prohibit the use of dot-product attention. As\nan exemplar, a model with efficient attention achieved state-of-the-art\naccuracies for stereo depth estimation on the Scene Flow dataset. Code is\navailable at https://github.com/cmsflash/efficient-attention.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 06:41:46 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2019 11:07:37 GMT"}, {"version": "v3", "created": "Sat, 23 Mar 2019 14:12:01 GMT"}, {"version": "v4", "created": "Sun, 31 Mar 2019 04:45:33 GMT"}, {"version": "v5", "created": "Sat, 16 Nov 2019 09:58:55 GMT"}, {"version": "v6", "created": "Fri, 22 Nov 2019 15:57:06 GMT"}, {"version": "v7", "created": "Sat, 7 Dec 2019 01:49:31 GMT"}, {"version": "v8", "created": "Mon, 13 Jan 2020 02:16:11 GMT"}, {"version": "v9", "created": "Wed, 11 Nov 2020 03:40:08 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Shen", "Zhuoran", ""], ["Zhang", "Mingyuan", ""], ["Zhao", "Haiyu", ""], ["Yi", "Shuai", ""], ["Li", "Hongsheng", ""]]}, {"id": "1812.01245", "submitter": "Hongyu Xiong", "authors": "Hongyu Xiong and Ruixiao Sun", "title": "Transferable Natural Language Interface to Structured Queries aided by\n  Adversarial Generation", "comments": "8 pages, 3 figures; accepted by AAAI Workshop 2019; accepted by\n  International Conference of Semantic Computing (ICSC) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A natural language interface (NLI) to structured query is intriguing due to\nits wide industrial applications and high economical values. In this work, we\ntackle the problem of domain adaptation for NLI with limited data on target\ndomain. Two important approaches are considered: (a) effective\ngeneral-knowledge-learning on source domain semantic parsing, and (b) data\naugmentation on target domain. We present a Structured Query Inference Network\n(SQIN) to enhance learning for domain adaptation, by separating schema\ninformation from NL and decoding SQL in a more structural-aware manner; we also\npropose a GAN-based augmentation technique (AugmentGAN) to mitigate the issue\nof lacking target domain data. We report solid results on GeoQuery, Overnight,\nand WikiSQL to demonstrate state-of-the-art performances for both in-domain and\ndomain-transfer tasks.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 06:42:49 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2018 17:36:50 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Xiong", "Hongyu", ""], ["Sun", "Ruixiao", ""]]}, {"id": "1812.01254", "submitter": "Mohammad Naghshvar", "authors": "Mohammad Naghshvar, Ahmed K. Sadek, Auke J. Wiggers", "title": "Risk-averse Behavior Planning for Autonomous Driving under Uncertainty", "comments": "7 pages, accepted to NeurIPS 2018 Workshop on Machine Learning for\n  Intelligent Transportation Systems (MLITS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous vehicles have to navigate the surrounding environment with partial\nobservability of other objects sharing the road. Sources of uncertainty in\nautonomous vehicle measurements include sensor fusion errors, limited sensor\nrange due to weather or object detection latency, occlusion, and hidden\nparameters such as other human driver intentions. Behavior planning must\nconsider all sources of uncertainty in deciding future vehicle maneuvers. This\npaper presents a scalable framework for risk-averse behavior planning under\nuncertainty by incorporating QMDP, unscented transform, and Monte Carlo tree\nsearch (MCTS). It is shown that upper confidence bound (UCB) for expanding the\ntree results in noisy Q-value estimates by the MCTS and a degraded performance\nof QMDP. A modification to action selection procedure in MCTS is proposed to\nachieve robust performance.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 07:28:26 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Naghshvar", "Mohammad", ""], ["Sadek", "Ahmed K.", ""], ["Wiggers", "Auke J.", ""]]}, {"id": "1812.01260", "submitter": "Zachary Kaden", "authors": "George Larionov, Zachary Kaden, Hima Varsha Dureddy, Gabriel Bayomi T.\n  Kalejaiye, Mihir Kale, Srividya Pranavi Potharaju, Ankit Parag Shah,\n  Alexander I Rudnicky", "title": "Tartan: A retrieval-based socialbot powered by a dynamic finite-state\n  machine architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the Tartan conversational agent built for the 2018 Alexa\nPrize Competition. Tartan is a non-goal-oriented socialbot focused around\nproviding users with an engaging and fluent casual conversation. Tartan's key\nfeatures include an emphasis on structured conversation based on flexible\nfinite-state models and an approach focused on understanding and using\nconversational acts. To provide engaging conversations, Tartan blends\nscript-like yet dynamic responses with data-based generative and retrieval\nmodels. Unique to Tartan is that our dialog manager is modeled as a dynamic\nFinite State Machine. To our knowledge, no other conversational agent\nimplementation has followed this specific structure.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 07:48:00 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Larionov", "George", ""], ["Kaden", "Zachary", ""], ["Dureddy", "Hima Varsha", ""], ["Kalejaiye", "Gabriel Bayomi T.", ""], ["Kale", "Mihir", ""], ["Potharaju", "Srividya Pranavi", ""], ["Shah", "Ankit Parag", ""], ["Rudnicky", "Alexander I", ""]]}, {"id": "1812.01278", "submitter": "Dorien Herremans", "authors": "Kin Wah Edward Lin, Balamurali B.T., Enyan Koh, Simon Lui, Dorien\n  Herremans", "title": "Singing Voice Separation Using a Deep Convolutional Neural Network\n  Trained by Ideal Binary Mask and Cross Entropy", "comments": "In Press, Neural Computing and Applications, Springer. 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Separating a singing voice from its music accompaniment remains an important\nchallenge in the field of music information retrieval. We present a unique\nneural network approach inspired by a technique that has revolutionized the\nfield of vision: pixel-wise image classification, which we combine with cross\nentropy loss and pretraining of the CNN as an autoencoder on singing voice\nspectrograms. The pixel-wise classification technique directly estimates the\nsound source label for each time-frequency (T-F) bin in our spectrogram image,\nthus eliminating common pre- and postprocessing tasks. The proposed network is\ntrained by using the Ideal Binary Mask (IBM) as the target output label. The\nIBM identifies the dominant sound source in each T-F bin of the magnitude\nspectrogram of a mixture signal, by considering each T-F bin as a pixel with a\nmulti-label (for each sound source). Cross entropy is used as the training\nobjective, so as to minimize the average probability error between the target\nand predicted label for each pixel. By treating the singing voice separation\nproblem as a pixel-wise classification task, we additionally eliminate one of\nthe commonly used, yet not easy to comprehend, postprocessing steps: the Wiener\nfilter postprocessing.\n  The proposed CNN outperforms the first runner up in the Music Information\nRetrieval Evaluation eXchange (MIREX) 2016 and the winner of MIREX 2014 with a\ngain of 2.2702 ~ 5.9563 dB global normalized source to distortion ratio (GNSDR)\nwhen applied to the iKala dataset. An experiment with the DSD100 dataset on the\nfull-tracks song evaluation task also shows that our model is able to compete\nwith cutting-edge singing voice separation systems which use multi-channel\nmodeling, data augmentation, and model blending.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 08:47:41 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Lin", "Kin Wah Edward", ""], ["T.", "Balamurali B.", ""], ["Koh", "Enyan", ""], ["Lui", "Simon", ""], ["Herremans", "Dorien", ""]]}, {"id": "1812.01351", "submitter": "Paulo Vitor Campos Souza", "authors": "Paulo Vitor de Campos Souza, Augusto Junio Guimaraes, Vanessa Souza\n  Araujo, Thiago Silva Rezende, Vinicius Jonathan Silva Araujo", "title": "Regularized Fuzzy Neural Networks to Aid Effort Forecasting in the\n  Construction and Software Development", "comments": null, "journal-ref": "Volume 9, Number 6, 2018", "doi": "10.5121/ijaia.2018.9602", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Predicting the time to build software is a very complex task for software\nengineering managers. There are complex factors that can directly interfere\nwith the productivity of the development team. Factors directly related to the\ncomplexity of the system to be developed drastically change the time necessary\nfor the completion of the works with the software factories. This work proposes\nthe use of a hybrid system based on artificial neural networks and fuzzy\nsystems to assist in the construction of an expert system based on rules to\nsupport in the prediction of hours destined to the development of software\naccording to the complexity of the elements present in the same. The set of\nfuzzy rules obtained by the system helps the management and control of software\ndevelopment by providing a base of interpretable estimates based on fuzzy\nrules. The model was submitted to tests on a real database, and its results\nwere promissory in the construction of an aid mechanism in the predictability\nof the software construction.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 11:57:46 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Souza", "Paulo Vitor de Campos", ""], ["Guimaraes", "Augusto Junio", ""], ["Araujo", "Vanessa Souza", ""], ["Rezende", "Thiago Silva", ""], ["Araujo", "Vinicius Jonathan Silva", ""]]}, {"id": "1812.01375", "submitter": "Xiaoguang Lin", "authors": "Lin Xiaoguang, Yang Yong, Zhang Ju", "title": "Design and implementation of smart cooking based on amazon echo", "comments": "9 pages, 3 figures, 2 tables", "journal-ref": "IJSCAI 4 (2018) 37-45", "doi": "10.5121/ijscai.2018.7403", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart cooking based on Amazon Echo uses the internet of things and cloud\ncomputing to assist in cooking food. People may speak to Amazon Echo during the\ncooking in order to get the information and situation of the cooking. Amazon\nEcho recognizes what people say, then transfers the information to the cloud\nservices, and speaks to people the results that cloud services make by querying\nthe embedded cooking knowledge and achieving the information of intelligent\nkitchen devices online. An intelligent food thermometer and its mobile\napplication are well-designed and implemented to monitor the temperature of\ncooking food.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 12:38:07 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Xiaoguang", "Lin", ""], ["Yong", "Yang", ""], ["Ju", "Zhang", ""]]}, {"id": "1812.01431", "submitter": "Bohdan Khomtchouk", "authors": "Bohdan Khomtchouk, Shyam Sudhakaran", "title": "Modeling natural language emergence with integral transform theory and\n  reinforcement learning", "comments": "9 pages, 4 figures, 2 tables. arXiv admin note: text overlap with\n  arXiv:1603.03153", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Zipf's law predicts a power-law relationship between word rank and frequency\nin language communication systems and has been widely reported in a variety of\nnatural language processing applications. However, the emergence of natural\nlanguage is often modeled as a function of bias between speaker and listener\ninterests, which lacks a direct way of relating information-theoretic bias to\nZipfian rank. A function of bias also serves as an unintuitive interpretation\nof the communicative effort exchanged between a speaker and a listener. We\ncounter these shortcomings by proposing a novel integral transform and kernel\nfor mapping communicative bias functions to corresponding word frequency-rank\nrepresentations at any arbitrary phase transition point, resulting in a direct\nway to link communicative effort (modeled by speaker/listener bias) to specific\nvocabulary used (represented by word rank). We demonstrate the practical\nutility of our integral transform by showing how a change from bias to rank\nresults in greater accuracy and performance at an image classification task for\nassigning word labels to images randomly subsampled from CIFAR10. We model this\ntask as a reinforcement learning game between a speaker and listener and\ncompare the relative impact of bias and Zipfian word rank on communicative\nperformance (and accuracy) between the two agents.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 19:12:04 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Khomtchouk", "Bohdan", ""], ["Sudhakaran", "Shyam", ""]]}, {"id": "1812.01487", "submitter": "Saket Tiwari", "authors": "Saket Tiwari, M. Prannoy", "title": "Hyperbolic Embeddings for Learning Options in Hierarchical Reinforcement\n  Learning", "comments": "We are redoing some of the experiments to obtain better results and\n  to change the approach a bit", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical reinforcement learning deals with the problem of breaking down\nlarge tasks into meaningful sub-tasks. Autonomous discovery of these sub-tasks\nhas remained a challenging problem. We propose a novel method of learning\nsub-tasks by combining paradigms of routing in computer networks and graph\nbased skill discovery within the options framework to define meaningful\nsub-goals. We apply the recent advancements of learning embeddings using\nRiemannian optimisation in the hyperbolic space to embed the state set into the\nhyperbolic space and create a model of the environment. In doing so we enforce\na global topology on the states and are able to exploit this topology to learn\nmeaningful sub-tasks. We demonstrate empirically, both in discrete and\ncontinuous domains, how these embeddings can improve the learning of meaningful\nsub-tasks.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 15:30:23 GMT"}, {"version": "v2", "created": "Sat, 16 Feb 2019 01:19:48 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Tiwari", "Saket", ""], ["Prannoy", "M.", ""]]}, {"id": "1812.01488", "submitter": "Saket Tiwari", "authors": "Saket Tiwari and Philip S. Thomas", "title": "Natural Option Critic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently proposed option-critic architecture Bacon et al. provide a\nstochastic policy gradient approach to hierarchical reinforcement learning.\nSpecifically, they provide a way to estimate the gradient of the expected\ndiscounted return with respect to parameters that define a finite number of\ntemporally extended actions, called \\textit{options}. In this paper we show how\nthe option-critic architecture can be extended to estimate the natural gradient\nof the expected discounted return. To this end, the central questions that we\nconsider in this paper are: 1) what is the definition of the natural gradient\nin this context, 2) what is the Fisher information matrix associated with an\noption's parameterized policy, 3) what is the Fisher information matrix\nassociated with an option's parameterized termination function, and 4) how can\na compatible function approximation approach be leveraged to obtain natural\ngradient estimates for both the parameterized policy and parameterized\ntermination functions of an option with per-time-step time and space complexity\nlinear in the total number of parameters. Based on answers to these questions\nwe introduce the natural option critic algorithm. Experimental results showcase\nimprovement over the vanilla gradient approach.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 15:33:26 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Tiwari", "Saket", ""], ["Thomas", "Philip S.", ""]]}, {"id": "1812.01569", "submitter": "Iris Seaman", "authors": "Iris Rubi Seaman, Jan-Willem van de Meent, David Wingate", "title": "Nested Reasoning About Autonomous Agents Using Probabilistic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As autonomous agents become more ubiquitous, they will eventually have to\nreason about the plans of other agents, which is known as theory of mind\nreasoning. We develop a planning-as-inference framework in which agents perform\nnested simulation to reason about the behavior of other agents in an online\nmanner. As a concrete application of this framework, we use probabilistic\nprograms to model a high-uncertainty variant of pursuit-evasion games in which\nan agent must make inferences about the other agents' plans to craft\ncounter-plans. Our probabilistic programs incorporate a variety of complex\nprimitives such as field-of-view calculations and path planners, which enable\nus to model quasi-realistic scenarios in a computationally tractable manner. We\nperform extensive experimental evaluations which establish a variety of\nrational behaviors and quantify how allocating computation across levels of\nnesting affects the variance of our estimators.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 18:19:34 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 20:31:26 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Seaman", "Iris Rubi", ""], ["van de Meent", "Jan-Willem", ""], ["Wingate", "David", ""]]}, {"id": "1812.01593", "submitter": "Yi Zhu", "authors": "Yi Zhu, Karan Sapra, Fitsum A. Reda, Kevin J. Shih, Shawn Newsam,\n  Andrew Tao and Bryan Catanzaro", "title": "Improving Semantic Segmentation via Video Propagation and Label\n  Relaxation", "comments": "CVPR 2019 Oral. Code link:\n  https://github.com/NVIDIA/semantic-segmentation. YouTube link:\n  https://www.youtube.com/watch?v=aEbXjGZDZSQ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic segmentation requires large amounts of pixel-wise annotations to\nlearn accurate models. In this paper, we present a video prediction-based\nmethodology to scale up training sets by synthesizing new training samples in\norder to improve the accuracy of semantic segmentation networks. We exploit\nvideo prediction models' ability to predict future frames in order to also\npredict future labels. A joint propagation strategy is also proposed to\nalleviate mis-alignments in synthesized samples. We demonstrate that training\nsegmentation models on datasets augmented by the synthesized samples leads to\nsignificant improvements in accuracy. Furthermore, we introduce a novel\nboundary label relaxation technique that makes training robust to annotation\nnoise and propagation artifacts along object boundaries. Our proposed methods\nachieve state-of-the-art mIoUs of 83.5% on Cityscapes and 82.9% on CamVid. Our\nsingle model, without model ensembles, achieves 72.8% mIoU on the KITTI\nsemantic segmentation test set, which surpasses the winning entry of the ROB\nchallenge 2018. Our code and videos can be found at\nhttps://nv-adlr.github.io/publication/2018-Segmentation.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 18:49:54 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 18:56:34 GMT"}, {"version": "v3", "created": "Wed, 3 Jul 2019 03:16:39 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Zhu", "Yi", ""], ["Sapra", "Karan", ""], ["Reda", "Fitsum A.", ""], ["Shih", "Kevin J.", ""], ["Newsam", "Shawn", ""], ["Tao", "Andrew", ""], ["Catanzaro", "Bryan", ""]]}, {"id": "1812.01628", "submitter": "Prithviraj Ammanabrolu", "authors": "Prithviraj Ammanabrolu and Mark O. Riedl", "title": "Playing Text-Adventure Games with Graph-Based Deep Reinforcement\n  Learning", "comments": "Proceedings of NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-based adventure games provide a platform on which to explore\nreinforcement learning in the context of a combinatorial action space, such as\nnatural language. We present a deep reinforcement learning architecture that\nrepresents the game state as a knowledge graph which is learned during\nexploration. This graph is used to prune the action space, enabling more\nefficient exploration. The question of which action to take can be reduced to a\nquestion-answering task, a form of transfer learning that pre-trains certain\nparts of our architecture. In experiments using the TextWorld framework, we\nshow that our proposed technique can learn a control policy faster than\nbaseline alternatives. We have also open-sourced our code at\nhttps://github.com/rajammanabrolu/KG-DQN.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 19:06:00 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 17:15:45 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Ammanabrolu", "Prithviraj", ""], ["Riedl", "Mark O.", ""]]}, {"id": "1812.01665", "submitter": "Niranjan Hasabnis", "authors": "Niranjan Hasabnis", "title": "Auto-tuning TensorFlow Threading Model for CPU Backend", "comments": "Paper presented at Machine Learning in HPC Environments workshop held\n  along with SuperComputing 2018, Dallas, Texas", "journal-ref": null, "doi": "10.1109/MLHPC.2018.000-7", "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  TensorFlow is a popular deep learning framework used by data scientists to\nsolve a wide-range of machine learning and deep learning problems such as image\nclassification and speech recognition. It also operates at a large scale and in\nheterogeneous environments --- it allows users to train neural network models\nor deploy them for inference using GPUs, CPUs and deep learning specific\ncustom-designed hardware such as TPUs. Even though TensorFlow supports a\nvariety of optimized backends, realizing the best performance using a backend\nmay require additional efforts. For instance, getting the best performance from\na CPU backend requires careful tuning of its threading model. Unfortunately,\nthe best tuning approach used today is manual, tedious, time-consuming, and,\nmore importantly, may not guarantee the best performance.\n  In this paper, we develop an automatic approach, called TensorTuner, to\nsearch for optimal parameter settings of TensorFlow's threading model for CPU\nbackends. We evaluate TensorTuner on both Eigen and Intel's MKL CPU backends\nusing a set of neural networks from TensorFlow's benchmarking suite. Our\nevaluation results demonstrate that the parameter settings found by TensorTuner\nproduce 2% to 123% performance improvement for the Eigen CPU backend and 1.5%\nto 28% performance improvement for the MKL CPU backend over the performance\nobtained using their best-known parameter settings. This highlights the fact\nthat the default parameter settings in Eigen CPU backend are not the ideal\nsettings; and even for a carefully hand-tuned MKL backend, the settings may be\nsub-optimal. Our evaluations also revealed that TensorTuner is efficient at\nfinding the optimal settings --- it is able to converge to the optimal settings\nquickly by pruning more than 90% of the parameter search space.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 20:20:29 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Hasabnis", "Niranjan", ""]]}, {"id": "1812.01687", "submitter": "Tianhang Zheng", "authors": "Tianhang Zheng, Changyou Chen, Junsong Yuan, Bo Li, Kui Ren", "title": "PointCloud Saliency Maps", "comments": "Accepted to ICCV19 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D point-cloud recognition with PointNet and its variants has received\nremarkable progress. A missing ingredient, however, is the ability to\nautomatically evaluate point-wise importance w.r.t.\\! classification\nperformance, which is usually reflected by a saliency map. A saliency map is an\nimportant tool as it allows one to perform further processes on point-cloud\ndata. In this paper, we propose a novel way of characterizing critical points\nand segments to build point-cloud saliency maps. Our method assigns each point\na score reflecting its contribution to the model-recognition loss. The saliency\nmap explicitly explains which points are the key for model recognition.\nFurthermore, aggregations of highly-scored points indicate important\nsegments/subsets in a point-cloud. Our motivation for constructing a saliency\nmap is by point dropping, which is a non-differentiable operator. To overcome\nthis issue, we approximate point-dropping with a differentiable procedure of\nshifting points towards the cloud centroid. Consequently, each saliency score\ncan be efficiently measured by the corresponding gradient of the loss w.r.t the\npoint under the spherical coordinates. Extensive evaluations on several\nstate-of-the-art point-cloud recognition models, including PointNet, PointNet++\nand DGCNN, demonstrate the veracity and generality of our proposed saliency\nmap. Code for experiments is released on\n\\url{https://github.com/tianzheng4/PointCloud-Saliency-Maps}.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 21:50:49 GMT"}, {"version": "v2", "created": "Sat, 2 Feb 2019 21:03:02 GMT"}, {"version": "v3", "created": "Fri, 15 Feb 2019 18:19:28 GMT"}, {"version": "v4", "created": "Sun, 31 Mar 2019 18:51:59 GMT"}, {"version": "v5", "created": "Thu, 1 Aug 2019 09:48:49 GMT"}, {"version": "v6", "created": "Thu, 12 Sep 2019 19:29:12 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Zheng", "Tianhang", ""], ["Chen", "Changyou", ""], ["Yuan", "Junsong", ""], ["Li", "Bo", ""], ["Ren", "Kui", ""]]}, {"id": "1812.01714", "submitter": "Yuji Yoshimura", "authors": "Yuji Yoshimura, Bill Cai, Zhoutong Wang, Carlo Ratti", "title": "Deep Learning Architect: Classification for Architectural Design through\n  the Eye of Artificial Intelligence", "comments": "22 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper applies state-of-the-art techniques in deep learning and computer\nvision to measure visual similarities between architectural designs by\ndifferent architects. Using a dataset consisting of web scraped images and an\noriginal collection of images of architectural works, we first train a deep\nconvolutional neural network (DCNN) model capable of achieving 73% accuracy in\nclassifying works belonging to 34 different architects. Through examining the\nweights in the trained DCNN model, we are able to quantitatively measure the\nvisual similarities between architects that are implicitly learned by our\nmodel. Using this measure, we cluster architects that are identified to be\nsimilar and compare our findings to conventional classification made by\narchitectural historians and theorists. Our clustering of architectural designs\nremarkably corroborates conventional views in architectural history, and the\nlearned architectural features also coheres with the traditional understanding\nof architectural designs.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 00:30:59 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Yoshimura", "Yuji", ""], ["Cai", "Bill", ""], ["Wang", "Zhoutong", ""], ["Ratti", "Carlo", ""]]}, {"id": "1812.01717", "submitter": "Sjoerd van Steenkiste", "authors": "Thomas Unterthiner, Sjoerd van Steenkiste, Karol Kurach, Raphael\n  Marinier, Marcin Michalski, Sylvain Gelly", "title": "Towards Accurate Generative Models of Video: A New Metric & Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances in deep generative models have lead to remarkable progress in\nsynthesizing high quality images. Following their successful application in\nimage processing and representation learning, an important next step is to\nconsider videos. Learning generative models of video is a much harder task,\nrequiring a model to capture the temporal dynamics of a scene, in addition to\nthe visual presentation of objects. While recent attempts at formulating\ngenerative models of video have had some success, current progress is hampered\nby (1) the lack of qualitative metrics that consider visual quality, temporal\ncoherence, and diversity of samples, and (2) the wide gap between purely\nsynthetic video data sets and challenging real-world data sets in terms of\ncomplexity. To this extent we propose Fr\\'{e}chet Video Distance (FVD), a new\nmetric for generative models of video, and StarCraft 2 Videos (SCV), a\nbenchmark of game play from custom starcraft 2 scenarios that challenge the\ncurrent capabilities of generative models of video. We contribute a large-scale\nhuman study, which confirms that FVD correlates well with qualitative human\njudgment of generated videos, and provide initial benchmark results on SCV.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 03:57:42 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 16:43:17 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Unterthiner", "Thomas", ""], ["van Steenkiste", "Sjoerd", ""], ["Kurach", "Karol", ""], ["Marinier", "Raphael", ""], ["Michalski", "Marcin", ""], ["Gelly", "Sylvain", ""]]}, {"id": "1812.01752", "submitter": "Pedro Sanches", "authors": "Pedro Sanches, Cyril Meyer, Vincent Vigon, Beno\\^it Naegel", "title": "Cerebrovascular Network Segmentation on MRA Images with Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has been shown to produce state of the art results in many\ntasks in biomedical imaging, especially in segmentation. Moreover, segmentation\nof the cerebrovascular structure from magnetic resonance angiography is a\nchallenging problem because its complex geometry and topology have a large\ninter-patient variability. Therefore, in this work, we present a convolutional\nneural network approach for this problem. Particularly, a new network topology\ninspired by the U-net 3D and by the Inception modules, entitled Uception. In\naddition, a discussion about the best objective function for sparse data also\nguided most choices during the project. State of the art models are also\nimplemented for a comparison purpose and final results show that the proposed\narchitecture has the best performance in this particular context.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 23:38:54 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Sanches", "Pedro", ""], ["Meyer", "Cyril", ""], ["Vigon", "Vincent", ""], ["Naegel", "Beno\u00eet", ""]]}, {"id": "1812.01756", "submitter": "Tim G. J. Rudner", "authors": "Tim G. J. Rudner, Marc Ru{\\ss}wurm, Jakub Fil, Ramona Pelich, Benjamin\n  Bischke, Veronika Kopackova, Piotr Bilinski", "title": "Multi$^{\\mathbf{3}}$Net: Segmenting Flooded Buildings via Fusion of\n  Multiresolution, Multisensor, and Multitemporal Satellite Imagery", "comments": "To appear in Proceedings of the Thirty-Third AAAI Conference on\n  Artificial Intelligence (AAAI-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach for rapid segmentation of flooded buildings by\nfusing multiresolution, multisensor, and multitemporal satellite imagery in a\nconvolutional neural network. Our model significantly expedites the generation\nof satellite imagery-based flood maps, crucial for first responders and local\nauthorities in the early stages of flood events. By incorporating multitemporal\nsatellite imagery, our model allows for rapid and accurate post-disaster damage\nassessment and can be used by governments to better coordinate medium- and\nlong-term financial assistance programs for affected areas. The network\nconsists of multiple streams of encoder-decoder architectures that extract\nspatiotemporal information from medium-resolution images and spatial\ninformation from high-resolution images before fusing the resulting\nrepresentations into a single medium-resolution segmentation map of flooded\nbuildings. We compare our model to state-of-the-art methods for building\nfootprint segmentation as well as to alternative fusion approaches for the\nsegmentation of flooded buildings and find that our model performs best on both\ntasks. We also demonstrate that our model produces highly accurate segmentation\nmaps of flooded buildings using only publicly available medium-resolution data\ninstead of significantly more detailed but sparsely available very\nhigh-resolution data. We release the first open-source dataset of fully\npreprocessed and labeled multiresolution, multispectral, and multitemporal\nsatellite images of disaster sites along with our source code.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 00:05:01 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Rudner", "Tim G. J.", ""], ["Ru\u00dfwurm", "Marc", ""], ["Fil", "Jakub", ""], ["Pelich", "Ramona", ""], ["Bischke", "Benjamin", ""], ["Kopackova", "Veronika", ""], ["Bilinski", "Piotr", ""]]}, {"id": "1812.01784", "submitter": "Edgar Sch\\\"onfeld", "authors": "Edgar Sch\\\"onfeld, Sayna Ebrahimi, Samarth Sinha, Trevor Darrell,\n  Zeynep Akata", "title": "Generalized Zero- and Few-Shot Learning via Aligned Variational\n  Autoencoders", "comments": "Accepted at CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many approaches in generalized zero-shot learning rely on cross-modal mapping\nbetween the image feature space and the class embedding space. As labeled\nimages are expensive, one direction is to augment the dataset by generating\neither images or image features. However, the former misses fine-grained\ndetails and the latter requires learning a mapping associated with class\nembeddings. In this work, we take feature generation one step further and\npropose a model where a shared latent space of image features and class\nembeddings is learned by modality-specific aligned variational autoencoders.\nThis leaves us with the required discriminative information about the image and\nclasses in the latent features, on which we train a softmax classifier. The key\nto our approach is that we align the distributions learned from images and from\nside-information to construct latent features that contain the essential\nmulti-modal information associated with unseen classes. We evaluate our learned\nlatent features on several benchmark datasets, i.e. CUB, SUN, AWA1 and AWA2,\nand establish a new state of the art on generalized zero-shot as well as on\nfew-shot learning. Moreover, our results on ImageNet with various zero-shot\nsplits show that our latent features generalize well in large-scale settings.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 02:20:12 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2018 14:50:48 GMT"}, {"version": "v3", "created": "Wed, 3 Apr 2019 15:11:06 GMT"}, {"version": "v4", "created": "Fri, 5 Apr 2019 12:52:25 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Sch\u00f6nfeld", "Edgar", ""], ["Ebrahimi", "Sayna", ""], ["Sinha", "Samarth", ""], ["Darrell", "Trevor", ""], ["Akata", "Zeynep", ""]]}, {"id": "1812.01804", "submitter": "Huangyi Ge", "authors": "Huangyi Ge, Sze Yiu Chau, Bruno Ribeiro, Ninghui Li", "title": "Random Spiking and Systematic Evaluation of Defenses Against Adversarial\n  Examples", "comments": "To be appear in ACM CODESPY 2020", "journal-ref": null, "doi": "10.1145/3374664.3375736", "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image classifiers often suffer from adversarial examples, which are generated\nby strategically adding a small amount of noise to input images to trick\nclassifiers into misclassification. Over the years, many defense mechanisms\nhave been proposed, and different researchers have made seemingly contradictory\nclaims on their effectiveness. We present an analysis of possible adversarial\nmodels, and propose an evaluation framework for comparing different defense\nmechanisms. As part of the framework, we introduce a more powerful and\nrealistic adversary strategy. Furthermore, we propose a new defense mechanism\ncalled Random Spiking (RS), which generalizes dropout and introduces random\nnoises in the training process in a controlled manner. Evaluations under our\nproposed framework suggest RS delivers better protection against adversarial\nexamples than many existing schemes.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 03:31:07 GMT"}, {"version": "v2", "created": "Mon, 4 Mar 2019 17:08:21 GMT"}, {"version": "v3", "created": "Sat, 12 Oct 2019 20:55:52 GMT"}, {"version": "v4", "created": "Mon, 20 Jan 2020 22:09:40 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Ge", "Huangyi", ""], ["Chau", "Sze Yiu", ""], ["Ribeiro", "Bruno", ""], ["Li", "Ninghui", ""]]}, {"id": "1812.01818", "submitter": "Masataro Asai", "authors": "Masataro Asai", "title": "Photo-Realistic Blocksworld Dataset", "comments": "The dataset generator is available at\n  https://github.com/ibm/photorealistic-blocksworld", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, we introduce an artificial dataset generator for\nPhoto-realistic Blocksworld domain. Blocksworld is one of the oldest high-level\ntask planning domain that is well defined but contains sufficient complexity,\ne.g., the conflicting subgoals and the decomposability into subproblems. We aim\nto make this dataset a benchmark for Neural-Symbolic integrated systems and\naccelerate the research in this area. The key advantage of such systems is the\nability to obtain a symbolic model from the real-world input and perform a\nfast, systematic, complete algorithm for symbolic reasoning, without any\nsupervision and the reward signal from the environment.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 05:04:15 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Asai", "Masataro", ""]]}, {"id": "1812.01825", "submitter": "Lu Pang", "authors": "Peixi Peng, Junliang Xing, Lu Pang", "title": "Cooperative Multi-Agent Policy Gradients with Sub-optimal Demonstration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many reality tasks such as robot coordination can be naturally modelled as\nmulti-agent cooperative system where the rewards are sparse. This paper focuses\non learning decentralized policies for such tasks using sub-optimal\ndemonstration. To learn the multi-agent cooperation effectively and tackle the\nsub-optimality of demonstration, a self-improving learning method is proposed:\nOn the one hand, the centralized state-action values are initialized by the\ndemonstration and updated by the learned decentralized policy to improve the\nsub-optimality. On the other hand, the Nash Equilibrium are found by the\ncurrent state-action value and are used as a guide to learn the policy. The\nproposed method is evaluated on the combat RTS games which requires a high\nlevel of multi-agent cooperation. Extensive experimental results on various\ncombat scenarios demonstrate that the proposed method can learn multi-agent\ncooperation effectively. It significantly outperforms many state-of-the-art\ndemonstration based approaches.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 05:47:43 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Peng", "Peixi", ""], ["Xing", "Junliang", ""], ["Pang", "Lu", ""]]}, {"id": "1812.01843", "submitter": "Kuldeep S. Meel", "authors": "Dmitry Malioutov and Kuldeep S. Meel", "title": "MLIC: A MaxSAT-Based framework for learning interpretable classification\n  rules", "comments": "Paper published in Proceedings of International Conference on\n  Constraint Programming (CP), 2018", "journal-ref": null, "doi": "10.1007/978-3-319-98334-9_21", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wide adoption of machine learning approaches in the industry, government,\nmedicine and science has renewed the interest in interpretable machine\nlearning: many decisions are too important to be delegated to black-box\ntechniques such as deep neural networks or kernel SVMs. Historically, problems\nof learning interpretable classifiers, including classification rules or\ndecision trees, have been approached by greedy heuristic methods as essentially\nall the exact optimization formulations are NP-hard. Our primary contribution\nis a MaxSAT-based framework, called MLIC, which allows principled search for\ninterpretable classification rules expressible in propositional logic. Our\napproach benefits from the revolutionary advances in the constraint\nsatisfaction community to solve large-scale instances of such problems. In\nexperimental evaluations over a collection of benchmarks arising from practical\nscenarios, we demonstrate its effectiveness: we show that the formulation can\nsolve large classification problems with tens or hundreds of thousands of\nexamples and thousands of features, and to provide a tunable balance of\naccuracy vs. interpretability. Furthermore, we show that in many problems\ninterpretability can be obtained at only a minor cost in accuracy. The primary\nobjective of the paper is to show that recent advances in the MaxSAT literature\nmake it realistic to find optimal (or very high quality near-optimal) solutions\nto large-scale classification problems. The key goal of the paper is to excite\nresearchers in both interpretable classification and in the CP community to\ntake it further and propose richer formulations, and to develop bespoke solvers\nattuned to the problem of interpretable ML.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 07:40:32 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Malioutov", "Dmitry", ""], ["Meel", "Kuldeep S.", ""]]}, {"id": "1812.01844", "submitter": "Jaiyam Sharma", "authors": "Jaiyam Sharma and Saket Navlakha", "title": "Improving Similarity Search with High-dimensional Locality-sensitive\n  Hashing", "comments": "12 pages, 7 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new class of data-independent locality-sensitive hashing (LSH)\nalgorithms based on the fruit fly olfactory circuit. The fundamental difference\nof this approach is that, instead of assigning hashes as dense points in a low\ndimensional space, hashes are assigned in a high dimensional space, which\nenhances their separability. We show theoretically and empirically that this\nnew family of hash functions is locality-sensitive and preserves rank\nsimilarity for inputs in any `p space. We then analyze different variations on\nthis strategy and show empirically that they outperform existing LSH methods\nfor nearest-neighbors search on six benchmark datasets. Finally, we propose a\nmulti-probe version of our algorithm that achieves higher performance for the\nsame query time, or conversely, that maintains performance of prior approaches\nwhile taking significantly less indexing time and memory. Overall, our approach\nleverages the advantages of separability provided by high-dimensional spaces,\nwhile still remaining computationally efficient\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 07:41:53 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Sharma", "Jaiyam", ""], ["Navlakha", "Saket", ""]]}, {"id": "1812.01856", "submitter": "Sylvain Bouveret", "authors": "Sylvain Bouveret and Katar\\'ina Cechl\\'arov\\'a and Julien Lesca", "title": "Chore division on a graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper considers fair allocation of indivisible nondisposable items that\ngenerate disutility (chores). We assume that these items are placed in the\nvertices of a graph and each agent's share has to form a connected subgraph of\nthis graph. Although a similar model has been investigated before for goods, we\nshow that the goods and chores settings are inherently different. In\nparticular, it is impossible to derive the solution of the chores instance from\nthe solution of its naturally associated fair division instance. We consider\nthree common fair division solution concepts, namely proportionality,\nenvy-freeness and equitability, and two individual disutility aggregation\nfunctions: additive and maximum based. We show that deciding the existence of a\nfair allocation is hard even if the underlying graph is a path or a star. We\nalso present some efficiently solvable special cases for these graph\ntopologies.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 08:39:06 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Bouveret", "Sylvain", ""], ["Cechl\u00e1rov\u00e1", "Katar\u00edna", ""], ["Lesca", "Julien", ""]]}, {"id": "1812.01887", "submitter": "Ying Shen", "authors": "Ying Shen, Yang Deng, Kaiqi Yuan, Li Liu, Yong Liu", "title": "Approach for Semi-automatic Construction of Anti-infective Drug Ontology\n  Based on Entity Linking", "comments": null, "journal-ref": "International Conference on Smart Computing and Communication\n  SmartCom 2017: Smart Computing and Communication pp 268-277", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontology can be used for the interpretation of natural language. To construct\nan anti-infective drug ontology, one needs to design and deploy a\nmethodological step to carry out the entity discovery and linking. Medical\nsynonym resources have been an important part of medical natural language\nprocessing (NLP). However, there are problems such as low precision and low\nrecall rate. In this study, an NLP approach is adopted to generate candidate\nentities. Open ontology is analyzed to extract semantic relations. Six-word\nvector features and word-level features are selected to perform the entity\nlinking. The extraction results of synonyms with a single feature and different\ncombinations of features are studied. Experiments show that our selected\nfeatures have achieved a precision rate of 86.77%, a recall rate of 89.03% and\nan F1 score of 87.89%. This paper finally presents the structure of the\nproposed ontology and its relevant statistical data.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 10:08:29 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Shen", "Ying", ""], ["Deng", "Yang", ""], ["Yuan", "Kaiqi", ""], ["Liu", "Li", ""], ["Liu", "Yong", ""]]}, {"id": "1812.01891", "submitter": "Ying Shen", "authors": "Ying Shen, Jo\\\"el Colloc, Armelle Jacquet-Andrieu, Ziyi Guo, Yong Liu", "title": "Constructing Ontology-Based Cancer Treatment Decision Support System\n  with Case-Based Reasoning", "comments": null, "journal-ref": "International Conference on Smart Computing and Communication\n  SmartCom 2017: Smart Computing and Communication pp 278-288", "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision support is a probabilistic and quantitative method designed for\nmodeling problems in situations with ambiguity. Computer technology can be\nemployed to provide clinical decision support and treatment recommendations.\nThe problem of natural language applications is that they lack formality and\nthe interpretation is not consistent. Conversely, ontologies can capture the\nintended meaning and specify modeling primitives. Disease Ontology (DO) that\npertains to cancer's clinical stages and their corresponding information\ncomponents is utilized to improve the reasoning ability of a decision support\nsystem (DSS). The proposed DSS uses Case-Based Reasoning (CBR) to consider\ndisease manifestations and provides physicians with treatment solutions from\nsimilar previous cases for reference. The proposed DSS supports natural\nlanguage processing (NLP) queries. The DSS obtained 84.63% accuracy in disease\nclassification with the help of the ontology.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 10:14:50 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Shen", "Ying", ""], ["Colloc", "Jo\u00ebl", ""], ["Jacquet-Andrieu", "Armelle", ""], ["Guo", "Ziyi", ""], ["Liu", "Yong", ""]]}, {"id": "1812.01893", "submitter": "Mariam Zouari", "authors": "Mariam Zouari, Nesrine Baklouti, Javier Sanchez Medina, Mounir Ben\n  Ayed and Adel M. Alimi", "title": "An Evolutionary Hierarchical Interval Type-2 Fuzzy Knowledge\n  Representation System (EHIT2FKRS) for Travel Route Assignment", "comments": "13 pages, 12 Tables, 18 figures, Journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urban Traffic Networks are characterized by high dynamics of traffic flow and\nincreased travel time, including waiting times. This leads to more complex road\ntraffic management. The present research paper suggests an innovative advanced\ntraffic management system based on Hierarchical Interval Type-2 Fuzzy Logic\nmodel optimized by the Particle Swarm Optimization (PSO) method. The aim of\ndesigning this system is to perform dynamic route assignment to relieve traffic\ncongestion and limit the unexpected fluctuation effects on traffic flow. The\nsuggested system is executed and simulated using SUMO, a well-known microscopic\ntraffic simulator. For the present study, we have tested four large and\nheterogeneous metropolitan areas located in the cities of Sfax, Luxembourg,\nBologna and Cologne. The experimental results proved the effectiveness of\nlearning the Hierarchical Interval type-2 Fuzzy logic using real time particle\nswarm optimization technique PSO to accomplish multiobjective optimality\nregarding two criteria: number of vehicles that reach their destination and\naverage travel time. The obtained results are encouraging, confirming the\nefficiency of the proposed system.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 10:16:00 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Zouari", "Mariam", ""], ["Baklouti", "Nesrine", ""], ["Medina", "Javier Sanchez", ""], ["Ayed", "Mounir Ben", ""], ["Alimi", "Adel M.", ""]]}, {"id": "1812.02215", "submitter": "John Hooker", "authors": "Danial Davarnia, J. N. Hooker", "title": "Consistency for 0-1 Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concepts of consistency have long played a key role in constraint programming\nbut never developed in integer programming (IP). Consistency nonetheless plays\na role in IP as well. For example, cutting planes can reduce backtracking by\nachieving various forms of consistency as well as by tightening the linear\nprogramming (LP) relaxation. We introduce a type of consistency that is\nparticularly suited for 0-1 programming and develop the associated theory. We\ndefine a 0-1 constraint set as LP-consistent when any partial assignment that\nis consistent with its linear programming relaxation is consistent with the\noriginal 0-1 constraint set. We prove basic properties of LP-consistency,\nincluding its relationship with Chvatal-Gomory cuts and the integer hull. We\nshow that a weak form of LP-consistency can reduce or eliminate backtracking in\na way analogous to k-consistency but is easier to achieve. In so doing, we\nidentify a class of valid inequalities that can be more effective than\ntraditional cutting planes at cutting off infeasible 0-1 partial assignments.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 20:41:02 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Davarnia", "Danial", ""], ["Hooker", "J. N.", ""]]}, {"id": "1812.02217", "submitter": "John Hooker", "authors": "John Hooker", "title": "Truly Autonomous Machines Are Ethical", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While many see the prospect of autonomous machines as threatening, autonomy\nmay be exactly what we want in a superintelligent machine. There is a sense of\nautonomy, deeply rooted in the ethical literature, in which an autonomous\nmachine is necessarily an ethical one. Development of the theory underlying\nthis idea not only reveals the advantages of autonomy, but it sheds light on a\nnumber of issues in the ethics of artificial intelligence. It helps us to\nunderstand what sort of obligations we owe to machines, and what obligations\nthey owe to us. It clears up the issue of assigning responsibility to machines\nor their creators. More generally, a concept of autonomy that is adequate to\nboth human and artificial intelligence can lead to a more adequate ethical\ntheory for both.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 20:47:11 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Hooker", "John", ""]]}, {"id": "1812.02340", "submitter": "Daniel Philps", "authors": "Daniel Philps, Tillman Weyde, Artur d'Avila Garcez, Roy Batchelor", "title": "Continual Learning Augmented Investment Decisions", "comments": "NeurIPS 2018 Workshop on Challenges and Opportunities for AI in\n  Financial Services: the Impact of Fairness, Explainability, Accuracy, and\n  Privacy, Montreal, Canada. This is a non-archival publication - the authors\n  may submit revisions and extensions of this paper to other publication venues", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-fin.CP q-fin.PM q-fin.TR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Investment decisions can benefit from incorporating an accumulated knowledge\nof the past to drive future decision making. We introduce Continual Learning\nAugmentation (CLA) which is based on an explicit memory structure and a feed\nforward neural network (FFNN) base model and used to drive long term financial\ninvestment decisions. We demonstrate that our approach improves accuracy in\ninvestment decision making while memory is addressed in an explainable way. Our\napproach introduces novel remember cues, consisting of empirically learned\nchange points in the absolute error series of the FFNN. Memory recall is also\nnovel, with contextual similarity assessed over time by sampling distances\nusing dynamic time warping (DTW). We demonstrate the benefits of our approach\nby using it in an expected return forecasting task to drive investment\ndecisions. In an investment simulation in a broad international equity universe\nbetween 2003-2017, our approach significantly outperforms FFNN base models. We\nalso illustrate how CLA's memory addressing works in practice, using a worked\nexample to demonstrate the explainability of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 04:26:25 GMT"}, {"version": "v2", "created": "Sat, 8 Dec 2018 17:26:47 GMT"}, {"version": "v3", "created": "Fri, 14 Dec 2018 10:19:57 GMT"}, {"version": "v4", "created": "Fri, 25 Jan 2019 09:51:52 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Philps", "Daniel", ""], ["Weyde", "Tillman", ""], ["Garcez", "Artur d'Avila", ""], ["Batchelor", "Roy", ""]]}, {"id": "1812.02425", "submitter": "Zhiqiang Shen", "authors": "Zhiqiang Shen and Zhankui He and Xiangyang Xue", "title": "MEAL: Multi-Model Ensemble via Adversarial Learning", "comments": "To appear in AAAI 2019. Code and models are available at:\n  https://github.com/AaronHeee/MEAL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Often the best performing deep neural models are ensembles of multiple\nbase-level networks. Unfortunately, the space required to store these many\nnetworks, and the time required to execute them at test-time, prohibits their\nuse in applications where test sets are large (e.g., ImageNet). In this paper,\nwe present a method for compressing large, complex trained ensembles into a\nsingle network, where knowledge from a variety of trained deep neural networks\n(DNNs) is distilled and transferred to a single DNN. In order to distill\ndiverse knowledge from different trained (teacher) models, we propose to use\nadversarial-based learning strategy where we define a block-wise training loss\nto guide and optimize the predefined student network to recover the knowledge\nin teacher models, and to promote the discriminator network to distinguish\nteacher vs. student features simultaneously. The proposed ensemble method\n(MEAL) of transferring distilled knowledge with adversarial learning exhibits\nthree important advantages: (1) the student network that learns the distilled\nknowledge with discriminators is optimized better than the original model; (2)\nfast inference is realized by a single forward pass, while the performance is\neven better than traditional ensembles from multi-original models; (3) the\nstudent network can learn the distilled knowledge from a teacher model that has\narbitrary structures. Extensive experiments on CIFAR-10/100, SVHN and ImageNet\ndatasets demonstrate the effectiveness of our MEAL method. On ImageNet, our\nResNet-50 based MEAL achieves top-1/5 21.79%/5.99% val error, which outperforms\nthe original model by 2.06%/1.14%. Code and models are available at:\nhttps://github.com/AaronHeee/MEAL\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 09:48:49 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2019 06:32:03 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Shen", "Zhiqiang", ""], ["He", "Zhankui", ""], ["Xue", "Xiangyang", ""]]}, {"id": "1812.02464", "submitter": "Craig Atkinson", "authors": "Craig Atkinson and Brendan McCane and Lech Szymanski and Anthony\n  Robins", "title": "Pseudo-Rehearsal: Achieving Deep Reinforcement Learning without\n  Catastrophic Forgetting", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2020.11.050", "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Neural networks can achieve excellent results in a wide variety of\napplications. However, when they attempt to sequentially learn, they tend to\nlearn the new task while catastrophically forgetting previous ones. We propose\na model that overcomes catastrophic forgetting in sequential reinforcement\nlearning by combining ideas from continual learning in both the image\nclassification domain and the reinforcement learning domain. This model\nfeatures a dual memory system which separates continual learning from\nreinforcement learning and a pseudo-rehearsal system that \"recalls\" items\nrepresentative of previous tasks via a deep generative network. Our model\nsequentially learns Atari 2600 games without demonstrating catastrophic\nforgetting and continues to perform above human level on all three games. This\nresult is achieved without: demanding additional storage requirements as the\nnumber of tasks increases, storing raw data or revisiting past tasks. In\ncomparison, previous state-of-the-art solutions are substantially more\nvulnerable to forgetting on these complex deep reinforcement learning tasks.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 11:20:18 GMT"}, {"version": "v2", "created": "Sun, 24 Feb 2019 22:31:47 GMT"}, {"version": "v3", "created": "Mon, 26 Aug 2019 02:16:29 GMT"}, {"version": "v4", "created": "Mon, 7 Oct 2019 01:42:20 GMT"}, {"version": "v5", "created": "Mon, 3 Aug 2020 05:52:01 GMT"}, {"version": "v6", "created": "Wed, 16 Dec 2020 21:38:56 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Atkinson", "Craig", ""], ["McCane", "Brendan", ""], ["Szymanski", "Lech", ""], ["Robins", "Anthony", ""]]}, {"id": "1812.02471", "submitter": "Giovanni Sileno", "authors": "Giovanni Sileno, Alexander Boer, Tom van Engers", "title": "The Role of Normware in Trustworthy and Explainable AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For being potentially destructive, in practice incomprehensible and for the\nmost unintelligible, contemporary technology is setting high challenges on our\nsociety. New conception methods are urgently required. Reorganizing ideas and\ndiscussions presented in AI and related fields, this position paper aims to\nhighlight the importance of normware--that is, computational artifacts\nspecifying norms--with respect to these issues, and argues for its\nirreducibility with respect to software by making explicit its neglected\necological dimension in the decision-making cycle.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 11:33:00 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Sileno", "Giovanni", ""], ["Boer", "Alexander", ""], ["van Engers", "Tom", ""]]}, {"id": "1812.02529", "submitter": "Haifeng Wang", "authors": "Haifeng Wang", "title": "Utilizing Imbalanced Data and Classification Cost Matrix to Predict\n  Movie Preferences", "comments": "12 pages, 4 figures", "journal-ref": "International Journal of Artificial Intelligence and Applications\n  (IJAIA), Vol.9, No.6, November 2018", "doi": "10.5121/ijaia.2018.9601", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a movie genre recommendation system based on\nimbalanced survey data and unequal classification costs for small and\nmedium-sized enterprises (SMEs) who need a data-based and analytical approach\nto stock favored movies and target marketing to young people. The dataset\nmaintains a detailed personal profile as predictors including demographic,\nbehavioral and preferences information for each user as well as imbalanced\ngenre preferences. These predictors do not include the information such as\nactors or directors. The paper applies Gentle boost, Adaboost and Bagged tree\nensembles as well as SVM machine learning algorithms to learn classification\nfrom one thousand observations and predict movie genre preferences with\nadjusted classification costs. The proposed recommendation system also selects\nimportant predictors to avoid overfitting and to shorten training time. This\npaper compares the test error among the above-mentioned algorithms that are\nused to recommend different movie genres. The prediction power is also\nindicated in a comparison of precision and recall with other state-of-the-art\nrecommendation systems. The proposed movie genre recommendation system solves\nproblems such as small dataset, imbalanced response, and unequal classification\ncosts.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 15:28:45 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Wang", "Haifeng", ""]]}, {"id": "1812.02534", "submitter": "Florentin Smarandache", "authors": "Florentin Smarandache", "title": "About Nonstandard Neutrosophic Logic (Answers to Imamura 'Note on the\n  Definition of Neutrosophic Logic')", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to more accurately situate and fit the neutrosophic logic into the\nframework of nonstandard analysis, we present the neutrosophic inequalities,\nneutrosophic equality, neutrosophic infimum and supremum, neutrosophic standard\nintervals, including the cases when the neutrosophic logic standard and\nnonstandard components T, I, F get values outside of the classical real unit\ninterval [0, 1], and a brief evolution of neutrosophic operators. The paper\nintends to answer Imamura criticism that we found benefic in better\nunderstanding the nonstandard neutrosophic logic, although the nonstandard\nneutrosophic logic was never used in practical applications.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 23:25:04 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 17:35:00 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Smarandache", "Florentin", ""]]}, {"id": "1812.02536", "submitter": "Sherzod Hakimov", "authors": "Sherzod Hakimov, Soufian Jebbara, Philipp Cimiano", "title": "Evaluating Architectural Choices for Deep Learning Approaches for\n  Question Answering over Knowledge Bases", "comments": "the longer version than the original publication at ICSC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The task of answering natural language questions over knowledge bases has\nreceived wide attention in recent years. Various deep learning architectures\nhave been proposed for this task. However, architectural design choices are\ntypically not systematically compared nor evaluated under the same conditions.\nIn this paper, we contribute to a better understanding of the impact of\narchitectural design choices by evaluating four different architectures under\nthe same conditions. We address the task of answering simple questions,\nconsisting in predicting the subject and predicate of a triple given a\nquestion. In order to provide a fair comparison of different architectures, we\nevaluate them under the same strategy for inferring the subject, and compare\ndifferent architectures for inferring the predicate. The architecture for\ninferring the subject is based on a standard LSTM model trained to recognize\nthe span of the subject in the question and on a linking component that links\nthe subject span to an entity in the knowledge base. The architectures for\npredicate inference are based on i) a standard softmax classifier ranging over\nall predicates as output, iii) a model that predicts a low-dimensional encoding\nof the property given entity representation and question, iii) a model that\nlearns to score a pair of subject and predicate given the question as well as\niv) a model based on the well-known FastText model. The comparison of\narchitectures shows that FastText provides better results than other\narchitectures.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 14:11:25 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 09:36:17 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Hakimov", "Sherzod", ""], ["Jebbara", "Soufian", ""], ["Cimiano", "Philipp", ""]]}, {"id": "1812.02559", "submitter": "Bo Shen", "authors": "Bo Shen, Wei Zhang, Haiyan Zhao, Zhi Jin and Yanhong Wu", "title": "Solving Pictorial Jigsaw Puzzle by Stigmergy-inspired Internet-based\n  Human Collective Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pictorial jigsaw (PJ) puzzle is a well-known leisure game for humans.\nUsually, a PJ puzzle game is played by one or several human players\nface-to-face in the physical space. In this paper, we focus on how to solve PJ\npuzzles in the cyberspace by a group of physically distributed human players.\nWe propose an approach to solving PJ puzzle by stigmergy-inspired\nInternet-based human collective intelligence. The core of the approach is a\ncontinuously executing loop, named the EIF loop, which consists of three\nactivities: exploration, integration, and feedback. In exploration, each player\ntries to solve the PJ puzzle alone, without direct interactions with other\nplayers. At any time, the result of a player's exploration is a partial\nsolution to the PJ puzzle, and a set of rejected neighboring relation between\npieces. The results of all players' exploration are integrated in real time\nthrough integration, with the output of a continuously updated collective\nopinion graph (COG). And through feedback, each player is provided with\npersonalized feedback information based on the current COG and the player's\nexploration result, in order to accelerate his/her puzzle-solving process.\nExploratory experiments show that: (1) supported by this approach, the time to\nsolve PJ puzzle is nearly linear to the reciprocal of the number of players,\nand shows better scalability to puzzle size than that of face-to-face\ncollaboration for 10-player groups; (2) for groups with 2 to 10 players, the\npuzzle-solving time decreases 31.36%-64.57% on average, compared with the best\nsingle players in the experiments.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 12:07:12 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 08:58:10 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Shen", "Bo", ""], ["Zhang", "Wei", ""], ["Zhao", "Haiyan", ""], ["Jin", "Zhi", ""], ["Wu", "Yanhong", ""]]}, {"id": "1812.02560", "submitter": "Vincent Conitzer", "authors": "Vincent Conitzer", "title": "Can Artificial Intelligence Do Everything That We Can?", "comments": "A shorter version appeared as \"Natural Intelligence Still Has Its\n  Advantages\" in The Wall Street Journal on August 28, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, I discuss what AI can and cannot yet do, and the\nimplications for humanity.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 23:26:36 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Conitzer", "Vincent", ""]]}, {"id": "1812.02573", "submitter": "Osbert Bastani", "authors": "Osbert Bastani, Xin Zhang, Armando Solar-Lezama", "title": "Probabilistic Verification of Fairness Properties via Concentration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning systems are increasingly used to make real world legal\nand financial decisions, it is of paramount importance that we develop\nalgorithms to verify that these systems do not discriminate against minorities.\nWe design a scalable algorithm for verifying fairness specifications. Our\nalgorithm obtains strong correctness guarantees based on adaptive concentration\ninequalities; such inequalities enable our algorithm to adaptively take samples\nuntil it has enough data to make a decision. We implement our algorithm in a\ntool called VeriFair, and show that it scales to large machine learning models,\nincluding a deep recurrent neural network that is more than five orders of\nmagnitude larger than the largest previously-verified neural network. While our\ntechnique only gives probabilistic guarantees due to the use of random samples,\nwe show that we can choose the probability of error to be extremely small.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 19:54:38 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2019 17:07:59 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Bastani", "Osbert", ""], ["Zhang", "Xin", ""], ["Solar-Lezama", "Armando", ""]]}, {"id": "1812.02576", "submitter": "Zhi-Xuan Tan", "authors": "Zhi-Xuan Tan, Jake Brawer and Brian Scassellati", "title": "That's Mine! Learning Ownership Relations and Norms for Robots", "comments": "9 pg., 2 fig., accepted for AAAI-2019. Video demo:\n  https://bit.ly/2z8obET GitHub: https://github.com/OwnageBot/ownage_bot", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability for autonomous agents to learn and conform to human norms is\ncrucial for their safety and effectiveness in social environments. While recent\nwork has led to frameworks for the representation and inference of simple\nsocial rules, research into norm learning remains at an exploratory stage.\nHere, we present a robotic system capable of representing, learning, and\ninferring ownership relations and norms. Ownership is represented as a graph of\nprobabilistic relations between objects and their owners, along with a database\nof predicate-based norms that constrain the actions permissible on owned\nobjects. To learn these norms and relations, our system integrates (i) a novel\nincremental norm learning algorithm capable of both one-shot learning and\ninduction from specific examples, (ii) Bayesian inference of ownership\nrelations in response to apparent rule violations, and (iii) percept-based\nprediction of an object's likely owners. Through a series of simulated and\nreal-world experiments, we demonstrate the competence and flexibility of the\nsystem in performing object manipulation tasks that require a variety of norms\nto be followed, laying the groundwork for future research into the acquisition\nand application of social norms.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 08:09:13 GMT"}, {"version": "v2", "created": "Thu, 10 Jan 2019 04:21:06 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Tan", "Zhi-Xuan", ""], ["Brawer", "Jake", ""], ["Scassellati", "Brian", ""]]}, {"id": "1812.02578", "submitter": "Daniel Estrada", "authors": "Daniel Estrada", "title": "Conscious enactive computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper looks at recent debates in the enactivist literature on\ncomputation and consciousness in order to assess major obstacles to building\nartificial conscious agents. We consider a proposal from Villalobos and\nDewhurst (2018) for enactive computation on the basis of organizational\nclosure. We attempt to improve the argument by reflecting on the closed paths\nthrough state space taken by finite state automata. This motivates a defense\nagainst Clark's recent criticisms of \"extended consciousness\", and perhaps a\nnew perspective on living with machines.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 17:48:11 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Estrada", "Daniel", ""]]}, {"id": "1812.02580", "submitter": "Debasis Mitra Ph.D.", "authors": "Debasis Mitra", "title": "Selected Qualitative Spatio-temporal Calculi Developed for Constraint\n  Reasoning: A Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article a few of the qualitative spatio-temporal knowledge\nrepresentation techniques developed by the constraint reasoning community\nwithin artificial intelligence are reviewed. The objective is to provide a\nbroad exposure to any other interested group who may utilize these\nrepresentations. The author has a particular interest in applying these calculi\n(in a broad sense) in topological data analysis, as these schemes are highly\nqualitative in nature.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 23:49:37 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Mitra", "Debasis", ""]]}, {"id": "1812.02632", "submitter": "Si-An Chen", "authors": "Si-An Chen, Voot Tangkaratt, Hsuan-Tien Lin, Masashi Sugiyama", "title": "Active Deep Q-learning with Demonstration", "comments": null, "journal-ref": "Mach Learn 109, 1699-1725 (2020)", "doi": "10.1007/s10994-019-05849-4", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has shown that although Reinforcement Learning (RL) can\nbenefit from expert demonstration, it usually takes considerable efforts to\nobtain enough demonstration. The efforts prevent training decent RL agents with\nexpert demonstration in practice. In this work, we propose Active Reinforcement\nLearning with Demonstration (ARLD), a new framework to streamline RL in terms\nof demonstration efforts by allowing the RL agent to query for demonstration\nactively during training. Under the framework, we propose Active Deep\nQ-Network, a novel query strategy which adapts to the dynamically-changing\ndistributions during the RL training process by estimating the uncertainty of\nrecent states. The expert demonstration data within Active DQN are then\nutilized by optimizing supervised max-margin loss in addition to temporal\ndifference loss within usual DQN training. We propose two methods of estimating\nthe uncertainty based on two state-of-the-art DQN models, namely the divergence\nof bootstrapped DQN and the variance of noisy DQN. The empirical results\nvalidate that both methods not only learn faster than other passive expert\ndemonstration methods with the same amount of demonstration and but also reach\nsuper-expert level of performance across four different tasks.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 16:13:43 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Chen", "Si-An", ""], ["Tangkaratt", "Voot", ""], ["Lin", "Hsuan-Tien", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1812.02636", "submitter": "Gil Avraham", "authors": "Yan Zuo, Gil Avraham, Tom Drummond", "title": "Traversing Latent Space using Decision Ferns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The practice of transforming raw data to a feature space so that inference\ncan be performed in that space has been popular for many years. Recently, rapid\nprogress in deep neural networks has given both researchers and practitioners\nenhanced methods that increase the richness of feature representations, be it\nfrom images, text or speech. In this work we show how a constructed latent\nspace can be explored in a controlled manner and argue that this complements\nwell founded inference methods. For constructing the latent space a Variational\nAutoencoder is used. We present a novel controller module that allows for\nsmooth traversal in the latent space and construct an end-to-end trainable\nframework. We explore the applicability of our method for performing spatial\ntransformations as well as kinematics for predicting future latent vectors of a\nvideo sequence.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 16:15:24 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Zuo", "Yan", ""], ["Avraham", "Gil", ""], ["Drummond", "Tom", ""]]}, {"id": "1812.02648", "submitter": "Hado van Hasselt", "authors": "Hado van Hasselt, Yotam Doron, Florian Strub, Matteo Hessel, Nicolas\n  Sonnerat, Joseph Modayil", "title": "Deep Reinforcement Learning and the Deadly Triad", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We know from reinforcement learning theory that temporal difference learning\ncan fail in certain cases. Sutton and Barto (2018) identify a deadly triad of\nfunction approximation, bootstrapping, and off-policy learning. When these\nthree properties are combined, learning can diverge with the value estimates\nbecoming unbounded. However, several algorithms successfully combine these\nthree properties, which indicates that there is at least a partial gap in our\nunderstanding. In this work, we investigate the impact of the deadly triad in\npractice, in the context of a family of popular deep reinforcement learning\nmodels - deep Q-networks trained with experience replay - analysing how the\ncomponents of this system play a role in the emergence of the deadly triad, and\nin the agent's performance\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 16:36:20 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["van Hasselt", "Hado", ""], ["Doron", "Yotam", ""], ["Strub", "Florian", ""], ["Hessel", "Matteo", ""], ["Sonnerat", "Nicolas", ""], ["Modayil", "Joseph", ""]]}, {"id": "1812.02690", "submitter": "Karan Singh", "authors": "Elad Hazan, Sham M. Kakade, Karan Singh, Abby Van Soest", "title": "Provably Efficient Maximum Entropy Exploration", "comments": "Updated experiment results; minor revisions in writing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose an agent is in a (possibly unknown) Markov Decision Process in the\nabsence of a reward signal, what might we hope that an agent can efficiently\nlearn to do? This work studies a broad class of objectives that are defined\nsolely as functions of the state-visitation frequencies that are induced by how\nthe agent behaves. For example, one natural, intrinsically defined, objective\nproblem is for the agent to learn a policy which induces a distribution over\nstate space that is as uniform as possible, which can be measured in an\nentropic sense. We provide an efficient algorithm to optimize such such\nintrinsically defined objectives, when given access to a black box planning\noracle (which is robust to function approximation). Furthermore, when\nrestricted to the tabular setting where we have sample based access to the MDP,\nour proposed algorithm is provably efficient, both in terms of its sample and\ncomputational complexities. Key to our algorithmic methodology is utilizing the\nconditional gradient method (a.k.a. the Frank-Wolfe algorithm) which utilizes\nan approximate MDP solver.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 18:15:44 GMT"}, {"version": "v2", "created": "Sat, 26 Jan 2019 01:54:32 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Hazan", "Elad", ""], ["Kakade", "Sham M.", ""], ["Singh", "Karan", ""], ["Van Soest", "Abby", ""]]}, {"id": "1812.02722", "submitter": "Halim Abbas", "authors": "Alyson Maslowski, Halim Abbas, Kelley Abrams, Sharief Taraman, Ford\n  Garberson, and Susan Segar", "title": "Project Rosetta: A Childhood Social, Emotional, and Behavioral\n  Developmental Ontology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a wide array of existing instruments used to assess childhood\nbehavior and development for the evaluation of social, emotional and behavioral\ndisorders. Many of these instruments either focus on one diagnostic category or\nencompass a broad set of childhood behaviors. We built an extensive ontology of\nthe questions associated with key features that have diagnostic relevance for\nchild behavioral conditions, such as Autism Spectrum Disorder (ASD),\nattention-deficit/hyperactivity disorder (ADHD), and anxiety, by incorporating\na subset of existing child behavioral instruments and categorizing each\nquestion into clinical domains. Each existing question and set of question\nresponses were then mapped to a new unique Rosetta question and set of answer\ncodes encompassing the semantic meaning and identified concept(s) of as many\nexisting questions as possible. This resulted in 1274 existing instrument\nquestions mapping to 209 Rosetta questions creating a minimal set of questions\nthat are comprehensive of each topic and subtopic. This resulting ontology can\nbe used to create more concise instruments across various ages and conditions,\nas well as create more robust overlapping datasets for both clinical and\nresearch use.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 18:57:52 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Maslowski", "Alyson", ""], ["Abbas", "Halim", ""], ["Abrams", "Kelley", ""], ["Taraman", "Sharief", ""], ["Garberson", "Ford", ""], ["Segar", "Susan", ""]]}, {"id": "1812.02783", "submitter": "Kaiqing Zhang", "authors": "Kaiqing Zhang and Zhuoran Yang and Han Liu and Tong Zhang and Tamer\n  Ba\\c{s}ar", "title": "Finite-Sample Analysis For Decentralized Batch Multi-Agent Reinforcement\n  Learning With Networked Agents", "comments": "Addressed comments from IFAC Congress 2020 and TAC reviews; added\n  simulations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the increasing interest in multi-agent reinforcement learning (MARL)\nin multiple communities, understanding its theoretical foundation has long been\nrecognized as a challenging problem. In this work, we address this problem by\nproviding a finite-sample analysis for decentralized batch MARL with networked\nagents. Specifically, we consider two decentralized MARL settings, where teams\nof agents are connected by time-varying communication networks, and either\ncollaborate or compete in a zero-sum game setting, without any central\ncontroller. These settings cover many conventional MARL settings in the\nliterature. For both settings, we develop batch MARL algorithms that can be\nimplemented in a decentralized fashion, and quantify the finite-sample errors\nof the estimated action-value functions. Our error analysis captures how the\nfunction class, the number of samples within each iteration, and the number of\niterations determine the statistical accuracy of the proposed algorithms. Our\nresults, compared to the finite-sample bounds for single-agent RL, involve\nadditional error terms caused by decentralized computation, which is inherent\nin our decentralized MARL setting. This work appears to be the first\nfinite-sample analysis for batch MARL, a step towards rigorous theoretical\nunderstanding of general MARL algorithms in the finite-sample regime.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 20:09:40 GMT"}, {"version": "v2", "created": "Thu, 20 Dec 2018 07:22:23 GMT"}, {"version": "v3", "created": "Tue, 25 Dec 2018 18:45:26 GMT"}, {"version": "v4", "created": "Sat, 5 Jan 2019 04:00:57 GMT"}, {"version": "v5", "created": "Sat, 26 Jan 2019 06:24:09 GMT"}, {"version": "v6", "created": "Thu, 30 May 2019 19:19:44 GMT"}, {"version": "v7", "created": "Tue, 12 Nov 2019 17:09:11 GMT"}, {"version": "v8", "created": "Mon, 14 Dec 2020 06:10:22 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Zhang", "Kaiqing", ""], ["Yang", "Zhuoran", ""], ["Liu", "Han", ""], ["Zhang", "Tong", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "1812.02788", "submitter": "Miguel L\\'azaro-Gredilla", "authors": "Miguel L\\'azaro-Gredilla, Dianhuan Lin, J. Swaroop Guntupalli, Dileep\n  George", "title": "Beyond imitation: Zero-shot task transfer on robots by learning concepts\n  as cognitive programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans can infer concepts from image pairs and apply those in the physical\nworld in a completely different setting, enabling tasks like IKEA assembly from\ndiagrams. If robots could represent and infer high-level concepts, it would\nsignificantly improve their ability to understand our intent and to transfer\ntasks between different environments. To that end, we introduce a computational\nframework that replicates aspects of human concept learning. Concepts are\nrepresented as programs on a novel computer architecture consisting of a visual\nperception system, working memory, and action controller. The instruction set\nof this \"cognitive computer\" has commands for parsing a visual scene, directing\ngaze and attention, imagining new objects, manipulating the contents of a\nvisual working memory, and controlling arm movement. Inferring a concept\ncorresponds to inducing a program that can transform the input to the output.\nSome concepts require the use of imagination and recursion. Previously learned\nconcepts simplify the learning of subsequent more elaborate concepts, and\ncreate a hierarchy of abstractions. We demonstrate how a robot can use these\nabstractions to interpret novel concepts presented to it as schematic images,\nand then apply those concepts in dramatically different situations. By bringing\ncognitive science ideas on mental imagery, perceptual symbols, embodied\ncognition, and deictic mechanisms into the realm of machine learning, our work\nbrings us closer to the goal of building robots that have interpretable\nrepresentations and commonsense.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 20:26:42 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["L\u00e1zaro-Gredilla", "Miguel", ""], ["Lin", "Dianhuan", ""], ["Guntupalli", "J. Swaroop", ""], ["George", "Dileep", ""]]}, {"id": "1812.02850", "submitter": "John Foley", "authors": "John Foley, Emma Tosch, Kaleigh Clary, David Jensen", "title": "ToyBox: Better Atari Environments for Testing Reinforcement Learning\n  Agents", "comments": "NeurIPS Systems for ML Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a widely accepted principle that software without tests has bugs.\nTesting reinforcement learning agents is especially difficult because of the\nstochastic nature of both agents and environments, the complexity of\nstate-of-the-art models, and the sequential nature of their predictions.\nRecently, the Arcade Learning Environment (ALE) has become one of the most\nwidely used benchmark suites for deep learning research, and state-of-the-art\nReinforcement Learning (RL) agents have been shown to routinely equal or exceed\nhuman performance on many ALE tasks. Since ALE is based on emulation of\noriginal Atari games, the environment does not provide semantically meaningful\nrepresentations of internal game state. This means that ALE has limited utility\nas an environment for supporting testing or model introspection. We propose\nToyBox, a collection of reimplementations of these games that solves this\ncritical problem and enables robust testing of RL agents.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 23:15:41 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 16:58:36 GMT"}, {"version": "v3", "created": "Fri, 25 Jan 2019 16:39:37 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Foley", "John", ""], ["Tosch", "Emma", ""], ["Clary", "Kaleigh", ""], ["Jensen", "David", ""]]}, {"id": "1812.02868", "submitter": "Sam Witty", "authors": "Sam Witty, Jun Ki Lee, Emma Tosch, Akanksha Atrey, Michael Littman,\n  David Jensen", "title": "Measuring and Characterizing Generalization in Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement-learning methods have achieved remarkable performance on\nchallenging control tasks. Observations of the resulting behavior give the\nimpression that the agent has constructed a generalized representation that\nsupports insightful action decisions. We re-examine what is meant by\ngeneralization in RL, and propose several definitions based on an agent's\nperformance in on-policy, off-policy, and unreachable states. We propose a set\nof practical methods for evaluating agents with these definitions of\ngeneralization. We demonstrate these techniques on a common benchmark task for\ndeep RL, and we show that the learned networks make poor decisions for states\nthat differ only slightly from on-policy states, even though those states are\nnot selected adversarially. Taken together, these results call into question\nthe extent to which deep Q-networks learn generalized representations, and\nsuggest that more experimentation and analysis is necessary before claims of\nrepresentation learning can be supported.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 01:32:02 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 13:17:52 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Witty", "Sam", ""], ["Lee", "Jun Ki", ""], ["Tosch", "Emma", ""], ["Atrey", "Akanksha", ""], ["Littman", "Michael", ""], ["Jensen", "David", ""]]}, {"id": "1812.02900", "submitter": "Scott Fujimoto", "authors": "Scott Fujimoto, David Meger, Doina Precup", "title": "Off-Policy Deep Reinforcement Learning without Exploration", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many practical applications of reinforcement learning constrain agents to\nlearn from a fixed batch of data which has already been gathered, without\noffering further possibility for data collection. In this paper, we demonstrate\nthat due to errors introduced by extrapolation, standard off-policy deep\nreinforcement learning algorithms, such as DQN and DDPG, are incapable of\nlearning with data uncorrelated to the distribution under the current policy,\nmaking them ineffective for this fixed batch setting. We introduce a novel\nclass of off-policy algorithms, batch-constrained reinforcement learning, which\nrestricts the action space in order to force the agent towards behaving close\nto on-policy with respect to a subset of the given data. We present the first\ncontinuous control deep reinforcement learning algorithm which can learn\neffectively from arbitrary, fixed batch data, and empirically demonstrate the\nquality of its behavior in several tasks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 04:03:25 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 19:58:23 GMT"}, {"version": "v3", "created": "Sat, 10 Aug 2019 03:36:31 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Fujimoto", "Scott", ""], ["Meger", "David", ""], ["Precup", "Doina", ""]]}, {"id": "1812.02942", "submitter": "Mieczys{\\l}aw K{\\l}opotek", "authors": "Mieczys{\\l}aw A. K{\\l}opotek, and S{\\l}awomir T. Wierzcho\\'n", "title": "On Marginally Correct Approximations of Dempster-Shafer Belief Functions\n  from Data", "comments": "M.A. K{\\l}opotek, S.T. Wierzcho\\'n: On Marginally Correct\n  Approximations of Dempster-Shafer Belief Functions from Data. Proc. IPMU'96\n  (Information Processing and Management of Uncertainty), Grenada (Spain),\n  Publisher: Universitaed de Granada, 1-5 July 1996, Vol II, pp. 769-774", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematical Theory of Evidence (MTE), a foundation for reasoning under\npartial ignorance, is blamed to leave frequencies outside (or aside of) its\nframework. The seriousness of this accusation is obvious: no experiment may be\nrun to compare the performance of MTE-based models of real world processes\nagainst real world data.\n  In this paper we consider this problem from the point of view of conditioning\nin the MTE. We describe the class of belief functions for which marginal\nconsistency with observed frequencies may be achieved and conditional belief\nfunctions are proper belief functions,%\\ and deal with implications for\n(marginal) approximation of general belief functions by this class of belief\nfunctions and for inference models in MTE.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 08:33:26 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["K\u0142opotek", "Mieczys\u0142aw A.", ""], ["Wierzcho\u0144", "S\u0142awomir T.", ""]]}, {"id": "1812.02953", "submitter": "Han Yu", "authors": "Han Yu, Zhiqi Shen, Chunyan Miao, Cyril Leung, Victor R. Lesser and\n  Qiang Yang", "title": "Building Ethics into Artificial Intelligence", "comments": null, "journal-ref": "H. Yu, Z. Shen, C. Miao, C. Leung, V. R. Lesser & Q. Yang,\n  \"Building Ethics into Artificial Intelligence,\" in Proceedings of the 27th\n  International Joint Conference on Artificial Intelligence (IJCAI'18), pp.\n  5527-5533, 2018", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As artificial intelligence (AI) systems become increasingly ubiquitous, the\ntopic of AI governance for ethical decision-making by AI has captured public\nimagination. Within the AI research community, this topic remains less familiar\nto many researchers. In this paper, we complement existing surveys, which\nlargely focused on the psychological, social and legal discussions of the\ntopic, with an analysis of recent advances in technical solutions for AI\ngovernance. By reviewing publications in leading AI conferences including AAAI,\nAAMAS, ECAI and IJCAI, we propose a taxonomy which divides the field into four\nareas: 1) exploring ethical dilemmas; 2) individual ethical decision\nframeworks; 3) collective ethical decision frameworks; and 4) ethics in\nhuman-AI interactions. We highlight the intuitions and key techniques used in\neach approach, and discuss promising future research directions towards\nsuccessful integration of ethical AI systems into human societies.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 09:18:01 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Yu", "Han", ""], ["Shen", "Zhiqi", ""], ["Miao", "Chunyan", ""], ["Leung", "Cyril", ""], ["Lesser", "Victor R.", ""], ["Yang", "Qiang", ""]]}, {"id": "1812.03007", "submitter": "Yin Liang", "authors": "Zecang Gu, Yin Liang, Zhaoxi Zhang", "title": "The Modeling of SDL Aiming at Knowledge Acquisition in Automatic Driving", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper we proposed an ultimate theory to solve the multi-target\ncontrol problem through its introduction to the machine learning framework in\nautomatic driving, which explored the implementation of excellent drivers'\nknowledge acquisition. Nowadays there exist some core problems that have not\nbeen fully realized by the researchers in automatic driving, such as the\noptimal way to control the multi-target objective functions of energy saving,\nsafe driving, headway distance control and comfort driving, as well as the\nresolvability of the networks that automatic driving relied on and the\nhigh-performance chips like GPU on the complex driving environments. According\nto these problems, we developed a new theory to map multitarget objective\nfunctions in different spaces into the same one and thus introduced a machine\nlearning framework of SDL(Super Deep Learning) for optimal multi-targetcontrol\nbased on knowledge acquisition. We will present in this paper the optimal\nmulti-target control by combining the fuzzy relationship of each multi-target\nobjective function and the implementation of excellent drivers' knowledge\nacquired by machine learning. Theoretically, the impact of this method will\nexceed that of the fuzzy control method used in automatic train.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 12:50:47 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Gu", "Zecang", ""], ["Liang", "Yin", ""], ["Zhang", "Zhaoxi", ""]]}, {"id": "1812.03075", "submitter": "Franc Brglez", "authors": "Franc Brglez", "title": "On Uncensored Mean First-Passage-Time Performance Experiments with\n  Multiwalk in $\\mathbb{R}^p$: a New Stochastic Optimization Algorithm", "comments": "8 pages, 5 figures. Invited talk, IEEE Proc. 7th Int. Conf. on\n  Reliability, InfoCom Technologies and Optimization (ICRITO'2018); Aug.\n  29--31, 2018, Amity University, Noida, India, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A rigorous empirical comparison of two stochastic solvers is important when\none of the solvers is a prototype of a new algorithm such as multiwalk (MWA).\nWhen searching for global minima in $\\mathbb{R}^p$, the key data structures of\nMWA include: $p$ rulers with each ruler assigned $m$ marks and a set of $p$\nneighborhood matrices of size up to $m(m-2)$, where each entry represents\nabsolute values of pairwise differences between $m$ marks. Before taking the\nnext step, a controller links the tableau of neighborhood matrices and computes\nnew and improved positions for each of the $m$ marks. The number of columns in\neach neighborhood matrix is denoted as the neighborhood radius $r_n \\le m-2$.\nAny variant of the DEA (differential evolution algorithm) has an effective\npopulation neighborhood of radius not larger than 1. Uncensored\nfirst-passage-time performance experiments that vary the neighborhood radius of\na MW-solver can thus be readily compared to existing variants of DE-solvers.\nThe paper considers seven test cases of increasing complexity and demonstrates,\nunder uncensored first-passage-time performance experiments: (1) significant\nvariability in convergence rate for seven DE-based solver configurations, and\n(2) consistent, monotonic, and significantly faster rate of convergence for the\nMW-solver prototype as we increase the neighborhood radius from 4 to its\nmaximum value.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 03:31:29 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Brglez", "Franc", ""]]}, {"id": "1812.03125", "submitter": "Batu Aytemiz", "authors": "Zeping Zhan, Batu Aytemiz, Adam M. Smith", "title": "Taking the Scenic Route: Automatic Exploration for Videogames", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine playtesting tools and game moment search engines require exposure to\nthe diversity of a game's state space if they are to report on or index the\nmost interesting moments of possible play. Meanwhile, mobile app distribution\nservices would like to quickly determine if a freshly-uploaded game is fit to\nbe published. Having access to a semantic map of reachable states in the game\nwould enable efficient inference in these applications. However, human gameplay\ndata is expensive to acquire relative to the coverage of a game that it\nprovides. We show that off-the-shelf automatic exploration strategies can\nexplore with an effectiveness comparable to human gameplay on the same\ntimescale. We contribute generic methods for quantifying exploration quality as\na function of time and demonstrate our metric on several elementary techniques\nand human players on a collection of commercial games sampled from multiple\ngame platforms (from Atari 2600 to Nintendo 64). Emphasizing the diversity of\nstates reached and the semantic map extracted, this work makes productive\ncontrast with the focus on finding a behavior policy or optimizing game score\nused in most automatic game playing research.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 17:38:46 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Zhan", "Zeping", ""], ["Aytemiz", "Batu", ""], ["Smith", "Adam M.", ""]]}, {"id": "1812.03183", "submitter": "Paul Knott PhD MPhys BSc", "authors": "L. O'Driscoll, R. Nichols, P. A. Knott", "title": "A hybrid machine-learning algorithm for designing quantum experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a hybrid machine-learning algorithm for designing quantum optics\nexperiments that produce specific quantum states. Our algorithm successfully\nfound experimental schemes to produce all 5 states we asked it to, including\nSchr\\\"odinger cat states and cubic phase states, all to a fidelity of over\n$96\\%$. Here we specifically focus on designing realistic experiments, and\nhence all of the algorithm's designs only contain experimental elements that\nare available with current technology. The core of our algorithm is a genetic\nalgorithm that searches for optimal arrangements of the experimental elements,\nbut to speed up the initial search we incorporate a neural network that\nclassifies quantum states. The latter is of independent interest, as it quickly\nlearned to accurately classify quantum states given their photon-number\ndistributions.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 19:01:38 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 14:08:37 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["O'Driscoll", "L.", ""], ["Nichols", "R.", ""], ["Knott", "P. A.", ""]]}, {"id": "1812.03243", "submitter": "Md Kamruzzaman Sarker", "authors": "Md Kamruzzaman Sarker, Pascal Hitzler", "title": "Efficient Concept Induction for Description Logics", "comments": "Accepted at AAAI-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concept Induction refers to the problem of creating complex Description Logic\nclass descriptions (i.e., TBox axioms) from instance examples (i.e., ABox\ndata). In this paper we look particularly at the case where both a set of\npositive and a set of negative instances are given, and complex class\nexpressions are sought under which the positive but not the negative examples\nfall. Concept induction has found applications in ontology engineering, but\nexisting algorithms have fundamental performance issues in some scenarios,\nmainly because a high number of invokations of an external Description Logic\nreasoner is usually required. In this paper we present a new algorithm for this\nproblem which drastically reduces the number of reasoner invokations needed.\nWhile this comes at the expense of a more limited traversal of the search\nspace, we show that our approach improves execution times by up to several\norders of magnitude, while output correctness, measured in the amount of\ncorrect coverage of the input instances, remains reasonably high in many cases.\nOur approach thus should provide a strong alternative to existing systems, in\nparticular in settings where other systems are prohibitively slow.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2018 00:10:05 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Sarker", "Md Kamruzzaman", ""], ["Hitzler", "Pascal", ""]]}, {"id": "1812.03285", "submitter": "Chanwoo Park", "authors": "Chanwoo Park, Jae Myung Kim, Seok Hyeon Ha, Jungwoo Lee", "title": "Sampling-based Bayesian Inference with gradient uncertainty", "comments": "Presented at the Workshop on Bayesian Deep Learning, NeurIPS 2018,\n  Montr\\'eal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks(NNs) have achieved impressive performance, often exceed\nhuman performance on many computer vision tasks. However, one of the most\nchallenging issues that still remains is that NNs are overconfident in their\npredictions, which can be very harmful when this arises in safety critical\napplications. In this paper, we show that predictive uncertainty can be\nefficiently estimated when we incorporate the concept of gradients uncertainty\ninto posterior sampling. The proposed method is tested on two different\ndatasets, MNIST for in-distribution confusing examples and notMNIST for\nout-of-distribution data. We show that our method is able to efficiently\nrepresent predictive uncertainty on both datasets.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2018 08:23:37 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 06:56:51 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Park", "Chanwoo", ""], ["Kim", "Jae Myung", ""], ["Ha", "Seok Hyeon", ""], ["Lee", "Jungwoo", ""]]}, {"id": "1812.03381", "submitter": "Tim Salimans", "authors": "Tim Salimans and Richard Chen", "title": "Learning Montezuma's Revenge from a Single Demonstration", "comments": "Deep RL Workshop, NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for learning from a single demonstration to solve\nhard exploration tasks like the Atari game Montezuma's Revenge. Instead of\nimitating human demonstrations, as proposed in other recent works, our approach\nis to maximize rewards directly. Our agent is trained using off-the-shelf\nreinforcement learning, but starts every episode by resetting to a state from a\ndemonstration. By starting from such demonstration states, the agent requires\nmuch less exploration to learn a game compared to when it starts from the\nbeginning of the game at every episode. We analyze reinforcement learning for\ntasks with sparse rewards in a simple toy environment, where we show that the\nrun-time of standard RL methods scales exponentially in the number of states\nbetween rewards. Our method reduces this to quadratic scaling, opening up many\ntasks that were previously infeasible. We then apply our method to Montezuma's\nRevenge, for which we present a trained agent achieving a high-score of 74,500,\nbetter than any previously published result.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2018 20:16:16 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Salimans", "Tim", ""], ["Chen", "Richard", ""]]}, {"id": "1812.03508", "submitter": "Jorge Fandinno", "authors": "Jorge Fandinno and Johannes Fichte", "title": "Proceedings of the eleventh Workshop on Answer Set Programming and Other\n  Computing Paradigms 2018", "comments": "Proceedings of the elevent Workshop on Answer Set Programming and\n  Other Computing Paradigms 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the eleventh Workshop on Answer Set Programming\nand Other Computing Paradigms (ASPOCP) 2018, which was held in Oxford, UK, July\n18th, 2018.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2018 16:05:25 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 09:40:06 GMT"}, {"version": "v3", "created": "Thu, 21 Nov 2019 15:51:23 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Fandinno", "Jorge", ""], ["Fichte", "Johannes", ""]]}, {"id": "1812.03509", "submitter": "Ziming Li", "authors": "Ziming Li, Julia Kiseleva, Maarten de Rijke", "title": "Dialogue Generation: From Imitation Learning to Inverse Reinforcement\n  Learning", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of adversarial dialogue generation models relies on the\nquality of the reward signal produced by the discriminator. The reward signal\nfrom a poor discriminator can be very sparse and unstable, which may lead the\ngenerator to fall into a local optimum or to produce nonsense replies. To\nalleviate the first problem, we first extend a recently proposed adversarial\ndialogue generation method to an adversarial imitation learning solution. Then,\nin the framework of adversarial inverse reinforcement learning, we propose a\nnew reward model for dialogue generation that can provide a more accurate and\nprecise reward signal for generator training. We evaluate the performance of\nthe resulting model with automatic metrics and human evaluations in two\nannotation settings. Our experimental results demonstrate that our model can\ngenerate more high-quality responses and achieve higher overall performance\nthan the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2018 16:05:43 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Li", "Ziming", ""], ["Kiseleva", "Julia", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1812.03535", "submitter": "Mark Levin", "authors": "Mark Sh. Levin", "title": "On balanced clustering with tree-like structures over clusters", "comments": "15 pages, 15 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article addresses balanced clustering problems with an additional\nrequirement as a tree-like structure over the obtained balanced clusters. This\nkind of clustering problems can be useful in some applications (e.g., network\ndesign, management and routing). Various types of the initial elements are\nconsidered. Four basic greedy-like solving strategies (design framework) are\nconsidered: balancing-spanning strategy, spanning-balancing strategy, direct\nstrategy, and design of layered structures with balancing. An extended\ndescription of the spanning-balancing strategy is presented including four\nsolving schemes and an illustrative numerical example.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2018 18:03:46 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Levin", "Mark Sh.", ""]]}, {"id": "1812.03596", "submitter": "Rahaf Aljundi", "authors": "Rahaf Aljundi and Klaas Kelchtermans and Tinne Tuytelaars", "title": "Task-Free Continual Learning", "comments": "Accepted as a conference paper in CVPR 2019. Rahaf Aljundi and Klaas\n  Kelchtermans have contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods proposed in the literature towards continual deep learning typically\noperate in a task-based sequential learning setup. A sequence of tasks is\nlearned, one at a time, with all data of current task available but not of\nprevious or future tasks. Task boundaries and identities are known at all\ntimes. This setup, however, is rarely encountered in practical applications.\nTherefore we investigate how to transform continual learning to an online\nsetup. We develop a system that keeps on learning over time in a streaming\nfashion, with data distributions gradually changing and without the notion of\nseparate tasks. To this end, we build on the work on Memory Aware Synapses, and\nshow how this method can be made online by providing a protocol to decide i)\nwhen to update the importance weights, ii) which data to use to update them,\nand iii) how to accumulate the importance weights at each update step.\nExperimental results show the validity of the approach in the context of two\napplications: (self-)supervised learning of a face recognition model by\nwatching soap series and learning a robot to avoid collisions.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 02:07:57 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 08:09:27 GMT"}, {"version": "v3", "created": "Mon, 19 Aug 2019 10:42:15 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Aljundi", "Rahaf", ""], ["Kelchtermans", "Klaas", ""], ["Tuytelaars", "Tinne", ""]]}, {"id": "1812.03625", "submitter": "Song Gao", "authors": "Shaohua Wang, Song Gao, Xin Feng, Alan T. Murray, Yuan Zeng", "title": "A context-based geoprocessing framework for optimizing meetup location\n  of multiple moving objects along road networks", "comments": "34 pages, 8 figures", "journal-ref": "International Journal of Geographical Information Science, 32(7),\n  1368-1390 (2018)", "doi": "10.1080/13658816.2018.1431838.", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given different types of constraints on human life, people must make\ndecisions that satisfy social activity needs. Minimizing costs (i.e., distance,\ntime, or money) associated with travel plays an important role in perceived and\nrealized social quality of life. Identifying optimal interaction locations on\nroad networks when there are multiple moving objects (MMO) with space-time\nconstraints remains a challenge. In this research, we formalize the problem of\nfinding dynamic ideal interaction locations for MMO as a spatial optimization\nmodel and introduce a context-based geoprocessing heuristic framework to\naddress this problem. As a proof of concept, a case study involving\nidentification of a meetup location for multiple people under traffic\nconditions is used to validate the proposed geoprocessing framework. Five\nheuristic methods with regard to efficient shortest-path search space have been\ntested. We find that the R* tree-based algorithm performs the best with high\nquality solutions and low computation time. This framework is implemented in a\nGIS environment to facilitate integration with external geographic contextual\ninformation, e.g., temporary road barriers, points of interest (POI), and\nreal-time traffic information, when dynamically searching for ideal meetup\nsites. The proposed method can be applied in trip planning, carpooling\nservices, collaborative interaction, and logistics management.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 05:10:31 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Wang", "Shaohua", ""], ["Gao", "Song", ""], ["Feng", "Xin", ""], ["Murray", "Alan T.", ""], ["Zeng", "Yuan", ""]]}, {"id": "1812.03789", "submitter": "Sander Beckers", "authors": "Sander Beckers and Joseph Y. Halpern", "title": "Abstracting Causal Models", "comments": "Appears in AAAI-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a sequence of successively more restrictive definitions of\nabstraction for causal models, starting with a notion introduced by Rubenstein\net al. (2017) called exact transformation that applies to probabilistic causal\nmodels, moving to a notion of uniform transformation that applies to\ndeterministic causal models and does not allow differences to be hidden by the\n\"right\" choice of distribution, and then to abstraction, where the\ninterventions of interest are determined by the map from low-level states to\nhigh-level states, and strong abstraction, which takes more seriously all\npotential interventions in a model, not just the allowed interventions. We show\nthat procedures for combining micro-variables into macro-variables are\ninstances of our notion of strong abstraction, as are all the examples\nconsidered by Rubenstein et al.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 13:41:42 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 15:46:41 GMT"}, {"version": "v3", "created": "Thu, 27 Jun 2019 12:23:45 GMT"}, {"version": "v4", "created": "Tue, 9 Jul 2019 18:32:39 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Beckers", "Sander", ""], ["Halpern", "Joseph Y.", ""]]}, {"id": "1812.03868", "submitter": "Naveen Sundar Govindarajulu", "authors": "Naveen Sundar Govindarajulu, Selmer Bringsjord and Rikhiya Ghosh", "title": "Toward the Engineering of Virtuous Machines", "comments": "To appear in the proceedings of AAAI/ACM Conference on AI, Ethics,\n  and Society (AIES) 2019 (http://www.aies-conference.com/accepted-papers/).\n  This subsumes and completes the earlier partial formalization described in\n  arXiv:1805.07797", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While various traditions under the 'virtue ethics' umbrella have been studied\nextensively and advocated by ethicists, it has not been clear that there exists\na version of virtue ethics rigorous enough to be a target for machine ethics\n(which we take to include the engineering of an ethical sensibility in a\nmachine or robot itself, not only the study of ethics in the humans who might\ncreate artificial agents). We begin to address this by presenting an embryonic\nformalization of a key part of any virtue-ethics theory: namely, the learning\nof virtue by a focus on exemplars of moral virtue. Our work is based in part on\na computational formal logic previously used to formally model other ethical\ntheories and principles therein, and to implement these models in artificial\nagents.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 16:30:20 GMT"}, {"version": "v2", "created": "Sun, 30 Dec 2018 05:37:19 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Govindarajulu", "Naveen Sundar", ""], ["Bringsjord", "Selmer", ""], ["Ghosh", "Rikhiya", ""]]}, {"id": "1812.03955", "submitter": "Norman Di Palo", "authors": "Norman Di Palo, Harri Valpola", "title": "Improving Model-Based Control and Active Exploration with Reconstruction\n  Uncertainty Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model based predictions of future trajectories of a dynamical system often\nsuffer from inaccuracies, forcing model based control algorithms to re-plan\noften, thus being computationally expensive, suboptimal and not reliable. In\nthis work, we propose a model agnostic method for estimating the uncertainty of\na model?s predictions based on reconstruction error, using it in control and\nexploration. As our experiments show, this uncertainty estimation can be used\nto improve control performance on a wide variety of environments by choosing\npredictions of which the model is confident. It can also be used for active\nlearning to explore more efficiently the environment by planning for\ntrajectories with high uncertainty, allowing faster model learning.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 18:09:10 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Di Palo", "Norman", ""], ["Valpola", "Harri", ""]]}, {"id": "1812.03980", "submitter": "Nicholas Mattei", "authors": "Francesca Rossi and Nicholas Mattei", "title": "Building Ethically Bounded AI", "comments": "Published at AAAI Blue Sky Track, winner of Blue Sky Award", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The more AI agents are deployed in scenarios with possibly unexpected\nsituations, the more they need to be flexible, adaptive, and creative in\nachieving the goal we have given them. Thus, a certain level of freedom to\nchoose the best path to the goal is inherent in making AI robust and flexible\nenough. At the same time, however, the pervasive deployment of AI in our life,\nwhether AI is autonomous or collaborating with humans, raises several ethical\nchallenges. AI agents should be aware and follow appropriate ethical principles\nand should thus exhibit properties such as fairness or other virtues. These\nethical principles should define the boundaries of AI's freedom and creativity.\nHowever, it is still a challenge to understand how to specify and reason with\nethical boundaries in AI agents and how to combine them appropriately with\nsubjective preferences and goal specifications. Some initial attempts employ\neither a data-driven example-based approach for both, or a symbolic rule-based\napproach for both. We envision a modular approach where any AI technique can be\nused for any of these essential ingredients in decision making or decision\nsupport systems, paired with a contextual approach to define their combination\nand relative weight. In a world where neither humans nor AI systems work in\nisolation, but are tightly interconnected, e.g., the Internet of Things, we\nalso envision a compositional approach to building ethically bounded AI, where\nthe ethical properties of each component can be fruitfully exploited to derive\nthose of the overall system. In this paper we define and motivate the notion of\nethically-bounded AI, we describe two concrete examples, and we outline some\noutstanding challenges.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 18:58:05 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Rossi", "Francesca", ""], ["Mattei", "Nicholas", ""]]}, {"id": "1812.04056", "submitter": "Georgios Georgiadis", "authors": "Georgios Georgiadis", "title": "Accelerating Convolutional Neural Networks via Activation Map\n  Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deep learning revolution brought us an extensive array of neural network\narchitectures that achieve state-of-the-art performance in a wide variety of\nComputer Vision tasks including among others, classification, detection and\nsegmentation. In parallel, we have also been observing an unprecedented demand\nin computational and memory requirements, rendering the efficient use of neural\nnetworks in low-powered devices virtually unattainable. Towards this end, we\npropose a three-stage compression and acceleration pipeline that sparsifies,\nquantizes and entropy encodes activation maps of Convolutional Neural Networks.\nSparsification increases the representational power of activation maps leading\nto both acceleration of inference and higher model accuracy. Inception-V3 and\nMobileNet-V1 can be accelerated by as much as $1.6\\times$ with an increase in\naccuracy of $0.38\\%$ and $0.54\\%$ on the ImageNet and CIFAR-10 datasets\nrespectively. Quantizing and entropy coding the sparser activation maps lead to\nhigher compression over the baseline, reducing the memory cost of the network\nexecution. Inception-V3 and MobileNet-V1 activation maps, quantized to $16$\nbits, are compressed by as much as $6\\times$ with an increase in accuracy of\n$0.36\\%$ and $0.55\\%$ respectively.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 19:50:44 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 17:42:08 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Georgiadis", "Georgios", ""]]}, {"id": "1812.04082", "submitter": "John Mern", "authors": "John Mern, Kyle Julian, Rachael E. Tompa, Mykel J. Kochenderfer", "title": "Visual Depth Mapping from Monocular Images using Recurrent Convolutional\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A reliable sense-and-avoid system is critical to enabling safe autonomous\noperation of unmanned aircraft. Existing sense-and-avoid methods often require\nspecialized sensors that are too large or power intensive for use on small\nunmanned vehicles. This paper presents a method to estimate object distances\nbased on visual image sequences, allowing for the use of low-cost, on-board\nmonocular cameras as simple collision avoidance sensors. We present a deep\nrecurrent convolutional neural network and training method to generate depth\nmaps from video sequences. Our network is trained using simulated camera and\ndepth data generated with Microsoft's AirSim simulator. Empirically, we show\nthat our model achieves superior performance compared to models generated using\nprior methods.We further demonstrate that the method can be used for\nsense-and-avoid of obstacles in simulation.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 20:53:49 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Mern", "John", ""], ["Julian", "Kyle", ""], ["Tompa", "Rachael E.", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1812.04128", "submitter": "Xingyu Zhao", "authors": "Xingyu Zhao, Valentin Robu, David Flynn, Fateme Dinmohammadi, Michael\n  Fisher, Matt Webster", "title": "Probabilistic Model Checking of Robots Deployed in Extreme Environments", "comments": "Version accepted at the 33rd AAAI Conference on Artificial\n  Intelligence, Honolulu, Hawaii, 2019", "journal-ref": null, "doi": "10.1609/aaai.v33i01.33018066", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots are increasingly used to carry out critical missions in extreme\nenvironments that are hazardous for humans. This requires a high degree of\noperational autonomy under uncertain conditions, and poses new challenges for\nassuring the robot's safety and reliability. In this paper, we develop a\nframework for probabilistic model checking on a layered Markov model to verify\nthe safety and reliability requirements of such robots, both at pre-mission\nstage and during runtime. Two novel estimators based on conservative Bayesian\ninference and imprecise probability model with sets of priors are introduced to\nlearn the unknown transition parameters from operational data. We demonstrate\nour approach using data from a real-world deployment of unmanned underwater\nvehicles in extreme environments.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 22:11:18 GMT"}, {"version": "v2", "created": "Sun, 30 Dec 2018 14:21:05 GMT"}, {"version": "v3", "created": "Fri, 15 Feb 2019 17:36:56 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Zhao", "Xingyu", ""], ["Robu", "Valentin", ""], ["Flynn", "David", ""], ["Dinmohammadi", "Fateme", ""], ["Fisher", "Michael", ""], ["Webster", "Matt", ""]]}, {"id": "1812.04179", "submitter": "Fengchao Xiong", "authors": "Fengchao Xiong, Jun Zhou and Yuntao Qian", "title": "Material Based Object Tracking in Hyperspectral Videos: Benchmark and\n  Algorithms", "comments": "Update results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traditional color images only depict color intensities in red, green and blue\nchannels, often making object trackers fail in challenging scenarios, e.g.,\nbackground clutter and rapid changes of target appearance. Alternatively,\nmaterial information of targets contained in a large amount of bands of\nhyperspectral images (HSI) is more robust to these difficult conditions. In\nthis paper, we conduct a comprehensive study on how material information can be\nutilized to boost object tracking from three aspects: benchmark dataset,\nmaterial feature representation and material based tracking. In terms of\nbenchmark, we construct a dataset of fully-annotated videos, which contain both\nhyperspectral and color sequences of the same scene. Material information is\nrepresented by spectral-spatial histogram of multidimensional gradient, which\ndescribes the 3D local spectral-spatial structure in an HSI, and fractional\nabundances of constituted material components which encode the underlying\nmaterial distribution. These two types of features are embedded into\ncorrelation filters, yielding material based tracking. Experimental results on\nthe collected benchmark dataset show the potentials and advantages of material\nbased object tracking.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 01:35:15 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2018 12:17:17 GMT"}, {"version": "v3", "created": "Sun, 23 Dec 2018 17:03:21 GMT"}, {"version": "v4", "created": "Fri, 5 Apr 2019 00:45:07 GMT"}, {"version": "v5", "created": "Wed, 10 Jul 2019 14:34:15 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Xiong", "Fengchao", ""], ["Zhou", "Jun", ""], ["Qian", "Yuntao", ""]]}, {"id": "1812.04218", "submitter": "Jiaming Song", "authors": "Jiaming Song, Pratyusha Kalluri, Aditya Grover, Shengjia Zhao, Stefano\n  Ermon", "title": "Learning Controllable Fair Representations", "comments": "AISTATS 2019, fixed a typo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning data representations that are transferable and are fair with respect\nto certain protected attributes is crucial to reducing unfair decisions while\npreserving the utility of the data. We propose an information-theoretically\nmotivated objective for learning maximally expressive representations subject\nto fairness constraints. We demonstrate that a range of existing approaches\noptimize approximations to the Lagrangian dual of our objective. In contrast to\nthese existing approaches, our objective allows the user to control the\nfairness of the representations by specifying limits on unfairness. Exploiting\nduality, we introduce a method that optimizes the model parameters as well as\nthe expressiveness-fairness trade-off. Empirical evidence suggests that our\nproposed method can balance the trade-off between multiple notions of fairness\nand achieves higher expressiveness at a lower computational cost.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 04:44:48 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 09:30:21 GMT"}, {"version": "v3", "created": "Sat, 14 Mar 2020 10:12:56 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Song", "Jiaming", ""], ["Kalluri", "Pratyusha", ""], ["Grover", "Aditya", ""], ["Zhao", "Shengjia", ""], ["Ermon", "Stefano", ""]]}, {"id": "1812.04238", "submitter": "Siddhant Srivastava", "authors": "Siddhant Srivastava, Anupam Shukla, Ritu Tiwari", "title": "Machine Translation : From Statistical to modern Deep-learning practices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine translation (MT) is an area of study in Natural Language processing\nwhich deals with the automatic translation of human language, from one language\nto another by the computer. Having a rich research history spanning nearly\nthree decades, Machine translation is one of the most sought after area of\nresearch in the linguistics and computational community. In this paper, we\ninvestigate the models based on deep learning that have achieved substantial\nprogress in recent years and becoming the prominent method in MT. We shall\ndiscuss the two main deep-learning based Machine Translation methods, one at\ncomponent or domain level which leverages deep learning models to enhance the\nefficacy of Statistical Machine Translation (SMT) and end-to-end deep learning\nmodels in MT which uses neural networks to find correspondence between the\nsource and target languages using the encoder-decoder architecture. We conclude\nthis paper by providing a time line of the major research problems solved by\nthe researchers and also provide a comprehensive overview of present areas of\nresearch in Neural Machine Translation.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 07:04:44 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Srivastava", "Siddhant", ""], ["Shukla", "Anupam", ""], ["Tiwari", "Ritu", ""]]}, {"id": "1812.04562", "submitter": "Alexander Lavin", "authors": "Alexander Lavin", "title": "Doubly Bayesian Optimization", "comments": "conflict of interest", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic programming systems enable users to encode model structure and\nnaturally reason about uncertainties, which can be leveraged towards improved\nBayesian optimization (BO) methods. Here we present a probabilistic program\nembedding of BO that is capable of addressing main issues such as problematic\ndomains (noisy, non-smooth, high-dimensional) and the neglected\ninner-optimization. Not only can we utilize programmable structure to\nincorporate domain knowledge to aid optimization, but dealing with\nuncertainties and implementing advanced BO techniques become trivial, crucial\nfor use in practice (particularly for non-experts). We demonstrate the efficacy\nof the approach on optimization benchmarks and a real-world drug development\nscenario.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 17:38:52 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 20:31:47 GMT"}, {"version": "v3", "created": "Fri, 1 Feb 2019 20:07:08 GMT"}, {"version": "v4", "created": "Tue, 5 Feb 2019 01:39:37 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Lavin", "Alexander", ""]]}, {"id": "1812.04597", "submitter": "Adarsh Subbaswamy", "authors": "Adarsh Subbaswamy, Peter Schulam, Suchi Saria", "title": "Preventing Failures Due to Dataset Shift: Learning Predictive Models\n  That Transport", "comments": "In Proceedings of the 22nd International Conference on Artificial\n  Intelligence and Statistics (AISTATS), 2019. Previously presented at the\n  NeurIPS 2018 Causal Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical supervised learning produces unreliable models when training and\ntarget distributions differ, with most existing solutions requiring samples\nfrom the target domain. We propose a proactive approach which learns a\nrelationship in the training domain that will generalize to the target domain\nby incorporating prior knowledge of aspects of the data generating process that\nare expected to differ as expressed in a causal selection diagram.\nSpecifically, we remove variables generated by unstable mechanisms from the\njoint factorization to yield the Surgery Estimator---an interventional\ndistribution that is invariant to the differences across environments. We prove\nthat the surgery estimator finds stable relationships in strictly more\nscenarios than previous approaches which only consider conditional\nrelationships, and demonstrate this in simulated experiments. We also evaluate\non real world data for which the true causal diagram is unknown, performing\ncompetitively against entirely data-driven approaches.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 18:32:52 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 18:11:05 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Subbaswamy", "Adarsh", ""], ["Schulam", "Peter", ""], ["Saria", "Suchi", ""]]}, {"id": "1812.04599", "submitter": "Konrad Zolna", "authors": "Konrad Zolna and Michal Zajac and Negar Rostamzadeh and Pedro O.\n  Pinheiro", "title": "Adversarial Framing for Image and Video Classification", "comments": "This is an extended version of the paper published at 33rd AAAI\n  Conference on Artificial Intelligence (see\n  https://doi.org/10.1609/aaai.v33i01.330110077 )", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are prone to adversarial attacks. In general, such attacks\ndeteriorate the quality of the input by either slightly modifying most of its\npixels, or by occluding it with a patch. In this paper, we propose a method\nthat keeps the image unchanged and only adds an adversarial framing on the\nborder of the image. We show empirically that our method is able to\nsuccessfully attack state-of-the-art methods on both image and video\nclassification problems. Notably, the proposed method results in a universal\nattack which is very fast at test time. Source code can be found at\nhttps://github.com/zajaczajac/adv_framing .\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 18:39:29 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 18:18:56 GMT"}, {"version": "v3", "created": "Thu, 17 Oct 2019 14:03:07 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Zolna", "Konrad", ""], ["Zajac", "Michal", ""], ["Rostamzadeh", "Negar", ""], ["Pinheiro", "Pedro O.", ""]]}, {"id": "1812.04604", "submitter": "David Chan", "authors": "Biye Jiang, David M. Chan, Tianhao Zhang, John F. Canny", "title": "Diagnostic Visualization for Deep Neural Networks Using Stochastic\n  Gradient Langevin Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The internal states of most deep neural networks are difficult to interpret,\nwhich makes diagnosis and debugging during training challenging. Activation\nmaximization methods are widely used, but lead to multiple optima and are hard\nto interpret (appear noise-like) for complex neurons. Image-based methods use\nmaximally-activating image regions which are easier to interpret, but do not\nprovide pixel-level insight into why the neuron responds to them. In this work\nwe introduce an MCMC method: Langevin Dynamics Activation Maximization (LDAM),\nwhich is designed for diagnostic visualization. LDAM provides two affordances\nin combination: the ability to explore the set of maximally activating\npre-images, and the ability to trade-off interpretability and pixel-level\naccuracy using a GAN-style discriminator as a regularizer. We present case\nstudies on MNIST, CIFAR and ImageNet datasets exploring these trade-offs.\nFinally we show that diagnostic visualization using LDAM leads to a novel\ninsight into the parameter averaging method for deep net training.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 18:43:52 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Jiang", "Biye", ""], ["Chan", "David M.", ""], ["Zhang", "Tianhao", ""], ["Canny", "John F.", ""]]}, {"id": "1812.04608", "submitter": "Shane Mueller", "authors": "Robert R. Hoffman, Shane T. Mueller, Gary Klein, Jordan Litman", "title": "Metrics for Explainable AI: Challenges and Prospects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The question addressed in this paper is: If we present to a user an AI system\nthat explains how it works, how do we know whether the explanation works and\nthe user has achieved a pragmatic understanding of the AI? In other words, how\ndo we know that an explanainable AI system (XAI) is any good? Our focus is on\nthe key concepts of measurement. We discuss specific methods for evaluating:\n(1) the goodness of explanations, (2) whether users are satisfied by\nexplanations, (3) how well users understand the AI systems, (4) how curiosity\nmotivates the search for explanations, (5) whether the user's trust and\nreliance on the AI are appropriate, and finally, (6) how the human-XAI work\nsystem performs. The recommendations we present derive from our integration of\nextensive research literatures and our own psychometric evaluations.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 18:50:02 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 09:31:08 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Hoffman", "Robert R.", ""], ["Mueller", "Shane T.", ""], ["Klein", "Gary", ""], ["Litman", "Jordan", ""]]}, {"id": "1812.04741", "submitter": "Marija Slavkovik", "authors": "Beishui Liao, Marija Slavkovik, Leendert van der Torre", "title": "Building Jiminy Cricket: An Architecture for Moral Agreements Among\n  Stakeholders", "comments": "Presented at the AAAI/ACM Artificial Intelligence, Ethics and Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An autonomous system is constructed by a manufacturer, operates in a society\nsubject to norms and laws, and is interacting with end-users. We address the\nchallenge of how the moral values and views of all stakeholders can be\nintegrated and reflected in the moral behaviour of the autonomous system. We\npropose an artificial moral agent architecture that uses techniques from\nnormative systems and formal argumentation to reach moral agreements among\nstakeholders. We show how our architecture can be used not only for ethical\npractical reasoning and collaborative decision-making, but also for the\nexplanation of such moral behavior.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 23:16:16 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 15:23:15 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Liao", "Beishui", ""], ["Slavkovik", "Marija", ""], ["van der Torre", "Leendert", ""]]}, {"id": "1812.04754", "submitter": "Guy Gur-Ari", "authors": "Guy Gur-Ari, Daniel A. Roberts, Ethan Dyer", "title": "Gradient Descent Happens in a Tiny Subspace", "comments": "9 pages + appendices, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that in a variety of large-scale deep learning scenarios the gradient\ndynamically converges to a very small subspace after a short period of\ntraining. The subspace is spanned by a few top eigenvectors of the Hessian\n(equal to the number of classes in the dataset), and is mostly preserved over\nlong periods of training. A simple argument then suggests that gradient descent\nmay happen mostly in this subspace. We give an example of this effect in a\nsolvable model of classification, and we comment on possible implications for\noptimization and learning.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 00:36:17 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Gur-Ari", "Guy", ""], ["Roberts", "Daniel A.", ""], ["Dyer", "Ethan", ""]]}, {"id": "1812.04769", "submitter": "Emanuel Diamant", "authors": "Emanuel Diamant", "title": "Designing Artificial Cognitive Architectures: Brain Inspired or\n  Biologically Inspired?", "comments": null, "journal-ref": null, "doi": "10.1016/j.procs.2018.11.023", "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Neural Networks (ANNs) were devised as a tool for Artificial\nIntelligence design implementations. However, it was soon became obvious that\nthey are unable to fulfill their duties. The fully autonomous way of ANNs\nworking, precluded from any human intervention or supervision, deprived of any\ntheoretical underpinning, leads to a strange state of affairs, when ANN\ndesigners cannot explain why and how they achieve their amazing and remarkable\nresults. Therefore, contemporary Artificial Intelligence R&D looks more like a\nModern Alchemy enterprise rather than a respected scientific or technological\nundertaking. On the other hand, modern biological science posits that\nintelligence can be distinguished not only in human brains. Intelligence today\nis considered as a fundamental property of each and every living being.\nTherefore, lower simplified forms of natural intelligence are more suitable for\ninvestigation and further replication in artificial cognitive architectures.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 01:40:51 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Diamant", "Emanuel", ""]]}, {"id": "1812.04814", "submitter": "Yi Zeng", "authors": "Yi Zeng, Enmeng Lu, Cunqing Huangfu", "title": "Linking Artificial Intelligence Principles", "comments": "AAAI Workshop on Artificial Intelligence Safety (AAAI-Safe AI 2019),\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence principles define social and ethical considerations\nto develop future AI. They come from research institutes, government\norganizations and industries. All versions of AI principles are with different\nconsiderations covering different perspectives and making different emphasis.\nNone of them can be considered as complete and can cover the rest AI principle\nproposals. Here we introduce LAIP, an effort and platform for linking and\nanalyzing different Artificial Intelligence Principles. We want to explicitly\nestablish the common topics and links among AI Principles proposed by different\norganizations and investigate on their uniqueness. Based on these efforts, for\nthe long-term future of AI, instead of directly adopting any of the AI\nprinciples, we argue for the necessity of incorporating various AI Principles\ninto a comprehensive framework and focusing on how they can interact and\ncomplete each other.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 05:43:57 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Zeng", "Yi", ""], ["Lu", "Enmeng", ""], ["Huangfu", "Cunqing", ""]]}, {"id": "1812.04840", "submitter": "Amir Aly", "authors": "Amir Aly and Tadahiro Taniguchi", "title": "Towards Understanding Language through Perception in Situated\n  Human-Robot Interaction: From Word Grounding to Grammar Induction", "comments": "Proceedings of the International Conference on Social Cognition in\n  Humans and Robots (socSMCs), Germany, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots are widely collaborating with human users in diferent tasks that\nrequire high-level cognitive functions to make them able to discover the\nsurrounding environment. A difcult challenge that we briefy highlight in this\nshort paper is inferring the latent grammatical structure of language, which\nincludes grounding parts of speech (e.g., verbs, nouns, adjectives, and\nprepositions) through visual perception, and induction of Combinatory\nCategorial Grammar (CCG) for phrases. This paves the way towards grounding\nphrases so as to make a robot able to understand human instructions\nappropriately during interaction.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 08:06:30 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 14:58:27 GMT"}, {"version": "v3", "created": "Fri, 13 Mar 2020 08:22:51 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Aly", "Amir", ""], ["Taniguchi", "Tadahiro", ""]]}, {"id": "1812.04907", "submitter": "Nicholas Guttenberg", "authors": "Nicholas Guttenberg, Nathaniel Virgo, Alexandra Penn", "title": "On the potential for open-endedness in neural networks", "comments": "17 pages, 6 figures; Final author version accepted for publication in\n  Artificial Life", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO cs.AI q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural evolution gives the impression of leading to an open-ended process of\nincreasing diversity and complexity. If our goal is to produce such\nopen-endedness artificially, this suggests an approach driven by evolutionary\nmetaphor. On the other hand, techniques from machine learning and artificial\nintelligence are often considered too narrow to provide the sort of exploratory\ndynamics associated with evolution. In this paper, we hope to bridge that gap\nby reviewing common barriers to open-endedness in the evolution-inspired\napproach and how they are dealt with in the evolutionary case - collapse of\ndiversity, saturation of complexity, and failure to form new kinds of\nindividuality. We then show how these problems map onto similar issues in the\nmachine learning approach, and discuss how the same insights and solutions\nwhich alleviated those barriers in evolutionary approaches can be ported over.\nAt the same time, the form these issues take in the machine learning\nformulation suggests new ways to analyze and resolve barriers to\nopen-endedness. Ultimately, we hope to inspire researchers to be able to\ninterchangeably use evolutionary and gradient-descent-based machine learning\nmethods to approach the design and creation of open-ended systems.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 11:39:38 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Guttenberg", "Nicholas", ""], ["Virgo", "Nathaniel", ""], ["Penn", "Alexandra", ""]]}, {"id": "1812.05070", "submitter": "Ivan Amaya", "authors": "I. Amaya, J. C. Ortiz-Bayliss, A. Rosales-P\\'erez, A. E.\n  Guti\\'errez-Rodr\\'iguez, S. E. Conant-Pablos, H. Terashima-Mar\\'in, C. A.\n  Coello Coello", "title": "Enhancing Selection Hyper-heuristics via Feature Transformations", "comments": "Accepted version of the article published in the IEEE Computational\n  Intelligence Magazine. DOI: 10.1109/MCI.2018.2807018 \\c{opyright}2018IEEE", "journal-ref": "IEEE Comput Intell Mag. 2018, 13(2)", "doi": "10.1109/MCI.2018.2807018", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyper-heuristics are a novel tool. They deal with complex optimization\nproblems where standalone solvers exhibit varied performance. Among such a tool\nreside selection hyper-heuristics. By combining the strengths of each solver,\nthis kind of hyper-heuristic offers a more robust tool. However, their\neffectiveness is highly dependent on the 'features' used to link them with the\nproblem that is being solved. Aiming at enhancing selection hyper-heuristics,\nin this paper we propose two types of transformation: explicit and implicit.\nThe first one directly changes the distribution of critical points within the\nfeature domain while using a Euclidean distance to measure proximity. The\nsecond one operates indirectly by preserving the distribution of critical\npoints but changing the distance metric through a kernel function. We focus on\nanalyzing the effect of each kind of transformation, and of their combinations.\nWe test our ideas in the domain of constraint satisfaction problems because of\ntheir popularity and many practical applications. In this work, we compare the\nperformance of our proposals against those of previously published data.\nFurthermore, we expand on previous research by increasing the number of\nanalyzed features. We found that, by incorporating transformations into the\nmodel of selection hyper-heuristics, overall performance can be improved,\nyielding more stable results. However, combining implicit and explicit\ntransformations was not as fruitful. Additionally, we ran some confirmatory\ntests on the domain of knapsack problems. Again, we observed improved\nstability, leading to the generation of hyper-heuristics whose profit had a\nstandard deviation between 20% and 30% smaller.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 18:14:06 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Amaya", "I.", ""], ["Ortiz-Bayliss", "J. C.", ""], ["Rosales-P\u00e9rez", "A.", ""], ["Guti\u00e9rrez-Rodr\u00edguez", "A. E.", ""], ["Conant-Pablos", "S. E.", ""], ["Terashima-Mar\u00edn", "H.", ""], ["Coello", "C. A. Coello", ""]]}, {"id": "1812.05212", "submitter": "Xin Wang", "authors": "Marcel Nassar, Xin Wang, Evren Tumer", "title": "Conditional Graph Neural Processes: A Functional Autoencoder Approach", "comments": "3 pages, 1 figure, 1 table, published in the Third Workshop on\n  Bayesian Deep Learning (NeurIPS 2018), Montr\\'eal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel encoder-decoder architecture to embed functional\nprocesses into latent vector spaces. This embedding can then be decoded to\nsample the encoded functions over any arbitrary domain. This autoencoder\ngeneralizes the recently introduced Conditional Neural Process (CNP) model of\nrandom processes. Our architecture employs the latest advances in graph neural\nnetworks to process irregularly sampled functions. Thus, we refer to our model\nas Conditional Graph Neural Process (CGNP). Graph neural networks can\neffectively exploit `local' structures of the metric spaces over which the\nfunctions/processes are defined. The contributions of this paper are twofold:\n(i) a novel graph-based encoder-decoder architecture for functional and process\nembeddings, and (ii) a demonstration of the importance of using the structure\nof metric spaces for this type of representations.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 00:52:56 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Nassar", "Marcel", ""], ["Wang", "Xin", ""], ["Tumer", "Evren", ""]]}, {"id": "1812.05224", "submitter": "Tong Wang", "authors": "Yunyi Li and Tong Wang", "title": "Next Hit Predictor - Self-exciting Risk Modeling for Predicting Next\n  Locations of Serial Crimes", "comments": null, "journal-ref": "AI for Social Good Workshop NIPS2018", "doi": null, "report-no": null, "categories": "stat.AP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is to predict the location of the next crime in a crime series,\nbased on the identified previous offenses in the series. We build a predictive\nmodel called Next Hit Predictor (NHP) that finds the most likely location of\nthe next serial crime via a carefully designed risk model. The risk model\nfollows the paradigm of a self-exciting point process which consists of a\nbackground crime risk and triggered risks stimulated by previous offenses in\nthe series. Thus, NHP creates a risk map for a crime series at hand. To train\nthe risk model, we formulate a convex learning objective that considers\npairwise rankings of locations and use stochastic gradient descent to learn the\noptimal parameters. Next Hit Predictor incorporates both spatial-temporal\nfeatures and geographical characteristics of prior crime locations in the\nseries. Next Hit Predictor has demonstrated promising results on decades' worth\nof serial crime data collected by the Crime Analysis Unit of the Cambridge\nPolice Department in Massachusetts, USA.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 01:57:26 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Li", "Yunyi", ""], ["Wang", "Tong", ""]]}, {"id": "1812.05233", "submitter": "Chi Zhang", "authors": "Chi Zhang, Yixin Zhu, Song-Chun Zhu", "title": "MetaStyle: Three-Way Trade-Off Among Speed, Flexibility, and Quality in\n  Neural Style Transfer", "comments": "AAAI 2019 spotlight. Supplementary:\n  http://wellyzhang.github.io/attach/aaai19zhang_supp.pdf GitHub:\n  https://github.com/WellyZhang/MetaStyle Project:\n  http://wellyzhang.github.io/project/metastyle.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An unprecedented booming has been witnessed in the research area of artistic\nstyle transfer ever since Gatys et al. introduced the neural method. One of the\nremaining challenges is to balance a trade-off among three critical\naspects---speed, flexibility, and quality: (i) the vanilla optimization-based\nalgorithm produces impressive results for arbitrary styles, but is\nunsatisfyingly slow due to its iterative nature, (ii) the fast approximation\nmethods based on feed-forward neural networks generate satisfactory artistic\neffects but bound to only a limited number of styles, and (iii)\nfeature-matching methods like AdaIN achieve arbitrary style transfer in a\nreal-time manner but at a cost of the compromised quality. We find it\nconsiderably difficult to balance the trade-off well merely using a single\nfeed-forward step and ask, instead, whether there exists an algorithm that\ncould adapt quickly to any style, while the adapted model maintains high\nefficiency and good image quality. Motivated by this idea, we propose a novel\nmethod, coined MetaStyle, which formulates the neural style transfer as a\nbilevel optimization problem and combines learning with only a few\npost-processing update steps to adapt to a fast approximation model with\nsatisfying artistic effects, comparable to the optimization-based methods for\nan arbitrary style. The qualitative and quantitative analysis in the\nexperiments demonstrates that the proposed approach achieves high-quality\narbitrary artistic style transfer effectively, with a good trade-off among\nspeed, flexibility, and quality.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 02:25:10 GMT"}, {"version": "v2", "created": "Sat, 22 Dec 2018 12:47:31 GMT"}, {"version": "v3", "created": "Thu, 7 Mar 2019 03:44:16 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Zhang", "Chi", ""], ["Zhu", "Yixin", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1812.05237", "submitter": "Ehsan Vahedi", "authors": "Mahdi Hajiaghayi, Ehsan Vahedi", "title": "Code Failure Prediction and Pattern Extraction using LSTM Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we use a well-known Deep Learning technique called Long Short\nTerm Memory (LSTM) recurrent neural networks to find sessions that are prone to\ncode failure in applications that rely on telemetry data for system health\nmonitoring. We also use LSTM networks to extract telemetry patterns that lead\nto a specific code failure. For code failure prediction, we treat the telemetry\nevents, sequence of telemetry events and the outcome of each sequence as words,\nsentence and sentiment in the context of sentiment analysis, respectively. Our\nproposed method is able to process a large set of data and can automatically\nhandle edge cases in code failure prediction. We take advantage of Bayesian\noptimization technique to find the optimal hyper parameters as well as the type\nof LSTM cells that leads to the best prediction performance. We then introduce\nthe Contributors and Blockers concepts. In this paper, contributors are the set\nof events that cause a code failure, while blockers are the set of events that\neach of them individually prevents a code failure from happening, even in\npresence of one or multiple contributor(s). Once the proposed LSTM model is\ntrained, we use a greedy approach to find the contributors and blockers. To\ndevelop and test our proposed method, we use synthetic (simulated) data in the\nfirst step. The synthetic data is generated using a number of rules for code\nfailures, as well as a number of rules for preventing a code failure from\nhappening. The trained LSTM model shows over 99% accuracy for detecting code\nfailures in the synthetic data. The results from the proposed method outperform\nthe classical learning models such as Decision Tree and Random Forest. Using\nthe proposed greedy method, we are able to find the contributors and blockers\nin the synthetic data in more than 90% of the cases, with a performance better\nthan sequential rule and pattern mining algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 02:46:44 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Hajiaghayi", "Mahdi", ""], ["Vahedi", "Ehsan", ""]]}, {"id": "1812.05256", "submitter": "Hyung-Jin Yoon", "authors": "Hyung-Jin Yoon, Huaiyu Chen, Kehan Long, Heling Zhang, Aditya\n  Gahlawat, Donghwan Lee, and Naira Hovakimyan", "title": "Learning to Communicate: A Machine Learning Framework for Heterogeneous\n  Multi-Agent Robotic Systems", "comments": "AIAA SciTech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a machine learning framework for multi-agent systems to learn both\nthe optimal policy for maximizing the rewards and the encoding of the high\ndimensional visual observation. The encoding is useful for sharing local visual\nobservations with other agents under communication resource constraints. The\nactor-encoder encodes the raw images and chooses an action based on local\nobservations and messages sent by the other agents. The machine learning agent\ngenerates not only an actuator command to the physical device, but also a\ncommunication message to the other agents. We formulate a reinforcement\nlearning problem, which extends the action space to consider the communication\naction as well. The feasibility of the reinforcement learning framework is\ndemonstrated using a 3D simulation environment with two collaborating agents.\nThe environment provides realistic visual observations to be used and shared\nbetween the two agents.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 04:26:01 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Yoon", "Hyung-Jin", ""], ["Chen", "Huaiyu", ""], ["Long", "Kehan", ""], ["Zhang", "Heling", ""], ["Gahlawat", "Aditya", ""], ["Lee", "Donghwan", ""], ["Hovakimyan", "Naira", ""]]}, {"id": "1812.05285", "submitter": "Minghao Guo", "authors": "Minghao Guo, Zhao Zhong, Wei Wu, Dahua Lin, and Junjie Yan", "title": "IRLAS: Inverse Reinforcement Learning for Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an inverse reinforcement learning method for\narchitecture search (IRLAS), which trains an agent to learn to search network\nstructures that are topologically inspired by human-designed network. Most\nexisting architecture search approaches totally neglect the topological\ncharacteristics of architectures, which results in complicated architecture\nwith a high inference latency. Motivated by the fact that human-designed\nnetworks are elegant in topology with a fast inference speed, we propose a\nmirror stimuli function inspired by biological cognition theory to extract the\nabstract topological knowledge of an expert human-design network (ResNeXt). To\navoid raising a too strong prior over the search space, we introduce inverse\nreinforcement learning to train the mirror stimuli function and exploit it as a\nheuristic guidance for architecture search, easily generalized to different\narchitecture search algorithms. On CIFAR-10, the best architecture searched by\nour proposed IRLAS achieves 2.60% error rate. For ImageNet mobile setting, our\nmodel achieves a state-of-the-art top-1 accuracy 75.28%, while being 2~4x\nfaster than most auto-generated architectures. A fast version of this model\nachieves 10% faster than MobileNetV2, while maintaining a higher accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 06:53:36 GMT"}, {"version": "v2", "created": "Fri, 14 Dec 2018 05:27:07 GMT"}, {"version": "v3", "created": "Mon, 11 Mar 2019 05:26:56 GMT"}, {"version": "v4", "created": "Mon, 19 Aug 2019 06:31:43 GMT"}, {"version": "v5", "created": "Wed, 6 Nov 2019 02:30:08 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Guo", "Minghao", ""], ["Zhong", "Zhao", ""], ["Wu", "Wei", ""], ["Lin", "Dahua", ""], ["Yan", "Junjie", ""]]}, {"id": "1812.05339", "submitter": "Lei Ma", "authors": "Xiaoning Du, Xiaofei Xie, Yi Li, Lei Ma, Jianjun Zhao, Yang Liu", "title": "DeepCruiser: Automated Guided Testing for Stateful Deep Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) defines a data-driven programming paradigm that\nautomatically composes the system decision logic from the training data. In\ncompany with the data explosion and hardware acceleration during the past\ndecade, DL achieves tremendous success in many cutting-edge applications.\nHowever, even the state-of-the-art DL systems still suffer from quality and\nreliability issues. It was only until recently that some preliminary progress\nwas made in testing feed-forward DL systems. In contrast to feed-forward DL\nsystems, recurrent neural networks (RNN) follow a very different architectural\ndesign, implementing temporal behaviors and memory with loops and internal\nstates. Such stateful nature of RNN contributes to its success in handling\nsequential inputs such as audio, natural languages and video processing, but\nalso poses new challenges for quality assurance.\n  In this paper, we initiate the very first step towards testing RNN-based\nstateful DL systems. We model RNN as an abstract state transition system, based\non which we define a set of test coverage criteria specialized for stateful DL\nsystems. Moreover, we propose an automated testing framework, DeepCruiser,\nwhich systematically generates tests in large scale to uncover defects of\nstateful DL systems with coverage guidance. Our in-depth evaluation on a\nstate-of-the-art speech-to-text DL system demonstrates the effectiveness of our\ntechnique in improving quality and reliability of stateful DL systems.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 09:49:58 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Du", "Xiaoning", ""], ["Xie", "Xiaofei", ""], ["Li", "Yi", ""], ["Ma", "Lei", ""], ["Zhao", "Jianjun", ""], ["Liu", "Yang", ""]]}, {"id": "1812.05362", "submitter": "Beishui Liao", "authors": "Beishui Liao, Michael Anderson and Susan Leigh Anderson", "title": "Representation, Justification and Explanation in a Value Driven Agent:\n  An Argumentation-Based Approach", "comments": "24 pages, 6 figures, submitted to JASSS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ethical and explainable artificial intelligence is an interdisciplinary\nresearch area involving computer science, philosophy, logic, the social\nsciences, etc. For an ethical autonomous system, the ability to justify and\nexplain its decision making is a crucial aspect of transparency and\ntrustworthiness. This paper takes a Value Driven Agent (VDA) as an example,\nexplicitly representing implicit knowledge of a machine learning-based\nautonomous agent and using this formalism to justify and explain the decisions\nof the agent. For this purpose, we introduce a novel formalism to describe the\nintrinsic knowledge and solutions of a VDA in each situation. Based on this\nformalism, we formulate an approach to justify and explain the decision-making\nprocess of a VDA, in terms of a typical argumentation formalism,\nAssumption-based Argumentation (ABA). As a result, a VDA in a given situation\nis mapped onto an argumentation framework in which arguments are defined by the\nnotion of deduction. Justified actions with respect to semantics from\nargumentation correspond to solutions of the VDA. The acceptance (rejection) of\narguments and their premises in the framework provides an explanation for why\nan action was selected (or not). Furthermore, we go beyond the existing version\nof VDA, considering not only practical reasoning, but also epistemic reasoning,\nsuch that the inconsistency of knowledge of the VDA can be identified, handled\nand explained.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 11:04:24 GMT"}, {"version": "v2", "created": "Sun, 20 Oct 2019 09:11:34 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Liao", "Beishui", ""], ["Anderson", "Michael", ""], ["Anderson", "Susan Leigh", ""]]}, {"id": "1812.05407", "submitter": "Shen Gao", "authors": "Shen Gao, Xiuying Chen, Piji Li, Zhaochun Ren, Lidong Bing, Dongyan\n  Zhao, Rui Yan", "title": "Abstractive Text Summarization by Incorporating Reader Comments", "comments": "Accepted by AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neural abstractive summarization field, conventional sequence-to-sequence\nbased models often suffer from summarizing the wrong aspect of the document\nwith respect to the main aspect. To tackle this problem, we propose the task of\nreader-aware abstractive summary generation, which utilizes the reader comments\nto help the model produce better summary about the main aspect. Unlike\ntraditional abstractive summarization task, reader-aware summarization\nconfronts two main challenges: (1) Comments are informal and noisy; (2) jointly\nmodeling the news document and the reader comments is challenging. To tackle\nthe above challenges, we design an adversarial learning model named\nreader-aware summary generator (RASG), which consists of four components: (1) a\nsequence-to-sequence based summary generator; (2) a reader attention module\ncapturing the reader focused aspects; (3) a supervisor modeling the semantic\ngap between the generated summary and reader focused aspects; (4) a goal\ntracker producing the goal for each generation step. The supervisor and the\ngoal tacker are used to guide the training of our framework in an adversarial\nmanner. Extensive experiments are conducted on our large-scale real-world text\nsummarization dataset, and the results show that RASG achieves the\nstate-of-the-art performance in terms of both automatic metrics and human\nevaluations. The experimental results also demonstrate the effectiveness of\neach module in our framework. We release our large-scale dataset for further\nresearch.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 13:13:23 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Gao", "Shen", ""], ["Chen", "Xiuying", ""], ["Li", "Piji", ""], ["Ren", "Zhaochun", ""], ["Bing", "Lidong", ""], ["Zhao", "Dongyan", ""], ["Yan", "Rui", ""]]}, {"id": "1812.05451", "submitter": "Sebastien Blandin", "authors": "Marc Jourdan, Sebastien Blandin, Laura Wynter, Pralhad Deshpande", "title": "A Probabilistic Model of the Bitcoin Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bitcoin transaction graph is a public data structure organized as\ntransactions between addresses, each associated with a logical entity. In this\nwork, we introduce a complete probabilistic model of the Bitcoin Blockchain. We\nfirst formulate a set of conditional dependencies induced by the Bitcoin\nprotocol at the block level and derive a corresponding fully observed graphical\nmodel of a Bitcoin block. We then extend the model to include hidden entity\nattributes such as the functional category of the associated logical agent and\nderive asymptotic bounds on the privacy properties implied by this model. At\nthe network level, we show evidence of complex transaction-to-transaction\nbehavior and present a relevant discriminative model of the agent categories.\nPerformance of both the block-based graphical model and the network-level\ndiscriminative model is evaluated on a subset of the public Bitcoin Blockchain.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 02:35:24 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Jourdan", "Marc", ""], ["Blandin", "Sebastien", ""], ["Wynter", "Laura", ""], ["Deshpande", "Pralhad", ""]]}, {"id": "1812.05556", "submitter": "Liane Gabora", "authors": "Steve DiPaola, Liane Gabora, and Graeme McCaig", "title": "Informing Artificial Intelligence Generative Techniques using Cognitive\n  Theories of Human Creativity", "comments": "18 pages; 6 figures. arXiv admin note: substantial text overlap with\n  arXiv:1610.02478", "journal-ref": "Procedia Computer Science, vol. 145 (pp. 158-168). Amsterdam:\n  Elsevier (2018)", "doi": "10.1016/j.procs.2018.11.024", "report-no": null, "categories": "cs.AI cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The common view that our creativity is what makes us uniquely human suggests\nthat incorporating research on human creativity into generative deep learning\ntechniques might be a fruitful avenue for making their outputs more compelling\nand human-like. Using an original synthesis of Deep Dream-based convolutional\nneural networks and cognitive based computational art rendering systems, we\nshow how honing theory, intrinsic motivation, and the notion of a 'seed\nincident' can be implemented computationally, and demonstrate their impact on\nthe resulting generative art. Conversely, we discuss how explorations in deep\nlearn-ing convolutional neural net generative systems can inform our\nunderstanding of human creativity. We conclude with ideas for further\ncross-fertilization between AI based computational creativity and psychology of\ncreativity.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 18:12:44 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 21:00:09 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["DiPaola", "Steve", ""], ["Gabora", "Liane", ""], ["McCaig", "Graeme", ""]]}, {"id": "1812.05591", "submitter": "Srishti Dhamija", "authors": "Srishti Dhamija and Pradeep Varakantham", "title": "TuSeRACT: Turn-Sample-Based Real-Time Traffic Signal Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time traffic signal control is a challenging problem owing to constantly\nchanging traffic demand patterns, limited planning time and various sources of\nuncertainty (e.g., turn movements, vehicle detection) in the real world.\nSURTRAC (Scalable URban TRAffic Control) is a recently developed traffic signal\ncontrol approach which computes delay-minimizing and coordinated (across\nneighbouring traffic lights) schedules of oncoming vehicle clusters in real\ntime. To ensure real-time responsiveness in the presence of turn-induced\nuncertainty, SURTRAC computes schedules which minimize the delay for the\nexpected turn movements as opposed to minimizing the expected delay under\nturn-induced uncertainty. This approximation ensures real-time tractability,\nbut degrades solution quality in the presence of turn-induced uncertainty. To\naddress this limitation, we introduce TuSeRACT (Turn Sample based Real-time\ntrAffic signal ConTrol), a distributed sample-based scheduling approach to\ntraffic signal control. Unlike SURTRAC, TuSeRACT computes schedules that\nminimize expected delay over sampled turn movements of observed traffic, and\ncommunicates samples of traffic outflows to neighbouring intersections. We\nformulate this sample-based scheduling problem as a constraint program and\nempirically evaluate our approach on synthetic traffic networks. Our approach\nprovides substantially lower mean vehicular waiting times relative to SURTRAC.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 18:57:53 GMT"}, {"version": "v2", "created": "Tue, 8 Jan 2019 18:46:52 GMT"}, {"version": "v3", "created": "Tue, 5 Feb 2019 12:06:47 GMT"}, {"version": "v4", "created": "Tue, 5 Mar 2019 18:58:28 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Dhamija", "Srishti", ""], ["Varakantham", "Pradeep", ""]]}, {"id": "1812.05659", "submitter": "Enes Karaaslan", "authors": "Enes Karaaslan, Ulas Bagci, F. Necati Catbas", "title": "Artificial Intelligence Assisted Infrastructure Assessment Using Mixed\n  Reality Systems", "comments": "5,240 word texts, 3 tables, 14 figures. Transportation Research\n  Record: Journal of the Transportation Research Board, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional methods for visual assessment of civil infrastructures have\ncertain limitations, such as subjectivity of the collected data, long\ninspection time, and high cost of labor. Although some new technologies i.e.\nrobotic techniques that are currently in practice can collect objective,\nquantified data, the inspectors own expertise is still critical in many\ninstances since these technologies are not designed to work interactively with\nhuman inspector. This study aims to create a smart, human centered method that\noffers significant contributions to infrastructure inspection, maintenance,\nmanagement practice, and safety for the bridge owners. By developing a smart\nMixed Reality framework, which can be integrated into a wearable holographic\nheadset device, a bridge inspector, for example, can automatically analyze a\ncertain defect such as a crack that he or she sees on an element, display its\ndimension information in real-time along with the condition state. Such systems\ncan potentially decrease the time and cost of infrastructure inspections by\naccelerating essential tasks of the inspector such as defect measurement,\ncondition assessment and data processing to management systems. The human\ncentered artificial intelligence will help the inspector collect more\nquantified and objective data while incorporating inspectors professional\njudgement. This study explains in detail the described system and related\nmethodologies of implementing attention guided semi supervised deep learning\ninto mixed reality technology, which interacts with the human inspector during\nassessment. Thereby, the inspector and the AI will collaborate or communicate\nfor improved visual inspection.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2018 19:46:00 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Karaaslan", "Enes", ""], ["Bagci", "Ulas", ""], ["Catbas", "F. Necati", ""]]}, {"id": "1812.05687", "submitter": "Peter Lillian", "authors": "Peter E. Lillian, Richard Meyes, Tobias Meisen", "title": "Ablation of a Robot's Brain: Neural Networks Under a Knife", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is still not fully understood exactly how neural networks are able to\nsolve the complex tasks that have recently pushed AI research forward. We\npresent a novel method for determining how information is structured inside a\nneural network. Using ablation (a neuroscience technique for cutting away parts\nof a brain to determine their function), we approach several neural network\narchitectures from a biological perspective. Through an analysis of this\nmethod's results, we examine important similarities between biological and\nartificial neural networks to search for the implicit knowledge locked away in\nthe network's weights.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 20:58:37 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 07:57:22 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Lillian", "Peter E.", ""], ["Meyes", "Richard", ""], ["Meisen", "Tobias", ""]]}, {"id": "1812.05794", "submitter": "Bo Zhang", "authors": "Bo Zhang, Bin Chen, Jin-lin Peng", "title": "The Entropy of Artificial Intelligence and a Case Study of AlphaZero\n  from Shannon's Perspective", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The recently released AlphaZero algorithm achieves superhuman performance in\nthe games of chess, shogi and Go, which raises two open questions. Firstly, as\nthere is a finite number of possibilities in the game, is there a quantifiable\nintelligence measurement for evaluating intelligent systems, e.g. AlphaZero?\nSecondly, AlphaZero introduces sophisticated reinforcement learning and\nself-play to efficiently encode the possible states, is there a simple\ninformation-theoretic model to represent the learning process and offer more\ninsights in fostering strong AI systems?\n  This paper explores the above two questions by proposing a simple variance of\nShannon's communication model, the concept of intelligence entropy and the\nUnified Intelligence-Communication Model is proposed, which provide an\ninformation-theoretic metric for investigating the intelligence level and also\nprovide an bound for intelligent agents in the form of Shannon's capacity,\nnamely, the intelligence capacity. This paper then applies the concept and\nmodel to AlphaZero as a case study and explains the learning process of\nintelligent agent as turbo-like iterative decoding, so that the learning\nperformance of AlphaZero may be quantitatively evaluated. Finally, conclusions\nare provided along with theoretical and practical remarks.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 06:06:29 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2018 08:49:34 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Zhang", "Bo", ""], ["Chen", "Bin", ""], ["Peng", "Jin-lin", ""]]}, {"id": "1812.05795", "submitter": "Tatsuji Takahashi", "authors": "Akihiro Tamatsukuri and Tatsuji Takahashi", "title": "Guaranteed satisficing and finite regret: Analysis of a cognitive\n  satisficing value function", "comments": "16 pages, 3 figures, supplementary information (A, B, and C) included", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As reinforcement learning algorithms are being applied to increasingly\ncomplicated and realistic tasks, it is becoming increasingly difficult to solve\nsuch problems within a practical time frame. Hence, we focus on a\n\\textit{satisficing} strategy that looks for an action whose value is above the\naspiration level (analogous to the break-even point), rather than the optimal\naction. In this paper, we introduce a simple mathematical model called\nrisk-sensitive satisficing ($RS$) that implements a satisficing strategy by\nintegrating risk-averse and risk-prone attitudes under the greedy policy. We\napply the proposed model to the $K$-armed bandit problems, which constitute the\nmost basic class of reinforcement learning tasks, and prove two propositions.\nThe first is that $RS$ is guaranteed to find an action whose value is above the\naspiration level. The second is that the regret (expected loss) of $RS$ is\nupper bounded by a finite value, given that the aspiration level is set to an\n\"optimal level\" so that satisficing implies optimizing. We confirm the results\nthrough numerical simulations and compare the performance of $RS$ with that of\nother representative algorithms for the $K$-armed bandit problems.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 06:26:50 GMT"}, {"version": "v2", "created": "Sat, 23 Feb 2019 11:11:14 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Tamatsukuri", "Akihiro", ""], ["Takahashi", "Tatsuji", ""]]}, {"id": "1812.05905", "submitter": "Tuomas Haarnoja", "authors": "Tuomas Haarnoja, Aurick Zhou, Kristian Hartikainen, George Tucker,\n  Sehoon Ha, Jie Tan, Vikash Kumar, Henry Zhu, Abhishek Gupta, Pieter Abbeel\n  and Sergey Levine", "title": "Soft Actor-Critic Algorithms and Applications", "comments": "arXiv admin note: substantial text overlap with arXiv:1801.01290", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free deep reinforcement learning (RL) algorithms have been successfully\napplied to a range of challenging sequential decision making and control tasks.\nHowever, these methods typically suffer from two major challenges: high sample\ncomplexity and brittleness to hyperparameters. Both of these challenges limit\nthe applicability of such methods to real-world domains. In this paper, we\ndescribe Soft Actor-Critic (SAC), our recently introduced off-policy\nactor-critic algorithm based on the maximum entropy RL framework. In this\nframework, the actor aims to simultaneously maximize expected return and\nentropy. That is, to succeed at the task while acting as randomly as possible.\nWe extend SAC to incorporate a number of modifications that accelerate training\nand improve stability with respect to the hyperparameters, including a\nconstrained formulation that automatically tunes the temperature\nhyperparameter. We systematically evaluate SAC on a range of benchmark tasks,\nas well as real-world challenging tasks such as locomotion for a quadrupedal\nrobot and robotic manipulation with a dexterous hand. With these improvements,\nSAC achieves state-of-the-art performance, outperforming prior on-policy and\noff-policy methods in sample-efficiency and asymptotic performance.\nFurthermore, we demonstrate that, in contrast to other off-policy algorithms,\nour approach is very stable, achieving similar performance across different\nrandom seeds. These results suggest that SAC is a promising candidate for\nlearning in real-world robotics tasks.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 04:44:29 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 12:10:47 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Haarnoja", "Tuomas", ""], ["Zhou", "Aurick", ""], ["Hartikainen", "Kristian", ""], ["Tucker", "George", ""], ["Ha", "Sehoon", ""], ["Tan", "Jie", ""], ["Kumar", "Vikash", ""], ["Zhu", "Henry", ""], ["Gupta", "Abhishek", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1812.05929", "submitter": "Fay\\c{c}al Ait Aoudia", "authors": "Fay\\c{c}al Ait Aoudia and Jakob Hoydis", "title": "Model-free Training of End-to-end Communication Systems", "comments": "Accepted for publication in JSAC Special Issue on Machine Learning in\n  Wireless Communication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea of end-to-end learning of communication systems through neural\nnetwork-based autoencoders has the shortcoming that it requires a\ndifferentiable channel model. We present in this paper a novel learning\nalgorithm which alleviates this problem. The algorithm enables training of\ncommunication systems with an unknown channel model or with non-differentiable\ncomponents. It iterates between training of the receiver using the true\ngradient, and training of the transmitter using an approximation of the\ngradient. We show that this approach works as well as model-based training for\na variety of channels and tasks. Moreover, we demonstrate the algorithm's\npractical viability through hardware implementation on software-defined radios\nwhere it achieves state-of-the-art performance over a coaxial cable and\nwireless channel.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 13:46:24 GMT"}, {"version": "v2", "created": "Sat, 23 Mar 2019 12:08:48 GMT"}, {"version": "v3", "created": "Mon, 1 Jul 2019 14:46:37 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Aoudia", "Fay\u00e7al Ait", ""], ["Hoydis", "Jakob", ""]]}, {"id": "1812.06015", "submitter": "C. Maria Keet", "authors": "C. Maria Keet and Kieren Davies and Agnieszka Lawrynowicz", "title": "More Effective Ontology Authoring with Test-Driven Development", "comments": "16 pages, 7 figures, extended tech report of ESWC17 demo paper and\n  extended version of a preprint of an article submitted for consideration in\n  IJAIT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontology authoring is a complex process, where commonly the automated\nreasoner is invoked for verification of newly introduced changes, therewith\namounting to a time-consuming test-last approach. Test-Driven Development (TDD)\nfor ontology authoring is a recent {\\em test-first} approach that aims to\nreduce authoring time and increase authoring efficiency. Current TDD testing\nfalls short on coverage of OWL features and possible test outcomes, the\nrigorous foundation thereof, and evaluations to ascertain its effectiveness.\n  We aim to address these issues in one instantiation of TDD for ontology\nauthoring. We first propose a succinct, logic-based model of TDD testing and\npresent novel TDD algorithms so as to cover also any OWL 2 class expression for\nthe TBox and for the principal ABox assertions, and prove their correctness.\nThe algorithms use methods from the OWL API directly such that reclassification\nis not necessary for test execution, therewith reducing ontology authoring\ntime. The algorithms were implemented in TDDonto2, a Prot\\'eg\\'e plugin.\nTDDonto2 was evaluated on editing efficiency and by users. The editing\nefficiency study demonstrated that it is faster than a typical ontology\nauthoring interface, especially for medium size and large ontologies. The user\nevaluation demonstrated that modellers make significantly less errors with\nTDDonto2 compared to the standard Prot\\'eg\\'e interface and complete their\ntasks better using less time. Thus, the results indicate that Test-Driven\nDevelopment is a promising approach in an ontology development methodology.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 16:47:03 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Keet", "C. Maria", ""], ["Davies", "Kieren", ""], ["Lawrynowicz", "Agnieszka", ""]]}, {"id": "1812.06028", "submitter": "Mieczys{\\l}aw K{\\l}opotek", "authors": "Andrzej Matuszewski, Mieczys{\\l}aw A. K{\\l}opotek", "title": "Factorization of Dempster-Shafer Belief Functions Based on Data", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": "IPI PAN Report 798", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One important obstacle in applying Dempster-Shafer Theory (DST) is its\nrelationship to frequencies. In particular, there exist serious difficulties in\nfinding factorizations of belief functions from data.\n  In probability theory factorizations are usually related to notion of\n(conditional) independence and their possibility tested accordingly. However,\nin DST conditional belief distributions prove to be non-proper belief functions\n(that is ones connected with negative \"frequencies\"). This makes statistical\ntesting of potential conditional independencies practically impossible, as no\ncoherent interpretation could be found so far for negative belief function\nvalues.\n  In this paper a novel attempt is made to overcome this difficulty. In the\nproposal no conditional beliefs are calculated, but instead a new measure F is\nintroduced within the framework of DST, closely related to conditional\nindependence, allowing to apply conventional statistical tests for detection of\ndependence/independence.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 17:05:59 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Matuszewski", "Andrzej", ""], ["K\u0142opotek", "Mieczys\u0142aw A.", ""]]}, {"id": "1812.06110", "submitter": "Pablo Samuel Castro", "authors": "Pablo Samuel Castro, Subhodeep Moitra, Carles Gelada, Saurabh Kumar,\n  Marc G. Bellemare", "title": "Dopamine: A Research Framework for Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (deep RL) research has grown significantly in\nrecent years. A number of software offerings now exist that provide stable,\ncomprehensive implementations for benchmarking. At the same time, recent deep\nRL research has become more diverse in its goals. In this paper we introduce\nDopamine, a new research framework for deep RL that aims to support some of\nthat diversity. Dopamine is open-source, TensorFlow-based, and provides compact\nand reliable implementations of some state-of-the-art deep RL agents. We\ncomplement this offering with a taxonomy of the different research objectives\nin deep RL research. While by no means exhaustive, our analysis highlights the\nheterogeneity of research in the field, and the value of frameworks such as\nours.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 19:03:38 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Castro", "Pablo Samuel", ""], ["Moitra", "Subhodeep", ""], ["Gelada", "Carles", ""], ["Kumar", "Saurabh", ""], ["Bellemare", "Marc G.", ""]]}, {"id": "1812.06120", "submitter": "Kathy Jang", "authors": "Kathy Jang, Eugene Vinitsky, Behdad Chalaki, Ben Remer, Logan Beaver,\n  Andreas Malikopoulos, Alexandre Bayen", "title": "Simulation to Scaled City: Zero-Shot Policy Transfer for Traffic Control\n  via Autonomous Vehicles", "comments": "To be published at the International Conference on Cyber Physical\n  Systems (ICCPS) 2019. 10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using deep reinforcement learning, we train control policies for autonomous\nvehicles leading a platoon of vehicles onto a roundabout. Using Flow, a library\nfor deep reinforcement learning in micro-simulators, we train two policies, one\npolicy with noise injected into the state and action space and one without any\ninjected noise. In simulation, the autonomous vehicle learns an emergent\nmetering behavior for both policies in which it slows to allow for smoother\nmerging. We then directly transfer this policy without any tuning to the\nUniversity of Delaware Scaled Smart City (UDSSC), a 1:25 scale testbed for\nconnected and automated vehicles. We characterize the performance of both\npolicies on the scaled city. We show that the noise-free policy winds up\ncrashing and only occasionally metering. However, the noise-injected policy\nconsistently performs the metering behavior and remains collision-free,\nsuggesting that the noise helps with the zero-shot policy transfer.\nAdditionally, the transferred, noise-injected policy leads to a 5% reduction of\naverage travel time and a reduction of 22% in maximum travel time in the UDSSC.\nVideos of the controllers can be found at\nhttps://sites.google.com/view/iccps-policy-transfer.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 19:20:09 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 21:41:17 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Jang", "Kathy", ""], ["Vinitsky", "Eugene", ""], ["Chalaki", "Behdad", ""], ["Remer", "Ben", ""], ["Beaver", "Logan", ""], ["Malikopoulos", "Andreas", ""], ["Bayen", "Alexandre", ""]]}, {"id": "1812.06161", "submitter": "Weiming Xiang", "authors": "Weiming Xiang, Hoang-Dung Tran, Taylor T. Johnson", "title": "Specification-Guided Safety Verification for Feedforward Neural Networks", "comments": "To be presented in AAAI Spring Symposium on Verification of Neural\n  Networks (VNN19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a specification-guided safety verification method for\nfeedforward neural networks with general activation functions. As such\nfeedforward networks are memoryless, they can be abstractly represented as\nmathematical functions, and the reachability analysis of the neural network\namounts to interval analysis problems. In the framework of interval analysis, a\ncomputationally efficient formula which can quickly compute the output interval\nsets of a neural network is developed. Then, a specification-guided\nreachability algorithm is developed. Specifically, the bisection process in the\nverification algorithm is completely guided by a given safety specification.\nDue to the employment of the safety specification, unnecessary computations are\navoided and thus the computational cost can be reduced significantly.\nExperiments show that the proposed method enjoys much more efficiency in safety\nverification with significantly less computational cost.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 20:47:54 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Xiang", "Weiming", ""], ["Tran", "Hoang-Dung", ""], ["Johnson", "Taylor T.", ""]]}, {"id": "1812.06176", "submitter": "Neil Mallinar", "authors": "Neil Mallinar, Abhishek Shah, Rajendra Ugrani, Ayush Gupta, Manikandan\n  Gurusankar, Tin Kam Ho, Q. Vera Liao, Yunfeng Zhang, Rachel K.E. Bellamy,\n  Robert Yates, Chris Desmarais, Blake McGregor", "title": "Bootstrapping Conversational Agents With Weak Supervision", "comments": "6 pages, 3 figures, 1 table, Accepted for publication in IAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many conversational agents in the market today follow a standard bot\ndevelopment framework which requires training intent classifiers to recognize\nuser input. The need to create a proper set of training examples is often the\nbottleneck in the development process. In many occasions agent developers have\naccess to historical chat logs that can provide a good quantity as well as\ncoverage of training examples. However, the cost of labeling them with tens to\nhundreds of intents often prohibits taking full advantage of these chat logs.\nIn this paper, we present a framework called \\textit{search, label, and\npropagate} (SLP) for bootstrapping intents from existing chat logs using weak\nsupervision. The framework reduces hours to days of labeling effort down to\nminutes of work by using a search engine to find examples, then relies on a\ndata programming approach to automatically expand the labels. We report on a\nuser study that shows positive user feedback for this new approach to build\nconversational agents, and demonstrates the effectiveness of using data\nprogramming for auto-labeling. While the system is developed for training\nconversational agents, the framework has broader application in significantly\nreducing labeling effort for training text classifiers.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 21:32:40 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Mallinar", "Neil", ""], ["Shah", "Abhishek", ""], ["Ugrani", "Rajendra", ""], ["Gupta", "Ayush", ""], ["Gurusankar", "Manikandan", ""], ["Ho", "Tin Kam", ""], ["Liao", "Q. Vera", ""], ["Zhang", "Yunfeng", ""], ["Bellamy", "Rachel K. E.", ""], ["Yates", "Robert", ""], ["Desmarais", "Chris", ""], ["McGregor", "Blake", ""]]}, {"id": "1812.06209", "submitter": "Amin Jaber", "authors": "Amin Jaber, Jiji Zhang, Elias Bareinboim", "title": "Causal Identification under Markov Equivalence", "comments": "10 pages, 4 figures, In Proceedings of the 34th Conference on\n  Uncertainty in Artificial Intelligence (UAI2018). AUAI Press: 978-987", "journal-ref": null, "doi": null, "report-no": "Report-no: R-35", "categories": "cs.AI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assessing the magnitude of cause-and-effect relations is one of the central\nchallenges found throughout the empirical sciences. The problem of\nidentification of causal effects is concerned with determining whether a causal\neffect can be computed from a combination of observational data and substantive\nknowledge about the domain under investigation, which is formally expressed in\nthe form of a causal graph. In many practical settings, however, the knowledge\navailable for the researcher is not strong enough so as to specify a unique\ncausal graph. Another line of investigation attempts to use observational data\nto learn a qualitative description of the domain called a Markov equivalence\nclass, which is the collection of causal graphs that share the same set of\nobserved features. In this paper, we marry both approaches and study the\nproblem of causal identification from an equivalence class, represented by a\npartial ancestral graph (PAG). We start by deriving a set of graphical\nproperties of PAGs that are carried over to its induced subgraphs. We then\ndevelop an algorithm to compute the effect of an arbitrary set of variables on\nan arbitrary outcome set. We show that the algorithm is strictly more powerful\nthan the current state of the art found in the literature.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2018 00:31:52 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Jaber", "Amin", ""], ["Zhang", "Jiji", ""], ["Bareinboim", "Elias", ""]]}, {"id": "1812.06234", "submitter": "Yogatheesan Varatharajah", "authors": "Yogatheesan Varatharajah, Brent Berry, Jan Cimbalnik, Vaclav Kremen,\n  Jamie Van Gompel, Matt Stead, Benjamin Brinkmann, Ravishankar Iyer, and\n  Gregory Worrell", "title": "Integrating Artificial Intelligence with Real-time Intracranial EEG\n  Monitoring to Automate Interictal Identification of Seizure Onset Zones in\n  Focal Epilepsy", "comments": "25 pages, Journal of neural engineering (2018)", "journal-ref": null, "doi": "10.1088/1741-2552/aac960", "report-no": null, "categories": "q-bio.NC cs.AI q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ability to map seizure-generating brain tissue, i.e., the seizure onset\nzone (SOZ), without recording actual seizures could reduce the duration of\ninvasive EEG monitoring for patients with drug-resistant epilepsy. A\nwidely-adopted practice in the literature is to compare the incidence\n(events/time) of putative pathological electrophysiological biomarkers\nassociated with epileptic brain tissue with the SOZ determined from spontaneous\nseizures recorded with intracranial EEG, primarily using a single biomarker.\nClinical translation of the previous efforts suffers from their inability to\ngeneralize across multiple patients because of (a) the inter-patient\nvariability and (b) the temporal variability in the epileptogenic activity.\nHere, we report an artificial intelligence-based approach for combining\nmultiple interictal electrophysiological biomarkers and their temporal\ncharacteristics as a way of accounting for the above barriers and show that it\ncan reliably identify seizure onset zones in a study cohort of 82 patients who\nunderwent evaluation for drug-resistant epilepsy. Our investigation provides\nevidence that utilizing the complementary information provided by multiple\nelectrophysiological biomarkers and their temporal characteristics can\nsignificantly improve the localization potential compared to previously\npublished single-biomarker incidence-based approaches, resulting in an average\narea under ROC curve (AUC) value of 0.73 in a cohort of 82 patients. Our\nresults also suggest that recording durations between ninety minutes and two\nhours are sufficient to localize SOZs with accuracies that may prove clinically\nrelevant. The successful validation of our approach on a large cohort of 82\npatients warrants future investigation on the feasibility of utilizing\nintra-operative EEG monitoring and artificial intelligence to localize\nepileptogenic brain tissue.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2018 05:15:40 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Varatharajah", "Yogatheesan", ""], ["Berry", "Brent", ""], ["Cimbalnik", "Jan", ""], ["Kremen", "Vaclav", ""], ["Van Gompel", "Jamie", ""], ["Stead", "Matt", ""], ["Brinkmann", "Benjamin", ""], ["Iyer", "Ravishankar", ""], ["Worrell", "Gregory", ""]]}, {"id": "1812.06292", "submitter": "Vinayakumar R", "authors": "Mohammed Harun Babu R, Vinayakumar R, Soman KP", "title": "A short review on Applications of Deep learning for Cyber security", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep learning is an advanced model of traditional machine learning. This has\nthe capability to extract optimal feature representation from raw input\nsamples. This has been applied towards various use cases in cyber security such\nas intrusion detection, malware classification, android malware detection, spam\nand phishing detection and binary analysis. This paper outlines the survey of\nall the works related to deep learning based solutions for various cyber\nsecurity use cases. Keywords: Deep learning, intrusion detection, malware\ndetection, Android malware detection, spam & phishing detection, traffic\nanalysis, binary analysis.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2018 14:17:40 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 04:47:40 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["R", "Mohammed Harun Babu", ""], ["R", "Vinayakumar", ""], ["KP", "Soman", ""]]}, {"id": "1812.06355", "submitter": "Hang Ma", "authors": "Hang Ma, Wolfgang H\\\"onig, T. K. Satish Kumar, Nora Ayanian, Sven\n  Koenig", "title": "Lifelong Path Planning with Kinematic Constraints for Multi-Agent Pickup\n  and Delivery", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Multi-Agent Pickup and Delivery (MAPD) problem models applications where\na large number of agents attend to a stream of incoming pickup-and-delivery\ntasks. Token Passing (TP) is a recent MAPD algorithm that is efficient and\neffective. We make TP even more efficient and effective by using a novel\ncombinatorial search algorithm, called Safe Interval Path Planning with\nReservation Table (SIPPwRT), for single-agent path planning. SIPPwRT uses an\nadvanced data structure that allows for fast updates and lookups of the current\npaths of all agents in an online setting. The resulting MAPD algorithm\nTP-SIPPwRT takes kinematic constraints of real robots into account directly\nduring planning, computes continuous agent movements with given velocities that\nwork on non-holonomic robots rather than discrete agent movements with uniform\nvelocity, and is complete for well-formed MAPD instances. We demonstrate its\nbenefits for automated warehouses using both an agent simulator and a standard\nrobot simulator. For example, we demonstrate that it can compute paths for\nhundreds of agents and thousands of tasks in seconds and is more efficient and\neffective than existing MAPD algorithms that use a post-processing step to\nadapt their paths to continuous agent movements with given velocities.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2018 20:55:25 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Ma", "Hang", ""], ["H\u00f6nig", "Wolfgang", ""], ["Kumar", "T. K. Satish", ""], ["Ayanian", "Nora", ""], ["Koenig", "Sven", ""]]}, {"id": "1812.06356", "submitter": "Hang Ma", "authors": "Hang Ma, Daniel Harabor, Peter J. Stuckey, Jiaoyang Li, Sven Koenig", "title": "Searching with Consistent Prioritization for Multi-Agent Path Finding", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study prioritized planning for Multi-Agent Path Finding (MAPF). Existing\nprioritized MAPF algorithms depend on rule-of-thumb heuristics and random\nassignment to determine a fixed total priority ordering of all agents a priori.\nWe instead explore the space of all possible partial priority orderings as part\nof a novel systematic and conflict-driven combinatorial search framework. In a\nvariety of empirical comparisons, we demonstrate state-of-the-art solution\nqualities and success rates, often with similar runtimes to existing\nalgorithms. We also develop new theoretical results that explore the\nlimitations of prioritized planning, in terms of completeness and optimality,\nfor the first time.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2018 21:00:17 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Ma", "Hang", ""], ["Harabor", "Daniel", ""], ["Stuckey", "Peter J.", ""], ["Li", "Jiaoyang", ""], ["Koenig", "Sven", ""]]}, {"id": "1812.06362", "submitter": "Po-Wei Wang", "authors": "Po-Wei Wang, J. Zico Kolter", "title": "Low-rank semidefinite programming for the MAX2SAT problem", "comments": "Accepted at AAAI'19. The code can be found at\n  https://github.com/locuslab/mixsat", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new algorithm for solving MAX2SAT problems based on\ncombining search methods with semidefinite programming approaches. Semidefinite\nprogramming techniques are well-known as a theoretical tool for approximating\nmaximum satisfiability problems, but their application has traditionally been\nvery limited by their speed and randomized nature. Our approach overcomes this\ndifficult by using a recent approach to low-rank semidefinite programming,\nspecialized to work in an incremental fashion suitable for use in an exact\nsearch algorithm. The method can be used both within complete or incomplete\nsolver, and we demonstrate on a variety of problems from recent competitions.\nOur experiments show that the approach is faster (sometimes by orders of\nmagnitude) than existing state-of-the-art complete and incomplete solvers,\nrepresenting a substantial advance in search methods specialized for MAX2SAT\nproblems.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2018 22:03:04 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Wang", "Po-Wei", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1812.06378", "submitter": "Hongyu Xiong", "authors": "Yinglan Ma, Hongyu Xiong, Zhe Hu and Lizhuang Ma", "title": "Efficient Super Resolution Using Binarized Neural Network", "comments": "10 Pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (DCNNs) have recently demonstrated\nhigh-quality results in single-image super-resolution (SR). DCNNs often suffer\nfrom over-parametrization and large amounts of redundancy, which results in\ninefficient inference and high memory usage, preventing massive applications on\nmobile devices. As a way to significantly reduce model size and computation\ntime, binarized neural network has only been shown to excel on semantic-level\ntasks such as image classification and recognition. However, little effort of\nnetwork quantization has been spent on image enhancement tasks like SR, as\nnetwork quantization is usually assumed to sacrifice pixel-level accuracy. In\nthis work, we explore an network-binarization approach for SR tasks without\nsacrificing much reconstruction accuracy. To achieve this, we binarize the\nconvolutional filters in only residual blocks, and adopt a learnable weight for\neach binary filter. We evaluate this idea on several state-of-the-art\nDCNN-based architectures, and show that binarized SR networks achieve\ncomparable qualitative and quantitative results as their real-weight\ncounterparts. Moreover, the proposed binarized strategy could help reduce model\nsize by 80% when applying on SRResNet, and could potentially speed up inference\nby 5 times.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 02:44:20 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Ma", "Yinglan", ""], ["Xiong", "Hongyu", ""], ["Hu", "Zhe", ""], ["Ma", "Lizhuang", ""]]}, {"id": "1812.06381", "submitter": "Wenji Li", "authors": "Zhun Fan, Wenji Li, Zhaojun Wang, Yutong Yuan, Fuzan Sun, Zhi Yang,\n  Jie Ruan, Zhaocheng Li and Erik Goodman", "title": "Embedding Push and Pull Search in the Framework of Differential\n  Evolution for Solving Constrained Single-objective Optimization Problems", "comments": "11 pages, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a push and pull search method in the framework of\ndifferential evolution (PPS-DE) to solve constrained single-objective\noptimization problems (CSOPs). More specifically, two sub-populations,\nincluding the top and bottom sub-populations, are collaborated with each other\nto search global optimal solutions efficiently. The top sub-population adopts\nthe pull and pull search (PPS) mechanism to deal with constraints, while the\nbottom sub-population use the superiority of feasible solutions (SF) technique\nto deal with constraints. In the top sub-population, the search process is\ndivided into two different stages --- push and pull stages.An adaptive DE\nvariant with three trial vector generation strategies is employed in the\nproposed PPS-DE. In the top sub-population, all the three trial vector\ngeneration strategies are used to generate offsprings, just like in CoDE. In\nthe bottom sub-population, a strategy adaptation, in which the trial vector\ngeneration strategies are periodically self-adapted by learning from their\nexperiences in generating promising solutions in the top sub-population, is\nused to choose a suitable trial vector generation strategy to generate one\noffspring. Furthermore, a parameter adaptation strategy from LSHADE44 is\nemployed in both sup-populations to generate scale factor $F$ and crossover\nrate $CR$ for each trial vector generation strategy. Twenty-eight CSOPs with\n10-, 30-, and 50-dimensional decision variables provided in the CEC2018\ncompetition on real parameter single objective optimization are optimized by\nthe proposed PPS-DE. The experimental results demonstrate that the proposed\nPPS-DE has the best performance compared with the other seven state-of-the-art\nalgorithms, including AGA-PPS, LSHADE44, LSHADE44+IDE, UDE, IUDE,\n$\\epsilon$MAg-ES and C$^2$oDE.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 02:52:31 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Fan", "Zhun", ""], ["Li", "Wenji", ""], ["Wang", "Zhaojun", ""], ["Yuan", "Yutong", ""], ["Sun", "Fuzan", ""], ["Yang", "Zhi", ""], ["Ruan", "Jie", ""], ["Li", "Zhaocheng", ""], ["Goodman", "Erik", ""]]}, {"id": "1812.06401", "submitter": "Ehsan Abbasnejad M", "authors": "Ehsan Abbasnejad, Qi Wu, Javen Shi, Anton van den Hengel", "title": "What's to know? Uncertainty as a Guide to Asking Goal-oriented Questions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the core challenges in Visual Dialogue problems is asking the question\nthat will provide the most useful information towards achieving the required\nobjective. Encouraging an agent to ask the right questions is difficult because\nwe don't know a-priori what information the agent will need to achieve its\ntask, and we don't have an explicit model of what it knows already. We propose\na solution to this problem based on a Bayesian model of the uncertainty in the\nimplicit model maintained by the visual dialogue agent, and in the function\nused to select an appropriate output. By selecting the question that minimises\nthe predicted regret with respect to this implicit model the agent actively\nreduces ambiguity. The Bayesian model of uncertainty also enables a principled\nmethod for identifying when enough information has been acquired, and an action\nshould be selected. We evaluate our approach on two goal-oriented dialogue\ndatasets, one for visual-based collaboration task and the other for a\nnegotiation-based task. Our uncertainty-aware information-seeking model\noutperforms its counterparts in these two challenging problems.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 06:12:45 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Abbasnejad", "Ehsan", ""], ["Wu", "Qi", ""], ["Shi", "Javen", ""], ["Hengel", "Anton van den", ""]]}, {"id": "1812.06410", "submitter": "Quanming Yao", "authors": "Yongqi Zhang and Quanming Yao and Yingxia Shao and Lei Chen", "title": "NSCaching: Simple and Efficient Negative Sampling for Knowledge Graph\n  Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graph (KG) embedding is a fundamental problem in data mining\nresearch with many real-world applications. It aims to encode the entities and\nrelations in the graph into low dimensional vector space, which can be used for\nsubsequent algorithms. Negative sampling, which samples negative triplets from\nnon-observed ones in the training data, is an important step in KG embedding.\nRecently, generative adversarial network (GAN), has been introduced in negative\nsampling. By sampling negative triplets with large scores, these methods avoid\nthe problem of vanishing gradient and thus obtain better performance. However,\nusing GAN makes the original model more complex and hard to train, where\nreinforcement learning must be used. In this paper, motivated by the\nobservation that negative triplets with large scores are important but rare, we\npropose to directly keep track of them with the cache. However, how to sample\nfrom and update the cache are two important questions. We carefully design the\nsolutions, which are not only efficient but also achieve a good balance between\nexploration and exploitation. In this way, our method acts as a \"distilled\"\nversion of previous GA-based methods, which does not waste training time on\nadditional parameters to fit the full distribution of negative triplets. The\nextensive experiments show that our method can gain significant improvement in\nvarious KG embedding models, and outperform the state-of-the-art negative\nsampling methods based on GAN.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 07:32:02 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 11:34:27 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Zhang", "Yongqi", ""], ["Yao", "Quanming", ""], ["Shao", "Yingxia", ""], ["Chen", "Lei", ""]]}, {"id": "1812.06426", "submitter": "Guangli Li", "authors": "Guangli Li, Lei Liu, Xueying Wang, Xiao Dong, Peng Zhao, Xiaobing Feng", "title": "Auto-tuning Neural Network Quantization Framework for Collaborative\n  Inference Between the Cloud and Edge", "comments": "Published at ICANN 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep neural networks (DNNs) have been widely applied in mobile\nintelligent applications. The inference for the DNNs is usually performed in\nthe cloud. However, it leads to a large overhead of transmitting data via\nwireless network. In this paper, we demonstrate the advantages of the\ncloud-edge collaborative inference with quantization. By analyzing the\ncharacteristics of layers in DNNs, an auto-tuning neural network quantization\nframework for collaborative inference is proposed. We study the effectiveness\nof mixed-precision collaborative inference of state-of-the-art DNNs by using\nImageNet dataset. The experimental results show that our framework can generate\nreasonable network partitions and reduce the storage on mobile devices with\ntrivial loss of accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 09:05:44 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Li", "Guangli", ""], ["Liu", "Lei", ""], ["Wang", "Xueying", ""], ["Dong", "Xiao", ""], ["Zhao", "Peng", ""], ["Feng", "Xiaobing", ""]]}, {"id": "1812.06455", "submitter": "Emir Mu\\~noz Mr", "authors": "Emir Mu\\~noz, Pasquale Minervini, Matthias Nickles", "title": "Embedding Cardinality Constraints in Neural Link Predictors", "comments": "8 pages, accepted at the 34th ACM/SIGAPP Symposium on Applied\n  Computing (SAC '19)", "journal-ref": null, "doi": "10.1145/3297280.3297502", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural link predictors learn distributed representations of entities and\nrelations in a knowledge graph. They are remarkably powerful in the link\nprediction and knowledge base completion tasks, mainly due to the learned\nrepresentations that capture important statistical dependencies in the data.\nRecent works in the area have focused on either designing new scoring functions\nor incorporating extra information into the learning process to improve the\nrepresentations. Yet the representations are mostly learned from the observed\nlinks between entities, ignoring commonsense or schema knowledge associated\nwith the relations in the graph. A fundamental aspect of the topology of\nrelational data is the cardinality information, which bounds the number of\npredictions given for a relation between a minimum and maximum frequency. In\nthis paper, we propose a new regularisation approach to incorporate relation\ncardinality constraints to any existing neural link predictor without affecting\ntheir efficiency or scalability. Our regularisation term aims to impose\nboundaries on the number of predictions with high probability, thus,\nstructuring the embeddings space to respect commonsense cardinality assumptions\nresulting in better representations. Experimental results on Freebase, WordNet\nand YAGO show that, given suitable prior knowledge, the proposed method\npositively impacts the predictive accuracy of downstream link prediction tasks.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 12:36:15 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Mu\u00f1oz", "Emir", ""], ["Minervini", "Pasquale", ""], ["Nickles", "Matthias", ""]]}, {"id": "1812.06459", "submitter": "Ali Nassif", "authors": "Mohammad Azzeh, Ali Bou Nassif, Shadi Banitaan, Cuauhtemoc\n  Lopez-Martin", "title": "Ensemble of Learning Project Productivity in Software Effort Based on\n  Use Case Points", "comments": "Accepted at the 17th IEEE International Conference on Machine\n  Learning and Applications, ICMLA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well recognized that the project productivity is a key driver in\nestimating software project effort from Use Case Point size metric at early\nsoftware development stages. Although, there are few proposed models for\npredicting productivity, there is no consistent conclusion regarding which\nmodel is the superior. Therefore, instead of building a new productivity\nprediction model, this paper presents a new ensemble construction mechanism\napplied for software project productivity prediction. Ensemble is an effective\ntechnique when performance of base models is poor. We proposed a weighted mean\nmethod to aggregate predicted productivities based on average of errors\nproduced by training model. The obtained results show that the using ensemble\nis a good alternative approach when accuracies of base models are not\nconsistently accurate over different datasets, and when models behave\ndiversely.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 13:15:26 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Azzeh", "Mohammad", ""], ["Nassif", "Ali Bou", ""], ["Banitaan", "Shadi", ""], ["Lopez-Martin", "Cuauhtemoc", ""]]}, {"id": "1812.06474", "submitter": "Victor Sanchez-Anguix Dr.", "authors": "Victor Sanchez-Anguix, Rithin Chalumuri, Reyhan Aydogan, Vicente\n  Julian", "title": "A near Pareto optimal approach to student-supervisor allocation with two\n  sided preferences and workload balance", "comments": null, "journal-ref": "Applied Soft Computing, 2018", "doi": "10.1016/j.asoc.2018.11.049", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of allocating students to supervisors for the development of a\npersonal project or a dissertation is a crucial activity in the higher\neducation environment, as it enables students to get feedback on their work\nfrom an expert and improve their personal, academic, and professional\nabilities. In this article, we propose a multi-objective and near Pareto\noptimal genetic algorithm for the allocation of students to supervisors. The\nallocation takes into consideration the students and supervisors' preferences\non research/project topics, the lower and upper supervision quotas of\nsupervisors, as well as the workload balance amongst supervisors. We introduce\nnovel mutation and crossover operators for the student-supervisor allocation\nproblem. The experiments carried out show that the components of the genetic\nalgorithm are more apt for the problem than classic components, and that the\ngenetic algorithm is capable of producing allocations that are near Pareto\noptimal in a reasonable time.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 15:01:55 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Sanchez-Anguix", "Victor", ""], ["Chalumuri", "Rithin", ""], ["Aydogan", "Reyhan", ""], ["Julian", "Vicente", ""]]}, {"id": "1812.06510", "submitter": "Tshilidzi Marwala", "authors": "Tshilidzi Marwala", "title": "The limit of artificial intelligence: Can machines be rational?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the question on whether machines can be rational. It\nobserves the existing reasons why humans are not rational which is due to\nimperfect and limited information, limited and inconsistent processing power\nthrough the brain and the inability to optimize decisions and achieve maximum\nutility. It studies whether these limitations of humans are transferred to the\nlimitations of machines. The conclusion reached is that even though machines\nare not rational advances in technological developments make these machines\nmore rational. It also concludes that machines can be more rational than\nhumans.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 17:57:16 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Marwala", "Tshilidzi", ""]]}, {"id": "1812.06535", "submitter": "Shlomo Chazan", "authors": "Shlomo E. Chazan, Sharon Gannot and Jacob Goldberger", "title": "Deep Clustering Based on a Mixture of Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a Deep Autoencoder MIxture Clustering (DAMIC)\nalgorithm based on a mixture of deep autoencoders where each cluster is\nrepresented by an autoencoder. A clustering network transforms the data into\nanother space and then selects one of the clusters. Next, the autoencoder\nassociated with this cluster is used to reconstruct the data-point. The\nclustering algorithm jointly learns the nonlinear data representation and the\nset of autoencoders. The optimal clustering is found by minimizing the\nreconstruction loss of the mixture of autoencoder network. Unlike other deep\nclustering algorithms, no regularization term is needed to avoid data\ncollapsing to a single point. Our experimental evaluations on image and text\ncorpora show significant improvement over state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 21:03:32 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 11:45:12 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Chazan", "Shlomo E.", ""], ["Gannot", "Sharon", ""], ["Goldberger", "Jacob", ""]]}, {"id": "1812.06544", "submitter": "Krishanu Sarker", "authors": "Krishanu Sarker, Mohamed Masoud, Saeid Belkasim, Shihao Ji", "title": "Towards Robust Human Activity Recognition from RGB Video Stream with\n  Limited Labeled Data", "comments": "To appear in ICMLA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human activity recognition based on video streams has received numerous\nattentions in recent years. Due to lack of depth information, RGB video based\nactivity recognition performs poorly compared to RGB-D video based solutions.\nOn the other hand, acquiring depth information, inertia etc. is costly and\nrequires special equipment, whereas RGB video streams are available in ordinary\ncameras. Hence, our goal is to investigate whether similar or even higher\naccuracy can be achieved with RGB-only modality. In this regard, we propose a\nnovel framework that couples skeleton data extracted from RGB video and deep\nBidirectional Long Short Term Memory (BLSTM) model for activity recognition. A\nbig challenge of training such a deep network is the limited training data, and\nexploring RGB-only stream significantly exaggerates the difficulty. We\ntherefore propose a set of algorithmic techniques to train this model\neffectively, e.g., data augmentation, dynamic frame dropout and gradient\ninjection. The experiments demonstrate that our RGB-only solution surpasses the\nstate-of-the-art approaches that all exploit RGB-D video streams by a notable\nmargin. This makes our solution widely deployable with ordinary cameras.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 22:19:43 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Sarker", "Krishanu", ""], ["Masoud", "Mohamed", ""], ["Belkasim", "Saeid", ""], ["Ji", "Shihao", ""]]}, {"id": "1812.06574", "submitter": "Yunzhe Hao", "authors": "Yunzhe Hao, Xuhui Huang, Meng Dong, Bo Xu", "title": "A Biologically Plausible Supervised Learning Method for Spiking Neural\n  Networks Using the Symmetric STDP Rule", "comments": "29 pages, 6 figures", "journal-ref": "Neural Networks 121C (2020) pp. 387-395", "doi": "10.1016/j.neunet.2019.09.007", "report-no": null, "categories": "cs.NE cs.AI cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) possess energy-efficient potential due to\nevent-based computation. However, supervised training of SNNs remains a\nchallenge as spike activities are non-differentiable. Previous SNNs training\nmethods can be generally categorized into two basic classes, i.e.,\nbackpropagation-like training methods and plasticity-based learning methods.\nThe former methods are dependent on energy-inefficient real-valued computation\nand non-local transmission, as also required in artificial neural networks\n(ANNs), whereas the latter are either considered to be biologically implausible\nor exhibit poor performance. Hence, biologically plausible (bio-plausible)\nhigh-performance supervised learning (SL) methods for SNNs remain deficient. In\nthis paper, we proposed a novel bio-plausible SNN model for SL based on the\nsymmetric spike-timing dependent plasticity (sym-STDP) rule found in\nneuroscience. By combining the sym-STDP rule with bio-plausible synaptic\nscaling and intrinsic plasticity of the dynamic threshold, our SNN model\nimplemented SL well and achieved good performance in the benchmark recognition\ntask (MNIST dataset). To reveal the underlying mechanism of our SL model, we\nvisualized both layer-based activities and synaptic weights using the\nt-distributed stochastic neighbor embedding (t-SNE) method after training and\nfound that they were well clustered, thereby demonstrating excellent\nclassification ability. Furthermore, to verify the robustness of our model, we\ntrained it on another more realistic dataset (Fashion-MNIST), which also showed\ngood performance. As the learning rules were bio-plausible and based purely on\nlocal spike events, our model could be easily applied to neuromorphic hardware\nfor online training and may be helpful for understanding SL information\nprocessing at the synaptic level in biological neural systems.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 01:38:14 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 03:33:43 GMT"}, {"version": "v3", "created": "Sun, 6 Oct 2019 09:27:27 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Hao", "Yunzhe", ""], ["Huang", "Xuhui", ""], ["Dong", "Meng", ""], ["Xu", "Bo", ""]]}, {"id": "1812.06585", "submitter": "Mingde Zhao", "authors": "Mingde Zhao and Hongwei Ge and Yi Lian and Kai Zhang", "title": "Generalizable Meta-Heuristic based on Temporal Estimation of Rewards for\n  Large Scale Blackbox Optimization", "comments": "7 pages of contents, 1 page of references, 2 pages for appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generalization abilities of heuristic optimizers may deteriorate with the\nincrement of the search space dimensionality. To achieve generalized\nperformance across Large Scale Blackbox Optimization (LSBO) tasks, it\nispossible to ensemble several heuristics and devise a meta-heuristic to\ncontrol their initiation. This paper first proposes a methodology of\ntransforming LSBO problems into online decision processes to maximize\nefficiency of resource utilization. Then, using the perspective of multi-armed\nbandits with non-stationary reward distributions, we propose a meta-heuristic\nbased on Temporal Estimation of Rewards (TER) to address such decision process.\nTER uses a window for temporal credit assignment and Boltzmann exploration to\nbalance the exploration-exploitation tradeoff. The prior-free TER generalizes\nacross LSBO tasks with flexibility for different types of limited computational\nresources (e.g. time, money, etc.) and is easy to be adapted to new tasks for\nits simplicity and easy interface for heuristic articulation. Tests on the\nbenchmarks validate the problem formulation and suggest significant\neffectiveness: when TER is articulated with three heuristics, competitive\nperformance is reported across different sets of benchmark problems with search\ndimensions up to 10000.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 02:36:26 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 16:03:08 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Zhao", "Mingde", ""], ["Ge", "Hongwei", ""], ["Lian", "Yi", ""], ["Zhang", "Kai", ""]]}, {"id": "1812.06673", "submitter": "Zhao Kang", "authors": "Zhao Kang, Haiqi Pan, Steven C.H. Hoi, Zenglin Xu", "title": "Robust Graph Learning from Noisy Data", "comments": null, "journal-ref": null, "doi": "10.1109/TCYB.2018.2887094", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning graphs from data automatically has shown encouraging performance on\nclustering and semisupervised learning tasks. However, real data are often\ncorrupted, which may cause the learned graph to be inexact or unreliable. In\nthis paper, we propose a novel robust graph learning scheme to learn reliable\ngraphs from real-world noisy data by adaptively removing noise and errors in\nthe raw data. We show that our proposed model can also be viewed as a robust\nversion of manifold regularized robust PCA, where the quality of the graph\nplays a critical role. The proposed model is able to boost the performance of\ndata clustering, semisupervised classification, and data recovery\nsignificantly, primarily due to two key factors: 1) enhanced low-rank recovery\nby exploiting the graph smoothness assumption, 2) improved graph construction\nby exploiting clean data recovered by robust PCA. Thus, it boosts the\nclustering, semi-supervised classification, and data recovery performance\noverall. Extensive experiments on image/document clustering, object\nrecognition, image shadow removal, and video background subtraction reveal that\nour model outperforms the previous state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 10:01:59 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Kang", "Zhao", ""], ["Pan", "Haiqi", ""], ["Hoi", "Steven C. H.", ""], ["Xu", "Zenglin", ""]]}, {"id": "1812.06705", "submitter": "Wu Xing", "authors": "Xing Wu, Shangwen Lv, Liangjun Zang, Jizhong Han, Songlin Hu", "title": "Conditional BERT Contextual Augmentation", "comments": "9 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel data augmentation method for labeled sentences called\nconditional BERT contextual augmentation. Data augmentation methods are often\napplied to prevent overfitting and improve generalization of deep neural\nnetwork models. Recently proposed contextual augmentation augments labeled\nsentences by randomly replacing words with more varied substitutions predicted\nby language model. BERT demonstrates that a deep bidirectional language model\nis more powerful than either an unidirectional language model or the shallow\nconcatenation of a forward and backward model. We retrofit BERT to conditional\nBERT by introducing a new conditional masked language model\\footnote{The term\n\"conditional masked language model\" appeared once in original BERT paper, which\nindicates context-conditional, is equivalent to term \"masked language model\".\nIn our paper, \"conditional masked language model\" indicates we apply extra\nlabel-conditional constraint to the \"masked language model\".} task. The well\ntrained conditional BERT can be applied to enhance contextual augmentation.\nExperiments on six various different text classification tasks show that our\nmethod can be easily applied to both convolutional or recurrent neural networks\nclassifier to obtain obvious improvement.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 11:26:42 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Wu", "Xing", ""], ["Lv", "Shangwen", ""], ["Zang", "Liangjun", ""], ["Han", "Jizhong", ""], ["Hu", "Songlin", ""]]}, {"id": "1812.06707", "submitter": "Rakshith Shetty", "authors": "Rakshith Shetty and Bernt Schiele and Mario Fritz", "title": "Not Using the Car to See the Sidewalk: Quantifying and Controlling the\n  Effects of Context in Classification and Segmentation", "comments": "14 pages (12 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Importance of visual context in scene understanding tasks is well recognized\nin the computer vision community. However, to what extent the computer vision\nmodels for image classification and semantic segmentation are dependent on the\ncontext to make their predictions is unclear. A model overly relying on context\nwill fail when encountering objects in context distributions different from\ntraining data and hence it is important to identify these dependencies before\nwe can deploy the models in the real-world. We propose a method to quantify the\nsensitivity of black-box vision models to visual context by editing images to\nremove selected objects and measuring the response of the target models. We\napply this methodology on two tasks, image classification and semantic\nsegmentation, and discover undesirable dependency between objects and context,\nfor example that \"sidewalk\" segmentation relies heavily on \"cars\" being present\nin the image. We propose an object removal based data augmentation solution to\nmitigate this dependency and increase the robustness of classification and\nsegmentation models to contextual variations. Our experiments show that the\nproposed data augmentation helps these models improve the performance in\nout-of-context scenarios, while preserving the performance on regular data.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 11:28:05 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Shetty", "Rakshith", ""], ["Schiele", "Bernt", ""], ["Fritz", "Mario", ""]]}, {"id": "1812.06722", "submitter": "Feiliang Ren", "authors": "Feiliang Ren, Yining Hou, Yan Li, Linfeng Pan, Yi Zhang, Xiaobo Liang,\n  Yongkang Liu, Yu Guo, Rongsheng Zhao, Ruicheng Ming, Huiming Wu", "title": "TechKG: A Large-Scale Chinese Technology-Oriented Knowledge Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph is a kind of valuable knowledge base which would benefit lots\nof AI-related applications. Up to now, lots of large-scale knowledge graphs\nhave been built. However, most of them are non-Chinese and designed for general\npurpose. In this work, we introduce TechKG, a large scale Chinese knowledge\ngraph that is technology-oriented. It is built automatically from massive\ntechnical papers that are published in Chinese academic journals of different\nresearch domains. Some carefully designed heuristic rules are used to extract\nhigh quality entities and relations. Totally, it comprises of over 260 million\ntriplets that are built upon more than 52 million entities which come from 38\nresearch domains. Our preliminary ex-periments indicate that TechKG has high\nadaptability and can be used as a dataset for many diverse AI-related\napplications. We released TechKG at: http://www.techkg.cn.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 11:59:53 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Ren", "Feiliang", ""], ["Hou", "Yining", ""], ["Li", "Yan", ""], ["Pan", "Linfeng", ""], ["Zhang", "Yi", ""], ["Liang", "Xiaobo", ""], ["Liu", "Yongkang", ""], ["Guo", "Yu", ""], ["Zhao", "Rongsheng", ""], ["Ming", "Ruicheng", ""], ["Wu", "Huiming", ""]]}, {"id": "1812.06745", "submitter": "Merlin G\\\"ottlinger", "authors": "Merlin G\\\"ottlinger, Lutz Schr\\\"oder", "title": "Trichotomic Argumentation Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The Aristotelian trichotomy distinguishes three aspects of argumentation:\nLogos, Ethos, and Pathos. Even rich argumentation representations like the\nArgument Interchange Format (AIF) are only concerned with capturing the Logos\naspect. Inference Anchoring Theory (IAT) adds the possibility to represent\nethical requirements on the illocutionary force edges linking locutions to\nillocutions, thereby allowing to capture some aspects of ethos. With the recent\nextensions AIF+ and Social Argument Interchange Format (S-AIF), which embed\ndialogue and speakers into the AIF argumentation representation, the basis for\nrepresenting all three aspects identified by Aristotle was formed. In the\npresent work, we develop the Trichotomic Argument Interchange Format (T-AIF),\nbuilding on the idea from S-AIF of adding the speakers to the argumentation\ngraph. We capture Logos in the usual known from AIF+, Ethos in form of weighted\nedges between actors representing trust, and Pathos via weighted edges from\nactors to illocutions representing their level of commitment to the\npropositions. This extended structured argumentation representation opens up\nnew possibilities of defining semantic properties on this rich graph in order\nto characterize and profile the reasoning patterns of the participating actors.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 13:12:03 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["G\u00f6ttlinger", "Merlin", ""], ["Schr\u00f6der", "Lutz", ""]]}, {"id": "1812.06791", "submitter": "Nathalia Moraes do Nascimento", "authors": "Nathalia Nascimento, Paulo Alencar, Carlos Lucena and Donald Cowan", "title": "An IoT Analytics Embodied Agent Model based on Context-Aware Machine\n  Learning", "comments": "6 pages. arXiv admin note: substantial text overlap with\n  arXiv:1802.03858", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agent-based Internet of Things (IoT) applications have recently emerged as\napplications that can involve sensors, wireless devices, machines and software\nthat can exchange data and be accessed remotely. Such applications have been\nproposed in several domains including health care, smart cities and\nagriculture. However, despite their increased adoption, deploying these\napplications in specific settings has been very challenging because of the\ncomplex static and dynamic variability of the physical devices such as sensors\nand actuators, the software application behavior and the environment in which\nthe application is embedded. In this paper, we propose a modeling approach for\nIoT analytics based on learning embodied agents (i.e. situated agents). The\napproach involves: (i) a variability model of IoT embodied agents; (ii)\nfeedback evaluative machine learning; and (iii) reconfiguration of a group of\nagents in accordance with environmental context. The proposed approach advances\nthe state of the art in that it facilitates the development of Agent-based IoT\napplications by explicitly capturing their complex and dynamic variabilities\nand supporting their self-configuration based on an context-aware and machine\nlearning-based approach.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 01:57:44 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Nascimento", "Nathalia", ""], ["Alencar", "Paulo", ""], ["Lucena", "Carlos", ""], ["Cowan", "Donald", ""]]}, {"id": "1812.06855", "submitter": "Yutian Chen", "authors": "Yutian Chen, Aja Huang, Ziyu Wang, Ioannis Antonoglou, Julian\n  Schrittwieser, David Silver, Nando de Freitas", "title": "Bayesian Optimization in AlphaGo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the development of AlphaGo, its many hyper-parameters were tuned with\nBayesian optimization multiple times. This automatic tuning process resulted in\nsubstantial improvements in playing strength. For example, prior to the match\nwith Lee Sedol, we tuned the latest AlphaGo agent and this improved its\nwin-rate from 50% to 66.5% in self-play games. This tuned version was deployed\nin the final match. Of course, since we tuned AlphaGo many times during its\ndevelopment cycle, the compounded contribution was even higher than this\npercentage. It is our hope that this brief case study will be of interest to Go\nfans, and also provide Bayesian optimization practitioners with some insights\nand inspiration.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 15:52:01 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Chen", "Yutian", ""], ["Huang", "Aja", ""], ["Wang", "Ziyu", ""], ["Antonoglou", "Ioannis", ""], ["Schrittwieser", "Julian", ""], ["Silver", "David", ""], ["de Freitas", "Nando", ""]]}, {"id": "1812.06861", "submitter": "Zhaoyang Lv", "authors": "Zhaoyang Lv, Frank Dellaert, James M. Rehg, Andreas Geiger", "title": "Taking a Deeper Look at the Inverse Compositional Algorithm", "comments": "Paper accepted at CVPR 2019, oral presentation. Code is available at\n  https://github.com/lvzhaoyang/DeeperInverseCompositionalAlgorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide a modern synthesis of the classic inverse\ncompositional algorithm for dense image alignment. We first discuss the\nassumptions made by this well-established technique, and subsequently propose\nto relax these assumptions by incorporating data-driven priors into this model.\nMore specifically, we unroll a robust version of the inverse compositional\nalgorithm and replace multiple components of this algorithm using more\nexpressive models whose parameters we train in an end-to-end fashion from data.\nOur experiments on several challenging 3D rigid motion estimation tasks\ndemonstrate the advantages of combining optimization with learning-based\ntechniques, outperforming the classic inverse compositional algorithm as well\nas data-driven image-to-pose regression approaches.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 15:58:10 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2019 04:53:10 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Lv", "Zhaoyang", ""], ["Dellaert", "Frank", ""], ["Rehg", "James M.", ""], ["Geiger", "Andreas", ""]]}, {"id": "1812.06873", "submitter": "Boris Chidlovskii", "authors": "Giorgio Giannone and Boris Chidlovskii", "title": "Learning Common Representation from RGB and Depth Images", "comments": "7 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new deep learning architecture for the tasks of semantic\nsegmentation and depth prediction from RGB-D images. We revise the state of art\nbased on the RGB and depth feature fusion, where both modalities are assumed to\nbe available at train and test time. We propose a new architecture where the\nfeature fusion is replaced with a common deep representation. Combined with an\nencoder-decoder type of the network, the architecture can jointly learn models\nfor semantic segmentation and depth estimation based on their common\nrepresentation. This representation, inspired by multi-view learning, offers\nseveral important advantages, such as using one modality available at test time\nto reconstruct the missing modality. In the RGB-D case, this enables the\ncross-modality scenarios, such as using depth data for semantically\nsegmentation and the RGB images for depth estimation. We demonstrate the\neffectiveness of the proposed network on two publicly available RGB-D datasets.\nThe experimental results show that the proposed method works well in both\nsemantic segmentation and depth estimation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 16:22:47 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Giannone", "Giorgio", ""], ["Chidlovskii", "Boris", ""]]}, {"id": "1812.06905", "submitter": "Alessio Zappone", "authors": "Alessio Zappone and Luca Sanguinetti and Merouane Debbah", "title": "User Association and Load Balancing for Massive MIMO through Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates the use of deep learning to perform user cell\nassociation for sum-rate maximization in Massive MIMO networks. It is shown how\na deep neural network can be trained to approach the optimal association rule\nwith a much more limited computational complexity, thus enabling to update the\nassociation rule in real-time, on the basis of the mobility patterns of users.\nIn particular, the proposed neural network design requires as input only the\nusers' geographical positions. Numerical results show that it guarantees the\nsame performance of traditional optimization-oriented methods.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 17:26:16 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Zappone", "Alessio", ""], ["Sanguinetti", "Luca", ""], ["Debbah", "Merouane", ""]]}, {"id": "1812.06920", "submitter": "Bho Matthiesen", "authors": "Bho Matthiesen, Alessio Zappone, Karl-L. Besser, Eduard A. Jorswieck,\n  Merouane Debbah", "title": "A Globally Optimal Energy-Efficient Power Control Framework and its\n  Efficient Implementation in Wireless Interference Networks", "comments": "submitted", "journal-ref": "IEEE Transactions on Signal Processing, Vol. 68, pp. 3887-3902,\n  Jun. 2020", "doi": "10.1109/TSP.2020.3000328", "report-no": null, "categories": "cs.IT cs.AI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work develops a novel power control framework for energy-efficient power\ncontrol in wireless networks. The proposed method is a new branch-and-bound\nprocedure based on problem-specific bounds for energy-efficiency maximization\nthat allow for faster convergence. This enables to find the global solution for\nall of the most common energy-efficient power control problems with a\ncomplexity that, although still exponential in the number of variables, is much\nlower than other available global optimization frameworks. Moreover, the\nreduced complexity of the proposed framework allows its practical\nimplementation through the use of deep neural networks. Specifically, thanks to\nits reduced complexity, the proposed method can be used to train an artificial\nneural network to predict the optimal resource allocation. This is in contrast\nwith other power control methods based on deep learning, which train the neural\nnetwork based on suboptimal power allocations due to the large complexity that\ngenerating large training sets of optimal power allocations would have with\navailable global optimization methods. As a benchmark, we also develop a novel\nfirst-order optimal power allocation algorithm. Numerical results show that a\nneural network can be trained to predict the optimal power allocation policy.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 17:42:25 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 18:49:03 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Matthiesen", "Bho", ""], ["Zappone", "Alessio", ""], ["Besser", "Karl-L.", ""], ["Jorswieck", "Eduard A.", ""], ["Debbah", "Merouane", ""]]}, {"id": "1812.06934", "submitter": "Ana Maria Barragan Montero Dr", "authors": "Ana M. Barragan-Montero, Dan Nguyen, Weiguo Lu, Mu-Han Lin, Xavier\n  Geets, Edmond Sterpin, and Steve Jiang", "title": "Three-Dimensional Dose Prediction for Lung IMRT Patients with Deep\n  Neural Networks: Robust Learning from Heterogeneous Beam Configurations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of neural networks to directly predict three-dimensional dose\ndistributions for automatic planning is becoming popular. However, the existing\nmethods only use patient anatomy as input and assume consistent beam\nconfiguration for all patients in the training database. The purpose of this\nwork is to develop a more general model that, in addition to patient anatomy,\nalso considers variable beam configurations, to achieve a more comprehensive\nautomatic planning with a potentially easier clinical implementation, without\nthe need of training specific models for different beam settings.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 18:17:12 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 16:57:31 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Barragan-Montero", "Ana M.", ""], ["Nguyen", "Dan", ""], ["Lu", "Weiguo", ""], ["Lin", "Mu-Han", ""], ["Geets", "Xavier", ""], ["Sterpin", "Edmond", ""], ["Jiang", "Steve", ""]]}, {"id": "1812.07049", "submitter": "Wenfu Wang", "authors": "Wenfu Wang, Zhijie Pan", "title": "DSNet for Real-Time Driving Scene Semantic Segmentation", "comments": "We have discovered some reported numbers unreproducible, and decided\n  to redesign the methods, and rewrite most of the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the very challenging task of semantic segmentation for autonomous\ndriving system. It must deliver decent semantic segmentation result for traffic\ncritical objects real-time. In this paper, we propose a very efficient yet\npowerful deep neural network for driving scene semantic segmentation termed as\nDriving Segmentation Network (DSNet). DSNet achieves state-of-the-art balance\nbetween accuracy and inference speed through efficient units and architecture\ndesign inspired by ShuffleNet V2 and ENet. More importantly, DSNet highlights\nclasses most critical with driving decision making through our novel Driving\nImportance-weighted Loss. We evaluate DSNet on Cityscapes dataset, our DSNet\nachieves 71.8% mean Intersection-over-Union (IoU) on validation set and 69.3%\non test set. Class-wise IoU scores show that Driving Importance-weighted Loss\ncould improve most driving critical classes by a large margin. Compared with\nENet, DSNet is 18.9% more accurate and 1.1+ times faster which implies great\npotential for autonomous driving application.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 07:59:02 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 01:57:07 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Wang", "Wenfu", ""], ["Pan", "Zhijie", ""]]}, {"id": "1812.07079", "submitter": "Emiliano Lorini", "authors": "Emiliano Lorini", "title": "Rethinking Epistemic Logic with Belief Bases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new semantics for a logic of explicit and implicit beliefs\nbased on the concept of multi-agent belief base. Differently from existing\nKripke-style semantics for epistemic logic in which the notions of possible\nworld and doxastic/epistemic alternative are primitive, in our semantics they\nare non-primitive but are defined from the concept of belief base. We provide a\ncomplete axiomatization and prove decidability for our logic via a finite model\nargument. We also provide a polynomial embedding of our logic into Fagin &\nHalpern's logic of general awareness and establish a complexity result for our\nlogic via the embedding.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 22:30:45 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Lorini", "Emiliano", ""]]}, {"id": "1812.07084", "submitter": "Glen Chou", "authors": "Glen Chou, Dmitry Berenson, Necmiye Ozay", "title": "Learning Constraints from Demonstrations", "comments": "Presented at the Workshop on the Algorithmic Foundations of Robotics\n  (WAFR), 2018, M\\'erida, Mexico", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the learning from demonstration paradigm by providing a method for\nlearning unknown constraints shared across tasks, using demonstrations of the\ntasks, their cost functions, and knowledge of the system dynamics and control\nconstraints. Given safe demonstrations, our method uses hit-and-run sampling to\nobtain lower cost, and thus unsafe, trajectories. Both safe and unsafe\ntrajectories are used to obtain a consistent representation of the unsafe set\nvia solving an integer program. Our method generalizes across system dynamics\nand learns a guaranteed subset of the constraint. We also provide theoretical\nanalysis on what subset of the constraint can be learnable from safe\ndemonstrations. We demonstrate our method on linear and nonlinear system\ndynamics, show that it can be modified to work with suboptimal demonstrations,\nand that it can also be used to learn constraints in a feature space.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 22:40:08 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 18:30:00 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Chou", "Glen", ""], ["Berenson", "Dmitry", ""], ["Ozay", "Necmiye", ""]]}, {"id": "1812.07098", "submitter": "Yosr Ghozzi", "authors": "Yosr Ghozzi, Nesrine Baklouti, Hani Hagras, Mounir Ben Ayed, and Adel\n  M. Alimi", "title": "Interval type-2 Beta Fuzzy Near set based approach to content based\n  image retrieval", "comments": "10 pages, 7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an automated search system, similarity is a key concept in solving a human\ntask. Indeed, human process is usually a natural categorization that underlies\nmany natural abilities such as image recovery, language comprehension, decision\nmaking, or pattern recognition. In the image search axis, there are several\nways to measure the similarity between images in an image database, to a query\nimage. Image search by content is based on the similarity of the visual\ncharacteristics of the images. The distance function used to evaluate the\nsimilarity between images depends on the criteria of the search but also on the\nrepresentation of the characteristics of the image; this is the main idea of\nthe near and fuzzy sets approaches. In this article, we introduce a new\ncategory of beta type-2 fuzzy sets for the description of image characteristics\nas well as the near sets approach for image recovery. Finally, we illustrate\nour work with examples of image recovery problems used in the real world.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 11:34:23 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Ghozzi", "Yosr", ""], ["Baklouti", "Nesrine", ""], ["Hagras", "Hani", ""], ["Ayed", "Mounir Ben", ""], ["Alimi", "Adel M.", ""]]}, {"id": "1812.07100", "submitter": "Avinash Kumar Singh", "authors": "Avinash Kumar Singh", "title": "On effective human robot interaction based on recognition and\n  association", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Faces play a magnificent role in human robot interaction, as they do in our\ndaily life. The inherent ability of the human mind facilitates us to recognize\na person by exploiting various challenges such as bad illumination, occlusions,\npose variation etc. which are involved in face recognition. But it is a very\ncomplex task in nature to identify a human face by humanoid robots. The recent\nliteratures on face biometric recognition are extremely rich in its application\non structured environment for solving human identification problem. But the\napplication of face biometric on mobile robotics is limited for its inability\nto produce accurate identification in uneven circumstances. The existing face\nrecognition problem has been tackled with our proposed component based\nfragmented face recognition framework. The proposed framework uses only a\nsubset of the full face such as eyes, nose and mouth to recognize a person.\nIt's less searching cost, encouraging accuracy and ability to handle various\nchallenges of face recognition offers its applicability on humanoid robots. The\nsecond problem in face recognition is the face spoofing, in which a face\nrecognition system is not able to distinguish between a person and an imposter\n(photo/video of the genuine user). The problem will become more detrimental\nwhen robots are used as an authenticator. A depth analysis method has been\ninvestigated in our research work to test the liveness of imposters to\ndiscriminate them from the legitimate users. The implication of the previous\nearned techniques has been used with respect to criminal identification with\nNAO robot. An eyewitness can interact with NAO through a user interface. NAO\nasks several questions about the suspect, such as age, height, her/his facial\nshape and size etc., and then making a guess about her/his face.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2018 11:00:13 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Singh", "Avinash Kumar", ""]]}, {"id": "1812.07104", "submitter": "Arindam Chowdhury", "authors": "Rohit Rahul, Arindam Chowdhury, Animesh, Samarth Mittal, Lovekesh Vig", "title": "Reading Industrial Inspection Sheets by Inferring Visual Relations", "comments": "Published in 3rd International Workshop on Robust Reading at Asian\n  Conference on Computer Vision 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The traditional mode of recording faults in heavy factory equipment has been\nvia hand marked inspection sheets, wherein a machine engineer manually marks\nthe faulty machine regions on a paper outline of the machine. Over the years,\nmillions of such inspection sheets have been recorded and the data within these\nsheets has remained inaccessible. However, with industries going digital and\nwaking up to the potential value of fault data for machine health monitoring,\nthere is an increased impetus towards digitization of these hand marked\ninspection records. To target this digitization, we propose a novel visual\npipeline combining state of the art deep learning models, with domain knowledge\nand low level vision techniques, followed by inference of visual relationships.\nOur framework is robust to the presence of both static and non-static\nbackground in the document, variability in the machine template diagrams,\nunstructured shape of graphical objects to be identified and variability in the\nstrokes of handwritten text. The proposed pipeline incorporates a capsule and\nspatial transformer network based classifier for accurate text reading, and a\ncustomized CTPN network for text detection in addition to hybrid techniques for\narrow detection and dialogue cloud removal. We have tested our approach on a\nreal world dataset of 50 inspection sheets for large containers and boilers.\nThe results are visually appealing and the pipeline achieved an accuracy of\n87.1% for text detection and 94.6% for text reading.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 13:10:14 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Rahul", "Rohit", ""], ["Chowdhury", "Arindam", ""], ["Animesh", "", ""], ["Mittal", "Samarth", ""], ["Vig", "Lovekesh", ""]]}, {"id": "1812.07105", "submitter": "Mrinal Haloi", "authors": "Mrinal Haloi", "title": "Towards Ophthalmologist Level Accurate Deep Learning System for OCT\n  Screening and Diagnosis", "comments": "JAMA submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose an advanced AI based grading system for OCT images.\nThe proposed system is a very deep fully convolutional attentive classification\nnetwork trained with end to end advanced transfer learning with online random\naugmentation. It uses quasi random augmentation that outputs confidence values\nfor diseases prevalence during inference. Its a fully automated retinal OCT\nanalysis AI system capable of pathological lesions understanding without any\noffline preprocessing/postprocessing step or manual feature extraction. We\npresent a state of the art performance on the publicly available Mendeley OCT\ndataset.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 14:42:10 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Haloi", "Mrinal", ""]]}, {"id": "1812.07151", "submitter": "Seongjin Choi", "authors": "Seongjin Choi, Jiwon Kim, Hwasoo Yeo", "title": "Attention-based Recurrent Neural Network for Urban Vehicle Trajectory\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing deployment of diverse positioning devices and\nlocation-based services, a huge amount of spatial and temporal information has\nbeen collected and accumulated as trajectory data. Among many applications,\ntrajectory-based location prediction is gaining increasing attention because of\nits potential to improve the performance of many applications in multiple\ndomains. This research focuses on trajectory sequence prediction methods using\ntrajectory data obtained from the vehicles in urban traffic network. As\nRecurrent Neural Network(RNN) model is previously proposed, we propose an\nimproved method of Attention-based Recurrent Neural Network model(ARNN) for\nurban vehicle trajectory prediction. We introduce attention mechanism into\nurban vehicle trajectory prediction to explain the impact of network-level\ntraffic state information. The model is evaluated using the Bluetooth data of\nprivate vehicles collected in Brisbane, Australia with 5 metrics which are\nwidely used in the sequence modeling. The proposed ARNN model shows significant\nperformance improvement compared to the existing RNN models considering not\nonly the cells to be visited but also the alignment of the cells in sequence.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 03:36:50 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 02:19:42 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Choi", "Seongjin", ""], ["Kim", "Jiwon", ""], ["Yeo", "Hwasoo", ""]]}, {"id": "1812.07172", "submitter": "Risto Vuorio", "authors": "Risto Vuorio, Shao-Hua Sun, Hexiang Hu, Joseph J. Lim", "title": "Toward Multimodal Model-Agnostic Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based meta-learners such as MAML are able to learn a meta-prior from\nsimilar tasks to adapt to novel tasks from the same distribution with few\ngradient updates. One important limitation of such frameworks is that they seek\na common initialization shared across the entire task distribution,\nsubstantially limiting the diversity of the task distributions that they are\nable to learn from. In this paper, we augment MAML with the capability to\nidentify tasks sampled from a multimodal task distribution and adapt quickly\nthrough gradient updates. Specifically, we propose a multimodal MAML algorithm\nthat is able to modulate its meta-learned prior according to the identified\ntask, allowing faster adaptation. We evaluate the proposed model on a diverse\nset of problems including regression, few-shot image classification, and\nreinforcement learning. The results demonstrate the effectiveness of our model\nin modulating the meta-learned prior in response to the characteristics of\ntasks sampled from a multimodal distribution.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 05:08:54 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Vuorio", "Risto", ""], ["Sun", "Shao-Hua", ""], ["Hu", "Hexiang", ""], ["Lim", "Joseph J.", ""]]}, {"id": "1812.07211", "submitter": "Velibor Mi\\v{s}i\\'c", "authors": "Dragos Florin Ciocan and Velibor V. Mi\\v{s}i\\'c", "title": "Interpretable Optimal Stopping", "comments": "84 pages, 25 figures; to appear in Management Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal stopping is the problem of deciding when to stop a stochastic system\nto obtain the greatest reward, arising in numerous application areas such as\nfinance, healthcare and marketing. State-of-the-art methods for\nhigh-dimensional optimal stopping involve approximating the value function or\nthe continuation value, and then using that approximation within a greedy\npolicy. Although such policies can perform very well, they are generally not\nguaranteed to be interpretable; that is, a decision maker may not be able to\neasily see the link between the current system state and the policy's action.\nIn this paper, we propose a new approach to optimal stopping, wherein the\npolicy is represented as a binary tree, in the spirit of naturally\ninterpretable tree models commonly used in machine learning. We show that the\nclass of tree policies is rich enough to approximate the optimal policy. We\nformulate the problem of learning such policies from observed trajectories of\nthe stochastic system as a sample average approximation (SAA) problem. We prove\nthat the SAA problem converges under mild conditions as the sample size\nincreases, but that computationally even immediate simplifications of the SAA\nproblem are theoretically intractable. We thus propose a tractable heuristic\nfor approximately solving the SAA problem, by greedily constructing the tree\nfrom the top down. We demonstrate the value of our approach by applying it to\nthe canonical problem of option pricing, using both synthetic instances and\ninstances using real S&P-500 data. Our method obtains policies that (1)\noutperform state-of-the-art non-interpretable methods, based on\nsimulation-regression and martingale duality, and (2) possess a remarkably\nsimple and intuitive structure.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 07:35:01 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2019 21:18:38 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Ciocan", "Dragos Florin", ""], ["Mi\u0161i\u0107", "Velibor V.", ""]]}, {"id": "1812.07297", "submitter": "Peng Peng", "authors": "Peng Peng, Liang Pang, Yufeng Yuan, Chao Gao", "title": "Continual Match Based Training in Pommerman: Technical Report", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Continual learning is the ability of agents to improve their capacities\nthroughout multiple tasks continually. While recent works in the literature of\ncontinual learning mostly focused on developing either particular loss\nfunctions or specialized structures of neural network explaining the episodic\nmemory or neural plasticity, we study continual learning from the perspective\nof the training mechanism. Specifically, we propose a COnitnual Match BAsed\nTraining (COMBAT) framework for training a population of advantage-actor-critic\n(A2C) agents in Pommerman, a partially observable multi-agent environment with\nno communication. Following the COMBAT framework, we trained an agent, namely,\nNavocado, that won the title of the top 1 learning agent in the NeurIPS 2018\nPommerman Competition. Two critical features of our agent are worth mentioning.\nFirstly, our agent did not learn from any demonstrations. Secondly, our agent\nis highly reproducible. As a technical report, we articulate the design of\nstate space, action space, reward, and most importantly, the COMBAT framework\nfor our Pommerman agent. We show in the experiments that Pommerman is a perfect\nenvironment for studying continual learning, and the agent can improve its\nperformance by continually learning new skills without forgetting the old ones.\nFinally, the result in the Pommerman Competition verifies the robustness of our\nagent when competing with various opponents.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 11:08:31 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Peng", "Peng", ""], ["Pang", "Liang", ""], ["Yuan", "Yufeng", ""], ["Gao", "Chao", ""]]}, {"id": "1812.07385", "submitter": "Arash Behboodi", "authors": "Emilio Rafael Balda, Arash Behboodi, Rudolf Mathar", "title": "Perturbation Analysis of Learning Algorithms: A Unifying Perspective on\n  Generation of Adversarial Examples", "comments": "arXiv admin note: text overlap with arXiv:1803.03607", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the tremendous success of deep neural networks in various learning\nproblems, it has been observed that adding an intentionally designed\nadversarial perturbation to inputs of these architectures leads to erroneous\nclassification with high confidence in the prediction. In this work, we propose\na general framework based on the perturbation analysis of learning algorithms\nwhich consists of convex programming and is able to recover many current\nadversarial attacks as special cases. The framework can be used to propose\nnovel attacks against learning algorithms for classification and regression\ntasks under various new constraints with closed form solutions in many\ninstances. In particular we derive new attacks against classification\nalgorithms which are shown to achieve comparable performances to notable\nexisting attacks. The framework is then used to generate adversarial\nperturbations for regression tasks which include single pixel and single subset\nattacks. By applying this method to autoencoding and image colorization tasks,\nit is shown that adversarial perturbations can effectively perturb the output\nof regression tasks as well.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2018 21:48:46 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Balda", "Emilio Rafael", ""], ["Behboodi", "Arash", ""], ["Mathar", "Rudolf", ""]]}, {"id": "1812.07441", "submitter": "Renjie Chen", "authors": "Renjie Chen and Craig Gotsman", "title": "A Scalable Heuristic for Fastest-Path Computation on Very Large Road\n  Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fastest-path queries between two points in a very large road map is an\nincreasingly important primitive in modern transportation and navigation\nsystems, thus very efficient computation of these paths is critical for system\nperformance and throughput. We present a method to compute an effective\nheuristic for the fastest path travel time between two points on a road map,\nwhich can be used to significantly accelerate the classical A* algorithm when\ncomputing fastest paths. Our method is based on two hierarchical sets of\nseparators of the map represented by two binary trees. A preprocessing step\ncomputes a short vector of values per road junction based on the separator\ntrees, which is then stored with the map and used to efficiently compute the\nheuristic at the online query stage. We demonstrate experimentally that this\nmethod scales well to any map size, providing a better quality heuristic, thus\nmore efficient A* search, for fastest path queries between points at all\ndistances - especially small and medium range - relative to other known\nheuristics.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 15:46:17 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 18:09:30 GMT"}, {"version": "v3", "created": "Fri, 4 Sep 2020 18:45:26 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Chen", "Renjie", ""], ["Gotsman", "Craig", ""]]}, {"id": "1812.07452", "submitter": "Thomas Carr", "authors": "Thomas Carr, Maria Chli, George Vogiatzis", "title": "Domain Adaptation for Reinforcement Learning on the Atari", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning agents have recently been successful across a\nvariety of discrete and continuous control tasks; however, they can be slow to\ntrain and require a large number of interactions with the environment to learn\na suitable policy. This is borne out by the fact that a reinforcement learning\nagent has no prior knowledge of the world, no pre-existing data to depend on\nand so must devote considerable time to exploration. Transfer learning can\nalleviate some of the problems by leveraging learning done on some source task\nto help learning on some target task. Our work presents an algorithm for\ninitialising the hidden feature representation of the target task. We propose a\ndomain adaptation method to transfer state representations and demonstrate\ntransfer across domains, tasks and action spaces. We utilise adversarial domain\nadaptation ideas combined with an adversarial autoencoder architecture. We\nalign our new policies' representation space with a pre-trained source policy,\ntaking target task data generated from a random policy. We demonstrate that\nthis initialisation step provides significant improvement when learning a new\nreinforcement learning task, which highlights the wide applicability of\nadversarial adaptation methods; even as the task and label/action space also\nchanges.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 16:08:57 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Carr", "Thomas", ""], ["Chli", "Maria", ""], ["Vogiatzis", "George", ""]]}, {"id": "1812.07469", "submitter": "Brad Dillman", "authors": "William W. Streilein, and Brad Dillman", "title": "Proceedings of the Artificial Intelligence for Cyber Security (AICS)\n  Workshop 2019", "comments": "AICS 2019 included 9 workshop papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume represents the proceedings of the Artificial Intelligence for\nCyber Security (AICS) Workshop 2019, held on January 27, 2019 in Honolulu,\nHawaii.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 18:51:48 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 13:54:04 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Streilein", "William W.", ""], ["Dillman", "Brad", ""]]}, {"id": "1812.07478", "submitter": "Hangyu Zhu", "authors": "Hangyu Zhu and Yaochu Jin", "title": "Multi-objective Evolutionary Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is an emerging technique used to prevent the leakage of\nprivate information. Unlike centralized learning that needs to collect data\nfrom users and store them collectively on a cloud server, federated learning\nmakes it possible to learn a global model while the data are distributed on the\nusers' devices. However, compared with the traditional centralized approach,\nthe federated setting consumes considerable communication resources of the\nclients, which is indispensable for updating global models and prevents this\ntechnique from being widely used. In this paper, we aim to optimize the\nstructure of the neural network models in federated learning using a\nmulti-objective evolutionary algorithm to simultaneously minimize the\ncommunication costs and the global model test errors. A scalable method for\nencoding network connectivity is adapted to federated learning to enhance the\nefficiency in evolving deep neural networks. Experimental results on both\nmultilayer perceptrons and convolutional neural networks indicate that the\nproposed optimization method is able to find optimized neural network models\nthat can not only significantly reduce communication costs but also improve the\nlearning performance of federated learning compared with the standard fully\nconnected neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 16:55:03 GMT"}, {"version": "v2", "created": "Sat, 8 Jun 2019 16:47:39 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Zhu", "Hangyu", ""], ["Jin", "Yaochu", ""]]}, {"id": "1812.07480", "submitter": "Ulrich Paquet", "authors": "Ulrich Paquet and Sumedh K. Ghaisas and Olivier Tieleman", "title": "A Factorial Mixture Prior for Compositional Deep Generative Models", "comments": "16 pagers, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We assume that a high-dimensional datum, like an image, is a compositional\nexpression of a set of properties, with a complicated non-linear relationship\nbetween the datum and its properties. This paper proposes a factorial mixture\nprior for capturing latent properties, thereby adding structured\ncompositionality to deep generative models. The prior treats a latent vector as\nbelonging to Cartesian product of subspaces, each of which is quantized\nseparately with a Gaussian mixture model. Some mixture components can be set to\nrepresent properties as observed random variables whenever labeled properties\nare present. Through a combination of stochastic variational inference and\ngradient descent, a method for learning how to infer discrete properties in an\nunsupervised or semi-supervised way is outlined and empirically evaluated.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 16:59:23 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Paquet", "Ulrich", ""], ["Ghaisas", "Sumedh K.", ""], ["Tieleman", "Olivier", ""]]}, {"id": "1812.07519", "submitter": "Franz J. Kir\\'aly", "authors": "Franz J Kir\\'aly and Bilal Mateen and Raphael Sonabend", "title": "NIPS - Not Even Wrong? A Systematic Review of Empirically Complete\n  Demonstrations of Algorithmic Effectiveness in the Machine Learning and\n  Artificial Intelligence Literature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: To determine the completeness of argumentative steps necessary to\nconclude effectiveness of an algorithm in a sample of current ML/AI supervised\nlearning literature.\n  Data Sources: Papers published in the Neural Information Processing Systems\n(NeurIPS, n\\'ee NIPS) journal where the official record showed a 2017 year of\npublication.\n  Eligibility Criteria: Studies reporting a (semi-)supervised model, or\npre-processing fused with (semi-)supervised models for tabular data.\n  Study Appraisal: Three reviewers applied the assessment criteria to determine\nargumentative completeness. The criteria were split into three groups,\nincluding: experiments (e.g real and/or synthetic data), baselines (e.g\nuninformed and/or state-of-art) and quantitative comparison (e.g. performance\nquantifiers with confidence intervals and formal comparison of the algorithm\nagainst baselines).\n  Results: Of the 121 eligible manuscripts (from the sample of 679 abstracts),\n99\\% used real-world data and 29\\% used synthetic data. 91\\% of manuscripts did\nnot report an uninformed baseline and 55\\% reported a state-of-art baseline.\n32\\% reported confidence intervals for performance but none provided references\nor exposition for how these were calculated. 3\\% reported formal comparisons.\n  Limitations: The use of one journal as the primary information source may not\nbe representative of all ML/AI literature. However, the NeurIPS conference is\nrecognised to be amongst the top tier concerning ML/AI studies, so it is\nreasonable to consider its corpus to be representative of high-quality\nresearch.\n  Conclusion: Using the 2017 sample of the NeurIPS supervised learning corpus\nas an indicator for the quality and trustworthiness of current ML/AI research,\nit appears that complete argumentative chains in demonstrations of algorithmic\neffectiveness are rare.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 17:32:39 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Kir\u00e1ly", "Franz J", ""], ["Mateen", "Bilal", ""], ["Sonabend", "Raphael", ""]]}, {"id": "1812.07544", "submitter": "Nikolay Nikolov", "authors": "Nikolay Nikolov, Johannes Kirschner, Felix Berkenkamp, Andreas Krause", "title": "Information-Directed Exploration for Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient exploration remains a major challenge for reinforcement learning.\nOne reason is that the variability of the returns often depends on the current\nstate and action, and is therefore heteroscedastic. Classical exploration\nstrategies such as upper confidence bound algorithms and Thompson sampling fail\nto appropriately account for heteroscedasticity, even in the bandit setting.\nMotivated by recent findings that address this issue in bandits, we propose to\nuse Information-Directed Sampling (IDS) for exploration in reinforcement\nlearning. As our main contribution, we build on recent advances in\ndistributional reinforcement learning and propose a novel, tractable\napproximation of IDS for deep Q-learning. The resulting exploration strategy\nexplicitly accounts for both parametric uncertainty and heteroscedastic\nobservation noise. We evaluate our method on Atari games and demonstrate a\nsignificant improvement over alternative approaches.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 18:20:49 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 01:10:25 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Nikolov", "Nikolay", ""], ["Kirschner", "Johannes", ""], ["Berkenkamp", "Felix", ""], ["Krause", "Andreas", ""]]}, {"id": "1812.07608", "submitter": "Haozhen Dong", "authors": "Haozhen Dong, Liang Gao, Xinyu Li, Haoran Zhong, Bing Zeng", "title": "Differential Evolution with Better and Nearest Option for Function\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential evolution(DE) is a conventional algorithm with fast convergence\nspeed. However, DE may be trapped in local optimal solution easily. Many\nresearchers devote themselves to improving DE. In our previously work, whale\nswarm algorithm have shown its strong searching performance due to its niching\nbased mutation strategy. Based on this fact, we propose a new DE algorithm\ncalled DE with Better and Nearest option (NbDE). In order to evaluate the\nperformance of NbDE, NbDE is compared with several meta-heuristic algorithms on\nnine classical benchmark test functions with different dimensions. The results\nshow that NbDE outperforms other algorithms in convergence speed and accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 02:52:02 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 00:47:46 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Dong", "Haozhen", ""], ["Gao", "Liang", ""], ["Li", "Xinyu", ""], ["Zhong", "Haoran", ""], ["Zeng", "Bing", ""]]}, {"id": "1812.07626", "submitter": "Tom Schaul", "authors": "Diana Borsa, Andr\\'e Barreto, John Quan, Daniel Mankowitz, R\\'emi\n  Munos, Hado van Hasselt, David Silver, Tom Schaul", "title": "Universal Successor Features Approximators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of a reinforcement learning (RL) agent to learn about many reward\nfunctions at the same time has many potential benefits, such as the\ndecomposition of complex tasks into simpler ones, the exchange of information\nbetween tasks, and the reuse of skills. We focus on one aspect in particular,\nnamely the ability to generalise to unseen tasks. Parametric generalisation\nrelies on the interpolation power of a function approximator that is given the\ntask description as input; one of its most common form are universal value\nfunction approximators (UVFAs). Another way to generalise to new tasks is to\nexploit structure in the RL problem itself. Generalised policy improvement\n(GPI) combines solutions of previous tasks into a policy for the unseen task;\nthis relies on instantaneous policy evaluation of old policies under the new\nreward function, which is made possible through successor features (SFs). Our\nproposed universal successor features approximators (USFAs) combine the\nadvantages of all of these, namely the scalability of UVFAs, the instant\ninference of SFs, and the strong generalisation of GPI. We discuss the\nchallenges involved in training a USFA, its generalisation properties and\ndemonstrate its practical benefits and transfer abilities on a large-scale\ndomain in which the agent has to navigate in a first-person perspective\nthree-dimensional environment.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 20:01:41 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Borsa", "Diana", ""], ["Barreto", "Andr\u00e9", ""], ["Quan", "John", ""], ["Mankowitz", "Daniel", ""], ["Munos", "R\u00e9mi", ""], ["van Hasselt", "Hado", ""], ["Silver", "David", ""], ["Schaul", "Tom", ""]]}, {"id": "1812.07627", "submitter": "Kian Kenyon-Dean", "authors": "Kian Kenyon-Dean, Andre Cianflone, Lucas Page-Caccia, Guillaume\n  Rabusseau, Jackie Chi Kit Cheung, Doina Precup", "title": "Clustering-Oriented Representation Learning with Attractive-Repulsive\n  Loss", "comments": "AAAI 2019 Workshop on Network Interpretability for Deep Learning (9\n  pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard loss function used to train neural network classifiers,\ncategorical cross-entropy (CCE), seeks to maximize accuracy on the training\ndata; building useful representations is not a necessary byproduct of this\nobjective. In this work, we propose clustering-oriented representation learning\n(COREL) as an alternative to CCE in the context of a generalized\nattractive-repulsive loss framework. COREL has the consequence of building\nlatent representations that collectively exhibit the quality of natural\nclustering within the latent space of the final hidden layer, according to a\npredefined similarity function. Despite being simple to implement, COREL\nvariants outperform or perform equivalently to CCE in a variety of scenarios,\nincluding image and news article classification using both feed-forward and\nconvolutional neural networks. Analysis of the latent spaces created with\ndifferent similarity functions facilitates insights on the different use cases\nCOREL variants can satisfy, where the Cosine-COREL variant makes a consistently\nclusterable latent space, while Gaussian-COREL consistently obtains better\nclassification accuracy than CCE.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 20:07:56 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Kenyon-Dean", "Kian", ""], ["Cianflone", "Andre", ""], ["Page-Caccia", "Lucas", ""], ["Rabusseau", "Guillaume", ""], ["Cheung", "Jackie Chi Kit", ""], ["Precup", "Doina", ""]]}, {"id": "1812.07671", "submitter": "Anusha Nagabandi", "authors": "Anusha Nagabandi, Chelsea Finn, Sergey Levine", "title": "Deep Online Learning via Meta-Learning: Continual Adaptation for\n  Model-Based RL", "comments": "Project website: https://sites.google.com/berkeley.edu/onlineviameta", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans and animals can learn complex predictive models that allow them to\naccurately and reliably reason about real-world phenomena, and they can adapt\nsuch models extremely quickly in the face of unexpected changes. Deep neural\nnetwork models allow us to represent very complex functions, but lack this\ncapacity for rapid online adaptation. The goal in this paper is to develop a\nmethod for continual online learning from an incoming stream of data, using\ndeep neural network models. We formulate an online learning procedure that uses\nstochastic gradient descent to update model parameters, and an expectation\nmaximization algorithm with a Chinese restaurant process prior to develop and\nmaintain a mixture of models to handle non-stationary task distributions. This\nallows for all models to be adapted as necessary, with new models instantiated\nfor task changes and old models recalled when previously seen tasks are\nencountered again. Furthermore, we observe that meta-learning can be used to\nmeta-train a model such that this direct online adaptation with SGD is\neffective, which is otherwise not the case for large function approximators. In\nthis work, we apply our meta-learning for online learning (MOLe) approach to\nmodel-based reinforcement learning, where adapting the predictive model is\ncritical for control; we demonstrate that MOLe outperforms alternative prior\nmethods, and enables effective continuous adaptation in non-stationary task\ndistributions such as varying terrains, motor failures, and unexpected\ndisturbances.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 22:27:31 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 19:11:23 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Nagabandi", "Anusha", ""], ["Finn", "Chelsea", ""], ["Levine", "Sergey", ""]]}, {"id": "1812.07887", "submitter": "Bin Wu", "authors": "Bin Wu, Qiang Fu, Jing Liang, Peng Qu, Xiaoqian Li, Liang Wang, Wei\n  Liu, Wei Yang, Yongsheng Liu", "title": "Hierarchical Macro Strategy Model for MOBA Game AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The next challenge of game AI lies in Real Time Strategy (RTS) games. RTS\ngames provide partially observable gaming environments, where agents interact\nwith one another in an action space much larger than that of GO. Mastering RTS\ngames requires both strong macro strategies and delicate micro level execution.\nRecently, great progress has been made in micro level execution, while complete\nsolutions for macro strategies are still lacking. In this paper, we propose a\nnovel learning-based Hierarchical Macro Strategy model for mastering MOBA\ngames, a sub-genre of RTS games. Trained by the Hierarchical Macro Strategy\nmodel, agents explicitly make macro strategy decisions and further guide their\nmicro level execution. Moreover, each of the agents makes independent strategy\ndecisions, while simultaneously communicating with the allies through\nleveraging a novel imitated cross-agent communication mechanism. We perform\ncomprehensive evaluations on a popular 5v5 Multiplayer Online Battle Arena\n(MOBA) game. Our 5-AI team achieves a 48% winning rate against human player\nteams which are ranked top 1% in the player ranking system.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 11:32:46 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Wu", "Bin", ""], ["Fu", "Qiang", ""], ["Liang", "Jing", ""], ["Qu", "Peng", ""], ["Li", "Xiaoqian", ""], ["Wang", "Liang", ""], ["Liu", "Wei", ""], ["Yang", "Wei", ""], ["Liu", "Yongsheng", ""]]}, {"id": "1812.07895", "submitter": "Mirko Polato", "authors": "Mirko Polato and Fabio Aiolli", "title": "Interpretable preference learning: a game theoretic framework for large\n  margin on-line feature and rule learning", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large body of research is currently investigating on the connection between\nmachine learning and game theory. In this work, game theory notions are\ninjected into a preference learning framework. Specifically, a preference\nlearning problem is seen as a two-players zero-sum game. An algorithm is\nproposed to incrementally include new useful features into the hypothesis. This\ncan be particularly important when dealing with a very large number of\npotential features like, for instance, in relational learning and rule\nextraction. A game theoretical analysis is used to demonstrate the convergence\nof the algorithm. Furthermore, leveraging on the natural analogy between\nfeatures and rules, the resulting models can be easily interpreted by humans.\nAn extensive set of experiments on classification tasks shows the effectiveness\nof the proposed method in terms of interpretability and feature selection\nquality, with accuracy at the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 11:58:19 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Polato", "Mirko", ""], ["Aiolli", "Fabio", ""]]}, {"id": "1812.07903", "submitter": "Paul Pu Liang", "authors": "Hui Han Chin, Paul Pu Liang", "title": "An Empirical Evaluation of Sketched SVD and its Application to Leverage\n  Score Ordering", "comments": "ACML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The power of randomized algorithms in numerical methods have led to fast\nsolutions which use the Singular Value Decomposition (SVD) as a core routine.\nHowever, given the large data size of modern and the modest runtime of SVD,\nmost practical algorithms would require some form of approximation, such as\nsketching, when running SVD. While these approximation methods satisfy many\ntheoretical guarantees, we provide the first algorithmic implementations for\nsketch-and-solve SVD problems on real-world, large-scale datasets. We provide a\ncomprehensive empirical evaluation of these algorithms and provide guidelines\non how to ensure accurate deployment to real-world data. As an application of\nsketched SVD, we present Sketched Leverage Score Ordering, a technique for\ndetermining the ordering of data in the training of neural networks. Our\ntechnique is based on the distributed computation of leverage scores using\nrandom projections. These computed leverage scores provide a flexible and\nefficient method to determine the optimal ordering of training data without\nmanual intervention or annotations. We present empirical results on an\nextensive set of experiments across image classification, language sentiment\nanalysis, and multi-modal sentiment analysis. Our method is faster compared to\nstandard randomized projection algorithms and shows improvements in convergence\nand results.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 12:06:58 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Chin", "Hui Han", ""], ["Liang", "Paul Pu", ""]]}, {"id": "1812.07909", "submitter": "Paul Rubenstein", "authors": "Paul K. Rubenstein, Yunpeng Li, Dominik Roblek", "title": "An Empirical Study of Generative Models with Encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are capable of producing high quality\nimage samples. However, unlike variational autoencoders (VAEs), GANs lack\nencoders that provide the inverse mapping for the generators, i.e., encode\nimages back to the latent space. In this work, we consider adversarially\nlearned generative models that also have encoders. We evaluate models based on\ntheir ability to produce high quality samples and reconstructions of real\nimages. Our main contributions are twofold: First, we find that the baseline\nBidirectional GAN (BiGAN) can be improved upon with the addition of an\nautoencoder loss, at the expense of an extra hyper-parameter to tune. Second,\nwe show that comparable performance to BiGAN can be obtained by simply training\nan encoder to invert the generator of a normal GAN.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 12:28:47 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Rubenstein", "Paul K.", ""], ["Li", "Yunpeng", ""], ["Roblek", "Dominik", ""]]}, {"id": "1812.07995", "submitter": "Yesmina Jaafra", "authors": "Yesmina Jaafra, Jean Luc Laurent, Aline Deruyver, Mohamed Saber Naceur", "title": "A Review of Meta-Reinforcement Learning for Deep Neural Networks\n  Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural networks are efficient and flexible models that perform well for\na variety of tasks such as image, speech recognition and natural language\nunderstanding. In particular, convolutional neural networks (CNN) generate a\nkeen interest among researchers in computer vision and more specifically in\nclassification tasks. CNN architecture and related hyperparameters are\ngenerally correlated to the nature of the processed task as the network\nextracts complex and relevant characteristics allowing the optimal convergence.\nDesigning such architectures requires significant human expertise, substantial\ncomputation time and doesn't always lead to the optimal network. Model\nconfiguration topic has been extensively studied in machine learning without\nleading to a standard automatic method. This survey focuses on reviewing and\ndiscussing the current progress in automating CNN architecture search.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 22:33:45 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Jaafra", "Yesmina", ""], ["Laurent", "Jean Luc", ""], ["Deruyver", "Aline", ""], ["Naceur", "Mohamed Saber", ""]]}, {"id": "1812.08039", "submitter": "Gabriel Marzinotto", "authors": "Gabriel Marzinotto (TALEP), Jeremy Auguste (TALEP), Frederic Bechet\n  (LIF), G\\'eraldine Damnati (FTR\\&D), Alexis Nasr (LIF)", "title": "Semantic Frame Parsing for Information Extraction : the CALOR corpus", "comments": null, "journal-ref": "LREC2018, May 2018, Miyazaki, France", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a publicly available corpus of French encyclopedic\nhistory texts annotated according to the Berkeley FrameNet formalism. The main\ndifference in our approach compared to previous works on semantic parsing with\nFrameNet is that we are not interested here in full text parsing but rather on\npartial parsing. The goal is to select from the FrameNet resources the minimal\nset of frames that are going to be useful for the applicative framework\ntargeted, in our case Information Extraction from encyclopedic documents. Such\nan approach leverages the manual annotation of larger corpora than those\nobtained through full text parsing and therefore opens the door to alternative\nmethods for Frame parsing than those used so far on the FrameNet 1.5 benchmark\ncorpus. The approaches compared in this study rely on an integrated sequence\nlabeling model which jointly optimizes frame identification and semantic role\nsegmentation and identification. The models compared are CRFs and multitasks\nbi-LSTMs.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 15:54:41 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Marzinotto", "Gabriel", "", "TALEP"], ["Auguste", "Jeremy", "", "TALEP"], ["Bechet", "Frederic", "", "LIF"], ["Damnati", "G\u00e9raldine", "", "FTR\\&D"], ["Nasr", "Alexis", "", "LIF"]]}, {"id": "1812.08094", "submitter": "Fangwen Tu", "authors": "Fangwen Tu, Shuzhi Sam Ge and Chang Chieh Hang", "title": "Shallow Cue Guided Deep Visual Tracking via Mixed Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, a robust visual tracking approach via mixed model based\nconvolutional neural networks (SDT) is developed. In order to handle abrupt or\nfast motion, a prior map is generated to facilitate the localization of region\nof interest (ROI) before the deep tracker is performed. A top-down saliency\nmodel with nineteen shallow cues are employed to construct the prior map with\nonline learnt combination weights. Moreover, apart from a holistic deep\nlearner, four local networks are also trained to learn different components of\nthe target. The generated four local heat maps will facilitate to rectify the\nholistic map by eliminating the distracters to avoid drifting. Furthermore, to\nguarantee the instance for online update of high quality, a prioritised update\nstrategy is implemented by casting the problem into a label noise problem. The\nselection probability is designed by considering both confidence values and\nbio-inspired memory for temporal information integration. Experiments are\nconducted qualitatively and quantitatively on a set of challenging image\nsequences. Comparative study demonstrates that the proposed algorithm\noutperforms other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 17:13:20 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Tu", "Fangwen", ""], ["Ge", "Shuzhi Sam", ""], ["Hang", "Chang Chieh", ""]]}, {"id": "1812.08237", "submitter": "Huadong Wang", "authors": "Yong Shi, Huadong Wang, Xin Shen, Lingfeng Niu", "title": "A Novel Large-scale Ordinal Regression Model", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ordinal regression (OR) is a special multiclass classification problem where\nan order relation exists among the labels. Recent years, people share their\nopinions and sentimental judgments conveniently with social networks and\nE-Commerce so that plentiful large-scale OR problems arise. However, few\nstudies have focused on this kind of problems. Nonparallel Support Vector\nOrdinal Regression (NPSVOR) is a SVM-based OR model, which learns a hyperplane\nfor each rank by solving a series of independent sub-optimization problems and\nthen ensembles those learned hyperplanes to predict. The previous studies are\nfocused on its nonlinear case and got a competitive testing performance, but\nits training is time consuming, particularly for large-scale data. In this\npaper, we consider NPSVOR's linear case and design an efficient training method\nbased on the dual coordinate descent method (DCD). To utilize the order\ninformation among labels in prediction, a new prediction function is also\nproposed. Extensive contrast experiments on the text OR datasets indicate that\nthe carefully implemented DCD is very suitable for training large data.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 20:53:24 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Shi", "Yong", ""], ["Wang", "Huadong", ""], ["Shen", "Xin", ""], ["Niu", "Lingfeng", ""]]}, {"id": "1812.08301", "submitter": "Xiaofan Xu", "authors": "Mi Sun Park, Xiaofan Xu, Cormac Brick", "title": "SQuantizer: Simultaneous Learning for Both Sparse and Low-precision\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have achieved state-of-the-art accuracies in a wide\nrange of computer vision, speech recognition, and machine translation tasks.\nHowever the limits of memory bandwidth and computational power constrain the\nrange of devices capable of deploying these modern networks. To address this\nproblem, we propose SQuantizer, a new training method that jointly optimizes\nfor both sparse and low-precision neural networks while maintaining high\naccuracy and providing a high compression rate. This approach brings\nsparsification and low-bit quantization into a single training pass, employing\nthese techniques in an order demonstrated to be optimal. Our method achieves\nstate-of-the-art accuracies using 4-bit and 2-bit precision for ResNet18,\nMobileNet-v2 and ResNet50, even with high degree of sparsity. The compression\nrates of 18x for ResNet18 and 17x for ResNet50, and 9x for MobileNet-v2 are\nobtained when SQuantizing both weights and activations within 1% and 2% loss in\naccuracy for ResNets and MobileNet-v2 respectively. An extension of these\ntechniques to object detection also demonstrates high accuracy on YOLO-v3.\nAdditionally, our method allows for fast single pass training, which is\nimportant for rapid prototyping and neural architecture search techniques.\nFinally extensive results from this simultaneous training approach allows us to\ndraw some useful insights into the relative merits of sparsity and\nquantization.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 00:55:55 GMT"}, {"version": "v2", "created": "Sat, 23 Mar 2019 20:47:47 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Park", "Mi Sun", ""], ["Xu", "Xiaofan", ""], ["Brick", "Cormac", ""]]}, {"id": "1812.08313", "submitter": "Dan Guralnik", "authors": "Dan P. Guralnik and Daniel E. Koditschek", "title": "Iterated Belief Revision Under Resource Constraints: Logic as Geometry", "comments": "Preprint, 58 pages including appendices, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DM cs.LG math.MG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We propose a variant of iterated belief revision designed for settings with\nlimited computational resources, such as mobile autonomous robots. The proposed\nmemory architecture---called the {\\em universal memory architecture}\n(UMA)---maintains an epistemic state in the form of a system of default rules\nsimilar to those studied by Pearl and by Goldszmidt and Pearl (systems $Z$ and\n$Z^+$). A duality between the category of UMA representations and the category\nof the corresponding model spaces, extending the Sageev-Roller duality between\ndiscrete poc sets and discrete median algebras provides a two-way dictionary\nfrom inference to geometry, leading to immense savings in computation, at a\ncost in the quality of representation that can be quantified in terms of\ntopological invariants. Moreover, the same framework naturally enables\ncomparisons between different model spaces, making it possible to analyze the\ndeficiencies of one model space in comparison to others. This paper develops\nthe formalism underlying UMA, analyzes the complexity of maintenance and\ninference operations in UMA, and presents some learning guarantees for\ndifferent UMA-based learners. Finally, we present simulation results to\nillustrate the viability of the approach, and close with a discussion of the\nstrengths, weaknesses, and potential development of UMA-based learners.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 01:58:04 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Guralnik", "Dan P.", ""], ["Koditschek", "Daniel E.", ""]]}, {"id": "1812.08342", "submitter": "Xiaowei Huang", "authors": "Xiaowei Huang and Daniel Kroening and Wenjie Ruan and James Sharp and\n  Youcheng Sun and Emese Thamo and Min Wu and Xinping Yi", "title": "A Survey of Safety and Trustworthiness of Deep Neural Networks:\n  Verification, Testing, Adversarial Attack and Defence, and Interpretability", "comments": "To appear in the journal of Computer Science Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, significant progress has been made on deep neural\nnetworks (DNNs) in achieving human-level performance on several long-standing\ntasks. With the broader deployment of DNNs on various applications, the\nconcerns over their safety and trustworthiness have been raised in public,\nespecially after the widely reported fatal incidents involving self-driving\ncars. Research to address these concerns is particularly active, with a\nsignificant number of papers released in the past few years. This survey paper\nconducts a review of the current research effort into making DNNs safe and\ntrustworthy, by focusing on four aspects: verification, testing, adversarial\nattack and defence, and interpretability. In total, we survey 202 papers, most\nof which were published after 2017.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 01:17:32 GMT"}, {"version": "v2", "created": "Wed, 26 Dec 2018 21:26:58 GMT"}, {"version": "v3", "created": "Fri, 18 Jan 2019 13:30:23 GMT"}, {"version": "v4", "created": "Fri, 26 Jul 2019 18:25:01 GMT"}, {"version": "v5", "created": "Sun, 31 May 2020 13:30:23 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Huang", "Xiaowei", ""], ["Kroening", "Daniel", ""], ["Ruan", "Wenjie", ""], ["Sharp", "James", ""], ["Sun", "Youcheng", ""], ["Thamo", "Emese", ""], ["Wu", "Min", ""], ["Yi", "Xinping", ""]]}, {"id": "1812.08352", "submitter": "Yu Cheng", "authors": "Yu Cheng, Zhe Gan, Yitong Li, Jingjing Liu, Jianfeng Gao", "title": "Sequential Attention GAN for Interactive Image Editing", "comments": "ACM MM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing text-to-image synthesis tasks are static single-turn\ngeneration, based on pre-defined textual descriptions of images. To explore\nmore practical and interactive real-life applications, we introduce a new task\n- Interactive Image Editing, where users can guide an agent to edit images via\nmulti-turn textual commands on-the-fly. In each session, the agent takes a\nnatural language description from the user as the input and modifies the image\ngenerated in the previous turn to a new design, following the user description.\nThe main challenges in this sequential and interactive image generation task\nare two-fold: 1) contextual consistency between a generated image and the\nprovided textual description; 2) step-by-step region-level modification to\nmaintain visual consistency across the generated image sequence in each\nsession. To address these challenges, we propose a novel Sequential Attention\nGenerative Adversarial Net-work (SeqAttnGAN), which applies a neural state\ntracker to encode the previous image and the textual description in each turn\nof the sequence, and uses a GAN framework to generate a modified version of the\nimage that is consistent with the preceding images and coherent with the\ndescription. To achieve better region-specific refinement, we also introduce a\nsequential attention mechanism into the model. To benchmark on the new task, we\nintroduce two new datasets, Zap-Seq and DeepFashion-Seq, which contain\nmulti-turn sessions with image-description sequences in the fashion domain.\nExperiments on both datasets show that the proposed SeqAttnGANmodel outperforms\nstate-of-the-art approaches on the interactive image editing task across all\nevaluation metrics including visual quality, image sequence coherence, and\ntext-image consistency.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 03:55:33 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 00:32:27 GMT"}, {"version": "v3", "created": "Sun, 8 Sep 2019 19:06:18 GMT"}, {"version": "v4", "created": "Wed, 5 Aug 2020 22:13:20 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Cheng", "Yu", ""], ["Gan", "Zhe", ""], ["Li", "Yitong", ""], ["Liu", "Jingjing", ""], ["Gao", "Jianfeng", ""]]}, {"id": "1812.08389", "submitter": "Shandong Dong", "authors": "Zhang Rong, Dong Shandong, Nie Xin, Xiao Shiguang", "title": "Feedforward Neural Network for Time Series Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series anomaly detection is usually formulated as finding outlier data\npoints relative to some usual data, which is also an important problem in\nindustry and academia. To ensure systems working stably, internet companies,\nbanks and other companies need to monitor time series, which is called KPI (Key\nPerformance Indicators), such as CPU used, number of orders, number of online\nusers and so on. However, millions of time series have several shapes (e.g.\nseasonal KPIs, KPIs of timed tasks and KPIs of CPU used), so that it is very\ndifficult to use a simple statistical model to detect anomaly for all kinds of\ntime series. Although some anomaly detectors have developed many years and some\nsupervised models are also available in this field, we find many methods have\ntheir own disadvantages. In this paper, we present our system, which is based\non deep feedforward neural network and detect anomaly points of time series.\nThe main difference between our system and other systems based on supervised\nmodels is that we do not need feature engineering of time series to train deep\nfeedforward neural network in our system, which is essentially an end-to-end\nsystem.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 07:11:11 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 01:28:14 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Rong", "Zhang", ""], ["Shandong", "Dong", ""], ["Xin", "Nie", ""], ["Shiguang", "Xiao", ""]]}, {"id": "1812.08390", "submitter": "Giora Alexandron", "authors": "Tanya Nazaretsky and Sara Hershkovitz and Giora Alexandron", "title": "Kappa Learning: A New Method for Measuring Similarity Between\n  Educational Items Using Performance Data", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequencing items in adaptive learning systems typically relies on a large\npool of interactive assessment items (questions) that are analyzed into a\nhierarchy of skills or Knowledge Components (KCs). Educational data mining\ntechniques can be used to analyze students performance data in order to\noptimize the mapping of items to KCs. Standard methods that map items into KCs\nusing item-similarity measures make the implicit assumption that students\nperformance on items that depend on the same skill should be similar. This\nassumption holds if the latent trait (mastery of the underlying skill) is\nrelatively fixed during students activity, as in the context of testing, which\nis the primary context in which these measures were developed and applied.\nHowever, in adaptive learning systems that aim for learning, and address\nsubject matters such as K6 Math that consist of multiple sub-skills, this\nassumption does not hold. In this paper we propose a new item-similarity\nmeasure, termed Kappa Learning (KL), which aims to address this gap. KL\nidentifies similarity between items under the assumption of learning, namely,\nthat learners mastery of the underlying skills changes as they progress through\nthe items. We evaluate Kappa Learning on data from a computerized tutor that\nteaches Fractions for 4th grade, with experts tagging as ground truth, and on\nsimulated data. Our results show that clustering that is based on Kappa\nLearning outperforms clustering that is based on commonly used similarity\nmeasures (Cohen Kappa, Yule, and Pearson).\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 07:12:45 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Nazaretsky", "Tanya", ""], ["Hershkovitz", "Sara", ""], ["Alexandron", "Giora", ""]]}, {"id": "1812.08425", "submitter": "Denys Katerenchuk", "authors": "Denys Katerenchuk", "title": "A Survey of Hierarchy Identification in Social Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Humans are social by nature. Throughout history, people have formed\ncommunities and built relationships. Most relationships with coworkers,\nfriends, and family are developed during face-to-face interactions. These\nrelationships are established through explicit means of communications such as\nwords and implicit such as intonation, body language, etc. By analyzing human\ninteractions we can derive information about the relationships and influence\namong conversation participants. However, with the development of the Internet,\npeople started to communicate through text in online social networks.\nInterestingly, they brought their communicational habits to the Internet. Many\nsocial network users form relationships with each other and establish\ncommunities with leaders and followers. Recognizing these hierarchical\nrelationships is an important task because it will help to understand social\nnetworks and predict future trends, improve recommendations, better target\nadvertisement, and improve national security by identifying leaders of\nanonymous terror groups. In this work, I provide an overview of current\nresearch in this area and present the state-of-the-art approaches to deal with\nthe problem of identifying hierarchical relationships in social networks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 08:56:52 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Katerenchuk", "Denys", ""]]}, {"id": "1812.08434", "submitter": "Jie Zhou", "authors": "Jie Zhou, Ganqu Cui, Shengding Hu, Zhengyan Zhang, Cheng Yang, Zhiyuan\n  Liu, Lifeng Wang, Changcheng Li, Maosong Sun", "title": "Graph Neural Networks: A Review of Methods and Applications", "comments": "Published at AI Open 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lots of learning tasks require dealing with graph data which contains rich\nrelation information among elements. Modeling physics systems, learning\nmolecular fingerprints, predicting protein interface, and classifying diseases\ndemand a model to learn from graph inputs. In other domains such as learning\nfrom non-structural data like texts and images, reasoning on extracted\nstructures (like the dependency trees of sentences and the scene graphs of\nimages) is an important research topic which also needs graph reasoning models.\nGraph neural networks (GNNs) are neural models that capture the dependence of\ngraphs via message passing between the nodes of graphs. In recent years,\nvariants of GNNs such as graph convolutional network (GCN), graph attention\nnetwork (GAT), graph recurrent network (GRN) have demonstrated ground-breaking\nperformances on many deep learning tasks. In this survey, we propose a general\ndesign pipeline for GNN models and discuss the variants of each component,\nsystematically categorize the applications, and propose four open problems for\nfuture research.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 09:30:12 GMT"}, {"version": "v2", "created": "Wed, 2 Jan 2019 02:01:05 GMT"}, {"version": "v3", "created": "Thu, 7 Mar 2019 09:08:03 GMT"}, {"version": "v4", "created": "Wed, 10 Jul 2019 14:50:01 GMT"}, {"version": "v5", "created": "Fri, 9 Apr 2021 07:27:34 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Zhou", "Jie", ""], ["Cui", "Ganqu", ""], ["Hu", "Shengding", ""], ["Zhang", "Zhengyan", ""], ["Yang", "Cheng", ""], ["Liu", "Zhiyuan", ""], ["Wang", "Lifeng", ""], ["Li", "Changcheng", ""], ["Sun", "Maosong", ""]]}, {"id": "1812.08451", "submitter": "Hendrik Poulsen Nautrup", "authors": "Hendrik Poulsen Nautrup, Nicolas Delfosse, Vedran Dunjko, Hans J.\n  Briegel, Nicolai Friis", "title": "Optimizing Quantum Error Correction Codes with Reinforcement Learning", "comments": "21 pages, 13 figures, 1 table, updated reference list, accepted for\n  publication in Quantum", "journal-ref": "Quantum 3, 215 (2019)", "doi": "10.22331/q-2019-12-16-215", "report-no": null, "categories": "quant-ph cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Quantum error correction is widely thought to be the key to fault-tolerant\nquantum computation. However, determining the most suited encoding for unknown\nerror channels or specific laboratory setups is highly challenging. Here, we\npresent a reinforcement learning framework for optimizing and fault-tolerantly\nadapting quantum error correction codes. We consider a reinforcement learning\nagent tasked with modifying a family of surface code quantum memories until a\ndesired logical error rate is reached. Using efficient simulations with about\n70 data qubits with arbitrary connectivity, we demonstrate that such a\nreinforcement learning agent can determine near-optimal solutions, in terms of\nthe number of data qubits, for various error models of interest. Moreover, we\nshow that agents trained on one setting are able to successfully transfer their\nexperience to different settings. This ability for transfer learning showcases\nthe inherent strengths of reinforcement learning and the applicability of our\napproach for optimization from off-line simulations to on-line laboratory\nsettings.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 09:54:05 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2019 12:33:10 GMT"}, {"version": "v3", "created": "Tue, 10 Dec 2019 14:20:14 GMT"}, {"version": "v4", "created": "Fri, 13 Dec 2019 14:35:12 GMT"}, {"version": "v5", "created": "Thu, 9 Apr 2020 17:09:51 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Nautrup", "Hendrik Poulsen", ""], ["Delfosse", "Nicolas", ""], ["Dunjko", "Vedran", ""], ["Briegel", "Hans J.", ""], ["Friis", "Nicolai", ""]]}, {"id": "1812.08586", "submitter": "Zhonghua Han", "authors": "Zhonghua Han, Quan Zhang, Haibo Shi, Yuanwei Qi, Liangliang Sun", "title": "Research on Limited Buffer Scheduling Problems in Flexible Flow Shops\n  with Setup Times", "comments": "Accepted for publication by International Journal of Modelling,\n  Identification and Control (IJMIC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to solve the limited buffer scheduling problems in flexible flow\nshops with setup times, this paper proposes an improved whale optimization\nalgorithm (IWOA) as a global optimization algorithm. Firstly, this paper\npresents a mathematic programming model for limited buffer in flexible flow\nshops with setup times, and applies the IWOA algorithm as the global\noptimization algorithm. Based on the whale optimization algorithm (WOA), the\nimproved algorithm uses Levy flight, opposition-based learning strategy and\nsimulated annealing to expand the search range, enhance the ability for jumping\nout of local extremum, and improve the continuous evolution of the algorithm.\nTo verify the improvement of the proposed algorithm on the optimization ability\nof the standard WOA algorithm, the IWOA algorithm is tested by verification\nexamples of small-scale and large-scale flexible flow shop scheduling problems,\nand the imperialist competitive algorithm (ICA), bat algorithm (BA), and whale\noptimization algorithm (WOA) are used for comparision. Based on the instance\ndata of bus manufacturer, simulation tests are made on the four algorithms\nunder variouis of practical evalucation scenarios. The simulation results show\nthat the IWOA algorithm can better solve this type of limited buffer scheduling\nproblem in flexible flow shops with setup times compared with the state of the\nart algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 18:02:42 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Han", "Zhonghua", ""], ["Zhang", "Quan", ""], ["Shi", "Haibo", ""], ["Qi", "Yuanwei", ""], ["Sun", "Liangliang", ""]]}, {"id": "1812.08593", "submitter": "Alireza Sadeghi", "authors": "Alireza Sadeghi, Fatemeh Sheikholeslami, Antonio G. Marques, and\n  Georgios B. Giannakis", "title": "Reinforcement Learning for Adaptive Caching with Dynamic Storage Pricing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Small base stations (SBs) of fifth-generation (5G) cellular networks are\nenvisioned to have storage devices to locally serve requests for reusable and\npopular contents by \\emph{caching} them at the edge of the network, close to\nthe end users. The ultimate goal is to shift part of the predictable load on\nthe back-haul links, from on-peak to off-peak periods, contributing to a better\noverall network performance and service experience. To enable the SBs with\nefficient \\textit{fetch-cache} decision-making schemes operating in dynamic\nsettings, this paper introduces simple but flexible generic time-varying\nfetching and caching costs, which are then used to formulate a constrained\nminimization of the aggregate cost across files and time. Since caching\ndecisions per time slot influence the content availability in future slots, the\nnovel formulation for optimal fetch-cache decisions falls into the class of\ndynamic programming. Under this generic formulation, first by considering\nstationary distributions for the costs and file popularities, an efficient\nreinforcement learning-based solver known as value iteration algorithm can be\nused to solve the emerging optimization problem. Later, it is shown that\npractical limitations on cache capacity can be handled using a particular\ninstance of the generic dynamic pricing formulation. Under this setting, to\nprovide a light-weight online solver for the corresponding optimization, the\nwell-known reinforcement learning algorithm, $Q$-learning, is employed to find\noptimal fetch-cache decisions. Numerical tests corroborating the merits of the\nproposed approach wrap up the paper.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 04:41:52 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 05:23:56 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Sadeghi", "Alireza", ""], ["Sheikholeslami", "Fatemeh", ""], ["Marques", "Antonio G.", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1812.08596", "submitter": "Salvatore Corrente", "authors": "Ana Sara Costa and Salvatore Corrente and Salvatore Greco and Jos\\'e\n  Rui Figueira and Jos\\'e Borbinha", "title": "A robust hierarchical nominal classification method based on similarity\n  and dissimilarity using loss function and an improved version of the deck of\n  cards method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cat-SD is a multiple criteria decision aiding method for dealing with nominal\nclassification problems. Actions are assessed according to multiple criteria\nand assigned to one or more categories. A set of reference actions is used for\ndefining each category. The assignment of an action to a given category depends\non the comparison of the action to each reference set according to likeness\nthresholds. Distinct sets of criteria weights, interaction coefficients, and\nlikeness thresholds can be defined per category. We propose to apply Multiple\nCriteria Hierarchy Process (MCHP) to Cat-SD. An adapted MCHP is proposed to\ntake into account possible interaction effects between criteria structured in a\nhierarchical way. On the basis of the known deck of cards method, we also\nconsider an imprecise elicitation of parameters permitting to take into account\ninteractions and antagonistic effects between criteria. The elicitation\nprocedure we are proposing can be applied to any Electre method. With the\npurpose of exploring the assignments obtained by Cat-SD considering possible\nsets of parameters, we propose to apply the Stochastic Multicriteria\nAcceptability Analysis (SMAA). The SMAA methodology allows to draw statistical\nconclusions on the classification of the actions. The proposed method,\nSMAA-hCat-SD, helps the decision maker to check the effects of the variation of\nparameters on the classification at different levels of the hierarchy. We\npropose also a procedure, based on the concept of loss function, to obtain a\nfinal classification fulfilling some requirements given by the decision maker\nand taking into account the hierarchy of criteria and the probabilistic\nassignments obtained applying SMAA. Also this procedure can be applied to any\nclassification Electre method.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 12:50:08 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 11:04:53 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Costa", "Ana Sara", ""], ["Corrente", "Salvatore", ""], ["Greco", "Salvatore", ""], ["Figueira", "Jos\u00e9 Rui", ""], ["Borbinha", "Jos\u00e9", ""]]}, {"id": "1812.08597", "submitter": "Prashan Madumal", "authors": "Prashan Madumal, Ronal Singh, Joshua Newn, Frank Vetere", "title": "Interaction Design for Explainable AI: Workshop Proceedings", "comments": "Workshop proceedings of Interaction Design for Explainable AI\n  workshop held at OzCHI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As artificial intelligence (AI) systems become increasingly complex and\nubiquitous, these systems will be responsible for making decisions that\ndirectly affect individuals and society as a whole. Such decisions will need to\nbe justified due to ethical concerns as well as trust, but achieving this has\nbecome difficult due to the `black-box' nature many AI models have adopted.\nExplainable AI (XAI) can potentially address this problem by explaining its\nactions, decisions and behaviours of the system to users. However, much\nresearch in XAI is done in a vacuum using only the researchers' intuition of\nwhat constitutes a `good' explanation while ignoring the interaction and the\nhuman aspect. This workshop invites researchers in the HCI community and\nrelated fields to have a discourse about human-centred approaches to XAI rooted\nin interaction and to shed light and spark discussion on interaction design\nchallenges in XAI.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 12:45:26 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Madumal", "Prashan", ""], ["Singh", "Ronal", ""], ["Newn", "Joshua", ""], ["Vetere", "Frank", ""]]}, {"id": "1812.08598", "submitter": "Nicolas Dupin", "authors": "Nicolas Dupin, El-Ghazali Talbi", "title": "Matheuristics to optimize refueling and maintenance planning of nuclear\n  power plants", "comments": null, "journal-ref": null, "doi": "10.1007/s10732-020-09450-0", "report-no": null, "categories": "cs.AI math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Planning the maintenance of nuclear power plants is a complex optimization\nproblem, involving a joint optimization of maintenance dates, fuel constraints\nand power production decisions. This paper investigates Mixed Integer Linear\nProgramming (MILP) matheuristics for this problem, to tackle large size\ninstances used in operations with a time scope of five years, and few\nrestrictions with time window constraints for the latest maintenance\noperations. Several constructive matheuristics and a Variable Neighborhood\nDescent local search are designed. The matheuristics are shown to be accurately\neffective for medium and large size instances. The matheuristics give also\nresults on the design of MILP formulations and neighborhoods for the problem.\nContributions for the operational applications are also discussed. It is shown\nthat the restriction of time windows, which was used to ease computations,\ninduces large over-costs and that this restriction is not required anymore with\nthe capabilities of matheuristics or local search to solve such size of\ninstances. Our matheuristics can be extended to a bi-objective optimization\nextension with stability costs, for the monthly re-optimization of the\nmaintenance planning in the real-life application.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 17:33:21 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 14:38:34 GMT"}, {"version": "v3", "created": "Sun, 6 Sep 2020 10:15:57 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Dupin", "Nicolas", ""], ["Talbi", "El-Ghazali", ""]]}, {"id": "1812.08658", "submitter": "Harsh Agrawal", "authors": "Harsh Agrawal, Karan Desai, Yufei Wang, Xinlei Chen, Rishabh Jain,\n  Mark Johnson, Dhruv Batra, Devi Parikh, Stefan Lee, Peter Anderson", "title": "nocaps: novel object captioning at scale", "comments": null, "journal-ref": "IEEE International Conference on Computer Vision (ICCV) 2019", "doi": "10.1109/ICCV.2019.00904", "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image captioning models have achieved impressive results on datasets\ncontaining limited visual concepts and large amounts of paired image-caption\ntraining data. However, if these models are to ever function in the wild, a\nmuch larger variety of visual concepts must be learned, ideally from less\nsupervision. To encourage the development of image captioning models that can\nlearn visual concepts from alternative data sources, such as object detection\ndatasets, we present the first large-scale benchmark for this task. Dubbed\n'nocaps', for novel object captioning at scale, our benchmark consists of\n166,100 human-generated captions describing 15,100 images from the OpenImages\nvalidation and test sets. The associated training data consists of COCO\nimage-caption pairs, plus OpenImages image-level labels and object bounding\nboxes. Since OpenImages contains many more classes than COCO, nearly 400 object\nclasses seen in test images have no or very few associated training captions\n(hence, nocaps). We extend existing novel object captioning models to establish\nstrong baselines for this benchmark and provide analysis to guide future work\non this task.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 16:04:05 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 23:13:30 GMT"}, {"version": "v3", "created": "Mon, 30 Sep 2019 20:10:33 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Agrawal", "Harsh", ""], ["Desai", "Karan", ""], ["Wang", "Yufei", ""], ["Chen", "Xinlei", ""], ["Jain", "Rishabh", ""], ["Johnson", "Mark", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""], ["Lee", "Stefan", ""], ["Anderson", "Peter", ""]]}, {"id": "1812.08763", "submitter": "Jorge Fandinno", "authors": "Pedro Cabalar, Jorge Fandinno and Luis Fari\\~nas del Cerro", "title": "Splitting Epistemic Logic Programs", "comments": "Theory and Practice of Logic Programming", "journal-ref": "Theory and Practice of Logic Programming 21 (2021) 296-316", "doi": "10.1017/S1471068420000058", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epistemic logic programs constitute an extension of the stable models\nsemantics to deal with new constructs called subjective literals. Informally\nspeaking, a subjective literal allows checking whether some regular literal is\ntrue in all stable models or in some stable model. As it can be imagined, the\nassociated semantics has proved to be non-trivial, as the truth of the\nsubjective literal may interfere with the set of stable models it is supposed\nto query. As a consequence, no clear agreement has been reached and different\nsemantic proposals have been made in the literature. Unfortunately, comparison\namong these proposals has been limited to a study of their effect on individual\nexamples, rather than identifying general properties to be checked. In this\npaper, we propose an extension of the well-known splitting property for logic\nprograms to the epistemic case. To this aim, we formally define when an\narbitrary semantics satisfies the epistemic splitting property and examine some\nof the consequences that can be derived from that, including its relation to\nconformant planning and to epistemic constraints. Interestingly, we prove\n(through counterexamples) that most of the existing proposals fail to fulfill\nthe epistemic splitting property, except the original semantics proposed by\nGelfond in 1991.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 18:45:08 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 14:30:19 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Cabalar", "Pedro", ""], ["Fandinno", "Jorge", ""], ["del Cerro", "Luis Fari\u00f1as", ""]]}, {"id": "1812.08781", "submitter": "Han Hu", "authors": "Bin Liu, Zhirong Wu, Han Hu and Stephen Lin", "title": "Deep Metric Transfer for Label Propagation with Limited Annotated Data", "comments": "Code is availble at\n  http://github.com/Microsoft/metric-transfer.pytorch", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study object recognition under the constraint that each object class is\nonly represented by very few observations. Semi-supervised learning, transfer\nlearning, and few-shot recognition all concern with achieving fast\ngeneralization with few labeled data. In this paper, we propose a generic\nframework that utilizes unlabeled data to aid generalization for all three\ntasks. Our approach is to create much more training data through label\npropagation from the few labeled examples to a vast collection of unannotated\nimages. The main contribution of the paper is that we show such a label\npropagation scheme can be highly effective when the similarity metric used for\npropagation is transferred from other related domains. We test various\ncombinations of supervised and unsupervised metric learning methods with\nvarious label propagation algorithms. We find that our framework is very\ngeneric without being sensitive to any specific techniques. By taking advantage\nof unlabeled data in this way, we achieve significant improvements on all three\ntasks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 18:57:28 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 06:46:33 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Liu", "Bin", ""], ["Wu", "Zhirong", ""], ["Hu", "Han", ""], ["Lin", "Stephen", ""]]}, {"id": "1812.08868", "submitter": "Tom Hanika", "authors": "Tom Hanika and Maren Koyda and Gerd Stumme", "title": "Relevant Attributes in Formal Contexts", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": "10.1007/978-3-030-23182-8_8", "report-no": null, "categories": "cs.AI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing conceptual structures, like formal concept lattices, is in the age\nof massive data sets a challenging task. There are various approaches to deal\nwith this, e.g., random sampling, parallelization, or attribute extraction. A\nso far not investigated method in the realm of formal concept analysis is\nattribute selection, as done in machine learning. Building up on this we\nintroduce a method for attribute selection in formal contexts. To this end, we\npropose the notion of relevant attributes which enables us to define a relative\nrelevance function, reflecting both the order structure of the concept lattice\nas well as distribution of objects on it. Finally, we overcome computational\nchallenges for computing the relative relevance through an approximation\napproach based on information entropy.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 22:07:16 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Hanika", "Tom", ""], ["Koyda", "Maren", ""], ["Stumme", "Gerd", ""]]}, {"id": "1812.08879", "submitter": "Bo-Hsiang (Andy) Tseng", "authors": "Bo-Hsiang Tseng, Florian Kreyssig, Pawel Budzianowski, Inigo\n  Casanueva, Yen-Chen Wu, Stefan Ultes, Milica Gasic", "title": "Variational Cross-domain Natural Language Generation for Spoken Dialogue\n  Systems", "comments": "Sigdial 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-domain natural language generation (NLG) is still a difficult task\nwithin spoken dialogue modelling. Given a semantic representation provided by\nthe dialogue manager, the language generator should generate sentences that\nconvey desired information. Traditional template-based generators can produce\nsentences with all necessary information, but these sentences are not\nsufficiently diverse. With RNN-based models, the diversity of the generated\nsentences can be high, however, in the process some information is lost. In\nthis work, we improve an RNN-based generator by considering latent information\nat the sentence level during generation using the conditional variational\nautoencoder architecture. We demonstrate that our model outperforms the\noriginal RNN-based generator, while yielding highly diverse sentences. In\naddition, our model performs better when the training data is limited.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 22:53:33 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Tseng", "Bo-Hsiang", ""], ["Kreyssig", "Florian", ""], ["Budzianowski", "Pawel", ""], ["Casanueva", "Inigo", ""], ["Wu", "Yen-Chen", ""], ["Ultes", "Stefan", ""], ["Gasic", "Milica", ""]]}, {"id": "1812.08904", "submitter": "Gabriel De La Cruz Jr", "authors": "Gabriel V. de la Cruz, Yunshu Du and Matthew E. Taylor", "title": "Pre-training with Non-expert Human Demonstration for Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": "10.1017/S0269888919000055", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (deep RL) has achieved superior performance in\ncomplex sequential tasks by using deep neural networks as function\napproximators to learn directly from raw input images. However, learning\ndirectly from raw images is data inefficient. The agent must learn feature\nrepresentation of complex states in addition to learning a policy. As a result,\ndeep RL typically suffers from slow learning speeds and often requires a\nprohibitively large amount of training time and data to reach reasonable\nperformance, making it inapplicable to real-world settings where data is\nexpensive. In this work, we improve data efficiency in deep RL by addressing\none of the two learning goals, feature learning. We leverage supervised\nlearning to pre-train on a small set of non-expert human demonstrations and\nempirically evaluate our approach using the asynchronous advantage actor-critic\nalgorithms (A3C) in the Atari domain. Our results show significant improvements\nin learning speed, even when the provided demonstration is noisy and of low\nquality.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 01:10:06 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["de la Cruz", "Gabriel V.", ""], ["Du", "Yunshu", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "1812.08928", "submitter": "Jiahui Yu", "authors": "Jiahui Yu, Linjie Yang, Ning Xu, Jianchao Yang, Thomas Huang", "title": "Slimmable Neural Networks", "comments": "Accepted in ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple and general method to train a single neural network\nexecutable at different widths (number of channels in a layer), permitting\ninstant and adaptive accuracy-efficiency trade-offs at runtime. Instead of\ntraining individual networks with different width configurations, we train a\nshared network with switchable batch normalization. At runtime, the network can\nadjust its width on the fly according to on-device benchmarks and resource\nconstraints, rather than downloading and offloading different models. Our\ntrained networks, named slimmable neural networks, achieve similar (and in many\ncases better) ImageNet classification accuracy than individually trained models\nof MobileNet v1, MobileNet v2, ShuffleNet and ResNet-50 at different widths\nrespectively. We also demonstrate better performance of slimmable models\ncompared with individual ones across a wide range of applications including\nCOCO bounding-box object detection, instance segmentation and person keypoint\ndetection without tuning hyper-parameters. Lastly we visualize and discuss the\nlearned features of slimmable networks. Code and models are available at:\nhttps://github.com/JiahuiYu/slimmable_networks\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 03:36:48 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Yu", "Jiahui", ""], ["Yang", "Linjie", ""], ["Xu", "Ning", ""], ["Yang", "Jianchao", ""], ["Huang", "Thomas", ""]]}, {"id": "1812.08947", "submitter": "Chuan Qin", "authors": "Chuan Qin, Hengshu Zhu, Tong Xu, Chen Zhu, Liang Jiang, Enhong Chen,\n  Hui Xiong", "title": "Enhancing Person-Job Fit for Talent Recruitment: An Ability-aware Neural\n  Network Approach", "comments": "This is an extended version of our SIGIR18 paper", "journal-ref": null, "doi": "10.1145/3209978.3210025", "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wide spread use of online recruitment services has led to information\nexplosion in the job market. As a result, the recruiters have to seek the\nintelligent ways for Person Job Fit, which is the bridge for adapting the right\njob seekers to the right positions. Existing studies on Person Job Fit have a\nfocus on measuring the matching degree between the talent qualification and the\njob requirements mainly based on the manual inspection of human resource\nexperts despite of the subjective, incomplete, and inefficient nature of the\nhuman judgement. To this end, in this paper, we propose a novel end to end\nAbility aware Person Job Fit Neural Network model, which has a goal of reducing\nthe dependence on manual labour and can provide better interpretation about the\nfitting results. The key idea is to exploit the rich information available at\nabundant historical job application data. Specifically, we propose a word level\nsemantic representation for both job requirements and job seekers' experiences\nbased on Recurrent Neural Network. Along this line, four hierarchical ability\naware attention strategies are designed to measure the different importance of\njob requirements for semantic representation, as well as measuring the\ndifferent contribution of each job experience to a specific ability\nrequirement. Finally, extensive experiments on a large scale real world data\nset clearly validate the effectiveness and interpretability of the APJFNN\nframework compared with several baselines.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 05:02:02 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Qin", "Chuan", ""], ["Zhu", "Hengshu", ""], ["Xu", "Tong", ""], ["Zhu", "Chen", ""], ["Jiang", "Liang", ""], ["Chen", "Enhong", ""], ["Xiong", "Hui", ""]]}, {"id": "1812.08957", "submitter": "Arthur Choi", "authors": "Arthur Choi and Ruocheng Wang and Adnan Darwiche", "title": "On the Relative Expressiveness of Bayesian and Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A neural network computes a function. A central property of neural networks\nis that they are \"universal approximators:\" for a given continuous function,\nthere exists a neural network that can approximate it arbitrarily well, given\nenough neurons (and some additional assumptions). In contrast, a Bayesian\nnetwork is a model, but each of its queries can be viewed as computing a\nfunction. In this paper, we identify some key distinctions between the\nfunctions computed by neural networks and those by marginal Bayesian network\nqueries, showing that the former are more expressive than the latter. Moreover,\nwe propose a simple augmentation to Bayesian networks (a testing operator),\nwhich enables their marginal queries to become \"universal approximators.\"\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 05:43:13 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Choi", "Arthur", ""], ["Wang", "Ruocheng", ""], ["Darwiche", "Adnan", ""]]}, {"id": "1812.08960", "submitter": "Hussein Abbass A", "authors": "Hussein Abbass, John Harvey, Kate Yaxley", "title": "Lifelong Testing of Smart Autonomous Systems by Shepherding a Swarm of\n  Watchdog Artificial Intelligence Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) technologies could be broadly categorised into\nAnalytics and Autonomy. Analytics focuses on algorithms offering perception,\ncomprehension, and projection of knowledge gleaned from sensorial data.\nAutonomy revolves around decision making, and influencing and shaping the\nenvironment through action production. A smart autonomous system (SAS) combines\nanalytics and autonomy to understand, learn, decide and act autonomously. To be\nuseful, SAS must be trusted and that requires testing. Lifelong learning of a\nSAS compounds the testing process. In the remote chance that it is possible to\nfully test and certify the system pre-release, which is theoretically an\nundecidable problem, it is near impossible to predict the future behaviours\nthat these systems, alone or collectively, will exhibit. While it may be\nfeasible to severely restrict such systems\\textquoteright \\ learning abilities\nto limit the potential unpredictability of their behaviours, an undesirable\nconsequence may be severely limiting their utility. In this paper, we propose\nthe architecture for a watchdog AI (WAI) agent dedicated to lifelong functional\ntesting of SAS. We further propose system specifications including a level of\nabstraction whereby humans shepherd a swarm of WAI agents to oversee an\necosystem made of humans and SAS. The discussion extends to the challenges,\npros, and cons of the proposed concept.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 05:53:47 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Abbass", "Hussein", ""], ["Harvey", "John", ""], ["Yaxley", "Kate", ""]]}, {"id": "1812.08974", "submitter": "Mohammad Mahfujur Rahman", "authors": "Mohammad Mahfujur Rahman, Clinton Fookes, Mahsa Baktashmotlagh, Sridha\n  Sridharan", "title": "Multi-component Image Translation for Deep Domain Generalization", "comments": "Accepted in WACV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaption (DA) and domain generalization (DG) are two closely related\nmethods which are both concerned with the task of assigning labels to an\nunlabeled data set. The only dissimilarity between these approaches is that DA\ncan access the target data during the training phase, while the target data is\ntotally unseen during the training phase in DG. The task of DG is challenging\nas we have no earlier knowledge of the target samples. If DA methods are\napplied directly to DG by a simple exclusion of the target data from training,\npoor performance will result for a given task. In this paper, we tackle the\ndomain generalization challenge in two ways. In our first approach, we propose\na novel deep domain generalization architecture utilizing synthetic data\ngenerated by a Generative Adversarial Network (GAN). The discrepancy between\nthe generated images and synthetic images is minimized using existing domain\ndiscrepancy metrics such as maximum mean discrepancy or correlation alignment.\nIn our second approach, we introduce a protocol for applying DA methods to a DG\nscenario by excluding the target data from the training phase, splitting the\nsource data to training and validation parts, and treating the validation data\nas target data for DA. We conduct extensive experiments on four cross-domain\nbenchmark datasets. Experimental results signify our proposed model outperforms\nthe current state-of-the-art methods for DG.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 07:03:31 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Rahman", "Mohammad Mahfujur", ""], ["Fookes", "Clinton", ""], ["Baktashmotlagh", "Mahsa", ""], ["Sridharan", "Sridha", ""]]}, {"id": "1812.08989", "submitter": "Jianfeng Gao", "authors": "Li Zhou, Jianfeng Gao, Di Li, Heung-Yeung Shum", "title": "The Design and Implementation of XiaoIce, an Empathetic Social Chatbot", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the development of Microsoft XiaoIce, the most popular\nsocial chatbot in the world. XiaoIce is uniquely designed as an AI companion\nwith an emotional connection to satisfy the human need for communication,\naffection, and social belonging. We take into account both intelligent quotient\n(IQ) and emotional quotient (EQ) in system design, cast human-machine social\nchat as decision-making over Markov Decision Processes (MDPs), and optimize\nXiaoIce for long-term user engagement, measured in expected Conversation-turns\nPer Session (CPS). We detail the system architecture and key components\nincluding dialogue manager, core chat, skills, and an empathetic computing\nmodule. We show how XiaoIce dynamically recognizes human feelings and states,\nunderstands user intent, and responds to user needs throughout long\nconversations. Since her launch in 2014, XiaoIce has communicated with over 660\nmillion active users and succeeded in establishing long-term relationships with\nmany of them. Analysis of large scale online logs shows that XiaoIce has\nachieved an average CPS of 23, which is significantly higher than that of other\nchatbots and even human conversations.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 08:01:31 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 21:23:51 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Zhou", "Li", ""], ["Gao", "Jianfeng", ""], ["Li", "Di", ""], ["Shum", "Heung-Yeung", ""]]}, {"id": "1812.09044", "submitter": "A. Adhikari", "authors": "Ajaya Adhikari, D.M.J Tax, Riccardo Satta, Matthias Fath", "title": "LEAFAGE: Example-based and Feature importance-based Explanationsfor\n  Black-box ML models", "comments": "Submitted to the 2019 Fuzz-IEEE conference (special session on\n  Advances on eXplainable Artificial Intelligence)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  As machine learning models become more accurate, they typically become more\ncomplex and uninterpretable by humans. The black-box character of these models\nholds back its acceptance in practice, especially in high-risk domains where\nthe consequences of failure could be catastrophic such as health-care or\ndefense. Providing understandable and useful explanations behind ML models or\npredictions can increase the trust of the user. Example-based reasoning, which\nentails leveraging previous experience with analogous tasks to make a decision,\nis a well known strategy for problem solving and justification. This work\npresents a new explanation extraction method called LEAFAGE, for a prediction\nmade by any black-box ML model. The explanation consists of the visualization\nof similar examples from the training set and the importance of each feature.\nMoreover, these explanations are contrastive which aims to take the\nexpectations of the user into account. LEAFAGE is evaluated in terms of\nfidelity to the underlying black-box model and usefulness to the user. The\nresults showed that LEAFAGE performs overall better than the current\nstate-of-the-art method LIME in terms of fidelity, on ML models with non-linear\ndecision boundary. A user-study was conducted which focused on revealing the\ndifferences between example-based and feature importance-based explanations. It\nshowed that example-based explanations performed significantly better than\nfeature importance-based explanation, in terms of perceived transparency,\ninformation sufficiency, competence and confidence. Counter-intuitively, when\nthe gained knowledge of the participants was tested, it showed that they\nlearned less about the black-box model after seeing a feature importance-based\nexplanation than seeing no explanation at all. The participants found feature\nimportance-based explanation vague and hard to generalize it to other\ninstances.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 11:02:09 GMT"}, {"version": "v2", "created": "Sun, 27 Jan 2019 17:19:06 GMT"}, {"version": "v3", "created": "Fri, 16 Aug 2019 09:59:57 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Adhikari", "Ajaya", ""], ["Tax", "D. M. J", ""], ["Satta", "Riccardo", ""], ["Fath", "Matthias", ""]]}, {"id": "1812.09077", "submitter": "Alberto Fachechi", "authors": "Elena Agliari, Francesco Alemanno, Adriano Barra, Alberto Fachechi", "title": "Dreaming neural networks: rigorous results", "comments": null, "journal-ref": null, "doi": "10.1088/1742-5468/ab371d", "report-no": "Roma01.Math", "categories": "cond-mat.dis-nn cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently a daily routine for associative neural networks has been proposed:\nthe network Hebbian-learns during the awake state (thus behaving as a standard\nHopfield model), then, during its sleep state, optimizing information storage,\nit consolidates pure patterns and removes spurious ones: this forces the\nsynaptic matrix to collapse to the projector one (ultimately approaching the\nKanter-Sompolinksy model). This procedure keeps the learning Hebbian-based (a\nbiological must) but, by taking advantage of a (properly stylized) sleep phase,\nstill reaches the maximal critical capacity (for symmetric interactions). So\nfar this emerging picture (as well as the bulk of papers on unlearning\ntechniques) was supported solely by mathematically-challenging routes, e.g.\nmainly replica-trick analysis and numerical simulations: here we rely\nextensively on Guerra's interpolation techniques developed for neural networks\nand, in particular, we extend the generalized stochastic stability approach to\nthe case. Confining our description within the replica symmetric approximation\n(where the previous ones lie), the picture painted regarding this\ngeneralization (and the previously existing variations on theme) is here\nentirely confirmed. Further, still relying on Guerra's schemes, we develop a\nsystematic fluctuation analysis to check where ergodicity is broken (an\nanalysis entirely absent in previous investigations). We find that, as long as\nthe network is awake, ergodicity is bounded by the Amit-Gutfreund-Sompolinsky\ncritical line (as it should), but, as the network sleeps, sleeping destroys\nspin glass states by extending both the retrieval as well as the ergodic\nregion: after an entire sleeping session the solely surviving regions are\nretrieval and ergodic ones and this allows the network to achieve the perfect\nretrieval regime (the number of storable patterns equals the number of neurons\nin the network).\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 12:29:48 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Agliari", "Elena", ""], ["Alemanno", "Francesco", ""], ["Barra", "Adriano", ""], ["Fachechi", "Alberto", ""]]}, {"id": "1812.09086", "submitter": "Mieczys{\\l}aw K{\\l}opotek", "authors": "S.T. Wierzcho\\'n and M.A. K{\\l}opotek and M. Michalewicz", "title": "Reasoning and Facts Explanation in Valuation Based Systems", "comments": "12 pasges", "journal-ref": "Fundamenta Informaticae 30(3/4)1997, pp. 359-371", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the literature, the optimization problem to identify a set of composite\nhypotheses H, which will yield the $k$ largest $P(H|S_e)$ where a composite\nhypothesis is an instantiation of all the nodes in the network except the\nevidence nodes \\cite{KSy:93} is of significant interest. This problem is called\n\"finding the $k$ Most Plausible Explanation (MPE) of a given evidence $S_e$ in\na Bayesian belief network\".\n  The problem of finding $k$ most probable hypotheses is generally NP-hard\n\\cite{Cooper:90}. Therefore in the past various simplifications of the task by\nrestricting $k$ (to 1 or 2), restricting the structure (e.g. to singly\nconnected networks), or shifting the complexity to spatial domain have been\ninvestigated.\n  A genetic algorithm is proposed in this paper to overcome some of these\nrestrictions while stepping out from probabilistic domain onto the general\nValuation based System (VBS) framework is also proposed by generalizing the\ngenetic algorithm approach to the realm of Dempster-Shafer belief calculus.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 12:41:00 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Wierzcho\u0144", "S. T.", ""], ["K\u0142opotek", "M. A.", ""], ["Michalewicz", "M.", ""]]}, {"id": "1812.09111", "submitter": "Timoth\\'ee Lesort", "authors": "Timoth\\'ee Lesort, Hugo Caselles-Dupr\\'e, Michael Garcia-Ortiz, Andrei\n  Stoian, David Filliat", "title": "Generative Models from the perspective of Continual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Which generative model is the most suitable for Continual Learning? This\npaper aims at evaluating and comparing generative models on disjoint sequential\nimage generation tasks. We investigate how several models learn and forget,\nconsidering various strategies: rehearsal, regularization, generative replay\nand fine-tuning. We used two quantitative metrics to estimate the generation\nquality and memory ability. We experiment with sequential tasks on three\ncommonly used benchmarks for Continual Learning (MNIST, Fashion MNIST and\nCIFAR10). We found that among all models, the original GAN performs best and\namong Continual Learning strategies, generative replay outperforms all other\nmethods. Even if we found satisfactory combinations on MNIST and Fashion MNIST,\ntraining generative models sequentially on CIFAR10 is particularly instable,\nand remains a challenge. Our code is available online\n\\footnote{\\url{https://github.com/TLESORT/Generative\\_Continual\\_Learning}}.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 13:35:32 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Lesort", "Timoth\u00e9e", ""], ["Caselles-Dupr\u00e9", "Hugo", ""], ["Garcia-Ortiz", "Michael", ""], ["Stoian", "Andrei", ""], ["Filliat", "David", ""]]}, {"id": "1812.09131", "submitter": "Chang Liu", "authors": "Chang Liu, Zhaowei Shang, Anyong Qin", "title": "A Multiscale Image Denoising Algorithm Based On Dilated Residual\n  Convolution Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image denoising is a classical problem in low level computer vision.\nModel-based optimization methods and deep learning approaches have been the two\nmain strategies for solving the problem. Model-based optimization methods are\nflexible for handling different inverse problems but are usually\ntime-consuming. In contrast, deep learning methods have fast testing speed but\nthe performance of these CNNs is still inferior. To address this issue, here we\npropose a novel deep residual learning model that combines the dilated residual\nconvolution and multi-scale convolution groups. Due to the complex patterns and\nstructures of inside an image, the multiscale convolution group is utilized to\nlearn those patterns and enlarge the receptive field. Specifically, the\nresidual connection and batch normalization are utilized to speed up the\ntraining process and maintain the denoising performance. In order to decrease\nthe gridding artifacts, we integrate the hybrid dilated convolution design into\nour model. To this end, this paper aims to train a lightweight and effective\ndenoiser based on multiscale convolution group. Experimental results have\ndemonstrated that the enhanced denoiser can not only achieve promising\ndenoising results, but also become a strong competitor in practical\napplication.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 14:13:07 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Liu", "Chang", ""], ["Shang", "Zhaowei", ""], ["Qin", "Anyong", ""]]}, {"id": "1812.09162", "submitter": "Nicolas Le Scouarnec", "authors": "Fabien Andr\\'e, Anne-Marie Kermarrec and Nicolas Le Scouarnec", "title": "Quicker ADC : Unlocking the hidden potential of Product Quantization\n  with SIMD", "comments": "Open-source implementation at\n  http://github.com/nlescoua/faiss-quickeradc", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2019 Early Access", "doi": "10.1109/TPAMI.2019.2952606", "report-no": null, "categories": "cs.CV cs.AI cs.DB cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient Nearest Neighbor (NN) search in high-dimensional spaces is a\nfoundation of many multimedia retrieval systems. A common approach is to rely\non Product Quantization, which allows the storage of large vector databases in\nmemory and efficient distance computations. Yet, implementations of nearest\nneighbor search with Product Quantization have their performance limited by the\nmany memory accesses they perform. Following this observation, Andr\\'e et al.\nproposed Quick ADC with up to $6\\times$ faster implementations of $m\\times{}4$\nproduct quantizers (PQ) leveraging specific SIMD instructions. Quicker ADC is a\ngeneralization of Quick ADC not limited to $m\\times{}4$ codes and supporting\nAVX-512, the latest revision of SIMD instruction set. In doing so, Quicker ADC\nfaces the challenge of using efficiently 5,6 and 7-bit shuffles that do not\nalign to computer bytes or words. To this end, we introduce (i) irregular\nproduct quantizers combining sub-quantizers of different granularity and (ii)\nsplit tables allowing lookup tables larger than registers. We evaluate Quicker\nADC with multiple indexes including Inverted Multi-Indexes and IVF HNSW and\nshow that it outperforms the reference optimized implementations (i.e., FAISS\nand polysemous codes) for numerous configurations. Finally, we release an\nopen-source fork of FAISS enhanced with Quicker ADC at\nhttp://github.com/nlescoua/faiss-quickeradc.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 14:51:27 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 21:39:48 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Andr\u00e9", "Fabien", ""], ["Kermarrec", "Anne-Marie", ""], ["Scouarnec", "Nicolas Le", ""]]}, {"id": "1812.09193", "submitter": "Gabriel Marzinotto", "authors": "Gabriel Marzinotto (TALEP), Fr\\'ed\\'eric B\\'echet (LIS, TALEP),\n  G\\'eraldine Damnati, Alexis Nasr (LIS, TALEP)", "title": "Sources of Complexity in Semantic Frame Parsing for Information\n  Extraction", "comments": null, "journal-ref": "International FrameNet Workshop 2018, May 2018, Miyazaki, Japan", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a Semantic Frame parsing System based on sequence\nlabeling methods, precisely BiLSTM models with highway connections, for\nperforming information extraction on a corpus of French encyclopedic history\ntexts annotated according to the Berkeley FrameNet formalism. The approach\nproposed in this study relies on an integrated sequence labeling model which\njointly optimizes frame identification and semantic role segmentation and\nidentification. The purpose of this study is to analyze the task complexity, to\nhighlight the factors that make Semantic Frame parsing a difficult task and to\nprovide detailed evaluations of the performance on different types of frames\nand sentences.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 15:30:17 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Marzinotto", "Gabriel", "", "TALEP"], ["B\u00e9chet", "Fr\u00e9d\u00e9ric", "", "LIS, TALEP"], ["Damnati", "G\u00e9raldine", "", "LIS, TALEP"], ["Nasr", "Alexis", "", "LIS, TALEP"]]}, {"id": "1812.09207", "submitter": "Tias Guns", "authors": "Tias Guns, Peter J. Stuckey and Guido Tack", "title": "Solution Dominance over Constraint Satisfaction Problems", "comments": "Presented at the ModRef18 workshop at CP18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint Satisfaction Problems (CSPs) typically have many solutions that\nsatisfy all constraints. Often though, some solutions are preferred over\nothers, that is, some solutions dominate other solutions. We present solution\ndominance as a formal framework to reason about such settings. We define\nConstraint Dominance Problems (CDPs) as CSPs with a dominance relation, that\nis, a preorder over the solutions of the CSP. This framework captures many\nwell-known variants of constraint satisfaction, including optimization,\nmulti-objective optimization, Max-CSP, minimal models, minimum correction\nsubsets as well as optimization over CP-nets and arbitrary dominance relations.\nWe extend MiniZinc, a declarative language for modeling CSPs, to CDPs by\nintroducing dominance nogoods; these can be derived from dominance relations in\na principled way. A generic method for solving arbitrary CDPs incrementally\ncalls a CSP solver and is compatible with any existing solver that supports\nMiniZinc. This encourages experimenting with different solution dominance\nrelations for a problem, as well as comparing different solvers without having\nto modify their implementations.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 15:54:34 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Guns", "Tias", ""], ["Stuckey", "Peter J.", ""], ["Tack", "Guido", ""]]}, {"id": "1812.09338", "submitter": "Grigor Aslanyan", "authors": "Grigor Aslanyan, Utkarsh Porwal", "title": "Position Bias Estimation for Unbiased Learning-to-Rank in eCommerce\n  Search", "comments": "10 pages, 3 figures", "journal-ref": "SPIRE 2019. Lecture Notes in Computer Science, vol 11811.\n  Springer, Cham", "doi": "10.1007/978-3-030-32686-9_4", "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Unbiased Learning-to-Rank framework has been recently proposed as a\ngeneral approach to systematically remove biases, such as position bias, from\nlearning-to-rank models. The method takes two steps - estimating click\npropensities and using them to train unbiased models. Most common methods\nproposed in the literature for estimating propensities involve some degree of\nintervention in the live search engine. An alternative approach proposed\nrecently uses an Expectation Maximization (EM) algorithm to estimate\npropensities by using ranking features for estimating relevances. In this work\nwe propose a novel method to directly estimate propensities which does not use\nany intervention in live search or rely on modeling relevance. Rather, we take\nadvantage of the fact that the same query-document pair may naturally change\nranks over time. This typically occurs for eCommerce search because of change\nof popularity of items over time, existence of time dependent ranking features,\nor addition or removal of items to the index (an item getting sold or a new\nitem being listed). However, our method is general and can be applied to any\nsearch engine for which the rank of the same document may naturally change over\ntime for the same query. We derive a simple likelihood function that depends on\npropensities only, and by maximizing the likelihood we are able to get\nestimates of the propensities. We apply this method to eBay search data to\nestimate click propensities for web and mobile search and compare these with\nestimates using the EM method. We also use simulated data to show that the\nmethod gives reliable estimates of the \"true\" simulated propensities. Finally,\nwe train an unbiased learning-to-rank model for eBay search using the estimated\npropensities and show that it outperforms both baselines - one without position\nbias correction and one with position bias correction using the EM method.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 19:05:15 GMT"}, {"version": "v2", "created": "Mon, 6 May 2019 22:13:30 GMT"}, {"version": "v3", "created": "Tue, 22 Oct 2019 17:53:19 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Aslanyan", "Grigor", ""], ["Porwal", "Utkarsh", ""]]}, {"id": "1812.09351", "submitter": "Quang Minh Ha", "authors": "Quang Minh Ha, Yves Deville, Quang Dung Pham, Minh Ho\\`ang H\\`a", "title": "A Hybrid Genetic Algorithm for the Traveling Salesman Problem with Drone", "comments": "Technical Report. 34 pages, 5 figures", "journal-ref": null, "doi": "10.1007/s10732-019-09431-y", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the Traveling Salesman Problem with Drone (TSP-D), in\nwhich a truck and drone are used to deliver parcels to customers. The objective\nof this problem is to either minimize the total operational cost (min-cost\nTSP-D) or minimize the completion time for the truck and drone (min-time\nTSP-D). This problem has gained a lot of attention in the last few years since\nit is matched with the recent trends in a new delivery method among logistics\ncompanies. To solve the TSP-D, we propose a hybrid genetic search with dynamic\npopulation management and adaptive diversity control based on a split\nalgorithm, problem-tailored crossover and local search operators, a new restore\nmethod to advance the convergence and an adaptive penalization mechanism to\ndynamically balance the search between feasible/infeasible solutions. The\ncomputational results show that the proposed algorithm outperforms existing\nmethods in terms of solution quality and improves best known solutions found in\nthe literature. Moreover, various analyses on the impacts of crossover choice\nand heuristic components have been conducted to analysis further their\nsensitivity to the performance of our method.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 19:42:56 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Ha", "Quang Minh", ""], ["Deville", "Yves", ""], ["Pham", "Quang Dung", ""], ["H\u00e0", "Minh Ho\u00e0ng", ""]]}, {"id": "1812.09376", "submitter": "Ravi Pandya", "authors": "Ravi Pandya, Sandy H. Huang, Dylan Hadfield-Menell, Anca D. Dragan", "title": "Human-AI Learning Performance in Multi-Armed Bandits", "comments": "Artificial Intelligence, Ethics and Society (AIES) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People frequently face challenging decision-making problems in which outcomes\nare uncertain or unknown. Artificial intelligence (AI) algorithms exist that\ncan outperform humans at learning such tasks. Thus, there is an opportunity for\nAI agents to assist people in learning these tasks more effectively. In this\nwork, we use a multi-armed bandit as a controlled setting in which to explore\nthis direction. We pair humans with a selection of agents and observe how well\neach human-agent team performs. We find that team performance can beat both\nhuman and agent performance in isolation. Interestingly, we also find that an\nagent's performance in isolation does not necessarily correlate with the\nhuman-agent team's performance. A drop in agent performance can lead to a\ndisproportionately large drop in team performance, or in some settings can even\nimprove team performance. Pairing a human with an agent that performs slightly\nbetter than them can make them perform much better, while pairing them with an\nagent that performs the same can make them them perform much worse. Further,\nour results suggest that people have different exploration strategies and might\nperform better with agents that match their strategy. Overall, optimizing\nhuman-agent team performance requires going beyond optimizing agent\nperformance, to understanding how the agent's suggestions will influence human\ndecision-making.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 21:28:11 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Pandya", "Ravi", ""], ["Huang", "Sandy H.", ""], ["Hadfield-Menell", "Dylan", ""], ["Dragan", "Anca D.", ""]]}, {"id": "1812.09421", "submitter": "Zunjing Wang", "authors": "Xiao-Feng Xie and Zun-Jing Wang", "title": "Exploiting Problem Structure in Combinatorial Landscapes: A Case Study\n  on Pure Mathematics Application", "comments": "7 pages, 2 figures, conference", "journal-ref": "International Joint Conference on Artificial Intelligence, New\n  York, 2016, pp.2683-2689", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we present a method using AI techniques to solve a case of\npure mathematics applications for finding narrow admissible tuples. The\noriginal problem is formulated into a combinatorial optimization problem. In\nparticular, we show how to exploit the local search structure to formulate the\nproblem landscape for dramatic reductions in search space and for non-trivial\nelimination in search barriers, and then to realize intelligent search\nstrategies for effectively escaping from local minima. Experimental results\ndemonstrate that the proposed method is able to efficiently find best known\nsolutions. This research sheds light on exploiting the local problem structure\nfor an efficient search in combinatorial landscapes as an application of AI to\na new problem domain.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2018 00:33:59 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Xie", "Xiao-Feng", ""], ["Wang", "Zun-Jing", ""]]}, {"id": "1812.09521", "submitter": "Jacob Menashe", "authors": "Jacob Menashe and Peter Stone", "title": "Escape Room: A Configurable Testbed for Hierarchical Reinforcement\n  Learning", "comments": "24 pages, 4 image figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent successes in Reinforcement Learning have encouraged a fast-growing\nnetwork of RL researchers and a number of breakthroughs in RL research. As the\nRL community and the body of RL work grows, so does the need for widely\napplicable benchmarks that can fairly and effectively evaluate a variety of RL\nalgorithms.\n  This need is particularly apparent in the realm of Hierarchical Reinforcement\nLearning (HRL). While many existing test domains may exhibit hierarchical\naction or state structures, modern RL algorithms still exhibit great difficulty\nin solving domains that necessitate hierarchical modeling and action planning,\neven when such domains are seemingly trivial. These difficulties highlight both\nthe need for more focus on HRL algorithms themselves, and the need for new\ntestbeds that will encourage and validate HRL research.\n  Existing HRL testbeds exhibit a Goldilocks problem; they are often either too\nsimple (e.g. Taxi) or too complex (e.g. Montezuma's Revenge from the Arcade\nLearning Environment). In this paper we present the Escape Room Domain (ERD), a\nnew flexible, scalable, and fully implemented testing domain for HRL that\nbridges the \"moderate complexity\" gap left behind by existing alternatives. ERD\nis open-source and freely available through GitHub, and conforms to widely-used\npublic testing interfaces for simple integration and testing with a variety of\npublic RL agent implementations. We show that the ERD presents a suite of\nchallenges with scalable difficulty to provide a smooth learning gradient from\nTaxi to the Arcade Learning Environment.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2018 12:29:20 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Menashe", "Jacob", ""], ["Stone", "Peter", ""]]}, {"id": "1812.09652", "submitter": "Lannan Luo", "authors": "Kimberly Redmond, Lannan Luo, Qiang Zeng", "title": "A Cross-Architecture Instruction Embedding Model for Natural Language\n  Processing-Inspired Binary Code Analysis", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a closed-source program, such as most of proprietary software and\nviruses, binary code analysis is indispensable for many tasks, such as code\nplagiarism detection and malware analysis. Today, source code is very often\ncompiled for various architectures, making cross-architecture binary code\nanalysis increasingly important. A binary, after being disassembled, is\nexpressed in an assembly languages. Thus, recent work starts exploring Natural\nLanguage Processing (NLP) inspired binary code analysis. In NLP, words are\nusually represented in high-dimensional vectors (i.e., embeddings) to\nfacilitate further processing, which is one of the most common and critical\nsteps in many NLP tasks. We regard instructions as words in NLP-inspired binary\ncode analysis, and aim to represent instructions as embeddings as well.\n  To facilitate cross-architecture binary code analysis, our goal is that\nsimilar instructions, regardless of their architectures, have embeddings close\nto each other. To this end, we propose a joint learning approach to generating\ninstruction embeddings that capture not only the semantics of instructions\nwithin an architecture, but also their semantic relationships across\narchitectures. To the best of our knowledge, this is the first work on building\ncross-architecture instruction embedding model. As a showcase, we apply the\nmodel to resolving one of the most fundamental problems for binary code\nsimilarity comparison---semantics-based basic block comparison, and the\nsolution outperforms the code statistics based approach. It demonstrates that\nit is promising to apply the model to other cross-architecture binary code\nanalysis tasks.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 03:44:03 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Redmond", "Kimberly", ""], ["Luo", "Lannan", ""], ["Zeng", "Qiang", ""]]}, {"id": "1812.09659", "submitter": "Dianbo Liu Dr", "authors": "Dianbo Liu, Nestor Sepulveda, Ming Zheng", "title": "Artificial neural networks condensation: A strategy to facilitate\n  adaption of machine learning in medical settings by reducing computational\n  burden", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) applications on healthcare can have a great impact on\npeople's lives helping deliver better and timely treatment to those in need. At\nthe same time, medical data is usually big and sparse requiring important\ncomputational resources. Although it might not be a problem for wide-adoption\nof ML tools in developed nations, availability of computational resource can\nvery well be limited in third-world nations. This can prevent the less favored\npeople from benefiting of the advancement in ML applications for healthcare. In\nthis project we explored methods to increase computational efficiency of ML\nalgorithms, in particular Artificial Neural Nets (NN), while not compromising\nthe accuracy of the predicted results. We used in-hospital mortality prediction\nas our case analysis based on the MIMIC III publicly available dataset. We\nexplored three methods on two different NN architectures. We reduced the size\nof recurrent neural net (RNN) and dense neural net (DNN) by applying pruning of\n\"unused\" neurons. Additionally, we modified the RNN structure by adding a\nhidden-layer to the LSTM cell allowing to use less recurrent layers for the\nmodel. Finally, we implemented quantization on DNN forcing the weights to be\n8-bits instead of 32-bits. We found that all our methods increased\ncomputational efficiency without compromising accuracy and some of them even\nachieved higher accuracy than the pre-condensed baseline models.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 05:08:24 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Liu", "Dianbo", ""], ["Sepulveda", "Nestor", ""], ["Zheng", "Ming", ""]]}, {"id": "1812.09660", "submitter": "Sailik Sengupta", "authors": "Ankur Chowdhary, Sailik Sengupta, Dijiang Huang, Subbarao Kambhampati", "title": "Markov Game Modeling of Moving Target Defense for Strategic Detection of\n  Threats in Cloud Networks", "comments": "Author names marked with * contributed equally and are listed in\n  alphabetical order", "journal-ref": null, "doi": null, "report-no": "AICS/2019/01", "categories": "cs.AI cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The processing and storage of critical data in large-scale cloud networks\nnecessitate the need for scalable security solutions. It has been shown that\ndeploying all possible security measures incurs a cost on performance by using\nup valuable computing and networking resources which are the primary selling\npoints for cloud service providers. Thus, there has been a recent interest in\ndeveloping Moving Target Defense (MTD) mechanisms that helps one optimize the\njoint objective of maximizing security while ensuring that the impact on\nperformance is minimized. Often, these techniques model the problem of\nmulti-stage attacks by stealthy adversaries as a single-step attack detection\ngame using graph connectivity measures as a heuristic to measure performance,\nthereby (1) losing out on valuable information that is inherently present in\ngraph-theoretic models designed for large cloud networks, and (2) coming up\nwith certain strategies that have asymmetric impacts on performance. In this\nwork, we leverage knowledge in attack graphs of a cloud network in formulating\na zero-sum Markov Game and use the Common Vulnerability Scoring System (CVSS)\nto come up with meaningful utility values for this game. Then, we show that the\noptimal strategy of placing detecting mechanisms against an adversary is\nequivalent to computing the mixed Min-max Equilibrium of the Markov Game. We\ncompare the gains obtained by using our method to other techniques presently\nused in cloud network security, thereby showing its effectiveness. Finally, we\nhighlight how the method was used for a small real-world cloud system.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 05:16:23 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 01:26:02 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Chowdhary", "Ankur", ""], ["Sengupta", "Sailik", ""], ["Huang", "Dijiang", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1812.09681", "submitter": "Zhuoqian Yang", "authors": "Zhuoqian Yang, Zengchang Qin, Jing Yu, Yue Hu", "title": "Scene Graph Reasoning with Prior Visual Relationship for Visual Question\n  Answering", "comments": "14 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key issues of Visual Question Answering (VQA) is to reason with\nsemantic clues in the visual content under the guidance of the question, how to\nmodel relational semantics still remains as a great challenge. To fully capture\nvisual semantics, we propose to reason over a structured visual representation\n- scene graph, with embedded objects and inter-object relationships. This shows\ngreat benefit over vanilla vector representations and implicit visual\nrelationship learning. Based on existing visual relationship models, we propose\na visual relationship encoder that projects visual relationships into a learned\ndeep semantic space constrained by visual context and language priors. Upon the\nconstructed graph, we propose a Scene Graph Convolutional Network (SceneGCN) to\njointly reason the object properties and relational semantics for the correct\nanswer. We demonstrate the model's effectiveness and interpretability on the\nchallenging GQA dataset and the classical VQA 2.0 dataset, remarkably achieving\nstate-of-the-art 54.56% accuracy on GQA compared to the existing best model.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 09:59:49 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 16:42:04 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Yang", "Zhuoqian", ""], ["Qin", "Zengchang", ""], ["Yu", "Jing", ""], ["Hu", "Yue", ""]]}, {"id": "1812.09707", "submitter": "David Peer", "authors": "David Peer, Sebastian Stabinger, Antonio Rodriguez-Sanchez", "title": "Increasing the adversarial robustness and explainability of capsule\n  networks with $\\gamma$-capsules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a new inductive bias for capsule networks and call\nnetworks that use this prior $\\gamma$-capsule networks. Our inductive bias that\nis inspired by TE neurons of the inferior temporal cortex increases the\nadversarial robustness and the explainability of capsule networks. A\ntheoretical framework with formal definitions of $\\gamma$-capsule networks and\nmetrics for evaluation are also provided. Under our framework we show that\ncommon capsule networks do not necessarily make use of this inductive bias. For\nthis reason we introduce a novel routing algorithm and use a different training\nalgorithm to be able to implement $\\gamma$-capsule networks. We then show\nexperimentally that $\\gamma$-capsule networks are indeed more transparent and\nmore robust against adversarial attacks than regular capsule networks.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 13:32:59 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 16:38:48 GMT"}, {"version": "v3", "created": "Mon, 18 Nov 2019 09:04:49 GMT"}, {"version": "v4", "created": "Thu, 5 Dec 2019 10:04:26 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Peer", "David", ""], ["Stabinger", "Sebastian", ""], ["Rodriguez-Sanchez", "Antonio", ""]]}, {"id": "1812.09718", "submitter": "Francesco Calimeri", "authors": "Francesco Calimeri, Simona Perri, Jessica Zangari", "title": "Optimizing Answer Set Computation via Heuristic-Based Decomposition", "comments": "28 pages, 6 figures, 4 tables, BEST PAPER AWARD at PADL 2018 (Los\n  Angeles, CA, USA), Under consideration in Theory and Practice of Logic\n  Programming (TPLP)", "journal-ref": "Theory and Practice of Logic Programming 19 (2019) 603-628", "doi": "10.1017/S1471068419000036", "report-no": null, "categories": "cs.AI cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer Set Programming (ASP) is a purely declarative formalism developed in\nthe field of logic programming and nonmonotonic reasoning: computational\nproblems are encoded by logic programs whose answer sets, corresponding to\nsolutions, are computed by an ASP system. Different, semantically equivalent,\nprograms can be defined for the same problem; however, performance of systems\nevaluating them might significantly vary. We propose an approach for\nautomatically transforming an input logic program into an equivalent one that\ncan be evaluated more efficiently. One can make use of existing\ntree-decomposition techniques for rewriting selected rules into a set of\nmultiple ones; the idea is to guide and adaptively apply them on the basis of\nproper new heuristics, to obtain a smart rewriting algorithm to be integrated\ninto an ASP system. The method is rather general: it can be adapted to any\nsystem and implement different preference policies. Furthermore, we define a\nset of new heuristics tailored at optimizing grounding, one of the main phases\nof the ASP computation; we use them in order to implement the approach into the\nASP system DLV, in particular into its grounding subsystem I-DLV, and carry out\nan extensive experimental activity for assessing the impact of the proposal.\nUnder consideration in Theory and Practice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 14:35:58 GMT"}, {"version": "v2", "created": "Fri, 11 Jan 2019 17:27:16 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Calimeri", "Francesco", ""], ["Perri", "Simona", ""], ["Zangari", "Jessica", ""]]}, {"id": "1812.09724", "submitter": "Xi Chen", "authors": "Xi Chen, Caylin Hickey", "title": "Parallelized Interactive Machine Learning on Autonomous Vehicles", "comments": "6 pages, NAECON 2018 - IEEE National Aerospace and Electronics\n  Conference", "journal-ref": null, "doi": "10.1109/NAECON.2018.8556776", "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (deep RL) has achieved superior performance in\ncomplex sequential tasks by learning directly from image input. A deep neural\nnetwork is used as a function approximator and requires no specific state\ninformation. However, one drawback of using only images as input is that this\napproach requires a prohibitively large amount of training time and data for\nthe model to learn the state feature representation and approach reasonable\nperformance. This is not feasible in real-world applications, especially when\nthe data are expansive and training phase could introduce disasters that affect\nhuman safety. In this work, we use a human demonstration approach to speed up\ntraining for learning features and use the resulting pre-trained model to\nreplace the neural network in the deep RL Deep Q-Network (DQN), followed by\nhuman interaction to further refine the model. We empirically evaluate our\napproach by using only a human demonstration model and modified DQN with human\ndemonstration model included in the Microsoft AirSim car simulator. Our results\nshow that (1) pre-training with human demonstration in a supervised learning\napproach is better and much faster at discovering features than DQN alone, (2)\ninitializing the DQN with a pre-trained model provides a significant\nimprovement in training time and performance even with limited human\ndemonstration, and (3) providing the ability for humans to supply suggestions\nduring DQN training can speed up the network's convergence on an optimal\npolicy, as well as allow it to learn more complex policies that are harder to\ndiscover by random exploration.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 14:57:28 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Chen", "Xi", ""], ["Hickey", "Caylin", ""]]}, {"id": "1812.09755", "submitter": "Amanpreet Singh", "authors": "Amanpreet Singh, Tushar Jain, Sainbayar Sukhbaatar", "title": "Learning when to Communicate at Scale in Multiagent Cooperative and\n  Competitive Tasks", "comments": "Accepted to ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning when to communicate and doing that effectively is essential in\nmulti-agent tasks. Recent works show that continuous communication allows\nefficient training with back-propagation in multi-agent scenarios, but have\nbeen restricted to fully-cooperative tasks. In this paper, we present\nIndividualized Controlled Continuous Communication Model (IC3Net) which has\nbetter training efficiency than simple continuous communication model, and can\nbe applied to semi-cooperative and competitive settings along with the\ncooperative settings. IC3Net controls continuous communication with a gating\nmechanism and uses individualized rewards foreach agent to gain better\nperformance and scalability while fixing credit assignment issues. Using\nvariety of tasks including StarCraft BroodWars explore and combat scenarios, we\nshow that our network yields improved performance and convergence rates than\nthe baselines as the scale increases. Our results convey that IC3Net agents\nlearn when to communicate based on the scenario and profitability.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 19:07:36 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Singh", "Amanpreet", ""], ["Jain", "Tushar", ""], ["Sukhbaatar", "Sainbayar", ""]]}, {"id": "1812.09790", "submitter": "Mehdi Zakroum", "authors": "Mehdi Zakroum, Abdellah Houmz, Mounir Ghogho, Ghita Mezzour,\n  Abdelkader Lahmadi, J\\'er\\^ome Fran\\c{c}ois and Mohammed El Koutbi", "title": "Exploratory Data Analysis of a Network Telescope Traffic and Prediction\n  of Port Probing Rates", "comments": "IEEE Intelligence and Security Informatics", "journal-ref": null, "doi": "10.1109/ISI.2018.8587323", "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the properties exhibited by large scale network probing traffic\nwould improve cyber threat intelligence. In addition, the prediction of probing\nrates is a key feature for security practitioners in their endeavors for making\nbetter operational decisions and for enhancing their defense strategy skills.\nIn this work, we study different aspects of the traffic captured by a /20\nnetwork telescope. First, we perform an exploratory data analysis of the\ncollected probing activities. The investigation includes probing rates at the\nport level, services interesting top network probers and the distribution of\nprobing rates by geolocation. Second, we extract the network probers\nexploration patterns. We model these behaviors using transition graphs\ndecorated with probabilities of switching from a port to another. Finally, we\nassess the capacity of Non-stationary Autoregressive and Vector Autoregressive\nmodels in predicting port probing rates as a first step towards using more\nrobust models for better forecasting performance.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 22:46:50 GMT"}, {"version": "v2", "created": "Sat, 27 Apr 2019 11:23:30 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Zakroum", "Mehdi", ""], ["Houmz", "Abdellah", ""], ["Ghogho", "Mounir", ""], ["Mezzour", "Ghita", ""], ["Lahmadi", "Abdelkader", ""], ["Fran\u00e7ois", "J\u00e9r\u00f4me", ""], ["Koutbi", "Mohammed El", ""]]}, {"id": "1812.09793", "submitter": "Mehdi Zakroum", "authors": "Mehdi Zakroum, Mounir Ghogho, Mustapha Faqir and Mohamed Aymane\n  Ahajjam", "title": "Deep Learning for Inferring the Surface Solar Irradiance from Sky\n  Imagery", "comments": null, "journal-ref": null, "doi": "10.1109/IRSEC.2017.8477236", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach to perform ground-based estimation and prediction\nof the surface solar irradiance with the view to predicting photovoltaic energy\nproduction. We propose the use of mini-batch k-means clustering to extract\nfeatures, referred to as per cluster number of pixels (PCNP), from sky images\ntaken by a low-cost fish eye camera. These features are first used to classify\nthe sky as clear or cloudy using a single hidden layer neural network; the\nclassification accuracy achieves 99.7%. If the sky is classified as cloudy, we\npropose to use a deep neural network having as input features the PCNP to\npredict intra-hour variability of the solar irradiance. Toward this objective,\nin this paper, we focus on estimating the deep neural network model relating\nthe PCNP features and the solar irradiance, which is an important step before\nperforming the prediction task. The proposed deep learning-based estimation\napproach is shown to have an accuracy of 95%.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 23:16:54 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Zakroum", "Mehdi", ""], ["Ghogho", "Mounir", ""], ["Faqir", "Mustapha", ""], ["Ahajjam", "Mohamed Aymane", ""]]}, {"id": "1812.09905", "submitter": "Xuli Liu", "authors": "Xuli Liu and Jihao Jin and Qi Wang and Tong Ruan and Yangming Zhou and\n  Daqi Gao and Yichao Yin", "title": "PatientEG Dataset: Bringing Event Graph Model with Temporal Relations to\n  Electronic Medical Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Medical activities, such as diagnoses, medicine treatments, and laboratory\ntests, as well as temporal relations between these activities are the basic\nconcepts in clinical research. However, existing relational data model on\nelectronic medical records (EMRs) lacks explicit and accurate semantic\ndefinitions of these concepts. It leads to the inconvenience of query\nconstruction and the inefficiency of query execution where multi-table join\nqueries are frequently required. In this paper, we propose a patient event\ngraph (PatientEG) model to capture the characteristics of EMRs. We respectively\ndefine five types of medical entities, five types of medical events and five\ntypes of temporal relations. Based on the proposed model, we also construct a\nPatientEG dataset with 191,294 events, 3,429 distinct entities, and 545,993\ntemporal relations using EMRs from Shanghai Shuguang hospital. To help to\nnormalize entity values which contain synonyms, hyponymies, and abbreviations,\nwe link them with the Chinese biomedical knowledge graph. With the help of\nPatientEG dataset, we are able to conveniently perform complex queries for\nclinical research such as auxiliary diagnosis and therapeutic effectiveness\nanalysis. In addition, we provide a SPARQL endpoint to access PatientEG dataset\nand the dataset is also publicly available online. Also, we list several\nillustrative SPARQL queries on our website.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2018 12:05:42 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Liu", "Xuli", ""], ["Jin", "Jihao", ""], ["Wang", "Qi", ""], ["Ruan", "Tong", ""], ["Zhou", "Yangming", ""], ["Gao", "Daqi", ""], ["Yin", "Yichao", ""]]}, {"id": "1812.09926", "submitter": "Sirui Xie", "authors": "Sirui Xie, Hehui Zheng, Chunxiao Liu, Liang Lin", "title": "SNAS: Stochastic Neural Architecture Search", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Stochastic Neural Architecture Search (SNAS), an economical\nend-to-end solution to Neural Architecture Search (NAS) that trains neural\noperation parameters and architecture distribution parameters in same round of\nback-propagation, while maintaining the completeness and differentiability of\nthe NAS pipeline. In this work, NAS is reformulated as an optimization problem\non parameters of a joint distribution for the search space in a cell. To\nleverage the gradient information in generic differentiable loss for\narchitecture search, a novel search gradient is proposed. We prove that this\nsearch gradient optimizes the same objective as reinforcement-learning-based\nNAS, but assigns credits to structural decisions more efficiently. This credit\nassignment is further augmented with locally decomposable reward to enforce a\nresource-efficient constraint. In experiments on CIFAR-10, SNAS takes less\nepochs to find a cell architecture with state-of-the-art accuracy than\nnon-differentiable evolution-based and reinforcement-learning-based NAS, which\nis also transferable to ImageNet. It is also shown that child networks of SNAS\ncan maintain the validation accuracy in searching, with which attention-based\nNAS requires parameter retraining to compete, exhibiting potentials to stride\ntowards efficient NAS on big datasets. We have released our implementation at\nhttps://github.com/SNAS-Series/SNAS-Series.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2018 14:13:16 GMT"}, {"version": "v2", "created": "Sat, 12 Jan 2019 17:19:01 GMT"}, {"version": "v3", "created": "Wed, 1 Apr 2020 00:44:35 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Xie", "Sirui", ""], ["Zheng", "Hehui", ""], ["Liu", "Chunxiao", ""], ["Lin", "Liang", ""]]}, {"id": "1812.09968", "submitter": "Qi Wang", "authors": "Xingxing Liang, Qi Wang, Yanghe Feng, Zhong Liu, Jincai Huang", "title": "VMAV-C: A Deep Attention-based Reinforcement Learning Algorithm for\n  Model-based Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent breakthroughs in Go play and strategic games have witnessed the great\npotential of reinforcement learning in intelligently scheduling in uncertain\nenvironment, but some bottlenecks are also encountered when we generalize this\nparadigm to universal complex tasks. Among them, the low efficiency of data\nutilization in model-free reinforcement algorithms is of great concern. In\ncontrast, the model-based reinforcement learning algorithms can reveal\nunderlying dynamics in learning environments and seldom suffer the data\nutilization problem. To address the problem, a model-based reinforcement\nlearning algorithm with attention mechanism embedded is proposed as an\nextension of World Models in this paper. We learn the environment model through\nMixture Density Network Recurrent Network(MDN-RNN) for agents to interact, with\ncombinations of variational auto-encoder(VAE) and attention incorporated in\nstate value estimates during the process of learning policy. In this way, agent\ncan learn optimal policies through less interactions with actual environment,\nand final experiments demonstrate the effectiveness of our model in control\nproblem.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2018 19:25:23 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Liang", "Xingxing", ""], ["Wang", "Qi", ""], ["Feng", "Yanghe", ""], ["Liu", "Zhong", ""], ["Huang", "Jincai", ""]]}, {"id": "1812.10078", "submitter": "Zachary Pardos", "authors": "Weijie Jiang, Zachary A. Pardos, Qiang Wei", "title": "Goal-based Course Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With cross-disciplinary academic interests increasing and academic advising\nresources over capacity, the importance of exploring data-assisted methods to\nsupport student decision making has never been higher. We build on the findings\nand methodologies of a quickly developing literature around prediction and\nrecommendation in higher education and develop a novel recurrent neural\nnetwork-based recommendation system for suggesting courses to help students\nprepare for target courses of interest, personalized to their estimated prior\nknowledge background and zone of proximal development. We validate the model\nusing tests of grade prediction and the ability to recover prerequisite\nrelationships articulated by the university. In the third validation, we run\nthe fully personalized recommendation for students the semester before taking a\nhistorically difficult course and observe differential overlap with our\nwould-be suggestions. While not proof of causal effectiveness, these three\nevaluation perspectives on the performance of the goal-based model build\nconfidence and bring us one step closer to deployment of this personalized\ncourse preparation affordance in the wild.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2018 09:30:46 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Jiang", "Weijie", ""], ["Pardos", "Zachary A.", ""], ["Wei", "Qiang", ""]]}, {"id": "1812.10097", "submitter": "Morteza Haghir Chehreghani", "authors": "Yuxin Chen and Morteza Haghir Chehreghani", "title": "Trip Prediction by Leveraging Trip Histories from Neighboring Users", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach for trip prediction by analyzing user's trip\nhistories. We augment users' (self-) trip histories by adding 'similar' trips\nfrom other users, which could be informative and useful for predicting future\ntrips for a given user. This also helps to cope with noisy or sparse trip\nhistories, where the self-history by itself does not provide a reliable\nprediction of future trips. We show empirical evidence that by enriching the\nusers' trip histories with additional trips, one can improve the prediction\nerror by 15%-40%, evaluated on multiple subsets of the Nancy2012 dataset. This\nreal-world dataset is collected from public transportation ticket validations\nin the city of Nancy, France. Our prediction tool is a central component of a\ntrip simulator system designed to analyze the functionality of public\ntransportation in the city of Nancy.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2018 12:37:32 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Chen", "Yuxin", ""], ["Chehreghani", "Morteza Haghir", ""]]}, {"id": "1812.10144", "submitter": "Tshilidzi Marwala", "authors": "Tshilidzi Marwala", "title": "Can rationality be measured?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies whether rationality can be computed. Rationality is\ndefined as the use of complete information, which is processed with a perfect\nbiological or physical brain, in an optimized fashion. To compute rationality\none needs to quantify how complete is the information, how perfect is the\nphysical or biological brain and how optimized is the entire decision making\nsystem. The rationality of a model (i.e. physical or biological brain) is\nmeasured by the expected accuracy of the model. The rationality of the\noptimization procedure is measured as the ratio of the achieved objective (i.e.\nutility) to the global objective. The overall rationality of a decision is\nmeasured as the product of the rationality of the model and the rationality of\nthe optimization procedure. The conclusion reached is that rationality can be\ncomputed for convex optimization problems.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2018 17:52:39 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Marwala", "Tshilidzi", ""]]}, {"id": "1812.10230", "submitter": "Xinwei Geng", "authors": "Xinwei Geng, Longyue Wang, Xing Wang, Bing Qin, Ting Liu, Zhaopeng Tu", "title": "Learning to Refine Source Representations for Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) models generally adopt an encoder-decoder\narchitecture for modeling the entire translation process. The encoder\nsummarizes the representation of input sentence from scratch, which is\npotentially a problem if the sentence is ambiguous. When translating a text,\nhumans often create an initial understanding of the source sentence and then\nincrementally refine it along the translation on the target side. Starting from\nthis intuition, we propose a novel encoder-refiner-decoder framework, which\ndynamically refines the source representations based on the generated\ntarget-side information at each decoding step. Since the refining operations\nare time-consuming, we propose a strategy, leveraging the power of\nreinforcement learning models, to decide when to refine at specific decoding\nsteps. Experimental results on both Chinese-English and English-German\ntranslation tasks show that the proposed approach significantly and\nconsistently improves translation performance over the standard encoder-decoder\nframework. Furthermore, when refining strategy is applied, results still show\nreasonable improvement over the baseline without much decrease in decoding\nspeed.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 05:17:03 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Geng", "Xinwei", ""], ["Wang", "Longyue", ""], ["Wang", "Xing", ""], ["Qin", "Bing", ""], ["Liu", "Ting", ""], ["Tu", "Zhaopeng", ""]]}, {"id": "1812.10235", "submitter": "Yu Wang", "authors": "Yu Wang, Yilin Shen, Hongxia Jin", "title": "A Bi-model based RNN Semantic Frame Parsing Model for Intent Detection\n  and Slot Filling", "comments": "5 pages, published at 2018 NAACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intent detection and slot filling are two main tasks for building a spoken\nlanguage understanding(SLU) system. Multiple deep learning based models have\ndemonstrated good results on these tasks . The most effective algorithms are\nbased on the structures of sequence to sequence models (or \"encoder-decoder\"\nmodels), and generate the intents and semantic tags either using separate\nmodels or a joint model. Most of the previous studies, however, either treat\nthe intent detection and slot filling as two separate parallel tasks, or use a\nsequence to sequence model to generate both semantic tags and intent. Most of\nthese approaches use one (joint) NN based model (including encoder-decoder\nstructure) to model two tasks, hence may not fully take advantage of the\ncross-impact between them. In this paper, new Bi-model based RNN semantic frame\nparsing network structures are designed to perform the intent detection and\nslot filling tasks jointly, by considering their cross-impact to each other\nusing two correlated bidirectional LSTMs (BLSTM). Our Bi-model structure with a\ndecoder achieves state-of-the-art result on the benchmark ATIS data, with about\n0.5$\\%$ intent accuracy improvement and 0.9 $\\%$ slot filling improvement.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 05:55:42 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Wang", "Yu", ""], ["Shen", "Yilin", ""], ["Jin", "Hongxia", ""]]}, {"id": "1812.10308", "submitter": "Harshavardhan Kamarthi", "authors": "Harshavardhan Kamarthi, Kousik Krishnan", "title": "Hierarchical Genetic Algorithms with evolving objective functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework of genetic algorithms which use multi-level\nhierarchies to solve an optimization problem by searching over the space of\nsimpler objective functions. We solve a variant of Travelling Salesman Problem\ncalled \\texttt{soft-TSP} and show that when the constraints on the overall\nobjective function are changed the algorithm adapts to churn out solutions for\nthe changed objective. We use this idea to speed up learning by systematically\naltering the constraints to find a more globally optimal solution. We also use\nthis framework to solve polynomial regression where the actual objective\nfunction is unknown but searching over space of available objective functions\nyields a good approximate solution.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 16:38:45 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 14:06:51 GMT"}, {"version": "v3", "created": "Mon, 5 Aug 2019 10:44:39 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Kamarthi", "Harshavardhan", ""], ["Krishnan", "Kousik", ""]]}, {"id": "1812.10358", "submitter": "Lior Bracha", "authors": "Lior Bracha, Gal Chechik", "title": "Informative Object Annotations: Tell Me Something I Don't Know", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capturing the interesting components of an image is a key aspect of image\nunderstanding. When a speaker annotates an image, selecting labels that are\ninformative greatly depends on the prior knowledge of a prospective listener.\nMotivated by cognitive theories of categorization and communication, we present\na new unsupervised approach to model this prior knowledge and quantify the\ninformativeness of a description. Specifically, we compute how knowledge of a\nlabel reduces uncertainty over the space of labels and utilize this to rank\ncandidate labels for describing an image. While the full estimation problem is\nintractable, we describe an efficient algorithm to approximate entropy\nreduction using a tree-structured graphical model. We evaluate our approach on\nthe open-images dataset using a new evaluation set of 10K ground-truth ratings\nand find that it achieves ~65% agreement with human raters, largely\noutperforming other unsupervised baseline approaches.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 16:12:30 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Bracha", "Lior", ""], ["Chechik", "Gal", ""]]}, {"id": "1812.10398", "submitter": "William Herlands", "authors": "Maria De-Arteaga, Amanda Coston, William Herlands", "title": "Proceedings of NeurIPS 2018 Workshop on Machine Learning for the\n  Developing World: Achieving Sustainable Impact", "comments": "18 papers in the proceedings. 10 additional papers were presented at\n  the workshop but not included in the proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of NeurIPS 2018 Workshop on Machine Learning for the\nDeveloping World: Achieving Sustainable Impact, held in Montreal, Canada on\nDecember 8, 2018\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 03:29:09 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 22:25:48 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["De-Arteaga", "Maria", ""], ["Coston", "Amanda", ""], ["Herlands", "William", ""]]}, {"id": "1812.10410", "submitter": "Maria Barbati Dr", "authors": "Maria Barbati and Jos\\`e Rui Figueira and Salvatore Greco and Alessio\n  Ishizaka and Simona Panaro", "title": "A multiple criteria methodology for priority based portfolio selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new methodology that combines a multiple criteria\nsorting or ranking method with a project portfolio selection procedure. The\nmulticriteria method permits to compare projects in terms of their priority\nassessed on the basis of a set of both qualitative and quantitative criteria.\nThen, a feasible set of projects, i.e. a portfolio, is selected according to\nthe priority defined by the multiple criteria method. In addition, the\nportfolio must satisfy a set of resources constraints, e.g. budget available,\nas well as some logical constraints, e.g. related to projects to be selected\ntogether or projects mutually exclusive. The proposed portfolio selection\nmethodology can be applied in different contexts. We present an application in\nthe urban planning domain where our approach allows to select a set of urban\nprojects on the basis of their priority, budgetary constraints and urban policy\nrequirements. Given the increasing interest of historical cities to reuse their\ncultural heritage, we applied and tested our methodology in this context. In\nparticular, we show how the methodology can support the prioritization of the\ninterventions on buildings with some historical value in the historic city\ncenter of Naples (Italy), taking into account several points of view.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 12:44:51 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 10:27:23 GMT"}, {"version": "v3", "created": "Sun, 21 Mar 2021 16:47:01 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Barbati", "Maria", ""], ["Figueira", "Jos\u00e8 Rui", ""], ["Greco", "Salvatore", ""], ["Ishizaka", "Alessio", ""], ["Panaro", "Simona", ""]]}, {"id": "1812.10464", "submitter": "Mikel Artetxe", "authors": "Mikel Artetxe, Holger Schwenk", "title": "Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual\n  Transfer and Beyond", "comments": "TACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an architecture to learn joint multilingual sentence\nrepresentations for 93 languages, belonging to more than 30 different families\nand written in 28 different scripts. Our system uses a single BiLSTM encoder\nwith a shared BPE vocabulary for all languages, which is coupled with an\nauxiliary decoder and trained on publicly available parallel corpora. This\nenables us to learn a classifier on top of the resulting embeddings using\nEnglish annotated data only, and transfer it to any of the 93 languages without\nany modification. Our experiments in cross-lingual natural language inference\n(XNLI dataset), cross-lingual document classification (MLDoc dataset) and\nparallel corpus mining (BUCC dataset) show the effectiveness of our approach.\nWe also introduce a new test set of aligned sentences in 112 languages, and\nshow that our sentence embeddings obtain strong results in multilingual\nsimilarity search even for low-resource languages. Our implementation, the\npre-trained encoder and the multilingual test set are available at\nhttps://github.com/facebookresearch/LASER\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 18:58:39 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 13:16:12 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Artetxe", "Mikel", ""], ["Schwenk", "Holger", ""]]}, {"id": "1812.10528", "submitter": "Lichao Sun", "authors": "Lichao Sun, Yingtong Dou, Carl Yang, Ji Wang, Philip S. Yu, Lifang He,\n  Bo Li", "title": "Adversarial Attack and Defense on Graph Data: A Survey", "comments": "In submission to Journal. For more open-source and up-to-date\n  information, please check our Github repository:\n  https://github.com/YingtongDou/graph-adversarial-learning-literature", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been widely applied to various applications\nincluding image classification, text generation, audio recognition, and graph\ndata analysis. However, recent studies have shown that DNNs are vulnerable to\nadversarial attacks. Though there are several works studying adversarial attack\nand defense strategies on domains such as images and natural language\nprocessing, it is still difficult to directly transfer the learned knowledge to\ngraph structure data due to its representation challenges. Given the importance\nof graph analysis, an increasing number of works start to analyze the\nrobustness of machine learning models on graph data. Nevertheless, current\nstudies considering adversarial behaviors on graph data usually focus on\nspecific types of attacks with certain assumptions. In addition, each work\nproposes its own mathematical formulation which makes the comparison among\ndifferent methods difficult. Therefore, in this paper, we aim to survey\nexisting adversarial learning strategies on graph data and first provide a\nunified formulation for adversarial learning on graph data which covers most\nadversarial learning studies on graph. Moreover, we also compare different\nattacks and defenses on graph data and discuss their corresponding\ncontributions and limitations. In this work, we systemically organize the\nconsidered works based on the features of each topic. This survey not only\nserves as a reference for the research community, but also brings a clear image\nresearchers outside this research domain. Besides, we also create an online\nresource and keep updating the relevant papers during the last two years. More\ndetails of the comparisons of various studies based on this survey are\nopen-sourced at\nhttps://github.com/YingtongDou/graph-adversarial-learning-literature.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 20:27:42 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 03:49:29 GMT"}, {"version": "v3", "created": "Tue, 14 Jul 2020 22:11:52 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Sun", "Lichao", ""], ["Dou", "Yingtong", ""], ["Yang", "Carl", ""], ["Wang", "Ji", ""], ["Yu", "Philip S.", ""], ["He", "Lifang", ""], ["Li", "Bo", ""]]}, {"id": "1812.10537", "submitter": "Tawfik Masrour", "authors": "Abdelmoula Khdoudi and Tawfik Masrour", "title": "Prediction of Industrial Process Parameters using Artificial\n  Intelligence Algorithms", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper, a method of defining the industrial process parameters\nfor a new product using machine learning algorithms will be presented. The\nstudy will describe how to go from the product characteristics till the\nprediction of the suitable machine parameters to produce a good quality of this\nproduct, and this is based on an historical training dataset of similar\nproducts with their respective process parameters. In the first part of our\nstudy, we will focus on the ultrasonic welding process definition, welding\nparameters and on how it operate. While in second part, we present the design\nand implementation of the prediction models such multiple linear regression,\nsupport vector regression, and we compare them to an artificial neural networks\nalgorithm. In the following part, we present a new application of Convolutional\nNeural Networks (CNN) to the industrial process parameters prediction. In\naddition, we will propose the generalization approach of our CNN to any\nprediction problem of industrial process parameters. Finally the results of the\nfour methods will be interpreted and discussed.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 21:04:13 GMT"}, {"version": "v2", "created": "Sun, 3 Feb 2019 18:26:22 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Khdoudi", "Abdelmoula", ""], ["Masrour", "Tawfik", ""]]}, {"id": "1812.10578", "submitter": "Truyen Tran", "authors": "Hoa Khanh Dam, Truyen Tran, John Grundy, Aditya Ghose, Yasutaka Kamei", "title": "Towards effective AI-powered agile project management", "comments": "In Proceedings of International Conference on Software Engineering\n  (ICSE 2019), (To appear), NIER track, May 2019 (Montreal, Canada)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of Artificial intelligence (AI) has the potential to significantly\ntransform the practice of project management. Project management has a large\nsocio-technical element with many uncertainties arising from variability in\nhuman aspects e.g., customers' needs, developers' performance and team\ndynamics. AI can assist project managers and team members by automating\nrepetitive, high-volume tasks to enable project analytics for estimation and\nrisk prediction, providing actionable recommendations, and even making\ndecisions. AI is potentially a game changer for project management in helping\nto accelerate productivity and increase project success rates. In this paper,\nwe propose a framework where AI technologies can be leveraged to offer support\nfor managing agile projects, which have become increasingly popular in the\nindustry.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 00:00:49 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Dam", "Hoa Khanh", ""], ["Tran", "Truyen", ""], ["Grundy", "John", ""], ["Ghose", "Aditya", ""], ["Kamei", "Yasutaka", ""]]}, {"id": "1812.10607", "submitter": "Ken Li", "authors": "Hui Li, Kailiang Hu, Zhibang Ge, Tao Jiang, Yuan Qi, Le Song", "title": "Double Neural Counterfactual Regret Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual Regret Minimization (CRF) is a fundamental and effective\ntechnique for solving Imperfect Information Games (IIG). However, the original\nCRF algorithm only works for discrete state and action spaces, and the\nresulting strategy is maintained as a tabular representation. Such tabular\nrepresentation limits the method from being directly applied to large games and\ncontinuing to improve from a poor strategy profile. In this paper, we propose a\ndouble neural representation for the imperfect information games, where one\nneural network represents the cumulative regret, and the other represents the\naverage strategy. Furthermore, we adopt the counterfactual regret minimization\nalgorithm to optimize this double neural representation. To make neural\nlearning efficient, we also developed several novel techniques including a\nrobust sampling method, mini-batch Monte Carlo Counterfactual Regret\nMinimization (MCCFR) and Monte Carlo Counterfactual Regret Minimization Plus\n(MCCFR+) which may be of independent interests. Experimentally, we demonstrate\nthat the proposed double neural algorithm converges significantly better than\nthe reinforcement learning counterpart.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 03:31:33 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Li", "Hui", ""], ["Hu", "Kailiang", ""], ["Ge", "Zhibang", ""], ["Jiang", "Tao", ""], ["Qi", "Yuan", ""], ["Song", "Le", ""]]}, {"id": "1812.10628", "submitter": "Amber Nigam", "authors": "Amber Nigam, Prashik Sahare, Kushagra Pandya", "title": "Intent Detection and Slots Prompt in a Closed-Domain Chatbot", "comments": "Accepted paper for IEEE ICSC 2019 (4 pages, 1 figure, 6 tables)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a methodology for predicting intent and slots of\na query for a chatbot that answers career-related queries. We take a\nmulti-staged approach where both the processes (intent-classification and\nslot-tagging) inform each other's decision-making in different stages. The\nmodel breaks down the problem into stages, solving one problem at a time and\npassing on relevant results of the current stage to the next, thereby reducing\nsearch space for subsequent stages, and eventually making classification and\ntagging more viable after each stage. We also observe that relaxing rules for a\nfuzzy entity-matching in slot-tagging after each stage (by maintaining a\nseparate Named Entity Tagger per stage) helps us improve performance, although\nat a slight cost of false-positives. Our model has achieved state-of-the-art\nperformance with F1-score of 77.63% for intent-classification and 82.24% for\nslot-tagging on our dataset that we would publicly release along with the\npaper.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 05:14:49 GMT"}, {"version": "v2", "created": "Thu, 10 Jan 2019 20:23:54 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Nigam", "Amber", ""], ["Sahare", "Prashik", ""], ["Pandya", "Kushagra", ""]]}, {"id": "1812.10757", "submitter": "Chandra Khatri", "authors": "Chandra Khatri, Behnam Hedayatnia, Anu Venkatesh, Jeff Nunn, Yi Pan,\n  Qing Liu, Han Song, Anna Gottardi, Sanjeev Kwatra, Sanju Pancholi, Ming\n  Cheng, Qinglang Chen, Lauren Stubel, Karthik Gopalakrishnan, Kate Bland,\n  Raefer Gabriel, Arindam Mandal, Dilek Hakkani-Tur, Gene Hwang, Nate Michel,\n  Eric King, Rohit Prasad", "title": "Advancing the State of the Art in Open Domain Dialog Systems through the\n  Alexa Prize", "comments": "2018 Alexa Prize Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building open domain conversational systems that allow users to have engaging\nconversations on topics of their choice is a challenging task. Alexa Prize was\nlaunched in 2016 to tackle the problem of achieving natural, sustained,\ncoherent and engaging open-domain dialogs. In the second iteration of the\ncompetition in 2018, university teams advanced the state of the art by using\ncontext in dialog models, leveraging knowledge graphs for language\nunderstanding, handling complex utterances, building statistical and\nhierarchical dialog managers, and leveraging model-driven signals from user\nresponses. The 2018 competition also included the provision of a suite of tools\nand models to the competitors including the CoBot (conversational bot) toolkit,\ntopic and dialog act detection models, conversation evaluators, and a sensitive\ncontent detection model so that the competing teams could focus on building\nknowledge-rich, coherent and engaging multi-turn dialog systems. This paper\noutlines the advances developed by the university teams as well as the Alexa\nPrize team to achieve the common goal of advancing the science of\nConversational AI. We address several key open-ended problems such as\nconversational speech recognition, open domain natural language understanding,\ncommonsense reasoning, statistical dialog management, and dialog evaluation.\nThese collaborative efforts have driven improved experiences by Alexa users to\nan average rating of 3.61, the median duration of 2 mins 18 seconds, and\naverage turns to 14.6, increases of 14%, 92%, 54% respectively since the launch\nof the 2018 competition. For conversational speech recognition, we have\nimproved our relative Word Error Rate by 55% and our relative Entity Error Rate\nby 34% since the launch of the Alexa Prize. Socialbots improved in quality\nsignificantly more rapidly in 2018, in part due to the release of the CoBot\ntoolkit.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 16:17:30 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Khatri", "Chandra", ""], ["Hedayatnia", "Behnam", ""], ["Venkatesh", "Anu", ""], ["Nunn", "Jeff", ""], ["Pan", "Yi", ""], ["Liu", "Qing", ""], ["Song", "Han", ""], ["Gottardi", "Anna", ""], ["Kwatra", "Sanjeev", ""], ["Pancholi", "Sanju", ""], ["Cheng", "Ming", ""], ["Chen", "Qinglang", ""], ["Stubel", "Lauren", ""], ["Gopalakrishnan", "Karthik", ""], ["Bland", "Kate", ""], ["Gabriel", "Raefer", ""], ["Mandal", "Arindam", ""], ["Hakkani-Tur", "Dilek", ""], ["Hwang", "Gene", ""], ["Michel", "Nate", ""], ["King", "Eric", ""], ["Prasad", "Rohit", ""]]}, {"id": "1812.10797", "submitter": "Jian Lin", "authors": "Jian Lin, Zhong Yuan Lai, Xiaopeng Li", "title": "Quantum Adiabatic Algorithm Design using Reinforcement Learning", "comments": "11 pages, 10 figures", "journal-ref": "Phys. Rev. A 101, 052327 (2020)", "doi": "10.1103/PhysRevA.101.052327", "report-no": null, "categories": "quant-ph cond-mat.dis-nn cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum algorithm design plays a crucial role in exploiting the computational\nadvantage of quantum devices. Here we develop a deep-reinforcement-learning\nbased approach for quantum adiabatic algorithm design. Our approach is\ngenerically applicable to a class of problems with solution hard-to-find but\neasy-to-verify, e.g., searching and NP-complete problems. We benchmark this\napproach in Grover-search and 3-SAT problems, and find that the\nadiabatic-algorithm obtained by our RL approach leads to significant\nimprovement in the resultant success probability. In application to Grover\nsearch, our RL-design automatically produces an adiabatic quantum algorithm\nthat has the quadratic speedup. We find for all our studied cases that\nquantitatively the RL-designed algorithm has a better performance compared to\nthe analytically constructed non-linear Hamiltonian path when the encoding\nHamiltonian is solvable, and that this RL-design approach remains applicable\neven when the non-linear Hamiltonian path is not analytically available. In\n3-SAT, we find RL-design has fascinating transferability---the adiabatic\nalgorithm obtained by training on a specific choice of clause number leads to\nbetter performance consistently over the linear algorithm on different clause\nnumbers. These findings suggest the applicability of reinforcement learning for\nautomated quantum adiabatic algorithm design. Further considering the\nestablished complexity-equivalence of circuit and adiabatic quantum algorithms,\nwe expect the RL-designed adiabatic algorithm to inspire novel circuit\nalgorithms as well. Our approach is potentially applicable to different quantum\nhardwares from trapped-ions and optical-lattices to superconducting-qubit\ndevices.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 19:00:03 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 04:50:35 GMT"}, {"version": "v3", "created": "Wed, 29 Apr 2020 04:42:26 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Lin", "Jian", ""], ["Lai", "Zhong Yuan", ""], ["Li", "Xiaopeng", ""]]}, {"id": "1812.10851", "submitter": "Pavel Surynek", "authors": "Pavel Surynek", "title": "A Summary of Adaptation of Techniques from Search-based Optimal\n  Multi-Agent Path Finding Solvers to Compilation-based Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the multi-agent path finding problem (MAPF) we are given a set of agents\neach with respective start and goal positions. The task is to find paths for\nall agents while avoiding collisions aiming to minimize an objective function.\nTwo such common objective functions is the sum-of-costs and the makespan. Many\noptimal solvers were introduced in the past decade - two prominent categories\nof solvers can be distinguished: search-based solvers and compilation-based\nsolvers.\n  Search-based solvers were developed and tested for the sum-of-costs objective\nwhile the most prominent compilation-based solvers that are built around\nBoolean satisfiability (SAT) were designed for the makespan objective. Very\nlittle was known on the performance and relevance of the compilation-based\napproach on the sum-of-costs objective. In this paper we show how to close the\ngap between these cost functions in the compilation-based approach. Moreover we\nstudy applicability of various techniques developed for search-based solvers in\nthe compilation-based approach.\n  A part of this paper introduces a SAT-solver that is directly aimed to solve\nthe sum-of-costs objective function. Using both a lower bound on the\nsum-of-costs and an upper bound on the makespan, we are able to have a\nreasonable number of variables in our SAT encoding. We then further improve the\nencoding by borrowing ideas from ICTS, a search-based solver. Experimental\nevaluation on several domains show that there are many scenarios where our new\nSAT-based methods outperforms the best variants of previous sum-of-costs search\nsolvers - the ICTS, CBS algorithms, and ICBS algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 00:36:29 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Surynek", "Pavel", ""]]}, {"id": "1812.10900", "submitter": "Kushal Shah", "authors": "Kushal Shah", "title": "Open-endedness in AI systems, cellular evolution and intellectual\n  discussions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the biggest challenges that artificial intelligence (AI) research is\nfacing in recent times is to develop algorithms and systems that are not only\ngood at performing a specific intelligent task but also good at learning a very\ndiverse of skills somewhat like humans do. In other words, the goal is to be\nable to mimic biological evolution which has produced all the living species on\nthis planet and which seems to have no end to its creativity. The process of\nintellectual discussions is also somewhat similar to biological evolution in\nthis regard and is responsible for many of the innovative discoveries and\ninventions that scientists and engineers have made in the past. In this paper,\nwe present an information theoretic analogy between the process of discussions\nand the molecular dynamics within a cell, showing that there is a common\nprocess of information exchange at the heart of these two seemingly different\nprocesses, which can perhaps help us in building AI systems capable of\nopen-ended innovation. We also discuss the role of consciousness in this\nprocess and present a framework for the development of open-ended AI systems.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 06:11:56 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Shah", "Kushal", ""]]}, {"id": "1812.10961", "submitter": "Sergey Belim", "authors": "S.V. Belim, N.F. Bogachenko, A.N. Kabanov", "title": "A Precedent Approach to Assigning Access Rights", "comments": null, "journal-ref": null, "doi": "10.1088/1742-6596/1210/1/012010", "report-no": null, "categories": "cs.CR cs.AI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To design a discretionary access control policy, a technique is proposed that\nuses the principle of analogies and is based on both the properties of objects\nand the properties of subjects. As attributes characterizing these properties,\nthe values of the security attributes of subjects and objects are chosen. The\nconcept of precedent is defined as an access rule explicitly specified by the\nsecurity administrator. The problem of interpolation of the access matrix is\nformulated: the security administrator defines a sequence of precedents, it is\nrequired to automate the process of filling the remaining cells of the access\nmatrix. On the family of sets of security attributes, a linear order is\nintroduced. The principles of filling the access matrix on the basis of analogy\nwith the dominant precedent in accordance with a given order relation are\ndeveloped. The analysis of the proposed methodology is performed and its main\nadvantages are revealed.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 11:51:14 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Belim", "S. V.", ""], ["Bogachenko", "N. F.", ""], ["Kabanov", "A. N.", ""]]}, {"id": "1812.10972", "submitter": "Michael Janner", "authors": "Michael Janner, Sergey Levine, William T. Freeman, Joshua B.\n  Tenenbaum, Chelsea Finn, Jiajun Wu", "title": "Reasoning About Physical Interactions with Object-Oriented Prediction\n  and Planning", "comments": "ICLR 2019, project page:\n  https://people.eecs.berkeley.edu/~janner/o2p2/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object-based factorizations provide a useful level of abstraction for\ninteracting with the world. Building explicit object representations, however,\noften requires supervisory signals that are difficult to obtain in practice. We\npresent a paradigm for learning object-centric representations for physical\nscene understanding without direct supervision of object properties. Our model,\nObject-Oriented Prediction and Planning (O2P2), jointly learns a perception\nfunction to map from image observations to object representations, a pairwise\nphysics interaction function to predict the time evolution of a collection of\nobjects, and a rendering function to map objects back to pixels. For\nevaluation, we consider not only the accuracy of the physical predictions of\nthe model, but also its utility for downstream tasks that require an actionable\nrepresentation of intuitive physics. After training our model on an image\nprediction task, we can use its learned representations to build block towers\nmore complicated than those observed during training.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 12:18:23 GMT"}, {"version": "v2", "created": "Mon, 7 Jan 2019 08:27:03 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Janner", "Michael", ""], ["Levine", "Sergey", ""], ["Freeman", "William T.", ""], ["Tenenbaum", "Joshua B.", ""], ["Finn", "Chelsea", ""], ["Wu", "Jiajun", ""]]}, {"id": "1812.11103", "submitter": "Tuomas Haarnoja", "authors": "Tuomas Haarnoja, Sehoon Ha, Aurick Zhou, Jie Tan, George Tucker,\n  Sergey Levine", "title": "Learning to Walk via Deep Reinforcement Learning", "comments": "RSS 2019, https://sites.google.com/view/minitaur-locomotion/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (deep RL) holds the promise of automating the\nacquisition of complex controllers that can map sensory inputs directly to\nlow-level actions. In the domain of robotic locomotion, deep RL could enable\nlearning locomotion skills with minimal engineering and without an explicit\nmodel of the robot dynamics. Unfortunately, applying deep RL to real-world\nrobotic tasks is exceptionally difficult, primarily due to poor sample\ncomplexity and sensitivity to hyperparameters. While hyperparameters can be\neasily tuned in simulated domains, tuning may be prohibitively expensive on\nphysical systems, such as legged robots, that can be damaged through extensive\ntrial-and-error learning. In this paper, we propose a sample-efficient deep RL\nalgorithm based on maximum entropy RL that requires minimal per-task tuning and\nonly a modest number of trials to learn neural network policies. We apply this\nmethod to learning walking gaits on a real-world Minitaur robot. Our method can\nacquire a stable gait from scratch directly in the real world in about two\nhours, without relying on any model or simulation, and the resulting policy is\nrobust to moderate variations in the environment. We further show that our\nalgorithm achieves state-of-the-art performance on simulated benchmarks with a\nsingle set of hyperparameters. Videos of training and the learned policy can be\nfound on the project website.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 10:07:13 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 09:36:49 GMT"}, {"version": "v3", "created": "Wed, 19 Jun 2019 17:40:58 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Haarnoja", "Tuomas", ""], ["Ha", "Sehoon", ""], ["Zhou", "Aurick", ""], ["Tan", "Jie", ""], ["Tucker", "George", ""], ["Levine", "Sergey", ""]]}, {"id": "1812.11142", "submitter": "Guy Marshall", "authors": "Guy Marshall and Andr\\'e Freitas", "title": "The Diagrammatic AI Language (DIAL): Version 0.1", "comments": "21 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, there is no consistent model for visually or formally representing\nthe architecture of AI systems. This lack of representation brings\ninterpretability, correctness and completeness challenges in the description of\nexisting models and systems. DIAL (The Diagrammatic AI Language) has been\ncreated with the aspiration of being an \"engineering schematic\" for AI Systems.\nIt is presented here as a starting point for a community dialogue towards a\ncommon diagrammatic language for AI Systems.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 18:11:12 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Marshall", "Guy", ""], ["Freitas", "Andr\u00e9", ""]]}, {"id": "1812.11158", "submitter": "Vishwanath D", "authors": "Vishwanath D, Lovekesh Vig, Gautam Shroff and Puneet Agarwal", "title": "MEETING BOT: Reinforcement Learning for Dialogue Based Meeting\n  Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present Meeting Bot, a reinforcement learning based\nconversational system that interacts with multiple users to schedule meetings.\nThe system is able to interpret user utterences and map them to preferred time\nslots, which are then fed to a reinforcement learning (RL) system with the goal\nof converging on an agreeable time slot. The RL system is able to adapt to user\npreferences and environmental changes in meeting arrival rate while still\nscheduling effectively. Learning is performed via policy gradient with\nexploration, by utilizing an MLP as an approximator of the policy function.\nResults demonstrate that the system outperforms standard scheduling algorithms\nin terms of overall scheduling efficiency. Additionally, the system is able to\nadapt its strategy to situations when users consistently reject or accept\nmeetings in certain slots (such as Friday afternoon versus Thursday morning),\nor when the meeting is called by members who are at a more senior designation.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 18:44:49 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["D", "Vishwanath", ""], ["Vig", "Lovekesh", ""], ["Shroff", "Gautam", ""], ["Agarwal", "Puneet", ""]]}, {"id": "1812.11166", "submitter": "Xiuming Zhang", "authors": "Xiuming Zhang, Zhoutong Zhang, Chengkai Zhang, Joshua B. Tenenbaum,\n  William T. Freeman, Jiajun Wu", "title": "Learning to Reconstruct Shapes from Unseen Classes", "comments": "NeurIPS 2018 (Oral). The first two authors contributed equally to\n  this paper. Project page: http://genre.csail.mit.edu/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From a single image, humans are able to perceive the full 3D shape of an\nobject by exploiting learned shape priors from everyday life. Contemporary\nsingle-image 3D reconstruction algorithms aim to solve this task in a similar\nfashion, but often end up with priors that are highly biased by training\nclasses. Here we present an algorithm, Generalizable Reconstruction (GenRe),\ndesigned to capture more generic, class-agnostic shape priors. We achieve this\nwith an inference network and training procedure that combine 2.5D\nrepresentations of visible surfaces (depth and silhouette), spherical shape\nrepresentations of both visible and non-visible surfaces, and 3D voxel-based\nrepresentations, in a principled manner that exploits the causal structure of\nhow 3D shapes give rise to 2D images. Experiments demonstrate that GenRe\nperforms well on single-view shape reconstruction, and generalizes to diverse\nnovel objects from categories not seen during training.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 18:52:50 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Zhang", "Xiuming", ""], ["Zhang", "Zhoutong", ""], ["Zhang", "Chengkai", ""], ["Tenenbaum", "Joshua B.", ""], ["Freeman", "William T.", ""], ["Wu", "Jiajun", ""]]}, {"id": "1812.11240", "submitter": "Norman Tasfi", "authors": "Norman Tasfi and Miriam Capretz", "title": "Dynamic Planning Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Dynamic Planning Networks (DPN), a novel architecture for deep\nreinforcement learning, that combines model-based and model-free aspects for\nonline planning. Our architecture learns to dynamically construct plans using a\nlearned state-transition model by selecting and traversing between simulated\nstates and actions to maximize information before acting. In contrast to\nmodel-free methods, model-based planning lets the agent efficiently test action\nhypotheses without performing costly trial-and-error in the environment. DPN\nlearns to efficiently form plans by expanding a single action-conditional state\ntransition at a time instead of exhaustively evaluating each action, reducing\nthe required number of state-transitions during planning by up to 96%. We\nobserve various emergent planning patterns used to solve environments,\nincluding classical search methods such as breadth-first and depth-first\nsearch. DPN shows improved data efficiency, performance, and generalization to\nnew and unseen domains in comparison to several baselines.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 22:37:30 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 15:15:44 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Tasfi", "Norman", ""], ["Capretz", "Miriam", ""]]}, {"id": "1812.11270", "submitter": "Yu Meng", "authors": "Yu Meng, Jiaming Shen, Chao Zhang, Jiawei Han", "title": "Weakly-Supervised Hierarchical Text Classification", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical text classification, which aims to classify text documents into\na given hierarchy, is an important task in many real-world applications.\nRecently, deep neural models are gaining increasing popularity for text\nclassification due to their expressive power and minimum requirement for\nfeature engineering. However, applying deep neural networks for hierarchical\ntext classification remains challenging, because they heavily rely on a large\namount of training data and meanwhile cannot easily determine appropriate\nlevels of documents in the hierarchical setting. In this paper, we propose a\nweakly-supervised neural method for hierarchical text classification. Our\nmethod does not require a large amount of training data but requires only\neasy-to-provide weak supervision signals such as a few class-related documents\nor keywords. Our method effectively leverages such weak supervision signals to\ngenerate pseudo documents for model pre-training, and then performs\nself-training on real unlabeled data to iteratively refine the model. During\nthe training process, our model features a hierarchical neural structure, which\nmimics the given hierarchy and is capable of determining the proper levels for\ndocuments with a blocking mechanism. Experiments on three datasets from\ndifferent domains demonstrate the efficacy of our method compared with a\ncomprehensive set of baselines.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2018 03:04:26 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Meng", "Yu", ""], ["Shen", "Jiaming", ""], ["Zhang", "Chao", ""], ["Han", "Jiawei", ""]]}, {"id": "1812.11314", "submitter": "Kehan Yang", "authors": "Yiming Shen, Kehan Yang, Yufeng Yuan and Simon Cheng Liu", "title": "Meta Reinforcement Learning with Distribution of Exploration Parameters\n  Learned by Evolution Strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel meta-learning method in a reinforcement\nlearning setting, based on evolution strategies (ES), exploration in parameter\nspace and deterministic policy gradients. ES methods are easy to parallelize,\nwhich is desirable for modern training architectures; however, such methods\ntypically require a huge number of samples for effective training. We use\ndeterministic policy gradients during adaptation and other techniques to\ncompensate for the sample-efficiency problem while maintaining the inherent\nscalability of ES methods. We demonstrate that our method achieves good results\ncompared to gradient-based meta-learning in high-dimensional control tasks in\nthe MuJoCo simulator. In addition, because of gradient-free methods in the\nmeta-training phase, which do not need information about gradients and policies\nin adaptation training, we predict and confirm our algorithm performs better in\ntasks that need multi-step adaptation.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2018 08:40:38 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 07:32:06 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Shen", "Yiming", ""], ["Yang", "Kehan", ""], ["Yuan", "Yufeng", ""], ["Liu", "Simon Cheng", ""]]}, {"id": "1812.11371", "submitter": "Michal \\v{C}ertick\\'y", "authors": "Mykyta Viazovskyi and Michal Certicky", "title": "StarAlgo: A Squad Movement Planning Library for StarCraft using Monte\n  Carlo Tree Search and Negamax", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-Time Strategy (RTS) games have recently become a popular testbed for\nartificial intelligence research. They represent a complex adversarial domain\nproviding a number of interesting AI challenges. There exists a wide variety of\nresearch-supporting software tools, libraries and frameworks for one RTS game\nin particular -- StarCraft: Brood War. These tools are designed to address\nvarious specific sub-problems, such as resource allocation or opponent\nmodelling so that researchers can focus exclusively on the tasks relevant to\nthem. We present one such tool -- a library called StarAlgo that produces plans\nfor the coordinated movement of squads (groups of combat units) within the game\nworld. StarAlgo library can solve the squad movement planning problem using one\nof two algorithms: Monte Carlo Tree Search Considering Durations (MCTSCD) and a\nslightly modified version of Negamax. We evaluate both the algorithms, compare\nthem, and demonstrate their usage. The library is implemented as a static C++\nlibrary that can be easily plugged into most StarCraft AI bots.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2018 14:21:19 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Viazovskyi", "Mykyta", ""], ["Certicky", "Michal", ""]]}, {"id": "1812.11391", "submitter": "Fathi Salem", "authors": "Fathi M. Salem", "title": "SLIM LSTMs", "comments": "7 pages, no figures. conference manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long Short-Term Memory (LSTM) Recurrent Neural networks (RNNs) rely on gating\nsignals, each driven by a function of a weighted sum of at least 3 components:\n(i) one of an adaptive weight matrix multiplied by the incoming external input\nvector sequence, (ii) one adaptive weight matrix multiplied by the previous\nmemory/state vector, and (iii) one adaptive bias vector. In effect, they\naugment the simple Recurrent Neural Networks (sRNNs) structure with the\naddition of a \"memory cell\" and the incorporation of at most 3 gating signals.\n  The standard LSTM structure and components encompass redundancy and overly\nincreased parameterization. In this paper, we systemically introduce variants\nof the LSTM RNNs, referred to as SLIM LSTMs. These variants express\naggressively reduced parameterizations to achieve computational saving and/or\nspeedup in (training) performance---while necessarily retaining (validation\naccuracy) performance comparable to the standard LSTM RNN.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2018 16:11:01 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Salem", "Fathi M.", ""]]}, {"id": "1812.11509", "submitter": "Abhishek Gupta", "authors": "Yew-Soon Ong, Abhishek Gupta", "title": "AIR5: Five Pillars of Artificial Intelligence Research", "comments": "5 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we provide and overview of what we consider to be some of\nthe most pressing research questions facing the fields of artificial\nintelligence (AI) and computational intelligence (CI); with the latter focusing\non algorithms that are inspired by various natural phenomena. We demarcate\nthese questions using five unique Rs - namely, (i) rationalizability, (ii)\nresilience, (iii) reproducibility, (iv) realism, and (v) responsibility.\nNotably, just as air serves as the basic element of biological life, the term\nAIR5 - cumulatively referring to the five aforementioned Rs - is introduced\nherein to mark some of the basic elements of artificial life (supporting the\nsustained growth of AI and CI). A brief summary of each of the Rs is presented,\nhighlighting their relevance as pillars of future research in this arena.\n", "versions": [{"version": "v1", "created": "Sun, 30 Dec 2018 11:00:48 GMT"}, {"version": "v2", "created": "Wed, 2 Jan 2019 06:46:39 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Ong", "Yew-Soon", ""], ["Gupta", "Abhishek", ""]]}, {"id": "1812.11586", "submitter": "Veronica Vilaplana", "authors": "Marc G\\'orriz, Albert Aparicio, Berta Ravent\\'os, Ver\\'onica\n  Vilaplana, Elisa Sayrol and Daniel L\\'opez-Codina", "title": "Leishmaniasis Parasite Segmentation and Classification using Deep\n  Learning", "comments": "10th International Conference, AMDO 2018, Palma de Mallorca, Spain,\n  July 12-13, 2018, Proceedings", "journal-ref": "Articulated Motion and Deformable Objects, Series volume 10945 ,\n  2018, Springer International Publishing AG, part of Springer Nature", "doi": "10.1007/978-3-319-94544-6", "report-no": null, "categories": "cs.CV cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Leishmaniasis is considered a neglected disease that causes thousands of\ndeaths annually in some tropical and subtropical countries. There are various\ntechniques to diagnose leishmaniasis of which manual microscopy is considered\nto be the gold standard. There is a need for the development of automatic\ntechniques that are able to detect parasites in a robust and unsupervised\nmanner. In this paper we present a procedure for automatizing the detection\nprocess based on a deep learning approach. We train a U-net model that\nsuccessfully segments leismania parasites and classifies them into\npromastigotes, amastigotes and adhered parasites.\n", "versions": [{"version": "v1", "created": "Sun, 30 Dec 2018 18:42:08 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["G\u00f3rriz", "Marc", ""], ["Aparicio", "Albert", ""], ["Ravent\u00f3s", "Berta", ""], ["Vilaplana", "Ver\u00f3nica", ""], ["Sayrol", "Elisa", ""], ["L\u00f3pez-Codina", "Daniel", ""]]}, {"id": "1812.11588", "submitter": "Veronica Vilaplana", "authors": "Adri\\`a Casamitjana, Marcel Cat\\`a, Irina S\\'anchez, Marc Combalia and\n  Ver\\'onica Vilaplana", "title": "Cascaded V-Net using ROI masks for brain tumor segmentation", "comments": "Third International Workshop, BrainLes 2017, Held in Conjunction with\n  MICCAI 2017, Quebec City, QC, Canada, September 14, 2017, Revised Selected\n  Papers", "journal-ref": "Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic\n  Brain Injuries, Series volume 10670, 2018, Springer International Publishing\n  AG, part of Springer Nature", "doi": "10.1007/978-3-319-75238-9", "report-no": null, "categories": "cs.CV cs.AI cs.CY cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we approach the brain tumor segmentation problem with a cascade\nof two CNNs inspired in the V-Net architecture \\cite{VNet}, reformulating\nresidual connections and making use of ROI masks to constrain the networks to\ntrain only on relevant voxels. This architecture allows dense training on\nproblems with highly skewed class distributions, such as brain tumor\nsegmentation, by focusing training only on the vecinity of the tumor area. We\nreport results on BraTS2017 Training and Validation sets.\n", "versions": [{"version": "v1", "created": "Sun, 30 Dec 2018 18:51:37 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Casamitjana", "Adri\u00e0", ""], ["Cat\u00e0", "Marcel", ""], ["S\u00e1nchez", "Irina", ""], ["Combalia", "Marc", ""], ["Vilaplana", "Ver\u00f3nica", ""]]}, {"id": "1812.11677", "submitter": "Ao Ren", "authors": "Ao Ren, Tianyun Zhang, Shaokai Ye, Jiayu Li, Wenyao Xu, Xuehai Qian,\n  Xue Lin, Yanzhi Wang", "title": "ADMM-NN: An Algorithm-Hardware Co-Design Framework of DNNs Using\n  Alternating Direction Method of Multipliers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.AR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To facilitate efficient embedded and hardware implementations of deep neural\nnetworks (DNNs), two important categories of DNN model compression techniques:\nweight pruning and weight quantization are investigated. The former leverages\nthe redundancy in the number of weights, whereas the latter leverages the\nredundancy in bit representation of weights. However, there lacks a systematic\nframework of joint weight pruning and quantization of DNNs, thereby limiting\nthe available model compression ratio. Moreover, the computation reduction,\nenergy efficiency improvement, and hardware performance overhead need to be\naccounted for besides simply model size reduction.\n  To address these limitations, we present ADMM-NN, the first\nalgorithm-hardware co-optimization framework of DNNs using Alternating\nDirection Method of Multipliers (ADMM), a powerful technique to deal with\nnon-convex optimization problems with possibly combinatorial constraints. The\nfirst part of ADMM-NN is a systematic, joint framework of DNN weight pruning\nand quantization using ADMM. It can be understood as a smart regularization\ntechnique with regularization target dynamically updated in each ADMM\niteration, thereby resulting in higher performance in model compression than\nprior work. The second part is hardware-aware DNN optimizations to facilitate\nhardware-level implementations.\n  Without accuracy loss, we can achieve 85$\\times$ and 24$\\times$ pruning on\nLeNet-5 and AlexNet models, respectively, significantly higher than prior work.\nThe improvement becomes more significant when focusing on computation\nreductions. Combining weight pruning and quantization, we achieve 1,910$\\times$\nand 231$\\times$ reductions in overall model size on these two benchmarks, when\nfocusing on data storage. Highly promising results are also observed on other\nrepresentative DNNs such as VGGNet and ResNet-50.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 02:26:48 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Ren", "Ao", ""], ["Zhang", "Tianyun", ""], ["Ye", "Shaokai", ""], ["Li", "Jiayu", ""], ["Xu", "Wenyao", ""], ["Qian", "Xuehai", ""], ["Lin", "Xue", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1812.11737", "submitter": "Alexander Kuhnle", "authors": "Alexander Kuhnle and Ann Copestake", "title": "The meaning of \"most\" for visual question answering models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The correct interpretation of quantifier statements in the context of a\nvisual scene requires non-trivial inference mechanisms. For the example of\n\"most\", we discuss two strategies which rely on fundamentally different\ncognitive concepts. Our aim is to identify what strategy deep learning models\nfor visual question answering learn when trained on such questions. To this\nend, we carefully design data to replicate experiments from psycholinguistics\nwhere the same question was investigated for humans. Focusing on the FiLM\nvisual question answering model, our experiments indicate that a form of\napproximate number system emerges whose performance declines with more\ndifficult scenes as predicted by Weber's law. Moreover, we identify confounding\nfactors, like spatial arrangement of the scene, which impede the effectiveness\nof this system.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 09:41:04 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 08:22:29 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Kuhnle", "Alexander", ""], ["Copestake", "Ann", ""]]}, {"id": "1812.11794", "submitter": "Thanh Thi Nguyen", "authors": "Thanh Thi Nguyen, Ngoc Duy Nguyen, Saeid Nahavandi", "title": "Deep Reinforcement Learning for Multi-Agent Systems: A Review of\n  Challenges, Solutions and Applications", "comments": null, "journal-ref": "IEEE Transactions on Cybernetics, 20 March 2020", "doi": "10.1109/TCYB.2020.2977374", "report-no": "https://ieeexplore.ieee.org/document/9043893", "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) algorithms have been around for decades and\nemployed to solve various sequential decision-making problems. These algorithms\nhowever have faced great challenges when dealing with high-dimensional\nenvironments. The recent development of deep learning has enabled RL methods to\ndrive optimal policies for sophisticated and capable agents, which can perform\nefficiently in these challenging environments. This paper addresses an\nimportant aspect of deep RL related to situations that require multiple agents\nto communicate and cooperate to solve complex tasks. A survey of different\napproaches to problems related to multi-agent deep RL (MADRL) is presented,\nincluding non-stationarity, partial observability, continuous state and action\nspaces, multi-agent training schemes, multi-agent transfer learning. The merits\nand demerits of the reviewed methods will be analyzed and discussed, with their\ncorresponding applications explored. It is envisaged that this review provides\ninsights about various MADRL methods and can lead to future development of more\nrobust and highly useful multi-agent learning methods for solving real-world\nproblems.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 13:39:54 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 13:21:20 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Nguyen", "Thanh Thi", ""], ["Nguyen", "Ngoc Duy", ""], ["Nahavandi", "Saeid", ""]]}, {"id": "1812.11850", "submitter": "Diego Ulisse Pizzagalli", "authors": "Diego Ulisse Pizzagalli, Santiago Fernandez Gonzalez, Rolf Krause", "title": "A shortest-path based clustering algorithm for joint human-machine\n  analysis of complex datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is a technique for the analysis of datasets obtained by empirical\nstudies in several disciplines with a major application for biomedical\nresearch. Essentially, clustering algorithms are executed by machines aiming at\nfinding groups of related points in a dataset. However, the result of grouping\ndepends on both metrics for point-to-point similarity and rules for\npoint-to-group association. Indeed, non-appropriate metrics and rules can lead\nto undesirable clustering artifacts. This is especially relevant for datasets,\nwhere groups with heterogeneous structures co-exist. In this work, we propose\nan algorithm that achieves clustering by exploring the paths between points.\nThis allows both, to evaluate the properties of the path (such as gaps, density\nvariations, etc.), and expressing the preference for certain paths. Moreover,\nour algorithm supports the integration of existing knowledge about admissible\nand non-admissible clusters by training a path classifier. We demonstrate the\naccuracy of the proposed method on challenging datasets including points from\nsynthetic shapes in publicly available benchmarks and microscopy data.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 15:50:53 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Pizzagalli", "Diego Ulisse", ""], ["Gonzalez", "Santiago Fernandez", ""], ["Krause", "Rolf", ""]]}, {"id": "1812.11918", "submitter": "Joshua Brul\\'e", "authors": "Joshua Brul\\'e", "title": "Whittemore: An embedded domain specific language for causal programming", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Whittemore, a language for causal programming. Causal\nprogramming is based on the theory of structural causal models and consists of\ntwo primary operations: identification, which finds formulas that compute\ncausal queries, and estimation, which applies formulas to transform probability\ndistributions to other probability distribution. Causal programming provides\nabstractions to declare models, queries, and distributions with syntax similar\nto standard mathematical notation, and conducts rigorous causal inference,\nwithout requiring detailed knowledge of the underlying algorithms. Examples of\ncausal inference with real data are provided, along with discussion of the\nimplementation and possibilities for future extension.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 20:41:20 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Brul\u00e9", "Joshua", ""]]}, {"id": "1812.11948", "submitter": "Matthias Nickles", "authors": "Matthias Nickles", "title": "Differentiable Satisfiability and Differentiable Answer Set Programming\n  for Sampling-Based Multi-Model Optimization", "comments": "Extended and revised version of a paper in the Proceedings of the 5th\n  International Workshop on Probabilistic Logic Programming (PLP2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Differentiable Satisfiability and Differentiable Answer Set\nProgramming (Differentiable SAT/ASP) for multi-model optimization. Models\n(answer sets or satisfying truth assignments) are sampled using a novel SAT/ASP\nsolving approach which uses a gradient descent-based branching mechanism.\nSampling proceeds until the value of a user-defined multi-model cost function\nreaches a given threshold. As major use cases for our approach we propose\ndistribution-aware model sampling and expressive yet scalable probabilistic\nlogic programming. As our main algorithmic approach to Differentiable SAT/ASP,\nwe introduce an enhancement of the state-of-the-art CDNL/CDCL algorithm for\nSAT/ASP solving. Additionally, we present alternative algorithms which use an\nunmodified ASP solver (Clingo/clasp) and map the optimization task to\nconventional answer set optimization or use so-called propagators. We also\nreport on the open source software DelSAT, a recent prototype implementation of\nour main algorithm, and on initial experimental results which indicate that\nDelSATs performance is, when applied to the use case of probabilistic logic\ninference, on par with Markov Logic Network (MLN) inference performance,\ndespite having advantageous properties compared to MLNs, such as the ability to\nexpress inductive definitions and to work with probabilities as weights\ndirectly in all cases. Our experiments also indicate that our main algorithm is\nstrongly superior in terms of performance compared to the presented alternative\napproaches which reduce a common instance of the general problem to regular\nSAT/ASP.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 18:39:58 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Nickles", "Matthias", ""]]}, {"id": "1812.11969", "submitter": "Dmitry Maximov", "authors": "Dmitry Maximov", "title": "Game Semantics and Linear Logic in the Cognition Process", "comments": "arXiv admin note: substantial text overlap with arXiv:1811.02216; a\n  comment is added to the second version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A description of the environment cognition process by intelligent systems\nwith a fixed set of system goals is suggested. Such a system is represented by\nthe set of its goals only without any models of the system elements or the\nenvironment. The set has a lattice structure and a monoid structure; thus, the\nstructure of linear logic is defined on the set. The cognition process of some\nenvironment by the system is described on this basis. The environment is\nrepresented as a configuration space of possible system positions which are\nestimated by an information amount (by corresponding sets). This information is\nsupplied to the system by the environment. Thus, it is possible to define the\ncategory of Conway games with a payoff on the configuration space and to choose\nan optimal system's play (i.e., a trajectory). The choice is determined by the\nrequirement of maximal information increasing and takes into account the\nstructure of the system goal set: the linear logic on the set is used to\ndetermine the priority of possible different parallel processes. The survey may\nbe useful to describe the behavior of robots and simple biological systems,\ne.g., ants.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 08:14:25 GMT"}, {"version": "v2", "created": "Wed, 2 Jan 2019 16:41:09 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Maximov", "Dmitry", ""]]}, {"id": "1812.11971", "submitter": "Alexander Sax", "authors": "Alexander Sax, Bradley Emi, Amir R. Zamir, Leonidas Guibas, Silvio\n  Savarese, Jitendra Malik", "title": "Mid-Level Visual Representations Improve Generalization and Sample\n  Efficiency for Learning Visuomotor Policies", "comments": "See project website, demos, and code at http://perceptual.actor", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How much does having visual priors about the world (e.g. the fact that the\nworld is 3D) assist in learning to perform downstream motor tasks (e.g.\ndelivering a package)? We study this question by integrating a generic\nperceptual skill set (e.g. a distance estimator, an edge detector, etc.) within\na reinforcement learning framework--see Figure 1. This skill set (hereafter\nmid-level perception) provides the policy with a more processed state of the\nworld compared to raw images.\n  We find that using a mid-level perception confers significant advantages over\ntraining end-to-end from scratch (i.e. not leveraging priors) in\nnavigation-oriented tasks. Agents are able to generalize to situations where\nthe from-scratch approach fails and training becomes significantly more sample\nefficient. However, we show that realizing these gains requires careful\nselection of the mid-level perceptual skills. Therefore, we refine our findings\ninto an efficient max-coverage feature set that can be adopted in lieu of raw\nimages. We perform our study in completely separate buildings for training and\ntesting and compare against visually blind baseline policies and\nstate-of-the-art feature learning methods.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 18:59:25 GMT"}, {"version": "v2", "created": "Fri, 19 Apr 2019 17:58:50 GMT"}, {"version": "v3", "created": "Mon, 22 Apr 2019 07:12:34 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Sax", "Alexander", ""], ["Emi", "Bradley", ""], ["Zamir", "Amir R.", ""], ["Guibas", "Leonidas", ""], ["Savarese", "Silvio", ""], ["Malik", "Jitendra", ""]]}]