[{"id": "1302.0126", "submitter": "Nicos Angelopoulos", "authors": "Nicos Angelopoulos and Roberto Bagnara", "title": "Proceedings of the 12th International Colloquium on Implementation of\n  Constraint and LOgic Programming Systems", "comments": "1 invited talk, 9 papers and 1 panel discussion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the papers presented at CICLOPS'12: 12th International\nColloquium on Implementation of Constraint and LOgic Programming Systems held\non Tueseday September 4th, 2012 in Budapest.\n  The program included 1 invited talk, 9 technical presentations and a panel\ndiscussion on Prolog open standards (open.pl). Each programme paper was\nreviewed by 3 reviewers.\n  CICLOPS'12 continues a tradition of successful workshops on Implementations\nof Logic Programming Systems, previously held in Budapest (1993) and Ithaca\n(1994), the Compulog Net workshops on Parallelism and Implementation\nTechnologies held in Madrid (1993 and 1994), Utrecht (1995) and Bonn (1996),\nthe Workshop on Parallelism and Implementation Technology for (Constraint)\nLogic Programming Languages held in Port Jefferson (1997), Manchester (1998),\nLas Cruces (1999), and London (2000), and more recently the Colloquium on\nImplementation of Constraint and LOgic Programming Systems in Paphos (2001),\nCopenhagen (2002), Mumbai (2003), Saint Malo (2004), Sitges (2005), Seattle\n(2006), Porto (2007), Udine (2008), Pasadena (2009), Edinburgh (2010) -\ntogether with WLPE, Lexington (2011).\n  We would like to thank all the authors, Tom Schrijvers for his invited talk,\nthe programme committee members, and the ICLP 2012 organisers. We would like to\nalso thank arXiv.org for providing permanent hosting.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2013 10:20:15 GMT"}], "update_date": "2013-02-04", "authors_parsed": [["Angelopoulos", "Nicos", ""], ["Bagnara", "Roberto", ""]]}, {"id": "1302.0216", "submitter": "Dimiter Dobrev", "authors": "Dimiter Dobrev", "title": "Comparison between the two definitions of AI", "comments": "added four new sections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two different definitions of the Artificial Intelligence concept have been\nproposed in papers [1] and [2]. The first definition is informal. It says that\nany program that is cleverer than a human being, is acknowledged as Artificial\nIntelligence. The second definition is formal because it avoids reference to\nthe concept of human being. The readers of papers [1] and [2] might be left\nwith the impression that both definitions are equivalent and the definition in\n[2] is simply a formal version of that in [1]. This paper will compare both\ndefinitions of Artificial Intelligence and, hopefully, will bring a better\nunderstanding of the concept.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2013 15:15:40 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2013 22:56:04 GMT"}], "update_date": "2013-08-26", "authors_parsed": [["Dobrev", "Dimiter", ""]]}, {"id": "1302.0334", "submitter": "Daniel Buehrer", "authors": "Daniel Buehrer and Chee-Hwa Lee", "title": "Class Algebra for Ontology Reasoning", "comments": "pp.2-13", "journal-ref": "Proc. of TOOLS Asia 99 (Technology of Object-Oriented Languages\n  and Systems, 1999 International Conference), IEEE Press", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class algebra provides a natural framework for sharing of ISA hierarchies\nbetween users that may be unaware of each other's definitions. This permits\ndata from relational databases, object-oriented databases, and tagged XML\ndocuments to be unioned into one distributed ontology, sharable by all users\nwithout the need for prior negotiation or the development of a \"standard\"\nontology for each field. Moreover, class algebra produces a functional\ncorrespondence between a class's class algebraic definition (i.e. its \"intent\")\nand the set of all instances which satisfy the expression (i.e. its \"extent\").\nThe framework thus provides assistance in quickly locating examples and\ncounterexamples of various definitions. This kind of information is very\nvaluable when developing models of the real world, and serves as an invaluable\ntool assisting in the proof of theorems concerning these class algebra\nexpressions. Finally, the relative frequencies of objects in the ISA hierarchy\ncan produce a useful Boolean algebra of probabilities. The probabilities can be\nused by traditional information-theoretic classification methodologies to\nobtain optimal ways of classifying objects in the database.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2013 02:18:00 GMT"}], "update_date": "2013-02-05", "authors_parsed": [["Buehrer", "Daniel", ""], ["Lee", "Chee-Hwa", ""]]}, {"id": "1302.0386", "submitter": "Jean-Baptiste Mouret", "authors": "Sylvain Koos, Antoine Cully, Jean-Baptiste Mouret", "title": "Fast Damage Recovery in Robotics with the T-Resilience Algorithm", "comments": null, "journal-ref": null, "doi": "10.1177/0278364913499192", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Damage recovery is critical for autonomous robots that need to operate for a\nlong time without assistance. Most current methods are complex and costly\nbecause they require anticipating each potential damage in order to have a\ncontingency plan ready. As an alternative, we introduce the T-resilience\nalgorithm, a new algorithm that allows robots to quickly and autonomously\ndiscover compensatory behaviors in unanticipated situations. This algorithm\nequips the robot with a self-model and discovers new behaviors by learning to\navoid those that perform differently in the self-model and in reality. Our\nalgorithm thus does not identify the damaged parts but it implicitly searches\nfor efficient behaviors that do not use them. We evaluate the T-Resilience\nalgorithm on a hexapod robot that needs to adapt to leg removal, broken legs\nand motor failures; we compare it to stochastic local search, policy gradient\nand the self-modeling algorithm proposed by Bongard et al. The behavior of the\nrobot is assessed on-board thanks to a RGB-D sensor and a SLAM algorithm. Using\nonly 25 tests on the robot and an overall running time of 20 minutes,\nT-Resilience consistently leads to substantially better results than the other\napproaches.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2013 14:53:05 GMT"}], "update_date": "2014-03-26", "authors_parsed": [["Koos", "Sylvain", ""], ["Cully", "Antoine", ""], ["Mouret", "Jean-Baptiste", ""]]}, {"id": "1302.0723", "submitter": "Kian Hsiang Low", "authors": "Nannan Cao, Kian Hsiang Low, John M. Dolan", "title": "Multi-Robot Informative Path Planning for Active Sensing of\n  Environmental Phenomena: A Tale of Two Algorithms", "comments": "12th International Conference on Autonomous Agents and Multiagent\n  Systems (AAMAS 2013), Extended version with proofs, 15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key problem of robotic environmental sensing and monitoring is that of\nactive sensing: How can a team of robots plan the most informative observation\npaths to minimize the uncertainty in modeling and predicting an environmental\nphenomenon? This paper presents two principled approaches to efficient\ninformation-theoretic path planning based on entropy and mutual information\ncriteria for in situ active sensing of an important broad class of\nwidely-occurring environmental phenomena called anisotropic fields. Our\nproposed algorithms are novel in addressing a trade-off between active sensing\nperformance and time efficiency. An important practical consequence is that our\nalgorithms can exploit the spatial correlation structure of Gaussian\nprocess-based anisotropic fields to improve time efficiency while preserving\nnear-optimal active sensing performance. We analyze the time complexity of our\nalgorithms and prove analytically that they scale better than state-of-the-art\nalgorithms with increasing planning horizon length. We provide theoretical\nguarantees on the active sensing performance of our algorithms for a class of\nexploration tasks called transect sampling, which, in particular, can be\nimproved with longer planning time and/or lower spatial correlation along the\ntransect. Empirical evaluation on real-world anisotropic field data shows that\nour algorithms can perform better or at least as well as the state-of-the-art\nalgorithms while often incurring a few orders of magnitude less computational\ntime, even when the field conditions are less favorable.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2013 15:34:12 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2013 05:50:14 GMT"}], "update_date": "2013-02-06", "authors_parsed": [["Cao", "Nannan", ""], ["Low", "Kian Hsiang", ""], ["Dolan", "John M.", ""]]}, {"id": "1302.0785", "submitter": "Ella Gale", "authors": "Ella Gale, Oliver Matthews, Ben de Lacy Costello and Andrew Adamatzky", "title": "Beyond Markov Chains, Towards Adaptive Memristor Network-based Music\n  Generation", "comments": "22 pages, 13 pages, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AI cs.NE cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We undertook a study of the use of a memristor network for music generation,\nmaking use of the memristor's memory to go beyond the Markov hypothesis. Seed\ntransition matrices are created and populated using memristor equations, and\nwhich are shown to generate musical melodies and change in style over time as a\nresult of feedback into the transition matrix. The spiking properties of simple\nmemristor networks are demonstrated and discussed with reference to\napplications of music making. The limitations of simulating composing memristor\nnetworks in von Neumann hardware is discussed and a hardware solution based on\nphysical memristor properties is presented.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2013 18:26:03 GMT"}], "update_date": "2013-02-05", "authors_parsed": [["Gale", "Ella", ""], ["Matthews", "Oliver", ""], ["Costello", "Ben de Lacy", ""], ["Adamatzky", "Andrew", ""]]}, {"id": "1302.1155", "submitter": "Kurt Ammon", "authors": "Kurt Ammon", "title": "An Effective Procedure for Computing \"Uncomputable\" Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an effective procedure that produces a natural number in its output\nfrom any natural number in its input, that is, it computes a total function.\nThe elementary operations of the procedure are Turing-computable. The procedure\nhas a second input which can contain the Goedel number of any Turing-computable\ntotal function whose range is a subset of the set of the Goedel numbers of all\nTuring-computable total functions. We prove that the second input cannot be set\nto the Goedel number of any Turing-computable function that computes the output\nfrom any natural number in its first input. In this sense, there is no Turing\nprogram that computes the output from its first input. The procedure is used to\ndefine creative procedures which compute functions that are not\nTuring-computable. We argue that creative procedures model an aspect of\nreasoning that cannot be modeled by Turing machines.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2013 19:11:59 GMT"}], "update_date": "2013-02-06", "authors_parsed": [["Ammon", "Kurt", ""]]}, {"id": "1302.1334", "submitter": "Yuriy Parzhin", "authors": "Yuri Parzhin", "title": "Principles of modal and vector theory of formal intelligence systems", "comments": "34 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The paper considers the class of information systems capable of solving\nheuristic problems on basis of formal theory that was termed modal and vector\ntheory of formal intelligent systems (FIS). The paper justifies the\nconstruction of FIS resolution algorithm, defines the main features of these\nsystems and proves theorems that underlie the theory. The principle of\nrepresentation diversity of FIS construction is formulated. The paper deals\nwith the main principles of constructing and functioning formal intelligent\nsystem (FIS) on basis of FIS modal and vector theory. The following phenomena\nare considered: modular architecture of FIS presentation sub-system, algorithms\nof data processing at every step of the stage of creating presentations.\nBesides the paper suggests the structure of neural elements, i.e. zone\ndetectors and processors that are the basis for FIS construction.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 12:16:33 GMT"}], "update_date": "2013-02-07", "authors_parsed": [["Parzhin", "Yuri", ""]]}, {"id": "1302.1520", "submitter": "Ami Berler", "authors": "Ami Berler, Solomon Eyal Shimony", "title": "Bayes Networks for Sonar Sensor Fusion", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-14-21", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wide-angle sonar mapping of the environment by mobile robot is nontrivial due\nto several sources of uncertainty: dropouts due to \"specular\" reflections,\nobstacle location uncertainty due to the wide beam, and distance measurement\nerror. Earlier papers address the latter problems, but dropouts remain a\nproblem in many environments. We present an approach that lifts the\noveroptimistic independence assumption used in earlier work, and use Bayes nets\nto represent the dependencies between objects of the model. Objects of the\nmodel consist of readings, and of regions in which \"quasi location invariance\"\nof the (possible) obstacles exists, with respect to the readings. Simulation\nsupports the method's feasibility. The model is readily extensible to allow for\nprior distributions, as well as other types of sensing operations.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:53:39 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Berler", "Ami", ""], ["Shimony", "Solomon Eyal", ""]]}, {"id": "1302.1521", "submitter": "John Bigham", "authors": "John Bigham", "title": "Exploiting Uncertain and Temporal Information in Correlation", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-22-29", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A modelling language is described which is suitable for the correlation of\ninformation when the underlying functional model of the system is incomplete or\nuncertain and the temporal dependencies are imprecise. An efficient and\nincremental implementation is outlined which depends on cost functions\nsatisfying certain criteria. Possibilistic logic and probability theory (as it\nis used in the applications targetted) satisfy these criteria.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:53:45 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Bigham", "John", ""]]}, {"id": "1302.1522", "submitter": "Craig Boutilier", "authors": "Craig Boutilier", "title": "Correlated Action Effects in Decision Theoretic Regression", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-30-37", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much recent research in decision theoretic planning has adopted Markov\ndecision processes (MDPs) as the model of choice, and has attempted to make\ntheir solution more tractable by exploiting problem structure. One particular\nalgorithm, structured policy construction achieves this by means of a decision\ntheoretic analog of goal regression using action descriptions based on Bayesian\nnetworks with tree-structured conditional probability tables. The algorithm as\npresented is not able to deal with actions with correlated effects. We describe\na new decision theoretic regression operator that corrects this weakness. While\nconceptually straightforward, this extension requires a somewhat more\ncomplicated technical approach.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:53:51 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Boutilier", "Craig", ""]]}, {"id": "1302.1523", "submitter": "Alex G. Buchner", "authors": "Alex G. Buchner, Werner Dubitzky, Alfons Schuster, Philippe Lopes,\n  Peter G. O'Donoghue, John G. Hughes, David A. Bell, Kenny Adamson, John A.\n  White, John M.C.C. Anderson, Maurice D. Mulvenna", "title": "Corporate Evidential Decision Making in Performance Prediction Domains", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-38-45", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance prediction or forecasting sporting outcomes involves a great deal\nof insight into the particular area one is dealing with, and a considerable\namount of intuition about the factors that bear on such outcomes and\nperformances. The mathematical Theory of Evidence offers representation\nformalisms which grant experts a high degree of freedom when expressing their\nsubjective beliefs in the context of decision-making situations like\nperformance prediction. Furthermore, this reasoning framework incorporates a\npowerful mechanism to systematically pool the decisions made by individual\nsubject matter experts. The idea behind such a combination of knowledge is to\nimprove the competence (quality) of the overall decision-making process. This\npaper reports on a performance prediction experiment carried out during the\nEuropean Football Championship in 1996. Relying on the knowledge of four\npredictors, Evidence Theory was used to forecast the final scores of all 31\nmatches. The results of this empirical study are very encouraging.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:53:56 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Buchner", "Alex G.", ""], ["Dubitzky", "Werner", ""], ["Schuster", "Alfons", ""], ["Lopes", "Philippe", ""], ["O'Donoghue", "Peter G.", ""], ["Hughes", "John G.", ""], ["Bell", "David A.", ""], ["Adamson", "Kenny", ""], ["White", "John A.", ""], ["Anderson", "John M. C. C.", ""], ["Mulvenna", "Maurice D.", ""]]}, {"id": "1302.1524", "submitter": "Luis M. de Campos", "authors": "Luis M. de Campos, Juan F. Huete", "title": "Algorithms for Learning Decomposable Models and Chordal Graphs", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-46-53", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decomposable dependency models and their graphical counterparts, i.e.,\nchordal graphs, possess a number of interesting and useful properties. On the\nbasis of two characterizations of decomposable models in terms of independence\nrelationships, we develop an exact algorithm for recovering the chordal\ngraphical representation of any given decomposable model. We also propose an\nalgorithm for learning chordal approximations of dependency models isomorphic\nto general undirected graphs.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:54:02 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["de Campos", "Luis M.", ""], ["Huete", "Juan F.", ""]]}, {"id": "1302.1525", "submitter": "Anthony R. Cassandra", "authors": "Anthony R. Cassandra, Michael L. Littman, Nevin Lianwen Zhang", "title": "Incremental Pruning: A Simple, Fast, Exact Method for Partially\n  Observable Markov Decision Processes", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-54-61", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most exact algorithms for general partially observable Markov decision\nprocesses (POMDPs) use a form of dynamic programming in which a\npiecewise-linear and convex representation of one value function is transformed\ninto another. We examine variations of the \"incremental pruning\" method for\nsolving this problem and compare them to earlier algorithms from theoretical\nand empirical perspectives. We find that incremental pruning is presently the\nmost efficient exact method for solving POMDPs.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:54:07 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Cassandra", "Anthony R.", ""], ["Littman", "Michael L.", ""], ["Zhang", "Nevin Lianwen", ""]]}, {"id": "1302.1526", "submitter": "Urszula Chajewska", "authors": "Urszula Chajewska, Joseph Y. Halpern", "title": "Defining Explanation in Probabilistic Systems", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-62-71", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As probabilistic systems gain popularity and are coming into wider use, the\nneed for a mechanism that explains the system's findings and recommendations\nbecomes more critical. The system will also need a mechanism for ordering\ncompeting explanations. We examine two representative approaches to explanation\nin the literature - one due to G\\\"ardenfors and one due to Pearl - and show\nthat both suffer from significant problems. We propose an approach to defining\na notion of \"better explanation\" that combines some of the features of both\ntogether with more recent work by Pearl and others on causality.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:54:13 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Chajewska", "Urszula", ""], ["Halpern", "Joseph Y.", ""]]}, {"id": "1302.1527", "submitter": "Adrian Y. W. Cheuk", "authors": "Adrian Y. W. Cheuk, Craig Boutilier", "title": "Structured Arc Reversal and Simulation of Dynamic Probabilistic Networks", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-72-79", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for arc reversal in Bayesian networks with\ntree-structured conditional probability tables, and consider some of its\nadvantages, especially for the simulation of dynamic probabilistic networks. In\nparticular, the method allows one to produce CPTs for nodes involved in the\nreversal that exploit regularities in the conditional distributions. We argue\nthat this approach alleviates some of the overhead associated with arc\nreversal, plays an important role in evidence integration and can be used to\nrestrict sampling of variables in DPNs. We also provide an algorithm that\ndetects the dynamic irrelevance of state variables in forward simulation. This\nalgorithm exploits the structured CPTs in a reversed network to determine, in a\ntime-independent fashion, the conditions under which a variable does or does\nnot need to be sampled.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:54:19 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Cheuk", "Adrian Y. W.", ""], ["Boutilier", "Craig", ""]]}, {"id": "1302.1528", "submitter": "Max Chickering", "authors": "David Maxwell Chickering, David Heckerman, Christopher Meek", "title": "A Bayesian Approach to Learning Bayesian Networks with Local Structure", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-80-89", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently several researchers have investigated techniques for using data to\nlearn Bayesian networks containing compact representations for the conditional\nprobability distributions (CPDs) stored at each node. The majority of this work\nhas concentrated on using decision-tree representations for the CPDs. In\naddition, researchers typically apply non-Bayesian (or asymptotically Bayesian)\nscoring functions such as MDL to evaluate the goodness-of-fit of networks to\nthe data. In this paper we investigate a Bayesian approach to learning Bayesian\nnetworks that contain the more general decision-graph representations of the\nCPDs. First, we describe how to evaluate the posterior probability that is, the\nBayesian score of such a network, given a database of observed cases. Second,\nwe describe various search spaces that can be used, in conjunction with a\nscoring function and a search procedure, to identify one or more high-scoring\nnetworks. Finally, we present an experimental evaluation of the search spaces,\nusing a greedy algorithm and a Bayesian scoring function.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:54:25 GMT"}, {"version": "v2", "created": "Sat, 16 May 2015 23:29:15 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Chickering", "David Maxwell", ""], ["Heckerman", "David", ""], ["Meek", "Christopher", ""]]}, {"id": "1302.1529", "submitter": "TongSheng Chu", "authors": "TongSheng Chu, Yang Xiang", "title": "Exploring Parallelism in Learning Belief Networks", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-90-98", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that a class of probabilistic domain models cannot be\nlearned correctly by several existing algorithms which employ a single-link\nlook ahead search. When a multi-link look ahead search is used, the\ncomputational complexity of the learning algorithm increases. We study how to\nuse parallelism to tackle the increased complexity in learning such models and\nto speed up learning in large domains. An algorithm is proposed to decompose\nthe learning task for parallel processing. A further task decomposition is used\nto balance load among processors and to increase the speed-up and efficiency.\nFor learning from very large datasets, we present a regrouping of the available\nprocessors such that slow data access through file can be replaced by fast\nmemory access. Our implementation in a parallel computer demonstrates the\neffectiveness of the algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:54:31 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Chu", "TongSheng", ""], ["Xiang", "Yang", ""]]}, {"id": "1302.1530", "submitter": "Matthew S. Collins", "authors": "Matthew S. Collins, Jonathan Oliver", "title": "Efficient Induction of Finite State Automata", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-99-107", "categories": "cs.AI cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new algorithm for the induction if complex finite\nstate automata from samples of behavior. The algorithm is based on information\ntheoretic principles. The algorithm reduces the search space by many orders of\nmagnitude over what was previously thought possible. We compare the algorithm\nwith some existing induction techniques for finite state automata and show that\nthe algorithm is much superior in both run time and quality of inductions.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:54:36 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Collins", "Matthew S.", ""], ["Oliver", "Jonathan", ""]]}, {"id": "1302.1531", "submitter": "Fabio Gagliardi Cozman", "authors": "Fabio Gagliardi Cozman", "title": "Robustness Analysis of Bayesian Networks with Local Convex Sets of\n  Distributions", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-108-115", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust Bayesian inference is the calculation of posterior probability bounds\ngiven perturbations in a probabilistic model. This paper focuses on\nperturbations that can be expressed locally in Bayesian networks through convex\nsets of distributions. Two approaches for combination of local models are\nconsidered. The first approach takes the largest set of joint distributions\nthat is compatible with the local sets of distributions; we show how to reduce\nthis type of robust inference to a linear programming problem. The second\napproach takes the convex hull of joint distributions generated from the local\nsets of distributions; we demonstrate how to apply interior-point optimization\nmethods to generate posterior bounds and how to generate approximations that\nare guaranteed to converge to correct posterior bounds. We also discuss\ncalculation of bounds for expected utilities and variances, and global\nperturbation models.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:54:41 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Cozman", "Fabio Gagliardi", ""]]}, {"id": "1302.1532", "submitter": "Adnan Darwiche", "authors": "Adnan Darwiche, Gregory M. Provan", "title": "A Standard Approach for Optimizing Belief Network Inference using Query\n  DAGs", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-116-123", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel, algorithm-independent approach to optimizing\nbelief network inference. rather than designing optimizations on an algorithm\nby algorithm basis, we argue that one should use an unoptimized algorithm to\ngenerate a Q-DAG, a compiled graphical representation of the belief network,\nand then optimize the Q-DAG and its evaluator instead. We present a set of\nQ-DAG optimizations that supplant optimizations designed for traditional\ninference algorithms, including zero compression, network pruning and caching.\nWe show that our Q-DAG optimizations require time linear in the Q-DAG size, and\nsignificantly simplify the process of designing algorithms for optimizing\nbelief network inference.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:54:47 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Darwiche", "Adnan", ""], ["Provan", "Gregory M.", ""]]}, {"id": "1302.1533", "submitter": "Thomas L. Dean", "authors": "Thomas L. Dean, Robert Givan, Sonia Leach", "title": "Model Reduction Techniques for Computing Approximately Optimal Solutions\n  for Markov Decision Processes", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-124-131", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for solving implicit (factored) Markov decision processes\n(MDPs) with very large state spaces. We introduce a property of state space\npartitions which we call epsilon-homogeneity. Intuitively, an\nepsilon-homogeneous partition groups together states that behave approximately\nthe same under all or some subset of policies. Borrowing from recent work on\nmodel minimization in computer-aided software verification, we present an\nalgorithm that takes a factored representation of an MDP and an 0<=epsilon<=1\nand computes a factored epsilon-homogeneous partition of the state space. This\npartition defines a family of related MDPs - those MDPs with state space equal\nto the blocks of the partition, and transition probabilities \"approximately\"\nlike those of any (original MDP) state in the source block. To formally study\nsuch families of MDPs, we introduce the new notion of a \"bounded parameter MDP\"\n(BMDP), which is a family of (traditional) MDPs defined by specifying upper and\nlower bounds on the transition probabilities and rewards. We describe\nalgorithms that operate on BMDPs to find policies that are approximately\noptimal with respect to the original MDP. In combination, our method for\nreducing a large implicit MDP to a possibly much smaller BMDP using an\nepsilon-homogeneous partition, and our methods for selecting actions in BMDPs\nconstitute a new approach for analyzing large implicit MDPs. Among its\nadvantages, this new approach provides insight into existing algorithms to\nsolving implicit MDPs, provides useful connections to work in automata theory\nand model minimization, and suggests methods, which involve varying epsilon, to\ntrade time and space (specifically in terms of the size of the corresponding\nstate space) for solution quality.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:54:52 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Dean", "Thomas L.", ""], ["Givan", "Robert", ""], ["Leach", "Sonia", ""]]}, {"id": "1302.1534", "submitter": "Rina Dechter", "authors": "Rina Dechter, Irina Rish", "title": "A Scheme for Approximating Probabilistic Inference", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-132-141", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a class of probabilistic approximation algorithms based\non bucket elimination which offer adjustable levels of accuracy and efficiency.\nWe analyze the approximation for several tasks: finding the most probable\nexplanation, belief updating and finding the maximum a posteriori hypothesis.\nWe identify regions of completeness and provide preliminary empirical\nevaluation on randomly generated networks.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:54:58 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Dechter", "Rina", ""], ["Rish", "Irina", ""]]}, {"id": "1302.1535", "submitter": "Soren L. Dittmer", "authors": "Soren L. Dittmer, Finn Verner Jensen", "title": "Myopic Value of Information in Influence Diagrams", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-142-149", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for calculation of myopic value of information in\ninfluence diagrams (Howard & Matheson, 1981) based on the strong junction tree\nframework (Jensen, Jensen & Dittmer, 1994). The difference in instantiation\norder in the influence diagrams is reflected in the corresponding junction\ntrees by the order in which the chance nodes are marginalized. This order of\nmarginalization can be changed by table expansion and in effect the same\njunction tree with expanded tables may be used for calculating the expected\nutility for scenarios with different instantiation order. We also compare our\nmethod to the classic method of modeling different instantiation orders in the\nsame influence diagram.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:55:04 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Dittmer", "Soren L.", ""], ["Jensen", "Finn Verner", ""]]}, {"id": "1302.1536", "submitter": "Jens Doerpmund", "authors": "Jens Doerpmund", "title": "Limitations of Skeptical Default Reasoning", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-150-156", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poole has shown that nonmonotonic logics do not handle the lottery paradox\ncorrectly. In this paper we will show that Pollock's theory of defeasible\nreasoning fails for the same reason: defeasible reasoning is incompatible with\nthe skeptical notion of derivability.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:55:09 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Doerpmund", "Jens", ""]]}, {"id": "1302.1537", "submitter": "Didier Dubois", "authors": "Didier Dubois, Helene Fargier, Henri Prade", "title": "Decision-making Under Ordinal Preferences and Comparative Uncertainty", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-157-164", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the problem of finding a preference relation on a set\nof acts from the knowledge of an ordering on events (subsets of states of the\nworld) describing the decision-maker (DM)s uncertainty and an ordering of\nconsequences of acts, describing the DMs preferences. However, contrary to\nclassical approaches to decision theory, we try to do it without resorting to\nany numerical representation of utility nor uncertainty, and without even using\nany qualitative scale on which both uncertainty and preference could be mapped.\nIt is shown that although many axioms of Savage theory can be preserved and\ndespite the intuitive appeal of the method for constructing a preference over\nacts, the approach is inconsistent with a probabilistic representation of\nuncertainty, but leads to the kind of uncertainty theory encountered in\nnon-monotonic reasoning (especially preferential and rational inference),\nclosely related to possibility theory. Moreover the method turns out to be\neither very little decisive or to lead to very risky decisions, although its\nbasic principles look sound. This paper raises the question of the very\npossibility of purely symbolic approaches to Savage-like decision-making under\nuncertainty and obtains preliminary negative results.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:55:15 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Dubois", "Didier", ""], ["Fargier", "Helene", ""], ["Prade", "Henri", ""]]}, {"id": "1302.1538", "submitter": "Nir Friedman", "authors": "Nir Friedman, Moises Goldszmidt", "title": "Sequential Update of Bayesian Network Structure", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-165-174", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an obvious need for improving the performance and accuracy of a\nBayesian network as new data is observed. Because of errors in model\nconstruction and changes in the dynamics of the domains, we cannot afford to\nignore the information in new data. While sequential update of parameters for a\nfixed structure can be accomplished using standard techniques, sequential\nupdate of network structure is still an open problem. In this paper, we\ninvestigate sequential update of Bayesian networks were both parameters and\nstructure are expected to change. We introduce a new approach that allows for\nthe flexible manipulation of the tradeoff between the quality of the learned\nnetworks and the amount of information that is maintained about past\nobservations. We formally describe our approach including the necessary\nmodifications to the scoring functions for learning Bayesian networks, evaluate\nits effectiveness through an empirical study, and extend it to the case of\nmissing data.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:55:21 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Friedman", "Nir", ""], ["Goldszmidt", "Moises", ""]]}, {"id": "1302.1539", "submitter": "Nir Friedman", "authors": "Nir Friedman, Stuart Russell", "title": "Image Segmentation in Video Sequences: A Probabilistic Approach", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-175-181", "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Background subtraction\" is an old technique for finding moving objects in a\nvideo sequence for example, cars driving on a freeway. The idea is that\nsubtracting the current image from a timeaveraged background image will leave\nonly nonstationary objects. It is, however, a crude approximation to the task\nof classifying each pixel of the current image; it fails with slow-moving\nobjects and does not distinguish shadows from moving objects. The basic idea of\nthis paper is that we can classify each pixel using a model of how that pixel\nlooks when it is part of different classes. We learn a mixture-of-Gaussians\nclassification model for each pixel using an unsupervised technique- an\nefficient, incremental version of EM. Unlike the standard image-averaging\napproach, this automatically updates the mixture component for each class\naccording to likelihood of membership; hence slow-moving objects are handled\nperfectly. Our approach also identifies and eliminates shadows much more\neffectively than other techniques such as thresholding. Application of this\nmethod as part of the Roadwatch traffic surveillance project is expected to\nresult in significant improvements in vehicle identification and tracking.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:55:26 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Friedman", "Nir", ""], ["Russell", "Stuart", ""]]}, {"id": "1302.1540", "submitter": "Judy Goldsmith", "authors": "Judy Goldsmith, Michael L. Littman, Martin Mundhenk", "title": "The Complexity of Plan Existence and Evaluation in Probabilistic Domains", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-182-189", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the computational complexity of testing and finding small plans in\nprobabilistic planning domains with succinct representations. We find that many\nproblems of interest are complete for a variety of complexity classes: NP,\nco-NP, PP, NP^PP, co-NP^PP, and PSPACE. Of these, the probabilistic classes PP\nand NP^PP are likely to be of special interest in the field of uncertainty in\nartificial intelligence and are deserving of additional study. These results\nsuggest a fruitful direction of future algorithmic development.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:55:32 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Goldsmith", "Judy", ""], ["Littman", "Michael L.", ""], ["Mundhenk", "Martin", ""]]}, {"id": "1302.1541", "submitter": "Carla P. Gomes", "authors": "Carla P. Gomes, Bart Selman", "title": "Algorithm Portfolio Design: Theory vs. Practice", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-190-197", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic algorithms are among the best for solving computationally hard\nsearch and reasoning problems. The runtime of such procedures is characterized\nby a random variable. Different algorithms give rise to different probability\ndistributions. One can take advantage of such differences by combining several\nalgorithms into a portfolio, and running them in parallel or interleaving them\non a single processor. We provide a detailed evaluation of the portfolio\napproach on distributions of hard combinatorial search problems. We show under\nwhat conditions the protfolio approach can have a dramatic computational\nadvantage over the best traditional methods.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:55:37 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Gomes", "Carla P.", ""], ["Selman", "Bart", ""]]}, {"id": "1302.1542", "submitter": "Russell Greiner", "authors": "Russell Greiner, Adam J. Grove, Dale Schuurmans", "title": "Learning Bayesian Nets that Perform Well", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-198-207", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Bayesian net (BN) is more than a succinct way to encode a probabilistic\ndistribution; it also corresponds to a function used to answer queries. A BN\ncan therefore be evaluated by the accuracy of the answers it returns. Many\nalgorithms for learning BNs, however, attempt to optimize another criterion\n(usually likelihood, possibly augmented with a regularizing term), which is\nindependent of the distribution of queries that are posed. This paper takes the\n\"performance criteria\" seriously, and considers the challenge of computing the\nBN whose performance - read \"accuracy over the distribution of queries\" - is\noptimal. We show that many aspects of this learning task are more difficult\nthan the corresponding subtasks in the standard model.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:55:43 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Greiner", "Russell", ""], ["Grove", "Adam J.", ""], ["Schuurmans", "Dale", ""]]}, {"id": "1302.1543", "submitter": "Adam J. Grove", "authors": "Adam J. Grove, Joseph Y. Halpern", "title": "Probability Update: Conditioning vs. Cross-Entropy", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-208-214", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditioning is the generally agreed-upon method for updating probability\ndistributions when one learns that an event is certainly true. But it has been\nargued that we need other rules, in particular the rule of cross-entropy\nminimization, to handle updates that involve uncertain information. In this\npaper we re-examine such a case: van Fraassen's Judy Benjamin problem, which in\nessence asks how one might update given the value of a conditional probability.\nWe argue that -- contrary to the suggestions in the literature -- it is\npossible to use simple conditionalization in this case, and thereby obtain\nanswers that agree fully with intuition. This contrasts with proposals such as\ncross-entropy, which are easier to apply but can give unsatisfactory answers.\nBased on the lessons from this example, we speculate on some general\nphilosophical issues concerning probability update.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:55:49 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Grove", "Adam J.", ""], ["Halpern", "Joseph Y.", ""]]}, {"id": "1302.1544", "submitter": "Vu A. Ha", "authors": "Vu A. Ha, Peter Haddawy", "title": "Problem-Focused Incremental Elicitation of Multi-Attribute Utility\n  Models", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-215-222", "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision theory has become widely accepted in the AI community as a useful\nframework for planning and decision making. Applying the framework typically\nrequires elicitation of some form of probability and utility information. While\nmuch work in AI has focused on providing representations and tools for\nelicitation of probabilities, relatively little work has addressed the\nelicitation of utility models. This imbalance is not particularly justified\nconsidering that probability models are relatively stable across problem\ninstances, while utility models may be different for each instance. Spending\nlarge amounts of time on elicitation can be undesirable for interactive systems\nused in low-stakes decision making and in time-critical decision making. In\nthis paper we investigate the issues of reasoning with incomplete utility\nmodels. We identify patterns of problem instances where plans can be proved to\nbe suboptimal if the (unknown) utility function satisfies certain conditions.\nWe present an approach to planning and decision making that performs the\nutility elicitation incrementally and in a way that is informed by the domain\nmodel.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:56:00 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Ha", "Vu A.", ""], ["Haddawy", "Peter", ""]]}, {"id": "1302.1546", "submitter": "Luis D. Hernandez", "authors": "Luis D. Hernandez, Serafin Moral", "title": "Inference with Idempotent Valuations", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-229-237", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Valuation based systems verifying an idempotent property are studied. A\npartial order is defined between the valuations giving them a lattice\nstructure. Then, two different strategies are introduced to represent\nvaluations: as infimum of the most informative valuations or as supremum of the\nleast informative ones. It is studied how to carry out computations with both\nrepresentations in an efficient way. The particular cases of finite sets and\nconvex polytopes are considered.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:56:12 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Hernandez", "Luis D.", ""], ["Moral", "Serafin", ""]]}, {"id": "1302.1547", "submitter": "Eric J. Horvitz", "authors": "Eric J. Horvitz, Jed Lengyel", "title": "Perception, Attention, and Resources: A Decision-Theoretic Approach to\n  Graphics Rendering", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-238-249", "categories": "cs.AI cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe work to control graphics rendering under limited computational\nresources by taking a decision-theoretic perspective on perceptual costs and\ncomputational savings of approximations. The work extends earlier work on the\ncontrol of rendering by introducing methods and models for computing the\nexpected cost associated with degradations of scene components. The expected\ncost is computed by considering the perceptual cost of degradations and a\nprobability distribution over the attentional focus of viewers. We review the\ncritical literature describing findings on visual search and attention, discuss\nthe implications of the findings, and introduce models of expected perceptual\ncost. Finally, we discuss policies that harness information about the expected\ncost of scene components.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:56:18 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Horvitz", "Eric J.", ""], ["Lengyel", "Jed", ""]]}, {"id": "1302.1548", "submitter": "Eric J. Horvitz", "authors": "Eric J. Horvitz, Adam Seiver", "title": "Time-Critical Reasoning: Representations and Application", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-250-257", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review the problem of time-critical action and discuss a reformulation\nthat shifts knowledge acquisition from the assessment of complex temporal\nprobabilistic dependencies to the direct assessment of time-dependent utilities\nover key outcomes of interest. We dwell on a class of decision problems\ncharacterized by the centrality of diagnosing and reacting in a timely manner\nto pathological processes. We motivate key ideas in the context of trauma-care\ntriage and transportation decisions.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:56:24 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Horvitz", "Eric J.", ""], ["Seiver", "Adam", ""]]}, {"id": "1302.1549", "submitter": "Jun Hu", "authors": "Jun Hu, Yang Xiang", "title": "Learning Belief Networks in Domains with Recursively Embedded Pseudo\n  Independent Submodels", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-258-265", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A pseudo independent (PI) model is a probabilistic domain model (PDM) where\nproper subsets of a set of collectively dependent variables display marginal\nindependence. PI models cannot be learned correctly by many algorithms that\nrely on a single link search. Earlier work on learning PI models has suggested\na straightforward multi-link search algorithm. However, when a domain contains\nrecursively embedded PI submodels, it may escape the detection of such an\nalgorithm. In this paper, we propose an improved algorithm that ensures the\nlearning of all embedded PI submodels whose sizes are upper bounded by a\npredetermined parameter. We show that this improved learning capability only\nincreases the complexity slightly beyond that of the previous algorithm. The\nperformance of the new algorithm is demonstrated through experiment.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:56:57 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Hu", "Jun", ""], ["Xiang", "Yang", ""]]}, {"id": "1302.1550", "submitter": "Manfred Jaeger", "authors": "Manfred Jaeger", "title": "Relational Bayesian Networks", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-266-273", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new method is developed to represent probabilistic relations on multiple\nrandom events. Where previously knowledge bases containing probabilistic rules\nwere used for this purpose, here a probability distribution over the relations\nis directly represented by a Bayesian network. By using a powerful way of\nspecifying conditional probability distributions in these networks, the\nresulting formalism is more expressive than the previous ones. Particularly, it\nprovides for constraints on equalities of events, and it allows to define\ncomplex, nested combination functions.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:57:05 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Jaeger", "Manfred", ""]]}, {"id": "1302.1551", "submitter": "Radim Jirousek", "authors": "Radim Jirousek", "title": "Composition of Probability Measures on Finite Spaces", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-274-281", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decomposable models and Bayesian networks can be defined as sequences of\noligo-dimensional probability measures connected with operators of composition.\nThe preliminary results suggest that the probabilistic models allowing for\neffective computational procedures are represented by sequences possessing a\nspecial property; we shall call them perfect sequences. The paper lays down the\nelementary foundation necessary for further study of iterative application of\noperators of composition. We believe to develop a technique describing several\ngraph models in a unifying way. We are convinced that practically all\ntheoretical results and procedures connected with decomposable models and\nBayesian networks can be translated into the terminology introduced in this\npaper. For example, complexity of computational procedures in these models is\nclosely dependent on possibility to change the ordering of oligo-dimensional\nmeasures defining the model. Therefore, in this paper, lot of attention is paid\nto possibility to change ordering of the operators of composition.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:57:13 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Jirousek", "Radim", ""]]}, {"id": "1302.1553", "submitter": "Uffe Kj{\\ae}rulff", "authors": "Uffe Kj{\\ae}rulff", "title": "Nested Junction Trees", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-294-301", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The efficiency of inference in both the Hugin and, most notably, the\nShafer-Shenoy architectures can be improved by exploiting the independence\nrelations induced by the incoming messages of a clique. That is, the message to\nbe sent from a clique can be computed via a factorization of the clique\npotential in the form of a junction tree. In this paper we show that by\nexploiting such nested junction trees in the computation of messages both space\nand time costs of the conventional propagation methods may be reduced. The\npaper presents a structured way of exploiting the nested junction trees\ntechnique to achieve such reductions. The usefulness of the method is\nemphasized through a thorough empirical evaluation involving ten large\nreal-world Bayesian networks and the Hugin inference algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:57:28 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Kj\u00e6rulff", "Uffe", ""]]}, {"id": "1302.1554", "submitter": "Daphne Koller", "authors": "Daphne Koller, Avi Pfeffer", "title": "Object-Oriented Bayesian Networks", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-302-313", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian networks provide a modeling language and associated inference\nalgorithm for stochastic domains. They have been successfully applied in a\nvariety of medium-scale applications. However, when faced with a large complex\ndomain, the task of modeling using Bayesian networks begins to resemble the\ntask of programming using logical circuits. In this paper, we describe an\nobject-oriented Bayesian network (OOBN) language, which allows complex domains\nto be described in terms of inter-related objects. We use a Bayesian network\nfragment to describe the probabilistic relations between the attributes of an\nobject. These attributes can themselves be objects, providing a natural\nframework for encoding part-of hierarchies. Classes are used to provide a\nreusable probabilistic model which can be applied to multiple similar objects.\nClasses also support inheritance of model fragments from a class to a subclass,\nallowing the common aspects of related classes to be defined only once. Our\nlanguage has clear declarative semantics: an OOBN can be interpreted as a\nstochastic functional program, so that it uniquely specifies a probabilistic\nmodel. We provide an inference algorithm for OOBNs, and show that much of the\nstructural information encoded by an OOBN--particularly the encapsulation of\nvariables within an object and the reuse of model fragments in different\ncontexts--can also be used to speed up the inference process.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:57:36 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Koller", "Daphne", ""], ["Pfeffer", "Avi", ""]]}, {"id": "1302.1555", "submitter": "Alexander V. Kozlov", "authors": "Alexander V. Kozlov, Daphne Koller", "title": "Nonuniform Dynamic Discretization in Hybrid Networks", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-314-325", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider probabilistic inference in general hybrid networks, which include\ncontinuous and discrete variables in an arbitrary topology. We reexamine the\nquestion of variable discretization in a hybrid network aiming at minimizing\nthe information loss induced by the discretization. We show that a nonuniform\npartition across all variables as opposed to uniform partition of each variable\nseparately reduces the size of the data structures needed to represent a\ncontinuous function. We also provide a simple but efficient procedure for\nnonuniform partition. To represent a nonuniform discretization in the computer\nmemory, we introduce a new data structure, which we call a Binary Split\nPartition (BSP) tree. We show that BSP trees can be an exponential factor\nsmaller than the data structures in the standard uniform discretization in\nmultiple dimensions and show how the BSP trees can be used in the standard join\ntree algorithm. We show that the accuracy of the inference process can be\nsignificantly improved by adjusting discretization with evidence. We construct\nan iterative anytime algorithm that gradually improves the quality of the\ndiscretization and the accuracy of the answer on a query. We provide empirical\nevidence that the algorithm converges.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:57:46 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Kozlov", "Alexander V.", ""], ["Koller", "Daphne", ""]]}, {"id": "1302.1556", "submitter": "Henry E. Kyburg Jr.", "authors": "Henry E. Kyburg Jr", "title": "Probabilistic Acceptance", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-326-333", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea of fully accepting statements when the evidence has rendered them\nprobable enough faces a number of difficulties. We leave the interpretation of\nprobability largely open, but attempt to suggest a contextual approach to full\nbelief. We show that the difficulties of probabilistic acceptance are not as\nsevere as they are sometimes painted, and that though there are oddities\nassociated with probabilistic acceptance they are in some instances less\nawkward than the difficulties associated with other nonmonotonic formalisms. We\nshow that the structure at which we arrive provides a natural home for\nstatistical inference.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:57:52 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Kyburg", "Henry E.", "Jr"]]}, {"id": "1302.1557", "submitter": "Kathryn Blackmond Laskey", "authors": "Kathryn Blackmond Laskey, Suzanne M. Mahoney", "title": "Network Fragments: Representing Knowledge for Constructing Probabilistic\n  Models", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-334-341", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In most current applications of belief networks, domain knowledge is\nrepresented by a single belief network that applies to all problem instances in\nthe domain. In more complex domains, problem-specific models must be\nconstructed from a knowledge base encoding probabilistic relationships in the\ndomain. Most work in knowledge-based model construction takes the rule as the\nbasic unit of knowledge. We present a knowledge representation framework that\npermits the knowledge base designer to specify knowledge in larger semantically\nmeaningful units which we call network fragments. Our framework provides for\nrepresentation of asymmetric independence and canonical intercausal\ninteraction. We discuss the combination of network fragments to form\nproblem-specific models to reason about particular problem instances. The\nframework is illustrated using examples from the domain of military situation\nawareness.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:57:59 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Laskey", "Kathryn Blackmond", ""], ["Mahoney", "Suzanne M.", ""]]}, {"id": "1302.1558", "submitter": "Yan Lin", "authors": "Yan Lin, Marek J. Druzdzel", "title": "Computational Advantages of Relevance Reasoning in Bayesian Belief\n  Networks", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-342-350", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a computational framework for reasoning in Bayesian\nbelief networks that derives significant advantages from focused inference and\nrelevance reasoning. This framework is based on d -separation and other simple\nand computationally efficient techniques for pruning irrelevant parts of a\nnetwork. Our main contribution is a technique that we call relevance-based\ndecomposition. Relevance-based decomposition approaches belief updating in\nlarge networks by focusing on their parts and decomposing them into partially\noverlapping subnetworks. This makes reasoning in some intractable networks\npossible and, in addition, often results in significant speedup, as the total\ntime taken to update all subnetworks is in practice often considerably less\nthan the time taken to update the network as a whole. We report results of\nempirical tests that demonstrate practical significance of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:58:06 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Lin", "Yan", ""], ["Druzdzel", "Marek J.", ""]]}, {"id": "1302.1559", "submitter": "Maite Lopez-Sanchez", "authors": "Maite Lopez-Sanchez, Ramon Lopez de Mantaras, Carles Sierra", "title": "Incremental Map Generation by Low Cost Robots Based on\n  Possibility/Necessity Grids", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-351-357", "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present some results obtained with a troupe of low-cost\nrobots designed to cooperatively explore and adquire the map of unknown\nstructured orthogonal environments. In order to improve the covering of the\nexplored zone, the robots show different behaviours and cooperate by\ntransferring each other the perceived environment when they meet. The returning\nrobots deliver to a host computer their partial maps and the host incrementally\ngenerates the map of the environment by means of apossibility/ necessity grid.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:58:12 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Lopez-Sanchez", "Maite", ""], ["de Mantaras", "Ramon Lopez", ""], ["Sierra", "Carles", ""]]}, {"id": "1302.1560", "submitter": "Todd Michael Mansell", "authors": "Todd Michael Mansell", "title": "A Target Classification Decision Aid", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-358-365", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A submarine's sonar team is responsible for detecting, localising and\nclassifying targets using information provided by the platform's sensor suite.\nThe information used to make these assessments is typically uncertain and/or\nincomplete and is likely to require a measure of confidence in its reliability.\nMoreover, improvements in sensor and communication technology are resulting in\nincreased amounts of on-platform and off-platform information available for\nevaluation. This proliferation of imprecise information increases the risk of\noverwhelming the operator. To assist the task of localisation and\nclassification a concept demonstration decision aid (Horizon), based on\nevidential reasoning, has been developed. Horizon is an information fusion\nsoftware package for representing and fusing imprecise information about the\nstate of the world, expressed across suitable frames of reference. The Horizon\nsoftware is currently at prototype stage.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:58:18 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Mansell", "Todd Michael", ""]]}, {"id": "1302.1561", "submitter": "Chris Meek", "authors": "Christopher Meek, David Heckerman", "title": "Structure and Parameter Learning for Causal Independence and Causal\n  Interaction Models", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-366-375", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses causal independence models and a generalization of these\nmodels called causal interaction models. Causal interaction models are models\nthat have independent mechanisms where a mechanism can have several causes. In\naddition to introducing several particular types of causal interaction models,\nwe show how we can apply the Bayesian approach to learning causal interaction\nmodels obtaining approximate posterior distributions for the models and obtain\nMAP and ML estimates for the parameters. We illustrate the approach with a\nsimulation study of learning model posteriors.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:58:24 GMT"}, {"version": "v2", "created": "Sat, 16 May 2015 23:30:56 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Meek", "Christopher", ""], ["Heckerman", "David", ""]]}, {"id": "1302.1562", "submitter": "Paul-Andre Monney", "authors": "Paul-Andre Monney", "title": "Support and Plausibility Degrees in Generalized Functional Models", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-376-383", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By discussing several examples, the theory of generalized functional models\nis shown to be very natural for modeling some situations of reasoning under\nuncertainty. A generalized functional model is a pair (f, P) where f is a\nfunction describing the interactions between a parameter variable, an\nobservation variable and a random source, and P is a probability distribution\nfor the random source. Unlike traditional functional models, generalized\nfunctional models do not require that there is only one value of the parameter\nvariable that is compatible with an observation and a realization of the random\nsource. As a consequence, the results of the analysis of a generalized\nfunctional model are not expressed in terms of probability distributions but\nrather by support and plausibility functions. The analysis of a generalized\nfunctional model is very logical and is inspired from ideas already put forward\nby R.A. Fisher in his theory of fiducial probability.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:58:30 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Monney", "Paul-Andre", ""]]}, {"id": "1302.1563", "submitter": "Scott B. Morris", "authors": "Scott B. Morris, Doug Cork, Richard E. Neapolitan", "title": "The Cognitive Processing of Causal Knowledge", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-384-391", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a brief description of the probabilistic causal graph model for\nrepresenting, reasoning with, and learning causal structure using Bayesian\nnetworks. It is then argued that this model is closely related to how humans\nreason with and learn causal structure. It is shown that studies in psychology\non discounting (reasoning concerning how the presence of one cause of an effect\nmakes another cause less probable) support the hypothesis that humans reach the\nsame judgments as algorithms for doing inference in Bayesian networks. Next, it\nis shown how studies by Piaget indicate that humans learn causal structure by\nobserving the same independencies and dependencies as those used by certain\nalgorithms for learning the structure of a Bayesian network. Based on this\nindication, a subjective definition of causality is forwarded. Finally, methods\nfor further testing the accuracy of these claims are discussed.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:58:35 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Morris", "Scott B.", ""], ["Cork", "Doug", ""], ["Neapolitan", "Richard E.", ""]]}, {"id": "1302.1564", "submitter": "David M Pennock", "authors": "David M. Pennock, Michael P. Wellman", "title": "Representing Aggregate Belief through the Competitive Equilibrium of a\n  Securities Market", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-392-400", "categories": "cs.AI cs.GT q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of belief aggregation: given a group of individual\nagents with probabilistic beliefs over a set of uncertain events, formulate a\nsensible consensus or aggregate probability distribution over these events.\nResearchers have proposed many aggregation methods, although on the question of\nwhich is best the general consensus is that there is no consensus. We develop a\nmarket-based approach to this problem, where agents bet on uncertain events by\nbuying or selling securities contingent on their outcomes. Each agent acts in\nthe market so as to maximize expected utility at given securities prices,\nlimited in its activity only by its own risk aversion. The equilibrium prices\nof goods in this market represent aggregate beliefs. For agents with constant\nrisk aversion, we demonstrate that the aggregate probability exhibits several\ndesirable properties, and is related to independently motivated techniques. We\nargue that the market-based approach provides a plausible mechanism for belief\naggregation in multiagent systems, as it directly addresses self-motivated\nagent incentives for participation and for truthfulness, and can provide a\ndecision-theoretic foundation for the \"expert weights\" often employed in\ncentralized pooling techniques.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:58:41 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Pennock", "David M.", ""], ["Wellman", "Michael P.", ""]]}, {"id": "1302.1565", "submitter": "Marco Ramoni", "authors": "Marco Ramoni, Paola Sebastiani", "title": "Learning Bayesian Networks from Incomplete Databases", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-401-408", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian approaches to learn the graphical structure of Bayesian Belief\nNetworks (BBNs) from databases share the assumption that the database is\ncomplete, that is, no entry is reported as unknown. Attempts to relax this\nassumption involve the use of expensive iterative methods to discriminate among\ndifferent structures. This paper introduces a deterministic method to learn the\ngraphical structure of a BBN from a possibly incomplete database. Experimental\nevaluations show a significant robustness of this method and a remarkable\nindependence of its execution time from the number of missing data.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:58:45 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Ramoni", "Marco", ""], ["Sebastiani", "Paola", ""]]}, {"id": "1302.1567", "submitter": "Solomon Eyal Shimony", "authors": "Solomon Eyal Shimony, Carmel Domshlak, Eugene Santos Jr", "title": "Cost-Sharing in Bayesian Knowledge Bases", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-421-428", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian knowledge bases (BKBs) are a generalization of Bayes networks and\nweighted proof graphs (WAODAGs), that allow cycles in the causal graph.\nReasoning in BKBs requires finding the most probable inferences consistent with\nthe evidence. The cost-sharing heuristic for finding least-cost explanations in\nWAODAGs was presented and shown to be effective by Charniak and Husain.\nHowever, the cycles in BKBs would make the definition of cost-sharing cyclic as\nwell, if applied directly to BKBs. By treating the defining equations of\ncost-sharing as a system of equations, one can properly define an admissible\ncost-sharing heuristic for BKBs. Empirical evaluation shows that cost-sharing\nimproves performance significantly when applied to BKBs.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:58:57 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Shimony", "Solomon Eyal", ""], ["Domshlak", "Carmel", ""], ["Santos", "Eugene", "Jr"]]}, {"id": "1302.1568", "submitter": "Yoav Shoham", "authors": "Yoav Shoham", "title": "Conditional Utility, Utility Independence, and Utility Networks", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-429-436", "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new interpretation of two related notions - conditional\nutility and utility independence. Unlike the traditional interpretation, the\nnew interpretation renders the notions the direct analogues of their\nprobabilistic counterparts. To capture these notions formally, we appeal to the\nnotion of utility distribution, introduced in previous paper. We show that\nutility distributions, which have a structure that is identical to that of\nprobability distributions, can be viewed as a special case of an additive\nmultiattribute utility functions, and show how this special case permits us to\ncapture the novel senses of conditional utility and utility independence.\nFinally, we present the notion of utility networks, which do for utilities what\nBayesian networks do for probabilities. Specifically, utility networks exploit\nthe new interpretation of conditional utility and utility independence to\ncompactly represent a utility distribution.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:59:02 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Shoham", "Yoav", ""]]}, {"id": "1302.1569", "submitter": "Choh Man Teng", "authors": "Choh Man Teng", "title": "Sequential Thresholds: Context Sensitive Default Extensions", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-437-444", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Default logic encounters some conceptual difficulties in representing common\nsense reasoning tasks. We argue that we should not try to formulate modular\ndefault rules that are presumed to work in all or most circumstances. We need\nto take into account the importance of the context which is continuously\nevolving during the reasoning process. Sequential thresholding is a\nquantitative counterpart of default logic which makes explicit the role context\nplays in the construction of a non-monotonic extension. We present a semantic\ncharacterization of generic non-monotonic reasoning, as well as the\ninstantiations pertaining to default logic and sequential thresholding. This\nprovides a link between the two mechanisms as well as a way to integrate the\ntwo that can be beneficial to both.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:59:08 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Teng", "Choh Man", ""]]}, {"id": "1302.1570", "submitter": "Moshe Tennenholtz", "authors": "Moshe Tennenholtz", "title": "On Stable Multi-Agent Behavior in Face of Uncertainty", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-445-452", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A stable joint plan should guarantee the achievement of a designer's goal in\na multi-agent environment, while ensuring that deviations from the prescribed\nplan would be detected. We present a computational framework where stable joint\nplans can be studied, as well as several basic results about the\nrepresentation, verification and synthesis of stable joint plans.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:59:13 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Tennenholtz", "Moshe", ""]]}, {"id": "1302.1571", "submitter": "Bo Thiesson", "authors": "Bo Thiesson", "title": "Score and Information for Recursive Exponential Models with Incomplete\n  Data", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-453-463", "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recursive graphical models usually underlie the statistical modelling\nconcerning probabilistic expert systems based on Bayesian networks. This paper\ndefines a version of these models, denoted as recursive exponential models,\nwhich have evolved by the desire to impose sophisticated domain knowledge onto\nlocal fragments of a model. Besides the structural knowledge, as specified by a\ngiven model, the statistical modelling may also include expert opinion about\nthe values of parameters in the model. It is shown how to translate imprecise\nexpert knowledge into approximately conjugate prior distributions. Based on\npossibly incomplete data, the score and the observed information are derived\nfor these models. This accounts for both the traditional score and observed\ninformation, derived as derivatives of the log-likelihood, and the posterior\nscore and observed information, derived as derivatives of the log-posterior\ndistribution. Throughout the paper the specialization into recursive graphical\nmodels is accounted for by a simple example.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:59:19 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Thiesson", "Bo", ""]]}, {"id": "1302.1573", "submitter": "Nevin Lianwen Zhang", "authors": "Nevin Lianwen Zhang, Wenju Liu", "title": "Region-Based Approximations for Planning in Stochastic Domains", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-472-480", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with planning in stochastic domains by means of\npartially observable Markov decision processes (POMDPs). POMDPs are difficult\nto solve. This paper identifies a subclass of POMDPs called region observable\nPOMDPs, which are easier to solve and can be used to approximate general POMDPs\nto arbitrary accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:59:30 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Zhang", "Nevin Lianwen", ""], ["Liu", "Wenju", ""]]}, {"id": "1302.1574", "submitter": "Nevin Lianwen Zhang", "authors": "Nevin Lianwen Zhang, Li Yan", "title": "Independence of Causal Influence and Clique Tree Propagation", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-481-488", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the role of independence of causal influence (ICI) in\nBayesian network inference. ICI allows one to factorize a conditional\nprobability table into smaller pieces. We describe a method for exploiting the\nfactorization in clique tree propagation (CTP) - the state-of-the-art exact\ninference algorithm for Bayesian networks. We also present empirical results\nshowing that the resulting algorithm is significantly more efficient than the\ncombination of CTP and previous techniques for exploiting ICI.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:59:36 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Zhang", "Nevin Lianwen", ""], ["Yan", "Li", ""]]}, {"id": "1302.1575", "submitter": "Nevin Lianwen Zhang", "authors": "Nevin Lianwen Zhang, Weihong Zhang", "title": "Fast Value Iteration for Goal-Directed Markov Decision Processes", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-489-494", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning problems where effects of actions are non-deterministic can be\nmodeled as Markov decision processes. Planning problems are usually\ngoal-directed. This paper proposes several techniques for exploiting the\ngoal-directedness to accelerate value iteration, a standard algorithm for\nsolving Markov decision processes. Empirical studies have shown that the\ntechniques can bring about significant speedups.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:59:41 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Zhang", "Nevin Lianwen", ""], ["Zhang", "Weihong", ""]]}, {"id": "1302.1669", "submitter": "Serge Gaspers", "authors": "Serge Gaspers and Victor Naroditskiy and Nina Narodytska and Toby\n  Walsh", "title": "Possible and Necessary Winner Problem in Social Polls", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social networks are increasingly being used to conduct polls. We introduce a\nsimple model of such social polling. We suppose agents vote sequentially, but\nthe order in which agents choose to vote is not necessarily fixed. We also\nsuppose that an agent's vote is influenced by the votes of their friends who\nhave already voted. Despite its simplicity, this model provides useful insights\ninto a number of areas including social polling, sequential voting, and\nmanipulation. We prove that the number of candidates and the network structure\naffect the computational complexity of computing which candidate necessarily or\npossibly can win in such a social poll. For social networks with bounded\ntreewidth and a bounded number of candidates, we provide polynomial algorithms\nfor both problems. In other cases, we prove that computing which candidates\nnecessarily or possibly win are computationally intractable.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2013 08:20:29 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Gaspers", "Serge", ""], ["Naroditskiy", "Victor", ""], ["Narodytska", "Nina", ""], ["Walsh", "Toby", ""]]}, {"id": "1302.1700", "submitter": "Dan Ciresan", "authors": "Alessandro Giusti, Dan C. Cire\\c{s}an, Jonathan Masci, Luca M.\n  Gambardella, J\\\"urgen Schmidhuber", "title": "Fast Image Scanning with Deep Max-Pooling Convolutional Neural Networks", "comments": "11 pages, 2 figures, 3 tables, 21 references, submitted to ICIP 2013", "journal-ref": "International Conference on Image Processing (ICIP) 2013,\n  Melbourne", "doi": null, "report-no": "IDSIA-01-13", "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks now excel at image classification, detection and\nsegmentation. When used to scan images by means of a sliding window, however,\ntheir high computational complexity can bring even the most powerful hardware\nto its knees. We show how dynamic programming can speedup the process by orders\nof magnitude, even when max-pooling layers are present.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2013 10:33:47 GMT"}], "update_date": "2013-05-07", "authors_parsed": [["Giusti", "Alessandro", ""], ["Cire\u015fan", "Dan C.", ""], ["Masci", "Jonathan", ""], ["Gambardella", "Luca M.", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1302.2056", "submitter": "Jose Hernandez-Orallo", "authors": "Jose Hernandez-Orallo", "title": "Complexity distribution of agent policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse the complexity of environments according to the policies that need\nto be used to achieve high performance. The performance results for a\npopulation of policies leads to a distribution that is examined in terms of\npolicy complexity and analysed through several diagrams and indicators. The\nnotion of environment response curve is also introduced, by inverting the\nperformance results into an ability scale. We apply all these concepts,\ndiagrams and indicators to a minimalistic environment class, agent-populated\nelementary cellular automata, showing how the difficulty, discriminating power\nand ranges (previous to normalisation) may vary for several environments.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2013 15:01:20 GMT"}], "update_date": "2013-02-11", "authors_parsed": [["Hernandez-Orallo", "Jose", ""]]}, {"id": "1302.2223", "submitter": "Marko Horvat", "authors": "Marko Horvat, Anton Grbin, Gordan Gledec", "title": "WNtags: A Web-Based Tool For Image Labeling And Retrieval With Lexical\n  Ontologies", "comments": "10 pages, 3 figures, published in 16th International Conference on\n  Knowledge-Based and Intelligent Information & Engineering Systems, 10-12 Sep\n  2012, San Sebastian, Spain", "journal-ref": "Frontiers in artificial intelligence and applications, 243, pp.\n  585-594 (2012)", "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ever growing number of image documents available on the Internet continuously\nmotivates research in better annotation models and more efficient retrieval\nmethods. Formal knowledge representation of objects and events in pictures,\ntheir interaction as well as context complexity becomes no longer an option for\na quality image repository, but a necessity. We present an ontology-based\nonline image annotation tool WNtags and demonstrate its usefulness in several\ntypical multimedia retrieval tasks using International Affective Picture System\nemotionally annotated image database. WNtags is built around WordNet lexical\nontology but considers Suggested Upper Merged Ontology as the preferred\nlabeling formalism. WNtags uses sets of weighted WordNet synsets as high-level\nimage semantic descriptors and query matching is performed with word stemming\nand node distance metrics. We also elaborate our near future plans to expand\nimage content description with induced affect as in stimuli for research of\nhuman emotion and attention.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2013 11:49:19 GMT"}, {"version": "v2", "created": "Tue, 5 Dec 2017 18:50:48 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Horvat", "Marko", ""], ["Grbin", "Anton", ""], ["Gledec", "Gordan", ""]]}, {"id": "1302.2465", "submitter": "Patrick Rodler", "authors": "Patrick Rodler and Kostyantyn Shchekotykhin and Philipp Fleiss and\n  Gerhard Friedrich", "title": "RIO: Minimizing User Interaction in Debugging of Knowledge Bases", "comments": "arXiv admin note: substantial text overlap with arXiv:1209.3734", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The best currently known interactive debugging systems rely upon some\nmeta-information in terms of fault probabilities in order to improve their\nefficiency. However, misleading meta information might result in a dramatic\ndecrease of the performance and its assessment is only possible a-posteriori.\nConsequently, as long as the actual fault is unknown, there is always some risk\nof suboptimal interactions. In this work we present a reinforcement learning\nstrategy that continuously adapts its behavior depending on the performance\nachieved and minimizes the risk of using low-quality meta information.\nTherefore, this method is suitable for application scenarios where reliable\nprior fault estimates are difficult to obtain. Using diverse real-world\nknowledge bases, we show that the proposed interactive query strategy is\nscalable, features decent reaction time, and outperforms both entropy-based and\nno-risk strategies on average w.r.t. required amount of user interaction.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2013 12:53:47 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2013 14:46:03 GMT"}], "update_date": "2013-03-07", "authors_parsed": [["Rodler", "Patrick", ""], ["Shchekotykhin", "Kostyantyn", ""], ["Fleiss", "Philipp", ""], ["Friedrich", "Gerhard", ""]]}, {"id": "1302.2828", "submitter": "Michal \\v{C}\\'ap", "authors": "Michal \\v{C}\\'ap and Peter Nov\\'ak and Ji\\v{r}\\'i Vok\\v{r}\\'inek and\n  Michal P\\v{e}chou\\v{c}ek", "title": "Multi-agent RRT*: Sampling-based Cooperative Pathfinding (Extended\n  Abstract)", "comments": "To appear at AAMAS 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative pathfinding is a problem of finding a set of non-conflicting\ntrajectories for a number of mobile agents. Its applications include planning\nfor teams of mobile robots, such as autonomous aircrafts, cars, or underwater\nvehicles. The state-of-the-art algorithms for cooperative pathfinding typically\nrely on some heuristic forward-search pathfinding technique, where A* is often\nthe algorithm of choice. Here, we propose MA-RRT*, a novel algorithm for\nmulti-agent path planning that builds upon a recently proposed\nasymptotically-optimal sampling-based algorithm for finding single-agent\nshortest path called RRT*. We experimentally evaluate the performance of the\nalgorithm and show that the sampling-based approach offers better scalability\nthan the classical forward-search approach in relatively large, but sparse\nenvironments, which are typical in real-world applications such as\nmulti-aircraft collision avoidance.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2013 15:47:43 GMT"}], "update_date": "2013-02-13", "authors_parsed": [["\u010c\u00e1p", "Michal", ""], ["Nov\u00e1k", "Peter", ""], ["Vok\u0159\u00ednek", "Ji\u0159\u00ed", ""], ["P\u011bchou\u010dek", "Michal", ""]]}, {"id": "1302.3549", "submitter": "Silvia Acid", "authors": "Silvia Acid, Luis M. de Campos", "title": "An Algorithm for Finding Minimum d-Separating Sets in Belief Networks", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-3-10", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The criterion commonly used in directed acyclic graphs (dags) for testing\ngraphical independence is the well-known d-separation criterion. It allows us\nto build graphical representations of dependency models (usually probabilistic\ndependency models) in the form of belief networks, which make easy\ninterpretation and management of independence relationships possible, without\nreference to numerical parameters (conditional probabilities). In this paper,\nwe study the following combinatorial problem: finding the minimum d-separating\nset for two nodes in a dag. This set would represent the minimum information\n(in the sense of minimum number of variables) necessary to prevent these two\nnodes from influencing each other. The solution to this basic problem and some\nof its extensions can be useful in several ways, as we shall see later. Our\nsolution is based on a two-step process: first, we reduce the original problem\nto the simpler one of finding a minimum separating set in an undirected graph,\nand second, we develop an algorithm for solving it.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:11:19 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Acid", "Silvia", ""], ["de Campos", "Luis M.", ""]]}, {"id": "1302.3550", "submitter": "John Mark Agosta", "authors": "John Mark Agosta", "title": "Constraining Influence Diagram Structure by Generative Planning: An\n  Application to the Optimization of Oil Spill Response", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-11-19", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper works through the optimization of a real world planning problem,\nwith a combination of a generative planning tool and an influence diagram\nsolver. The problem is taken from an existing application in the domain of oil\nspill emergency response. The planning agent manages constraints that order\nsets of feasible equipment employment actions. This is mapped at an\nintermediate level of abstraction onto an influence diagram. In addition, the\nplanner can apply a surveillance operator that determines observability of the\nstate---the unknown trajectory of the oil. The uncertain world state and the\nobjective function properties are part of the influence diagram structure, but\nnot represented in the planning agent domain. By exploiting this structure\nunder the constraints generated by the planning agent, the influence diagram\nsolution complexity simplifies considerably, and an optimum solution to the\nemployment problem based on the objective function is found. Finding this\noptimum is equivalent to the simultaneous evaluation of a range of plans. This\nresult is an example of bounded optimality, within the limitations of this\nhybrid generative planner and influence diagram architecture.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:11:25 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Agosta", "John Mark", ""]]}, {"id": "1302.3551", "submitter": "Satnam Alag", "authors": "Satnam Alag, Alice M. Agogino", "title": "Inference Using Message Propagation and Topology Transformation in\n  Vector Gaussian Continuous Networks", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-20-27", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend Gaussian networks - directed acyclic graphs that encode\nprobabilistic relationships between variables - to its vector form. Vector\nGaussian continuous networks consist of composite nodes representing\nmultivariates, that take continuous values. These vector or composite nodes can\nrepresent correlations between parents, as opposed to conventional univariate\nnodes. We derive rules for inference in these networks based on two methods:\nmessage propagation and topology transformation. These two approaches lead to\nthe development of algorithms, that can be implemented in either a centralized\nor a decentralized manner. The domain of application of these networks are\nmonitoring and estimation problems. This new representation along with the\nrules for inference developed here can be used to derive current Bayesian\nalgorithms such as the Kalman filter, and provide a rich foundation to develop\nnew algorithms. We illustrate this process by deriving the decentralized form\nof the Kalman filter. This work unifies concepts from artificial intelligence\nand modern control theory.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:11:31 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Alag", "Satnam", ""], ["Agogino", "Alice M.", ""]]}, {"id": "1302.3552", "submitter": "Constantin F. Aliferis", "authors": "Constantin F. Aliferis, Gregory F. Cooper", "title": "A Structurally and Temporally Extended Bayesian Belief Network Model:\n  Definitions, Properties, and Modeling Techniques", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-28-39", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We developed the language of Modifiable Temporal Belief Networks (MTBNs) as a\nstructural and temporal extension of Bayesian Belief Networks (BNs) to\nfacilitate normative temporal and causal modeling under uncertainty. In this\npaper we present definitions of the model, its components, and its fundamental\nproperties. We also discuss how to represent various types of temporal\nknowledge, with an emphasis on hybrid temporal-explicit time modeling, dynamic\nstructures, avoiding causal temporal inconsistencies, and dealing with models\nthat involve simultaneously actions (decisions) and causal and non-causal\nassociations. We examine the relationships among BNs, Modifiable Belief\nNetworks, and MTBNs with a single temporal granularity, and suggest areas of\napplication suitable to each one of them.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:11:37 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Aliferis", "Constantin F.", ""], ["Cooper", "Gregory F.", ""]]}, {"id": "1302.3553", "submitter": "Steen A. Andersson", "authors": "Steen A. Andersson, David Madigan, Michael D. Perlman", "title": "An Alternative Markov Property for Chain Graphs", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-40-48", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphical Markov models use graphs, either undirected, directed, or mixed, to\nrepresent possible dependences among statistical variables. Applications of\nundirected graphs (UDGs) include models for spatial dependence and image\nanalysis, while acyclic directed graphs (ADGs), which are especially convenient\nfor statistical analysis, arise in such fields as genetics and psychometrics\nand as models for expert systems and Bayesian belief networks. Lauritzen,\nWermuth and Frydenberg (LWF) introduced a Markov property for chain graphs,\nwhich are mixed graphs that can be used to represent simultaneously both causal\nand associative dependencies and which include both UDGs and ADGs as special\ncases. In this paper an alternative Markov property (AMP) for chain graphs is\nintroduced, which in some ways is a more direct extension of the ADG Markov\nproperty than is the LWF property for chain graph.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:11:42 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Andersson", "Steen A.", ""], ["Madigan", "David", ""], ["Perlman", "Michael D.", ""]]}, {"id": "1302.3554", "submitter": "Ella M. Atkins", "authors": "Ella M. Atkins, Edmund H. Durfee, Kang G. Shin", "title": "Plan Development using Local Probabilistic Models", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-49-56", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate models of world state transitions are necessary when building\nplans for complex systems operating in dynamic environments. External event\nprobabilities can depend on state feature values as well as time spent in that\nparticular state. We assign temporally -dependent probability functions to\nstate transitions. These functions are used to locally compute state\nprobabilities, which are then used to select highly probable goal paths and\neliminate improbable states. This probabilistic model has been implemented in\nthe Cooperative Intelligent Real-time Control Architecture (CIRCA), which\ncombines an AI planner with a separate real-time system such that plans are\ndeveloped, scheduled, and executed with real-time guarantees. We present flight\nsimulation tests that demonstrate how our probabilistic model may improve CIRCA\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:11:48 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Atkins", "Ella M.", ""], ["Durfee", "Edmund H.", ""], ["Shin", "Kang G.", ""]]}, {"id": "1302.3555", "submitter": "Donald Bamber", "authors": "Donald Bamber", "title": "Entailment in Probability of Thresholded Generalizations", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-57-64", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A nonmonotonic logic of thresholded generalizations is presented. Given\npropositions A and B from a language L and a positive integer k, the\nthresholded generalization A=>B{k} means that the conditional probability\nP(B|A) falls short of one by no more than c*d^k. A two-level probability\nstructure is defined. At the lower level, a model is defined to be a\nprobability function on L. At the upper level, there is a probability\ndistribution over models. A definition is given of what it means for a\ncollection of thresholded generalizations to entail another thresholded\ngeneralization. This nonmonotonic entailment relation, called \"entailment in\nprobability\", has the feature that its conclusions are \"probabilistically\ntrustworthy\" meaning that, given true premises, it is improbable that an\nentailed conclusion would be false. A procedure is presented for ascertaining\nwhether any given collection of premises entails any given conclusion. It is\nshown that entailment in probability is closely related to Goldszmidt and\nPearl's System-Z^+, thereby demonstrating that the conclusions of System-Z^+\nare probabilistically trustworthy.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:11:54 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Bamber", "Donald", ""]]}, {"id": "1302.3556", "submitter": "Claude Barrouil", "authors": "Claude Barrouil, Jerome Lemaire", "title": "Object Recognition with Imperfect Perception and Redundant Description", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-65-72", "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with a scene recognition system in a robotics contex. The\ngeneral problem is to match images with <I>a priori</I> descriptions. A typical\nmission would consist in identifying an object in an installation with a vision\nsystem situated at the end of a manipulator and with a human operator provided\ndescription, formulated in a pseudo-natural language, and possibly redundant.\nThe originality of this work comes from the nature of the description, from the\nspecial attention given to the management of imprecision and uncertainty in the\ninterpretation process and from the way to assess the description redundancy so\nas to reinforce the overall matching likelihood.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:12:00 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Barrouil", "Claude", ""], ["Lemaire", "Jerome", ""]]}, {"id": "1302.3557", "submitter": "Mathias Bauer", "authors": "Mathias Bauer", "title": "Approximations for Decision Making in the Dempster-Shafer Theory of\n  Evidence", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-73-80", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational complexity of reasoning within the Dempster-Shafer theory\nof evidence is one of the main points of criticism this formalism has to face.\nTo overcome this difficulty various approximation algorithms have been\nsuggested that aim at reducing the number of focal elements in the belief\nfunctions involved. Besides introducing a new algorithm using this method, this\npaper describes an empirical study that examines the appropriateness of these\napproximation procedures in decision making situations. It presents the\nempirical findings and discusses the various tradeoffs that have to be taken\ninto account when actually applying one of these methods.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:12:06 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Bauer", "Mathias", ""]]}, {"id": "1302.3558", "submitter": "Ann Becker", "authors": "Ann Becker, Dan Geiger", "title": "A Sufficiently Fast Algorithm for Finding Close to Optimal Junction\n  Trees", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-81-89", "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An algorithm is developed for finding a close to optimal junction tree of a\ngiven graph G. The algorithm has a worst case complexity O(c^k n^a) where a and\nc are constants, n is the number of vertices, and k is the size of the largest\nclique in a junction tree of G in which this size is minimized. The algorithm\nguarantees that the logarithm of the size of the state space of the heaviest\nclique in the junction tree produced is less than a constant factor off the\noptimal value. When k = O(log n), our algorithm yields a polynomial inference\nalgorithm for Bayesian networks.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:12:12 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Becker", "Ann", ""], ["Geiger", "Dan", ""]]}, {"id": "1302.3559", "submitter": "Salem Benferhat", "authors": "Salem Benferhat, Didier Dubois, Henri Prade", "title": "Coping with the Limitations of Rational Inference in the Framework of\n  Possibility Theory", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-90-97", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Possibility theory offers a framework where both Lehmann's \"preferential\ninference\" and the more productive (but less cautious) \"rational closure\ninference\" can be represented. However, there are situations where the second\ninference does not provide expected results either because it cannot produce\nthem, or even provide counter-intuitive conclusions. This state of facts is not\ndue to the principle of selecting a unique ordering of interpretations (which\ncan be encoded by one possibility distribution), but rather to the absence of\nconstraints expressing pieces of knowledge we have implicitly in mind. It is\nadvocated in this paper that constraints induced by independence information\ncan help finding the right ordering of interpretations. In particular,\nindependence constraints can be systematically assumed with respect to formulas\ncomposed of literals which do not appear in the conditional knowledge base, or\nfor default rules with respect to situations which are \"normal\" according to\nthe other default rules in the base. The notion of independence which is used\ncan be easily expressed in the qualitative setting of possibility theory.\nMoreover, when a counter-intuitive plausible conclusion of a set of defaults,\nis in its rational closure, but not in its preferential closure, it is always\npossible to repair the set of defaults so as to produce the desired conclusion.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:12:18 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Benferhat", "Salem", ""], ["Dubois", "Didier", ""], ["Prade", "Henri", ""]]}, {"id": "1302.3560", "submitter": "Blai Bonet", "authors": "Blai Bonet, Hector Geffner", "title": "Arguing for Decisions: A Qualitative Model of Decision Making", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-98-105", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a qualitative model of decision making with two aims: to describe\nhow people make simple decisions and to enable computer programs to do the\nsame. Current approaches based on Planning or Decisions Theory either ignore\nuncertainty and tradeoffs, or provide languages and algorithms that are too\ncomplex for this task. The proposed model provides a language based on rules, a\nsemantics based on high probabilities and lexicographical preferences, and a\ntransparent decision procedure where reasons for and against decisions\ninteract. The model is no substitude for Decision Theory, yet for decisions\nthat people find easy to explain it may provide an appealing alternative.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:12:23 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Bonet", "Blai", ""], ["Geffner", "Hector", ""]]}, {"id": "1302.3562", "submitter": "Craig Boutilier", "authors": "Craig Boutilier, Nir Friedman, Moises Goldszmidt, Daphne Koller", "title": "Context-Specific Independence in Bayesian Networks", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-115-123", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian networks provide a language for qualitatively representing the\nconditional independence properties of a distribution. This allows a natural\nand compact representation of the distribution, eases knowledge acquisition,\nand supports effective inference algorithms. It is well-known, however, that\nthere are certain independencies that we cannot capture qualitatively within\nthe Bayesian network structure: independencies that hold only in certain\ncontexts, i.e., given a specific assignment of values to certain variables. In\nthis paper, we propose a formal notion of context-specific independence (CSI),\nbased on regularities in the conditional probability tables (CPTs) at a node.\nWe present a technique, analogous to (and based on) d-separation, for\ndetermining when such independence holds in a given network. We then focus on a\nparticular qualitative representation scheme - tree-structured CPTs - for\ncapturing CSI. We suggest ways in which this representation can be used to\nsupport effective inference algorithms. In particular, we present a structural\ndecomposition of the resulting network which can improve the performance of\nclustering algorithms, and an alternative algorithm based on cutset\nconditioning.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:12:34 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Boutilier", "Craig", ""], ["Friedman", "Nir", ""], ["Goldszmidt", "Moises", ""], ["Koller", "Daphne", ""]]}, {"id": "1302.3563", "submitter": "John Breese", "authors": "John S. Breese, David Heckerman", "title": "Decision-Theoretic Troubleshooting: A Framework for Repair and\n  Experiment", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-124-132", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop and extend existing decision-theoretic methods for troubleshooting\na nonfunctioning device. Traditionally, diagnosis with Bayesian networks has\nfocused on belief updating---determining the probabilities of various faults\ngiven current observations. In this paper, we extend this paradigm to include\ntaking actions. In particular, we consider three classes of actions: (1) we can\nmake observations regarding the behavior of a device and infer likely faults as\nin traditional diagnosis, (2) we can repair a component and then observe the\nbehavior of the device to infer likely faults, and (3) we can change the\nconfiguration of the device, observe its new behavior, and infer the likelihood\nof faults. Analysis of latter two classes of troubleshooting actions requires\nincorporating notions of persistence into the belief-network formalism used for\nprobabilistic inference.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:12:40 GMT"}, {"version": "v2", "created": "Sun, 17 May 2015 23:18:21 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Breese", "John S.", ""], ["Heckerman", "David", ""]]}, {"id": "1302.3564", "submitter": "Enrique F. Castillo", "authors": "Enrique F. Castillo, Cristina Solares, Patricia Gomez", "title": "Tail Sensitivity Analysis in Bayesian Networks", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-133-140", "categories": "cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents an efficient method for simulating the tails of a target\nvariable Z=h(X) which depends on a set of basic variables X=(X_1, ..., X_n). To\nthis aim, variables X_i, i=1, ..., n are sequentially simulated in such a\nmanner that Z=h(x_1, ..., x_i-1, X_i, ..., X_n) is guaranteed to be in the tail\nof Z. When this method is difficult to apply, an alternative method is\nproposed, which leads to a low rejection proportion of sample values, when\ncompared with the Monte Carlo method. Both methods are shown to be very useful\nto perform a sensitivity analysis of Bayesian networks, when very large\nconfidence intervals for the marginal/conditional probabilities are required,\nas in reliability or risk analysis. The methods are shown to behave best when\nall scores coincide. The required modifications for this to occur are\ndiscussed. The methods are illustrated with several examples and one example of\napplication to a real case is used to illustrate the whole process.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:12:46 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Castillo", "Enrique F.", ""], ["Solares", "Cristina", ""], ["Gomez", "Patricia", ""]]}, {"id": "1302.3565", "submitter": "Tom Chavez", "authors": "Tom Chavez", "title": "Decision-Analytic Approaches to Operational Decision Making: Application\n  and Observation", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-141-149", "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision analysis (DA) and the rich set of tools developed by researchers in\ndecision making under uncertainty show great potential to penetrate the\ntechnological content of the products and services delivered by firms in a\nvariety of industries as well as the business processes used to deliver those\nproducts and services to market. In this paper I describe work in progress at\nSun Microsystems in the application of decision-analytic methods to Operational\nDecision Making (ODM) in its World-Wide Operations (WWOPS) Business Management\nGroup. Working with membersof product engineering, marketing, and sales,\noperations planners from WWOPS have begun to use a decision-analytic framework\ncalled SCRAM (Supply Communication/Risk Assessment and Management) to structure\nand solve problems in product planning, tracking, and transition. Concepts such\nas information value provide a powerful method of managing huge information\nsets and thereby enable managers to focus attention on factors that matter most\nfor their business. Finally, our process-oriented introduction of\ndecision-analytic methods to Sun managers has led to a focused effort to\ndevelop decision support software based on methods from decision making under\nuncertainty.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:12:52 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Chavez", "Tom", ""]]}, {"id": "1302.3566", "submitter": "David Maxwell Chickering", "authors": "David Maxwell Chickering", "title": "Learning Equivalence Classes of Bayesian Networks Structures", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-150-157", "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approaches to learning Bayesian networks from data typically combine a\nscoring function with a heuristic search procedure. Given a Bayesian network\nstructure, many of the scoring functions derived in the literature return a\nscore for the entire equivalence class to which the structure belongs. When\nusing such a scoring function, it is appropriate for the heuristic search\nalgorithm to search over equivalence classes of Bayesian networks as opposed to\nindividual structures. We present the general formulation of a search space for\nwhich the states of the search correspond to equivalence classes of structures.\nUsing this space, any one of a number of heuristic search algorithms can easily\nbe applied. We compare greedy search performance in the proposed search space\nto greedy search performance in a search space for which the states correspond\nto individual Bayesian network structures.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:12:58 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Chickering", "David Maxwell", ""]]}, {"id": "1302.3567", "submitter": "Max Chickering", "authors": "David Maxwell Chickering, David Heckerman", "title": "Efficient Approximations for the Marginal Likelihood of Incomplete Data\n  Given a Bayesian Network", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-158-168", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss Bayesian methods for learning Bayesian networks when data sets are\nincomplete. In particular, we examine asymptotic approximations for the\nmarginal likelihood of incomplete data given a Bayesian network. We consider\nthe Laplace approximation and the less accurate but more efficient BIC/MDL\napproximation. We also consider approximations proposed by Draper (1993) and\nCheeseman and Stutz (1995). These approximations are as efficient as BIC/MDL,\nbut their accuracy has not been studied in any depth. We compare the accuracy\nof these approximations under the assumption that the Laplace approximation is\nthe most accurate. In experiments using synthetic data generated from discrete\nnaive-Bayes models having a hidden root node, we find that the CS measure is\nthe most accurate.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:13:03 GMT"}, {"version": "v2", "created": "Sun, 17 May 2015 00:07:34 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Chickering", "David Maxwell", ""], ["Heckerman", "David", ""]]}, {"id": "1302.3568", "submitter": "Lonnie Chrisman", "authors": "Lonnie Chrisman", "title": "Independence with Lower and Upper Probabilities", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-169-177", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is shown that the ability of the interval probability representation to\ncapture epistemological independence is severely limited. Two events are\nepistemologically independent if knowledge of the first event does not alter\nbelief (i.e., probability bounds) about the second. However, independence in\nthis form can only exist in a 2-monotone probability function in degenerate\ncases i.e., if the prior bounds are either point probabilities or entirely\nvacuous. Additional limitations are characterized for other classes of lower\nprobabilities as well. It is argued that these phenomena are simply a matter of\ninterpretation. They appear to be limitations when one interprets probability\nbounds as a measure of epistemological indeterminacy (i.e., uncertainty arising\nfrom a lack of knowledge), but are exactly as one would expect when probability\nintervals are interpreted as representations of ontological indeterminacy\n(indeterminacy introduced by structural approximations). The ontological\ninterpretation is introduced and discussed.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:13:09 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Chrisman", "Lonnie", ""]]}, {"id": "1302.3569", "submitter": "Lonnie Chrisman", "authors": "Lonnie Chrisman", "title": "Propagation of 2-Monotone Lower Probabilities on an Undirected Graph", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-178-185", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lower and upper probabilities, also known as Choquet capacities, are widely\nused as a convenient representation for sets of probability distributions. This\npaper presents a graphical decomposition and exact propagation algorithm for\ncomputing marginal posteriors of 2-monotone lower probabilities (equivalently,\n2-alternating upper probabilities).\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:13:15 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Chrisman", "Lonnie", ""]]}, {"id": "1302.3570", "submitter": "Fabio Gagliardi Cozman", "authors": "Fabio Gagliardi Cozman, Eric Krotkov", "title": "Quasi-Bayesian Strategies for Efficient Plan Generation: Application to\n  the Planning to Observe Problem", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-186-193", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quasi-Bayesian theory uses convex sets of probability distributions and\nexpected loss to represent preferences about plans. The theory focuses on\ndecision robustness, i.e., the extent to which plans are affected by deviations\nin subjective assessments of probability. The present work presents solutions\nfor plan generation when robustness of probability assessments must be\nincluded: plans contain information about the robustness of certain actions.\nThe surprising result is that some problems can be solved faster in the\nQuasi-Bayesian framework than within usual Bayesian theory. We investigate this\non the planning to observe problem, i.e., an agent must decide whether to take\nnew observations or not. The fundamental question is: How, and how much, to\nsearch for a \"best\" plan, based on the robustness of probability assessments?\nPlan generation algorithms are derived in the context of material\nclassification with an acoustic robotic probe. A package that constructs\nQuasi-Bayesian plans is available through anonymous ftp.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:13:21 GMT"}], "update_date": "2016-11-04", "authors_parsed": [["Cozman", "Fabio Gagliardi", ""], ["Krotkov", "Eric", ""]]}, {"id": "1302.3571", "submitter": "Bruce D'Ambrosio", "authors": "Bruce D'Ambrosio, Scott Burgess", "title": "Some Experiments with Real-Time Decision Algorithms", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-194-202", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time Decision algorithms are a class of incremental resource-bounded\n[Horvitz, 89] or anytime [Dean, 93] algorithms for evaluating influence\ndiagrams. We present a test domain for real-time decision algorithms, and the\nresults of experiments with several Real-time Decision Algorithms in this\ndomain. The results demonstrate high performance for two algorithms, a\ndecision-evaluation variant of Incremental Probabilisitic Inference [D'Ambrosio\n93] and a variant of an algorithm suggested by Goldszmidt, [Goldszmidt, 95],\nPK-reduced. We discuss the implications of these experimental results and\nexplore the broader applicability of these algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:13:27 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["D'Ambrosio", "Bruce", ""], ["Burgess", "Scott", ""]]}, {"id": "1302.3572", "submitter": "Rina Dechter", "authors": "Rina Dechter", "title": "Bucket Elimination: A Unifying Framework for Several Probabilistic\n  Inference", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-211-219", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic inference algorithms for finding the most probable explanation,\nthe maximum aposteriori hypothesis, and the maximum expected utility and for\nupdating belief are reformulated as an elimination--type algorithm called\nbucket elimination. This emphasizes the principle common to many of the\nalgorithms appearing in that literature and clarifies their relationship to\nnonserial dynamic programming algorithms. We also present a general way of\ncombining conditioning and elimination within this framework. Bounds on\ncomplexity are given for all the algorithms as a function of the problem's\nstructure.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:13:33 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Dechter", "Rina", ""]]}, {"id": "1302.3573", "submitter": "Rina Dechter", "authors": "Rina Dechter", "title": "Topological Parameters for Time-Space Tradeoff", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-220-227", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a family of algorithms combining tree-clustering\nwith conditioning that trade space for time. Such algorithms are useful for\nreasoning in probabilistic and deterministic networks as well as for\naccomplishing optimization tasks. By analyzing the problem structure it will be\npossible to select from a spectrum the algorithm that best meets a given\ntime-space specification.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:13:38 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Dechter", "Rina", ""]]}, {"id": "1302.3574", "submitter": "AnHai Doan", "authors": "AnHai Doan, Peter Haddawy", "title": "Sound Abstraction of Probabilistic Actions in The Constraint Mass\n  Assignment Framework", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-228-235", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a formal and practical framework for sound abstraction of\nprobabilistic actions. We start by precisely defining the concept of sound\nabstraction within the context of finite-horizon planning (where each plan is a\nfinite sequence of actions). Next we show that such abstraction cannot be\nperformed within the traditional probabilistic action representation, which\nmodels a world with a single probability distribution over the state space. We\nthen present the constraint mass assignment representation, which models the\nworld with a set of probability distributions and is a generalization of mass\nassignment representations. Within this framework, we present sound abstraction\nprocedures for three types of action abstraction. We end the paper with\ndiscussions and related work on sound and approximate abstraction. We give\npointers to papers in which we discuss other sound abstraction-related issues,\nincluding applications, estimating loss due to abstraction, and automatically\ngenerating abstraction hierarchies.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:13:44 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Doan", "AnHai", ""], ["Haddawy", "Peter", ""]]}, {"id": "1302.3575", "submitter": "Didier Dubois", "authors": "Didier Dubois, Henri Prade", "title": "Belief Revision with Uncertain Inputs in the Possibilistic Setting", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-236-243", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses belief revision under uncertain inputs in the framework\nof possibility theory. Revision can be based on two possible definitions of the\nconditioning operation, one based on min operator which requires a purely\nordinal scale only, and another based on product, for which a richer structure\nis needed, and which is a particular case of Dempster's rule of conditioning.\nBesides, revision under uncertain inputs can be understood in two different\nways depending on whether the input is viewed, or not, as a constraint to\nenforce. Moreover, it is shown that M.A. Williams' transmutations, originally\ndefined in the setting of Spohn's functions, can be captured in this framework,\nas well as Boutilier's natural revision.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:13:49 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Dubois", "Didier", ""], ["Prade", "Henri", ""]]}, {"id": "1302.3576", "submitter": "Yousri El Fattah", "authors": "Yousri El Fattah, Rina Dechter", "title": "An Evaluation of Structural Parameters for Probabilistic Reasoning:\n  Results on Benchmark Circuits", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-244-251", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many algorithms for processing probabilistic networks are dependent on the\ntopological properties of the problem's structure. Such algorithms (e.g.,\nclustering, conditioning) are effective only if the problem has a sparse graph\ncaptured by parameters such as tree width and cycle-cut set size. In this paper\nwe initiate a study to determine the potential of structure-based algorithms in\nreal-life applications. We analyze empirically the structural properties of\nproblems coming from the circuit diagnosis domain. Specifically, we locate\nthose properties that capture the effectiveness of clustering and conditioning\nas well as of a family of conditioning+clustering algorithms designed to\ngradually trade space for time. We perform our analysis on 11 benchmark\ncircuits widely used in the testing community. We also report on the effect of\nordering heuristics on tree-clustering and show that, on our benchmarks, the\nwell-known max-cardinality ordering is substantially inferior to an ordering\ncalled min-degree.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:13:55 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Fattah", "Yousri El", ""], ["Dechter", "Rina", ""]]}, {"id": "1302.3577", "submitter": "Nir Friedman", "authors": "Nir Friedman, Moises Goldszmidt", "title": "Learning Bayesian Networks with Local Structure", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-252-262", "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we examine a novel addition to the known methods for learning\nBayesian networks from data that improves the quality of the learned networks.\nOur approach explicitly represents and learns the local structure in the\nconditional probability tables (CPTs), that quantify these networks. This\nincreases the space of possible models, enabling the representation of CPTs\nwith a variable number of parameters that depends on the learned local\nstructures. The resulting learning procedure is capable of inducing models that\nbetter emulate the real complexity of the interactions present in the data. We\ndescribe the theoretical foundations and practical aspects of learning local\nstructures, as well as an empirical evaluation of the proposed method. This\nevaluation indicates that learning curves characterizing the procedure that\nexploits the local structure converge faster than these of the standard\nprocedure. Our results also show that networks learned with local structure\ntend to be more complex (in terms of arcs), yet require less parameters.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:14:02 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Friedman", "Nir", ""], ["Goldszmidt", "Moises", ""]]}, {"id": "1302.3578", "submitter": "Nir Friedman", "authors": "Nir Friedman, Joseph Y. Halpern", "title": "A Qualitative Markov Assumption and its Implications for Belief Change", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-263-273", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of belief change has been an active area in philosophy and AI. In\nrecent years two special cases of belief change, belief revision and belief\nupdate, have been studied in detail. Roughly, revision treats a surprising\nobservation as a sign that previous beliefs were wrong, while update treats a\nsurprising observation as an indication that the world has changed. In general,\nwe would expect that an agent making an observation may both want to revise\nsome earlier beliefs and assume that some change has occurred in the world. We\ndefine a novel approach to belief change that allows us to do this, by applying\nideas from probability theory in a qualitative setting. The key idea is to use\na qualitative Markov assumption, which says that state transitions are\nindependent. We show that a recent approach to modeling qualitative uncertainty\nusing plausibility measures allows us to make such a qualitative Markov\nassumption in a relatively straightforward way, and show how the Markov\nassumption can be used to provide an attractive belief-change model.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:14:08 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Friedman", "Nir", ""], ["Halpern", "Joseph Y.", ""]]}, {"id": "1302.3580", "submitter": "Dan Geiger", "authors": "Dan Geiger, David Heckerman, Christopher Meek", "title": "Asymptotic Model Selection for Directed Networks with Hidden Variables", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-283-290", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the Bayesian Information Criterion (BIC), an asymptotic\napproximation for the marginal likelihood, to Bayesian networks with hidden\nvariables. This approximation can be used to select models given large samples\nof data. The standard BIC as well as our extension punishes the complexity of a\nmodel according to the dimension of its parameters. We argue that the dimension\nof a Bayesian network with hidden variables is the rank of the Jacobian matrix\nof the transformation between the parameters of the network and the parameters\nof the observable variables. We compute the dimensions of several networks\nincluding the naive Bayes model with a hidden root node.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:14:19 GMT"}, {"version": "v2", "created": "Sat, 16 May 2015 23:35:58 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Geiger", "Dan", ""], ["Heckerman", "David", ""], ["Meek", "Christopher", ""]]}, {"id": "1302.3581", "submitter": "Vu A. Ha", "authors": "Vu A. Ha, Peter Haddawy", "title": "Theoretical Foundations for Abstraction-Based Probabilistic Planning", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-291-298", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling worlds and actions under uncertainty is one of the central problems\nin the framework of decision-theoretic planning. The representation must be\ngeneral enough to capture real-world problems but at the same time it must\nprovide a basis upon which theoretical results can be derived. The central\nnotion in the framework we propose here is that of the affine-operator, which\nserves as a tool for constructing (convex) sets of probability distributions,\nand which can be considered as a generalization of belief functions and\ninterval mass assignments. Uncertainty in the state of the worlds is modeled\nwith sets of probability distributions, represented by affine-trees while\nactions are defined as tree-manipulators. A small set of key properties of the\naffine-operator is presented, forming the basis for most existing\noperator-based definitions of probabilistic action projection and action\nabstraction. We derive and prove correct three projection rules, which vividly\nillustrate the precision-complexity tradeoff in plan projection. Finally, we\nshow how the three types of action abstraction identified by Haddawy and Doan\nare manifested in the present framework.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:14:25 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Ha", "Vu A.", ""], ["Haddawy", "Peter", ""]]}, {"id": "1302.3582", "submitter": "Max Henrion", "authors": "Max Henrion, Malcolm Pradhan, Brendan del Favero, Kurt Huang, Gregory\n  M. Provan, Paul O'Rorke", "title": "Why Is Diagnosis Using Belief Networks Insensitive to Imprecision In\n  Probabilities?", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-307-314", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has found that diagnostic performance with Bayesian belief\nnetworks is often surprisingly insensitive to imprecision in the numerical\nprobabilities. For example, the authors have recently completed an extensive\nstudy in which they applied random noise to the numerical probabilities in a\nset of belief networks for medical diagnosis, subsets of the CPCS network, a\nsubset of the QMR (Quick Medical Reference) focused on liver and bile diseases.\nThe diagnostic performance in terms of the average probabilities assigned to\nthe actual diseases showed small sensitivity even to large amounts of noise. In\nthis paper, we summarize the findings of this study and discuss possible\nexplanations of this low sensitivity. One reason is that the criterion for\nperformance is average probability of the true hypotheses, rather than average\nerror in probability, which is insensitive to symmetric noise distributions.\nBut, we show that even asymmetric, logodds-normal noise has modest effects. A\nsecond reason is that the gold-standard posterior probabilities are often near\nzero or one, and are little disturbed by noise.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:14:34 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Henrion", "Max", ""], ["Pradhan", "Malcolm", ""], ["del Favero", "Brendan", ""], ["Huang", "Kurt", ""], ["Provan", "Gregory M.", ""], ["O'Rorke", "Paul", ""]]}, {"id": "1302.3583", "submitter": "Michael C. Horsch", "authors": "Michael C. Horsch, David L. Poole", "title": "Flexible Policy Construction by Information Refinement", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-315-324", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on work towards flexible algorithms for solving decision problems\nrepresented as influence diagrams. An algorithm is given to construct a tree\nstructure for each decision node in an influence diagram. Each tree represents\na decision function and is constructed incrementally. The improvements to the\ntree converge to the optimal decision function (neglecting computational costs)\nand the asymptotic behaviour is only a constant factor worse than dynamic\nprogramming techniques, counting the number of Bayesian network queries.\nEmpirical results show how expected utility increases with the size of the tree\nand the number of Bayesian net calculations.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:14:40 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Horsch", "Michael C.", ""], ["Poole", "David L.", ""]]}, {"id": "1302.3584", "submitter": "Kurt Huang", "authors": "Kurt Huang, Max Henrion", "title": "Efficient Search-Based Inference for Noisy-OR Belief Networks:\n  TopEpsilon", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-325-331", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference algorithms for arbitrary belief networks are impractical for large,\ncomplex belief networks. Inference algorithms for specialized classes of belief\nnetworks have been shown to be more efficient. In this paper, we present a\nsearch-based algorithm for approximate inference on arbitrary, noisy-OR belief\nnetworks, generalizing earlier work on search-based inference for two-level,\nnoisy-OR belief networks. Initial experimental results appear promising.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:14:45 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Huang", "Kurt", ""], ["Henrion", "Max", ""]]}, {"id": "1302.3585", "submitter": "Pablo H. Ibarguengoytia", "authors": "Pablo H. Ibarguengoytia, Luis Enrique Sucar, Sunil Vadera", "title": "A Probabilistic Model For Sensor Validation", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-332-339", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The validation of data from sensors has become an important issue in the\noperation and control of modern industrial plants. One approach is to use\nknowledge based techniques to detect inconsistencies in measured data. This\narticle presents a probabilistic model for the detection of such\ninconsistencies. Based on probability propagation, this method is able to find\nthe existence of a possible fault among the set of sensors. That is, if an\nerror exists, many sensors present an apparent fault due to the propagation\nfrom the sensor(s) with a real fault. So the fault detection mechanism can only\ntell if a sensor has a potential fault, but it can not tell if the fault is\nreal or apparent. So the central problem is to develop a theory, and then an\nalgorithm, for distinguishing real and apparent faults, given that one or more\nsensors can fail at the same time. This article then, presents an approach\nbased on two levels: (i) probabilistic reasoning, to detect a potential fault,\nand (ii) constraint management, to distinguish the real fault from the apparent\nones. The proposed approach is exemplified by applying it to a power plant\nmodel.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:14:51 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Ibarguengoytia", "Pablo H.", ""], ["Sucar", "Luis Enrique", ""], ["Vadera", "Sunil", ""]]}, {"id": "1302.3586", "submitter": "Tommi S. Jaakkola", "authors": "Tommi S. Jaakkola, Michael I. Jordan", "title": "Computing Upper and Lower Bounds on Likelihoods in Intractable Networks", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-340-348", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present deterministic techniques for computing upper and lower bounds on\nmarginal probabilities in sigmoid and noisy-OR networks. These techniques\nbecome useful when the size of the network (or clique size) precludes exact\ncomputations. We illustrate the tightness of the bounds by numerical\nexperiments.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:14:57 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Jaakkola", "Tommi S.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1302.3587", "submitter": "Allan Leck Jensen", "authors": "Allan Leck Jensen, Finn Verner Jensen", "title": "MIDAS - An Influence Diagram for Management of Mildew in Winter Wheat", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-349-356", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a prototype of a decision support system for management of the\nfungal disease mildew in winter wheat. The prototype is based on an influence\ndiagram which is used to determine the optimal time and dose of mildew\ntreatments. This involves multiple decision opportunities over time,\nstochasticity, inaccurate information and incomplete knowledge. The paper\ndescribes the practical and theoretical problems encountered during the\nconstruction of the influence diagram, and also the experience with the\nprototype.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:15:02 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Jensen", "Allan Leck", ""], ["Jensen", "Finn Verner", ""]]}, {"id": "1302.3588", "submitter": "Alexander V. Kozlov", "authors": "Alexander V. Kozlov, Jaswinder Pal Singh", "title": "Computational Complexity Reduction for BN2O Networks Using Similarity of\n  States", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-357-364", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although probabilistic inference in a general Bayesian belief network is an\nNP-hard problem, computation time for inference can be reduced in most\npractical cases by exploiting domain knowledge and by making approximations in\nthe knowledge representation. In this paper we introduce the property of\nsimilarity of states and a new method for approximate knowledge representation\nand inference which is based on this property. We define two or more states of\na node to be similar when the ratio of their probabilities, the likelihood\nratio, does not depend on the instantiations of the other nodes in the network.\nWe show that the similarity of states exposes redundancies in the joint\nprobability distribution which can be exploited to reduce the computation time\nof probabilistic inference in networks with multiple similar states, and that\nthe computational complexity in the networks with exponentially many similar\nstates might be polynomial. We demonstrate our ideas on the example of a BN2O\nnetwork -- a two layer network often used in diagnostic problems -- by reducing\nit to a very close network with multiple similar states. We show that the\nanswers to practical queries converge very fast to the answers obtained with\nthe original network. The maximum error is as low as 5% for models that require\nonly 10% of the computation time needed by the original BN2O model.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:15:08 GMT"}], "update_date": "2016-11-04", "authors_parsed": [["Kozlov", "Alexander V.", ""], ["Singh", "Jaswinder Pal", ""]]}, {"id": "1302.3589", "submitter": "Henry E. Kyburg Jr.", "authors": "Henry E. Kyburg Jr", "title": "Uncertain Inferences and Uncertain Conclusions", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-365-372", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty may be taken to characterize inferences, their conclusions, their\npremises or all three. Under some treatments of uncertainty, the inferences\nitself is never characterized by uncertainty. We explore both the significance\nof uncertainty in the premises and in the conclusion of an argument that\ninvolves uncertainty. We argue that for uncertainty to characterize the\nconclusion of an inference is natural, but that there is an interplay between\nuncertainty in the premises and uncertainty in the procedure of argument\nitself. We show that it is possible in principle to incorporate all uncertainty\nin the premises, rendering uncertainty arguments deductively valid. But we then\nargue (1) that this does not reflect human argument, (2) that it is\ncomputationally costly, and (3) that the gain in simplicity obtained by\nallowing uncertainty inference can sometimes outweigh the loss of flexibility\nit entails.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:15:14 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Kyburg", "Henry E.", "Jr"]]}, {"id": "1302.3591", "submitter": "Suzanne M. Mahoney", "authors": "Suzanne M. Mahoney, Kathryn Blackmond Laskey", "title": "Network Engineering for Complex Belief Networks", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-389-396", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Like any large system development effort, the construction of a complex\nbelief network model requires systems engineering to manage the design and\nconstruction process. We propose a rapid prototyping approach to network\nengineering. We describe criteria for identifying network modules and the use\nof \"stubs\" to represent not-yet-constructed modules. We propose an object\noriented representation for belief networks which captures the semantics of the\nproblem in addition to conditional independencies and probabilities. Methods\nfor evaluating complex belief network models are discussed. The ideas are\nillustrated with examples from a large belief network construction problem in\nthe military intelligence domain.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:15:26 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Mahoney", "Suzanne M.", ""], ["Laskey", "Kathryn Blackmond", ""]]}, {"id": "1302.3592", "submitter": "Liem Ngo", "authors": "Liem Ngo", "title": "Probabilistic Disjunctive Logic Programming", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-397-404", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a framework for combining Disjunctive Logic\nProgramming and Poole's Probabilistic Horn Abduction. We use the concept of\nhypothesis to specify the probability structure. We consider the case in which\nprobabilistic information is not available. Instead of using probability\nintervals, we allow for the specification of the probabilities of disjunctions.\nBecause minimal models are used as characteristic models in disjunctive logic\nprogramming, we apply the principle of indifference on the set of minimal\nmodels to derive default probability values. We define the concepts of\nexplanation and partial explanation of a formula, and use them to determine the\ndefault probability distribution(s) induced by a program. An algorithm for\ncalculating the default probability of a goal is presented.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:15:32 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Ngo", "Liem", ""]]}, {"id": "1302.3593", "submitter": "David M Pennock", "authors": "David M. Pennock, Michael P. Wellman", "title": "Toward a Market Model for Bayesian Inference", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-405-413", "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a methodology for representing probabilistic relationships in a\ngeneral-equilibrium economic model. Specifically, we define a precise mapping\nfrom a Bayesian network with binary nodes to a market price system where\nconsumers and producers trade in uncertain propositions. We demonstrate the\ncorrespondence between the equilibrium prices of goods in this economy and the\nprobabilities represented by the Bayesian network. A computational market model\nsuch as this may provide a useful framework for investigations of belief\naggregation, distributed probabilistic inference, resource allocation under\nuncertainty, and other problems of decentralized uncertainty.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:15:38 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Pennock", "David M.", ""], ["Wellman", "Michael P.", ""]]}, {"id": "1302.3594", "submitter": "Mark Alan Peot", "authors": "Mark Alan Peot", "title": "Geometric Implications of the Naive Bayes Assumption", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-414-419", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A naive (or Idiot) Bayes network is a network with a single hypothesis node\nand several observations that are conditionally independent given the\nhypothesis. We recently surveyed a number of members of the UAI community and\ndiscovered a general lack of understanding of the implications of the Naive\nBayes assumption on the kinds of problems that can be solved by these networks.\nIt has long been recognized [Minsky 61] that if observations are binary, the\ndecision surfaces in these networks are hyperplanes. We extend this result\n(hyperplane separability) to Naive Bayes networks with m-ary observations. In\naddition, we illustrate the effect of observation-observation dependencies on\ndecision surfaces. Finally, we discuss the implications of these results on\nknowledge acquisition and research in learning.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:15:44 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Peot", "Mark Alan", ""]]}, {"id": "1302.3595", "submitter": "Judea Pearl", "authors": "Judea Pearl, Rina Dechter", "title": "Identifying Independencies in Causal Graphs with Feedback", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-420-426", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the d -separation criterion constitutes a valid test for\nconditional independence relationships that are induced by feedback systems\ninvolving discrete variables.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:15:49 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Pearl", "Judea", ""], ["Dechter", "Rina", ""]]}, {"id": "1302.3596", "submitter": "Kim-Leng Poh", "authors": "Kim-Leng Poh, Eric J. Horvitz", "title": "A Graph-Theoretic Analysis of Information Value", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-427-435", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive qualitative relationships about the informational relevance of\nvariables in graphical decision models based on a consideration of the topology\nof the models. Specifically, we identify dominance relations for the expected\nvalue of information on chance variables in terms of their position and\nrelationships in influence diagrams. The qualitative relationships can be\nharnessed to generate nonnumerical procedures for ordering uncertain variables\nin a decision model by their informational relevance.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:15:55 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Poh", "Kim-Leng", ""], ["Horvitz", "Eric J.", ""]]}, {"id": "1302.3597", "submitter": "David L Poole", "authors": "David L. Poole", "title": "A Framework for Decision-Theoretic Planning I: Combining the Situation\n  Calculus, Conditional Plans, Probability and Utility", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-436-445", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows how we can combine logical representations of actions and\ndecision theory in such a manner that seems natural for both. In particular we\nassume an axiomatization of the domain in terms of situation calculus, using\nwhat is essentially Reiter's solution to the frame problem, in terms of the\ncompletion of the axioms defining the state change. Uncertainty is handled in\nterms of the independent choice logic, which allows for independent choices and\na logic program that gives the consequences of the choices. As part of the\nconsequences are a specification of the utility of (final) states. The robot\nadopts robot plans, similar to the GOLOG programming language. Within this\nlogic, we can define the expected utility of a conditional plan, based on the\naxiomatization of the actions, the uncertainty and the utility. The ?planning'\nproblem is to find the plan with the highest expected utility. This is related\nto recent structured representations for POMDPs; here we use stochastic\nsituation calculus rules to specify the state transition function and the\nreward/value function. Finally we show that with stochastic frame axioms,\nactions representations in probabilistic STRIPS are exponentially larger than\nusing the representation proposed here.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:16:00 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Poole", "David L.", ""]]}, {"id": "1302.3598", "submitter": "Malcolm Pradhan", "authors": "Malcolm Pradhan, Paul Dagum", "title": "Optimal Monte Carlo Estimation of Belief Network Inference", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-446-453", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two Monte Carlo sampling algorithms for probabilistic inference\nthat guarantee polynomial-time convergence for a larger class of network than\ncurrent sampling algorithms provide. These new methods are variants of the\nknown likelihood weighting algorithm. We use of recent advances in the theory\nof optimal stopping rules for Monte Carlo simulation to obtain an inference\napproximation with relative error epsilon and a small failure probability\ndelta. We present an empirical evaluation of the algorithms which demonstrates\ntheir improved performance.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:16:06 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Pradhan", "Malcolm", ""], ["Dagum", "Paul", ""]]}, {"id": "1302.3599", "submitter": "Thomas S. Richardson", "authors": "Thomas S. Richardson", "title": "A Discovery Algorithm for Directed Cyclic Graphs", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-454-461", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directed acyclic graphs have been used fruitfully to represent causal\nstrucures (Pearl 1988). However, in the social sciences and elsewhere models\nare often used which correspond both causally and statistically to directed\ngraphs with directed cycles (Spirtes 1995). Pearl (1993) discussed predicting\nthe effects of intervention in models of this kind, so-called linear\nnon-recursive structural equation models. This raises the question of whether\nit is possible to make inferences about causal structure with cycles, form\nsample data. In particular do there exist general, informative, feasible and\nreliable precedures for inferring causal structure from conditional\nindependence relations among variables in a sample generated by an unknown\ncausal structure? In this paper I present a discovery algorithm that is correct\nin the large sample limit, given commonly (but often implicitly) made plausible\nassumptions, and which provides information about the existence or\nnon-existence of causal pathways from one variable to another. The algorithm is\npolynomial on sparse graphs.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:16:12 GMT"}], "update_date": "2020-10-24", "authors_parsed": [["Richardson", "Thomas S.", ""]]}, {"id": "1302.3600", "submitter": "Thomas S. Richardson", "authors": "Thomas S. Richardson", "title": "A Polynomial-Time Algorithm for Deciding Markov Equivalence of Directed\n  Cyclic Graphical Models", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-462-469", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the concept of d-separation was originally defined for directed\nacyclic graphs (see Pearl 1988), there is a natural extension of he concept to\ndirected cyclic graphs. When exactly the same set of d-separation relations\nhold in two directed graphs, no matter whether respectively cyclic or acyclic,\nwe say that they are Markov equivalent. In other words, when two directed\ncyclic graphs are Markov equivalent, the set of distributions that satisfy a\nnatural extension of the Global Directed Markov condition (Lauritzen et al.\n1990) is exactly the same for each graph. There is an obvious exponential (in\nthe number of vertices) time algorithm for deciding Markov equivalence of two\ndirected cyclic graphs; simply chech all of the d-separation relations in each\ngraph. In this paper I state a theorem that gives necessary and sufficient\nconditions for the Markov equivalence of two directed cyclic graphs, where each\nof the conditions can be checked in polynomial time. Hence, the theorem can be\neasily adapted into a polynomial time algorithm for deciding the Markov\nequivalence of two directed cyclic graphs. Although space prohibits inclusion\nof correctness proofs, they are fully described in Richardson (1994b).\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:16:18 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Richardson", "Thomas S.", ""]]}, {"id": "1302.3601", "submitter": "Wilhelm Roedder", "authors": "Wilhelm Roedder, Carl-Heinz Meyer", "title": "Coherent Knowledge Processing at Maximum Entropy by SPIRIT", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-470-476", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SPIRIT is an expert system shell for probabilistic knowledge bases. Knowledge\nacquisition is performed by processing facts and rules on discrete variables in\na rich syntax. The shell generates a probability distribution which respects\nall acquired facts and rules and which maximizes entropy. The user-friendly\ndevices of SPIRIT to define variables, formulate rules and create the knowledge\nbase are revealed in detail. Inductive learning is possible. Medium sized\napplications show the power of the system.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:16:23 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Roedder", "Wilhelm", ""], ["Meyer", "Carl-Heinz", ""]]}, {"id": "1302.3602", "submitter": "Eugene Santos Jr.", "authors": "Eugene Santos Jr., Solomon Eyal Shimony, Edward Williams", "title": "Sample-and-Accumulate Algorithms for Belief Updating in Bayes Networks", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-477-484", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Belief updating in Bayes nets, a well known computationally hard problem, has\nrecently been approximated by several deterministic algorithms, and by various\nrandomized approximation algorithms. Deterministic algorithms usually provide\nprobability bounds, but have an exponential runtime. Some randomized schemes\nhave a polynomial runtime, but provide only probability estimates. We present\nrandomized algorithms that enumerate high-probability partial instantiations,\nresulting in probability bounds. Some of these algorithms are also sampling\nalgorithms. Specifically, we introduce and evaluate a variant of backward\nsampling, both as a sampling algorithm and as a randomized enumeration\nalgorithm. We also relax the implicit assumption used by both sampling and\naccumulation algorithms, that query nodes must be instantiated in all the\nsamples.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:16:30 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Santos", "Eugene", "Jr."], ["Shimony", "Solomon Eyal", ""], ["Williams", "Edward", ""]]}, {"id": "1302.3603", "submitter": "Ross D. Shachter", "authors": "Ross D. Shachter, Marvin Mandelbaum", "title": "A Measure of Decision Flexibility", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-485-491", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a decision-analytical approach to comparing the flexibility of\ndecision situations from the perspective of a decision-maker who exhibits\nconstant risk-aversion over a monetary value model. Our approach is simple yet\nseems to be consistent with a variety of flexibility concepts, including robust\nand adaptive alternatives. We try to compensate within the model for\nuncertainty that was not anticipated or not modeled. This approach not only\nallows one to compare the flexibility of plans, but also guides the search for\nnew, more flexible alternatives.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:16:35 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Shachter", "Ross D.", ""], ["Mandelbaum", "Marvin", ""]]}, {"id": "1302.3604", "submitter": "Prakash P. Shenoy", "authors": "Prakash P. Shenoy", "title": "Binary Join Trees", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-492-499", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main goal of this paper is to describe a data structure called binary\njoin trees that are useful in computing multiple marginals efficiently using\nthe Shenoy-Shafer architecture. We define binary join trees, describe their\nutility, and sketch a procedure for constructing them.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:16:41 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Shenoy", "Prakash P.", ""]]}, {"id": "1302.3605", "submitter": "Sampath Srinivas", "authors": "Sampath Srinivas, Pandurang Nayak", "title": "Efficient Enumeration of Instantiations in Bayesian Networks", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-500-508", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past several years Bayesian networks have been applied to a wide\nvariety of problems. A central problem in applying Bayesian networks is that of\nfinding one or more of the most probable instantiations of a network. In this\npaper we develop an efficient algorithm that incrementally enumerates the\ninstantiations of a Bayesian network in decreasing order of probability. Such\nenumeration algorithms are applicable in a variety of applications ranging from\nmedical expert systems to model-based diagnosis. Fundamentally, our algorithm\nis simply performing a lazy enumeration of the sorted list of all\ninstantiations of the network. This insight leads to a very concise algorithm\nstatement which is both easily understood and implemented. We show that for\nsingly connected networks, our algorithm generates the next instantiation in\ntime polynomial in the size of the network. The algorithm extends to arbitrary\nBayesian networks using standard conditioning techniques. We empirically\nevaluate the enumeration algorithm and demonstrate its practicality.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:16:47 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Srinivas", "Sampath", ""], ["Nayak", "Pandurang", ""]]}, {"id": "1302.3606", "submitter": "Milan Studeny", "authors": "Milan Studeny", "title": "On Separation Criterion and Recovery Algorithm for Chain Graphs", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-509-516", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chain graphs give a natural unifying point of view on Markov and Bayesian\nnetworks and enlarge the potential of graphical models for description of\nconditional independence structures. In the paper a direct graphical separation\ncriterion for chain graphs, called c-separation, which generalizes the\nd-separation criterion for Bayesian networks is introduced (recalled). It is\nequivalent to the classic moralization criterion for chain graphs and complete\nin sense that for every chain graph there exists a probability distribution\nsatisfying exactly conditional independencies derivable from the chain graph by\nthe c-separation criterion. Every class of Markov equivalent chain graphs can\nbe uniquely described by a natural representative, called the largest chain\ngraph. A recovery algorithm, which on basis of the (conditional) dependency\nmodel induced by an unknown chain graph finds the corresponding largest chain\ngraph, is presented.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:16:53 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Studeny", "Milan", ""]]}, {"id": "1302.3607", "submitter": "Choh Man Teng", "authors": "Choh Man Teng", "title": "Possible World Partition Sequences: A Unifying Framework for Uncertain\n  Reasoning", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-517-524", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When we work with information from multiple sources, the formalism each\nemploys to handle uncertainty may not be uniform. In order to be able to\ncombine these knowledge bases of different formats, we need to first establish\na common basis for characterizing and evaluating the different formalisms, and\nprovide a semantics for the combined mechanism. A common framework can provide\nan infrastructure for building an integrated system, and is essential if we are\nto understand its behavior. We present a unifying framework based on an ordered\npartition of possible worlds called partition sequences, which corresponds to\nour intuitive notion of biasing towards certain possible scenarios when we are\nuncertain of the actual situation. We show that some of the existing\nformalisms, namely, default logic, autoepistemic logic, probabilistic\nconditioning and thresholding (generalized conditioning), and possibility\ntheory can be incorporated into this general framework.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:17:00 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Teng", "Choh Man", ""]]}, {"id": "1302.3608", "submitter": "Sylvie Thiebaux", "authors": "Sylvie Thiebaux, Marie-Odile Cordier, Olivier Jehl, Jean-Paul Krivine", "title": "Supply Restoration in Power Distribution Systems - A Case Study in\n  Integrating Model-Based Diagnosis and Repair Planning", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-525-532", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrating diagnosis and repair is particularly crucial when gaining\nsufficient information to discriminate between several candidate diagnoses\nrequires carrying out some repair actions. A typical case is supply restoration\nin a faulty power distribution system. This problem, which is a major concern\nfor electricity distributors, features partial observability, and stochastic\nrepair actions which are more elaborate than simple replacement of components.\nThis paper analyses the difficulties in applying existing work on integrating\nmodel-based diagnosis and repair and on planning in partially observable\nstochastic domains to this real-world problem, and describes the pragmatic\napproach we have retained so far.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:17:05 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Thiebaux", "Sylvie", ""], ["Cordier", "Marie-Odile", ""], ["Jehl", "Olivier", ""], ["Krivine", "Jean-Paul", ""]]}, {"id": "1302.3609", "submitter": "Robert L. Welch", "authors": "Robert L. Welch", "title": "Real Time Estimation of Bayesian Networks", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-533-544", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For real time evaluation of a Bayesian network when there is not sufficient\ntime to obtain an exact solution, a guaranteed response time, approximate\nsolution is required. It is shown that nontraditional methods utilizing\nestimators based on an archive of trial solutions and genetic search can\nprovide an approximate solution that is considerably superior to the\ntraditional Monte Carlo simulation methods.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:17:11 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Welch", "Robert L.", ""]]}, {"id": "1302.3610", "submitter": "Michael S. K. M. Wong", "authors": "Michael S. K. M. Wong", "title": "Testing Implication of Probabilistic Dependencies", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-545-553", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Axiomatization has been widely used for testing logical implications. This\npaper suggests a non-axiomatic method, the chase, to test if a new dependency\nfollows from a given set of probabilistic dependencies. Although the chase\ncomputation may require exponential time in some cases, this technique is a\npowerful tool for establishing nontrivial theoretical results. More\nimportantly, this approach provides valuable insight into the intriguing\nconnection between relational databases and probabilistic reasoning systems.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:17:17 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Wong", "Michael S. K. M.", ""]]}, {"id": "1302.3611", "submitter": "Peter R. Wurman", "authors": "Peter R. Wurman, Michael P. Wellman", "title": "Optimal Factory Scheduling using Stochastic Dominance A*", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-554-563", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine a standard factory scheduling problem with stochastic processing\nand setup times, minimizing the expectation of the weighted number of tardy\njobs. Because the costs of operators in the schedule are stochastic and\nsequence dependent, standard dynamic programming algorithms such as A* may fail\nto find the optimal schedule. The SDA* (Stochastic Dominance A*) algorithm\nremedies this difficulty by relaxing the pruning condition. We present an\nimproved state-space search formulation for these problems and discuss the\nconditions under which stochastic scheduling problems can be solved optimally\nusing SDA*. In empirical testing on randomly generated problems, we found that\nin 70%, the expected cost of the optimal stochastic solution is lower than that\nof the solution derived using a deterministic approximation, with comparable\nsearch effort.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:17:23 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Wurman", "Peter R.", ""], ["Wellman", "Michael P.", ""]]}, {"id": "1302.3612", "submitter": "Yang Xiang", "authors": "Yang Xiang, Michael S. K. M. Wong, N. Cercone", "title": "Critical Remarks on Single Link Search in Learning Belief Networks", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-564-571", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In learning belief networks, the single link lookahead search is widely\nadopted to reduce the search space. We show that there exists a class of\nprobabilistic domain models which displays a special pattern of dependency. We\nanalyze the behavior of several learning algorithms using different scoring\nmetrics such as the entropy, conditional independence, minimal description\nlength and Bayesian metrics. We demonstrate that single link lookahead search\nprocedures (employed in these algorithms) cannot learn these models correctly.\nThus, when the underlying domain model actually belongs to this class, the use\nof a single link search procedure will result in learning of an incorrect\nmodel. This may lead to inference errors when the model is used. Our analysis\nsuggests that if the prior knowledge about a domain does not rule out the\npossible existence of these models, a multi-link lookahead search or other\nheuristics should be used for the learning process.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:17:29 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Xiang", "Yang", ""], ["Wong", "Michael S. K. M.", ""], ["Cercone", "N.", ""]]}, {"id": "1302.3831", "submitter": "Diederik Aerts", "authors": "Diederik Aerts and Sandro Sozzo", "title": "Quantum Entanglement in Concept Combinations", "comments": "16 pages, no figures", "journal-ref": "International Journal of Theoretical Physics, 53, pp. 3587-3603,\n  2014", "doi": "10.1007/s10773-013-1946-z", "report-no": null, "categories": "cs.AI cs.CL quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in the application of quantum structures to cognitive science\nconfirms that these structures quite systematically appear in the dynamics of\nconcepts and their combinations and quantum-based models faithfully represent\nexperimental data of situations where classical approaches are problematical.\nIn this paper, we analyze the data we collected in an experiment on a specific\nconceptual combination, showing that Bell's inequalities are violated in the\nexperiment. We present a new refined entanglement scheme to model these data\nwithin standard quantum theory rules, where 'entangled measurements and\nentangled evolutions' occur, in addition to the expected 'entangled states',\nand present a full quantum representation in complex Hilbert space of the data.\nThis stronger form of entanglement in measurements and evolutions might have\nrelevant applications in the foundations of quantum theory, as well as in the\ninterpretation of nonlocality tests. It could indeed explain some\nnon-negligible 'anomalies' identified in EPR-Bell experiments.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2013 18:20:25 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2013 17:51:50 GMT"}], "update_date": "2015-12-31", "authors_parsed": [["Aerts", "Diederik", ""], ["Sozzo", "Sandro", ""]]}, {"id": "1302.3988", "submitter": "Valerio Capraro", "authors": "Valerio Capraro", "title": "A solution concept for games with altruism and cooperation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the years, numerous experiments have been accumulated to show that\ncooperation is not casual and depends on the payoffs of the game. These\nfindings suggest that humans have attitude to cooperation by nature and the\nsame person may act more or less cooperatively depending on the particular\npayoffs. In other words, people do not act a priori as single agents, but they\nforecast how the game would be played if they formed coalitions and then they\nplay according to their best forecast. In this paper we formalize this idea and\nwe define a new solution concept for one-shot normal form games. We prove that\nthis \\emph{cooperative equilibrium} exists for all finite games and it explains\na number of different experimental findings, such as (1) the rate of\ncooperation in the Prisoner's dilemma depends on the cost-benefit ratio; (2)\nthe rate of cooperation in the Traveler's dilemma depends on the bonus/penalty;\n(3) the rate of cooperation in the Publig Goods game depends on the pro-capite\nmarginal return and on the numbers of players; (4) the rate of cooperation in\nthe Bertrand competition depends on the number of players; (5) players tend to\nbe fair in the bargaining problem; (6) players tend to be fair in the Ultimatum\ngame; (7) players tend to be altruist in the Dictator game; (8) offers in the\nUltimatum game are larger than offers in the Dictator game.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2013 18:59:54 GMT"}, {"version": "v2", "created": "Sat, 2 Mar 2013 18:35:33 GMT"}, {"version": "v3", "created": "Wed, 10 Apr 2013 16:12:32 GMT"}, {"version": "v4", "created": "Tue, 10 Sep 2013 00:15:14 GMT"}], "update_date": "2013-09-11", "authors_parsed": [["Capraro", "Valerio", ""]]}, {"id": "1302.4245", "submitter": "Andrew Wilson", "authors": "Andrew Gordon Wilson and Ryan Prescott Adams", "title": "Gaussian Process Kernels for Pattern Discovery and Extrapolation", "comments": "10 pages, 5 figures, 1 table. Minor edits and titled changed from\n  \"Gaussian Process Covariance Kernels for Pattern Discovery and Extrapolation\"\n  to \"Gaussian Process Kernels for Pattern Discovery and Extrapolation\".\n  Appears at the International Conference on Machine Learning (ICML), JMLR W&CP\n  28(3):1067-1075, 2013", "journal-ref": "International Conference on Machine Learning (ICML), JMLR W&CP\n  28(3):1067-1075, 2013", "doi": null, "report-no": null, "categories": "stat.ML cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes are rich distributions over functions, which provide a\nBayesian nonparametric approach to smoothing and interpolation. We introduce\nsimple closed form kernels that can be used with Gaussian processes to discover\npatterns and enable extrapolation. These kernels are derived by modelling a\nspectral density -- the Fourier transform of a kernel -- with a Gaussian\nmixture. The proposed kernels support a broad class of stationary covariances,\nbut Gaussian process inference remains simple and analytic. We demonstrate the\nproposed kernels by discovering patterns and performing long range\nextrapolation on synthetic examples, as well as atmospheric CO2 trends and\nairline passenger data. We also show that we can reconstruct standard\ncovariances within our framework.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2013 12:41:50 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2013 12:52:04 GMT"}, {"version": "v3", "created": "Tue, 31 Dec 2013 16:41:30 GMT"}], "update_date": "2014-01-03", "authors_parsed": [["Wilson", "Andrew Gordon", ""], ["Adams", "Ryan Prescott", ""]]}, {"id": "1302.4381", "submitter": "Marc Maier", "authors": "Marc Maier, Katerina Marazopoulou, David Jensen", "title": "Reasoning about Independence in Probabilistic Models of Relational Data", "comments": "61 pages, substantial revisions to formalisms, theory, and related\n  work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the theory of d-separation to cases in which data instances are not\nindependent and identically distributed. We show that applying the rules of\nd-separation directly to the structure of probabilistic models of relational\ndata inaccurately infers conditional independence. We introduce relational\nd-separation, a theory for deriving conditional independence facts from\nrelational models. We provide a new representation, the abstract ground graph,\nthat enables a sound, complete, and computationally efficient method for\nanswering d-separation queries about relational models, and we present\nempirical results that demonstrate effectiveness.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2013 18:33:47 GMT"}, {"version": "v2", "created": "Fri, 10 May 2013 21:20:06 GMT"}, {"version": "v3", "created": "Mon, 6 Jan 2014 18:04:39 GMT"}], "update_date": "2014-01-07", "authors_parsed": [["Maier", "Marc", ""], ["Marazopoulou", "Katerina", ""], ["Jensen", "David", ""]]}, {"id": "1302.4421", "submitter": "Oliver Kullmann", "authors": "Matthew Gwynne, Oliver Kullmann", "title": "Towards a theory of good SAT representations", "comments": "59 pages; second version with some extended discussions and editorial\n  corrections, third version with extended introduction, more examples and\n  explanations, and some editorial improvements, fourth version with further\n  examples, explanations and discussions, and with added computational\n  experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim at providing a foundation of a theory of \"good\" SAT representations F\nof boolean functions f. We argue that the hierarchy UC_k of unit-refutation\ncomplete clause-sets of level k, introduced by the authors, provides the most\nbasic target classes, that is, F in UC_k is to be achieved for k as small as\nfeasible. If F does not contain new variables, i.e., F is equivalent (as a CNF)\nto f, then F in UC_1 is similar to \"achieving (generalised) arc consistency\"\nknown from the literature (it is somewhat weaker, but theoretically much nicer\nto handle). We show that for polysize representations of boolean functions in\nthis sense, the hierarchy UC_k is strict. The boolean functions for these\nseparations are \"doped\" minimally unsatisfiable clause-sets of deficiency 1;\nthese functions have been introduced in [Sloan, Soerenyi, Turan, 2007], and we\ngeneralise their construction and show a correspondence to a strengthened\nnotion of irredundant sub-clause-sets. Turning from lower bounds to upper\nbounds, we believe that many common CNF representations fit into the UC_k\nscheme, and we give some basic tools to construct representations in UC_1 with\nnew variables, based on the Tseitin translation. Note that regarding new\nvariables the UC_1-representations are stronger than mere \"arc consistency\",\nsince the new variables are not excluded from consideration.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2013 20:40:06 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2013 00:04:46 GMT"}, {"version": "v3", "created": "Thu, 21 Mar 2013 00:46:37 GMT"}, {"version": "v4", "created": "Fri, 10 May 2013 17:45:54 GMT"}], "update_date": "2013-05-13", "authors_parsed": [["Gwynne", "Matthew", ""], ["Kullmann", "Oliver", ""]]}, {"id": "1302.4475", "submitter": "Emil  Kotomin", "authors": "Emil Kotomin", "title": "In Love With a Robot: the Dawn of Machine-To-Machine Marketing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article looks at mass market artificial intelligence tools in the context\nof their ever-growing sophistication, availability and market penetration. The\nsubject is especially relevant today for these exact reasons - if a few years\nago AI was the subject of high tech research and science fiction novels, today,\nwe increasingly rely on cloud robotics to cater to our daily needs - to trade\nstock, predict weather, manage diaries, find friends and buy presents online.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2013 22:40:28 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2013 21:57:35 GMT"}, {"version": "v3", "created": "Wed, 3 Aug 2016 08:39:55 GMT"}], "update_date": "2016-08-04", "authors_parsed": [["Kotomin", "Emil", ""]]}, {"id": "1302.4545", "submitter": "Burkhard Schipper", "authors": "Burkhard C. Schipper", "title": "Preference-Based Unawareness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Morris (1996, 1997) introduced preference-based definitions of knowledge and\nbelief in standard state-space structures. This paper extends this\npreference-based approach to unawareness structures (Heifetz, Meier, and\nSchipper, 2006, 2008). By defining unawareness and knowledge in terms of\npreferences over acts in unawareness structures and showing their equivalence\nto the epistemic notions of unawareness and knowledge, we try to build a bridge\nbetween decision theory and epistemic logic. Unawareness of an event is\ncharacterized behaviorally as the event being null and its negation being null.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2013 08:52:40 GMT"}], "update_date": "2013-02-20", "authors_parsed": [["Schipper", "Burkhard C.", ""]]}, {"id": "1302.4888", "submitter": "Yue Shi", "authors": "Yue Shi, Martha Larson, Alan Hanjalic", "title": "Exploiting Social Tags for Cross-Domain Collaborative Filtering", "comments": "Manuscript under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most challenging problems in recommender systems based on the\ncollaborative filtering (CF) concept is data sparseness, i.e., limited user\npreference data is available for making recommendations. Cross-domain\ncollaborative filtering (CDCF) has been studied as an effective mechanism to\nalleviate data sparseness of one domain using the knowledge about user\npreferences from other domains. A key question to be answered in the context of\nCDCF is what common characteristics can be deployed to link different domains\nfor effective knowledge transfer. In this paper, we assess the usefulness of\nuser-contributed (social) tags in this respect. We do so by means of the\nGeneralized Tag-induced Cross-domain Collaborative Filtering (GTagCDCF)\napproach that we propose in this paper and that we developed based on the\ngeneral collective matrix factorization framework. Assessment is done by a\nseries of experiments, using publicly available CF datasets that represent\nthree cross-domain cases, i.e., two two-domain cases and one three-domain case.\nA comparative analysis on two-domain cases involving GTagCDCF and several\nstate-of-the-art CDCF approaches indicates the increased benefit of using\nsocial tags as representatives of explicit links between domains for CDCF as\ncompared to the implicit links deployed by the existing CDCF methods. In\naddition, we show that users from different domains can already benefit from\nGTagCDCF if they only share a few common tags. Finally, we use the three-domain\ncase to validate the robustness of GTagCDCF with respect to the scale of\ndatasets and the varying number of domains.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 12:37:33 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2013 16:03:11 GMT"}], "update_date": "2013-12-25", "authors_parsed": [["Shi", "Yue", ""], ["Larson", "Martha", ""], ["Hanjalic", "Alan", ""]]}, {"id": "1302.4928", "submitter": "Fahiem Bacchus", "authors": "Fahiem Bacchus, Adam J. Grove", "title": "Graphical Models for Preference and Utility", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-3-10", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic independence can dramatically simplify the task of eliciting,\nrepresenting, and computing with probabilities in large domains. A key\ntechnique in achieving these benefits is the idea of graphical modeling. We\nsurvey existing notions of independence for utility functions in a\nmulti-attribute space, and suggest that these can be used to achieve similar\nadvantages. Our new results concern conditional additive independence, which we\nshow always has a perfect representation as separation in an undirected graph\n(a Markov network). Conditional additive independencies entail a particular\nfunctional for the utility function that is analogous to a product\ndecomposition of a probability function, and confers analogous benefits. This\nfunctional form has been utilized in the Bayesian network and influence diagram\nliterature, but generally without an explanation in terms of independence. The\nfunctional form yields a decomposition of the utility function that can greatly\nspeed up expected utility calculations, particularly when the utility graph has\na similar topology to the probabilistic network being used.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:18:51 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Bacchus", "Fahiem", ""], ["Grove", "Adam J.", ""]]}, {"id": "1302.4929", "submitter": "Alexander Balke", "authors": "Alexander Balke, Judea Pearl", "title": "Counterfactuals and Policy Analysis in Structural Models", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-11-18", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluation of counterfactual queries (e.g., \"If A were true, would C have\nbeen true?\") is important to fault diagnosis, planning, determination of\nliability, and policy analysis. We present a method of revaluating\ncounterfactuals when the underlying causal model is represented by structural\nmodels - a nonlinear generalization of the simultaneous equations models\ncommonly used in econometrics and social sciences. This new method provides a\ncoherent means for evaluating policies involving the control of variables\nwhich, prior to enacting the policy were influenced by other variables in the\nsystem.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:18:56 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Balke", "Alexander", ""], ["Pearl", "Judea", ""]]}, {"id": "1302.4930", "submitter": "Salem Benferhat", "authors": "Salem Benferhat, Alessandro Saffiotti, Philippe Smets", "title": "Belief Functions and Default Reasoning", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-19-26", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach to dealing with default information based on the\ntheory of belief functions. Our semantic structures, inspired by Adams'\nepsilon-semantics, are epsilon-belief assignments, where values committed to\nfocal elements are either close to 0 or close to 1. We define two systems based\non these structures, and relate them to other non-monotonic systems presented\nin the literature. We show that our second system correctly addresses the\nwell-known problems of specificity, irrelevance, blocking of inheritance,\nambiguity, and redundancy.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:19:02 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Benferhat", "Salem", ""], ["Saffiotti", "Alessandro", ""], ["Smets", "Philippe", ""]]}, {"id": "1302.4931", "submitter": "Luca Boldrin", "authors": "Luca Boldrin, Claudio Sossai", "title": "An Algebraic Semantics for Possibilistic Logic", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-27-35", "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The first contribution of this paper is the presentation of a Pavelka - like\nformulation of possibilistic logic in which the language is naturally enriched\nby two connectives which represent negation (eg) and a new type of conjunction\n(otimes). The space of truth values for this logic is the lattice of\npossibility functions, that, from an algebraic point of view, forms a quantal.\nA second contribution comes from the understanding of the new conjunction as\nthe combination of tokens of information coming from different sources, which\nmakes our language \"dynamic\". A Gentzen calculus is presented, which is proved\nsound and complete with respect to the given semantics. The problem of truth\nfunctionality is discussed in this context.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:19:06 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Boldrin", "Luca", ""], ["Sossai", "Claudio", ""]]}, {"id": "1302.4932", "submitter": "John S. Breese", "authors": "John S. Breese, Russ Blake", "title": "Automating Computer Bottleneck Detection with Belief Nets", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-36-45", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an application of belief networks to the diagnosis of bottlenecks\nin computer systems. The technique relies on a high-level functional model of\nthe interaction between application workloads, the Windows NT operating system,\nand system hardware. Given a workload description, the model predicts the\nvalues of observable system counters available from the Windows NT performance\nmonitoring tool. Uncertainty in workloads, predictions, and counter values are\ncharacterized with Gaussian distributions. During diagnostic inference, we use\nobserved performance monitor values to find the most probable assignment to the\nworkload parameters. In this paper we provide some background on automated\nbottleneck detection, describe the structure of the system model, and discuss\nempirical procedures for model calibration and verification. Part of the\ncalibration process includes generating a dataset to estimate a multivariate\nGaussian error model. Initial results in diagnosing bottlenecks are presented.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:19:11 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Breese", "John S.", ""], ["Blake", "Russ", ""]]}, {"id": "1302.4933", "submitter": "Wray L. Buntine", "authors": "Wray L. Buntine", "title": "Chain Graphs for Learning", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-46-54", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chain graphs combine directed and undirected graphs and their underlying\nmathematics combines properties of the two. This paper gives a simplified\ndefinition of chain graphs based on a hierarchical combination of Bayesian\n(directed) and Markov (undirected) networks. Examples of a chain graph are\nmultivariate feed-forward networks, clustering with conditional interaction\nbetween variables, and forms of Bayes classifiers. Chain graphs are then\nextended using the notation of plates so that samples and data analysis\nproblems can be represented in a graphical model as well. Implications for\nlearning are discussed in the conclusion.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:19:16 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Buntine", "Wray L.", ""]]}, {"id": "1302.4934", "submitter": "Enrique F. Castillo", "authors": "Enrique F. Castillo, Remco R. Bouckaert, Jose M. Sarabia, Cristina\n  Solares", "title": "Error Estimation in Approximate Bayesian Belief Network Inference", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-55-62", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We can perform inference in Bayesian belief networks by enumerating\ninstantiations with high probability thus approximating the marginals. In this\npaper, we present a method for determining the fraction of instantiations that\nhas to be considered such that the absolute error in the marginals does not\nexceed a predefined value. The method is based on extreme value theory.\nEssentially, the proposed method uses the reversed generalized Pareto\ndistribution to model probabilities of instantiations below a given threshold.\nBased on this distribution, an estimate of the maximal absolute error if\ninstantiations with probability smaller than u are disregarded can be made.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:19:22 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Castillo", "Enrique F.", ""], ["Bouckaert", "Remco R.", ""], ["Sarabia", "Jose M.", ""], ["Solares", "Cristina", ""]]}, {"id": "1302.4935", "submitter": "Juan Luis Castro", "authors": "Juan Luis Castro, Jose Manuel Zurita", "title": "Generating the Structure of a Fuzzy Rule under Uncertainty", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-63-67", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to present a method for identifying the structure of\na rule in a fuzzy model. For this purpose, an ATMS shall be used (Zurita 1994).\nAn algorithm obtaining the identification of the structure will be suggested\n(Castro 1995). The minimal structure of the rule (with respect to the number of\nvariables that must appear in the rule) will be found by this algorithm.\nFurthermore, the identification parameters shall be obtained simultaneously.\nThe proposed method shall be applied for classification to an example. The {em\nIris Plant Database} shall be learnt for all three kinds of plants.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:19:27 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Castro", "Juan Luis", ""], ["Zurita", "Jose Manuel", ""]]}, {"id": "1302.4936", "submitter": "Didier Cayrac", "authors": "Didier Cayrac, Didier Dubois, Henri Prade", "title": "Practical Model-Based Diagnosis with Qualitative Possibilistic\n  Uncertainty", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-68-76", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An approach to fault isolation that exploits vastly incomplete models is\npresented. It relies on separate descriptions of each component behavior,\ntogether with the links between them, which enables focusing of the reasoning\nto the relevant part of the system. As normal observations do not need\nexplanation, the behavior of the components is limited to anomaly propagation.\nDiagnostic solutions are disorders (fault modes or abnormal signatures) that\nare consistent with the observations, as well as abductive explanations. An\nordinal representation of uncertainty based on possibility theory provides a\nsimple exception-tolerant description of the component behaviors. We can for\ninstance distinguish between effects that are more or less certainly present\n(or absent) and effects that are more or less certainly present (or absent)\nwhen a given anomaly is present. A realistic example illustrates the benefits\nof this approach.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:19:32 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Cayrac", "Didier", ""], ["Dubois", "Didier", ""], ["Prade", "Henri", ""]]}, {"id": "1302.4937", "submitter": "Tom Chavez", "authors": "Tom Chavez, Ross D. Shachter", "title": "Decision Flexibility", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-77-86", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of new methods and representations for temporal\ndecision-making requires a principled basis for characterizing and measuring\nthe flexibility of decision strategies in the face of uncertainty. Our goal in\nthis paper is to provide a framework - not a theory - for observing how\ndecision policies behave in the face of informational perturbations, to gain\nclues as to how they might behave in the face of unanticipated, possibly\nunarticulated uncertainties. To this end, we find it beneficial to distinguish\nbetween two types of uncertainty: \"Small World\" and \"Large World\" uncertainty.\nThe first type can be resolved by posing an unambiguous question to a\n\"clairvoyant,\" and is anchored on some well-defined aspect of a decision frame.\nThe second type is more troublesome, yet it is often of greater interest when\nwe address the issue of flexibility; this type of uncertainty can be resolved\nonly by consulting a \"psychic.\" We next observe that one approach to\nflexibility used in the economics literature is already implicitly accounted\nfor in the Maximum Expected Utility (MEU) principle from decision theory.\nThough simple, the observation establishes the context for a more illuminating\nnotion of flexibility, what we term flexibility with respect to information\nrevelation. We show how to perform flexibility analysis of a static (i.e.,\nsingle period) decision problem using a simple example, and we observe that the\nmost flexible alternative thus identified is not necessarily the MEU\nalternative. We extend our analysis for a dynamic (i.e., multi-period) model,\nand we demonstrate how to calculate the value of flexibility for decision\nstrategies that allow downstream revision of an upstream commitment decision.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:19:37 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Chavez", "Tom", ""], ["Shachter", "Ross D.", ""]]}, {"id": "1302.4938", "submitter": "David Maxwell Chickering", "authors": "David Maxwell Chickering", "title": "A Transformational Characterization of Equivalent Bayesian Network\n  Structures", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-87-98", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple characterization of equivalent Bayesian network\nstructures based on local transformations. The significance of the\ncharacterization is twofold. First, we are able to easily prove several new\ninvariant properties of theoretical interest for equivalent structures. Second,\nwe use the characterization to derive an efficient algorithm that identifies\nall of the compelled edges in a structure. Compelled edge identification is of\nparticular importance for learning Bayesian network structures from data\nbecause these edges indicate causal relationships when certain assumptions\nhold.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:19:42 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Chickering", "David Maxwell", ""]]}, {"id": "1302.4939", "submitter": "Adnan Darwiche", "authors": "Adnan Darwiche", "title": "Conditioning Methods for Exact and Approximate Inference in Causal\n  Networks", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-99-107", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two algorithms for exact and approximate inference in causal\nnetworks. The first algorithm, dynamic conditioning, is a refinement of cutset\nconditioning that has linear complexity on some networks for which cutset\nconditioning is exponential. The second algorithm, B-conditioning, is an\nalgorithm for approximate inference that allows one to trade-off the quality of\napproximations with the computation time. We also present some experimental\nresults illustrating the properties of the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:19:47 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Darwiche", "Adnan", ""]]}, {"id": "1302.4940", "submitter": "Luis M. de Campos", "authors": "Luis M. de Campos, Serafin Moral", "title": "Independence Concepts for Convex Sets of Probabilities", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-108-115", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study different concepts of independence for convex sets of\nprobabilities. There will be two basic ideas for independence. The first is\nirrelevance. Two variables are independent when a change on the knowledge about\none variable does not affect the other. The second one is factorization. Two\nvariables are independent when the joint convex set of probabilities can be\ndecomposed on the product of marginal convex sets. In the case of the Theory of\nProbability, these two starting points give rise to the same definition. In the\ncase of convex sets of probabilities, the resulting concepts will be strongly\nrelated, but they will not be equivalent. As application of the concept of\nindependence, we shall consider the problem of building a global convex set\nfrom marginal convex sets of probabilities.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:19:52 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["de Campos", "Luis M.", ""], ["Moral", "Serafin", ""]]}, {"id": "1302.4941", "submitter": "Denise L. Draper", "authors": "Denise L. Draper", "title": "Clustering Without (Thinking About) Triangulation", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-125-133", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The undirected technique for evaluating belief networks [Jensen, et.al.,\n1990, Lauritzen and Spiegelhalter, 1988] requires clustering the nodes in the\nnetwork into a junction tree. In the traditional view, the junction tree is\nconstructed from the cliques of the moralized and triangulated belief network:\ntriangulation is taken to be the primitive concept, the goal towards which any\nclustering algorithm (e.g. node elimination) is directed. In this paper, we\npresent an alternative conception of clustering, in which clusters and the\njunction tree property play the role of primitives: given a graph (not a tree)\nof clusters which obey (a modified version of) the junction tree property, we\ntransform this graph until we have obtained a tree. There are several\nadvantages to this approach: it is much clearer and easier to understand, which\nis important for humans who are constructing belief networks; it admits a wider\nrange of heuristics which may enable more efficient or superior clustering\nalgorithms; and it serves as the natural basis for an incremental clustering\nscheme, which we describe.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:19:57 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Draper", "Denise L.", ""]]}, {"id": "1302.4942", "submitter": "Eric Driver", "authors": "Eric Driver, Darryl Morrell", "title": "Implementation of Continuous Bayesian Networks Using Sums of Weighted\n  Gaussians", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-134-140", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian networks provide a method of representing conditional independence\nbetween random variables and computing the probability distributions associated\nwith these random variables. In this paper, we extend Bayesian network\nstructures to compute probability density functions for continuous random\nvariables. We make this extension by approximating prior and conditional\ndensities using sums of weighted Gaussian distributions and then finding the\npropagation rules for updating the densities in terms of these weights. We\npresent a simple example that illustrates the Bayesian network for continuous\nvariables; this example shows the effect of the network structure and\napproximation errors on the computation of densities for variables in the\nnetwork.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:20:02 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Driver", "Eric", ""], ["Morrell", "Darryl", ""]]}, {"id": "1302.4943", "submitter": "Marek J. Druzdzel", "authors": "Marek J. Druzdzel, Linda C. van der Gaag", "title": "Elicitation of Probabilities for Belief Networks: Combining Qualitative\n  and Quantitative Information", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-141-148", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the usefulness of belief networks for reasoning under uncertainty is\nwidely accepted, obtaining numerical probabilities that they require is still\nperceived a major obstacle. Often not enough statistical data is available to\nallow for reliable probability estimation. Available information may not be\ndirectly amenable for encoding in the network. Finally, domain experts may be\nreluctant to provide numerical probabilities. In this paper, we propose a\nmethod for elicitation of probabilities from a domain expert that is\nnon-invasive and accommodates whatever probabilistic information the expert is\nwilling to state. We express all available information, whether qualitative or\nquantitative in nature, in a canonical form consisting of (in) equalities\nexpressing constraints on the hyperspace of possible joint probability\ndistributions. We then use this canonical form to derive second-order\nprobability distributions over the desired probabilities.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:20:07 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Druzdzel", "Marek J.", ""], ["van der Gaag", "Linda C.", ""]]}, {"id": "1302.4944", "submitter": "Didier Dubois", "authors": "Didier Dubois, Henri Prade", "title": "Numerical Representations of Acceptance", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-149-156", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accepting a proposition means that our confidence in this proposition is\nstrictly greater than the confidence in its negation. This paper investigates\nthe subclass of uncertainty measures, expressing confidence, that capture the\nidea of acceptance, what we call acceptance functions. Due to the monotonicity\nproperty of confidence measures, the acceptance of a proposition entails the\nacceptance of any of its logical consequences. In agreement with the idea that\na belief set (in the sense of Gardenfors) must be closed under logical\nconsequence, it is also required that the separate acceptance o two\npropositions entail the acceptance of their conjunction. Necessity (and\npossibility) measures agree with this view of acceptance while probability and\nbelief functions generally do not. General properties of acceptance functions\nare estabilished. The motivation behind this work is the investigation of a\nsetting for belief revision more general than the one proposed by Alchourron,\nGardenfors and Makinson, in connection with the notion of conditioning.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:20:13 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Dubois", "Didier", ""], ["Prade", "Henri", ""]]}, {"id": "1302.4945", "submitter": "Kazuo J. Ezawa", "authors": "Kazuo J. Ezawa, Til Schuermann", "title": "Fraud/Uncollectible Debt Detection Using a Bayesian Network Based\n  Learning System: A Rare Binary Outcome with Mixed Data Structures", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-157-166", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fraud/uncollectible debt problem in the telecommunications industry\npresents two technical challenges: the detection and the treatment of the\naccount given the detection. In this paper, we focus on the first problem of\ndetection using Bayesian network models, and we briefly discuss the application\nof a normative expert system for the treatment at the end. We apply Bayesian\nnetwork models to the problem of fraud/uncollectible debt detection for\ntelecommunication services. In addition to being quite successful at predicting\nrare event outcomes, it is able to handle a mixture of categorical and\ncontinuous data. We present a performance comparison using linear and\nnon-linear discriminant analysis, classification and regression trees, and\nBayesian network models\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:20:19 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Ezawa", "Kazuo J.", ""], ["Schuermann", "Til", ""]]}, {"id": "1302.4946", "submitter": "Helene Fargier", "authors": "Helene Fargier, Jerome Lang, Roger Martin-Clouaire, Thomas Schiex", "title": "A Constraint Satisfaction Approach to Decision under Uncertainty", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-167-174", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Constraint Satisfaction Problem (CSP) framework offers a simple and sound\nbasis for representing and solving simple decision problems, without\nuncertainty. This paper is devoted to an extension of the CSP framework\nenabling us to deal with some decisions problems under uncertainty. This\nextension relies on a differentiation between the agent-controllable decision\nvariables and the uncontrollable parameters whose values depend on the\noccurrence of uncertain events. The uncertainty on the values of the parameters\nis assumed to be given under the form of a probability distribution. Two\nalgorithms are given, for computing respectively decisions solving the problem\nwith a maximal probability, and conditional decisions mapping the largest\npossible amount of possible cases to actual decisions.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:20:24 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Fargier", "Helene", ""], ["Lang", "Jerome", ""], ["Martin-Clouaire", "Roger", ""], ["Schiex", "Thomas", ""]]}, {"id": "1302.4947", "submitter": "Nir Friedman", "authors": "Nir Friedman, Joseph Y. Halpern", "title": "Plausibility Measures: A User's Guide", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-175-184", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine a new approach to modeling uncertainty based on plausibility\nmeasures, where a plausibility measure just associates with an event its\nplausibility, an element is some partially ordered set. This approach is easily\nseen to generalize other approaches to modeling uncertainty, such as\nprobability measures, belief functions, and possibility measures. The lack of\nstructure in a plausibility measure makes it easy for us to add structure on an\n\"as needed\" basis, letting us examine what is required to ensure that a\nplausibility measure has certain properties of interest. This gives us insight\ninto the essential features of the properties in question, while allowing us to\nprove general results that apply to many approaches to reasoning about\nuncertainty. Plausibility measures have already proved useful in analyzing\ndefault reasoning. In this paper, we examine their \"algebraic properties,\"\nanalogues to the use of + and * in probability theory. An understanding of such\nproperties will be essential if plausibility measures are to be used in\npractice as a representation tool.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:20:29 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Friedman", "Nir", ""], ["Halpern", "Joseph Y.", ""]]}, {"id": "1302.4948", "submitter": "David Galles", "authors": "David Galles, Judea Pearl", "title": "Testing Identifiability of Causal Effects", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-185-195", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns the probabilistic evaluation of the effects of actions in\nthe presence of unmeasured variables. We show that the identification of causal\neffect between a singleton variable X and a set of variables Y can be\naccomplished systematically, in time polynomial in the number of variables in\nthe graph. When the causal effect is identifiable, a closed-form expression can\nbe obtained for the probability that the action will achieve a specified goal,\nor a set of goals.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:20:35 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Galles", "David", ""], ["Pearl", "Judea", ""]]}, {"id": "1302.4949", "submitter": "Dan Geiger", "authors": "Dan Geiger, David Heckerman", "title": "A Characterization of the Dirichlet Distribution with Application to\n  Learning Bayesian Networks", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-196-207", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a new characterization of the Dirichlet distribution. This\ncharacterization implies that under assumptions made by several previous\nauthors for learning belief networks, a Dirichlet prior on the parameters is\ninevitable.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:20:41 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Geiger", "Dan", ""], ["Heckerman", "David", ""]]}, {"id": "1302.4950", "submitter": "Moises Goldszmidt", "authors": "Moises Goldszmidt", "title": "Fast Belief Update Using Order-of-Magnitude Probabilities", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-208-216", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm, called Predict, for updating beliefs in causal\nnetworks quantified with order-of-magnitude probabilities. The algorithm takes\nadvantage of both the structure and the quantification of the network and\npresents a polynomial asymptotic complexity. Predict exhibits a conservative\nbehavior in that it is always sound but not always complete. We provide\nsufficient conditions for completeness and present algorithms for testing these\nconditions and for computing a complete set of plausible values. We propose\nPredict as an efficient method to estimate probabilistic values and illustrate\nits use in conjunction with two known algorithms for probabilistic inference.\nFinally, we describe an application of Predict to plan evaluation, present\nexperimental results, and discuss issues regarding its use with conditional\nlogics of belief, and in the characterization of irrelevance.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:20:47 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Goldszmidt", "Moises", ""]]}, {"id": "1302.4951", "submitter": "Benjamin N. Grosof", "authors": "Benjamin N. Grosof", "title": "Transforming Prioritized Defaults and Specificity into Parallel Defaults", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-217-228", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to transform any set of prioritized propositional defaults into\nan equivalent set of parallel (i.e., unprioritized) defaults, in\ncircumscription. We give an algorithm to implement the transform. We show how\nto use the transform algorithm as a generator of a whole family of inferencing\nalgorithms for circumscription. The method is to employ the transform algorithm\nas a front end to any inferencing algorithm, e.g., one of the previously\navailable, that handles the parallel (empty) case of prioritization. Our\nalgorithms provide not just coverage of a new expressive class, but also\nalternatives to previous algorithms for implementing the previously covered\nclass (?layered?) of prioritization. In particular, we give a new\nquery-answering algorithm for prioritized cirumscription which is sound and\ncomplete for the full expressive class of unrestricted finite prioritization\npartial orders, for propositional defaults (or minimized predicates). By\ncontrast, previous algorithms required that the prioritization partial order be\nlayered, i.e., structured similar to the system of rank in the military. Our\nalgorithm enables, for the first time, the implementation of the most useful\nclass of prioritization: non-layered prioritization partial orders. Default\ninheritance, for example, typically requires non-layered prioritization to\nrepresent specificity adequately. Our algorithm enables not only the\nimplementation of default inheritance (and specificity) within prioritized\ncircumscription, but also the extension and combination of default inheritance\nwith other kinds of prioritized default reasoning, e.g.: with stratified logic\nprograms with negation-as-failure. Such logic programs are previously known to\nbe representable equivalently as layered-priority predicate circumscriptions.\nWorst-case, the transform increases the number of defaults exponentially. We\ndiscuss how inferencing is practically implementable nevertheless in two kinds\nof situations: general expressiveness but small numbers of defaults, or\nexpressive special cases with larger numbers of defaults. One such expressive\nspecial case is non-?top-heaviness? of the prioritization partial order. In\naddition to its direct implementation, the transform can also be exploited\nanalytically to generate special case algorithms, e.g., a tractable transform\nfor a class within default inheritance (detailed in another, forthcoming\npaper). We discuss other aspects of the significance of the fundamental result.\nOne can view the transform as reducing n degrees of partially ordered belief\nconfidence to just 2 degrees of confidence: for-sure and (unprioritized)\ndefault. Ordinary, parallel default reasoning, e.g., in parallel\ncircumscription or Poole's Theorist, can be viewed in these terms as reducing 2\ndegrees of confidence to just 1 degree of confidence: that of the non-monotonic\ntheory's conclusions. The expressive reduction's computational complexity\nsuggests that prioritization is valuable for its expressive conciseness, just\nas defaults are for theirs. For Reiter's Default Logic and Poole's Theorist,\nthe transform implies how to extend those formalisms so as to equip them with a\nconcept of prioritization that is exactly equivalent to that in\ncircumscription. This provides an interesting alternative to Brewka's approach\nto equipping them with prioritization-type precedence.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:20:52 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Grosof", "Benjamin N.", ""]]}, {"id": "1302.4952", "submitter": "Peter Haddawy", "authors": "Peter Haddawy, AnHai Doan, Richard Goodwin", "title": "Efficient Decision-Theoretic Planning: Techniques and Empirical Analysis", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-229-236", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses techniques for performing efficient decision-theoretic\nplanning. We give an overview of the DRIPS decision-theoretic refinement\nplanning system, which uses abstraction to efficiently identify optimal plans.\nWe present techniques for automatically generating search control information,\nwhich can significantly improve the planner's performance. We evaluate the\nefficiency of DRIPS both with and without the search control rules on a complex\nmedical planning problem and compare its performance to that of a\nbranch-and-bound decision tree algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:20:57 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Haddawy", "Peter", ""], ["Doan", "AnHai", ""], ["Goodwin", "Richard", ""]]}, {"id": "1302.4953", "submitter": "Petr Hajek", "authors": "Petr Hajek, Lluis Godo, Francesc Esteva", "title": "Fuzzy Logic and Probability", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-237-244", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we deal with a new approach to probabilistic reasoning in a\nlogical framework. Nearly almost all logics of probability that have been\nproposed in the literature are based on classical two-valued logic. After\nmaking clear the differences between fuzzy logic and probability theory, here\nwe propose a {em fuzzy} logic of probability for which completeness results (in\na probabilistic sense) are provided. The main idea behind this approach is that\nprobability values of crisp propositions can be understood as truth-values of\nsome suitable fuzzy propositions associated to the crisp ones. Moreover,\nsuggestions and examples of how to extend the formalism to cope with\nconditional probabilities and with other uncertainty formalisms are also\nprovided.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:21:03 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Hajek", "Petr", ""], ["Godo", "Lluis", ""], ["Esteva", "Francesc", ""]]}, {"id": "1302.4954", "submitter": "Steve Hanks", "authors": "Steve Hanks, David Madigan, Jonathan Gavrin", "title": "Probabilistic Temporal Reasoning with Endogenous Change", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-245-254", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a probabilistic model for reasoning about the state of a\nsystem as it changes over time, both due to exogenous and endogenous\ninfluences. Our target domain is a class of medical prediction problems that\nare neither so urgent as to preclude careful diagnosis nor progress so slowly\nas to allow arbitrary testing and treatment options. In these domains there is\ntypically enough time to gather information about the patient's state and\nconsider alternative diagnoses and treatments, but the temporal interaction\nbetween the timing of tests, treatments, and the course of the disease must\nalso be considered. Our approach is to elicit a qualitative structural model of\nthe patient from a human expert---the model identifies important attributes,\nthe way in which exogenous changes affect attribute values, and the way in\nwhich the patient's condition changes endogenously. We then elicit\nprobabilistic information to capture the expert's uncertainty about the effects\nof tests and treatments and the nature and timing of endogenous state changes.\nThis paper describes the model in the context of a problem in treating vehicle\naccident trauma, and suggests a method for solving the model based on the\ntechnique of sequential imputation. A complementary goal of this work is to\nunderstand and synthesize a disparate collection of research efforts all using\nthe name ?probabilistic temporal reasoning.? This paper analyzes related work\nand points out essential differences between our proposed model and other\napproaches in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:21:08 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Hanks", "Steve", ""], ["Madigan", "David", ""], ["Gavrin", "Jonathan", ""]]}, {"id": "1302.4955", "submitter": "David Harmanec", "authors": "David Harmanec", "title": "Toward a Characterization of Uncertainty Measure for the Dempster-Shafer\n  Theory", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-255-261", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a working paper summarizing results of an ongoing research project\nwhose aim is to uniquely characterize the uncertainty measure for the\nDempster-Shafer Theory. A set of intuitive axiomatic requirements is presented,\nsome of their implications are shown, and the proof is given of the minimality\nof recently proposed measure AU among all measures satisfying the proposed\nrequirements.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:21:13 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Harmanec", "David", ""]]}, {"id": "1302.4956", "submitter": "David Heckerman", "authors": "David Heckerman, Ross D. Shachter", "title": "A Definition and Graphical Representation for Causality", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-262-273", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a precise definition of cause and effect in terms of a fundamental\nnotion called unresponsiveness. Our definition is based on Savage's (1954)\nformulation of decision theory and departs from the traditional view of\ncausation in that our causal assertions are made relative to a set of\ndecisions. An important consequence of this departure is that we can reason\nabout cause locally, not requiring a causal explanation for every dependency.\nSuch local reasoning can be beneficial because it may not be necessary to\ndetermine whether a particular dependency is causal to make a decision. Also in\nthis paper, we examine the graphical encoding of causal relationships. We show\nthat influence diagrams in canonical form are an accurate and efficient\nrepresentation of causal relationships. In addition, we establish a\ncorrespondence between canonical form and Pearl's causal theory.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:21:18 GMT"}, {"version": "v2", "created": "Sat, 16 May 2015 23:43:57 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Heckerman", "David", ""], ["Shachter", "Ross D.", ""]]}, {"id": "1302.4957", "submitter": "David Heckerman", "authors": "David Heckerman, Dan Geiger", "title": "Learning Bayesian Networks: A Unification for Discrete and Gaussian\n  Domains", "comments": "This version has improved pointers to the literature", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-274-284", "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We examine Bayesian methods for learning Bayesian networks from a combination\nof prior knowledge and statistical data. In particular, we unify the approaches\nwe presented at last year's conference for discrete and Gaussian domains. We\nderive a general Bayesian scoring metric, appropriate for both domains. We then\nuse this metric in combination with well-known statistical facts about the\nDirichlet and normal--Wishart distributions to derive our metrics for discrete\nand Gaussian domains.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:21:23 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 13:25:36 GMT"}, {"version": "v3", "created": "Tue, 29 Jun 2021 19:41:53 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Heckerman", "David", ""], ["Geiger", "Dan", ""]]}, {"id": "1302.4958", "submitter": "David Heckerman", "authors": "David Heckerman", "title": "A Bayesian Approach to Learning Causal Networks", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-285-295", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whereas acausal Bayesian networks represent probabilistic independence,\ncausal Bayesian networks represent causal relationships. In this paper, we\nexamine Bayesian methods for learning both types of networks. Bayesian methods\nfor learning acausal networks are fairly well developed. These methods often\nemploy assumptions to facilitate the construction of priors, including the\nassumptions of parameter independence, parameter modularity, and likelihood\nequivalence. We show that although these assumptions also can be appropriate\nfor learning causal networks, we need additional assumptions in order to learn\ncausal networks. We introduce two sufficient assumptions, called {em mechanism\nindependence} and {em component independence}. We show that these new\nassumptions, when combined with parameter independence, parameter modularity,\nand likelihood equivalence, allow us to apply methods for learning acausal\nnetworks to learn causal networks.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:21:29 GMT"}, {"version": "v2", "created": "Sat, 16 May 2015 23:38:36 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Heckerman", "David", ""]]}, {"id": "1302.4959", "submitter": "Eric J. Horvitz", "authors": "Eric J. Horvitz, Matthew Barry", "title": "Display of Information for Time-Critical Decision Making", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-296-305", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe methods for managing the complexity of information displayed to\npeople responsible for making high-stakes, time-critical decisions. The\ntechniques provide tools for real-time control of the configuration and\nquantity of information displayed to a user, and a methodology for designing\nflexible human-computer interfaces for monitoring applications. After defining\na prototypical set of display decision problems, we introduce the expected\nvalue of revealed information (EVRI) and the related measure of expected value\nof displayed information (EVDI). We describe how these measures can be used to\nenhance computer displays used for monitoring complex systems. We motivate the\npresentation by discussing our efforts to employ decision-theoretic control of\ndisplays for a time-critical monitoring application at the NASA Mission Control\nCenter in Houston.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:21:34 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Horvitz", "Eric J.", ""], ["Barry", "Matthew", ""]]}, {"id": "1302.4960", "submitter": "Eric J. Horvitz", "authors": "Eric J. Horvitz, Adrian Klein", "title": "Reasoning, Metareasoning, and Mathematical Truth: Studies of Theorem\n  Proving under Limited Resources", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-306-314", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In earlier work, we introduced flexible inference and decision-theoretic\nmetareasoning to address the intractability of normative inference. Here,\nrather than pursuing the task of computing beliefs and actions with decision\nmodels composed of distinctions about uncertain events, we examine methods for\ninferring beliefs about mathematical truth before an automated theorem prover\ncompletes a proof. We employ a Bayesian analysis to update belief in truth,\ngiven theorem-proving progress, and show how decision-theoretic methods can be\nused to determine the value of continuing to deliberate versus taking immediate\naction in time-critical situations.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:21:39 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Horvitz", "Eric J.", ""], ["Klein", "Adrian", ""]]}, {"id": "1302.4961", "submitter": "Mark Hulme", "authors": "Mark Hulme", "title": "Improved Sampling for Diagnostic Reasoning in Bayesian Networks", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-315-322", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian networks offer great potential for use in automating large scale\ndiagnostic reasoning tasks. Gibbs sampling is the main technique used to\nperform diagnostic reasoning in large richly interconnected Bayesian networks.\nUnfortunately Gibbs sampling can take an excessive time to generate a\nrepresentative sample. In this paper we describe and test a number of heuristic\nstrategies for improving sampling in noisy-or Bayesian networks. The strategies\ninclude Monte Carlo Markov chain sampling techniques other than Gibbs sampling.\nEmphasis is put on strategies that can be implemented in distributed systems.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:21:44 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Hulme", "Mark", ""]]}, {"id": "1302.4962", "submitter": "Finn Verner Jensen", "authors": "Finn Verner Jensen", "title": "Cautious Propagation in Bayesian Networks", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-323-328", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the situation where some evidence e has been entered to a Bayesian\nnetwork. When performing conflict analysis, sensitivity analysis, or when\nanswering questions like \"What if the finding on X had been y instead of x?\"\nyou need probabilities P (e'| h), where e' is a subset of e, and h is a\nconfiguration of a (possibly empty) set of variables. Cautious propagation is a\nmodification of HUGIN propagation into a Shafer-Shenoy-like architecture. It is\nless efficient than HUGIN propagation; however, it provides easy access to P\n(e'| h) for a great deal of relevant subsets e'.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:21:50 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Jensen", "Finn Verner", ""]]}, {"id": "1302.4963", "submitter": "Ali Jenzarli", "authors": "Ali Jenzarli", "title": "Information/Relevance Influence Diagrams", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-329-337", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we extend the influence diagram (ID) representation for\ndecisions under uncertainty. In the standard ID, arrows into a decision node\nare only informational; they do not represent constraints on what the decision\nmaker can do. We can represent such constraints only indirectly, using arrows\nto the children of the decision and sometimes adding more variables to the\ninfluence diagram, thus making the ID more complicated. Users of influence\ndiagrams often want to represent constraints by arrows into decision nodes. We\nrepresent constraints on decisions by allowing relevance arrows into decision\nnodes. We call the resulting representation information/relevance influence\ndiagrams (IRIDs). Information/relevance influence diagrams allow for direct\nrepresentation and specification of constrained decisions. We use a combination\nof stochastic dynamic programming and Gibbs sampling to solve IRIDs. This\nmethod is especially useful when exact methods for solving IDs fail.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:21:55 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Jenzarli", "Ali", ""]]}, {"id": "1302.4964", "submitter": "George H. John", "authors": "George H. John, Pat Langley", "title": "Estimating Continuous Distributions in Bayesian Classifiers", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-338-345", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When modeling a probability distribution with a Bayesian network, we are\nfaced with the problem of how to handle continuous variables. Most previous\nwork has either solved the problem by discretizing, or assumed that the data\nare generated by a single Gaussian. In this paper we abandon the normality\nassumption and instead use statistical methods for nonparametric density\nestimation. For a naive Bayesian classifier, we present experimental results on\na variety of natural and artificial domains, comparing two methods of density\nestimation: assuming normality and modeling each conditional distribution with\na single Gaussian; and using nonparametric kernel density estimation. We\nobserve large reductions in error on several natural and artificial data sets,\nwhich suggests that kernel estimation is a useful tool for learning Bayesian\nmodels.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:22:01 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["John", "George H.", ""], ["Langley", "Pat", ""]]}, {"id": "1302.4965", "submitter": "Keiji Kanazawa", "authors": "Keiji Kanazawa, Daphne Koller, Stuart Russell", "title": "Stochastic Simulation Algorithms for Dynamic Probabilistic Networks", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-346-351", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic simulation algorithms such as likelihood weighting often give\nfast, accurate approximations to posterior probabilities in probabilistic\nnetworks, and are the methods of choice for very large networks. Unfortunately,\nthe special characteristics of dynamic probabilistic networks (DPNs), which are\nused to represent stochastic temporal processes, mean that standard simulation\nalgorithms perform very poorly. In essence, the simulation trials diverge\nfurther and further from reality as the process is observed over time. In this\npaper, we present simulation algorithms that use the evidence observed at each\ntime step to push the set of trials back towards reality. The first algorithm,\n\"evidence reversal\" (ER) restructures each time slice of the DPN so that the\nevidence nodes for the slice become ancestors of the state variables. The\nsecond algorithm, called \"survival of the fittest\" sampling (SOF),\n\"repopulates\" the set of trials at each time step using a stochastic\nreproduction rate weighted by the likelihood of the evidence according to each\ntrial. We compare the performance of each algorithm with likelihood weighting\non the original network, and also investigate the benefits of combining the ER\nand SOF methods. The ER/SOF combination appears to maintain bounded error\nindependent of the number of time steps in the simulation.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:22:06 GMT"}], "update_date": "2016-11-26", "authors_parsed": [["Kanazawa", "Keiji", ""], ["Koller", "Daphne", ""], ["Russell", "Stuart", ""]]}, {"id": "1302.4966", "submitter": "Grigoris I. Karakoulas", "authors": "Grigoris I. Karakoulas", "title": "Probabilistic Exploration in Planning while Learning", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-352-361", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential decision tasks with incomplete information are characterized by\nthe exploration problem; namely the trade-off between further exploration for\nlearning more about the environment and immediate exploitation of the accrued\ninformation for decision-making. Within artificial intelligence, there has been\nan increasing interest in studying planning-while-learning algorithms for these\ndecision tasks. In this paper we focus on the exploration problem in\nreinforcement learning and Q-learning in particular. The existing exploration\nstrategies for Q-learning are of a heuristic nature and they exhibit limited\nscaleability in tasks with large (or infinite) state and action spaces.\nEfficient experimentation is needed for resolving uncertainties when possible\nplans are compared (i.e. exploration). The experimentation should be sufficient\nfor selecting with statistical significance a locally optimal plan (i.e.\nexploitation). For this purpose, we develop a probabilistic hill-climbing\nalgorithm that uses a statistical selection procedure to decide how much\nexploration is needed for selecting a plan which is, with arbitrarily high\nprobability, arbitrarily close to a locally optimal one. Due to its generality\nthe algorithm can be employed for the exploration strategy of robust\nQ-learning. An experiment on a relatively complex control task shows that the\nproposed exploration strategy performs better than a typical exploration\nstrategy.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:22:12 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Karakoulas", "Grigoris I.", ""]]}, {"id": "1302.4967", "submitter": "Young-Gyun Kim", "authors": "Young-Gyun Kim, Marco Valtorta", "title": "On the Detection of Conflicts in Diagnostic Bayesian Networks Using\n  Abstraction", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-362-367", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important issue in the use of expert systems is the so-called brittleness\nproblem. Expert systems model only a limited part of the world. While the\nexplicit management of uncertainty in expert systems itigates the brittleness\nproblem, it is still possible for a system to be used, unwittingly, in ways\nthat the system is not prepared to address. Such a situation may be detected by\nthe method of straw models, first presented by Jensen et al. [1990] and later\ngeneralized and justified by Laskey [1991]. We describe an algorithm, which we\nhave implemented, that takes as input an annotated diagnostic Bayesian network\n(the base model) and constructs, without assistance, a bipartite network to be\nused as a straw model. We show that in some cases this straw model is better\nthat the independent straw model of Jensen et al., the only other straw model\nfor which a construction algorithm has been designed and implemented.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:22:17 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Kim", "Young-Gyun", ""], ["Valtorta", "Marco", ""]]}, {"id": "1302.4968", "submitter": "Uffe Kj{\\ae}rulff", "authors": "Uffe Kj{\\ae}rulff", "title": "HUGS: Combining Exact Inference and Gibbs Sampling in Junction Trees", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-368-375", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dawid, Kjaerulff and Lauritzen (1994) provided a preliminary description of a\nhybrid between Monte-Carlo sampling methods and exact local computations in\njunction trees. Utilizing the strengths of both methods, such hybrid inference\nmethods has the potential of expanding the class of problems which can be\nsolved under bounded resources as well as solving problems which otherwise\nresist exact solutions. The paper provides a detailed description of a\nparticular instance of such a hybrid scheme; namely, combination of exact\ninference and Gibbs sampling in discrete Bayesian networks. We argue that this\ncombination calls for an extension of the usual message passing scheme of\nordinary junction trees.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:22:22 GMT"}], "update_date": "2013-08-12", "authors_parsed": [["Kj\u00e6rulff", "Uffe", ""]]}, {"id": "1302.4969", "submitter": "Alexander V. Kozlov", "authors": "Alexander V. Kozlov, Jaswinder Pal Singh", "title": "Sensitivities: An Alternative to Conditional Probabilities for Bayesian\n  Belief Networks", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-376-385", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show an alternative way of representing a Bayesian belief network by\nsensitivities and probability distributions. This representation is equivalent\nto the traditional representation by conditional probabilities, but makes\ndependencies between nodes apparent and intuitively easy to understand. We also\npropose a QR matrix representation for the sensitivities and/or conditional\nprobabilities which is more efficient, in both memory requirements and\ncomputational speed, than the traditional representation for computer-based\nimplementations of probabilistic inference. We use sensitivities to show that\nfor a certain class of binary networks, the computation time for approximate\nprobabilistic inference with any positive upper bound on the error of the\nresult is independent of the size of the network. Finally, as an alternative to\ntraditional algorithms that use conditional probabilities, we describe an exact\nalgorithm for probabilistic inference that uses the QR-representation for\nsensitivities and updates probability distributions of nodes in a network\naccording to messages from the neighbors.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:22:26 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Kozlov", "Alexander V.", ""], ["Singh", "Jaswinder Pal", ""]]}, {"id": "1302.4970", "submitter": "Paul J. Krause", "authors": "Paul J. Krause, John Fox, Philip Judson", "title": "Is There a Role for Qualitative Risk Assessment?", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-386-393", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classically, risk is characterized by a point value probability indicating\nthe likelihood of occurrence of an adverse effect. However, there are domains\nwhere the attainability of objective numerical risk characterizations is\nincreasingly being questioned. This paper reviews the arguments in favour of\nextending classical techniques of risk assessment to incorporate meaningful\nqualitative and weak quantitative risk characterizations. A technique in which\nlinguistic uncertainty terms are defined in terms of patterns of argument is\nthen proposed. The technique is demonstrated using a prototype computer-based\nsystem for predicting the carcinogenic risk due to novel chemical compounds.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:22:31 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Krause", "Paul J.", ""], ["Fox", "John", ""], ["Judson", "Philip", ""]]}, {"id": "1302.4971", "submitter": "Michael L. Littman", "authors": "Michael L. Littman, Thomas L. Dean, Leslie Pack Kaelbling", "title": "On the Complexity of Solving Markov Decision Problems", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-394-402", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov decision problems (MDPs) provide the foundations for a number of\nproblems of interest to AI researchers studying automated planning and\nreinforcement learning. In this paper, we summarize results regarding the\ncomplexity of solving MDPs and the running time of MDP solution algorithms. We\nargue that, although MDPs can be solved efficiently in theory, more study is\nneeded to reveal practical algorithms for solving large problems quickly. To\nencourage future research, we sketch some alternative methods of analysis that\nrely on the structure of MDPs.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:22:36 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Littman", "Michael L.", ""], ["Dean", "Thomas L.", ""], ["Kaelbling", "Leslie Pack", ""]]}, {"id": "1302.4972", "submitter": "Christopher Meek", "authors": "Christopher Meek", "title": "Causal Inference and Causal Explanation with Background Knowledge", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-403-410", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents correct algorithms for answering the following two\nquestions; (i) Does there exist a causal explanation consistent with a set of\nbackground knowledge which explains all of the observed independence facts in a\nsample? (ii) Given that there is such a causal explanation what are the causal\nrelationships common to every such causal explanation?\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:22:41 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Meek", "Christopher", ""]]}, {"id": "1302.4973", "submitter": "Christopher Meek", "authors": "Christopher Meek", "title": "Strong Completeness and Faithfulness in Bayesian Networks", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-411-418", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A completeness result for d-separation applied to discrete Bayesian networks\nis presented and it is shown that in a strong measure-theoretic sense almost\nall discrete distributions for a given network structure are faithful; i.e. the\nindependence facts true of the distribution are all and only those entailed by\nthe network structure.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:22:46 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Meek", "Christopher", ""]]}, {"id": "1302.4974", "submitter": "Liem Ngo", "authors": "Liem Ngo, Peter Haddawy, James Helwig", "title": "A Theoretical Framework for Context-Sensitive Temporal Probability Model\n  Construction with Application to Plan Projection", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-419-426", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a context-sensitive temporal probability logic for representing\nclasses of discrete-time temporal Bayesian networks. Context constraints allow\ninference to be focused on only the relevant portions of the probabilistic\nknowledge. We provide a declarative semantics for our language. We present a\nBayesian network construction algorithm whose generated networks give sound and\ncomplete answers to queries. We use related concepts in logic programming to\njustify our approach. We have implemented a Bayesian network construction\nalgorithm for a subset of the theory and demonstrate it's application to the\nproblem of evaluating the effectiveness of treatments for acute cardiac\nconditions.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:22:52 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Ngo", "Liem", ""], ["Haddawy", "Peter", ""], ["Helwig", "James", ""]]}, {"id": "1302.4975", "submitter": "Simon Parsons", "authors": "Simon Parsons", "title": "Refining Reasoning in Qualitative Probabilistic Networks", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-427-434", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years there has been a spate of papers describing systems for\nprobabilisitic reasoning which do not use numerical probabilities. In some\ncases the simple set of values used by these systems make it impossible to\npredict how a probability will change or which hypothesis is most likely given\ncertain evidence. This paper concentrates on such situations, and suggests a\nnumber of ways in which they may be resolved by refining the representation.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:22:58 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Parsons", "Simon", ""]]}, {"id": "1302.4976", "submitter": "Judea Pearl", "authors": "Judea Pearl", "title": "On the Testability of Causal Models with Latent and Instrumental\n  Variables", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-435-443", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Certain causal models involving unmeasured variables induce no independence\nconstraints among the observed variables but imply, nevertheless, inequality\ncontraints on the observed distribution. This paper derives a general formula\nfor such instrumental variables, that is, exogenous variables that directly\naffect some variables but not all. With the help of this formula, it is\npossible to test whether a model involving instrumental variables may account\nfor the data, or, conversely, whether a given variables can be deemed\ninstrumental.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:23:04 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Pearl", "Judea", ""]]}, {"id": "1302.4977", "submitter": "Judea Pearl", "authors": "Judea Pearl, James M. Robins", "title": "Probabilistic Evaluation of Sequential Plans from Causal Models with\n  Hidden Variables", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-444-453", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper concerns the probabilistic evaluation of plans in the presence of\nunmeasured variables, each plan consisting of several concurrent or sequential\nactions. We establish a graphical criterion for recognizing when the effects of\na given plan can be predicted from passive observations on measured variables\nonly. When the criterion is satisfied, a closed-form expression is provided for\nthe probability that the plan will achieve a specified goal.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:23:09 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Pearl", "Judea", ""], ["Robins", "James M.", ""]]}, {"id": "1302.4978", "submitter": "David L Poole", "authors": "David L. Poole", "title": "Exploiting the Rule Structure for Decision Making within the Independent\n  Choice Logic", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-454-463", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the independent choice logic, and in particular the\n\"single agent with nature\" instance of the independent choice logic, namely\nICLdt. This is a logical framework for decision making uncertainty that extends\nboth logic programming and stochastic models such as influence diagrams. This\npaper shows how the representation of a decision problem within the independent\nchoice logic can be exploited to cut down the combinatorics of dynamic\nprogramming. One of the main problems with influence diagram evaluation\ntechniques is the need to optimise a decision for all values of the 'parents'\nof a decision variable. In this paper we show how the rule based nature of the\nICLdt can be exploited so that we only make distinctions in the values of the\ninformation available for a decision that will make a difference to utility.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:23:14 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Poole", "David L.", ""]]}, {"id": "1302.4979", "submitter": "Gregory M. Provan", "authors": "Gregory M. Provan", "title": "Abstraction in Belief Networks: The Role of Intermediate States in\n  Diagnostic Reasoning", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-464-473", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian belief networks are bing increasingly used as a knowledge\nrepresentation for diagnostic reasoning. One simple method for conducting\ndiagnostic reasoning is to represent system faults and observations only. In\nthis paper, we investigate how having intermediate nodes-nodes other than fault\nand observation nodes affects the diagnostic performance of a Bayesian belief\nnetwork. We conducted a series of experiments on a set of real belief networks\nfor medical diagnosis in liver and bile disease. We compared the effects on\ndiagnostic performance of a two-level network consisting just of disease and\nfinding nodes with that of a network which models intermediate\npathophysiological disease states as well. We provide some theoretical evidence\nfor differences observed between the abstracted two-level network and the full\nnetwork.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:23:19 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Provan", "Gregory M.", ""]]}, {"id": "1302.4980", "submitter": "David V. Pynadath", "authors": "David V. Pynadath, Michael P. Wellman", "title": "Accounting for Context in Plan Recognition, with Application to Traffic\n  Monitoring", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-472-481", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical approaches to plan recognition start from a representation of an\nagent's possible plans, and reason evidentially from observations of the\nagent's actions to assess the plausibility of the various candidates. A more\nexpansive view of the task (consistent with some prior work) accounts for the\ncontext in which the plan was generated, the mental state and planning process\nof the agent, and consequences of the agent's actions in the world. We present\na general Bayesian framework encompassing this view, and focus on how context\ncan be exploited in plan recognition. We demonstrate the approach on a problem\nin traffic monitoring, where the objective is to induce the plan of the driver\nfrom observation of vehicle movements. Starting from a model of how the driver\ngenerates plans, we show how the highway context can appropriately influence\nthe recognizer's interpretation of observed driver behavior.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:23:24 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Pynadath", "David V.", ""], ["Wellman", "Michael P.", ""]]}, {"id": "1302.4981", "submitter": "Prakash P. Shenoy", "authors": "Prakash P. Shenoy", "title": "A New Pruning Method for Solving Decision Trees and Game Trees", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-482-490", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main goal of this paper is to describe a new pruning method for solving\ndecision trees and game trees. The pruning method for decision trees suggests a\nslight variant of decision trees that we call scenario trees. In scenario\ntrees, we do not need a conditional probability for each edge emanating from a\nchance node. Instead, we require a joint probability for each path from the\nroot node to a leaf node. We compare the pruning method to the traditional\nrollback method for decision trees and game trees. For problems that require\nBayesian revision of probabilities, a scenario tree representation with the\npruning method is more efficient than a decision tree representation with the\nrollback method. For game trees, the pruning method is more efficient than the\nrollback method.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:23:29 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Shenoy", "Prakash P.", ""]]}, {"id": "1302.4982", "submitter": "Peter L. Spirtes", "authors": "Peter L. Spirtes", "title": "Directed Cyclic Graphical Representations of Feedback Models", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-491-498", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of directed acyclic graphs (DAGs) to represent conditional\nindependence relations among random variables has proved fruitful in a variety\nof ways. Recursive structural equation models are one kind of DAG model.\nHowever, non-recursive structural equation models of the kinds used to model\neconomic processes are naturally represented by directed cyclic graphs with\nindependent errors, a characterization of conditional independence errors, a\ncharacterization of conditional independence constraints is obtained, and it is\nshown that the result generalizes in a natural way to systems in which the\nerror variables or noises are statistically dependent. For non-linear systems\nwith independent errors a sufficient condition for conditional independence of\nvariables in associated distributions is obtained.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:23:34 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Spirtes", "Peter L.", ""]]}, {"id": "1302.4983", "submitter": "Peter L. Spirtes", "authors": "Peter L. Spirtes, Christopher Meek, Thomas S. Richardson", "title": "Causal Inference in the Presence of Latent Variables and Selection Bias", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-499-506", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that there is a general, informative and reliable procedure for\ndiscovering causal relations when, for all the investigator knows, both latent\nvariables and selection bias may be at work. Given information about\nconditional independence and dependence relations between measured variables,\neven when latent variables and selection bias may be present, there are\nsufficient conditions for reliably concluding that there is a causal path from\none variable to another, and sufficient conditions for reliably concluding when\nno such causal path exists.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:23:38 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Spirtes", "Peter L.", ""], ["Meek", "Christopher", ""], ["Richardson", "Thomas S.", ""]]}, {"id": "1302.4984", "submitter": "Sampath Srinivas", "authors": "Sampath Srinivas", "title": "Modeling Failure Priors and Persistence in Model-Based Diagnosis", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-507-514", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic model-based diagnosis computes the posterior probabilities of\nfailure of components from the prior probabilities of component failure and\nobservations of system behavior. One problem with this method is that such\npriors are almost never directly available. One of the reasons is that the\nprior probability estimates include an implicit notion of a time interval over\nwhich they are specified -- for example, if the probability of failure of a\ncomponent is 0.05, is this over the period of a day or is this over a week? A\nsecond problem facing probabilistic model-based diagnosis is the modeling of\npersistence. Say we have an observation about a system at time t_1 and then\nanother observation at a later time t_2. To compute posterior probabilities\nthat take into account both the observations, we need some model of how the\nstate of the system changes from time t_1 to t_2. In this paper, we address\nthese problems using techniques from Reliability theory. We show how to compute\nthe failure prior of a component from an empirical measure of its reliability\n-- the Mean Time Between Failure (MTBF). We also develop a scheme to model\npersistence when handling multiple time tagged observations.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:23:43 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Srinivas", "Sampath", ""]]}, {"id": "1302.4985", "submitter": "Sampath Srinivas", "authors": "Sampath Srinivas", "title": "A Polynomial Algorithm for Computing the Optimal Repair Strategy in a\n  System with Independent Component Failures", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-515-522", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of diagnosis is to compute good repair strategies in response to\nanomalous system behavior. In a decision theoretic framework, a good repair\nstrategy has low expected cost. In a general formulation of the problem, the\ncomputation of the optimal (lowest expected cost) repair strategy for a system\nwith multiple faults is intractable. In this paper, we consider an interesting\nand natural restriction on the behavior of the system being diagnosed: (a) the\nsystem exhibits faulty behavior if and only if one or more components is\nmalfunctioning. (b) The failures of the system components are independent.\nGiven this restriction on system behavior, we develop a polynomial time\nalgorithm for computing the optimal repair strategy. We then go on to introduce\na system hierarchy and the notion of inspecting (testing) components before\nrepair. We develop a linear time algorithm for computing an optimal repair\nstrategy for the hierarchical system which includes both repair and inspection.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:23:48 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Srinivas", "Sampath", ""]]}, {"id": "1302.4986", "submitter": "Sampath Srinivas", "authors": "Sampath Srinivas, Eric J. Horvitz", "title": "Exploiting System Hierarchy to Compute Repair Plans in Probabilistic\n  Model-based Diagnosis", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-523-531", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of model-based diagnosis is to isolate causes of anomalous system\nbehavior and recommend inexpensive repair actions in response. In general,\nprecomputing optimal repair policies is intractable. To date, investigators\naddressing this problem have explored approximations that either impose\nrestrictions on the system model (such as a single fault assumption) or compute\nan immediate best action with limited lookahead. In this paper, we develop a\nformulation of repair in model-based diagnosis and a repair algorithm that\ncomputes optimal sequences of actions. This optimal approach is costly but can\nbe applied to precompute an optimal repair strategy for compact systems. We\nshow how we can exploit a hierarchical system specification to make this\napproach tractable for large systems. When introducing hierarchy, we also\nconsider the tradeoff between simply replacing a component and decomposing it\nto repair its subcomponents. The hierarchical repair algorithm is suitable for\noff-line precomputation of an optimal repair strategy. A modification of the\nalgorithm takes advantage of an iterative deepening scheme to trade off\ninference time and the quality of the computed strategy.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:23:54 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Srinivas", "Sampath", ""], ["Horvitz", "Eric J.", ""]]}, {"id": "1302.4987", "submitter": "Michael P. Wellman", "authors": "Michael P. Wellman, Matthew Ford, Kenneth Larson", "title": "Path Planning under Time-Dependent Uncertainty", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-532-539", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard algorithms for finding the shortest path in a graph require that the\ncost of a path be additive in edge costs, and typically assume that costs are\ndeterministic. We consider the problem of uncertain edge costs, with potential\nprobabilistic dependencies among the costs. Although these dependencies violate\nthe standard dynamic-programming decomposition, we identify a weaker stochastic\nconsistency condition that justifies a generalized dynamic-programming approach\nbased on stochastic dominance. We present a revised path-planning algorithm and\nprove that it produces optimal paths under time-dependent uncertain costs. We\ntest the algorithm by applying it to a model of stochastic bus networks, and\npresent empirical performance results comparing it to some alternatives.\nFinally, we consider extensions of these concepts to a more general class of\nproblems of heuristic search under uncertainty.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:24:00 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Wellman", "Michael P.", ""], ["Ford", "Matthew", ""], ["Larson", "Kenneth", ""]]}, {"id": "1302.4988", "submitter": "Emil Weydert", "authors": "Emil Weydert", "title": "Defaults and Infinitesimals: Defeasible Inference by Nonarchimedean\n  Entropy-Maximization", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-540-547", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new semantics for defeasible inference based on extended\nprobability measures allowed to take infinitesimal values, on the\ninterpretation of defaults as generalized conditional probability constraints\nand on a preferred-model implementation of entropy maximization.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:24:05 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Weydert", "Emil", ""]]}, {"id": "1302.4989", "submitter": "Nic Wilson", "authors": "Nic Wilson", "title": "An Order of Magnitude Calculus", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-548-555", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a simple calculus for order of magnitude reasoning. A\nsemantics is given with soundness and completeness results. Order of magnitude\nprobability functions are easily defined and turn out to be equivalent to kappa\nfunctions, which are slight generalizations of Spohn's Natural Conditional\nFunctions. The calculus also gives rise to an order of magnitude decision\ntheory, which can be used to justify an amended version of Pearl's decision\ntheory for kappa functions, although the latter is weaker and less expressive.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:24:11 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Wilson", "Nic", ""]]}, {"id": "1302.4990", "submitter": "Michael S. K. M. Wong", "authors": "Michael S. K. M. Wong, C. J. Butz, Yang Xiang", "title": "A Method for Implementing a Probabilistic Model as a Relational Database", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-556-564", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses a method for implementing a probabilistic inference\nsystem based on an extended relational data model. This model provides a\nunified approach for a variety of applications such as dynamic programming,\nsolving sparse linear equations, and constraint propagation. In this framework,\nthe probability model is represented as a generalized relational database.\nSubsequent probabilistic requests can be processed as standard relational\nqueries. Conventional database management systems can be easily adopted for\nimplementing such an approximate reasoning system.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:24:15 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Wong", "Michael S. K. M.", ""], ["Butz", "C. J.", ""], ["Xiang", "Yang", ""]]}, {"id": "1302.4991", "submitter": "Yang Xiang", "authors": "Yang Xiang", "title": "Optimization of Inter-Subnet Belief Updating in Multiply Sectioned\n  Bayesian Networks", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-565-573", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments show that Multiply Sectioned Bayesian Networks (MSBNs)\ncan be used for diagnosis of natural systems as well as for model-based\ndiagnosis of artificial systems. They can be applied to single-agent oriented\nreasoning systems as well as multi-agent distributed probabilistic reasoning\nsystems. Belief propagation between a pair of subnets plays a central role in\nmaintenance of global consistency in a MSBN. This paper studies the operation\nUpdateBelief, presented originally with MSBNs, for inter-subnet propagation. We\nanalyze how the operation achieves its intended functionality, which provides\nhints as for how its efficiency can be improved. We then define two new\nversions of UpdateBelief that reduce the computation time for inter-subnet\npropagation. One of them is optimal in the sense that the minimum amount of\ncomputation for coordinating multi-linkage belief propagation is required. The\noptimization problem is solved through the solution of a graph-theoretic\nproblem: the minimum weight open tour in a tree.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:24:20 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Xiang", "Yang", ""]]}, {"id": "1302.4992", "submitter": "Hong Xu", "authors": "Hong Xu, Philippe Smets", "title": "Generating Explanations for Evidential Reasoning", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-574-581", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present two methods to provide explanations for reasoning\nwith belief functions in the valuation-based systems. One approach, inspired by\nStrat's method, is based on sensitivity analysis, but its computation is\nsimpler thus easier to implement than Strat's. The other one is to examine the\nimpact of evidence on the conclusion based on the measure of the information\ncontent in the evidence. We show the property of additivity for the pieces of\nevidence that are conditional independent within the context of the\nvaluation-based systems. We will give an example to show how these approaches\nare applied in an evidential network.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:24:26 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Xu", "Hong", ""], ["Smets", "Philippe", ""]]}, {"id": "1302.4993", "submitter": "Nevin Lianwen Zhang", "authors": "Nevin Lianwen Zhang", "title": "Inference with Causal Independence in the CPSC Network", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-582-589", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports experiments with the causal independence inference\nalgorithm proposed by Zhang and Poole (1994b) on the CPSC network created by\nPradhan et al. (1994). It is found that the algorithm is able to answer 420 of\nthe 422 possible zero-observation queries, 94 of 100 randomly generated\nfive-observation queries, 87 of 100 randomly generated ten-observation queries,\nand 69 of 100 randomly generated twenty-observation queries.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:24:30 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Zhang", "Nevin Lianwen", ""]]}, {"id": "1302.5215", "submitter": "Anandaraj", "authors": "A. Anandaraj, P. Kalaivani, V. Rameshkumar", "title": "Development Of Ontology-Based Intelligent System For Software Testing", "comments": "International Journal of Communication, Computation and Innovation. /\n  Volume 2, Issue 2, 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software testing is a prime factor in software industry. Besides knowing the\nimportance of testing, only limited time is allocated for teaching it. It will\nbe more efficient if testing is taught simultaneously with programming\nfoundations. This integrated learning of testing techniques and programming\nallows the programmers to perform in a better way and this leads to the\nimprovement of the performance of the industry progress. In this paper, a\ntechnique named ontology is introduced, it first defines the various testing\nprocess in hierarchy and define relationships among them, to share and reuse\nthe knowledge that is captured, secondly metadata is created by natural\nlanguage processing and finally, the application use ontologies to support test\nmanagement, it act as knowledge base for multiple environment with the\nintegrated teaching of programming foundation and testing concepts. Keywords:\nMeta Data, Ontology, Software Testing, Integration, Programming Foundations.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2013 08:45:49 GMT"}], "update_date": "2013-02-22", "authors_parsed": [["Anandaraj", "A.", ""], ["Kalaivani", "P.", ""], ["Rameshkumar", "V.", ""]]}, {"id": "1302.5417", "submitter": "Anandaraj", "authors": "P. Kalaivani, A. Anandaraj, K. Raja", "title": "An Ontology Construction Approach for the Domain Of Poultry Science\n  Using Protege", "comments": "arXiv admin note: text overlap with arXiv:1302.5215", "journal-ref": "International Journal of Information Technology and Management\n  Sciences / Volume 1, Issue 2, 2011, ISSN:2231-6752", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The information retrieval systems that are present nowadays are mainly based\non full text matching of keywords or topic based classification. This matching\nof keywords often returns a large number of irrelevant information and this\ndoes not meet the users query requirement. In order to solve this problem and\nto enhance the search using semantic environment, a technique named ontology is\nimplemented for the field of poultry in this paper. Ontology is an emerging\ntechnique in the current field of research in semantic environment. This paper\nconstructs ontology using the tool named Protege version 4.0 and this also\ngenerates Resource Description Framework schema and XML scripts for using\npoultry ontology in web.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2013 09:19:11 GMT"}], "update_date": "2013-02-25", "authors_parsed": [["Kalaivani", "P.", ""], ["Anandaraj", "A.", ""], ["Raja", "K.", ""]]}, {"id": "1302.5681", "submitter": "Samantha Leung", "authors": "Joseph Y. Halpern and Samantha Leung", "title": "Weighted Sets of Probabilities and Minimax Weighted Expected Regret: New\n  Approaches for Representing Uncertainty and Making Decisions", "comments": "Full version of an article [arXiv:1210.4853] that appeared in UAI '12", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a setting where an agent's uncertainty is represented by a set of\nprobability measures, rather than a single measure. Measure-by-measure updating\nof such a set of measures upon acquiring new information is well-known to\nsuffer from problems; agents are not always able to learn appropriately. To\ndeal with these problems, we propose using weighted sets of probabilities: a\nrepresentation where each measure is associated with a weight, which denotes\nits significance. We describe a natural approach to updating in such a\nsituation and a natural approach to determining the weights. We then show how\nthis representation can be used in decision-making, by modifying a standard\napproach to decision making -- minimizing expected regret -- to obtain minimax\nweighted expected regret (MWER). We provide an axiomatization that\ncharacterizes preferences induced by MWER both in the static and dynamic case.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2013 20:11:12 GMT"}], "update_date": "2016-11-04", "authors_parsed": [["Halpern", "Joseph Y.", ""], ["Leung", "Samantha", ""]]}, {"id": "1302.5824", "submitter": "Min Chen", "authors": "B. Duffy, A. Dasgupta, R. Kosara, S. Walton and M. Chen", "title": "Measuring Visual Complexity of Cluster-Based Visualizations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Handling visual complexity is a challenging problem in visualization owing to\nthe subjectiveness of its definition and the difficulty in devising\ngeneralizable quantitative metrics. In this paper we address this challenge by\nmeasuring the visual complexity of two common forms of cluster-based\nvisualizations: scatter plots and parallel coordinatess. We conceptualize\nvisual complexity as a form of visual uncertainty, which is a measure of the\ndegree of difficulty for humans to interpret a visual representation correctly.\nWe propose an algorithm for estimating visual complexity for the aforementioned\nvisualizations using Allen's interval algebra. We first establish a set of\nprimitive 2-cluster cases in scatter plots and another set for parallel\ncoordinatess based on symmetric isomorphism. We confirm that both are the\nminimal sets and verify the correctness of their members computationally. We\nscore the uncertainty of each primitive case based on its topological\nproperties, including the existence of overlapping regions, splitting regions\nand meeting points or edges. We compare a few optional scoring schemes against\na set of subjective scores by humans, and identify the one that is the most\nconsistent with the subjective scores. Finally, we extend the 2-cluster measure\nto k-cluster measure as a general purpose estimator of visual complexity for\nthese two forms of cluster-based visualization.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2013 16:34:35 GMT"}], "update_date": "2013-02-26", "authors_parsed": [["Duffy", "B.", ""], ["Dasgupta", "A.", ""], ["Kosara", "R.", ""], ["Walton", "S.", ""], ["Chen", "M.", ""]]}, {"id": "1302.6031", "submitter": "Ondrej \\v{S}uch", "authors": "Ondrej Such", "title": "Phoneme discrimination using KS algebra I", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our work we define a new algebra of operators as a substitute for fuzzy\nlogic. Its primary purpose is for construction of binary discriminators for\nphonemes based on spectral content. It is optimized for design of\nnon-parametric computational circuits, and makes uses of 4 operations: $\\min$,\n$\\max$, the difference and generalized additively homogenuous means.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2013 10:13:09 GMT"}], "update_date": "2013-02-26", "authors_parsed": [["Such", "Ondrej", ""]]}, {"id": "1302.6214", "submitter": "Alexander Korobeynikov Vasilyevich", "authors": "A.V. Korobeynikov, I.I. Islamgaliev", "title": "Modification of conceptual clustering algorithm Cobweb for numerical\n  data using fuzzy membership function", "comments": "in Russian", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modification of a conceptual clustering algorithm Cobweb for the purpose of\nits application for numerical data is offered. Keywords: clustering, algorithm\nCobweb, numerical data, fuzzy membership function.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2013 20:15:06 GMT"}], "update_date": "2013-02-26", "authors_parsed": [["Korobeynikov", "A. V.", ""], ["Islamgaliev", "I. I.", ""]]}, {"id": "1302.6442", "submitter": "Alain-J\\'er\\^ome Foug\\`eres", "authors": "Alain-J\\'er\\^ome Foug\\`eres", "title": "A Modelling Approach Based on Fuzzy Agents", "comments": "10 pages, 8 figures, 35 references", "journal-ref": "IJCSI-2012-9-6-4655", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modelling of complex systems is mainly based on the decomposition of these\nsystems in autonomous elements, and the identification and definitio9n of\npossible interactions between these elements. For this, the agent-based\napproach is a modelling solution often proposed. Complexity can also be due to\nexternal events or internal to systems, whose main characteristics are\nuncertainty, imprecision, or whose perception is subjective (i.e. interpreted).\nInsofar as fuzzy logic provides a solution for modelling uncertainty, the\nconcept of fuzzy agent can model both the complexity and uncertainty. This\npaper focuses on introducing the concept of fuzzy agent: a classical\narchitecture of agent is redefined according to a fuzzy perspective. A\npedagogical illustration of fuzzy agentification of a smart watering system is\nthen proposed.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 14:24:36 GMT"}], "update_date": "2013-02-27", "authors_parsed": [["Foug\u00e8res", "Alain-J\u00e9r\u00f4me", ""]]}, {"id": "1302.6557", "submitter": "Richard M Jiang", "authors": "Richard M Jiang", "title": "Geodesic-based Salient Object Detection", "comments": "The manuscript was submitted to a conference. Due to anonymous review\n  policy by the conference, I'd like to withdraw it temporarily", "journal-ref": "This is a revised version of our submissions to CVPR 2012, SIGRAPH\n  Asia 2012, and CVPR 2013;", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Saliency detection has been an intuitive way to provide useful cues for\nobject detection and segmentation, as desired for many vision and graphics\napplications. In this paper, we provided a robust method for salient object\ndetection and segmentation. Other than using various pixel-level contrast\ndefinitions, we exploited global image structures and proposed a new geodesic\nmethod dedicated for salient object detection. In the proposed approach, a new\ngeodesic scheme, namely geodesic tunneling is proposed to tackle with textures\nand local chaotic structures. With our new geodesic approach, a geodesic\nsaliency map is estimated in correspondence to spatial structures in an image.\nExperimental evaluation on a salient object benchmark dataset validated that\nour algorithm consistently outperformed a number of the state-of-art saliency\nmethods, yielding higher precision and better recall rates. With the robust\nsaliency estimation, we also present an unsupervised hierarchical salient\nobject cut scheme simply using adaptive saliency thresholding, which attained\nthe highest score in our F-measure test. We also applied our geodesic cut\nscheme to a number of image editing tasks as demonstrated in additional\nexperiments.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 19:52:02 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2013 18:41:55 GMT"}], "update_date": "2013-11-11", "authors_parsed": [["Jiang", "Richard M", ""]]}, {"id": "1302.6584", "submitter": "Qiang Liu", "authors": "Qiang Liu and Alexander Ihler", "title": "Variational Algorithms for Marginal MAP", "comments": "This is a journal version of our conference paper \"variational\n  algorithms for marginal MAP\" in UAI 201 [arXiv:1202.3742]; this version is\n  considerably expanded, with more detail in its development, examples,\n  algorithms, and proofs; additional experiments; and a junction graph version\n  of the central message-passing algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The marginal maximum a posteriori probability (MAP) estimation problem, which\ncalculates the mode of the marginal posterior distribution of a subset of\nvariables with the remaining variables marginalized, is an important inference\nproblem in many models, such as those with hidden variables or uncertain\nparameters. Unfortunately, marginal MAP can be NP-hard even on trees, and has\nattracted less attention in the literature compared to the joint MAP\n(maximization) and marginalization problems. We derive a general dual\nrepresentation for marginal MAP that naturally integrates the marginalization\nand maximization operations into a joint variational optimization problem,\nmaking it possible to easily extend most or all variational-based algorithms to\nmarginal MAP. In particular, we derive a set of \"mixed-product\" message passing\nalgorithms for marginal MAP, whose form is a hybrid of max-product, sum-product\nand a novel \"argmax-product\" message updates. We also derive a class of\nconvergent algorithms based on proximal point methods, including one that\ntransforms the marginal MAP problem into a sequence of standard marginalization\nproblems. Theoretically, we provide guarantees under which our algorithms give\nglobally or locally optimal solutions, and provide novel upper bounds on the\noptimal objectives. Empirically, we demonstrate that our algorithms\nsignificantly outperform the existing approaches, including a state-of-the-art\nalgorithm based on local search methods.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 20:58:59 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2013 18:33:03 GMT"}, {"version": "v3", "created": "Thu, 18 Jul 2013 00:29:57 GMT"}], "update_date": "2013-07-19", "authors_parsed": [["Liu", "Qiang", ""], ["Ihler", "Alexander", ""]]}, {"id": "1302.6595", "submitter": "Ratnadip Adhikari", "authors": "Ratnadip Adhikari, R. K. Agrawal", "title": "Combining Multiple Time Series Models Through A Robust Weighted\n  Mechanism", "comments": "6 pages, 3 figures, 2 tables, conference", "journal-ref": "International Conference on Recent Advances in Information\n  Technology, 2012", "doi": "10.1109/RAIT.2012.6194621", "report-no": null, "categories": "cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improvement of time series forecasting accuracy through combining multiple\nmodels is an important as well as a dynamic area of research. As a result,\nvarious forecasts combination methods have been developed in literature.\nHowever, most of them are based on simple linear ensemble strategies and hence\nignore the possible relationships between two or more participating models. In\nthis paper, we propose a robust weighted nonlinear ensemble technique which\nconsiders the individual forecasts from different models as well as the\ncorrelations among them while combining. The proposed ensemble is constructed\nusing three well-known forecasting models and is tested for three real-world\ntime series. A comparison is made among the proposed scheme and three other\nwidely used linear combination methods, in terms of the obtained forecast\nerrors. This comparison shows that our ensemble scheme provides significantly\nlower forecast errors than each individual model as well as each of the four\nlinear combination methods.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 21:01:42 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Adhikari", "Ratnadip", ""], ["Agrawal", "R. K.", ""]]}, {"id": "1302.6602", "submitter": "Lamiaa Ibrahim Fattouh", "authors": "Lamiaa Fattouh Ibrahim, Manal Hamed Al Harbi", "title": "Using Modified Partitioning Around Medoids Clustering Technique in\n  Mobile Network Planning", "comments": "10 pages, 15 figures", "journal-ref": "International Journal of Computer Science Issues Volume 9, Issue\n  6, November 2012", "doi": null, "report-no": null, "categories": "cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every cellular network deployment requires planning and optimization in order\nto provide adequate coverage, capacity, and quality of service (QoS).\nOptimization mobile radio network planning is a very complex task, as many\naspects must be taken into account. With the rapid development in mobile\nnetwork we need effective network planning tool to satisfy the need of\ncustomers. However, deciding upon the optimum placement for the base stations\n(BS s) to achieve best services while reducing the cost is a complex task\nrequiring vast computational resource. This paper introduces the spatial\nclustering to solve the Mobile Networking Planning problem. It addresses\nantenna placement problem or the cell planning problem, involves locating and\nconfiguring infrastructure for mobile networks by modified the original\nPartitioning Around Medoids PAM algorithm. M-PAM (Modified Partitioning Around\nMedoids) has been proposed to satisfy the requirements and constraints. PAM\nneeds to specify number of clusters (k) before starting to search for the best\nlocations of base stations. The M-PAM algorithm uses the radio network planning\nto determine k. We calculate for each cluster its coverage and capacity and\ndetermine if they satisfy the mobile requirements, if not we will increase (k)\nand reapply algorithms depending on two methods for clustering. Implementation\nof this algorithm to a real case study is presented. Experimental results and\nanalysis indicate that the M-PAM algorithm when applying method two is\neffective in case of heavy load distribution, and leads to minimum number of\nbase stations, which directly affected onto the cost of planning the network.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 21:12:30 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Ibrahim", "Lamiaa Fattouh", ""], ["Harbi", "Manal Hamed Al", ""]]}, {"id": "1302.6617", "submitter": "Timothy Hunter", "authors": "Timothy Hunter, Aude Hofleitner, Jack Reilly, Walid Krichene, Jerome\n  Thai, Anastasios Kouvelas, Pieter Abbeel, Alexandre Bayen", "title": "Arriving on time: estimating travel time distributions on large-scale\n  road networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most optimal routing problems focus on minimizing travel time or distance\ntraveled. Oftentimes, a more useful objective is to maximize the probability of\non-time arrival, which requires statistical distributions of travel times,\nrather than just mean values. We propose a method to estimate travel time\ndistributions on large-scale road networks, using probe vehicle data collected\nfrom GPS. We present a framework that works with large input of data, and\nscales linearly with the size of the network. Leveraging the planar topology of\nthe graph, the method computes efficiently the time correlations between\nneighboring streets. First, raw probe vehicle traces are compressed into pairs\nof travel times and number of stops for each traversed road segment using a\n`stop-and-go' algorithm developed for this work. The compressed data is then\nused as input for training a path travel time model, which couples a Markov\nmodel along with a Gaussian Markov random field. Finally, scalable inference\nalgorithms are developed for obtaining path travel time distributions from the\ncomposite MM-GMRF model. We illustrate the accuracy and scalability of our\nmodel on a 505,000 road link network spanning the San Francisco Bay Area.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 22:36:46 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Hunter", "Timothy", ""], ["Hofleitner", "Aude", ""], ["Reilly", "Jack", ""], ["Krichene", "Walid", ""], ["Thai", "Jerome", ""], ["Kouvelas", "Anastasios", ""], ["Abbeel", "Pieter", ""], ["Bayen", "Alexandre", ""]]}, {"id": "1302.6677", "submitter": "Ashish Sabharwal", "authors": "Stefano Ermon, Carla P. Gomes, Ashish Sabharwal, Bart Selman", "title": "Taming the Curse of Dimensionality: Discrete Integration by Hashing and\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integration is affected by the curse of dimensionality and quickly becomes\nintractable as the dimensionality of the problem grows. We propose a randomized\nalgorithm that, with high probability, gives a constant-factor approximation of\na general discrete integral defined over an exponentially large set. This\nalgorithm relies on solving only a small number of instances of a discrete\ncombinatorial optimization problem subject to randomly generated parity\nconstraints used as a hash function. As an application, we demonstrate that\nwith a small number of MAP queries we can efficiently approximate the partition\nfunction of discrete graphical models, which can in turn be used, for instance,\nfor marginal computation or model selection.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 06:45:28 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Ermon", "Stefano", ""], ["Gomes", "Carla P.", ""], ["Sabharwal", "Ashish", ""], ["Selman", "Bart", ""]]}, {"id": "1302.6779", "submitter": "Constantin F. Aliferis", "authors": "Constantin F. Aliferis, Gregory F. Cooper", "title": "An Evaluation of an Algorithm for Inductive Learning of Bayesian Belief\n  Networks Usin", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-8-14", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian learning of belief networks (BLN) is a method for automatically\nconstructing belief networks (BNs) from data using search and Bayesian scoring\ntechniques. K2 is a particular instantiation of the method that implements a\ngreedy search strategy. To evaluate the accuracy of K2, we randomly generated a\nnumber of BNs and for each of those we simulated data sets. K2 was then used to\ninduce the generating BNs from the simulated data. We examine the performance\nof the program, and the factors that influence it. We also present a simple BN\nmodel, developed from our results, which predicts the accuracy of K2, when\ngiven various characteristics of the data set.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:13:16 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Aliferis", "Constantin F.", ""], ["Cooper", "Gregory F.", ""]]}, {"id": "1302.6780", "submitter": "Russ B. Altman", "authors": "Russ B. Altman, Cheng C. Chen, William B. Poland, Jaswinder Pal Singh", "title": "Probabilistic Constraint Satisfaction with Non-Gaussian Noise", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-15-22", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have previously reported a Bayesian algorithm for determining the\ncoordinates of points in three-dimensional space from uncertain constraints.\nThis method is useful in the determination of biological molecular structure.\nIt is limited, however, by the requirement that the uncertainty in the\nconstraints be normally distributed. In this paper, we present an extension of\nthe original algorithm that allows constraint uncertainty to be represented as\na mixture of Gaussians, and thereby allows arbitrary constraint distributions.\nWe illustrate the performance of this algorithm on a problem drawn from the\ndomain of molecular structure determination, in which a multicomponent\nconstraint representation produces a much more accurate solution than the old\nsingle component mechanism. The new mechanism uses mixture distributions to\ndecompose the problem into a set of independent problems with unimodal\nconstraint uncertainty. The results of the unimodal subproblems are\nperiodically recombined using Bayes' law, to avoid combinatorial explosion. The\nnew algorithm is particularly suited for parallel implementation.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:13:22 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Altman", "Russ B.", ""], ["Chen", "Cheng C.", ""], ["Poland", "William B.", ""], ["Singh", "Jaswinder Pal", ""]]}, {"id": "1302.6781", "submitter": "Derek D. Ayers", "authors": "Derek D. Ayers", "title": "A Bayesian Method Reexamined", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-23-27", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines the \"K2\" network scoring metric of Cooper and Herskovits.\nIt shows counterintuitive results from applying this metric to simple networks.\nOne family of noninformative priors is suggested for assigning equal scores to\nequivalent networks.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:13:31 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Ayers", "Derek D.", ""]]}, {"id": "1302.6782", "submitter": "Adriano Azevedo-Filho", "authors": "Adriano Azevedo-Filho, Ross D. Shachter", "title": "Laplace's Method Approximations for Probabilistic Inference in Belief\n  Networks with Continuous Variables", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-28-36", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Laplace's method, a family of asymptotic methods used to approximate\nintegrals, is presented as a potential candidate for the tool box of techniques\nused for knowledge acquisition and probabilistic inference in belief networks\nwith continuous variables. This technique approximates posterior moments and\nmarginal posterior distributions with reasonable accuracy [errors are O(n^-2)\nfor posterior means] in many interesting cases. The method also seems promising\nfor computing approximations for Bayes factors for use in the context of model\nselection, model uncertainty and mixtures of pdfs. The limitations, regularity\nconditions and computational difficulties for the implementation of Laplace's\nmethod are comparable to those associated with the methods of maximum\nlikelihood and posterior mode analysis.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:13:37 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Azevedo-Filho", "Adriano", ""], ["Shachter", "Ross D.", ""]]}, {"id": "1302.6783", "submitter": "Fahiem Bacchus", "authors": "Fahiem Bacchus, Adam J. Grove, Joseph Y. Halpern, Daphne Koller", "title": "Generating New Beliefs From Old", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-37-45", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In previous work [BGHK92, BGHK93], we have studied the random-worlds approach\n-- a particular (and quite powerful) method for generating degrees of belief\n(i.e., subjective probabilities) from a knowledge base consisting of objective\n(first-order, statistical, and default) information. But allowing a knowledge\nbase to contain only objective information is sometimes limiting. We\noccasionally wish to include information about degrees of belief in the\nknowledge base as well, because there are contexts in which old beliefs\nrepresent important information that should influence new beliefs. In this\npaper, we describe three quite general techniques for extending a method that\ngenerates degrees of belief from objective information to one that can make use\nof degrees of belief as well. All of our techniques are bloused on well-known\napproaches, such as cross-entropy. We discuss general connections between the\ntechniques and in particular show that, although conceptually and technically\nquite different, all of the techniques give the same answer when applied to the\nrandom-worlds method.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:13:44 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Bacchus", "Fahiem", ""], ["Grove", "Adam J.", ""], ["Halpern", "Joseph Y.", ""], ["Koller", "Daphne", ""]]}, {"id": "1302.6784", "submitter": "Alexander Balke", "authors": "Alexander Balke, Judea Pearl", "title": "Counterfactual Probabilities: Computational Methods, Bounds and\n  Applications", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-46-54", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluation of counterfactual queries (e.g., \"If A were true, would C have\nbeen true?\") is important to fault diagnosis, planning, and determination of\nliability. In this paper we present methods for computing the probabilities of\nsuch queries using the formulation proposed in [Balke and Pearl, 1994], where\nthe antecedent of the query is interpreted as an external action that forces\nthe proposition A to be true. When a prior probability is available on the\ncausal mechanisms governing the domain, counterfactual probabilities can be\nevaluated precisely. However, when causal knowledge is specified as conditional\nprobabilities on the observables, only bounds can computed. This paper develops\ntechniques for evaluating these bounds, and demonstrates their use in two\napplications: (1) the determination of treatment efficacy from studies in which\nsubjects may choose their own treatment, and (2) the determination of liability\nin product-safety litigation.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:13:50 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Balke", "Alexander", ""], ["Pearl", "Judea", ""]]}, {"id": "1302.6786", "submitter": "Ildar Z. Batyrshin", "authors": "Ildar Z. Batyrshin", "title": "Modus Ponens Generating Function in the Class of ^-valuations of\n  Plausibility", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-55-59", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the problem of construction of inference procedures which can\nmanipulate with uncertainties measured in ordinal scales and fulfill to the\nproperty of strict monotonicity of conclusion. The class of A-valuations of\nplausibility is considered where operations based only on information about\nlinear ordering of plausibility values are used. In this class the modus ponens\ngenerating function fulfiling to the property of strict monotonicity of\nconclusions is introduced.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:13:56 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Batyrshin", "Ildar Z.", ""]]}, {"id": "1302.6787", "submitter": "Ann Becker", "authors": "Ann Becker, Dan Geiger", "title": "Approximation Algorithms for the Loop Cutset Problem", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-60-68", "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to find a small loop curser in a Bayesian network. Finding such a\nloop cutset is the first step in the method of conditioning for inference. Our\nalgorithm for finding a loop cutset, called MGA, finds a loop cutset which is\nguaranteed in the worst case to contain less than twice the number of variables\ncontained in a minimum loop cutset. We test MGA on randomly generated graphs\nand find that the average ratio between the number of instances associated with\nthe algorithms' output and the number of instances associated with a minimum\nsolution is 1.22.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:14:02 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Becker", "Ann", ""], ["Geiger", "Dan", ""]]}, {"id": "1302.6788", "submitter": "Philippe Besnard", "authors": "Philippe Besnard, Jerome Lang", "title": "Possibility and Necessity Functions over Non-classical Logics", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-69-76", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an integration of possibility theory into non-classical logics. We\nobtain many formal results that generalize the case where possibility and\nnecessity functions are based on classical logic. We show how useful such an\napproach is by applying it to reasoning under uncertain and inconsistent\ninformation.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:14:08 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Besnard", "Philippe", ""], ["Lang", "Jerome", ""]]}, {"id": "1302.6789", "submitter": "Raj Bhatnagar", "authors": "Raj Bhatnagar", "title": "Exploratory Model Building", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-77-85", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some instances of creative thinking require an agent to build and test\nhypothetical theories. Such a reasoner needs to explore the space of not only\nthose situations that have occurred in the past, but also those that are\nrationally conceivable. In this paper we present a formalism for exploring the\nspace of conceivable situation-models for those domains in which the knowledge\nis primarily probabilistic in nature. The formalism seeks to construct\nconsistent, minimal, and desirable situation-descriptions by selecting suitable\ndomain-attributes and dependency relationships from the available domain\nknowledge.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:14:14 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Bhatnagar", "Raj", ""]]}, {"id": "1302.6791", "submitter": "Jim S. Blythe", "authors": "Jim S. Blythe", "title": "Planning with External Events", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-94-101", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I describe a planning methodology for domains with uncertainty in the form of\nexternal events that are not completely predictable. The events are represented\nby enabling conditions and probabilities of occurrence. The planner is\ngoal-directed and backward chaining, but the subgoals are suggested by\nanalyzing the probability of success of the partial plan rather than being\nsimply the open conditions of the operators in the plan. The partial plan is\nrepresented as a Bayesian belief net to compute its probability of success.\nSince calculating the probability of success of a plan can be very expensive I\nintroduce two other techniques for computing it, one that uses Monte Carlo\nsimulation to estimate it and one based on a Markov chain representation that\nuses knowledge about the dependencies between the predicates describing the\ndomain.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:14:26 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Blythe", "Jim S.", ""]]}, {"id": "1302.6792", "submitter": "Remco R. Bouckaert", "authors": "Remco R. Bouckaert", "title": "Properties of Bayesian Belief Network Learning Algorithms", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-102-109", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian belief network learning algorithms have three basic components: a\nmeasure of a network structure and a database, a search heuristic that chooses\nnetwork structures to be considered, and a method of estimating the probability\ntables from the database. This paper contributes to all these three topics. The\nbehavior of the Bayesian measure of Cooper and Herskovits and a minimum\ndescription length (MDL) measure are compared with respect to their properties\nfor both limiting size and finite size databases. It is shown that the MDL\nmeasure has more desirable properties than the Bayesian measure when a\ndistribution is to be learned. It is shown that selecting belief networks with\ncertain minimallity properties is NP-hard. This result justifies the use of\nsearch heuristics instead of exact algorithms for choosing network structures\nto be considered. In some cases, a collection of belief networks can be\nrepresented by a single belief network which leads to a new kind of probability\ntable estimation called smoothing. We argue that smoothing can be efficiently\nimplemented by incorporating it in the search heuristic. Experimental results\nsuggest that for learning probabilities of belief networks smoothing is\nhelpful.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:14:31 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Bouckaert", "Remco R.", ""]]}, {"id": "1302.6793", "submitter": "Remco R. Bouckaert", "authors": "Remco R. Bouckaert", "title": "A Stratified Simulation Scheme for Inference in Bayesian Belief Networks", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-110-118", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation schemes for probabilistic inference in Bayesian belief networks\noffer many advantages over exact algorithms; for example, these schemes have a\nlinear and thus predictable runtime while exact algorithms have exponential\nruntime. Experiments have shown that likelihood weighting is one of the most\npromising simulation schemes. In this paper, we present a new simulation scheme\nthat generates samples more evenly spread in the sample space than the\nlikelihood weighting scheme. We show both theoretically and experimentally that\nthe stratified scheme outperforms likelihood weighting in average runtime and\nerror in estimates of beliefs.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:14:37 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Bouckaert", "Remco R.", ""]]}, {"id": "1302.6794", "submitter": "Tom Chavez", "authors": "Tom Chavez, Max Henrion", "title": "Efficient Estimation of the Value of Information in Monte Carlo Models", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-119-127", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The expected value of information (EVI) is the most powerful measure of\nsensitivity to uncertainty in a decision model: it measures the potential of\ninformation to improve the decision, and hence measures the expected value of\noutcome. Standard methods for computing EVI use discrete variables and are\ncomputationally intractable for models that contain more than a few variables.\nMonte Carlo simulation provides the basis for more tractable evaluation of\nlarge predictive models with continuous and discrete variables, but so far\ncomputation of EVI in a Monte Carlo setting also has appeared impractical. We\nintroduce an approximate approach based on pre-posterior analysis for\nestimating EVI in Monte Carlo models. Our method uses a linear approximation to\nthe value function and multiple linear regression to estimate the linear model\nfrom the samples. The approach is efficient and practical for extremely large\nmodels. It allows easy estimation of EVI for perfect or partial information on\nindividual variables or on combinations of variables. We illustrate its\nimplementation within Demos (a decision modeling system), and its application\nto a large model for crisis transportation planning.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:14:43 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Chavez", "Tom", ""], ["Henrion", "Max", ""]]}, {"id": "1302.6795", "submitter": "Bruce D'Ambrosio", "authors": "Bruce D'Ambrosio", "title": "Symbolic Probabilitistic Inference in Large BN2O Networks", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-128-135", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A BN2O network is a two level belief net in which the parent interactions are\nmodeled using the noisy-or interaction model. In this paper we discuss\napplication of the SPI local expression language to efficient inference in\nlarge BN2O networks. In particular, we show that there is significant\nstructure, which can be exploited to improve over the Quickscore result. We\nfurther describe how symbolic techniques can provide information which can\nsignificantly reduce the computation required for computing all cause posterior\nmarginals. Finally, we present a novel approximation technique with preliminary\nexperimental results.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:14:49 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["D'Ambrosio", "Bruce", ""]]}, {"id": "1302.6796", "submitter": "Adnan Darwiche", "authors": "Adnan Darwiche, Moises Goldszmidt", "title": "Action Networks: A Framework for Reasoning about Actions and Change\n  under Uncertainty", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-136-144", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes action networks as a semantically well-founded framework\nfor reasoning about actions and change under uncertainty. Action networks add\ntwo primitives to probabilistic causal networks: controllable variables and\npersistent variables. Controllable variables allow the representation of\nactions as directly setting the value of specific events in the domain, subject\nto preconditions. Persistent variables provide a canonical model of persistence\naccording to which both the state of a variable and the causal mechanism\ndictating its value persist over time unless intervened upon by an action (or\nits consequences). Action networks also allow different methods for quantifying\nthe uncertainty in causal relationships, which go beyond traditional\nprobabilistic quantification. This paper describes both recent results and work\nin progress.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:14:55 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Darwiche", "Adnan", ""], ["Goldszmidt", "Moises", ""]]}, {"id": "1302.6797", "submitter": "Adnan Darwiche", "authors": "Adnan Darwiche, Moises Goldszmidt", "title": "On the Relation between Kappa Calculus and Probabilistic Reasoning", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-145-153", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the connection between kappa calculus and probabilistic reasoning in\ndiagnosis applications. Specifically, we abstract a probabilistic belief\nnetwork for diagnosing faults into a kappa network and compare the ordering of\nfaults computed using both methods. We show that, at least for the example\nexamined, the ordering of faults coincide as long as all the causal relations\nin the original probabilistic network are taken into account. We also provide a\nformal analysis of some network structures where the two methods will differ.\nBoth kappa rankings and infinitesimal probabilities have been used extensively\nto study default reasoning and belief revision. But little has been done on\nutilizing their connection as outlined above. This is partly because the\nrelation between kappa and probability calculi assumes that probabilities are\narbitrarily close to one (or zero). The experiments in this paper investigate\nthis relation when this assumption is not satisfied. The reported results have\nimportant implications on the use of kappa rankings to enhance the knowledge\nengineering of uncertainty models.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:15:01 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Darwiche", "Adnan", ""], ["Goldszmidt", "Moises", ""]]}, {"id": "1302.6798", "submitter": "Ron Davidson", "authors": "Ron Davidson, Michael R. Fehling", "title": "A Structured, Probabilistic Representation of Action", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-154-161", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When agents devise plans for execution in the real world, they face two\nimportant forms of uncertainty: they can never have complete knowledge about\nthe state of the world, and they do not have complete control, as the effects\nof their actions are uncertain. While most classical planning methods avoid\nexplicit uncertainty reasoning, we believe that uncertainty should be\nexplicitly represented and reasoned about. We develop a probabilistic\nrepresentation for states and actions, based on belief networks. We define\nconditional belief nets (CBNs) to capture the probabilistic dependency of the\neffects of an action upon the state of the world. We also use a CBN to\nrepresent the intrinsic relationships among entities in the environment, which\npersist from state to state. We present a simple projection algorithm to\nconstruct the belief network of the state succeeding an action, using the\nenvironment CBN model to infer indirect effects. We discuss how the qualitative\naspects of belief networks and CBNs make them appropriate for the various\nstages of the problem solving process, from model construction to the design of\nplanning algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:15:07 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Davidson", "Ron", ""], ["Fehling", "Michael R.", ""]]}, {"id": "1302.6799", "submitter": "Richard Dearden", "authors": "Richard Dearden, Craig Boutilier", "title": "Integrating Planning and Execution in Stochastic Domains", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-162-169", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate planning in time-critical domains represented as Markov\nDecision Processes, showing that search based techniques can be a very powerful\nmethod for finding close to optimal plans. To reduce the computational cost of\nplanning in these domains, we execute actions as we construct the plan, and\nsacrifice optimality by searching to a fixed depth and using a heuristic\nfunction to estimate the value of states. Although this paper concentrates on\nthe search algorithm, we also discuss ways of constructing heuristic functions\nsuitable for this approach. Our results show that by interleaving search and\nexecution, close to optimal policies can be found without the computational\nrequirements of other approaches.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:15:13 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Dearden", "Richard", ""], ["Boutilier", "Craig", ""]]}, {"id": "1302.6800", "submitter": "Denise L. Draper", "authors": "Denise L. Draper, Steve Hanks", "title": "Localized Partial Evaluation of Belief Networks", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-170-177", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most algorithms for propagating evidence through belief networks have been\nexact and exhaustive: they produce an exact (point-valued) marginal probability\nfor every node in the network. Often, however, an application will not need\ninformation about every n ode in the network nor will it need exact\nprobabilities. We present the localized partial evaluation (LPE) propagation\nalgorithm, which computes interval bounds on the marginal probability of a\nspecified query node by examining a subset of the nodes in the entire network.\nConceptually, LPE ignores parts of the network that are \"too far away\" from the\nqueried node to have much impact on its value. LPE has the \"anytime\" property\nof being able to produce better solutions (tighter intervals) given more time\nto consider more of the network.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:15:20 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Draper", "Denise L.", ""], ["Hanks", "Steve", ""]]}, {"id": "1302.6801", "submitter": "Denise L. Draper", "authors": "Denise L. Draper, Steve Hanks, Daniel Weld", "title": "A Probabilistic Model of Action for Least-Commitment Planning with\n  Information Gather", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-178-186", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI planning algorithms have addressed the problem of generating sequences of\noperators that achieve some input goal, usually assuming that the planning\nagent has perfect control over and information about the world. Relaxing these\nassumptions requires an extension to the action representation that allows\nreasoning both about the changes an action makes and the information it\nprovides. This paper presents an action representation that extends the\ndeterministic STRIPS model, allowing actions to have both causal and\ninformational effects, both of which can be context dependent and noisy. We\nalso demonstrate how a standard least-commitment planning algorithm can be\nextended to include informational actions and contingent execution.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:15:26 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Draper", "Denise L.", ""], ["Hanks", "Steve", ""], ["Weld", "Daniel", ""]]}, {"id": "1302.6802", "submitter": "Marek J. Druzdzel", "authors": "Marek J. Druzdzel", "title": "Some Properties of Joint Probability Distributions", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-187-194", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several Artificial Intelligence schemes for reasoning under uncertainty\nexplore either explicitly or implicitly asymmetries among probabilities of\nvarious states of their uncertain domain models. Even though the correct\nworking of these schemes is practically contingent upon the existence of a\nsmall number of probable states, no formal justification has been proposed of\nwhy this should be the case. This paper attempts to fill this apparent gap by\nstudying asymmetries among probabilities of various states of uncertain models.\nBy rewriting the joint probability distribution over a model's variables into a\nproduct of individual variables' prior and conditional probability\ndistributions, and applying central limit theorem to this product, we can\ndemonstrate that the probabilities of individual states of the model can be\nexpected to be drawn from highly skewed, log-normal distributions. With\nsufficient asymmetry in individual prior and conditional probability\ndistributions, a small fraction of states can be expected to cover a large\nportion of the total probability space with the remaining states having\npractically negligible probability. Theoretical discussion is supplemented by\nsimulation results and an illustrative real-world example.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:15:32 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Druzdzel", "Marek J.", ""]]}, {"id": "1302.6803", "submitter": "Didier Dubois", "authors": "Didier Dubois, Luis Farinas del Cerro, Andreas Herzig, Henri Prade", "title": "An Ordinal View of Independence with Application to Plausible Reasoning", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-195-203", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ordinal view of independence is studied in the framework of possibility\ntheory. We investigate three possible definitions of dependence, of increasing\nstrength. One of them is the counterpart to the multiplication law in\nprobability theory, and the two others are based on the notion of conditional\npossibility. These two have enough expressive power to support the whole\npossibility theory, and a complete axiomatization is provided for the strongest\none. Moreover we show that weak independence is well-suited to the problems of\nbelief change and plausible reasoning, especially to address the problem of\nblocking of property inheritance in exception-tolerant taxonomic reasoning.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:15:38 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Dubois", "Didier", ""], ["del Cerro", "Luis Farinas", ""], ["Herzig", "Andreas", ""], ["Prade", "Henri", ""]]}, {"id": "1302.6804", "submitter": "Florence Dupin de Saint-Cyr", "authors": "Florence Dupin de Saint-Cyr, Jerome Lang, Thomas Schiex", "title": "Penalty logic and its Link with Dempster-Shafer Theory", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-204-211", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Penalty logic, introduced by Pinkas, associates to each formula of a\nknowledge base the price to pay if this formula is violated. Penalties may be\nused as a criterion for selecting preferred consistent subsets in an\ninconsistent knowledge base, thus inducing a non-monotonic inference relation.\nA precise formalization and the main properties of penalty logic and of its\nassociated non-monotonic inference relation are given in the first part. We\nalso show that penalty logic and Dempster-Shafer theory are related, especially\nin the infinitesimal case.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:15:44 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["de Saint-Cyr", "Florence Dupin", ""], ["Lang", "Jerome", ""], ["Schiex", "Thomas", ""]]}, {"id": "1302.6805", "submitter": "Kazuo J. Ezawa", "authors": "Kazuo J. Ezawa", "title": "Value of Evidence on Influence Diagrams", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-212-220", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce evidence propagation operations on influence\ndiagrams and a concept of value of evidence, which measures the value of\nexperimentation. Evidence propagation operations are critical for the\ncomputation of the value of evidence, general update and inference operations\nin normative expert systems which are based on the influence diagram\n(generalized Bayesian network) paradigm. The value of evidence allows us to\ncompute directly an outcome sensitivity, a value of perfect information and a\nvalue of control which are used in decision analysis (the science of decision\nmaking under uncertainty). More specifically, the outcome sensitivity is the\nmaximum difference among the values of evidence, the value of perfect\ninformation is the expected value of the values of evidence, and the value of\ncontrol is the optimal value of the values of evidence. We also discuss an\nimplementation and a relative computational efficiency issues related to the\nvalue of evidence and the value of perfect information.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:15:51 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Ezawa", "Kazuo J.", ""]]}, {"id": "1302.6806", "submitter": "Pascale Fonck", "authors": "Pascale Fonck", "title": "Conditional Independence in Possibility Theory", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-221-226", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Possibilistic conditional independence is investigated: we propose a\ndefinition of this notion similar to the one used in probability theory. The\nlinks between independence and non-interactivity are investigated, and\nproperties of these relations are given. The influence of the conjunction used\nto define a conditional measure of possibility is also highlighted: we examine\nthree types of conjunctions: Lukasiewicz - like T-norms, product-like T-norms\nand the minimum operator.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:15:56 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Fonck", "Pascale", ""]]}, {"id": "1302.6807", "submitter": "Robert Fung", "authors": "Robert Fung, Brendan del Favero", "title": "Backward Simulation in Bayesian Networks", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-227-234", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backward simulation is an approximate inference technique for Bayesian belief\nnetworks. It differs from existing simulation methods in that it starts\nsimulation from the known evidence and works backward (i.e., contrary to the\ndirection of the arcs). The technique's focus on the evidence leads to improved\nconvergence in situations where the posterior beliefs are dominated by the\nevidence rather than by the prior probabilities. Since this class of situations\nis large, the technique may make practical the application of approximate\ninference in Bayesian belief networks to many real-world problems.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:16:02 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Fung", "Robert", ""], ["del Favero", "Brendan", ""]]}, {"id": "1302.6808", "submitter": "David Heckerman", "authors": "Dan Geiger and David Heckerman", "title": "Learning Gaussian Networks", "comments": "This version has improved pointers to the literature", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-235-243", "categories": "cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe algorithms for learning Bayesian networks from a combination of\nuser knowledge and statistical data. The algorithms have two components: a\nscoring metric and a search procedure. The scoring metric takes a network\nstructure, statistical data, and a user's prior knowledge, and returns a score\nproportional to the posterior probability of the network structure given the\ndata. The search procedure generates networks for evaluation by the scoring\nmetric. Previous work has concentrated on metrics for domains containing only\ndiscrete variables, under the assumption that data represents a multinomial\nsample. In this paper, we extend this work, developing scoring metrics for\ndomains containing all continuous variables or a mixture of discrete and\ncontinuous variables, under the assumption that continuous data is sampled from\na multivariate normal distribution. Our work extends traditional statistical\napproaches for identifying vanishing regression coefficients in that we\nidentify two important assumptions, called event equivalence and parameter\nmodularity, that when combined allow the construction of prior distributions\nfor multivariate normal parameters from a single prior Bayesian network\nspecified by a user.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:16:08 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 13:10:19 GMT"}, {"version": "v3", "created": "Sun, 27 Jun 2021 16:16:19 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Geiger", "Dan", ""], ["Heckerman", "David", ""]]}, {"id": "1302.6809", "submitter": "Dan Geiger", "authors": "Dan Geiger, Azaria Paz, Judea Pearl", "title": "On Testing Whether an Embedded Bayesian Network Represents a Probability\n  Model", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-244-252", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing the validity of probabilistic models containing unmeasured (hidden)\nvariables is shown to be a hard task. We show that the task of testing whether\nmodels are structurally incompatible with the data at hand, requires an\nexponential number of independence evaluations, each of the form: \"X is\nconditionally independent of Y, given Z.\" In contrast, a linear number of such\nevaluations is required to test a standard Bayesian network (one per vertex).\nOn the positive side, we show that if a network with hidden variables G has a\ntree skeleton, checking whether G represents a given probability model P\nrequires the polynomial number of such independence evaluations. Moreover, we\nprovide an algorithm that efficiently constructs a tree-structured Bayesian\nnetwork (with hidden variables) that represents P if such a network exists, and\nfurther recognizes when such a network does not exist.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:16:13 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Geiger", "Dan", ""], ["Paz", "Azaria", ""], ["Pearl", "Judea", ""]]}, {"id": "1302.6810", "submitter": "Robert P. Goldman", "authors": "Robert P. Goldman, Mark S. Boddy", "title": "Epsilon-Safe Planning", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-253-261", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an approach to high-level conditional planning we call\nepsilon-safe planning. This probabilistic approach commits us to planning to\nmeet some specified goal with a probability of success of at least 1-epsilon\nfor some user-supplied epsilon. We describe several algorithms for epsilon-safe\nplanning based on conditional planners. The two conditional planners we discuss\nare Peot and Smith's nonlinear conditional planner, CNLP, and our own linear\nconditional planner, PLINTH. We present a straightforward extension to\nconditional planners for which computing the necessary probabilities is simple,\nemploying a commonly-made but perhaps overly-strong independence assumption. We\nalso discuss a second approach to epsilon-safe planning which relaxes this\nindependence assumption, involving the incremental construction of a\nprobability dependence model in conjunction with the construction of the plan\ngraph.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:16:19 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Goldman", "Robert P.", ""], ["Boddy", "Mark S.", ""]]}, {"id": "1302.6811", "submitter": "Peter Haddawy", "authors": "Peter Haddawy", "title": "Generating Bayesian Networks from Probability Logic Knowledge Bases", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-262-269", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for dynamically generating Bayesian networks from\nknowledge bases consisting of first-order probability logic sentences. We\npresent a subset of probability logic sufficient for representing the class of\nBayesian networks with discrete-valued nodes. We impose constraints on the form\nof the sentences that guarantee that the knowledge base contains all the\nprobabilistic information necessary to generate a network. We define the\nconcept of d-separation for knowledge bases and prove that a knowledge base\nwith independence conditions defined by d-separation is a complete\nspecification of a probability distribution. We present a network generation\nalgorithm that, given an inference problem in the form of a query Q and a set\nof evidence E, generates a network to compute P(Q|E). We prove the algorithm to\nbe correct.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:16:25 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Haddawy", "Peter", ""]]}, {"id": "1302.6812", "submitter": "Peter Haddawy", "authors": "Peter Haddawy, AnHai Doan", "title": "Abstracting Probabilistic Actions", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-270-277", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the problem of abstracting conditional probabilistic\nactions. We identify two distinct types of abstraction: intra-action\nabstraction and inter-action abstraction. We define what it means for the\nabstraction of an action to be correct and then derive two methods of\nintra-action abstraction and two methods of inter-action abstraction which are\ncorrect according to this criterion. We illustrate the developed techniques by\napplying them to actions described with the temporal action representation used\nin the DRIPS decision-theoretic planner and we describe how the planner uses\nabstraction to reduce the complexity of planning.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:16:31 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Haddawy", "Peter", ""], ["Doan", "AnHai", ""]]}, {"id": "1302.6813", "submitter": "Petr Hajek", "authors": "Petr Hajek, Dagmar Harmancov\\'a, Francesc Esteva, Pere Garcia, Lluis\n  Godo", "title": "On Modal Logics for Qualitative Possibility in a Fuzzy Setting", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-278-285", "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the possibilistic approach to uncertainty modeling, the paper presents\na modal logical system to reason about qualitative (comparative) statements of\nthe possibility (and necessity) of fuzzy propositions. We relate this\nqualitative modal logic to the many--valued analogues MVS5 and MVKD45 of the\nwell known modal logics of knowledge and belief S5 and KD45 respectively.\nCompleteness results are obtained for such logics and therefore, they extend\nprevious existing results for qualitative possibilistic logics in the classical\nnon-fuzzy setting.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:16:37 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Hajek", "Petr", ""], ["Harmancov\u00e1", "Dagmar", ""], ["Esteva", "Francesc", ""], ["Garcia", "Pere", ""], ["Godo", "Lluis", ""]]}, {"id": "1302.6814", "submitter": "David Heckerman", "authors": "David Heckerman, John S. Breese", "title": "A New Look at Causal Independence", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-286-292", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heckerman (1993) defined causal independence in terms of a set of temporal\nconditional independence statements. These statements formalized certain types\nof causal interaction where (1) the effect is independent of the order that\ncauses are introduced and (2) the impact of a single cause on the effect does\nnot depend on what other causes have previously been applied. In this paper, we\nintroduce an equivalent a temporal characterization of causal independence\nbased on a functional representation of the relationship between causes and the\neffect. In this representation, the interaction between causes and effect can\nbe written as a nested decomposition of functions. Causal independence can be\nexploited by representing this decomposition in the belief network, resulting\nin representations that are more efficient for inference than general causal\nmodels. We present empirical results showing the benefits of a\ncausal-independence representation for belief-network inference.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:16:44 GMT"}, {"version": "v2", "created": "Sun, 17 May 2015 00:03:17 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Heckerman", "David", ""], ["Breese", "John S.", ""]]}, {"id": "1302.6815", "submitter": "David Heckerman", "authors": "David Heckerman, Dan Geiger, David Maxwell Chickering", "title": "Learning Bayesian Networks: The Combination of Knowledge and Statistical\n  Data", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-293-301", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe algorithms for learning Bayesian networks from a combination of\nuser knowledge and statistical data. The algorithms have two components: a\nscoring metric and a search procedure. The scoring metric takes a network\nstructure, statistical data, and a user's prior knowledge, and returns a score\nproportional to the posterior probability of the network structure given the\ndata. The search procedure generates networks for evaluation by the scoring\nmetric. Our contributions are threefold. First, we identify two important\nproperties of metrics, which we call event equivalence and parameter\nmodularity. These properties have been mostly ignored, but when combined,\ngreatly simplify the encoding of a user's prior knowledge. In particular, a\nuser can express her knowledge-for the most part-as a single prior Bayesian\nnetwork for the domain. Second, we describe local search and annealing\nalgorithms to be used in conjunction with scoring metrics. In the special case\nwhere each node has at most one parent, we show that heuristic search can be\nreplaced with a polynomial algorithm to identify the networks with the highest\nscore. Third, we describe a methodology for evaluating Bayesian-network\nlearning algorithms. We apply this approach to a comparison of metrics and\nsearch procedures.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:16:50 GMT"}, {"version": "v2", "created": "Sat, 16 May 2015 23:46:48 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Heckerman", "David", ""], ["Geiger", "Dan", ""], ["Chickering", "David Maxwell", ""]]}, {"id": "1302.6816", "submitter": "David Heckerman", "authors": "David Heckerman, Ross D. Shachter", "title": "A Decision-Based View of Causality", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-302-310", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most traditional models of uncertainty have focused on the associational\nrelationship among variables as captured by conditional dependence. In order to\nsuccessfully manage intelligent systems for decision making, however, we must\nbe able to predict the effects of actions. In this paper, we attempt to unite\ntwo branches of research that address such predictions: causal modeling and\ndecision analysis. First, we provide a definition of causal dependence in\ndecision-analytic terms, which we derive from consequences of causal dependence\ncited in the literature. Using this definition, we show how causal dependence\ncan be represented within an influence diagram. In particular, we identify two\ninadequacies of an ordinary influence diagram as a representation for cause. We\nintroduce a special class of influence diagrams, called causal influence\ndiagrams, which corrects one of these problems, and identify situations where\nthe other inadequacy can be eliminated. In addition, we describe the\nrelationships between Howard Canonical Form and existing graphical\nrepresentations of cause.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:16:56 GMT"}, {"version": "v2", "created": "Sat, 16 May 2015 23:48:17 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Heckerman", "David", ""], ["Shachter", "Ross D.", ""]]}, {"id": "1302.6817", "submitter": "Jochen Heinsohn", "authors": "Jochen Heinsohn", "title": "Probabilistic Description Logics", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-311-318", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On the one hand, classical terminological knowledge representation excludes\nthe possibility of handling uncertain concept descriptions involving, e.g.,\n\"usually true\" concept properties, generalized quantifiers, or exceptions. On\nthe other hand, purely numerical approaches for handling uncertainty in general\nare unable to consider terminological knowledge. This paper presents the\nlanguage ACP which is a probabilistic extension of terminological logics and\naims at closing the gap between the two areas of research. We present the\nformal semantics underlying the language ALUP and introduce the probabilistic\nformalism that is based on classes of probabilities and is realized by means of\nprobabilistic constraints. Besides inferring implicitly existent probabilistic\nrelationships, the constraints guarantee terminological and probabilistic\nconsistency. Altogether, the new language ALUP applies to domains where both\nterm descriptions and uncertainty have to be handled.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:17:01 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Heinsohn", "Jochen", ""]]}, {"id": "1302.6818", "submitter": "Max Henrion", "authors": "Max Henrion, Gregory M. Provan, Brendan del Favero, Gillian Sanders", "title": "An Experimental Comparison of Numerical and Qualitative Probabilistic\n  Reasoning", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-319-326", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Qualitative and infinitesimal probability schemes are consistent with the\naxioms of probability theory, but avoid the need for precise numerical\nprobabilities. Using qualitative probabilities could substantially reduce the\neffort for knowledge engineering and improve the robustness of results. We\nexamine experimentally how well infinitesimal probabilities (the kappa-calculus\nof Goldszmidt and Pearl) perform a diagnostic task - troubleshooting a car that\nwill not start by comparison with a conventional numerical belief network. We\nfound the infinitesimal scheme to be as good as the numerical scheme in\nidentifying the true fault. The performance of the infinitesimal scheme worsens\nsignificantly for prior fault probabilities greater than 0.03. These results\nsuggest that infinitesimal probability methods may be of substantial practical\nvalue for machine diagnosis with small prior fault probabilities.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:17:07 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Henrion", "Max", ""], ["Provan", "Gregory M.", ""], ["del Favero", "Brendan", ""], ["Sanders", "Gillian", ""]]}, {"id": "1302.6819", "submitter": "Bernhard Hollunder", "authors": "Bernhard Hollunder", "title": "An Alternative Proof Method for Possibilistic Logic and its Application\n  to Terminological Logics", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-327-335", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Possibilistic logic, an extension of first-order logic, deals with\nuncertainty that can be estimated in terms of possibility and necessity\nmeasures. Syntactically, this means that a first-order formula is equipped with\na possibility degree or a necessity degree that expresses to what extent the\nformula is possibly or necessarily true. Possibilistic resolution yields a\ncalculus for possibilistic logic which respects the semantics developed for\npossibilistic logic. A drawback, which possibilistic resolution inherits from\nclassical resolution, is that it may not terminate if applied to formulas\nbelonging to decidable fragments of first-order logic. Therefore we propose an\nalternative proof method for possibilistic logic. The main feature of this\nmethod is that it completely abstracts from a concrete calculus but uses as\nbasic operation a test for classical entailment. We then instantiate\npossibilistic logic with a terminological logic, which is a decidable subclass\no f first-order logic but nevertheless much more expressive than propositional\nlogic. This yields an extension of terminological logics towards the\nrepresentation of uncertain knowledge which is satisfactory from a semantic as\nwell as algorithmic point of view.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:17:13 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Hollunder", "Bernhard", ""]]}, {"id": "1302.6820", "submitter": "Yen-Teh Hsia", "authors": "Yen-Teh Hsia", "title": "Possibilistic Conditioning and Propagation", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-336-343", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an axiomatization of confidence transfer - a known conditioning\nscheme - from the perspective of expectation-based inference in the sense of\nGardenfors and Makinson. Then, we use the notion of belief independence to\n\"filter out\" different proposal s of possibilistic conditioning rules, all are\nvariations of confidence transfer. Among the three rules that we consider, only\nDempster's rule of conditioning passes the test of supporting the notion of\nbelief independence. With the use of this conditioning rule, we then show that\nwe can use local computation for computing desired conditional marginal\npossibilities of the joint possibility satisfying the given constraints. It\nturns out that our local computation scheme is already proposed by Shenoy.\nHowever, our intuitions are completely different from that of Shenoy. While\nShenoy just defines a local computation scheme that fits his framework of\nvaluation-based systems, we derive that local computation scheme from II(,8) =\ntI(,8 I a) * II(a) and appropriate independence assumptions, just like how the\nBayesians derive their local computation scheme.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:17:19 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Hsia", "Yen-Teh", ""]]}, {"id": "1302.6821", "submitter": "Marcus J. Huber", "authors": "Marcus J. Huber, Edmund H. Durfee, Michael P. Wellman", "title": "The Automated Mapping of Plans for Plan Recognition", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-344-351", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To coordinate with other agents in its environment, an agent needs models of\nwhat the other agents are trying to do. When communication is impossible or\nexpensive, this information must be acquired indirectly via plan recognition.\nTypical approaches to plan recognition start with a specification of the\npossible plans the other agents may be following, and develop special\ntechniques for discriminating among the possibilities. Perhaps more desirable\nwould be a uniform procedure for mapping plans to general structures supporting\ninference based on uncertain and incomplete observations. In this paper, we\ndescribe a set of methods for converting plans represented in a flexible\nprocedural language to observation models represented as probabilistic belief\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:17:25 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Huber", "Marcus J.", ""], ["Durfee", "Edmund H.", ""], ["Wellman", "Michael P.", ""]]}, {"id": "1302.6822", "submitter": "Manfred Jaeger", "authors": "Manfred Jaeger", "title": "A Logic for Default Reasoning About Probabilities", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-352-359", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A logic is defined that allows to express information about statistical\nprobabilities and about degrees of belief in specific propositions. By\ninterpreting the two types of probabilities in one common probability space,\nthe semantics given are well suited to model the influence of statistical\ninformation on the formation of subjective beliefs. Cross entropy minimization\nis a key element in these semantics, the use of which is justified by showing\nthat the resulting logic exhibits some very reasonable properties.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:17:31 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Jaeger", "Manfred", ""]]}, {"id": "1302.6823", "submitter": "Finn Verner Jensen", "authors": "Finn Verner Jensen, Frank Jensen", "title": "Optimal Junction Trees", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-360-366", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper deals with optimality issues in connection with updating beliefs in\nnetworks. We address two processes: triangulation and construction of junction\ntrees. In the first part, we give a simple algorithm for constructing an\noptimal junction tree from a triangulated network. In the second part, we argue\nthat any exact method based on local calculations must either be less efficient\nthan the junction tree method, or it has an optimality problem equivalent to\nthat of triangulation.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:17:36 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Jensen", "Finn Verner", ""], ["Jensen", "Frank", ""]]}, {"id": "1302.6824", "submitter": "Frank Jensen", "authors": "Frank Jensen, Finn Verner Jensen, Soren L. Dittmer", "title": "From Influence Diagrams to Junction Trees", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-367-373", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to the solution of decision problems formulated as\ninfluence diagrams. This approach involves a special triangulation of the\nunderlying graph, the construction of a junction tree with special properties,\nand a message passing algorithm operating on the junction tree for computation\nof expected utilities and optimal decision policies.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:17:42 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Jensen", "Frank", ""], ["Jensen", "Finn Verner", ""], ["Dittmer", "Soren L.", ""]]}, {"id": "1302.6825", "submitter": "Uffe Kj{\\ae}rulff", "authors": "Uffe Kj{\\ae}rulff", "title": "Reduction of Computational Complexity in Bayesian Networks through\n  Removal of Weak Dependencies", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-374-382", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a method for reducing the computational complexity of\nBayesian networks through identification and removal of weak dependencies\n(removal of links from the (moralized) independence graph). The removal of a\nsmall number of links may reduce the computational complexity dramatically,\nsince several fill-ins and moral links may be rendered superfluous by the\nremoval. The method is described in terms of impact on the independence graph,\nthe junction tree, and the potential functions associated with these. An\nempirical evaluation of the method using large real-world networks demonstrates\nthe applicability of the method. Further, the method, which has been\nimplemented in Hugin, complements the approximation method suggested by Jensen\n& Andersen (1990).\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:17:48 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Kj\u00e6rulff", "Uffe", ""]]}, {"id": "1302.6826", "submitter": "Wai Lam", "authors": "Wai Lam, Fahiem Bacchus", "title": "Using New Data to Refine a Bayesian Network", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-383-390", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the issue of refining an existent Bayesian network structure using\nnew data which might mention only a subset of the variables. Most previous\nworks have only considered the refinement of the network's conditional\nprobability parameters, and have not addressed the issue of refining the\nnetwork's structure. We develop a new approach for refining the network's\nstructure. Our approach is based on the Minimal Description Length (MDL)\nprinciple, and it employs an adapted version of a Bayesian network learning\nalgorithm developed in our previous work. One of the adaptations required is to\nmodify the previous algorithm to account for the structure of the existent\nnetwork. The learning algorithm generates a partial network structure which can\nthen be used to improve the existent network. We also present experimental\nevidence demonstrating the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:17:54 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Lam", "Wai", ""], ["Bacchus", "Fahiem", ""]]}, {"id": "1302.6827", "submitter": "Jerome Lang", "authors": "Jerome Lang", "title": "Syntax-based Default Reasoning as Probabilistic Model-based Diagnosis", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-391-398", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We view the syntax-based approaches to default reasoning as a model-based\ndiagnosis problem, where each source giving a piece of information is\nconsidered as a component. It is formalized in the ATMS framework (each source\ncorresponds to an assumption). We assume then that all sources are independent\nand \"fail\" with a very small probability. This leads to a probability\nassignment on the set of candidates, or equivalently on the set of consistent\nenvironments. This probability assignment induces a Dempster-Shafer belief\nfunction which measures the probability that a proposition can be deduced from\nthe evidence. This belief function can be used in several different ways to\ndefine a non-monotonic consequence relation. We study and compare these\nconsequence relations. The -case of prioritized knowledge bases is briefly\nconsidered.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:18:00 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Lang", "Jerome", ""]]}, {"id": "1302.6829", "submitter": "Stephane Lapointe", "authors": "Stephane Lapointe, Rene Proulx", "title": "Fuzzy Geometric Relations to Represent Hierarchical Spatial Information", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-407-415", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A model to represent spatial information is presented in this paper. It is\nbased on fuzzy constraints represented as fuzzy geometric relations that can be\nhierarchically structured. The concept of spatial template is introduced to\ncapture the idea of interrelated objects in two-dimensional space. The\nrepresentation model is used to specify imprecise or vague information\nconsisting in relative locations and orientations of template objects. It is\nshown in this paper how a template represented by this model can be matched\nagainst a crisp situation to recognize a particular instance of this template.\nFurthermore, the proximity measure (fuzzy measure) between the instance and the\ntemplate is worked out - this measure can be interpreted as a degree of\nsimilarity. In this context, template recognition can be viewed as a case of\nfuzzy pattern recognition. The results of this work have been implemented and\napplied to a complex military problem from which this work originated.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:18:12 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Lapointe", "Stephane", ""], ["Proulx", "Rene", ""]]}, {"id": "1302.6830", "submitter": "Paul E. Lehner", "authors": "Paul E. Lehner, Christopher Elsaesser, Scott A. Musman", "title": "Constructing Belief Networks to Evaluate Plans", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-416-422", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines the problem of constructing belief networks to evaluate\nplans produced by an knowledge-based planner. Techniques are presented for\nhandling various types of complicating plan features. These include plans with\ncontext-dependent consequences, indirect consequences, actions with\npreconditions that must be true during the execution of an action,\ncontingencies, multiple levels of abstraction multiple execution agents with\npartially-ordered and temporally overlapping actions, and plans which reference\nspecific times and time durations.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:18:18 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Lehner", "Paul E.", ""], ["Elsaesser", "Christopher", ""], ["Musman", "Scott A.", ""]]}, {"id": "1302.6831", "submitter": "Todd Michael Mansell", "authors": "Todd Michael Mansell, Grahame Smith", "title": "Operator Selection While Planning Under Uncertainty", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-423-431", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the best first search strategy used by U-Plan (Mansell\n1993a), a planning system that constructs quantitatively ranked plans given an\nincomplete description of an uncertain environment. U-Plan uses uncertain and\nincomplete evidence de scribing the environment, characterizes it using a\nDempster-Shafer interval, and generates a set of possible world states. Plan\nconstruction takes place in an abstraction hierarchy where strategic decisions\nare made before tactical decisions. Search through this abstraction hierarchy\nis guided by a quantitative measure (expected fulfillment) based on decision\ntheory. The search strategy is best first with the provision to update expected\nfulfillment and review previous decisions in the light of planning\ndevelopments. U-Plan generates multiple plans for multiple possible worlds, and\nattempts to use existing plans for new world situations. A super-plan is then\nconstructed, based on merging the set of plans and appropriately timed\nknowledge acquisition operators, which are used to decide between plan\nalternatives during plan execution.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:18:23 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Mansell", "Todd Michael", ""], ["Smith", "Grahame", ""]]}, {"id": "1302.6832", "submitter": "Wolfgang Nejdl", "authors": "Wolfgang Nejdl, Johann Gamper", "title": "Model-Based Diagnosis with Qualitative Temporal Uncertainty", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-432-439", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe a framework for model-based diagnosis of dynamic\nsystems, which extends previous work in this field by using and expressing\ntemporal uncertainty in the form of qualitative interval relations a la Allen.\nBased on a logical framework extended by qualitative and quantitative temporal\nconstraints we show how to describe behavioral models (both consistency- and\nabductive-based), discuss how to use abstract observations and show how\nabstract temporal diagnoses are computed. This yields an expressive framework,\nwhich allows the representation of complex temporal behavior allowing us to\nrepresent temporal uncertainty. Due to its abstraction capabilities computation\nis made independent of the number of observations and time points in a temporal\nsetting. An example of hepatitis diagnosis is used throughout the paper.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:18:29 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Nejdl", "Wolfgang", ""], ["Gamper", "Johann", ""]]}, {"id": "1302.6833", "submitter": "Keung-Chi Ng", "authors": "Keung-Chi Ng, Tod S. Levitt", "title": "Incremental Dynamic Construction of Layered Polytree Networks", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-440-446", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Certain classes of problems, including perceptual data understanding,\nrobotics, discovery, and learning, can be represented as incremental,\ndynamically constructed belief networks. These automatically constructed\nnetworks can be dynamically extended and modified as evidence of new\nindividuals becomes available. The main result of this paper is the incremental\nextension of the singly connected polytree network in such a way that the\nnetwork retains its singly connected polytree structure after the changes. The\nalgorithm is deterministic and is guaranteed to have a complexity of single\nnode addition that is at most of order proportional to the number of nodes (or\nsize) of the network. Additional speed-up can be achieved by maintaining the\npath information. Despite its incremental and dynamic nature, the algorithm can\nalso be used for probabilistic inference in belief networks in a fashion\nsimilar to other exact inference algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:18:35 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Ng", "Keung-Chi", ""], ["Levitt", "Tod S.", ""]]}, {"id": "1302.6835", "submitter": "Judea Pearl", "authors": "Judea Pearl", "title": "A Probabilistic Calculus of Actions", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-454-462", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a symbolic machinery that admits both probabilistic and causal\ninformation about a given domain and produces probabilistic statements about\nthe effect of actions and the impact of observations. The calculus admits two\ntypes of conditioning operators: ordinary Bayes conditioning, P(y|X = x), which\nrepresents the observation X = x, and causal conditioning, P(y|do(X = x)), read\nthe probability of Y = y conditioned on holding X constant (at x) by deliberate\naction. Given a mixture of such observational and causal sentences, together\nwith the topology of the causal graph, the calculus derives new conditional\nprobabilities of both types, thus enabling one to quantify the effects of\nactions (and policies) from partially specified knowledge bases, such as\nBayesian networks in which some conditional probabilities may not be available.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:18:47 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Pearl", "Judea", ""]]}, {"id": "1302.6836", "submitter": "Stephen G. Pimentel", "authors": "Stephen G. Pimentel, Lawrence M. Brem", "title": "Robust Planning in Uncertain Environments", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-463-469", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a novel approach to planning which takes advantage of\ndecision theory to greatly improve robustness in an uncertain environment. We\npresent an algorithm which computes conditional plans of maximum expected\nutility. This algorithm relies on a representation of the search space as an\nAND/OR tree and employs a depth-limit to control computation costs. A numeric\nrobustness factor, which parameterizes the utility function, allows the user to\nmodulate the degree of risk-aversion employed by the planner. Via a look-ahead\nsearch, the planning algorithm seeks to find an optimal plan using expected\nutility as its optimization criterion. We present experimental results obtained\nby applying our algorithm to a non-deterministic extension of the blocks world\ndomain. Our results demonstrate that the robustness factor governs the degree\nof risk embodied in the conditional plans computed by our algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:18:53 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Pimentel", "Stephen G.", ""], ["Brem", "Lawrence M.", ""]]}, {"id": "1302.6837", "submitter": "Michael Pittarelli", "authors": "Michael Pittarelli", "title": "Anytime Decision Making with Imprecise Probabilities", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-470-477", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines methods of decision making that are able to accommodate\nlimitations on both the form in which uncertainty pertaining to a decision\nproblem can be realistically represented and the amount of computing time\navailable before a decision must be made. The methods are anytime algorithms in\nthe sense of Boddy and Dean 1991. Techniques are presented for use with Frisch\nand Haddawy's [1992] anytime deduction system, with an anytime adaptation of\nNilsson's [1986] probabilistic logic, and with a probabilistic database model.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:18:58 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Pittarelli", "Michael", ""]]}, {"id": "1302.6838", "submitter": "William B. Poland", "authors": "William B. Poland, Ross D. Shachter", "title": "Three Approaches to Probability Model Selection", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-478-483", "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper compares three approaches to the problem of selecting among\nprobability models to fit data (1) use of statistical criteria such as Akaike's\ninformation criterion and Schwarz's \"Bayesian information criterion,\" (2)\nmaximization of the posterior probability of the model, and (3) maximization of\nan effectiveness ratio? trading off accuracy and computational cost. The\nunifying characteristic of the approaches is that all can be viewed as\nmaximizing a penalized likelihood function. The second approach with suitable\nprior distributions has been shown to reduce to the first. This paper shows\nthat the third approach reduces to the second for a particular form of the\neffectiveness ratio, and illustrates all three approaches with the problem of\nselecting the number of components in a mixture of Gaussian distributions.\nUnlike the first two approaches, the third can be used even when the candidate\nmodels are chosen for computational efficiency, without regard to physical\ninterpretation, so that the likelihood and the prior distribution over models\ncannot be interpreted literally. As the most general and computationally\noriented of the approaches, it is especially useful for artificial intelligence\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:19:04 GMT"}], "update_date": "2016-11-04", "authors_parsed": [["Poland", "William B.", ""], ["Shachter", "Ross D.", ""]]}, {"id": "1302.6839", "submitter": "Malcolm Pradhan", "authors": "Malcolm Pradhan, Gregory M. Provan, Blackford Middleton, Max Henrion", "title": "Knowledge Engineering for Large Belief Networks", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-484-490", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present several techniques for knowledge engineering of large belief\nnetworks (BNs) based on the our experiences with a network derived from a large\nmedical knowledge base. The noisyMAX, a generalization of the noisy-OR gate, is\nused to model causal in dependence in a BN with multi-valued variables. We\ndescribe the use of leak probabilities to enforce the closed-world assumption\nin our model. We present Netview, a visualization tool based on causal\nindependence and the use of leak probabilities. The Netview software allows\nknowledge engineers to dynamically view sub-networks for knowledge engineering,\nand it provides version control for editing a BN. Netview generates\nsub-networks in which leak probabilities are dynamically updated to reflect the\nmissing portions of the network.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:19:10 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Pradhan", "Malcolm", ""], ["Provan", "Gregory M.", ""], ["Middleton", "Blackford", ""], ["Henrion", "Max", ""]]}, {"id": "1302.6840", "submitter": "Runping Qi", "authors": "Runping Qi, Nevin Lianwen Zhang, David L. Poole", "title": "Solving Asymmetric Decision Problems with Influence Diagrams", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-491-497", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While influence diagrams have many advantages as a representation framework\nfor Bayesian decision problems, they have a serious drawback in handling\nasymmetric decision problems. To be represented in an influence diagram, an\nasymmetric decision problem must be symmetrized. A considerable amount of\nunnecessary computation may be involved when a symmetrized influence diagram is\nevaluated by conventional algorithms. In this paper we present an approach for\navoiding such unnecessary computation in influence diagram evaluation.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:19:16 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Qi", "Runping", ""], ["Zhang", "Nevin Lianwen", ""], ["Poole", "David L.", ""]]}, {"id": "1302.6841", "submitter": "Marco Ramoni", "authors": "Marco Ramoni, Alberto Riva", "title": "Belief Maintenance in Bayesian Networks", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-498-505", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Belief Networks (BBNs) are a powerful formalism for reasoning under\nuncertainty but bear some severe limitations: they require a large amount of\ninformation before any reasoning process can start, they have limited\ncontradiction handling capabilities, and their ability to provide explanations\nfor their conclusion is still controversial. There exists a class of reasoning\nsystems, called Truth Maintenance Systems (TMSs), which are able to deal with\npartially specified knowledge, to provide well-founded explanation for their\nconclusions, and to detect and handle contradictions. TMSs incorporating\nmeasure of uncertainty are called Belief Maintenance Systems (BMSs). This paper\ndescribes how a BMS based on probabilistic logic can be applied to BBNs, thus\nintroducing a new class of BBNs, called Ignorant Belief Networks, able to\nincrementally deal with partially specified conditional dependencies, to\nprovide explanations, and to detect and handle contradictions.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:19:22 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Ramoni", "Marco", ""], ["Riva", "Alberto", ""]]}, {"id": "1302.6842", "submitter": "Eugene Santos Jr.", "authors": "Eugene Santos Jr., Solomon Eyal Shimony", "title": "Belief Updating by Enumerating High-Probability Independence-Based\n  Assignments", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-506-513", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Independence-based (IB) assignments to Bayesian belief networks were\noriginally proposed as abductive explanations. IB assignments assign fewer\nvariables in abductive explanations than do schemes assigning values to all\nevidentially supported variables. We use IB assignments to approximate marginal\nprobabilities in Bayesian belief networks. Recent work in belief updating for\nBayes networks attempts to approximate posterior probabilities by finding a\nsmall number of the highest probability complete (or perhaps evidentially\nsupported) assignments. Under certain assumptions, the probability mass in the\nunion of these assignments is sufficient to obtain a good approximation. Such\nmethods are especially useful for highly-connected networks, where the maximum\nclique size or the cutset size make the standard algorithms intractable. Since\nIB assignments contain fewer assigned variables, the probability mass in each\nassignment is greater than in the respective complete assignment. Thus, fewer\nIB assignments are sufficient, and a good approximation can be obtained more\nefficiently. IB assignments can be used for efficiently approximating posterior\nnode probabilities even in cases which do not obey the rather strict skewness\nassumptions used in previous research. Two algorithms for finding the high\nprobability IB assignments are suggested: one by doing a best-first heuristic\nsearch, and another by special-purpose integer linear programming. Experimental\nresults show that this approach is feasible for highly connected belief\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:19:28 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Santos", "Eugene", "Jr."], ["Shimony", "Solomon Eyal", ""]]}, {"id": "1302.6843", "submitter": "Ross D. Shachter", "authors": "Ross D. Shachter, Stig K. Andersen, Peter Szolovits", "title": "Global Conditioning for Probabilistic Inference in Belief Networks", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-514-522", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new approach to probabilistic inference on belief\nnetworks, global conditioning, which is a simple generalization of Pearl's\n(1986b) method of loopcutset conditioning. We show that global conditioning, as\nwell as loop-cutset conditioning, can be thought of as a special case of the\nmethod of Lauritzen and Spiegelhalter (1988) as refined by Jensen et al (199Oa;\n1990b). Nonetheless, this approach provides new opportunities for parallel\nprocessing and, in the case of sequential processing, a tradeoff of time for\nmemory. We also show how a hybrid method (Suermondt and others 1990) combining\nloop-cutset conditioning with Jensen's method can be viewed within our\nframework. By exploring the relationships between these methods, we develop a\nunifying framework in which the advantages of each approach can be combined\nsuccessfully.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:19:34 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Shachter", "Ross D.", ""], ["Andersen", "Stig K.", ""], ["Szolovits", "Peter", ""]]}, {"id": "1302.6844", "submitter": "Philippe Smets", "authors": "Philippe Smets", "title": "Belief Induced by the Partial Knowledge of the Probabilities", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-523-532", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct the belief function that quantifies the agent, beliefs about\nwhich event of Q will occurred when he knows that the event is selected by a\nchance set-up and that the probability function associated to the chance set up\nis only partially known.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:19:41 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Smets", "Philippe", ""]]}, {"id": "1302.6845", "submitter": "Paul Snow", "authors": "Paul Snow", "title": "Ignorance and the Expressiveness of Single- and Set-Valued Probability\n  Models of Belief", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-531-537", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over time, there have hen refinements in the way that probability\ndistributions are used for representing beliefs. Models which rely on single\nprobability distributions depict a complete ordering among the propositions of\ninterest, yet human beliefs are sometimes not completely ordered. Non-singleton\nsets of probability distributions can represent partially ordered beliefs.\nConvex sets are particularly convenient and expressive, but it is known that\nthere are reasonable patterns of belief whose faithful representation require\nless restrictive sets. The present paper shows that prior ignorance about three\nor more exclusive alternatives and the emergence of partially ordered beliefs\nwhen evidence is obtained defy representation by any single set of\ndistributions, but yield to a representation baud on several uts. The partial\norder is shown to be a partial qualitative probability which shares some\nintuitively appealing attributes with probability distributions.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:19:46 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Snow", "Paul", ""]]}, {"id": "1302.6846", "submitter": "Sampath Srinivas", "authors": "Sampath Srinivas", "title": "A Probabilistic Approach to Hierarchical Model-based Diagnosis", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-538-545", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based diagnosis reasons backwards from a functional schematic of a\nsystem to isolate faults given observations of anomalous behavior. We develop a\nfully probabilistic approach to model based diagnosis and extend it to support\nhierarchical models. Our scheme translates the functional schematic into a\nBayesian network and diagnostic inference takes place in the Bayesian network.\nA Bayesian network diagnostic inference algorithm is modified to take advantage\nof the hierarchy to give computational gains.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:19:52 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Srinivas", "Sampath", ""]]}, {"id": "1302.6847", "submitter": "Milan Studeny", "authors": "Milan Studeny", "title": "Semigraphoids Are Two-Antecedental Approximations of Stochastic\n  Conditional Independence Models", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-546-552", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The semigraphoid closure of every couple of CI-statements (GI=conditional\nindependence) is a stochastic CI-model. As a consequence of this result it is\nshown that every probabilistically sound inference rule for CI-model, having at\nmost two antecedents, is derivable from the semigraphoid inference rules. This\njustifies the use of semigraphoids as approximations of stochastic CI-models in\nprobabilistic reasoning. The list of all 19 potential dominant elements of the\nmentioned semigraphoid closure is given as a byproduct.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:19:58 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Studeny", "Milan", ""]]}, {"id": "1302.6848", "submitter": "Sek-Wah Tan", "authors": "Sek-Wah Tan", "title": "Exceptional Subclasses in Qualitative Probability", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-553-559", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  System Z+ [Goldszmidt and Pearl, 1991, Goldszmidt, 1992] is a formalism for\nreasoning with normality defaults of the form \"typically if phi then + (with\nstrength cf)\" where 6 is a positive integer. The system has a critical\nshortcoming in that it does not sanction inheritance across exceptional\nsubclasses. In this paper we propose an extension to System Z+ that rectifies\nthis shortcoming by extracting additional conditions between worlds from the\ndefaults database. We show that the additional constraints do not change the\nnotion of the consistency of a database. We also make comparisons with\ncompeting default reasoning systems.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:20:04 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Tan", "Sek-Wah", ""]]}, {"id": "1302.6849", "submitter": "Pei Wang", "authors": "Pei Wang", "title": "A Defect in Dempster-Shafer Theory", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-560-566", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By analyzing the relationships among chance, weight of evidence and degree of\nbeliefwe show that the assertion \"probability functions are special cases of\nbelief functions\" and the assertion \"Dempster's rule can be used to combine\nbelief functions based on distinct bodies of evidence\" together lead to an\ninconsistency in Dempster-Shafer theory. To solve this problem, we must reject\nsome fundamental postulates of the theory. We introduce a new approach for\nuncertainty management that shares many intuitive ideas with D-S theory, while\navoiding this problem.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:20:10 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Wang", "Pei", ""]]}, {"id": "1302.6850", "submitter": "Michael P. Wellman", "authors": "Michael P. Wellman, Chao-Lin Liu", "title": "State-space Abstraction for Anytime Evaluation of Probabilistic Networks", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-567-574", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One important factor determining the computational complexity of evaluating a\nprobabilistic network is the cardinality of the state spaces of the nodes. By\nvarying the granularity of the state spaces, one can trade off accuracy in the\nresult for computational efficiency. We present an anytime procedure for\napproximate evaluation of probabilistic networks based on this idea. On\napplication to some simple networks, the procedure exhibits a smooth\nimprovement in approximation quality as computation time increases. This\nsuggests that state-space abstraction is one more useful control parameter for\ndesigning real-time probabilistic reasoners.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:20:17 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Wellman", "Michael P.", ""], ["Liu", "Chao-Lin", ""]]}, {"id": "1302.6851", "submitter": "Emil Weydert", "authors": "Emil Weydert", "title": "General Belief Measures", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-575-582", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probability measures by themselves, are known to be inappropriate for\nmodeling the dynamics of plain belief and their excessively strong\nmeasurability constraints make them unsuitable for some representational tasks,\ne.g. in the context of firstorder knowledge. In this paper, we are therefore\ngoing to look for possible alternatives and extensions. We begin by delimiting\nthe general area of interest, proposing a minimal list of assumptions to be\nsatisfied by any reasonable quasi-probabilistic valuation concept. Within this\nframework, we investigate two particularly interesting kinds of quasi-measures\nwhich are not or much less affected by the traditional problems. * Ranking\nmeasures, which generalize Spohn-type and possibility measures. * Cumulative\nmeasures, which combine the probabilistic and the ranking philosophy, allowing\nthereby a fine-grained account of static and dynamic belief.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:20:23 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Weydert", "Emil", ""]]}, {"id": "1302.6852", "submitter": "Nic Wilson", "authors": "Nic Wilson", "title": "Generating Graphoids from Generalised Conditional Probability", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-583-590", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We take a general approach to uncertainty on product spaces, and give\nsufficient conditions for the independence structures of uncertainty measures\nto satisfy graphoid properties. Since these conditions are arguably more\nintuitive than some of the graphoid properties, they can be viewed as\nexplanations why probability and certain other formalisms generate graphoids.\nThe conditions include a sufficient condition for the Intersection property\nwhich can still apply even if there is a strong logical relations hip between\nthe variables. We indicate how these results can be used to produce theories of\nqualitative conditional probability which are semi-graphoids and graphoids.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:20:29 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Wilson", "Nic", ""]]}, {"id": "1302.6853", "submitter": "Michael S. K. M. Wong", "authors": "Michael S. K. M. Wong, Z. W. Wang", "title": "On Axiomatization of Probabilistic Conditional Independencies", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-591-597", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the connection between probabilistic conditional\nindependence in uncertain reasoning and data dependency in relational\ndatabases. As a demonstration of the usefulness of this preliminary\ninvestigation, an alternate proof is presented for refuting the conjecture\nsuggested by Pearl and Paz that probabilistic conditional independencies have a\ncomplete axiomatization.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:20:35 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Wong", "Michael S. K. M.", ""], ["Wang", "Z. W.", ""]]}, {"id": "1302.6854", "submitter": "Hong Xu", "authors": "Hong Xu, Philippe Smets", "title": "Evidential Reasoning with Conditional Belief Functions", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-598-605", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the existing evidential networks with belief functions, the relations\namong the variables are always represented by joint belief functions on the\nproduct space of the involved variables. In this paper, we use conditional\nbelief functions to represent such relations in the network and show some\nrelations of these two kinds of representations. We also present a propagation\nalgorithm for such networks. By analyzing the properties of some special\nevidential networks with conditional belief functions, we show that the\nreasoning process can be simplified in such kinds of networks.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:20:41 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Xu", "Hong", ""], ["Smets", "Philippe", ""]]}, {"id": "1302.6855", "submitter": "Nevin Lianwen Zhang", "authors": "Nevin Lianwen Zhang, David L Poole", "title": "Inter-causal Independence and Heterogeneous Factorization", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-606-614", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that conditional independence can be used to factorize a\njoint probability into a multiplication of conditional probabilities. This\npaper proposes a constructive definition of inter-causal independence, which\ncan be used to further factorize a conditional probability. An inference\nalgorithm is developed, which makes use of both conditional independence and\ninter-causal independence to reduce inference complexity in Bayesian networks.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:20:47 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Zhang", "Nevin Lianwen", ""], ["Poole", "David L", ""]]}, {"id": "1302.7056", "submitter": "Wesam Elshamy", "authors": "Wesam Elshamy, Doina Caragea, William Hsu", "title": "KSU KDD: Word Sense Induction by Clustering in Topic Space", "comments": null, "journal-ref": "Proceedings of the 5th International Workshop on Semantic\n  Evaluation, pages 367-370, Uppsala, Sweden, July 2010. Association for\n  Computational Linguistics", "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe our language-independent unsupervised word sense induction\nsystem. This system only uses topic features to cluster different word senses\nin their global context topic space. Using unlabeled data, this system trains a\nlatent Dirichlet allocation (LDA) topic model then uses it to infer the topics\ndistribution of the test instances. By clustering these topics distributions in\ntheir topic space we cluster them into different senses. Our hypothesis is that\ncloseness in topic space reflects similarity between different word senses.\nThis system participated in SemEval-2 word sense induction and disambiguation\ntask and achieved the second highest V-measure score among all other systems.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2013 02:10:38 GMT"}], "update_date": "2015-03-06", "authors_parsed": [["Elshamy", "Wesam", ""], ["Caragea", "Doina", ""], ["Hsu", "William", ""]]}, {"id": "1302.7175", "submitter": "Hado van Hasselt", "authors": "Hado van Hasselt", "title": "Estimating the Maximum Expected Value: An Analysis of (Nested) Cross\n  Validation and the Maximum Sample Average", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the accuracy of the two most common estimators for the maximum\nexpected value of a general set of random variables: a generalization of the\nmaximum sample average, and cross validation. No unbiased estimator exists and\nwe show that it is non-trivial to select a good estimator without knowledge\nabout the distributions of the random variables. We investigate and bound the\nbias and variance of the aforementioned estimators and prove consistency. The\nvariance of cross validation can be significantly reduced, but not without\nrisking a large bias. The bias and variance of different variants of cross\nvalidation are shown to be very problem-dependent, and a wrong choice can lead\nto very inaccurate estimates.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2013 12:48:32 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2013 15:04:48 GMT"}], "update_date": "2013-03-04", "authors_parsed": [["van Hasselt", "Hado", ""]]}, {"id": "1302.7251", "submitter": "Sofie De Clercq", "authors": "Sofie De Clercq and Steven Schockaert and Martine De Cock and Ann\n  Now\\'e", "title": "Modeling Stable Matching Problems with Answer Set Programming", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Stable Marriage Problem (SMP) is a well-known matching problem first\nintroduced and solved by Gale and Shapley (1962). Several variants and\nextensions to this problem have since been investigated to cover a wider set of\napplications. Each time a new variant is considered, however, a new algorithm\nneeds to be developed and implemented. As an alternative, in this paper we\npropose an encoding of the SMP using Answer Set Programming (ASP). Our encoding\ncan easily be extended and adapted to the needs of specific applications. As an\nillustration we show how stable matchings can be found when individuals may\ndesignate unacceptable partners and ties between preferences are allowed.\nSubsequently, we show how our ASP based encoding naturally allows us to select\nspecific stable matchings which are optimal according to a given criterion.\nEach time, we can rely on generic and efficient off-the-shelf answer set\nsolvers to find (optimal) stable matchings.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2013 16:43:43 GMT"}, {"version": "v2", "created": "Thu, 2 May 2013 05:39:33 GMT"}], "update_date": "2013-05-03", "authors_parsed": [["De Clercq", "Sofie", ""], ["Schockaert", "Steven", ""], ["De Cock", "Martine", ""], ["Now\u00e9", "Ann", ""]]}]