[{"id": "1809.00088", "submitter": "Jing Qian", "authors": "Jing Qian, Mai ElSherief, Elizabeth Belding, William Yang Wang", "title": "Hierarchical CVAE for Fine-Grained Hate Speech Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing work on automated hate speech detection typically focuses on binary\nclassification or on differentiating among a small set of categories. In this\npaper, we propose a novel method on a fine-grained hate speech classification\ntask, which focuses on differentiating among 40 hate groups of 13 different\nhate group categories. We first explore the Conditional Variational Autoencoder\n(CVAE) as a discriminative model and then extend it to a hierarchical\narchitecture to utilize the additional hate category information for more\naccurate prediction. Experimentally, we show that incorporating the hate\ncategory information for training can significantly improve the classification\nperformance and our proposed model outperforms commonly-used discriminative\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 23:53:18 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Qian", "Jing", ""], ["ElSherief", "Mai", ""], ["Belding", "Elizabeth", ""], ["Wang", "William Yang", ""]]}, {"id": "1809.00130", "submitter": "Ming Ding", "authors": "Ming Ding, Jie Tang, Jie Zhang", "title": "Semi-supervised Learning on Graphs with Generative Adversarial Nets", "comments": "to appear in CIKM 2018", "journal-ref": null, "doi": "10.1145/3269206.3271768", "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate how generative adversarial nets (GANs) can help\nsemi-supervised learning on graphs. We first provide insights on working\nprinciples of adversarial learning over graphs and then present GraphSGAN, a\nnovel approach to semi-supervised learning on graphs. In GraphSGAN, generator\nand classifier networks play a novel competitive game. At equilibrium,\ngenerator generates fake samples in low-density areas between subgraphs. In\norder to discriminate fake samples from the real, classifier implicitly takes\nthe density property of subgraph into consideration. An efficient adversarial\nlearning algorithm has been developed to improve traditional normalized graph\nLaplacian regularization with a theoretical guarantee. Experimental results on\nseveral different genres of datasets show that the proposed GraphSGAN\nsignificantly outperforms several state-of-the-art methods. GraphSGAN can be\nalso trained using mini-batch, thus enjoys the scalability advantage.\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 08:02:45 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Ding", "Ming", ""], ["Tang", "Jie", ""], ["Zhang", "Jie", ""]]}, {"id": "1809.00204", "submitter": "Stephan Baier", "authors": "Stephan Baier, Yunpu Ma, Volker Tresp", "title": "Improving Visual Relationship Detection using Semantic Modeling of Scene\n  Descriptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured scene descriptions of images are useful for the automatic\nprocessing and querying of large image databases. We show how the combination\nof a semantic and a visual statistical model can improve on the task of mapping\nimages to their associated scene description. In this paper we consider scene\ndescriptions which are represented as a set of triples (subject, predicate,\nobject), where each triple consists of a pair of visual objects, which appear\nin the image, and the relationship between them (e.g. man-riding-elephant,\nman-wearing-hat). We combine a standard visual model for object detection,\nbased on convolutional neural networks, with a latent variable model for link\nprediction. We apply multiple state-of-the-art link prediction methods and\ncompare their capability for visual relationship detection. One of the main\nadvantages of link prediction methods is that they can also generalize to\ntriples, which have never been observed in the training data. Our experimental\nresults on the recently published Stanford Visual Relationship dataset, a\nchallenging real world dataset, show that the integration of a semantic model\nusing link prediction methods can significantly improve the results for visual\nrelationship detection. Our combined approach achieves superior performance\ncompared to the state-of-the-art method from the Stanford computer vision\ngroup.\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 15:11:12 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Baier", "Stephan", ""], ["Ma", "Yunpu", ""], ["Tresp", "Volker", ""]]}, {"id": "1809.00224", "submitter": "Jack Parry", "authors": "Jack Parry", "title": "Finding the Answers with Definition Models", "comments": "MSc Dissertation, University of Edinburgh, <10,000 words", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by a previous attempt to answer crossword questions using neural\nnetworks (Hill, Cho, Korhonen, & Bengio, 2015), this dissertation implements\nextensions to improve the performance of this existing definition model on the\ntask of answering crossword questions. A discussion and evaluation of the\noriginal implementation finds that there are some ways in which the recurrent\nneural model could be extended. Insights from related fields neural language\nmodeling and neural machine translation provide the justification and means\nrequired for these extensions. Two extensions are applied to the LSTM encoder,\nfirst taking the average of LSTM states across the sequence and secondly using\na bidirectional LSTM, both implementations serve to improve model performance\non a definitions and crossword test set. In order to improve performance on\ncrossword questions, the training data is increased to include crossword\nquestions and answers, and this serves to improve results on definitions as\nwell as crossword questions. The final experiments are conducted using sub-word\nunit segmentation, first on the source side and then later preliminary\nexperimentation is conducted to facilitate character-level output. Initially,\nan exact reproduction of the baseline results proves unsuccessful. Despite\nthis, the extensions improve performance, allowing the definition model to\nsurpass the performance of the recurrent neural network variants of the\nprevious work (Hill, et al., 2015).\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 17:21:01 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Parry", "Jack", ""]]}, {"id": "1809.00258", "submitter": "Yogatheesan Varatharajah", "authors": "Yogatheesan Varatharajah, Brent Berry, Sanmi Koyejo, and Ravishankar\n  Iyer", "title": "A Contextual-bandit-based Approach for Informed Decision-making in\n  Clinical Trials", "comments": "13 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical trials involving multiple treatments utilize randomization of the\ntreatment assignments to enable the evaluation of treatment efficacies in an\nunbiased manner. Such evaluation is performed in post hoc studies that usually\nuse supervised-learning methods that rely on large amounts of data collected in\na randomized fashion. That approach often proves to be suboptimal in that some\nparticipants may suffer and even die as a result of having not received the\nmost appropriate treatments during the trial. Reinforcement-learning methods\nimprove the situation by making it possible to learn the treatment efficacies\ndynamically during the course of the trial, and to adapt treatment assignments\naccordingly. Recent efforts using \\textit{multi-arm bandits}, a type of\nreinforcement-learning methods, have focused on maximizing clinical outcomes\nfor a population that was assumed to be homogeneous. However, those approaches\nhave failed to account for the variability among participants that is becoming\nincreasingly evident as a result of recent clinical-trial-based studies. We\npresent a contextual-bandit-based online treatment optimization algorithm that,\nin choosing treatments for new participants in the study, takes into account\nnot only the maximization of the clinical outcomes but also the patient\ncharacteristics. We evaluated our algorithm using a real clinical trial dataset\nfrom the International Stroke Trial. The results of our retrospective analysis\nindicate that the proposed approach performs significantly better than either a\nrandom assignment of treatments (the current gold standard) or a\nmulti-arm-bandit-based approach, providing substantial gains in the percentage\nof participants who are assigned the most suitable treatments. The\ncontextual-bandit and multi-arm bandit approaches provide 72.63% and 64.34%\ngains, respectively, compared to a random assignment.\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 22:07:23 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Varatharajah", "Yogatheesan", ""], ["Berry", "Brent", ""], ["Koyejo", "Sanmi", ""], ["Iyer", "Ravishankar", ""]]}, {"id": "1809.00263", "submitter": "Qiangeng Xu", "authors": "Qiangeng Xu, Hanwang Zhang, Weiyue Wang, Peter N. Belhumeur, Ulrich\n  Neumann", "title": "Stochastic Dynamics for Video Infilling", "comments": "Winter Conference on Applications of Computer Vision (WACV 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a stochastic dynamics video infilling (SDVI)\nframework to generate frames between long intervals in a video. Our task\ndiffers from video interpolation which aims to produce transitional frames for\na short interval between every two frames and increase the temporal resolution.\nOur task, namely video infilling, however, aims to infill long intervals with\nplausible frame sequences. Our framework models the infilling as a constrained\nstochastic generation process and sequentially samples dynamics from the\ninferred distribution. SDVI consists of two parts: (1) a bi-directional\nconstraint propagation module to guarantee the spatial-temporal coherence among\nframes, (2) a stochastic sampling process to generate dynamics from the\ninferred distributions. Experimental results show that SDVI can generate clear\nframe sequences with varying contents. Moreover, motions in the generated\nsequence are realistic and able to transfer smoothly from the given start frame\nto the terminal frame. Our project site is\nhttps://xharlie.github.io/projects/project_sites/SDVI/video_results.html\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 22:58:49 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 03:25:49 GMT"}, {"version": "v3", "created": "Wed, 28 Nov 2018 04:56:46 GMT"}, {"version": "v4", "created": "Thu, 6 Jun 2019 02:24:44 GMT"}, {"version": "v5", "created": "Fri, 7 Jun 2019 09:13:07 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Xu", "Qiangeng", ""], ["Zhang", "Hanwang", ""], ["Wang", "Weiyue", ""], ["Belhumeur", "Peter N.", ""], ["Neumann", "Ulrich", ""]]}, {"id": "1809.00329", "submitter": "Yvonne Huang", "authors": "Yafang Huang and Hai Zhao", "title": "Chinese Pinyin Aided IME, Input What You Have Not Keystroked Yet", "comments": "7 pages, accepted by EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chinese pinyin input method engine (IME) converts pinyin into character so\nthat Chinese characters can be conveniently inputted into computer through\ncommon keyboard. IMEs work relying on its core component, pinyin-to-character\nconversion (P2C). Usually Chinese IMEs simply predict a list of character\nsequences for user choice only according to user pinyin input at each turn.\nHowever, Chinese inputting is a multi-turn online procedure, which can be\nsupposed to be exploited for further user experience promoting. This paper thus\nfor the first time introduces a sequence-to-sequence model with gated-attention\nmechanism for the core task in IMEs. The proposed neural P2C model is learned\nby encoding previous input utterance as extra context to enable our IME capable\nof predicting character sequence with incomplete pinyin input. Our model is\nevaluated in different benchmark datasets showing great user experience\nimprovement compared to traditional models, which demonstrates the first\nengineering practice of building Chinese aided IME.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 12:01:27 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Huang", "Yafang", ""], ["Zhao", "Hai", ""]]}, {"id": "1809.00345", "submitter": "Dar\\'io Garigliotti", "authors": "Dar\\'io Garigliotti and Krisztian Balog", "title": "IntentsKB: A Knowledge Base of Entity-Oriented Search Intents", "comments": "Proceedings of the 27th ACM International Conference on Information\n  and Knowledge Management (CIKM'18), 2018. 4 pages. 2 figures", "journal-ref": null, "doi": "10.1145/3269206.3269257", "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of constructing a knowledge base of entity-oriented\nsearch intents. Search intents are defined on the level of entity types, each\ncomprising of a high-level intent category (property, website, service, or\nother), along with a cluster of query terms used to express that intent. These\nmachine-readable statements can be leveraged in various applications, e.g., for\ngenerating entity cards or query recommendations. By structuring\nservice-oriented search intents, we take one step towards making entities\nactionable. The main contribution of this paper is a pipeline of components we\ndevelop to construct a knowledge base of entity intents. We evaluate\nperformance both component-wise and end-to-end, and demonstrate that our\napproach is able to generate high-quality data.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 14:29:05 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Garigliotti", "Dar\u00edo", ""], ["Balog", "Krisztian", ""]]}, {"id": "1809.00385", "submitter": "Chenwei Zhang", "authors": "Congying Xia, Chenwei Zhang, Xiaohui Yan, Yi Chang, Philip S. Yu", "title": "Zero-shot User Intent Detection via Capsule Neural Networks", "comments": "In EMNLP 2018 as a long paper. Previously available on\n  http://doi.org/10.13140/RG.2.2.11739.46889", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User intent detection plays a critical role in question-answering and dialog\nsystems. Most previous works treat intent detection as a classification problem\nwhere utterances are labeled with predefined intents. However, it is\nlabor-intensive and time-consuming to label users' utterances as intents are\ndiversely expressed and novel intents will continually be involved. Instead, we\nstudy the zero-shot intent detection problem, which aims to detect emerging\nuser intents where no labeled utterances are currently available. We propose\ntwo capsule-based architectures: INTENT-CAPSNET that extracts semantic features\nfrom utterances and aggregates them to discriminate existing intents, and\nINTENTCAPSNET-ZSL which gives INTENTCAPSNET the zero-shot learning ability to\ndiscriminate emerging intents via knowledge transfer from existing intents.\nExperiments on two real-world datasets show that our model not only can better\ndiscriminate diversely expressed existing intents, but is also able to\ndiscriminate emerging intents when no labeled utterances are available.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 20:22:48 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Xia", "Congying", ""], ["Zhang", "Chenwei", ""], ["Yan", "Xiaohui", ""], ["Chang", "Yi", ""], ["Yu", "Philip S.", ""]]}, {"id": "1809.00410", "submitter": "Disha Shrivastava", "authors": "Disha Shrivastava, Abhijit Mishra, Karthik Sankaranarayanan", "title": "Modeling Topical Coherence in Discourse without Supervision", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coherence of text is an important attribute to be measured for both manually\nand automatically generated discourse; but well-defined quantitative metrics\nfor it are still elusive. In this paper, we present a metric for scoring\ntopical coherence of an input paragraph on a real-valued scale by analyzing its\nunderlying topical structure. We first extract all possible topics that the\nsentences of a paragraph of text are related to. Coherence of this text is then\nmeasured by computing: (a) the degree of uncertainty of the topics with respect\nto the paragraph, and (b) the relatedness between these topics. All components\nof our modular framework rely only on unlabeled data and WordNet, thus making\nit completely unsupervised, which is an important feature for general-purpose\nusage of any metric. Experiments are conducted on two datasets - a publicly\navailable dataset for essay grading (representing human discourse), and a\nsynthetic dataset constructed by mixing content from multiple paragraphs\ncovering diverse topics. Our evaluation shows that the measured coherence\nscores are positively correlated with the ground truth for both the datasets.\nFurther validation to our coherence scores is provided by conducting human\nevaluation on the synthetic data, showing a significant agreement of 79.3%\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 23:49:31 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Shrivastava", "Disha", ""], ["Mishra", "Abhijit", ""], ["Sankaranarayanan", "Karthik", ""]]}, {"id": "1809.00414", "submitter": "Disha Shrivastava", "authors": "Disha Shrivastava, Sreyash Kenkre, Santosh Penubothula", "title": "Hypernyms Through Intra-Article Organization in Wikipedia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new measure for unsupervised hypernym detection and\ndirectionality. The motivation is to keep the measure computationally light and\nportatable across languages. We show that the relative physical location of\nwords in explanatory articles captures the directionality property. Further,\nthe phrases in section titles of articles about the word, capture the semantic\nsimilarity needed for hypernym detection task. We experimentally show that the\ncombination of features coming from these two simple measures suffices to\nproduce results comparable with the best unsupervised measures in terms of the\naverage precision.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 00:04:49 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Shrivastava", "Disha", ""], ["Kenkre", "Sreyash", ""], ["Penubothula", "Santosh", ""]]}, {"id": "1809.00494", "submitter": "Diego Esteves", "authors": "Diego Esteves, Aniketh Janardhan Reddy, Piyush Chawla and Jens Lehmann", "title": "Belittling the Source: Trustworthiness Indicators to Obfuscate Fake News\n  on the Web", "comments": null, "journal-ref": "EMNLP 2018: Conference on Empirical Methods in Natural Language\n  Processing (The First Workshop on Fact Extraction and Verification)", "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growth of the internet, the number of fake-news online has been\nproliferating every year. The consequences of such phenomena are manifold,\nranging from lousy decision-making process to bullying and violence episodes.\nTherefore, fact-checking algorithms became a valuable asset. To this aim, an\nimportant step to detect fake-news is to have access to a credibility score for\na given information source. However, most of the widely used Web indicators\nhave either been shut-down to the public (e.g., Google PageRank) or are not\nfree for use (Alexa Rank). Further existing databases are short-manually\ncurated lists of online sources, which do not scale. Finally, most of the\nresearch on the topic is theoretical-based or explore confidential data in a\nrestricted simulation environment. In this paper we explore current research,\nhighlight the challenges and propose solutions to tackle the problem of\nclassifying websites into a credibility scale. The proposed model automatically\nextracts source reputation cues and computes a credibility factor, providing\nvaluable insights which can help in belittling dubious and confirming trustful\nunknown websites. Experimental results outperform state of the art in the\n2-classes and 5-classes setting.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 08:37:33 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Esteves", "Diego", ""], ["Reddy", "Aniketh Janardhan", ""], ["Chawla", "Piyush", ""], ["Lehmann", "Jens", ""]]}, {"id": "1809.00509", "submitter": "Diego Esteves", "authors": "Aniketh Janardhan Reddy and Gil Rocha and Diego Esteves", "title": "DeFactoNLP: Fact Verification using Entity Recognition, TFIDF Vector\n  Comparison and Decomposable Attention", "comments": null, "journal-ref": "EMNLP 2018: Conference on Empirical Methods in Natural Language\n  Processing (The First Workshop on Fact Extraction and Verification)", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe DeFactoNLP, the system we designed for the FEVER\n2018 Shared Task. The aim of this task was to conceive a system that can not\nonly automatically assess the veracity of a claim but also retrieve evidence\nsupporting this assessment from Wikipedia. In our approach, the Wikipedia\ndocuments whose Term Frequency-Inverse Document Frequency (TFIDF) vectors are\nmost similar to the vector of the claim and those documents whose names are\nsimilar to those of the named entities (NEs) mentioned in the claim are\nidentified as the documents which might contain evidence. The sentences in\nthese documents are then supplied to a textual entailment recognition module.\nThis module calculates the probability of each sentence supporting the claim,\ncontradicting the claim or not providing any relevant information to assess the\nveracity of the claim. Various features computed using these probabilities are\nfinally used by a Random Forest classifier to determine the overall\ntruthfulness of the claim. The sentences which support this classification are\nreturned as evidence. Our approach achieved a 0.4277 evidence F1-score, a\n0.5136 label accuracy and a 0.3833 FEVER score.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 09:07:17 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Reddy", "Aniketh Janardhan", ""], ["Rocha", "Gil", ""], ["Esteves", "Diego", ""]]}, {"id": "1809.00549", "submitter": "Ben Bogin", "authors": "Ben Bogin, Mor Geva, Jonathan Berant", "title": "Emergence of Communication in an Interactive World with Consistent\n  Speakers", "comments": "Emergent Communication Workshop @ NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training agents to communicate with one another given task-based supervision\nonly has attracted considerable attention recently, due to the growing interest\nin developing models for human-agent interaction. Prior work on the topic\nfocused on simple environments, where training using policy gradient was\nfeasible despite the non-stationarity of the agents during training. In this\npaper, we present a more challenging environment for testing the emergence of\ncommunication from raw pixels, where training using policy gradient fails. We\npropose a new model and training algorithm, that utilizes the structure of a\nlearned representation space to produce more consistent speakers at the initial\nphases of training, which stabilizes learning. We empirically show that our\nalgorithm substantially improves performance compared to policy gradient. We\nalso propose a new alignment-based metric for measuring context-independence in\nemerged communication and find our method increases context-independence\ncompared to policy gradient and other competitive baselines.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 11:05:00 GMT"}, {"version": "v2", "created": "Sun, 24 Mar 2019 09:23:31 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Bogin", "Ben", ""], ["Geva", "Mor", ""], ["Berant", "Jonathan", ""]]}, {"id": "1809.00564", "submitter": "Stefano Cerri", "authors": "Philippe Lemoisson (UMR TETIS), Stefano A. Cerri (SMILE)", "title": "ViewpointS: towards a Collective Brain", "comments": null, "journal-ref": "Ngoc Thanh Nguyen; Elias Pimenidis; Zaheer Khan; Bogdan\n  Trawi{\\'n}ski. ICCCI: International Conference on Computational Collective\n  Intelligence, Sep 2018, Bristol, United Kingdom. Springer Verlag, 10th\n  International Conference on Computational Collective Intelligence, LNCS\n  (11055), pp.3-12, 2018, http://www.iccci2018.org", "doi": "10.1007/978-3-319-98443-8_1", "report-no": null, "categories": "cs.MA cs.AI cs.SI q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tracing knowledge acquisition and linking learning events to interaction\nbetween peers is a major challenge of our times. We have conceived, designed\nand evaluated a new paradigm for constructing and using collective knowledge by\nWeb interactions that we called ViewpointS. By exploiting the similarity with\nEdelman's Theory of Neuronal Group Selection (TNGS), we conjecture that it may\nbe metaphorically considered a Collective Brain, especially effective in the\ncase of trans-disciplinary representations. Far from being without doubts, in\nthe paper we present the reasons (and the limits) of our proposal that aims to\nbecome a useful integrating tool for future quantitative explorations of\nindividual as well as collective learning at different degrees of granu-larity.\nWe are therefore challenging each of the current approaches: the logical one in\nthe semantic Web, the statistical one in mining and deep learning, the social\none in recommender systems based on authority and trust; not in each of their\nown preferred field of operation, rather in their integration weaknesses far\nfrom the holistic and dynamic behavior of the human brain.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 11:51:13 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Lemoisson", "Philippe", "", "UMR TETIS"], ["Cerri", "Stefano A.", "", "SMILE"]]}, {"id": "1809.00567", "submitter": "Xavier Gir\\'o-i-Nieto", "authors": "Marc Assens, Xavier Giro-i-Nieto, Kevin McGuinness and Noel E.\n  O'Connor", "title": "PathGAN: Visual Scanpath Prediction with Generative Adversarial Networks", "comments": "ECCV 2018 Workshop on Egocentric Perception, Interaction and\n  Computing (EPIC). This work obtained the 2nd award in Prediction of Head-gaze\n  Scan-paths for Images, and the 2nd award in Prediction of Eye-gaze Scan-paths\n  for Images at the IEEE ICME 2018 Salient360! Challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce PathGAN, a deep neural network for visual scanpath prediction\ntrained on adversarial examples. A visual scanpath is defined as the sequence\nof fixation points over an image defined by a human observer with its gaze.\nPathGAN is composed of two parts, the generator and the discriminator. Both\nparts extract features from images using off-the-shelf networks, and train\nrecurrent layers to generate or discriminate scanpaths accordingly. In scanpath\nprediction, the stochastic nature of the data makes it very difficult to\ngenerate realistic predictions using supervised learning strategies, but we\nadopt adversarial training as a suitable alternative. Our experiments prove how\nPathGAN improves the state of the art of visual scanpath prediction on the iSUN\nand Salient360! datasets. Source code and models are available at\nhttps://imatge-upc.github.io/pathgan/\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 11:57:38 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Assens", "Marc", ""], ["Giro-i-Nieto", "Xavier", ""], ["McGuinness", "Kevin", ""], ["O'Connor", "Noel E.", ""]]}, {"id": "1809.00647", "submitter": "Zhengzhong Liu", "authors": "Zhengzhong Liu, Chenyan Xiong, Teruko Mitamura, Eduard Hovy", "title": "Automatic Event Salience Identification", "comments": "EMNLP 2018, 11 pages. Datasets, models and codes:\n  https://github.com/hunterhector/EventSalience", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying the salience (i.e. importance) of discourse units is an important\ntask in language understanding. While events play important roles in text\ndocuments, little research exists on analyzing their saliency status. This\npaper empirically studies the Event Salience task and proposes two salience\ndetection models based on content similarities and discourse relations. The\nfirst is a feature based salience model that incorporates similarities among\ndiscourse units. The second is a neural model that captures more complex\nrelations between discourse units. Tested on our new large-scale event salience\ncorpus, both methods significantly outperform the strong frequency baseline,\nwhile our neural model further improves the feature based one by a large\nmargin. Our analyses demonstrate that our neural model captures interesting\nconnections between salience and discourse unit relations (e.g., scripts and\nframe structures).\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 16:35:07 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Liu", "Zhengzhong", ""], ["Xiong", "Chenyan", ""], ["Mitamura", "Teruko", ""], ["Hovy", "Eduard", ""]]}, {"id": "1809.00716", "submitter": "Sajad Saeedi", "authors": "Wenbin Li (1), Sajad Saeedi (1), John McCormac (1), Ronald Clark (1),\n  Dimos Tzoumanikas (1), Qing Ye (2), Yuzhong Huang (2), Rui Tang (2), Stefan\n  Leutenegger (1) ((1) Department of Computing, Imperial College London, London\n  UK, SW7 2AZ (2) KooLab, Kujiale.com, Hangzhou China)", "title": "InteriorNet: Mega-scale Multi-sensor Photo-realistic Indoor Scenes\n  Dataset", "comments": "British Machine Vision Conference (BMVC) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Datasets have gained an enormous amount of popularity in the computer vision\ncommunity, from training and evaluation of Deep Learning-based methods to\nbenchmarking Simultaneous Localization and Mapping (SLAM). Without a doubt,\nsynthetic imagery bears a vast potential due to scalability in terms of amounts\nof data obtainable without tedious manual ground truth annotations or\nmeasurements. Here, we present a dataset with the aim of providing a higher\ndegree of photo-realism, larger scale, more variability as well as serving a\nwider range of purposes compared to existing datasets. Our dataset leverages\nthe availability of millions of professional interior designs and millions of\nproduction-level furniture and object assets -- all coming with fine geometric\ndetails and high-resolution texture. We render high-resolution and high\nframe-rate video sequences following realistic trajectories while supporting\nvarious camera types as well as providing inertial measurements. Together with\nthe release of the dataset, we will make executable program of our interactive\nsimulator software as well as our renderer available at\nhttps://interiornetdataset.github.io. To showcase the usability and uniqueness\nof our dataset, we show benchmarking results of both sparse and dense SLAM\nalgorithms.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 20:42:27 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Li", "Wenbin", ""], ["Saeedi", "Sajad", ""], ["McCormac", "John", ""], ["Clark", "Ronald", ""], ["Tzoumanikas", "Dimos", ""], ["Ye", "Qing", ""], ["Huang", "Yuzhong", ""], ["Tang", "Rui", ""], ["Leutenegger", "Stefan", ""]]}, {"id": "1809.00794", "submitter": "Zhiting Hu", "authors": "Zhiting Hu, Haoran Shi, Bowen Tan, Wentao Wang, Zichao Yang, Tiancheng\n  Zhao, Junxian He, Lianhui Qin, Di Wang, Xuezhe Ma, Zhengzhong Liu, Xiaodan\n  Liang, Wangrong Zhu, Devendra Singh Sachan, Eric P. Xing", "title": "Texar: A Modularized, Versatile, and Extensible Toolkit for Text\n  Generation", "comments": "ACL 2019 demo, expanded version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Texar, an open-source toolkit aiming to support the broad set of\ntext generation tasks that transform any inputs into natural language, such as\nmachine translation, summarization, dialog, content manipulation, and so forth.\nWith the design goals of modularity, versatility, and extensibility in mind,\nTexar extracts common patterns underlying the diverse tasks and methodologies,\ncreates a library of highly reusable modules, and allows arbitrary model\narchitectures and algorithmic paradigms. In Texar, model architecture,\ninference, and learning processes are properly decomposed. Modules at a high\nconcept level can be freely assembled and plugged in/swapped out. The toolkit\nalso supports a rich set of large-scale pretrained models. Texar is thus\nparticularly suitable for researchers and practitioners to do fast prototyping\nand experimentation. The versatile toolkit also fosters technique sharing\nacross different text generation tasks. Texar supports both TensorFlow and\nPyTorch, and is released under Apache License 2.0 at https://www.texar.io.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 04:40:34 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 00:12:39 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Hu", "Zhiting", ""], ["Shi", "Haoran", ""], ["Tan", "Bowen", ""], ["Wang", "Wentao", ""], ["Yang", "Zichao", ""], ["Zhao", "Tiancheng", ""], ["He", "Junxian", ""], ["Qin", "Lianhui", ""], ["Wang", "Di", ""], ["Ma", "Xuezhe", ""], ["Liu", "Zhengzhong", ""], ["Liang", "Xiaodan", ""], ["Zhu", "Wangrong", ""], ["Sachan", "Devendra Singh", ""], ["Xing", "Eric P.", ""]]}, {"id": "1809.00832", "submitter": "Eunji Jeong", "authors": "Eunji Jeong, Joo Seong Jeong, Soojeong Kim, Gyeong-In Yu, Byung-Gon\n  Chun", "title": "Improving the Expressiveness of Deep Learning Frameworks with Recursion", "comments": "Appeared in EuroSys 2018. 13 pages, 11 figures", "journal-ref": "EuroSys 2018: Thirteenth EuroSys Conference, April 23-26, 2018,\n  Porto, Portugal", "doi": "10.1145/3190508.3190530", "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recursive neural networks have widely been used by researchers to handle\napplications with recursively or hierarchically structured data. However,\nembedded control flow deep learning frameworks such as TensorFlow, Theano,\nCaffe2, and MXNet fail to efficiently represent and execute such neural\nnetworks, due to lack of support for recursion. In this paper, we add recursion\nto the programming model of existing frameworks by complementing their design\nwith recursive execution of dataflow graphs as well as additional APIs for\nrecursive definitions. Unlike iterative implementations, which can only\nunderstand the topological index of each node in recursive data structures, our\nrecursive implementation is able to exploit the recursive relationships between\nnodes for efficient execution based on parallel computation. We present an\nimplementation on TensorFlow and evaluation results with various recursive\nneural network models, showing that our recursive implementation not only\nconveys the recursive nature of recursive neural networks better than other\nimplementations, but also uses given resources more effectively to reduce\ntraining and inference time.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 08:31:21 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Jeong", "Eunji", ""], ["Jeong", "Joo Seong", ""], ["Kim", "Soojeong", ""], ["Yu", "Gyeong-In", ""], ["Chun", "Byung-Gon", ""]]}, {"id": "1809.00852", "submitter": "Huanhuan Yu", "authors": "Huanhuan Yu, Menglei Hu and Songcan Chen", "title": "Multi-target Unsupervised Domain Adaptation without Exactly Shared\n  Categories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation (UDA) aims to learn the unlabeled target\ndomain by transferring the knowledge of the labeled source domain. To date,\nmost of the existing works focus on the scenario of one source domain and one\ntarget domain (1S1T), and just a few works concern the scenario of multiple\nsource domains and one target domain (mS1T). While, to the best of our\nknowledge, almost no work concerns the scenario of one source domain and\nmultiple target domains (1SmT), in which these unlabeled target domains may not\nnecessarily share the same categories, therefore, contrasting to mS1T, 1SmT is\nmore challenging. Accordingly, for such a new UDA scenario, we propose a UDA\nframework through the model parameter adaptation (PA-1SmT). A key ingredient of\nPA-1SmT is to transfer knowledge through adaptive learning of a common model\nparameter dictionary, which is completely different from existing popular\nmethods for UDA, such as subspace alignment, distribution matching etc., and\ncan also be directly used for DA of privacy protection due to the fact that the\nknowledge is transferred just via the model parameters rather than data itself.\nFinally, our experimental results on three domain adaptation benchmark datasets\ndemonstrate the superiority of our framework.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 09:18:19 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 07:13:46 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Yu", "Huanhuan", ""], ["Hu", "Menglei", ""], ["Chen", "Songcan", ""]]}, {"id": "1809.00858", "submitter": "Anthony Hunter", "authors": "Anthony Hunter", "title": "Non-monotonic Reasoning in Deductive Argumentation", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Argumentation is a non-monotonic process. This reflects the fact that\nargumentation involves uncertain information, and so new information can cause\na change in the conclusions drawn. However, the base logic does not need to be\nnon-monotonic. Indeed, most proposals for structured argumentation use a\nmonotonic base logic (e.g. some form of modus ponens with a rule-based\nlanguage, or classical logic). Nonetheless, there are issues in capturing\ndefeasible reasoning in argumentation including choice of base logic and\nmodelling of defeasible knowledge. And there are insights and tools to be\nharnessed for research in non-monontonic logics. We consider some of these\nissues in this paper.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 09:29:37 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Hunter", "Anthony", ""]]}, {"id": "1809.00946", "submitter": "Jerry Li", "authors": "Jerry Li", "title": "Twin-GAN -- Unpaired Cross-Domain Image Translation with Weight-Sharing\n  GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for translating unlabeled images from one domain into\nanalog images in another domain. We employ a progressively growing\nskip-connected encoder-generator structure and train it with a GAN loss for\nrealistic output, a cycle consistency loss for maintaining same-domain\ntranslation identity, and a semantic consistency loss that encourages the\nnetwork to keep the input semantic features in the output. We apply our\nframework on the task of translating face images, and show that it is capable\nof learning semantic mappings for face images with no supervised one-to-one\nimage mapping.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 23:09:03 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Li", "Jerry", ""]]}, {"id": "1809.00949", "submitter": "Idris Jeelani", "authors": "Idris Jeelani, Kevin Han and Alex Albert", "title": "Automating Analysis of Construction Workers Viewing Patterns for\n  Personalized Safety Training and Management", "comments": "ISARC 2018 Submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unrecognized hazards increase the likelihood of workplace fatalities and\ninjuries substantially. However, recent research has demonstrated that a large\nproportion of hazards remain unrecognized in dynamic construction environments.\nRecent studies have suggested a strong correlation between viewing patterns of\nworkers and their hazard recognition performance. Hence, it is important to\nstudy and analyze the viewing patterns of workers to gain a better\nunderstanding of their hazard recognition performance. The objective of this\nexploratory research is to explore hazard recognition as a visual search\nprocess to identifying various visual search factors that affect the process of\nhazard recognition. Further, the study also proposes a framework to develop a\nvision based tool capable of recording and analyzing viewing patterns of\nconstruction workers and generate feedback for personalized training and\nproactive safety management.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 18:15:53 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Jeelani", "Idris", ""], ["Han", "Kevin", ""], ["Albert", "Alex", ""]]}, {"id": "1809.00953", "submitter": "Burak Satar", "authors": "Burak Satar, Ahmet Emir Dirik", "title": "Deep Learning Based Vehicle Make-Model Classification", "comments": "10 pages, ICANN 2018: Artificial Neural Networks and Machine Learning", "journal-ref": "Lecture Notes in Computer Science book series 2018 (LNCS, volume\n  11141). Springer, Cham", "doi": "10.1007/978-3-030-01424-7_53", "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper studies the problems of vehicle make & model classification. Some\nof the main challenges are reaching high classification accuracy and reducing\nthe annotation time of the images. To address these problems, we have created a\nfine-grained database using online vehicle marketplaces of Turkey. A pipeline\nis proposed to combine an SSD (Single Shot Multibox Detector) model with a CNN\n(Convolutional Neural Network) model to train on the database. In the pipeline,\nwe first detect the vehicles by following an algorithm which reduces the time\nfor annotation. Then, we feed them into the CNN model. It is reached\napproximately 4% better classification accuracy result than using a\nconventional CNN model. Next, we propose to use the detected vehicles as ground\ntruth bounding box (GTBB) of the images and feed them into an SSD model in\nanother pipeline. At this stage, it is reached reasonable classification\naccuracy result without using perfectly shaped GTBB. Lastly, an application is\nimplemented in a use case by using our proposed pipelines. It detects the\nunauthorized vehicles by comparing their license plate numbers and make &\nmodels. It is assumed that license plates are readable.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 14:05:31 GMT"}, {"version": "v2", "created": "Sat, 9 Feb 2019 20:46:17 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Satar", "Burak", ""], ["Dirik", "Ahmet Emir", ""]]}, {"id": "1809.00969", "submitter": "Anima Majumder", "authors": "Madhu Babu V, Anima Majumder, Kaushik Das and Swagat Kumar", "title": "A Deeper Insight into the UnDEMoN: Unsupervised Deep Network for Depth\n  and Ego-Motion Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an unsupervised deep learning framework called UnDEMoN\nfor estimating dense depth map and 6-DoF camera pose information directly from\nmonocular images. The proposed network is trained using unlabeled monocular\nstereo image pairs and is shown to provide superior performance in depth and\nego-motion estimation compared to the existing state-of-the-art. These\nimprovements are achieved by introducing a new objective function that aims to\nminimize spatial as well as temporal reconstruction losses simultaneously.\nThese losses are defined using bi-linear sampling kernel and penalized using\nthe Charbonnier penalty function. The objective function, thus created,\nprovides robustness to image gradient noises thereby improving the overall\nestimation accuracy without resorting to any coarse to fine strategies which\nare currently prevalent in the literature. Another novelty lies in the fact\nthat we combine a disparity-based depth estimation network with a pose\nestimation network to obtain absolute scale-aware 6 DOF Camera pose and\nsuperior depth map. The effectiveness of the proposed approach is demonstrated\nthrough performance comparison with the existing supervised and unsupervised\nmethods on the KITTI driving dataset.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 11:40:58 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 10:40:56 GMT"}, {"version": "v3", "created": "Tue, 27 Nov 2018 09:21:17 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Babu", "Madhu", "V"], ["Majumder", "Anima", ""], ["Das", "Kaushik", ""], ["Kumar", "Swagat", ""]]}, {"id": "1809.00970", "submitter": "Laurent Lejeune", "authors": "Laurent Lejeune, Jan Grossrieder, Raphael Sznitman", "title": "Iterative multi-path tracking for video and volume segmentation with\n  sparse point supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent machine learning strategies for segmentation tasks have shown great\nability when trained on large pixel-wise annotated image datasets. It remains a\nmajor challenge however to aggregate such datasets, as the time and monetary\ncost associated with collecting extensive annotations is extremely high. This\nis particularly the case for generating precise pixel-wise annotations in video\nand volumetric image data. To this end, this work presents a novel framework to\nproduce pixel-wise segmentations using minimal supervision. Our method relies\non 2D point supervision, whereby a single 2D location within an object of\ninterest is provided on each image of the data. Our method then estimates the\nobject appearance in a semi-supervised fashion by learning\nobject-image-specific features and by using these in a semi-supervised learning\nframework. Our object model is then used in a graph-based optimization problem\nthat takes into account all provided locations and the image data in order to\ninfer the complete pixel-wise segmentation. In practice, we solve this\noptimally as a tracking problem using a K-shortest path approach. Both the\nobject model and segmentation are then refined iteratively to further improve\nthe final segmentation. We show that by collecting 2D locations using a gaze\ntracker, our approach can provide state-of-the-art segmentations on a range of\nobjects and image modalities (video and 3D volumes), and that these can then be\nused to train supervised machine learning classifiers.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 13:38:50 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Lejeune", "Laurent", ""], ["Grossrieder", "Jan", ""], ["Sznitman", "Raphael", ""]]}, {"id": "1809.00979", "submitter": "Thanh Tran", "authors": "Thanh Tran, Kyumin Lee, Yiming Liao, Dongwon Lee", "title": "Regularizing Matrix Factorization with User and Item Embeddings for\n  Recommendation", "comments": "CIKM 2018", "journal-ref": "CIKM 2018", "doi": "10.1145/3269206.3271730", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following recent successes in exploiting both latent factor and word\nembedding models in recommendation, we propose a novel Regularized\nMulti-Embedding (RME) based recommendation model that simultaneously\nencapsulates the following ideas via decomposition: (1) which items a user\nlikes, (2) which two users co-like the same items, (3) which two items users\noften co-liked, and (4) which two items users often co-disliked. In\nexperimental validation, the RME outperforms competing state-of-the-art models\nin both explicit and implicit feedback datasets, significantly improving\nRecall@5 by 5.9~7.0%, NDCG@20 by 4.3~5.6%, and MAP@10 by 7.9~8.9%. In addition,\nunder the cold-start scenario for users with the lowest number of interactions,\nagainst the competing models, the RME outperforms NDCG@5 by 20.2% and 29.4% in\nMovieLens-10M and MovieLens-20M datasets, respectively. Our datasets and source\ncode are available at: https://github.com/thanhdtran/RME.git.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 05:47:40 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Tran", "Thanh", ""], ["Lee", "Kyumin", ""], ["Liao", "Yiming", ""], ["Lee", "Dongwon", ""]]}, {"id": "1809.01036", "submitter": "L\\^e Nguy\\^en Hoang", "authors": "L\\^e Nguy\\^en Hoang", "title": "A Roadmap for Robust End-to-End Alignment", "comments": "21 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper discussed the {\\it robust alignment} problem, that is, the problem\nof aligning the goals of algorithms with human preferences. It presented a\ngeneral roadmap to tackle this issue. Interestingly, this roadmap identifies 5\ncritical steps, as well as many relevant aspects of these 5 steps. In other\nwords, we have presented a large number of hopefully more tractable subproblems\nthat readers are highly encouraged to tackle. Hopefully, this combination\nallows to better highlight the most pressing problems, how every expertise can\nbe best used to, and how combining the solutions to subproblems might add up to\nsolve robust alignment.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 15:19:44 GMT"}, {"version": "v2", "created": "Sun, 21 Oct 2018 11:01:41 GMT"}, {"version": "v3", "created": "Mon, 25 Feb 2019 09:32:09 GMT"}, {"version": "v4", "created": "Tue, 25 Feb 2020 08:45:45 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Hoang", "L\u00ea Nguy\u00ean", ""]]}, {"id": "1809.01124", "submitter": "Medhini Narasimhan", "authors": "Medhini Narasimhan, Alexander G. Schwing", "title": "Straight to the Facts: Learning Knowledge Base Retrieval for Factual\n  Visual Question Answering", "comments": "Accepted to ECCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering is an important task for autonomous agents and virtual\nassistants alike and was shown to support the disabled in efficiently\nnavigating an overwhelming environment. Many existing methods focus on\nobservation-based questions, ignoring our ability to seamlessly combine\nobserved content with general knowledge. To understand interactions with a\nknowledge base, a dataset has been introduced recently and keyword matching\ntechniques were shown to yield compelling results despite being vulnerable to\nmisconceptions due to synonyms and homographs. To address this issue, we\ndevelop a learning-based approach which goes straight to the facts via a\nlearned embedding space. We demonstrate state-of-the-art results on the\nchallenging recently introduced fact-based visual question answering dataset,\noutperforming competing methods by more than 5%.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 17:59:55 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Narasimhan", "Medhini", ""], ["Schwing", "Alexander G.", ""]]}, {"id": "1809.01220", "submitter": "Benjamin Ayton", "authors": "Benjamin J Ayton, Brian C Williams", "title": "Vulcan: A Monte Carlo Algorithm for Large Chance Constrained MDPs with\n  Risk Bounding Functions", "comments": "33 pages, 12 figures. In review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chance Constrained Markov Decision Processes maximize reward subject to a\nbounded probability of failure, and have been frequently applied for planning\nwith potentially dangerous outcomes or unknown environments. Solution\nalgorithms have required strong heuristics or have been limited to relatively\nsmall problems with up to millions of states, because the optimal action to\ntake from a given state depends on the probability of failure in the rest of\nthe policy, leading to a coupled problem that is difficult to solve. In this\npaper we examine a generalization of a CCMDP that trades off probability of\nfailure against reward through a functional relationship. We derive a\nconstraint that can be applied to each state history in a policy individually,\nand which guarantees that the chance constraint will be satisfied. The approach\ndecouples states in the CCMDP, so that large problems can be solved\nefficiently. We then introduce Vulcan, which uses our constraint in order to\napply Monte Carlo Tree Search to CCMDPs. Vulcan can be applied to problems\nwhere it is unfeasible to generate the entire state space, and policies must be\nreturned in an anytime manner. We show that Vulcan and its variants run tens to\nhundreds of times faster than linear programming methods, and over ten times\nfaster than heuristic based methods, all without the need for a heuristic, and\nreturning solutions with a mean suboptimality on the order of a few percent.\nFinally, we use Vulcan to solve for a chance constrained policy in a CCMDP with\nover $10^{13}$ states in 3 minutes.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 19:42:22 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Ayton", "Benjamin J", ""], ["Williams", "Brian C", ""]]}, {"id": "1809.01266", "submitter": "Lei Ma", "authors": "Xiaofei Xie, Lei Ma, Felix Juefei-Xu, Hongxu Chen, Minhui Xue, Bo Li,\n  Yang Liu, Jianjun Zhao, Jianxiong Yin, and Simon See", "title": "DeepHunter: Hunting Deep Neural Network Defects via Coverage-Guided\n  Fuzzing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In company with the data explosion over the past decade, deep neural network\n(DNN) based software has experienced unprecedented leap and is becoming the key\ndriving force of many novel industrial applications, including many\nsafety-critical scenarios such as autonomous driving. Despite great success\nachieved in various human intelligence tasks, similar to traditional software,\nDNNs could also exhibit incorrect behaviors caused by hidden defects causing\nsevere accidents and losses. In this paper, we propose DeepHunter, an automated\nfuzz testing framework for hunting potential defects of general-purpose DNNs.\nDeepHunter performs metamorphic mutation to generate new semantically preserved\ntests, and leverages multiple plugable coverage criteria as feedback to guide\nthe test generation from different perspectives. To be scalable towards\npractical-sized DNNs, DeepHunter maintains multiple tests in a batch, and\nprioritizes the tests selection based on active feedback. The effectiveness of\nDeepHunter is extensively investigated on 3 popular datasets (MNIST, CIFAR-10,\nImageNet) and 7 DNNs with diverse complexities, under a large set of 6 coverage\ncriteria as feedback. The large-scale experiments demonstrate that DeepHunter\ncan (1) significantly boost the coverage with guidance; (2) generate useful\ntests to detect erroneous behaviors and facilitate the DNN model quality\nevaluation; (3) accurately capture potential defects during DNN quantization\nfor platform migration.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 23:07:45 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 00:49:53 GMT"}, {"version": "v3", "created": "Fri, 16 Nov 2018 05:36:16 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Xie", "Xiaofei", ""], ["Ma", "Lei", ""], ["Juefei-Xu", "Felix", ""], ["Chen", "Hongxu", ""], ["Xue", "Minhui", ""], ["Li", "Bo", ""], ["Liu", "Yang", ""], ["Zhao", "Jianjun", ""], ["Yin", "Jianxiong", ""], ["See", "Simon", ""]]}, {"id": "1809.01272", "submitter": "Mikel Artetxe", "authors": "Mikel Artetxe, Gorka Labaka, Eneko Agirre", "title": "Unsupervised Statistical Machine Translation", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While modern machine translation has relied on large parallel corpora, a\nrecent line of work has managed to train Neural Machine Translation (NMT)\nsystems from monolingual corpora only (Artetxe et al., 2018c; Lample et al.,\n2018). Despite the potential of this approach for low-resource settings,\nexisting systems are far behind their supervised counterparts, limiting their\npractical interest. In this paper, we propose an alternative approach based on\nphrase-based Statistical Machine Translation (SMT) that significantly closes\nthe gap with supervised systems. Our method profits from the modular\narchitecture of SMT: we first induce a phrase table from monolingual corpora\nthrough cross-lingual embedding mappings, combine it with an n-gram language\nmodel, and fine-tune hyperparameters through an unsupervised MERT variant. In\naddition, iterative backtranslation improves results further, yielding, for\ninstance, 14.08 and 26.22 BLEU points in WMT 2014 English-German and\nEnglish-French, respectively, an improvement of more than 7-10 BLEU points over\nprevious unsupervised systems, and closing the gap with supervised SMT (Moses\ntrained on Europarl) down to 2-5 BLEU points. Our implementation is available\nat https://github.com/artetxem/monoses\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 23:22:28 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Artetxe", "Mikel", ""], ["Labaka", "Gorka", ""], ["Agirre", "Eneko", ""]]}, {"id": "1809.01341", "submitter": "Pouya Pezeshkpour", "authors": "Pouya Pezeshkpour, Liyan Chen and Sameer Singh", "title": "Embedding Multimodal Relational Data for Knowledge Base Completion", "comments": "Published at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representing entities and relations in an embedding space is a well-studied\napproach for machine learning on relational data. Existing approaches, however,\nprimarily focus on simple link structure between a finite set of entities,\nignoring the variety of data types that are often used in knowledge bases, such\nas text, images, and numerical values. In this paper, we propose multimodal\nknowledge base embeddings (MKBE) that use different neural encoders for this\nvariety of observed data, and combine them with existing relational models to\nlearn embeddings of the entities and multimodal data. Further, using these\nlearned embedings and different neural decoders, we introduce a novel\nmultimodal imputation model to generate missing multimodal values, like text\nand images, from information in the knowledge base. We enrich existing\nrelational datasets to create two novel benchmarks that contain additional\ninformation such as textual descriptions and images of the original entities.\nWe demonstrate that our models utilize this additional information effectively\nto provide more accurate link prediction, achieving state-of-the-art results\nwith a considerable gap of 5-7% over existing methods. Further, we evaluate the\nquality of our generated multimodal values via a user study. We have release\nthe datasets and the open-source implementation of our models at\nhttps://github.com/pouyapez/mkbe\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 06:07:31 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 18:13:10 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Pezeshkpour", "Pouya", ""], ["Chen", "Liyan", ""], ["Singh", "Sameer", ""]]}, {"id": "1809.01479", "submitter": "Andreas Hanselowski Dr.", "authors": "Andreas Hanselowski, Hao Zhang, Zile Li, Daniil Sorokin, Benjamin\n  Schiller, Claudia Schulz, Iryna Gurevych", "title": "UKP-Athene: Multi-Sentence Textual Entailment for Claim Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Fact Extraction and VERification (FEVER) shared task was launched to\nsupport the development of systems able to verify claims by extracting\nsupporting or refuting facts from raw text. The shared task organizers provide\na large-scale dataset for the consecutive steps involved in claim verification,\nin particular, document retrieval, fact extraction, and claim classification.\nIn this paper, we present our claim verification pipeline approach, which,\naccording to the preliminary results, scored third in the shared task, out of\n23 competing systems. For the document retrieval, we implemented a new entity\nlinking approach. In order to be able to rank candidate facts and classify a\nclaim on the basis of several selected facts, we introduce two extensions to\nthe Enhanced LSTM (ESIM).\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 14:06:11 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 10:45:21 GMT"}, {"version": "v3", "created": "Wed, 13 Feb 2019 13:42:34 GMT"}, {"version": "v4", "created": "Wed, 8 May 2019 15:35:47 GMT"}, {"version": "v5", "created": "Thu, 9 May 2019 08:00:19 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Hanselowski", "Andreas", ""], ["Zhang", "Hao", ""], ["Li", "Zile", ""], ["Sorokin", "Daniil", ""], ["Schiller", "Benjamin", ""], ["Schulz", "Claudia", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1809.01497", "submitter": "Jingfeng Yang", "authors": "Jingfeng Yang and Sujian Li", "title": "Chinese Discourse Segmentation Using Bilingual Discourse Commonality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discourse segmentation aims to segment Elementary Discourse Units (EDUs) and\nis a fundamental task in discourse analysis. For Chinese, previous researches\nidentify EDUs just through discriminating the functions of punctuations. In\nthis paper, we argue that Chinese EDUs may not end at the punctuation positions\nand should follow the definition of EDU in RST-DT. With this definition, we\nconduct Chinese discourse segmentation with the help of English labeled\ndata.Using discourse commonality between English and Chinese, we design an\nadversarial neural network framework to extract common language-independent\nfeatures and language-specific features which are useful for discourse\nsegmentation, when there is no or only a small scale of Chinese labeled data\navailable. Experiments on discourse segmentation demonstrate that our models\ncan leverage common features from bilingual data, and learn efficient\nChinese-specific features from a small amount of Chinese labeled data,\noutperforming the baseline models.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 00:57:09 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Yang", "Jingfeng", ""], ["Li", "Sujian", ""]]}, {"id": "1809.01498", "submitter": "Benjamin Wilson", "authors": "Matthias Leimeister, Benjamin J. Wilson", "title": "Skip-gram word embeddings in hyperbolic space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has demonstrated that embeddings of tree-like graphs in\nhyperbolic space surpass their Euclidean counterparts in performance by a large\nmargin. Inspired by these results and scale-free structure in the word\nco-occurrence graph, we present an algorithm for learning word embeddings in\nhyperbolic space from free text. An objective function based on the hyperbolic\ndistance is derived and included in the skip-gram negative-sampling\narchitecture of word2vec. The hyperbolic word embeddings are then evaluated on\nword similarity and analogy benchmarks. The results demonstrate the potential\nof hyperbolic word embeddings, particularly in low dimensions, though without\nclear superiority over their Euclidean counterparts. We further discuss\nsubtleties in the formulation of the analogy task in curved spaces.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 13:54:45 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 12:36:58 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Leimeister", "Matthias", ""], ["Wilson", "Benjamin J.", ""]]}, {"id": "1809.01524", "submitter": "Christopher Bates", "authors": "Christopher J. Bates and Ilker Yildirim and Joshua B. Tenenbaum and\n  Peter Battaglia", "title": "Modeling human intuitions about liquid flow with particle-based\n  simulation", "comments": "Under review at PLOS Computational Biology", "journal-ref": null, "doi": "10.1371/journal.pcbi.1007210", "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans can easily describe, imagine, and, crucially, predict a wide variety\nof behaviors of liquids--splashing, squirting, gushing, sloshing, soaking,\ndripping, draining, trickling, pooling, and pouring--despite tremendous\nvariability in their material and dynamical properties. Here we propose and\ntest a computational model of how people perceive and predict these liquid\ndynamics, based on coarse approximate simulations of fluids as collections of\ninteracting particles. Our model is analogous to a \"game engine in the head\",\ndrawing on techniques for interactive simulations (as in video games) that\noptimize for efficiency and natural appearance rather than physical accuracy.\nIn two behavioral experiments, we found that the model accurately captured\npeople's predictions about how liquids flow among complex solid obstacles, and\nwas significantly better than two alternatives based on simple heuristics and\ndeep neural networks. Our model was also able to explain how people's\npredictions varied as a function of the liquids' properties (e.g., viscosity\nand stickiness). Together, the model and empirical results extend the recent\nproposal that human physical scene understanding for the dynamics of rigid,\nsolid objects can be supported by approximate probabilistic simulation, to the\nmore complex and unexplored domain of fluid dynamics.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 14:03:32 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Bates", "Christopher J.", ""], ["Yildirim", "Ilker", ""], ["Tenenbaum", "Joshua B.", ""], ["Battaglia", "Peter", ""]]}, {"id": "1809.01560", "submitter": "Victor Gallego", "authors": "Victor Gallego, Roi Naveiro, David Rios Insua", "title": "Reinforcement Learning under Threats", "comments": "Extends the verson published at the Proceedings of the AAAI\n  Conference on Artificial Intelligence 33,\n  https://www.aaai.org/ojs/index.php/AAAI/article/view/5106", "journal-ref": null, "doi": "10.1609/aaai.v33i01.33019939", "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In several reinforcement learning (RL) scenarios, mainly in security\nsettings, there may be adversaries trying to interfere with the reward\ngenerating process. In this paper, we introduce Threatened Markov Decision\nProcesses (TMDPs), which provide a framework to support a decision maker\nagainst a potential adversary in RL. Furthermore, we propose a level-$k$\nthinking scheme resulting in a new learning framework to deal with TMDPs. After\nintroducing our framework and deriving theoretical results, relevant empirical\nevidence is given via extensive experiments, showing the benefits of accounting\nfor adversaries while the agent learns.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 14:56:09 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 12:15:05 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Gallego", "Victor", ""], ["Naveiro", "Roi", ""], ["Insua", "David Rios", ""]]}, {"id": "1809.01564", "submitter": "Julian Nubert", "authors": "Julian Nubert, Nicholas Giai Truong, Abel Lim, Herbert Ilhan Tanujaya,\n  Leah Lim, Mai Anh Vu", "title": "Traffic Density Estimation using a Convolutional Neural Network", "comments": "Machine Learning Project National University of Singapore. 6 pages, 5\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this project is to introduce and present a machine learning\napplication that aims to improve the quality of life of people in Singapore. In\nparticular, we investigate the use of machine learning solutions to tackle the\nproblem of traffic congestion in Singapore. In layman's terms, we seek to make\nSingapore (or any other city) a smoother place. To accomplish this aim, we\npresent an end-to-end system comprising of 1. A traffic density estimation\nalgorithm at traffic lights/junctions and 2. a suitable traffic signal control\nalgorithms that make use of the density information for better traffic control.\nTraffic density estimation can be obtained from traffic junction images using\nvarious machine learning techniques (combined with CV tools). After research\ninto various advanced machine learning methods, we decided on convolutional\nneural networks (CNNs). We conducted experiments on our algorithms, using the\npublicly available traffic camera dataset published by the Land Transport\nAuthority (LTA) to demonstrate the feasibility of this approach. With these\ntraffic density estimates, different traffic algorithms can be applied to\nminimize congestion at traffic junctions in general.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 15:03:23 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Nubert", "Julian", ""], ["Truong", "Nicholas Giai", ""], ["Lim", "Abel", ""], ["Tanujaya", "Herbert Ilhan", ""], ["Lim", "Leah", ""], ["Vu", "Mai Anh", ""]]}, {"id": "1809.01575", "submitter": "Heinke Hihn", "authors": "Heinke Hihn, Sebastian Gottwald, and Daniel A. Braun", "title": "Bounded Rational Decision-Making with Adaptive Neural Network Priors", "comments": "Published in ANNPR 2018: Artificial Neural Networks in Pattern\n  Recognition", "journal-ref": "Pancioni L., Schwenker F., Trentin E. (eds) Artificial Neural\n  Networks in Pattern Recognition. ANNPR 2018. Lecture Notes in Computer\n  Science, vol 11081. Springer, Cham", "doi": "10.1007/978-3-319-99978-4_17", "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bounded rationality investigates utility-optimizing decision-makers with\nlimited information-processing power. In particular, information theoretic\nbounded rationality models formalize resource constraints abstractly in terms\nof relative Shannon information, namely the Kullback-Leibler Divergence between\nthe agents' prior and posterior policy. Between prior and posterior lies an\nanytime deliberation process that can be instantiated by sample-based\nevaluations of the utility function through Markov Chain Monte Carlo (MCMC)\noptimization. The most simple model assumes a fixed prior and can relate\nabstract information-theoretic processing costs to the number of sample\nevaluations. However, more advanced models would also address the question of\nlearning, that is how the prior is adapted over time such that generated prior\nproposals become more efficient. In this work we investigate generative neural\nnetworks as priors that are optimized concurrently with anytime sample-based\ndecision-making processes such as MCMC. We evaluate this approach on toy\nexamples.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 08:36:09 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Hihn", "Heinke", ""], ["Gottwald", "Sebastian", ""], ["Braun", "Daniel A.", ""]]}, {"id": "1809.01577", "submitter": "Chenguang Lu", "authors": "Chenguang Lu", "title": "From Bayesian Inference to Logical Bayesian Inference: A New\n  Mathematical Frame for Semantic Communication and Machine Learning", "comments": "12 Pages, 1 figure, 31 equations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Inference (BI) uses the Bayes' posterior whereas Logical Bayesian\nInference (LBI) uses the truth function or membership function as the inference\ntool. LBI was proposed because BI was not compatible with the classical Bayes'\nprediction and didn't use logical probability and hence couldn't express\nsemantic meaning. In LBI, statistical probability and logical probability are\nstrictly distinguished, used at the same time, and linked by the third kind of\nBayes' Theorem. The Shannon channel consists of a set of transition probability\nfunctions whereas the semantic channel consists of a set of truth functions.\nWhen a sample is large enough, we can directly derive the semantic channel from\nShannon's channel. Otherwise, we can use parameters to construct truth\nfunctions and use the Maximum Semantic Information (MSI) criterion to optimize\nthe truth functions. The MSI criterion is equivalent to the Maximum Likelihood\n(ML) criterion, and compatible with the Regularized Least Square (RLS)\ncriterion. By matching the two channels one with another, we can obtain the\nChannels' Matching (CM) algorithm. This algorithm can improve multi-label\nclassifications, maximum likelihood estimations (including unseen instance\nclassifications), and mixture models. In comparison with BI, LBI 1) uses the\nprior P(X) of X instead of that of Y or {\\theta} and fits cases where the\nsource P(X) changes, 2) can be used to solve the denotations of labels, and 3)\nis more compatible with the classical Bayes' prediction and likelihood method.\nLBI also provides a confirmation measure between -1 and 1 for induction.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 11:39:11 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Lu", "Chenguang", ""]]}, {"id": "1809.01587", "submitter": "Minsuk Kahng", "authors": "Minsuk Kahng, Nikhil Thorat, Duen Horng Chau, Fernanda Vi\\'egas,\n  Martin Wattenberg", "title": "GAN Lab: Understanding Complex Deep Generative Models using Interactive\n  Visual Experimentation", "comments": "This paper will be published in the IEEE Transactions on\n  Visualization and Computer Graphics, 25(1), January 2019, and presented at\n  IEEE VAST 2018", "journal-ref": null, "doi": "10.1109/TVCG.2018.2864500", "report-no": null, "categories": "cs.HC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent success in deep learning has generated immense interest among\npractitioners and students, inspiring many to learn about this new technology.\nWhile visual and interactive approaches have been successfully developed to\nhelp people more easily learn deep learning, most existing tools focus on\nsimpler models. In this work, we present GAN Lab, the first interactive\nvisualization tool designed for non-experts to learn and experiment with\nGenerative Adversarial Networks (GANs), a popular class of complex deep\nlearning models. With GAN Lab, users can interactively train generative models\nand visualize the dynamic training process's intermediate results. GAN Lab\ntightly integrates an model overview graph that summarizes GAN's structure, and\na layered distributions view that helps users interpret the interplay between\nsubmodels. GAN Lab introduces new interactive experimentation features for\nlearning complex deep learning models, such as step-by-step training at\nmultiple levels of abstraction for understanding intricate training dynamics.\nImplemented using TensorFlow.js, GAN Lab is accessible to anyone via modern web\nbrowsers, without the need for installation or specialized hardware, overcoming\na major practical challenge in deploying interactive tools for deep learning.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 15:51:50 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Kahng", "Minsuk", ""], ["Thorat", "Nikhil", ""], ["Chau", "Duen Horng", ""], ["Vi\u00e9gas", "Fernanda", ""], ["Wattenberg", "Martin", ""]]}, {"id": "1809.01604", "submitter": "Julian Dolby", "authors": "Kavitha Srinivas, Abraham Gale, Julian Dolby", "title": "Merging datasets through deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Merging datasets is a key operation for data analytics. A frequent\nrequirement for merging is joining across columns that have different surface\nforms for the same entity (e.g., the name of a person might be represented as\n\"Douglas Adams\" or \"Adams, Douglas\"). Similarly, ontology alignment can require\nrecognizing distinct surface forms of the same entity, especially when\nontologies are independently developed. However, data management systems are\ncurrently limited to performing merges based on string equality, or at best\nusing string similarity. We propose an approach to performing merges based on\ndeep learning models. Our approach depends on (a) creating a deep learning\nmodel that maps surface forms of an entity into a set of vectors such that\nalternate forms for the same entity are closest in vector space, (b) indexing\nthese vectors using a nearest neighbors algorithm to find the forms that can be\npotentially joined together. To build these models, we had to adapt techniques\nfrom metric learning due to the characteristics of the data; specifically we\ndescribe novel sample selection techniques and loss functions that work for\nthis problem. To evaluate our approach, we used Wikidata as ground truth and\nbuilt models from datasets with approximately 1.1M people's names (200K\nidentities) and 130K company names (70K identities). We developed models that\nallow for joins with precision@1 of .75-.81 and recall of .74-.81. We make the\nmodels available for aligning people or companies across multiple datasets.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 16:19:26 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Srinivas", "Kavitha", ""], ["Gale", "Abraham", ""], ["Dolby", "Julian", ""]]}, {"id": "1809.01621", "submitter": "Marco Antonio Casanova", "authors": "Marco A. Casanova, R\\^omulo Magalh\\~aes", "title": "An Algebra of Lightweight Ontologies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper argues that certain ontology design problems are profitably\naddressed by treating ontologies as theories and by defining a set of\noperations that create new ontologies, including their constraints, out of\nother ontologies. The paper first shows how to use the operations in the\ncontext of ontology reuse, how to take advantage of the operations to compare\ndifferent ontologies, or different versions of an ontology, and how the\noperations may help design mediated schemas in a bottom up fashion. The core of\nthe paper discusses how to compute the operations for lightweight ontologies\nand addresses the question of minimizing the set of constraints of a\nlightweight ontology. Finally, the paper describes an implementation of the\noperations, as a Prot\\'eg\\'e plug-in.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 17:00:10 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Casanova", "Marco A.", ""], ["Magalh\u00e3es", "R\u00f4mulo", ""]]}, {"id": "1809.01628", "submitter": "Mariana Souza", "authors": "Mariana A. Souza, George D. C. Cavalcanti, Rafael M. O. Cruz, Robert\n  Sabourin", "title": "Online local pool generation for dynamic classifier selection: an\n  extended version", "comments": "Extended version of the paper: M. A. Souza, G. D. Cavalcanti, R. M.\n  Cruz, R. Sabourin, Online local pool generation for dynamic classifier\n  selection, Pattern Recognition 85 (2019) 132 - 148", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Classifier Selection (DCS) techniques have difficulty in selecting\nthe most competent classifier in a pool, even when its presence is assured.\nSince the DCS techniques rely only on local data to estimate a classifier's\ncompetence, the manner in which the pool is generated could affect the choice\nof the best classifier for a given sample. That is, the global perspective in\nwhich pools are generated may not help the DCS techniques in selecting a\ncompetent classifier for samples that are likely to be mislabelled. Thus, we\npropose in this work an online pool generation method that produces a locally\naccurate pool for test samples in difficult regions of the feature space. The\ndifficulty of a given area is determined by the classification difficulty of\nthe samples in it. That way, by using classifiers that were generated in a\nlocal scope, it could be easier for the DCS techniques to select the best one\nfor the difficult samples. For the query samples in easy regions, a simple\nnearest neighbors rule is used. In the extended version of this work, a deep\nanalysis on the correlation between instance hardness and the performance of\nDCS techniques is presented. An instance hardness measure that conveys the\ndegree of local class overlap is then used to decide when the local pool is\nused in the proposed scheme. The proposed method yielded significantly greater\nrecognition rates in comparison to a Bagging-generated pool and two other\nglobal pool generation schemes for all DCS techniques evaluated. The proposed\nscheme's performance was also significantly superior to three state-of-the-art\nclassification models and statistically equivalent to five of them. Moreover,\nan extended analysis on the computational complexity of the proposed method and\nof several DS techniques is presented in this version. We also provide the\nimplementation of the proposed technique using the DESLib library on GitHub.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 17:13:02 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Souza", "Mariana A.", ""], ["Cavalcanti", "George D. C.", ""], ["Cruz", "Rafael M. O.", ""], ["Sabourin", "Robert", ""]]}, {"id": "1809.01696", "submitter": "Jie Lei", "authors": "Jie Lei, Licheng Yu, Mohit Bansal, Tamara L. Berg", "title": "TVQA: Localized, Compositional Video Question Answering", "comments": "EMNLP 2018 (13 pages; Data and Leaderboard at:\n  http://tvqa.cs.unc.edu). Updated with test-public results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed an increasing interest in image-based\nquestion-answering (QA) tasks. However, due to data limitations, there has been\nmuch less work on video-based QA. In this paper, we present TVQA, a large-scale\nvideo QA dataset based on 6 popular TV shows. TVQA consists of 152,545 QA pairs\nfrom 21,793 clips, spanning over 460 hours of video. Questions are designed to\nbe compositional in nature, requiring systems to jointly localize relevant\nmoments within a clip, comprehend subtitle-based dialogue, and recognize\nrelevant visual concepts. We provide analyses of this new dataset as well as\nseveral baselines and a multi-stream end-to-end trainable neural network\nframework for the TVQA task. The dataset is publicly available at\nhttp://tvqa.cs.unc.edu.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 19:14:11 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 21:34:05 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Lei", "Jie", ""], ["Yu", "Licheng", ""], ["Bansal", "Mohit", ""], ["Berg", "Tamara L.", ""]]}, {"id": "1809.01721", "submitter": "Ismail Shahin", "authors": "Ismail Shahin and Ali Bou Nassif", "title": "Three-Stage Speaker Verification Architecture in Emotional Talking\n  Environments", "comments": "18 pages. arXiv admin note: substantial text overlap with\n  arXiv:1804.00155, arXiv:1707.00137", "journal-ref": "International Journal of Speech Technology, 2018", "doi": "10.1007/s10772-018-9543-4", "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker verification performance in neutral talking environment is usually\nhigh, while it is sharply decreased in emotional talking environments. This\nperformance degradation in emotional environments is due to the problem of\nmismatch between training in neutral environment while testing in emotional\nenvironments. In this work, a three-stage speaker verification architecture has\nbeen proposed to enhance speaker verification performance in emotional\nenvironments. This architecture is comprised of three cascaded stages: gender\nidentification stage followed by an emotion identification stage followed by a\nspeaker verification stage. The proposed framework has been evaluated on two\ndistinct and independent emotional speech datasets: in-house dataset and\nEmotional Prosody Speech and Transcripts dataset. Our results show that speaker\nverification based on both gender information and emotion information is\nsuperior to each of speaker verification based on gender information only,\nemotion information only, and neither gender information nor emotion\ninformation. The attained average speaker verification performance based on the\nproposed framework is very alike to that attained in subjective assessment by\nhuman listeners.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 09:25:35 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Shahin", "Ismail", ""], ["Nassif", "Ali Bou", ""]]}, {"id": "1809.01771", "submitter": "Roger Stein", "authors": "Roger A. Stein, Patricia A. Jaques, Joao F. Valiati", "title": "An Analysis of Hierarchical Text Classification Using Word Embeddings", "comments": "Article accepted for publication in Information Sciences on Sep 1st,\n  2018", "journal-ref": null, "doi": "10.1016/j.ins.2018.09.001", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient distributed numerical word representation models (word embeddings)\ncombined with modern machine learning algorithms have recently yielded\nconsiderable improvement on automatic document classification tasks. However,\nthe effectiveness of such techniques has not been assessed for the hierarchical\ntext classification (HTC) yet. This study investigates the application of those\nmodels and algorithms on this specific problem by means of experimentation and\nanalysis. We trained classification models with prominent machine learning\nalgorithm implementations---fastText, XGBoost, SVM, and Keras' CNN---and\nnoticeable word embeddings generation methods---GloVe, word2vec, and\nfastText---with publicly available data and evaluated them with measures\nspecifically appropriate for the hierarchical context. FastText achieved an\n${}_{LCA}F_1$ of 0.893 on a single-labeled version of the RCV1 dataset. An\nanalysis indicates that using word embeddings and its flavors is a very\npromising approach for HTC.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 00:31:51 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Stein", "Roger A.", ""], ["Jaques", "Patricia A.", ""], ["Valiati", "Joao F.", ""]]}, {"id": "1809.01807", "submitter": "Kory W Mathewson", "authors": "Kory W. Mathewson and Piotr Mirowski", "title": "Improbotics: Exploring the Imitation Game using Machine Intelligence in\n  Improvised Theatre", "comments": "8 pages, 6 figures, AAAI Publications, 2018 Artificial Intelligence\n  and Interactive Digital Entertainment Conference (AIIDE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Theatrical improvisation (impro or improv) is a demanding form of live,\ncollaborative performance. Improv is a humorous and playful artform built on an\nopen-ended narrative structure which simultaneously celebrates effort and\nfailure. It is thus an ideal test bed for the development and deployment of\ninteractive artificial intelligence (AI)-based conversational agents, or\nartificial improvisors. This case study introduces an improv show experiment\nfeaturing human actors and artificial improvisors. We have previously developed\na deep-learning-based artificial improvisor, trained on movie subtitles, that\ncan generate plausible, context-based, lines of dialogue suitable for theatre\n(Mathewson and Mirowski 2017). In this work, we have employed it to control\nwhat a subset of human actors say during an improv performance. We also give\nhuman-generated lines to a different subset of performers. All lines are\nprovided to actors with headphones and all performers are wearing headphones.\nThis paper describes a Turing test, or imitation game, taking place in a\ntheatre, with both the audience members and the performers left to guess who is\na human and who is a machine. In order to test scientific hypotheses about the\nperception of humans versus machines we collect anonymous feedback from\nvolunteer performers and audience members. Our results suggest that rehearsal\nincreases proficiency and possibility to control events in the performance.\nThat said, consistency with real world experience is limited by the interface\nand the mechanisms used to perform the show. We also show that human-generated\nlines are shorter, more positive, and have less difficult words with more\ngrammar and spelling mistakes than the artificial improvisor generated lines.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 03:46:01 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Mathewson", "Kory W.", ""], ["Mirowski", "Piotr", ""]]}, {"id": "1809.01816", "submitter": "Marcus Rohrbach", "authors": "Satwik Kottur, Jos\\'e M. F. Moura, Devi Parikh, Dhruv Batra, Marcus\n  Rohrbach", "title": "Visual Coreference Resolution in Visual Dialog using Neural Module\n  Networks", "comments": "ECCV 2018 + results on VisDial v1.0 dataset", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual dialog entails answering a series of questions grounded in an image,\nusing dialog history as context. In addition to the challenges found in visual\nquestion answering (VQA), which can be seen as one-round dialog, visual dialog\nencompasses several more. We focus on one such problem called visual\ncoreference resolution that involves determining which words, typically noun\nphrases and pronouns, co-refer to the same entity/object instance in an image.\nThis is crucial, especially for pronouns (e.g., `it'), as the dialog agent must\nfirst link it to a previous coreference (e.g., `boat'), and only then can rely\non the visual grounding of the coreference `boat' to reason about the pronoun\n`it'. Prior work (in visual dialog) models visual coreference resolution either\n(a) implicitly via a memory network over history, or (b) at a coarse level for\nthe entire question; and not explicitly at a phrase level of granularity. In\nthis work, we propose a neural module network architecture for visual dialog by\nintroducing two novel modules - Refer and Exclude - that perform explicit,\ngrounded, coreference resolution at a finer word level. We demonstrate the\neffectiveness of our model on MNIST Dialog, a visually simple yet\ncoreference-wise complex dataset, by achieving near perfect accuracy, and on\nVisDial, a large and challenging visual dialog dataset on real images, where\nour model outperforms other approaches, and is more interpretable, grounded,\nand consistent qualitatively.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 04:36:22 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Kottur", "Satwik", ""], ["Moura", "Jos\u00e9 M. F.", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""], ["Rohrbach", "Marcus", ""]]}, {"id": "1809.01819", "submitter": "Saachi Jain", "authors": "Saachi Jain, David Hallac, Rok Sosic, Jure Leskovec", "title": "MASA: Motif-Aware State Assignment in Noisy Time Series Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex systems, such as airplanes, cars, or financial markets, produce\nmultivariate time series data consisting of a large number of system\nmeasurements over a period of time. Such data can be interpreted as a sequence\nof states, where each state represents a prototype of system behavior. An\nimportant problem in this domain is to identify repeated sequences of states,\nknown as motifs. Such motifs correspond to complex behaviors that capture\ncommon sequences of state transitions. For example, in automotive data, a motif\nof \"making a turn\" might manifest as a sequence of states: slowing down,\nturning the wheel, and then speeding back up. However, discovering these motifs\nis challenging, because the individual states and state assignments are\nunknown, have different durations, and need to be jointly learned from the\nnoisy time series. Here we develop motif-aware state assignment (MASA), a\nmethod to discover common motifs in noisy time series data and leverage those\nmotifs to more robustly assign states to measurements. We formulate the problem\nof motif discovery as a large optimization problem, which we solve using an\nexpectation-maximization type approach. MASA performs well in the presence of\nnoise in the input data and is scalable to very large datasets. Experiments on\nsynthetic data show that MASA outperforms state-of-the-art baselines by up to\n38.2%, and two case studies demonstrate how our approach discovers insightful\nmotifs in the presence of noise in real-world time series data.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 04:50:08 GMT"}, {"version": "v2", "created": "Sun, 23 Jun 2019 00:24:56 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Jain", "Saachi", ""], ["Hallac", "David", ""], ["Sosic", "Rok", ""], ["Leskovec", "Jure", ""]]}, {"id": "1809.01843", "submitter": "Jonathan Efroni", "authors": "Yonathan Efroni, Gal Dalal, Bruno Scherrer, Shie Mannor", "title": "How to Combine Tree-Search Methods in Reinforcement Learning", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finite-horizon lookahead policies are abundantly used in Reinforcement\nLearning and demonstrate impressive empirical success. Usually, the lookahead\npolicies are implemented with specific planning methods such as Monte Carlo\nTree Search (e.g. in AlphaZero). Referring to the planning problem as tree\nsearch, a reasonable practice in these implementations is to back up the value\nonly at the leaves while the information obtained at the root is not leveraged\nother than for updating the policy. Here, we question the potency of this\napproach. Namely, the latter procedure is non-contractive in general, and its\nconvergence is not guaranteed. Our proposed enhancement is straightforward and\nsimple: use the return from the optimal tree path to back up the values at the\ndescendants of the root. This leads to a $\\gamma^h$-contracting procedure,\nwhere $\\gamma$ is the discount factor and $h$ is the tree depth. To establish\nour results, we first introduce a notion called \\emph{multiple-step greedy\nconsistency}. We then provide convergence rates for two algorithmic\ninstantiations of the above enhancement in the presence of noise injected to\nboth the tree search stage and value estimation stage.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 06:40:08 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2019 07:26:42 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Efroni", "Yonathan", ""], ["Dalal", "Gal", ""], ["Scherrer", "Bruno", ""], ["Mannor", "Shie", ""]]}, {"id": "1809.01852", "submitter": "Junyuan Shang", "authors": "Junyuan Shang, Cao Xiao, Tengfei Ma, Hongyan Li, Jimeng Sun", "title": "GAMENet: Graph Augmented MEmory Networks for Recommending Medication\n  Combination", "comments": "AAAI 2019; change the template and fix some typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent progress in deep learning is revolutionizing the healthcare domain\nincluding providing solutions to medication recommendations, especially\nrecommending medication combination for patients with complex health\nconditions. Existing approaches either do not customize based on patient health\nhistory, or ignore existing knowledge on drug-drug interactions (DDI) that\nmight lead to adverse outcomes. To fill this gap, we propose the Graph\nAugmented Memory Networks (GAMENet), which integrates the drug-drug\ninteractions knowledge graph by a memory module implemented as a graph\nconvolutional networks, and models longitudinal patient records as the query.\nIt is trained end-to-end to provide safe and personalized recommendation of\nmedication combination. We demonstrate the effectiveness and safety of GAMENet\nby comparing with several state-of-the-art methods on real EHR data. GAMENet\noutperformed all baselines in all effectiveness measures, and also achieved\n3.60% DDI rate reduction from existing EHR data.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 07:30:13 GMT"}, {"version": "v2", "created": "Sat, 17 Nov 2018 06:56:54 GMT"}, {"version": "v3", "created": "Thu, 7 Mar 2019 04:27:19 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Shang", "Junyuan", ""], ["Xiao", "Cao", ""], ["Ma", "Tengfei", ""], ["Li", "Hongyan", ""], ["Sun", "Jimeng", ""]]}, {"id": "1809.01898", "submitter": "Jo\\~ao R. Campos", "authors": "Jo\\~ao R. Campos, Marco Vieira, Ernesto Costa", "title": "Propheticus: Generalizable Machine Learning Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to recent technological developments, Machine Learning (ML), a subfield\nof Artificial Intelligence (AI), has been successfully used to process and\nextract knowledge from a variety of complex problems. However, a thorough ML\napproach is complex and highly dependent on the problem at hand. Additionally,\nimplementing the logic required to execute the experiments is no small nor\ntrivial deed, consequentially increasing the probability of faulty code which\ncan compromise the results. Propheticus is a data-driven framework which\nresults of the need for a tool that abstracts some of the inherent complexity\nof ML, whilst being easy to understand and use, as well as to adapt and expand\nto assist the user's specific needs. Propheticus systematizes and enforces\nvarious complex concepts of an ML experiment workflow, taking into account the\nnature of both the problem and the data. It contains functionalities to execute\nall the different tasks, from data preprocessing, to results analysis and\ncomparison. Notwithstanding, it can be fairly easily adapted to different\nproblems due to its flexible architecture, and customized as needed to address\nthe user's needs.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 09:26:03 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Campos", "Jo\u00e3o R.", ""], ["Vieira", "Marco", ""], ["Costa", "Ernesto", ""]]}, {"id": "1809.01941", "submitter": "Shaojie Jiang", "authors": "Shaojie Jiang, Maarten de Rijke", "title": "Why are Sequence-to-Sequence Models So Dull? Understanding the\n  Low-Diversity Problem of Chatbots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diversity is a long-studied topic in information retrieval that usually\nrefers to the requirement that retrieved results should be non-repetitive and\ncover different aspects. In a conversational setting, an additional dimension\nof diversity matters: an engaging response generation system should be able to\noutput responses that are diverse and interesting. Sequence-to-sequence\n(Seq2Seq) models have been shown to be very effective for response generation.\nHowever, dialogue responses generated by Seq2Seq models tend to have low\ndiversity. In this paper, we review known sources and existing approaches to\nthis low-diversity problem. We also identify a source of low diversity that has\nbeen little studied so far, namely model over-confidence. We sketch several\ndirections for tackling model over-confidence and, hence, the low-diversity\nproblem, including confidence penalties and label smoothing.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 12:24:04 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Jiang", "Shaojie", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1809.01942", "submitter": "Augusto Luis Ballardini", "authors": "Augusto Luis Ballardini", "title": "A tutorial on Particle Swarm Optimization Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a tutorial on the Data Clustering technique using the\nParticle Swarm Optimization approach. Following the work proposed by Merwe et\nal. here we present an in-deep analysis of the algorithm together with a Matlab\nimplementation and a short tutorial that explains how to modify the proposed\nimplementation and the effect of the parameters of the original algorithm.\nMoreover, we provide a comparison against the results obtained using the well\nknown K-Means approach. All the source code presented in this paper is publicly\navailable under the GPL-v2 license.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 12:24:44 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Ballardini", "Augusto Luis", ""]]}, {"id": "1809.01943", "submitter": "Jiaming Xu", "authors": "Yiqun Yao, Jiaming Xu, Feng Wang, Bo Xu", "title": "Cascaded Mutual Modulation for Visual Reasoning", "comments": "to appear in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Visual reasoning is a special visual question answering problem that is\nmulti-step and compositional by nature, and also requires intensive text-vision\ninteractions. We propose CMM: Cascaded Mutual Modulation as a novel end-to-end\nvisual reasoning model. CMM includes a multi-step comprehension process for\nboth question and image. In each step, we use a Feature-wise Linear Modulation\n(FiLM) technique to enable textual/visual pipeline to mutually control each\nother. Experiments show that CMM significantly outperforms most related models,\nand reach state-of-the-arts on two visual reasoning benchmarks: CLEVR and NLVR,\ncollected from both synthetic and natural languages. Ablation studies confirm\nthat both our multistep framework and our visual-guided language modulation are\ncritical to the task. Our code is available at\nhttps://github.com/FlamingHorizon/CMM-VR.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 12:26:24 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Yao", "Yiqun", ""], ["Xu", "Jiaming", ""], ["Wang", "Feng", ""], ["Xu", "Bo", ""]]}, {"id": "1809.01991", "submitter": "Fabrizio Sebastiani", "authors": "Fabrizio Sebastiani", "title": "Evaluation Measures for Quantification: An Axiomatic Approach", "comments": "36 pages, 2 figures. Submitted for publication in the Information\n  Retrieval Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantification is the task of estimating, given a set $\\sigma$ of unlabelled\nitems and a set of classes $\\mathcal{C}=\\{c_{1}, \\ldots, c_{|\\mathcal{C}|}\\}$,\nthe prevalence (or `relative frequency') in $\\sigma$ of each class $c_{i}\\in\n\\mathcal{C}$. While quantification may in principle be solved by classifying\neach item in $\\sigma$ and counting how many such items have been labelled with\n$c_{i}$, it has long been shown that this `classify and count' (CC) method\nyields suboptimal quantification accuracy. As a result, quantification is no\nlonger considered a mere byproduct of classification, and has evolved as a task\nof its own. While the scientific community has devoted a lot of attention to\ndevising more accurate quantification methods, it has not devoted much to\ndiscussing what properties an \\emph{evaluation measure for quantification}\n(EMQ) should enjoy, and which EMQs should be adopted as a result. This paper\nlies down a number of interesting properties that an EMQ may or may not enjoy,\ndiscusses if (and when) each of these properties is desirable, surveys the EMQs\nthat have been used so far, and discusses whether they enjoy or not the above\nproperties. As a result of this investigation, some of the EMQs that have been\nused in the literature turn out to be severely unfit, while others emerge as\ncloser to what the quantification community actually needs. However, a\nsignificant result is that no existing EMQ satisfies all the properties\nidentified as desirable, thus indicating that more research is needed in order\nto identify (or synthesize) a truly adequate EMQ.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 13:47:53 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Sebastiani", "Fabrizio", ""]]}, {"id": "1809.01997", "submitter": "Han Xiao", "authors": "Han Xiao, Feng Wang, Jianfeng Yan, Jingyao Zheng", "title": "Dual Ask-Answer Network for Machine Reading Comprehension", "comments": "8 pages, 5 figures, 4 tables. Code is available at\n  https://github.com/hanxiao/daanet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are three modalities in the reading comprehension setting: question,\nanswer and context. The task of question answering or question generation aims\nto infer an answer or a question when given the counterpart based on context.\nWe present a novel two-way neural sequence transduction model that connects\nthree modalities, allowing it to learn two tasks simultaneously and mutually\nbenefit one another. During training, the model receives\nquestion-context-answer triplets as input and captures the cross-modal\ninteraction via a hierarchical attention process. Unlike previous joint\nlearning paradigms that leverage the duality of question generation and\nquestion answering at data level, we solve such dual tasks at the architecture\nlevel by mirroring the network structure and partially sharing components at\ndifferent layers. This enables the knowledge to be transferred from one task to\nanother, helping the model to find a general representation for each modality.\nThe evaluation on four public datasets shows that our dual-learning model\noutperforms the mono-learning counterpart as well as the state-of-the-art joint\nmodels on both question answering and question generation tasks.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 13:57:03 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 10:55:43 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Xiao", "Han", ""], ["Wang", "Feng", ""], ["Yan", "Jianfeng", ""], ["Zheng", "Jingyao", ""]]}, {"id": "1809.02031", "submitter": "Joan Bruna", "authors": "David Folqu\\'e, Sainbayar Sukhbaatar, Arthur Szlam, Joan Bruna", "title": "Planning with Arithmetic and Geometric Attributes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A desirable property of an intelligent agent is its ability to understand its\nenvironment to quickly generalize to novel tasks and compose simpler tasks into\nmore complex ones. If the environment has geometric or arithmetic structure,\nthe agent should exploit these for faster generalization. Building on recent\nwork that augments the environment with user-specified attributes, we show that\nfurther equipping these attributes with the appropriate geometric and\narithmetic structure brings substantial gains in sample complexity.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 15:03:13 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Folqu\u00e9", "David", ""], ["Sukhbaatar", "Sainbayar", ""], ["Szlam", "Arthur", ""], ["Bruna", "Joan", ""]]}, {"id": "1809.02032", "submitter": "Tristan Aumentado-Armstrong", "authors": "Tristan Aumentado-Armstrong", "title": "Latent Molecular Optimization for Targeted Therapeutic Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE q-bio.BM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We devise an approach for targeted molecular design, a problem of interest in\ncomputational drug discovery: given a target protein site, we wish to generate\na chemical with both high binding affinity to the target and satisfactory\npharmacological properties. This problem is made difficult by the enormity and\ndiscreteness of the space of potential therapeutics, as well as the\ngraph-structured nature of biomolecular surface sites. Using a dataset of\nprotein-ligand complexes, we surmount these issues by extracting a signature of\nthe target site with a graph convolutional network and by encoding the discrete\nchemical into a continuous latent vector space. The latter embedding permits\ngradient-based optimization in molecular space, which we perform using learned\ndifferentiable models of binding affinity and other pharmacological properties.\nWe show that our approach is able to efficiently optimize these multiple\nobjectives and discover new molecules with potentially useful binding\nproperties, validated via docking methods.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 17:19:41 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Aumentado-Armstrong", "Tristan", ""]]}, {"id": "1809.02040", "submitter": "Linfeng Song", "authors": "Linfeng Song, Zhiguo Wang, Mo Yu, Yue Zhang, Radu Florian and Daniel\n  Gildea", "title": "Exploring Graph-structured Passage Representation for Multi-hop Reading\n  Comprehension with Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop reading comprehension focuses on one type of factoid question,\nwhere a system needs to properly integrate multiple pieces of evidence to\ncorrectly answer a question. Previous work approximates global evidence with\nlocal coreference information, encoding coreference chains with DAG-styled GRU\nlayers within a gated-attention reader. However, coreference is limited in\nproviding information for rich inference. We introduce a new method for better\nconnecting global evidence, which forms more complex graphs compared to DAGs.\nTo perform evidence integration on our graphs, we investigate two recent graph\nneural networks, namely graph convolutional network (GCN) and graph recurrent\nnetwork (GRN). Experiments on two standard datasets show that richer global\ninformation leads to better answers. Our method performs better than all\npublished results on these datasets.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 15:18:14 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Song", "Linfeng", ""], ["Wang", "Zhiguo", ""], ["Yu", "Mo", ""], ["Zhang", "Yue", ""], ["Florian", "Radu", ""], ["Gildea", "Daniel", ""]]}, {"id": "1809.02070", "submitter": "Tianfu Wu", "authors": "Sameera Lanka and Tianfu Wu", "title": "ARCHER: Aggressive Rewards to Counter bias in Hindsight Experience\n  Replay", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experience replay is an important technique for addressing\nsample-inefficiency in deep reinforcement learning (RL), but faces difficulty\nin learning from binary and sparse rewards due to disproportionately few\nsuccessful experiences in the replay buffer. Hindsight experience replay (HER)\nwas recently proposed to tackle this difficulty by manipulating unsuccessful\ntransitions, but in doing so, HER introduces a significant bias in the replay\nbuffer experiences and therefore achieves a suboptimal improvement in\nsample-efficiency. In this paper, we present an analysis on the source of bias\nin HER, and propose a simple and effective method to counter the bias, to most\neffectively harness the sample-efficiency provided by HER. Our method,\nmotivated by counter-factual reasoning and called ARCHER, extends HER with a\ntrade-off to make rewards calculated for hindsight experiences numerically\ngreater than real rewards. We validate our algorithm on two continuous control\nenvironments from DeepMind Control Suite - Reacher and Finger, which simulate\nmanipulation tasks with a robotic arm - in combination with various reward\nfunctions, task complexities and goal sampling strategies. Our experiments\nconsistently demonstrate that countering bias using more aggressive hindsight\nrewards increases sample efficiency, thus establishing the greater benefit of\nARCHER in RL applications with limited computing budget.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 16:08:39 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 00:31:16 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Lanka", "Sameera", ""], ["Wu", "Tianfu", ""]]}, {"id": "1809.02077", "submitter": "Zilong Lin", "authors": "Zilong Lin, Yong Shi, Zhi Xue", "title": "IDSGAN: Generative Adversarial Networks for Attack Generation against\n  Intrusion Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an important tool in security, the intrusion detection system bears the\nresponsibility of the defense to network attacks performed by malicious\ntraffic. Nowadays, with the help of machine learning algorithms, the intrusion\ndetection system develops rapidly. However, the robustness of this system is\nquestionable when it faces the adversarial attacks. To improve the detection\nsystem, more potential attack approaches are under research. In this paper, a\nframework of the generative adversarial networks, called IDSGAN, is proposed to\ngenerate the adversarial malicious traffic records aiming to attack intrusion\ndetection systems by deceiving and evading the detection. Given that the\ninternal structure of the detection system is unknown to attackers, the\nadversarial attack examples perform the black-box attacks against the detection\nsystem. IDSGAN leverages a generator to transform original malicious traffic\nrecords into adversarial malicious ones. A discriminator classifies traffic\nexamples and learns the black-box detection system. More significantly, to\nguarantee the validity of the intrusion, only part of the nonfunctional\nfeatures are modified in attack traffic. Based on the tests to the dataset\nNSL-KDD, the feasibility of the model is indicated by attacking multiple kinds\nof the detection system models with different attack categories, achieving the\nexcellent results. Moreover, the robustness of IDSGAN is verified by changing\nthe amount of the modified features.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 16:24:42 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 03:57:00 GMT"}, {"version": "v3", "created": "Sun, 16 Jun 2019 13:45:43 GMT"}, {"version": "v4", "created": "Fri, 23 Apr 2021 15:35:57 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Lin", "Zilong", ""], ["Shi", "Yong", ""], ["Xue", "Zhi", ""]]}, {"id": "1809.02079", "submitter": "Tong Niu", "authors": "Tong Niu and Mohit Bansal", "title": "Adversarial Over-Sensitivity and Over-Stability Strategies for Dialogue\n  Models", "comments": "CoNLL 2018 (15 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two categories of model-agnostic adversarial strategies that\nreveal the weaknesses of several generative, task-oriented dialogue models:\nShould-Not-Change strategies that evaluate over-sensitivity to small and\nsemantics-preserving edits, as well as Should-Change strategies that test if a\nmodel is over-stable against subtle yet semantics-changing modifications. We\nnext perform adversarial training with each strategy, employing a max-margin\napproach for negative generative examples. This not only makes the target\ndialogue model more robust to the adversarial inputs, but also helps it perform\nsignificantly better on the original inputs. Moreover, training on all\nstrategies combined achieves further improvements, achieving a new\nstate-of-the-art performance on the original task (also verified via human\nevaluation). In addition to adversarial training, we also address the\nrobustness task at the model-level, by feeding it subword units as both inputs\nand outputs, and show that the resulting model is equally competitive, requires\nonly 1/4 of the original vocabulary size, and is robust to one of the\nadversarial strategies (to which the original model is vulnerable) even without\nadversarial training.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 16:27:32 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Niu", "Tong", ""], ["Bansal", "Mohit", ""]]}, {"id": "1809.02094", "submitter": "Mikel Artetxe", "authors": "Mikel Artetxe, Gorka Labaka, I\\~nigo Lopez-Gazpio, Eneko Agirre", "title": "Uncovering divergent linguistic information in word embeddings with\n  lessons for intrinsic and extrinsic evaluation", "comments": "CoNLL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following the recent success of word embeddings, it has been argued that\nthere is no such thing as an ideal representation for words, as different\nmodels tend to capture divergent and often mutually incompatible aspects like\nsemantics/syntax and similarity/relatedness. In this paper, we show that each\nembedding model captures more information than directly apparent. A linear\ntransformation that adjusts the similarity order of the model without any\nexternal resource can tailor it to achieve better results in those aspects,\nproviding a new perspective on how embeddings encode divergent linguistic\ninformation. In addition, we explore the relation between intrinsic and\nextrinsic evaluation, as the effect of our transformations in downstream tasks\nis higher for unsupervised systems than for supervised ones.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 17:08:21 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Artetxe", "Mikel", ""], ["Labaka", "Gorka", ""], ["Lopez-Gazpio", "I\u00f1igo", ""], ["Agirre", "Eneko", ""]]}, {"id": "1809.02112", "submitter": "Yueh-Hua Wu", "authors": "Yueh-Hua Wu, Fan-Yun Sun, Yen-Yu Chang, Shou-De Lin", "title": "ANS: Adaptive Network Scaling for Deep Rectifier Reinforcement Learning\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work provides a thorough study on how reward scaling can affect\nperformance of deep reinforcement learning agents. In particular, we would like\nto answer the question that how does reward scaling affect non-saturating ReLU\nnetworks in RL? This question matters because ReLU is one of the most effective\nactivation functions for deep learning models. We also propose an Adaptive\nNetwork Scaling framework to find a suitable scale of the rewards during\nlearning for better performance. We conducted empirical studies to justify the\nsolution.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 17:39:18 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 03:27:13 GMT"}, {"version": "v3", "created": "Wed, 31 Oct 2018 08:00:32 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Wu", "Yueh-Hua", ""], ["Sun", "Fan-Yun", ""], ["Chang", "Yen-Yu", ""], ["Lin", "Shou-De", ""]]}, {"id": "1809.02145", "submitter": "Alexia Jolicoeur-Martineau", "authors": "Alexia Jolicoeur-Martineau", "title": "GANs beyond divergence minimization", "comments": "Associated repository:\n  https://github.com/AlexiaJM/GANsBeyondDivergenceMin", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) can be interpreted as an adversarial\ngame between two players, a discriminator D and a generator G, in which D\nlearns to classify real from fake data and G learns to generate realistic data\nby \"fooling\" D into thinking that fake data is actually real data. Currently, a\ndominating view is that G actually learns by minimizing a divergence given that\nthe general objective function is a divergence when D is optimal. However, this\nview has been challenged due to inconsistencies between theory and practice. In\nthis paper, we discuss of the properties associated with most loss functions\nfor G (e.g., saturating/non-saturating f-GAN, LSGAN, WGAN, etc.). We show that\nthese loss functions are not divergences and do not have the same equilibrium\nas expected of divergences. This suggests that G does not need to minimize the\nsame objective function as D maximize, nor maximize the objective of D after\nswapping real data with fake data (non-saturating GAN) but can instead use a\nwide range of possible loss functions to learn to generate realistic data. We\ndefine GANs through two separate and independent D maximization and G\nminimization steps. We generalize the generator step to four new classes of\nloss functions, most of which are actual divergences (while traditional G loss\nfunctions are not). We test a wide variety of loss functions from these four\nclasses on a synthetic dataset and on CIFAR-10. We observe that most loss\nfunctions converge well and provide comparable data generation quality to\nnon-saturating GAN, LSGAN, and WGAN-GP generator loss functions, whether we use\ndivergences or non-divergences. These results suggest that GANs do not conform\nwell to the divergence minimization theory and form a much broader range of\nmodels than previously assumed.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 18:00:26 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Jolicoeur-Martineau", "Alexia", ""]]}, {"id": "1809.02193", "submitter": "Andres Campero", "authors": "Andres Campero and Aldo Pareja and Tim Klinger and Josh Tenenbaum and\n  Sebastian Riedel", "title": "Logical Rule Induction and Theory Learning Using Neural Theorem Proving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hallmark of human cognition is the ability to continually acquire and\ndistill observations of the world into meaningful, predictive theories. In this\npaper we present a new mechanism for logical theory acquisition which takes a\nset of observed facts and learns to extract from them a set of logical rules\nand a small set of core facts which together entail the observations. Our\napproach is neuro-symbolic in the sense that the rule pred- icates and core\nfacts are given dense vector representations. The rules are applied to the core\nfacts using a soft unification procedure to infer additional facts. After k\nsteps of forward inference, the consequences are compared to the initial\nobservations and the rules and core facts are then encouraged towards\nrepresentations that more faithfully generate the observations through\ninference. Our approach is based on a novel neural forward-chaining\ndifferentiable rule induction network. The rules are interpretable and learned\ncompositionally from their predicates, which may be invented. We demonstrate\nthe efficacy of our approach on a variety of ILP rule induction and domain\ntheory learning datasets.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 19:49:20 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 18:46:21 GMT"}, {"version": "v3", "created": "Wed, 12 Sep 2018 21:34:59 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Campero", "Andres", ""], ["Pareja", "Aldo", ""], ["Klinger", "Tim", ""], ["Tenenbaum", "Josh", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1809.02206", "submitter": "Akshat Agarwal", "authors": "Akshat Agarwal, Ryan Hope, Katia Sycara", "title": "Challenges of Context and Time in Reinforcement Learning: Introducing\n  Space Fortress as a Benchmark", "comments": "8 pages. Code available at https://github.com/agakshat/spacefortress\n  .Supersedes arXiv:1805.06824", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in deep reinforcement learning (RL) has coalesced around improving\nperformance on benchmarks like the Arcade Learning Environment. However, these\nbenchmarks conspicuously miss important characteristics like abrupt\ncontext-dependent shifts in strategy and temporal sensitivity that are often\npresent in real-world domains. As a result, RL research has not focused on\nthese challenges, resulting in algorithms which do not understand critical\nchanges in context, and have little notion of real world time. To tackle this\nissue, this paper introduces the game of Space Fortress as a RL benchmark which\nincorporates these characteristics. We show that existing state-of-the-art RL\nalgorithms are unable to learn to play the Space Fortress game. We then confirm\nthat this poor performance is due to the RL algorithms' context insensitivity\nand reward sparsity. We also identify independent axes along which to vary\ncontext and temporal sensitivity, allowing Space Fortress to be used as a\ntestbed for understanding both characteristics in combination and also in\nisolation. We release Space Fortress as an open-source Gym environment.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 20:17:44 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Agarwal", "Akshat", ""], ["Hope", "Ryan", ""], ["Sycara", "Katia", ""]]}, {"id": "1809.02232", "submitter": "Matthew Guzdial", "authors": "Matthew Guzdial and Mark Riedl", "title": "Automated Game Design via Conceptual Expansion", "comments": "7 pages, 3 figures, Artificial Intelligence and Interactive Digital\n  Entertainment", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated game design has remained a key challenge within the field of Game\nAI. In this paper, we introduce a method for recombining existing games to\ncreate new games through a process called conceptual expansion. Prior automated\ngame design approaches have relied on hand-authored or crowd-sourced knowledge,\nwhich limits the scope and applications of such systems. Our approach instead\nrelies on machine learning to learn approximate representations of games. Our\napproach recombines knowledge from these learned representations to create new\ngames via conceptual expansion. We evaluate this approach by demonstrating the\nability for the system to recreate existing games. To the best of our\nknowledge, this represents the first machine learning-based automated game\ndesign system.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 21:53:39 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Guzdial", "Matthew", ""], ["Riedl", "Mark", ""]]}, {"id": "1809.02251", "submitter": "Zhong Meng", "authors": "Zhong Meng, Jinyu Li, Yifan Gong and Biing-Hwang (Fred) Juang", "title": "Adversarial Feature-Mapping for Speech Enhancement", "comments": "5 pages, 2 figures, Interspeech 2018", "journal-ref": "Interspeech 2018", "doi": "10.21437/Interspeech.2018-2461", "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature-mapping with deep neural networks is commonly used for single-channel\nspeech enhancement, in which a feature-mapping network directly transforms the\nnoisy features to the corresponding enhanced ones and is trained to minimize\nthe mean square errors between the enhanced and clean features. In this paper,\nwe propose an adversarial feature-mapping (AFM) method for speech enhancement\nwhich advances the feature-mapping approach with adversarial learning. An\nadditional discriminator network is introduced to distinguish the enhanced\nfeatures from the real clean ones. The two networks are jointly optimized to\nminimize the feature-mapping loss and simultaneously mini-maximize the\ndiscrimination loss. The distribution of the enhanced features is further\npushed towards that of the clean features through this adversarial multi-task\ntraining. To achieve better performance on ASR task, senone-aware (SA) AFM is\nfurther proposed in which an acoustic model network is jointly trained with the\nfeature-mapping and discriminator networks to optimize the senone\nclassification loss in addition to the AFM losses. Evaluated on the CHiME-3\ndataset, the proposed AFM achieves 16.95% and 5.27% relative word error rate\n(WER) improvements over the real noisy data and the feature-mapping baseline\nrespectively and the SA-AFM achieves 9.85% relative WER improvement over the\nmulti-conditional acoustic model.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 23:42:21 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 15:53:15 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Meng", "Zhong", "", "Fred"], ["Li", "Jinyu", "", "Fred"], ["Gong", "Yifan", "", "Fred"], ["Biing-Hwang", "", "", "Fred"], ["Juang", "", ""]]}, {"id": "1809.02260", "submitter": "Brian Shay", "authors": "Brian Shay, Patrick Brazil", "title": "The Force of Proof by Which Any Argument Prevails", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Jakob Bernoulli, working in the late 17th century, identified a gap in\ncontemporary probability theory. He cautioned that it was inadequate to specify\nforce of proof (probability of provability) for some kinds of uncertain\narguments. After 300 years, this gap remains in present-day probability theory.\nWe present axioms analogous to Kolmogorov's axioms for probability, specifying\nuncertainty that lies in an argument's inference/implication itself rather than\nin its premise and conclusion. The axioms focus on arguments spanning two\nBoolean algebras, but generalize the obligatory: \"force of proof of A implies B\nis the probability of B or not A\" in the case that the Boolean algebras are\nidentical. We propose a categorical framework that relies on generalized\nprobabilities (objects) to express uncertainty in premises, to mix with\narguments (morphisms) to express uncertainty embedded directly in\ninference/implication. There is a direct application to Shafer's evidence\ntheory (Dempster-Shafer theory), greatly expanding its scope for applications.\nTherefore, we can offer this framework not only as an optimal solution to a\ndifficult historical puzzle, but also to advance the frontiers of contemporary\nartificial intelligence.\n  Keywords: force of proof, probability of provability, Ars Conjectandi, non\nadditive probabilities, evidence theory.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 00:24:29 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Shay", "Brian", ""], ["Brazil", "Patrick", ""]]}, {"id": "1809.02306", "submitter": "Takashi Wada", "authors": "Takashi Wada, Tomoharu Iwata", "title": "Unsupervised Cross-lingual Word Embedding by Multilingual Neural\n  Language Models", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an unsupervised method to obtain cross-lingual embeddings without\nany parallel data or pre-trained word embeddings. The proposed model, which we\ncall multilingual neural language models, takes sentences of multiple languages\nas an input. The proposed model contains bidirectional LSTMs that perform as\nforward and backward language models, and these networks are shared among all\nthe languages. The other parameters, i.e. word embeddings and linear\ntransformation between hidden states and outputs, are specific to each\nlanguage. The shared LSTMs can capture the common sentence structure among all\nlanguages. Accordingly, word embeddings of each language are mapped into a\ncommon latent space, making it possible to measure the similarity of words\nacross multiple languages. We evaluate the quality of the cross-lingual word\nembeddings on a word alignment task. Our experiments demonstrate that our model\ncan obtain cross-lingual embeddings of much higher quality than existing\nunsupervised models when only a small amount of monolingual data (i.e. 50k\nsentences) are available, or the domains of monolingual data are different\nacross languages.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 04:17:40 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Wada", "Takashi", ""], ["Iwata", "Tomoharu", ""]]}, {"id": "1809.02317", "submitter": "Soumi Chattopadhyay", "authors": "Soumi Chattopadhyay, Ansuman Banerjee", "title": "QoS aware Automatic Web Service Composition with Multiple objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With an increasing number of web services, providing an end-to-end Quality of\nService (QoS) guarantee in responding to user queries is becoming an important\nconcern. Multiple QoS parameters (e.g., response time, latency, throughput,\nreliability, availability, success rate) are associated with a service,\nthereby, service composition with a large number of candidate services is a\nchallenging multi-objective optimization problem. In this paper, we study the\nmulti-constrained multi-objective QoS aware web service composition problem and\npropose three different approaches to solve the same, one optimal, based on\nPareto front construction and two other based on heuristically traversing the\nsolution space. We compare the performance of the heuristics against the\noptimal, and show the effectiveness of our proposals over other classical\napproaches for the same problem setting, with experiments on WSC-2009 and\nICEBE-2005 datasets.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 05:47:39 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Chattopadhyay", "Soumi", ""], ["Banerjee", "Ansuman", ""]]}, {"id": "1809.02343", "submitter": "Parth Mehta", "authors": "Parth Mehta, Prasenjit Majumder", "title": "Exploiting local and global performance of candidate systems for\n  aggregation of summarization techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With an ever growing number of extractive summarization techniques being\nproposed, there is less clarity then ever about how good each system is\ncompared to the rest. Several studies highlight the variance in performance of\nthese systems with change in datasets or even across documents within the same\ncorpus. An effective way to counter this variance and to make the systems more\nrobust could be to use inputs from multiple systems when generating a summary.\nIn the present work, we define a novel way of creating such ensemble by\nexploiting similarity between the content of candidate summaries to estimate\ntheir reliability. We define GlobalRank which captures the performance of a\ncandidate system on an overall corpus and LocalRank which estimates its\nperformance on a given document cluster. We then use these two scores to assign\na weight to each individual systems, which is then used to generate the new\naggregate ranking. Experiments on DUC2003 and DUC 2004 datasets show a\nsignificant improvement in terms of ROUGE score, over existing sate-of-art\ntechniques.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 08:18:01 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Mehta", "Parth", ""], ["Majumder", "Prasenjit", ""]]}, {"id": "1809.02378", "submitter": "Seydou Ba", "authors": "Seydou Ba, Takuya Hiraoka, Takashi Onishi, Toru Nakata, Yoshimasa\n  Tsuruoka", "title": "Monte Carlo Tree Search with Scalable Simulation Periods for\n  Continuously Running Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo Tree Search (MCTS) is particularly adapted to domains where the\npotential actions can be represented as a tree of sequential decisions. For an\neffective action selection, MCTS performs many simulations to build a reliable\ntree representation of the decision space. As such, a bottleneck to MCTS\nappears when enough simulations cannot be performed between action selections.\nThis is particularly highlighted in continuously running tasks, for which the\ntime available to perform simulations between actions tends to be limited due\nto the environment's state constantly changing. In this paper, we present an\napproach that takes advantage of the anytime characteristic of MCTS to increase\nthe simulation time when allowed. Our approach is to effectively balance the\nprospect of selecting an action with the time that can be spared to perform\nMCTS simulations before the next action selection. For that, we considered the\nsimulation time as a decision variable to be selected alongside an action. We\nextended the Hierarchical Optimistic Optimization applied to Tree (HOOT) method\nto adapt our approach to environments with a continuous decision space. We\nevaluated our approach for environments with a continuous decision space\nthrough OpenAI gym's Pendulum and Continuous Mountain Car environments and for\nenvironments with discrete action space through the arcade learning environment\n(ALE) platform. The evaluation results show that, with variable simulation\ntimes, the proposed approach outperforms the conventional MCTS in the evaluated\ncontinuous decision space tasks and improves the performance of MCTS in most of\nthe ALE tasks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 09:56:21 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Ba", "Seydou", ""], ["Hiraoka", "Takuya", ""], ["Onishi", "Takashi", ""], ["Nakata", "Toru", ""], ["Tsuruoka", "Yoshimasa", ""]]}, {"id": "1809.02382", "submitter": "Muhao Chen", "authors": "Muhao Chen, Yingtao Tian, Xuelu Chen, Zijun Xue, Carlo Zaniolo", "title": "On2Vec: Embedding-based Relation Prediction for Ontology Population", "comments": "SDM-18. 9 pages, 3 figures", "journal-ref": null, "doi": "10.1137/1.9781611975321.36", "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Populating ontology graphs represents a long-standing problem for the\nSemantic Web community. Recent advances in translation-based graph embedding\nmethods for populating instance-level knowledge graphs lead to promising new\napproaching for the ontology population problem. However, unlike instance-level\ngraphs, the majority of relation facts in ontology graphs come with\ncomprehensive semantic relations, which often include the properties of\ntransitivity and symmetry, as well as hierarchical relations. These\ncomprehensive relations are often too complex for existing graph embedding\nmethods, and direct application of such methods is not feasible. Hence, we\npropose On2Vec, a novel translation-based graph embedding method for ontology\npopulation. On2Vec integrates two model components that effectively\ncharacterize comprehensive relation facts in ontology graphs. The first is the\nComponent-specific Model that encodes concepts and relations into\nlow-dimensional embedding spaces without a loss of relational properties; the\nsecond is the Hierarchy Model that performs focused learning of hierarchical\nrelation facts. Experiments on several well-known ontology graphs demonstrate\nthe promising capabilities of On2Vec in predicting and verifying new relation\nfacts. These promising results also make possible significant improvements in\nrelated methods.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 10:00:53 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Chen", "Muhao", ""], ["Tian", "Yingtao", ""], ["Chen", "Xuelu", ""], ["Xue", "Zijun", ""], ["Zaniolo", "Carlo", ""]]}, {"id": "1809.02383", "submitter": "Haruo Hosoya", "authors": "Haruo Hosoya", "title": "Group-based Learning of Disentangled Representations with\n  Generalizability for Novel Contents", "comments": null, "journal-ref": "published in IJCAI 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensory data are often comprised of independent content and transformation\nfactors. For example, face images may have shapes as content and poses as\ntransformation. To infer separately these factors from given data, various\n``disentangling'' models have been proposed. However, many of these are\nsupervised or semi-supervised, either requiring attribute labels that are often\nunavailable or disallowing for generalization over new contents. In this study,\nwe introduce a novel deep generative model, called group-based variational\nautoencoders. In this, we assume no explicit labels, but a weaker form of\nstructure that groups together data instances having the same content but\ntransformed differently; we thereby separately estimate a group-common factor\nas content and an instance-specific factor as transformation. This approach\nallows for learning to represent a general continuous space of contents, which\ncan accommodate unseen contents. Despite the simplicity, our model succeeded in\nlearning, from five datasets, content representations that are highly separate\nfrom the transformation representation and generalizable to data with novel\ncontents. We further provide detailed analysis of the latent content code and\nshow insight into how our model obtains the notable transformation invariance\nand content generalizability.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 10:00:54 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 00:55:30 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Hosoya", "Haruo", ""]]}, {"id": "1809.02387", "submitter": "Yubin Deng", "authors": "Yubin Deng, Ke Yu, Dahua Lin, Xiaoou Tang, Chen Change Loy", "title": "Improving On-policy Learning with Statistical Reward Accumulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has obtained significant breakthroughs in recent\nyears. Most methods in deep-RL achieve good results via the maximization of the\nreward signal provided by the environment, typically in the form of discounted\ncumulative returns. Such reward signals represent the immediate feedback of a\nparticular action performed by an agent. However, tasks with sparse reward\nsignals are still challenging to on-policy methods. In this paper, we introduce\nan effective characterization of past reward statistics (which can be seen as\nlong-term feedback signals) to supplement this immediate reward feedback. In\nparticular, value functions are learned with multi-critics supervision,\nenabling complex value functions to be more easily approximated in on-policy\nlearning, even when the reward signals are sparse. We also introduce a novel\nexploration mechanism called \"hot-wiring\" that can give a boost to seemingly\ntrapped agents. We demonstrate the effectiveness of our advantage actor\nmulti-critic (A2MC) method across the discrete domains in Atari games as well\nas continuous domains in the MuJoCo environments. A video demo is provided at\nhttps://youtu.be/zBmpf3Yz8tc.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 10:10:12 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Deng", "Yubin", ""], ["Yu", "Ke", ""], ["Lin", "Dahua", ""], ["Tang", "Xiaoou", ""], ["Loy", "Chen Change", ""]]}, {"id": "1809.02393", "submitter": "Yanghoon Kim", "authors": "Yanghoon Kim and Hwanhee Lee and Joongbo Shin and Kyomin Jung", "title": "Improving Neural Question Generation using Answer Separation", "comments": "The paper is accepted to AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural question generation (NQG) is the task of generating a question from a\ngiven passage with deep neural networks. Previous NQG models suffer from a\nproblem that a significant proportion of the generated questions include words\nin the question target, resulting in the generation of unintended questions. In\nthis paper, we propose answer-separated seq2seq, which better utilizes the\ninformation from both the passage and the target answer. By replacing the\ntarget answer in the original passage with a special token, our model learns to\nidentify which interrogative word should be used. We also propose a new module\ntermed keyword-net, which helps the model better capture the key information in\nthe target answer and generate an appropriate question. Experimental results\ndemonstrate that our answer separation method significantly reduces the number\nof improper questions which include answers. Consequently, our model\nsignificantly outperforms previous state-of-the-art NQG models.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 10:35:42 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 01:43:12 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Kim", "Yanghoon", ""], ["Lee", "Hwanhee", ""], ["Shin", "Joongbo", ""], ["Jung", "Kyomin", ""]]}, {"id": "1809.02394", "submitter": "Jiajie Peng", "authors": "Hansheng Xue, Jiajie Peng, Xuequn Shang", "title": "Deep Feature Learning of Multi-Network Topology for Node Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks are ubiquitous structure that describes complex relationships\nbetween different entities in the real world. As a critical component of\nprediction task over nodes in networks, learning the feature representation of\nnodes has become one of the most active areas recently. Network Embedding,\naiming to learn non-linear and low-dimensional feature representation based on\nnetwork topology, has been proved to be helpful on tasks of network analysis,\nespecially node classification. For many real-world systems, multiple types of\nrelations are naturally represented by multiple networks. However, existing\nnetwork embedding methods mainly focus on single network embedding and neglect\nthe information shared among different networks. In this paper, we propose a\nnovel multiple network embedding method based on semisupervised autoencoder,\nnamed DeepMNE, which captures complex topological structures of multi-networks\nand takes the correlation among multi-networks into account. We evaluate\nDeepMNE on the task of node classification with two real-world datasets. The\nexperimental results demonstrate the superior performance of our method over\nfour state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 10:36:22 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Xue", "Hansheng", ""], ["Peng", "Jiajie", ""], ["Shang", "Xuequn", ""]]}, {"id": "1809.02441", "submitter": "Jangho Kim", "authors": "Jangho Kim, Jeesoo Kim, Nojun Kwak", "title": "StackNet: Stacking Parameters for Continual learning", "comments": "CVPR 2020 Workshop on Continual Learning in Computer Vision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a neural network for a classification task typically assumes that\nthe data to train are given from the beginning. However, in the real world,\nadditional data accumulate gradually and the model requires additional training\nwithout accessing the old training data. This usually leads to the catastrophic\nforgetting problem which is inevitable for the traditional training methodology\nof neural networks. In this paper, we propose a continual learning method that\nis able to learn additional tasks while retaining the performance of previously\nlearned tasks by stacking parameters. Composed of two complementary components,\nthe index module and the StackNet, our method estimates the index of the\ncorresponding task for an input sample with the index module and utilizes a\nparticular portion of StackNet with this index. The StackNet guarantees no\ndegradation in the performance of the previously learned tasks and the index\nmodule shows high confidence in finding the origin of an input sample. Compared\nto the previous work of PackNet, our method is competitive and highly\nintuitive.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 12:39:13 GMT"}, {"version": "v2", "created": "Wed, 1 May 2019 08:10:25 GMT"}, {"version": "v3", "created": "Tue, 21 Apr 2020 01:23:09 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Kim", "Jangho", ""], ["Kim", "Jeesoo", ""], ["Kwak", "Nojun", ""]]}, {"id": "1809.02494", "submitter": "Alejandro Ramos Soto", "authors": "Alejandro Ramos-Soto and Ehud Reiter and Kees van Deemter and Jose M.\n  Alonso and Albert Gatt", "title": "Meteorologists and Students: A resource for language grounding of\n  geographical descriptors", "comments": "Resource paper, 5 pages, 6 figures, 1 table. Conference: INLG 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a data resource which can be useful for research purposes on\nlanguage grounding tasks in the context of geographical referring expression\ngeneration. The resource is composed of two data sets that encompass 25\ndifferent geographical descriptors and a set of associated graphical\nrepresentations, drawn as polygons on a map by two groups of human subjects:\nteenage students and expert meteorologists.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 14:20:32 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Ramos-Soto", "Alejandro", ""], ["Reiter", "Ehud", ""], ["van Deemter", "Kees", ""], ["Alonso", "Jose M.", ""], ["Gatt", "Albert", ""]]}, {"id": "1809.02499", "submitter": "Hongyu Guo", "authors": "Hongyu Guo and Yongyi Mao and Richong Zhang", "title": "MixUp as Locally Linear Out-Of-Manifold Regularization", "comments": "Accepted by AAAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MixUp is a recently proposed data-augmentation scheme, which linearly\ninterpolates a random pair of training examples and correspondingly the one-hot\nrepresentations of their labels. Training deep neural networks with such\nadditional data is shown capable of significantly improving the predictive\naccuracy of the current art. The power of MixUp, however, is primarily\nestablished empirically and its working and effectiveness have not been\nexplained in any depth. In this paper, we develop an understanding for MixUp as\na form of \"out-of-manifold regularization\", which imposes certain \"local\nlinearity\" constraints on the model's input space beyond the data manifold.\nThis analysis enables us to identify a limitation of MixUp, which we call\n\"manifold intrusion\". In a nutshell, manifold intrusion in MixUp is a form of\nunder-fitting resulting from conflicts between the synthetic labels of the\nmixed-up examples and the labels of original training data. Such a phenomenon\nusually happens when the parameters controlling the generation of mixing\npolicies are not sufficiently fine-tuned on the training data. To address this\nissue, we propose a novel adaptive version of MixUp, where the mixing policies\nare automatically learned from the data using an additional network and\nobjective function designed to avoid manifold intrusion. The proposed\nregularizer, AdaMixUp, is empirically evaluated on several benchmark datasets.\nExtensive experiments demonstrate that AdaMixUp improves upon MixUp when\napplied to the current art of deep classification models.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 14:26:17 GMT"}, {"version": "v2", "created": "Sun, 14 Oct 2018 01:11:46 GMT"}, {"version": "v3", "created": "Thu, 22 Nov 2018 19:37:01 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Guo", "Hongyu", ""], ["Mao", "Yongyi", ""], ["Zhang", "Richong", ""]]}, {"id": "1809.02591", "submitter": "Remi Tachet Des Combes", "authors": "Remi Tachet, Philip Bachman and Harm van Seijen", "title": "Learning Invariances for Policy Generalization", "comments": "7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While recent progress has spawned very powerful machine learning systems,\nthose agents remain extremely specialized and fail to transfer the knowledge\nthey gain to similar yet unseen tasks. In this paper, we study a simple\nreinforcement learning problem and focus on learning policies that encode the\nproper invariances for generalization to different settings. We evaluate three\npotential methods for policy generalization: data augmentation, meta-learning\nand adversarial training. We find our data augmentation method to be effective,\nand study the potential of meta-learning and adversarial learning as\nalternative task-agnostic approaches.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 17:32:19 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 12:57:19 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Tachet", "Remi", ""], ["Bachman", "Philip", ""], ["van Seijen", "Harm", ""]]}, {"id": "1809.02627", "submitter": "Arthur Juliani", "authors": "Arthur Juliani, Vincent-Pierre Berges, Ervin Teng, Andrew Cohen,\n  Jonathan Harper, Chris Elion, Chris Goy, Yuan Gao, Hunter Henry, Marwan\n  Mattar, Danny Lange", "title": "Unity: A General Platform for Intelligent Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in artificial intelligence have been driven by the presence\nof increasingly realistic and complex simulated environments. However, many of\nthe existing environments provide either unrealistic visuals, inaccurate\nphysics, low task complexity, restricted agent perspective, or a limited\ncapacity for interaction among artificial agents. Furthermore, many platforms\nlack the ability to flexibly configure the simulation, making the simulated\nenvironment a black-box from the perspective of the learning system. In this\nwork, we propose a novel taxonomy of existing simulation platforms and discuss\nthe highest level class of general platforms which enable the development of\nlearning environments that are rich in visual, physical, task, and social\ncomplexity. We argue that modern game engines are uniquely suited to act as\ngeneral platforms and as a case study examine the Unity engine and open source\nUnity ML-Agents Toolkit. We then survey the research enabled by Unity and the\nUnity ML-Agents Toolkit, discussing the kinds of research a flexible,\ninteractive and easily configurable general platform can facilitate.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 18:13:25 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 17:59:11 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Juliani", "Arthur", ""], ["Berges", "Vincent-Pierre", ""], ["Teng", "Ervin", ""], ["Cohen", "Andrew", ""], ["Harper", "Jonathan", ""], ["Elion", "Chris", ""], ["Goy", "Chris", ""], ["Gao", "Yuan", ""], ["Henry", "Hunter", ""], ["Mattar", "Marwan", ""], ["Lange", "Danny", ""]]}, {"id": "1809.02637", "submitter": "Vrindavan Harrison", "authors": "Vrindavan Harrison and Marilyn Walker", "title": "Neural Generation of Diverse Questions using Answer Focus, Contextual\n  and Linguistic Features", "comments": "Accepted to appear at INLG 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question Generation is the task of automatically creating questions from\ntextual input. In this work we present a new Attentional Encoder--Decoder\nRecurrent Neural Network model for automatic question generation. Our model\nincorporates linguistic features and an additional sentence embedding to\ncapture meaning at both sentence and word levels. The linguistic features are\ndesigned to capture information related to named entity recognition, word case,\nand entity coreference resolution. In addition our model uses a copying\nmechanism and a special answer signal that enables generation of numerous\ndiverse questions on a given sentence. Our model achieves state of the art\nresults of 19.98 Bleu_4 on a benchmark Question Generation dataset,\noutperforming all previously published results by a significant margin. A human\nevaluation also shows that these added features improve the quality of the\ngenerated questions.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 18:47:20 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2018 21:50:26 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Harrison", "Vrindavan", ""], ["Walker", "Marilyn", ""]]}, {"id": "1809.02649", "submitter": "Wenlu Wang", "authors": "Wenlu Wang, Yingtao Tian, Hongyu Xiong, Haixun Wang, Wei-Shinn Ku", "title": "A Transfer-Learnable Natural Language Interface for Databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational database management systems (RDBMSs) are powerful because they are\nable to optimize and answer queries against any relational database. A natural\nlanguage interface (NLI) for a database, on the other hand, is tailored to\nsupport that specific database. In this work, we introduce a general purpose\ntransfer-learnable NLI with the goal of learning one model that can be used as\nNLI for any relational database. We adopt the data management principle of\nseparating data and its schema, but with the additional support for the\nidiosyncrasy and complexity of natural languages. Specifically, we introduce an\nautomatic annotation mechanism that separates the schema and the data, where\nthe schema also covers knowledge about natural language. Furthermore, we\npropose a customized sequence model that translates annotated natural language\nqueries to SQL statements. We show in experiments that our approach outperforms\nprevious NLI methods on the WikiSQL dataset and the model we learned can be\napplied to another benchmark dataset OVERNIGHT without retraining.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 19:38:51 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Wang", "Wenlu", ""], ["Tian", "Yingtao", ""], ["Xiong", "Hongyu", ""], ["Wang", "Haixun", ""], ["Ku", "Wei-Shinn", ""]]}, {"id": "1809.02657", "submitter": "Palash Goyal", "authors": "Palash Goyal, Sujit Rokka Chhetri, Arquimedes Canedo", "title": "dyngraph2vec: Capturing Network Dynamics using Dynamic Graph\n  Representation Learning", "comments": null, "journal-ref": null, "doi": "10.1016/j.knosys.2019.06.024", "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning graph representations is a fundamental task aimed at capturing\nvarious properties of graphs in vector space. The most recent methods learn\nsuch representations for static networks. However, real world networks evolve\nover time and have varying dynamics. Capturing such evolution is key to\npredicting the properties of unseen networks. To understand how the network\ndynamics affect the prediction performance, we propose an embedding approach\nwhich learns the structure of evolution in dynamic graphs and can predict\nunseen links with higher precision. Our model, dyngraph2vec, learns the\ntemporal transitions in the network using a deep architecture composed of dense\nand recurrent layers. We motivate the need of capturing dynamics for prediction\non a toy data set created using stochastic block models. We then demonstrate\nthe efficacy of dyngraph2vec over existing state-of-the-art methods on two real\nworld data sets. We observe that learning dynamics can improve the quality of\nembedding and yield better performance in link prediction.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 20:03:51 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 14:49:56 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Goyal", "Palash", ""], ["Chhetri", "Sujit Rokka", ""], ["Canedo", "Arquimedes", ""]]}, {"id": "1809.02719", "submitter": "Haohan Wang", "authors": "Haohan Wang, Da Sun, Eric P. Xing", "title": "What If We Simply Swap the Two Text Fragments? A Straightforward yet\n  Effective Way to Test the Robustness of Methods to Confounding Signals in\n  Nature Language Inference Tasks", "comments": "8 pages, to appear at AAAI 19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nature language inference (NLI) task is a predictive task of determining the\ninference relationship of a pair of natural language sentences. With the\nincreasing popularity of NLI, many state-of-the-art predictive models have been\nproposed with impressive performances. However, several works have noticed the\nstatistical irregularities in the collected NLI data set that may result in an\nover-estimated performance of these models and proposed remedies. In this\npaper, we further investigate the statistical irregularities, what we refer as\nconfounding factors, of the NLI data sets. With the belief that some NLI labels\nshould preserve under swapping operations, we propose a simple yet effective\nway (swapping the two text fragments) of evaluating the NLI predictive models\nthat naturally mitigate the observed problems. Further, we continue to train\nthe predictive models with our swapping manner and propose to use the deviation\nof the model's evaluation performances under different percentages of training\ntext fragments to be swapped to describe the robustness of a predictive model.\nOur evaluation metrics leads to some interesting understandings of recent\npublished NLI methods. Finally, we also apply the swapping operation on NLI\nmodels to see the effectiveness of this straightforward method in mitigating\nthe confounding factor problems in training generic sentence embeddings for\nother NLP transfer tasks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 23:59:22 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 01:28:11 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Wang", "Haohan", ""], ["Sun", "Da", ""], ["Xing", "Eric P.", ""]]}, {"id": "1809.02721", "submitter": "Marcelo Prates", "authors": "Marcelo O. R. Prates, Pedro H. C. Avelar, Henrique Lemos, Luis Lamb,\n  Moshe Vardi", "title": "Learning to Solve NP-Complete Problems - A Graph Neural Network for\n  Decision TSP", "comments": "Accepted for presentation at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNN) are a promising technique for bridging\ndifferential programming and combinatorial domains. GNNs employ trainable\nmodules which can be assembled in different configurations that reflect the\nrelational structure of each problem instance. In this paper, we show that GNNs\ncan learn to solve, with very little supervision, the decision variant of the\nTraveling Salesperson Problem (TSP), a highly relevant $\\mathcal{NP}$-Complete\nproblem. Our model is trained to function as an effective message-passing\nalgorithm in which edges (embedded with their weights) communicate with\nvertices for a number of iterations after which the model is asked to decide\nwhether a route with cost $<C$ exists. We show that such a network can be\ntrained with sets of dual examples: given the optimal tour cost $C^{*}$, we\nproduce one decision instance with target cost $x\\%$ smaller and one with\ntarget cost $x\\%$ larger than $C^{*}$. We were able to obtain $80\\%$ accuracy\ntraining with $-2\\%,+2\\%$ deviations, and the same trained model can generalize\nfor more relaxed deviations with increasing performance. We also show that the\nmodel is capable of generalizing for larger problem sizes. Finally, we provide\na method for predicting the optimal route cost within $2\\%$ deviation from the\nground truth. In summary, our work shows that Graph Neural Networks are\npowerful enough to solve $\\mathcal{NP}$-Complete problems which combine\nsymbolic and numeric data.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 00:11:51 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 18:02:19 GMT"}, {"version": "v3", "created": "Fri, 16 Nov 2018 12:10:20 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Prates", "Marcelo O. R.", ""], ["Avelar", "Pedro H. C.", ""], ["Lemos", "Henrique", ""], ["Lamb", "Luis", ""], ["Vardi", "Moshe", ""]]}, {"id": "1809.02735", "submitter": "Jinpeng Wang", "authors": "Feng Nie, Jinpeng Wang, Jin-Ge Yao, Rong Pan, Chin-Yew Lin", "title": "Operations Guided Neural Networks for High Fidelity Data-To-Text\n  Generation", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent neural models for data-to-text generation are mostly based on\ndata-driven end-to-end training over encoder-decoder networks. Even though the\ngenerated texts are mostly fluent and informative, they often generate\ndescriptions that are not consistent with the input structured data. This is a\ncritical issue especially in domains that require inference or calculations\nover raw data. In this paper, we attempt to improve the fidelity of neural\ndata-to-text generation by utilizing pre-executed symbolic operations. We\npropose a framework called Operation-guided Attention-based\nsequence-to-sequence network (OpAtt), with a specifically designed gating\nmechanism as well as a quantization module for operation results to utilize\ninformation from pre-executed operations. Experiments on two sports datasets\nshow our proposed method clearly improves the fidelity of the generated texts\nto the input structured data.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 01:49:03 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Nie", "Feng", ""], ["Wang", "Jinpeng", ""], ["Yao", "Jin-Ge", ""], ["Pan", "Rong", ""], ["Lin", "Chin-Yew", ""]]}, {"id": "1809.02753", "submitter": "Nguyen Van Huynh", "authors": "Nguyen Van Huynh, Dinh Thai Hoang, Diep N. Nguyen, Eryk Dutkiewicz,\n  Dusit Niyato, and Ping Wang", "title": "Optimal and Low-Complexity Dynamic Spectrum Access for RF-Powered\n  Ambient Backscatter System with Online Reinforcement Learning", "comments": "30 pages, 9 figures, journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ambient backscatter has been introduced with a wide range of applications for\nlow power wireless communications. In this article, we propose an optimal and\nlow-complexity dynamic spectrum access framework for RF-powered ambient\nbackscatter system. In this system, the secondary transmitter not only harvests\nenergy from ambient signals (from incumbent users), but also backscatters these\nsignals to its receiver for data transmission. Under the dynamics of the\nambient signals, we first adopt the Markov decision process (MDP) framework to\nobtain the optimal policy for the secondary transmitter, aiming to maximize the\nsystem throughput. However, the MDP-based optimization requires complete\nknowledge of environment parameters, e.g., the probability of a channel to be\nidle and the probability of a successful packet transmission, that may not be\npractical to obtain. To cope with such incomplete knowledge of the environment,\nwe develop a low-complexity online reinforcement learning algorithm that allows\nthe secondary transmitter to \"learn\" from its decisions and then attain the\noptimal policy. Simulation results show that the proposed learning algorithm\nnot only efficiently deals with the dynamics of the environment, but also\nimproves the average throughput up to 50% and reduces the blocking probability\nand delay up to 80% compared with conventional methods.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 04:01:58 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Van Huynh", "Nguyen", ""], ["Hoang", "Dinh Thai", ""], ["Nguyen", "Diep N.", ""], ["Dutkiewicz", "Eryk", ""], ["Niyato", "Dusit", ""], ["Wang", "Ping", ""]]}, {"id": "1809.02786", "submitter": "Dan Peng", "authors": "Dan Peng, Zizhan Zheng, Xiaofeng Zhang", "title": "Structure-Preserving Transformation: Generating Diverse and Transferable\n  Adversarial Examples", "comments": "The AAAI-2019 Workshop on Artificial Intelligence for Cyber Security\n  (AICS)", "journal-ref": null, "doi": null, "report-no": "AICS/2019/09", "categories": "cs.LG cs.AI cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are perturbed inputs designed to fool machine learning\nmodels. Most recent works on adversarial examples for image classification\nfocus on directly modifying pixels with minor perturbations. A common\nrequirement in all these works is that the malicious perturbations should be\nsmall enough (measured by an L_p norm for some p) so that they are\nimperceptible to humans. However, small perturbations can be unnecessarily\nrestrictive and limit the diversity of adversarial examples generated. Further,\nan L_p norm based distance metric ignores important structure patterns hidden\nin images that are important to human perception. Consequently, even the minor\nperturbation introduced in recent works often makes the adversarial examples\nless natural to humans. More importantly, they often do not transfer well and\nare therefore less effective when attacking black-box models especially for\nthose protected by a defense mechanism. In this paper, we propose a\nstructure-preserving transformation (SPT) for generating natural and diverse\nadversarial examples with extremely high transferability. The key idea of our\napproach is to allow perceptible deviation in adversarial examples while\nkeeping structure patterns that are central to a human classifier. Empirical\nresults on the MNIST and the fashion-MNIST datasets show that adversarial\nexamples generated by our approach can easily bypass strong adversarial\ntraining. Further, they transfer well to other target models with no loss or\nlittle loss of successful attack rate.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 10:26:50 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2018 15:42:00 GMT"}, {"version": "v3", "created": "Sat, 22 Dec 2018 09:07:32 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Peng", "Dan", ""], ["Zheng", "Zizhan", ""], ["Zhang", "Xiaofeng", ""]]}, {"id": "1809.02790", "submitter": "Chao Wang", "authors": "Chao Wang and Hui Jiang", "title": "The Lower The Simpler: Simplifying Hierarchical Recurrent Models", "comments": "NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve the training efficiency of hierarchical recurrent models without\ncompromising their performance, we propose a strategy named as `the lower the\nsimpler', which is to simplify the baseline models by making the lower layers\nsimpler than the upper layers. We carry out this strategy to simplify two\ntypical hierarchical recurrent models, namely Hierarchical Recurrent\nEncoder-Decoder (HRED) and R-NET, whose basic building block is GRU.\nSpecifically, we propose Scalar Gated Unit (SGU), which is a simplified variant\nof GRU, and use it to replace the GRUs at the middle layers of HRED and R-NET.\nBesides, we also use Fixed-size Ordinally-Forgetting Encoding (FOFE), which is\nan efficient encoding method without any trainable parameter, to replace the\nGRUs at the bottom layers of HRED and R-NET. The experimental results show that\nthe simplified HRED and the simplified R-NET contain significantly less\ntrainable parameters, consume significantly less training time, and achieve\nslightly better performance than their baseline models.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 11:54:09 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 16:14:36 GMT"}, {"version": "v3", "created": "Wed, 15 May 2019 02:01:14 GMT"}, {"version": "v4", "created": "Mon, 20 May 2019 19:26:07 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Wang", "Chao", ""], ["Jiang", "Hui", ""]]}, {"id": "1809.02804", "submitter": "Zhi-Hua Zhou", "authors": "Peng Zhao, Le-Wen Cai, Zhi-Hua Zhou", "title": "Handling Concept Drift via Model Reuse", "comments": null, "journal-ref": "Machine Learning, 2020, 109(3): 533-568", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world applications, data are often collected in the form of\nstream, and thus the distribution usually changes in nature, which is referred\nas concept drift in literature. We propose a novel and effective approach to\nhandle concept drift via model reuse, leveraging previous knowledge by reusing\nmodels. Each model is associated with a weight representing its reusability\ntowards current data, and the weight is adaptively adjusted according to the\nmodel performance. We provide generalization and regret analysis. Experimental\nresults also validate the superiority of our approach on both synthetic and\nreal-world datasets.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 14:13:46 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Zhao", "Peng", ""], ["Cai", "Le-Wen", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1809.02838", "submitter": "Linfeng Liu", "authors": "Linfeng Liu, Liping Liu", "title": "Non-Parametric Variational Inference with Graph Convolutional Networks\n  for Gaussian Processes", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference for GP models with non-Gaussian noises is computationally expensive\nwhen dealing with large datasets. Many recent inference methods approximate the\nposterior distribution with a simpler distribution defined on a small number of\ninducing points. The inference is accurate only when data points have strong\ncorrelation with these inducing points. In this paper, we consider the\ninference problem in a different direction: GP function values in the posterior\nare mostly correlated in short distance. We construct a variational\ndistribution such that the inference for a data point considers only its\nneighborhood. With this construction, the variational lower bound is highly\ndecomposible, hence we can run stochastic optimization with very small batches.\nWe then train Graph Convolutional Networks as a reusable model to identify\nvariational parameters for each data point. Model reuse greatly reduces the\nnumber of parameters and the number of iterations needed in optimization. The\nproposed method significantly speeds up the inference and often gets more\naccurate results than previous methods.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 17:20:45 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Liu", "Linfeng", ""], ["Liu", "Liping", ""]]}, {"id": "1809.02855", "submitter": "Amr El-Wakeel", "authors": "Amr S. El-Wakeel, Aboelmagd Noureldin, Hossam S. Hassanein and Nizar\n  Zorba", "title": "iDriveSense: Dynamic Route Planning Involving Roads Quality Information", "comments": "Globecom 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owing to the expeditious growth in the information and communication\ntechnologies, smart cities have raised the expectations in terms of efficient\nfunctioning and management. One key aspect of residents' daily comfort is\nassured through affording reliable traffic management and route planning.\nComprehensively, the majority of the present trip planning applications and\nservice providers are enabling their trip planning recommendations relying on\nshortest paths and/or fastest routes. However, such suggestions may discount\ndrivers' preferences with respect to safe and less disturbing trips. Road\nanomalies such as cracks, potholes, and manholes induce risky driving scenarios\nand can lead to vehicles damages and costly repairs. Accordingly, in this\npaper, we propose a crowdsensing based dynamic route planning system.\nLeveraging both the vehicle motion sensors and the inertial sensors within the\nsmart devices, road surface types and anomalies have been detected and\ncategorized. In addition, the monitored events are geo-referenced utilizing GPS\nreceivers on both vehicles and smart devices. Consequently, road segments\nassessments are conducted using fuzzy system models based on aspects such as\nthe number of anomalies and their severity levels in each road segment.\nAfterward, another fuzzy model is adopted to recommend the best trip routes\nbased on the road segments quality in each potential route. Extensive road\nexperiments are held to build and show the potential of the proposed system.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 19:21:09 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["El-Wakeel", "Amr S.", ""], ["Noureldin", "Aboelmagd", ""], ["Hassanein", "Hossam S.", ""], ["Zorba", "Nizar", ""]]}, {"id": "1809.02869", "submitter": "Pedram Daee", "authors": "Tomi Peltola, Mustafa Mert \\c{C}elikok, Pedram Daee, Samuel Kaski", "title": "Machine Teaching of Active Sequential Learners", "comments": "24 pages, 16 figures. This version focuses more on machine teaching\n  while the previous version focused more on human-computer interaction and\n  user modelling. The title has been updated accordingly. Code and data\n  available at\n  https://github.com/AaltoPML/machine-teaching-of-active-sequential-learners .\n  NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine teaching addresses the problem of finding the best training data that\ncan guide a learning algorithm to a target model with minimal effort. In\nconventional settings, a teacher provides data that are consistent with the\ntrue data distribution. However, for sequential learners which actively choose\ntheir queries, such as multi-armed bandits and active learners, the teacher can\nonly provide responses to the learner's queries, not design the full data. In\nthis setting, consistent teachers can be sub-optimal for finite horizons. We\nformulate this sequential teaching problem, which current techniques in machine\nteaching do not address, as a Markov decision process, with the dynamics\nnesting a model of the learner and the actions being the teacher's responses.\nFurthermore, we address the complementary problem of learning from a teacher\nthat plans: to recognise the teaching intent of the responses, the learner is\nendowed with a model of the teacher. We test the formulation with multi-armed\nbandit learners in simulated experiments and a user study. The results show\nthat learning is improved by (i) planning teaching and (ii) the learner having\na model of the teacher. The approach gives tools to taking into account\nstrategic (planning) behaviour of users of interactive intelligent systems,\nsuch as recommendation engines, by considering them as boundedly optimal\nteachers.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 20:39:31 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 10:40:50 GMT"}, {"version": "v3", "created": "Fri, 1 Nov 2019 06:30:11 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Peltola", "Tomi", ""], ["\u00c7elikok", "Mustafa Mert", ""], ["Daee", "Pedram", ""], ["Kaski", "Samuel", ""]]}, {"id": "1809.02904", "submitter": "Matthew Stephenson", "authors": "Matthew Stephenson, Damien Anderson, Ahmed Khalifa, John Levine,\n  Jochen Renz, Julian Togelius, Christoph Salge", "title": "A Continuous Information Gain Measure to Find the Most Discriminatory\n  Problems for AI Benchmarking", "comments": "8 pages, 1 figure, 2 tables", "journal-ref": "IEEE Congress on Evolutionary Computation (IEEE CEC), Special\n  Session on Games, Glasgow, UK, 2020", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an information-theoretic method for selecting a subset\nof problems which gives the most information about a group of problem-solving\nalgorithms. This method was tested on the games in the General Video Game AI\n(GVGAI) framework, allowing us to identify a smaller set of games that still\ngives a large amount of information about the abilities of different\ngame-playing agents. This approach can be used to make agent testing more\nefficient. We can achieve almost as good discriminatory accuracy when testing\non only a handful of games as when testing on more than a hundred games,\nsomething which is often computationally infeasible. Furthermore, this method\ncan be extended to study the dimensions of the effective variance in game\ndesign between these games, allowing us to identify which games differentiate\nbetween agents in the most complementary ways.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 00:56:20 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2018 04:16:15 GMT"}, {"version": "v3", "created": "Mon, 18 May 2020 10:21:26 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Stephenson", "Matthew", ""], ["Anderson", "Damien", ""], ["Khalifa", "Ahmed", ""], ["Levine", "John", ""], ["Renz", "Jochen", ""], ["Togelius", "Julian", ""], ["Salge", "Christoph", ""]]}, {"id": "1809.02906", "submitter": "Weicheng Cai", "authors": "Jinkun Chen, Weicheng Cai, Danwei Cai, Zexin Cai, Haibin Zhong, Ming\n  Li", "title": "End-to-end Language Identification using NetFV and NetVLAD", "comments": "Accepted for ISCSLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we apply the NetFV and NetVLAD layers for the end-to-end\nlanguage identification task. NetFV and NetVLAD layers are the differentiable\nimplementations of the standard Fisher Vector and Vector of Locally Aggregated\nDescriptors (VLAD) methods, respectively. Both of them can encode a sequence of\nfeature vectors into a fixed dimensional vector which is very important to\nprocess those variable-length utterances. We first present the relevances and\ndifferences between the classical i-vector and the aforementioned encoding\nschemes. Then, we construct a flexible end-to-end framework including a\nconvolutional neural network (CNN) architecture and an encoding layer (NetFV or\nNetVLAD) for the language identification task. Experimental results on the NIST\nLRE 2007 close-set task show that the proposed system achieves significant EER\nreductions against the conventional i-vector baseline and the CNN temporal\naverage pooling system, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 01:07:11 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Chen", "Jinkun", ""], ["Cai", "Weicheng", ""], ["Cai", "Danwei", ""], ["Cai", "Zexin", ""], ["Zhong", "Haibin", ""], ["Li", "Ming", ""]]}, {"id": "1809.02909", "submitter": "Chuancun Yin", "authors": "Xiuyan Sha, Zeshui Xu, Chuancun Yin", "title": "Elliptical Distributions-Based Weights-Determining Method for OWA\n  Operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ordered weighted averaging (OWA) operators play a crucial role in\naggregating multiple criteria evaluations into an overall assessment supporting\nthe decision makers' choice. One key point steps is to determine the associated\nweights. In this paper, we first briefly review some main methods for\ndetermining the weights by using distribution functions. Then we propose a new\napproach for determining OWA weights by using the RIM quantifier. Motivated by\nthe idea of normal distribution-based method to determine the OWA weights, we\ndevelop a method based on elliptical distributions for determining the OWA\nweights, and some of its desirable properties have been investigated.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 01:40:45 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Sha", "Xiuyan", ""], ["Xu", "Zeshui", ""], ["Yin", "Chuancun", ""]]}, {"id": "1809.02926", "submitter": "Liting Sun", "authors": "Liting Sun, Wei Zhan and Masayoshi Tomizuka", "title": "Probabilistic Prediction of Interactive Driving Behavior via\n  Hierarchical Inverse Reinforcement Learning", "comments": "ITSC2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous vehicles (AVs) are on the road. To safely and efficiently interact\nwith other road participants, AVs have to accurately predict the behavior of\nsurrounding vehicles and plan accordingly. Such prediction should be\nprobabilistic, to address the uncertainties in human behavior. Such prediction\nshould also be interactive, since the distribution over all possible\ntrajectories of the predicted vehicle depends not only on historical\ninformation, but also on future plans of other vehicles that interact with it.\nTo achieve such interaction-aware predictions, we propose a probabilistic\nprediction approach based on hierarchical inverse reinforcement learning (IRL).\nFirst, we explicitly consider the hierarchical trajectory-generation process of\nhuman drivers involving both discrete and continuous driving decisions. Based\non this, the distribution over all future trajectories of the predicted vehicle\nis formulated as a mixture of distributions partitioned by the discrete\ndecisions. Then we apply IRL hierarchically to learn the distributions from\nreal human demonstrations. A case study for the ramp-merging driving scenario\nis provided. The quantitative results show that the proposed approach can\naccurately predict both the discrete driving decisions such as yield or pass as\nwell as the continuous trajectories.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 05:44:16 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Sun", "Liting", ""], ["Zhan", "Wei", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1809.02927", "submitter": "Jiachen Li", "authors": "Jiachen Li, Hengbo Ma, Wei Zhan and Masayoshi Tomizuka", "title": "Generic Probabilistic Interactive Situation Recognition and Prediction:\n  From Virtual to Real", "comments": "Accepted by The 21st IEEE International Conference on Intelligent\n  Transportation Systems (2018 IEEE ITSC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate and robust recognition and prediction of traffic situation plays an\nimportant role in autonomous driving, which is a prerequisite for risk\nassessment and effective decision making. Although there exist a lot of works\ndealing with modeling driver behavior of a single object, it remains a\nchallenge to make predictions for multiple highly interactive agents that react\nto each other simultaneously. In this work, we propose a generic probabilistic\nhierarchical recognition and prediction framework which employs a two-layer\nHidden Markov Model (TLHMM) to obtain the distribution of potential situations\nand a learning-based dynamic scene evolution model to sample a group of future\ntrajectories. Instead of predicting motions of a single entity, we propose to\nget the joint distribution by modeling multiple interactive agents as a whole\nsystem. Moreover, due to the decoupling property of the layered structure, our\nmodel is suitable for knowledge transfer from simulation to real world\napplications as well as among different traffic scenarios, which can reduce the\ncomputational efforts of training and the demand for a large data amount. A\ncase study of highway ramp merging scenario is demonstrated to verify the\neffectiveness and accuracy of the proposed framework.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 06:02:50 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Li", "Jiachen", ""], ["Ma", "Hengbo", ""], ["Zhan", "Wei", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1809.02992", "submitter": "Wen Zhang", "authors": "Wen Zhang, Liang Huang, Yang Feng, Lei Shen and Qun Liu", "title": "Speeding Up Neural Machine Translation Decoding by Cube Pruning", "comments": "11pages, 11 figures, EMNLP-2018 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although neural machine translation has achieved promising results, it\nsuffers from slow translation speed. The direct consequence is that a trade-off\nhas to be made between translation quality and speed, thus its performance can\nnot come into full play. We apply cube pruning, a popular technique to speed up\ndynamic programming, into neural machine translation to speed up the\ntranslation. To construct the equivalence class, similar target hidden states\nare combined, leading to less RNN expansion operations on the target side and\nless \\$\\mathrm{softmax}\\$ operations over the large target vocabulary. The\nexperiments show that, at the same or even better translation quality, our\nmethod can translate faster compared with naive beam search by \\$3.3\\times\\$ on\nGPUs and \\$3.5\\times\\$ on CPUs.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 15:45:25 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Zhang", "Wen", ""], ["Huang", "Liang", ""], ["Feng", "Yang", ""], ["Shen", "Lei", ""], ["Liu", "Qun", ""]]}, {"id": "1809.03001", "submitter": "C. Maria Keet", "authors": "Pablo Rub\\'en Fillottrani and C. Maria Keet", "title": "Evidence-based lean logic profiles for conceptual data modelling\n  languages", "comments": "22 pages, 5 figures, 5 tables, 100 references; substantial extension\n  to the ADBIS'15 paper; submitted to an international journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple logic-based reconstructions of conceptual data modelling languages\nsuch as EER, UML Class Diagrams, and ORM exist. They mainly cover various\nfragments of the languages and none are formalised such that the logic applies\nsimultaneously for all three modelling language families as unifying mechanism.\nThis hampers interchangeability, interoperability, and tooling support. In\naddition, due to the lack of a systematic design process of the logic used for\nthe formalisation, hidden choices permeate the formalisations that have\nrendered them incompatible. We aim to address these problems, first, by\nstructuring the logic design process in a methodological way. We generalise and\nextend the DSL design process to apply to logic language design more generally\nand, in particular, by incorporating an ontological analysis of language\nfeatures in the process. Second, we specify minimal logic profiles availing of\nthis extended process, including the ontological commitments embedded in the\nlanguages, of evidence gathered of language feature usage, and of computational\ncomplexity insights from Description Logics (DL). The profiles characterise the\nessential logic structure needed to handle the semantics of conceptual models,\ntherewith enabling the development of interoperability tools. There is no known\nDL language that matches exactly the features of those profiles and the common\ncore is small (in the tractable DL $\\mathcal{ALNI}$). Although hardly any\ninconsistencies can be derived with the profiles, it is promising for scalable\nruntime use of conceptual data models.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 16:22:43 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 14:19:26 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Fillottrani", "Pablo Rub\u00e9n", ""], ["Keet", "C. Maria", ""]]}, {"id": "1809.03044", "submitter": "Alexander Kuhnle", "authors": "Alexander Kuhnle, Huiyuan Xie, Ann Copestake", "title": "How clever is the FiLM model, and how clever can it be?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The FiLM model achieves close-to-perfect performance on the diagnostic CLEVR\ndataset and is distinguished from other such models by having a comparatively\nsimple and easily transferable architecture. In this paper, we investigate in\nmore detail the ability of FiLM to learn various linguistic constructions. Our\nmain results show that (a) FiLM is not able to learn relational statements\nstraight away except for very simple instances, (b) training on a broader set\nof instances as well as pretraining on simpler instance types can help\nalleviate these learning difficulties, (c) mixing is less robust than\npretraining and very sensitive to the compositional structure of the dataset.\nOverall, our results suggest that the approach of big all-encompassing datasets\nand the paradigm of \"the effectiveness of data\" may have fundamental\nlimitations.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 21:08:57 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Kuhnle", "Alexander", ""], ["Xie", "Huiyuan", ""], ["Copestake", "Ann", ""]]}, {"id": "1809.03051", "submitter": "Reza Ghaeini", "authors": "Reza Ghaeini, Xiaoli Z. Fern, Prasad Tadepalli", "title": "Attentional Multi-Reading Sarcasm Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing sarcasm often requires a deep understanding of multiple sources\nof information, including the utterance, the conversational context, and real\nworld facts. Most of the current sarcasm detection systems consider only the\nutterance in isolation. There are some limited attempts toward taking into\naccount the conversational context. In this paper, we propose an interpretable\nend-to-end model that combines information from both the utterance and the\nconversational context to detect sarcasm, and demonstrate its effectiveness\nthrough empirical evaluations. We also study the behavior of the proposed model\nto provide explanations for the model's decisions. Importantly, our model is\ncapable of determining the impact of utterance and conversational context on\nthe model's decisions. Finally, we provide an ablation study to illustrate the\nimpact of different components of the proposed model.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 22:33:20 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Ghaeini", "Reza", ""], ["Fern", "Xiaoli Z.", ""], ["Tadepalli", "Prasad", ""]]}, {"id": "1809.03057", "submitter": "Martin Schmid", "authors": "Martin Schmid, Neil Burch, Marc Lanctot, Matej Moravcik, Rudolf\n  Kadlec, Michael Bowling", "title": "Variance Reduction in Monte Carlo Counterfactual Regret Minimization\n  (VR-MCCFR) for Extensive Form Games using Baselines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning strategies for imperfect information games from samples of\ninteraction is a challenging problem. A common method for this setting, Monte\nCarlo Counterfactual Regret Minimization (MCCFR), can have slow long-term\nconvergence rates due to high variance. In this paper, we introduce a variance\nreduction technique (VR-MCCFR) that applies to any sampling variant of MCCFR.\nUsing this technique, per-iteration estimated values and updates are\nreformulated as a function of sampled values and state-action baselines,\nsimilar to their use in policy gradient reinforcement learning. The new\nformulation allows estimates to be bootstrapped from other estimates within the\nsame episode, propagating the benefits of baselines along the sampled\ntrajectory; the estimates remain unbiased even when bootstrapping from other\nestimates. Finally, we show that given a perfect baseline, the variance of the\nvalue estimates can be reduced to zero. Experimental evaluation shows that\nVR-MCCFR brings an order of magnitude speedup, while the empirical variance\ndecreases by three orders of magnitude. The decreased variance allows for the\nfirst time CFR+ to be used with sampling, increasing the speedup to two orders\nof magnitude.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 23:03:54 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Schmid", "Martin", ""], ["Burch", "Neil", ""], ["Lanctot", "Marc", ""], ["Moravcik", "Matej", ""], ["Kadlec", "Rudolf", ""], ["Bowling", "Michael", ""]]}, {"id": "1809.03073", "submitter": "Bryon Aragam", "authors": "Chen Dan, Liu Leqi, Bryon Aragam, Pradeep Ravikumar, Eric P. Xing", "title": "Sample Complexity of Nonparametric Semi-Supervised Learning", "comments": "18 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the sample complexity of semi-supervised learning (SSL) and\nintroduce new assumptions based on the mismatch between a mixture model learned\nfrom unlabeled data and the true mixture model induced by the (unknown) class\nconditional distributions. Under these assumptions, we establish an\n$\\Omega(K\\log K)$ labeled sample complexity bound without imposing parametric\nassumptions, where $K$ is the number of classes. Our results suggest that even\nin nonparametric settings it is possible to learn a near-optimal classifier\nusing only a few labeled samples. Unlike previous theoretical work which\nfocuses on binary classification, we consider general multiclass classification\n($K>2$), which requires solving a difficult permutation learning problem. This\npermutation defines a classifier whose classification error is controlled by\nthe Wasserstein distance between mixing measures, and we provide finite-sample\nresults characterizing the behaviour of the excess risk of this classifier.\nFinally, we describe three algorithms for computing these estimators based on a\nconnection to bipartite graph matching, and perform experiments to illustrate\nthe superiority of the MLE over the majority vote estimator.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 01:12:26 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Dan", "Chen", ""], ["Leqi", "Liu", ""], ["Aragam", "Bryon", ""], ["Ravikumar", "Pradeep", ""], ["Xing", "Eric P.", ""]]}, {"id": "1809.03075", "submitter": "Gabriele Farina", "authors": "Gabriele Farina, Christian Kroer, Tuomas Sandholm", "title": "Online Convex Optimization for Sequential Decision Processes and\n  Extensive-Form Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regret minimization is a powerful tool for solving large-scale extensive-form\ngames. State-of-the-art methods rely on minimizing regret locally at each\ndecision point. In this work we derive a new framework for regret minimization\non sequential decision problems and extensive-form games with general compact\nconvex sets at each decision point and general convex losses, as opposed to\nprior work which has been for simplex decision points and linear losses. We\ncall our framework laminar regret decomposition. It generalizes the CFR\nalgorithm to this more general setting. Furthermore, our framework enables a\nnew proof of CFR even in the known setting, which is derived from a perspective\nof decomposing polytope regret, thereby leading to an arguably simpler\ninterpretation of the algorithm. Our generalization to convex compact sets and\nconvex losses allows us to develop new algorithms for several problems:\nregularized sequential decision making, regularized Nash equilibria in\nextensive-form games, and computing approximate extensive-form perfect\nequilibria. Our generalization also leads to the first regret-minimization\nalgorithm for computing reduced-normal-form quantal response equilibria based\non minimizing local regrets. Experiments show that our framework leads to\nalgorithms that scale at a rate comparable to the fastest variants of\ncounterfactual regret minimization for computing Nash equilibrium, and\ntherefore our approach leads to the first algorithm for computing quantal\nresponse equilibria in extremely large games. Finally we show that our\nframework enables a new kind of scalable opponent exploitation approach.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 01:28:24 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Farina", "Gabriele", ""], ["Kroer", "Christian", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "1809.03084", "submitter": "Kohei Yata", "authors": "Yusuke Narita, Shota Yasui, Kohei Yata", "title": "Efficient Counterfactual Learning from Bandit Feedback", "comments": "accepted at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What is the most statistically efficient way to do off-policy evaluation and\noptimization with batch data from bandit feedback? For log data generated by\ncontextual bandit algorithms, we consider offline estimators for the expected\nreward from a counterfactual policy. Our estimators are shown to have lowest\nvariance in a wide class of estimators, achieving variance reduction relative\nto standard estimators. We then apply our estimators to improve advertisement\ndesign by a major advertisement company. Consistent with the theoretical\nresult, our estimators allow us to improve on the existing bandit algorithm\nwith more statistical confidence compared to a state-of-the-art benchmark.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 02:08:14 GMT"}, {"version": "v2", "created": "Sun, 2 Dec 2018 21:07:33 GMT"}, {"version": "v3", "created": "Wed, 5 Dec 2018 23:41:04 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Narita", "Yusuke", ""], ["Yasui", "Shota", ""], ["Yata", "Kohei", ""]]}, {"id": "1809.03119", "submitter": "Alex James Dr", "authors": "Kazybek Adam, Kamilya Smagulova, Alex Pappachen James", "title": "Memristive LSTM network hardware architecture for time-series predictive\n  modeling problem", "comments": "IEEE Asia Pacific Conference on Circuits and Systems, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis of time-series data allows to identify long-term trends and make\npredictions that can help to improve our lives. With the rapid development of\nartificial neural networks, long short-term memory (LSTM) recurrent neural\nnetwork (RNN) configuration is found to be capable in dealing with time-series\nforecasting problems where data points are time-dependent and possess\nseasonality trends. Gated structure of LSTM cell and flexibility in network\ntopology (one-to-many, many-to-one, etc.) allows to model systems with multiple\ninput variables and control several parameters such as the size of the\nlook-back window to make a prediction and number of time steps to be predicted.\nThese make LSTM attractive tool over conventional methods such as\nautoregression models, the simple average, moving average, naive approach,\nARIMA, Holt's linear trend method, Holt's Winter seasonal method, and others.\nIn this paper, we propose a hardware implementation of LSTM network\narchitecture for time-series forecasting problem. All simulations were\nperformed using TSMC 0.18um CMOS technology and HP memristor model.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 03:35:33 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Adam", "Kazybek", ""], ["Smagulova", "Kamilya", ""], ["James", "Alex Pappachen", ""]]}, {"id": "1809.03125", "submitter": "Michael Ekstrand", "authors": "Michael D. Ekstrand", "title": "LensKit for Python: Next-Generation Software for Recommender System\n  Experiments", "comments": "8 pages; accepted for publication in CIKM 2020", "journal-ref": null, "doi": "10.1145/3340531.3412778", "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LensKit is an open-source toolkit for building, researching, and learning\nabout recommender systems. First released in 2010 as a Java framework, it has\nsupported diverse published research, small-scale production deployments, and\neducation in both MOOC and traditional classroom settings. In this paper, I\npresent the next generation of the LensKit project, re-envisioning the original\ntool's objectives as flexible Python package for supporting recommender systems\nresearch and development. LensKit for Python (LKPY) enables researchers and\nstudents to build robust, flexible, and reproducible experiments that make use\nof the large and growing PyData and Scientific Python ecosystem, including\nscikit-learn, TensorFlow, and PyTorch. To that end, it provides classical\ncollaborative filtering implementations, recommender system evaluation metrics,\ndata preparation routines, and tools for efficiently batch running\nrecommendation algorithms, all usable in any combination with each other or\nwith other Python software.\n  This paper describes the design goals, use cases, and capabilities of LKPY,\ncontextualized in a reflection on the successes and failures of the original\nLensKit for Java software.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 04:15:05 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 00:35:21 GMT"}, {"version": "v3", "created": "Fri, 10 Jul 2020 21:04:58 GMT"}, {"version": "v4", "created": "Thu, 3 Sep 2020 16:45:09 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Ekstrand", "Michael D.", ""]]}, {"id": "1809.03149", "submitter": "Weixun Wang", "authors": "Weixun Wang, Junqi Jin, Jianye Hao, Chunjie Chen, Chuan Yu, Weinan\n  Zhang, Jun Wang, Xiaotian Hao, Yixi Wang, Han Li, Jian Xu, Kun Gai", "title": "Learning Adaptive Display Exposure for Real-Time Advertising", "comments": "accepted by CIKM2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In E-commerce advertising, where product recommendations and product ads are\npresented to users simultaneously, the traditional setting is to display ads at\nfixed positions. However, under such a setting, the advertising system loses\nthe flexibility to control the number and positions of ads, resulting in\nsub-optimal platform revenue and user experience. Consequently, major\ne-commerce platforms (e.g., Taobao.com) have begun to consider more flexible\nways to display ads. In this paper, we investigate the problem of advertising\nwith adaptive exposure: can we dynamically determine the number and positions\nof ads for each user visit under certain business constraints so that the\nplatform revenue can be increased? More specifically, we consider two types of\nconstraints: request-level constraint ensures user experience for each user\nvisit, and platform-level constraint controls the overall platform monetization\nrate. We model this problem as a Constrained Markov Decision Process with\nper-state constraint (psCMDP) and propose a constrained two-level reinforcement\nlearning approach to decompose the original problem into two relatively\nindependent sub-problems. To accelerate policy learning, we also devise a\nconstrained hindsight experience replay mechanism. Experimental evaluations on\nindustry-scale real-world datasets demonstrate the merits of our approach in\nboth obtaining higher revenue under the constraints and the effectiveness of\nthe constrained hindsight experience replay mechanism.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 06:15:42 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 01:55:56 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Wang", "Weixun", ""], ["Jin", "Junqi", ""], ["Hao", "Jianye", ""], ["Chen", "Chunjie", ""], ["Yu", "Chuan", ""], ["Zhang", "Weinan", ""], ["Wang", "Jun", ""], ["Hao", "Xiaotian", ""], ["Wang", "Yixi", ""], ["Li", "Han", ""], ["Xu", "Jian", ""], ["Gai", "Kun", ""]]}, {"id": "1809.03152", "submitter": "Xun Yang", "authors": "Di Wu, Cheng Chen, Xun Yang, Xiujun Chen, Qing Tan, Jian Xu, Kun Gai", "title": "A Multi-Agent Reinforcement Learning Method for Impression Allocation in\n  Online Display Advertising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In online display advertising, guaranteed contracts and real-time bidding\n(RTB) are two major ways to sell impressions for a publisher. Despite the\nincreasing popularity of RTB, there is still half of online display advertising\nrevenue generated from guaranteed contracts. Therefore, simultaneously selling\nimpressions through both guaranteed contracts and RTB is a straightforward\nchoice for a publisher to maximize its yield. However, deriving the optimal\nstrategy to allocate impressions is not a trivial task, especially when the\nenvironment is unstable in real-world applications. In this paper, we formulate\nthe impression allocation problem as an auction problem where each contract can\nsubmit virtual bids for individual impressions. With this formulation, we\nderive the optimal impression allocation strategy by solving the optimal\nbidding functions for contracts. Since the bids from contracts are decided by\nthe publisher, we propose a multi-agent reinforcement learning (MARL) approach\nto derive cooperative policies for the publisher to maximize its yield in an\nunstable environment. The proposed approach also resolves the common challenges\nin MARL such as input dimension explosion, reward credit assignment, and\nnon-stationary environment. Experimental evaluations on large-scale real\ndatasets demonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 06:38:22 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Wu", "Di", ""], ["Chen", "Cheng", ""], ["Yang", "Xun", ""], ["Chen", "Xiujun", ""], ["Tan", "Qing", ""], ["Xu", "Jian", ""], ["Gai", "Kun", ""]]}, {"id": "1809.03194", "submitter": "Agustinus Kristiadi", "authors": "Debanjan Chaudhuri, Agustinus Kristiadi, Jens Lehmann, and Asja\n  Fischer", "title": "Improving Response Selection in Multi-Turn Dialogue Systems by\n  Incorporating Domain Knowledge", "comments": "Published as conference paper at CoNLL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building systems that can communicate with humans is a core problem in\nArtificial Intelligence. This work proposes a novel neural network architecture\nfor response selection in an end-to-end multi-turn conversational dialogue\nsetting. The architecture applies context level attention and incorporates\nadditional external knowledge provided by descriptions of domain-specific\nwords. It uses a bi-directional Gated Recurrent Unit (GRU) for encoding context\nand responses and learns to attend over the context words given the latent\nresponse representation and vice versa.In addition, it incorporates external\ndomain specific information using another GRU for encoding the domain keyword\ndescriptions. This allows better representation of domain-specific keywords in\nresponses and hence improves the overall performance. Experimental results show\nthat our model outperforms all other state-of-the-art methods for response\nselection in multi-turn conversations.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 09:10:25 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 17:34:42 GMT"}, {"version": "v3", "created": "Mon, 5 Nov 2018 10:11:29 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Chaudhuri", "Debanjan", ""], ["Kristiadi", "Agustinus", ""], ["Lehmann", "Jens", ""], ["Fischer", "Asja", ""]]}, {"id": "1809.03200", "submitter": "Karl Kurzer", "authors": "Karl Kurzer, Florian Engelhorn, J. Marius Z\\\"ollner", "title": "Decentralized Cooperative Planning for Automated Vehicles with\n  Continuous Monte Carlo Tree Search", "comments": null, "journal-ref": null, "doi": "10.1109/ITSC.2018.8569988", "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urban traffic scenarios often require a high degree of cooperation between\ntraffic participants to ensure safety and efficiency. Observing the behavior of\nothers, humans infer whether or not others are cooperating. This work aims to\nextend the capabilities of automated vehicles, enabling them to cooperate\nimplicitly in heterogeneous environments. Continuous actions allow for\narbitrary trajectories and hence are applicable to a much wider class of\nproblems than existing cooperative approaches with discrete action spaces.\nBased on cooperative modeling of other agents, Monte Carlo Tree Search (MCTS)\nin conjunction with Decoupled-UCT evaluates the action-values of each agent in\na cooperative and decentralized way, respecting the interdependence of actions\namong traffic participants. The extension to continuous action spaces is\naddressed by incorporating novel MCTS-specific enhancements for efficient\nsearch space exploration. The proposed algorithm is evaluated under different\nscenarios, showing that the algorithm is able to achieve effective cooperative\nplanning and generate solutions egocentric planning fails to identify.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 09:16:26 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Kurzer", "Karl", ""], ["Engelhorn", "Florian", ""], ["Z\u00f6llner", "J. Marius", ""]]}, {"id": "1809.03202", "submitter": "Alberto Garcia-Duran", "authors": "Alberto Garc\\'ia-Dur\\'an, Sebastijan Duman\\v{c}i\\'c, Mathias Niepert", "title": "Learning Sequence Encoders for Temporal Knowledge Graph Completion", "comments": "EMNLP'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on link prediction in knowledge graphs has mainly focused on static\nmulti-relational data. In this work we consider temporal knowledge graphs where\nrelations between entities may only hold for a time interval or a specific\npoint in time. In line with previous work on static knowledge graphs, we\npropose to address this problem by learning latent entity and relation type\nrepresentations. To incorporate temporal information, we utilize recurrent\nneural networks to learn time-aware representations of relation types which can\nbe used in conjunction with existing latent factorization methods. The proposed\napproach is shown to be robust to common challenges in real-world KGs: the\nsparsity and heterogeneity of temporal expressions. Experiments show the\nbenefits of our approach on four temporal KGs. The data sets are available\nunder a permissive BSD-3 license 1.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 09:17:04 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Garc\u00eda-Dur\u00e1n", "Alberto", ""], ["Duman\u010di\u0107", "Sebastijan", ""], ["Niepert", "Mathias", ""]]}, {"id": "1809.03260", "submitter": "Diptikalyan Saha", "authors": "Aniya Agarwal, Pranay Lohia, Seema Nagar, Kuntal Dey, Diptikalyan Saha", "title": "Automated Test Generation to Detect Individual Discrimination in AI\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dependability on AI models is of utmost importance to ensure full acceptance\nof the AI systems. One of the key aspects of the dependable AI system is to\nensure that all its decisions are fair and not biased towards any individual.\nIn this paper, we address the problem of detecting whether a model has an\nindividual discrimination. Such a discrimination exists when two individuals\nwho differ only in the values of their protected attributes (such as,\ngender/race) while the values of their non-protected ones are exactly the same,\nget different decisions. Measuring individual discrimination requires an\nexhaustive testing, which is infeasible for a non-trivial system. In this\npaper, we present an automated technique to generate test inputs, which is\ngeared towards finding individual discrimination. Our technique combines the\nwell-known technique called symbolic execution along with the local\nexplainability for generation of effective test cases. Our experimental results\nclearly demonstrate that our technique produces 3.72 times more successful test\ncases than the existing state-of-the-art across all our chosen benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 12:11:21 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Agarwal", "Aniya", ""], ["Lohia", "Pranay", ""], ["Nagar", "Seema", ""], ["Dey", "Kuntal", ""], ["Saha", "Diptikalyan", ""]]}, {"id": "1809.03272", "submitter": "Le Trieu Phong", "authors": "Le Trieu Phong and Tran Thi Phuong", "title": "Privacy-Preserving Deep Learning via Weight Transmission", "comments": "Full version of a conference paper at NSS 2017", "journal-ref": "IEEE Transactions on Information Forensics and Security (Volume:\n  14, Issue: 11, Nov. 2019)", "doi": "10.1109/TIFS.2019.2911169", "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the scenario that multiple data owners wish to apply a\nmachine learning method over the combined dataset of all owners to obtain the\nbest possible learning output but do not want to share the local datasets owing\nto privacy concerns. We design systems for the scenario that the stochastic\ngradient descent (SGD) algorithm is used as the machine learning method because\nSGD (or its variants) is at the heart of recent deep learning techniques over\nneural networks. Our systems differ from existing systems in the following\nfeatures: {\\bf (1)} any activation function can be used, meaning that no\nprivacy-preserving-friendly approximation is required; {\\bf (2)} gradients\ncomputed by SGD are not shared but the weight parameters are shared instead;\nand {\\bf (3)} robustness against colluding parties even in the extreme case\nthat only one honest party exists. We prove that our systems, while\nprivacy-preserving, achieve the same learning accuracy as SGD and hence retain\nthe merit of deep learning with respect to accuracy. Finally, we conduct\nseveral experiments using benchmark datasets, and show that our systems\noutperform previous system in terms of learning accuracies.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 12:36:05 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 06:43:25 GMT"}, {"version": "v3", "created": "Tue, 12 Feb 2019 06:44:53 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Phong", "Le Trieu", ""], ["Phuong", "Tran Thi", ""]]}, {"id": "1809.03327", "submitter": "Ning Xu", "authors": "Ning Xu, Linjie Yang, Yuchen Fan, Dingcheng Yue, Yuchen Liang,\n  Jianchao Yang, and Thomas Huang", "title": "YouTube-VOS: A Large-Scale Video Object Segmentation Benchmark", "comments": "Dataset Report. arXiv admin note: substantial text overlap with\n  arXiv:1809.00461", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning long-term spatial-temporal features are critical for many video\nanalysis tasks. However, existing video segmentation methods predominantly rely\non static image segmentation techniques, and methods capturing temporal\ndependency for segmentation have to depend on pretrained optical flow models,\nleading to suboptimal solutions for the problem. End-to-end sequential learning\nto explore spatialtemporal features for video segmentation is largely limited\nby the scale of available video segmentation datasets, i.e., even the largest\nvideo segmentation dataset only contains 90 short video clips. To solve this\nproblem, we build a new large-scale video object segmentation dataset called\nYouTube Video Object Segmentation dataset (YouTube-VOS). Our dataset contains\n4,453 YouTube video clips and 94 object categories. This is by far the largest\nvideo object segmentation dataset to our knowledge and has been released at\nhttp://youtube-vos.org. We further evaluate several existing state-of-the-art\nvideo object segmentation algorithms on this dataset which aims to establish\nbaselines for the development of new algorithms in the future.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 04:19:45 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Xu", "Ning", ""], ["Yang", "Linjie", ""], ["Fan", "Yuchen", ""], ["Yue", "Dingcheng", ""], ["Liang", "Yuchen", ""], ["Yang", "Jianchao", ""], ["Huang", "Thomas", ""]]}, {"id": "1809.03330", "submitter": "Stefano Rosa", "authors": "Zhihua Wang, Stefano Rosa, Yishu Miao, Zihang Lai, Linhai Xie, Andrew\n  Markham, Niki Trigoni", "title": "Neural Allocentric Intuitive Physics Prediction from Real Videos", "comments": "Added references, minor changes. arXiv admin note: text overlap with\n  arXiv:1506.02025 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are able to make rich predictions about the future dynamics of\nphysical objects from a glance. On the other hand, most existing computer\nvision approaches require strong assumptions about the underlying system,\nad-hoc modeling, or annotated datasets, to carry out even simple predictions.\nTo tackle this gap, we propose a new perspective on the problem of learning\nintuitive physics that is inspired by the spatial memory representation of\nobjects and spaces in human brains, in particular the co-existence of\negocentric and allocentric spatial representations. We present a generic\nframework that learns a layered representation of the physical world, using a\ncascade of invertible modules. In this framework, real images are first\nconverted to a synthetic domain representation that reduces complexity arising\nfrom lighting and texture. Then, an allocentric viewpoint transformer removes\nviewpoint complexity by projecting images to a canonical view. Finally, a novel\nRecurrent Latent Variation Network (RLVN) architecture learns the dynamics of\nthe objects interacting with the environment and predicts future motion,\nleveraging the availability of unlimited synthetic simulations. Predicted\nframes are then projected back to the original camera view and translated back\nto the real world domain. Experimental results show the ability of the\nframework to consistently and accurately predict several frames in the future\nand the ability to adapt to real images.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 10:33:56 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 12:05:28 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Wang", "Zhihua", ""], ["Rosa", "Stefano", ""], ["Miao", "Yishu", ""], ["Lai", "Zihang", ""], ["Xie", "Linhai", ""], ["Markham", "Andrew", ""], ["Trigoni", "Niki", ""]]}, {"id": "1809.03359", "submitter": "Quentin Cappart", "authors": "Quentin Cappart, Emmanuel Goutierre, David Bergman, Louis-Martin\n  Rousseau", "title": "Improving Optimization Bounds using Machine Learning: Decision Diagrams\n  meet Deep Reinforcement Learning", "comments": "Accepted and presented at AAAI'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding tight bounds on the optimal solution is a critical element of\npractical solution methods for discrete optimization problems. In the last\ndecade, decision diagrams (DDs) have brought a new perspective on obtaining\nupper and lower bounds that can be significantly better than classical bounding\nmechanisms, such as linear relaxations. It is well known that the quality of\nthe bounds achieved through this flexible bounding method is highly reliant on\nthe ordering of variables chosen for building the diagram, and finding an\nordering that optimizes standard metrics is an NP-hard problem. In this paper,\nwe propose an innovative and generic approach based on deep reinforcement\nlearning for obtaining an ordering for tightening the bounds obtained with\nrelaxed and restricted DDs. We apply the approach to both the Maximum\nIndependent Set Problem and the Maximum Cut Problem. Experimental results on\nsynthetic instances show that the deep reinforcement learning approach, by\nachieving tighter objective function bounds, generally outperforms ordering\nmethods commonly used in the literature when the distribution of instances is\nknown. To the best knowledge of the authors, this is the first paper to apply\nmachine learning to directly improve relaxation bounds obtained by\ngeneral-purpose bounding mechanisms for combinatorial optimization problems.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 14:41:17 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 18:27:35 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Cappart", "Quentin", ""], ["Goutierre", "Emmanuel", ""], ["Bergman", "David", ""], ["Rousseau", "Louis-Martin", ""]]}, {"id": "1809.03363", "submitter": "Ethan Harris", "authors": "Ethan Harris, Matthew Painter and Jonathon Hare", "title": "Torchbearer: A Model Fitting Library for PyTorch", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce torchbearer, a model fitting library for pytorch aimed at\nresearchers working on deep learning or differentiable programming. The\ntorchbearer library provides a high level metric and callback API that can be\nused for a wide range of applications. We also include a series of built in\ncallbacks that can be used for: model persistence, learning rate decay,\nlogging, data visualization and more. The extensive documentation includes an\nexample library for deep learning and dynamic programming problems and can be\nfound at http://torchbearer.readthedocs.io. The code is licensed under the MIT\nLicense and available at https://github.com/ecs-vlc/torchbearer.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 14:46:35 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Harris", "Ethan", ""], ["Painter", "Matthew", ""], ["Hare", "Jonathon", ""]]}, {"id": "1809.03371", "submitter": "Brijnesh Jain", "authors": "Brijnesh Jain", "title": "Revisiting Inaccuracies of Time Series Averaging under Dynamic Time\n  Warping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article revisits an analysis on inaccuracies of time series averaging\nunder dynamic time warping conducted by \\cite{Niennattrakul2007}. The authors\npresented a correctness-criterion and introduced drift-outs of averages from\nclusters. They claimed that averages are inaccurate if they are incorrect or\ndrift-outs. Furthermore, they conjectured that such inaccuracies are caused by\nthe lack of triangle inequality. We show that a rectified version of the\ncorrectness-criterion is unsatisfiable and that the concept of drift-out is\ngeometrically and operationally inconclusive. Satisfying the triangle\ninequality is insufficient to achieve correctness and unnecessary to overcome\nthe drift-out phenomenon. We place the concept of drift-out on a principled\nbasis and show that sample means as global minimizers of a Fr\\'echet function\nnever drift out. The adjusted drift-out is a way to test to which extent an\napproximation is coherent. Empirical results show that solutions obtained by\nthe state-of-the-art methods SSG and DBA are incoherent approximations of a\nsample mean in over a third of all trials.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 15:32:28 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Jain", "Brijnesh", ""]]}, {"id": "1809.03406", "submitter": "Erik Peterson", "authors": "Erik J Peterson, Necati Alp M\\\"uyesser, Timothy Verstynen, Kyle\n  Dunovan", "title": "Combining imagination and heuristics to learn strategies that generalize", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep reinforcement learning can match or exceed human performance in stable\ncontexts, but with minor changes to the environment artificial networks, unlike\nhumans, often cannot adapt. Humans rely on a combination of heuristics to\nsimplify computational load and imagination to extend experiential learning to\nnew and more challenging environments. Motivated by theories of the\nhierarchical organization of the human prefrontal networks, we have developed a\nmodel of hierarchical reinforcement learning that combines both heuristics and\nimagination into a stumbler-strategist network. We test performance of this\nnetwork using Wythoff's game, a gridworld environment with a known optimal\nstrategy. We show that a heuristic labeling of each position as hot or cold,\ncombined with imagined play, both accelerates learning and promotes transfer to\nnovel games, while also improving model interpretability.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 15:43:57 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 20:40:35 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Peterson", "Erik J", ""], ["M\u00fcyesser", "Necati Alp", ""], ["Verstynen", "Timothy", ""], ["Dunovan", "Kyle", ""]]}, {"id": "1809.03428", "submitter": "Ji Wang", "authors": "Ji Wang and Jianguo Zhang and Weidong Bao and Xiaomin Zhu and Bokai\n  Cao and Philip S. Yu", "title": "Not Just Privacy: Improving Performance of Private Deep Learning in\n  Mobile Cloud", "comments": "Conference version accepted by KDD'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing demand for on-device deep learning services calls for a highly\nefficient manner to deploy deep neural networks (DNNs) on mobile devices with\nlimited capacity. The cloud-based solution is a promising approach to enabling\ndeep learning applications on mobile devices where the large portions of a DNN\nare offloaded to the cloud. However, revealing data to the cloud leads to\npotential privacy risk. To benefit from the cloud data center without the\nprivacy risk, we design, evaluate, and implement a cloud-based framework ARDEN\nwhich partitions the DNN across mobile devices and cloud data centers. A simple\ndata transformation is performed on the mobile device, while the\nresource-hungry training and the complex inference rely on the cloud data\ncenter. To protect the sensitive information, a lightweight privacy-preserving\nmechanism consisting of arbitrary data nullification and random noise addition\nis introduced, which provides strong privacy guarantee. A rigorous privacy\nbudget analysis is given. Nonetheless, the private perturbation to the original\ndata inevitably has a negative impact on the performance of further inference\non the cloud side. To mitigate this influence, we propose a noisy training\nmethod to enhance the cloud-side network robustness to perturbed data. Through\nthe sophisticated design, ARDEN can not only preserve privacy but also improve\nthe inference performance. To validate the proposed ARDEN, a series of\nexperiments based on three image datasets and a real mobile application are\nconducted. The experimental results demonstrate the effectiveness of ARDEN.\nFinally, we implement ARDEN on a demo system to verify its practicality.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 16:09:58 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 02:50:41 GMT"}, {"version": "v3", "created": "Sat, 5 Jan 2019 11:21:17 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Wang", "Ji", ""], ["Zhang", "Jianguo", ""], ["Bao", "Weidong", ""], ["Zhu", "Xiaomin", ""], ["Cao", "Bokai", ""], ["Yu", "Philip S.", ""]]}, {"id": "1809.03449", "submitter": "Chao Wang", "authors": "Chao Wang and Hui Jiang", "title": "Explicit Utilization of General Knowledge in Machine Reading\n  Comprehension", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To bridge the gap between Machine Reading Comprehension (MRC) models and\nhuman beings, which is mainly reflected in the hunger for data and the\nrobustness to noise, in this paper, we explore how to integrate the neural\nnetworks of MRC models with the general knowledge of human beings. On the one\nhand, we propose a data enrichment method, which uses WordNet to extract\ninter-word semantic connections as general knowledge from each given\npassage-question pair. On the other hand, we propose an end-to-end MRC model\nnamed as Knowledge Aided Reader (KAR), which explicitly uses the above\nextracted general knowledge to assist its attention mechanisms. Based on the\ndata enrichment method, KAR is comparable in performance with the\nstate-of-the-art MRC models, and significantly more robust to noise than them.\nWhen only a subset (20%-80%) of the training examples are available, KAR\noutperforms the state-of-the-art MRC models by a large margin, and is still\nreasonably robust to noise.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 16:42:22 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 02:06:58 GMT"}, {"version": "v3", "created": "Mon, 20 May 2019 19:30:35 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Wang", "Chao", ""], ["Jiang", "Hui", ""]]}, {"id": "1809.03470", "submitter": "Marek Wydmuch", "authors": "Marek Wydmuch, Micha{\\l} Kempka, Wojciech Ja\\'skowski", "title": "ViZDoom Competitions: Playing Doom from Pixels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the first two editions of Visual Doom AI Competition,\nheld in 2016 and 2017. The challenge was to create bots that compete in a\nmulti-player deathmatch in a first-person shooter (FPS) game, Doom. The bots\nhad to make their decisions based solely on visual information, i.e., a raw\nscreen buffer. To play well, the bots needed to understand their surroundings,\nnavigate, explore, and handle the opponents at the same time. These aspects,\ntogether with the competitive multi-agent aspect of the game, make the\ncompetition a unique platform for evaluating the state of the art reinforcement\nlearning algorithms. The paper discusses the rules, solutions, results, and\nstatistics that give insight into the agents' behaviors. Best-performing agents\nare described in more detail. The results of the competition lead to the\nconclusion that, although reinforcement learning can produce capable Doom bots,\nthey still are not yet able to successfully compete against humans in this\ngame. The paper also revisits the ViZDoom environment, which is a flexible,\neasy to use, and efficient 3D platform for research for vision-based\nreinforcement learning, based on a well-recognized first-person perspective\ngame Doom.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 17:41:39 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Wydmuch", "Marek", ""], ["Kempka", "Micha\u0142", ""], ["Ja\u015bkowski", "Wojciech", ""]]}, {"id": "1809.03478", "submitter": "Wei Zhan", "authors": "Wei Zhan, Liting Sun, Yeping Hu, Jiachen Li, and Masayoshi Tomizuka", "title": "Towards a Fatality-Aware Benchmark of Probabilistic Reaction Prediction\n  in Highly Interactive Driving Scenarios", "comments": "2018 IEEE 21st International Conference on Intelligent Transportation\n  Systems (ITSC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous vehicles should be able to generate accurate probabilistic\npredictions for uncertain behavior of other road users. Moreover, reactive\npredictions are necessary in highly interactive driving scenarios to answer\n\"what if I take this action in the future\" for autonomous vehicles. There is no\nexisting unified framework to homogenize the problem formulation,\nrepresentation simplification, and evaluation metric for various prediction\nmethods, such as probabilistic graphical models (PGM), neural networks (NN) and\ninverse reinforcement learning (IRL). In this paper, we formulate a\nprobabilistic reaction prediction problem, and reveal the relationship between\nreaction and situation prediction problems. We employ prototype trajectories\nwith designated motion patterns other than \"intention\" to homogenize the\nrepresentation so that probabilities corresponding to each trajectory generated\nby different methods can be evaluated. We also discuss the reasons why\n\"intention\" is not suitable to serve as a motion indicator in highly\ninteractive scenarios. We propose to use Brier score as the baseline metric for\nevaluation. In order to reveal the fatality of the consequences when the\npredictions are adopted by decision-making and planning, we propose a\nfatality-aware metric, which is a weighted Brier score based on the criticality\nof the trajectory pairs of the interacting entities. Conservatism and\nnon-defensiveness are defined from the weighted Brier score to indicate the\nconsequences caused by inaccurate predictions. Modified methods based on PGM,\nNN and IRL are provided to generate probabilistic reaction predictions in an\nexemplar scenario of nudging from a highway ramp. The results are evaluated by\nthe baseline and proposed metrics to construct a mini benchmark. Analysis on\nthe properties of each method is also provided by comparing the baseline and\nproposed metric scores.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 17:48:58 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Zhan", "Wei", ""], ["Sun", "Liting", ""], ["Hu", "Yeping", ""], ["Li", "Jiachen", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1809.03541", "submitter": "Ramin Moghaddass", "authors": "Ramin Moghaddass and Cynthia Rudin", "title": "Bayesian Patchworks: An Approach to Case-Based Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Doctors often rely on their past experience in order to diagnose patients.\nFor a doctor with enough experience, almost every patient would have\nsimilarities to key cases seen in the past, and each new patient could be\nviewed as a mixture of these key past cases. Because doctors often tend to\nreason this way, an efficient computationally aided diagnostic tool that thinks\nin the same way might be helpful in locating key past cases of interest that\ncould assist with diagnosis. This article develops a novel mathematical model\nto mimic the type of logical thinking that physicians use when considering past\ncases. The proposed model can also provide physicians with explanations that\nwould be similar to the way they would naturally reason about cases. The\nproposed method is designed to yield predictive accuracy, computational\nefficiency, and insight into medical data; the key element is the insight into\nmedical data, in some sense we are automating a complicated process that\nphysicians might perform manually. We finally implemented the result of this\nwork on two publicly available healthcare datasets, for heart disease\nprediction and breast cancer prediction.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 18:40:46 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Moghaddass", "Ramin", ""], ["Rudin", "Cynthia", ""]]}, {"id": "1809.03559", "submitter": "Ji Wang", "authors": "Ji Wang and Bokai Cao and Philip S. Yu and Lichao Sun and Weidong Bao\n  and Xiaomin Zhu", "title": "Deep Learning Towards Mobile Applications", "comments": "Conference version accepted by ICDCS'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed an explosive growth of mobile devices. Mobile\ndevices are permeating every aspect of our daily lives. With the increasing\nusage of mobile devices and intelligent applications, there is a soaring demand\nfor mobile applications with machine learning services. Inspired by the\ntremendous success achieved by deep learning in many machine learning tasks, it\nbecomes a natural trend to push deep learning towards mobile applications.\nHowever, there exist many challenges to realize deep learning in mobile\napplications, including the contradiction between the miniature nature of\nmobile devices and the resource requirement of deep neural networks, the\nprivacy and security concerns about individuals' data, and so on. To resolve\nthese challenges, during the past few years, great leaps have been made in this\narea. In this paper, we provide an overview of the current challenges and\nrepresentative achievements about pushing deep learning on mobile devices from\nthree aspects: training with mobile data, efficient inference on mobile\ndevices, and applications of mobile deep learning. The former two aspects cover\nthe primary tasks of deep learning. Then, we go through our two recent\napplications that apply the data collected by mobile devices to inferring mood\ndisturbance and user identification. Finally, we conclude this paper with the\ndiscussion of the future of this area.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 19:28:57 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Wang", "Ji", ""], ["Cao", "Bokai", ""], ["Yu", "Philip S.", ""], ["Sun", "Lichao", ""], ["Bao", "Weidong", ""], ["Zhu", "Xiaomin", ""]]}, {"id": "1809.03609", "submitter": "Mohamed Ibrahim", "authors": "Mohamed R. Ibrahim, James Haworth, Tao Cheng", "title": "URBAN-i: From urban scenes to mapping slums, transport modes, and\n  pedestrians in cities using deep learning and computer vision", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": "10.1177/2399808319846517", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Within the burgeoning expansion of deep learning and computer vision across\nthe different fields of science, when it comes to urban development, deep\nlearning and computer vision applications are still limited towards the notions\nof smart cities and autonomous vehicles. Indeed, a wide gap of knowledge\nappears when it comes to cities and urban regions in less developed countries\nwhere the chaos of informality is the dominant scheme. How can deep learning\nand Artificial Intelligence (AI) untangle the complexities of informality to\nadvance urban modelling and our understanding of cities? Various questions and\ndebates can be raised concerning the future of cities of the North and the\nSouth in the paradigm of AI and computer vision. In this paper, we introduce a\nnew method for multipurpose realistic-dynamic urban modelling relying on deep\nlearning and computer vision, using deep Convolutional Neural Networks (CNN),\nto sense and detect informality and slums in urban scenes from aerial and\nstreet view images in addition to detection of pedestrian and transport modes.\nThe model has been trained on images of urban scenes in cities across the\nglobe. The model shows a good validation of understanding a wide spectrum of\nnuances among the planned and the unplanned regions, including informal and\nslum areas. We attempt to advance urban modelling for better understanding the\ndynamics of city developments. We also aim to exemplify the significant impacts\nof AI in cities beyond how smart cities are discussed and perceived in the\nmainstream. The algorithms of the URBAN-i model are fully-coded in Python\nprogramming with the pre-trained deep learning models to be used as a tool for\nmapping and city modelling in the various corner of the globe, including\ninformal settlements and slum regions.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 21:49:38 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Ibrahim", "Mohamed R.", ""], ["Haworth", "James", ""], ["Cheng", "Tao", ""]]}, {"id": "1809.03656", "submitter": "Francesco Olivieri", "authors": "Francesco Olivieri, Guido Governatori, Matteo Cristani, Nick van\n  Beest, Silvano Colombo-Tosatto", "title": "Resource-driven Substructural Defeasible Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear Logic and Defeasible Logic have been adopted to formalise different\nfeatures relevant to agents: consumption of resources, and reasoning with\nexceptions. We propose a framework to combine sub-structural features,\ncorresponding to the consumption of resources, with defeasibility aspects, and\nwe discuss the design choices for the framework.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 02:09:03 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Olivieri", "Francesco", ""], ["Governatori", "Guido", ""], ["Cristani", "Matteo", ""], ["van Beest", "Nick", ""], ["Colombo-Tosatto", "Silvano", ""]]}, {"id": "1809.03695", "submitter": "Aitor Soroa Dr.", "authors": "Oier Lopez de Lacalle, Aitor Soroa, Eneko Agirre", "title": "Evaluating Multimodal Representations on Sentence Similarity: vSTS,\n  Visual Semantic Textual Similarity Dataset", "comments": null, "journal-ref": "ICCV17: second workshop on Closing the Loop Between Vision and\n  Language. Venice, Italy. 2017", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce vSTS, a new dataset for measuring textual\nsimilarity of sentences using multimodal information. The dataset is comprised\nby images along with its respectively textual captions. We describe the dataset\nboth quantitatively and qualitatively, and claim that it is a valid gold\nstandard for measuring automatic multimodal textual similarity systems. We also\ndescribe the initial experiments combining the multimodal information.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 06:40:36 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["de Lacalle", "Oier Lopez", ""], ["Soroa", "Aitor", ""], ["Agirre", "Eneko", ""]]}, {"id": "1809.03864", "submitter": "Ramin M. Hasani", "authors": "Ramin M. Hasani, Alexander Amini, Mathias Lechner, Felix Naser, Radu\n  Grosu, Daniela Rus", "title": "Response Characterization for Auditing Cell Dynamics in Long Short-term\n  Memory Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel method to interpret recurrent neural\nnetworks (RNNs), particularly long short-term memory networks (LSTMs) at the\ncellular level. We propose a systematic pipeline for interpreting individual\nhidden state dynamics within the network using response characterization\nmethods. The ranked contribution of individual cells to the network's output is\ncomputed by analyzing a set of interpretable metrics of their decoupled step\nand sinusoidal responses. As a result, our method is able to uniquely identify\nneurons with insightful dynamics, quantify relationships between dynamical\nproperties and test accuracy through ablation analysis, and interpret the\nimpact of network capacity on a network's dynamical distribution. Finally, we\ndemonstrate generalizability and scalability of our method by evaluating a\nseries of different benchmark sequential datasets.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 13:27:36 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Hasani", "Ramin M.", ""], ["Amini", "Alexander", ""], ["Lechner", "Mathias", ""], ["Naser", "Felix", ""], ["Grosu", "Radu", ""], ["Rus", "Daniela", ""]]}, {"id": "1809.03916", "submitter": "Maarten Bieshaar", "authors": "Maarten Bieshaar, G\\\"unther Reitberger, Stefan Zernetsch, Bernhard\n  Sick, Erich Fuchs, Konrad Doll", "title": "Detecting Intentions of Vulnerable Road Users Based on Collective\n  Intelligence", "comments": "20 pages, published at Automatisiertes und vernetztes Fahren (AAET),\n  Braunschweig, Germany, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vulnerable road users (VRUs, i.e. cyclists and pedestrians) will play an\nimportant role in future traffic. To avoid accidents and achieve a highly\nefficient traffic flow, it is important to detect VRUs and to predict their\nintentions. In this article a holistic approach for detecting intentions of\nVRUs by cooperative methods is presented. The intention detection consists of\nbasic movement primitive prediction, e.g. standing, moving, turning, and a\nforecast of the future trajectory. Vehicles equipped with sensors, data\nprocessing systems and communication abilities, referred to as intelligent\nvehicles, acquire and maintain a local model of their surrounding traffic\nenvironment, e.g. crossing cyclists. Heterogeneous, open sets of agents\n(cooperating and interacting vehicles, infrastructure, e.g. cameras and laser\nscanners, and VRUs equipped with smart devices and body-worn sensors) exchange\ninformation forming a multi-modal sensor system with the goal to reliably and\nrobustly detect VRUs and their intentions under consideration of real time\nrequirements and uncertainties. The resulting model allows to extend the\nperceptual horizon of the individual agent beyond their own sensory\ncapabilities, enabling a longer forecast horizon. Concealments,\nimplausibilities and inconsistencies are resolved by the collective\nintelligence of cooperating agents. Novel techniques of signal processing and\nmodelling in combination with analytical and learning based approaches of\npattern and activity recognition are used for detection, as well as intention\nprediction of VRUs. Cooperation, by means of probabilistic sensor and knowledge\nfusion, takes place on the level of perception and intention recognition. Based\non the requirements of the cooperative approach for the communication a new\nstrategy for an ad hoc network is proposed.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 14:18:49 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Bieshaar", "Maarten", ""], ["Reitberger", "G\u00fcnther", ""], ["Zernetsch", "Stefan", ""], ["Sick", "Bernhard", ""], ["Fuchs", "Erich", ""], ["Doll", "Konrad", ""]]}, {"id": "1809.03928", "submitter": "Maurizio Parton", "authors": "Francesco Morandin and Gianluca Amato and Rosa Gini and Carlo Metta\n  and Maurizio Parton and Gian-Carlo Pascutto", "title": "SAI, a Sensible Artificial Intelligence that plays Go", "comments": "Updated for IJCNN 2019 conference", "journal-ref": "2019 International Joint Conference on Neural Networks (IJCNN)", "doi": "10.1109/IJCNN.2019.8852266", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a multiple-komi modification of the AlphaGo Zero/Leela Zero\nparadigm. The winrate as a function of the komi is modeled with a\ntwo-parameters sigmoid function, so that the neural network must predict just\none more variable to assess the winrate for all komi values. A second novel\nfeature is that training is based on self-play games that occasionally branch\n-- with changed komi -- when the position is uneven. With this setting,\nreinforcement learning is showed to work on 7x7 Go, obtaining very strong\nplaying agents. As a useful byproduct, the sigmoid parameters given by the\nnetwork allow to estimate the score difference on the board, and to evaluate\nhow much the game is decided.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 14:30:01 GMT"}, {"version": "v2", "created": "Wed, 1 May 2019 08:16:29 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Morandin", "Francesco", ""], ["Amato", "Gianluca", ""], ["Gini", "Rosa", ""], ["Metta", "Carlo", ""], ["Parton", "Maurizio", ""], ["Pascutto", "Gian-Carlo", ""]]}, {"id": "1809.03956", "submitter": "Jinsheng Ren", "authors": "Fei Deng, Jinsheng Ren, Feng Chen", "title": "Abstraction Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a gap between artificial intelligence and human intelligence.\nIn this paper, we identify three key elements forming human intelligence, and\nsuggest that abstraction learning combines these elements and is thus a way to\nbridge the gap. Prior researches in artificial intelligence either specify\nabstraction by human experts, or take abstraction as a qualitative explanation\nfor the model. This paper aims to learn abstraction directly. We tackle three\nmain challenges: representation, objective function, and learning algorithm.\nSpecifically, we propose a partition structure that contains pre-allocated\nabstraction neurons; we formulate abstraction learning as a constrained\noptimization problem, which integrates abstraction properties; we develop a\nnetwork evolution algorithm to solve this problem. This complete framework is\nnamed ONE (Optimization via Network Evolution). In our experiments on MNIST,\nONE shows elementary human-like intelligence, including low energy consumption,\nknowledge sharing, and lifelong learning.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 15:02:24 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Deng", "Fei", ""], ["Ren", "Jinsheng", ""], ["Chen", "Feng", ""]]}, {"id": "1809.03979", "submitter": "Juan Rojas", "authors": "Hongmin Wu, Shuangqi Luo, Longxin Chen, Shuangda Duan, Sakmongkon\n  Chumkamon, Dong Liu, Yisheng Guan, and Juan Rojas", "title": "Endowing Robots with Longer-term Autonomy by Recovering from External\n  Disturbances in Manipulation through Grounded Anomaly Classification and\n  Recovery Policies", "comments": "33 pages, 28 figures. Supplemental info, code, and videos found at:\n  http://www.juanrojas.net/re_enact_adapt/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robot manipulation is increasingly poised to interact with humans in\nco-shared workspaces. Despite increasingly robust manipulation and control\nalgorithms, failure modes continue to exist whenever models do not capture the\ndynamics of the unstructured environment. To obtain longer-term horizons in\nrobot automation, robots must develop introspection and recovery abilities. We\ncontribute a set of recovery policies to deal with anomalies produced by\nexternal disturbances as well as anomaly classification through the use of\nnon-parametric statistics with memoized variational inference with scalable\nadaptation. A recovery critic stands atop of a tightly-integrated, graph-based\nonline motion-generation and introspection system that resolves a wide range of\nanomalous situations. Policies, skills, and introspection models are learned\nincrementally and contextually in a task. Two task-level recovery policies:\nre-enactment and adaptation resolve accidental and persistent anomalies\nrespectively. The introspection system uses non-parametric priors along with\nMarkov jump linear systems and memoized variational inference with scalable\nadaptation to learn a model from the data. Extensive real-robot experimentation\nwith various strenuous anomalous conditions is induced and resolved at\ndifferent phases of a task and in different combinations. The system executes\naround-the-clock introspection and recovery and even elicited self-recovery\nwhen misclassifications occurred.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 15:37:25 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Wu", "Hongmin", ""], ["Luo", "Shuangqi", ""], ["Chen", "Longxin", ""], ["Duan", "Shuangda", ""], ["Chumkamon", "Sakmongkon", ""], ["Liu", "Dong", ""], ["Guan", "Yisheng", ""], ["Rojas", "Juan", ""]]}, {"id": "1809.04040", "submitter": "Noam Brown", "authors": "Noam Brown and Tuomas Sandholm", "title": "Solving Imperfect-Information Games via Discounted Regret Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual regret minimization (CFR) is a family of iterative algorithms\nthat are the most popular and, in practice, fastest approach to approximately\nsolving large imperfect-information games. In this paper we introduce novel CFR\nvariants that 1) discount regrets from earlier iterations in various ways (in\nsome cases differently for positive and negative regrets), 2) reweight\niterations in various ways to obtain the output strategies, 3) use a\nnon-standard regret minimizer and/or 4) leverage \"optimistic regret matching\".\nThey lead to dramatically improved performance in many settings. For one, we\nintroduce a variant that outperforms CFR+, the prior state-of-the-art\nalgorithm, in every game tested, including large-scale realistic settings. CFR+\nis a formidable benchmark: no other algorithm has been able to outperform it.\nFinally, we show that, unlike CFR+, many of the important new variants are\ncompatible with modern imperfect-information-game pruning techniques and one is\nalso compatible with sampling in the game tree.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 17:11:17 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 14:30:48 GMT"}, {"version": "v3", "created": "Thu, 21 Feb 2019 18:58:33 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Brown", "Noam", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "1809.04106", "submitter": "Christoph Trattner", "authors": "Christoph Trattner (University of Bergen), Vanessa Murdock (Amazon),\n  Steven Chang (Quora)", "title": "ACM RecSys 2018 Late-Breaking Results Proceedings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ACM RecSys'18 Late-Breaking Results track (previously known as the Poster\ntrack) is part of the main program of the 2018 ACM Conference on Recommender\nSystems in Vancouver, Canada. The track attracted 48 submissions this year out\nof which 18 papers could be accepted resulting in an acceptance rated of 37.5%.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 18:52:56 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Trattner", "Christoph", "", "University of Bergen"], ["Murdock", "Vanessa", "", "Amazon"], ["Chang", "Steven", "", "Quora"]]}, {"id": "1809.04113", "submitter": "Tianxing He", "authors": "Tianxing He and James Glass", "title": "Detecting egregious responses in neural sequence-to-sequence models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we attempt to answer a critical question: whether there exists\nsome input sequence that will cause a well-trained discrete-space neural\nnetwork sequence-to-sequence (seq2seq) model to generate egregious outputs\n(aggressive, malicious, attacking, etc.). And if such inputs exist, how to find\nthem efficiently. We adopt an empirical methodology, in which we first create\nlists of egregious output sequences, and then design a discrete optimization\nalgorithm to find input sequences that will cause the model to generate them.\nMoreover, the optimization algorithm is enhanced for large vocabulary search\nand constrained to search for input sequences that are likely to be input by\nreal-world users. In our experiments, we apply this approach to dialogue\nresponse generation models trained on three real-world dialogue data-sets:\nUbuntu, Switchboard and OpenSubtitles, testing whether the model can generate\nmalicious responses. We demonstrate that given the trigger inputs our algorithm\nfinds, a significant number of malicious sentences are assigned large\nprobability by the model, which reveals an undesirable consequence of standard\nseq2seq training.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 19:11:51 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 17:45:04 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["He", "Tianxing", ""], ["Glass", "James", ""]]}, {"id": "1809.04136", "submitter": "Juntao Wang Mr", "authors": "Yiling Chen and Yang Liu and Juntao Wang", "title": "Randomized Wagering Mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wagering mechanisms are one-shot betting mechanisms that elicit agents'\npredictions of an event. For deterministic wagering mechanisms, an existing\nimpossibility result has shown incompatibility of some desirable theoretical\nproperties. In particular, Pareto optimality (no profitable side bet before\nallocation) can not be achieved together with weak incentive compatibility,\nweak budget balance and individual rationality. In this paper, we expand the\ndesign space of wagering mechanisms to allow randomization and ask whether\nthere are randomized wagering mechanisms that can achieve all previously\nconsidered desirable properties, including Pareto optimality. We answer this\nquestion positively with two classes of randomized wagering mechanisms: i) one\nsimple randomized lottery-type implementation of existing deterministic\nwagering mechanisms, and ii) another family of simple and randomized wagering\nmechanisms which we call surrogate wagering mechanisms, which are robust to\nnoisy ground truth. This family of mechanisms builds on the idea of learning\nwith noisy labels (Natarajan et al. 2013) as well as a recent extension of this\nidea to the information elicitation without verification setting (Liu and Chen\n2018). We show that a broad family of randomized wagering mechanisms satisfy\nall desirable theoretical properties.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 20:06:03 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 03:40:24 GMT"}, {"version": "v3", "created": "Wed, 7 Nov 2018 16:01:29 GMT"}, {"version": "v4", "created": "Fri, 30 Nov 2018 06:49:37 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Chen", "Yiling", ""], ["Liu", "Yang", ""], ["Wang", "Juntao", ""]]}, {"id": "1809.04198", "submitter": "Heinrich Jiang", "authors": "Andrew Cotter, Heinrich Jiang, Serena Wang, Taman Narayan, Maya Gupta,\n  Seungil You, Karthik Sridharan", "title": "Optimization with Non-Differentiable Constraints with Applications to\n  Fairness, Recall, Churn, and Other Goals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that many machine learning goals, such as improved fairness metrics,\ncan be expressed as constraints on the model's predictions, which we call rate\nconstraints. We study the problem of training non-convex models subject to\nthese rate constraints (or any non-convex and non-differentiable constraints).\nIn the non-convex setting, the standard approach of Lagrange multipliers may\nfail. Furthermore, if the constraints are non-differentiable, then one cannot\noptimize the Lagrangian with gradient-based methods. To solve these issues, we\nintroduce the proxy-Lagrangian formulation. This new formulation leads to an\nalgorithm that produces a stochastic classifier by playing a two-player\nnon-zero-sum game solving for what we call a semi-coarse correlated\nequilibrium, which in turn corresponds to an approximately optimal and feasible\nsolution to the constrained optimization problem. We then give a procedure\nwhich shrinks the randomized solution down to one that is a mixture of at most\n$m+1$ deterministic solutions, given $m$ constraints. This culminates in\nalgorithms that can solve non-convex constrained optimization problems with\npossibly non-differentiable and non-convex constraints with theoretical\nguarantees. We provide extensive experimental results enforcing a wide range of\npolicy goals including different fairness metrics, and other goals on accuracy,\ncoverage, recall, and churn.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 23:41:47 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Cotter", "Andrew", ""], ["Jiang", "Heinrich", ""], ["Wang", "Serena", ""], ["Narayan", "Taman", ""], ["Gupta", "Maya", ""], ["You", "Seungil", ""], ["Sridharan", "Karthik", ""]]}, {"id": "1809.04232", "submitter": "Akifumi Wachi", "authors": "Akifumi Wachi, Hiroshi Kajino, Asim Munawar", "title": "Safe Exploration in Markov Decision Processes with Time-Variant Safety\n  using Spatio-Temporal Gaussian Process", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world applications (e.g., planetary exploration, robot\nnavigation), an autonomous agent must be able to explore a space with\nguaranteed safety. Most safe exploration algorithms in the field of\nreinforcement learning and robotics have been based on the assumption that the\nsafety features are a priori known and time-invariant. This paper presents a\nlearning algorithm called ST-SafeMDP for exploring Markov decision processes\n(MDPs) that is based on the assumption that the safety features are a priori\nunknown and time-variant. In this setting, the agent explores MDPs while\nconstraining the probability of entering unsafe states defined by a safety\nfunction being below a threshold. The unknown and time-variant safety values\nare modeled using a spatio-temporal Gaussian process. However, there remains an\nissue that an agent may have no viable action in a shrinking true safe space.\nTo address this issue, we formulate a problem maximizing the cumulative number\nof safe states in the worst case scenario with respect to future observations.\nThe effectiveness of this approach was demonstrated in two simulation settings,\nincluding one using real lunar terrain data.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 02:43:19 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Wachi", "Akifumi", ""], ["Kajino", "Hiroshi", ""], ["Munawar", "Asim", ""]]}, {"id": "1809.04234", "submitter": "Liheng Chen", "authors": "Liheng Chen, Yanru Qu, Zhenghui Wang, Lin Qiu, Weinan Zhang, Ken Chen,\n  Shaodian Zhang, Yong Yu", "title": "Sampled in Pairs and Driven by Text: A New Graph Embedding Framework", "comments": "Accepted by WWW 2019 (The World Wide Web Conference. ACM, 2019)", "journal-ref": "Proceedings of the 2019 World Wide Web Conference", "doi": "10.1145/3308558.3313520", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In graphs with rich texts, incorporating textual information with structural\ninformation would benefit constructing expressive graph embeddings. Among\nvarious graph embedding models, random walk (RW)-based is one of the most\npopular and successful groups. However, it is challenged by two issues when\napplied on graphs with rich texts: (i) sampling efficiency: deriving from the\ntraining objective of RW-based models (e.g., DeepWalk and node2vec), we show\nthat RW-based models are likely to generate large amounts of redundant training\nsamples due to three main drawbacks. (ii) text utilization: these models have\ndifficulty in dealing with zero-shot scenarios where graph embedding models\nhave to infer graph structures directly from texts. To solve these problems, we\npropose a novel framework, namely Text-driven Graph Embedding with Pairs\nSampling (TGE-PS). TGE-PS uses Pairs Sampling (PS) to improve the sampling\nstrategy of RW, being able to reduce ~99% training samples while preserving\ncompetitive performance. TGE-PS uses Text-driven Graph Embedding (TGE), an\ninductive graph embedding approach, to generate node embeddings from texts.\nSince each node contains rich texts, TGE is able to generate high-quality\nembeddings and provide reasonable predictions on existence of links to unseen\nnodes. We evaluate TGE-PS on several real-world datasets, and experiment\nresults demonstrate that TGE-PS produces state-of-the-art results on both\ntraditional and zero-shot link prediction tasks.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 02:53:00 GMT"}, {"version": "v2", "created": "Sat, 12 Oct 2019 05:29:41 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Chen", "Liheng", ""], ["Qu", "Yanru", ""], ["Wang", "Zhenghui", ""], ["Qiu", "Lin", ""], ["Zhang", "Weinan", ""], ["Chen", "Ken", ""], ["Zhang", "Shaodian", ""], ["Yu", "Yong", ""]]}, {"id": "1809.04258", "submitter": "Zeheng Wang", "authors": "Yuanzhe Yao, Zeheng Wang, Liang Li, Kun Lu, Runyu Liu, Zhiyuan Liu,\n  Jing Yan", "title": "An Ontology-Based Artificial Intelligence Model for Medicine Side-Effect\n  Prediction: Taking Traditional Chinese Medicine as An Example", "comments": null, "journal-ref": null, "doi": "10.1155/2019/8617503", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, an ontology-based model for AI-assisted medicine side-effect\n(SE) prediction is developed, where three main components, including the drug\nmodel, the treatment model, and the AI-assisted prediction model, of proposed\nmodel are presented. To validate the proposed model, an ANN structure is\nestablished and trained by two hundred and forty-two TCM prescriptions. These\ndata are gathered and classified from the most famous ancient TCM book and more\nthan one thousand SE reports, in which two ontology-based attributions, hot and\ncold, are introduced to evaluate whether the prescription will cause SE or not.\nThe results preliminarily reveal that it is a relationship between the\nontology-based attributions and the corresponding predicted indicator that can\nbe learnt by AI for predicting the SE, which suggests the proposed model has a\npotential in AI-assisted SE prediction. However, it should be noted that, the\nproposed model highly depends on the sufficient clinic data, and hereby, much\ndeeper exploration is important for enhancing the accuracy of the prediction.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 05:04:58 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 07:02:37 GMT"}, {"version": "v3", "created": "Tue, 1 Oct 2019 05:02:36 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Yao", "Yuanzhe", ""], ["Wang", "Zeheng", ""], ["Li", "Liang", ""], ["Lu", "Kun", ""], ["Liu", "Runyu", ""], ["Liu", "Zhiyuan", ""], ["Yan", "Jing", ""]]}, {"id": "1809.04280", "submitter": "Jia Pan", "authors": "Zhe Hu, Jia Pan, Tingxiang Fan, Ruigang Yang, Dinesh Manocha", "title": "Safe Navigation with Human Instructions in Complex Scenes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a robotic navigation algorithm with natural\nlanguage interfaces, which enables a robot to safely walk through a changing\nenvironment with moving persons by following human instructions such as \"go to\nthe restaurant and keep away from people\". We first classify human instructions\ninto three types: the goal, the constraints, and uninformative phrases. Next,\nwe provide grounding for the extracted goal and constraint items in a dynamic\nmanner along with the navigation process, to deal with the target objects that\nare too far away for sensor observation and the appearance of moving obstacles\nlike humans. In particular, for a goal phrase (e.g., \"go to the restaurant\"),\nwe ground it to a location in a predefined semantic map and treat it as a goal\nfor a global motion planner, which plans a collision-free path in the workspace\nfor the robot to follow. For a constraint phrase (e.g., \"keep away from\npeople\"), we dynamically add the corresponding constraint into a local planner\nby adjusting the values of a local costmap according to the results returned by\nthe object detection module. The updated costmap is then used to compute a\nlocal collision avoidance control for the safe navigation of the robot. By\ncombining natural language processing, motion planning, and computer vision,\nour developed system is demonstrated to be able to successfully follow natural\nlanguage navigation instructions to achieve navigation tasks in both simulated\nand real-world scenarios. Videos are available at\nhttps://sites.google.com/view/snhi\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 07:09:08 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Hu", "Zhe", ""], ["Pan", "Jia", ""], ["Fan", "Tingxiang", ""], ["Yang", "Ruigang", ""], ["Manocha", "Dinesh", ""]]}, {"id": "1809.04288", "submitter": "Thao Le", "authors": "Thao Minh Le, Nobuyuki Shimizu, Takashi Miyazaki, Koichi Shinoda", "title": "Deep Learning Based Multi-modal Addressee Recognition in Visual Scenes\n  with Utterances", "comments": "Proceedings of the Twenty-Seventh International Joint Conference on\n  Artificial Intelligence Main track. Pages 1546-1553", "journal-ref": null, "doi": "10.24963/ijcai.2018/214", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread use of intelligent systems, such as smart speakers,\naddressee recognition has become a concern in human-computer interaction, as\nmore and more people expect such systems to understand complicated social\nscenes, including those outdoors, in cafeterias, and hospitals. Because\nprevious studies typically focused only on pre-specified tasks with limited\nconversational situations such as controlling smart homes, we created a mock\ndataset called Addressee Recognition in Visual Scenes with Utterances (ARVSU)\nthat contains a vast body of image variations in visual scenes with an\nannotated utterance and a corresponding addressee for each scenario. We also\npropose a multi-modal deep-learning-based model that takes different human\ncues, specifically eye gazes and transcripts of an utterance corpus, into\naccount to predict the conversational addressee from a specific speaker's view\nin various real-life conversational scenarios. To the best of our knowledge, we\nare the first to introduce an end-to-end deep learning model that combines\nvision and transcripts of utterance for addressee recognition. As a result, our\nstudy suggests that future addressee recognition can reach the ability to\nunderstand human intention in many social situations previously unexplored, and\nour modality dataset is a first step in promoting research in this field.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 07:43:23 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Le", "Thao Minh", ""], ["Shimizu", "Nobuyuki", ""], ["Miyazaki", "Takashi", ""], ["Shinoda", "Koichi", ""]]}, {"id": "1809.04306", "submitter": "Xiaoyuan Yi", "authors": "Xiaoyuan Yi, Maosong Sun, Ruoyu Li, Zonghan Yang", "title": "Chinese Poetry Generation with a Working Memory Model", "comments": "7 pages, 3 figures, 4 tables, published in proceedings of IJCAI 2018", "journal-ref": "In Proceedings of the Twenty-Seventh International Joint\n  Conference on Artificial Intelligence, pages 4553-4559, Stockholm, Sweden,\n  2018", "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an exquisite and concise literary form, poetry is a gem of human culture.\nAutomatic poetry generation is an essential step towards computer creativity.\nIn recent years, several neural models have been designed for this task.\nHowever, among lines of a whole poem, the coherence in meaning and topics still\nremains a big challenge. In this paper, inspired by the theoretical concept in\ncognitive psychology, we propose a novel Working Memory model for poetry\ngeneration. Different from previous methods, our model explicitly maintains\ntopics and informative limited history in a neural memory. During the\ngeneration process, our model reads the most relevant parts from memory slots\nto generate the current line. After each line is generated, it writes the most\nsalient parts of the previous line into memory slots. By dynamic manipulation\nof the memory, our model keeps a coherent information flow and learns to\nexpress each topic flexibly and naturally. We experiment on three different\ngenres of Chinese poetry: quatrain, iambic and chinoiserie lyric. Both\nautomatic and human evaluation results show that our model outperforms current\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 08:31:20 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Yi", "Xiaoyuan", ""], ["Sun", "Maosong", ""], ["Li", "Ruoyu", ""], ["Yang", "Zonghan", ""]]}, {"id": "1809.04313", "submitter": "Xiaoyuan Yi", "authors": "Xiaoyuan Yi, Ruoyu Li, Maosong Sun", "title": "Chinese Poetry Generation with a Salient-Clue Mechanism", "comments": "10pages, 1.5 page for references, 6 figures, 3 tables, will be\n  published in CoNLL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a precious part of the human cultural heritage, Chinese poetry has\ninfluenced people for generations. Automatic poetry composition is a challenge\nfor AI. In recent years, significant progress has been made in this area\nbenefiting from the development of neural networks. However, the coherence in\nmeaning, theme or even artistic conception for a generated poem as a whole\nstill remains a big problem. In this paper, we propose a novel Salient-Clue\nmechanism for Chinese poetry generation. Different from previous work which\ntried to exploit all the context information, our model selects the most\nsalient characters automatically from each so-far generated line to gradually\nform a salient clue, which is utilized to guide successive poem generation\nprocess so as to eliminate interruptions and improve coherence. Besides, our\nmodel can be flexibly extended to control the generated poem in different\naspects, for example, poetry style, which further enhances the coherence.\nExperimental results show that our model is very effective, outperforming three\nstrong baselines.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 08:50:30 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Yi", "Xiaoyuan", ""], ["Li", "Ruoyu", ""], ["Sun", "Maosong", ""]]}, {"id": "1809.04318", "submitter": "Hangbo Bao", "authors": "Hangbo Bao, Shaohan Huang, Furu Wei, Lei Cui, Yu Wu, Chuanqi Tan,\n  Songhao Piao, Ming Zhou", "title": "Neural Melody Composition from Lyrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a novel task that learns to compose music from\nnatural language. Given the lyrics as input, we propose a melody composition\nmodel that generates lyrics-conditional melody as well as the exact alignment\nbetween the generated melody and the given lyrics simultaneously. More\nspecifically, we develop the melody composition model based on the\nsequence-to-sequence framework. It consists of two neural encoders to encode\nthe current lyrics and the context melody respectively, and a hierarchical\ndecoder to jointly produce musical notes and the corresponding alignment.\nExperimental results on lyrics-melody pairs of 18,451 pop songs demonstrate the\neffectiveness of our proposed methods. In addition, we apply a singing voice\nsynthesizer software to synthesize the \"singing\" of the lyrics and melodies for\nhuman evaluation. Results indicate that our generated melodies are more\nmelodious and tuneful compared with the baseline method.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 09:03:20 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Bao", "Hangbo", ""], ["Huang", "Shaohan", ""], ["Wei", "Furu", ""], ["Cui", "Lei", ""], ["Wu", "Yu", ""], ["Tan", "Chuanqi", ""], ["Piao", "Songhao", ""], ["Zhou", "Ming", ""]]}, {"id": "1809.04322", "submitter": "Weihao Yuan", "authors": "Weihao Yuan, Kaiyu Hang, Haoran Song, Danica Kragic, Michael Y. Wang\n  and Johannes A. Stork", "title": "Reinforcement Learning in Topology-based Representation for Human Body\n  Movement with Whole Arm Manipulation", "comments": "Submitted to RA-L with ICRA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Moving a human body or a large and bulky object can require the strength of\nwhole arm manipulation (WAM). This type of manipulation places the load on the\nrobot's arms and relies on global properties of the interaction to\nsucceed---rather than local contacts such as grasping or non-prehensile\npushing. In this paper, we learn to generate motions that enable WAM for\nholding and transporting of humans in certain rescue or patient care scenarios.\nWe model the task as a reinforcement learning problem in order to provide a\nbehavior that can directly respond to external perturbation and human motion.\nFor this, we represent global properties of the robot-human interaction with\ntopology-based coordinates that are computed from arm and torso positions.\nThese coordinates also allow transferring the learned policy to other body\nshapes and sizes. For training and evaluation, we simulate a dynamic sea rescue\nscenario and show in quantitative experiments that the policy can solve unseen\nscenarios with differently-shaped humans, floating humans, or with perception\nnoise. Our qualitative experiments show the subsequent transporting after\nholding is achieved and we demonstrate that the policy can be directly\ntransferred to a real world setting.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 09:17:48 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Yuan", "Weihao", ""], ["Hang", "Kaiyu", ""], ["Song", "Haoran", ""], ["Kragic", "Danica", ""], ["Wang", "Michael Y.", ""], ["Stork", "Johannes A.", ""]]}, {"id": "1809.04343", "submitter": "Giovanni Iacca Dr.", "authors": "Giovanni Iacca and Fabio Caraffini", "title": "Compact Optimization Algorithms with Re-sampled Inheritance", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-16692-2_35", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compact optimization algorithms are a class of Estimation of Distribution\nAlgorithms (EDAs) characterized by extremely limited memory requirements (hence\nthey are called \"compact\"). As all EDAs, compact algorithms build and update a\nprobabilistic model of the distribution of solutions within the search space,\nas opposed to population-based algorithms that instead make use of an explicit\npopulation of solutions. In addition to that, to keep their memory consumption\nlow, compact algorithms purposely employ simple probabilistic models that can\nbe described with a small number of parameters. Despite their simplicity,\ncompact algorithms have shown good performances on a broad range of benchmark\nfunctions and real-world problems. However, compact algorithms also come with\nsome drawbacks, i.e. they tend to premature convergence and show poorer\nperformance on non-separable problems. To overcome these limitations, here we\ninvestigate a possible algorithmic scheme obtained by combining compact\nalgorithms with a non-disruptive restart mechanism taken from the literature,\nnamed Re-Sampled Inheritance (RI). The resulting compact algorithms with RI are\ntested on the CEC 2014 benchmark functions. The numerical results show on the\none hand that the use of RI consistently enhances the performances of compact\nalgorithms, still keeping a limited usage of memory. On the other hand, our\nexperiments show that among the tested algorithms, the best performance is\nobtained by compact Differential Evolution with RI.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 10:11:20 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 10:50:51 GMT"}, {"version": "v3", "created": "Sun, 7 Apr 2019 15:47:05 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Iacca", "Giovanni", ""], ["Caraffini", "Fabio", ""]]}, {"id": "1809.04344", "submitter": "Sandro Pezzelle", "authors": "Shailza Jolly and Sandro Pezzelle and Tassilo Klein and Andreas Dengel\n  and Moin Nabi", "title": "The Wisdom of MaSSeS: Majority, Subjectivity, and Semantic Similarity in\n  the Evaluation of VQA", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce MASSES, a simple evaluation metric for the task of Visual\nQuestion Answering (VQA). In its standard form, the VQA task is operationalized\nas follows: Given an image and an open-ended question in natural language,\nsystems are required to provide a suitable answer. Currently, model performance\nis evaluated by means of a somehow simplistic metric: If the predicted answer\nis chosen by at least 3 human annotators out of 10, then it is 100% correct.\nThough intuitively valuable, this metric has some important limitations. First,\nit ignores whether the predicted answer is the one selected by the Majority\n(MA) of annotators. Second, it does not account for the quantitative\nSubjectivity (S) of the answers in the sample (and dataset). Third, information\nabout the Semantic Similarity (SES) of the responses is completely neglected.\nBased on such limitations, we propose a multi-component metric that accounts\nfor all these issues. We show that our metric is effective in providing a more\nfine-grained evaluation both on the quantitative and qualitative level.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 10:11:39 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Jolly", "Shailza", ""], ["Pezzelle", "Sandro", ""], ["Klein", "Tassilo", ""], ["Dengel", "Andreas", ""], ["Nabi", "Moin", ""]]}, {"id": "1809.04356", "submitter": "Hassan Ismail Fawaz", "authors": "Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber, Lhassane\n  Idoumghar, Pierre-Alain Muller", "title": "Deep learning for time series classification: a review", "comments": "Accepted at Data Mining and Knowledge Discovery", "journal-ref": null, "doi": "10.1007/s10618-019-00619-1", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time Series Classification (TSC) is an important and challenging problem in\ndata mining. With the increase of time series data availability, hundreds of\nTSC algorithms have been proposed. Among these methods, only a few have\nconsidered Deep Neural Networks (DNNs) to perform this task. This is surprising\nas deep learning has seen very successful applications in the last years. DNNs\nhave indeed revolutionized the field of computer vision especially with the\nadvent of novel deeper architectures such as Residual and Convolutional Neural\nNetworks. Apart from images, sequential data such as text and audio can also be\nprocessed with DNNs to reach state-of-the-art performance for document\nclassification and speech recognition. In this article, we study the current\nstate-of-the-art performance of deep learning algorithms for TSC by presenting\nan empirical study of the most recent DNN architectures for TSC. We give an\noverview of the most successful deep learning applications in various time\nseries domains under a unified taxonomy of DNNs for TSC. We also provide an\nopen source deep learning framework to the TSC community where we implemented\neach of the compared approaches and evaluated them on a univariate TSC\nbenchmark (the UCR/UEA archive) and 12 multivariate time series datasets. By\ntraining 8,730 deep learning models on 97 time series datasets, we propose the\nmost exhaustive study of DNNs for TSC to date.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 10:55:33 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2018 17:49:17 GMT"}, {"version": "v3", "created": "Thu, 14 Mar 2019 08:14:31 GMT"}, {"version": "v4", "created": "Tue, 14 May 2019 14:41:18 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Fawaz", "Hassan Ismail", ""], ["Forestier", "Germain", ""], ["Weber", "Jonathan", ""], ["Idoumghar", "Lhassane", ""], ["Muller", "Pierre-Alain", ""]]}, {"id": "1809.04359", "submitter": "Dimitrios Kollias", "authors": "Dimitrios Kollias, Stefanos Zafeiriou", "title": "Training Deep Neural Networks with Different Datasets In-the-wild: The\n  Emotion Recognition Paradigm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel procedure is presented in this paper, for training a deep\nconvolutional and recurrent neural network, taking into account both the\navailable training data set and some information extracted from similar\nnetworks trained with other relevant data sets. This information is included in\nan extended loss function used for the network training, so that the network\ncan have an improved performance when applied to the other data sets, without\nforgetting the learned knowledge from the original data set. Facial expression\nand emotion recognition in-the-wild is the test bed application that is used to\ndemonstrate the improved performance achieved using the proposed approach. In\nthis framework, we provide an experimental study on categorical emotion\nrecognition using datasets from a very recent related emotion recognition\nchallenge.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 11:16:31 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Kollias", "Dimitrios", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "1809.04362", "submitter": "Bruno Escoffier", "authors": "Bruno Escoffier, Hugo Gilbert, Ad\\`ele Pass-Lanneau", "title": "Iterative Delegations in Liquid Democracy with Restricted Preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study liquid democracy, a collective decision making\nparadigm which lies between direct and representative democracy. One main\nfeature of liquid democracy is that voters can delegate their votes in a\ntransitive manner so that: A delegates to B and B delegates to C leads to A\ndelegates to C. Unfortunately, this process may not converge as there may not\neven exist a stable state (also called equilibrium). In this paper, we\ninvestigate the stability of the delegation process in liquid democracy when\nvoters have restricted types of preference on the agent representing them\n(e.g., single-peaked preferences). We show that various natural structures of\npreferences guarantee the existence of an equilibrium and we obtain both\ntractability and hardness results for the problem of computing several\nequilibria with some desirable properties.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 11:30:54 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 15:26:12 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Escoffier", "Bruno", ""], ["Gilbert", "Hugo", ""], ["Pass-Lanneau", "Ad\u00e8le", ""]]}, {"id": "1809.04382", "submitter": "Nimrod Talmon", "authors": "Piotr Faliszewski and Nimrod Talmon", "title": "A Framework for Approval-based Budgeting Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define and study a general framework for approval-based budgeting methods\nand compare certain methods within this framework by their axiomatic and\ncomputational properties. Furthermore, we visualize their behavior on certain\nEuclidean distributions and analyze them experimentally.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 12:34:30 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Faliszewski", "Piotr", ""], ["Talmon", "Nimrod", ""]]}, {"id": "1809.04399", "submitter": "Slava Jankin Mikhaylov", "authors": "Slava Jankin Mikhaylov and Marc Esteve and Averill Campion", "title": "Artificial Intelligence for the Public Sector: Opportunities and\n  challenges of cross-sector collaboration", "comments": null, "journal-ref": "Philosophical Transactions of the Royal Society A, 2018, Volume\n  376, Issue 2128", "doi": "10.1098/rsta.2017.0357", "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public sector organisations are increasingly interested in using data science\nand artificial intelligence capabilities to deliver policy and generate\nefficiencies in high uncertainty environments. The long-term success of data\nscience and AI in the public sector relies on effectively embedding it into\ndelivery solutions for policy implementation. However, governments cannot do\nthis integration of AI into public service delivery on their own. The UK\nGovernment Industrial Strategy is clear that delivering on the AI grand\nchallenge requires collaboration between universities and public and private\nsectors. This cross-sectoral collaborative approach is the norm in applied AI\ncentres of excellence around the world. Despite their popularity, cross-sector\ncollaborations entail serious management challenges that hinder their success.\nIn this article we discuss the opportunities and challenges from AI for public\nsector. Finally, we propose a series of strategies to successfully manage these\ncross-sectoral collaborations.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 13:12:07 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Mikhaylov", "Slava Jankin", ""], ["Esteve", "Marc", ""], ["Campion", "Averill", ""]]}, {"id": "1809.04423", "submitter": "Ramin M. Hasani", "authors": "Ramin Hasani, Mathias Lechner, Alexander Amini, Daniela Rus, Radu\n  Grosu", "title": "Can a Compact Neuronal Circuit Policy be Re-purposed to Learn Simple\n  Robotic Control?", "comments": "arXiv admin note: substantial text overlap with arXiv:1803.08554", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a neural information processing system which is obtained by\nre-purposing the function of a biological neural circuit model, to govern\nsimulated and real-world control tasks. Inspired by the structure of the\nnervous system of the soil-worm, C. elegans, we introduce Neuronal Circuit\nPolicies (NCPs), defined as the model of biological neural circuits\nreparameterized for the control of an alternative task. We learn instances of\nNCPs to control a series of robotic tasks, including the autonomous parking of\na real-world rover robot. For reconfiguration of the purpose of the neural\ncircuit, we adopt a search-based optimization algorithm. Neuronal circuit\npolicies perform on par and in some cases surpass the performance of\ncontemporary deep learning models with the advantage leveraging significantly\nfewer learnable parameters and realizing interpretable dynamics at the\ncell-level.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 15:05:12 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 13:12:37 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Hasani", "Ramin", ""], ["Lechner", "Mathias", ""], ["Amini", "Alexander", ""], ["Rus", "Daniela", ""], ["Grosu", "Radu", ""]]}, {"id": "1809.04497", "submitter": "Abdul Fatir Ansari", "authors": "Abdul Fatir Ansari and Harold Soh", "title": "Hyperprior Induced Unsupervised Disentanglement of Latent\n  Representations", "comments": "AAAI-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of unsupervised disentanglement of latent\nrepresentations learnt via deep generative models. In contrast to current\napproaches that operate on the evidence lower bound (ELBO), we argue that\nstatistical independence in the latent space of VAEs can be enforced in a\nprincipled hierarchical Bayesian manner. To this effect, we augment the\nstandard VAE with an inverse-Wishart (IW) prior on the covariance matrix of the\nlatent code. By tuning the IW parameters, we are able to encourage (or\ndiscourage) independence in the learnt latent dimensions. Extensive\nexperimental results on a range of datasets (2DShapes, 3DChairs, 3DFaces and\nCelebA) show our approach to outperform the $\\beta$-VAE and is competitive with\nthe state-of-the-art FactorVAE. Our approach achieves significantly better\ndisentanglement and reconstruction on a new dataset (CorrelatedEllipses) which\nintroduces correlations between the factors of variation.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 14:53:19 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 10:17:22 GMT"}, {"version": "v3", "created": "Sun, 6 Jan 2019 09:30:19 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Ansari", "Abdul Fatir", ""], ["Soh", "Harold", ""]]}, {"id": "1809.04506", "submitter": "Vincent Francois-Lavet", "authors": "Vincent Fran\\c{c}ois-Lavet, Yoshua Bengio, Doina Precup, Joelle Pineau", "title": "Combined Reinforcement Learning via Abstract Representations", "comments": "Accepted to the Thirty-Third AAAI Conference On Artificial\n  Intelligence, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the quest for efficient and robust reinforcement learning methods, both\nmodel-free and model-based approaches offer advantages. In this paper we\npropose a new way of explicitly bridging both approaches via a shared\nlow-dimensional learned encoding of the environment, meant to capture\nsummarizing abstractions. We show that the modularity brought by this approach\nleads to good generalization while being computationally efficient, with\nplanning happening in a smaller latent state space. In addition, this approach\nrecovers a sufficient low-dimensional representation of the environment, which\nopens up new strategies for interpretable AI, exploration and transfer\nlearning.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 15:12:49 GMT"}, {"version": "v2", "created": "Sun, 18 Nov 2018 23:47:15 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Fran\u00e7ois-Lavet", "Vincent", ""], ["Bengio", "Yoshua", ""], ["Precup", "Doina", ""], ["Pineau", "Joelle", ""]]}, {"id": "1809.04520", "submitter": "Sergey Rodionov", "authors": "Alexey Potapov, Sergey Rodionov", "title": "Genetic algorithms with DNN-based trainable crossover as an example of\n  partial specialization of general search", "comments": "AGI 2017 procedding, The final publication is available at\n  link.springer.com", "journal-ref": null, "doi": "10.1007/978-3-319-63703-7_10", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Universal induction relies on some general search procedure that is doomed to\nbe inefficient. One possibility to achieve both generality and efficiency is to\nspecialize this procedure w.r.t. any given narrow task. However, complete\nspecialization that implies direct mapping from the task parameters to\nsolutions (discriminative models) without search is not always possible. In\nthis paper, partial specialization of general search is considered in the form\nof genetic algorithms (GAs) with a specialized crossover operator. We perform a\nfeasibility study of this idea implementing such an operator in the form of a\ndeep feedforward neural network. GAs with trainable crossover operators are\ncompared with the result of complete specialization, which is also represented\nas a deep neural network. Experimental results show that specialized GAs can be\nmore efficient than both general GAs and discriminative models.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 10:14:58 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Potapov", "Alexey", ""], ["Rodionov", "Sergey", ""]]}, {"id": "1809.04525", "submitter": "Wei Li", "authors": "Min Chen, Yixue Hao, Kai Lin, Zhiyong Yuan, Long Hu", "title": "Label-less Learning for Traffic Control in an Edge Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of intelligent applications (e.g., self-driving,\nreal-time emotion recognition, etc), there are higher requirements for the\ncloud intelligence. However, cloud intelligence depends on the multi-modal data\ncollected by user equipments (UEs). Due to the limited capacity of network\nbandwidth, offloading all data generated from the UEs to the remote cloud is\nimpractical. Thus, in this article, we consider the challenging issue of\nachieving a certain level of cloud intelligence while reducing network traffic.\nIn order to solve this problem, we design a traffic control algorithm based on\nlabel-less learning on the edge cloud, which is dubbed as LLTC. By the use of\nthe limited computing and storage resources at edge cloud, LLTC evaluates the\nvalue of data, which will be offloaded. Specifically, we first give a statement\nof the problem and the system architecture. Then, we design the LLTC algorithm\nin detail. Finally, we set up the system testbed. Experimental results show\nthat the proposed LLTC can guarantee the required cloud intelligence while\nminimizing the amount of data transmission.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 12:32:31 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Chen", "Min", ""], ["Hao", "Yixue", ""], ["Lin", "Kai", ""], ["Yuan", "Zhiyong", ""], ["Hu", "Long", ""]]}, {"id": "1809.04558", "submitter": "Timo Korthals", "authors": "Timo Korthals, J\\\"urgen Leitner, Ulrich R\\\"uckert", "title": "Coordinated Heterogeneous Distributed Perception based on Latent Space\n  Representation", "comments": "IROS 2018 Second Workshop on Multi-robot Perception-Driven Control\n  and Planning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a reinforcement approach for distributed sensing based on the\nlatent space derived from multi-modal deep generative models. Our contribution\nprovides insights to the following benefits: Detections can be exchanged\neffectively between robots equipped with uni-modal sensors due to a shared\nlatent representation of information that is trained by a Variational Auto\nEncoder (VAE). Sensor-fusion can be applied asynchronously due to the\ngenerative feature of the VAE. Deep Q-Networks (DQNs) are trained to minimize\nuncertainty in latent space by coordinating robots to a Point-of-Interest (PoI)\nwhere their sensor modality can provide beneficial information about the PoI.\nAdditionally, we show that the decrease in uncertainty can be defined as the\ndirect reward signal for training the DQN.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 16:50:39 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Korthals", "Timo", ""], ["Leitner", "J\u00fcrgen", ""], ["R\u00fcckert", "Ulrich", ""]]}, {"id": "1809.04560", "submitter": "Ramakanth Pasunuru", "authors": "Ramakanth Pasunuru, Mohit Bansal", "title": "Game-Based Video-Context Dialogue", "comments": "EMNLP 2018 (14 pages) (fixed Table5 typo in v2)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current dialogue systems focus more on textual and speech context knowledge\nand are usually based on two speakers. Some recent work has investigated static\nimage-based dialogue. However, several real-world human interactions also\ninvolve dynamic visual context (similar to videos) as well as dialogue\nexchanges among multiple speakers. To move closer towards such multimodal\nconversational skills and visually-situated applications, we introduce a new\nvideo-context, many-speaker dialogue dataset based on live-broadcast soccer\ngame videos and chats from Twitch.tv. This challenging testbed allows us to\ndevelop visually-grounded dialogue models that should generate relevant\ntemporal and spatial event language from the live video, while also being\nrelevant to the chat history. For strong baselines, we also present several\ndiscriminative and generative models, e.g., based on tridirectional attention\nflow (TriDAF). We evaluate these models via retrieval ranking-recall, automatic\nphrase-matching metrics, as well as human evaluation studies. We also present\ndataset analyses, model ablations, and visualizations to understand the\ncontribution of different modalities and model components.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 16:53:13 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2018 15:26:48 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Pasunuru", "Ramakanth", ""], ["Bansal", "Mohit", ""]]}, {"id": "1809.04585", "submitter": "Yichen Jiang", "authors": "Yichen Jiang, Mohit Bansal", "title": "Closed-Book Training to Improve Summarization Encoder Memory", "comments": "EMNLP 2018 (16 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A good neural sequence-to-sequence summarization model should have a strong\nencoder that can distill and memorize the important information from long input\ntexts so that the decoder can generate salient summaries based on the encoder's\nmemory. In this paper, we aim to improve the memorization capabilities of the\nencoder of a pointer-generator model by adding an additional 'closed-book'\ndecoder without attention and pointer mechanisms. Such a decoder forces the\nencoder to be more selective in the information encoded in its memory state\nbecause the decoder can't rely on the extra information provided by the\nattention and possibly copy modules, and hence improves the entire model. On\nthe CNN/Daily Mail dataset, our 2-decoder model outperforms the baseline\nsignificantly in terms of ROUGE and METEOR metrics, for both cross-entropy and\nreinforced setups (and on human evaluation). Moreover, our model also achieves\nhigher scores in a test-only DUC-2002 generalizability setup. We further\npresent a memory ability test, two saliency metrics, as well as several\nsanity-check ablations (based on fixed-encoder, gradient-flow cut, and model\ncapacity) to prove that the encoder of our 2-decoder model does in fact learn\nstronger memory representations than the baseline encoder.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 17:50:07 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Jiang", "Yichen", ""], ["Bansal", "Mohit", ""]]}, {"id": "1809.04673", "submitter": "Rishabh Iyer", "authors": "Rishabh Iyer, Nimit Acharya, Tanuja Bompada, Denis Charles, Eren\n  Manavoglu", "title": "A Unified Batch Online Learning Framework for Click Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a unified framework for Batch Online Learning (OL) for Click\nPrediction in Search Advertisement. Machine Learning models once deployed, show\nnon-trivial accuracy and calibration degradation over time due to model\nstaleness. It is therefore necessary to regularly update models, and do so\nautomatically. This paper presents two paradigms of Batch Online Learning, one\nwhich incrementally updates the model parameters via an early stopping\nmechanism, and another which does so through a proximal regularization. We\nargue how both these schemes naturally trade-off between old and new data. We\nthen theoretically and empirically show that these two seemingly different\nschemes are closely related. Through extensive experiments, we demonstrate the\nutility of of our OL framework; how the two OL schemes relate to each other and\nhow they trade-off between the new and historical data. We then compare batch\nOL to full model retrains, and show how online learning is more robust to data\nissues. We also demonstrate the long term impact of Online Learning, the role\nof the initial Models in OL, the impact of delays in the update, and finally\nconclude with some implementation details and challenges in deploying a real\nworld online learning system in production. While this paper mostly focuses on\napplication of click prediction for search advertisement, we hope that the\nlessons learned here can be carried over to other problem domains.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 21:01:55 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Iyer", "Rishabh", ""], ["Acharya", "Nimit", ""], ["Bompada", "Tanuja", ""], ["Charles", "Denis", ""], ["Manavoglu", "Eren", ""]]}, {"id": "1809.04683", "submitter": "Shuhan Yuan", "authors": "Panpan Zheng, Shuhan Yuan, Xintao Wu", "title": "SAFE: A Neural Survival Analysis Model for Fraud Early Detection", "comments": "To appear in AAAI-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many online platforms have deployed anti-fraud systems to detect and prevent\nfraudulent activities. However, there is usually a gap between the time that a\nuser commits a fraudulent action and the time that the user is suspended by the\nplatform. How to detect fraudsters in time is a challenging problem. Most of\nthe existing approaches adopt classifiers to predict fraudsters given their\nactivity sequences along time. The main drawback of classification models is\nthat the prediction results between consecutive timestamps are often\ninconsistent. In this paper, we propose a survival analysis based fraud early\ndetection model, SAFE, which maps dynamic user activities to survival\nprobabilities that are guaranteed to be monotonically decreasing along time.\nSAFE adopts recurrent neural network (RNN) to handle user activity sequences\nand directly outputs hazard values at each timestamp, and then, survival\nprobability derived from hazard values is deployed to achieve consistent\npredictions. Because we only observe the user suspended time instead of the\nfraudulent activity time in the training data, we revise the loss function of\nthe regular survival model to achieve fraud early detection. Experimental\nresults on two real world datasets demonstrate that SAFE outperforms both the\nsurvival analysis model and recurrent neural network model alone as well as\nstate-of-the-art fraud early detection approaches.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 21:28:26 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 21:12:08 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Zheng", "Panpan", ""], ["Yuan", "Shuhan", ""], ["Wu", "Xintao", ""]]}, {"id": "1809.04684", "submitter": "Jiahao Chen", "authors": "Jiahao Chen", "title": "Fair lending needs explainable models for responsible recommendation", "comments": "4 pages, position paper accepted for FATREC 2018 conference at ACM\n  RecSys", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The financial services industry has unique explainability and fairness\nchallenges arising from compliance and ethical considerations in credit\ndecisioning. These challenges complicate the use of model machine learning and\nartificial intelligence methods in business decision processes.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 21:29:20 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Chen", "Jiahao", ""]]}, {"id": "1809.04686", "submitter": "Orhan Firat", "authors": "Akiko Eriguchi, Melvin Johnson, Orhan Firat, Hideto Kazawa, Wolfgang\n  Macherey", "title": "Zero-Shot Cross-lingual Classification Using Multilingual Neural Machine\n  Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transferring representations from large supervised tasks to downstream tasks\nhas shown promising results in AI fields such as Computer Vision and Natural\nLanguage Processing (NLP). In parallel, the recent progress in Machine\nTranslation (MT) has enabled one to train multilingual Neural MT (NMT) systems\nthat can translate between multiple languages and are also capable of\nperforming zero-shot translation. However, little attention has been paid to\nleveraging representations learned by a multilingual NMT system to enable\nzero-shot multilinguality in other NLP tasks. In this paper, we demonstrate a\nsimple framework, a multilingual Encoder-Classifier, for cross-lingual transfer\nlearning by reusing the encoder from a multilingual NMT system and stitching it\nwith a task-specific classifier component. Our proposed model achieves\nsignificant improvements in the English setup on three benchmark tasks - Amazon\nReviews, SST and SNLI. Further, our system can perform classification in a new\nlanguage for which no classification data was seen during training, showing\nthat zero-shot classification is possible and remarkably competitive. In order\nto understand the underlying factors contributing to this finding, we conducted\na series of analyses on the effect of the shared vocabulary, the training data\ntype for NMT, classifier complexity, encoder representation power, and model\ngeneralization on zero-shot performance. Our results provide strong evidence\nthat the representations learned from multilingual NMT systems are widely\napplicable across languages and tasks.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 21:34:03 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Eriguchi", "Akiko", ""], ["Johnson", "Melvin", ""], ["Firat", "Orhan", ""], ["Kazawa", "Hideto", ""], ["Macherey", "Wolfgang", ""]]}, {"id": "1809.04708", "submitter": "Ikhlas Alhussien", "authors": "Ikhlas Alhussien, Erik Cambria, Zhang NengSheng", "title": "Semantically Enhanced Models for Commonsense Knowledge Acquisition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense knowledge is paramount to enable intelligent systems. Typically,\nit is characterized as being implicit and ambiguous, hindering thereby the\nautomation of its acquisition. To address these challenges, this paper presents\nsemantically enhanced models to enable reasoning through resolving part of\ncommonsense ambiguity. The proposed models enhance in a knowledge graph\nembedding (KGE) framework for knowledge base completion. Experimental results\nshow the effectiveness of the new semantic models in commonsense reasoning.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 23:23:46 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2018 00:06:53 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Alhussien", "Ikhlas", ""], ["Cambria", "Erik", ""], ["NengSheng", "Zhang", ""]]}, {"id": "1809.04737", "submitter": "Xintao Wu", "authors": "Yongkai Wu and Lu Zhang and Xintao Wu", "title": "Fairness-aware Classification: Criterion, Convexity, and Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness-aware classification is receiving increasing attention in the\nmachine learning fields. Recently research proposes to formulate the\nfairness-aware classification as constrained optimization problems. However,\nseveral limitations exist in previous works due to the lack of a theoretical\nframework for guiding the formulation. In this paper, we propose a general\nframework for learning fair classifiers which addresses previous limitations.\nThe framework formulates various commonly-used fairness metrics as convex\nconstraints that can be directly incorporated into classic classification\nmodels. Within the framework, we propose a constraint-free criterion on the\ntraining data which ensures that any classifier learned from the data is fair.\nWe also derive the constraints which ensure that the real fairness metric is\nsatisfied when surrogate functions are used to achieve convexity. Our framework\ncan be used to for formulating fairness-aware classification with fairness\nguarantee and computational efficiency. The experiments using real-world\ndatasets demonstrate our theoretical results and show the effectiveness of\nproposed framework and methods.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 01:56:57 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Wu", "Yongkai", ""], ["Zhang", "Lu", ""], ["Wu", "Xintao", ""]]}, {"id": "1809.04739", "submitter": "Sweta Karlekar", "authors": "Sweta Karlekar, Mohit Bansal", "title": "SafeCity: Understanding Diverse Forms of Sexual Harassment Personal\n  Stories", "comments": "EMNLP 2018 (7 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent rise of #MeToo, an increasing number of personal stories\nabout sexual harassment and sexual abuse have been shared online. In order to\npush forward the fight against such harassment and abuse, we present the task\nof automatically categorizing and analyzing various forms of sexual harassment,\nbased on stories shared on the online forum SafeCity. For the labels of\ngroping, ogling, and commenting, our single-label CNN-RNN model achieves an\naccuracy of 86.5%, and our multi-label model achieves a Hamming score of 82.5%.\nFurthermore, we present analysis using LIME, first-derivative saliency\nheatmaps, activation clustering, and embedding visualization to interpret\nneural model predictions and demonstrate how this extracts features that can\nhelp automatically fill out incident reports, identify unsafe areas, avoid\nunsafe practices, and 'pin the creeps'.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 02:00:23 GMT"}, {"version": "v2", "created": "Fri, 14 Sep 2018 02:01:22 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Karlekar", "Sweta", ""], ["Bansal", "Mohit", ""]]}, {"id": "1809.04771", "submitter": "EPTCS", "authors": "Ekaterina Komendantskaya Dr (Heriot-Watt University), Yue Li\n  (Heriot-Watt University)", "title": "Towards Coinductive Theory Exploration in Horn Clause Logic: Position\n  Paper", "comments": "In Proceedings HCVS 2018, arXiv:1809.04554", "journal-ref": "EPTCS 278, 2018, pp. 27-33", "doi": "10.4204/EPTCS.278.5", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coinduction occurs in two guises in Horn clause logic: in proofs of\nself-referencing properties and relations, and in proofs involving construction\nof (possibly irregular) infinite data. Both instances of coinductive reasoning\nappeared in the literature before, but a systematic analysis of these two kinds\nof proofs and of their relation was lacking. We propose a general\nproof-theoretic framework for handling both kinds of coinduction arising in\nHorn clause logic. To this aim, we propose a coinductive extension of Miller et\nal's framework of uniform proofs and prove its soundness relative to\ncoinductive models of Horn clause logic.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 04:48:51 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Dr", "Ekaterina Komendantskaya", "", "Heriot-Watt University"], ["Li", "Yue", "", "Heriot-Watt University"]]}, {"id": "1809.04797", "submitter": "Marcel Salathe", "authors": "Marcel Salath\\'e, Thomas Wiegand, Markus Wenzel", "title": "Focus Group on Artificial Intelligence for Health", "comments": "Whitepaper on ITU Focus Group AI4H for 1st workshop at WHO", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial Intelligence (AI) - the phenomenon of machines being able to solve\nproblems that require human intelligence - has in the past decade seen an\nenormous rise of interest due to significant advances in effectiveness and use.\nThe health sector, one of the most important sectors for societies and\neconomies worldwide, is particularly interesting for AI applications, given the\nongoing digitalisation of all types of health information. The potential for AI\nassistance in the health domain is immense, because AI can support medical\ndecision making at reduced costs, everywhere. However, due to the complexity of\nAI algorithms, it is difficult to distinguish good from bad AI-based solutions\nand to understand their strengths and weaknesses, which is crucial for\nclarifying responsibilities and for building trust. For this reason, the\nInternational Telecommunication Union (ITU) has established a new Focus Group\non \"Artificial Intelligence for Health\" (FG-AI4H) in partnership with the World\nHealth Organization (WHO). Health and care services are usually the\nresponsibility of a government - even when provided through private insurance\nsystems - and thus under the responsibility of WHO/ITU member states. FG-AI4H\nwill identify opportunities for international standardization, which will\nfoster the application of AI to health issues on a global scale. In particular,\nit will establish a standardized assessment framework with open benchmarks for\nthe evaluation of AI-based methods for health, such as AI-based diagnosis,\ntriage or treatment decisions.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 06:46:34 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Salath\u00e9", "Marcel", ""], ["Wiegand", "Thomas", ""], ["Wenzel", "Markus", ""]]}, {"id": "1809.04861", "submitter": "Christian Stra{\\ss}er", "authors": "AnneMarie Borg, Christian Stra{\\ss}er", "title": "Relevance in Structured Argumentation", "comments": "Extended version of the paper with the same name published in the\n  main track of IJCAI 2018. It countains additionally a treatment of credulous\n  and weak skeptical semantics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study properties related to relevance in non-monotonic consequence\nrelations obtained by systems of structured argumentation. Relevance desiderata\nconcern the robustness of a consequence relation under the addition of\nirrelevant information. For an account of what (ir)relevance amounts to we use\nsyntactic and semantic considerations. Syntactic criteria have been proposed in\nthe domain of relevance logic and were recently used in argumentation theory\nunder the names of non-interference and crash-resistance. The basic idea is\nthat the conclusions of a given argumentative theory should be robust under\nadding information that shares no propositional variables with the original\ndatabase. Some semantic relevance criteria are known from non-monotonic logic.\nFor instance, cautious monotony states that if we obtain certain conclusions\nfrom an argumentation theory, we may expect to still obtain the same\nconclusions if we add some of them to the given database. In this paper we\ninvestigate properties of structured argumentation systems that warrant\nrelevance desiderata.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 09:52:03 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 06:28:12 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Borg", "AnneMarie", ""], ["Stra\u00dfer", "Christian", ""]]}, {"id": "1809.04918", "submitter": "Sean Barton", "authors": "Sean L. Barton, Nicholas R. Waytowich, Derrik E. Asher", "title": "Coordination-driven learning in multi-agent problem spaces", "comments": "AAAI Fall Symposium 2018, Concept Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the role of coordination as a direct learning objective in\nmulti-agent reinforcement learning (MARL) domains. To this end, we present a\nnovel means of quantifying coordination in multi-agent systems, and discuss the\nimplications of using such a measure to optimize coordinated agent policies.\nThis concept has important implications for adversary-aware RL, which we take\nto be a sub-domain of multi-agent learning.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 12:44:48 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Barton", "Sean L.", ""], ["Waytowich", "Nicholas R.", ""], ["Asher", "Derrik E.", ""]]}, {"id": "1809.04942", "submitter": "Raka Jovanovic", "authors": "Raka Jovanovic, Milan Tuba, Stefan Voss", "title": "Fixed set search applied to the traveling salesman problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a new population based metaheuristic called the\nfixed set search (FSS). The proposed approach represents a method of adding a\nlearning mechanism to the greedy randomized adaptive search procedure (GRASP).\nThe basic concept of FSS is to avoid focusing on specific high quality\nsolutions but on parts or elements that such solutions have. This is done\nthrough fixing a set of elements that exist in such solutions and dedicating\ncomputational effort to finding near optimal solutions for the underlying\nsubproblem. The simplicity of implementing the proposed method is illustrated\non the traveling salesman problem. Our computational experiments show that the\nFSS manages to find significantly better solutions than the GRASP it is based\non and also the dynamic convexized method.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 11:21:18 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Jovanovic", "Raka", ""], ["Tuba", "Milan", ""], ["Voss", "Stefan", ""]]}, {"id": "1809.04983", "submitter": "Kalpit Thakkar", "authors": "Kalpit Thakkar, P J Narayanan", "title": "Part-based Graph Convolutional Network for Action Recognition", "comments": "Main: 13 pages, 3 figures, 2 tables. Supplementary: 5 pages, 3\n  figures, 1 table. Accepted at BMVC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human actions comprise of joint motion of articulated body parts or\n`gestures'. Human skeleton is intuitively represented as a sparse graph with\njoints as nodes and natural connections between them as edges. Graph\nconvolutional networks have been used to recognize actions from skeletal\nvideos. We introduce a part-based graph convolutional network (PB-GCN) for this\ntask, inspired by Deformable Part-based Models (DPMs). We divide the skeleton\ngraph into four subgraphs with joints shared across them and learn a\nrecognition model using a part-based graph convolutional network. We show that\nsuch a model improves performance of recognition, compared to a model using\nentire skeleton graph. Instead of using 3D joint coordinates as node features,\nwe show that using relative coordinates and temporal displacements boosts\nperformance. Our model achieves state-of-the-art performance on two challenging\nbenchmark datasets NTURGB+D and HDM05, for skeletal action recognition.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 14:22:58 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Thakkar", "Kalpit", ""], ["Narayanan", "P J", ""]]}, {"id": "1809.04988", "submitter": "Eric Crawford", "authors": "Eric Crawford, Guillaume Rabusseau, Joelle Pineau", "title": "Sequential Coordination of Deep Models for Learning Visual Arithmetic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving machine intelligence requires a smooth integration of perception\nand reasoning, yet models developed to date tend to specialize in one or the\nother; sophisticated manipulation of symbols acquired from rich perceptual\nspaces has so far proved elusive. Consider a visual arithmetic task, where the\ngoal is to carry out simple arithmetical algorithms on digits presented under\nnatural conditions (e.g. hand-written, placed randomly). We propose a\ntwo-tiered architecture for tackling this problem. The lower tier consists of a\nheterogeneous collection of information processing modules, which can include\npre-trained deep neural networks for locating and extracting characters from\nthe image, as well as modules performing symbolic transformations on the\nrepresentations extracted by perception. The higher tier consists of a\ncontroller, trained using reinforcement learning, which coordinates the modules\nin order to solve the high-level task. For instance, the controller may learn\nin what contexts to execute the perceptual networks and what symbolic\ntransformations to apply to their outputs. The resulting model is able to solve\na variety of tasks in the visual arithmetic domain, and has several advantages\nover standard, architecturally homogeneous feedforward networks including\nimproved sample efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 14:27:25 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Crawford", "Eric", ""], ["Rabusseau", "Guillaume", ""], ["Pineau", "Joelle", ""]]}, {"id": "1809.05001", "submitter": "Son-Il Kwak", "authors": "Son-il Kwak, Gum-ju Kim, Michio Sugeno, Gwang-chol Li, Myong-suk Son,\n  Hyok-chol Kim, Un-ha Kim", "title": "Reductive property of new fuzzy reasoning method based on distance\n  measure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Firstly in this paper we propose a new criterion function for evaluation of\nthe reductive property about the fuzzy reasoning result for fuzzy modus ponens\nand fuzzy modus tollens. Secondly unlike fuzzy reasoning methods based on the\nsimilarity measure, we propose a new fuzzy reasoning method based on distance\nmeasure. Thirdly the reductive property for 5 fuzzy reasoning methods are\nchecked with respect to fuzzy modus ponens and fuzzy modus tollens. Through the\nexperiment, we show that proposed method is better than the previous methods in\naccordance with human thinking.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 10:37:22 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Kwak", "Son-il", ""], ["Kim", "Gum-ju", ""], ["Sugeno", "Michio", ""], ["Li", "Gwang-chol", ""], ["Son", "Myong-suk", ""], ["Kim", "Hyok-chol", ""], ["Kim", "Un-ha", ""]]}, {"id": "1809.05021", "submitter": "Navaneethkrishnan Balamuralidhar", "authors": "Navaneethkrishnan B, Pranjal Biswas, Saumya Kumaar Saksena, Gautham\n  Anand, S N Omkar", "title": "State-Space Identification of Unmanned Helicopter Dynamics using\n  Invasive Weed Optimization Algorithm on Flight Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to achieve a good level of autonomy in unmanned helicopters, an\naccurate replication of vehicle dynamics is required, which is achievable\nthrough precise mathematical modeling. This paper aims to identify a parametric\nstate-space system for an unmanned helicopter to a good level of accuracy using\nInvasive Weed Optimization (IWO) algorithm. The flight data of Align TREX 550\nflybarless helicopter is used in the identification process. The rigid-body\ndynamics of the helicopter is modeled in a state-space form that has 40\nparameters, which serve as control variables for the IWO algorithm. The results\nafter 1000 iterations were compared with the traditionally used Prediction\nError Minimization (PEM) method and also with Genetic Algorithm (GA), which\nserve as references. Results show a better level of correlation between the\nactual and estimated responses of the system identified using IWO to that of\nPEM and GA.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 11:08:08 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["B", "Navaneethkrishnan", ""], ["Biswas", "Pranjal", ""], ["Saksena", "Saumya Kumaar", ""], ["Anand", "Gautham", ""], ["Omkar", "S N", ""]]}, {"id": "1809.05053", "submitter": "Alexis Conneau", "authors": "Alexis Conneau, Guillaume Lample, Ruty Rinott, Adina Williams, Samuel\n  R. Bowman, Holger Schwenk, Veselin Stoyanov", "title": "XNLI: Evaluating Cross-lingual Sentence Representations", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art natural language processing systems rely on supervision in\nthe form of annotated data to learn competent models. These models are\ngenerally trained on data in a single language (usually English), and cannot be\ndirectly used beyond that language. Since collecting data in every language is\nnot realistic, there has been a growing interest in cross-lingual language\nunderstanding (XLU) and low-resource cross-language transfer. In this work, we\nconstruct an evaluation set for XLU by extending the development and test sets\nof the Multi-Genre Natural Language Inference Corpus (MultiNLI) to 15\nlanguages, including low-resource languages such as Swahili and Urdu. We hope\nthat our dataset, dubbed XNLI, will catalyze research in cross-lingual sentence\nunderstanding by providing an informative standard evaluation task. In\naddition, we provide several baselines for multilingual sentence understanding,\nincluding two based on machine translation systems, and two that use parallel\ndata to train aligned multilingual bag-of-words and LSTM encoders. We find that\nXNLI represents a practical and challenging evaluation suite, and that directly\ntranslating the test data yields the best performance among available\nbaselines.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 16:39:53 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Conneau", "Alexis", ""], ["Lample", "Guillaume", ""], ["Rinott", "Ruty", ""], ["Williams", "Adina", ""], ["Bowman", "Samuel R.", ""], ["Schwenk", "Holger", ""], ["Stoyanov", "Veselin", ""]]}, {"id": "1809.05054", "submitter": "Tianze Shi", "authors": "Tianze Shi, Kedar Tatwawadi, Kaushik Chakrabarti, Yi Mao, Oleksandr\n  Polozov, Weizhu Chen", "title": "IncSQL: Training Incremental Text-to-SQL Parsers with Non-Deterministic\n  Oracles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a sequence-to-action parsing approach for the natural language to\nSQL task that incrementally fills the slots of a SQL query with feasible\nactions from a pre-defined inventory. To account for the fact that typically\nthere are multiple correct SQL queries with the same or very similar semantics,\nwe draw inspiration from syntactic parsing techniques and propose to train our\nsequence-to-action models with non-deterministic oracles. We evaluate our\nmodels on the WikiSQL dataset and achieve an execution accuracy of 83.7% on the\ntest set, a 2.1% absolute improvement over the models trained with traditional\nstatic oracles assuming a single correct target SQL query. When further\ncombined with the execution-guided decoding strategy, our model sets a new\nstate-of-the-art performance at an execution accuracy of 87.1%.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 16:42:21 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 17:55:37 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Shi", "Tianze", ""], ["Tatwawadi", "Kedar", ""], ["Chakrabarti", "Kaushik", ""], ["Mao", "Yi", ""], ["Polozov", "Oleksandr", ""], ["Chen", "Weizhu", ""]]}, {"id": "1809.05068", "submitter": "Jiajun Wu", "authors": "Jiajun Wu, Chengkai Zhang, Xiuming Zhang, Zhoutong Zhang, William T.\n  Freeman, Joshua B. Tenenbaum", "title": "Learning Shape Priors for Single-View 3D Completion and Reconstruction", "comments": "ECCV 2018. The first two authors contributed equally to this work.\n  Project page: http://shapehd.csail.mit.edu/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of single-view 3D shape completion or reconstruction is\nchallenging, because among the many possible shapes that explain an\nobservation, most are implausible and do not correspond to natural objects.\nRecent research in the field has tackled this problem by exploiting the\nexpressiveness of deep convolutional networks. In fact, there is another level\nof ambiguity that is often overlooked: among plausible shapes, there are still\nmultiple shapes that fit the 2D image equally well; i.e., the ground truth\nshape is non-deterministic given a single-view input. Existing fully supervised\napproaches fail to address this issue, and often produce blurry mean shapes\nwith smooth surfaces but no fine details.\n  In this paper, we propose ShapeHD, pushing the limit of single-view shape\ncompletion and reconstruction by integrating deep generative models with\nadversarially learned shape priors. The learned priors serve as a regularizer,\npenalizing the model only if its output is unrealistic, not if it deviates from\nthe ground truth. Our design thus overcomes both levels of ambiguity\naforementioned. Experiments demonstrate that ShapeHD outperforms state of the\nart by a large margin in both shape completion and shape reconstruction on\nmultiple real datasets.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 17:23:13 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Wu", "Jiajun", ""], ["Zhang", "Chengkai", ""], ["Zhang", "Xiuming", ""], ["Zhang", "Zhoutong", ""], ["Freeman", "William T.", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1809.05070", "submitter": "Jiajun Wu", "authors": "Zhijian Liu, William T. Freeman, Joshua B. Tenenbaum, Jiajun Wu", "title": "Physical Primitive Decomposition", "comments": "ECCV 2018. Project page: http://ppd.csail.mit.edu/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objects are made of parts, each with distinct geometry, physics,\nfunctionality, and affordances. Developing such a distributed, physical,\ninterpretable representation of objects will facilitate intelligent agents to\nbetter explore and interact with the world. In this paper, we study physical\nprimitive decomposition---understanding an object through its components, each\nwith physical and geometric attributes. As annotated data for object parts and\nphysics are rare, we propose a novel formulation that learns physical\nprimitives by explaining both an object's appearance and its behaviors in\nphysical events. Our model performs well on block towers and tools in both\nsynthetic and real scenarios; we also demonstrate that visual and physical\nobservations often provide complementary signals. We further present ablation\nand behavioral studies to better understand our model and contrast it with\nhuman performance.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 17:23:20 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Liu", "Zhijian", ""], ["Freeman", "William T.", ""], ["Tenenbaum", "Joshua B.", ""], ["Wu", "Jiajun", ""]]}, {"id": "1809.05096", "submitter": "Gregory Palmer", "authors": "Gregory Palmer, Rahul Savani, Karl Tuyls", "title": "Negative Update Intervals in Deep Multi-Agent Reinforcement Learning", "comments": "11 Pages, 6 Figures, AAMAS2019 Conference Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Multi-Agent Reinforcement Learning (MA-RL), independent cooperative\nlearners must overcome a number of pathologies to learn optimal joint policies.\nAddressing one pathology often leaves approaches vulnerable towards others. For\ninstance, hysteretic Q-learning addresses miscoordination while leaving agents\nvulnerable towards misleading stochastic rewards. Other methods, such as\nleniency, have proven more robust when dealing with multiple pathologies\nsimultaneously. However, leniency has predominately been studied within the\ncontext of strategic form games (bimatrix games) and fully observable Markov\ngames consisting of a small number of probabilistic state transitions. This\nraises the question of whether these findings scale to more complex domains.\nFor this purpose we implement a temporally extend version of the Climb Game,\nwithin which agents must overcome multiple pathologies simultaneously,\nincluding relative overgeneralisation, stochasticity, the alter-exploration and\nmoving target problems, while learning from a large observation space. We find\nthat existing lenient and hysteretic approaches fail to consistently learn near\noptimal joint-policies in this environment. To address these pathologies we\nintroduce Negative Update Intervals-DDQN (NUI-DDQN), a Deep MA-RL algorithm\nwhich discards episodes yielding cumulative rewards outside the range of\nexpanding intervals. NUI-DDQN consistently gravitates towards optimal\njoint-policies in our environment, overcoming the outlined pathologies.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 15:46:55 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 09:20:12 GMT"}, {"version": "v3", "created": "Tue, 7 May 2019 09:34:03 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Palmer", "Gregory", ""], ["Savani", "Rahul", ""], ["Tuyls", "Karl", ""]]}, {"id": "1809.05127", "submitter": "Garrett Goh", "authors": "Khushmeen Sakloth, Wesley Beckner, Jim Pfaendtner, Garrett B. Goh", "title": "IL-Net: Using Expert Knowledge to Guide the Design of Furcated Neural\n  Networks", "comments": "Submitted to peer-reviewed ML conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) excel at extracting patterns. Through\nrepresentation learning and automated feature engineering on large datasets,\nsuch models have been highly successful in computer vision and natural language\napplications. Designing optimal network architectures from a principled or\nrational approach however has been less than successful, with the best\nsuccessful approaches utilizing an additional machine learning algorithm to\ntune the network hyperparameters. However, in many technical fields, there\nexist established domain knowledge and understanding about the subject matter.\nIn this work, we develop a novel furcated neural network architecture that\nutilizes domain knowledge as high-level design principles of the network. We\ndemonstrate proof-of-concept by developing IL-Net, a furcated network for\npredicting the properties of ionic liquids, which is a class of complex\nmulti-chemicals entities. Compared to existing state-of-the-art approaches, we\nshow that furcated networks can improve model accuracy by approximately 20-35%,\nwithout using additional labeled data. Lastly, we distill two key design\nprinciples for furcated networks that can be adapted to other domains.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 18:22:04 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Sakloth", "Khushmeen", ""], ["Beckner", "Wesley", ""], ["Pfaendtner", "Jim", ""], ["Goh", "Garrett B.", ""]]}, {"id": "1809.05214", "submitter": "Ignasi Clavera", "authors": "Ignasi Clavera, Jonas Rothfuss, John Schulman, Yasuhiro Fujita, Tamim\n  Asfour, Pieter Abbeel", "title": "Model-Based Reinforcement Learning via Meta-Policy Optimization", "comments": "First 2 authors contributed equally. Accepted for Conference on Robot\n  Learning (CoRL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning approaches carry the promise of being data\nefficient. However, due to challenges in learning dynamics models that\nsufficiently match the real-world dynamics, they struggle to achieve the same\nasymptotic performance as model-free methods. We propose Model-Based\nMeta-Policy-Optimization (MB-MPO), an approach that foregoes the strong\nreliance on accurate learned dynamics models. Using an ensemble of learned\ndynamic models, MB-MPO meta-learns a policy that can quickly adapt to any model\nin the ensemble with one policy gradient step. This steers the meta-policy\ntowards internalizing consistent dynamics predictions among the ensemble while\nshifting the burden of behaving optimally w.r.t. the model discrepancies\ntowards the adaptation step. Our experiments show that MB-MPO is more robust to\nmodel imperfections than previous model-based approaches. Finally, we\ndemonstrate that our approach is able to match the asymptotic performance of\nmodel-free methods while requiring significantly less experience.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 01:15:28 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Clavera", "Ignasi", ""], ["Rothfuss", "Jonas", ""], ["Schulman", "John", ""], ["Fujita", "Yasuhiro", ""], ["Asfour", "Tamim", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1809.05239", "submitter": "Xu Chen", "authors": "Tao Ouyang and Zhi Zhou and Xu Chen", "title": "Follow Me at the Edge: Mobility-Aware Dynamic Service Placement for\n  Mobile Edge Computing", "comments": "The paper is accepted by IEEE Journal on Selected Areas in\n  Communications, Aug. 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.DC cs.MM cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile edge computing is a new computing paradigm, which pushes cloud\ncomputing capabilities away from the centralized cloud to the network edge.\nHowever, with the sinking of computing capabilities, the new challenge incurred\nby user mobility arises: since end-users typically move erratically, the\nservices should be dynamically migrated among multiple edges to maintain the\nservice performance, i.e., user-perceived latency. Tackling this problem is\nnon-trivial since frequent service migration would greatly increase the\noperational cost. To address this challenge in terms of the performance-cost\ntrade-off, in this paper we study the mobile edge service performance\noptimization problem under long-term cost budget constraint. To address user\nmobility which is typically unpredictable, we apply Lyapunov optimization to\ndecompose the long-term optimization problem into a series of real-time\noptimization problems which do not require a priori knowledge such as user\nmobility. As the decomposed problem is NP-hard, we first design an\napproximation algorithm based on Markov approximation to seek a near-optimal\nsolution. To make our solution scalable and amenable to future 5G application\nscenario with large-scale user devices, we further propose a distributed\napproximation scheme with greatly reduced time complexity, based on the\ntechnique of best response update. Rigorous theoretical analysis and extensive\nevaluations demonstrate the efficacy of the proposed centralized and\ndistributed schemes.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 03:07:40 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Ouyang", "Tao", ""], ["Zhou", "Zhi", ""], ["Chen", "Xu", ""]]}, {"id": "1809.05247", "submitter": "Lingfei Wu", "authors": "Lingfei Wu, Ian E.H. Yen, Jie Chen, and Rui Yan", "title": "Revisiting Random Binning Features: Fast Convergence and Strong\n  Parallelizability", "comments": "KDD16, Oral Paper, Add Code Link for generating Random Binning\n  Features", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel method has been developed as one of the standard approaches for\nnonlinear learning, which however, does not scale to large data set due to its\nquadratic complexity in the number of samples. A number of kernel approximation\nmethods have thus been proposed in the recent years, among which the random\nfeatures method gains much popularity due to its simplicity and direct\nreduction of nonlinear problem to a linear one. The Random Binning (RB)\nfeature, proposed in the first random-feature paper \\cite{rahimi2007random},\nhas drawn much less attention than the Random Fourier (RF) feature. In this\nwork, we observe that the RB features, with right choice of optimization\nsolver, could be orders-of-magnitude more efficient than other random features\nand kernel approximation methods under the same requirement of accuracy. We\nthus propose the first analysis of RB from the perspective of optimization,\nwhich by interpreting RB as a Randomized Block Coordinate Descent in the\ninfinite-dimensional space, gives a faster convergence rate compared to that of\nother random features. In particular, we show that by drawing $R$ random grids\nwith at least $\\kappa$ number of non-empty bins per grid in expectation, RB\nmethod achieves a convergence rate of $O(1/(\\kappa R))$, which not only\nsharpens its $O(1/\\sqrt{R})$ rate from Monte Carlo analysis, but also shows a\n$\\kappa$ times speedup over other random features under the same analysis\nframework. In addition, we demonstrate another advantage of RB in the\nL1-regularized setting, where unlike other random features, a RB-based\nCoordinate Descent solver can be parallelized with guaranteed speedup\nproportional to $\\kappa$. Our extensive experiments demonstrate the superior\nperformance of the RB features over other random features and kernel\napproximation methods. Our code and data is available at {\n\\url{https://github.com/teddylfwu/RB_GEN}}.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 04:06:35 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 02:49:53 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Wu", "Lingfei", ""], ["Yen", "Ian E. H.", ""], ["Chen", "Jie", ""], ["Yan", "Rui", ""]]}, {"id": "1809.05275", "submitter": "Ravindra Guntur", "authors": "Kumar Mrityunjay and Guntur Ravindra", "title": "Learning to Fingerprint the Latent Structure in Question Articulation", "comments": "Pre-Print, ACCEPTED FOR PRESENTATION AT the 17th IEEE INTERNATIONAL\n  CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA2018)", "journal-ref": null, "doi": "10.1109/ICMLA.2018.00019", "report-no": null, "categories": "cs.AI cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract Machine understanding of questions is tightly related to recognition\nof articulation in the context of the computational capabilities of an\nunderlying processing algorithm. In this paper a mathematical model to capture\nand distinguish the latent structure in the articulation of questions is\npresented. We propose an objective-driven approach to represent this latent\nstructure and show that such an approach is beneficial when examples of\ncomplementary objectives are not available. We show that the latent structure\ncan be represented as a system that maximizes a cost function related to the\nunderlying objective. Further, we show that the optimization formulation can be\napproximated to building a memory of patterns represented as a trained neural\nauto-encoder. Experimental evaluation using many clusters of questions, each\nrelated to an objective, shows 80% recognition accuracy and negligible false\npositive across these clusters of questions. We then extend the same memory to\na related task where the goal is to iteratively refine a dataset of questions\nbased on the latent articulation. We also demonstrate a refinement scheme\ncalled K-fingerprints, that achieves nearly 100% recognition with negligible\nfalse positive across the different clusters of questions.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 06:51:01 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Mrityunjay", "Kumar", ""], ["Ravindra", "Guntur", ""]]}, {"id": "1809.05309", "submitter": "Vaishak Belle", "authors": "Vaishak Belle", "title": "On Plans With Loops and Noise", "comments": "Proceedings of AAMAS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an influential paper, Levesque proposed a formal specification for\nanalysing the correctness of program-like plans, such as conditional plans,\niterative plans, and knowledge-based plans. He motivated a logical\ncharacterisation within the situation calculus that included binary sensing\nactions. While the characterisation does not immediately yield a practical\nalgorithm, the specification serves as a general skeleton to explore the\nsynthesis of program-like plans for reasonable, tractable fragments.\n  Increasingly, classical plan structures are being applied to stochastic\nenvironments such as robotics applications. This raises the question as to what\nthe specification for correctness should look like, since Levesque's account\nmakes the assumption that sensing is exact and actions are deterministic.\nBuilding on a situation calculus theory for reasoning about degrees of belief\nand noise, we revisit the execution semantics of generalised plans. The\nspecification is then used to analyse the correctness of example plans.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 08:58:49 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Belle", "Vaishak", ""]]}, {"id": "1809.05314", "submitter": "Vaishak Belle", "authors": "Vaishak Belle, Hector J. Levesque", "title": "Reasoning about Discrete and Continuous Noisy Sensors and Effectors in\n  Dynamical Systems", "comments": "To appear in Artificial Intelligence 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the many approaches for reasoning about degrees of belief in the\npresence of noisy sensing and acting, the logical account proposed by Bacchus,\nHalpern, and Levesque is perhaps the most expressive. While their formalism is\nquite general, it is restricted to fluents whose values are drawn from discrete\nfinite domains, as opposed to the continuous domains seen in many robotic\napplications. In this work, we show how this limitation in that approach can be\nlifted. By dealing seamlessly with both discrete distributions and continuous\ndensities within a rich theory of action, we provide a very general logical\nspecification of how belief should change after acting and sensing in complex\nnoisy domains.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 09:09:04 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Belle", "Vaishak", ""], ["Levesque", "Hector J.", ""]]}, {"id": "1809.05467", "submitter": "Panagiotis Mandros", "authors": "Panagiotis Mandros, Mario Boley, Jilles Vreeken", "title": "Discovering Reliable Dependencies from Data: Hardness and Improved\n  Algorithms", "comments": "Accepted to Proceedings of the IEEE International Conference on Data\n  Mining (ICDM'18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reliable fraction of information is an attractive score for quantifying\n(functional) dependencies in high-dimensional data. In this paper, we\nsystematically explore the algorithmic implications of using this measure for\noptimization. We show that the problem is NP-hard, which justifies the usage of\nworst-case exponential-time as well as heuristic search methods. We then\nsubstantially improve the practical performance for both optimization styles by\nderiving a novel admissible bounding function that has an unbounded potential\nfor additional pruning over the previously proposed one. Finally, we\nempirically investigate the approximation ratio of the greedy algorithm and\nshow that it produces highly competitive results in a fraction of time needed\nfor complete branch-and-bound style search.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 15:33:06 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Mandros", "Panagiotis", ""], ["Boley", "Mario", ""], ["Vreeken", "Jilles", ""]]}, {"id": "1809.05485", "submitter": "Pavel Naumov", "authors": "Pavel Naumov and Jia Tao", "title": "Blameworthiness in Strategic Games", "comments": null, "journal-ref": "33rd AAAI Conference on Artificial Intelligence (AAAI-19), January\n  27-February 1, 2019, Honolulu, Hawaii, USA", "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LO cs.MA math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are multiple notions of coalitional responsibility. The focus of this\npaper is on the blameworthiness defined through the principle of alternative\npossibilities: a coalition is blamable for a statement if the statement is\ntrue, but the coalition had a strategy to prevent it. The main technical result\nis a sound and complete bimodal logical system that describes properties of\nblameworthiness in one-shot games.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 16:09:50 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Naumov", "Pavel", ""], ["Tao", "Jia", ""]]}, {"id": "1809.05502", "submitter": "Eunjeong Koh", "authors": "Eunjeong Stella Koh and Shahrokh Yadegari", "title": "Mugeetion: Musical Interface Using Facial Gesture and Emotion", "comments": "4 pages, accepted to ICMC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  People feel emotions when listening to music. However, emotions are not\ntangible objects that can be exploited in the music composition process as they\nare difficult to capture and quantify in algorithms. We present a novel musical\ninterface, Mugeetion, designed to capture occurring instances of emotional\nstates from users' facial gestures and relay that data to associated musical\nfeatures. Mugeetion can translate qualitative data of emotional states into\nquantitative data, which can be utilized in the sound generation process. We\nalso presented and tested this work in the exhibition of sound installation,\nHearing Seascape, using the audiences' facial expressions. Audiences heard\nchanges in the background sound based on their emotional state. The process\ncontributes multiple research areas, such as gesture tracking systems,\nemotion-sound modeling, and the connection between sound and facial gesture.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 16:52:47 GMT"}, {"version": "v2", "created": "Sun, 7 Oct 2018 23:34:51 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Koh", "Eunjeong Stella", ""], ["Yadegari", "Shahrokh", ""]]}, {"id": "1809.05504", "submitter": "Bryan Wilder", "authors": "Bryan Wilder, Bistra Dilkina, Milind Tambe", "title": "Melding the Data-Decisions Pipeline: Decision-Focused Learning for\n  Combinatorial Optimization", "comments": "Full version of paper accepted at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating impact in real-world settings requires artificial intelligence\ntechniques to span the full pipeline from data, to predictive models, to\ndecisions. These components are typically approached separately: a machine\nlearning model is first trained via a measure of predictive accuracy, and then\nits predictions are used as input into an optimization algorithm which produces\na decision. However, the loss function used to train the model may easily be\nmisaligned with the end goal, which is to make the best decisions possible.\nHand-tuning the loss function to align with optimization is a difficult and\nerror-prone process (which is often skipped entirely).\n  We focus on combinatorial optimization problems and introduce a general\nframework for decision-focused learning, where the machine learning model is\ndirectly trained in conjunction with the optimization algorithm to produce\nhigh-quality decisions. Technically, our contribution is a means of integrating\ncommon classes of discrete optimization problems into deep learning or other\npredictive models, which are typically trained via gradient descent. The main\nidea is to use a continuous relaxation of the discrete problem to propagate\ngradients through the optimization procedure. We instantiate this framework for\ntwo broad classes of combinatorial problems: linear programs and submodular\nmaximization. Experimental results across a variety of domains show that\ndecision-focused learning often leads to improved optimization performance\ncompared to traditional methods. We find that standard measures of accuracy are\nnot a reliable proxy for a predictive model's utility in optimization, and our\nmethod's ability to specify the true goal as the model's training objective\nyields substantial dividends across a range of decision problems.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 17:08:04 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 00:14:56 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Wilder", "Bryan", ""], ["Dilkina", "Bistra", ""], ["Tambe", "Milind", ""]]}, {"id": "1809.05522", "submitter": "Tong Wu", "authors": "Tong Wu and Wenfeng Zhao and Edward Keefer and Zhi Yang", "title": "Deep Compressive Autoencoder for Action Potential Compression in\n  Large-Scale Neural Recording", "comments": "19 pages, 13 figures", "journal-ref": null, "doi": "10.1088/1741-2552/aae18d", "report-no": null, "categories": "cs.NE cs.AI q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the coordinated activity underlying brain computations requires\nlarge-scale, simultaneous recordings from distributed neuronal structures at a\ncellular-level resolution. One major hurdle to design high-bandwidth,\nhigh-precision, large-scale neural interfaces lies in the formidable data\nstreams that are generated by the recorder chip and need to be online\ntransferred to a remote computer. The data rates can require hundreds to\nthousands of I/O pads on the recorder chip and power consumption on the order\nof Watts for data streaming alone. We developed a deep learning-based\ncompression model to reduce the data rate of multichannel action potentials.\nThe proposed model is built upon a deep compressive autoencoder (CAE) with\ndiscrete latent embeddings. The encoder is equipped with residual\ntransformations to extract representative features from spikes, which are\nmapped into the latent embedding space and updated via vector quantization\n(VQ). The decoder network reconstructs spike waveforms from the quantized\nlatent embeddings. Experimental results show that the proposed model\nconsistently outperforms conventional methods by achieving much higher\ncompression ratios (20-500x) and better or comparable reconstruction\naccuracies. Testing results also indicate that CAE is robust against a diverse\nrange of imperfections, such as waveform variation and spike misalignment, and\nhas minor influence on spike sorting accuracy. Furthermore, we have estimated\nthe hardware cost and real-time performance of CAE and shown that it could\nsupport thousands of recording channels simultaneously without excessive\npower/heat dissipation. The proposed model can reduce the required data\ntransmission bandwidth in large-scale recording experiments and maintain good\nsignal qualities. The code of this work has been made available at\nhttps://github.com/tong-wu-umn/spike-compression-autoencoder\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 17:48:23 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 00:25:48 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Wu", "Tong", ""], ["Zhao", "Wenfeng", ""], ["Keefer", "Edward", ""], ["Yang", "Zhi", ""]]}, {"id": "1809.05524", "submitter": "Prasanna Parthasarathi", "authors": "Prasanna Parthasarathi and Joelle Pineau", "title": "Extending Neural Generative Conversational Model using External\n  Knowledge Sources", "comments": "Accepted in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of connectionist approaches in conversational agents has been\nprogressing rapidly due to the availability of large corpora. However current\ngenerative dialogue models often lack coherence and are content poor. This work\nproposes an architecture to incorporate unstructured knowledge sources to\nenhance the next utterance prediction in chit-chat type of generative dialogue\nmodels. We focus on Sequence-to-Sequence (Seq2Seq) conversational agents\ntrained with the Reddit News dataset, and consider incorporating external\nknowledge from Wikipedia summaries as well as from the NELL knowledge base. Our\nexperiments show faster training time and improved perplexity when leveraging\nexternal knowledge.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 17:53:53 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Parthasarathi", "Prasanna", ""], ["Pineau", "Joelle", ""]]}, {"id": "1809.05650", "submitter": "Stephen Pauwels", "authors": "Stephen Pauwels, Toon Calders", "title": "Detecting and Explaining Drifts in Yearly Grant Applications", "comments": "BPI Challenge 2018 - Academic Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the lifetime of a Business Process changes can be made to the\nworkflow, the required resources, required documents, . . . . Different traces\nfrom the same Business Process within a single log file can thus differ\nsubstantially due to these changes. We propose a method that is able to detect\nconcept drift in multivariate log files with a dozen attributes. We test our\napproach on the BPI Challenge 2018 data con- sisting of applications for EU\ndirect payment from farmers in Germany where we use it to detect Concept Drift.\nIn contrast to other methods our algorithm does not require the manual\nselection of the features used to detect drift. Our method first creates a\nmodel that captures the re- lations between attributes and between events of\ndifferent time steps. This model is then used to score every event and trace.\nThese scores can be used to detect outlying cases and concept drift. Thanks to\nthe decomposability of the score we are able to perform detailed root-cause\nanalysis.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 05:06:25 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 08:14:12 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Pauwels", "Stephen", ""], ["Calders", "Toon", ""]]}, {"id": "1809.05676", "submitter": "Prabhat Nagarajan", "authors": "Prabhat Nagarajan, Garrett Warnell, Peter Stone", "title": "Deterministic Implementations for Reproducibility in Deep Reinforcement\n  Learning", "comments": "17 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep reinforcement learning (DRL) has led to numerous successes in\nrecent years, reproducing these successes can be extremely challenging. One\nreproducibility challenge particularly relevant to DRL is nondeterminism in the\ntraining process, which can substantially affect the results. Motivated by this\nchallenge, we study the positive impacts of deterministic implementations in\neliminating nondeterminism in training. To do so, we consider the particular\ncase of the deep Q-learning algorithm, for which we produce a deterministic\nimplementation by identifying and controlling all sources of nondeterminism in\nthe training process. One by one, we then allow individual sources of\nnondeterminism to affect our otherwise deterministic implementation, and\nmeasure the impact of each source on the variance in performance. We find that\nindividual sources of nondeterminism can substantially impact the performance\nof agent, illustrating the benefits of deterministic implementations. In\naddition, we also discuss the important role of deterministic implementations\nin achieving exact replicability of results.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 08:53:28 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 11:13:05 GMT"}, {"version": "v3", "created": "Mon, 31 Dec 2018 04:39:18 GMT"}, {"version": "v4", "created": "Tue, 8 Jan 2019 15:55:22 GMT"}, {"version": "v5", "created": "Sun, 9 Jun 2019 12:56:34 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Nagarajan", "Prabhat", ""], ["Warnell", "Garrett", ""], ["Stone", "Peter", ""]]}, {"id": "1809.05679", "submitter": "Liang Yao", "authors": "Liang Yao, Chengsheng Mao, Yuan Luo", "title": "Graph Convolutional Networks for Text Classification", "comments": "Accepted by 33rd AAAI Conference on Artificial Intelligence (AAAI\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text classification is an important and classical problem in natural language\nprocessing. There have been a number of studies that applied convolutional\nneural networks (convolution on regular grid, e.g., sequence) to\nclassification. However, only a limited number of studies have explored the\nmore flexible graph convolutional neural networks (convolution on non-grid,\ne.g., arbitrary graph) for the task. In this work, we propose to use graph\nconvolutional networks for text classification. We build a single text graph\nfor a corpus based on word co-occurrence and document word relations, then\nlearn a Text Graph Convolutional Network (Text GCN) for the corpus. Our Text\nGCN is initialized with one-hot representation for word and document, it then\njointly learns the embeddings for both words and documents, as supervised by\nthe known class labels for documents. Our experimental results on multiple\nbenchmark datasets demonstrate that a vanilla Text GCN without any external\nword embeddings or knowledge outperforms state-of-the-art methods for text\nclassification. On the other hand, Text GCN also learns predictive word and\ndocument embeddings. In addition, experimental results show that the\nimprovement of Text GCN over state-of-the-art comparison methods become more\nprominent as we lower the percentage of training data, suggesting the\nrobustness of Text GCN to less training data in text classification.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 09:13:12 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2018 10:06:08 GMT"}, {"version": "v3", "created": "Tue, 13 Nov 2018 05:23:40 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Yao", "Liang", ""], ["Mao", "Chengsheng", ""], ["Luo", "Yuan", ""]]}, {"id": "1809.05714", "submitter": "Philipp Ennen", "authors": "Philipp Ennen, Pia Bresenitz, Rene Vossen, Frank Hees", "title": "Learning Robust Manipulation Skills with Guided Policy Search via\n  Generative Motor Reflexes", "comments": "IEEE International Conference on Robotics and Automation (ICRA) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Guided Policy Search enables robots to learn control policies for complex\nmanipulation tasks efficiently. Therein, the control policies are represented\nas high-dimensional neural networks which derive robot actions based on states.\nHowever, due to the small number of real-world trajectory samples in Guided\nPolicy Search, the resulting neural networks are only robust in the\nneighbourhood of the trajectory distribution explored by real-world\ninteractions. In this paper, we present a new policy representation called\nGenerative Motor Reflexes, which is able to generate robust actions over a\nbroader state space compared to previous methods. In contrast to prior\nstate-action policies, Generative Motor Reflexes map states to parameters for a\nstate-dependent motor reflex, which is then used to derive actions. Robustness\nis achieved by generating similar motor reflexes for many states. We evaluate\nthe presented method in simulated and real-world manipulation tasks, including\ncontact-rich peg-in-hole tasks. Using these evaluation tasks, we show that\npolicies represented as Generative Motor Reflexes lead to robust manipulation\nskills also outside the explored trajectory distribution with less training\nneeds compared to previous methods.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 13:24:17 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 13:36:02 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Ennen", "Philipp", ""], ["Bresenitz", "Pia", ""], ["Vossen", "Rene", ""], ["Hees", "Frank", ""]]}, {"id": "1809.05717", "submitter": "Thuong Nguyen Canh", "authors": "Thuong Nguyen Canh and Byeungwoo Jeon", "title": "Multi-Scale Deep Compressive Sensing Network", "comments": "4 pages, 4 figures, 2 tables, IEEE International Conference on Visual\n  Communication and Image Processing (VCIP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With joint learning of sampling and recovery, the deep learning-based\ncompressive sensing (DCS) has shown significant improvement in performance and\nrunning time reduction. Its reconstructed image, however, losses high-frequency\ncontent especially at low subrates. This happens similarly in the multi-scale\nsampling scheme which also samples more low-frequency components. In this\npaper, we propose a multi-scale DCS convolutional neural network (MS-DCSNet) in\nwhich we convert image signal using multiple scale-based wavelet transform,\nthen capture it through convolution block by block across scales. The initial\nreconstructed image is directly recovered from multi-scale measurements.\nMulti-scale wavelet convolution is utilized to enhance the final reconstruction\nquality. The network is able to learn both multi-scale sampling and multi-scale\nreconstruction, thus results in better reconstruction quality.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 14:05:27 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 10:51:07 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Canh", "Thuong Nguyen", ""], ["Jeon", "Byeungwoo", ""]]}, {"id": "1809.05720", "submitter": "Nicholas Mattei", "authors": "Avinash Balakrishnan, Djallel Bouneffouf, Nicholas Mattei, Francesca\n  Rossi", "title": "Incorporating Behavioral Constraints in Online AI Systems", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI systems that learn through reward feedback about the actions they take are\nincreasingly deployed in domains that have significant impact on our daily\nlife. However, in many cases the online rewards should not be the only guiding\ncriteria, as there are additional constraints and/or priorities imposed by\nregulations, values, preferences, or ethical principles. We detail a novel\nonline agent that learns a set of behavioral constraints by observation and\nuses these learned constraints as a guide when making decisions in an online\nsetting while still being reactive to reward feedback. To define this agent, we\npropose to adopt a novel extension to the classical contextual multi-armed\nbandit setting and we provide a new algorithm called Behavior Constrained\nThompson Sampling (BCTS) that allows for online learning while obeying\nexogenous constraints. Our agent learns a constrained policy that implements\nthe observed behavioral constraints demonstrated by a teacher agent, and then\nuses this constrained policy to guide the reward-based online exploration and\nexploitation. We characterize the upper bound on the expected regret of the\ncontextual bandit algorithm that underlies our agent and provide a case study\nwith real world data in two application domains. Our experiments show that the\ndesigned agent is able to act within the set of behavior constraints without\nsignificantly degrading its overall reward performance.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 14:24:37 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Balakrishnan", "Avinash", ""], ["Bouneffouf", "Djallel", ""], ["Mattei", "Nicholas", ""], ["Rossi", "Francesca", ""]]}, {"id": "1809.05724", "submitter": "Pavan Kapanipathi", "authors": "Xiaoyan Wang, Pavan Kapanipathi, Ryan Musa, Mo Yu, Kartik\n  Talamadupula, Ibrahim Abdelaziz, Maria Chang, Achille Fokoue, Bassem Makni,\n  Nicholas Mattei, Michael Witbrock", "title": "Improving Natural Language Inference Using External Knowledge in the\n  Science Questions Domain", "comments": "9 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural Language Inference (NLI) is fundamental to many Natural Language\nProcessing (NLP) applications including semantic search and question answering.\nThe NLI problem has gained significant attention thanks to the release of large\nscale, challenging datasets. Present approaches to the problem largely focus on\nlearning-based methods that use only textual information in order to classify\nwhether a given premise entails, contradicts, or is neutral with respect to a\ngiven hypothesis. Surprisingly, the use of methods based on structured\nknowledge -- a central topic in artificial intelligence -- has not received\nmuch attention vis-a-vis the NLI problem. While there are many open knowledge\nbases that contain various types of reasoning information, their use for NLI\nhas not been well explored. To address this, we present a combination of\ntechniques that harness knowledge graphs to improve performance on the NLI\nproblem in the science questions domain. We present the results of applying our\ntechniques on text, graph, and text-to-graph based models, and discuss\nimplications for the use of external knowledge in solving the NLI problem. Our\nmodel achieves the new state-of-the-art performance on the NLI problem over the\nSciTail science questions dataset.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 14:37:46 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 15:50:33 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Wang", "Xiaoyan", ""], ["Kapanipathi", "Pavan", ""], ["Musa", "Ryan", ""], ["Yu", "Mo", ""], ["Talamadupula", "Kartik", ""], ["Abdelaziz", "Ibrahim", ""], ["Chang", "Maria", ""], ["Fokoue", "Achille", ""], ["Makni", "Bassem", ""], ["Mattei", "Nicholas", ""], ["Witbrock", "Michael", ""]]}, {"id": "1809.05726", "submitter": "Nicholas Mattei", "authors": "Ryan Musa, Xiaoyan Wang, Achille Fokoue, Nicholas Mattei, Maria Chang,\n  Pavan Kapanipathi, Bassem Makni, Kartik Talamadupula, Michael Witbrock", "title": "Answering Science Exam Questions Using Query Rewriting with Background\n  Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-domain question answering (QA) is an important problem in AI and NLP\nthat is emerging as a bellwether for progress on the generalizability of AI\nmethods and techniques. Much of the progress in open-domain QA systems has been\nrealized through advances in information retrieval methods and corpus\nconstruction. In this paper, we focus on the recently introduced ARC Challenge\ndataset, which contains 2,590 multiple choice questions authored for\ngrade-school science exams. These questions are selected to be the most\nchallenging for current QA systems, and current state of the art performance is\nonly slightly better than random chance. We present a system that rewrites a\ngiven question into queries that are used to retrieve supporting text from a\nlarge corpus of science-related text. Our rewriter is able to incorporate\nbackground knowledge from ConceptNet and -- in tandem with a generic textual\nentailment system trained on SciTail that identifies support in the retrieved\nresults -- outperforms several strong baselines on the end-to-end QA task\ndespite only being trained to identify essential terms in the original source\nquestion. We use a generalizable decision methodology over the retrieved\nevidence and answer candidates to select the best answer. By combining query\nrewriting, background knowledge, and textual entailment our system is able to\noutperform several strong baselines on the ARC dataset.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 14:49:23 GMT"}, {"version": "v2", "created": "Sat, 6 Apr 2019 02:03:14 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Musa", "Ryan", ""], ["Wang", "Xiaoyan", ""], ["Fokoue", "Achille", ""], ["Mattei", "Nicholas", ""], ["Chang", "Maria", ""], ["Kapanipathi", "Pavan", ""], ["Makni", "Bassem", ""], ["Talamadupula", "Kartik", ""], ["Witbrock", "Michael", ""]]}, {"id": "1809.05762", "submitter": "John Kingston", "authors": "John KC Kingston", "title": "Using Artificial Intelligence to Support Compliance with the General\n  Data Protection Regulation", "comments": null, "journal-ref": "Artificial Intelligence and Law (2017) 25, 429 - 443", "doi": "10.1007/s10506-017-9206-9", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The General Data Protection Regulation (GDPR) is a European Union regulation\nthat will replace the existing Data Protection Directive on 25 May 2018. The\nmost significant change is a huge increase in the maximum fine that can be\nlevied for breaches of the regulation. Yet fewer than half of UK companies are\nfully aware of GDPR - and a number of those who were preparing for it stopped\ndoing so when the Brexit vote was announced. A last-minute rush to become\ncompliant is therefore expected, and numerous companies are starting to offer\nadvice, checklists and consultancy on how to comply with GDPR. In such an\nenvironment, artificial intelligence technologies ought to be able to assist by\nproviding best advice; asking all and only the relevant questions; monitoring\nactivities; and carrying out assessments. The paper considers four areas of\nGDPR compliance where rule based technologies and/or machine learning\ntechniques may be relevant: * Following compliance checklists and codes of\nconduct; * Supporting risk assessments; * Complying with the new regulations\nregarding technologies that perform automatic profiling; * Complying with the\nnew regulations concerning recognising and reporting breaches of security. It\nconcludes that AI technology can support each of these four areas. The\nrequirements that GDPR (or organisations that need to comply with GDPR) state\nfor explanation and justification of reasoning imply that rule-based approaches\nare likely to be more helpful than machine learning approaches. However, there\nmay be good business reasons to take a different approach in some\ncircumstances.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 19:57:02 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Kingston", "John KC", ""]]}, {"id": "1809.05763", "submitter": "Anton Wiehe", "authors": "Anton Orell Wiehe, Nil Stolt Ans\\'o, Madalina M. Drugan, Marco A.\n  Wiering", "title": "Sampled Policy Gradient for Learning to Play the Game Agar.io", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, a new offline actor-critic learning algorithm is introduced:\nSampled Policy Gradient (SPG). SPG samples in the action space to calculate an\napproximated policy gradient by using the critic to evaluate the samples. This\nsampling allows SPG to search the action-Q-value space more globally than\ndeterministic policy gradient (DPG), enabling it to theoretically avoid more\nlocal optima. SPG is compared to Q-learning and the actor-critic algorithms\nCACLA and DPG in a pellet collection task and a self play environment in the\ngame Agar.io. The online game Agar.io has become massively popular on the\ninternet due to intuitive game design and the ability to instantly compete\nagainst players around the world. From the point of view of artificial\nintelligence this game is also very intriguing: The game has a continuous input\nand action space and allows to have diverse agents with complex strategies\ncompete against each other. The experimental results show that Q-Learning and\nCACLA outperform a pre-programmed greedy bot in the pellet collection task, but\nall algorithms fail to outperform this bot in a fighting scenario. The SPG\nalgorithm is analyzed to have great extendability through offline exploration\nand it matches DPG in performance even in its basic form without extensive\nsampling.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 20:01:06 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Wiehe", "Anton Orell", ""], ["Ans\u00f3", "Nil Stolt", ""], ["Drugan", "Madalina M.", ""], ["Wiering", "Marco A.", ""]]}, {"id": "1809.05807", "submitter": "Mingyu Ma", "authors": "Yunfei Long, Mingyu Ma, Qin Lu, Rong Xiang and Chu-Ren Huang", "title": "Dual Memory Network Model for Biased Product Review Classification", "comments": "To appear in 2018 EMNLP 9th Workshop on Computational Approaches to\n  Subjectivity, Sentiment and Social Media Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In sentiment analysis (SA) of product reviews, both user and product\ninformation are proven to be useful. Current tasks handle user profile and\nproduct information in a unified model which may not be able to learn salient\nfeatures of users and products effectively. In this work, we propose a dual\nuser and product memory network (DUPMN) model to learn user profiles and\nproduct reviews using separate memory networks. Then, the two representations\nare used jointly for sentiment prediction. The use of separate models aims to\ncapture user profiles and product information more effectively. Compared to\nstate-of-the-art unified prediction models, the evaluations on three benchmark\ndatasets, IMDB, Yelp13, and Yelp14, show that our dual learning model gives\nperformance gain of 0.6%, 1.2%, and 0.9%, respectively. The improvements are\nalso deemed very significant measured by p-values.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 03:56:21 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Long", "Yunfei", ""], ["Ma", "Mingyu", ""], ["Lu", "Qin", ""], ["Xiang", "Rong", ""], ["Huang", "Chu-Ren", ""]]}, {"id": "1809.05870", "submitter": "Jakub Mare\\v{c}ek", "authors": "Mark Kozdoba, Jakub Marecek, Tigran Tchrakian, and Shie Mannor", "title": "On-Line Learning of Linear Dynamical Systems: Exponential Forgetting in\n  Kalman Filters", "comments": null, "journal-ref": "Proceedings of the Thirty-Third AAAI Conference on Artificial\n  Intelligence, 2019. Pages: 4098-4105", "doi": "10.1609/aaai.v33i01.33014098", "report-no": null, "categories": "math.ST cs.AI cs.LG math.OC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kalman filter is a key tool for time-series forecasting and analysis. We show\nthat the dependence of a prediction of Kalman filter on the past is decaying\nexponentially, whenever the process noise is non-degenerate. Therefore, Kalman\nfilter may be approximated by regression on a few recent observations.\nSurprisingly, we also show that having some process noise is essential for the\nexponential decay. With no process noise, it may happen that the forecast\ndepends on all of the past uniformly, which makes forecasting more difficult.\n  Based on this insight, we devise an on-line algorithm for improper learning\nof a linear dynamical system (LDS), which considers only a few most recent\nobservations. We use our decay results to provide the first regret bounds\nw.r.t. to Kalman filters within learning an LDS. That is, we compare the\nresults of our algorithm to the best, in hindsight, Kalman filter for a given\nsignal. Also, the algorithm is practical: its per-update run-time is linear in\nthe regression depth.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 13:21:49 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Kozdoba", "Mark", ""], ["Marecek", "Jakub", ""], ["Tchrakian", "Tigran", ""], ["Mannor", "Shie", ""]]}, {"id": "1809.05884", "submitter": "Yongcheng Liu", "authors": "Yongcheng Liu, Lu Sheng, Jing Shao, Junjie Yan, Shiming Xiang and\n  Chunhong Pan", "title": "Multi-Label Image Classification via Knowledge Distillation from\n  Weakly-Supervised Detection", "comments": "accepted by ACM Multimedia 2018, 9 pages, 4 figures, 5 tables", "journal-ref": null, "doi": "10.1145/3240508.3240567", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label image classification is a fundamental but challenging task\ntowards general visual understanding. Existing methods found the region-level\ncues (e.g., features from RoIs) can facilitate multi-label classification.\nNevertheless, such methods usually require laborious object-level annotations\n(i.e., object labels and bounding boxes) for effective learning of the\nobject-level visual features. In this paper, we propose a novel and efficient\ndeep framework to boost multi-label classification by distilling knowledge from\nweakly-supervised detection task without bounding box annotations.\nSpecifically, given the image-level annotations, (1) we first develop a\nweakly-supervised detection (WSD) model, and then (2) construct an end-to-end\nmulti-label image classification framework augmented by a knowledge\ndistillation module that guides the classification model by the WSD model\naccording to the class-level predictions for the whole image and the\nobject-level visual features for object RoIs. The WSD model is the teacher\nmodel and the classification model is the student model. After this cross-task\nknowledge distillation, the performance of the classification model is\nsignificantly improved and the efficiency is maintained since the WSD model can\nbe safely discarded in the test phase. Extensive experiments on two large-scale\ndatasets (MS-COCO and NUS-WIDE) show that our framework achieves superior\nperformances over the state-of-the-art methods on both performance and\nefficiency.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 14:35:03 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 12:28:58 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Liu", "Yongcheng", ""], ["Sheng", "Lu", ""], ["Shao", "Jing", ""], ["Yan", "Junjie", ""], ["Xiang", "Shiming", ""], ["Pan", "Chunhong", ""]]}, {"id": "1809.05888", "submitter": "Sanjay Sahay", "authors": "Mohit Sewak, Sanjay K. Sahay and Hemant Rathore", "title": "An investigation of a deep learning based malware detection system", "comments": "13 Pages, 4 figures", "journal-ref": "ACM, pp. 26, Proceedings of the 13th International Conference on\n  Availability, Reliability and Security (ARES), 27-30 Aug., 2018, University\n  of Hamburg, Germany", "doi": "10.1145/3230833.3230835", "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a Deep Learning based system for malware detection. In the\ninvestigation, we experiment with different combination of Deep Learning\narchitectures including Auto-Encoders, and Deep Neural Networks with varying\nlayers over Malicia malware dataset on which earlier studies have obtained an\naccuracy of (98%) with an acceptable False Positive Rates (1.07%). But these\nresults were done using extensive man-made custom domain features and investing\ncorresponding feature engineering and design efforts. In our proposed approach,\nbesides improving the previous best results (99.21% accuracy and a False\nPositive Rate of 0.19%) indicates that Deep Learning based systems could\ndeliver an effective defense against malware. Since it is good in automatically\nextracting higher conceptual features from the data, Deep Learning based\nsystems could provide an effective, general and scalable mechanism for\ndetection of existing and unknown malware.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 14:39:28 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Sewak", "Mohit", ""], ["Sahay", "Sanjay K.", ""], ["Rathore", "Hemant", ""]]}, {"id": "1809.05889", "submitter": "Sanjay Sahay", "authors": "Mohit Sewak, Sanjay K. Sahay and Hemant Rathore", "title": "Comparison of Deep Learning and the Classical Machine Learning Algorithm\n  for the Malware Detection", "comments": "11 Pages, 1 figure", "journal-ref": "IEEE, pp. 293-296, 19th IEEE/ACIS International Conference on\n  Software Engineering, Artificial Intelligence, Networking and\n  Parallel/Distributed Computing (SNPD), 2018", "doi": "10.1109/SNPD.2018.8441123", "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Deep Learning has been showing promising results in various\nArtificial Intelligence applications like image recognition, natural language\nprocessing, language modeling, neural machine translation, etc. Although, in\ngeneral, it is computationally more expensive as compared to classical machine\nlearning techniques, their results are found to be more effective in some\ncases. Therefore, in this paper, we investigated and compared one of the Deep\nLearning Architecture called Deep Neural Network (DNN) with the classical\nRandom Forest (RF) machine learning algorithm for the malware classification.\nWe studied the performance of the classical RF and DNN with 2, 4 & 7 layers\narchitectures with the four different feature sets, and found that irrespective\nof the features inputs, the classical RF accuracy outperforms the DNN.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 14:40:16 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Sewak", "Mohit", ""], ["Sahay", "Sanjay K.", ""], ["Rathore", "Hemant", ""]]}, {"id": "1809.05890", "submitter": "Adeyinka K. Akanbi MR", "authors": "A. K. Akanbi and M. Masinde", "title": "Semantic Interoperability Middleware Architecture for Heterogeneous\n  Environmental Data Sources", "comments": "10 pages, 6 figures, IST Africa 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data heterogeneity hampers the effort to integrate and infer knowledge from\nvast heterogeneous data sources. An application case study is described, in\nwhich the objective was to semantically represent and integrate structured data\nfrom sensor devices with unstructured data in the form of local indigenous\nknowledge. However, the semantic representation of these heterogeneous data\nsources for environmental monitoring systems is not well supported yet. To\ncombat the incompatibility issues, a dedicated semantic middleware solution is\nrequired. In this paper, we describe and evaluate a cross-domain middleware\narchitecture that semantically integrates and generate inference from\nheterogeneous data sources. These use of semantic technology for predicting and\nforecasting complex environmental phenomenon will increase the degree of\naccuracy of environmental monitoring systems.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 14:48:45 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Akanbi", "A. K.", ""], ["Masinde", "M.", ""]]}, {"id": "1809.05897", "submitter": "Sebastian Gottwald", "authors": "Sebastian Gottwald, Daniel A. Braun", "title": "Systems of bounded rational agents with information-theoretic\n  constraints", "comments": "35 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Specialization and hierarchical organization are important features of\nefficient collaboration in economical, artificial, and biological systems.\nHere, we investigate the hypothesis that both features can be explained by the\nfact that each entity of such a system is limited in a certain way. We propose\nan information-theoretic approach based on a Free Energy principle, in order to\ncomputationally analyze systems of bounded rational agents that deal with such\nlimitations optimally. We find that specialization allows to focus on fewer\ntasks, thus leading to a more efficient execution, but in turn requires\ncoordination in hierarchical structures of specialized experts and coordinating\nunits. Our results suggest that hierarchical architectures of specialized units\nat lower levels that are coordinated by units at higher levels are optimal,\ngiven that each unit's information-processing capability is limited and\nconforms to constraints on complexity costs.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 15:43:11 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Gottwald", "Sebastian", ""], ["Braun", "Daniel A.", ""]]}, {"id": "1809.05904", "submitter": "Jason R.C. Nurse Dr", "authors": "Aastha Madaan and Jason R.C. Nurse and David De Roure and Kieron\n  O'Hara and Wendy Hall and Sadie Creese", "title": "A Storm in an IoT Cup: The Emergence of Cyber-Physical Social Machines", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": "SSRN-3250383", "categories": "cs.CY cs.AI cs.HC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of social machines is increasingly being used to characterise\nvarious socio-cognitive spaces on the Web. Social machines are human\ncollectives using networked digital technology which initiate real-world\nprocesses and activities including human communication, interactions and\nknowledge creation. As such, they continuously emerge and fade on the Web. The\nrelationship between humans and machines is made more complex by the adoption\nof Internet of Things (IoT) sensors and devices. The scale, automation,\ncontinuous sensing, and actuation capabilities of these devices add an extra\ndimension to the relationship between humans and machines making it difficult\nto understand their evolution at either the systemic or the conceptual level.\nThis article describes these new socio-technical systems, which we term\nCyber-Physical Social Machines, through different exemplars, and considers the\nassociated challenges of security and privacy.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 16:00:02 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 14:47:47 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Madaan", "Aastha", ""], ["Nurse", "Jason R. C.", ""], ["De Roure", "David", ""], ["O'Hara", "Kieron", ""], ["Hall", "Wendy", ""], ["Creese", "Sadie", ""]]}, {"id": "1809.05922", "submitter": "Tyler Hayes", "authors": "Tyler L. Hayes, Nathan D. Cahill, Christopher Kanan", "title": "Memory Efficient Experience Replay for Streaming Learning", "comments": "To appear in the IEEE International Conference on Robotics and\n  Automation (ICRA) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In supervised machine learning, an agent is typically trained once and then\ndeployed. While this works well for static settings, robots often operate in\nchanging environments and must quickly learn new things from data streams. In\nthis paradigm, known as streaming learning, a learner is trained online, in a\nsingle pass, from a data stream that cannot be assumed to be independent and\nidentically distributed (iid). Streaming learning will cause conventional deep\nneural networks (DNNs) to fail for two reasons: 1) they need multiple passes\nthrough the entire dataset; and 2) non-iid data will cause catastrophic\nforgetting. An old fix to both of these issues is rehearsal. To learn a new\nexample, rehearsal mixes it with previous examples, and then this mixture is\nused to update the DNN. Full rehearsal is slow and memory intensive because it\nstores all previously observed examples, and its effectiveness for preventing\ncatastrophic forgetting has not been studied in modern DNNs. Here, we describe\nthe ExStream algorithm for memory efficient rehearsal and compare it to\nalternatives. We find that full rehearsal can eliminate catastrophic forgetting\nin a variety of streaming learning settings, with ExStream performing well\nusing far less memory and computation.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 18:04:33 GMT"}, {"version": "v2", "created": "Sat, 23 Feb 2019 23:32:51 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Hayes", "Tyler L.", ""], ["Cahill", "Nathan D.", ""], ["Kanan", "Christopher", ""]]}, {"id": "1809.05951", "submitter": "Emanuel Sallinger", "authors": "Gerald Berger, Georg Gottlob, Andreas Pieris, Emanuel Sallinger", "title": "The Space-Efficient Core of Vadalog", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vadalog is a system for performing complex reasoning tasks such as those\nrequired in advanced knowledge graphs. The logical core of the underlying\nVadalog language is the warded fragment of tuple-generating dependencies\n(TGDs). This formalism ensures tractable reasoning in data complexity, while a\nrecent analysis focusing on a practical implementation led to the reasoning\nalgorithm around which the Vadalog system is built. A fundamental question that\nhas emerged in the context of Vadalog is the following: can we limit the\nrecursion allowed by wardedness in order to obtain a formalism that provides a\nconvenient syntax for expressing useful recursive statements, and at the same\ntime achieves space-efficiency? After analyzing several real-life examples of\nwarded sets of TGDs provided by our industrial partners, as well as recent\nbenchmarks, we observed that recursion is often used in a restricted way: the\nbody of a TGD contains at most one atom whose predicate is mutually recursive\nwith a predicate in the head. We show that this type of recursion, known as\npiece-wise linear in the Datalog literature, is the answer to our main\nquestion. We further show that piece-wise linear recursion alone, without the\nwardedness condition, is not enough as it leads to the undecidability of\nreasoning. We finally study the relative expressiveness of the query languages\nbased on (piece-wise linear) warded sets of TGDs.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 20:33:45 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Berger", "Gerald", ""], ["Gottlob", "Georg", ""], ["Pieris", "Andreas", ""], ["Sallinger", "Emanuel", ""]]}, {"id": "1809.05959", "submitter": "Pavel Surynek", "authors": "Pavel Surynek", "title": "Lazy Modeling of Variants of Token Swapping Problem and Multi-agent Path\n  Finding through Combination of Satisfiability Modulo Theories and\n  Conflict-based Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address item relocation problems in graphs in this paper. We assume items\nplaced in vertices of an undirected graph with at most one item per vertex.\nItems can be moved across edges while various constraints depending on the type\nof relocation problem must be satisfied. We introduce a general problem\nformulation that encompasses known types of item relocation problems such as\nmulti-agent path finding (MAPF) and token swapping (TSWAP). In this formulation\nwe express two new types of relocation problems derived from token swapping\nthat we call token rotation (TROT) and token permutation (TPERM). Our solving\napproach for item relocation combines satisfiability modulo theory (SMT) with\nconflict-based search (CBS). We interpret CBS in the SMT framework where we\nstart with the basic model and refine the model with a collision resolution\nconstraint whenever a collision between items occurs in the current solution.\nThe key difference between the standard CBS and our SMT-based modification of\nCBS (SMT-CBS) is that the standard CBS branches the search to resolve the\ncollision while in SMT-CBS we iteratively add a single disjunctive collision\nresolution constraint. Experimental evaluation on several benchmarks shows that\nthe SMT-CBS algorithm significantly outperforms the standard CBS. We also\ncompared SMT-CBS with a modification of the SAT-based MDD-SAT solver that uses\nan eager modeling of item relocation in which all potential collisions are\neliminated by constrains in advance. Experiments show that lazy approach in\nSMT-CBS produce fewer constraint than MDD-SAT and also achieves faster solving\nrun-times.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 21:19:35 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Surynek", "Pavel", ""]]}, {"id": "1809.05972", "submitter": "Yizhe Zhang", "authors": "Yizhe Zhang, Michel Galley, Jianfeng Gao, Zhe Gan, Xiujun Li, Chris\n  Brockett, Bill Dolan", "title": "Generating Informative and Diverse Conversational Responses via\n  Adversarial Information Maximization", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Responses generated by neural conversational models tend to lack\ninformativeness and diversity. We present Adversarial Information Maximization\n(AIM), an adversarial learning strategy that addresses these two related but\ndistinct problems. To foster response diversity, we leverage adversarial\ntraining that allows distributional matching of synthetic and real responses.\nTo improve informativeness, our framework explicitly optimizes a variational\nlower bound on pairwise mutual information between query and response.\nEmpirical results from automatic and human evaluations demonstrate that our\nmethods significantly boost informativeness and diversity.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 22:45:51 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2018 03:01:19 GMT"}, {"version": "v3", "created": "Fri, 26 Oct 2018 21:13:43 GMT"}, {"version": "v4", "created": "Sat, 3 Nov 2018 22:23:24 GMT"}, {"version": "v5", "created": "Tue, 6 Nov 2018 19:53:52 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Zhang", "Yizhe", ""], ["Galley", "Michel", ""], ["Gao", "Jianfeng", ""], ["Gan", "Zhe", ""], ["Li", "Xiujun", ""], ["Brockett", "Chris", ""], ["Dolan", "Bill", ""]]}, {"id": "1809.05989", "submitter": "Alexander Wong", "authors": "Alexander Wong, Mohammad Javad Shafiee, Brendan Chwyl, and Francis Li", "title": "FermiNets: Learning generative machines to generate efficient neural\n  networks via generative synthesis", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tremendous potential exhibited by deep learning is often offset by\narchitectural and computational complexity, making widespread deployment a\nchallenge for edge scenarios such as mobile and other consumer devices. To\ntackle this challenge, we explore the following idea: Can we learn generative\nmachines to automatically generate deep neural networks with efficient network\narchitectures? In this study, we introduce the idea of generative synthesis,\nwhich is premised on the intricate interplay between a generator-inquisitor\npair that work in tandem to garner insights and learn to generate highly\nefficient deep neural networks that best satisfies operational requirements.\nWhat is most interesting is that, once a generator has been learned through\ngenerative synthesis, it can be used to generate not just one but a large\nvariety of different, unique highly efficient deep neural networks that satisfy\noperational requirements. Experimental results for image classification,\nsemantic segmentation, and object detection tasks illustrate the efficacy of\ngenerative synthesis in producing generators that automatically generate highly\nefficient deep neural networks (which we nickname FermiNets) with higher model\nefficiency and lower computational costs (reaching >10x more efficient and\nfewer multiply-accumulate operations than several tested state-of-the-art\nnetworks), as well as higher energy efficiency (reaching >4x improvements in\nimage inferences per joule consumed on a Nvidia Tegra X2 mobile processor). As\nsuch, generative synthesis can be a powerful, generalized approach for\naccelerating and improving the building of deep neural networks for on-device\nedge scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 01:26:57 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 19:14:50 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Wong", "Alexander", ""], ["Shafiee", "Mohammad Javad", ""], ["Chwyl", "Brendan", ""], ["Li", "Francis", ""]]}, {"id": "1809.06004", "submitter": "Hu Xu", "authors": "Hu Xu, Bing Liu, Lei Shu, P. Yu", "title": "Open-world Learning and Application to Product Classification", "comments": "accepted by The Web Conference (WWW 2019) Previous title: Learning to\n  Accept New Classes without Training", "journal-ref": null, "doi": "10.1145/3308558.3313644", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classic supervised learning makes the closed-world assumption, meaning that\nclasses seen in testing must have been seen in training. However, in the\ndynamic world, new or unseen class examples may appear constantly. A model\nworking in such an environment must be able to reject unseen classes (not seen\nor used in training). If enough data is collected for the unseen classes, the\nsystem should incrementally learn to accept/classify them. This learning\nparadigm is called open-world learning (OWL). Existing OWL methods all need\nsome form of re-training to accept or include the new classes in the overall\nmodel. In this paper, we propose a meta-learning approach to the problem. Its\nkey novelty is that it only needs to train a meta-classifier, which can then\ncontinually accept new classes when they have enough labeled data for the\nmeta-classifier to use, and also detect/reject future unseen classes. No\nre-training of the meta-classifier or a new overall classifier covering all old\nand new classes is needed. In testing, the method only uses the examples of the\nseen classes (including the newly added classes) on-the-fly for classification\nand rejection. Experimental results demonstrate the effectiveness of the new\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 03:08:58 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 23:25:46 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Xu", "Hu", ""], ["Liu", "Bing", ""], ["Shu", "Lei", ""], ["Yu", "P.", ""]]}, {"id": "1809.06098", "submitter": "Alberto Maria Metelli", "authors": "Alberto Maria Metelli, Matteo Papini, Francesco Faccio, and Marcello\n  Restelli", "title": "Policy Optimization via Importance Sampling", "comments": null, "journal-ref": "32nd Conference on Neural Information Processing Systems (NIPS\n  2018), Montr\\'eal, Canada", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy optimization is an effective reinforcement learning approach to solve\ncontinuous control tasks. Recent achievements have shown that alternating\nonline and offline optimization is a successful choice for efficient trajectory\nreuse. However, deciding when to stop optimizing and collect new trajectories\nis non-trivial, as it requires to account for the variance of the objective\nfunction estimate. In this paper, we propose a novel, model-free, policy search\nalgorithm, POIS, applicable in both action-based and parameter-based settings.\nWe first derive a high-confidence bound for importance sampling estimation;\nthen we define a surrogate objective function, which is optimized offline\nwhenever a new batch of trajectories is collected. Finally, the algorithm is\ntested on a selection of continuous control tasks, with both linear and deep\npolicies, and compared with state-of-the-art policy optimization methods.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 09:42:26 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 10:47:21 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Metelli", "Alberto Maria", ""], ["Papini", "Matteo", ""], ["Faccio", "Francesco", ""], ["Restelli", "Marcello", ""]]}, {"id": "1809.06180", "submitter": "Riccardo Zese", "authors": "Riccardo Zese, Giuseppe Cota, Evelina Lamma, Elena Bellodi, Fabrizio\n  Riguzzi", "title": "Probabilistic DL Reasoning with Pinpointing Formulas: A Prolog-based\n  Approach", "comments": null, "journal-ref": "Theory and Practice of Logic Programming, 19 (3), 449-476, 2019", "doi": "10.1017/S1471068418000480", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When modeling real world domains we have to deal with information that is\nincomplete or that comes from sources with different trust levels. This\nmotivates the need for managing uncertainty in the Semantic Web. To this\npurpose, we introduced a probabilistic semantics, named DISPONTE, in order to\ncombine description logics with probability theory. The probability of a query\ncan be then computed from the set of its explanations by building a Binary\nDecision Diagram (BDD). The set of explanations can be found using the tableau\nalgorithm, which has to handle non-determinism. Prolog, with its efficient\nhandling of non-determinism, is suitable for implementing the tableau\nalgorithm. TRILL and TRILLP are systems offering a Prolog implementation of the\ntableau algorithm. TRILLP builds a pinpointing formula, that compactly\nrepresents the set of explanations and can be directly translated into a BDD.\nBoth reasoners were shown to outperform state-of-the-art DL reasoners. In this\npaper, we present an improvement of TRILLP, named TORNADO, in which the BDD is\ndirectly built during the construction of the tableau, further speeding up the\noverall inference process. An experimental comparison shows the effectiveness\nof TORNADO. All systems can be tried online in the TRILL on SWISH web\napplication at http://trill.ml.unife.it/.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 13:13:02 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 09:15:01 GMT"}, {"version": "v3", "created": "Mon, 1 Apr 2019 11:44:58 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Zese", "Riccardo", ""], ["Cota", "Giuseppe", ""], ["Lamma", "Evelina", ""], ["Bellodi", "Elena", ""], ["Riguzzi", "Fabrizio", ""]]}, {"id": "1809.06196", "submitter": "Zhuo Chen", "authors": "Zhuo Chen, Weisi Lin, Shiqi Wang, Lingyu Duan, Alex C. Kot", "title": "Intermediate Deep Feature Compression: the Next Battlefield of\n  Intelligent Sensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advances of hardware technology have made the intelligent analysis\nequipped at the front-end with deep learning more prevailing and practical. To\nbetter enable the intelligent sensing at the front-end, instead of compressing\nand transmitting visual signals or the ultimately utilized top-layer deep\nlearning features, we propose to compactly represent and convey the\nintermediate-layer deep learning features of high generalization capability, to\nfacilitate the collaborating approach between front and cloud ends. This\nstrategy enables a good balance among the computational load, transmission load\nand the generalization ability for cloud servers when deploying the deep neural\nnetworks for large scale cloud based visual analysis. Moreover, the presented\nstrategy also makes the standardization of deep feature coding more feasible\nand promising, as a series of tasks can simultaneously benefit from the\ntransmitted intermediate layers. We also present the results for evaluation of\nlossless deep feature compression with four benchmark data compression methods,\nwhich provides meaningful investigations and baselines for future research and\nstandardization activities.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 13:38:41 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Chen", "Zhuo", ""], ["Lin", "Weisi", ""], ["Wang", "Shiqi", ""], ["Duan", "Lingyu", ""], ["Kot", "Alex C.", ""]]}, {"id": "1809.06201", "submitter": "Matthew Guzdial", "authors": "Zijin Luo, Matthew Guzdial, Nicholas Liao and Mark Riedl", "title": "Player Experience Extraction from Gameplay Video", "comments": "8 pages, 6 figures, AIIDE 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to extract the sequence of game events for a given player's\nplay-through has traditionally required access to the game's engine or source\ncode. This serves as a barrier to researchers, developers, and hobbyists who\nmight otherwise benefit from these game logs. In this paper we present two\napproaches to derive game logs from game video via convolutional neural\nnetworks and transfer learning. We evaluate the approaches in a Super Mario\nBros. clone, Mega Man and Skyrim. Our results demonstrate our approach\noutperforms random forest and other transfer baselines.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 22:00:46 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Luo", "Zijin", ""], ["Guzdial", "Matthew", ""], ["Liao", "Nicholas", ""], ["Riedl", "Mark", ""]]}, {"id": "1809.06205", "submitter": "Aristotelis Charalampous", "authors": "Aristotelis Charalampous, Sotirios Chatzis", "title": "Quantum Statistics-Inspired Neural Attention", "comments": "Submitted to The 23rd Pacific-Asia Conference on Knowledge Discovery\n  and Data Mining (PAKDD 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Sequence-to-sequence (encoder-decoder) models with attention constitute a\ncornerstone of deep learning research, as they have enabled unprecedented\nsequential data modeling capabilities. This effectiveness largely stems from\nthe capacity of these models to infer salient temporal dynamics over long\nhorizons; these are encoded into the obtained neural attention (NA)\ndistributions. However, existing NA formulations essentially constitute\npoint-wise selection mechanisms over the observed source sequences; that is,\nattention weights computation relies on the assumption that each source\nsequence element is independent of the rest. Unfortunately, although\nconvenient, this assumption fails to account for higher-order dependencies\nwhich might be prevalent in real-world data. This paper addresses these\nlimitations by leveraging Quantum-Statistical modeling arguments. Specifically,\nour work broadens the notion of NA, by attempting to account for the case that\nthe NA model becomes inherently incapable of discerning between individual\nsource elements; this is assumed to be the case due to higher-order temporal\ndynamics. On the contrary, we postulate that in some cases selection may be\nfeasible only at the level of pairs of source sequence elements. To this end,\nwe cast NA into inference of an attention density matrix (ADM) approximation.\nWe derive effective training and inference algorithms, and evaluate our\napproach in the context of a machine translation (MT) application. We perform\nexperiments with challenging benchmark datasets. As we show, our approach\nyields favorable outcomes in terms of several evaluation metrics.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 13:58:13 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 13:31:44 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Charalampous", "Aristotelis", ""], ["Chatzis", "Sotirios", ""]]}, {"id": "1809.06225", "submitter": "Zheng Lian", "authors": "Zheng Lian, Ya Li, Jianhua Tao, Jian Huang", "title": "Investigation of Multimodal Features, Classifiers and Fusion Methods for\n  Emotion Recognition", "comments": "9 pages, 11 figures and 4 Tables. EmotiW2018 challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic emotion recognition is a challenging task. In this paper, we\npresent our effort for the audio-video based sub-challenge of the Emotion\nRecognition in the Wild (EmotiW) 2018 challenge, which requires participants to\nassign a single emotion label to the video clip from the six universal emotions\n(Anger, Disgust, Fear, Happiness, Sad and Surprise) and Neutral. The proposed\nmultimodal emotion recognition system takes audio, video and text information\ninto account. Except for handcraft features, we also extract bottleneck\nfeatures from deep neutral networks (DNNs) via transfer learning. Both temporal\nclassifiers and non-temporal classifiers are evaluated to obtain the best\nunimodal emotion classification result. Then possibilities are extracted and\npassed into the Beam Search Fusion (BS-Fusion). We test our method in the\nEmotiW 2018 challenge and we gain promising results. Compared with the baseline\nsystem, there is a significant improvement. We achieve 60.34% accuracy on the\ntesting dataset, which is only 1.5% lower than the winner. It shows that our\nmethod is very competitive.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 08:56:25 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Lian", "Zheng", ""], ["Li", "Ya", ""], ["Tao", "Jianhua", ""], ["Huang", "Jian", ""]]}, {"id": "1809.06244", "submitter": "Frank Glavin", "authors": "David L. Smyth, Sai Abinesh, Nazli B. Karimi, Brett Drury, Ihsan\n  Ullah, Frank G. Glavin, Michael G. Madden", "title": "A Virtual Testbed for Critical Incident Investigation with Autonomous\n  Remote Aerial Vehicle Surveying, Artificial Intelligence, and Decision\n  Support", "comments": "arXiv admin note: substantial text overlap with arXiv:1806.04497", "journal-ref": "IWAISe, 2nd International Workshop on A.I. in Security, European\n  Conference on Machine Learning 2018", "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous robotics and artificial intelligence techniques can be used to\nsupport human personnel in the event of critical incidents. These incidents can\npose great danger to human life. Some examples of such assistance include:\nmulti-robot surveying of the scene; collection of sensor data and scene\nimagery, real-time risk assessment and analysis; object identification and\nanomaly detection; and retrieval of relevant supporting documentation such as\nstandard operating procedures (SOPs). These incidents, although often rare, can\ninvolve chemical, biological, radiological/nuclear or explosive (CBRNE)\nsubstances and can be of high consequence. Real-world training and deployment\nof these systems can be costly and sometimes not feasible. For this reason, we\nhave developed a realistic 3D model of a CBRNE scenario to act as a testbed for\nan initial set of assisting AI tools that we have developed.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 14:29:47 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 11:15:56 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Smyth", "David L.", ""], ["Abinesh", "Sai", ""], ["Karimi", "Nazli B.", ""], ["Drury", "Brett", ""], ["Ullah", "Ihsan", ""], ["Glavin", "Frank G.", ""], ["Madden", "Michael G.", ""]]}, {"id": "1809.06260", "submitter": "Jun Feng", "authors": "Jun Feng, Heng Li, Minlie Huang, Shichen Liu, Wenwu Ou, Zhirong Wang\n  and Xiaoyan Zhu", "title": "Learning to Collaborate: Multi-Scenario Ranking via Multi-Agent\n  Reinforcement Learning", "comments": "WWW2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ranking is a fundamental and widely studied problem in scenarios such as\nsearch, advertising, and recommendation. However, joint optimization for\nmulti-scenario ranking, which aims to improve the overall performance of\nseveral ranking strategies in different scenarios, is rather untouched.\nSeparately optimizing each individual strategy has two limitations. The first\none is lack of collaboration between scenarios meaning that each strategy\nmaximizes its own objective but ignores the goals of other strategies, leading\nto a sub-optimal overall performance. The second limitation is the inability of\nmodeling the correlation between scenarios meaning that independent\noptimization in one scenario only uses its own user data but ignores the\ncontext in other scenarios.\n  In this paper, we formulate multi-scenario ranking as a fully cooperative,\npartially observable, multi-agent sequential decision problem. We propose a\nnovel model named Multi-Agent Recurrent Deterministic Policy Gradient (MA-RDPG)\nwhich has a communication component for passing messages, several private\nactors (agents) for making actions for ranking, and a centralized critic for\nevaluating the overall performance of the co-working actors. Each scenario is\ntreated as an agent (actor). Agents collaborate with each other by sharing a\nglobal action-value function (the critic) and passing messages that encodes\nhistorical information across scenarios. The model is evaluated with online\nsettings on a large E-commerce platform. Results show that the proposed model\nexhibits significant improvements against baselines in terms of the overall\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 14:45:21 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Feng", "Jun", ""], ["Li", "Heng", ""], ["Huang", "Minlie", ""], ["Liu", "Shichen", ""], ["Ou", "Wenwu", ""], ["Wang", "Zhirong", ""], ["Zhu", "Xiaoyan", ""]]}, {"id": "1809.06305", "submitter": "Xiao Li", "authors": "Xiao Li, Yao Ma and Calin Belta", "title": "Automata Guided Reinforcement Learning With Demonstrations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tasks with complex temporal structures and long horizons pose a challenge for\nreinforcement learning agents due to the difficulty in specifying the tasks in\nterms of reward functions as well as large variances in the learning signals.\nWe propose to address these problems by combining temporal logic (TL) with\nreinforcement learning from demonstrations. Our method automatically generates\nintrinsic rewards that align with the overall task goal given a TL task\nspecification. The policy resulting from our framework has an interpretable and\nhierarchical structure. We validate the proposed method experimentally on a set\nof robotic manipulation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 16:17:28 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2018 22:10:42 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Li", "Xiao", ""], ["Ma", "Yao", ""], ["Belta", "Calin", ""]]}, {"id": "1809.06309", "submitter": "Yicheng Wang", "authors": "Lisa Bauer, Yicheng Wang, Mohit Bansal", "title": "Commonsense for Generative Multi-Hop Question Answering Tasks", "comments": "EMNLP 2018 (22 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reading comprehension QA tasks have seen a recent surge in popularity, yet\nmost works have focused on fact-finding extractive QA. We instead focus on a\nmore challenging multi-hop generative task (NarrativeQA), which requires the\nmodel to reason, gather, and synthesize disjoint pieces of information within\nthe context to generate an answer. This type of multi-step reasoning also often\nrequires understanding implicit relations, which humans resolve via external,\nbackground commonsense knowledge. We first present a strong generative baseline\nthat uses a multi-attention mechanism to perform multiple hops of reasoning and\na pointer-generator decoder to synthesize the answer. This model performs\nsubstantially better than previous generative models, and is competitive with\ncurrent state-of-the-art span prediction models. We next introduce a novel\nsystem for selecting grounded multi-hop relational commonsense information from\nConceptNet via a pointwise mutual information and term-frequency based scoring\nfunction. Finally, we effectively use this extracted commonsense information to\nfill in gaps of reasoning between context hops, using a selectively-gated\nattention mechanism. This boosts the model's performance significantly (also\nverified via human evaluation), establishing a new state-of-the-art for the\ntask. We also show promising initial results of the generalizability of our\nbackground knowledge enhancements by demonstrating some improvement on\nQAngaroo-WikiHop, another multi-hop reasoning dataset.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 16:24:00 GMT"}, {"version": "v2", "created": "Fri, 11 Jan 2019 17:08:37 GMT"}, {"version": "v3", "created": "Sat, 1 Jun 2019 03:50:14 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Bauer", "Lisa", ""], ["Wang", "Yicheng", ""], ["Bansal", "Mohit", ""]]}, {"id": "1809.06404", "submitter": "Ahmed Qureshi", "authors": "Ahmed H. Qureshi, Byron Boots and Michael C. Yip", "title": "Adversarial Imitation via Variational Inverse Reinforcement Learning", "comments": "Paper published at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a problem of learning the reward and policy from expert examples\nunder unknown dynamics. Our proposed method builds on the framework of\ngenerative adversarial networks and introduces the empowerment-regularized\nmaximum-entropy inverse reinforcement learning to learn near-optimal rewards\nand policies. Empowerment-based regularization prevents the policy from\noverfitting to expert demonstrations, which advantageously leads to more\ngeneralized behaviors that result in learning near-optimal rewards. Our method\nsimultaneously learns empowerment through variational information maximization\nalong with the reward and policy under the adversarial learning formulation. We\nevaluate our approach on various high-dimensional complex control tasks. We\nalso test our learned rewards in challenging transfer learning problems where\ntraining and testing environments are made to be different from each other in\nterms of dynamics or structure. The results show that our proposed method not\nonly learns near-optimal rewards and policies that are matching expert behavior\nbut also performs significantly better than state-of-the-art inverse\nreinforcement learning algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 18:47:47 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 19:27:41 GMT"}, {"version": "v3", "created": "Fri, 22 Feb 2019 23:32:23 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Qureshi", "Ahmed H.", ""], ["Boots", "Byron", ""], ["Yip", "Michael C.", ""]]}, {"id": "1809.06473", "submitter": "Sahin Geyik", "authors": "Rohan Ramanath, Hakan Inan, Gungor Polatkan, Bo Hu, Qi Guo, Cagri\n  Ozcaglar, Xianren Wu, Krishnaram Kenthapadi, Sahin Cem Geyik", "title": "Towards Deep and Representation Learning for Talent Search at LinkedIn", "comments": "This paper has been accepted for publication in ACM CIKM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Talent search and recommendation systems at LinkedIn strive to match the\npotential candidates to the hiring needs of a recruiter or a hiring manager\nexpressed in terms of a search query or a job posting. Recent work in this\ndomain has mainly focused on linear models, which do not take complex\nrelationships between features into account, as well as ensemble tree models,\nwhich introduce non-linearity but are still insufficient for exploring all the\npotential feature interactions, and strictly separate feature generation from\nmodeling. In this paper, we present the results of our application of deep and\nrepresentation learning models on LinkedIn Recruiter. Our key contributions\ninclude: (i) Learning semantic representations of sparse entities within the\ntalent search domain, such as recruiter ids, candidate ids, and skill entity\nids, for which we utilize neural network models that take advantage of LinkedIn\nEconomic Graph, and (ii) Deep models for learning recruiter engagement and\ncandidate response in talent search applications. We also explore learning to\nrank approaches applied to deep models, and show the benefits for the talent\nsearch use case. Finally, we present offline and online evaluation results for\nLinkedIn talent search and recommendation systems, and discuss potential\nchallenges along the path to a fully deep model architecture. The challenges\nand approaches discussed generalize to any multi-faceted search engine.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 23:11:50 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Ramanath", "Rohan", ""], ["Inan", "Hakan", ""], ["Polatkan", "Gungor", ""], ["Hu", "Bo", ""], ["Guo", "Qi", ""], ["Ozcaglar", "Cagri", ""], ["Wu", "Xianren", ""], ["Kenthapadi", "Krishnaram", ""], ["Geyik", "Sahin Cem", ""]]}, {"id": "1809.06481", "submitter": "Sahin Geyik", "authors": "Sahin Cem Geyik, Qi Guo, Bo Hu, Cagri Ozcaglar, Ketan Thakkar, Xianren\n  Wu, Krishnaram Kenthapadi", "title": "Talent Search and Recommendation Systems at LinkedIn: Practical\n  Challenges and Lessons Learned", "comments": "This paper has been accepted for publication at ACM SIGIR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LinkedIn Talent Solutions business contributes to around 65% of LinkedIn's\nannual revenue, and provides tools for job providers to reach out to potential\ncandidates and for job seekers to find suitable career opportunities.\nLinkedIn's job ecosystem has been designed as a platform to connect job\nproviders and job seekers, and to serve as a marketplace for efficient matching\nbetween potential candidates and job openings. A key mechanism to help achieve\nthese goals is the LinkedIn Recruiter product, which enables recruiters to\nsearch for relevant candidates and obtain candidate recommendations for their\njob postings. In this work, we highlight a set of unique information retrieval,\nsystem, and modeling challenges associated with talent search and\nrecommendation systems.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 00:03:15 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Geyik", "Sahin Cem", ""], ["Guo", "Qi", ""], ["Hu", "Bo", ""], ["Ozcaglar", "Cagri", ""], ["Thakkar", "Ketan", ""], ["Wu", "Xianren", ""], ["Kenthapadi", "Krishnaram", ""]]}, {"id": "1809.06488", "submitter": "Sahin Geyik", "authors": "Sahin Cem Geyik, Vijay Dialani, Meng Meng, Ryan Smith", "title": "In-Session Personalization for Talent Search", "comments": "This paper has been accepted for publication at ACM CIKM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous efforts in recommendation of candidates for talent search followed\nthe general pattern of receiving an initial search criteria and generating a\nset of candidates utilizing a pre-trained model. Traditionally, the generated\nrecommendations are final, that is, the list of potential candidates is not\nmodified unless the user explicitly changes his/her search criteria. In this\npaper, we are proposing a candidate recommendation model which takes into\naccount the immediate feedback of the user, and updates the candidate\nrecommendations at each step. This setting also allows for very uninformative\ninitial search queries, since we pinpoint the user's intent due to the feedback\nduring the search session. To achieve our goal, we employ an intent clustering\nmethod based on topic modeling which separates the candidate space into\nmeaningful, possibly overlapping, subsets (which we call intent clusters) for\neach position. On top of the candidate segments, we apply a multi-armed bandit\napproach to choose which intent cluster is more appropriate for the current\nsession. We also present an online learning scheme which updates the intent\nclusters within the session, due to user feedback, to achieve further\npersonalization. Our offline experiments as well as the results from the online\ndeployment of our solution demonstrate the benefits of our proposed\nmethodology.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 00:24:23 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Geyik", "Sahin Cem", ""], ["Dialani", "Vijay", ""], ["Meng", "Meng", ""], ["Smith", "Ryan", ""]]}, {"id": "1809.06537", "submitter": "Cunchao Tu", "authors": "Shangbang Long, Cunchao Tu, Zhiyuan Liu, Maosong Sun", "title": "Automatic Judgment Prediction via Legal Reading Comprehension", "comments": "10 pages, 4 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic judgment prediction aims to predict the judicial results based on\ncase materials. It has been studied for several decades mainly by lawyers and\njudges, considered as a novel and prospective application of artificial\nintelligence techniques in the legal field. Most existing methods follow the\ntext classification framework, which fails to model the complex interactions\namong complementary case materials. To address this issue, we formalize the\ntask as Legal Reading Comprehension according to the legal scenario. Following\nthe working protocol of human judges, LRC predicts the final judgment results\nbased on three types of information, including fact description, plaintiffs'\npleas, and law articles. Moreover, we propose a novel LRC model, AutoJudge,\nwhich captures the complex semantic interactions among facts, pleas, and laws.\nIn experiments, we construct a real-world civil case dataset for LRC.\nExperimental results on this dataset demonstrate that our model achieves\nsignificant improvement over state-of-the-art models. We will publish all\nsource codes and datasets of this work on \\urlgithub.com for further research.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 05:26:40 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Long", "Shangbang", ""], ["Tu", "Cunchao", ""], ["Liu", "Zhiyuan", ""], ["Sun", "Maosong", ""]]}, {"id": "1809.06559", "submitter": "Yilin Shen", "authors": "Yilin Shen and Xiangyu Zeng and Yu Wang and Hongxia Jin", "title": "User Information Augmented Semantic Frame Parsing using Coarse-to-Fine\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic frame parsing is a crucial component in spoken language\nunderstanding (SLU) to build spoken dialog systems. It has two main tasks:\nintent detection and slot filling. Although state-of-the-art approaches showed\ngood results, they require large annotated training data and long training\ntime. In this paper, we aim to alleviate these drawbacks for semantic frame\nparsing by utilizing the ubiquitous user information. We design a novel\ncoarse-to-fine deep neural network model to incorporate prior knowledge of user\ninformation intermediately to better and quickly train a semantic frame parser.\nDue to the lack of benchmark dataset with real user information, we synthesize\nthe simplest type of user information (location and time) on ATIS benchmark\ndata. The results show that our approach leverages such simple user information\nto outperform state-of-the-art approaches by 0.25% for intent detection and\n0.31% for slot filling using standard training data. When using smaller\ntraining data, the performance improvement on intent detection and slot filling\nreaches up to 1.35% and 1.20% respectively. We also show that our approach can\nachieve similar performance as state-of-the-art approaches by using less than\n80% annotated training data. Moreover, the training time to achieve the similar\nperformance is also reduced by over 60%.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 07:08:59 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Shen", "Yilin", ""], ["Zeng", "Xiangyu", ""], ["Wang", "Yu", ""], ["Jin", "Hongxia", ""]]}, {"id": "1809.06625", "submitter": "Chengwei Zhang", "authors": "Chengwei Zhang and Xiaohong Li and Jianye Hao and Siqi Chen and Karl\n  Tuyls and Zhiyong Feng and Wanli Xue and Rong Chen", "title": "SCC-rFMQ Learning in Cooperative Markov Games with Continuous Actions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although many reinforcement learning methods have been proposed for learning\nthe optimal solutions in single-agent continuous-action domains, multiagent\ncoordination domains with continuous actions have received relatively few\ninvestigations. In this paper, we propose an independent learner hierarchical\nmethod, named Sample Continuous Coordination with recursive Frequency Maximum\nQ-Value (SCC-rFMQ), which divides the cooperative problem with continuous\nactions into two layers. The first layer samples a finite set of actions from\nthe continuous action spaces by a re-sampling mechanism with variable\nexploratory rates, and the second layer evaluates the actions in the sampled\naction set and updates the policy using a reinforcement learning cooperative\nmethod. By constructing cooperative mechanisms at both levels, SCC-rFMQ can\nhandle cooperative problems in continuous action cooperative Markov games\neffectively. The effectiveness of SCC-rFMQ is experimentally demonstrated on\ntwo well-designed games, i.e., a continuous version of the climbing game and a\ncooperative version of the boat problem. Experimental results show that\nSCC-rFMQ outperforms other reinforcement learning algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 10:19:35 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Zhang", "Chengwei", ""], ["Li", "Xiaohong", ""], ["Hao", "Jianye", ""], ["Chen", "Siqi", ""], ["Tuyls", "Karl", ""], ["Feng", "Zhiyong", ""], ["Xue", "Wanli", ""], ["Chen", "Rong", ""]]}, {"id": "1809.06638", "submitter": "Zeynep G\\\"ozen Saribatur", "authors": "Zeynep G. Saribatur, Thomas Eiter", "title": "Towards Abstraction in ASP with an Application on Reasoning about Agent\n  Policies", "comments": "Proceedings of the 11th Workshop on Answer Set Programming and Other\n  Computing Paradigms 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ASP programs are a convenient tool for problem solving, whereas with large\nproblem instances the size of the state space can be prohibitive. We consider\nabstraction as a means of over-approximation and introduce a method to\nautomatically abstract (possibly non-ground) ASP programs that preserves their\nstructure, while reducing the size of the problem. One particular application\ncase is the problem of defining declarative policies for reactive agents and\nreasoning about them, which we illustrate on examples.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 10:54:40 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Saribatur", "Zeynep G.", ""], ["Eiter", "Thomas", ""]]}, {"id": "1809.06639", "submitter": "Alejandro Rodr\\'iguez-Gonz\\'alez", "authors": "Marjan Najafabadipour, Juan Manuel Tu\\~nas, Alejandro\n  Rodr\\'iguez-Gonz\\'alez, Ernestina Menasalvas", "title": "Lung Cancer Concept Annotation from Spanish Clinical Narratives", "comments": "10 pages, 6 figures", "journal-ref": "Data Integration in the Life Sciences (DILS 2018)", "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent rapid increase in the generation of clinical data and rapid\ndevelopment of computational science make us able to extract new insights from\nmassive datasets in healthcare industry. Oncological clinical notes are\ncreating rich databases for documenting patients history and they potentially\ncontain lots of patterns that could help in better management of the disease.\nHowever, these patterns are locked within free text (unstructured) portions of\nclinical documents and consequence in limiting health professionals to extract\nuseful information from them and to finally perform Query and Answering (QA)\nprocess in an accurate way. The Information Extraction (IE) process requires\nNatural Language Processing (NLP) techniques to assign semantics to these\npatterns. Therefore, in this paper, we analyze the design of annotators for\nspecific lung cancer concepts that can be integrated over Apache Unstructured\nInformation Management Architecture (UIMA) framework. In addition, we explain\nthe details of generation and storage of annotation outcomes.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 10:55:03 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Najafabadipour", "Marjan", ""], ["Tu\u00f1as", "Juan Manuel", ""], ["Rodr\u00edguez-Gonz\u00e1lez", "Alejandro", ""], ["Menasalvas", "Ernestina", ""]]}, {"id": "1809.06641", "submitter": "Joachim Fainberg", "authors": "Joachim Fainberg, Ben Krause, Mihai Dobre, Marco Damonte, Emmanuel\n  Kahembwe, Daniel Duma, Bonnie Webber, Federico Fancellu", "title": "Talking to myself: self-dialogues as data for conversational agents", "comments": "5 pages, 5 pages appendix, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational agents are gaining popularity with the increasing ubiquity of\nsmart devices. However, training agents in a data driven manner is challenging\ndue to a lack of suitable corpora. This paper presents a novel method for\ngathering topical, unstructured conversational data in an efficient way:\nself-dialogues through crowd-sourcing. Alongside this paper, we include a\ncorpus of 3.6 million words across 23 topics. We argue the utility of the\ncorpus by comparing self-dialogues with standard two-party conversations as\nwell as data from other corpora.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 11:09:49 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 10:16:52 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Fainberg", "Joachim", ""], ["Krause", "Ben", ""], ["Dobre", "Mihai", ""], ["Damonte", "Marco", ""], ["Kahembwe", "Emmanuel", ""], ["Duma", "Daniel", ""], ["Webber", "Bonnie", ""], ["Fancellu", "Federico", ""]]}, {"id": "1809.06646", "submitter": "Johannes Dornheim", "authors": "Johannes Dornheim, Norbert Link, Peter Gumbsch", "title": "Model-Free Adaptive Optimal Control of Episodic Fixed-Horizon\n  Manufacturing Processes using Reinforcement Learning", "comments": "Journal preprint version", "journal-ref": "International Journal of Control, Automation and Systems (2019)", "doi": "10.1007/s12555-019-0120-7", "report-no": null, "categories": "cs.SY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A self-learning optimal control algorithm for episodic fixed-horizon\nmanufacturing processes with time-discrete control actions is proposed and\nevaluated on a simulated deep drawing process. The control model is built\nduring consecutive process executions under optimal control via reinforcement\nlearning, using the measured product quality as reward after each process\nexecution. Prior model formulation, which is required by state-of-the-art\nalgorithms from model predictive control and approximate dynamic programming,\nis therefore obsolete. This avoids several difficulties namely in system\nidentification, accurate modelling, and runtime complexity, that arise when\ndealing with processes subject to nonlinear dynamics and stochastic influences.\nInstead of using pre-created process and observation models, value\nfunction-based reinforcement learning algorithms build functions of expected\nfuture reward, which are used to derive optimal process control decisions. The\nexpectation functions are learned online, by interacting with the process. The\nproposed algorithm takes stochastic variations of the process conditions into\naccount and is able to cope with partial observability. A Q-learning-based\nmethod for adaptive optimal control of partially observable episodic\nfixed-horizon manufacturing processes is developed and studied. The resulting\nalgorithm is instantiated and evaluated by applying it to a simulated\nstochastic optimal control problem in metal sheet deep drawing.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 11:20:27 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 10:37:01 GMT"}, {"version": "v3", "created": "Wed, 20 Feb 2019 16:00:59 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Dornheim", "Johannes", ""], ["Link", "Norbert", ""], ["Gumbsch", "Peter", ""]]}, {"id": "1809.06691", "submitter": "Boyuan Feng", "authors": "Boyuan Feng, Kun Wan, Shu Yang, Yufei Ding", "title": "SECS: Efficient Deep Stream Processing via Class Skew Dichotomy", "comments": "arXiv admin note: text overlap with arXiv:1611.06453 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite that accelerating convolutional neural network (CNN) receives an\nincreasing research focus, the save on resource consumption always comes with a\ndecrease in accuracy. To both increase accuracy and decrease resource\nconsumption, we explore an environment information, called class skew, which is\neasily available and exists widely in daily life. Since the class skew may\nswitch as time goes, we bring up probability layer to utilize class skew\nwithout any overhead during the runtime. Further, we observe class skew\ndichotomy that some class skew may appear frequently in the future, called hot\nclass skew, and others will never appear again or appear seldom, called cold\nclass skew. Inspired by techniques from source code optimization, two modes,\ni.e., interpretation and compilation, are proposed. The interpretation mode\npursues efficient adaption during runtime for cold class skew and the\ncompilation mode aggressively optimize on hot ones for more efficient\ndeployment in the future. Aggressive optimization is processed by\nclass-specific pruning and provides extra benefit. Finally, we design a\nsystematic framework, SECS, to dynamically detect class skew, processing\ninterpretation and compilation, as well as select the most accurate\narchitectures under the runtime resource budget. Extensive evaluations show\nthat SECS can realize end-to-end classification speedups by a factor of 3x to\n11x relative to state-of-the-art convolutional neural networks, at a higher\naccuracy.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 18:03:47 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Feng", "Boyuan", ""], ["Wan", "Kun", ""], ["Yang", "Shu", ""], ["Ding", "Yufei", ""]]}, {"id": "1809.06709", "submitter": "Pankaj Gupta", "authors": "Pankaj Gupta and Yatin Chaudhary and Florian Buettner and Hinrich\n  Sch\\\"utze", "title": "Document Informed Neural Autoregressive Topic Models with Distributional\n  Prior", "comments": "AAAI2019. arXiv admin note: substantial text overlap with\n  arXiv:1808.03793", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address two challenges in topic models: (1) Context information around\nwords helps in determining their actual meaning, e.g., \"networks\" used in the\ncontexts \"artificial neural networks\" vs. \"biological neuron networks\".\nGenerative topic models infer topic-word distributions, taking no or only\nlittle context into account. Here, we extend a neural autoregressive topic\nmodel to exploit the full context information around words in a document in a\nlanguage modeling fashion. The proposed model is named as iDocNADE. (2) Due to\nthe small number of word occurrences (i.e., lack of context) in short text and\ndata sparsity in a corpus of few documents, the application of topic models is\nchallenging on such texts. Therefore, we propose a simple and efficient way of\nincorporating external knowledge into neural autoregressive topic models: we\nuse embeddings as a distributional prior. The proposed variants are named as\nDocNADEe and iDocNADEe.\n  We present novel neural autoregressive topic model variants that consistently\noutperform state-of-the-art generative topic models in terms of generalization,\ninterpretability (topic coherence) and applicability (retrieval and\nclassification) over 7 long-text and 8 short-text datasets from diverse\ndomains.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 12:48:16 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 16:25:06 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Gupta", "Pankaj", ""], ["Chaudhary", "Yatin", ""], ["Buettner", "Florian", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1809.06716", "submitter": "Nan Tian", "authors": "Nan Tian, Jinfa Chen, Mas Ma, Robert Zhang, Bill Huang, Ken Goldberg\n  and Somayeh Sojoudi", "title": "A Fog Robotic System for Dynamic Visual Servoing", "comments": "7 pages, 5 figures, ICRA 2019 (submitted, under review)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Cloud Robotics is a paradigm where distributed robots are connected to cloud\nservices via networks to access unlimited computation power, at the cost of\nnetwork communication. However, due to limitations such as network latency and\nvariability, it is difficult to control dynamic, human compliant service robots\ndirectly from the cloud. In this work, by leveraging asynchronous protocol with\na heartbeat signal, we combine cloud robotics with a smart edge device to build\na Fog Robotic system. We use the system to enable robust teleoperation of a\ndynamic self-balancing robot from the cloud. We first use the system to pick up\nboxes from static locations, a task commonly performed in warehouse logistics.\nTo make cloud teleoperation more efficient, we deploy image based visual\nservoing (IBVS) to perform box pickups automatically. Visual feedbacks,\nincluding apriltag recognition and tracking, are performed in the cloud to\nemulate a Fog Robotic object recognition system for IBVS. We demonstrate the\nfeasibility of real-time dynamic automation system using this cloud-edge\nhybrid, which opens up possibilities of deploying dynamic robotic control with\ndeep-learning recognition systems in Fog Robotics. Finally, we show that Fog\nRobotics enables the self-balancing service robot to pick up a box\nautomatically from a person under unstructured environments.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 07:58:09 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Tian", "Nan", ""], ["Chen", "Jinfa", ""], ["Ma", "Mas", ""], ["Zhang", "Robert", ""], ["Huang", "Bill", ""], ["Goldberg", "Ken", ""], ["Sojoudi", "Somayeh", ""]]}, {"id": "1809.06723", "submitter": "Biplav Srivastava", "authors": "Biplav Srivastava", "title": "Decision-support for the Masses by Enabling Conversations with Open Data", "comments": "6 pages. arXiv admin note: text overlap with arXiv:1803.09789", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open data refers to data that is freely available for reuse. Although there\nhas been rapid increase in availability of open data to public in the last\ndecade, this has not translated into better decision-support tools for them. We\npropose intelligent conversation generators as a grand challenge that would\nautomatically create data-driven conversation interfaces (CIs), also known as\nchatbots or dialog systems, from open data and deliver personalized analytical\ninsights to users based on their contextual needs. Such generators will not\nonly help bring Artificial Intelligence (AI)-based solutions for important\nsocietal problems to the masses but also advance AI by providing an integrative\ntestbed for human-centric AI and filling gaps in the state-of-art towards this\naim.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 17:59:43 GMT"}, {"version": "v2", "created": "Fri, 11 Jan 2019 14:18:14 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Srivastava", "Biplav", ""]]}, {"id": "1809.06775", "submitter": "Norberto Ritzmann J\\'unior", "authors": "Norberto Ritzmann Junior and Julio Cesar Nievola", "title": "A generalized financial time series forecasting model based on automatic\n  feature engineering using genetic algorithms and support vector machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the genetic algorithm for time window optimization, which is an\nembedded genetic algorithm (GA), to optimize the time window (TW) of the\nattributes using feature selection and support vector machine. This GA is\nevolved using the results of a trading simulation, and it determines the best\nTW for each technical indicator. An appropriate evaluation was conducted using\na walk-forward trading simulation, and the trained model was verified to be\ngeneralizable for forecasting other stock data. The results show that using the\nGA to determine the TW can improve the rate of return, leading to better\nprediction models than those resulting from using the default TW.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 14:40:19 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Junior", "Norberto Ritzmann", ""], ["Nievola", "Julio Cesar", ""]]}, {"id": "1809.06848", "submitter": "Remi Tachet Des Combes", "authors": "Remi Tachet, Mohammad Pezeshki, Samira Shabanian, Aaron Courville,\n  Yoshua Bengio", "title": "On the Learning Dynamics of Deep Neural Networks", "comments": "19 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While a lot of progress has been made in recent years, the dynamics of\nlearning in deep nonlinear neural networks remain to this day largely\nmisunderstood. In this work, we study the case of binary classification and\nprove various properties of learning in such networks under strong assumptions\nsuch as linear separability of the data. Extending existing results from the\nlinear case, we confirm empirical observations by proving that the\nclassification error also follows a sigmoidal shape in nonlinear architectures.\nWe show that given proper initialization, learning expounds parallel\nindependent modes and that certain regions of parameter space might lead to\nfailed training. We also demonstrate that input norm and features' frequency in\nthe dataset lead to distinct convergence speeds which might shed some light on\nthe generalization capabilities of deep neural networks. We provide a\ncomparison between the dynamics of learning with cross-entropy and hinge\nlosses, which could prove useful to understand recent progress in the training\nof generative adversarial networks. Finally, we identify a phenomenon that we\nbaptize gradient starvation where the most frequent features in a dataset\nprevent the learning of other less frequent but equally informative features.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 17:58:49 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 13:55:46 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 22:06:39 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Tachet", "Remi", ""], ["Pezeshki", "Mohammad", ""], ["Shabanian", "Samira", ""], ["Courville", "Aaron", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1809.06911", "submitter": "David Orden", "authors": "David Orden and Encarnaci\\'on Fern\\'andez-Fern\\'andez and Jos\\'e M.\n  Rodr\\'iguez-Nogales and Josefina Vila-Crespo", "title": "Testing SensoGraph, a geometric approach for fast sensory evaluation", "comments": "21 pages, 7 figures, 3 tables. Accepted at Food Quality and\n  Preference", "journal-ref": "Food Quality and Preference 72 (2019), 1-9", "doi": "10.1016/j.foodqual.2018.09.005", "report-no": null, "categories": "cs.CG cs.AI cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces SensoGraph, a novel approach for fast sensory\nevaluation using two-dimensional geometric techniques. In the tasting sessions,\nthe assessors follow their own criteria to place samples on a tablecloth,\naccording to the similarity between samples. In order to analyse the data\ncollected, first a geometric clustering is performed to each tablecloth,\nextracting connections between the samples. Then, these connections are used to\nconstruct a global similarity matrix. Finally, a graph drawing algorithm is\nused to obtain a 2D consensus graphic, which reflects the global opinion of the\npanel by (1) positioning closer those samples that have been globally perceived\nas similar and (2) showing the strength of the connections between samples. The\nproposal is validated by performing four tasting sessions, with three types of\npanels tasting different wines, and by developing a new software to implement\nthe proposed techniques. The results obtained show that the graphics provide\nsimilar positionings of the samples as the consensus maps obtained by multiple\nfactor analysis (MFA), further providing extra information about connections\nbetween samples, not present in any previous method. The main conclusion is\nthat the use of geometric techniques provides information complementary to MFA,\nand of a different type. Finally, the method proposed is computationally able\nto manage a significantly larger number of assessors than MFA, which can be\nuseful for the comparison of pictures by a huge number of consumers, via the\nInternet.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 07:38:31 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Orden", "David", ""], ["Fern\u00e1ndez-Fern\u00e1ndez", "Encarnaci\u00f3n", ""], ["Rodr\u00edguez-Nogales", "Jos\u00e9 M.", ""], ["Vila-Crespo", "Josefina", ""]]}, {"id": "1809.06937", "submitter": "Hannah Li", "authors": "Ramesh Johari, Vijay Kamble, Anilesh K. Krishnaswamy, Hannah Li", "title": "Exploration vs. Exploitation in Team Formation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An online labor platform faces an online learning problem in matching workers\nwith jobs and using the performance on these jobs to create better future\nmatches. This learning problem is complicated by the rise of complex tasks on\nthese platforms, such as web development and product design, that require a\nteam of workers to complete. The success of a job is now a function of the\nskills and contributions of all workers involved, which may be unknown to both\nthe platform and the client who posted the job. These team matchings result in\na structured correlation between what is known about the individuals and this\ninformation can be utilized to create better future matches. We analyze two\nnatural settings where the performance of a team is dictated by its strongest\nand its weakest member, respectively. We find that both problems pose an\nexploration-exploitation tradeoff between learning the performance of untested\nteams and repeating previously tested teams that resulted in a good\nperformance. We establish fundamental regret bounds and design near-optimal\nalgorithms that uncover several insights into these tradeoffs.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 21:15:45 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 22:58:12 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Johari", "Ramesh", ""], ["Kamble", "Vijay", ""], ["Krishnaswamy", "Anilesh K.", ""], ["Li", "Hannah", ""]]}, {"id": "1809.06987", "submitter": "Colin White", "authors": "Maria-Florina Balcan, Travis Dick, Colin White", "title": "Data-Driven Clustering via Parameterized Lloyd's Families", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms for clustering points in metric spaces is a long-studied area of\nresearch. Clustering has seen a multitude of work both theoretically, in\nunderstanding the approximation guarantees possible for many objective\nfunctions such as k-median and k-means clustering, and experimentally, in\nfinding the fastest algorithms and seeding procedures for Lloyd's algorithm.\nThe performance of a given clustering algorithm depends on the specific\napplication at hand, and this may not be known up front. For example, a\n\"typical instance\" may vary depending on the application, and different\nclustering heuristics perform differently depending on the instance.\n  In this paper, we define an infinite family of algorithms generalizing\nLloyd's algorithm, with one parameter controlling the initialization procedure,\nand another parameter controlling the local search procedure. This family of\nalgorithms includes the celebrated k-means++ algorithm, as well as the classic\nfarthest-first traversal algorithm. We design efficient learning algorithms\nwhich receive samples from an application-specific distribution over clustering\ninstances and learn a near-optimal clustering algorithm from the class. We show\nthe best parameters vary significantly across datasets such as MNIST, CIFAR,\nand mixtures of Gaussians. Our learned algorithms never perform worse than\nk-means++, and on some datasets we see significant improvements.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 02:36:25 GMT"}, {"version": "v2", "created": "Sun, 6 Jan 2019 03:09:42 GMT"}, {"version": "v3", "created": "Fri, 24 May 2019 06:44:07 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Balcan", "Maria-Florina", ""], ["Dick", "Travis", ""], ["White", "Colin", ""]]}, {"id": "1809.07004", "submitter": "Jeannette Bohg", "authors": "Hamza Merzic and Miroslav Bogdanovic and Daniel Kappler and Ludovic\n  Righetti and Jeannette Bohg", "title": "Leveraging Contact Forces for Learning to Grasp", "comments": "7 pages, 5 figures, Submitted to ICRA'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grasping objects under uncertainty remains an open problem in robotics\nresearch. This uncertainty is often due to noisy or partial observations of the\nobject pose or shape. To enable a robot to react appropriately to unforeseen\neffects, it is crucial that it continuously takes sensor feedback into account.\nWhile visual feedback is important for inferring a grasp pose and reaching for\nan object, contact feedback offers valuable information during manipulation and\ngrasp acquisition. In this paper, we use model-free deep reinforcement learning\nto synthesize control policies that exploit contact sensing to generate robust\ngrasping under uncertainty. We demonstrate our approach on a multi-fingered\nhand that exhibits more complex finger coordination than the commonly used\ntwo-fingered grippers. We conduct extensive experiments in order to assess the\nperformance of the learned policies, with and without contact sensing. While it\nis possible to learn grasping policies without contact sensing, our results\nsuggest that contact feedback allows for a significant improvement of grasping\nrobustness under object pose uncertainty and for objects with a complex shape.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 03:55:54 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Merzic", "Hamza", ""], ["Bogdanovic", "Miroslav", ""], ["Kappler", "Daniel", ""], ["Righetti", "Ludovic", ""], ["Bohg", "Jeannette", ""]]}, {"id": "1809.07009", "submitter": "Yuchi Huo", "authors": "Yuchi Huo and Sung-Eui Yoon", "title": "Light Field Neural Network", "comments": "Need some time to produce and test the prototype", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an optical neural network system made by off-the-shelf\ncomponents. In order to test the evaluate the physical property of the proposed\nsystem, we are making a prototype. After further discussions with our\ncooperators, we are agreed that the prototype implementation may take longer\ntime than we expected earlier. Therefore we reach a consensus on withdrawing\nthe paper until the physical data is available.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 04:19:28 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 04:09:35 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Huo", "Yuchi", ""], ["Yoon", "Sung-Eui", ""]]}, {"id": "1809.07027", "submitter": "Ville Vakkuri", "authors": "Ville Vakkuri and Pekka Abrahamsson", "title": "The Key Concepts of Ethics of Artificial Intelligence - A Keyword based\n  Systematic Mapping Study", "comments": "This is the author's version of the work. The copyright holder's\n  version can be found at http://dx.doi.org/10.1109/ICE.2018.8436265", "journal-ref": "2018 IEEE International Conference on Engineering, Technology and\n  Innovation (ICE/ITMC), Stuttgart, 2018", "doi": "10.1109/ICE.2018.8436265", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing influence and decision-making capacities of Autonomous systems\nand Artificial Intelligence in our lives force us to consider the values\nembedded in these systems. But how ethics should be implemented into these\nsystems? In this study, the solution is seen on philosophical conceptualization\nas a framework to form practical implementation model for ethics of AI. To take\nthe first steps on conceptualization main concepts used on the field needs to\nbe identified. A keyword based Systematic Mapping Study (SMS) on the keywords\nused in AI and ethics was conducted to help in identifying, defying and\ncomparing main concepts used in current AI ethics discourse. Out of 1062 papers\nretrieved SMS discovered 37 re-occurring keywords in 83 academic papers. We\nsuggest that the focus on finding keywords is the first step in guiding and\nproviding direction for future research in the AI ethics field.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 07:01:53 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Vakkuri", "Ville", ""], ["Abrahamsson", "Pekka", ""]]}, {"id": "1809.07045", "submitter": "Soumi Chattopadhyay", "authors": "Soumi Chattopadhyay, Ansuman Banerjee", "title": "A Methodology for Search Space Reduction in QoS Aware Semantic Web\n  Service Composition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The semantic information regulates the expressiveness of a web service.\nState-of-the-art approaches in web services research have used the semantics of\na web service for different purposes, mainly for service discovery,\ncomposition, execution etc. In this paper, our main focus is on semantic driven\nQuality of Service (QoS) aware service composition. Most of the contemporary\napproaches on service composition have used the semantic information to combine\nthe services appropriately to generate the composition solution. However, in\nthis paper, our intention is to use the semantic information to expedite the\nservice composition algorithm. Here, we present a service composition framework\nthat uses semantic information of a web service to generate different clusters,\nwhere the services are semantically related within a cluster. Our final aim is\nto construct a composition solution using these clusters that can efficiently\nscale to large service spaces, while ensuring solution quality. Experimental\nresults show the efficiency of our proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 07:53:29 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 06:00:30 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Chattopadhyay", "Soumi", ""], ["Banerjee", "Ansuman", ""]]}, {"id": "1809.07066", "submitter": "Vishal Sunder", "authors": "Vishal Sunder, Lovekesh Vig, Arnab Chatterjee, Gautam Shroff", "title": "Prosocial or Selfish? Agents with different behaviors for Contract\n  Negotiation using Reinforcement Learning", "comments": "Proceedings of the 11th International Workshop on Automated\n  Negotiations (held in conjunction with IJCAI 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an effective technique for training deep learning agents capable\nof negotiating on a set of clauses in a contract agreement using a simple\ncommunication protocol. We use Multi Agent Reinforcement Learning to train both\nagents simultaneously as they negotiate with each other in the training\nenvironment. We also model selfish and prosocial behavior to varying degrees in\nthese agents. Empirical evidence is provided showing consistency in agent\nbehaviors. We further train a meta agent with a mixture of behaviors by\nlearning an ensemble of different models using reinforcement learning. Finally,\nto ascertain the deployability of the negotiating agents, we conducted\nexperiments pitting the trained agents against human players. Results\ndemonstrate that the agents are able to hold their own against human players,\noften emerging as winners in the negotiation. Our experiments demonstrate that\nthe meta agent is able to reasonably emulate human behavior.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 08:46:34 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Sunder", "Vishal", ""], ["Vig", "Lovekesh", ""], ["Chatterjee", "Arnab", ""], ["Shroff", "Gautam", ""]]}, {"id": "1809.07098", "submitter": "Danilo Vasconcellos  Vargas", "authors": "Danilo Vasconcellos Vargas, Hirotaka Takano, Junichi Murata", "title": "Novelty-organizing team of classifiers in noisy and dynamic environments", "comments": null, "journal-ref": "2015 IEEE Congress on Evolutionary Computation (CEC)", "doi": "10.1109/CEC.2015.7257254", "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the real world, the environment is constantly changing with the input\nvariables under the effect of noise. However, few algorithms were shown to be\nable to work under those circumstances. Here, Novelty-Organizing Team of\nClassifiers (NOTC) is applied to the continuous action mountain car as well as\ntwo variations of it: a noisy mountain car and an unstable weather mountain\ncar. These problems take respectively noise and change of problem dynamics into\naccount. Moreover, NOTC is compared with NeuroEvolution of Augmenting\nTopologies (NEAT) in these problems, revealing a trade-off between the\napproaches. While NOTC achieves the best performance in all of the problems,\nNEAT needs less trials to converge. It is demonstrated that NOTC achieves\nbetter performance because of its division of the input space (creating easier\nproblems). Unfortunately, this division of input space also requires a bit of\ntime to bootstrap.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 09:38:20 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Vargas", "Danilo Vasconcellos", ""], ["Takano", "Hirotaka", ""], ["Murata", "Junichi", ""]]}, {"id": "1809.07133", "submitter": "Nico Potyka", "authors": "Nico Potyka", "title": "Extending Modular Semantics for Bipolar Weighted Argumentation\n  (Technical Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weighted bipolar argumentation frameworks offer a tool for decision support\nand social media analysis. Arguments are evaluated by an iterative procedure\nthat takes initial weights and attack and support relations into account. Until\nrecently, convergence of these iterative procedures was not very well\nunderstood in cyclic graphs. Mossakowski and Neuhaus recently introduced a\nunification of different approaches and proved first convergence and divergence\nresults. We build up on this work, simplify and generalize convergence results\nand complement them with runtime guarantees. As it turns out, there is a\ntradeoff between semantics' convergence guarantees and their ability to move\nstrength values away from the initial weights. We demonstrate that divergence\nproblems can be avoided without this tradeoff by continuizing semantics.\nSemantically, we extend the framework with a Duality property that assures a\nsymmetric impact of attack and support relations. We also present a Java\nimplementation of modular semantics and explain the practical usefulness of the\ntheoretical ideas.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 11:54:46 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 15:17:02 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Potyka", "Nico", ""]]}, {"id": "1809.07141", "submitter": "Patrick Kahl", "authors": "Anthony P. Leclerc and Patrick Thor Kahl", "title": "A survey of advances in epistemic logic program solvers", "comments": "Proceedings of the 11th Workshop on Answer Set Programming and Other\n  Computing Paradigms 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research in extensions of Answer Set Programming has included a\nrenewed interest in the language of Epistemic Specifications, which adds modal\noperators K (\"known\") and M (\"may be true\") to provide for more powerful\nintrospective reasoning and enhanced capability, particularly when reasoning\nwith incomplete information. An epistemic logic program is a set of rules in\nthis language. Infused with the research has been the desire for an efficient\nsolver to enable the practical use of such programs for problem solving. In\nthis paper, we report on the current state of development of epistemic logic\nprogram solvers.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 12:18:10 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Leclerc", "Anthony P.", ""], ["Kahl", "Patrick Thor", ""]]}, {"id": "1809.07193", "submitter": "Peng Sun", "authors": "Peng Sun, Xinghai Sun, Lei Han, Jiechao Xiong, Qing Wang, Bo Li, Yang\n  Zheng, Ji Liu, Yongsheng Liu, Han Liu, Tong Zhang", "title": "TStarBots: Defeating the Cheating Level Builtin AI in StarCraft II in\n  the Full Game", "comments": "add link for source code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Starcraft II (SC2) is widely considered as the most challenging Real Time\nStrategy (RTS) game. The underlying challenges include a large observation\nspace, a huge (continuous and infinite) action space, partial observations,\nsimultaneous move for all players, and long horizon delayed rewards for local\ndecisions. To push the frontier of AI research, Deepmind and Blizzard jointly\ndeveloped the StarCraft II Learning Environment (SC2LE) as a testbench of\ncomplex decision making systems. SC2LE provides a few mini games such as\nMoveToBeacon, CollectMineralShards, and DefeatRoaches, where some AI agents\nhave achieved the performance level of human professional players. However, for\nfull games, the current AI agents are still far from achieving human\nprofessional level performance. To bridge this gap, we present two full game AI\nagents in this paper - the AI agent TStarBot1 is based on deep reinforcement\nlearning over a flat action structure, and the AI agent TStarBot2 is based on\nhard-coded rules over a hierarchical action structure. Both TStarBot1 and\nTStarBot2 are able to defeat the built-in AI agents from level 1 to level 10 in\na full game (1v1 Zerg-vs-Zerg game on the AbyssalReef map), noting that level\n8, level 9, and level 10 are cheating agents with unfair advantages such as\nfull vision on the whole map and resource harvest boosting. To the best of our\nknowledge, this is the first public work to investigate AI agents that can\ndefeat the built-in AI in the StarCraft II full game.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 13:45:47 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 03:33:01 GMT"}, {"version": "v3", "created": "Thu, 27 Dec 2018 09:29:31 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Sun", "Peng", ""], ["Sun", "Xinghai", ""], ["Han", "Lei", ""], ["Xiong", "Jiechao", ""], ["Wang", "Qing", ""], ["Li", "Bo", ""], ["Zheng", "Yang", ""], ["Liu", "Ji", ""], ["Liu", "Yongsheng", ""], ["Liu", "Han", ""], ["Zhang", "Tong", ""]]}, {"id": "1809.07269", "submitter": "Chandrakant Bothe", "authors": "Chandrakant Bothe, Fernando Garcia, Arturo Cruz Maya, Amit Kumar\n  Pandey, Stefan Wermter", "title": "Towards Dialogue-based Navigation with Multivariate Adaptation driven by\n  Intention and Politeness for Social Robots", "comments": "Proceedings of ICSR 2018", "journal-ref": null, "doi": "10.1007/978-3-030-05204-1_23", "report-no": null, "categories": "cs.RO cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Service robots need to show appropriate social behaviour in order to be\ndeployed in social environments such as healthcare, education, retail, etc.\nSome of the main capabilities that robots should have are navigation and\nconversational skills. If the person is impatient, the person might want a\nrobot to navigate faster and vice versa. Linguistic features that indicate\npoliteness can provide social cues about a person's patient and impatient\nbehaviour. The novelty presented in this paper is to dynamically incorporate\npoliteness in robotic dialogue systems for navigation. Understanding the\npoliteness in users' speech can be used to modulate the robot behaviour and\nresponses. Therefore, we developed a dialogue system to navigate in an indoor\nenvironment, which produces different robot behaviours and responses based on\nusers' intention and degree of politeness. We deploy and test our system with\nthe Pepper robot that adapts to the changes in user's politeness.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 16:08:50 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 12:49:17 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Bothe", "Chandrakant", ""], ["Garcia", "Fernando", ""], ["Maya", "Arturo Cruz", ""], ["Pandey", "Amit Kumar", ""], ["Wermter", "Stefan", ""]]}, {"id": "1809.07347", "submitter": "Sanket Diwale", "authors": "Sanket Diwale and Colin Jones", "title": "A Generalized Representer Theorem for Hilbert Space - Valued Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The necessary and sufficient conditions for existence of a generalized\nrepresenter theorem are presented for learning Hilbert space-valued functions.\nRepresenter theorems involving explicit basis functions and Reproducing Kernels\nare a common occurrence in various machine learning algorithms like generalized\nleast squares, support vector machines, Gaussian process regression and kernel\nbased deep neural networks to name a few. Due to the more general structure of\nthe underlying variational problems, the theory is also relevant to other\napplication areas like optimal control, signal processing and decision making.\nWe present the generalized representer as a unified view for supervised and\nsemi-supervised learning methods, using the theory of linear operators and\nsubspace valued maps. The implications of the theorem are presented with\nexamples of multi input-multi output regression, kernel based deep neural\nnetworks, stochastic regression and sparsity learning problems as being special\ncases in this unified view.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 18:00:51 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Diwale", "Sanket", ""], ["Jones", "Colin", ""]]}, {"id": "1809.07412", "submitter": "Martin Butz", "authors": "Martin V. Butz and David Bilkey and Dania Humaidan and Alistair Knott\n  and Sebastian Otte", "title": "Learning, Planning, and Control in a Monolithic Neural Event Inference\n  Architecture", "comments": "This is the final revision submitted to the Neural Networks journal.\n  The revision mainly includes improvements in language, explanation, and\n  additional references and system relations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce REPRISE, a REtrospective and PRospective Inference SchEme, which\nlearns temporal event-predictive models of dynamical systems. REPRISE infers\nthe unobservable contextual event state and accompanying temporal predictive\nmodels that best explain the recently encountered sensorimotor experiences\nretrospectively. Meanwhile, it optimizes upcoming motor activities\nprospectively in a goal-directed manner. Here, REPRISE is implemented by a\nrecurrent neural network (RNN), which learns temporal forward models of the\nsensorimotor contingencies generated by different simulated dynamic vehicles.\nThe RNN is augmented with contextual neurons, which enable the encoding of\ndistinct, but related, sensorimotor dynamics as compact event codes. We show\nthat REPRISE concurrently learns to separate and approximate the encountered\nsensorimotor dynamics: it analyzes sensorimotor error signals adapting both\ninternal contextual neural activities and connection weight values. Moreover,\nwe show that REPRISE can exploit the learned model to induce goal-directed,\nmodel-predictive control, that is, approximate active inference: Given a goal\nstate, the system imagines a motor command sequence optimizing it with the\nprospective objective to minimize the distance to the goal. The RNN activities\nthus continuously imagine the upcoming future and reflect on the recent past,\noptimizing the predictive model, the hidden neural state activities, and the\nupcoming motor activities. As a result, event-predictive neural encodings\ndevelop, which allow the invocation of highly effective and adaptive\ngoal-directed sensorimotor control.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 21:25:13 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 14:30:59 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Butz", "Martin V.", ""], ["Bilkey", "David", ""], ["Humaidan", "Dania", ""], ["Knott", "Alistair", ""], ["Otte", "Sebastian", ""]]}, {"id": "1809.07424", "submitter": "Besmira Nushi", "authors": "Besmira Nushi, Ece Kamar, Eric Horvitz", "title": "Towards Accountable AI: Hybrid Human-Machine Analyses for Characterizing\n  System Failure", "comments": null, "journal-ref": "AAAI Conference on Human Computation and Crowdsourcing 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning systems move from computer-science laboratories into the\nopen world, their accountability becomes a high priority problem.\nAccountability requires deep understanding of system behavior and its failures.\nCurrent evaluation methods such as single-score error metrics and confusion\nmatrices provide aggregate views of system performance that hide important\nshortcomings. Understanding details about failures is important for identifying\npathways for refinement, communicating the reliability of systems in different\nsettings, and for specifying appropriate human oversight and engagement.\nCharacterization of failures and shortcomings is particularly complex for\nsystems composed of multiple machine learned components. For such systems,\nexisting evaluation methods have limited expressiveness in describing and\nexplaining the relationship among input content, the internal states of system\ncomponents, and final output quality. We present Pandora, a set of hybrid\nhuman-machine methods and tools for describing and explaining system failures.\nPandora leverages both human and system-generated observations to summarize\nconditions of system malfunction with respect to the input content and system\narchitecture. We share results of a case study with a machine learning pipeline\nfor image captioning that show how detailed performance views can be beneficial\nfor analysis and debugging.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 22:53:46 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Nushi", "Besmira", ""], ["Kamar", "Ece", ""], ["Horvitz", "Eric", ""]]}, {"id": "1809.07435", "submitter": "Kristopher De Asis", "authors": "Kristopher De Asis, Brendan Bennett, Richard S. Sutton", "title": "Predicting Periodicity with Temporal Difference Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal difference (TD) learning is an important approach in reinforcement\nlearning, as it combines ideas from dynamic programming and Monte Carlo methods\nin a way that allows for online and incremental model-free learning. A key idea\nof TD learning is that it is learning predictive knowledge about the\nenvironment in the form of value functions, from which it can derive its\nbehavior to address long-term sequential decision making problems. The agent's\nhorizon of interest, that is, how immediate or long-term a TD learning agent\npredicts into the future, is adjusted through a discount rate parameter. In\nthis paper, we introduce an alternative view on the discount rate, with insight\nfrom digital signal processing, to include complex-valued discounting. Our\nresults show that setting the discount rate to appropriately chosen complex\nnumbers allows for online and incremental estimation of the Discrete Fourier\nTransform (DFT) of a signal of interest with TD learning. We thereby extend the\ntypes of knowledge representable by value functions, which we show are\nparticularly useful for identifying periodic effects in the reward sequence.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 00:07:27 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["De Asis", "Kristopher", ""], ["Bennett", "Brendan", ""], ["Sutton", "Richard S.", ""]]}, {"id": "1809.07436", "submitter": "Chengsheng Mao", "authors": "Chengsheng Mao, Yiheng Pan, Zexian Zeng, Liang Yao, Yuan Luo", "title": "Deep Generative Classifiers for Thoracic Disease Diagnosis with Chest\n  X-ray Images", "comments": "BIBM 2018 accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thoracic diseases are very serious health problems that plague a large number\nof people. Chest X-ray is currently one of the most popular methods to diagnose\nthoracic diseases, playing an important role in the healthcare workflow.\nHowever, reading the chest X-ray images and giving an accurate diagnosis remain\nchallenging tasks for expert radiologists. With the success of deep learning in\ncomputer vision, a growing number of deep neural network architectures were\napplied to chest X-ray image classification. However, most of the previous deep\nneural network classifiers were based on deterministic architectures which are\nusually very noise-sensitive and are likely to aggravate the overfitting issue.\nIn this paper, to make a deep architecture more robust to noise and to reduce\noverfitting, we propose using deep generative classifiers to automatically\ndiagnose thorax diseases from the chest X-ray images. Unlike the traditional\ndeterministic classifier, a deep generative classifier has a distribution\nmiddle layer in the deep neural network. A sampling layer then draws a random\nsample from the distribution layer and input it to the following layer for\nclassification. The classifier is generative because the class label is\ngenerated from samples of a related distribution. Through training the model\nwith a certain amount of randomness, the deep generative classifiers are\nexpected to be robust to noise and can reduce overfitting and then achieve good\nperformances. We implemented our deep generative classifiers based on a number\nof well-known deterministic neural network architectures, and tested our models\non the chest X-ray14 dataset. The results demonstrated the superiority of deep\ngenerative classifiers compared with the corresponding deep deterministic\nclassifiers.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 00:13:50 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 18:41:48 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Mao", "Chengsheng", ""], ["Pan", "Yiheng", ""], ["Zeng", "Zexian", ""], ["Yao", "Liang", ""], ["Luo", "Yuan", ""]]}, {"id": "1809.07499", "submitter": "Joseph K J", "authors": "K J Joseph and Vineeth N Balasubramanian", "title": "MASON: A Model AgnoStic ObjectNess Framework", "comments": "Accepted at AutoNUE Workshop, 15th European Conference on Computer\n  Vision (ECCV), September 2018, Munich, Germany", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a simple, yet very effective method to localize dominant\nforeground objects in an image, to pixel-level precision. The proposed method\n'MASON' (Model-AgnoStic ObjectNess) uses a deep convolutional network to\ngenerate category-independent and model-agnostic heat maps for any image. The\nnetwork is not explicitly trained for the task, and hence, can be used\noff-the-shelf in tandem with any other network or task. We show that this\nframework scales to a wide variety of images, and illustrate the effectiveness\nof MASON in three varied application contexts.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 07:08:38 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Joseph", "K J", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "1809.07607", "submitter": "Shrinivasan Patnaikuni", "authors": "Shrinivasan R Patnaik Patnaikuni, Dr. Sachin R Gengaje", "title": "Syntactico-Semantic Reasoning using PCFG, MEBN & PP Attachment Ambiguity", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic context free grammars (PCFG) have been the core of the\nprobabilistic reasoning based parsers for several years especially in the\ncontext of the NLP. Multi entity bayesian networks (MEBN) a First Order Logic\nprobabilistic reasoning methodology is widely adopted and used method for\nuncertainty reasoning. Further upper ontology like Probabilistic Ontology Web\nLanguage (PR-OWL) built using MEBN takes care of probabilistic ontologies which\nmodel and capture the uncertainties inherent in the domain's semantic\ninformation. The paper attempts to establish a link between probabilistic\nreasoning in PCFG and MEBN by proposing a formal description of PCFG driven by\nMEBN leading to usage of PR-OWL modeled ontologies in PCFG parsers.\nFurthermore, the paper outlines an approach to resolve prepositional phrase\n(PP) attachment ambiguity using the proposed mapping between PCFG and MEBN.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 13:20:58 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 05:04:28 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Patnaikuni", "Shrinivasan R Patnaik", ""], ["Gengaje", "Dr. Sachin R", ""]]}, {"id": "1809.07614", "submitter": "Chaluka Salgado", "authors": "Chaluka Salgado (1), Muhammad Aamir Cheema (1), David Taniar (1) ((1)\n  Monash University, Clayton, Australia)", "title": "An Efficient Approximation Algorithm for Multi-criteria Indoor Route\n  Planning Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A route planning query has many real-world applications and has been studied\nextensively in outdoor spaces such as road networks or Euclidean space. Despite\nits many applications in indoor venues (e.g., shopping centres, libraries,\nairports), almost all existing studies are specifically designed for outdoor\nspaces and do not take into account unique properties of the indoor spaces such\nas hallways, stairs, escalators, rooms etc. We identify this research gap and\nformally define the problem of category aware multi-criteria route planning\nquery, denoted by CAM, which returns the optimal route from an indoor source\npoint to an indoor target point that passes through at least one indoor point\nfrom each given category while minimizing the total cost of the route in terms\nof travel distance and other relevant attributes. We show that CAM query is\nNP-hard. Based on a novel dominance-based pruning, we propose an efficient\nalgorithm which generates high-quality results. We provide an extensive\nexperimental study conducted on the largest shopping centre in Australia and\ncompare our algorithm with alternative approaches. The experiments demonstrate\nthat our algorithm is highly efficient and produces quality results.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 03:14:31 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Salgado", "Chaluka", ""], ["Cheema", "Muhammad Aamir", ""], ["Taniar", "David", ""]]}, {"id": "1809.07636", "submitter": "Hanqing Tian", "authors": "Hanqing Tian, Jun Ni, Jibin Hu", "title": "Autonomous Driving System Design for Formula Student Driverless Racecar", "comments": "The 2018 IEEE Intelligent Vehicles Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper summarizes the work of building the autonomous system including\ndetection system and path tracking controller for a formula student autonomous\nracecar. A LIDAR-vision cooperating method of detecting traffic cone which is\nused as track mark is proposed. Detection algorithm of the racecar also\nimplements a precise and high rate localization method which combines the\nGPS-INS data and LIDAR odometry. Besides, a track map including the location\nand color information of the cones is built simultaneously. Finally, the system\nand vehicle performance on a closed loop track is tested. This paper also\nbriefly introduces the Formula Student Autonomous Competition (FSAC) in 2017.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 14:58:43 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Tian", "Hanqing", ""], ["Ni", "Jun", ""], ["Hu", "Jibin", ""]]}, {"id": "1809.07656", "submitter": "Alexander Gorban", "authors": "A.N. Gorban, V.A. Makarov, I.Y. Tyukin", "title": "The unreasonable effectiveness of small neural ensembles in\n  high-dimensional brain", "comments": "Review paper, accepted in Physics of Life Reviews; minor corrections", "journal-ref": null, "doi": "10.1016/j.plrev.2018.09.005", "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the widely-spread consensus on the brain complexity, sprouts of the\nsingle neuron revolution emerged in neuroscience in the 1970s. They brought\nmany unexpected discoveries, including grandmother or concept cells and sparse\ncoding of information in the brain.\n  In machine learning for a long time, the famous curse of dimensionality\nseemed to be an unsolvable problem. Nevertheless, the idea of the blessing of\ndimensionality becomes gradually more and more popular. Ensembles of\nnon-interacting or weakly interacting simple units prove to be an effective\ntool for solving essentially multidimensional problems. This approach is\nespecially useful for one-shot (non-iterative) correction of errors in large\nlegacy artificial intelligence systems.\n  These simplicity revolutions in the era of complexity have deep fundamental\nreasons grounded in geometry of multidimensional data spaces. To explore and\nunderstand these reasons we revisit the background ideas of statistical\nphysics. In the course of the 20th century they were developed into the\nconcentration of measure theory. New stochastic separation theorems reveal the\nfine structure of the data clouds.\n  We review and analyse biological, physical, and mathematical problems at the\ncore of the fundamental question: how can high-dimensional brain organise\nreliable and fast learning in high-dimensional world of data by simple tools?\n  Two critical applications are reviewed to exemplify the approach: one-shot\ncorrection of errors in intellectual systems and emergence of static and\nassociative memories in ensembles of single neurons.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 14:53:11 GMT"}, {"version": "v2", "created": "Sat, 10 Nov 2018 10:57:11 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Gorban", "A. N.", ""], ["Makarov", "V. A.", ""], ["Tyukin", "I. Y.", ""]]}, {"id": "1809.07690", "submitter": "Weili Zhang", "authors": "Weili Zhang", "title": "Optimal flow analysis, prediction and application", "comments": "Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis employs statistical learning technique to analyze, predict and\nsolve the fixed charge network flow (FCNF) problem, which is common encountered\nin many real-world network problems. The cost structure for flows in the FCNF\ninvolves both fixed and variable costs. The FCNF problem is modeled mixed\nbinary linear programs and can be solved with standard commercial solvers,\nwhich use branch and bound algorithm. This problem is important for its widely\napplications and solving challenges. There does not exist a efficient algorithm\nto solve this problem optimally due to lacking tight bounds. To the best of our\nknowledge, this is the first work that employs statistical learning technique\nto analyze the optimal flow of the FCNF problem. Most algorithms developed to\nsolve the FCNF problem are based on the cost structure, relaxation, etc. We\nstart from the network characteristics and explore the relationship between\nproperties of nodes, arcs and networks and the optimal flow. This is a\nbi-direction approach and the findings can be used to locate the features that\naffect the optimal flow most significantly, predict the optimal arcs and\nprovide information to solve the FCNF problem. In particular, we define 33\nfeatures based on the network characteristics, from which using step wise\nregression, we identify 26 statistical significant predictors for logistic\nregression to predict which arcs will have positive flow in the optimal\nsolutions. The predictive model achieves 88% accuracy and the area under\nreceiver operating characteristic curve is 0.95. Two applications are\ninvestigated. Firstly, the predictive results can be used directly as component\ncritical index. The failure of arcs with higher critical index result in more\ncost increase over the entire network.\n", "versions": [{"version": "v1", "created": "Sat, 11 Aug 2018 05:57:04 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Zhang", "Weili", ""]]}, {"id": "1809.07695", "submitter": "Pedro Henrique da Costa Avelar", "authors": "Pedro H. C. Avelar and Henrique Lemos and Marcelo O. R. Prates and\n  Luis Lamb", "title": "Multitask Learning on Graph Neural Networks: Learning Multiple Graph\n  Centrality Measures with a Unified Network", "comments": "Published at ICANN2019. 10 pages, 3 Figures", "journal-ref": null, "doi": "10.1007/978-3-030-30493-5_63", "report-no": null, "categories": "cs.SI cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of deep learning to symbolic domains remains an active\nresearch endeavour. Graph neural networks (GNN), consisting of trained neural\nmodules which can be arranged in different topologies at run time, are sound\nalternatives to tackle relational problems which lend themselves to graph\nrepresentations. In this paper, we show that GNNs are capable of multitask\nlearning, which can be naturally enforced by training the model to refine a\nsingle set of multidimensional embeddings $\\in \\mathbb{R}^d$ and decode them\ninto multiple outputs by connecting MLPs at the end of the pipeline. We\ndemonstrate the multitask learning capability of the model in the relevant\nrelational problem of estimating network centrality measures, focusing\nprimarily on producing rankings based on these measures, i.e. is vertex $v_1$\nmore central than vertex $v_2$ given centrality $c$?. We then show that a GNN\ncan be trained to develop a \\emph{lingua franca} of vertex embeddings from\nwhich all relevant information about any of the trained centrality measures can\nbe decoded. The proposed model achieves $89\\%$ accuracy on a test dataset of\nrandom instances with up to 128 vertices and is shown to generalise to larger\nproblem sizes. The model is also shown to obtain reasonable accuracy on a\ndataset of real world instances with up to 4k vertices, vastly surpassing the\nsizes of the largest instances with which the model was trained ($n=128$).\nFinally, we believe that our contributions attest to the potential of GNNs in\nsymbolic domains in general and in relational learning in particular.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 12:01:37 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 13:04:48 GMT"}, {"version": "v3", "created": "Thu, 8 Nov 2018 17:56:26 GMT"}, {"version": "v4", "created": "Thu, 28 Nov 2019 18:39:30 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Avelar", "Pedro H. C.", ""], ["Lemos", "Henrique", ""], ["Prates", "Marcelo O. R.", ""], ["Lamb", "Luis", ""]]}, {"id": "1809.07731", "submitter": "A. Rupam Mahmood", "authors": "A. Rupam Mahmood, Dmytro Korenkevych, Gautham Vasan, William Ma, James\n  Bergstra", "title": "Benchmarking Reinforcement Learning Algorithms on Real-World Robots", "comments": "Appears in Proceedings of the Second Conference on Robot Learning\n  (CoRL 2018). Companion video at https://youtu.be/ovDfhvjpQd8 and source code\n  at https://github.com/kindredresearch/SenseAct", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through many recent successes in simulation, model-free reinforcement\nlearning has emerged as a promising approach to solving continuous control\nrobotic tasks. The research community is now able to reproduce, analyze and\nbuild quickly on these results due to open source implementations of learning\nalgorithms and simulated benchmark tasks. To carry forward these successes to\nreal-world applications, it is crucial to withhold utilizing the unique\nadvantages of simulations that do not transfer to the real world and experiment\ndirectly with physical robots. However, reinforcement learning research with\nphysical robots faces substantial resistance due to the lack of benchmark tasks\nand supporting source code. In this work, we introduce several reinforcement\nlearning tasks with multiple commercially available robots that present varying\nlevels of learning difficulty, setup, and repeatability. On these tasks, we\ntest the learning performance of off-the-shelf implementations of four\nreinforcement learning algorithms and analyze sensitivity to their\nhyper-parameters to determine their readiness for applications in various\nreal-world tasks. Our results show that with a careful setup of the task\ninterface and computations, some of these implementations can be readily\napplicable to physical robots. We find that state-of-the-art learning\nalgorithms are highly sensitive to their hyper-parameters and their relative\nordering does not transfer across tasks, indicating the necessity of re-tuning\nthem for each task for best performance. On the other hand, the best\nhyper-parameter configuration from one task may often result in effective\nlearning on held-out tasks even with different robots, providing a reasonable\ndefault. We make the benchmark tasks publicly available to enhance\nreproducibility in real-world reinforcement learning.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 16:46:04 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Mahmood", "A. Rupam", ""], ["Korenkevych", "Dmytro", ""], ["Vasan", "Gautham", ""], ["Ma", "William", ""], ["Bergstra", "James", ""]]}, {"id": "1809.07751", "submitter": "Brian Lucena", "authors": "Brian Lucena", "title": "Spline-Based Probability Calibration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many classification problems it is desirable to output well-calibrated\nprobabilities on the different classes. We propose a robust, non-parametric\nmethod of calibrating probabilities called SplineCalib that utilizes smoothing\nsplines to determine a calibration function. We demonstrate how applying\ncertain transformations as part of the calibration process can improve\nperformance on problems in deep learning and other domains where the scores\ntend to be \"overconfident\". We adapt the approach to multi-class problems and\nfind that better calibration can improve accuracy as well as log-loss by better\nresolving uncertain cases. Finally, we present a cross-validated approach to\ncalibration which conserves data. Significant improvements to log-loss and\naccuracy are shown on several different problems. We also introduce the\nml-insights python package which contains an implementation of the SplineCalib\nalgorithm.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 17:36:24 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Lucena", "Brian", ""]]}, {"id": "1809.07803", "submitter": "Axel Abels", "authors": "Axel Abels, Diederik M. Roijers, Tom Lenaerts, Ann Now\\'e, Denis\n  Steckelmacher", "title": "Dynamic Weights in Multi-Objective Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world decision problems are characterized by multiple conflicting\nobjectives which must be balanced based on their relative importance. In the\ndynamic weights setting the relative importance changes over time and\nspecialized algorithms that deal with such change, such as a tabular\nReinforcement Learning (RL) algorithm by Natarajan and Tadepalli (2005), are\nrequired. However, this earlier work is not feasible for RL settings that\nnecessitate the use of function approximators. We generalize across weight\nchanges and high-dimensional inputs by proposing a multi-objective Q-network\nwhose outputs are conditioned on the relative importance of objectives and we\nintroduce Diverse Experience Replay (DER) to counter the inherent\nnon-stationarity of the Dynamic Weights setting. We perform an extensive\nexperimental evaluation and compare our methods to adapted algorithms from Deep\nMulti-Task/Multi-Objective Reinforcement Learning and show that our proposed\nnetwork in combination with DER dominates these adapted algorithms across\nweight change scenarios and problem domains.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 18:52:15 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 14:51:55 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Abels", "Axel", ""], ["Roijers", "Diederik M.", ""], ["Lenaerts", "Tom", ""], ["Now\u00e9", "Ann", ""], ["Steckelmacher", "Denis", ""]]}, {"id": "1809.07806", "submitter": "Jayaraman J. Thiagarajan", "authors": "Jayaraman J. Thiagarajan, Deepta Rajan and Prasanna Sattigeri", "title": "Understanding Behavior of Clinical Models under Domain Shifts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hypothesis that computational models can be reliable enough to be adopted\nin prognosis and patient care is revolutionizing healthcare. Deep learning, in\nparticular, has been a game changer in building predictive models, thus leading\nto community-wide data curation efforts. However, due to inherent variabilities\nin population characteristics and biological systems, these models are often\nbiased to the training datasets. This can be limiting when models are deployed\nin new environments, when there are systematic domain shifts not known a\npriori. In this paper, we propose to emulate a large class of domain shifts,\nthat can occur in clinical settings, with a given dataset, and argue that\nevaluating the behavior of predictive models in light of those shifts is an\neffective way to quantify their reliability. More specifically, we develop an\napproach for building realistic scenarios, based on analysis of \\textit{disease\nlandscapes} in multi-label classification. Using the openly available MIMIC-III\nEHR dataset for phenotyping, for the first time, our work sheds light into data\nregimes where deep clinical models can fail to generalize. This work emphasizes\nthe need for novel validation mechanisms driven by real-world domain shifts in\nAI for healthcare.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 19:03:14 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 01:39:12 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Thiagarajan", "Jayaraman J.", ""], ["Rajan", "Deepta", ""], ["Sattigeri", "Prasanna", ""]]}, {"id": "1809.07842", "submitter": "Kirsten Lloyd", "authors": "Kirsten Lloyd", "title": "Bias Amplification in Artificial Intelligence Systems", "comments": "Presented at AAAI FSS-18: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As Artificial Intelligence (AI) technologies proliferate, concern has\ncentered around the long-term dangers of job loss or threats of machines\ncausing harm to humans. All of this concern, however, detracts from the more\npertinent and already existing threats posed by AI today: its ability to\namplify bias found in training datasets, and swiftly impact marginalized\npopulations at scale. Government and public sector institutions have a\nresponsibility to citizens to establish a dialogue with technology developers\nand release thoughtful policy around data standards to ensure diverse\nrepresentation in datasets to prevent bias amplification and ensure that AI\nsystems are built with inclusion in mind.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 20:29:56 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Lloyd", "Kirsten", ""]]}, {"id": "1809.07863", "submitter": "Juan Rodriguez-Aguilar", "authors": "Marc Pujol-Gonzalez, Jesus Cerquides, Pedro Meseguer, Juan A.\n  Rodriguez-Aguilar, Milind Tambe", "title": "Decentralized dynamic task allocation for UAVs with limited\n  communication range", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Limited-range Online Routing Problem (LORP), which involves a\nteam of Unmanned Aerial Vehicles (UAVs) with limited communication range that\nmust autonomously coordinate to service task requests. We first show a general\napproach to cast this dynamic problem as a sequence of decentralized task\nallocation problems. Then we present two solutions both based on modeling the\nallocation task as a Markov Random Field to subsequently assess decisions by\nmeans of the decentralized Max-Sum algorithm. Our first solution assumes\nindependence between requests, whereas our second solution also considers the\nUAVs' workloads. A thorough empirical evaluation shows that our workload-based\nsolution consistently outperforms current state-of-the-art methods in a wide\nrange of scenarios, lowering the average service time up to 16%. In the\nbest-case scenario there is no gap between our decentralized solution and\ncentralized techniques. In the worst-case scenario we manage to reduce by 25%\nthe gap between current decentralized and centralized techniques. Thus, our\nsolution becomes the method of choice for our problem.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 13:09:22 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Pujol-Gonzalez", "Marc", ""], ["Cerquides", "Jesus", ""], ["Meseguer", "Pedro", ""], ["Rodriguez-Aguilar", "Juan A.", ""], ["Tambe", "Milind", ""]]}, {"id": "1809.07878", "submitter": "Rohan Chitnis", "authors": "Rohan Chitnis, Leslie Pack Kaelbling, Tom\\'as Lozano-P\\'erez", "title": "Learning Quickly to Plan Quickly Using Modular Meta-Learning", "comments": "ICRA 2019 final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-object manipulation problems in continuous state and action spaces can\nbe solved by planners that search over sampled values for the continuous\nparameters of operators. The efficiency of these planners depends critically on\nthe effectiveness of the samplers used, but effective sampling in turn depends\non details of the robot, environment, and task. Our strategy is to learn\nfunctions called \"specializers\" that generate values for continuous operator\nparameters, given a state description and values for the discrete parameters.\nRather than trying to learn a single specializer for each operator from large\namounts of data on a single task, we take a modular meta-learning approach. We\ntrain on multiple tasks and learn a variety of specializers that, on a new\ntask, can be quickly adapted using relatively little data -- thus, our system\n\"learns quickly to plan quickly\" using these specializers. We validate our\napproach experimentally in simulated 3D pick-and-place tasks with continuous\nstate and action spaces. Visit http://tinyurl.com/chitnis-icra-19 for a\nsupplementary video.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 22:01:52 GMT"}, {"version": "v2", "created": "Sat, 16 Feb 2019 03:12:51 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Chitnis", "Rohan", ""], ["Kaelbling", "Leslie Pack", ""], ["Lozano-P\u00e9rez", "Tom\u00e1s", ""]]}, {"id": "1809.07882", "submitter": "Lance Kaplan", "authors": "Lance Kaplan, Federico Cerutti, Murat Sensoy, Alun Preece, Paul\n  Sullivan", "title": "Uncertainty Aware AI ML: Why and How", "comments": "Presented at AAAI FSS-18: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper argues the need for research to realize uncertainty-aware\nartificial intelligence and machine learning (AI\\&ML) systems for decision\nsupport by describing a number of motivating scenarios. Furthermore, the paper\ndefines uncertainty-awareness and lays out the challenges along with surveying\nsome promising research directions. A theoretical demonstration illustrates how\ntwo emerging uncertainty-aware ML and AI technologies could be integrated and\nbe of value for a route planning operation.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 22:15:06 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Kaplan", "Lance", ""], ["Cerutti", "Federico", ""], ["Sensoy", "Murat", ""], ["Preece", "Alun", ""], ["Sullivan", "Paul", ""]]}, {"id": "1809.07888", "submitter": "Federico Cerutti", "authors": "Federico Cerutti and Lance Kaplan and Angelika Kimmig and Murat Sensoy", "title": "Probabilistic Logic Programming with Beta-Distributed Random Variables", "comments": "Accepted for presentation at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We enable aProbLog---a probabilistic logical programming approach---to reason\nin presence of uncertain probabilities represented as Beta-distributed random\nvariables. We achieve the same performance of state-of-the-art algorithms for\nhighly specified and engineered domains, while simultaneously we maintain the\nflexibility offered by aProbLog in handling complex relational domains. Our\nmotivation is that faithfully capturing the distribution of probabilities is\nnecessary to compute an expected utility for effective decision making under\nuncertainty: unfortunately, these probability distributions can be highly\nuncertain due to sparse data. To understand and accurately manipulate such\nprobability distributions we need a well-defined theoretical framework that is\nprovided by the Beta distribution, which specifies a distribution of\nprobabilities representing all the possible values of a probability when the\nexact value is unknown.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 23:01:58 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 19:37:15 GMT"}, {"version": "v3", "created": "Thu, 15 Nov 2018 10:43:18 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Cerutti", "Federico", ""], ["Kaplan", "Lance", ""], ["Kimmig", "Angelika", ""], ["Sensoy", "Murat", ""]]}, {"id": "1809.07893", "submitter": "Trevor Davis", "authors": "Trevor Davis and Kevin Waugh and Michael Bowling", "title": "Solving Large Extensive-Form Games with Strategy Constraints", "comments": "Appeared in AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extensive-form games are a common model for multiagent interactions with\nimperfect information. In two-player zero-sum games, the typical solution\nconcept is a Nash equilibrium over the unconstrained strategy set for each\nplayer. In many situations, however, we would like to constrain the set of\npossible strategies. For example, constraints are a natural way to model\nlimited resources, risk mitigation, safety, consistency with past observations\nof behavior, or other secondary objectives for an agent. In small games,\noptimal strategies under linear constraints can be found by solving a linear\nprogram; however, state-of-the-art algorithms for solving large games cannot\nhandle general constraints. In this work we introduce a generalized form of\nCounterfactual Regret Minimization that provably finds optimal strategies under\nany feasible set of convex constraints. We demonstrate the effectiveness of our\nalgorithm for finding strategies that mitigate risk in security games, and for\nopponent modeling in poker games when given only partial observations of\nprivate information.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 23:50:05 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 20:57:43 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Davis", "Trevor", ""], ["Waugh", "Kevin", ""], ["Bowling", "Michael", ""]]}, {"id": "1809.07999", "submitter": "Kyungmin Kim", "authors": "Kyung-Min Kim, Seong-Ho Choi, Jin-Hwa Kim, Byoung-Tak Zhang", "title": "Multimodal Dual Attention Memory for Video Story Question Answering", "comments": "Accepted for ECCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a video story question-answering (QA) architecture, Multimodal\nDual Attention Memory (MDAM). The key idea is to use a dual attention mechanism\nwith late fusion. MDAM uses self-attention to learn the latent concepts in\nscene frames and captions. Given a question, MDAM uses the second attention\nover these latent concepts. Multimodal fusion is performed after the dual\nattention processes (late fusion). Using this processing pipeline, MDAM learns\nto infer a high-level vision-language joint representation from an abstraction\nof the full video content. We evaluate MDAM on PororoQA and MovieQA datasets\nwhich have large-scale QA annotations on cartoon videos and movies,\nrespectively. For both datasets, MDAM achieves new state-of-the-art results\nwith significant margins compared to the runner-up models. We confirm the best\nperformance of the dual attention mechanism combined with late fusion by\nablation studies. We also perform qualitative analysis by visualizing the\ninference mechanisms of MDAM.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 09:19:12 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Kim", "Kyung-Min", ""], ["Choi", "Seong-Ho", ""], ["Kim", "Jin-Hwa", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1809.08034", "submitter": "Jorge Fandinno", "authors": "Jorge Fandinno and Claudia Schulz", "title": "Answering the \"why\" in Answer Set Programming - A Survey of Explanation\n  Approaches", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) approaches to problem-solving and\ndecision-making are becoming more and more complex, leading to a decrease in\nthe understandability of solutions. The European Union's new General Data\nProtection Regulation tries to tackle this problem by stipulating a \"right to\nexplanation\" for decisions made by AI systems. One of the AI paradigms that may\nbe affected by this new regulation is Answer Set Programming (ASP). Thanks to\nthe emergence of efficient solvers, ASP has recently been used for\nproblem-solving in a variety of domains, including medicine, cryptography, and\nbiology. To ensure the successful application of ASP as a problem-solving\nparadigm in the future, explanations of ASP solutions are crucial. In this\nsurvey, we give an overview of approaches that provide an answer to the\nquestion of why an answer set is a solution to a given problem, notably\noff-line justifications, causal graphs, argumentative explanations and why-not\nprovenance, and highlight their similarities and differences. Moreover, we\nreview methods explaining why a set of literals is not an answer set or why no\nsolution exists at all.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 10:52:08 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Fandinno", "Jorge", ""], ["Schulz", "Claudia", ""]]}, {"id": "1809.08059", "submitter": "John Kingston", "authors": "John Kingston", "title": "Conducting Feasibility Studies for Knowledge Based Systems", "comments": "Presented at ES 2003, the annual conference of the BCS Specialist\n  Group on Artificial Intelligence, December 2003", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes how to carry out a feasibility study for a potential\nknowledge based system application. It discusses factors to be considered under\nthree headings: the business case, the technical feasibility, and stakeholder\nissues. It concludes with a case study of a feasibility study for a KBS to\nguide surgeons in diagnosis and treatment of thyroid conditions.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 12:29:27 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Kingston", "John", ""]]}, {"id": "1809.08097", "submitter": "Amar Prakash Azad", "authors": "Amar Prakash Azad, Dinesh Garg, Priyanka Agrawal, Arun Kumar", "title": "Deep Domain Adaptation under Deep Label Scarcity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal behind Domain Adaptation (DA) is to leverage the labeled examples\nfrom a source domain so as to infer an accurate model in a target domain where\nlabels are not available or in scarce at the best. A state-of-the-art approach\nfor the DA is due to (Ganin et al. 2016), known as DANN, where they attempt to\ninduce a common representation of source and target domains via adversarial\ntraining. This approach requires a large number of labeled examples from the\nsource domain to be able to infer a good model for the target domain. However,\nin many situations obtaining labels in the source domain is expensive which\nresults in deteriorated performance of DANN and limits its applicability in\nsuch scenarios. In this paper, we propose a novel approach to overcome this\nlimitation. In our work, we first establish that DANN reduces the original DA\nproblem into a semi-supervised learning problem over the space of common\nrepresentation. Next, we propose a learning approach, namely TransDANN, that\namalgamates adversarial learning and transductive learning to mitigate the\ndetrimental impact of limited source labels and yields improved performance.\nExperimental results (both on text and images) show a significant boost in the\nperformance of TransDANN over DANN under such scenarios. We also provide\ntheoretical justification for the performance boost.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 12:32:47 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Azad", "Amar Prakash", ""], ["Garg", "Dinesh", ""], ["Agrawal", "Priyanka", ""], ["Kumar", "Arun", ""]]}, {"id": "1809.08098", "submitter": "Shiqi Wang", "authors": "Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, Suman Jana", "title": "Efficient Formal Safety Analysis of Neural Networks", "comments": "Accepted to NIPS'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are increasingly deployed in real-world safety-critical\ndomains such as autonomous driving, aircraft collision avoidance, and malware\ndetection. However, these networks have been shown to often mispredict on\ninputs with minor adversarial or even accidental perturbations. Consequences of\nsuch errors can be disastrous and even potentially fatal as shown by the recent\nTesla autopilot crash. Thus, there is an urgent need for formal analysis\nsystems that can rigorously check neural networks for violations of different\nsafety properties such as robustness against adversarial perturbations within a\ncertain $L$-norm of a given image. An effective safety analysis system for a\nneural network must be able to either ensure that a safety property is\nsatisfied by the network or find a counterexample, i.e., an input for which the\nnetwork will violate the property. Unfortunately, most existing techniques for\nperforming such analysis struggle to scale beyond very small networks and the\nones that can scale to larger networks suffer from high false positives and\ncannot produce concrete counterexamples in case of a property violation. In\nthis paper, we present a new efficient approach for rigorously checking\ndifferent safety properties of neural networks that significantly outperforms\nexisting approaches by multiple orders of magnitude. Our approach can check\ndifferent safety properties and find concrete counterexamples for networks that\nare 10$\\times$ larger than the ones supported by existing analysis techniques.\nWe believe that our approach to estimating tight output bounds of a network for\na given input range can also help improve the explainability of neural networks\nand guide the training process of more robust neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 20:21:28 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 02:29:30 GMT"}, {"version": "v3", "created": "Wed, 7 Nov 2018 22:30:38 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Wang", "Shiqi", ""], ["Pei", "Kexin", ""], ["Whitehouse", "Justin", ""], ["Yang", "Junfeng", ""], ["Jana", "Suman", ""]]}, {"id": "1809.08101", "submitter": "Adeyinka K. Akanbi MR", "authors": "A. K. Akanbi, M. Masinde", "title": "Towards the Development of a Rule-based Drought Early Warning Expert\n  Systems using Indigenous Knowledge", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drought forecasting and prediction is a complicated process due to the\ncomplexity and scalability of the environmental parameters involved. Hence, it\nrequired a high level of expertise to predict. In this paper, we describe the\nresearch and development of a rule-based drought early warning expert systems\n(RB-DEWES) for forecasting drought using local indigenous knowledge obtained\nfrom domain experts. The system generates inference by using rule set and\nprovides drought advisory information with attributed certainty factor (CF)\nbased on the user's input. The system is believed to be the first expert system\nfor drought forecasting to use local indigenous knowledge on drought. The\narchitecture and components such as knowledge base, JESS inference engine and\nmodel base of the system and their functions are presented.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 20:22:28 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Akanbi", "A. K.", ""], ["Masinde", "M.", ""]]}, {"id": "1809.08113", "submitter": "Yong Zhang", "authors": "Yong Zhang, Yu Zhang, Zhao Zhang, Jie Bao, Yunpeng Song", "title": "Human activity recognition based on time series analysis using U-Net", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional human activity recognition (HAR) based on time series adopts\nsliding window analysis method. This method faces the multi-class window\nproblem which mistakenly labels different classes of sampling points within a\nwindow as a class. In this paper, a HAR algorithm based on U-Net is proposed to\nperform activity labeling and prediction at each sampling point. The activity\ndata of the triaxial accelerometer is mapped into an image with the single\npixel column and multi-channel which is input into the U-Net network for\ntraining and recognition. Our proposal can complete the pixel-level gesture\nrecognition function. The method does not need manual feature extraction and\ncan effectively identify short-term behaviors in long-term activity sequences.\nWe collected the Sanitation dataset and tested the proposed scheme with four\nopen data sets. The experimental results show that compared with Support Vector\nMachine (SVM), k-Nearest Neighbor (kNN), Decision Tree(DT), Quadratic\nDiscriminant Analysis (QDA), Convolutional Neural Network (CNN) and Fully\nConvolutional Networks (FCN) methods, our proposal has the highest accuracy and\nF1-socre in each dataset, and has stable performance and high robustness. At\nthe same time, after the U-Net has finished training, our proposal can achieve\nfast enough recognition speed.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 07:16:33 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Zhang", "Yong", ""], ["Zhang", "Yu", ""], ["Zhang", "Zhao", ""], ["Bao", "Jie", ""], ["Song", "Yunpeng", ""]]}, {"id": "1809.08208", "submitter": "Syed Yusha Kareem", "authors": "Syed Yusha Kareem, Luca Buoncompagni, Fulvio Mastrogiovanni", "title": "Arianna+: Scalable Human Activity Recognition by Reasoning with a\n  Network of Ontologies", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aging population ratios are rising significantly. Meanwhile, smart home based\nhealth monitoring services are evolving rapidly to become a viable alternative\nto traditional healthcare solutions. Such services can augment qualitative\nanalyses done by gerontologists with quantitative data. Hence, the recognition\nof Activities of Daily Living (ADL) has become an active domain of research in\nrecent times. For a system to perform human activity recognition in a\nreal-world environment, multiple requirements exist, such as scalability,\nrobustness, ability to deal with uncertainty (e.g., missing sensor data), to\noperate with multi-occupants and to take into account their privacy and\nsecurity. This paper attempts to address the requirements of scalability and\nrobustness, by describing a reasoning mechanism based on modular spatial and/or\ntemporal context models as a network of ontologies. The reasoning mechanism has\nbeen implemented in a smart home system referred to as Arianna+. The paper\npresents and discusses a use case, and experiments are performed on a simulated\ndataset, to showcase Arianna+'s modularity feature, internal working, and\ncomputational performance. Results indicate scalability and robustness for\nhuman activity recognition processes.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 17:00:56 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Kareem", "Syed Yusha", ""], ["Buoncompagni", "Luca", ""], ["Mastrogiovanni", "Fulvio", ""]]}, {"id": "1809.08291", "submitter": "Simon DeDeo", "authors": "Christina Boyce-Jacino and Simon DeDeo", "title": "Opacity, Obscurity, and the Geometry of Question-Asking", "comments": "24 pages, 7 tables, 4 figures. Comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI physics.soc-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asking questions is a pervasive human activity, but little is understood\nabout what makes them difficult to answer. An analysis of a pair of large\ndatabases, of New York Times crosswords and questions from the quiz-show\nJeopardy, establishes two orthogonal dimensions of question difficulty:\nobscurity (the rarity of the answer) and opacity (the indirectness of question\ncues, operationalized with word2vec). The importance of opacity, and the role\nof synergistic information in resolving it, suggests that accounts of\ndifficulty in terms of prior expectations captures only a part of the\nquestion-asking process. A further regression analysis shows the presence of\nadditional dimensions to question-asking: question complexity, the answer's\nlocal network density, cue intersection, and the presence of signal words. Our\nwork shows how question-askers can help their interlocutors by using contextual\ncues, or, conversely, how a particular kind of unfamiliarity with the domain in\nquestion can make it harder for individuals to learn from others. Taken\ntogether, these results suggest how Bayesian models of question difficulty can\nbe supplemented by process models and accounts of the heuristics individuals\nuse to navigate conceptual spaces.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 20:01:30 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Boyce-Jacino", "Christina", ""], ["DeDeo", "Simon", ""]]}, {"id": "1809.08304", "submitter": "Yuanlin Zhang", "authors": "Elias Marcopoulos and Yuanlin Zhang", "title": "onlineSPARC: a Programming Environment for Answer Set Programming", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in logic programming (e.g., the development of the Answer Set\nProgramming paradigm) has made it possible to teach it to general undergraduate\nand even middle/high school students. Given the limited exposure of these\nstudents to computer science, the complexity of downloading, installing and\nusing tools for writing logic programs could be a major barrier for logic\nprogramming to reach a much wider audience. We developed onlineSPARC, an online\nanswer set programming environment with a self contained file system and a\nsimple interface. It allows users to type/edit logic programs and perform\nseveral tasks over programs, including asking a query to a program, getting the\nanswer sets of a program, and producing a drawing/animation based on the answer\nsets of a program.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 20:38:17 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Marcopoulos", "Elias", ""], ["Zhang", "Yuanlin", ""]]}, {"id": "1809.08343", "submitter": "Nicholas Mattei", "authors": "Ritesh Noothigattu, Djallel Bouneffouf, Nicholas Mattei, Rachita\n  Chandra, Piyush Madan, Kush Varshney, Murray Campbell, Moninder Singh,\n  Francesca Rossi", "title": "Interpretable Multi-Objective Reinforcement Learning through Policy\n  Orchestration", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous cyber-physical agents and systems play an increasingly large role\nin our lives. To ensure that agents behave in ways aligned with the values of\nthe societies in which they operate, we must develop techniques that allow\nthese agents to not only maximize their reward in an environment, but also to\nlearn and follow the implicit constraints of society. These constraints and\nnorms can come from any number of sources including regulations, business\nprocess guidelines, laws, ethical principles, social norms, and moral values.\nWe detail a novel approach that uses inverse reinforcement learning to learn a\nset of unspecified constraints from demonstrations of the task, and\nreinforcement learning to learn to maximize the environment rewards. More\nprecisely, we assume that an agent can observe traces of behavior of members of\nthe society but has no access to the explicit set of constraints that give rise\nto the observed behavior. Inverse reinforcement learning is used to learn such\nconstraints, that are then combined with a possibly orthogonal value function\nthrough the use of a contextual bandit-based orchestrator that picks a\ncontextually-appropriate choice between the two policies (constraint-based and\nenvironment reward-based) when taking actions. The contextual bandit\norchestrator allows the agent to mix policies in novel ways, taking the best\nactions from either a reward maximizing or constrained policy. In addition, the\norchestrator is transparent on which policy is being employed at each time\nstep. We test our algorithms using a Pac-Man domain and show that the agent is\nable to learn to act optimally, act within the demonstrated constraints, and\nmix these two functions in complex ways.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 23:38:17 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Noothigattu", "Ritesh", ""], ["Bouneffouf", "Djallel", ""], ["Mattei", "Nicholas", ""], ["Chandra", "Rachita", ""], ["Madan", "Piyush", ""], ["Varshney", "Kush", ""], ["Campbell", "Murray", ""], ["Singh", "Moninder", ""], ["Rossi", "Francesca", ""]]}, {"id": "1809.08346", "submitter": "Amir Erfan Eshratifar", "authors": "Amir Erfan Eshratifar, Mohammad Saeed Abrishami, David Eigen, Massoud\n  Pedram", "title": "A Meta-Learning Approach for Custom Model Training", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer-learning and meta-learning are two effective methods to apply\nknowledge learned from large data sources to new tasks. In few-class, few-shot\ntarget task settings (i.e. when there are only a few classes and training\nexamples available in the target task), meta-learning approaches that optimize\nfor future task learning have outperformed the typical transfer approach of\ninitializing model weights from a pre-trained starting point. But as we\nexperimentally show, meta-learning algorithms that work well in the few-class\nsetting do not generalize well in many-shot and many-class cases. In this\npaper, we propose a joint training approach that combines both\ntransfer-learning and meta-learning. Benefiting from the advantages of each,\nour method obtains improved generalization performance on unseen target tasks\nin both few- and many-class and few- and many-shot scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 23:47:34 GMT"}, {"version": "v2", "created": "Fri, 8 Feb 2019 04:32:50 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Eshratifar", "Amir Erfan", ""], ["Abrishami", "Mohammad Saeed", ""], ["Eigen", "David", ""], ["Pedram", "Massoud", ""]]}, {"id": "1809.08350", "submitter": "Nicholas Mattei", "authors": "Andrea Loreggia, Nicholas Mattei, Francesca Rossi, K. Brent Venable", "title": "CPMetric: Deep Siamese Networks for Learning Distances Between\n  Structured Preferences", "comments": null, "journal-ref": "Artificial Intelligence. IJCAI 2019 International Workshops. IJCAI\n  2019. Lecture Notes in Computer Science, vol 12158. Springer, Cham", "doi": "10.1007/978-3-030-56150-5_11", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preference are central to decision making by both machines and humans.\nRepresenting, learning, and reasoning with preferences is an important area of\nstudy both within computer science and across the sciences. When working with\npreferences it is necessary to understand and compute the distance between sets\nof objects, e.g., the preferences of a user and a the descriptions of objects\nto be recommended. We present CPDist, a novel neural network to address the\nproblem of learning to measure the distance between structured preference\nrepresentations. We use the popular CP-net formalism to represent preferences\nand then leverage deep neural networks to learn a recently proposed metric\nfunction that is computationally hard to compute directly. CPDist is a novel\nmetric learning approach based on the use of deep siamese networks which learn\nthe Kendal Tau distance between partial orders that are induced by compact\npreference representations. We find that CPDist is able to learn the distance\nfunction with high accuracy and outperform existing approximation algorithms on\nboth the regression and classification task using less computation time.\nPerformance remains good even when CPDist is trained with only a small number\nof samples compared to the dimension of the solution space, indicating the\nnetwork generalizes well.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 23:56:53 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 19:47:20 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Loreggia", "Andrea", ""], ["Mattei", "Nicholas", ""], ["Rossi", "Francesca", ""], ["Venable", "K. Brent", ""]]}, {"id": "1809.08391", "submitter": "Ryota Natsume", "authors": "Ryota Natsume, Kazuki Inoue, Yoshihiro Fukuhara, Shintaro Yamamoto,\n  Shigeo Morishima, Hirokatsu Kataoka", "title": "Understanding Fake Faces", "comments": "11 pages, 3 figures, ECCV 2018 Workshop on Brain-Driven Computer\n  Vision (BDCV)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face recognition research is one of the most active topics in computer vision\n(CV), and deep neural networks (DNN) are now filling the gap between\nhuman-level and computer-driven performance levels in face verification\nalgorithms. However, although the performance gap appears to be narrowing in\nterms of accuracy-based expectations, a curious question has arisen;\nspecifically, \"Face understanding of AI is really close to that of human?\" In\nthe present study, in an effort to confirm the brain-driven concept, we conduct\nimage-based detection, classification, and generation using an in-house created\nfake face database. This database has two configurations: (i) false positive\nface detections produced using both the Viola Jones (VJ) method and\nconvolutional neural networks (CNN), and (ii) simulacra that have fundamental\ncharacteristics that resemble faces but are completely artificial. The results\nshow a level of suggestive knowledge that indicates the continuing existence of\na gap between the capabilities of recent vision-based face recognition\nalgorithms and human-level performance. On a positive note, however, we have\nobtained knowledge that will advance the progress of face-understanding models.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2018 06:42:34 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Natsume", "Ryota", ""], ["Inoue", "Kazuki", ""], ["Fukuhara", "Yoshihiro", ""], ["Yamamoto", "Shintaro", ""], ["Morishima", "Shigeo", ""], ["Kataoka", "Hirokatsu", ""]]}, {"id": "1809.08422", "submitter": "Jingchi Jiang", "authors": "Jingchi Jiang, Huanzheng Wang, Jing Xie, Xitong Guo, Yi Guan, Qiubin\n  Yu", "title": "Medical Knowledge Embedding Based on Recursive Neural Network for\n  Multi-Disease Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The representation of knowledge based on first-order logic captures the\nrichness of natural language and supports multiple probabilistic inference\nmodels. Although symbolic representation enables quantitative reasoning with\nstatistical probability, it is difficult to utilize with machine learning\nmodels as they perform numerical operations. In contrast, knowledge embedding\n(i.e., high-dimensional and continuous vectors) is a feasible approach to\ncomplex reasoning that can not only retain the semantic information of\nknowledge but also establish the quantifiable relationship among them. In this\npaper, we propose recursive neural knowledge network (RNKN), which combines\nmedical knowledge based on first-order logic with recursive neural network for\nmulti-disease diagnosis. After RNKN is efficiently trained from manually\nannotated Chinese Electronic Medical Records (CEMRs), diagnosis-oriented\nknowledge embeddings and weight matrixes are learned. Experimental results\nverify that the diagnostic accuracy of RNKN is superior to that of some\nclassical machine learning models and Markov logic network (MLN). The results\nalso demonstrate that the more explicit the evidence extracted from CEMRs is,\nthe better is the performance achieved. RNKN gradually exhibits the\ninterpretation of knowledge embeddings as the number of training epochs\nincreases.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2018 10:07:46 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Jiang", "Jingchi", ""], ["Wang", "Huanzheng", ""], ["Xie", "Jing", ""], ["Guo", "Xitong", ""], ["Guan", "Yi", ""], ["Yu", "Qiubin", ""]]}, {"id": "1809.08509", "submitter": "Biplav Srivastava", "authors": "Himadri Mishra, Ramashish Gaurav, Biplav Srivastava", "title": "A Train Status Assistant for Indian Railways", "comments": "2 pages, demonstration chatbot, learning, train delay", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trains are part-and-parcel of every day lives in countries with large,\ndiverse, multi-lingual population like India. Consequently, an assistant which\ncan accurately predict and explain train delays will help people and businesses\nalike. We present a novel conversation agent which can engage with people about\ntrain status and inform them about its delay at in-line stations. It is trained\non past delay data from a subset of trains and generalizes to others.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 01:48:50 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Mishra", "Himadri", ""], ["Gaurav", "Ramashish", ""], ["Srivastava", "Biplav", ""]]}, {"id": "1809.08546", "submitter": "Yongxiang Fan", "authors": "Yongxiang Fan, Hsien-Chung Lin, Te Tang, Masayoshi Tomizuka", "title": "A Learning Framework for Robust Bin Picking by Customized Grippers", "comments": "Submitted to 2019 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2019). arXiv admin note: text overlap with\n  arXiv:1803.11290", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Customized grippers have specifically designed fingers to increase the\ncontact area with the workpieces and improve the grasp robustness. However,\ngrasp planning for customized grippers is challenging due to the object\nvariations, surface contacts and structural constraints of the grippers. In\nthis paper, we propose a learning framework to plan robust grasps for\ncustomized grippers in real-time. The learning framework contains a low-level\noptimization-based planner to search for optimal grasps locally under object\nshape variations, and a high-level learning-based explorer to learn the grasp\nexploration based on previous grasp experience. The optimization-based planner\nuses an iterative surface fitting (ISF) to simultaneously search for optimal\ngripper transformation and finger displacement by minimizing the surface\nfitting error. The high-level learning-based explorer trains a region-based\nconvolutional neural network (R-CNN) to propose good optimization regions,\nwhich avoids ISF getting stuck in bad local optima and improves the collision\navoidance performance. The proposed learning framework with RCNN-ISF is able to\nconsider the structural constraints of the gripper, learn grasp exploration\nstrategy from previous experience, and plan optimal grasps in clutter\nenvironment in real-time. The effectiveness of the algorithm is verified by\nexperiments.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 07:08:19 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 04:29:44 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Fan", "Yongxiang", ""], ["Lin", "Hsien-Chung", ""], ["Tang", "Te", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1809.08548", "submitter": "Yongxiang Fan", "authors": "Yongxiang Fan and Jieliang Luo and Masayoshi Tomizuka", "title": "A Learning Framework for High Precision Industrial Assembly", "comments": "accepted by International Conference on Robotics and Automation\n  (ICRA2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic assembly has broad applications in industries. Traditional assembly\ntasks utilize predefined trajectories or tuned force control parameters, which\nmake the automatic assembly time-consuming, difficult to generalize, and not\nrobust to uncertainties. In this paper, we propose a learning framework for\nhigh precision industrial assembly. The framework combines both the supervised\nlearning and the reinforcement learning. The supervised learning utilizes\ntrajectory optimization to provide the initial guidance to the policy, while\nthe reinforcement learning utilizes actor-critic algorithm to establish the\nevaluation system even the supervisor is not accurate. The proposed learning\nframework is more efficient compared with the reinforcement learning and\nachieves better stability performance than the supervised learning. The\neffectiveness of the method is verified by both the simulation and experiment.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 07:08:35 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 04:17:10 GMT"}, {"version": "v3", "created": "Mon, 15 Apr 2019 23:50:18 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Fan", "Yongxiang", ""], ["Luo", "Jieliang", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1809.08568", "submitter": "Shoubo Hu", "authors": "Shoubo Hu, Zhitang Chen, Vahid Partovi Nia, Laiwan Chan, Yanhui Geng", "title": "Causal Inference and Mechanism Clustering of A Mixture of Additive Noise\n  Models", "comments": "Published at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inference of the causal relationship between a pair of observed variables\nis a fundamental problem in science, and most existing approaches are based on\none single causal model. In practice, however, observations are often collected\nfrom multiple sources with heterogeneous causal models due to certain\nuncontrollable factors, which renders causal analysis results obtained by a\nsingle model skeptical. In this paper, we generalize the Additive Noise Model\n(ANM) to a mixture model, which consists of a finite number of ANMs, and\nprovide the condition of its causal identifiability. To conduct model\nestimation, we propose Gaussian Process Partially Observable Model (GPPOM), and\nincorporate independence enforcement into it to learn latent parameter\nassociated with each observation. Causal inference and clustering according to\nthe underlying generating mechanisms of the mixture model are addressed in this\nwork. Experiments on synthetic and real data demonstrate the effectiveness of\nour proposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 09:57:14 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 18:11:35 GMT"}, {"version": "v3", "created": "Sun, 11 Nov 2018 13:04:29 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Hu", "Shoubo", ""], ["Chen", "Zhitang", ""], ["Nia", "Vahid Partovi", ""], ["Chan", "Laiwan", ""], ["Geng", "Yanhui", ""]]}, {"id": "1809.08585", "submitter": "Haruna Isah", "authors": "Tiffany Leung, Farhana Zulkernine, Haruna Isah", "title": "The use of Virtual Reality in Enhancing Interdisciplinary Research and\n  Education", "comments": "6 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Virtual Reality (VR) is increasingly being recognized for its educational\npotential and as an effective way to convey new knowledge to people, it\nsupports interactive and collaborative activities. Affordable VR powered by\nmobile technologies is opening a new world of opportunities that can transform\nthe ways in which we learn and engage with others. This paper reports our study\nregarding the application of VR in stimulating interdisciplinary communication.\nIt investigates the promises of VR in interdisciplinary education and research.\nThe main contributions of this study are (i) literature review of theories of\nlearning underlying the justification of the use of VR systems in education,\n(ii) taxonomy of the various types and implementations of VR systems and their\napplication in supporting education and research (iii) evaluation of\neducational applications of VR from a broad range of disciplines, (iv)\ninvestigation of how the learning process and learning outcomes are affected by\nVR systems, and (v) comparative analysis of VR and traditional methods of\nteaching in terms of quality of learning. This study seeks to inspire and\ninform interdisciplinary researchers and learners about the ways in which VR\nmight support them and also VR software developers to push the limits of their\ncraft.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 12:22:11 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Leung", "Tiffany", ""], ["Zulkernine", "Farhana", ""], ["Isah", "Haruna", ""]]}, {"id": "1809.08590", "submitter": "Kaiyu Chen", "authors": "Kaiyu Chen, Yihan Dong, Xipeng Qiu, Zitian Chen", "title": "Neural Arithmetic Expression Calculator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a pure neural solver for arithmetic expression\ncalculation (AEC) problem. Previous work utilizes the powerful capabilities of\ndeep neural networks and attempts to build an end-to-end model to solve this\nproblem. However, most of these methods can only deal with the additive\noperations. It is still a challenging problem to solve the complex expression\ncalculation problem, which includes the adding, subtracting, multiplying,\ndividing and bracketing operations. In this work, we regard the arithmetic\nexpression calculation as a hierarchical reinforcement learning problem. An\narithmetic operation is decomposed into a series of sub-tasks, and each\nsub-task is dealt with by a skill module. The skill module could be a basic\nmodule performing elementary operations, or interactive module performing\ncomplex operations by invoking other skill models. With curriculum learning,\nour model can deal with a complex arithmetic expression calculation with the\ndeep hierarchical structure of skill models. Experiments show that our model\nsignificantly outperforms the previous models for arithmetic expression\ncalculation.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 13:05:28 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Chen", "Kaiyu", ""], ["Dong", "Yihan", ""], ["Qiu", "Xipeng", ""], ["Chen", "Zitian", ""]]}, {"id": "1809.08626", "submitter": "Arash Mahyari", "authors": "Arash Golibagh Mahyari, Thomas Locker", "title": "Domain Adaptation for Robot Predictive Maintenance Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industrial robots play an increasingly important role in a growing number of\nfields. For example, robotics is used to increase productivity while reducing\ncosts in various aspects of manufacturing. Since robots are often set up in\nproduction lines, the breakdown of a single robot has a negative impact on the\nentire process, in the worst case bringing the whole line to a halt until the\nissue is resolved, leading to substantial financial losses due to the\nunforeseen downtime. Therefore, predictive maintenance systems based on the\ninternal signals of robots have gained attention as an essential component of\nrobotics service offerings. The main shortcoming of existing predictive\nmaintenance algorithms is that the extracted features typically differ\nsignificantly from the learnt model when the operation of the robot changes,\nincurring false alarms. In order to mitigate this problem, predictive\nmaintenance algorithms require the model to be retrained with normal data of\nthe new operation. In this paper, we propose a novel solution based on transfer\nlearning to pass the knowledge of the trained model from one operation to\nanother in order to prevent the need for retraining and to eliminate such false\nalarms. The deployment of the proposed unsupervised transfer learning algorithm\non real-world datasets demonstrates that the algorithm can not only distinguish\nbetween operation and mechanical condition change, it further yields a sharper\ndeviation from the trained model in case of a mechanical condition change and\nthus detects mechanical issues with higher confidence.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 16:29:29 GMT"}, {"version": "v2", "created": "Mon, 4 Mar 2019 15:44:18 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 19:37:38 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Mahyari", "Arash Golibagh", ""], ["Locker", "Thomas", ""]]}, {"id": "1809.08713", "submitter": "Sein Minn", "authors": "Sein Minn, Yi Yu, Michel C. Desmarais, Feida Zhu, Jill Jenn Vie", "title": "Deep Knowledge Tracing and Dynamic Student Classification for Knowledge\n  Tracing", "comments": "IEEE International Conference on Data Mining, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Intelligent Tutoring System (ITS), tracing the student's knowledge state\nduring learning has been studied for several decades in order to provide more\nsupportive learning instructions. In this paper, we propose a novel model for\nknowledge tracing that i) captures students' learning ability and dynamically\nassigns students into distinct groups with similar ability at regular time\nintervals, and ii) combines this information with a Recurrent Neural Network\narchitecture known as Deep Knowledge Tracing. Experimental results confirm that\nthe proposed model is significantly better at predicting student performance\nthan well known state-of-the-art techniques for student modelling.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 01:11:45 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 14:18:38 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Minn", "Sein", ""], ["Yu", "Yi", ""], ["Desmarais", "Michel C.", ""], ["Zhu", "Feida", ""], ["Vie", "Jill Jenn", ""]]}, {"id": "1809.08748", "submitter": "Kamran Zia Mr", "authors": "Kamran Zia, Nauman Javed, Muhammad Nadeem Sial, Sohail Ahmed, Hifsa\n  Iram, Asad Amir Pirzada", "title": "A Survey of Conventional and Artificial Intelligence / Learning based\n  Resource Allocation and Interference Mitigation Schemes in D2D Enabled\n  Networks", "comments": "Submitted in IEEE journal for Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  5th generation networks are envisioned to provide seamless and ubiquitous\nconnection to 1000-fold more devices and is believed to provide ultra-low\nlatency and higher data rates up to tens of Gbps. Different technologies\nenabling these requirements are being developed including mmWave\ncommunications, Massive MIMO and beamforming, Device to Device (D2D)\ncommunications and Heterogeneous Networks. D2D communication is a promising\ntechnology to enable applications requiring high bandwidth such as online\nstreaming and online gaming etc. It can also provide ultra- low latencies\nrequired for applications like vehicle to vehicle communication for autonomous\ndriving. D2D communication can provide higher data rates with high energy\nefficiency and spectral efficiency compared to conventional communication. The\nperformance benefits of D2D communication can be best achieved when D2D users\nreuses the spectrum being utilized by the conventional cellular users. This\nspectrum sharing in a multi-tier heterogeneous network will introduce complex\ninterference among D2D users and cellular users which needs to be resolved.\nMotivated by limited number of surveys for interference mitigation and resource\nallocation in D2D enabled heterogeneous networks, we have surveyed different\nconventional and artificial intelligence based interference mitigation and\nresource allocation schemes developed in recent years. Our contribution lies in\nthe analysis of conventional interference mitigation techniques and their\nshortcomings. Finally, the strengths of AI based techniques are determined and\nopen research challenges deduced from the recent research are presented.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 04:15:37 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Zia", "Kamran", ""], ["Javed", "Nauman", ""], ["Sial", "Muhammad Nadeem", ""], ["Ahmed", "Sohail", ""], ["Iram", "Hifsa", ""], ["Pirzada", "Asad Amir", ""]]}, {"id": "1809.08751", "submitter": "Frank Dignum", "authors": "Frank Dignum", "title": "Interactions as Social Practices: towards a formalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent models are a suitable starting point to model complex social\ninteractions. However, as the complexity of the systems increase, we argue that\nnovel modeling approaches are needed that can deal with inter-dependencies at\ndifferent levels of society, where many heterogeneous parties (software agents,\nrobots, humans) are interacting and reacting to each other. In this paper, we\npresent a formalization of a social framework for agents based in the concept\nof Social Practices as high level specifications of normal (expected) behavior\nin a given social context. We argue that social practices facilitate the\npractical reasoning of agents in standard social interactions.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 04:32:17 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Dignum", "Frank", ""]]}, {"id": "1809.08823", "submitter": "Douglas Summers Stay", "authors": "Douglas Summers-Stay, Peter Sutor, Dandan Li", "title": "Representing Sets as Summed Semantic Vectors", "comments": "In Biologically Inspired Cognitive Architectures 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representing meaning in the form of high dimensional vectors is a common and\npowerful tool in biologically inspired architectures. While the meaning of a\nset of concepts can be summarized by taking a (possibly weighted) sum of their\nassociated vectors, this has generally been treated as a one-way operation. In\nthis paper we show how a technique built to aid sparse vector decomposition\nallows in many cases the exact recovery of the inputs and weights to such a\nsum, allowing a single vector to represent an entire set of vectors from a\ndictionary. We characterize the number of vectors that can be recovered under\nvarious conditions, and explore several ways such a tool can be used for\nvector-based reasoning.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 09:55:37 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Summers-Stay", "Douglas", ""], ["Sutor", "Peter", ""], ["Li", "Dandan", ""]]}, {"id": "1809.08860", "submitter": "Seshadhri Srinivasan", "authors": "Mainak Dan and Seshadhri Srinivasan", "title": "A Comparative Study: Adaptive Fuzzy Inference Systems for Energy\n  Prediction in Urban Buildings", "comments": "5 pages, 2 figures, keyword: Short-term energy prediction, evolving\n  Takagi-Sugeno model, meta-cognitive fuzzy inference system, sequential\n  adaptive fuzzy inference system", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This investigation aims to study different adaptive fuzzy inference\nalgorithms capable of real-time sequential learning and prediction of\ntime-series data. A brief qualitative description of these algorithms namely\nmeta-cognitive fuzzy inference system (McFIS), sequential adaptive fuzzy\ninference system (SAFIS) and evolving Takagi-Sugeno (ETS) model provide a\ncomprehensive comparison of their working principle, especially their unique\ncharacteristics are discussed. These algorithms are then simulated with dataset\ncollected at one of the academic buildings at Nanyang Technological University,\nSingapore. The performance are compared by means of the root mean squared error\n(RMSE) and non-destructive error index (NDEI) of the predicted output. Analysis\nshows that McFIS shows promising results either with lower RMSE and NDEI or\nwith lower architectural complexity over ETS and SAFIS. Statistical Analysis\nalso reveals the significance of the outcome of these algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 12:00:37 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Dan", "Mainak", ""], ["Srinivasan", "Seshadhri", ""]]}, {"id": "1809.08885", "submitter": "Nilg\\\"un \\c{S}eng\\\"oz", "authors": "Tuncay Yigit, Utku Kose, Nilgun Sengoz", "title": "Robotics Rights and Ethics Rules", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is very important to adhere strictly to ethical and social influences when\ndelivering most of our life to artificial intelligence systems. With industry\n4.0, the internet of things, data analysis and automation have begun to be of\ngreat importance in our lives. With the Yapanese version of Industry 5.0, it\nhas come to our attention that machine-human interaction and human intelligence\nare working in harmony with the cognitive computer. In this context, robots\nworking on artificial intelligence algorithms co-ordinated with the development\nof technology have begun to enter our lives. But the consequences of the recent\ncomplaints of the Robots have been that important issues have arisen about how\nto be followed in terms of intellectual property and ethics. Although there are\nno laws regulating robots in our country at present, laws on robot ethics and\nrights abroad have entered into force. This means that it is important that we\norganize the necessary arrangements in the way that robots and artificial\nintelligence are so important in the new world order. In this study, it was\naimed to examine the existing rules of machine and robot ethics and to set an\nexample for the arrangements to be made in our country, and various discussions\nwere given in this context.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 13:02:09 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Yigit", "Tuncay", ""], ["Kose", "Utku", ""], ["Sengoz", "Nilgun", ""]]}, {"id": "1809.08887", "submitter": "Tao Yu", "authors": "Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan\n  Li, James Ma, Irene Li, Qingning Yao, Shanelle Roman, Zilin Zhang, Dragomir\n  Radev", "title": "Spider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain\n  Semantic Parsing and Text-to-SQL Task", "comments": "EMNLP 2018, Long Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Spider, a large-scale, complex and cross-domain semantic parsing\nand text-to-SQL dataset annotated by 11 college students. It consists of 10,181\nquestions and 5,693 unique complex SQL queries on 200 databases with multiple\ntables, covering 138 different domains. We define a new complex and\ncross-domain semantic parsing and text-to-SQL task where different complex SQL\nqueries and databases appear in train and test sets. In this way, the task\nrequires the model to generalize well to both new SQL queries and new database\nschemas. Spider is distinct from most of the previous semantic parsing tasks\nbecause they all use a single database and the exact same programs in the train\nset and the test set. We experiment with various state-of-the-art models and\nthe best model achieves only 12.4% exact matching accuracy on a database split\nsetting. This shows that Spider presents a strong challenge for future\nresearch. Our dataset and task are publicly available at\nhttps://yale-lily.github.io/spider\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 13:03:13 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2018 05:47:19 GMT"}, {"version": "v3", "created": "Mon, 8 Oct 2018 08:14:41 GMT"}, {"version": "v4", "created": "Thu, 25 Oct 2018 20:36:13 GMT"}, {"version": "v5", "created": "Sat, 2 Feb 2019 23:53:18 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Yu", "Tao", ""], ["Zhang", "Rui", ""], ["Yang", "Kai", ""], ["Yasunaga", "Michihiro", ""], ["Wang", "Dongxu", ""], ["Li", "Zifan", ""], ["Ma", "James", ""], ["Li", "Irene", ""], ["Yao", "Qingning", ""], ["Roman", "Shanelle", ""], ["Zhang", "Zilin", ""], ["Radev", "Dragomir", ""]]}, {"id": "1809.08923", "submitter": "Yue Wang", "authors": "Yue Wang, Qi Meng, Wei Cheng, Yuting Liug, Zhi-Ming Ma, Tie-Yan Liu", "title": "Target Transfer Q-Learning and Its Convergence Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Q-learning is one of the most popular methods in Reinforcement Learning (RL).\nTransfer Learning aims to utilize the learned knowledge from source tasks to\nhelp new tasks to improve the sample complexity of the new tasks. Considering\nthat data collection in RL is both more time and cost consuming and Q-learning\nconverges slowly comparing to supervised learning, different kinds of transfer\nRL algorithms are designed. However, most of them are heuristic with no\ntheoretical guarantee of the convergence rate. Therefore, it is important for\nus to clearly understand when and how will transfer learning help RL method and\nprovide the theoretical guarantee for the improvement of the sample complexity.\nIn this paper, we propose to transfer the Q-function learned in the source task\nto the target of the Q-learning in the new task when certain safe conditions\nare satisfied. We call this new transfer Q-learning method target transfer\nQ-Learning. The safe conditions are necessary to avoid the harm to the new\ntasks and thus ensure the convergence of the algorithm. We study the\nconvergence rate of the target transfer Q-learning. We prove that if the two\ntasks are similar with respect to the MDPs, the optimal Q-functions in the\nsource and new RL tasks are similar which means the error of the transferred\ntarget Q-function in new MDP is small. Also, the convergence rate analysis\nshows that the target transfer Q-Learning will converge faster than Q-learning\nif the error of the transferred target Q-function is smaller than the current\nQ-function in the new task. Based on our theoretical results, we design the\nsafe condition as the Bellman error of the transferred target Q-function is\nless than the current Q-function. Our experiments are consistent with our\ntheoretical founding and verified the effectiveness of our proposed target\ntransfer Q-learning method.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 05:31:26 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Wang", "Yue", ""], ["Meng", "Qi", ""], ["Cheng", "Wei", ""], ["Liug", "Yuting", ""], ["Ma", "Zhi-Ming", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1809.08925", "submitter": "Tu-Hoa Pham", "authors": "Tu-Hoa Pham, Giovanni De Magistris, Don Joven Agravante, Subhajit\n  Chaudhury, Asim Munawar, Ryuki Tachibana", "title": "Constrained Exploration and Recovery from Experience Shaping", "comments": "Code: https://github.com/IBM/constrained-rl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of reinforcement learning under safety requirements,\nin which an agent is trained to complete a given task, typically formalized as\nthe maximization of a reward signal over time, while concurrently avoiding\nundesirable actions or states, associated to lower rewards, or penalties. The\nconstruction and balancing of different reward components can be difficult in\nthe presence of multiple objectives, yet is crucial for producing a satisfying\npolicy. For example, in reaching a target while avoiding obstacles, low\ncollision penalties can lead to reckless movements while high penalties can\ndiscourage exploration. To circumvent this limitation, we examine the effect of\npast actions in terms of safety to estimate which are acceptable or should be\navoided in the future. We then actively reshape the action space of the agent\nduring reinforcement learning, so that reward-driven exploration is constrained\nwithin safety limits. We propose an algorithm enabling the learning of such\nsafety constraints in parallel with reinforcement learning and demonstrate its\neffectiveness in terms of both task completion and training time.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 06:11:11 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Pham", "Tu-Hoa", ""], ["De Magistris", "Giovanni", ""], ["Agravante", "Don Joven", ""], ["Chaudhury", "Subhajit", ""], ["Munawar", "Asim", ""], ["Tachibana", "Ryuki", ""]]}, {"id": "1809.08926", "submitter": "Yue Wang", "authors": "Yue Wang, Wei Chen, Yuting Liu, Zhi-Ming Ma, Tie-Yan Liu", "title": "Finite Sample Analysis of the GTD Policy Evaluation Algorithms in Markov\n  Setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning (RL) , one of the key components is policy\nevaluation, which aims to estimate the value function (i.e., expected long-term\naccumulated reward) of a policy. With a good policy evaluation method, the RL\nalgorithms will estimate the value function more accurately and find a better\npolicy. When the state space is large or continuous \\emph{Gradient-based\nTemporal Difference(GTD)} policy evaluation algorithms with linear function\napproximation are widely used. Considering that the collection of the\nevaluation data is both time and reward consuming, a clear understanding of the\nfinite sample performance of the policy evaluation algorithms is very important\nto reinforcement learning. Under the assumption that data are i.i.d. generated,\nprevious work provided the finite sample analysis of the GTD algorithms with\nconstant step size by converting them into convex-concave saddle point\nproblems. However, it is well-known that, the data are generated from Markov\nprocesses rather than i.i.d. in RL problems.. In this paper, in the realistic\nMarkov setting, we derive the finite sample bounds for the general\nconvex-concave saddle point problems, and hence for the GTD algorithms. We have\nthe following discussions based on our bounds. (1) With variants of step size,\nGTD algorithms converge. (2) The convergence rate is determined by the step\nsize, with the mixing time of the Markov process as the coefficient. The faster\nthe Markov processes mix, the faster the convergence. (3) We explain that the\nexperience replay trick is effective by improving the mixing property of the\nMarkov process. To the best of our knowledge, our analysis is the first to\nprovide finite sample bounds for the GTD algorithms in Markov setting.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 06:09:21 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Wang", "Yue", ""], ["Chen", "Wei", ""], ["Liu", "Yuting", ""], ["Ma", "Zhi-Ming", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1809.08927", "submitter": "Zixing Zhang", "authors": "Jing Han, Zixing Zhang, Nicholas Cummins, and Bj\\\"orn Schuller", "title": "Adversarial Training in Affective Computing and Sentiment Analysis:\n  Recent Advances and Perspectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years, adversarial training has become an extremely active\nresearch topic and has been successfully applied to various Artificial\nIntelligence (AI) domains. As a potentially crucial technique for the\ndevelopment of the next generation of emotional AI systems, we herein provide a\ncomprehensive overview of the application of adversarial training to affective\ncomputing and sentiment analysis. Various representative adversarial training\nalgorithms are explained and discussed accordingly, aimed at tackling diverse\nchallenges associated with emotional AI systems. Further, we highlight a range\nof potential future research directions. We expect that this overview will help\nfacilitate the development of adversarial training for affective computing and\nsentiment analysis in both the academic and industrial communities.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 08:27:01 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Han", "Jing", ""], ["Zhang", "Zixing", ""], ["Cummins", "Nicholas", ""], ["Schuller", "Bj\u00f6rn", ""]]}, {"id": "1809.08935", "submitter": "Georgios Balikas", "authors": "Georgios Balikas", "title": "Lexical Bias In Essay Level Prediction", "comments": "CAp 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically predicting the level of non-native English speakers given their\nwritten essays is an interesting machine learning problem. In this work I\npresent the system \"balikasg\" that achieved the state-of-the-art performance in\nthe CAp 2018 data science challenge among 14 systems. I detail the feature\nextraction, feature engineering and model selection steps and I evaluate how\nthese decisions impact the system's performance. The paper concludes with\nremarks for future work.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 12:04:44 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Balikas", "Georgios", ""]]}, {"id": "1809.08962", "submitter": "William L\\'echelle", "authors": "William L\\'echelle, Fabrizio Gotti, Philippe Langlais", "title": "WiRe57 : A Fine-Grained Benchmark for Open Information Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build a reference for the task of Open Information Extraction, on five\ndocuments. We tentatively resolve a number of issues that arise, including\ninference and granularity. We seek to better pinpoint the requirements for the\ntask. We produce our annotation guidelines specifying what is correct to\nextract and what is not. In turn, we use this reference to score existing Open\nIE systems. We address the non-trivial problem of evaluating the extractions\nproduced by systems against the reference tuples, and share our evaluation\nscript. Among seven compared extractors, we find the MinIE system to perform\nbest.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 14:19:59 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 04:53:05 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["L\u00e9chelle", "William", ""], ["Gotti", "Fabrizio", ""], ["Langlais", "Philippe", ""]]}, {"id": "1809.09060", "submitter": "Isidro Cortes-Ciriano PhD", "authors": "Isidro Cortes-Ciriano and Andreas Bender", "title": "Deep Confidence: A Computationally Efficient Framework for Calculating\n  Reliable Errors for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1021/acs.jcim.8b00542", "report-no": null, "categories": "cs.LG cs.AI q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning architectures have proved versatile in a number of drug\ndiscovery applications, including the modelling of in vitro compound activity.\nWhile controlling for prediction confidence is essential to increase the trust,\ninterpretability and usefulness of virtual screening models in drug discovery,\ntechniques to estimate the reliability of the predictions generated with deep\nlearning networks remain largely underexplored. Here, we present Deep\nConfidence, a framework to compute valid and efficient confidence intervals for\nindividual predictions using the deep learning technique Snapshot Ensembling\nand conformal prediction. Specifically, Deep Confidence generates an ensemble\nof deep neural networks by recording the network parameters throughout the\nlocal minima visited during the optimization phase of a single neural network.\nThis approach serves to derive a set of base learners (i.e., snapshots) with\ncomparable predictive power on average, that will however generate slightly\ndifferent predictions for a given instance. The variability across base\nlearners and the validation residuals are in turn harnessed to compute\nconfidence intervals using the conformal prediction framework. Using a set of\n24 diverse IC50 data sets from ChEMBL 23, we show that Snapshot Ensembles\nperform on par with Random Forest (RF) and ensembles of independently trained\ndeep neural networks. In addition, we find that the confidence regions\npredicted using the Deep Confidence framework span a narrower set of values.\nOverall, Deep Confidence represents a highly versatile error prediction\nframework that can be applied to any deep learning-based application at no\nextra computational cost.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 17:08:08 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Cortes-Ciriano", "Isidro", ""], ["Bender", "Andreas", ""]]}, {"id": "1809.09081", "submitter": "Mahardhika Pratama Dr", "authors": "Mahardhika Pratama, Andri Ashfahani, Yew Soon Ong, Savitha Ramasamy\n  and Edwin Lughofer", "title": "Autonomous Deep Learning: Incremental Learning of Denoising Autoencoder\n  for Evolving Data Streams", "comments": "have been submitted to AAAI 2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generative learning phase of Autoencoder (AE) and its successor Denosing\nAutoencoder (DAE) enhances the flexibility of data stream method in exploiting\nunlabelled samples. Nonetheless, the feasibility of DAE for data stream\nanalytic deserves in-depth study because it characterizes a fixed network\ncapacity which cannot adapt to rapidly changing environments. An automated\nconstruction of a denoising autoeconder, namely deep evolving denoising\nautoencoder (DEVDAN), is proposed in this paper. DEVDAN features an open\nstructure both in the generative phase and in the discriminative phase where\ninput features can be automatically added and discarded on the fly. A network\nsignificance (NS) method is formulated in this paper and is derived from the\nbias-variance concept. This method is capable of estimating the statistical\ncontribution of the network structure and its hidden units which precursors an\nideal state to add or prune input features. Furthermore, DEVDAN is free of the\nproblem- specific threshold and works fully in the single-pass learning\nfashion. The efficacy of DEVDAN is numerically validated using nine\nnon-stationary data stream problems simulated under the prequential\ntest-then-train protocol where DEVDAN is capable of delivering an improvement\nof classification accuracy to recently published online learning works while\nhaving flexibility in the automatic extraction of robust input features and in\nadapting to rapidly changing environments.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 17:49:09 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Pratama", "Mahardhika", ""], ["Ashfahani", "Andri", ""], ["Ong", "Yew Soon", ""], ["Ramasamy", "Savitha", ""], ["Lughofer", "Edwin", ""]]}, {"id": "1809.09095", "submitter": "Yang Yu", "authors": "Zhen-Jia Pang, Ruo-Ze Liu, Zhou-Yu Meng, Yi Zhang, Yang Yu, Tong Lu", "title": "On Reinforcement Learning for Full-length Game of StarCraft", "comments": "Appeared in AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  StarCraft II poses a grand challenge for reinforcement learning. The main\ndifficulties of it include huge state and action space and a long-time horizon.\nIn this paper, we investigate a hierarchical reinforcement learning approach\nfor StarCraft II. The hierarchy involves two levels of abstraction. One is the\nmacro-action automatically extracted from expert's trajectories, which reduces\nthe action space in an order of magnitude yet remains effective. The other is a\ntwo-layer hierarchical architecture which is modular and easy to scale,\nenabling a curriculum transferring from simpler tasks to more complex tasks.\nThe reinforcement training algorithm for this architecture is also\ninvestigated. On a 64x64 map and using restrictive units, we achieve a winning\nrate of more than 99\\% against the difficulty level-1 built-in AI. Through the\ncurriculum transfer learning algorithm and a mixture of combat model, we can\nachieve over 93\\% winning rate of Protoss against the most difficult\nnon-cheating built-in AI (level-7) of Terran, training within two days using a\nsingle machine with only 48 CPU cores and 8 K40 GPUs. It also shows strong\ngeneralization performance, when tested against never seen opponents including\ncheating levels built-in AI and all levels of Zerg and Protoss built-in AI. We\nhope this study could shed some light on the future research of large-scale\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 15:48:28 GMT"}, {"version": "v2", "created": "Sun, 3 Feb 2019 18:00:54 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Pang", "Zhen-Jia", ""], ["Liu", "Ruo-Ze", ""], ["Meng", "Zhou-Yu", ""], ["Zhang", "Yi", ""], ["Yu", "Yang", ""], ["Lu", "Tong", ""]]}, {"id": "1809.09147", "submitter": "Akshat Agarwal", "authors": "Akshat Agarwal, Abhinau Kumar V, Kyle Dunovan, Erik Peterson, Timothy\n  Verstynen, Katia Sycara", "title": "Better Safe than Sorry: Evidence Accumulation Allows for Safe\n  Reinforcement Learning", "comments": "8 pages, 3 figures. Code available at\n  https://github.com/agakshat/evidence-accumulation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the real world, agents often have to operate in situations with incomplete\ninformation, limited sensing capabilities, and inherently stochastic\nenvironments, making individual observations incomplete and unreliable.\nMoreover, in many situations it is preferable to delay a decision rather than\nrun the risk of making a bad decision. In such situations it is necessary to\naggregate information before taking an action; however, most state of the art\nreinforcement learning (RL) algorithms are biased towards taking actions\n\\textit{at every time step}, even if the agent is not particularly confident in\nits chosen action. This lack of caution can lead the agent to make critical\nmistakes, regardless of prior experience and acclimation to the environment.\nMotivated by theories of dynamic resolution of uncertainty during decision\nmaking in biological brains, we propose a simple accumulator module which\naccumulates evidence in favor of each possible decision, encodes uncertainty as\na dynamic competition between actions, and acts on the environment only when it\nis sufficiently confident in the chosen action. The agent makes no decision by\ndefault, and the burden of proof to make a decision falls on the policy to\naccrue evidence strongly in favor of a single decision. Our results show that\nthis accumulator module achieves near-optimal performance on a simple guessing\ngame, far outperforming deep recurrent networks using traditional, forced\naction selection policies.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 18:13:01 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Agarwal", "Akshat", ""], ["Kumar", "Abhinau", "V"], ["Dunovan", "Kyle", ""], ["Peterson", "Erik", ""], ["Verstynen", "Timothy", ""], ["Sycara", "Katia", ""]]}, {"id": "1809.09261", "submitter": "Aleksandra Faust", "authors": "Aleksandra Faust, James B. Aimone, Conrad D. James and Lydia Tapia", "title": "Resilient Computing with Reinforcement Learning on a Dynamical System:\n  Case Study in Sorting", "comments": "11 pages, accepted to CDC 2018. Here with additional evaluations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots and autonomous agents often complete goal-based tasks with limited\nresources, relying on imperfect models and sensor measurements. In particular,\nreinforcement learning (RL) and feedback control can be used to help a robot\nachieve a goal. Taking advantage of this body of work, this paper formulates\ngeneral computation as a feedback-control problem, which allows the agent to\nautonomously overcome some limitations of standard procedural language\nprogramming: resilience to errors and early program termination. Our\nformulation considers computation to be trajectory generation in the program's\nvariable space. The computing then becomes a sequential decision making\nproblem, solved with reinforcement learning (RL), and analyzed with Lyapunov\nstability theory to assess the agent's resilience and progression to the goal.\nWe do this through a case study on a quintessential computer science problem,\narray sorting. Evaluations show that our RL sorting agent makes steady progress\nto an asymptotically stable goal, is resilient to faulty components, and\nperforms less array manipulations than traditional Quicksort and Bubble sort.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 00:07:20 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Faust", "Aleksandra", ""], ["Aimone", "James B.", ""], ["James", "Conrad D.", ""], ["Tapia", "Lydia", ""]]}, {"id": "1809.09293", "submitter": "Vaneet Aggarwal", "authors": "Vaneet Aggarwal and Hamed Asadi and Mayank Gupta and Jae Joong Lee and\n  Denny Yu", "title": "Covfefe: A Computer Vision Approach For Estimating Force Exertion", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cumulative exposure to repetitive and forceful activities may lead to\nmusculoskeletal injuries which not only reduce workers' efficiency and\nproductivity, but also affect their quality of life. Thus, widely accessible\ntechniques for reliable detection of unsafe muscle force exertion levels for\nhuman activity is necessary for their well-being. However, measurement of force\nexertion levels is challenging and the existing techniques pose a great\nchallenge as they are either intrusive, interfere with human-machine interface,\nand/or subjective in the nature, thus are not scalable for all workers. In this\nwork, we use face videos and the photoplethysmography (PPG) signals to classify\nforce exertion levels of 0\\%, 50\\%, and 100\\% (representing rest, moderate\neffort, and high effort), thus providing a non-intrusive and scalable approach.\nEfficient feature extraction approaches have been investigated, including\nstandard deviation of the movement of different landmarks of the face,\ndistances between peaks and troughs in the PPG signals. We note that the PPG\nsignals can be obtained from the face videos, thus giving an efficient\nclassification algorithm for the force exertion levels using face videos. Based\non the data collected from 20 subjects, features extracted from the face videos\ngive 90\\% accuracy in classification among the 100\\% and the combination of 0\\%\nand 50\\% datasets. Further combining the PPG signals provide 81.7\\% accuracy.\nThe approach is also shown to be robust to the correctly identify force level\nwhen the person is talking, even though such datasets are not included in the\ntraining.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 02:45:19 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Aggarwal", "Vaneet", ""], ["Asadi", "Hamed", ""], ["Gupta", "Mayank", ""], ["Lee", "Jae Joong", ""], ["Yu", "Denny", ""]]}, {"id": "1809.09331", "submitter": "Hamidreza Alvari", "authors": "Hamidreza Alvari, Elham Shaabani, and Paulo Shakarian", "title": "Early Identification of Pathogenic Social Media Accounts", "comments": "IEEE Intelligence and Security Informatics (ISI) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pathogenic Social Media (PSM) accounts such as terrorist supporters exploit\nlarge communities of supporters for conducting attacks on social media. Early\ndetection of these accounts is crucial as they are high likely to be key users\nin making a harmful message \"viral\". In this paper, we make the first attempt\non utilizing causal inference to identify PSMs within a short time frame around\ntheir activity. We propose a time-decay causality metric and incorporate it\ninto a causal community detection-based algorithm. The proposed algorithm is\napplied to groups of accounts sharing similar causality features and is\nfollowed by a classification algorithm to classify accounts as PSM or not.\nUnlike existing techniques that take significant time to collect information\nsuch as network, cascade path, or content, our scheme relies solely on action\nlog of users. Results on a real-world dataset from Twitter demonstrate\neffectiveness and efficiency of our approach. We achieved precision of 0.84 for\ndetecting PSMs only based on their first 10 days of activity; the misclassified\naccounts were then detected 10 days later.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 06:10:51 GMT"}, {"version": "v2", "created": "Wed, 26 Sep 2018 04:11:21 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Alvari", "Hamidreza", ""], ["Shaabani", "Elham", ""], ["Shakarian", "Paulo", ""]]}, {"id": "1809.09332", "submitter": "Hongyao Tang", "authors": "Hongyao Tang, Jianye Hao, Tangjie Lv, Yingfeng Chen, Zongzhang Zhang,\n  Hangtian Jia, Chunxu Ren, Yan Zheng, Zhaopeng Meng, Changjie Fan, Li Wang", "title": "Hierarchical Deep Multiagent Reinforcement Learning with Temporal\n  Abstraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiagent reinforcement learning (MARL) is commonly considered to suffer\nfrom non-stationary environments and exponentially increasing policy space. It\nwould be even more challenging when rewards are sparse and delayed over long\ntrajectories. In this paper, we study hierarchical deep MARL in cooperative\nmultiagent problems with sparse and delayed reward. With temporal abstraction,\nwe decompose the problem into a hierarchy of different time scales and\ninvestigate how agents can learn high-level coordination based on the\nindependent skills learned at the low level. Three hierarchical deep MARL\narchitectures are proposed to learn hierarchical policies under different MARL\nparadigms. Besides, we propose a new experience replay mechanism to alleviate\nthe issue of the sparse transitions at the high level of abstraction and the\nnon-stationarity of multiagent learning. We empirically demonstrate the\neffectiveness of our approaches in two domains with extremely sparse feedback:\n(1) a variety of Multiagent Trash Collection tasks, and (2) a challenging\nonline mobile game, i.e., Fever Basketball Defense.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 06:19:22 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 11:00:01 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Tang", "Hongyao", ""], ["Hao", "Jianye", ""], ["Lv", "Tangjie", ""], ["Chen", "Yingfeng", ""], ["Zhang", "Zongzhang", ""], ["Jia", "Hangtian", ""], ["Ren", "Chunxu", ""], ["Zheng", "Yan", ""], ["Meng", "Zhaopeng", ""], ["Fan", "Changjie", ""], ["Wang", "Li", ""]]}, {"id": "1809.09337", "submitter": "Ruocheng Guo", "authors": "Ruocheng Guo, Lu Cheng, Jundong Li, P. Richard Hahn, Huan Liu", "title": "A Survey of Learning Causality with Data: Problems and Methods", "comments": "35 pages, accepted by ACM CSUR", "journal-ref": null, "doi": "10.1145/3397269", "report-no": null, "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work considers the question of how convenient access to copious data\nimpacts our ability to learn causal effects and relations. In what ways is\nlearning causality in the era of big data different from -- or the same as --\nthe traditional one? To answer this question, this survey provides a\ncomprehensive and structured review of both traditional and frontier methods in\nlearning causality and relations along with the connections between causality\nand machine learning. This work points out on a case-by-case basis how big data\nfacilitates, complicates, or motivates each approach.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 06:33:18 GMT"}, {"version": "v2", "created": "Wed, 26 Sep 2018 01:43:19 GMT"}, {"version": "v3", "created": "Fri, 19 Apr 2019 16:38:36 GMT"}, {"version": "v4", "created": "Tue, 5 May 2020 04:06:27 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Guo", "Ruocheng", ""], ["Cheng", "Lu", ""], ["Li", "Jundong", ""], ["Hahn", "P. Richard", ""], ["Liu", "Huan", ""]]}, {"id": "1809.09408", "submitter": "Shengbin Jia", "authors": "Shengbin Jia and Yang Xiang", "title": "Chinese User Service Intention Classification Based on Hybrid Neural\n  Network", "comments": "CMVIT2019", "journal-ref": null, "doi": "10.1088/1742-6596/1229/1/012054", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to satisfy the consumers' increasing personalized service demand,\nthe Intelligent service has arisen. User service intention recognition is an\nimportant challenge for intelligent service system to provide precise service.\nIt is difficult for the intelligent system to understand the semantics of user\ndemand which leads to poor recognition effect, because of the noise in user\nrequirement descriptions. Therefore, a hybrid neural network classification\nmodel based on BiLSTM and CNN is proposed to recognize users service\nintentions. The model can fuse the temporal semantics and spatial semantics of\nthe user descriptions. The experimental results show that our model achieves a\nbetter effect compared with other models, reaching 0.94 on the F1 score.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 10:56:20 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 08:53:05 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Jia", "Shengbin", ""], ["Xiang", "Yang", ""]]}, {"id": "1809.09414", "submitter": "Shengbin Jia", "authors": "Shengbin Jia and Yang Xiang and Xiaojun Chen", "title": "Triple Trustworthiness Measurement for Knowledge Graph", "comments": "This paper has been accepted by WWW 2019", "journal-ref": null, "doi": "10.1145/3308558.3313586", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Knowledge graph (KG) uses the triples to describe the facts in the real\nworld. It has been widely used in intelligent analysis and applications.\nHowever, possible noises and conflicts are inevitably introduced in the process\nof constructing. And the KG based tasks or applications assume that the\nknowledge in the KG is completely correct and inevitably bring about potential\ndeviations. In this paper, we establish a knowledge graph triple\ntrustworthiness measurement model that quantify their semantic correctness and\nthe true degree of the facts expressed. The model is a crisscrossing neural\nnetwork structure. It synthesizes the internal semantic information in the\ntriples and the global inference information of the KG to achieve the\ntrustworthiness measurement and fusion in the three levels of entity level,\nrelationship level, and KG global level. We analyzed the validity of the model\noutput confidence values, and conducted experiments in the real-world dataset\nFB15K (from Freebase) for the knowledge graph error detection task. The\nexperimental results showed that compared with other models, our model achieved\nsignificant and consistent improvements.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 11:37:27 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 06:21:40 GMT"}, {"version": "v3", "created": "Tue, 19 Feb 2019 07:57:27 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Jia", "Shengbin", ""], ["Xiang", "Yang", ""], ["Chen", "Xiaojun", ""]]}, {"id": "1809.09419", "submitter": "Matthew Guzdial", "authors": "Matthew Guzdial, Joshua Reno, Jonathan Chen, Gillian Smith, and Mark\n  Riedl", "title": "Explainable PCGML via Game Design Patterns", "comments": "8 pages, 3 figures, Fifth Experimental AI in Games Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Procedural content generation via Machine Learning (PCGML) is the umbrella\nterm for approaches that generate content for games via machine learning. One\nof the benefits of PCGML is that, unlike search or grammar-based PCG, it does\nnot require hand authoring of initial content or rules. Instead, PCGML relies\non existing content and black box models, which can be difficult to tune or\ntweak without expert knowledge. This is especially problematic when a human\ndesigner needs to understand how to manipulate their data or models to achieve\ndesired results. We present an approach to Explainable PCGML via Design\nPatterns in which the design patterns act as a vocabulary and mode of\ninteraction between user and model. We demonstrate that our technique\noutperforms non-explainable versions of our system in interactions with five\nexpert designers, four of whom lack any machine learning expertise.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 11:54:46 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Guzdial", "Matthew", ""], ["Reno", "Joshua", ""], ["Chen", "Jonathan", ""], ["Smith", "Gillian", ""], ["Riedl", "Mark", ""]]}, {"id": "1809.09420", "submitter": "Matthew Guzdial", "authors": "Matthew Guzdial, Nicholas Liao and Mark Riedl", "title": "Co-Creative Level Design via Machine Learning", "comments": "7 pages, 2 figures, Fifth Experimental AI in Games Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Procedural Level Generation via Machine Learning (PLGML), the study of\ngenerating game levels with machine learning, has received a large amount of\nrecent academic attention. For certain measures these approaches have shown\nsuccess at replicating the quality of existing game levels. However, it is\nunclear the extent to which they might benefit human designers. In this paper\nwe present a framework for co-creative level design with a PLGML agent. In\nsupport of this framework we present results from a user study and results from\na comparative study of PLGML approaches.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 11:56:52 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Guzdial", "Matthew", ""], ["Liao", "Nicholas", ""], ["Riedl", "Mark", ""]]}, {"id": "1809.09424", "submitter": "Matthew Guzdial", "authors": "Matthew Guzdial, Shukan Shah and Mark Riedl", "title": "Towards Automated Let's Play Commentary", "comments": "5 pages, 2 figures, Fifth Experimental AI in Games Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the problem of generating Let's Play-style commentary of\ngameplay video via machine learning. We propose an analysis of Let's Play\ncommentary and a framework for building such a system. To test this framework\nwe build an initial, naive implementation, which we use to interrogate the\nassumptions of the framework. We demonstrate promising results towards future\nLet's Play commentary generation.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 12:09:52 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Guzdial", "Matthew", ""], ["Shah", "Shukan", ""], ["Riedl", "Mark", ""]]}, {"id": "1809.09444", "submitter": "Iain Barclay", "authors": "Iain Barclay, Alun Preece, Ian Taylor", "title": "Defining the Collective Intelligence Supply Chain", "comments": "Presented at AAAI FSS-18: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Organisations are increasingly open to scrutiny, and need to be able to prove\nthat they operate in a fair and ethical way. Accountability should extend to\nthe production and use of the data and knowledge assets used in AI systems, as\nit would for any raw material or process used in production of physical goods.\nThis paper considers collective intelligence, comprising data and knowledge\ngenerated by crowd-sourced workforces, which can be used as core components of\nAI systems. A proposal is made for the development of a supply chain model for\ntracking the creation and use of crowdsourced collective intelligence assets,\nwith a blockchain based decentralised architecture identified as an appropriate\nmeans of providing validation, accountability and fairness.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 12:57:30 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Barclay", "Iain", ""], ["Preece", "Alun", ""], ["Taylor", "Ian", ""]]}, {"id": "1809.09468", "submitter": "S\\'ergio Pereira", "authors": "Sergio Pereira, Raphael Meier, Victor Alves, Mauricio Reyes and Carlos\n  A. Silva", "title": "Automatic brain tumor grading from MRI data using convolutional neural\n  networks and quality assessment", "comments": "Accepted and presented at iMIMIC - Workshop on Interpretability of\n  Machine Intelligence in Medical Image Computing", "journal-ref": null, "doi": "10.1007/978-3-030-02628-8", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Glioblastoma Multiforme is a high grade, very aggressive, brain tumor, with\npatients having a poor prognosis. Lower grade gliomas are less aggressive, but\nthey can evolve into higher grade tumors over time. Patient management and\ntreatment can vary considerably with tumor grade, ranging from tumor resection\nfollowed by a combined radio- and chemotherapy to a \"wait and see\" approach.\nHence, tumor grading is important for adequate treatment planning and\nmonitoring. The gold standard for tumor grading relies on histopathological\ndiagnosis of biopsy specimens. However, this procedure is invasive, time\nconsuming, and prone to sampling error. Given these disadvantages, automatic\ntumor grading from widely used MRI protocols would be clinically important, as\na way to expedite treatment planning and assessment of tumor evolution. In this\npaper, we propose to use Convolutional Neural Networks for predicting tumor\ngrade directly from imaging data. In this way, we overcome the need for expert\nannotations of regions of interest. We evaluate two prediction approaches: from\nthe whole brain, and from an automatically defined tumor region. Finally, we\nemploy interpretability methodologies as a quality assurance stage to check if\nthe method is using image regions indicative of tumor grade for classification.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 13:32:41 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Pereira", "Sergio", ""], ["Meier", "Raphael", ""], ["Alves", "Victor", ""], ["Reyes", "Mauricio", ""], ["Silva", "Carlos A.", ""]]}, {"id": "1809.09478", "submitter": "Yawei Luo", "authors": "Yawei Luo, Liang Zheng, Tao Guan, Junqing Yu, Yi Yang", "title": "Taking A Closer Look at Domain Shift: Category-level Adversaries for\n  Semantics Consistent Domain Adaptation", "comments": "CVPR2019 Oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We consider the problem of unsupervised domain adaptation in semantic\nsegmentation. The key in this campaign consists in reducing the domain shift,\ni.e., enforcing the data distributions of the two domains to be similar. A\npopular strategy is to align the marginal distribution in the feature space\nthrough adversarial learning. However, this global alignment strategy does not\nconsider the local category-level feature distribution. A possible consequence\nof the global movement is that some categories which are originally well\naligned between the source and target may be incorrectly mapped. To address\nthis problem, this paper introduces a category-level adversarial network,\naiming to enforce local semantic consistency during the trend of global\nalignment. Our idea is to take a close look at the category-level data\ndistribution and align each class with an adaptive adversarial loss.\nSpecifically, we reduce the weight of the adversarial loss for category-level\naligned features while increasing the adversarial force for those poorly\naligned. In this process, we decide how well a feature is category-level\naligned between source and target by a co-training approach. In two domain\nadaptation tasks, i.e., GTA5 -> Cityscapes and SYNTHIA -> Cityscapes, we\nvalidate that the proposed method matches the state of the art in segmentation\naccuracy.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 13:43:25 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2018 12:10:31 GMT"}, {"version": "v3", "created": "Mon, 1 Apr 2019 14:25:06 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Luo", "Yawei", ""], ["Zheng", "Liang", ""], ["Guan", "Tao", ""], ["Yu", "Junqing", ""], ["Yang", "Yi", ""]]}, {"id": "1809.09495", "submitter": "Jie Fan", "authors": "Jie Fan", "title": "A family of neighborhood contingency logics", "comments": "18 pages. arXiv admin note: substantial text overlap with\n  arXiv:1802.03516", "journal-ref": "Notre Dame J. Formal Logic 60, no. 4 (2019), 683-699", "doi": "10.1215/00294527-2019-0025", "report-no": null, "categories": "math.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes the axiomatizations of contingency logics of various\nnatural classes of neighborhood frames. In particular, by defining a suitable\ncanonical neighborhood function, we give sound and complete axiomatizations of\nmonotone contingency logic and regular contingency logic, thereby answering two\nopen questions raised by Bakhtiari, van Ditmarsch, and Hansen. The canonical\nfunction is inspired by a function proposed by Kuhn in~1995. We show that\nKuhn's function is actually equal to a related function originally given by\nHumberstone.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 02:21:46 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Fan", "Jie", ""]]}, {"id": "1809.09762", "submitter": "Rodrigo Canaan", "authors": "Rodrigo Canaan, Stefan Menzel, Julian Togelius and Andy Nealen", "title": "Towards Game-based Metrics for Computational Co-creativity", "comments": "IEEE Computational Intelligence and Games (CIG) conference, 2018,\n  Maastricht. 8 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the following question: what game-like interactive system would\nprovide a good environment for measuring the impact and success of a\nco-creative, cooperative agent? Creativity is often formulated in terms of\nnovelty, value, surprise and interestingness. We review how these concepts are\nmeasured in current computational intelligence research and provide a mapping\nfrom modern electronic and tabletop games to open research problems in\nmixed-initiative systems and computational co-creativity. We propose\napplication scenarios for future research, and a number of metrics under which\nthe performance of cooperative agents in these environments will be evaluated.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 00:05:47 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Canaan", "Rodrigo", ""], ["Menzel", "Stefan", ""], ["Togelius", "Julian", ""], ["Nealen", "Andy", ""]]}, {"id": "1809.09764", "submitter": "Rodrigo Canaan", "authors": "Rodrigo Canaan, Haotian Shen, Ruben Rodriguez Torrado, Julian\n  Togelius, Andy Nealen and Stefan Menzel", "title": "Evolving Agents for the Hanabi 2018 CIG Competition", "comments": "IEEE Computational Intelligence and Games (CIG) conference, 2018,\n  Maastricht. 8 pages, 1 figure, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hanabi is a cooperative card game with hidden information that has won\nimportant awards in the industry and received some recent academic attention. A\ntwo-track competition of agents for the game will take place in the 2018 CIG\nconference. In this paper, we develop a genetic algorithm that builds\nrule-based agents by determining the best sequence of rules from a fixed rule\nset to use as strategy. In three separate experiments, we remove human\nassumptions regarding the ordering of rules, add new, more expressive rules to\nthe rule set and independently evolve agents specialized at specific game\nsizes. As result, we achieve scores superior to previously published research\nfor the mirror and mixed evaluation of agents.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 00:12:03 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Canaan", "Rodrigo", ""], ["Shen", "Haotian", ""], ["Torrado", "Ruben Rodriguez", ""], ["Togelius", "Julian", ""], ["Nealen", "Andy", ""], ["Menzel", "Stefan", ""]]}, {"id": "1809.09810", "submitter": "Daniel Seita", "authors": "Daniel Seita, Nawid Jamali, Michael Laskey, Ajay Kumar Tanwani, Ron\n  Berenstein, Prakash Baskaran, Soshi Iba, John Canny, Ken Goldberg", "title": "Deep Transfer Learning of Pick Points on Fabric for Robot Bed-Making", "comments": "International Symposium on Robotics Research (ISRR) 2019. Expanded\n  and revised version of arXiv:1711.02525 as well as earlier versions here\n  under the title \"Robot Bed-Making: Deep Transfer Learning Using Depth Sensing\n  of Deformable Fabric\". Project website at\n  https://sites.google.com/view/bed-make", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental challenge in manipulating fabric for clothes folding and\ntextiles manufacturing is computing \"pick points\" to effectively modify the\nstate of an uncertain manifold. We present a supervised deep transfer learning\napproach to locate pick points using depth images for invariance to color and\ntexture. We consider the task of bed-making, where a robot sequentially grasps\nand pulls at pick points to increase blanket coverage. We perform physical\nexperiments with two mobile manipulator robots, the Toyota HSR and the Fetch,\nand three blankets of different colors and textures. We compare coverage\nresults from (1) human supervision, (2) a baseline of picking at the uppermost\nblanket point, and (3) learned pick points. On a quarter-scale twin bed, a\nmodel trained with combined data from the two robots achieves 92% blanket\ncoverage compared with 83% for the baseline and 95% for human supervisors. The\nmodel transfers to two novel blankets and achieves 93% coverage. Average\ncoverage results of 92% for 193 beds suggest that transfer-invariant robot pick\npoints on fabric can be effectively learned.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 05:09:55 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2018 03:39:45 GMT"}, {"version": "v3", "created": "Mon, 16 Sep 2019 22:26:01 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Seita", "Daniel", ""], ["Jamali", "Nawid", ""], ["Laskey", "Michael", ""], ["Tanwani", "Ajay Kumar", ""], ["Berenstein", "Ron", ""], ["Baskaran", "Prakash", ""], ["Iba", "Soshi", ""], ["Canny", "John", ""], ["Goldberg", "Ken", ""]]}, {"id": "1809.09876", "submitter": "Ozer Ozkahraman", "authors": "\\\"Ozer \\\"Ozkahraman and Petter \\\"Ogren", "title": "Underwater Caging and Capture for Autonomous Underwater Vehicles", "comments": "To be appear in: Proceedings of Global OCEANS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of caging and eventual capture of an\nunderwater entity using multiple Autonomous Underwater Vehicles (AUVs) in a 3D\nwater volume We solve this problem both with and without taking bathymetry into\naccount. Our proposed algorithm for range-limited sensing in 3D environments\ncaptures a finite-speed entity based on sparse and irregular observations.\nAfter an isolated initial sighting of the entity, the uncertainty of its\nwhereabouts grows while deployment of the AUV system is underway. To contain\nthe entity, an initial cage, or barrier of sensing footprints, is created\naround the initial sighting, using islands and other terrain as part of the\ncage if available. After the initial cage is established, the system waits for\na second sighting, and the possible opportunity to create a smaller, shrinkable\ncage. This process continues until at some point it is possible to create this\nsmaller cage, resulting in capture, meaning the entity is sensed directly and\ncontinuously. We present a set of algorithms for addressing the scenario above,\nand illustrate their performance on a set of examples. The proposed algorithm\nis a combination of solutions to the min-cut problem, the set cover problem,\nthe linear bottleneck assignment problem and the Thomson problem.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 09:51:20 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 15:53:52 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2020 09:27:06 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["\u00d6zkahraman", "\u00d6zer", ""], ["\u00d6gren", "Petter", ""]]}, {"id": "1809.09924", "submitter": "Bj\\\"orn Barz", "authors": "Bj\\\"orn Barz, Joachim Denzler", "title": "Hierarchy-based Image Embeddings for Semantic Image Retrieval", "comments": "Accepted at WACV 2019. Source code:\n  https://github.com/cvjena/semantic-embeddings", "journal-ref": "2019 IEEE Winter Conference on Applications of Computer Vision\n  (WACV), Waikoloa Village, HI, USA, 2019, pp. 638-647", "doi": "10.1109/WACV.2019.00073", "report-no": null, "categories": "cs.CV cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks trained for classification have been found to learn\npowerful image representations, which are also often used for other tasks such\nas comparing images w.r.t. their visual similarity. However, visual similarity\ndoes not imply semantic similarity. In order to learn semantically\ndiscriminative features, we propose to map images onto class embeddings whose\npair-wise dot products correspond to a measure of semantic similarity between\nclasses. Such an embedding does not only improve image retrieval results, but\ncould also facilitate integrating semantics for other tasks, e.g., novelty\ndetection or few-shot learning. We introduce a deterministic algorithm for\ncomputing the class centroids directly based on prior world-knowledge encoded\nin a hierarchy of classes such as WordNet. Experiments on CIFAR-100, NABirds,\nand ImageNet show that our learned semantic image embeddings improve the\nsemantic consistency of image retrieval results by a large margin.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 11:58:19 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2018 14:03:18 GMT"}, {"version": "v3", "created": "Wed, 21 Nov 2018 11:55:13 GMT"}, {"version": "v4", "created": "Tue, 19 Mar 2019 15:13:18 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Barz", "Bj\u00f6rn", ""], ["Denzler", "Joachim", ""]]}, {"id": "1809.09925", "submitter": "Yawei Luo", "authors": "Yawei Luo, Tao Guan, Junqing Yu, Ping Liu, Yi Yang", "title": "Every Node Counts: Self-Ensembling Graph Convolutional Networks for\n  Semi-Supervised Learning", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional network (GCN) provides a powerful means for graph-based\nsemi-supervised tasks. However, as a localized first-order approximation of\nspectral graph convolution, the classic GCN can not take full advantage of\nunlabeled data, especially when the unlabeled node is far from labeled ones. To\ncapitalize on the information from unlabeled nodes to boost the training for\nGCN, we propose a novel framework named Self-Ensembling GCN (SEGCN), which\nmarries GCN with Mean Teacher - another powerful model in semi-supervised\nlearning. SEGCN contains a student model and a teacher model. As a student, it\nnot only learns to correctly classify the labeled nodes, but also tries to be\nconsistent with the teacher on unlabeled nodes in more challenging situations,\nsuch as a high dropout rate and graph collapse. As a teacher, it averages the\nstudent model weights and generates more accurate predictions to lead the\nstudent. In such a mutual-promoting process, both labeled and unlabeled samples\ncan be fully utilized for backpropagating effective gradients to train GCN. In\nthree article classification tasks, i.e. Citeseer, Cora and Pubmed, we validate\nthat the proposed method matches the state of the arts in the classification\naccuracy.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 11:59:00 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Luo", "Yawei", ""], ["Guan", "Tao", ""], ["Yu", "Junqing", ""], ["Liu", "Ping", ""], ["Yang", "Yi", ""]]}, {"id": "1809.10007", "submitter": "Nicolas Anastassacos", "authors": "Nicolas Anastassacos, Mirco Musolesi", "title": "Learning through Probing: a decentralized reinforcement learning\n  architecture for social dilemmas", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent reinforcement learning has received significant interest in\nrecent years notably due to the advancements made in deep reinforcement\nlearning which have allowed for the developments of new architectures and\nlearning algorithms. Using social dilemmas as the training ground, we present a\nnovel learning architecture, Learning through Probing (LTP), where agents\nutilize a probing mechanism to incorporate how their opponent's behavior\nchanges when an agent takes an action. We use distinct training phases and\nadjust rewards according to the overall outcome of the experiences accounting\nfor changes to the opponents behavior. We introduce a parameter eta to\ndetermine the significance of these future changes to opponent behavior. When\napplied to the Iterated Prisoner's Dilemma (IPD), LTP agents demonstrate that\nthey can learn to cooperate with each other, achieving higher average\ncumulative rewards than other reinforcement learning methods while also\nmaintaining good performance in playing against static agents that are present\nin Axelrod tournaments. We compare this method with traditional reinforcement\nlearning algorithms and agent-tracking techniques to highlight key differences\nand potential applications. We also draw attention to the differences between\nsolving games and societal-like interactions and analyze the training of\nQ-learning agents in makeshift societies. This is to emphasize how cooperation\nmay emerge in societies and demonstrate this using environments where\ninteractions with opponents are determined through a random encounter format of\nthe IPD.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 14:10:13 GMT"}, {"version": "v2", "created": "Sat, 22 Dec 2018 13:49:32 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Anastassacos", "Nicolas", ""], ["Musolesi", "Mirco", ""]]}, {"id": "1809.10036", "submitter": "Dinesh Verma", "authors": "Dinesh Verma, Simon Julier, Greg Cirincione", "title": "Federated AI for building AI Solutions across Multiple Agencies", "comments": "Presented at AAAI FSS-18: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The different sets of regulations existing for differ-ent agencies within the\ngovernment make the task of creating AI enabled solutions in government\ndif-ficult. Regulatory restrictions inhibit sharing of da-ta across different\nagencies, which could be a significant impediment to training AI models. We\ndiscuss the challenges that exist in environments where data cannot be freely\nshared and assess tech-nologies which can be used to work around these\nchallenges. We present results on building AI models using the concept of\nfederated AI, which al-lows creation of models without moving the training data\naround.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 02:26:38 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Verma", "Dinesh", ""], ["Julier", "Simon", ""], ["Cirincione", "Greg", ""]]}, {"id": "1809.10049", "submitter": "Rohan Varma A", "authors": "Rohan Varma, Jelena Kova\\v{c}evi\\'c", "title": "Sampling Theory for Graph Signals on Product Graphs", "comments": "Accepted to GlobalSIP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we extend the sampling theory on graphs by constructing a\nframework that exploits the structure in product graphs for efficient sampling\nand recovery of bandlimited graph signals that lie on them. Product graphs are\ngraphs that are composed from smaller graph atoms; we motivate how this model\nis a flexible and useful way to model richer classes of data that can be\nmulti-modal in nature. Previous works have established a sampling theory on\ngraphs for bandlimited signals. Importantly, the framework achieves significant\nsavings in both sample complexity and computational complexity\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 15:08:08 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Varma", "Rohan", ""], ["Kova\u010devi\u0107", "Jelena", ""]]}, {"id": "1809.10054", "submitter": "Lidia Contreras-Ochando", "authors": "Lidia Contreras-Ochando, C\\'esar Ferri, Jos\\'e Hern\\'andez-Orallo,\n  Fernando Mart\\'inez-Plumed, Mar\\'ia Jos\\'e Ram\\'irez-Quintana, Susumu\n  Katayama", "title": "General-purpose Declarative Inductive Programming with Domain-Specific\n  Background Knowledge for Data Wrangling Automation", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given one or two examples, humans are good at understanding how to solve a\nproblem independently of its domain, because they are able to detect what the\nproblem is and to choose the appropriate background knowledge according to the\ncontext. For instance, presented with the string \"8/17/2017\" to be transformed\nto \"17th of August of 2017\", humans will process this in two steps: (1) they\nrecognise that it is a date and (2) they map the date to the 17th of August of\n2017. Inductive Programming (IP) aims at learning declarative (functional or\nlogic) programs from examples. Two key advantages of IP are the use of\nbackground knowledge and the ability to synthesise programs from a few\ninput/output examples (as humans do). In this paper we propose to use IP as a\nmeans for automating repetitive data manipulation tasks, frequently presented\nduring the process of {\\em data wrangling} in many data manipulation problems.\nHere we show that with the use of general-purpose declarative (programming)\nlanguages jointly with generic IP systems and the definition of domain-specific\nknowledge, many specific data wrangling problems from different application\ndomains can be automatically solved from very few examples. We also propose an\nintegrated benchmark for data wrangling, which we share publicly for the\ncommunity.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 15:12:14 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Contreras-Ochando", "Lidia", ""], ["Ferri", "C\u00e9sar", ""], ["Hern\u00e1ndez-Orallo", "Jos\u00e9", ""], ["Mart\u00ednez-Plumed", "Fernando", ""], ["Ram\u00edrez-Quintana", "Mar\u00eda Jos\u00e9", ""], ["Katayama", "Susumu", ""]]}, {"id": "1809.10093", "submitter": "Pooya Abolghasemi", "authors": "Pooya Abolghasemi, Amir Mazaheri, Mubarak Shah and Ladislau B\\\"ol\\\"oni", "title": "Pay attention! - Robustifying a Deep Visuomotor Policy through\n  Task-Focused Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several recent studies have demonstrated the promise of deep visuomotor\npolicies for robot manipulator control. Despite impressive progress, these\nsystems are known to be vulnerable to physical disturbances, such as accidental\nor adversarial bumps that make them drop the manipulated object. They also tend\nto be distracted by visual disturbances such as objects moving in the robot's\nfield of view, even if the disturbance does not physically prevent the\nexecution of the task. In this paper, we propose an approach for augmenting a\ndeep visuomotor policy trained through demonstrations with Task Focused visual\nAttention (TFA). The manipulation task is specified with a natural language\ntext such as `move the red bowl to the left'. This allows the visual attention\ncomponent to concentrate on the current object that the robot needs to\nmanipulate. We show that even in benign environments, the TFA allows the policy\nto consistently outperform a variant with no attention mechanism. More\nimportantly, the new policy is significantly more robust: it regularly recovers\nfrom severe physical disturbances (such as bumps causing it to drop the object)\nfrom which the baseline policy, i.e. with no visual attention, almost never\nrecovers. In addition, we show that the proposed policy performs correctly in\nthe presence of a wide class of visual disturbances, exhibiting a behavior\nreminiscent of human selective visual attention experiments. Our proposed\napproach consists of a VAE-GAN network which encodes the visual input and feeds\nit to a Motor network that moves the robot joints. Also, our approach benefits\nfrom a teacher network for the TFA that leverages textual input command to\nrobustify the visual encoder against various types of disturbances.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 16:06:34 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 23:54:47 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Abolghasemi", "Pooya", ""], ["Mazaheri", "Amir", ""], ["Shah", "Mubarak", ""], ["B\u00f6l\u00f6ni", "Ladislau", ""]]}, {"id": "1809.10108", "submitter": "Tiantian Li", "authors": "Tiantian Li, Bo Wang, Min Zhou, Junzo Watada", "title": "Short-term load forecasting using optimized LSTM networks based on EMD", "comments": "16 pages,11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short-term load forecasting is one of the crucial sections in smart grid.\nPrecise forecasting enables system operators to make reliable unit commitment\nand power dispatching decisions. With the advent of big data, a number of\nartificial intelligence techniques such as back propagation, support vector\nmachine have been used to predict the load of the next day. Nevertheless, due\nto the noise of raw data and the randomness of power load, forecasting errors\nof existing approaches are relatively large. In this study, a short-term load\nforecasting method is proposed on the basis of empirical mode decomposition and\nlong short-term memory networks, the parameters of which are optimized by a\nparticle swarm optimization algorithm. Essentially, empirical mode\ndecomposition can decompose the original time series of historical data into\nrelatively stationary components and long short-term memory network is able to\nemphasize as well as model the timing of data, the joint use of which is\nexpected to effectively apply the characteristics of data itself, so as to\nimprove the predictive accuracy. The effectiveness of this research is\nexemplified on a realistic data set, the experimental results of which show\nthat the proposed method has higher forecasting accuracy and applicability, as\ncompared with existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 08:26:25 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Li", "Tiantian", ""], ["Wang", "Bo", ""], ["Zhou", "Min", ""], ["Watada", "Junzo", ""]]}, {"id": "1809.10124", "submitter": "Aleksandra Faust", "authors": "Hao-Tien Lewis Chiang, Aleksandra Faust, Marek Fiser, Anthony Francis", "title": "Learning Navigation Behaviors End-to-End with AutoRL", "comments": "Accepted to RA-L/ICRA 2019. Chiang and Faust contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We learn end-to-end point-to-point and path-following navigation behaviors\nthat avoid moving obstacles. These policies receive noisy lidar observations\nand output robot linear and angular velocities. The policies are trained in\nsmall, static environments with AutoRL, an evolutionary automation layer around\nReinforcement Learning (RL) that searches for a deep RL reward and neural\nnetwork architecture with large-scale hyper-parameter optimization. AutoRL\nfirst finds a reward that maximizes task completion, and then finds a neural\nnetwork architecture that maximizes the cumulative of the found reward.\nEmpirical evaluations, both in simulation and on-robot, show that AutoRL\npolicies do not suffer from the catastrophic forgetfulness that plagues many\nother deep reinforcement learning algorithms, generalize to new environments\nand moving obstacles, are robust to sensor, actuator, and localization noise,\nand can serve as robust building blocks for larger navigation tasks. Our\npath-following and point-to-point policies are respectively 23% and 26% more\nsuccessful than comparison methods across new environments. Video at:\nhttps://youtu.be/0UwkjpUEcbI\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 17:09:56 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 23:31:47 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Chiang", "Hao-Tien Lewis", ""], ["Faust", "Aleksandra", ""], ["Fiser", "Marek", ""], ["Francis", "Anthony", ""]]}, {"id": "1809.10141", "submitter": "Maxime Petit", "authors": "Maxime Petit (imagine), Amaury Depierre (imagine), Xiaofang Wang\n  (imagine), Emmanuel Dellandr\\'ea (LIRIS), Liming Chen (imagine)", "title": "Developmental Bayesian Optimization of Black-Box with Visual\n  Similarity-Based Transfer Learning", "comments": null, "journal-ref": "IEEE International Conference on Development and Learning and\n  Epigenetic Robotics (ICDL-EpiRob), Sep 2018, Tokyo, Japan. 2018", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a developmental framework based on a long-term memory and\nreasoning mechanisms (Vision Similarity and Bayesian Optimisation). This\narchitecture allows a robot to optimize autonomously hyper-parameters that need\nto be tuned from any action and/or vision module, treated as a black-box. The\nlearning can take advantage of past experiences (stored in the episodic and\nprocedural memories) in order to warm-start the exploration using a set of\nhyper-parameters previously optimized from objects similar to the new unknown\none (stored in a semantic memory). As example, the system has been used to\noptimized 9 continuous hyper-parameters of a professional software (Kamido)\nboth in simulation and with a real robot (industrial robotic arm Fanuc) with a\ntotal of 13 different objects. The robot is able to find a good object-specific\noptimization in 68 (simulation) or 40 (real) trials. In simulation, we\ndemonstrate the benefit of the transfer learning based on visual similarity, as\nopposed to an amnesic learning (i.e. learning from scratch all the time).\nMoreover, with the real robot, we show that the method consistently outperforms\nthe manual optimization from an expert with less than 2 hours of training time\nto achieve more than 88% of success.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 09:06:38 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 07:56:02 GMT"}, {"version": "v3", "created": "Wed, 3 Oct 2018 12:09:03 GMT"}, {"version": "v4", "created": "Tue, 16 Oct 2018 10:02:02 GMT"}, {"version": "v5", "created": "Wed, 17 Oct 2018 08:26:10 GMT"}, {"version": "v6", "created": "Thu, 18 Oct 2018 06:30:25 GMT"}, {"version": "v7", "created": "Fri, 19 Oct 2018 06:26:33 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Petit", "Maxime", "", "imagine"], ["Depierre", "Amaury", "", "imagine"], ["Wang", "Xiaofang", "", "imagine"], ["Dellandr\u00e9a", "Emmanuel", "", "LIRIS"], ["Chen", "Liming", "", "imagine"]]}, {"id": "1809.10199", "submitter": "Junqiao Zhao", "authors": "Lu Sun, Junqiao Zhao, Xudong He, Chen Ye", "title": "DLO: Direct LiDAR Odometry for 2.5D Outdoor Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For autonomous vehicles, high-precision real-time localization is the\nguarantee of stable driving. Compared with the visual odometry (VO), the LiDAR\nodometry (LO) has the advantages of higher accuracy and better stability.\nHowever, 2D LO is only suitable for the indoor environment, and 3D LO has less\nefficiency in general. Both are not suitable for the online localization of an\nautonomous vehicle in an outdoor driving environment. In this paper, a direct\nLO method based on the 2.5D grid map is proposed. The fast semi-dense direct\nmethod proposed for VO is employed to register two 2.5D maps. Experiments show\nthat this method is superior to both the 3D-NDT and LOAM in the outdoor\nenvironment.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 01:20:06 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Sun", "Lu", ""], ["Zhao", "Junqiao", ""], ["He", "Xudong", ""], ["Ye", "Chen", ""]]}, {"id": "1809.10238", "submitter": "Joseph K J", "authors": "K J Joseph, Arghya Pal, Sailaja Rajanala, Vineeth N Balasubramanian", "title": "C4Synth: Cross-Caption Cycle-Consistent Text-to-Image Synthesis", "comments": "To appear in the proceedings of IEEE Winter Conference on\n  Applications of Computer Vision, WACV-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generating an image from its description is a challenging task worth solving\nbecause of its numerous practical applications ranging from image editing to\nvirtual reality. All existing methods use one single caption to generate a\nplausible image. A single caption by itself, can be limited, and may not be\nable to capture the variety of concepts and behavior that may be present in the\nimage. We propose two deep generative models that generate an image by making\nuse of multiple captions describing it. This is achieved by ensuring\n'Cross-Caption Cycle Consistency' between the multiple captions and the\ngenerated image(s). We report quantitative and qualitative results on the\nstandard Caltech-UCSD Birds (CUB) and Oxford-102 Flowers datasets to validate\nthe efficacy of the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 07:18:57 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Joseph", "K J", ""], ["Pal", "Arghya", ""], ["Rajanala", "Sailaja", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "1809.10253", "submitter": "Ryan Julian", "authors": "Ryan Julian, Eric Heiden, Zhanpeng He, Hejia Zhang, Stefan Schaal,\n  Joseph J. Lim, Gaurav Sukhatme, Karol Hausman", "title": "Scaling simulation-to-real transfer by learning composable robot skills", "comments": "Presented at ISER 2018. See\n  https://www.youtube.com/watch?v=Syr2RQTHqTs for supplemental video", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel solution to the problem of simulation-to-real transfer,\nwhich builds on recent advances in robot skill decomposition. Rather than\nfocusing on minimizing the simulation-reality gap, we learn a set of diverse\npolicies that are parameterized in a way that makes them easily reusable. This\ndiversity and parameterization of low-level skills allows us to find a\ntransferable policy that is able to use combinations and variations of\ndifferent skills to solve more complex, high-level tasks. In particular, we\nfirst use simulation to jointly learn a policy for a set of low-level skills,\nand a \"skill embedding\" parameterization which can be used to compose them.\nLater, we learn high-level policies which actuate the low-level policies via\nthis skill embedding parameterization. The high-level policies encode how and\nwhen to reuse the low-level skills together to achieve specific high-level\ntasks. Importantly, our method learns to control a real robot in joint-space to\nachieve these high-level tasks with little or no on-robot time, despite the\nfact that the low-level policies may not be perfectly transferable from\nsimulation to real, and that the low-level skills were not trained on any\nexamples of high-level tasks. We illustrate the principles of our method using\ninformative simulation experiments. We then verify its usefulness for real\nrobotics problems by learning, transferring, and composing free-space and\ncontact motion skills on a Sawyer robot using only joint-space control. We\nexperiment with several techniques for composing pre-learned skills, and find\nthat our method allows us to use both learning-based approaches and efficient\nsearch-based planning to achieve high-level tasks using only pre-learned\nskills.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 22:21:02 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 00:37:06 GMT"}, {"version": "v3", "created": "Tue, 13 Nov 2018 21:42:51 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Julian", "Ryan", ""], ["Heiden", "Eric", ""], ["He", "Zhanpeng", ""], ["Zhang", "Hejia", ""], ["Schaal", "Stefan", ""], ["Lim", "Joseph J.", ""], ["Sukhatme", "Gaurav", ""], ["Hausman", "Karol", ""]]}, {"id": "1809.10267", "submitter": "Chi Zhang", "authors": "Chi Zhang, Shagan Sah, Thang Nguyen, Dheeraj Peri, Alexander Loui,\n  Carl Salvaggio, Raymond Ptucha", "title": "Semantic Sentence Embeddings for Paraphrasing and Text Summarization", "comments": "5 pages, 4 figures, IEEE GlobalSIP 2017 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces a sentence to vector encoding framework suitable for\nadvanced natural language processing. Our latent representation is shown to\nencode sentences with common semantic information with similar vector\nrepresentations. The vector representation is extracted from an encoder-decoder\nmodel which is trained on sentence paraphrase pairs. We demonstrate the\napplication of the sentence representations for two different tasks -- sentence\nparaphrasing and paragraph summarization, making it attractive for commonly\nused recurrent frameworks that process text. Experimental results help gain\ninsight how vector representations are suitable for advanced language\nembedding.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 23:38:19 GMT"}], "update_date": "2018-09-30", "authors_parsed": [["Zhang", "Chi", ""], ["Sah", "Shagan", ""], ["Nguyen", "Thang", ""], ["Peri", "Dheeraj", ""], ["Loui", "Alexander", ""], ["Salvaggio", "Carl", ""], ["Ptucha", "Raymond", ""]]}, {"id": "1809.10276", "submitter": "Edward Raff", "authors": "Edward Raff", "title": "Growing and Retaining AI Talent for the United States Government", "comments": "Presented at AAAI FSS-18: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence and Machine Learning have become transformative to a\nnumber of industries, and as such many industries need for AI talent is\nincreasing the demand for individuals with these skills. This continues to\nexacerbate the difficulty of acquiring and retaining talent for the United\nStates Federal Government, both for its direct employees as well as the\ncompanies that support it. We take the position that by focusing on growing and\nretaining current talent through a number of cultural changes, the government\ncan work to remediate this problem today.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 00:17:18 GMT"}], "update_date": "2018-09-30", "authors_parsed": [["Raff", "Edward", ""]]}, {"id": "1809.10283", "submitter": "Christopher Iliffe Sprague", "authors": "Christopher Iliffe Sprague, Petter \\\"Ogren", "title": "Adding Neural Network Controllers to Behavior Trees without Destroying\n  Performance Guarantees", "comments": "Submitted to IEEE Transactions on Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show how Behavior Trees that have performance guarantees,\nin terms of safety and goal convergence, can be extended with components that\nwere designed using machine learning, without destroying those performance\nguarantees.\n  Machine learning approaches such as reinforcement learning or learning from\ndemonstration can be very appealing to AI designers that want efficient and\nrealistic behaviors in their agents. However, those algorithms seldom provide\nguarantees for solving the given task in all different situations while keeping\nthe agent safe. Instead, such guarantees are often easier to find for manually\ndesigned model based approaches. In this paper we exploit the modularity of\nBehavior trees to extend a given design with an efficient, but possibly\nunreliable, machine learning component in a way that preserves the guarantees.\nThe approach is illustrated with an inverted pendulum example.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 12:23:19 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 11:36:39 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Sprague", "Christopher Iliffe", ""], ["\u00d6gren", "Petter", ""]]}, {"id": "1809.10286", "submitter": "Leopoldo Bertossi", "authors": "Leopoldo Bertossi", "title": "Repair-Based Degrees of Database Inconsistency: Computation and\n  Complexity", "comments": "Some editing made and some new paragraphs added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generic numerical measure of the inconsistency of a database\nwith respect to a set of integrity constraints. It is based on an abstract\nrepair semantics. In particular, an inconsistency measure associated to\ncardinality-repairs is investigated in detail. More specifically, it is shown\nthat it can be computed via answer-set programs, but sometimes its computation\ncan be intractable in data complexity. However, polynomial-time deterministic\nand randomized approximations are exhibited. The behavior of this measure under\nsmall updates is analyzed, obtaining fixed-parameter tractability results.\nFurthermore, alternative inconsistency measures are proposed and discussed.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 00:57:33 GMT"}, {"version": "v2", "created": "Sun, 23 Dec 2018 02:32:17 GMT"}, {"version": "v3", "created": "Tue, 22 Jan 2019 17:14:34 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Bertossi", "Leopoldo", ""]]}, {"id": "1809.10315", "submitter": "Jingfeng Zhang", "authors": "Jingfeng Zhang, Laura Wynter", "title": "Smooth Inter-layer Propagation of Stabilized Neural Networks for\n  Classification", "comments": "Revised Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has studied the reasons for the remarkable performance of deep\nneural networks in image classification. We examine batch normalization on the\none hand and the dynamical systems view of residual networks on the other hand.\nOur goal is in understanding the notions of stability and smoothness of the\ninter-layer propagation of ResNets so as to explain when they contribute to\nsignificantly enhanced performance. We postulate that such stability is of\nimportance for the trained ResNet to transfer.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 02:23:00 GMT"}, {"version": "v2", "created": "Sat, 29 Sep 2018 03:25:06 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Zhang", "Jingfeng", ""], ["Wynter", "Laura", ""]]}, {"id": "1809.10326", "submitter": "Yunhao Tang", "authors": "Yunhao Tang, Shipra Agrawal", "title": "Boosting Trust Region Policy Optimization by Normalizing Flows Policy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to improve trust region policy search with normalizing flows\npolicy. We illustrate that when the trust region is constructed by KL\ndivergence constraints, normalizing flows policy generates samples far from the\n'center' of the previous policy iterate, which potentially enables better\nexploration and helps avoid bad local optima. Through extensive comparisons, we\nshow that the normalizing flows policy significantly improves upon baseline\narchitectures especially on high-dimensional tasks with complex dynamics.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 03:19:53 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 19:22:48 GMT"}, {"version": "v3", "created": "Fri, 1 Feb 2019 14:28:17 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Tang", "Yunhao", ""], ["Agrawal", "Shipra", ""]]}, {"id": "1809.10336", "submitter": "Tao Ma", "authors": "Tao Ma", "title": "Multi-task Learning for Financial Forecasting", "comments": "The methods and results of this paper have been proved to be wrong.\n  So we want to withdraw it to keep others from following the wrong results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial forecasting is challenging and attractive in machine learning.\nThere are many classic solutions, as well as many deep learning based methods,\nproposed to deal with it yielding encouraging performance. Stock time series\nforecasting is the most representative problem in financial forecasting. Due to\nthe strong connections among stocks, the information valuable for forecasting\nis not only included in individual stocks, but also included in the stocks\nrelated to them. However, most previous works focus on one single stock, which\neasily ignore the valuable information in others. To leverage more information,\nin this paper, we propose a jointly forecasting approach to process multiple\ntime series of related stocks simultaneously, using multi-task learning\nframework. Compared to the previous works, we use multiple networks to forecast\nmultiple related stocks, using the shared and private information of them\nsimultaneously through multi-task learning. Moreover, we propose an attention\nmethod learning an optimized weighted combination of shared and private\ninformation based on the idea of Capital Asset Pricing Model (CAPM) to help\nforecast. Experimental results on various data show improved forecasting\nperformance over baseline methods.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 04:03:03 GMT"}, {"version": "v2", "created": "Sat, 15 Dec 2018 14:25:41 GMT"}, {"version": "v3", "created": "Tue, 22 Jan 2019 09:19:22 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Ma", "Tao", ""]]}, {"id": "1809.10436", "submitter": "Daniel P. Lupp", "authors": "Henrik Forssell, Christian Kindermann, Daniel P. Lupp, Uli Sattler,\n  Evgenij Thorstensen", "title": "Generating Ontologies from Templates: A Rule-Based Approach for\n  Capturing Regularity", "comments": "Technical report, extended version of paper accepted to DL Workshop\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a second-order language that can be used to succinctly specify\nontologies in a consistent and transparent manner. This language is based on\nontology templates (OTTR), a framework for capturing recurring patterns of\naxioms in ontological modelling. The language and our results are independent\nof any specific DL. We define the language and its semantics, including the\ncase of negation-as-failure, investigate reasoning over ontologies specified\nusing our language, and show results about the decidability of useful reasoning\ntasks about the language itself. We also state and discuss some open problems\nthat we believe to be of interest.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 10:10:20 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Forssell", "Henrik", ""], ["Kindermann", "Christian", ""], ["Lupp", "Daniel P.", ""], ["Sattler", "Uli", ""], ["Thorstensen", "Evgenij", ""]]}, {"id": "1809.10438", "submitter": "Alex James Dr", "authors": "Kazybek Adam, Kamilya Smagulova, Olga Krestinskaya, Alex Pappachen\n  James", "title": "Wafer Quality Inspection using Memristive LSTM, ANN, DNN and HTM", "comments": null, "journal-ref": "IEEE Electrical Design of Advanced Packaging and Systems\n  Symposium, 2018", "doi": null, "report-no": null, "categories": "cs.ET cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automated wafer inspection and quality control is a complex and\ntime-consuming task, which can speed up using neuromorphic memristive\narchitectures, as a separate inspection device or integrating directly into\nsensors. This paper presents the performance analysis and comparison of\ndifferent neuromorphic architectures for patterned wafer quality inspection and\nclassification. The application of non-volatile memristive devices in these\narchitectures ensures low power consumption, small on-chip area scalability. We\ndemonstrate that Long-Short Term Memory (LSTM) outperforms other architectures\nfor the same number of training iterations, and has relatively low on-chip area\nand power consumption.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 10:13:06 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Adam", "Kazybek", ""], ["Smagulova", "Kamilya", ""], ["Krestinskaya", "Olga", ""], ["James", "Alex Pappachen", ""]]}, {"id": "1809.10441", "submitter": "Dmitry Maximov", "authors": "Dmitry Maximov and Yury Legovich and Vladimir Goncharenko", "title": "A Way to Facilitate Decision Making in a Mixed Group of Manned and\n  Unmanned Aerial Vehicles", "comments": "18 pages total, 12 ones of the text, appendix, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A mixed group of manned and unmanned aerial vehicles is considered as a\ndistributed system. A lattice of tasks which may be fulfilled by the system\nmatches to it. An external multiplication operation is defined at the lattice,\nwhich defines correspondingly linear logic operations. Linear implication and\ntensor product are used to choose a system reconfiguration variant, i.e., to\ndetermine a new task executor choice. The task lattice structure (i.e., the\nsystem purpose) and the operation definitions largely define the choice. Thus,\nthe choice is mainly the system purpose consequence. Such a method of the\nbehavior variant choice facilitates the decision making by the pilot\ncontrolling the group. The suggested approach is illustrated using an example\nof a mixed group control at forest fire compression.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 10:28:10 GMT"}, {"version": "v2", "created": "Thu, 15 Nov 2018 08:15:04 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Maximov", "Dmitry", ""], ["Legovich", "Yury", ""], ["Goncharenko", "Vladimir", ""]]}, {"id": "1809.10565", "submitter": "Yu Zhao", "authors": "Yu Zhao, Zhenhui Shi, Jingyang Zhang, Dong Chen, Lixu Gu", "title": "A novel active learning framework for classification: using weighted\n  rank aggregation to achieve multiple query criteria", "comments": "34 pages, 21 figures, 11 tables,", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple query criteria active learning (MQCAL) methods have a higher\npotential performance than conventional active learning methods in which only\none criterion is deployed for sample selection. A central issue related to\nMQCAL methods concerns the development of an integration criteria strategy\n(ICS) that makes full use of all criteria. The conventional ICS adopted in\nrelevant research all facilitate the desired effects, but several limitations\nstill must be addressed. For instance, some of the strategies are not\nsufficiently scalable during the design process, and the number and type of\ncriteria involved are dictated. Thus, it is challenging for the user to\nintegrate other criteria into the original process unless modifications are\nmade to the algorithm. Other strategies are too dependent on empirical\nparameters, which can only be acquired by experience or cross-validation and\nthus lack generality; additionally, these strategies are counter to the\nintention of active learning, as samples need to be labeled in the validation\nset before the active learning process can begin. To address these limitations,\nwe propose a novel MQCAL method for classification tasks that employs a third\nstrategy via weighted rank aggregation. The proposed method serves as a\nheuristic means to select high-value samples of high scalability and generality\nand is implemented through a three-step process: (1) the transformation of the\nsample selection to sample ranking and scoring, (2) the computation of the\nself-adaptive weights of each criterion, and (3) the weighted aggregation of\neach sample rank list. Ultimately, the sample at the top of the aggregated\nranking list is the most comprehensively valuable and must be labeled. Several\nexperiments generating 257 wins, 194 ties and 49 losses against other\nstate-of-the-art MQCALs are conducted to verify that the proposed method can\nachieve superior results.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 15:12:54 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Zhao", "Yu", ""], ["Shi", "Zhenhui", ""], ["Zhang", "Jingyang", ""], ["Chen", "Dong", ""], ["Gu", "Lixu", ""]]}, {"id": "1809.10595", "submitter": "Jinyuan Yu Mr.", "authors": "Zheng Xie, XingYu Fu and JinYuan Yu", "title": "AlphaGomoku: An AlphaGo-based Gomoku Artificial Intelligence using\n  Curriculum Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this project, we combine AlphaGo algorithm with Curriculum Learning to\ncrack the game of Gomoku. Modifications like Double Networks Mechanism and\nWinning Value Decay are implemented to solve the intrinsic asymmetry and\nshort-sight of Gomoku. Our final AI AlphaGomoku, through two days' training on\na single GPU, has reached humans' playing level.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 16:10:01 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Xie", "Zheng", ""], ["Fu", "XingYu", ""], ["Yu", "JinYuan", ""]]}, {"id": "1809.10635", "submitter": "Gido van de Ven", "authors": "Gido M. van de Ven, Andreas S. Tolias", "title": "Generative replay with feedback connections as a general strategy for\n  continual learning", "comments": "17 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major obstacle to developing artificial intelligence applications capable\nof true lifelong learning is that artificial neural networks quickly or\ncatastrophically forget previously learned tasks when trained on a new one.\nNumerous methods for alleviating catastrophic forgetting are currently being\nproposed, but differences in evaluation protocols make it difficult to directly\ncompare their performance. To enable more meaningful comparisons, here we\nidentified three distinct scenarios for continual learning based on whether\ntask identity is known and, if it is not, whether it needs to be inferred.\nPerforming the split and permuted MNIST task protocols according to each of\nthese scenarios, we found that regularization-based approaches (e.g., elastic\nweight consolidation) failed when task identity needed to be inferred. In\ncontrast, generative replay combined with distillation (i.e., using class\nprobabilities as \"soft targets\") achieved superior performance in all three\nscenarios. Addressing the issue of efficiency, we reduced the computational\ncost of generative replay by integrating the generative model into the main\nmodel by equipping it with generative feedback or backward connections. This\nReplay-through-Feedback approach substantially shortened training time with no\nor negligible loss in performance. We believe this to be an important first\nstep towards making the powerful technique of generative replay scalable to\nreal-world continual learning applications.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 16:55:58 GMT"}, {"version": "v2", "created": "Wed, 17 Apr 2019 09:20:24 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["van de Ven", "Gido M.", ""], ["Tolias", "Andreas S.", ""]]}, {"id": "1809.10679", "submitter": "Nasrin Sadeghianpourhamami", "authors": "Nasrin Sadeghianpourhamami, Johannes Deleu, Chris Develder", "title": "Definition and evaluation of model-free coordination of electrical\n  vehicle charging with reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Initial DR studies mainly adopt model predictive control and thus require\naccurate models of the control problem (e.g., a customer behavior model), which\nare to a large extent uncertain for the EV scenario. Hence, model-free\napproaches, especially based on reinforcement learning (RL) are an attractive\nalternative. In this paper, we propose a new Markov decision process (MDP)\nformulation in the RL framework, to jointly coordinate a set of EV charging\nstations. State-of-the-art algorithms either focus on a single EV, or perform\nthe control of an aggregate of EVs in multiple steps (e.g., aggregate load\ndecisions in one step, then a step translating the aggregate decision to\nindividual connected EVs). On the contrary, we propose an RL approach to\njointly control the whole set of EVs at once. We contribute a new MDP\nformulation, with a scalable state representation that is independent of the\nnumber of EV charging stations. Further, we use a batch reinforcement learning\nalgorithm, i.e., an instance of fitted Q-iteration, to learn the optimal\ncharging policy. We analyze its performance using simulation experiments based\non a real-world EV charging data. More specifically, we (i) explore the various\nsettings in training the RL policy (e.g., duration of the period with training\ndata), (ii) compare its performance to an oracle all-knowing benchmark (which\nprovides an upper bound for performance, relying on information that is not\navailable or at least imperfect in practice), (iii) analyze performance over\ntime, over the course of a full year to evaluate possible performance\nfluctuations (e.g, across different seasons), and (iv) demonstrate the\ngeneralization capacity of a learned control policy to larger sets of charging\nstations.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 10:34:41 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 19:00:36 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Sadeghianpourhamami", "Nasrin", ""], ["Deleu", "Johannes", ""], ["Develder", "Chris", ""]]}, {"id": "1809.10749", "submitter": "Quynh Nguyen", "authors": "Quynh Nguyen, Mahesh Chandra Mukkamala, Matthias Hein", "title": "On the loss landscape of a class of deep neural networks with no bad\n  local valleys", "comments": "Accepted at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify a class of over-parameterized deep neural networks with standard\nactivation functions and cross-entropy loss which provably have no bad local\nvalley, in the sense that from any point in parameter space there exists a\ncontinuous path on which the cross-entropy loss is non-increasing and gets\narbitrarily close to zero. This implies that these networks have no sub-optimal\nstrict local minima.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 20:09:59 GMT"}, {"version": "v2", "created": "Mon, 24 Dec 2018 00:58:29 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Nguyen", "Quynh", ""], ["Mukkamala", "Mahesh Chandra", ""], ["Hein", "Matthias", ""]]}, {"id": "1809.10756", "submitter": "Jan-Willem Van De Meent", "authors": "Jan-Willem van de Meent and Brooks Paige and Hongseok Yang and Frank\n  Wood", "title": "An Introduction to Probabilistic Programming", "comments": "Under review at Foundations and Trends in Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document is designed to be a first-year graduate-level introduction to\nprobabilistic programming. It not only provides a thorough background for\nanyone wishing to use a probabilistic programming system, but also introduces\nthe techniques needed to design and build these systems. It is aimed at people\nwho have an undergraduate-level understanding of either or, ideally, both\nprobabilistic machine learning and programming languages.\n  We start with a discussion of model-based reasoning and explain why\nconditioning as a foundational computation is central to the fields of\nprobabilistic machine learning and artificial intelligence. We then introduce a\nsimple first-order probabilistic programming language (PPL) whose programs\ndefine static-computation-graph, finite-variable-cardinality models. In the\ncontext of this restricted PPL we introduce fundamental inference algorithms\nand describe how they can be implemented in the context of models denoted by\nprobabilistic programs.\n  In the second part of this document, we introduce a higher-order\nprobabilistic programming language, with a functionality analogous to that of\nestablished programming languages. This affords the opportunity to define\nmodels with dynamic computation graphs, at the cost of requiring inference\nmethods that generate samples by repeatedly executing the program. Foundational\ninference algorithms for this kind of probabilistic programming language are\nexplained in the context of an interface between program executions and an\ninference controller.\n  This document closes with a chapter on advanced topics which we believe to\nbe, at the time of writing, interesting directions for probabilistic\nprogramming research; directions that point towards a tight integration with\ndeep neural network research and the development of systems for next-generation\nartificial intelligence applications.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 20:44:23 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["van de Meent", "Jan-Willem", ""], ["Paige", "Brooks", ""], ["Yang", "Hongseok", ""], ["Wood", "Frank", ""]]}, {"id": "1809.10788", "submitter": "Jonathan Juett", "authors": "Jonathan Juett and Benjamin Kuipers", "title": "Learning and Acting in Peripersonal Space: Moving, Reaching, and\n  Grasping", "comments": "35 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The young infant explores its body, its sensorimotor system, and the\nimmediately accessible parts of its environment, over the course of a few\nmonths creating a model of peripersonal space useful for reaching and grasping\nobjects around it. Drawing on constraints from the empirical literature on\ninfant behavior, we present a preliminary computational model of this learning\nprocess, implemented and evaluated on a physical robot. The learning agent\nexplores the relationship between the configuration space of the arm, sensing\njoint angles through proprioception, and its visual perceptions of the hand and\ngrippers. The resulting knowledge is represented as the peripersonal space\n(PPS) graph, where nodes represent states of the arm, edges represent safe\nmovements, and paths represent safe trajectories from one pose to another. In\nour model, the learning process is driven by intrinsic motivation. When\nrepeatedly performing an action, the agent learns the typical result, but also\ndetects unusual outcomes, and is motivated to learn how to make those unusual\nresults reliable. Arm motions typically leave the static background unchanged,\nbut occasionally bump an object, changing its static position. The reach action\nis learned as a reliable way to bump and move an object in the environment.\nSimilarly, once a reliable reach action is learned, it typically makes a\nquasi-static change in the environment, moving an object from one static\nposition to another. The unusual outcome is that the object is accidentally\ngrasped (thanks to the innate Palmar reflex), and thereafter moves dynamically\nwith the hand. Learning to make grasps reliable is more complex than for\nreaches, but we demonstrate significant progress. Our current results are steps\ntoward autonomous sensorimotor learning of motion, reaching, and grasping in\nperipersonal space, based on unguided exploration and intrinsic motivation.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 22:39:45 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Juett", "Jonathan", ""], ["Kuipers", "Benjamin", ""]]}, {"id": "1809.10791", "submitter": "Razieh Nabi", "authors": "Razieh Nabi, Phyllis Kanki, Ilya Shpitser", "title": "Estimation of Personalized Effects Associated With Causal Pathways", "comments": null, "journal-ref": "In Proceedings of the Thirty Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI), 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of personalized decision making is to map a unit's characteristics\nto an action tailored to maximize the expected outcome for that unit. Obtaining\nhigh-quality mappings of this type is the goal of the dynamic regime\nliterature. In healthcare settings, optimizing policies with respect to a\nparticular causal pathway may be of interest as well. For example, we may wish\nto maximize the chemical effect of a drug given data from an observational\nstudy where the chemical effect of the drug on the outcome is entangled with\nthe indirect effect mediated by differential adherence. In such cases, we may\nwish to optimize the direct effect of a drug, while keeping the indirect effect\nto that of some reference treatment. [16] shows how to combine mediation\nanalysis and dynamic treatment regime ideas to defines policies associated with\ncausal pathways and counterfactual responses to these policies. In this paper,\nwe derive a variety of methods for learning high quality policies of this type\nfrom data, in a causal model corresponding to a longitudinal setting of\npractical importance. We illustrate our methods via a dataset of HIV patients\nundergoing therapy, gathered in the Nigerian PEPFAR program.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 22:49:29 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Nabi", "Razieh", ""], ["Kanki", "Phyllis", ""], ["Shpitser", "Ilya", ""]]}, {"id": "1809.10842", "submitter": "Yi Wu", "authors": "Yi Wu, Yuxin Wu, Aviv Tamar, Stuart Russell, Georgia Gkioxari,\n  Yuandong Tian", "title": "Learning and Planning with a Semantic Model", "comments": "submitted to ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building deep reinforcement learning agents that can generalize and adapt to\nunseen environments remains a fundamental challenge for AI. This paper\ndescribes progresses on this challenge in the context of man-made environments,\nwhich are visually diverse but contain intrinsic semantic regularities. We\npropose a hybrid model-based and model-free approach, LEArning and Planning\nwith Semantics (LEAPS), consisting of a multi-target sub-policy that acts on\nvisual inputs, and a Bayesian model over semantic structures. When placed in an\nunseen environment, the agent plans with the semantic model to make high-level\ndecisions, proposes the next sub-target for the sub-policy to execute, and\nupdates the semantic model based on new observations. We perform experiments in\nvisual navigation tasks using House3D, a 3D environment that contains diverse\nhuman-designed indoor scenes with real-world objects. LEAPS outperforms strong\nbaselines that do not explicitly plan using the semantic content.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 03:30:37 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Wu", "Yi", ""], ["Wu", "Yuxin", ""], ["Tamar", "Aviv", ""], ["Russell", "Stuart", ""], ["Gkioxari", "Georgia", ""], ["Tian", "Yuandong", ""]]}, {"id": "1809.10875", "submitter": "Zhuolin Yang", "authors": "Zhuolin Yang, Bo Li, Pin-Yu Chen, Dawn Song", "title": "Characterizing Audio Adversarial Examples Using Temporal Dependency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have highlighted adversarial examples as a ubiquitous threat\nto different neural network models and many downstream applications.\nNonetheless, as unique data properties have inspired distinct and powerful\nlearning principles, this paper aims to explore their potentials towards\nmitigating adversarial inputs. In particular, our results reveal the importance\nof using the temporal dependency in audio data to gain discriminate power\nagainst adversarial examples. Tested on the automatic speech recognition (ASR)\ntasks and three recent audio adversarial attacks, we find that (i) input\ntransformation developed from image adversarial defense provides limited\nrobustness improvement and is subtle to advanced attacks; (ii) temporal\ndependency can be exploited to gain discriminative power against audio\nadversarial examples and is resistant to adaptive attacks considered in our\nexperiments. Our results not only show promising means of improving the\nrobustness of ASR systems, but also offer novel insights in exploiting\ndomain-specific data properties to mitigate negative effects of adversarial\nexamples.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 06:39:42 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 15:21:37 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Yang", "Zhuolin", ""], ["Li", "Bo", ""], ["Chen", "Pin-Yu", ""], ["Song", "Dawn", ""]]}, {"id": "1809.10889", "submitter": "Zheyi Pan", "authors": "Zheyi Pan, Yuxuan Liang, Junbo Zhang, Xiuwen Yi, Yong Yu and Yu Zheng", "title": "HyperST-Net: Hypernetworks for Spatio-Temporal Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatio-temporal (ST) data, which represent multiple time series data\ncorresponding to different spatial locations, are ubiquitous in real-world\ndynamic systems, such as air quality readings. Forecasting over ST data is of\ngreat importance but challenging as it is affected by many complex factors,\nincluding spatial characteristics, temporal characteristics and the intrinsic\ncausality between them. In this paper, we propose a general framework\n(HyperST-Net) based on hypernetworks for deep ST models. More specifically, it\nconsists of three major modules: a spatial module, a temporal module and a\ndeduction module. Among them, the deduction module derives the parameter\nweights of the temporal module from the spatial characteristics, which are\nextracted by the spatial module. Then, we design a general form of HyperST\nlayer as well as different forms for several basic layers in neural networks,\nincluding the dense layer (HyperST-Dense) and the convolutional layer\n(HyperST-Conv). Experiments on three types of real-world tasks demonstrate that\nthe predictive models integrated with our framework achieve significant\nimprovements, and outperform the state-of-the-art baselines as well.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 07:29:21 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Pan", "Zheyi", ""], ["Liang", "Yuxuan", ""], ["Zhang", "Junbo", ""], ["Yi", "Xiuwen", ""], ["Yu", "Yong", ""], ["Zheng", "Yu", ""]]}, {"id": "1809.10903", "submitter": "Kuang Zhou", "authors": "Kuang Zhou (NPU), Quan Pan (NPU), Arnaud Martin (DRUID)", "title": "Evidential community detection based on density peaks", "comments": null, "journal-ref": "BELIEF 2018 - The 5th International Conference on Belief\n  Functions, Sep 2018, Compi{\\`e}gne, France", "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Credal partitions in the framework of belief functions can give us a better\nunderstanding of the analyzed data set. In order to find credal community\nstructure in graph data sets, in this paper, we propose a novel evidential\ncommunity detection algorithm based on density peaks (EDPC). Two new metrics,\nthe local density $\\rho$ and the minimum dissimi-larity $\\delta$, are first\ndefined for each node in the graph. Then the nodes with both higher $\\rho$ and\n$\\delta$ values are identified as community centers. Finally, the remaing nodes\nare assigned with corresponding community labels through a simple two-step\nevidential label propagation strategy. The membership of each node is described\nin the form of basic belief assignments , which can well express the\nuncertainty included in the community structure of the graph. The experiments\ndemonstrate the effectiveness of the proposed method on real-world networks.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 08:05:47 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Zhou", "Kuang", "", "NPU"], ["Pan", "Quan", "", "NPU"], ["Martin", "Arnaud", "", "DRUID"]]}, {"id": "1809.10946", "submitter": "Giovanni Casini", "authors": "Richard Booth, Giovanni Casini, Thomas Meyer, Ivan Varzinczak", "title": "On Rational Entailment for Propositional Typicality Logic", "comments": "27 pages; extended and elaborated version of a paper presented at the\n  24th International Joint Conference on Artificial Intelligence (IJCAI 2015)", "journal-ref": null, "doi": "10.1016/j.artint.2019.103178", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Propositional Typicality Logic (PTL) is a recently proposed logic, obtained\nby enriching classical propositional logic with a typicality operator capturing\nthe most typical (alias normal or conventional) situations in which a given\nsentence holds. The semantics of PTL is in terms of ranked models as studied in\nthe well-known KLM approach to preferential reasoning and therefore KLM-style\nrational consequence relations can be embedded in PTL. In spite of the\nnon-monotonic features introduced by the semantics adopted for the typicality\noperator, the obvious Tarskian definition of entailment for PTL remains\nmonotonic and is therefore not appropriate in many contexts. Our first\nimportant result is an impossibility theorem showing that a set of proposed\npostulates that at first all seem appropriate for a notion of entailment with\nregard to typicality cannot be satisfied simultaneously. Closer inspection\nreveals that this result is best interpreted as an argument for advocating the\ndevelopment of more than one type of PTL entailment. In the spirit of this\ninterpretation, we investigate three different (semantic) versions of\nentailment for PTL, each one based on the definition of rational closure as\nintroduced by Lehmann and Magidor for KLM-style conditionals, and constructed\nusing different notions of minimality.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 10:19:16 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 22:08:57 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Booth", "Richard", ""], ["Casini", "Giovanni", ""], ["Meyer", "Thomas", ""], ["Varzinczak", "Ivan", ""]]}, {"id": "1809.11017", "submitter": "Peifeng Wang", "authors": "Peifeng Wang, Shuangyin Li, Rong pan", "title": "Incorporating GAN for Negative Sampling in Knowledge Representation\n  Learning", "comments": "Accepted to AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge representation learning aims at modeling knowledge graph by\nencoding entities and relations into a low dimensional space. Most of the\ntraditional works for knowledge embedding need negative sampling to minimize a\nmargin-based ranking loss. However, those works construct negative samples\nthrough a random mode, by which the samples are often too trivial to fit the\nmodel efficiently. In this paper, we propose a novel knowledge representation\nlearning framework based on Generative Adversarial Networks (GAN). In this\nGAN-based framework, we take advantage of a generator to obtain high-quality\nnegative samples. Meanwhile, the discriminator in GAN learns the embeddings of\nthe entities and relations in knowledge graph. Thus, we can incorporate the\nproposed GAN-based framework into various traditional models to improve the\nability of knowledge representation learning. Experimental results show that\nour proposed GAN-based framework outperforms baselines on triplets\nclassification and link prediction tasks.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 04:37:24 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Wang", "Peifeng", ""], ["Li", "Shuangyin", ""], ["pan", "Rong", ""]]}, {"id": "1809.11044", "submitter": "Andrea Tacchetti", "authors": "Andrea Tacchetti, H. Francis Song, Pedro A. M. Mediano, Vinicius\n  Zambaldi, Neil C. Rabinowitz, Thore Graepel, Matthew Botvinick, Peter W.\n  Battaglia", "title": "Relational Forward Models for Multi-Agent Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The behavioral dynamics of multi-agent systems have a rich and orderly\nstructure, which can be leveraged to understand these systems, and to improve\nhow artificial agents learn to operate in them. Here we introduce Relational\nForward Models (RFM) for multi-agent learning, networks that can learn to make\naccurate predictions of agents' future behavior in multi-agent environments.\nBecause these models operate on the discrete entities and relations present in\nthe environment, they produce interpretable intermediate representations which\noffer insights into what drives agents' behavior, and what events mediate the\nintensity and valence of social interactions. Furthermore, we show that\nembedding RFM modules inside agents results in faster learning systems compared\nto non-augmented baselines. As more and more of the autonomous systems we\ndevelop and interact with become multi-agent in nature, developing richer\nanalysis tools for characterizing how and why agents make decisions is\nincreasingly necessary. Moreover, developing artificial agents that quickly and\nsafely learn to coordinate with one another, and with humans in shared\nenvironments, is crucial.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 14:10:39 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Tacchetti", "Andrea", ""], ["Song", "H. Francis", ""], ["Mediano", "Pedro A. M.", ""], ["Zambaldi", "Vinicius", ""], ["Rabinowitz", "Neil C.", ""], ["Graepel", "Thore", ""], ["Botvinick", "Matthew", ""], ["Battaglia", "Peter W.", ""]]}, {"id": "1809.11074", "submitter": "Keting Lu", "authors": "Keting Lu, Shiqi Zhang, Peter Stone, Xiaoping Chen", "title": "Robot Representation and Reasoning with Knowledge from Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) agents aim at learning by interacting with an\nenvironment, and are not designed for representing or reasoning with\ndeclarative knowledge. Knowledge representation and reasoning (KRR) paradigms\nare strong in declarative KRR tasks, but are ill-equipped to learn from such\nexperiences. In this work, we integrate logical-probabilistic KRR with\nmodel-based RL, enabling agents to simultaneously reason with declarative\nknowledge and learn from interaction experiences. The knowledge from humans and\nRL is unified and used for dynamically computing task-specific planning models\nunder potentially new environments. Experiments were conducted using a mobile\nrobot working on dialog, navigation, and delivery tasks. Results show\nsignificant improvements, in comparison to existing model-based RL methods.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 15:02:21 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 07:38:48 GMT"}, {"version": "v3", "created": "Thu, 22 Nov 2018 13:56:47 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Lu", "Keting", ""], ["Zhang", "Shiqi", ""], ["Stone", "Peter", ""], ["Chen", "Xiaoping", ""]]}, {"id": "1809.11089", "submitter": "Gavin Pearson", "authors": "Gavin Pearson (1), Phil Jolley (2) and Geraint Evans (3) ((1) Dstl,\n  (2) IBM, (3) Defence Academy)", "title": "A Systems Approach to Achieving the Benefits of Artificial Intelligence\n  in UK Defence", "comments": "Presented at AAAI FSS-18: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": "Dstl/CP111074", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to exploit the opportunities offered by AI within UK Defence\ncalls for an understanding of systemic issues required to achieve an effective\noperational capability. This paper provides the authors' views of issues which\ncurrently block UK Defence from fully benefitting from AI technology. These are\nsituated within a reference model for the AI Value Train, so enabling the\ncommunity to address the exploitation of such data and software intensive\nsystems in a systematic, end to end manner. The paper sets out the conditions\nfor success including: Researching future solutions to known problems and\nclearly defined use cases; Addressing achievable use cases to show benefit;\nEnhancing the availability of Defence-relevant data; Enhancing Defence 'know\nhow' in AI; Operating Software Intensive supply chain eco-systems at required\nbreadth and pace; Governance and, the integration of software and platform\nsupply chains and operating models.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 15:32:21 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Pearson", "Gavin", ""], ["Jolley", "Phil", ""], ["Evans", "Geraint", ""]]}, {"id": "1809.11099", "submitter": "Michael F\\\"arber", "authors": "Michael F\\\"arber, Achim Rettinger", "title": "Which Knowledge Graph Is Best for Me?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, DBpedia, Freebase, OpenCyc, Wikidata, and YAGO have been\npublished as noteworthy large, cross-domain, and freely available knowledge\ngraphs. Although extensively in use, these knowledge graphs are hard to compare\nagainst each other in a given setting. Thus, it is a challenge for researchers\nand developers to pick the best knowledge graph for their individual needs. In\nour recent survey, we devised and applied data quality criteria to the\nabove-mentioned knowledge graphs. Furthermore, we proposed a framework for\nfinding the most suitable knowledge graph for a given setting. With this paper\nwe intend to ease the access to our in-depth survey by presenting simplified\nrules that map individual data quality requirements to specific knowledge\ngraphs. However, this paper does not intend to replace our previously\nintroduced decision-support framework. For an informed decision on which KG is\nbest for you we still refer to our in-depth survey.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 15:44:21 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["F\u00e4rber", "Michael", ""], ["Rettinger", "Achim", ""]]}, {"id": "1809.11155", "submitter": "Hamed Sadeghi", "authors": "Jules Gagnon-Marchand, Hamed Sadeghi, Md. Akmal Haidar and Mehdi\n  Rezagholizadeh", "title": "SALSA-TEXT : self attentive latent space based adversarial text\n  generation", "comments": "10 pages, 3 figures, under review at ICLR 2019", "journal-ref": "Canadian AI 2019", "doi": "10.1007/978-3-030-18305-9_10", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the success of self attention mechanism and Transformer\narchitecture in sequence transduction and image generation applications, we\npropose novel self attention-based architectures to improve the performance of\nadversarial latent code- based schemes in text generation. Adversarial latent\ncode-based text generation has recently gained a lot of attention due to their\npromising results. In this paper, we take a step to fortify the architectures\nused in these setups, specifically AAE and ARAE. We benchmark two latent\ncode-based methods (AAE and ARAE) designed based on adversarial setups. In our\nexperiments, the Google sentence compression dataset is utilized to compare our\nmethod with these methods using various objective and subjective measures. The\nexperiments demonstrate the proposed (self) attention-based models outperform\nthe state-of-the-art in adversarial code-based text generation.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 17:38:36 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2018 16:42:59 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Gagnon-Marchand", "Jules", ""], ["Sadeghi", "Hamed", ""], ["Haidar", "Md. Akmal", ""], ["Rezagholizadeh", "Mehdi", ""]]}, {"id": "1809.11160", "submitter": "Tom Hanika", "authors": "Maximilian Felde and Tom Hanika", "title": "Formal Context Generation using Dirichlet Distributions", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": "10.1007/978-3-030-23182-8_5", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We suggest an improved way to randomly generate formal contexts based on\nDirichlet distributions. For this purpose we investigate the predominant way to\ngenerate formal contexts, a coin-tossing model, recapitulate some of its\nshortcomings and examine its stochastic model. Building up on this we propose\nour Dirichlet model and develop an algorithm employing this idea. By comparing\nour generation model to a coin-tossing model we show that our approach is a\nsignificant improvement with respect to the variety of contexts generated.\nFinally, we outline a possible application in null model generation for formal\ncontexts.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 17:48:15 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Felde", "Maximilian", ""], ["Hanika", "Tom", ""]]}, {"id": "1809.11169", "submitter": "Yunzhu Li", "authors": "Yunzhu Li, Jiajun Wu, Jun-Yan Zhu, Joshua B. Tenenbaum, Antonio\n  Torralba, Russ Tedrake", "title": "Propagation Networks for Model-Based Control Under Partial Observation", "comments": "Accepted to ICRA 2019. Project Page: http://propnet.csail.mit.edu\n  Video: https://youtu.be/ZAxHXegkz48", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been an increasing interest in learning dynamics simulators for\nmodel-based control. Compared with off-the-shelf physics engines, a learnable\nsimulator can quickly adapt to unseen objects, scenes, and tasks. However,\nexisting models like interaction networks only work for fully observable\nsystems; they also only consider pairwise interactions within a single time\nstep, both restricting their use in practical systems. We introduce Propagation\nNetworks (PropNet), a differentiable, learnable dynamics model that handles\npartially observable scenarios and enables instantaneous propagation of signals\nbeyond pairwise interactions. Experiments show that our propagation networks\nnot only outperform current learnable physics engines in forward simulation,\nbut also achieve superior performance on various control tasks. Compared with\nexisting model-free deep reinforcement learning algorithms, model-based control\nwith propagation networks is more accurate, efficient, and generalizable to\nnew, partially observable scenes and tasks.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 17:58:10 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2019 02:20:25 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Li", "Yunzhu", ""], ["Wu", "Jiajun", ""], ["Zhu", "Jun-Yan", ""], ["Tenenbaum", "Joshua B.", ""], ["Torralba", "Antonio", ""], ["Tedrake", "Russ", ""]]}]