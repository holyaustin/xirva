[{"id": "2106.00008", "submitter": "Dongxiao Zhang", "authors": "Hao Xu and Dongxiao Zhang", "title": "Robust discovery of partial differential equations in complex situations", "comments": "20 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven discovery of partial differential equations (PDEs) has achieved\nconsiderable development in recent years. Several aspects of problems have been\nresolved by sparse regression-based and neural network-based methods. However,\nthe performances of existing methods lack stability when dealing with complex\nsituations, including sparse data with high noise, high-order derivatives and\nshock waves, which bring obstacles to calculating derivatives accurately.\nTherefore, a robust PDE discovery framework, called the robust deep\nlearning-genetic algorithm (R-DLGA), that incorporates the physics-informed\nneural network (PINN), is proposed in this work. In the framework, a\npreliminary result of potential terms provided by the deep learning-genetic\nalgorithm is added into the loss function of the PINN as physical constraints\nto improve the accuracy of derivative calculation. It assists to optimize the\npreliminary result and obtain the ultimately discovered PDE by eliminating the\nerror compensation terms. The stability and accuracy of the proposed R-DLGA in\nseveral complex situations are examined for proof-and-concept, and the results\nprove that the proposed framework is able to calculate derivatives accurately\nwith the optimization of PINN and possesses surprising robustness to complex\nsituations, including sparse data with high noise, high-order derivatives, and\nshock waves.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 02:11:59 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Xu", "Hao", ""], ["Zhang", "Dongxiao", ""]]}, {"id": "2106.00009", "submitter": "Dongxiao Zhang", "authors": "Junsheng Zeng, Hao Xu, Yuntian Chen, and Dongxiao Zhang", "title": "Deep-Learning Discovers Macroscopic Governing Equations for Viscous\n  Gravity Currents from Microscopic Simulation Data", "comments": "10 pages, 2 figures,and SI", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.AI cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep-learning has been successfully applied in a variety of science\nand engineering problems owing to its strong high-dimensional nonlinear mapping\ncapability, it is of limited use in scientific knowledge discovery. In this\nwork, we propose a deep-learning based framework to discover the macroscopic\ngoverning equation of viscous gravity current based on high-resolution\nmicroscopic simulation data without the need for prior knowledge of underlying\nterms. For two typical scenarios with different viscosity ratios, the\ndeep-learning based equations exactly capture the same dominated terms as the\ntheoretically derived equations for describing long-term asymptotic behaviors,\nwhich validates the proposed framework. Unknown macroscopic equations are then\nobtained for describing short-term behaviors, and hidden mechanisms are\neventually discovered with deep-learned explainable compensation terms and\ncorresponding coefficients. Consequently, the presented deep-learning framework\nshows considerable potential for discovering unrevealed intrinsic laws in\nscientific semantic space from raw experimental or simulation results in data\nspace.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 02:24:57 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Zeng", "Junsheng", ""], ["Xu", "Hao", ""], ["Chen", "Yuntian", ""], ["Zhang", "Dongxiao", ""]]}, {"id": "2106.00012", "submitter": "Asier Guti\\'errez-Fandi\\~no", "authors": "Asier Guti\\'errez-Fandi\\~no, David P\\'erez-Fern\\'andez, Jordi\n  Armengol-Estap\\'e, Marta Villegas", "title": "Persistent Homology Captures the Generalization of Neural Networks\n  Without A Validation Set", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.AT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The training of neural networks is usually monitored with a validation\n(holdout) set to estimate the generalization of the model. This is done instead\nof measuring intrinsic properties of the model to determine whether it is\nlearning appropriately. In this work, we suggest studying the training of\nneural networks with Algebraic Topology, specifically Persistent Homology (PH).\nUsing simplicial complex representations of neural networks, we study the PH\ndiagram distance evolution on the neural network learning process with\ndifferent architectures and several datasets. Results show that the PH diagram\ndistance between consecutive neural network states correlates with the\nvalidation accuracy, implying that the generalization error of a neural network\ncould be intrinsically estimated without any holdout set.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 09:17:31 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Guti\u00e9rrez-Fandi\u00f1o", "Asier", ""], ["P\u00e9rez-Fern\u00e1ndez", "David", ""], ["Armengol-Estap\u00e9", "Jordi", ""], ["Villegas", "Marta", ""]]}, {"id": "2106.00038", "submitter": "Lei Jiang", "authors": "Qian Lou and Lei Jiang", "title": "HEMET: A Homomorphic-Encryption-Friendly Privacy-Preserving Mobile\n  Neural Network Architecture", "comments": null, "journal-ref": "The Thirty-eighth International Conference on Machine Learning\n  2021", "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently Homomorphic Encryption (HE) is used to implement Privacy-Preserving\nNeural Networks (PPNNs) that perform inferences directly on encrypted data\nwithout decryption. Prior PPNNs adopt mobile network architectures such as\nSqueezeNet for smaller computing overhead, but we find na\\\"ively using mobile\nnetwork architectures for a PPNN does not necessarily achieve shorter inference\nlatency. Despite having less parameters, a mobile network architecture\ntypically introduces more layers and increases the HE multiplicative depth of a\nPPNN, thereby prolonging its inference latency. In this paper, we propose a\n\\textbf{HE}-friendly privacy-preserving \\textbf{M}obile neural n\\textbf{ET}work\narchitecture, \\textbf{HEMET}. Experimental results show that, compared to\nstate-of-the-art (SOTA) PPNNs, HEMET reduces the inference latency by\n$59.3\\%\\sim 61.2\\%$, and improves the inference accuracy by $0.4 \\% \\sim\n0.5\\%$.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 18:05:53 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Lou", "Qian", ""], ["Jiang", "Lei", ""]]}, {"id": "2106.00073", "submitter": "Tanujay Saha", "authors": "Jacob Brown, Tanujay Saha, Niraj K. Jha", "title": "GRAVITAS: Graphical Reticulated Attack Vectors for Internet-of-Things\n  Aggregate Security", "comments": "This article has been published in IEEE Transactions on Emerging\n  Topics in Computing, 2021", "journal-ref": null, "doi": "10.1109/TETC.2021.3082525", "report-no": null, "categories": "cs.CR cs.AI cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Internet-of-Things (IoT) and cyber-physical systems (CPSs) may consist of\nthousands of devices connected in a complex network topology. The diversity and\ncomplexity of these components present an enormous attack surface, allowing an\nadversary to exploit security vulnerabilities of different devices to execute a\npotent attack. Though significant efforts have been made to improve the\nsecurity of individual devices in these systems, little attention has been paid\nto security at the aggregate level. In this article, we describe a\ncomprehensive risk management system, called GRAVITAS, for IoT/CPS that can\nidentify undiscovered attack vectors and optimize the placement of defenses\nwithin the system for optimal performance and cost. While existing risk\nmanagement systems consider only known attacks, our model employs a machine\nlearning approach to extrapolate undiscovered exploits, enabling us to identify\nattacks overlooked by manual penetration testing (pen-testing). The model is\nflexible enough to analyze practically any IoT/CPS and provide the system\nadministrator with a concrete list of suggested defenses that can reduce system\nvulnerability at optimal cost. GRAVITAS can be employed by governments,\ncompanies, and system administrators to design secure IoT/CPS at scale,\nproviding a quantitative measure of security and efficiency in a world where\nIoT/CPS devices will soon be ubiquitous.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 19:35:23 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Brown", "Jacob", ""], ["Saha", "Tanujay", ""], ["Jha", "Niraj K.", ""]]}, {"id": "2106.00077", "submitter": "Nicolas Holliman Professor", "authors": "Nicolas Steven Holliman", "title": "Automating Visualization Quality Assessment: a Case Study in Higher\n  Education", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a case study in the use of machine+human mixed intelligence for\nvisualization quality assessment, applying automated visualization quality\nmetrics to support the human assessment of data visualizations produced as\ncoursework by students taking higher education courses. A set of image\ninformatics algorithms including edge congestion, visual saliency and colour\nanalysis generate machine analysis of student visualizations. The insight from\nthe image informatics outputs has proved helpful for the marker in assessing\nthe work and is also provided to the students as part of a written report on\ntheir work. Student and external reviewer comments suggest that the addition of\nthe image informatics outputs to the standard feedback document was a positive\nstep. We review the ethical challenges of working with assessment data and of\nautomating assessment processes.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 19:52:08 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Holliman", "Nicolas Steven", ""]]}, {"id": "2106.00116", "submitter": "Jenia Jitsev", "authors": "Mehdi Cherti and Jenia Jitsev", "title": "Effect of large-scale pre-training on full and few-shot transfer\n  learning for natural and medical images", "comments": "Preprint. Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Transfer learning aims to exploit pre-trained models for more efficient\nfollow-up training on wide range of downstream tasks and datasets, enabling\nsuccessful training also on small data. Recent line of work posits strong\nbenefits for model generalization and transfer when model size, data size, and\ncompute budget are increased for the pre-training. It remains however still\nlargely unclear whether the observed transfer improvement due to increase in\nscale also holds when source and target data distributions are far apart from\neach other. In this work we conduct large-scale pre-training on large source\ndatasets of either natural (ImageNet-21k/1k) or medical chest X-Ray images and\ncompare full and few-shot transfer using different target datasets from both\nnatural and medical imaging domains. Our observations provide evidence that\nwhile pre-training and transfer on closely related datasets do show clear\nbenefit of increasing model and data size during pre-training, such benefits\nare not clearly visible when source and target datasets are further apart.\nThese observations hold across both full and few-shot transfer and indicate\nthat scaling laws pointing to improvement of generalization and transfer with\nincreasing model and data size are incomplete and should be revised by taking\ninto account the type and proximity of the source and target data, to correctly\npredict the effect of model and data scale during pre-training on transfer.\nRemarkably, in full shot transfer to a large X-Ray chest imaging target\n(PadChest), the largest model pre-trained on ImageNet-21k slightly outperforms\nbest models pre-trained on large X-Ray chest imaging data. This indicates\npossibility to obtain high quality models for domain-specific transfer even\nwithout access to large domain-specific data, by pre-training instead on\ncomparably very large, generic source data.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 21:55:56 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 15:33:51 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Cherti", "Mehdi", ""], ["Jitsev", "Jenia", ""]]}, {"id": "2106.00133", "submitter": "Maayan Shvo", "authors": "Maayan Shvo, Zhiming Hu, Rodrigo Toro Icarte, Iqbal Mohomed, Allan\n  Jepson, Sheila A. McIlraith", "title": "AppBuddy: Learning to Accomplish Tasks in Mobile Apps via Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human beings, even small children, quickly become adept at figuring out how\nto use applications on their mobile devices. Learning to use a new app is often\nachieved via trial-and-error, accelerated by transfer of knowledge from past\nexperiences with like apps. The prospect of building a smarter smartphone - one\nthat can learn how to achieve tasks using mobile apps - is tantalizing. In this\npaper we explore the use of Reinforcement Learning (RL) with the goal of\nadvancing this aspiration. We introduce an RL-based framework for learning to\naccomplish tasks in mobile apps. RL agents are provided with states derived\nfrom the underlying representation of on-screen elements, and rewards that are\nbased on progress made in the task. Agents can interact with screen elements by\ntapping or typing. Our experimental results, over a number of mobile apps, show\nthat RL agents can learn to accomplish multi-step tasks, as well as achieve\nmodest generalization across different apps. More generally, we develop a\nplatform which addresses several engineering challenges to enable an effective\nRL training environment. Our AppBuddy platform is compatible with OpenAI Gym\nand includes a suite of mobile apps and benchmark tasks that supports a\ndiversity of RL research in the mobile app setting.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 23:02:38 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 17:56:58 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Shvo", "Maayan", ""], ["Hu", "Zhiming", ""], ["Icarte", "Rodrigo Toro", ""], ["Mohomed", "Iqbal", ""], ["Jepson", "Allan", ""], ["McIlraith", "Sheila A.", ""]]}, {"id": "2106.00134", "submitter": "Tianlong Chen", "authors": "Xuxi Chen, Zhenyu Zhang, Yongduo Sui, Tianlong Chen", "title": "GANs Can Play Lottery Tickets Too", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative adversarial networks (GANs) have gained growing popularity in\nnumerous scenarios, while usually suffer from high parameter complexities for\nresource-constrained real-world applications. However, the compression of GANs\nhas less been explored. A few works show that heuristically applying\ncompression techniques normally leads to unsatisfactory results, due to the\nnotorious training instability of GANs. In parallel, the lottery ticket\nhypothesis shows prevailing success on discriminative models, in locating\nsparse matching subnetworks capable of training in isolation to full model\nperformance. In this work, we for the first time study the existence of such\ntrainable matching subnetworks in deep GANs. For a range of GANs, we certainly\nfind matching subnetworks at 67%-74% sparsity. We observe that with or without\npruning discriminator has a minor effect on the existence and quality of\nmatching subnetworks, while the initialization weights used in the\ndiscriminator play a significant role. We then show the powerful\ntransferability of these subnetworks to unseen tasks. Furthermore, extensive\nexperimental results demonstrate that our found subnetworks substantially\noutperform previous state-of-the-art GAN compression approaches in both image\ngeneration (e.g. SNGAN) and image-to-image translation GANs (e.g. CycleGAN).\nCodes available at https://github.com/VITA-Group/GAN-LTH.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 23:03:00 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Chen", "Xuxi", ""], ["Zhang", "Zhenyu", ""], ["Sui", "Yongduo", ""], ["Chen", "Tianlong", ""]]}, {"id": "2106.00143", "submitter": "Tharindu Ranasinghe Mr", "authors": "Tharindu Ranasinghe, Constantin Orasan, Ruslan Mitkov", "title": "An Exploratory Analysis of Multilingual Word-Level Quality Estimation\n  with Cross-Lingual Transformers", "comments": "Accepted to appear at the ACL-IJCNLP 2021 Main conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most studies on word-level Quality Estimation (QE) of machine translation\nfocus on language-specific models. The obvious disadvantages of these\napproaches are the need for labelled data for each language pair and the high\ncost required to maintain several language-specific models. To overcome these\nproblems, we explore different approaches to multilingual, word-level QE. We\nshow that these QE models perform on par with the current language-specific\nmodels. In the cases of zero-shot and few-shot QE, we demonstrate that it is\npossible to accurately predict word-level quality for any given new language\npair from models trained on other language pairs. Our findings suggest that the\nword-level QE models based on powerful pre-trained transformers that we propose\nin this paper generalise well across languages, making them more useful in\nreal-world scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 23:21:10 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Ranasinghe", "Tharindu", ""], ["Orasan", "Constantin", ""], ["Mitkov", "Ruslan", ""]]}, {"id": "2106.00158", "submitter": "David Paulius", "authors": "David Paulius, Alejandro Agostini, Yu Sun and Dongheui Lee", "title": "A Road-map to Robot Task Execution with the Functional Object-Oriented\n  Network", "comments": "Ubiquitous Robots 2021 Submission -- 4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following work on joint object-action representations, the functional\nobject-oriented network (FOON) was introduced as a knowledge graph\nrepresentation for robots. Taking the form of a bipartite graph, a FOON\ncontains symbolic or high-level information that would be pertinent to a\nrobot's understanding of its environment and tasks in a way that mirrors human\nunderstanding of actions. In this work, we outline a road-map for future\ndevelopment of FOON and its application in robotic systems for task planning as\nwell as knowledge acquisition from demonstration. We propose preliminary ideas\nto show how a FOON can be created in a real-world scenario with a robot and\nhuman teacher in a way that can jointly augment existing knowledge in a FOON\nand teach a robot the skills it needs to replicate the demonstrated actions and\nsolve a given manipulation problem.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 00:43:04 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Paulius", "David", ""], ["Agostini", "Alejandro", ""], ["Sun", "Yu", ""], ["Lee", "Dongheui", ""]]}, {"id": "2106.00188", "submitter": "Rowan Zellers", "authors": "Rowan Zellers, Ari Holtzman, Matthew Peters, Roozbeh Mottaghi,\n  Aniruddha Kembhavi, Ali Farhadi, Yejin Choi", "title": "PIGLeT: Language Grounding Through Neuro-Symbolic Interaction in a 3D\n  World", "comments": "ACL 2021 camera ready, project page at\n  https://rowanzellers.com/piglet/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose PIGLeT: a model that learns physical commonsense knowledge through\ninteraction, and then uses this knowledge to ground language. We factorize\nPIGLeT into a physical dynamics model, and a separate language model. Our\ndynamics model learns not just what objects are but also what they do: glass\ncups break when thrown, plastic ones don't. We then use it as the interface to\nour language model, giving us a unified model of linguistic form and grounded\nmeaning. PIGLeT can read a sentence, simulate neurally what might happen next,\nand then communicate that result through a literal symbolic representation, or\nnatural language.\n  Experimental results show that our model effectively learns world dynamics,\nalong with how to communicate them. It is able to correctly forecast \"what\nhappens next\" given an English sentence over 80% of the time, outperforming a\n100x larger, text-to-text approach by over 10%. Likewise, its natural language\nsummaries of physical interactions are also judged by humans as more accurate\nthan LM alternatives. We present comprehensive analysis showing room for future\nwork.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 02:32:12 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Zellers", "Rowan", ""], ["Holtzman", "Ari", ""], ["Peters", "Matthew", ""], ["Mottaghi", "Roozbeh", ""], ["Kembhavi", "Aniruddha", ""], ["Farhadi", "Ali", ""], ["Choi", "Yejin", ""]]}, {"id": "2106.00200", "submitter": "Haitian Sun", "authors": "Haitian Sun, William W. Cohen, Ruslan Salakhutdinov", "title": "End-to-End Multihop Retrieval for Compositional Question Answering over\n  Long Documents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering complex questions from long documents requires aggregating multiple\npieces of evidence and then predicting the answers. In this paper, we propose a\nmulti-hop retrieval method, DocHopper, to answer compositional questions over\nlong documents. At each step, DocHopper retrieves a paragraph or sentence\nembedding from the document, mixes the retrieved result with the query, and\nupdates the query for the next step. In contrast to many other retrieval-based\nmethods (e.g., RAG or REALM) the query is not augmented with a token sequence:\ninstead, it is augmented by \"numerically\" combining it with another neural\nrepresentation. This means that model is end-to-end differentiable. We\ndemonstrate that utilizing document structure in this was can largely improve\nquestion-answering and retrieval performance on long documents. We experimented\nwith DocHopper on three different QA tasks that require reading long documents\nto answer compositional questions: discourse entailment reasoning, factual QA\nwith table and text, and information seeking QA from academic papers. DocHopper\noutperforms all baseline models and achieves state-of-the-art results on all\ndatasets. Additionally, DocHopper is efficient at inference time, being 3~10\ntimes faster than the baselines.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 03:13:35 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Sun", "Haitian", ""], ["Cohen", "William W.", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "2106.00221", "submitter": "Yong Liu", "authors": "Yong Liu, Xiangning Chen, Minhao Cheng, Cho-Jui Hsieh, Yang You", "title": "Concurrent Adversarial Learning for Large-Batch Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-batch training has become a commonly used technique when training\nneural networks with a large number of GPU/TPU processors. As batch size\nincreases, stochastic optimizers tend to converge to sharp local minima,\nleading to degraded test performance. Current methods usually use extensive\ndata augmentation to increase the batch size, but we found the performance gain\nwith data augmentation decreases as batch size increases, and data augmentation\nwill become insufficient after certain point. In this paper, we propose to use\nadversarial learning to increase the batch size in large-batch training.\nDespite being a natural choice for smoothing the decision surface and biasing\ntowards a flat region, adversarial learning has not been successfully applied\nin large-batch training since it requires at least two sequential gradient\ncomputations at each step, which will at least double the running time compared\nwith vanilla training even with a large number of processors. To overcome this\nissue, we propose a novel Concurrent Adversarial Learning (ConAdv) method that\ndecouple the sequential gradient computations in adversarial learning by\nutilizing staled parameters. Experimental results demonstrate that ConAdv can\nsuccessfully increase the batch size on both ResNet-50 and EfficientNet\ntraining on ImageNet while maintaining high accuracy. In particular, we show\nConAdv along can achieve 75.3\\% top-1 accuracy on ImageNet ResNet-50 training\nwith 96K batch size, and the accuracy can be further improved to 76.2\\% when\ncombining ConAdv with data augmentation. This is the first work successfully\nscales ResNet-50 training batch size to 96K.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 04:26:02 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Liu", "Yong", ""], ["Chen", "Xiangning", ""], ["Cheng", "Minhao", ""], ["Hsieh", "Cho-Jui", ""], ["You", "Yang", ""]]}, {"id": "2106.00241", "submitter": "Shining Liang", "authors": "Shining Liang, Ming Gong, Jian Pei, Linjun Shou, Wanli Zuo, Xianglin\n  Zuo, Daxin Jiang", "title": "Reinforced Iterative Knowledge Distillation for Cross-Lingual Named\n  Entity Recognition", "comments": "KDD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Named entity recognition (NER) is a fundamental component in many\napplications, such as Web Search and Voice Assistants. Although deep neural\nnetworks greatly improve the performance of NER, due to the requirement of\nlarge amounts of training data, deep neural networks can hardly scale out to\nmany languages in an industry setting. To tackle this challenge, cross-lingual\nNER transfers knowledge from a rich-resource language to languages with low\nresources through pre-trained multilingual language models. Instead of using\ntraining data in target languages, cross-lingual NER has to rely on only\ntraining data in source languages, and optionally adds the translated training\ndata derived from source languages. However, the existing cross-lingual NER\nmethods do not make good use of rich unlabeled data in target languages, which\nis relatively easy to collect in industry applications. To address the\nopportunities and challenges, in this paper we describe our novel practice in\nMicrosoft to leverage such large amounts of unlabeled data in target languages\nin real production settings. To effectively extract weak supervision signals\nfrom the unlabeled data, we develop a novel approach based on the ideas of\nsemi-supervised learning and reinforcement learning. The empirical study on\nthree benchmark data sets verifies that our approach establishes the new\nstate-of-the-art performance with clear edges. Now, the NER techniques reported\nin this paper are on their way to become a fundamental component for Web\nranking, Entity Pane, Answers Triggering, and Question Answering in the\nMicrosoft Bing search engine. Moreover, our techniques will also serve as part\nof the Spoken Language Understanding module for a commercial voice assistant.\nWe plan to open source the code of the prototype framework after deployment.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 05:46:22 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Liang", "Shining", ""], ["Gong", "Ming", ""], ["Pei", "Jian", ""], ["Shou", "Linjun", ""], ["Zuo", "Wanli", ""], ["Zuo", "Xianglin", ""], ["Jiang", "Daxin", ""]]}, {"id": "2106.00257", "submitter": "Yu Wang", "authors": "Yu Wang, Hongxia Jin", "title": "A Coarse to Fine Question Answering System based on Reinforcement\n  Learning", "comments": "9 pages, original work published in AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a coarse to fine question answering (CFQA) system\nbased on reinforcement learning which can efficiently processes documents with\ndifferent lengths by choosing appropriate actions. The system is designed using\nan actor-critic based deep reinforcement learning model to achieve multi-step\nquestion answering. Compared to previous QA models targeting on datasets mainly\ncontaining either short or long documents, our multi-step coarse to fine model\ntakes the merits from multiple system modules, which can handle both short and\nlong documents. The system hence obtains a much better accuracy and faster\ntrainings speed compared to the current state-of-the-art models. We test our\nmodel on four QA datasets, WIKEREADING, WIKIREADING LONG, CNN and SQuAD, and\ndemonstrate 1.3$\\%$-1.7$\\%$ accuracy improvements with 1.5x-3.4x training\nspeed-ups in comparison to the baselines using state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 06:41:48 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Wang", "Yu", ""], ["Jin", "Hongxia", ""]]}, {"id": "2106.00258", "submitter": "Qianyu Feng", "authors": "Qianyu Feng, Bang Zhang, Yi Yang", "title": "Divide and Rule: Recurrent Partitioned Network for Dynamic Processes", "comments": "arXiv admin note: text overlap with arXiv:2007.15240,\n  arXiv:2007.00631 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In general, many dynamic processes are involved with interacting variables,\nfrom physical systems to sociological analysis. The interplay of components in\nthe system can give rise to confounding dynamic behavior. Many approaches model\ntemporal sequences holistically ignoring the internal interaction which are\nimpotent in capturing the protogenic actuation. Differently, our goal is to\nrepresent a system with a part-whole hierarchy and discover the implied\ndependencies among intra-system variables: inferring the interactions that\npossess causal effects on the sub-system behavior with REcurrent partItioned\nNetwork (REIN). The proposed architecture consists of (i) a perceptive module\nthat extracts a hierarchical and temporally consistent representation of the\nobservation at multiple levels, (ii) a deductive module for determining the\nrelational connection between neurons at each level, and (iii) a statistical\nmodule that can predict the future by conditioning on the temporal\ndistributional estimation. Our model is demonstrated to be effective in\nidentifying the componential interactions with limited observation and stable\nin long-term future predictions experimented with diverse physical systems.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 06:45:56 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Feng", "Qianyu", ""], ["Zhang", "Bang", ""], ["Yang", "Yi", ""]]}, {"id": "2106.00263", "submitter": "Mengfan Liu", "authors": "Mengfan Liu, Pengyang Shao, Kun Zhang", "title": "Graph-based Exercise- and Knowledge-Aware Learning Network for Student\n  Performance Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting student performance is a fundamental task in Intelligent Tutoring\nSystems (ITSs), by which we can learn about students' knowledge level and\nprovide personalized teaching strategies for them. Researchers have made plenty\nof efforts on this task. They either leverage educational psychology methods to\npredict students' scores according to the learned knowledge proficiency, or\nmake full use of Collaborative Filtering (CF) models to represent latent\nfactors of students and exercises. However, most of these methods either\nneglect the exercise-specific characteristics (e.g., exercise materials), or\ncannot fully explore the high-order interactions between students, exercises,\nas well as knowledge concepts. To this end, we propose a Graph-based Exercise-\nand Knowledge-Aware Learning Network for accurate student score prediction.\nSpecifically, we learn students' mastery of exercises and knowledge concepts\nrespectively to model the two-fold effects of exercises and knowledge concepts.\nThen, to model the high-order interactions, we apply graph convolution\ntechniques in the prediction process. Extensive experiments on two real-world\ndatasets prove the effectiveness of our proposed Graph-EKLN.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 06:53:17 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Liu", "Mengfan", ""], ["Shao", "Pengyang", ""], ["Zhang", "Kun", ""]]}, {"id": "2106.00266", "submitter": "Oriol Corcoll", "authors": "Oriol Corcoll, Raul Vicente", "title": "Did I do that? Blame as a means to identify controlled effects in\n  reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Modeling controllable aspects of the environment enable better prioritization\nof interventions and has become a popular exploration strategy in reinforcement\nlearning methods. Despite repeatedly achieving State-of-the-Art results, this\napproach has only been studied as a proxy to a reward-based task and has not\nyet been evaluated on its own. We show that solutions relying on action\nprediction fail to model important events. Humans, on the other hand, assign\nblame to their actions to decide what they controlled. Here we propose\nControlled Effect Network (CEN), an unsupervised method based on counterfactual\nmeasures of blame. CEN is evaluated in a wide range of environments showing\nthat it can identify controlled effects better than popular models based on\naction prediction.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 06:58:31 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Corcoll", "Oriol", ""], ["Vicente", "Raul", ""]]}, {"id": "2106.00274", "submitter": "Alex D\\'iaz Santos", "authors": "Alex D\\'iaz and Damian Steele", "title": "Analysis of classifiers robust to noisy labels", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We explore contemporary robust classification algorithms for overcoming\nclass-dependant labelling noise: Forward, Importance Re-weighting and\nT-revision. The classifiers are trained and evaluated on class-conditional\nrandom label noise data while the final test data is clean. We demonstrate\nmethods for estimating the transition matrix in order to obtain better\nclassifier performance when working with noisy data. We apply deep learning to\nthree data-sets and derive an end-to-end analysis with unknown noise on the\nCIFAR data-set from scratch. The effectiveness and robustness of the\nclassifiers are analysed, and we compare and contrast the results of each\nexperiment are using top-1 accuracy as our criterion.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 07:14:51 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["D\u00edaz", "Alex", ""], ["Steele", "Damian", ""]]}, {"id": "2106.00285", "submitter": "Jiahui Li", "authors": "Jiahui Li, Kun Kuang, Baoxiang Wang, Furui Liu, Long Chen, Fei Wu and\n  Jun Xiao", "title": "Shapley Counterfactual Credits for Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": "10.1145/3447548.3467420", "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Centralized Training with Decentralized Execution (CTDE) has been a popular\nparadigm in cooperative Multi-Agent Reinforcement Learning (MARL) settings and\nis widely used in many real applications. One of the major challenges in the\ntraining process is credit assignment, which aims to deduce the contributions\nof each agent according to the global rewards. Existing credit assignment\nmethods focus on either decomposing the joint value function into individual\nvalue functions or measuring the impact of local observations and actions on\nthe global value function. These approaches lack a thorough consideration of\nthe complicated interactions among multiple agents, leading to an unsuitable\nassignment of credit and subsequently mediocre results on MARL. We propose\nShapley Counterfactual Credit Assignment, a novel method for explicit credit\nassignment which accounts for the coalition of agents. Specifically, Shapley\nValue and its desired properties are leveraged in deep MARL to credit any\ncombinations of agents, which grants us the capability to estimate the\nindividual credit for each agent. Despite this capability, the main technical\ndifficulty lies in the computational complexity of Shapley Value who grows\nfactorially as the number of agents. We instead utilize an approximation method\nvia Monte Carlo sampling, which reduces the sample complexity while maintaining\nits effectiveness. We evaluate our method on StarCraft II benchmarks across\ndifferent scenarios. Our method outperforms existing cooperative MARL\nalgorithms significantly and achieves the state-of-the-art, with especially\nlarge margins on tasks with more severe difficulties.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 07:38:34 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 04:49:11 GMT"}, {"version": "v3", "created": "Thu, 22 Jul 2021 15:01:22 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Li", "Jiahui", ""], ["Kuang", "Kun", ""], ["Wang", "Baoxiang", ""], ["Liu", "Furui", ""], ["Chen", "Long", ""], ["Wu", "Fei", ""], ["Xiao", "Jun", ""]]}, {"id": "2106.00297", "submitter": "Guoming Tang", "authors": "Yu Zhang, Guoming Tang, Qianyi Huang, Yi Wang, Hong Xu", "title": "More Behind Your Electricity Bill: a Dual-DNN Approach to Non-Intrusive\n  Load Monitoring", "comments": "9 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Non-intrusive load monitoring (NILM) is a well-known single-channel blind\nsource separation problem that aims to decompose the household energy\nconsumption into itemised energy usage of individual appliances. In this way,\nconsiderable energy savings could be achieved by enhancing household's\nawareness of energy usage. Recent investigations have shown that deep neural\nnetworks (DNNs) based approaches are promising for the NILM task. Nevertheless,\nthey normally ignore the inherent properties of appliance operations in the\nnetwork design, potentially leading to implausible results. We are thus\nmotivated to develop the dual Deep Neural Networks (dual-DNN), which aims to i)\ntake advantage of DNNs' learning capability of latent features and ii) empower\nthe DNN architecture with identification ability of universal properties.\nSpecifically in the design of dual-DNN, we adopt one subnetwork to measure\npower ratings of different appliances' operation states, and the other\nsubnetwork to identify the running states of target appliances. The final\nresult is then obtained by multiplying these two network outputs and meanwhile\nconsidering the multi-state property of household appliances. To enforce the\nsparsity property in appliance's state operating, we employ median filtering\nand hard gating mechanisms to the subnetwork for state identification. Compared\nwith the state-of-the-art NILM methods, our dual-DNN approach demonstrates a\n21.67% performance improvement in average on two public benchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 08:06:33 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Zhang", "Yu", ""], ["Tang", "Guoming", ""], ["Huang", "Qianyi", ""], ["Wang", "Yi", ""], ["Xu", "Hong", ""]]}, {"id": "2106.00306", "submitter": "Vasiliki Voukelatou", "authors": "Vasiliki Voukelatou, Ioanna Miliou, Fosca Giannotti, Luca Pappalardo", "title": "Understanding peacefulness through the world news", "comments": "19 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Peacefulness is a principal dimension of well-being for all humankind and is\nthe way out of inequity and every single form of violence. Thus, its\nmeasurement has lately drawn the attention of researchers and policy-makers.\nDuring the last years, novel digital data streams have drastically changed the\nresearch in this field. In the current study, we exploit information extracted\nfrom Global Data on Events, Location, and Tone (GDELT) digital news database,\nto capture peacefulness through the Global Peace Index (GPI). Applying\npredictive machine learning models, we demonstrate that news media attention\nfrom GDELT can be used as a proxy for measuring GPI at a monthly level.\nAdditionally, we use the SHAP methodology to obtain the most important\nvariables that drive the predictions. This analysis highlights each country's\nprofile and provides explanations for the predictions overall, and particularly\nfor the errors and the events that drive these errors. We believe that digital\ndata exploited by Social Good researchers, policy-makers, and peace-builders,\nwith data science tools as powerful as machine learning, could contribute to\nmaximize the societal benefits and minimize the risks to peacefulness.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 08:24:57 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 14:17:03 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Voukelatou", "Vasiliki", ""], ["Miliou", "Ioanna", ""], ["Giannotti", "Fosca", ""], ["Pappalardo", "Luca", ""]]}, {"id": "2106.00327", "submitter": "Zixuan Li", "authors": "Zixuan Li, Xiaolong Jin, Saiping Guan, Wei Li, Jiafeng Guo, Yuanzhuo\n  Wang and Xueqi Cheng", "title": "Search from History and Reason for Future: Two-stage Reasoning on\n  Temporal Knowledge Graphs", "comments": "ACL 2021 long paper (main conference)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal Knowledge Graphs (TKGs) have been developed and used in many\ndifferent areas. Reasoning on TKGs that predicts potential facts (events) in\nthe future brings great challenges to existing models. When facing a prediction\ntask, human beings usually search useful historical information (i.e., clues)\nin their memories and then reason for future meticulously. Inspired by this\nmechanism, we propose CluSTeR to predict future facts in a two-stage manner,\nClue Searching and Temporal Reasoning, accordingly. Specifically, at the clue\nsearching stage, CluSTeR learns a beam search policy via reinforcement learning\n(RL) to induce multiple clues from historical facts. At the temporal reasoning\nstage, it adopts a graph convolution network based sequence method to deduce\nanswers from clues. Experiments on four datasets demonstrate the substantial\nadvantages of CluSTeR compared with the state-of-the-art methods. Moreover, the\nclues found by CluSTeR further provide interpretability for the results.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 09:01:22 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Li", "Zixuan", ""], ["Jin", "Xiaolong", ""], ["Guan", "Saiping", ""], ["Li", "Wei", ""], ["Guo", "Jiafeng", ""], ["Wang", "Yuanzhuo", ""], ["Cheng", "Xueqi", ""]]}, {"id": "2106.00352", "submitter": "Mark Anderson", "authors": "Mark Anderson and Anders S{\\o}gaard and Carlos G\\'omez Rodr\\'iguez", "title": "Replicating and Extending \"Because Their Treebanks Leak\": Graph\n  Isomorphism, Covariants, and Parser Performance", "comments": "To appear in the Proceedings of the 59th Annual Meeting of the\n  Association for Computational Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  S{\\o}gaard (2020) obtained results suggesting the fraction of trees occurring\nin the test data isomorphic to trees in the training set accounts for a\nnon-trivial variation in parser performance. Similar to other statistical\nanalyses in NLP, the results were based on evaluating linear regressions.\nHowever, the study had methodological issues and was undertaken using a small\nsample size leading to unreliable results. We present a replication study in\nwhich we also bin sentences by length and find that only a small subset of\nsentences vary in performance with respect to graph isomorphism. Further, the\ncorrelation observed between parser performance and graph isomorphism in the\nwild disappears when controlling for covariants. However, in a controlled\nexperiment, where covariants are kept fixed, we do observe a strong\ncorrelation. We suggest that conclusions drawn from statistical analyses like\nthis need to be tempered and that controlled experiments can complement them by\nmore readily teasing factors apart.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 10:00:46 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 07:18:18 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Anderson", "Mark", ""], ["S\u00f8gaard", "Anders", ""], ["Rodr\u00edguez", "Carlos G\u00f3mez", ""]]}, {"id": "2106.00379", "submitter": "Luca Capezzuto", "authors": "Luca Capezzuto, Danesh Tarapore, and Sarvapali D. Ramchurn", "title": "Large-scale, Dynamic and Distributed Coalition Formation with Spatial\n  and Temporal Constraints", "comments": "18 pages, 3 figures, accepted at EUMAS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The Coalition Formation with Spatial and Temporal constraints Problem (CFSTP)\nis a multi-agent task allocation problem in which few agents have to perform\nmany tasks, each with its deadline and workload. To maximize the number of\ncompleted tasks, the agents need to cooperate by forming, disbanding and\nreforming coalitions. The original mathematical programming formulation of the\nCFSTP is difficult to implement, since it is lengthy and based on the\nproblematic Big-M method. In this paper, we propose a compact and\neasy-to-implement formulation. Moreover, we design D-CTS, a distributed version\nof the state-of-the-art CFSTP algorithm. Using public London Fire Brigade\nrecords, we create a dataset with $347588$ tasks and a test framework that\nsimulates the mobilization of firefighters in dynamic environments. In problems\nwith up to $150$ agents and $3000$ tasks, compared to DSA-SDP, a\nstate-of-the-art distributed algorithm, D-CTS completes $3.79\\% \\pm [42.22\\%,\n1.96\\%]$ more tasks, and is one order of magnitude more efficient in terms of\ncommunication overhead and time complexity. D-CTS sets the first large-scale,\ndynamic and distributed CFSTP benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 10:41:49 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Capezzuto", "Luca", ""], ["Tarapore", "Danesh", ""], ["Ramchurn", "Sarvapali D.", ""]]}, {"id": "2106.00390", "submitter": "Laura Giordano", "authors": "Laura Giordano", "title": "On the KLM properties of a fuzzy DL with Typicality", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper investigates the properties of a fuzzy logic of typicality. The\nextension of fuzzy logic with a typicality operator was proposed in recent work\nto define a fuzzy multipreference semantics for Multilayer Perceptrons, by\nregarding the deep neural network as a conditional knowledge base. In this\npaper, we study its properties. First, a monotonic extension of a fuzzy ALC\nwith typicality is considered (called ALC^FT) and a reformulation the KLM\nproperties of a preferential consequence relation for this logic is devised.\nMost of the properties are satisfied, depending on the reformulation and on the\nfuzzy combination functions considered. We then strengthen ALC^FT with a\nclosure construction by introducing a notion of faithful model of a weighted\nknowledge base, which generalizes the notion of coherent model of a conditional\nknowledge base previously introduced, and we study its properties.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 10:57:46 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 12:31:46 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Giordano", "Laura", ""]]}, {"id": "2106.00393", "submitter": "Francesco Giannini", "authors": "Giuseppe Marra, Michelangelo Diligenti, Francesco Giannini and Marco\n  Maggini", "title": "Learning Representations for Sub-Symbolic Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuro-symbolic methods integrate neural architectures, knowledge\nrepresentation and reasoning. However, they have been struggling at both\ndealing with the intrinsic uncertainty of the observations and scaling to real\nworld applications. This paper presents Relational Reasoning Networks (R2N), a\nnovel end-to-end model that performs relational reasoning in the latent space\nof a deep learner architecture, where the representations of constants, ground\natoms and their manipulations are learned in an integrated fashion. Unlike flat\narchitectures like Knowledge Graph Embedders, which can only represent\nrelations between entities, R2Ns define an additional computational structure,\naccounting for higher-level relations among the ground atoms. The considered\nrelations can be explicitly known, like the ones defined by logic formulas, or\ndefined as unconstrained correlations among groups of ground atoms. R2Ns can be\napplied to purely symbolic tasks or as a neuro-symbolic platform to integrate\nlearning and reasoning in heterogeneous problems with both symbolic and\nfeature-based represented entities. The proposed model bridges the gap between\nprevious neuro-symbolic methods that have been either limited in terms of\nscalability or expressivity. The proposed methodology is shown to achieve\nstate-of-the-art results in different experimental settings.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 11:02:22 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Marra", "Giuseppe", ""], ["Diligenti", "Michelangelo", ""], ["Giannini", "Francesco", ""], ["Maggini", "Marco", ""]]}, {"id": "2106.00421", "submitter": "Yang Li", "authors": "Yang Li, Yu Shen, Wentao Zhang, Yuanwei Chen, Huaijun Jiang, Mingchao\n  Liu, Jiawei Jiang, Jinyang Gao, Wentao Wu, Zhi Yang, Ce Zhang, Bin Cui", "title": "OpenBox: A Generalized Black-box Optimization Service", "comments": null, "journal-ref": "Proceedings of the 27th ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining (KDD-2021)", "doi": "10.1145/3447548.3467061", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Black-box optimization (BBO) has a broad range of applications, including\nautomatic machine learning, engineering, physics, and experimental design.\nHowever, it remains a challenge for users to apply BBO methods to their\nproblems at hand with existing software packages, in terms of applicability,\nperformance, and efficiency. In this paper, we build OpenBox, an open-source\nand general-purpose BBO service with improved usability. The modular design\nbehind OpenBox also facilitates flexible abstraction and optimization of basic\nBBO components that are common in other existing systems. OpenBox is\ndistributed, fault-tolerant, and scalable. To improve efficiency, OpenBox\nfurther utilizes \"algorithm agnostic\" parallelization and transfer learning.\nOur experimental results demonstrate the effectiveness and efficiency of\nOpenBox compared to existing systems.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 12:02:50 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 13:27:41 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Li", "Yang", ""], ["Shen", "Yu", ""], ["Zhang", "Wentao", ""], ["Chen", "Yuanwei", ""], ["Jiang", "Huaijun", ""], ["Liu", "Mingchao", ""], ["Jiang", "Jiawei", ""], ["Gao", "Jinyang", ""], ["Wu", "Wentao", ""], ["Yang", "Zhi", ""], ["Zhang", "Ce", ""], ["Cui", "Bin", ""]]}, {"id": "2106.00451", "submitter": "Fan Huang", "authors": "Fan Huang", "title": "Highlight Timestamp Detection Model for Comedy Videos via Multimodal\n  Sentiment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the videos on the Internet are prevailing. The precise and in-depth\nunderstanding of the videos is a difficult but valuable problem for both\nplatforms and researchers. The existing video understand models do well in\nobject recognition tasks but currently still cannot understand the abstract and\ncontextual features like highlight humor frames in comedy videos. The current\nindustrial works are also mainly focused on the basic category classification\ntask based on the appearances of objects. The feature detection methods for the\nabstract category remains blank. A data structure that includes the information\nof video frames, audio spectrum and texts provide a new direction to explore.\nThe multimodal models are proposed to make this in-depth video understanding\nmission possible. In this paper, we analyze the difficulties in abstract\nunderstanding of videos and propose a multimodal structure to obtain\nstate-of-the-art performance in this field. Then we select several benchmarks\nfor multimodal video understanding and apply the most suitable model to find\nthe best performance. At last, we evaluate the overall spotlights and drawbacks\nof the models and methods in this paper and point out the possible directions\nfor further improvements.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 08:39:19 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Huang", "Fan", ""]]}, {"id": "2106.00456", "submitter": "Thanh Vinh Vo", "authors": "Thanh Vinh Vo, Trong Nghia Hoang, Young Lee, Tze-Yun Leong", "title": "Federated Estimation of Causal Effects from Observational Data", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern applications collect data that comes in federated spirit, with\ndata kept locally and undisclosed. Till date, most insight into the causal\ninference requires data to be stored in a central repository. We present a\nnovel framework for causal inference with federated data sources. We assess and\nintegrate local causal effects from different private data sources without\ncentralizing them. Then, the treatment effects on subjects from observational\ndata using a non-parametric reformulation of the classical potential outcomes\nframework is estimated. We model the potential outcomes as a random function\ndistributed by Gaussian processes, whose defining parameters can be efficiently\nlearned from multiple data sources, respecting privacy constraints. We\ndemonstrate the promise and efficiency of the proposed approach through a set\nof simulated and real-world benchmark examples.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 08:06:00 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Vo", "Thanh Vinh", ""], ["Hoang", "Trong Nghia", ""], ["Lee", "Young", ""], ["Leong", "Tze-Yun", ""]]}, {"id": "2106.00459", "submitter": "Kuldeep Singh", "authors": "Abhishek Nadgeri, Anson Bastos, Kuldeep Singh, Isaiah Onando Mulang',\n  Johannes Hoffart, Saeedeh Shekarpour, Vijay Saraswat", "title": "KGPool: Dynamic Knowledge Graph Context Selection for Relation\n  Extraction", "comments": "ACL 2021 (findings)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel method for relation extraction (RE) from a single\nsentence, mapping the sentence and two given entities to a canonical fact in a\nknowledge graph (KG). Especially in this presumed sentential RE setting, the\ncontext of a single sentence is often sparse. This paper introduces the KGPool\nmethod to address this sparsity, dynamically expanding the context with\nadditional facts from the KG. It learns the representation of these facts\n(entity alias, entity descriptions, etc.) using neural methods, supplementing\nthe sentential context. Unlike existing methods that statically use all\nexpanded facts, KGPool conditions this expansion on the sentence. We study the\nefficacy of KGPool by evaluating it with different neural models and KGs\n(Wikidata and NYT Freebase). Our experimental evaluation on standard datasets\nshows that by feeding the KGPool representation into a Graph Neural Network,\nthe overall method is significantly more accurate than state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 13:12:24 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 20:48:02 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Nadgeri", "Abhishek", ""], ["Bastos", "Anson", ""], ["Singh", "Kuldeep", ""], ["Mulang'", "Isaiah Onando", ""], ["Hoffart", "Johannes", ""], ["Shekarpour", "Saeedeh", ""], ["Saraswat", "Vijay", ""]]}, {"id": "2106.00461", "submitter": "Paolo Bajardi", "authors": "Elvio G. Amparore and Alan Perotti and Paolo Bajardi", "title": "To trust or not to trust an explanation: using LEAF to evaluate local\n  linear XAI methods", "comments": "16 pages, 8 figures", "journal-ref": "PeerJ Computer Science 7:e479 (2021)", "doi": "10.7717/peerj-cs.479", "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The main objective of eXplainable Artificial Intelligence (XAI) is to provide\neffective explanations for black-box classifiers. The existing literature lists\nmany desirable properties for explanations to be useful, but there is no\nconsensus on how to quantitatively evaluate explanations in practice. Moreover,\nexplanations are typically used only to inspect black-box models, and the\nproactive use of explanations as a decision support is generally overlooked.\nAmong the many approaches to XAI, a widely adopted paradigm is Local Linear\nExplanations - with LIME and SHAP emerging as state-of-the-art methods. We show\nthat these methods are plagued by many defects including unstable explanations,\ndivergence of actual implementations from the promised theoretical properties,\nand explanations for the wrong label. This highlights the need to have standard\nand unbiased evaluation procedures for Local Linear Explanations in the XAI\nfield. In this paper we address the problem of identifying a clear and\nunambiguous set of metrics for the evaluation of Local Linear Explanations.\nThis set includes both existing and novel metrics defined specifically for this\nclass of explanations. All metrics have been included in an open Python\nframework, named LEAF. The purpose of LEAF is to provide a reference for end\nusers to evaluate explanations in a standardised and unbiased way, and to guide\nresearchers towards developing improved explainable techniques.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 13:14:12 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Amparore", "Elvio G.", ""], ["Perotti", "Alan", ""], ["Bajardi", "Paolo", ""]]}, {"id": "2106.00497", "submitter": "Li Su", "authors": "Yu-Te Wu, Yin-Jyun Luo, Tsung-Ping Chen, I-Chieh Wei, Jui-Yang Hsu,\n  Yi-Chin Chuang, Li Su", "title": "Omnizart: A General Toolbox for Automatic Music Transcription", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present and release Omnizart, a new Python library that provides a\nstreamlined solution to automatic music transcription (AMT). Omnizart\nencompasses modules that construct the life-cycle of deep learning-based AMT,\nand is designed for ease of use with a compact command-line interface. To the\nbest of our knowledge, Omnizart is the first transcription toolkit which offers\nmodels covering a wide class of instruments ranging from solo, instrument\nensembles, percussion instruments to vocal, as well as models for chord\nrecognition and beat/downbeat tracking, two music information retrieval (MIR)\ntasks highly related to AMT.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 14:00:14 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Wu", "Yu-Te", ""], ["Luo", "Yin-Jyun", ""], ["Chen", "Tsung-Ping", ""], ["Wei", "I-Chieh", ""], ["Hsu", "Jui-Yang", ""], ["Chuang", "Yi-Chin", ""], ["Su", "Li", ""]]}, {"id": "2106.00501", "submitter": "Fuhui Zhou", "authors": "Qihui Wu, Tianchen Ruan, Fuhui Zhou, Yang Huang, Fan Xu, Shijin Zhao,\n  Ya Liu, and Xuyang Huang", "title": "A Unified Cognitive Learning Framework for Adapting to Dynamic\n  Environment and Tasks", "comments": "This paper has been submitted to IEEE Wireless Communications\n  Magazine(minor revision)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many machine learning frameworks have been proposed and used in wireless\ncommunications for realizing diverse goals. However, their incapability of\nadapting to the dynamic wireless environment and tasks and of self-learning\nlimit their extensive applications and achievable performance. Inspired by the\ngreat flexibility and adaptation of primate behaviors due to the brain\ncognitive mechanism, a unified cognitive learning (CL) framework is proposed\nfor the dynamic wireless environment and tasks. The mathematical framework for\nour proposed CL is established. Using the public and authoritative dataset, we\ndemonstrate that our proposed CL framework has three advantages, namely, the\ncapability of adapting to the dynamic environment and tasks, the self-learning\ncapability and the capability of 'good money driving out bad money' by taking\nmodulation recognition as an example. The proposed CL framework can enrich the\ncurrent learning frameworks and widen the applications.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 14:08:20 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Wu", "Qihui", ""], ["Ruan", "Tianchen", ""], ["Zhou", "Fuhui", ""], ["Huang", "Yang", ""], ["Xu", "Fan", ""], ["Zhao", "Shijin", ""], ["Liu", "Ya", ""], ["Huang", "Xuyang", ""]]}, {"id": "2106.00510", "submitter": "Deepanway Ghosal", "authors": "Deepanway Ghosal and Pengfei Hong and Siqi Shen and Navonil Majumder\n  and Rada Mihalcea and Soujanya Poria", "title": "CIDER: Commonsense Inference for Dialogue Explanation and Reasoning", "comments": "SIGDIAL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Commonsense inference to understand and explain human language is a\nfundamental research problem in natural language processing. Explaining human\nconversations poses a great challenge as it requires contextual understanding,\nplanning, inference, and several aspects of reasoning including causal,\ntemporal, and commonsense reasoning. In this work, we introduce CIDER -- a\nmanually curated dataset that contains dyadic dialogue explanations in the form\nof implicit and explicit knowledge triplets inferred using contextual\ncommonsense inference. Extracting such rich explanations from conversations can\nbe conducive to improving several downstream applications. The annotated\ntriplets are categorized by the type of commonsense knowledge present (e.g.,\ncausal, conditional, temporal). We set up three different tasks conditioned on\nthe annotated dataset: Dialogue-level Natural Language Inference, Span\nExtraction, and Multi-choice Span Selection. Baseline results obtained with\ntransformer-based models reveal that the tasks are difficult, paving the way\nfor promising future research. The dataset and the baseline implementations are\npublicly available at https://cider-task.github.io/cider/.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 14:14:46 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 02:47:05 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Ghosal", "Deepanway", ""], ["Hong", "Pengfei", ""], ["Shen", "Siqi", ""], ["Majumder", "Navonil", ""], ["Mihalcea", "Rada", ""], ["Poria", "Soujanya", ""]]}, {"id": "2106.00517", "submitter": "Zhou Tianze", "authors": "Tianze Zhou, Fubiao Zhang, Kun Shao, Kai Li, Wenhan Huang, Jun Luo,\n  Weixun Wang, Yaodong Yang, Hangyu Mao, Bin Wang, Dong Li, Wulong Liu, Jianye\n  Hao", "title": "Cooperative Multi-Agent Transfer Learning with Level-Adaptive Credit\n  Assignment", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Extending transfer learning to cooperative multi-agent reinforcement learning\n(MARL) has recently received much attention. In contrast to the single-agent\nsetting, the coordination indispensable in cooperative MARL constrains each\nagent's policy. However, existing transfer methods focus exclusively on agent\npolicy and ignores coordination knowledge. We propose a new architecture that\nrealizes robust coordination knowledge transfer through appropriate\ndecomposition of the overall coordination into several coordination patterns.\nWe use a novel mixing network named level-adaptive QTransformer\n(LA-QTransformer) to realize agent coordination that considers credit\nassignment, with appropriate coordination patterns for different agents\nrealized by a novel level-adaptive Transformer (LA-Transformer) dedicated to\nthe transfer of coordination knowledge. In addition, we use a novel agent\nnetwork named Population Invariant agent with Transformer (PIT) to realize the\ncoordination transfer in more varieties of scenarios. Extensive experiments in\nStarCraft II micro-management show that LA-QTransformer together with PIT\nachieves superior performance compared with state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 14:22:57 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 06:16:03 GMT"}, {"version": "v3", "created": "Thu, 3 Jun 2021 09:30:05 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Zhou", "Tianze", ""], ["Zhang", "Fubiao", ""], ["Shao", "Kun", ""], ["Li", "Kai", ""], ["Huang", "Wenhan", ""], ["Luo", "Jun", ""], ["Wang", "Weixun", ""], ["Yang", "Yaodong", ""], ["Mao", "Hangyu", ""], ["Wang", "Bin", ""], ["Li", "Dong", ""], ["Liu", "Wulong", ""], ["Hao", "Jianye", ""]]}, {"id": "2106.00524", "submitter": "Marina Delianidi", "authors": "Marina Delianidi, Konstantinos Diamantaras, George Chrysogonidis,\n  Vasileios Nikiforidis", "title": "Student Performance Prediction Using Dynamic Neural Models", "comments": "9 pages, 4 figures, to be published in EDM 2021: the 14th\n  International Conference on Educational Data Mining, June 29 - July 2, 2021,\n  Paris, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of predicting the correctness of the student's\nresponse on the next exam question based on their previous interactions in the\ncourse of their learning and evaluation process. We model the student\nperformance as a dynamic problem and compare the two major classes of dynamic\nneural architectures for its solution, namely the finite-memory Time Delay\nNeural Networks (TDNN) and the potentially infinite-memory Recurrent Neural\nNetworks (RNN). Since the next response is a function of the knowledge state of\nthe student and this, in turn, is a function of their previous responses and\nthe skills associated with the previous questions, we propose a two-part\nnetwork architecture. The first part employs a dynamic neural network (either\nTDNN or RNN) to trace the student knowledge state. The second part applies on\ntop of the dynamic part and it is a multi-layer feed-forward network which\ncompletes the classification task of predicting the student response based on\nour estimate of the student knowledge state. Both input skills and previous\nresponses are encoded using different embeddings. Regarding the skill\nembeddings we tried two different initialization schemes using (a) random\nvectors and (b) pretrained vectors matching the textual descriptions of the\nskills. Our experiments show that the performance of the RNN approach is better\ncompared to the TDNN approach in all datasets that we have used. Also, we show\nthat our RNN architecture outperforms the state-of-the-art models in four out\nof five datasets. It is worth noting that the TDNN approach also outperforms\nthe state of the art models in four out of five datasets, although it is\nslightly worse than our proposed RNN approach. Finally, contrary to our\nexpectations, we find that the initialization of skill embeddings using\npretrained vectors offers practically no advantage over random initialization.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 14:40:28 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Delianidi", "Marina", ""], ["Diamantaras", "Konstantinos", ""], ["Chrysogonidis", "George", ""], ["Nikiforidis", "Vasileios", ""]]}, {"id": "2106.00526", "submitter": "Zhenglun Kong", "authors": "Wei Niu, Zhenglun Kong, Geng Yuan, Weiwen Jiang, Jiexiong Guan, Caiwen\n  Ding, Pu Zhao, Sijia Liu, Bin Ren, Yanzhi Wang", "title": "A Compression-Compilation Framework for On-mobile Real-time BERT\n  Applications", "comments": "arXiv admin note: substantial text overlap with arXiv:2009.06823", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer-based deep learning models have increasingly demonstrated high\naccuracy on many natural language processing (NLP) tasks. In this paper, we\npropose a compression-compilation co-design framework that can guarantee the\nidentified model to meet both resource and real-time specifications of mobile\ndevices. Our framework applies a compiler-aware neural architecture\noptimization method (CANAO), which can generate the optimal compressed model\nthat balances both accuracy and latency. We are able to achieve up to 7.8x\nspeedup compared with TensorFlow-Lite with only minor accuracy loss. We present\ntwo types of BERT applications on mobile devices: Question Answering (QA) and\nText Generation. Both can be executed in real-time with latency as low as 45ms.\nVideos for demonstrating the framework can be found on\nhttps://www.youtube.com/watch?v=_WIRvK_2PZI\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 16:19:11 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 17:58:13 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Niu", "Wei", ""], ["Kong", "Zhenglun", ""], ["Yuan", "Geng", ""], ["Jiang", "Weiwen", ""], ["Guan", "Jiexiong", ""], ["Ding", "Caiwen", ""], ["Zhao", "Pu", ""], ["Liu", "Sijia", ""], ["Ren", "Bin", ""], ["Wang", "Yanzhi", ""]]}, {"id": "2106.00538", "submitter": "Laurens Arp", "authors": "Laurens Arp", "title": "A Markov Reward Process-Based Approach to Spatial Interpolation", "comments": "This is a Master Thesis for the Computer Science MSc programme at\n  Leiden University", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The interpolation of spatial data can be of tremendous value in various\napplications, such as forecasting weather from only a few measurements of\nmeteorological or remote sensing data. Existing methods for spatial\ninterpolation, such as variants of kriging and spatial autoregressive models,\ntend to suffer from at least one of the following limitations: (a) the\nassumption of stationarity, (b) the assumption of isotropy, and (c) the\ntrade-off between modelling local or global spatial interaction. Addressing\nthese issues in this work, we propose the use of Markov reward processes (MRPs)\nas a spatial interpolation method, and we introduce three variants thereof: (i)\na basic static discount MRP (SD-MRP), (ii) an accurate but mostly theoretical\noptimised MRP (O-MRP), and (iii) a transferable weight prediction MRP (WP-MRP).\nAll variants of MRP interpolation operate locally, while also implicitly\naccounting for global spatial relationships in the entire system through\nrecursion. Additionally, O-MRP and WP-MRP no longer assume stationarity and are\nrobust to anisotropy. We evaluated our proposed methods by comparing the mean\nabsolute errors of their interpolated grid cells to those of 7 common\nbaselines, selected from models based on spatial autocorrelation, (spatial)\nregression, and deep learning.\n  We performed detailed evaluations on two publicly available datasets (local\nGDP values, and COVID-19 patient trajectory data). The results from these\nexperiments clearly show the competitive advantage of MRP interpolation, which\nachieved significantly lower errors than the existing methods in 23 out of 40\nexperimental conditions, or 35 out of 40 when including O-MRP.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 14:52:54 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 11:13:33 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Arp", "Laurens", ""]]}, {"id": "2106.00543", "submitter": "Amrit Singh Bedi", "authors": "Junyu Zhang, Amrit Singh Bedi, Mengdi Wang, and Alec Koppel", "title": "MARL with General Utilities via Decentralized Shadow Reward Actor-Critic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We posit a new mechanism for cooperation in multi-agent reinforcement\nlearning (MARL) based upon any nonlinear function of the team's long-term\nstate-action occupancy measure, i.e., a \\emph{general utility}. This subsumes\nthe cumulative return but also allows one to incorporate risk-sensitivity,\nexploration, and priors. % We derive the {\\bf D}ecentralized {\\bf S}hadow\nReward {\\bf A}ctor-{\\bf C}ritic (DSAC) in which agents alternate between policy\nevaluation (critic), weighted averaging with neighbors (information mixing),\nand local gradient updates for their policy parameters (actor). DSAC augments\nthe classic critic step by requiring agents to (i) estimate their local\noccupancy measure in order to (ii) estimate the derivative of the local utility\nwith respect to their occupancy measure, i.e., the \"shadow reward\". DSAC\nconverges to $\\epsilon$-stationarity in $\\mathcal{O}(1/\\epsilon^{2.5})$\n(Theorem \\ref{theorem:final}) or faster $\\mathcal{O}(1/\\epsilon^{2})$\n(Corollary \\ref{corollary:communication}) steps with high probability,\ndepending on the amount of communications. We further establish the\nnon-existence of spurious stationary points for this problem, that is, DSAC\nfinds the globally optimal policy (Corollary \\ref{corollary:global}).\nExperiments demonstrate the merits of goals beyond the cumulative return in\ncooperative MARL.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 19:05:48 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 17:20:27 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Zhang", "Junyu", ""], ["Bedi", "Amrit Singh", ""], ["Wang", "Mengdi", ""], ["Koppel", "Alec", ""]]}, {"id": "2106.00545", "submitter": "Victor Veitch", "authors": "Victor Veitch, Alexander D'Amour, Steve Yadlowsky, Jacob Eisenstein", "title": "Counterfactual Invariance to Spurious Correlations: Why and How to Pass\n  Stress Tests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Informally, a `spurious correlation' is the dependence of a model on some\naspect of the input data that an analyst thinks shouldn't matter. In machine\nlearning, these have a know-it-when-you-see-it character; e.g., changing the\ngender of a sentence's subject changes a sentiment predictor's output. To check\nfor spurious correlations, we can `stress test' models by perturbing irrelevant\nparts of input data and seeing if model predictions change. In this paper, we\nstudy stress testing using the tools of causal inference. We introduce\n\\emph{counterfactual invariance} as a formalization of the requirement that\nchanging irrelevant parts of the input shouldn't change model predictions. We\nconnect counterfactual invariance to out-of-domain model performance, and\nprovide practical schemes for learning (approximately) counterfactual invariant\npredictors (without access to counterfactual examples). It turns out that both\nthe means and implications of counterfactual invariance depend fundamentally on\nthe true underlying causal structure of the data. Distinct causal structures\nrequire distinct regularization schemes to induce counterfactual invariance.\nSimilarly, counterfactual invariance implies different domain shift guarantees\ndepending on the underlying causal structure. This theory is supported by\nempirical results on text classification.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 14:39:38 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 03:11:24 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Veitch", "Victor", ""], ["D'Amour", "Alexander", ""], ["Yadlowsky", "Steve", ""], ["Eisenstein", "Jacob", ""]]}, {"id": "2106.00546", "submitter": "Joao Marques-Silva", "authors": "Yacine Izza, Alexey Ignatiev, Nina Narodytska, Martin C. Cooper, Joao\n  Marques-Silva", "title": "Efficient Explanations With Relevant Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent work proposed $\\delta$-relevant inputs (or sets) as a probabilistic\nexplanation for the predictions made by a classifier on a given input.\n$\\delta$-relevant sets are significant because they serve to relate\n(model-agnostic) Anchors with (model-accurate) PI- explanations, among other\nexplanation approaches. Unfortunately, the computation of smallest size\n$\\delta$-relevant sets is complete for ${NP}^{PP}$, rendering their computation\nlargely infeasible in practice. This paper investigates solutions for tackling\nthe practical limitations of $\\delta$-relevant sets. First, the paper\nalternatively considers the computation of subset-minimal sets. Second, the\npaper studies concrete families of classifiers, including decision trees among\nothers. For these cases, the paper shows that the computation of subset-minimal\n$\\delta$-relevant sets is in NP, and can be solved with a polynomial number of\ncalls to an NP oracle. The experimental evaluation compares the proposed\napproach with heuristic explainers for the concrete case of the classifiers\nstudied in the paper, and confirms the advantage of the proposed solution over\nthe state of the art.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 14:57:58 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Izza", "Yacine", ""], ["Ignatiev", "Alexey", ""], ["Narodytska", "Nina", ""], ["Cooper", "Martin C.", ""], ["Marques-Silva", "Joao", ""]]}, {"id": "2106.00588", "submitter": "Jianbiao Mei", "authors": "Jianbiao Mei, Mengmeng Wang, Yeneng Lin, Yong Liu", "title": "TransVOS: Video Object Segmentation with Transformers", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Space-Time Memory Network (STM) based methods have achieved\nstate-of-the-art performance in semi-supervised video object segmentation\n(VOS). A critical problem in this task is how to model the dependency both\namong different frames and inside every frame. However, most of these methods\nneglect the spatial relationships (inside each frame) and do not make full use\nof the temporal relationships (among different frames). In this paper, we\npropose a new transformer-based framework, termed TransVOS, introducing a\nvision transformer to fully exploit and model both the temporal and spatial\nrelationships. Moreover, most STM-based approaches employ two disparate\nencoders to extract features of two significant inputs, i.e., reference sets\n(history frames with predicted masks) and query frame, respectively, increasing\nthe models' parameters and complexity. To slim the popular two-encoder pipeline\nwhile keeping the effectiveness, we design a single two-path feature extractor\nto encode the above two inputs in a unified way. Extensive experiments\ndemonstrate the superiority of our TransVOS over state-of-the-art methods on\nboth DAVIS and YouTube-VOS datasets. Codes will be released when it is\npublished.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 15:56:10 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Mei", "Jianbiao", ""], ["Wang", "Mengmeng", ""], ["Lin", "Yeneng", ""], ["Liu", "Yong", ""]]}, {"id": "2106.00592", "submitter": "Kaiyang Zhou", "authors": "Kaiyang Zhou, Chen Change Loy, Ziwei Liu", "title": "Semi-Supervised Domain Generalization with Stochastic StyleMatch", "comments": "Tech report. Code available at\n  https://github.com/KaiyangZhou/ssdg-benchmark", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing research on domain generalization assumes source data gathered\nfrom multiple domains are fully annotated. However, in real-world applications,\nwe might have only a few labels available from each source domain due to high\nannotation cost, along with abundant unlabeled data that are much easier to\nobtain. In this work, we investigate semi-supervised domain generalization\n(SSDG), a more realistic and practical setting. Our proposed approach,\nStyleMatch, is inspired by FixMatch, a state-of-the-art semi-supervised\nlearning method based on pseudo-labeling, with several new ingredients tailored\nto solve SSDG. Specifically, 1) to mitigate overfitting in the scarce labeled\nsource data while improving robustness against noisy pseudo labels, we\nintroduce stochastic modeling to the classifier's weights, seen as class\nprototypes, with Gaussian distributions. 2) To enhance generalization under\ndomain shift, we upgrade FixMatch's two-view consistency learning paradigm\nbased on weak and strong augmentations to a multi-view version with style\naugmentation as the third complementary view. To provide a comprehensive study\nand evaluation, we establish two SSDG benchmarks, which cover a wide range of\nstrong baseline methods developed in relevant areas including domain\ngeneralization and semi-supervised learning. Extensive experiments demonstrate\nthat StyleMatch achieves the best out-of-distribution generalization\nperformance in the low-data regime. We hope our approach and benchmarks can\npave the way for future research on data-efficient and generalizable learning\nsystems.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 16:00:08 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Zhou", "Kaiyang", ""], ["Loy", "Chen Change", ""], ["Liu", "Ziwei", ""]]}, {"id": "2106.00611", "submitter": "Andriy Temko Dr", "authors": "Alison OShea, Rehan Ahmed, Gordon Lightbody, Sean Mathieson, Elena\n  Pavlidis, Rhodri Lloyd, Francesco Pisani, Willian Marnane, Geraldine Boylan,\n  Andriy Temko", "title": "Deep Learning for EEG Seizure Detection in Preterm Infants", "comments": null, "journal-ref": "Int J Neural Syst (2021)", "doi": "10.1142/S0129065721500088", "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  EEG is the gold standard for seizure detection in the newborn infant, but EEG\ninterpretation in the preterm group is particularly challenging; trained\nexperts are scarce and the task of interpreting EEG in real-time is arduous.\nPreterm infants are reported to have a higher incidence of seizures compared to\nterm infants. Preterm EEG morphology differs from that of term infants, which\nimplies that seizure detection algorithms trained on term EEG may not be\nappropriate. The task of developing preterm specific algorithms becomes\nextra-challenging given the limited amount of annotated preterm EEG data\navailable. This paper explores novel deep learning (DL) architectures for the\ntask of neonatal seizure detection in preterm infants. The study tests and\ncompares several approaches to address the problem: training on data from\nfull-term infants; training on data from preterm infants; training on\nage-specific preterm data and transfer learning. The system performance is\nassessed on a large database of continuous EEG recordings of 575h in duration.\nIt is shown that the accuracy of a validated term-trained EEG seizure detection\nalgorithm, based on a support vector machine classifier, when tested on preterm\ninfants falls well short of the performance achieved for full-term infants. An\nAUC of 88.3% was obtained when tested on preterm EEG as compared to 96.6%\nobtained when tested on term EEG. When re-trained on preterm EEG, the\nperformance marginally increases to 89.7%. An alternative DL approach shows a\nmore stable trend when tested on the preterm cohort, starting with an AUC of\n93.3% for the term-trained algorithm and reaching 95.0% by transfer learning\nfrom the term model using available preterm data.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 14:03:56 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["OShea", "Alison", ""], ["Ahmed", "Rehan", ""], ["Lightbody", "Gordon", ""], ["Mathieson", "Sean", ""], ["Pavlidis", "Elena", ""], ["Lloyd", "Rhodri", ""], ["Pisani", "Francesco", ""], ["Marnane", "Willian", ""], ["Boylan", "Geraldine", ""], ["Temko", "Andriy", ""]]}, {"id": "2106.00655", "submitter": "Michael Crosscombe", "authors": "Michael Crosscombe and Jonathan Lawry", "title": "The Impact of Network Connectivity on Collective Learning", "comments": "13 pages, 5 figures. To appear at the 15th International Symposium on\n  Distributed Autonomous Robotic Systems 2021. Presented at the joint\n  DARS-SWARM 2021 symposium held (virtually) in Kyoto, Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In decentralised autonomous systems it is the interactions between individual\nagents which govern the collective behaviours of the system. These local-level\ninteractions are themselves often governed by an underlying network structure.\nThese networks are particularly important for collective learning and\ndecision-making whereby agents must gather evidence from their environment and\npropagate this information to other agents in the system. Models for collective\nbehaviours may often rely upon the assumption of total connectivity between\nagents to provide effective information sharing within the system, but this\nassumption may be ill-advised. In this paper we investigate the impact that the\nunderlying network has on performance in the context of collective learning.\nThrough simulations we study small-world networks with varying levels of\nconnectivity and randomness and conclude that totally-connected networks result\nin higher average error when compared to networks with less connectivity.\nFurthermore, we show that networks of high regularity outperform networks with\nincreasing levels of random connectivity.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 17:39:26 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 14:10:45 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Crosscombe", "Michael", ""], ["Lawry", "Jonathan", ""]]}, {"id": "2106.00660", "submitter": "Ilia Shumailov", "authors": "David Khachaturov, Ilia Shumailov, Yiren Zhao, Nicolas Papernot, Ross\n  Anderson", "title": "Markpainting: Adversarial Machine Learning meets Inpainting", "comments": "Proceedings of the 38th International Conference on Machine Learning\n  (ICML 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Inpainting is a learned interpolation technique that is based on generative\nmodeling and used to populate masked or missing pieces in an image; it has wide\napplications in picture editing and retouching. Recently, inpainting started\nbeing used for watermark removal, raising concerns. In this paper we study how\nto manipulate it using our markpainting technique. First, we show how an image\nowner with access to an inpainting model can augment their image in such a way\nthat any attempt to edit it using that model will add arbitrary visible\ninformation. We find that we can target multiple different models\nsimultaneously with our technique. This can be designed to reconstitute a\nwatermark if the editor had been trying to remove it. Second, we show that our\nmarkpainting technique is transferable to models that have different\narchitectures or were trained on different datasets, so watermarks created\nusing it are difficult for adversaries to remove. Markpainting is novel and can\nbe used as a manipulation alarm that becomes visible in the event of\ninpainting.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 17:45:52 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Khachaturov", "David", ""], ["Shumailov", "Ilia", ""], ["Zhao", "Yiren", ""], ["Papernot", "Nicolas", ""], ["Anderson", "Ross", ""]]}, {"id": "2106.00661", "submitter": "Tom Zahavy", "authors": "Tom Zahavy, Brendan O'Donoghue, Guillaume Desjardins and Satinder\n  Singh", "title": "Reward is enough for convex MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximising a cumulative reward function that is Markov and stationary, i.e.,\ndefined over state-action pairs and independent of time, is sufficient to\ncapture many kinds of goals in a Markov Decision Process (MDP) based on the\nReinforcement Learning (RL) problem formulation. However, not all goals can be\ncaptured in this manner. Specifically, it is easy to see that Convex MDPs in\nwhich goals are expressed as convex functions of stationary distributions\ncannot, in general, be formulated in this manner. In this paper, we reformulate\nthe convex MDP problem as a min-max game between the policy and cost (negative\nreward) players using Fenchel duality and propose a meta-algorithm for solving\nit. We show that the average of the policies produced by an RL agent that\nmaximizes the non-stationary reward produced by the cost player converges to an\noptimal solution to the convex MDP. Finally, we show that the meta-algorithm\nunifies several disparate branches of reinforcement learning algorithms in the\nliterature, such as apprenticeship learning, variational intrinsic control,\nconstrained MDPs, and pure exploration into a single framework.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 17:46:25 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Zahavy", "Tom", ""], ["O'Donoghue", "Brendan", ""], ["Desjardins", "Guillaume", ""], ["Singh", "Satinder", ""]]}, {"id": "2106.00666", "submitter": "Yuxin Fang", "authors": "Yuxin Fang, Bencheng Liao, Xinggang Wang, Jiemin Fang, Jiyang Qi, Rui\n  Wu, Jianwei Niu, Wenyu Liu", "title": "You Only Look at One Sequence: Rethinking Transformer in Vision through\n  Object Detection", "comments": "18 pages, 7 tables, 5 figures. Add Appendix & some missing references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can Transformer perform $2\\mathrm{D}$ object-level recognition from a pure\nsequence-to-sequence perspective with minimal knowledge about the $2\\mathrm{D}$\nspatial structure? To answer this question, we present You Only Look at One\nSequence (YOLOS), a series of object detection models based on the na\\\"ive\nVision Transformer with the fewest possible modifications as well as inductive\nbiases. We find that YOLOS pre-trained on the mid-sized ImageNet-$1k$ dataset\nonly can already achieve competitive object detection performance on COCO,\n\\textit{e.g.}, YOLOS-Base directly adopted from BERT-Base can achieve $42.0$\nbox AP. We also discuss the impacts as well as limitations of current pre-train\nschemes and model scaling strategies for Transformer in vision through object\ndetection. Code and model weights are available at\n\\url{https://github.com/hustvl/YOLOS}.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 17:54:09 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 02:28:30 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Fang", "Yuxin", ""], ["Liao", "Bencheng", ""], ["Wang", "Xinggang", ""], ["Fang", "Jiemin", ""], ["Qi", "Jiyang", ""], ["Wu", "Rui", ""], ["Niu", "Jianwei", ""], ["Liu", "Wenyu", ""]]}, {"id": "2106.00669", "submitter": "Tom Zahavy", "authors": "Tom Zahavy, Brendan O'Donoghue, Andre Barreto, Volodymyr Mnih,\n  Sebastian Flennerhag and Satinder Singh", "title": "Discovering Diverse Nearly Optimal Policies withSuccessor Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding different solutions to the same problem is a key aspect of\nintelligence associated with creativity and adaptation to novel situations. In\nreinforcement learning, a set of diverse policies can be useful for\nexploration, transfer, hierarchy, and robustness. We propose Diverse Successive\nPolicies, a method for discovering policies that are diverse in the space of\nSuccessor Features, while assuring that they are near optimal. We formalize the\nproblem as a Constrained Markov Decision Process (CMDP) where the goal is to\nfind policies that maximize diversity, characterized by an intrinsic diversity\nreward, while remaining near-optimal with respect to the extrinsic reward of\nthe MDP. We also analyze how recently proposed robustness and discrimination\nrewards perform and find that they are sensitive to the initialization of the\nprocedure and may converge to sub-optimal solutions. To alleviate this, we\npropose new explicit diversity rewards that aim to minimize the correlation\nbetween the Successor Features of the policies in the set. We compare the\ndifferent diversity mechanisms in the DeepMind Control Suite and find that the\ntype of explicit diversity we are proposing is important to discover distinct\nbehavior, like for example different locomotion patterns.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 17:56:13 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Zahavy", "Tom", ""], ["O'Donoghue", "Brendan", ""], ["Barreto", "Andre", ""], ["Mnih", "Volodymyr", ""], ["Flennerhag", "Sebastian", ""], ["Singh", "Satinder", ""]]}, {"id": "2106.00672", "submitter": "Marcin Andrychowicz", "authors": "Manu Orsini, Anton Raichuk, L\\'eonard Hussenot, Damien Vincent, Robert\n  Dadashi, Sertan Girgin, Matthieu Geist, Olivier Bachem, Olivier Pietquin,\n  Marcin Andrychowicz", "title": "What Matters for Adversarial Imitation Learning?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial imitation learning has become a popular framework for imitation\nin continuous control. Over the years, several variations of its components\nwere proposed to enhance the performance of the learned policies as well as the\nsample complexity of the algorithm. In practice, these choices are rarely\ntested all together in rigorous empirical studies. It is therefore difficult to\ndiscuss and understand what choices, among the high-level algorithmic options\nas well as low-level implementation details, matter. To tackle this issue, we\nimplement more than 50 of these choices in a generic adversarial imitation\nlearning framework and investigate their impacts in a large-scale study (>500k\ntrained agents) with both synthetic and human-generated demonstrations. While\nmany of our findings confirm common practices, some of them are surprising or\neven contradict prior work. In particular, our results suggest that artificial\ndemonstrations are not a good proxy for human data and that the very common\npractice of evaluating imitation algorithms only with synthetic demonstrations\nmay lead to algorithms which perform poorly in the more realistic scenarios\nwith human demonstrations.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 17:58:08 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Orsini", "Manu", ""], ["Raichuk", "Anton", ""], ["Hussenot", "L\u00e9onard", ""], ["Vincent", "Damien", ""], ["Dadashi", "Robert", ""], ["Girgin", "Sertan", ""], ["Geist", "Matthieu", ""], ["Bachem", "Olivier", ""], ["Pietquin", "Olivier", ""], ["Andrychowicz", "Marcin", ""]]}, {"id": "2106.00687", "submitter": "Nik Dennler", "authors": "Nik Dennler, Germain Haessig, Matteo Cartiglia, Giacomo Indiveri", "title": "Online Detection of Vibration Anomalies Using Balanced Spiking Neural\n  Networks", "comments": "This work is presented at the 2021 IEEE AICAS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Vibration patterns yield valuable information about the health state of a\nrunning machine, which is commonly exploited in predictive maintenance tasks\nfor large industrial systems. However, the overhead, in terms of size,\ncomplexity and power budget, required by classical methods to exploit this\ninformation is often prohibitive for smaller-scale applications such as\nautonomous cars, drones or robotics. Here we propose a neuromorphic approach to\nperform vibration analysis using spiking neural networks that can be applied to\na wide range of scenarios. We present a spike-based end-to-end pipeline able to\ndetect system anomalies from vibration data, using building blocks that are\ncompatible with analog-digital neuromorphic circuits. This pipeline operates in\nan online unsupervised fashion, and relies on a cochlea model, on feedback\nadaptation and on a balanced spiking neural network. We show that the proposed\nmethod achieves state-of-the-art performance or better against two publicly\navailable data sets. Further, we demonstrate a working proof-of-concept\nimplemented on an asynchronous neuromorphic processor device. This work\nrepresents a significant step towards the design and implementation of\nautonomous low-power edge-computing devices for online vibration monitoring.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 18:00:02 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Dennler", "Nik", ""], ["Haessig", "Germain", ""], ["Cartiglia", "Matteo", ""], ["Indiveri", "Giacomo", ""]]}, {"id": "2106.00707", "submitter": "Shihong Deng", "authors": "Changnan Xiao, Haosen Shi, Jiajun Fan, Shihong Deng", "title": "An Entropy Regularization Free Mechanism for Policy-based Reinforcement\n  Learning", "comments": "arXiv admin note: text overlap with arXiv:2105.03923", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy-based reinforcement learning methods suffer from the policy collapse\nproblem. We find valued-based reinforcement learning methods with\n{\\epsilon}-greedy mechanism are capable of enjoying three characteristics,\nClosed-form Diversity, Objective-invariant Exploration and Adaptive Trade-off,\nwhich help value-based methods avoid the policy collapse problem. However,\nthere does not exist a parallel mechanism for policy-based methods that\nachieves all three characteristics. In this paper, we propose an entropy\nregularization free mechanism that is designed for policy-based methods, which\nachieves Closed-form Diversity, Objective-invariant Exploration and Adaptive\nTrade-off. Our experiments show that our mechanism is super sample-efficient\nfor policy-based methods and boosts a policy-based baseline to a new\nState-Of-The-Art on Arcade Learning Environment.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 18:04:19 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Xiao", "Changnan", ""], ["Shi", "Haosen", ""], ["Fan", "Jiajun", ""], ["Deng", "Shihong", ""]]}, {"id": "2106.00720", "submitter": "Arghya Datta", "authors": "Arghya Datta, S. Joshua Swamidass", "title": "Fair-Net: A Network Architecture For Reducing Performance Disparity\n  Between Identifiable Sub-Populations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In real world datasets, particular groups are under-represented, much rarer\nthan others, and machine learning classifiers will often preform worse on\nunder-represented populations. This problem is aggravated across many domains\nwhere datasets are class imbalanced, with a minority class far rarer than the\nmajority class. Naive approaches to handle under-representation and class\nimbalance include training sub-population specific classifiers that handle\nclass imbalance or training a global classifier that overlooks sub-population\ndisparities and aims to achieve high overall accuracy by handling class\nimbalance. In this study, we find that these approaches are vulnerable in class\nimbalanced datasets with minority sub-populations. We introduced Fair-Net, a\nbranched multitask neural network architecture that improves both\nclassification accuracy and probability calibration across identifiable\nsub-populations in class imbalanced datasets. Fair-Nets is a straightforward\nextension to the output layer and error function of a network, so can be\nincorporated in far more complex architectures. Empirical studies with three\nreal world benchmark datasets demonstrate that Fair-Net improves classification\nand calibration performance, substantially reducing performance disparity\nbetween gender and racial sub-populations.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 18:26:08 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Datta", "Arghya", ""], ["Swamidass", "S. Joshua", ""]]}, {"id": "2106.00745", "submitter": "Ofek Rafaeli", "authors": "Ofek Rafaeli, Omri Abend, Leshem Choshen, Dmitry Nikolaev", "title": "Part of Speech and Universal Dependency effects on English Arabic\n  Machine Translation", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this research paper, I will elaborate on a method to evaluate machine\ntranslation models based on their performance on underlying syntactical\nphenomena between English and Arabic languages. This method is especially\nimportant as such \"neural\" and \"machine learning\" are hard to fine-tune and\nchange. Thus, finding a way to evaluate them easily and diversely would greatly\nhelp the task of bettering them.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 19:48:23 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 11:24:28 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Rafaeli", "Ofek", ""], ["Abend", "Omri", ""], ["Choshen", "Leshem", ""], ["Nikolaev", "Dmitry", ""]]}, {"id": "2106.00746", "submitter": "Dimitri Bertsekas", "authors": "Dimitri Bertsekas", "title": "On-Line Policy Iteration for Infinite Horizon Dynamic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we propose an on-line policy iteration (PI) algorithm for\nfinite-state infinite horizon discounted dynamic programming, whereby the\npolicy improvement operation is done on-line, only for the states that are\nencountered during operation of the system. This allows the continuous\nupdating/improvement of the current policy, thus resulting in a form of on-line\nPI that incorporates the improved controls into the current policy as new\nstates and controls are generated. The algorithm converges in a finite number\nof stages to a type of locally optimal policy, and suggests the possibility of\nvariants of PI and multiagent PI where the policy improvement is simplified.\nMoreover, the algorithm can be used with on-line replanning, and is also\nwell-suited for on-line PI algorithms with value and policy approximations.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 19:50:22 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Bertsekas", "Dimitri", ""]]}, {"id": "2106.00786", "submitter": "Peter Hase", "authors": "Peter Hase, Harry Xie, Mohit Bansal", "title": "Search Methods for Sufficient, Socially-Aligned Feature Importance\n  Explanations with In-Distribution Counterfactuals", "comments": "26 pages, 4 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature importance (FI) estimates are a popular form of explanation, and they\nare commonly created and evaluated by computing the change in model confidence\ncaused by removing certain input features at test time. For example, in the\nstandard Sufficiency metric, only the top-k most important tokens are kept. In\nthis paper, we study several under-explored dimensions of FI-based\nexplanations, providing conceptual and empirical improvements for this form of\nexplanation. First, we advance a new argument for why it can be problematic to\nremove features from an input when creating or evaluating explanations: the\nfact that these counterfactual inputs are out-of-distribution (OOD) to models\nimplies that the resulting explanations are socially misaligned. The crux of\nthe problem is that the model prior and random weight initialization influence\nthe explanations (and explanation metrics) in unintended ways. To resolve this\nissue, we propose a simple alteration to the model training process, which\nresults in more socially aligned explanations and metrics. Second, we compare\namong five approaches for removing features from model inputs. We find that\nsome methods produce more OOD counterfactuals than others, and we make\nrecommendations for selecting a feature-replacement function. Finally, we\nintroduce four search-based methods for identifying FI explanations and compare\nthem to strong baselines, including LIME, Integrated Gradients, and random\nsearch. On experiments with six diverse text classification datasets, we find\nthat the only method that consistently outperforms random search is a Parallel\nLocal Search that we introduce. Improvements over the second-best method are as\nlarge as 5.4 points for Sufficiency and 17 points for Comprehensiveness. All\nsupporting code is publicly available at\nhttps://github.com/peterbhase/ExplanationSearch.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 20:36:48 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Hase", "Peter", ""], ["Xie", "Harry", ""], ["Bansal", "Mohit", ""]]}, {"id": "2106.00790", "submitter": "SueYeon Chung", "authors": "SueYeon Chung", "title": "Statistical Mechanics of Neural Processing of Object Manifolds", "comments": "PhD thesis, Harvard University, Cambridge, Massachusetts, USA. 2017.\n  Some chapters report joint work", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Invariant object recognition is one of the most fundamental cognitive tasks\nperformed by the brain. In the neural state space, different objects with\nstimulus variabilities are represented as different manifolds. In this\ngeometrical perspective, object recognition becomes the problem of linearly\nseparating different object manifolds. In feedforward visual hierarchy, it has\nbeen suggested that the object manifold representations are reformatted across\nthe layers, to become more linearly separable. Thus, a complete theory of\nperception requires characterizing the ability of linear readout networks to\nclassify object manifolds from variable neural responses.\n  A theory of the perceptron of isolated points was pioneered by E. Gardner who\nformulated it as a statistical mechanics problem and analyzed it using replica\ntheory. In this thesis, we generalize Gardner's analysis and establish a theory\nof linear classification of manifolds synthesizing statistical and geometric\nproperties of high dimensional signals. [..] Next, we generalize our theory\nfurther to linear classification of general perceptual manifolds, such as point\nclouds. We identify that the capacity of a manifold is determined that\neffective radius, R_M, and effective dimension, D_M. Finally, we show\nextensions relevant for applications to real data, incorporating correlated\nmanifolds, heterogenous manifold geometries, sparse labels and nonlinear\nclassifications. Then, we demonstrate how object-based manifolds transform in\nstandard deep networks.\n  This thesis lays the groundwork for a computational theory of neuronal\nprocessing of objects, providing quantitative measures for linear separability\nof object manifolds. We hope this theory will provide new insights into the\ncomputational principles underlying processing of sensory representations in\nbiological and artificial neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 20:49:14 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Chung", "SueYeon", ""]]}, {"id": "2106.00794", "submitter": "Nikita Nangia", "authors": "Nikita Nangia, Saku Sugawara, Harsh Trivedi, Alex Warstadt, Clara\n  Vania, Samuel R. Bowman", "title": "What Ingredients Make for an Effective Crowdsourcing Protocol for\n  Difficult NLU Data Collection Tasks?", "comments": "ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsourcing is widely used to create data for common natural language\nunderstanding tasks. Despite the importance of these datasets for measuring and\nrefining model understanding of language, there has been little focus on the\ncrowdsourcing methods used for collecting the datasets. In this paper, we\ncompare the efficacy of interventions that have been proposed in prior work as\nways of improving data quality. We use multiple-choice question answering as a\ntestbed and run a randomized trial by assigning crowdworkers to write questions\nunder one of four different data collection protocols. We find that asking\nworkers to write explanations for their examples is an ineffective stand-alone\nstrategy for boosting NLU example difficulty. However, we find that training\ncrowdworkers, and then using an iterative process of collecting data, sending\nfeedback, and qualifying workers based on expert judgments is an effective\nmeans of collecting challenging data. But using crowdsourced, instead of expert\njudgments, to qualify workers and send feedback does not prove to be effective.\nWe observe that the data from the iterative protocol with expert assessments is\nmore challenging by several measures. Notably, the human--model gap on the\nunanimous agreement portion of this data is, on average, twice as large as the\ngap for the baseline protocol data.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 21:05:52 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Nangia", "Nikita", ""], ["Sugawara", "Saku", ""], ["Trivedi", "Harsh", ""], ["Warstadt", "Alex", ""], ["Vania", "Clara", ""], ["Bowman", "Samuel R.", ""]]}, {"id": "2106.00797", "submitter": "Maxime Vono", "authors": "Maxime Vono, Vincent Plassier, Alain Durmus, Aymeric Dieuleveut, Eric\n  Moulines", "title": "QLSD: Quantised Langevin stochastic dynamics for Bayesian federated\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning aims at conducting inference when data are decentralised\nand locally stored on several clients, under two main constraints: data\nownership and communication overhead. In this paper, we address these issues\nunder the Bayesian paradigm. To this end, we propose a novel Markov chain Monte\nCarlo algorithm coined \\texttt{QLSD} built upon quantised versions of\nstochastic gradient Langevin dynamics. To improve performance in a big data\nregime, we introduce variance-reduced alternatives of our methodology referred\nto as \\texttt{QLSD}$^\\star$ and \\texttt{QLSD}$^{++}$. We provide both\nnon-asymptotic and asymptotic convergence guarantees for the proposed\nalgorithms and illustrate their benefits on several federated learning\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 21:08:54 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Vono", "Maxime", ""], ["Plassier", "Vincent", ""], ["Durmus", "Alain", ""], ["Dieuleveut", "Aymeric", ""], ["Moulines", "Eric", ""]]}, {"id": "2106.00808", "submitter": "Sorawit Saengkyongam", "authors": "Sorawit Saengkyongam, Nikolaj Thams, Jonas Peters and Niklas Pfister", "title": "Invariant Policy Learning: A Causal Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decade, contextual bandit and reinforcement learning algorithms\nhave been successfully used in various interactive learning systems such as\nonline advertising, recommender systems, and dynamic pricing. However, they\nhave yet to be widely adopted in high-stakes application domains, such as\nhealthcare. One reason may be that existing approaches assume that the\nunderlying mechanisms are static in the sense that they do not change over time\nor over different environments. In many real world systems, however, the\nmechanisms are subject to shifts across environments which may invalidate the\nstatic environment assumption. In this paper, we tackle the problem of\nenvironmental shifts under the framework of offline contextual bandits. We view\nthe environmental shift problem through the lens of causality and propose\nmulti-environment contextual bandits that allow for changes in the underlying\nmechanisms. We adopt the concept of invariance from the causality literature\nand introduce the notion of policy invariance. We argue that policy invariance\nis only relevant if unobserved confounders are present and show that, in that\ncase, an optimal invariant policy is guaranteed, under certain assumptions, to\ngeneralize across environments. Our results do not only provide a solution to\nthe environmental shift problem but also establish concrete connections among\ncausality, invariance and contextual bandits.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 21:20:48 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 09:46:47 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Saengkyongam", "Sorawit", ""], ["Thams", "Nikolaj", ""], ["Peters", "Jonas", ""], ["Pfister", "Niklas", ""]]}, {"id": "2106.00842", "submitter": "M. Ali Vosoughi", "authors": "M. Ali Vosoughi and Axel Wismuller", "title": "Leveraging Pre-Images to Discover Nonlinear Relationships in\n  Multivariate Environments", "comments": "5 pages, 4 Figures, Conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Causal discovery, beyond the inference of a network as a collection of\nconnected dots, offers a crucial functionality in scientific discovery using\nartificial intelligence. The questions that arise in multiple domains, such as\nphysics, physiology, the strategic decision in uncertain environments with\nmultiple agents, climatology, among many others, have roots in causality and\nreasoning. It became apparent that many real-world temporal observations are\nnonlinearly related to each other. While the number of observations can be as\nhigh as millions of points, the number of temporal samples can be minimal due\nto ethical or practical reasons, leading to the curse-of-dimensionality in\nlarge-scale systems. This paper proposes a novel method using kernel principal\ncomponent analysis and pre-images to obtain nonlinear dependencies of\nmultivariate time-series data. We show that our method outperforms\nstate-of-the-art causal discovery methods when the observations are restricted\nby time and are nonlinearly related. Extensive simulations on both real-world\nand synthetic datasets with various topologies are provided to evaluate our\nproposed methods.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 22:42:51 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Vosoughi", "M. Ali", ""], ["Wismuller", "Axel", ""]]}, {"id": "2106.00858", "submitter": "Jiri Navratil", "authors": "Jiri Navratil, Benjamin Elder, Matthew Arnold, Soumya Ghosh, Prasanna\n  Sattigeri", "title": "Uncertainty Characteristics Curves: A Systematic Assessment of\n  Prediction Intervals", "comments": "10 pages main paper, 9 pages appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate quantification of model uncertainty has long been recognized as a\nfundamental requirement for trusted AI. In regression tasks, uncertainty is\ntypically quantified using prediction intervals calibrated to a specific\noperating point, making evaluation and comparison across different studies\ndifficult. Our work leverages: (1) the concept of operating characteristics\ncurves and (2) the notion of a gain over a simple reference, to derive a novel\noperating point agnostic assessment methodology for prediction intervals. The\npaper describes the corresponding algorithm, provides a theoretical analysis,\nand demonstrates its utility in multiple scenarios. We argue that the proposed\nmethod addresses the current need for comprehensive assessment of prediction\nintervals and thus represents a valuable addition to the uncertainty\nquantification toolbox.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 23:46:44 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Navratil", "Jiri", ""], ["Elder", "Benjamin", ""], ["Arnold", "Matthew", ""], ["Ghosh", "Soumya", ""], ["Sattigeri", "Prasanna", ""]]}, {"id": "2106.00872", "submitter": "Divyansh Kaushik", "authors": "Divyansh Kaushik, Douwe Kiela, Zachary C. Lipton, Wen-tau Yih", "title": "On the Efficacy of Adversarial Data Collection for Question Answering:\n  Results from a Large-Scale Randomized Study", "comments": "Accepted at ACL-IJCNLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In adversarial data collection (ADC), a human workforce interacts with a\nmodel in real time, attempting to produce examples that elicit incorrect\npredictions. Researchers hope that models trained on these more challenging\ndatasets will rely less on superficial patterns, and thus be less brittle.\nHowever, despite ADC's intuitive appeal, it remains unclear when training on\nadversarial datasets produces more robust models. In this paper, we conduct a\nlarge-scale controlled study focused on question answering, assigning workers\nat random to compose questions either (i) adversarially (with a model in the\nloop); or (ii) in the standard fashion (without a model). Across a variety of\nmodels and datasets, we find that models trained on adversarial data usually\nperform better on other adversarial datasets but worse on a diverse collection\nof out-of-domain evaluation sets. Finally, we provide a qualitative analysis of\nadversarial (vs standard) data, identifying key differences and offering\nguidance for future research.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 00:48:33 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Kaushik", "Divyansh", ""], ["Kiela", "Douwe", ""], ["Lipton", "Zachary C.", ""], ["Yih", "Wen-tau", ""]]}, {"id": "2106.00873", "submitter": "Zhenyu Zhong", "authors": "Zhisheng Hu, Shengjian Guo, Zhenyu Zhong, Kang Li", "title": "Coverage-based Scene Fuzzing for Virtual Autonomous Driving Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation-based virtual testing has become an essential step to ensure the\nsafety of autonomous driving systems. Testers need to handcraft the virtual\ndriving scenes and configure various environmental settings like surrounding\ntraffic, weather conditions, etc. Due to the huge amount of configuration\npossibilities, the human efforts are subject to the inefficiency in detecting\nflaws in industry-class autonomous driving system. This paper proposes a\ncoverage-driven fuzzing technique to automatically generate diverse\nconfiguration parameters to form new driving scenes. Experimental results show\nthat our fuzzing method can significantly reduce the cost in deriving new risky\nscenes from the initial setup designed by testers. We expect automated fuzzing\nwill become a common practice in virtual testing for autonomous driving\nsystems.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 00:49:59 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Hu", "Zhisheng", ""], ["Guo", "Shengjian", ""], ["Zhong", "Zhenyu", ""], ["Li", "Kang", ""]]}, {"id": "2106.00874", "submitter": "Munazza Zaib", "authors": "Munazza Zaib and Wei Emma Zhang and Quan Z. Sheng and Adnan Mahmood\n  and Yang Zhang", "title": "Conversational Question Answering: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering (QA) systems provide a way of querying the information\navailable in various formats including, but not limited to, unstructured and\nstructured data in natural languages. It constitutes a considerable part of\nconversational artificial intelligence (AI) which has led to the introduction\nof a special research topic on Conversational Question Answering (CQA), wherein\na system is required to understand the given context and then engages in\nmulti-turn QA to satisfy the user's information needs. Whilst the focus of most\nof the existing research work is subjected to single-turn QA, the field of\nmulti-turn QA has recently grasped attention and prominence owing to the\navailability of large-scale, multi-turn QA datasets and the development of\npre-trained language models. With a good amount of models and research papers\nadding to the literature every year recently, there is a dire need of arranging\nand presenting the related work in a unified manner to streamline future\nresearch. This survey, therefore, is an effort to present a comprehensive\nreview of the state-of-the-art research trends of CQA primarily based on\nreviewed papers from 2016-2021. Our findings show that there has been a trend\nshift from single-turn to multi-turn QA which empowers the field of\nConversational AI from different perspectives. This survey is intended to\nprovide an epitome for the research community with the hope of laying a strong\nfoundation for the field of CQA.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 01:06:34 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 01:02:38 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Zaib", "Munazza", ""], ["Zhang", "Wei Emma", ""], ["Sheng", "Quan Z.", ""], ["Mahmood", "Adnan", ""], ["Zhang", "Yang", ""]]}, {"id": "2106.00887", "submitter": "Zanbo Wang", "authors": "Zanbo Wang, Wei Wei, Xianling Mao, Shanshan Feng, Pan Zhou, Zhiyong He\n  and Sheng Jiang", "title": "Exploiting Global Contextual Information for Document-level Named Entity\n  Recognition", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing named entity recognition (NER) approaches are based on sequence\nlabeling models, which focus on capturing the local context dependencies.\nHowever, the way of taking one sentence as input prevents the modeling of\nnon-sequential global context, which is useful especially when local context\ninformation is limited or ambiguous. To this end, we propose a model called\nGlobal Context enhanced Document-level NER (GCDoc) to leverage global\ncontextual information from two levels, i.e., both word and sentence. At\nword-level, a document graph is constructed to model a wider range of\ndependencies between words, then obtain an enriched contextual representation\nfor each word via graph neural networks (GNN). To avoid the interference of\nnoise information, we further propose two strategies. First we apply the\nepistemic uncertainty theory to find out tokens whose representations are less\nreliable, thereby helping prune the document graph. Then a selective auxiliary\nclassifier is proposed to effectively learn the weight of edges in document\ngraph and reduce the importance of noisy neighbour nodes. At sentence-level,\nfor appropriately modeling wider context beyond single sentence, we employ a\ncross-sentence module which encodes adjacent sentences and fuses it with the\ncurrent sentence representation via attention and gating mechanisms. Extensive\nexperiments on two benchmark NER datasets (CoNLL 2003 and Ontonotes 5.0 English\ndataset) demonstrate the effectiveness of our proposed model. Our model reaches\nF1 score of 92.22 (93.40 with BERT) on CoNLL 2003 dataset and 88.32 (90.49 with\nBERT) on Ontonotes 5.0 dataset, achieving new state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 01:52:07 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Wang", "Zanbo", ""], ["Wei", "Wei", ""], ["Mao", "Xianling", ""], ["Feng", "Shanshan", ""], ["Zhou", "Pan", ""], ["He", "Zhiyong", ""], ["Jiang", "Sheng", ""]]}, {"id": "2106.00897", "submitter": "Wanqi Xue", "authors": "Wanqi Xue, Youzhi Zhang, Shuxin Li, Xinrun Wang, Bo An, Chai Kiat Yeo", "title": "Solving Large-Scale Extensive-Form Network Security Games via Neural\n  Fictitious Self-Play", "comments": "Published as a conference paper in IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Securing networked infrastructures is important in the real world. The\nproblem of deploying security resources to protect against an attacker in\nnetworked domains can be modeled as Network Security Games (NSGs).\nUnfortunately, existing approaches, including the deep learning-based\napproaches, are inefficient to solve large-scale extensive-form NSGs. In this\npaper, we propose a novel learning paradigm, NSG-NFSP, to solve large-scale\nextensive-form NSGs based on Neural Fictitious Self-Play (NFSP). Our main\ncontributions include: i) reforming the best response (BR) policy network in\nNFSP to be a mapping from action-state pair to action-value, to make the\ncalculation of BR possible in NSGs; ii) converting the average policy network\nof an NFSP agent into a metric-based classifier, helping the agent to assign\ndistributions only on legal actions rather than all actions; iii) enabling NFSP\nwith high-level actions, which can benefit training efficiency and stability in\nNSGs; and iv) leveraging information contained in graphs of NSGs by learning\nefficient graph node embeddings. Our algorithm significantly outperforms\nstate-of-the-art algorithms in both scalability and solution quality.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 02:22:52 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Xue", "Wanqi", ""], ["Zhang", "Youzhi", ""], ["Li", "Shuxin", ""], ["Wang", "Xinrun", ""], ["An", "Bo", ""], ["Yeo", "Chai Kiat", ""]]}, {"id": "2106.00903", "submitter": "Liang Ding", "authors": "Liang Ding, Longyue Wang, Xuebo Liu, Derek F. Wong, Dacheng Tao and\n  Zhaopeng Tu", "title": "Rejuvenating Low-Frequency Words: Making the Most of Parallel Data in\n  Non-Autoregressive Translation", "comments": "ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Knowledge distillation (KD) is commonly used to construct synthetic data for\ntraining non-autoregressive translation (NAT) models. However, there exists a\ndiscrepancy on low-frequency words between the distilled and the original data,\nleading to more errors on predicting low-frequency words. To alleviate the\nproblem, we directly expose the raw data into NAT by leveraging pretraining. By\nanalyzing directed alignments, we found that KD makes low-frequency source\nwords aligned with targets more deterministically but fails to align sufficient\nlow-frequency words from target to source. Accordingly, we propose reverse KD\nto rejuvenate more alignments for low-frequency target words. To make the most\nof authentic and synthetic data, we combine these complementary approaches as a\nnew training strategy for further boosting NAT performance. We conduct\nexperiments on five translation benchmarks over two advanced architectures.\nResults demonstrate that the proposed approach can significantly and\nuniversally improve translation quality by reducing translation errors on\nlow-frequency words. Encouragingly, our approach achieves 28.2 and 33.9 BLEU\npoints on the WMT14 English-German and WMT16 Romanian-English datasets,\nrespectively. Our code, data, and trained models are available at\n\\url{https://github.com/longyuewangdcu/RLFW-NAT}.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 02:41:40 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Ding", "Liang", ""], ["Wang", "Longyue", ""], ["Liu", "Xuebo", ""], ["Wong", "Derek F.", ""], ["Tao", "Dacheng", ""], ["Tu", "Zhaopeng", ""]]}, {"id": "2106.00905", "submitter": "Rakhmatulin Ildar", "authors": "R. Ildar and E. Pomazov", "title": "Low-cost Stereovision system (disparity map) for few dollars", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The paper presents an analysis of the latest developments in the field of\nstereo vision in the low-cost segment, both for prototypes and for industrial\ndesigns. We described the theory of stereo vision and presented information\nabout cameras and data transfer protocols and their compatibility with various\ndevices. The theory in the field of image processing for stereo vision\nprocesses is considered and the calibration process is described in detail.\nUltimately, we presented the developed stereo vision system and provided the\nmain points that need to be considered when developing such systems. The final,\nwe presented software for adjusting stereo vision parameters in real-time in\nthe python language in the Windows operating system.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 02:55:03 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Ildar", "R.", ""], ["Pomazov", "E.", ""]]}, {"id": "2106.00920", "submitter": "Rishabh Joshi", "authors": "Rishabh Joshi, Vidhisha Balachandran, Shikhar Vashishth, Alan Black,\n  Yulia Tsvetkov", "title": "DialoGraph: Incorporating Interpretable Strategy-Graph Networks into\n  Negotiation Dialogues", "comments": "Accepted at ICLR 2021; https://openreview.net/forum?id=kDnal_bbb-E", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To successfully negotiate a deal, it is not enough to communicate fluently:\npragmatic planning of persuasive negotiation strategies is essential. While\nmodern dialogue agents excel at generating fluent sentences, they still lack\npragmatic grounding and cannot reason strategically. We present DialoGraph, a\nnegotiation system that incorporates pragmatic strategies in a negotiation\ndialogue using graph neural networks. DialoGraph explicitly incorporates\ndependencies between sequences of strategies to enable improved and\ninterpretable prediction of next optimal strategies, given the dialogue\ncontext. Our graph-based method outperforms prior state-of-the-art negotiation\nmodels both in the accuracy of strategy/dialogue act prediction and in the\nquality of downstream dialogue response generation. We qualitatively show\nfurther benefits of learned strategy-graphs in providing explicit associations\nbetween effective negotiation strategies over the course of the dialogue,\nleading to interpretable and strategic dialogues.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 03:34:36 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Joshi", "Rishabh", ""], ["Balachandran", "Vidhisha", ""], ["Vashishth", "Shikhar", ""], ["Black", "Alan", ""], ["Tsvetkov", "Yulia", ""]]}, {"id": "2106.00922", "submitter": "Sina Ghiassian", "authors": "Sina Ghiassian, Richard S. Sutton", "title": "An Empirical Comparison of Off-policy Prediction Learning Algorithms on\n  the Collision Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy prediction -- learning the value function for one policy from data\ngenerated while following another policy -- is one of the most challenging\nsubproblems in reinforcement learning. This paper presents empirical results\nwith eleven prominent off-policy learning algorithms that use linear function\napproximation: five Gradient-TD methods, two Emphatic-TD methods, Off-policy\nTD($\\lambda$), Vtrace, and versions of Tree Backup and ABQ modified to apply to\na prediction setting. Our experiments used the Collision task, a small\nidealized off-policy problem analogous to that of an autonomous car trying to\npredict whether it will collide with an obstacle. We assessed the performance\nof the algorithms according to their learning rate, asymptotic error level, and\nsensitivity to step-size and bootstrapping parameters. By these measures, the\neleven algorithms can be partially ordered on the Collision task. In the top\ntier, the two Emphatic-TD algorithms learned the fastest, reached the lowest\nerrors, and were robust to parameter settings. In the middle tier, the five\nGradient-TD algorithms and Off-policy TD($\\lambda$) were more sensitive to the\nbootstrapping parameter. The bottom tier comprised Vtrace, Tree Backup, and\nABQ; these algorithms were no faster and had higher asymptotic error than the\nothers. Our results are definitive for this task, though of course experiments\nwith more tasks are needed before an overall assessment of the algorithms'\nmerits can be made.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 03:45:43 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 20:57:53 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Ghiassian", "Sina", ""], ["Sutton", "Richard S.", ""]]}, {"id": "2106.00942", "submitter": "Kourosh Hakhamaneshi", "authors": "Kourosh Hakhamaneshi, Pieter Abbeel, Vladimir Stojanovic, Aditya\n  Grover", "title": "JUMBO: Scalable Multi-task Bayesian Optimization using Offline Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The goal of Multi-task Bayesian Optimization (MBO) is to minimize the number\nof queries required to accurately optimize a target black-box function, given\naccess to offline evaluations of other auxiliary functions. When offline\ndatasets are large, the scalability of prior approaches comes at the expense of\nexpressivity and inference quality. We propose JUMBO, an MBO algorithm that\nsidesteps these limitations by querying additional data based on a combination\nof acquisition signals derived from training two Gaussian Processes (GP): a\ncold-GP operating directly in the input domain and a warm-GP that operates in\nthe feature space of a deep neural network pretrained using the offline data.\nSuch a decomposition can dynamically control the reliability of information\nderived from the online and offline data and the use of pretrained neural\nnetworks permits scalability to large offline datasets. Theoretically, we\nderive regret bounds for JUMBO and show that it achieves no-regret under\nconditions analogous to GP-UCB (Srinivas et. al. 2010). Empirically, we\ndemonstrate significant performance improvements over existing approaches on\ntwo real-world optimization problems: hyper-parameter optimization and\nautomated circuit design.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 05:03:38 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Hakhamaneshi", "Kourosh", ""], ["Abbeel", "Pieter", ""], ["Stojanovic", "Vladimir", ""], ["Grover", "Aditya", ""]]}, {"id": "2106.00958", "submitter": "Diogo Almeida", "authors": "Diogo Almeida, Clemens Winter, Jie Tang, Wojciech Zaremba", "title": "A Generalizable Approach to Learning Optimizers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A core issue with learning to optimize neural networks has been the lack of\ngeneralization to real world problems. To address this, we describe a system\ndesigned from a generalization-first perspective, learning to update optimizer\nhyperparameters instead of model parameters directly using novel features,\nactions, and a reward function. This system outperforms Adam at all neural\nnetwork tasks including on modalities not seen during training. We achieve 2x\nspeedups on ImageNet, and a 2.5x speedup on a language modeling task using over\n5 orders of magnitude more compute than the training tasks.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 06:03:18 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 19:36:13 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Almeida", "Diogo", ""], ["Winter", "Clemens", ""], ["Tang", "Jie", ""], ["Zaremba", "Wojciech", ""]]}, {"id": "2106.00969", "submitter": "Shikhar Singh", "authors": "Shikhar Singh, Nuan Wen, Yu Hou, Pegah Alipoormolabashi, Te-Lin Wu,\n  Xuezhe Ma, Nanyun Peng", "title": "COM2SENSE: A Commonsense Reasoning Benchmark with Complementary\n  Sentences", "comments": "In Proceedings of Findings of the Association for Computational\n  Linguistics: ACL 2021 (ACL-Findings). Contains 16 pages, 14 figures and 11\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense reasoning is intuitive for humans but has been a long-term\nchallenge for artificial intelligence (AI). Recent advancements in pretrained\nlanguage models have shown promising results on several commonsense benchmark\ndatasets. However, the reliability and comprehensiveness of these benchmarks\ntowards assessing model's commonsense reasoning ability remains unclear. To\nthis end, we introduce a new commonsense reasoning benchmark dataset comprising\nnatural language true/false statements, with each sample paired with its\ncomplementary counterpart, resulting in 4k sentence pairs. We propose a\npairwise accuracy metric to reliably measure an agent's ability to perform\ncommonsense reasoning over a given situation. The dataset is crowdsourced and\nenhanced with an adversarial model-in-the-loop setup to incentivize challenging\nsamples. To facilitate a systematic analysis of commonsense capabilities, we\ndesign our dataset along the dimensions of knowledge domains, reasoning\nscenarios and numeracy. Experimental results demonstrate that our strongest\nbaseline (UnifiedQA-3B), after fine-tuning, achieves ~71% standard accuracy and\n~51% pairwise accuracy, well below human performance (~95% for both metrics).\nThe dataset is available at https://github.com/PlusLabNLP/Com2Sense.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 06:31:55 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Singh", "Shikhar", ""], ["Wen", "Nuan", ""], ["Hou", "Yu", ""], ["Alipoormolabashi", "Pegah", ""], ["Wu", "Te-Lin", ""], ["Ma", "Xuezhe", ""], ["Peng", "Nanyun", ""]]}, {"id": "2106.00978", "submitter": "Tuan-Anh Nguyen Dang", "authors": "Tuan-Anh D. Nguyen, Hieu M. Vu, Nguyen Hong Son, Minh-Tien Nguyen", "title": "A Span Extraction Approach for Information Extraction on Visually-Rich\n  Documents", "comments": "Accepted to Document Images and Language Workshop at ICDAR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Information extraction (IE) for visually-rich documents (VRDs) has achieved\nSOTA performance recently thanks to the adaptation of Transformer-based\nlanguage models, which shows the great potential of pre-training methods. In\nthis paper, we present a new approach to improve the capability of language\nmodel pre-training on VRDs. Firstly, we introduce a new query-based IE model\nthat employs span extraction instead of using the common sequence labeling\napproach. Secondly, to further extend the span extraction formulation, we\npropose a new training task that focuses on modelling the relationships among\nsemantic entities within a document. This task enables target spans to be\nextracted recursively and can be used to pre-train the model or as an IE\ndownstream task. Evaluation on three datasets of popular business documents\n(invoices, receipts) shows that our proposed method achieves significant\nimprovements compared to existing models. The method also provides a mechanism\nfor knowledge accumulation from multiple downstream IE tasks.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 06:50:04 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 08:05:17 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Nguyen", "Tuan-Anh D.", ""], ["Vu", "Hieu M.", ""], ["Son", "Nguyen Hong", ""], ["Nguyen", "Minh-Tien", ""]]}, {"id": "2106.00980", "submitter": "Tuan-Anh Nguyen Dang", "authors": "Tuan-Anh Nguyen Dang, Duc-Thanh Hoang, Quang-Bach Tran, Chih-Wei Pan,\n  Thanh-Dat Nguyen", "title": "End-to-End Hierarchical Relation Extraction for Generic Form\n  Understanding", "comments": "Accepted to ICPR 2020", "journal-ref": "2020 25th International Conference on Pattern Recognition (ICPR)", "doi": "10.1109/ICPR48806.2021.9412778", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Form understanding is a challenging problem which aims to recognize semantic\nentities from the input document and their hierarchical relations. Previous\napproaches face significant difficulty dealing with the complexity of the task,\nthus treat these objectives separately. To this end, we present a novel deep\nneural network to jointly perform both entity detection and link prediction in\nan end-to-end fashion. Our model extends the Multi-stage Attentional U-Net\narchitecture with the Part-Intensity Fields and Part-Association Fields for\nlink prediction, enriching the spatial information flow with the additional\nsupervision from entity linking. We demonstrate the effectiveness of the model\non the Form Understanding in Noisy Scanned Documents (FUNSD) dataset, where our\nmethod substantially outperforms the original model and state-of-the-art\nbaselines in both Entity Labeling and Entity Linking task.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 06:51:35 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Dang", "Tuan-Anh Nguyen", ""], ["Hoang", "Duc-Thanh", ""], ["Tran", "Quang-Bach", ""], ["Pan", "Chih-Wei", ""], ["Nguyen", "Thanh-Dat", ""]]}, {"id": "2106.00984", "submitter": "Guoxian Yu", "authors": "Yunfeng Zhao, Guoxian Yu, Lei Liu, Zhongmin Yan, Lizhen Cui and\n  Carlotta Domeniconi", "title": "Few-Shot Partial-Label Learning", "comments": "Accepted by International Joint Conference on Artificial Intelligence\n  (IJCAI2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial-label learning (PLL) generally focuses on inducing a noise-tolerant\nmulti-class classifier by training on overly-annotated samples, each of which\nis annotated with a set of labels, but only one is the valid label. A basic\npromise of existing PLL solutions is that there are sufficient partial-label\n(PL) samples for training. However, it is more common than not to have just few\nPL samples at hand when dealing with new tasks. Furthermore, existing few-shot\nlearning algorithms assume precise labels of the support set; as such,\nirrelevant labels may seriously mislead the meta-learner and thus lead to a\ncompromised performance. How to enable PLL under a few-shot learning setting is\nan important problem, but not yet well studied. In this paper, we introduce an\napproach called FsPLL (Few-shot PLL). FsPLL first performs adaptive distance\nmetric learning by an embedding network and rectifying prototypes on the tasks\npreviously encountered. Next, it calculates the prototype of each class of a\nnew task in the embedding network. An unseen example can then be classified via\nits distance to each prototype. Experimental results on widely-used few-shot\ndatasets (Omniglot and miniImageNet) demonstrate that our FsPLL can achieve a\nsuperior performance than the state-of-the-art methods across different\nsettings, and it needs fewer samples for quickly adapting to new tasks.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 07:03:54 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Zhao", "Yunfeng", ""], ["Yu", "Guoxian", ""], ["Liu", "Lei", ""], ["Yan", "Zhongmin", ""], ["Cui", "Lizhen", ""], ["Domeniconi", "Carlotta", ""]]}, {"id": "2106.00988", "submitter": "Bogdan Trasnea", "authors": "Bogdan Trasnea, Cosmin Ginerica, Mihai Zaha, Gigel Macesanu, Claudiu\n  Pozna, Sorin Grigorescu", "title": "OctoPath: An OcTree Based Self-Supervised Learning Approach to Local\n  Trajectory Planning for Mobile Robots", "comments": null, "journal-ref": "Sensors 2021, 21(11), 3606", "doi": "10.3390/s21113606", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Autonomous mobile robots are usually faced with challenging situations when\ndriving in complex environments. Namely, they have to recognize the static and\ndynamic obstacles, plan the driving path and execute their motion. For\naddressing the issue of perception and path planning, in this paper, we\nintroduce OctoPath , which is an encoder-decoder deep neural network, trained\nin a self-supervised manner to predict the local optimal trajectory for the\nego-vehicle. Using the discretization provided by a 3D octree environment\nmodel, our approach reformulates trajectory prediction as a classification\nproblem with a configurable resolution. During training, OctoPath minimizes the\nerror between the predicted and the manually driven trajectories in a given\ntraining dataset. This allows us to avoid the pitfall of regression-based\ntrajectory estimation, in which there is an infinite state space for the output\ntrajectory points. Environment sensing is performed using a 40-channel\nmechanical LiDAR sensor, fused with an inertial measurement unit and wheels\nodometry for state estimation. The experiments are performed both in simulation\nand real-life, using our own developed GridSim simulator and RovisLab's\nAutonomous Mobile Test Unit platform. We evaluate the predictions of OctoPath\nin different driving scenarios, both indoor and outdoor, while benchmarking our\nsystem against a baseline hybrid A-Star algorithm and a regression-based\nsupervised learning method, as well as against a CNN learning-based optimal\npath planning method.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 07:10:54 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Trasnea", "Bogdan", ""], ["Ginerica", "Cosmin", ""], ["Zaha", "Mihai", ""], ["Macesanu", "Gigel", ""], ["Pozna", "Claudiu", ""], ["Grigorescu", "Sorin", ""]]}, {"id": "2106.00990", "submitter": "Shih-Hung Tsai", "authors": "Shih-hung Tsai, Chao-Chun Liang, Hsin-Min Wang, Keh-Yih Su", "title": "Sequence to General Tree: Knowledge-Guided Geometry Word Problem Solving", "comments": "ACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the recent advancements in deep learning, neural solvers have gained\npromising results in solving math word problems. However, these SOTA solvers\nonly generate binary expression trees that contain basic arithmetic operators\nand do not explicitly use the math formulas. As a result, the expression trees\nthey produce are lengthy and uninterpretable because they need to use multiple\noperators and constants to represent one single formula. In this paper, we\npropose sequence-to-general tree (S2G) that learns to generate interpretable\nand executable operation trees where the nodes can be formulas with an\narbitrary number of arguments. With nodes now allowed to be formulas, S2G can\nlearn to incorporate mathematical domain knowledge into problem-solving, making\nthe results more interpretable. Experiments show that S2G can achieve a better\nperformance against strong baselines on problems that require domain knowledge.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 07:15:06 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Tsai", "Shih-hung", ""], ["Liang", "Chao-Chun", ""], ["Wang", "Hsin-Min", ""], ["Su", "Keh-Yih", ""]]}, {"id": "2106.00992", "submitter": "Bac Nguyen", "authors": "Bac Nguyen and Fabien Cardinaux", "title": "NVC-Net: End-to-End Adversarial Voice Conversion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice conversion has gained increasing popularity in many applications of\nspeech synthesis. The idea is to change the voice identity from one speaker\ninto another while keeping the linguistic content unchanged. Many voice\nconversion approaches rely on the use of a vocoder to reconstruct the speech\nfrom acoustic features, and as a consequence, the speech quality heavily\ndepends on such a vocoder. In this paper, we propose NVC-Net, an end-to-end\nadversarial network, which performs voice conversion directly on the raw audio\nwaveform of arbitrary length. By disentangling the speaker identity from the\nspeech content, NVC-Net is able to perform non-parallel traditional\nmany-to-many voice conversion as well as zero-shot voice conversion from a\nshort utterance of an unseen target speaker. Importantly, NVC-Net is\nnon-autoregressive and fully convolutional, achieving fast inference. Our model\nis capable of producing samples at a rate of more than 3600 kHz on an NVIDIA\nV100 GPU, being orders of magnitude faster than state-of-the-art methods under\nthe same hardware configurations. Objective and subjective evaluations on\nnon-parallel many-to-many voice conversion tasks show that NVC-Net obtains\ncompetitive results with significantly fewer parameters.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 07:19:58 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Nguyen", "Bac", ""], ["Cardinaux", "Fabien", ""]]}, {"id": "2106.00993", "submitter": "Jiawei Huang", "authors": "Jiawei Huang, Nan Jiang", "title": "On the Convergence Rate of Off-Policy Policy Optimization Methods with\n  Density-Ratio Correction", "comments": "47 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the convergence properties of off-policy policy\nimprovement algorithms with state-action density ratio correction under\nfunction approximation setting, where the objective function is formulated as a\nmax-max-min optimization problem. We characterize the bias of the learning\nobjective and present two strategies with finite-time convergence guarantees.\nIn our first strategy, we present algorithm P-SREDA with convergence rate\n$O(\\epsilon^{-3})$, whose dependency on $\\epsilon$ is optimal. In our second\nstrategy, we propose a new off-policy actor-critic style algorithm named\nO-SPIM. We prove that O-SPIM converges to a stationary point with total\ncomplexity $O(\\epsilon^{-4})$, which matches the convergence rate of some\nrecent actor-critic algorithms in the on-policy setting.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 07:26:29 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Huang", "Jiawei", ""], ["Jiang", "Nan", ""]]}, {"id": "2106.01006", "submitter": "Liang Qiu", "authors": "Liang Qiu, Yuan Liang, Yizhou Zhao, Pan Lu, Baolin Peng, Zhou Yu, Ying\n  Nian Wu, Song-Chun Zhu", "title": "SocAoG: Incremental Graph Parsing for Social Relation Inference in\n  Dialogues", "comments": "Long paper (oral) accepted by ACL-IJCNLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring social relations from dialogues is vital for building emotionally\nintelligent robots to interpret human language better and act accordingly. We\nmodel the social network as an And-or Graph, named SocAoG, for the consistency\nof relations among a group and leveraging attributes as inference cues.\nMoreover, we formulate a sequential structure prediction task, and propose an\n$\\alpha$-$\\beta$-$\\gamma$ strategy to incrementally parse SocAoG for the\ndynamic inference upon any incoming utterance: (i) an $\\alpha$ process\npredicting attributes and relations conditioned on the semantics of dialogues,\n(ii) a $\\beta$ process updating the social relations based on related\nattributes, and (iii) a $\\gamma$ process updating individual's attributes based\non interpersonal social relations. Empirical results on DialogRE and MovieGraph\nshow that our model infers social relations more accurately than the\nstate-of-the-art methods. Moreover, the ablation study shows the three\nprocesses complement each other, and the case study demonstrates the dynamic\nrelational inference.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 08:07:42 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 07:45:14 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Qiu", "Liang", ""], ["Liang", "Yuan", ""], ["Zhao", "Yizhou", ""], ["Lu", "Pan", ""], ["Peng", "Baolin", ""], ["Yu", "Zhou", ""], ["Wu", "Ying Nian", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "2106.01009", "submitter": "Jindong Wang", "authors": "Yiqiang Chen, Wang Lu, Jindong Wang, Xin Qin", "title": "FedHealth 2: Weighted Federated Transfer Learning via Batch\n  Normalization for Personalized Healthcare", "comments": "Accepted by IJCAI-21 workshop on federated learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The success of machine learning applications often needs a large quantity of\ndata. Recently, federated learning (FL) is attracting increasing attention due\nto the demand for data privacy and security, especially in the medical field.\nHowever, the performance of existing FL approaches often deteriorates when\nthere exist domain shifts among clients, and few previous works focus on\npersonalization in healthcare. In this article, we propose FedHealth 2, an\nextension of FedHealth \\cite{chen2020fedhealth} to tackle domain shifts and get\npersonalized models for local clients. FedHealth 2 obtains the client\nsimilarities via a pretrained model, and then it averages all weighted models\nwith preserving local batch normalization. Wearable activity recognition and\nCOVID-19 auxiliary diagnosis experiments have evaluated that FedHealth 2 can\nachieve better accuracy (10%+ improvement for activity recognition) and\npersonalized healthcare without compromising privacy and security.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 08:10:50 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 02:28:19 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Chen", "Yiqiang", ""], ["Lu", "Wang", ""], ["Wang", "Jindong", ""], ["Qin", "Xin", ""]]}, {"id": "2106.01043", "submitter": "Rohan Giriraj", "authors": "Rohan Giriraj, Sinnu Susan Thomas", "title": "Causal Discovery in Knowledge Graphs by Exploiting Asymmetric Properties\n  of Non-Gaussian Distributions", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, causal modelling has been used widely to improve\ngeneralization and to provide interpretability in machine learning models. To\ndetermine cause-effect relationships in the absence of a randomized trial, we\ncan model causal systems with counterfactuals and interventions given enough\ndomain knowledge. However, there are several cases where domain knowledge is\nalmost absent and the only recourse is using a statistical method to estimate\ncausal relationships. While there have been several works done in estimating\ncausal relationships in unstructured data, we are yet to find a well-defined\nframework for estimating causal relationships in Knowledge Graphs (KG). It is\ncommonly used to provide a semantic framework for data with complex\ninter-domain relationships. In this work, we define a hybrid approach that\nallows us to discover cause-effect relationships in KG. The proposed approach\nis based around the finding of the instantaneous causal structure of a\nnon-experimental matrix using a non-Gaussian model, i.e; finding the causal\nordering of the variables in a non-Gaussian setting. The non-experimental\nmatrix is a low-dimensional tensor projection obtained by decomposing the\nadjacency tensor of a KG. We use two different pre-existing algorithms, one for\nthe causal discovery and the other for decomposing the KG and combining them to\nget the causal structure in a KG.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 09:33:05 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Giriraj", "Rohan", ""], ["Thomas", "Sinnu Susan", ""]]}, {"id": "2106.01048", "submitter": "Conor F. Hayes", "authors": "Conor F. Hayes, Timothy Verstraeten, Diederik M. Roijers, Enda Howley,\n  Patrick Mannion", "title": "Expected Scalarised Returns Dominance: A New Solution Concept for\n  Multi-Objective Decision Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In many real-world scenarios, the utility of a user is derived from the\nsingle execution of a policy. In this case, to apply multi-objective\nreinforcement learning, the expected utility of the returns must be optimised.\nVarious scenarios exist where a user's preferences over objectives (also known\nas the utility function) are unknown or difficult to specify. In such\nscenarios, a set of optimal policies must be learned. However, settings where\nthe expected utility must be maximised have been largely overlooked by the\nmulti-objective reinforcement learning community and, as a consequence, a set\nof optimal solutions has yet to be defined. In this paper we address this\nchallenge by proposing first-order stochastic dominance as a criterion to build\nsolution sets to maximise expected utility. We also propose a new dominance\ncriterion, known as expected scalarised returns (ESR) dominance, that extends\nfirst-order stochastic dominance to allow a set of optimal policies to be\nlearned in practice. We then define a new solution concept called the ESR set,\nwhich is a set of policies that are ESR dominant. Finally, we define a new\nmulti-objective distributional tabular reinforcement learning (MOT-DRL)\nalgorithm to learn the ESR set in a multi-objective multi-armed bandit setting.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 09:42:42 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Hayes", "Conor F.", ""], ["Verstraeten", "Timothy", ""], ["Roijers", "Diederik M.", ""], ["Howley", "Enda", ""], ["Mannion", "Patrick", ""]]}, {"id": "2106.01072", "submitter": "James Thorne", "authors": "James Thorne, Andreas Vlachos", "title": "Evidence-based Factual Error Correction", "comments": "Uploaded as a new paper in error. Please see the replacement of arxiv\n  paper 2012.15788v2 for this version: arXiv:2012.15788", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the task of factual error correction: performing edits\nto a claim so that the generated rewrite is better supported by evidence. This\nextends the well-studied task of fact verification by providing a mechanism to\ncorrect written texts that are refuted or only partially supported by evidence.\nWe demonstrate that it is feasible to train factual error correction systems\nfrom existing fact checking datasets which only contain labeled claims\naccompanied by evidence, but not the correction. We achieve this by employing a\ntwo-stage distant supervision approach that incorporates evidence into masked\nclaims when generating corrections. Our approach, based on the T5 transformer\nand using retrieved evidence, achieved better results than existing work which\nused a pointer copy network and gold evidence, producing accurate factual error\ncorrections for 5x more instances in human evaluation and a .125 increase in\nSARI score. The evaluation is conducted on a dataset of 65,000 instances based\non a recent fact verification shared task and we release it to enable further\nwork on the task.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 11:00:17 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 10:29:43 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Thorne", "James", ""], ["Vlachos", "Andreas", ""]]}, {"id": "2106.01074", "submitter": "James Thorne", "authors": "James Thorne, Majid Yazdani, Marzieh Saeidi, Fabrizio Silvestri,\n  Sebastian Riedel, Alon Halevy", "title": "Database Reasoning Over Text", "comments": "To appear at ACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural models have shown impressive performance gains in answering queries\nfrom natural language text. However, existing works are unable to support\ndatabase queries, such as \"List/Count all female athletes who were born in 20th\ncentury\", which require reasoning over sets of relevant facts with operations\nsuch as join, filtering and aggregation. We show that while state-of-the-art\ntransformer models perform very well for small databases, they exhibit\nlimitations in processing noisy data, numerical operations, and queries that\naggregate facts. We propose a modular architecture to answer these\ndatabase-style queries over multiple spans from text and aggregating these at\nscale. We evaluate the architecture using WikiNLDB, a novel dataset for\nexploring such queries. Our architecture scales to databases containing\nthousands of facts whereas contemporary models are limited by how many facts\ncan be encoded. In direct comparison on small databases, our approach increases\noverall answer accuracy from 85% to 90%. On larger databases, our approach\nretains its accuracy whereas transformer baselines could not encode the\ncontext.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 11:09:40 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Thorne", "James", ""], ["Yazdani", "Majid", ""], ["Saeidi", "Marzieh", ""], ["Silvestri", "Fabrizio", ""], ["Riedel", "Sebastian", ""], ["Halevy", "Alon", ""]]}, {"id": "2106.01086", "submitter": "Junyoung Park", "authors": "Junyoung Park, Jaehyeong Chun, Sang Hun Kim, Youngkook Kim, Jinkyoo\n  Park", "title": "Learning to schedule job-shop problems: Representation and policy\n  learning using graph neural network and reinforcement learning", "comments": "16 pages, 8 figures", "journal-ref": "International Journal of Production Research International Journal\n  of Production Research, Volume 59, 2021 - Issue 11, Pages 3360-3377", "doi": "10.1080/00207543.2020.1870013", "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework to learn to schedule a job-shop problem (JSSP) using a\ngraph neural network (GNN) and reinforcement learning (RL). We formulate the\nscheduling process of JSSP as a sequential decision-making problem with graph\nrepresentation of the state to consider the structure of JSSP. In solving the\nformulated problem, the proposed framework employs a GNN to learn that node\nfeatures that embed the spatial structure of the JSSP represented as a graph\n(representation learning) and derive the optimum scheduling policy that maps\nthe embedded node features to the best scheduling action (policy learning). We\nemploy Proximal Policy Optimization (PPO) based RL strategy to train these two\nmodules in an end-to-end fashion. We empirically demonstrate that the GNN\nscheduler, due to its superb generalization capability, outperforms practically\nfavored dispatching rules and RL-based schedulers on various benchmark JSSP. We\nalso confirmed that the proposed framework learns a transferable scheduling\npolicy that can be employed to schedule a completely new JSSP (in terms of size\nand parameters) without further training.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 11:40:22 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Park", "Junyoung", ""], ["Chun", "Jaehyeong", ""], ["Kim", "Sang Hun", ""], ["Kim", "Youngkook", ""], ["Park", "Jinkyoo", ""]]}, {"id": "2106.01097", "submitter": "Sidharth Pancholi", "authors": "Sarojadevi Palani, Prabhu Rajagopal, Sidharth Pancholi", "title": "T-BERT -- Model for Sentiment Analysis of Micro-blogs Integrating Topic\n  Model and BERT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sentiment analysis (SA) has become an extensive research area in recent years\nimpacting diverse fields including ecommerce, consumer business, and politics,\ndriven by increasing adoption and usage of social media platforms. It is\nchallenging to extract topics and sentiments from unsupervised short texts\nemerging in such contexts, as they may contain figurative words, strident data,\nand co-existence of many possible meanings for a single word or phrase, all\ncontributing to obtaining incorrect topics. Most prior research is based on a\nspecific theme/rhetoric/focused-content on a clean dataset. In the work\nreported here, the effectiveness of BERT(Bidirectional Encoder Representations\nfrom Transformers) in sentiment classification tasks from a raw live dataset\ntaken from a popular microblogging platform is demonstrated. A novel T-BERT\nframework is proposed to show the enhanced performance obtainable by combining\nlatent topics with contextual BERT embeddings. Numerical experiments were\nconducted on an ensemble with about 42000 datasets using NimbleBox.ai platform\nwith a hardware configuration consisting of Nvidia Tesla K80(CUDA), 4 core CPU,\n15GB RAM running on an isolated Google Cloud Platform instance. The empirical\nresults show that the model improves in performance while adding topics to BERT\nand an accuracy rate of 90.81% on sentiment classification using BERT with the\nproposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 12:01:47 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Palani", "Sarojadevi", ""], ["Rajagopal", "Prabhu", ""], ["Pancholi", "Sidharth", ""]]}, {"id": "2106.01127", "submitter": "Chun-Hao Chang", "authors": "Chun-Hao Chang, George Alexandru Adam, Anna Goldenberg", "title": "Towards Robust Classification Model by Counterfactual and Invariant Data\n  Generation", "comments": "Accepted in 2021 CVPR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the success of machine learning applications in science, industry,\nand society in general, many approaches are known to be non-robust, often\nrelying on spurious correlations to make predictions. Spuriousness occurs when\nsome features correlate with labels but are not causal; relying on such\nfeatures prevents models from generalizing to unseen environments where such\ncorrelations break. In this work, we focus on image classification and propose\ntwo data generation processes to reduce spuriousness. Given human annotations\nof the subset of the features responsible (causal) for the labels (e.g.\nbounding boxes), we modify this causal set to generate a surrogate image that\nno longer has the same label (i.e. a counterfactual image). We also alter\nnon-causal features to generate images still recognized as the original labels,\nwhich helps to learn a model invariant to these features. In several\nchallenging datasets, our data generations outperform state-of-the-art methods\nin accuracy when spurious correlations break, and increase the saliency focus\non causal features providing better explanations.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 12:48:29 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 06:14:35 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Chang", "Chun-Hao", ""], ["Adam", "George Alexandru", ""], ["Goldenberg", "Anna", ""]]}, {"id": "2106.01134", "submitter": "Wei Liao", "authors": "Wei Liao and Xiaohui Wei and Jizhou Lai", "title": "Smooth Q-learning: Accelerate Convergence of Q-learning Using Similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An improvement of Q-learning is proposed in this paper. It is different from\nclassic Q-learning in that the similarity between different states and actions\nis considered in the proposed method. During the training, a new updating\nmechanism is used, in which the Q value of the similar state-action pairs are\nupdated synchronously. The proposed method can be used in combination with both\ntabular Q-learning function and deep Q-learning. And the results of numerical\nexamples illustrate that compared to the classic Q-learning, the proposed\nmethod has a significantly better performance.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 13:05:24 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Liao", "Wei", ""], ["Wei", "Xiaohui", ""], ["Lai", "Jizhou", ""]]}, {"id": "2106.01177", "submitter": "Nicolas Skatchkovsky", "authors": "Nicolas Skatchkovsky, Osvaldo Simeone, Hyeryung Jang", "title": "Learning to Time-Decode in Spiking Neural Networks Through the\n  Information Bottleneck", "comments": "Under review for conference publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the key challenges in training Spiking Neural Networks (SNNs) is that\ntarget outputs typically come in the form of natural signals, such as labels\nfor classification or images for generative models, and need to be encoded into\nspikes. This is done by handcrafting target spiking signals, which in turn\nimplicitly fixes the mechanisms used to decode spikes into natural signals,\ne.g., rate decoding. The arbitrary choice of target signals and decoding rule\ngenerally impairs the capacity of the SNN to encode and process information in\nthe timing of spikes. To address this problem, this work introduces a hybrid\nvariational autoencoder architecture, consisting of an encoding SNN and a\ndecoding Artificial Neural Network (ANN). The role of the decoding ANN is to\nlearn how to best convert the spiking signals output by the SNN into the target\nnatural signal. A novel end-to-end learning rule is introduced that optimizes a\ndirected information bottleneck training criterion via surrogate gradients. We\ndemonstrate the applicability of the technique in an experimental settings on\nvarious tasks, including real-life datasets.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 14:14:47 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Skatchkovsky", "Nicolas", ""], ["Simeone", "Osvaldo", ""], ["Jang", "Hyeryung", ""]]}, {"id": "2106.01191", "submitter": "Jiasheng Si", "authors": "Jiasheng Si, Deyu Zhou, Tongzhe Li, Xingyu Shi, Yulan He", "title": "Topic-Aware Evidence Reasoning and Stance-Aware Aggregation for Fact\n  Verification", "comments": "Accepted by ACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fact verification is a challenging task that requires simultaneously\nreasoning and aggregating over multiple retrieved pieces of evidence to\nevaluate the truthfulness of a claim. Existing approaches typically (i) explore\nthe semantic interaction between the claim and evidence at different\ngranularity levels but fail to capture their topical consistency during the\nreasoning process, which we believe is crucial for verification; (ii) aggregate\nmultiple pieces of evidence equally without considering their implicit stances\nto the claim, thereby introducing spurious information. To alleviate the above\nissues, we propose a novel topic-aware evidence reasoning and stance-aware\naggregation model for more accurate fact verification, with the following four\nkey properties: 1) checking topical consistency between the claim and evidence;\n2) maintaining topical coherence among multiple pieces of evidence; 3) ensuring\nsemantic similarity between the global topic information and the semantic\nrepresentation of evidence; 4) aggregating evidence based on their implicit\nstances to the claim. Extensive experiments conducted on the two benchmark\ndatasets demonstrate the superiority of the proposed model over several\nstate-of-the-art approaches for fact verification. The source code can be\nobtained from https://github.com/jasenchn/TARSA.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 14:33:12 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Si", "Jiasheng", ""], ["Zhou", "Deyu", ""], ["Li", "Tongzhe", ""], ["Shi", "Xingyu", ""], ["He", "Yulan", ""]]}, {"id": "2106.01195", "submitter": "Tuhin Chakrabarty Mr", "authors": "Tuhin Chakrabarty, Debanjan Ghosh, Adam Poliak, Smaranda Muresan", "title": "Figurative Language in Recognizing Textual Entailment", "comments": "ACL 2021 (Findings)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a collection of recognizing textual entailment (RTE) datasets\nfocused on figurative language. We leverage five existing datasets annotated\nfor a variety of figurative language -- simile, metaphor, and irony -- and\nframe them into over 12,500 RTE examples.We evaluate how well state-of-the-art\nmodels trained on popular RTE datasets capture different aspects of figurative\nlanguage. Our results and analyses indicate that these models might not\nsufficiently capture figurative language, struggling to perform pragmatic\ninference and reasoning about world knowledge. Ultimately, our datasets provide\na challenging testbed for evaluating RTE models.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 14:37:32 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 14:20:10 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Chakrabarty", "Tuhin", ""], ["Ghosh", "Debanjan", ""], ["Poliak", "Adam", ""], ["Muresan", "Smaranda", ""]]}, {"id": "2106.01242", "submitter": "Ferdinando Fioretto", "authors": "Anudit Nagar, Cuong Tran, Ferdinando Fioretto", "title": "A Privacy-Preserving and Trustable Multi-agent Learning Framework", "comments": "This paper is an extended version of Reference [32]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed multi-agent learning enables agents to cooperatively train a\nmodel without requiring to share their datasets. While this setting ensures\nsome level of privacy, it has been shown that, even when data is not directly\nshared, the training process is vulnerable to privacy attacks including data\nreconstruction and model inversion attacks. Additionally, malicious agents that\ntrain on inverted labels or random data, may arbitrarily weaken the accuracy of\nthe global model. This paper addresses these challenges and presents\nPrivacy-preserving and trustable Distributed Learning (PT-DL), a fully\ndecentralized framework that relies on Differential Privacy to guarantee strong\nprivacy protections of the agents' data, and Ethereum smart contracts to ensure\ntrustability. The paper shows that PT-DL is resilient up to a 50% collusion\nattack, with high probability, in a malicious trust model and the experimental\nevaluation illustrates the benefits of the proposed model as a\nprivacy-preserving and trustable distributed multi-agent learning system on\nseveral classification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 15:46:27 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Nagar", "Anudit", ""], ["Tran", "Cuong", ""], ["Fioretto", "Ferdinando", ""]]}, {"id": "2106.01263", "submitter": "Chiyu Song", "authors": "Chiyu Song, Hongliang He, Huachuan Qiu, Haofei Yu, Zhenzhong Lan", "title": "Global-Selector: A New Benchmark Dataset and Model Architecture for\n  Multi-turn Response Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an essential component of dialogue systems, multi-turn response selection\naims to pick out the optimal response among a set of candidates to improve the\ndialogue fluency. In this paper, we investigate three problems of current\nresponse selection approaches, especially for generation-based conversational\nagents: (i) Existing approaches are often formulated as a sentence scoring\nproblem, which does not consider relationships between responses. (ii) Existing\nmodels tend to select undesirable candidates that have large overlaps with the\ndialogue history. (iii) Negative instances in training are mainly constructed\nby random sampling from the corpus, whereas generated candidates in practice\ntypically have a closer distribution. To address the above problems, we create\na new dataset called ConvAI2+ and propose a new response selector called\nGlobal-Selector. Experimental results show that Global-Selector trained on\nConvAI2+ have noticeable improvements in both accuracy and inference speed.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 16:14:51 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Song", "Chiyu", ""], ["He", "Hongliang", ""], ["Qiu", "Huachuan", ""], ["Yu", "Haofei", ""], ["Lan", "Zhenzhong", ""]]}, {"id": "2106.01277", "submitter": "Pierre Gutierrez", "authors": "Pierre Gutierrez, Antoine Cordier, Tha\\\"is Caldeira, Th\\'eophile\n  Sautory", "title": "Data augmentation and pre-trained networks for extremely low data\n  regimes unsupervised visual inspection", "comments": "16 pages, 8 figures, 9 tables, SPIE proceedings of Optical Metrology\n  conference (https://spie.org/conferences-and-exhibitions/optical-metrology)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The use of deep features coming from pre-trained neural networks for\nunsupervised anomaly detection purposes has recently gathered momentum in the\ncomputer vision field. In particular, industrial inspection applications can\ntake advantage of such features, as demonstrated by the multiple successes of\nrelated methods on the MVTec Anomaly Detection (MVTec AD) dataset. These\nmethods make use of neural networks pre-trained on auxiliary classification\ntasks such as ImageNet. However, to our knowledge, no comparative study of\nrobustness to the low data regimes between these approaches has been conducted\nyet. For quality inspection applications, the handling of limited sample sizes\nmay be crucial as large quantities of images are not available for small\nseries. In this work, we aim to compare three approaches based on deep\npre-trained features when varying the quantity of available data in MVTec AD:\nKNN, Mahalanobis, and PaDiM. We show that although these methods are mostly\nrobust to small sample sizes, they still can benefit greatly from using data\naugmentation in the original image space, which allows to deal with very small\nproduction runs.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 16:37:20 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Gutierrez", "Pierre", ""], ["Cordier", "Antoine", ""], ["Caldeira", "Tha\u00efs", ""], ["Sautory", "Th\u00e9ophile", ""]]}, {"id": "2106.01288", "submitter": "Charlotte Frenkel", "authors": "Charlotte Frenkel, David Bol, Giacomo Indiveri", "title": "Bottom-Up and Top-Down Neural Processing Systems Design: Neuromorphic\n  Intelligence as the Convergence of Natural and Artificial Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Moore's law has driven exponential computing power expectations, its\nnearing end calls for new avenues for improving the overall system performance.\nOne of these avenues is the exploration of new alternative brain-inspired\ncomputing architectures that promise to achieve the flexibility and\ncomputational efficiency of biological neural processing systems. Within this\ncontext, neuromorphic intelligence represents a paradigm shift in computing\nbased on the implementation of spiking neural network architectures tightly\nco-locating processing and memory. In this paper, we provide a comprehensive\noverview of the field, highlighting the different levels of granularity present\nin existing silicon implementations, comparing approaches that aim at\nreplicating natural intelligence (bottom-up) versus those that aim at solving\npractical artificial intelligence applications (top-down), and assessing the\nbenefits of the different circuit design styles used to achieve these goals.\nFirst, we present the analog, mixed-signal and digital circuit design styles,\nidentifying the boundary between processing and memory through time\nmultiplexing, in-memory computation and novel devices. Next, we highlight the\nkey tradeoffs for each of the bottom-up and top-down approaches, survey their\nsilicon implementations, and carry out detailed comparative analyses to extract\ndesign guidelines. Finally, we identify both necessary synergies and missing\nelements required to achieve a competitive advantage for neuromorphic edge\ncomputing over conventional machine-learning accelerators, and outline the key\nelements for a framework toward neuromorphic intelligence.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 16:51:45 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Frenkel", "Charlotte", ""], ["Bol", "David", ""], ["Indiveri", "Giacomo", ""]]}, {"id": "2106.01317", "submitter": "Yichen Jiang", "authors": "Yichen Jiang, Asli Celikyilmaz, Paul Smolensky, Paul Soulos, Sudha\n  Rao, Hamid Palangi, Roland Fernandez, Caitlin Smith, Mohit Bansal, Jianfeng\n  Gao", "title": "Enriching Transformers with Structured Tensor-Product Representations\n  for Abstractive Summarization", "comments": "NAACL 2021 (14 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstractive summarization, the task of generating a concise summary of input\ndocuments, requires: (1) reasoning over the source document to determine the\nsalient pieces of information scattered across the long document, and (2)\ncomposing a cohesive text by reconstructing these salient facts into a shorter\nsummary that faithfully reflects the complex relations connecting these facts.\nIn this paper, we adapt TP-TRANSFORMER (Schlag et al., 2019), an architecture\nthat enriches the original Transformer (Vaswani et al., 2017) with the\nexplicitly compositional Tensor Product Representation (TPR), for the task of\nabstractive summarization. The key feature of our model is a structural bias\nthat we introduce by encoding two separate representations for each token to\nrepresent the syntactic structure (with role vectors) and semantic content\n(with filler vectors) separately. The model then binds the role and filler\nvectors into the TPR as the layer output. We argue that the structured\nintermediate representations enable the model to take better control of the\ncontents (salient facts) and structures (the syntax that connects the facts)\nwhen generating the summary. Empirically, we show that our TP-TRANSFORMER\noutperforms the Transformer and the original TP-TRANSFORMER significantly on\nseveral abstractive summarization datasets based on both automatic and human\nevaluations. On several syntactic and semantic probing tasks, we demonstrate\nthe emergent structural information in the role vectors and improved syntactic\ninterpretability in the TPR layer outputs. Code and models are available at\nhttps://github.com/jiangycTarheel/TPT-Summ.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 17:32:33 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Jiang", "Yichen", ""], ["Celikyilmaz", "Asli", ""], ["Smolensky", "Paul", ""], ["Soulos", "Paul", ""], ["Rao", "Sudha", ""], ["Palangi", "Hamid", ""], ["Fernandez", "Roland", ""], ["Smith", "Caitlin", ""], ["Bansal", "Mohit", ""], ["Gao", "Jianfeng", ""]]}, {"id": "2106.01325", "submitter": "David Lindner", "authors": "David Lindner and Hoda Heidari and Andreas Krause", "title": "Addressing the Long-term Impact of ML Decisions via Policy Regret", "comments": "Accepted to IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) increasingly informs the allocation of opportunities to\nindividuals and communities in areas such as lending, education, employment,\nand beyond. Such decisions often impact their subjects' future characteristics\nand capabilities in an a priori unknown fashion. The decision-maker, therefore,\nfaces exploration-exploitation dilemmas akin to those in multi-armed bandits.\nFollowing prior work, we model communities as arms. To capture the long-term\neffects of ML-based allocation decisions, we study a setting in which the\nreward from each arm evolves every time the decision-maker pulls that arm. We\nfocus on reward functions that are initially increasing in the number of pulls\nbut may become (and remain) decreasing after a certain point. We argue that an\nacceptable sequential allocation of opportunities must take an arm's potential\nfor growth into account. We capture these considerations through the notion of\npolicy regret, a much stronger notion than the often-studied external regret,\nand present an algorithm with provably sub-linear policy regret for\nsufficiently long time horizons. We empirically compare our algorithm with\nseveral baselines and find that it consistently outperforms them, in particular\nfor long time horizons.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 17:38:10 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Lindner", "David", ""], ["Heidari", "Hoda", ""], ["Krause", "Andreas", ""]]}, {"id": "2106.01331", "submitter": "Tao Chen", "authors": "Tao Chen and Miqing Li", "title": "Multi-Objectivizing Software Configuration Tuning (for a single\n  performance concern)", "comments": "13 pages, 7 figures, 4 tables. In Proceedings of the 29th ACM Joint\n  European Software Engineering Conference and Symposium on the Foundations of\n  Software Engineering (ESEC/FSE'21), 2021", "journal-ref": null, "doi": "10.1145/3468264.3468555", "report-no": null, "categories": "cs.DC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatically tuning software configuration for optimizing a single\nperformance attribute (e.g., minimizing latency) is not trivial, due to the\nnature of the configuration systems (e.g., complex landscape and expensive\nmeasurement). To deal with the problem, existing work has been focusing on\ndeveloping various effective optimizers. However, a prominent issue that all\nthese optimizers need to take care of is how to avoid the search being trapped\nin local optima -- a hard nut to crack for software configuration tuning due to\nits rugged and sparse landscape, and neighboring configurations tending to\nbehave very differently. Overcoming such in an expensive measurement setting is\neven more challenging. In this paper, we take a different perspective to tackle\nthis issue. Instead of focusing on improving the optimizer, we work on the\nlevel of optimization model. We do this by proposing a meta\nmulti-objectivization model (MMO) that considers an auxiliary performance\nobjective (e.g., throughput in addition to latency). What makes this model\nunique is that we do not optimize the auxiliary performance objective, but\nrather use it to make similarly-performing while different configurations less\ncomparable (i.e. Pareto nondominated to each other), thus preventing the search\nfrom being trapped in local optima.\n  Experiments on eight real-world software systems/environments with diverse\nperformance attributes reveal that our MMO model is statistically more\neffective than state-of-the-art single-objective counterparts in overcoming\nlocal optima (up to 42% gain), while using as low as 24% of their measurements\nto achieve the same (or better) performance result.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 03:03:53 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Chen", "Tao", ""], ["Li", "Miqing", ""]]}, {"id": "2106.01342", "submitter": "Gowthami Somepalli", "authors": "Gowthami Somepalli, Micah Goldblum, Avi Schwarzschild, C. Bayan Bruss,\n  Tom Goldstein", "title": "SAINT: Improved Neural Networks for Tabular Data via Row Attention and\n  Contrastive Pre-Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Tabular data underpins numerous high-impact applications of machine learning\nfrom fraud detection to genomics and healthcare. Classical approaches to\nsolving tabular problems, such as gradient boosting and random forests, are\nwidely used by practitioners. However, recent deep learning methods have\nachieved a degree of performance competitive with popular techniques. We devise\na hybrid deep learning approach to solving tabular data problems. Our method,\nSAINT, performs attention over both rows and columns, and it includes an\nenhanced embedding method. We also study a new contrastive self-supervised\npre-training method for use when labels are scarce. SAINT consistently improves\nperformance over previous deep learning methods, and it even outperforms\ngradient boosting methods, including XGBoost, CatBoost, and LightGBM, on\naverage over a variety of benchmark tasks.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 17:51:05 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Somepalli", "Gowthami", ""], ["Goldblum", "Micah", ""], ["Schwarzschild", "Avi", ""], ["Bruss", "C. Bayan", ""], ["Goldstein", "Tom", ""]]}, {"id": "2106.01345", "submitter": "Lili Chen", "authors": "Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover,\n  Michael Laskin, Pieter Abbeel, Aravind Srinivas, Igor Mordatch", "title": "Decision Transformer: Reinforcement Learning via Sequence Modeling", "comments": "First two authors contributed equally. Last two authors advised\n  equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a framework that abstracts Reinforcement Learning (RL) as a\nsequence modeling problem. This allows us to draw upon the simplicity and\nscalability of the Transformer architecture, and associated advances in\nlanguage modeling such as GPT-x and BERT. In particular, we present Decision\nTransformer, an architecture that casts the problem of RL as conditional\nsequence modeling. Unlike prior approaches to RL that fit value functions or\ncompute policy gradients, Decision Transformer simply outputs the optimal\nactions by leveraging a causally masked Transformer. By conditioning an\nautoregressive model on the desired return (reward), past states, and actions,\nour Decision Transformer model can generate future actions that achieve the\ndesired return. Despite its simplicity, Decision Transformer matches or exceeds\nthe performance of state-of-the-art model-free offline RL baselines on Atari,\nOpenAI Gym, and Key-to-Door tasks.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 17:53:39 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 17:09:59 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Chen", "Lili", ""], ["Lu", "Kevin", ""], ["Rajeswaran", "Aravind", ""], ["Lee", "Kimin", ""], ["Grover", "Aditya", ""], ["Laskin", "Michael", ""], ["Abbeel", "Pieter", ""], ["Srinivas", "Aravind", ""], ["Mordatch", "Igor", ""]]}, {"id": "2106.01350", "submitter": "Joao Marques-Silva", "authors": "Xuanxiang Huang, Yacine Izza, Alexey Ignatiev, Joao Marques-Silva", "title": "On Efficiently Explaining Graph-Based Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent work has shown that not only decision trees (DTs) may not be\ninterpretable but also proposed a polynomial-time algorithm for computing one\nPI-explanation of a DT. This paper shows that for a wide range of classifiers,\nglobally referred to as decision graphs, and which include decision trees and\nbinary decision diagrams, but also their multi-valued variants, there exist\npolynomial-time algorithms for computing one PI-explanation. In addition, the\npaper also proposes a polynomial-time algorithm for computing one contrastive\nexplanation. These novel algorithms build on explanation graphs (XpG's). XpG's\ndenote a graph representation that enables both theoretical and practically\nefficient computation of explanations for decision graphs. Furthermore, the\npaper proposes a practically efficient solution for the enumeration of\nexplanations, and studies the complexity of deciding whether a given feature is\nincluded in some explanation. For the concrete case of decision trees, the\npaper shows that the set of all contrastive explanations can be enumerated in\npolynomial time. Finally, the experimental results validate the practical\napplicability of the algorithms proposed in the paper on a wide range of\npublicly available benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 17:55:41 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 08:15:16 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Huang", "Xuanxiang", ""], ["Izza", "Yacine", ""], ["Ignatiev", "Alexey", ""], ["Marques-Silva", "Joao", ""]]}, {"id": "2106.01352", "submitter": "Ahmed Qureshi", "authors": "Ahmed H. Qureshi, Arsalan Mousavian, Chris Paxton, Michael C. Yip, and\n  Dieter Fox", "title": "NeRP: Neural Rearrangement Planning for Unknown Objects", "comments": "Please refer to our supplementary video: https://youtu.be/CJb1IzH94eo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots will be expected to manipulate a wide variety of objects in complex\nand arbitrary ways as they become more widely used in human environments. As\nsuch, the rearrangement of objects has been noted to be an important benchmark\nfor AI capabilities in recent years. We propose NeRP (Neural Rearrangement\nPlanning), a deep learning based approach for multi-step neural object\nrearrangement planning which works with never-before-seen objects, that is\ntrained on simulation data, and generalizes to the real world. We compare NeRP\nto several naive and model-based baselines, demonstrating that our approach is\nmeasurably better and can efficiently arrange unseen objects in fewer steps and\nwith less planning time. Finally, we demonstrate it on several challenging\nrearrangement problems in the real world.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 17:56:27 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 18:02:18 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Qureshi", "Ahmed H.", ""], ["Mousavian", "Arsalan", ""], ["Paxton", "Chris", ""], ["Yip", "Michael C.", ""], ["Fox", "Dieter", ""]]}, {"id": "2106.01354", "submitter": "Swarnadeep Saha", "authors": "Swarnadeep Saha, Prateek Yadav, Mohit Bansal", "title": "multiPRover: Generating Multiple Proofs for Improved Interpretability in\n  Rule Reasoning", "comments": "NAACL 2021 (16 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on a type of linguistic formal reasoning where the goal is to reason\nover explicit knowledge in the form of natural language facts and rules (Clark\net al., 2020). A recent work, named PRover (Saha et al., 2020), performs such\nreasoning by answering a question and also generating a proof graph that\nexplains the answer. However, compositional reasoning is not always unique and\nthere may be multiple ways of reaching the correct answer. Thus, in our work,\nwe address a new and challenging problem of generating multiple proof graphs\nfor reasoning over natural language rule-bases. Each proof provides a different\nrationale for the answer, thereby improving the interpretability of such\nreasoning systems. In order to jointly learn from all proof graphs and exploit\nthe correlations between multiple proofs for a question, we pose this task as a\nset generation problem over structured output spaces where each proof is\nrepresented as a directed graph. We propose two variants of a proof-set\ngeneration model, multiPRover. Our first model, Multilabel-multiPRover,\ngenerates a set of proofs via multi-label classification and implicit\nconditioning between the proofs; while the second model, Iterative-multiPRover,\ngenerates proofs iteratively by explicitly conditioning on the previously\ngenerated proofs. Experiments on multiple synthetic, zero-shot, and\nhuman-paraphrased datasets reveal that both multiPRover models significantly\noutperform PRover on datasets containing multiple gold proofs.\nIterative-multiPRover obtains state-of-the-art proof F1 in zero-shot scenarios\nwhere all examples have single correct proofs. It also generalizes better to\nquestions requiring higher depths of reasoning where multiple proofs are more\nfrequent. Our code and models are publicly available at\nhttps://github.com/swarnaHub/multiPRover\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 17:58:35 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Saha", "Swarnadeep", ""], ["Yadav", "Prateek", ""], ["Bansal", "Mohit", ""]]}, {"id": "2106.01355", "submitter": "Weihua Zhou", "authors": "Zhuo He, Xinwei Zhang, Chen Zhao, Zhiyong Qian, Yao Wang, Xiaofeng\n  Hou, Jiangang Zou, Weihua Zhou", "title": "A method using deep learning to discover new predictors of CRT response\n  from mechanical dyssynchrony on gated SPECT MPI", "comments": "10 pages, 3 figures, will submit to journal of nuclear cardiology", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background. Studies have shown that the conventional left ventricular\nmechanical dyssynchrony (LVMD) parameters have their own statistical\nlimitations. The purpose of this study is to extract new LVMD parameters from\nthe phase analysis of gated SPECT MPI by deep learning to help CRT patient\nselection. Methods. One hundred and three patients who underwent rest gated\nSPECT MPI were enrolled in this study. CRT response was defined as a decrease\nin left ventricular end-systolic volume (LVESV) >= 15% at 6 +- 1 month follow\nup. Autoencoder (AE), an unsupervised deep learning method, was trained by the\nraw LV systolic phase polar maps to extract new LVMD parameters, called\nAE-based LVMD parameters. Correlation analysis was used to explain the\nrelationships between new parameters with conventional LVMD parameters.\nUnivariate and multivariate analyses were used to establish a multivariate\nmodel for predicting CRT response. Results. Complete data were obtained in 102\npatients, 44.1% of them were classified as CRT responders. AE-based LVMD\nparameter was significant in the univariate (OR 1.24, 95% CI 1.07 - 1.44, P =\n0.006) and multivariate analyses (OR 1.03, 95% CI 1.01 - 1.06, P = 0.006).\nMoreover, it had incremental value over PSD (AUC 0.72 vs. 0.63, LH 8.06, P =\n0.005) and PBW (AUC 0.72 vs. 0.64, LH 7.87, P = 0.005), combined with\nsignificant clinic characteristics, including LVEF and gender. Conclusions. The\nnew LVMD parameters extracted by autoencoder from the baseline gated SPECT MPI\nhas the potential to improve the prediction of CRT response.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 15:49:31 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["He", "Zhuo", ""], ["Zhang", "Xinwei", ""], ["Zhao", "Chen", ""], ["Qian", "Zhiyong", ""], ["Wang", "Yao", ""], ["Hou", "Xiaofeng", ""], ["Zou", "Jiangang", ""], ["Zhou", "Weihua", ""]]}, {"id": "2106.01367", "submitter": "David Coimbra", "authors": "David Coimbra, Sofia Reis, Rui Abreu, Corina P\\u{a}s\\u{a}reanu, Hakan\n  Erdogmus", "title": "On using distributed representations of source code for the detection of\n  C security vulnerabilities", "comments": "Submitted to DX 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG cs.PL cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents an evaluation of the code representation model Code2vec\nwhen trained on the task of detecting security vulnerabilities in C source\ncode. We leverage the open-source library astminer to extract path-contexts\nfrom the abstract syntax trees of a corpus of labeled C functions. Code2vec is\ntrained on the resulting path-contexts with the task of classifying a function\nas vulnerable or non-vulnerable. Using the CodeXGLUE benchmark, we show that\nthe accuracy of Code2vec for this task is comparable to simple\ntransformer-based methods such as pre-trained RoBERTa, and outperforms more\nnaive NLP-based methods. We achieved an accuracy of 61.43% while maintaining\nlow computational requirements relative to larger models.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 21:18:23 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Coimbra", "David", ""], ["Reis", "Sofia", ""], ["Abreu", "Rui", ""], ["P\u0103s\u0103reanu", "Corina", ""], ["Erdogmus", "Hakan", ""]]}, {"id": "2106.01399", "submitter": "J. Walker Orr", "authors": "J. Walker Orr, Nathaniel Russell", "title": "Automatic Assessment of the Design Quality of Python Programs with\n  Personalized Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The assessment of program functionality can generally be accomplished with\nstraight-forward unit tests. However, assessing the design quality of a program\nis a much more difficult and nuanced problem. Design quality is an important\nconsideration since it affects the readability and maintainability of programs.\nAssessing design quality and giving personalized feedback is very time\nconsuming task for instructors and teaching assistants. This limits the scale\nof giving personalized feedback to small class settings. Further, design\nquality is nuanced and is difficult to concisely express as a set of rules. For\nthese reasons, we propose a neural network model to both automatically assess\nthe design of a program and provide personalized feedback to guide students on\nhow to make corrections. The model's effectiveness is evaluated on a corpus of\nstudent programs written in Python. The model has an accuracy rate from 83.67%\nto 94.27%, depending on the dataset, when predicting design scores as compared\nto historical instructor assessment. Finally, we present a study where students\ntried to improve the design of their programs based on the personalized\nfeedback produced by the model. Students who participated in the study improved\ntheir program design scores by 19.58%.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 18:04:53 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Orr", "J. Walker", ""], ["Russell", "Nathaniel", ""]]}, {"id": "2106.01404", "submitter": "Jongwook Choi", "authors": "Jongwook Choi, Archit Sharma, Honglak Lee, Sergey Levine, Shixiang\n  Shane Gu", "title": "Variational Empowerment as Representation Learning for Goal-Based\n  Reinforcement Learning", "comments": "Accepted at International Conference on Machine Learning (ICML) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to reach goal states and learning diverse skills through mutual\ninformation (MI) maximization have been proposed as principled frameworks for\nself-supervised reinforcement learning, allowing agents to acquire broadly\napplicable multitask policies with minimal reward engineering. Starting from a\nsimple observation that the standard goal-conditioned RL (GCRL) is encapsulated\nby the optimization objective of variational empowerment, we discuss how GCRL\nand MI-based RL can be generalized into a single family of methods, which we\nname variational GCRL (VGCRL), interpreting variational MI maximization, or\nvariational empowerment, as representation learning methods that acquire\nfunctionally-aware state representations for goal reaching. This novel\nperspective allows us to: (1) derive simple but unexplored variants of GCRL to\nstudy how adding small representation capacity can already expand its\ncapabilities; (2) investigate how discriminator function capacity and\nsmoothness determine the quality of discovered skills, or latent goals, through\nmodifying latent dimensionality and applying spectral normalization; (3) adapt\ntechniques such as hindsight experience replay (HER) from GCRL to MI-based RL;\nand lastly, (4) propose a novel evaluation metric, named latent goal reaching\n(LGR), for comparing empowerment algorithms with different choices of latent\ndimensionality and discriminator parameterization. Through principled\nmathematical derivations and careful experimental studies, our work lays a\nnovel foundation from which to evaluate, analyze, and develop representation\nlearning techniques in goal-based RL.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 18:12:26 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Choi", "Jongwook", ""], ["Sharma", "Archit", ""], ["Lee", "Honglak", ""], ["Levine", "Sergey", ""], ["Gu", "Shixiang Shane", ""]]}, {"id": "2106.01410", "submitter": "Prasanna Sattigeri", "authors": "Soumya Ghosh, Q. Vera Liao, Karthikeyan Natesan Ramamurthy, Jiri\n  Navratil, Prasanna Sattigeri, Kush R. Varshney, Yunfeng Zhang", "title": "Uncertainty Quantification 360: A Holistic Toolkit for Quantifying and\n  Communicating the Uncertainty of AI", "comments": "Added references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe an open source Python toolkit named Uncertainty\nQuantification 360 (UQ360) for the uncertainty quantification of AI models. The\ngoal of this toolkit is twofold: first, to provide a broad range of\ncapabilities to streamline as well as foster the common practices of\nquantifying, evaluating, improving, and communicating uncertainty in the AI\napplication development lifecycle; second, to encourage further exploration of\nUQ's connections to other pillars of trustworthy AI such as fairness and\ntransparency through the dissemination of latest research and education\nmaterials. Beyond the Python package (\\url{https://github.com/IBM/UQ360}), we\nhave developed an interactive experience (\\url{http://uq360.mybluemix.net}) and\nguidance materials as educational tools to aid researchers and developers in\nproducing and communicating high-quality uncertainties in an effective manner.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 18:29:04 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 01:08:35 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Ghosh", "Soumya", ""], ["Liao", "Q. Vera", ""], ["Ramamurthy", "Karthikeyan Natesan", ""], ["Navratil", "Jiri", ""], ["Sattigeri", "Prasanna", ""], ["Varshney", "Kush R.", ""], ["Zhang", "Yunfeng", ""]]}, {"id": "2106.01416", "submitter": "Absalom Ezugwu", "authors": "Olaide N. Oyelade and Absalom E. Ezugwu", "title": "Ebola Optimization Search Algorithm (EOSA): A new metaheuristic\n  algorithm based on the propagation model of Ebola virus disease", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Ebola virus and the disease in effect tend to randomly move individuals\nin the population around susceptible, infected, quarantined, hospitalized,\nrecovered, and dead sub-population. Motivated by the effectiveness in\npropagating the disease through the virus, a new bio-inspired and\npopulation-based optimization algorithm is proposed. This paper presents a\nnovel metaheuristic algorithm named Ebola optimization algorithm (EOSA). To\ncorrectly achieve this, this study models the propagation mechanism of the\nEbola virus disease, emphasising all consistent states of the propagation. The\nmodel was further represented using a mathematical model based on first-order\ndifferential equations. After that, the combined propagation and mathematical\nmodels were adapted for developing the new metaheuristic algorithm. To evaluate\nthe proposed method's performance and capability compared with other\noptimization methods, the underlying propagation and mathematical models were\nfirst investigated to determine how they successfully simulate the EVD.\nFurthermore, two sets of benchmark functions consisting of forty-seven (47)\nclassical and over thirty (30) constrained IEEE CEC-2017 benchmark functions\nare investigated numerically. The results indicate that the performance of the\nproposed algorithm is competitive with other state-of-the-art optimization\nmethods based on scalability analysis, convergence analysis, and sensitivity\nanalysis. Extensive simulation results indicate that the EOSA outperforms other\nstate-of-the-art popular metaheuristic optimization algorithms such as the\nParticle Swarm Optimization Algorithm (PSO), Genetic Algorithm (GA), and\nArtificial Bee Colony Algorithm (ABC) on some shifted, high dimensional and\nlarge search range problems.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 18:41:56 GMT"}, {"version": "v2", "created": "Sat, 19 Jun 2021 21:02:53 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Oyelade", "Olaide N.", ""], ["Ezugwu", "Absalom E.", ""]]}, {"id": "2106.01420", "submitter": "Amin Karbasi", "authors": "Amin Karbasi, Vahab Mirrokni, Mohammad Shadravan", "title": "Parallelizing Thompson Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  How can we make use of information parallelism in online decision making\nproblems while efficiently balancing the exploration-exploitation trade-off? In\nthis paper, we introduce a batch Thompson Sampling framework for two canonical\nonline decision making problems, namely, stochastic multi-arm bandit and linear\ncontextual bandit with finitely many arms. Over a time horizon $T$, our\n\\textit{batch} Thompson Sampling policy achieves the same (asymptotic) regret\nbound of a fully sequential one while carrying out only $O(\\log T)$ batch\nqueries. To achieve this exponential reduction, i.e., reducing the number of\ninteractions from $T$ to $O(\\log T)$, our batch policy dynamically determines\nthe duration of each batch in order to balance the exploration-exploitation\ntrade-off. We also demonstrate experimentally that dynamic batch allocation\ndramatically outperforms natural baselines such as static batch allocations.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 18:51:57 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Karbasi", "Amin", ""], ["Mirrokni", "Vahab", ""], ["Shadravan", "Mohammad", ""]]}, {"id": "2106.01423", "submitter": "Henry Kvinge", "authors": "Henry Kvinge, Scott Howland, Nico Courts, Lauren A. Phillips, John\n  Buckheit, Zachary New, Elliott Skomski, Jung H. Lee, Sandeep Tiwari, Jessica\n  Hibler, Courtney D. Corley, Nathan O. Hodas", "title": "One Representation to Rule Them All: Identifying Out-of-Support Examples\n  in Few-shot Learning with Generic Representations", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of few-shot learning has made remarkable strides in developing\npowerful models that can operate in the small data regime. Nearly all of these\nmethods assume every unlabeled instance encountered will belong to a handful of\nknown classes for which one has examples. This can be problematic for\nreal-world use cases where one routinely finds 'none-of-the-above' examples. In\nthis paper we describe this challenge of identifying what we term\n'out-of-support' (OOS) examples. We describe how this problem is subtly\ndifferent from out-of-distribution detection and describe a new method of\nidentifying OOS examples within the Prototypical Networks framework using a\nfixed point which we call the generic representation. We show that our method\noutperforms other existing approaches in the literature as well as other\napproaches that we propose in this paper. Finally, we investigate how the use\nof such a generic point affects the geometry of a model's feature space.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 19:07:27 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Kvinge", "Henry", ""], ["Howland", "Scott", ""], ["Courts", "Nico", ""], ["Phillips", "Lauren A.", ""], ["Buckheit", "John", ""], ["New", "Zachary", ""], ["Skomski", "Elliott", ""], ["Lee", "Jung H.", ""], ["Tiwari", "Sandeep", ""], ["Hibler", "Jessica", ""], ["Corley", "Courtney D.", ""], ["Hodas", "Nathan O.", ""]]}, {"id": "2106.01441", "submitter": "Sabri Pllana", "authors": "Suejb Memeti and Sabri Pllana", "title": "Optimization of Heterogeneous Systems with AI Planning Heuristics and\n  Machine Learning: A Performance and Energy Aware Approach", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Heterogeneous computing systems provide high performance and energy\nefficiency. However, to optimally utilize such systems, solutions that\ndistribute the work across host CPUs and accelerating devices are needed. In\nthis paper, we present a performance and energy aware approach that combines AI\nplanning heuristics for parameter space exploration with a machine learning\nmodel for performance and energy evaluation to determine a near-optimal system\nconfiguration. For data-parallel applications our approach determines a\nnear-optimal host-device distribution of work, number of processing units\nrequired and the corresponding scheduling strategy. We evaluate our approach\nfor various heterogeneous systems accelerated with GPU or the Intel Xeon Phi.\nThe experimental results demonstrate that our approach finds a near-optimal\nsystem configuration by evaluating only about 7% of reasonable configurations.\nFurthermore, the performance per Joule estimation of system configurations\nusing our machine learning model is more than 1000x faster compared to the\nsystem evaluation by program execution.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 19:45:53 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Memeti", "Suejb", ""], ["Pllana", "Sabri", ""]]}, {"id": "2106.01451", "submitter": "Richard Diehl Martinez", "authors": "Richard Diehl Martinez, Scott Novotney, Ivan Bulyko, Ariya Rastrow,\n  Andreas Stolcke, Ankur Gandhe", "title": "Attention-based Contextual Language Model Adaptation for Speech\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Language modeling (LM) for automatic speech recognition (ASR) does not\nusually incorporate utterance level contextual information. For some domains\nlike voice assistants, however, additional context, such as the time at which\nan utterance was spoken, provides a rich input signal. We introduce an\nattention mechanism for training neural speech recognition language models on\nboth text and non-linguistic contextual data. When applied to a large\nde-identified dataset of utterances collected by a popular voice assistant\nplatform, our method reduces perplexity by 7.0% relative over a standard LM\nthat does not incorporate contextual information. When evaluated on utterances\nextracted from the long tail of the dataset, our method improves perplexity by\n9.0% relative over a standard LM and by over 2.8% relative when compared to a\nstate-of-the-art model for contextual LM.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 20:19:57 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Martinez", "Richard Diehl", ""], ["Novotney", "Scott", ""], ["Bulyko", "Ivan", ""], ["Rastrow", "Ariya", ""], ["Stolcke", "Andreas", ""], ["Gandhe", "Ankur", ""]]}, {"id": "2106.01465", "submitter": "Jieyu Zhao", "authors": "Jieyu Zhao, Daniel Khashabi, Tushar Khot, Ashish Sabharwal, and\n  Kai-Wei Chang", "title": "Ethical-Advice Taker: Do Language Models Understand Natural Language\n  Interventions?", "comments": "9 pages, Findings of ACL-IJCNLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Is it possible to use natural language to intervene in a model's behavior and\nalter its prediction in a desired way? We investigate the effectiveness of\nnatural language interventions for reading-comprehension systems, studying this\nin the context of social stereotypes. Specifically, we propose a new language\nunderstanding task, Linguistic Ethical Interventions (LEI), where the goal is\nto amend a question-answering (QA) model's unethical behavior by communicating\ncontext-specific principles of ethics and equity to it. To this end, we build\nupon recent methods for quantifying a system's social stereotypes, augmenting\nthem with different kinds of ethical interventions and the desired model\nbehavior under such interventions. Our zero-shot evaluation finds that even\ntoday's powerful neural language models are extremely poor ethical-advice\ntakers, that is, they respond surprisingly little to ethical interventions even\nthough these interventions are stated as simple sentences. Few-shot learning\nimproves model behavior but remains far from the desired outcome, especially\nwhen evaluated for various types of generalization. Our new task thus poses a\nnovel language understanding challenge for the community.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 20:57:58 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Zhao", "Jieyu", ""], ["Khashabi", "Daniel", ""], ["Khot", "Tushar", ""], ["Sabharwal", "Ashish", ""], ["Chang", "Kai-Wei", ""]]}, {"id": "2106.01489", "submitter": "Ziyun Li", "authors": "Ziyun Li, Xinshao Wang, Haojin Yang, Di Hu, Neil M. Robertson, David\n  A. Clifton, Christoph Meinel", "title": "Not All Knowledge Is Created Equal", "comments": "Selective mutual knowledge distillation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Mutual knowledge distillation (MKD) improves a model by distilling knowledge\nfrom another model. However, not all knowledge is certain and correct,\nespecially under adverse conditions. For example, label noise usually leads to\nless reliable models due to the undesired memorisation [1, 2]. Wrong knowledge\nmisleads the learning rather than helps. This problem can be handled by two\naspects: (i) improving the reliability of a model where the knowledge is from\n(i.e., knowledge source's reliability); (ii) selecting reliable knowledge for\ndistillation. In the literature, making a model more reliable is widely studied\nwhile selective MKD receives little attention. Therefore, we focus on studying\nselective MKD and highlight its importance in this work.\n  Concretely, a generic MKD framework, Confident knowledge selection followed\nby Mutual Distillation (CMD), is designed. The key component of CMD is a\ngeneric knowledge selection formulation, making the selection threshold either\nstatic (CMD-S) or progressive (CMD-P). Additionally, CMD covers two special\ncases: zero knowledge and all knowledge, leading to a unified MKD framework. We\nempirically find CMD-P performs better than CMD-S. The main reason is that a\nmodel's knowledge upgrades and becomes confident as the training progresses.\n  Extensive experiments are present to demonstrate the effectiveness of CMD and\nthoroughly justify the design of CMD. For example, CMD-P obtains new\nstate-of-the-art results in robustness against label noise.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 22:06:55 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Li", "Ziyun", ""], ["Wang", "Xinshao", ""], ["Yang", "Haojin", ""], ["Hu", "Di", ""], ["Robertson", "Neil M.", ""], ["Clifton", "David A.", ""], ["Meinel", "Christoph", ""]]}, {"id": "2106.01494", "submitter": "Shujian Zhang", "authors": "Shujian Zhang, Chengyue Gong, Eunsol Choi", "title": "Knowing More About Questions Can Help: Improving Calibration in Question\n  Answering", "comments": "ACL 2021 (finding)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study calibration in question answering, estimating whether model\ncorrectly predicts answer for each question. Unlike prior work which mainly\nrely on the model's confidence score, our calibrator incorporates information\nabout the input example (e.g., question and the evidence context). Together\nwith data augmentation via back translation, our simple approach achieves 5-10%\ngains in calibration accuracy on reading comprehension benchmarks. Furthermore,\nwe present the first calibration study in the open retrieval setting, comparing\nthe calibration accuracy of retrieval-based span prediction models and answer\ngeneration models. Here again, our approach shows consistent gains over\ncalibrators relying on the model confidence. Our simple and efficient\ncalibrator can be easily adapted to many tasks and model architectures, showing\nrobust gains in all settings.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 22:22:52 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Zhang", "Shujian", ""], ["Gong", "Chengyue", ""], ["Choi", "Eunsol", ""]]}, {"id": "2106.01503", "submitter": "Garrick Cabour", "authors": "Garrick Cabour, Andr\\'es Morales, \\'Elise Ledoux, Samuel Bassetto", "title": "Towards an Explanation Space to Align Humans and Explainable-AI Teamwork", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Providing meaningful and actionable explanations to end-users is a\nfundamental prerequisite for implementing explainable intelligent systems in\nthe real world. Explainability is a situated interaction between a user and the\nAI system rather than being static design principles. The content of\nexplanations is context-dependent and must be defined by evidence about the\nuser and its context. This paper seeks to operationalize this concept by\nproposing a formative architecture that defines the explanation space from a\nuser-inspired perspective. The architecture comprises five intertwined\ncomponents to outline explanation requirements for a task: (1) the end-users\nmental models, (2) the end-users cognitive process, (3) the user interface, (4)\nthe human-explainer agent, and the (5) agent process. We first define each\ncomponent of the architecture. Then we present the Abstracted Explanation\nSpace, a modeling tool that aggregates the architecture's components to support\ndesigners in systematically aligning explanations with the end-users work\npractices, needs, and goals. It guides the specifications of what needs to be\nexplained (content - end-users mental model), why this explanation is necessary\n(context - end-users cognitive process), to delimit how to explain it (format -\nhuman-explainer agent and user interface), and when should the explanations be\ngiven. We then exemplify the tool's use in an ongoing case study in the\naircraft maintenance domain. Finally, we discuss possible contributions of the\ntool, known limitations/areas for improvement, and future work to be done.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 23:17:29 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Cabour", "Garrick", ""], ["Morales", "Andr\u00e9s", ""], ["Ledoux", "\u00c9lise", ""], ["Bassetto", "Samuel", ""]]}, {"id": "2106.01577", "submitter": "Honghao Wei", "authors": "Honghao Wei, Xin Liu, Lei Ying", "title": "A Provably-Efficient Model-Free Algorithm for Constrained Markov\n  Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the first {\\em model-free}, {\\em simulator-free}\nreinforcement learning algorithm for Constrained Markov Decision Processes\n(CMDPs) with sublinear regret and zero constraint violation. The algorithm is\nnamed Triple-Q because it has three key components: a Q-function (also called\naction-value function) for the cumulative reward, a Q-function for the\ncumulative utility for the constraint, and a virtual-Queue that\n(over)-estimates the cumulative constraint violation. Under Triple-Q, at each\nstep, an action is chosen based on the pseudo-Q-value that is a combination of\nthe three Q values. The algorithm updates the reward and utility Q-values with\nlearning rates that depend on the visit counts to the corresponding (state,\naction) pairs and are periodically reset. In the episodic CMDP setting,\nTriple-Q achieves $\\tilde{\\cal O}\\left(\\frac{1 }{\\delta}H^4\nS^{\\frac{1}{2}}A^{\\frac{1}{2}}K^{\\frac{4}{5}} \\right)$ regret, where $K$ is the\ntotal number of episodes, $H$ is the number of steps in each episode, $S$ is\nthe number of states, $A$ is the number of actions, and $\\delta$ is Slater's\nconstant. Furthermore, Triple-Q guarantees zero constraint violation when $K$\nis sufficiently large. Finally, the computational complexity of Triple-Q is\nsimilar to SARSA for unconstrained MDPs and is computationally efficient.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 03:53:27 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Wei", "Honghao", ""], ["Liu", "Xin", ""], ["Ying", "Lei", ""]]}, {"id": "2106.01592", "submitter": "Shuo Jiang", "authors": "Shuo Jiang, Jie Hu, Kristin L. Wood, Jianxi Luo", "title": "Data-Driven Design-by-Analogy: State of the Art and Future Directions", "comments": "A Preprint Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Design-by-Analogy (DbA) is a design methodology wherein new solutions,\nopportunities or designs are generated in a target domain based on inspiration\ndrawn from a source domain; it can benefit designers in mitigating design\nfixation and improving design ideation outcomes. Recently, the increasingly\navailable design databases and rapidly advancing data science and artificial\nintelligence technologies have presented new opportunities for developing\ndata-driven methods and tools for DbA support. In this study, we survey\nexisting data-driven DbA studies and categorize individual studies according to\nthe data, methods, and applications in four categories, namely, analogy\nencoding, retrieval, mapping, and evaluation. Based on both nuanced organic\nreview and structured analysis, this paper elucidates the state of the art of\ndata-driven DbA research to date and benchmarks it with the frontier of data\nscience and AI research to identify promising research opportunities and\ndirections for the field. Finally, we propose a future conceptual data-driven\nDbA system that integrates all propositions.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 04:35:34 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Jiang", "Shuo", ""], ["Hu", "Jie", ""], ["Wood", "Kristin L.", ""], ["Luo", "Jianxi", ""]]}, {"id": "2106.01596", "submitter": "Ho Hin Lee", "authors": "Ho Hin Lee, Yucheng Tang, Qi Yang, Xin Yu, Shunxing Bao, Bennett A.\n  Landman, Yuankai Huo", "title": "Attention-Guided Supervised Contrastive Learning for Semantic\n  Segmentation", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrastive learning has shown superior performance in embedding global and\nspatial invariant features in computer vision (e.g., image classification).\nHowever, its overall success of embedding local and spatial variant features is\nstill limited, especially for semantic segmentation. In a per-pixel prediction\ntask, more than one label can exist in a single image for segmentation (e.g.,\nan image contains both cat, dog, and grass), thereby it is difficult to define\n'positive' or 'negative' pairs in a canonical contrastive learning setting. In\nthis paper, we propose an attention-guided supervised contrastive learning\napproach to highlight a single semantic object every time as the target. With\nour design, the same image can be embedded to different semantic clusters with\nsemantic attention (i.e., coerce semantic masks) as an additional input\nchannel. To achieve such attention, a novel two-stage training strategy is\npresented. We evaluate the proposed method on multi-organ medical image\nsegmentation task, as our major task, with both in-house data and BTCV 2015\ndatasets. Comparing with the supervised and semi-supervised training\nstate-of-the-art in the backbone of ResNet-50, our proposed pipeline yields\nsubstantial improvement of 5.53% and 6.09% in Dice score for both medical image\nsegmentation cohorts respectively. The performance of the proposed method on\nnatural images is assessed via PASCAL VOC 2012 dataset, and achieves 2.75%\nsubstantial improvement.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 05:01:11 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Lee", "Ho Hin", ""], ["Tang", "Yucheng", ""], ["Yang", "Qi", ""], ["Yu", "Xin", ""], ["Bao", "Shunxing", ""], ["Landman", "Bennett A.", ""], ["Huo", "Yuankai", ""]]}, {"id": "2106.01597", "submitter": "Kaushal Kumar Maurya", "authors": "Kaushal Kumar Maurya, Maunendra Sankar Desarkar, Yoshinobu Kano and\n  Kumari Deepshikha", "title": "ZmBART: An Unsupervised Cross-lingual Transfer Framework for Language\n  Generation", "comments": "Accepted in Findings of ACL-IJCNLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the recent advancement in NLP research, cross-lingual transfer for\nnatural language generation is relatively understudied. In this work, we\ntransfer supervision from high resource language (HRL) to multiple low-resource\nlanguages (LRLs) for natural language generation (NLG). We consider four NLG\ntasks (text summarization, question generation, news headline generation, and\ndistractor generation) and three syntactically diverse languages, i.e.,\nEnglish, Hindi, and Japanese. We propose an unsupervised cross-lingual language\ngeneration framework (called ZmBART) that does not use any parallel or\npseudo-parallel/back-translated data. In this framework, we further pre-train\nmBART sequence-to-sequence denoising auto-encoder model with an auxiliary task\nusing monolingual data of three languages. The objective function of the\nauxiliary task is close to the target tasks which enriches the multi-lingual\nlatent representation of mBART and provides good initialization for target\ntasks. Then, this model is fine-tuned with task-specific supervised English\ndata and directly evaluated with low-resource languages in the Zero-shot\nsetting. To overcome catastrophic forgetting and spurious correlation issues,\nwe applied freezing model component and data argumentation approaches\nrespectively. This simple modeling approach gave us promising results.We\nexperimented with few-shot training (with 1000 supervised data points) which\nboosted the model performance further. We performed several ablations and\ncross-lingual transferability analyses to demonstrate the robustness of ZmBART.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 05:08:01 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Maurya", "Kaushal Kumar", ""], ["Desarkar", "Maunendra Sankar", ""], ["Kano", "Yoshinobu", ""], ["Deepshikha", "Kumari", ""]]}, {"id": "2106.01609", "submitter": "Piji Li", "authors": "Piji Li and Shuming Shi", "title": "Tail-to-Tail Non-Autoregressive Sequence Prediction for Chinese\n  Grammatical Error Correction", "comments": "Accepted in the main conference of ACL 2021. Code:\n  https://github.com/lipiji/TtT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of Chinese Grammatical Error Correction (CGEC) and\npresent a new framework named Tail-to-Tail (\\textbf{TtT}) non-autoregressive\nsequence prediction to address the deep issues hidden in CGEC. Considering that\nmost tokens are correct and can be conveyed directly from source to target, and\nthe error positions can be estimated and corrected based on the bidirectional\ncontext information, thus we employ a BERT-initialized Transformer Encoder as\nthe backbone model to conduct information modeling and conveying. Considering\nthat only relying on the same position substitution cannot handle the\nvariable-length correction cases, various operations such substitution,\ndeletion, insertion, and local paraphrasing are required jointly. Therefore, a\nConditional Random Fields (CRF) layer is stacked on the up tail to conduct\nnon-autoregressive sequence prediction by modeling the token dependencies.\nSince most tokens are correct and easily to be predicted/conveyed to the\ntarget, then the models may suffer from a severe class imbalance issue. To\nalleviate this problem, focal loss penalty strategies are integrated into the\nloss functions. Moreover, besides the typical fix-length error correction\ndatasets, we also construct a variable-length corpus to conduct experiments.\nExperimental results on standard datasets, especially on the variable-length\ndatasets, demonstrate the effectiveness of TtT in terms of sentence-level\nAccuracy, Precision, Recall, and F1-Measure on tasks of error Detection and\nCorrection.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 05:56:57 GMT"}, {"version": "v2", "created": "Sun, 20 Jun 2021 07:55:11 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Li", "Piji", ""], ["Shi", "Shuming", ""]]}, {"id": "2106.01615", "submitter": "Quanyu Liao", "authors": "Quanyu Liao, Yuezun Li, Xin Wang, Bin Kong, Bin Zhu, Siwei Lyu,\n  Youbing Yin, Qi Song, Xi Wu", "title": "Imperceptible Adversarial Examples for Fake Image Detection", "comments": "Accepted by ICIP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fooling people with highly realistic fake images generated with Deepfake or\nGANs brings a great social disturbance to our society. Many methods have been\nproposed to detect fake images, but they are vulnerable to adversarial\nperturbations -- intentionally designed noises that can lead to the wrong\nprediction. Existing methods of attacking fake image detectors usually generate\nadversarial perturbations to perturb almost the entire image. This is redundant\nand increases the perceptibility of perturbations. In this paper, we propose a\nnovel method to disrupt the fake image detection by determining key pixels to a\nfake image detector and attacking only the key pixels, which results in the\n$L_0$ and the $L_2$ norms of adversarial perturbations much less than those of\nexisting works. Experiments on two public datasets with three fake image\ndetectors indicate that our proposed method achieves state-of-the-art\nperformance in both white-box and black-box attacks.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 06:25:04 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Liao", "Quanyu", ""], ["Li", "Yuezun", ""], ["Wang", "Xin", ""], ["Kong", "Bin", ""], ["Zhu", "Bin", ""], ["Lyu", "Siwei", ""], ["Yin", "Youbing", ""], ["Song", "Qi", ""], ["Wu", "Xi", ""]]}, {"id": "2106.01639", "submitter": "Chathura Gamage", "authors": "Chathura Gamage, Matthew Stephenson, Vimukthini Pinto, Jochen Renz", "title": "Deceptive Level Generation for Angry Birds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Angry Birds AI competition has been held over many years to encourage the\ndevelopment of AI agents that can play Angry Birds game levels better than\nhuman players. Many different agents with various approaches have been employed\nover the competition's lifetime to solve this task. Even though the performance\nof these agents has increased significantly over the past few years, they still\nshow major drawbacks in playing deceptive levels. This is because most of the\ncurrent agents try to identify the best next shot rather than planning an\neffective sequence of shots. In order to encourage advancements in such agents,\nwe present an automated methodology to generate deceptive game levels for Angry\nBirds. Even though there are many existing content generators for Angry Birds,\nthey do not focus on generating deceptive levels. In this paper, we propose a\nprocedure to generate deceptive levels for six deception categories that can\nfool the state-of-the-art Angry Birds playing AI agents. Our results show that\ngenerated deceptive levels exhibit similar characteristics of human-created\ndeceptive levels. Additionally, we define metrics to measure the stability,\nsolvability, and degree of deception of the generated levels.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 07:20:30 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Gamage", "Chathura", ""], ["Stephenson", "Matthew", ""], ["Pinto", "Vimukthini", ""], ["Renz", "Jochen", ""]]}, {"id": "2106.01650", "submitter": "Gavin Suddrey", "authors": "Gavin Suddrey, Ben Talbot and Frederic Maire", "title": "Learning and Executing Re-usable Behaviour Trees from Natural Language\n  Instruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Domestic and service robots have the potential to transform industries such\nas health care and small-scale manufacturing, as well as the homes in which we\nlive. However, due to the overwhelming variety of tasks these robots will be\nexpected to complete, providing generic out-of-the-box solutions that meet the\nneeds of every possible user is clearly intractable. To address this problem,\nrobots must therefore not only be capable of learning how to complete novel\ntasks at run-time, but the solutions to these tasks must also be informed by\nthe needs of the user. In this paper we demonstrate how behaviour trees, a well\nestablished control architecture in the fields of gaming and robotics, can be\nused in conjunction with natural language instruction to provide a robust and\nmodular control architecture for instructing autonomous agents to learn and\nperform novel complex tasks. We also show how behaviour trees generated using\nour approach can be generalised to novel scenarios, and can be re-used in\nfuture learning episodes to create increasingly complex behaviours. We validate\nthis work against an existing corpus of natural language instructions,\ndemonstrate the application of our approach on both a simulated robot solving a\ntoy problem, as well as two distinct real-world robot platforms which,\nrespectively, complete a block sorting scenario, and a patrol scenario.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 07:47:06 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Suddrey", "Gavin", ""], ["Talbot", "Ben", ""], ["Maire", "Frederic", ""]]}, {"id": "2106.01655", "submitter": "Lorenzo Steccanella", "authors": "Lorenzo Steccanella, Simone Totaro, Anders Jonsson", "title": "Hierarchical Representation Learning for Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper we present a novel method for learning hierarchical\nrepresentations of Markov decision processes. Our method works by partitioning\nthe state space into subsets, and defines subtasks for performing transitions\nbetween the partitions. We formulate the problem of partitioning the state\nspace as an optimization problem that can be solved using gradient descent\ngiven a set of sampled trajectories, making our method suitable for\nhigh-dimensional problems with large state spaces. We empirically validate the\nmethod, by showing that it can successfully learn a useful hierarchical\nrepresentation in a navigation domain. Once learned, the hierarchical\nrepresentation can be used to solve different tasks in the given domain, thus\ngeneralizing knowledge across tasks.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 07:53:18 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Steccanella", "Lorenzo", ""], ["Totaro", "Simone", ""], ["Jonsson", "Anders", ""]]}, {"id": "2106.01666", "submitter": "Kai-Hui Liang", "authors": "Kai-Hui Liang, Weiyan Shi, Yoojung Oh, Jingwen Zhang, Zhou Yu", "title": "Discovering Chatbot's Self-Disclosure's Impact on User Trust, Affinity,\n  and Recommendation Effectiveness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, chatbots have been empowered to engage in social\nconversations with humans and have the potential to elicit people to disclose\ntheir personal experiences, opinions, and emotions. However, how and to what\nextent people respond to chabots' self-disclosure remain less known. In this\nwork, we designed a social chatbot with three self-disclosure levels that\nconducted small talks and provided relevant recommendations to people. 372\nMTurk participants were randomized to one of the four groups with different\nself-disclosure levels to converse with the chatbot on two topics, movies, and\nCOVID-19. We found that people's self-disclosure level was strongly reciprocal\nto a chatbot's self-disclosure level. Chatbots' self-disclosure also positively\nimpacted engagement and users' perception of the bot and led to a more\neffective recommendation such that participants enjoyed and agreed more with\nthe recommendations.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 08:16:25 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Liang", "Kai-Hui", ""], ["Shi", "Weiyan", ""], ["Oh", "Yoojung", ""], ["Zhang", "Jingwen", ""], ["Yu", "Zhou", ""]]}, {"id": "2106.01680", "submitter": "Junyoung Park", "authors": "Junyoung Park, Jinhyun Choo, Jinkyoo Park", "title": "Convergent Graph Solvers", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the convergent graph solver (CGS), a deep learning method that\nlearns iterative mappings to predict the properties of a graph system at its\nstationary state (fixed point) with guaranteed convergence. CGS systematically\ncomputes the fixed points of a target graph system and decodes them to estimate\nthe stationary properties of the system without the prior knowledge of existing\nsolvers or intermediate solutions. The forward propagation of CGS proceeds in\nthree steps: (1) constructing the input dependent linear contracting iterative\nmaps, (2) computing the fixed-points of the linear maps, and (3) decoding the\nfixed-points to estimate the properties. The contractivity of the constructed\nlinear maps guarantees the existence and uniqueness of the fixed points\nfollowing the Banach fixed point theorem. To train CGS efficiently, we also\nderive a tractable analytical expression for its gradient by leveraging the\nimplicit function theorem. We evaluate the performance of CGS by applying it to\nvarious network-analytic and graph benchmark problems. The results indicate\nthat CGS has competitive capabilities for predicting the stationary properties\nof graph systems, irrespective of whether the target systems are linear or\nnon-linear. CGS also shows high performance for graph classification problems\nwhere the existence or the meaning of a fixed point is hard to be clearly\ndefined, which highlights the potential of CGS as a general graph neural\nnetwork architecture.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 08:29:17 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 12:14:40 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Park", "Junyoung", ""], ["Choo", "Jinhyun", ""], ["Park", "Jinkyoo", ""]]}, {"id": "2106.01683", "submitter": "Udaya B Rongala", "authors": "Udaya B. Rongala and Henrik J\\\"orntell", "title": "Rich dynamics caused by known biological brain network features\n  resulting in stateful networks", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The mammalian brain could contain dense and sparse network connectivity\nstructures, including both excitatory and inhibitory neurons, but is without\nany clearly defined output layer. The neurons have time constants, which mean\nthat the integrated network structure has state memory. The network structure\ncontains complex mutual interactions between the neurons under different\nconditions, which depend on the internal state of the network. The internal\nstate can be defined as the distribution of activity across all individual\nneurons across the network. Therefore, the state of a neuron/network becomes a\ndefining factor for how information is represented within the network. Towards\nthis study, we constructed a fully connected (with dense/sparse coding\nstrategies) recurrent network comprising of both excitatory and inhibitory\nneurons, driven by pseudo-random inputs of varying frequencies. In this study\nwe assessed the impact of varying specific intrinsic parameters of the neurons\nthat enriched network state dynamics, such as initial neuron activity, amount\nof inhibition in combination with thresholded neurons and conduction delays.\nThe impact was assessed by quantifying the changes in mutual interactions\nbetween the neurons within the network for each given input. We found such\neffects were more profound in sparsely connected networks than in densely\nconnected networks. However, also densely connected networks could make use of\nsuch dynamic changes in the mutual interactions between neurons, as a given\ninput could induce multiple different network states.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 08:32:43 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Rongala", "Udaya B.", ""], ["J\u00f6rntell", "Henrik", ""]]}, {"id": "2106.01686", "submitter": "Ningyu Zhang", "authors": "Ningyu Zhang, Qianghuai Jia, Shumin Deng, Xiang Chen, Hongbin Ye, Hui\n  Chen, Huaixiao Tou, Gang Huang, Zhao Wang, Nengwei Hua, Huajun Chen", "title": "AliCG: Fine-grained and Evolvable Conceptual Graph Construction for\n  Semantic Search at Alibaba", "comments": "Accepted by KDD 2021 (Applied Data Science Track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conceptual graphs, which is a particular type of Knowledge Graphs, play an\nessential role in semantic search. Prior conceptual graph construction\napproaches typically extract high-frequent, coarse-grained, and time-invariant\nconcepts from formal texts. In real applications, however, it is necessary to\nextract less-frequent, fine-grained, and time-varying conceptual knowledge and\nbuild taxonomy in an evolving manner. In this paper, we introduce an approach\nto implementing and deploying the conceptual graph at Alibaba. Specifically, We\npropose a framework called AliCG which is capable of a) extracting fine-grained\nconcepts by a novel bootstrapping with alignment consensus approach, b) mining\nlong-tail concepts with a novel low-resource phrase mining approach, c)\nupdating the graph dynamically via a concept distribution estimation method\nbased on implicit and explicit user behaviors. We have deployed the framework\nat Alibaba UC Browser. Extensive offline evaluation as well as online A/B\ntesting demonstrate the efficacy of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 08:44:03 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Zhang", "Ningyu", ""], ["Jia", "Qianghuai", ""], ["Deng", "Shumin", ""], ["Chen", "Xiang", ""], ["Ye", "Hongbin", ""], ["Chen", "Hui", ""], ["Tou", "Huaixiao", ""], ["Huang", "Gang", ""], ["Wang", "Zhao", ""], ["Hua", "Nengwei", ""], ["Chen", "Huajun", ""]]}, {"id": "2106.01703", "submitter": "Nirav Diwan", "authors": "Nirav Diwan, Tanmoy Chakravorty, Zubair Shafiq", "title": "Fingerprinting Fine-tuned Language Models in the Wild", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are concerns that the ability of language models (LMs) to generate high\nquality synthetic text can be misused to launch spam, disinformation, or\npropaganda. Therefore, the research community is actively working on developing\napproaches to detect whether a given text is organic or synthetic. While this\nis a useful first step, it is important to be able to further fingerprint the\nauthor LM to attribute its origin. Prior work on fingerprinting LMs is limited\nto attributing synthetic text generated by a handful (usually < 10) of\npre-trained LMs. However, LMs such as GPT2 are commonly fine-tuned in a myriad\nof ways (e.g., on a domain-specific text corpus) before being used to generate\nsynthetic text. It is challenging to fingerprinting fine-tuned LMs because the\nuniverse of fine-tuned LMs is much larger in realistic scenarios. To address\nthis challenge, we study the problem of large-scale fingerprinting of\nfine-tuned LMs in the wild. Using a real-world dataset of synthetic text\ngenerated by 108 different fine-tuned LMs, we conduct comprehensive experiments\nto demonstrate the limitations of existing fingerprinting approaches. Our\nresults show that fine-tuning itself is the most effective in attributing the\nsynthetic text generated by fine-tuned LMs.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 09:07:54 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Diwan", "Nirav", ""], ["Chakravorty", "Tanmoy", ""], ["Shafiq", "Zubair", ""]]}, {"id": "2106.01708", "submitter": "Buliao Huang", "authors": "Buliao Huang and Yunhui Zhu and Muhammad Usman and Huanhuan Chen", "title": "Semi-supervised Learning with Missing Values Imputation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Incomplete instances with various missing attributes in many real-world\napplications have brought challenges to the classification tasks. Missing\nvalues imputation methods are often employed to replace the missing values with\nsubstitute values. However, this process often separates the imputation and\nclassification, which may lead to inferior performance since label information\nare often ignored during imputation. Moreover, traditional methods may rely on\nimproper assumptions to initialize the missing values, whereas the\nunreliability of such initialization might lead to inferior performance. To\naddress these problems, a novel semi-supervised conditional normalizing flow\n(SSCFlow) is proposed in this paper. SSCFlow explicitly utilizes the label\ninformation to facilitate the imputation and classification simultaneously by\nestimating the conditional distribution of incomplete instances with a novel\nsemi-supervised normalizing flow. Moreover, SSCFlow treats the initialized\nmissing values as corrupted initial imputation and iteratively reconstructs\ntheir latent representations with an overcomplete denoising autoencoder to\napproximate their true conditional distribution. Experiments on real-world\ndatasets demonstrate the robustness and effectiveness of the proposed\nalgorithm.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 09:24:58 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 13:21:15 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Huang", "Buliao", ""], ["Zhu", "Yunhui", ""], ["Usman", "Muhammad", ""], ["Chen", "Huanhuan", ""]]}, {"id": "2106.01709", "submitter": "Shuang Zeng", "authors": "Shuang Zeng, Yuting Wu and Baobao Chang", "title": "SIRE: Separate Intra- and Inter-sentential Reasoning for Document-level\n  Relation Extraction", "comments": "11 pages, 3 figures, 3 tables, Long paper accepted by Findings of\n  ACL-IJCNLP 2021", "journal-ref": "ACL-IJCNLP 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Document-level relation extraction has attracted much attention in recent\nyears. It is usually formulated as a classification problem that predicts\nrelations for all entity pairs in the document. However, previous works\nindiscriminately represent intra- and inter-sentential relations in the same\nway, confounding the different patterns for predicting them. Besides, they\ncreate a document graph and use paths between entities on the graph as clues\nfor logical reasoning. However, not all entity pairs can be connected with a\npath and have the correct logical reasoning paths in their graph. Thus many\ncases of logical reasoning cannot be covered. This paper proposes an effective\narchitecture, SIRE, to represent intra- and inter-sentential relations in\ndifferent ways. We design a new and straightforward form of logical reasoning\nmodule that can cover more logical reasoning chains. Experiments on the public\ndatasets show SIRE outperforms the previous state-of-the-art methods. Further\nanalysis shows that our predictions are reliable and explainable. Our code is\navailable at https://github.com/DreamInvoker/SIRE.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 09:25:44 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Zeng", "Shuang", ""], ["Wu", "Yuting", ""], ["Chang", "Baobao", ""]]}, {"id": "2106.01714", "submitter": "Xiao Zhang", "authors": "Xiao Zhang, Dongrui Wu, Haoyi Xiong, Bo Dai", "title": "Optimization Variance: Exploring Generalization Properties of DNNs", "comments": "Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike the conventional wisdom in statistical learning theory, the test error\nof a deep neural network (DNN) often demonstrates double descent: as the model\ncomplexity increases, it first follows a classical U-shaped curve and then\nshows a second descent. Through bias-variance decomposition, recent studies\nrevealed that the bell-shaped variance is the major cause of model-wise double\ndescent (when the DNN is widened gradually). This paper investigates epoch-wise\ndouble descent, i.e., the test error of a DNN also shows double descent as the\nnumber of training epoches increases. By extending the bias-variance analysis\nto epoch-wise double descent of the zero-one loss, we surprisingly find that\nthe variance itself, without the bias, varies consistently with the test error.\nInspired by this result, we propose a novel metric, optimization variance (OV),\nto measure the diversity of model updates caused by the stochastic gradients of\nrandom training batches drawn in the same iteration. OV can be estimated using\nsamples from the training set only but correlates well with the (unknown)\n\\emph{test} error, and hence early stopping may be achieved without using a\nvalidation set.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 09:34:17 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Zhang", "Xiao", ""], ["Wu", "Dongrui", ""], ["Xiong", "Haoyi", ""], ["Dai", "Bo", ""]]}, {"id": "2106.01741", "submitter": "David Mark Bossens", "authors": "David M. Bossens and Adam J. Sobey", "title": "Lifetime policy reuse and the importance of task capacity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A long-standing challenge in artificial intelligence is lifelong learning. In\nlifelong learning, many tasks are presented in sequence and learners must\nefficiently transfer knowledge between tasks while avoiding catastrophic\nforgetting over long lifetimes. On these problems, policy reuse and other\nmulti-policy reinforcement learning techniques can learn many tasks. However,\nthey can generate many temporary or permanent policies, resulting in memory\nissues. Consequently, there is a need for lifetime-scalable methods that\ncontinually refine a policy library of a pre-defined size. This paper presents\na first approach to lifetime-scalable policy reuse. To pre-select the number of\npolicies, a notion of task capacity, the maximal number of tasks that a policy\ncan accurately solve, is proposed. To evaluate lifetime policy reuse using this\nmethod, two state-of-the-art single-actor base-learners are compared: 1) a\nvalue-based reinforcement learner, Deep Q-Network (DQN) or Deep Recurrent\nQ-Network (DRQN); and 2) an actor-critic reinforcement learner, Proximal Policy\nOptimisation (PPO) with or without Long Short-Term Memory layer. By selecting\nthe number of policies based on task capacity, D(R)QN achieves near-optimal\nperformance with 6 policies in a 27-task MDP domain and 9 policies in an\n18-task POMDP domain; with fewer policies, catastrophic forgetting and negative\ntransfer are observed. Due to slow, monotonic improvement, PPO requires fewer\npolicies, 1 policy for the 27-task domain and 4 policies for the 18-task\ndomain, but it learns the tasks with lower accuracy than D(R)QN. These findings\nvalidate lifetime-scalable policy reuse and suggest using D(R)QN for larger and\nPPO for smaller library sizes.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 10:42:49 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Bossens", "David M.", ""], ["Sobey", "Adam J.", ""]]}, {"id": "2106.01750", "submitter": "Shrisha Rao", "authors": "Ronak Doshi and Ajay Ramesh Ranganathan and Shrisha Rao", "title": "Modeling Influencer Marketing Campaigns In Social Networks", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In the present day, more than 3.8 billion people around the world actively\nuse social media. The effectiveness of social media in facilitating quick and\neasy sharing of information has attracted brands and advertizers who wish to\nuse the platform to market products via the influencers in the network.\nInfluencers, owing to their massive popularity, provide a huge potential\ncustomer base generating higher returns of investment in a very short period.\nHowever, it is not straightforward to decide which influencers should be\nselected for an advertizing campaign that can generate maximum returns with\nminimum investment. In this work, we present an agent-based model (ABM) that\ncan simulate the dynamics of influencer advertizing campaigns in a variety of\nscenarios and can help to discover the best influencer marketing strategy. Our\nsystem is a probabilistic graph-based model that incorporates real-world\nfactors such as customers' interest in a product, customer behavior, the\nwillingness to pay, a brand's investment cap, influencers' engagement with\ninfluence diffusion, and the nature of the product being advertized viz. luxury\nand non-luxury.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 11:01:06 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Doshi", "Ronak", ""], ["Ranganathan", "Ajay Ramesh", ""], ["Rao", "Shrisha", ""]]}, {"id": "2106.01770", "submitter": "Susanne Trick", "authors": "Susanne Trick, Constantin A. Rothkopf", "title": "A Normative Model of Classifier Fusion", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining the outputs of multiple classifiers or experts into a single\nprobabilistic classification is a fundamental task in machine learning with\nbroad applications from classifier fusion to expert opinion pooling. Here we\npresent a hierarchical Bayesian model of probabilistic classifier fusion based\non a new correlated Dirichlet distribution. This distribution explicitly models\npositive correlations between marginally Dirichlet-distributed random vectors\nthereby allowing normative modeling of correlations between base classifiers or\nexperts. The proposed model naturally accommodates the classic Independent\nOpinion Pool and other independent fusion algorithms as special cases. It is\nevaluated by uncertainty reduction and correctness of fusion on synthetic and\nreal-world data sets. We show that a change in performance of the fused\nclassifier due to uncertainty reduction can be Bayes optimal even for highly\ncorrelated base classifiers.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 11:52:13 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Trick", "Susanne", ""], ["Rothkopf", "Constantin A.", ""]]}, {"id": "2106.01777", "submitter": "Aaron Snoswell", "authors": "Aaron J. Snoswell, Surya P. N. Singh, Nan Ye", "title": "LiMIIRL: Lightweight Multiple-Intent Inverse Reinforcement Learning", "comments": "Under review for NeurIPS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multiple-Intent Inverse Reinforcement Learning (MI-IRL) seeks to find a\nreward function ensemble to rationalize demonstrations of different but\nunlabelled intents. Within the popular expectation maximization (EM) framework\nfor learning probabilistic MI-IRL models, we present a warm-start strategy\nbased on up-front clustering of the demonstrations in feature space. Our\ntheoretical analysis shows that this warm-start solution produces a\nnear-optimal reward ensemble, provided the behavior modes satisfy mild\nseparation conditions. We also propose a MI-IRL performance metric that\ngeneralizes the popular Expected Value Difference measure to directly assesses\nlearned rewards against the ground-truth reward ensemble. Our metric elegantly\naddresses the difficulty of pairing up learned and ground truth rewards via a\nmin-cost flow formulation, and is efficiently computable. We also develop a\nMI-IRL benchmark problem that allows for more comprehensive algorithmic\nevaluations. On this problem, we find our MI-IRL warm-start strategy helps\navoid poor quality local minima reward ensembles, resulting in a significant\nimprovement in behavior clustering. Our extensive sensitivity analysis\ndemonstrates that the quality of the learned reward ensembles is improved under\nvarious settings, including cases where our theoretical assumptions do not\nnecessarily hold. Finally, we demonstrate the effectiveness of our methods by\ndiscovering distinct driving styles in a large real-world dataset of driver GPS\ntrajectories.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 12:00:38 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Snoswell", "Aaron J.", ""], ["Singh", "Surya P. N.", ""], ["Ye", "Nan", ""]]}, {"id": "2106.01784", "submitter": "Ben Green", "authors": "Ben Green", "title": "The Contestation of Tech Ethics: A Sociotechnical Approach to Ethics and\n  Technology in Action", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent controversies related to topics such as fake news, privacy, and\nalgorithmic bias have prompted increased public scrutiny of digital\ntechnologies and soul-searching among many of the people associated with their\ndevelopment. In response, the tech industry, academia, civil society, and\ngovernments have rapidly increased their attention to \"ethics\" in the design\nand use of digital technologies (\"tech ethics\"). Yet almost as quickly as\nethics discourse has proliferated across the world of digital technologies, the\nlimitations of these approaches have also become apparent: tech ethics is vague\nand toothless, is subsumed into corporate logics and incentives, and has a\nmyopic focus on individual engineers and technology design rather than on the\nstructures and cultures of technology production. As a result of these\nlimitations, many have grown skeptical of tech ethics and its proponents,\ncharging them with \"ethics-washing\": promoting ethics research and discourse to\ndefuse criticism and government regulation without committing to ethical\nbehavior. By looking at how ethics has been taken up in both science and\nbusiness in superficial and depoliticizing ways, I recast tech ethics as a\nterrain of contestation where the central fault line is not whether it is\ndesirable to be ethical, but what \"ethics\" entails and who gets to define it.\nThis framing highlights the significant limits of current approaches to tech\nethics and the importance of studying the formulation and real-world effects of\ntech ethics. In order to identify and develop more rigorous strategies for\nreforming digital technologies and the social relations that they mediate, I\ndescribe a sociotechnical approach to tech ethics, one that reflexively applies\nmany of tech ethics' own lessons regarding digital technologies to tech ethics\nitself.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 12:16:08 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Green", "Ben", ""]]}, {"id": "2106.01786", "submitter": "Charbel Merhej", "authors": "Charbel Merhej, Ryan Beal, Sarvapali Ramchurn (University of\n  Southampton), Tim Matthews (Sentient Sports)", "title": "What Happened Next? Using Deep Learning to Value Defensive Actions in\n  Football Event-Data", "comments": "10 pages, 7 figures, Proceedings of the 27th ACM SIGKDD Conference on\n  Knowledge Discovery and Data Mining (KDD '21), August 14--18, 2021, Virtual\n  Event, Singapore", "journal-ref": null, "doi": "10.1145/3447548.3467090", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Objectively quantifying the value of player actions in football (soccer) is a\nchallenging problem. To date, studies in football analytics have mainly focused\non the attacking side of the game, while there has been less work on\nevent-driven metrics for valuing defensive actions (e.g., tackles and\ninterceptions). Therefore in this paper, we use deep learning techniques to\ndefine a novel metric that values such defensive actions by studying the threat\nof passages of play that preceded them. By doing so, we are able to value\ndefensive actions based on what they prevented from happening in the game. Our\nDefensive Action Expected Threat (DAxT) model has been validated using\nreal-world event-data from the 2017/2018 and 2018/2019 English Premier League\nseasons, and we combine our model outputs with additional features to derive an\noverall rating of defensive ability for players. Overall, we find that our\nmodel is able to predict the impact of defensive actions allowing us to better\nvalue defenders using event-data.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 12:18:26 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Merhej", "Charbel", "", "University of\n  Southampton"], ["Beal", "Ryan", "", "University of\n  Southampton"], ["Ramchurn", "Sarvapali", "", "University of\n  Southampton"], ["Matthews", "Tim", "", "Sentient Sports"]]}, {"id": "2106.01798", "submitter": "Mathias Niepert", "authors": "Mathias Niepert and Pasquale Minervini and Luca Franceschi", "title": "Implicit MLE: Backpropagating Through Discrete Exponential Family\n  Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Integrating discrete probability distributions and combinatorial optimization\nproblems into neural networks has numerous applications but poses several\nchallenges. We propose Implicit Maximum Likelihood Estimation (I-MLE), a\nframework for end-to-end learning of models combining discrete exponential\nfamily distributions and differentiable neural components. I-MLE is widely\napplicable: it only requires the ability to compute the most probable states;\nand does not rely on smooth relaxations. The framework encompasses several\napproaches, such as perturbation-based implicit differentiation and recent\nmethods to differentiate through black-box combinatorial solvers. We introduce\na novel class of noise distributions for approximating marginals via\nperturb-and-MAP. Moreover, we show that I-MLE simplifies to maximum likelihood\nestimation when used in some recently studied learning settings that involve\ncombinatorial solvers. Experiments on several datasets suggest that I-MLE is\ncompetitive with and often outperforms existing approaches which rely on\nproblem-specific relaxations.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 12:42:21 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Niepert", "Mathias", ""], ["Minervini", "Pasquale", ""], ["Franceschi", "Luca", ""]]}, {"id": "2106.01804", "submitter": "Haiyang Xu", "authors": "Haiyang Xu, Ming Yan, Chenliang Li, Bin Bi, Songfang Huang, Wenming\n  Xiao and Fei Huang", "title": "E2E-VLP: End-to-End Vision-Language Pre-training Enhanced by Visual\n  Learning", "comments": "ACL2021 main conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision-language pre-training (VLP) on large-scale image-text pairs has\nachieved huge success for the cross-modal downstream tasks. The most existing\npre-training methods mainly adopt a two-step training procedure, which firstly\nemploys a pre-trained object detector to extract region-based visual features,\nthen concatenates the image representation and text embedding as the input of\nTransformer to train. However, these methods face problems of using\ntask-specific visual representation of the specific object detector for generic\ncross-modal understanding, and the computation inefficiency of two-stage\npipeline. In this paper, we propose the first end-to-end vision-language\npre-trained model for both V+L understanding and generation, namely E2E-VLP,\nwhere we build a unified Transformer framework to jointly learn visual\nrepresentation, and semantic alignments between image and text. We incorporate\nthe tasks of object detection and image captioning into pre-training with a\nunified Transformer encoder-decoder architecture for enhancing visual learning.\nAn extensive set of experiments have been conducted on well-established\nvision-language downstream tasks to demonstrate the effectiveness of this novel\nVLP paradigm.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 12:50:26 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 06:56:48 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Xu", "Haiyang", ""], ["Yan", "Ming", ""], ["Li", "Chenliang", ""], ["Bi", "Bin", ""], ["Huang", "Songfang", ""], ["Xiao", "Wenming", ""], ["Huang", "Fei", ""]]}, {"id": "2106.01826", "submitter": "Beren Millidge Mr", "authors": "Beren Millidge", "title": "Towards a Mathematical Theory of Abstraction", "comments": "03/06/21 initial upload. 25/06/21 minor fixes and corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the utility of well-chosen abstractions for understanding and\npredicting the behaviour of complex systems is well appreciated, precisely what\nan abstraction $\\textit{is}$ has so far has largely eluded mathematical\nformalization. In this paper, we aim to set out a mathematical theory of\nabstraction. We provide a precise characterisation of what an abstraction is\nand, perhaps more importantly, suggest how abstractions can be learnt directly\nfrom data both for static datasets and for dynamical systems. We define an\nabstraction to be a small set of `summaries' of a system which can be used to\nanswer a set of queries about the system or its behaviour. The difference\nbetween the ground truth behaviour of the system on the queries and the\nbehaviour of the system predicted only by the abstraction provides a measure of\nthe `leakiness' of the abstraction which can be used as a loss function to\ndirectly learn abstractions from data. Our approach can be considered a\ngeneralization of classical statistics where we are not interested in\nreconstructing `the data' in full, but are instead only concerned with\nanswering a set of arbitrary queries about the data. While highly theoretical,\nour results have deep implications for statistical inference and machine\nlearning and could be used to develop explicit methods for learning precise\nkinds of abstractions directly from data.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 13:23:49 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 19:37:18 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Millidge", "Beren", ""]]}, {"id": "2106.01834", "submitter": "Timoth\\'ee Lesort", "authors": "Timoth\\'ee Lesort, Thomas George, Irina Rish", "title": "Continual Learning in Deep Networks: an Analysis of the Last Layer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study how different output layer types of a deep neural network learn and\nforget in continual learning settings. We describe the three factors affecting\ncatastrophic forgetting in the output layer: (1) weights modifications, (2)\ninterferences, and (3) projection drift. Our goal is to provide more insights\ninto how different types of output layers can address (1) and (2). We also\npropose potential solutions and evaluate them on several benchmarks. We show\nthat the best-performing output layer type depends on the data distribution\ndrifts or the amount of data available. In particular, in some cases where a\nstandard linear layer would fail, it is sufficient to change the\nparametrization and get significantly better performance while still training\nwith SGD. Our results and analysis shed light on the dynamics of the output\nlayer in continual learning scenarios and help select the best-suited output\nlayer for a given scenario.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 13:41:29 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Lesort", "Timoth\u00e9e", ""], ["George", "Thomas", ""], ["Rish", "Irina", ""]]}, {"id": "2106.01862", "submitter": "Jesse Hagenaars", "authors": "Federico Paredes-Vall\\'es, Jesse Hagenaars, Guido de Croon", "title": "Self-Supervised Learning of Event-Based Optical Flow with Spiking Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic sensing and computing hold a promise for highly energy-efficient\nand high-bandwidth-sensor processing. A major challenge for neuromorphic\ncomputing is that learning algorithms for traditional artificial neural\nnetworks (ANNs) do not transfer directly to spiking neural networks (SNNs) due\nto the discrete spikes and more complex neuronal dynamics. As a consequence,\nSNNs have not yet been successfully applied to complex, large-scale tasks. In\nthis article, we focus on the self-supervised learning problem of optical flow\nestimation from event-based camera inputs, and investigate the changes that are\nnecessary to the state-of-the-art ANN training pipeline in order to\nsuccessfully tackle it with SNNs. More specifically, we first modify the input\nevent representation to encode a much smaller time slice with minimal explicit\ntemporal information. Consequently, we make the network's neuronal dynamics and\nrecurrent connections responsible for integrating information over time.\nMoreover, we reformulate the self-supervised loss function for event-based\noptical flow to improve its convexity. We perform experiments with various\ntypes of recurrent ANNs and SNNs using the proposed pipeline. Concerning SNNs,\nwe investigate the effects of elements such as parameter initialization and\noptimization, surrogate gradient shape, and adaptive neuronal mechanisms. We\nfind that initialization and surrogate gradient width play a crucial part in\nenabling learning with sparse inputs, while the inclusion of adaptivity and\nlearnable neuronal parameters can improve performance. We show that the\nperformance of the proposed ANNs and SNNs are on par with that of the current\nstate-of-the-art ANNs trained in a self-supervised manner.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 14:03:41 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Paredes-Vall\u00e9s", "Federico", ""], ["Hagenaars", "Jesse", ""], ["de Croon", "Guido", ""]]}, {"id": "2106.01865", "submitter": "Taufiq Hasan", "authors": "Farhat Binte Azam, Md. Istiaq Ansari, Ian Mclane, Taufiq Hasan", "title": "Heart Sound Classification Considering Additive Noise and Convolutional\n  Distortion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cardiac auscultation is an essential point-of-care method used for the early\ndiagnosis of heart diseases. Automatic analysis of heart sounds for abnormality\ndetection is faced with the challenges of additive noise and sensor-dependent\ndegradation. This paper aims to develop methods to address the cardiac\nabnormality detection problem when both types of distortions are present in the\ncardiac auscultation sound. We first mathematically analyze the effect of\nadditive and convolutional noise on short-term filterbank-based features and a\nConvolutional Neural Network (CNN) layer. Based on the analysis, we propose a\ncombination of linear and logarithmic spectrogram-image features. These 2D\nfeatures are provided as input to a residual CNN network (ResNet) for heart\nsound abnormality detection. Experimental validation is performed on an\nopen-access heart sound abnormality detection dataset involving noisy\nrecordings obtained from multiple stethoscope sensors. The proposed method\nachieves significantly improved results compared to the conventional\napproaches, with an area under the ROC (receiver operating characteristics)\ncurve (AUC) of 91.36%, F-1 score of 84.09%, and Macc (mean of sensitivity and\nspecificity) of 85.08%. We also show that the proposed method shows the best\nmean accuracy across different source domains including stethoscope and noise\nvariability, demonstrating its effectiveness in different recording conditions.\nThe proposed combination of linear and logarithmic features along with the\nResNet classifier effectively minimizes the impact of background noise and\nsensor variability for classifying phonocardiogram (PCG) signals. The proposed\nmethod paves the way towards developing computer-aided cardiac auscultation\nsystems in noisy environments using low-cost stethoscopes.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 14:09:04 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Azam", "Farhat Binte", ""], ["Ansari", "Md. Istiaq", ""], ["Mclane", "Ian", ""], ["Hasan", "Taufiq", ""]]}, {"id": "2106.01871", "submitter": "Xin Tao", "authors": "Xin Tao, Jonas M{\\aa}rtensson, H{\\aa}kan Warnquist, Anna Pernest{\\aa}l", "title": "Short-term Maintenance Planning of Autonomous Trucks for Minimizing\n  Economic Risk", "comments": "22 pages, 13 figures, journal, submitted to Reliability Engineering &\n  System Safety, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New autonomous driving technologies are emerging every day and some of them\nhave been commercially applied in the real world. While benefiting from these\ntechnologies, autonomous trucks are facing new challenges in short-term\nmaintenance planning, which directly influences the truck operator's profit. In\nthis paper, we implement a vehicle health management system by addressing the\nmaintenance planning issues of autonomous trucks on a transport mission. We\nalso present a maintenance planning model using a risk-based decision-making\nmethod, which identifies the maintenance decision with minimal economic risk of\nthe truck company. Both availability losses and maintenance costs are\nconsidered when evaluating the economic risk. We demonstrate the proposed model\nby numerical experiments illustrating real-world scenarios. In the experiments,\ncompared to three baseline methods, the expected economic risk of the proposed\nmethod is reduced by up to $47\\%$. We also conduct sensitivity analyses of\ndifferent model parameters. The analyses show that the economic risk\nsignificantly decreases when the estimation accuracy of remaining useful life,\nthe maximal allowed time of delivery delay before order cancellation, or the\nnumber of workshops increases. The experiment results contribute to identifying\nfuture research and development attentions of autonomous trucks from an\neconomic perspective.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 10:31:51 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Tao", "Xin", ""], ["M\u00e5rtensson", "Jonas", ""], ["Warnquist", "H\u00e5kan", ""], ["Pernest\u00e5l", "Anna", ""]]}, {"id": "2106.01883", "submitter": "Xue Yang", "authors": "Xue Yang, Xiaojiang Yang, Jirui Yang, Qi Ming, Wentao Wang, Qi Tian,\n  Junchi Yan", "title": "Learning High-Precision Bounding Box for Rotated Object Detection via\n  Kullback-Leibler Divergence", "comments": "15 pages, 5 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing rotated object detectors are mostly inherited from the horizontal\ndetection paradigm, as the latter has evolved into a well-developed area.\nHowever, these detectors are difficult to perform prominently in high-precision\ndetection due to the limitation of current regression loss design, especially\nfor objects with large aspect ratios. Taking the perspective that horizontal\ndetection is a special case for rotated object detection, in this paper, we are\nmotivated to change the design of rotation regression loss from induction\nparadigm to deduction methodology, in terms of the relation between rotation\nand horizontal detection. We show that one essential challenge is how to\nmodulate the coupled parameters in the rotation regression loss, as such the\nestimated parameters can influence to each other during the dynamic joint\noptimization, in an adaptive and synergetic way. Specifically, we first convert\nthe rotated bounding box into a 2-D Gaussian distribution, and then calculate\nthe Kullback-Leibler Divergence (KLD) between the Gaussian distributions as the\nregression loss. By analyzing the gradient of each parameter, we show that KLD\n(and its derivatives) can dynamically adjust the parameter gradients according\nto the characteristics of the object. It will adjust the importance (gradient\nweight) of the angle parameter according to the aspect ratio. This mechanism\ncan be vital for high-precision detection as a slight angle error would cause a\nserious accuracy drop for large aspect ratios objects. More importantly, we\nhave proved that KLD is scale invariant. We further show that the KLD loss can\nbe degenerated into the popular $l_{n}$-norm loss for horizontal detection.\nExperimental results on seven datasets using different detectors show its\nconsistent superiority, and codes are available at\nhttps://github.com/yangxue0827/RotationDetection.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 14:29:19 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 09:16:58 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Yang", "Xue", ""], ["Yang", "Xiaojiang", ""], ["Yang", "Jirui", ""], ["Ming", "Qi", ""], ["Wang", "Wentao", ""], ["Tian", "Qi", ""], ["Yan", "Junchi", ""]]}, {"id": "2106.01920", "submitter": "Kunal Bhardwaj", "authors": "Kunal Bhardwaj", "title": "Convolutional Neural Network(CNN/ConvNet) in Stock Price Movement\n  Prediction", "comments": "19 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With technological advancements and the exponential growth of data, we have\nbeen unfolding different capabilities of neural networks in different sectors.\nIn this paper, I have tried to use a specific type of Neural Network known as\nConvolutional Neural Network(CNN/ConvNet) in the stock market. In other words,\nI have tried to construct and train a convolutional neural network on past\nstock prices data and then tried to predict the movement of stock price i.e.\nwhether the stock price would rise or fall, in the coming time.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 15:14:46 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Bhardwaj", "Kunal", ""]]}, {"id": "2106.01947", "submitter": "Lirong Xia", "authors": "Lirong Xia", "title": "The Smoothed Satisfaction of Voting Axioms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.TH cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the work towards a comprehensive picture of the smoothed\nsatisfaction of voting axioms, to provide a finer and more realistic foundation\nfor comparing voting rules. We adopt the smoothed social choice framework,\nwhere an adversary chooses arbitrarily correlated \"ground truth\" preferences\nfor the agents, on top of which random noises are added. We focus on\ncharacterizing the smoothed satisfaction of two well-studied voting axioms:\nCondorcet criterion and participation. We prove that for any fixed number of\nalternatives, when the number of voters $n$ is sufficiently large, the smoothed\nsatisfaction of the Condorcet criterion under a wide range of voting rules is\n$1$, $1-\\exp(-\\Theta(n))$, $\\Theta(n^{-0.5})$, $ \\exp(-\\Theta(n))$, or being\n$\\Theta(1)$ and $1-\\Theta(1)$ at the same time; and the smoothed satisfaction\nof participation is $1-\\Theta(n^{-0.5})$. Our results address open questions by\nBerg and Lepelley in 1994 for these rules, and also confirm the following\nhigh-level message: the Condorcet criterion is a bigger concern than\nparticipation under realistic models.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 15:55:11 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Xia", "Lirong", ""]]}, {"id": "2106.01950", "submitter": "Ulme Wennberg", "authors": "Ulme Wennberg, Gustav Eje Henter", "title": "The Case for Translation-Invariant Self-Attention in Transformer-Based\n  Language Models", "comments": "11 pages, 8 figures, Accepted to ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mechanisms for encoding positional information are central for\ntransformer-based language models. In this paper, we analyze the position\nembeddings of existing language models, finding strong evidence of translation\ninvariance, both for the embeddings themselves and for their effect on\nself-attention. The degree of translation invariance increases during training\nand correlates positively with model performance. Our findings lead us to\npropose translation-invariant self-attention (TISA), which accounts for the\nrelative position between tokens in an interpretable fashion without needing\nconventional position embeddings. Our proposal has several theoretical\nadvantages over existing position-representation approaches. Experiments show\nthat it improves on regular ALBERT on GLUE tasks, while only adding orders of\nmagnitude less positional parameters.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 15:56:26 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Wennberg", "Ulme", ""], ["Henter", "Gustav Eje", ""]]}, {"id": "2106.01958", "submitter": "Abhishek Ramdas Nair", "authors": "Abhishek Ramdas Nair, Pallab Kumar Nath, Shantanu Chakrabartty, Chetan\n  Singh Thakur", "title": "Multiplierless MP-Kernel Machine For Energy-efficient Edge Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.AR cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel framework for designing multiplierless kernel machines\nthat can be used on resource-constrained platforms like intelligent edge\ndevices. The framework uses a piecewise linear (PWL) approximation based on a\nmargin propagation (MP) technique and uses only addition/subtraction, shift,\ncomparison, and register underflow/overflow operations. We propose a\nhardware-friendly MP-based inference and online training algorithm that has\nbeen optimized for a Field Programmable Gate Array (FPGA) platform. Our FPGA\nimplementation eliminates the need for DSP units and reduces the number of\nLUTs. By reusing the same hardware for inference and training, we show that the\nplatform can overcome classification errors and local minima artifacts that\nresult from the MP approximation. Using the FPGA platform, we also show that\nthe proposed multiplierless MP-kernel machine demonstrates superior performance\nin terms of power, performance, and area compared to other comparable\nimplementations.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 16:06:08 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Nair", "Abhishek Ramdas", ""], ["Nath", "Pallab Kumar", ""], ["Chakrabartty", "Shantanu", ""], ["Thakur", "Chetan Singh", ""]]}, {"id": "2106.01960", "submitter": "Gaurav Sahu", "authors": "Olga Vechtomova, Gaurav Sahu, Dhruv Kumar", "title": "LyricJam: A system for generating lyrics for live instrumental music", "comments": "Accepted to International Conference on Computational Creativity\n  (ICCC) 2021 [Oral]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.CL cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe a real-time system that receives a live audio stream from a jam\nsession and generates lyric lines that are congruent with the live music being\nplayed. Two novel approaches are proposed to align the learned latent spaces of\naudio and text representations that allow the system to generate novel lyric\nlines matching live instrumental music. One approach is based on adversarial\nalignment of latent representations of audio and lyrics, while the other\napproach learns to transfer the topology from the music latent space to the\nlyric latent space. A user study with music artists using the system showed\nthat the system was useful not only in lyric composition, but also encouraged\nthe artists to improvise and find new musical expressions. Another user study\ndemonstrated that users preferred the lines generated using the proposed\nmethods to the lines generated by a baseline model.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 16:06:46 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Vechtomova", "Olga", ""], ["Sahu", "Gaurav", ""], ["Kumar", "Dhruv", ""]]}, {"id": "2106.01977", "submitter": "Alexandros Nikou PhD", "authors": "Alexandros Nikou, Anusha Mujumdar, Marin Orlic, Aneta Vulgarakis\n  Feljan", "title": "Safe RAN control: A Symbolic Reinforcement Learning Approach", "comments": "Submitted to IEEE Global Communications Conference (GLOBECOM) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a Symbolic Reinforcement Learning (SRL) based\narchitecture for safety control of Radio Access Network (RAN) applications. In\nparticular, we provide a purely automated procedure in which a user can specify\nhigh-level logical safety specifications for a given cellular network topology\nin order for the latter to execute optimal safe performance which is measured\nthrough certain Key Performance Indicators (KPIs). The network consists of a\nset of fixed Base Stations (BS) which are equipped with antennas, which one can\ncontrol by adjusting their vertical tilt angle. The aforementioned process is\ncalled Remote Electrical Tilt (RET) optimization. Recent research has focused\non performing this RET optimization by employing Reinforcement Learning (RL)\nstrategies due to the fact that they have self-learning capabilities to adapt\nin uncertain environments. The term safety refers to particular constraints\nbounds of the network KPIs in order to guarantee that when the algorithms are\ndeployed in a live network, the performance is maintained. In our proposed\narchitecture the safety is ensured through model-checking techniques over\ncombined discrete system models (automata) that are abstracted through the\nlearning process. We introduce a user interface (UI) developed to help a user\nset intent specifications to the system, and inspect the difference in agent\nproposed actions, and those that are allowed and blocked according to the\nsafety specification.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 16:45:40 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Nikou", "Alexandros", ""], ["Mujumdar", "Anusha", ""], ["Orlic", "Marin", ""], ["Feljan", "Aneta Vulgarakis", ""]]}, {"id": "2106.01978", "submitter": "Dou Hu", "authors": "Dou Hu, Lingwei Wei, Xiaoyong Huai", "title": "DialogueCRN: Contextual Reasoning Networks for Emotion Recognition in\n  Conversations", "comments": "11 pages, accepted by ACL-IJCNLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion Recognition in Conversations (ERC) has gained increasing attention\nfor developing empathetic machines. Recently, many approaches have been devoted\nto perceiving conversational context by deep learning models. However, these\napproaches are insufficient in understanding the context due to lacking the\nability to extract and integrate emotional clues. In this work, we propose\nnovel Contextual Reasoning Networks (DialogueCRN) to fully understand the\nconversational context from a cognitive perspective. Inspired by the Cognitive\nTheory of Emotion, we design multi-turn reasoning modules to extract and\nintegrate emotional clues. The reasoning module iteratively performs an\nintuitive retrieving process and a conscious reasoning process, which imitates\nhuman unique cognitive thinking. Extensive experiments on three public\nbenchmark datasets demonstrate the effectiveness and superiority of the\nproposed model.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 16:47:38 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 05:28:04 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Hu", "Dou", ""], ["Wei", "Lingwei", ""], ["Huai", "Xiaoyong", ""]]}, {"id": "2106.01998", "submitter": "Akbar Siami Namin", "authors": "Faranak Abri, Luis Felipe Gutierrez, Chaitra T. Kulkarni, Akbar Siami\n  Namin, Keith S. Jones", "title": "Toward Explainable Users: Using NLP to Enable AI to Understand Users'\n  Perceptions of Cyber Attacks", "comments": "20 pages, 3 figures, COMPSAC'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To understand how end-users conceptualize consequences of cyber security\nattacks, we performed a card sorting study, a well-known technique in Cognitive\nSciences, where participants were free to group the given consequences of\nchosen cyber attacks into as many categories as they wished using rationales\nthey see fit. The results of the open card sorting study showed a large amount\nof inter-participant variation making the research team wonder how the\nconsequences of security attacks were comprehended by the participants. As an\nexploration of whether it is possible to explain user's mental model and\nbehavior through Artificial Intelligence (AI) techniques, the research team\ncompared the card sorting data with the outputs of a number of Natural Language\nProcessing (NLP) techniques with the goal of understanding how participants\nperceived and interpreted the consequences of cyber attacks written in natural\nlanguages. The results of the NLP-based exploration methods revealed an\ninteresting observation implying that participants had mostly employed checking\nindividual keywords in each sentence to group cyber attack consequences\ntogether and less considered the semantics behind the description of\nconsequences of cyber attacks. The results reported in this paper are seemingly\nuseful and important for cyber attacks comprehension from user's perspectives.\nTo the best of our knowledge, this paper is the first introducing the use of AI\ntechniques in explaining and modeling users' behavior and their perceptions\nabout a context. The novel idea introduced here is about explaining users using\nAI.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 17:17:16 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Abri", "Faranak", ""], ["Gutierrez", "Luis Felipe", ""], ["Kulkarni", "Chaitra T.", ""], ["Namin", "Akbar Siami", ""], ["Jones", "Keith S.", ""]]}, {"id": "2106.02003", "submitter": "Kaiwen Jiang", "authors": "Kaiwen Jiang, Stephanie Stacy, Chuyu Wei, Adelpha Chan, Federico\n  Rossano, Yixin Zhu, Tao Gao", "title": "Individual vs. Joint Perception: a Pragmatic Model of Pointing as\n  Communicative Smithian Helping", "comments": "7 pages, 3 figures. Accepted to CogSci 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The simple gesture of pointing can greatly augment ones ability to comprehend\nstates of the world based on observations. It triggers additional inferences\nrelevant to ones task at hand. We model an agents update to its belief of the\nworld based on individual observations using a partially observable Markov\ndecision process (POMDP), a mainstream artificial intelligence (AI) model of\nhow to act rationally according to beliefs formed through observation. On top\nof that, we model pointing as a communicative act between agents who have a\nmutual understanding that the pointed observation must be relevant and\ninterpretable. Our model measures relevance by defining a Smithian Value of\nInformation (SVI) as the utility improvement of the POMDP agent before and\nafter receiving the pointing. We model that agents calculate SVI by using the\ncognitive theory of Smithian helping as a principle of coordinating separate\nbeliefs for action prediction and action evaluation. We then import SVI into\nrational speech act (RSA) as the utility function of an utterance. These lead\nus to a pragmatic model of pointing allowing for contextually flexible\ninterpretations. We demonstrate the power of our Smithian pointing model by\nextending the Wumpus world, a classic AI task where a hunter hunts a monster\nwith only partial observability of the world. We add another agent as a guide\nwho can only help by marking an observation already perceived by the hunter\nwith a pointing or not, without providing new observations or offering any\ninstrumental help. Our results show that this severely limited and overloaded\ncommunication nevertheless significantly improves the hunters performance. The\nadvantage of pointing is indeed due to a computation of relevance based on\nSmithian helping, as it disappears completely when the task is too difficult or\ntoo easy for the guide to help.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 17:21:23 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Jiang", "Kaiwen", ""], ["Stacy", "Stephanie", ""], ["Wei", "Chuyu", ""], ["Chan", "Adelpha", ""], ["Rossano", "Federico", ""], ["Zhu", "Yixin", ""], ["Gao", "Tao", ""]]}, {"id": "2106.02012", "submitter": "Akbar Siami Namin", "authors": "Shuvalaxmi Dass, Prerit Datta, Akbar Siami Namin", "title": "Attack Prediction using Hidden Markov Model", "comments": "20 pages, 4 figures, COMPSAC'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is important to predict any adversarial attacks and their types to enable\neffective defense systems. Often it is hard to label such activities as\nmalicious ones without adequate analytical reasoning. We propose the use of\nHidden Markov Model (HMM) to predict the family of related attacks. Our\nproposed model is based on the observations often agglomerated in the form of\nlog files and from the target or the victim's perspective. We have built an\nHMM-based prediction model and implemented our proposed approach using Viterbi\nalgorithm, which generates a sequence of states corresponding to stages of a\nparticular attack. As a proof of concept and also to demonstrate the\nperformance of the model, we have conducted a case study on predicting a family\nof attacks called Action Spoofing.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 17:32:06 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Dass", "Shuvalaxmi", ""], ["Datta", "Prerit", ""], ["Namin", "Akbar Siami", ""]]}, {"id": "2106.02034", "submitter": "Yongming Rao", "authors": "Yongming Rao, Wenliang Zhao, Benlin Liu, Jiwen Lu, Jie Zhou, Cho-Jui\n  Hsieh", "title": "DynamicViT: Efficient Vision Transformers with Dynamic Token\n  Sparsification", "comments": "Project page: https://dynamicvit.ivg-research.xyz/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention is sparse in vision transformers. We observe the final prediction\nin vision transformers is only based on a subset of most informative tokens,\nwhich is sufficient for accurate image recognition. Based on this observation,\nwe propose a dynamic token sparsification framework to prune redundant tokens\nprogressively and dynamically based on the input. Specifically, we devise a\nlightweight prediction module to estimate the importance score of each token\ngiven the current features. The module is added to different layers to prune\nredundant tokens hierarchically. To optimize the prediction module in an\nend-to-end manner, we propose an attention masking strategy to differentiably\nprune a token by blocking its interactions with other tokens. Benefiting from\nthe nature of self-attention, the unstructured sparse tokens are still hardware\nfriendly, which makes our framework easy to achieve actual speed-up. By\nhierarchically pruning 66% of the input tokens, our method greatly reduces\n31%~37% FLOPs and improves the throughput by over 40% while the drop of\naccuracy is within 0.5% for various vision transformers. Equipped with the\ndynamic token sparsification framework, DynamicViT models can achieve very\ncompetitive complexity/accuracy trade-offs compared to state-of-the-art CNNs\nand vision transformers on ImageNet. Code is available at\nhttps://github.com/raoyongming/DynamicViT\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 17:57:41 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Rao", "Yongming", ""], ["Zhao", "Wenliang", ""], ["Liu", "Benlin", ""], ["Lu", "Jiwen", ""], ["Zhou", "Jie", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "2106.02036", "submitter": "Rohit Girdhar", "authors": "Rohit Girdhar and Kristen Grauman", "title": "Anticipative Video Transformer", "comments": "Ranked #1 on CVPR'21 EPIC-Kitchens Action Anticipation challenge\n  leaderboard. Project page: http://facebookresearch.github.io/AVT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Anticipative Video Transformer (AVT), an end-to-end\nattention-based video modeling architecture that attends to the previously\nobserved video in order to anticipate future actions. We train the model\njointly to predict the next action in a video sequence, while also learning\nframe feature encoders that are predictive of successive future frames'\nfeatures. Compared to existing temporal aggregation strategies, AVT has the\nadvantage of both maintaining the sequential progression of observed actions\nwhile still capturing long-range dependencies--both critical for the\nanticipation task. Through extensive experiments, we show that AVT obtains the\nbest reported performance on four popular action anticipation benchmarks:\nEpicKitchens-55, EpicKitchens-100, EGTEA Gaze+, and 50-Salads, including\noutperforming all submissions to the EpicKitchens-100 CVPR'21 challenge.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 17:57:55 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Girdhar", "Rohit", ""], ["Grauman", "Kristen", ""]]}, {"id": "2106.02039", "submitter": "Michael Janner", "authors": "Michael Janner, Qiyang Li, Sergey Levine", "title": "Reinforcement Learning as One Big Sequence Modeling Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is typically concerned with estimating\nsingle-step policies or single-step models, leveraging the Markov property to\nfactorize the problem in time. However, we can also view RL as a sequence\nmodeling problem, with the goal being to predict a sequence of actions that\nleads to a sequence of high rewards. Viewed in this way, it is tempting to\nconsider whether powerful, high-capacity sequence prediction models that work\nwell in other domains, such as natural-language processing, can also provide\nsimple and effective solutions to the RL problem. To this end, we explore how\nRL can be reframed as \"one big sequence modeling\" problem, using\nstate-of-the-art Transformer architectures to model distributions over\nsequences of states, actions, and rewards. Addressing RL as a sequence modeling\nproblem significantly simplifies a range of design decisions: we no longer\nrequire separate behavior policy constraints, as is common in prior work on\noffline model-free RL, and we no longer require ensembles or other epistemic\nuncertainty estimators, as is common in prior work on model-based RL. All of\nthese roles are filled by the same Transformer sequence model. In our\nexperiments, we demonstrate the flexibility of this approach across\nlong-horizon dynamics prediction, imitation learning, goal-conditioned RL, and\noffline RL.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 17:58:51 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 06:04:33 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Janner", "Michael", ""], ["Li", "Qiyang", ""], ["Levine", "Sergey", ""]]}, {"id": "2106.02040", "submitter": "Huazhe Xu", "authors": "Huazhe Xu, Yuping Luo, Shaoxiong Wang, Trevor Darrell, Roberto\n  Calandra", "title": "Towards Learning to Play Piano with Dexterous Hands and Touch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The virtuoso plays the piano with passion, poetry and extraordinary technical\nability. As Liszt said (a virtuoso)must call up scent and blossom, and breathe\nthe breath of life. The strongest robots that can play a piano are based on a\ncombination of specialized robot hands/piano and hardcoded planning algorithms.\nIn contrast to that, in this paper, we demonstrate how an agent can learn\ndirectly from machine-readable music score to play the piano with dexterous\nhands on a simulated piano using reinforcement learning (RL) from scratch. We\ndemonstrate the RL agents can not only find the correct key position but also\ndeal with various rhythmic, volume and fingering, requirements. We achieve this\nby using a touch-augmented reward and a novel curriculum of tasks. We conclude\nby carefully studying the important aspects to enable such learning algorithms\nand that can potentially shed light on future research in this direction.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 17:59:31 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 23:09:52 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Xu", "Huazhe", ""], ["Luo", "Yuping", ""], ["Wang", "Shaoxiong", ""], ["Darrell", "Trevor", ""], ["Calandra", "Roberto", ""]]}, {"id": "2106.02067", "submitter": "Daniela Mihai", "authors": "Daniela Mihai, Jonathon Hare", "title": "Learning to Draw: Emergent Communication through Sketching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evidence that visual communication preceded written language and provided a\nbasis for it goes back to prehistory, in forms such as cave and rock paintings\ndepicting traces of our distant ancestors. Emergent communication research has\nsought to explore how agents can learn to communicate in order to\ncollaboratively solve tasks. Existing research has focused on language, with a\nlearned communication channel transmitting sequences of discrete tokens between\nthe agents. In this work, we explore a visual communication channel between\nagents that are allowed to draw with simple strokes. Our agents are\nparameterised by deep neural networks, and the drawing procedure is\ndifferentiable, allowing for end-to-end training. In the framework of a\nreferential communication game, we demonstrate that agents can not only\nsuccessfully learn to communicate by drawing, but with appropriate inductive\nbiases, can do so in a fashion that humans can interpret. We hope to encourage\nfuture research to consider visual communication as a more flexible and\ndirectly interpretable alternative of training collaborative agents.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 18:17:55 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Mihai", "Daniela", ""], ["Hare", "Jonathon", ""]]}, {"id": "2106.02073", "submitter": "Xiaoyan Han", "authors": "X.Y. Han, Vardan Papyan, David L. Donoho", "title": "Neural Collapse Under MSE Loss: Proximity to and Dynamics on the Central\n  Path", "comments": "Appendix contains [Section A] empirical experiments, [Sections B-D]\n  discussions and proofs of theoretical results, and [Section E] survey of\n  related works examining Neural Collapse", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.DG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recent work [Papyan, Han, and Donoho, 2020] discovered a phenomenon called\nNeural Collapse (NC) that occurs pervasively in today's deep net training\nparadigm of driving cross-entropy loss towards zero. In this phenomenon, the\nlast-layer features collapse to their class-means, both the classifiers and\nclass-means collapse to the same Simplex Equiangular Tight Frame (ETF), and the\nbehavior of the last-layer classifier converges to that of the\nnearest-class-mean decision rule. Since then, follow-ups-such as Mixon et al.\n[2020] and Poggio and Liao [2020a,b]-formally analyzed this inductive bias by\nreplacing the hard-to-study cross-entropy by the more tractable mean squared\nerror (MSE) loss. But, these works stopped short of demonstrating the empirical\nreality of MSE-NC on benchmark datasets and canonical networks-as had been done\nin Papyan, Han, and Donoho [2020] for the cross-entropy loss. In this work, we\nestablish the empirical reality of MSE-NC by reporting experimental\nobservations for three prototypical networks and five canonical datasets with\ncode for reproducing NC. Following this, we develop three main contributions\ninspired by MSE-NC. Firstly, we show a new theoretical decomposition of the MSE\nloss into (A) a term assuming the last-layer classifier is exactly the\nleast-squares or Webb and Lowe [1990] classifier and (B) a term capturing the\ndeviation from this least-squares classifier. Secondly, we exhibit experiments\non canonical datasets and networks demonstrating that, during training,\nterm-(B) is negligible. This motivates a new theoretical construct: the central\npath, where the linear classifier stays MSE-optimal-for the given feature\nactivations-throughout the dynamics. Finally, through our study of continually\nrenormalized gradient flow along the central path, we produce closed-form\ndynamics that predict full Neural Collapse in an unconstrained features model.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 18:31:41 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Han", "X. Y.", ""], ["Papyan", "Vardan", ""], ["Donoho", "David L.", ""]]}, {"id": "2106.02097", "submitter": "Mingde Zhao", "authors": "Mingde Zhao, Zhen Liu, Sitao Luan, Shuyuan Zhang, Doina Precup, Yoshua\n  Bengio", "title": "A Consciousness-Inspired Planning Agent for Model-Based Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present an end-to-end, model-based deep reinforcement learning agent which\ndynamically attends to relevant parts of its state, in order to plan and to\ngeneralize better out-of-distribution. The agent's architecture uses a set\nrepresentation and a bottleneck mechanism, forcing the number of entities to\nwhich the agent attends at each planning step to be small. In experiments with\ncustomized MiniGrid environments with different dynamics, we observe that the\ndesign allows agents to learn to plan effectively, by attending to the relevant\nobjects, leading to better out-of-distribution generalization.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 19:35:19 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Zhao", "Mingde", ""], ["Liu", "Zhen", ""], ["Luan", "Sitao", ""], ["Zhang", "Shuyuan", ""], ["Precup", "Doina", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2106.02114", "submitter": "Matthew Ferland", "authors": "Kyle Burke, Matthew Ferland, Shanghua Teng", "title": "Winning the War by (Strategically) Losing Battles: Settling the\n  Complexity of Grundy-Values in Undirected Geography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We settle two long-standing complexity-theoretical questions-open since 1981\nand 1993-in combinatorial game theory (CGT).\n  We prove that the Grundy value (a.k.a. nim-value, or nimber) of Undirected\nGeography is PSPACE-complete to compute. This exhibits a stark contrast with a\nresult from 1993 that Undirected Geography is polynomial-time solvable. By\ndistilling to a simple reduction, our proof further establishes a dichotomy\ntheorem, providing a \"phase transition to intractability\" in Grundy-value\ncomputation, sharply characterized by a maximum degree of four: The Grundy\nvalue of Undirected Geography over any degree-three graph is polynomial-time\ncomputable, but over degree-four graphs-even when planar and bipartite-is\nPSPACE-hard. Additionally, we show, for the first time, how to construct\nUndirected Geography instances with Grundy value $\\ast n$ and size polynomial\nin n.\n  We strengthen a result from 1981 showing that sums of tractable partisan\ngames are PSPACE-complete in two fundamental ways. First, since Undirected\nGeography is an impartial ruleset, we extend the hardness of sums to impartial\ngames, a strict subset of partisan. Second, the 1981 construction is not built\nfrom a natural ruleset, instead using a long sum of tailored short-depth game\npositions. We use the sum of two Undirected Geography positions to create our\nhard instances. Our result also has computational implications to\nSprague-Grundy Theory (1930s) which shows that the Grundy value of the\ndisjunctive sum of any two impartial games can be computed-in polynomial\ntime-from their Grundy values. In contrast, we prove that assuming PSPACE\n$\\neq$ P, there is no general polynomial-time method to summarize two\npolynomial-time solvable impartial games to efficiently solve their disjunctive\nsum.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 20:13:18 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Burke", "Kyle", ""], ["Ferland", "Matthew", ""], ["Teng", "Shanghua", ""]]}, {"id": "2106.02164", "submitter": "Stephanie Stacy", "authors": "Stephanie Stacy, Chenfei Li, Minglu Zhao, Yiling Yun, Qingyi Zhao, Max\n  Kleiman-Weiner and Tao Gao", "title": "Modeling Communication to Coordinate Perspectives in Cooperation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication is highly overloaded. Despite this, even young children are\ngood at leveraging context to understand ambiguous signals. We propose a\ncomputational account of overloaded signaling from a shared agency perspective\nwhich we call the Imagined We for Communication. Under this framework,\ncommunication helps cooperators coordinate their perspectives, allowing them to\nact together to achieve shared goals. We assume agents are rational\ncooperators, which puts constraints on how signals can be sent and interpreted.\nWe implement this model in a set of simulations demonstrating this model's\nsuccess under increasing ambiguity as well as increasing layers of reasoning.\nOur model is capable of improving performance with deeper recursive reasoning;\nhowever, it outperforms comparison baselines at even the shallowest level,\nhighlighting how shared knowledge and cooperative logic can do much of the\nheavy-lifting in language.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 22:37:20 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Stacy", "Stephanie", ""], ["Li", "Chenfei", ""], ["Zhao", "Minglu", ""], ["Yun", "Yiling", ""], ["Zhao", "Qingyi", ""], ["Kleiman-Weiner", "Max", ""], ["Gao", "Tao", ""]]}, {"id": "2106.02182", "submitter": "Chenyu You", "authors": "Nuo Chen, Chenyu You, Yuexian Zou", "title": "Self-supervised Dialogue Learning for Spoken Conversational Question\n  Answering", "comments": "To Appear Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spoken conversational question answering (SCQA), the answer to the\ncorresponding question is generated by retrieving and then analyzing a fixed\nspoken document, including multi-part conversations. Most SCQA systems have\nconsidered only retrieving information from ordered utterances. However, the\nsequential order of dialogue is important to build a robust spoken\nconversational question answering system, and the changes of utterances order\nmay severely result in low-quality and incoherent corpora. To this end, we\nintroduce a self-supervised learning approach, including incoherence\ndiscrimination, insertion detection, and question prediction, to explicitly\ncapture the coreference resolution and dialogue coherence among spoken\ndocuments. Specifically, we design a joint learning framework where the\nauxiliary self-supervised tasks can enable the pre-trained SCQA systems towards\nmore coherent and meaningful spoken dialogue learning. We also utilize the\nproposed self-supervised learning tasks to capture intra-sentence coherence.\nExperimental results demonstrate that our proposed method provides more\ncoherent, meaningful, and appropriate responses, yielding superior performance\ngains compared to the original pre-trained language models. Our method achieves\nstate-of-the-art results on the Spoken-CoQA dataset.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 00:09:38 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 19:53:17 GMT"}, {"version": "v3", "created": "Thu, 24 Jun 2021 16:31:29 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Chen", "Nuo", ""], ["You", "Chenyu", ""], ["Zou", "Yuexian", ""]]}, {"id": "2106.02183", "submitter": "Noura Al Moubayed", "authors": "Elizabeth Excell and Noura Al Moubayed", "title": "Towards Equal Gender Representation in the Annotations of Toxic Language\n  Detection", "comments": "Paper is accepted at GeBNLP2021 workshop at ACL-IJCNLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Classifiers tend to propagate biases present in the data on which they are\ntrained. Hence, it is important to understand how the demographic identities of\nthe annotators of comments affect the fairness of the resulting model. In this\npaper, we focus on the differences in the ways men and women annotate comments\nfor toxicity, investigating how these differences result in models that amplify\nthe opinions of male annotators. We find that the BERT model as-sociates toxic\ncomments containing offensive words with male annotators, causing the model to\npredict 67.7% of toxic comments as having been annotated by men. We show that\nthis disparity between gender predictions can be mitigated by removing\noffensive words and highly toxic comments from the training data. We then apply\nthe learned associations between gender and language to toxic language\nclassifiers, finding that models trained exclusively on female-annotated data\nperform 1.8% better than those trained solely on male-annotated data and that\ntraining models on data after removing all offensive words reduces bias in the\nmodel by 55.5% while increasing the sensitivity by 0.4%.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 00:12:38 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Excell", "Elizabeth", ""], ["Moubayed", "Noura Al", ""]]}, {"id": "2106.02190", "submitter": "Yulun Wu", "authors": "Yulun Wu, Nicholas Choma, Andrew Chen, Mikaela Cashman, \\'Erica T.\n  Prates, Manesh Shah, Ver\\'onica G. Melesse Vergara, Austin Clyde, Thomas S.\n  Brettin, Wibe A. de Jong, Neeraj Kumar, Martha S. Head, Rick L. Stevens,\n  Peter Nugent, Daniel A. Jacobson, James B. Brown", "title": "Spatial Graph Attention and Curiosity-driven Policy for Antiviral Drug\n  Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We developed Distilled Graph Attention Policy Networks (DGAPNs), a\ncuriosity-driven reinforcement learning model to generate novel\ngraph-structured chemical representations that optimize user-defined objectives\nby efficiently navigating a physically constrained domain. The framework is\nexamined on the task of generating molecules that are designed to bind,\nnoncovalently, to functional sites of SARS-CoV-2 proteins. We present a spatial\nGraph Attention Network (sGAT) that leverages self-attention over both node and\nedge attributes as well as encoding spatial structure -- this capability is of\nconsiderable interest in areas such as molecular and synthetic biology and drug\ndiscovery. An attentional policy network is then introduced to learn decision\nrules for a dynamic, fragment-based chemical environment, and state-of-the-art\npolicy gradient techniques are employed to train the network with enhanced\nstability. Exploration is efficiently encouraged by incorporating innovation\nreward bonuses learned and proposed by random network distillation. In\nexperiments, our framework achieved outstanding results compared to\nstate-of-the-art algorithms, while increasing the diversity of proposed\nmolecules and reducing the complexity of paths to chemical synthesis.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 00:36:47 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 09:43:59 GMT"}, {"version": "v3", "created": "Sun, 20 Jun 2021 02:29:27 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Wu", "Yulun", ""], ["Choma", "Nicholas", ""], ["Chen", "Andrew", ""], ["Cashman", "Mikaela", ""], ["Prates", "\u00c9rica T.", ""], ["Shah", "Manesh", ""], ["Vergara", "Ver\u00f3nica G. Melesse", ""], ["Clyde", "Austin", ""], ["Brettin", "Thomas S.", ""], ["de Jong", "Wibe A.", ""], ["Kumar", "Neeraj", ""], ["Head", "Martha S.", ""], ["Stevens", "Rick L.", ""], ["Nugent", "Peter", ""], ["Jacobson", "Daniel A.", ""], ["Brown", "James B.", ""]]}, {"id": "2106.02193", "submitter": "Bogdan Mazoure", "authors": "Bogdan Mazoure, Ahmed M. Ahmed, Patrick MacAlpine, R Devon Hjelm,\n  Andrey Kolobov", "title": "Cross-Trajectory Representation Learning for Zero-Shot Generalization in\n  RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A highly desirable property of a reinforcement learning (RL) agent -- and a\nmajor difficulty for deep RL approaches -- is the ability to generalize\npolicies learned on a few tasks over a high-dimensional observation space to\nsimilar tasks not seen during training. Many promising approaches to this\nchallenge consider RL as a process of training two functions simultaneously: a\ncomplex nonlinear encoder that maps high-dimensional observations to a latent\nrepresentation space, and a simple linear policy over this space. We posit that\na superior encoder for zero-shot generalization in RL can be trained by using\nsolely an auxiliary SSL objective if the training process encourages the\nencoder to map behaviorally similar observations to similar representations, as\nreward-based signal can cause overfitting in the encoder (Raileanu et al.,\n2021). We propose Cross-Trajectory Representation Learning (CTRL), a method\nthat runs within an RL agent and conditions its encoder to recognize behavioral\nsimilarity in observations by applying a novel SSL objective to pairs of\ntrajectories from the agent's policies. CTRL can be viewed as having the same\neffect as inducing a pseudo-bisimulation metric but, crucially, avoids the use\nof rewards and associated overfitting risks. Our experiments ablate various\ncomponents of CTRL and demonstrate that in combination with PPO it achieves\nbetter generalization performance on the challenging Procgen benchmark suite\n(Cobbe et al., 2020).\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 00:43:10 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Mazoure", "Bogdan", ""], ["Ahmed", "Ahmed M.", ""], ["MacAlpine", "Patrick", ""], ["Hjelm", "R Devon", ""], ["Kolobov", "Andrey", ""]]}, {"id": "2106.02204", "submitter": "Jonathan Balloch", "authors": "Xiangyu Peng, Jonathan C. Balloch, Mark O. Riedl", "title": "Detecting and Adapting to Novelty in Games", "comments": "10 pages, 5 figures, Accepted to the AAAI21 Workshop on on\n  Reinforcement Learning in Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Open-world novelty occurs when the rules of an environment can change\nabruptly, such as when a game player encounters \"house rules\". To address\nopen-world novelty, game playing agents must be able to detect when novelty is\ninjected, and to quickly adapt to the new rules. We propose a model-based\nreinforcement learning approach where game state and rules are represented as\nknowledge graphs. The knowledge graph representation of the state and rules\nallows novelty to be detected as changes in the knowledge graph, assists with\nthe training of deep reinforcement learners, and enables imagination-based\nre-training where the agent uses the knowledge graph to perform look-ahead.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 01:41:02 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Peng", "Xiangyu", ""], ["Balloch", "Jonathan C.", ""], ["Riedl", "Mark O.", ""]]}, {"id": "2106.02205", "submitter": "Ze-Feng Gao", "authors": "Peiyu Liu, Ze-Feng Gao, Wayne Xin Zhao, Z.Y. Xie, Zhong-Yi Lu, Ji-Rong\n  Wen", "title": "Enabling Lightweight Fine-tuning for Pre-trained Language Model\n  Compression based on Matrix Product Operators", "comments": "Accepted by ACL 2021 main conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI quant-ph", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper presents a novel pre-trained language models (PLM) compression\napproach based on the matrix product operator (short as MPO) from quantum\nmany-body physics. It can decompose an original matrix into central tensors\n(containing the core information) and auxiliary tensors (with only a small\nproportion of parameters). With the decomposed MPO structure, we propose a\nnovel fine-tuning strategy by only updating the parameters from the auxiliary\ntensors, and design an optimization algorithm for MPO-based approximation over\nstacked network architectures. Our approach can be applied to the original or\nthe compressed PLMs in a general way, which derives a lighter network and\nsignificantly reduces the parameters to be fine-tuned. Extensive experiments\nhave demonstrated the effectiveness of the proposed approach in model\ncompression, especially the reduction in finetuning parameters (91% reduction\non average).\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 01:50:15 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Liu", "Peiyu", ""], ["Gao", "Ze-Feng", ""], ["Zhao", "Wayne Xin", ""], ["Xie", "Z. Y.", ""], ["Lu", "Zhong-Yi", ""], ["Wen", "Ji-Rong", ""]]}, {"id": "2106.02206", "submitter": "Linfeng Liu", "authors": "Linfeng Liu, Michael C. Hughes, Soha Hassoun, Li-Ping Liu", "title": "Stochastic Iterative Graph Matching", "comments": "To appear in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent works leveraging Graph Neural Networks to approach graph matching\ntasks have shown promising results. Recent progress in learning discrete\ndistributions poses new opportunities for learning graph matching models. In\nthis work, we propose a new model, Stochastic Iterative Graph MAtching (SIGMA),\nto address the graph matching problem. Our model defines a distribution of\nmatchings for a graph pair so the model can explore a wide range of possible\nmatchings. We further introduce a novel multi-step matching procedure, which\nlearns how to refine a graph pair's matching results incrementally. The model\nalso includes dummy nodes so that the model does not have to find matchings for\nnodes without correspondence. We fit this model to data via scalable stochastic\noptimization. We conduct extensive experiments across synthetic graph datasets\nas well as biochemistry and computer vision applications. Across all tasks, our\nresults show that SIGMA can produce significantly improved graph matching\nresults compared to state-of-the-art models. Ablation studies verify that each\nof our components (stochastic training, iterative matching, and dummy nodes)\noffers noticeable improvement.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 02:05:35 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Liu", "Linfeng", ""], ["Hughes", "Michael C.", ""], ["Hassoun", "Soha", ""], ["Liu", "Li-Ping", ""]]}, {"id": "2106.02213", "submitter": "Alex D\\'iaz Santos", "authors": "Alex D\\'iaz, Damian Steele", "title": "Analysis of the robustness of NMF algorithms", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We examine three non-negative matrix factorization techniques; L2-norm,\nL1-norm, and L2,1-norm. Our aim is to establish the performance of these\ndifferent approaches, and their robustness in real-world applications such as\nfeature selection while managing computational complexity, sensitivity to noise\nand more. We thoroughly examine each approach from a theoretical perspective,\nand examine the performance of each using a series of experiments drawing on\nboth the ORL and YaleB datasets. We examine the Relative Reconstruction Errors\n(RRE), Average Accuracy and Normalized Mutual Information (NMI) as criteria\nunder a range of simulated noise scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 02:35:24 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["D\u00edaz", "Alex", ""], ["Steele", "Damian", ""]]}, {"id": "2106.02216", "submitter": "Jundong Li", "authors": "Xiaoying Xing, Hongfu Liu, Chen Chen, Jundong Li", "title": "Fairness-Aware Unsupervised Feature Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection is a prevalent data preprocessing paradigm for various\nlearning tasks. Due to the expensive cost of acquiring supervision information,\nunsupervised feature selection sparks great interests recently. However,\nexisting unsupervised feature selection algorithms do not have fairness\nconsiderations and suffer from a high risk of amplifying discrimination by\nselecting features that are over associated with protected attributes such as\ngender, race, and ethnicity. In this paper, we make an initial investigation of\nthe fairness-aware unsupervised feature selection problem and develop a\nprincipled framework, which leverages kernel alignment to find a subset of\nhigh-quality features that can best preserve the information in the original\nfeature space while being minimally correlated with protected attributes.\nSpecifically, different from the mainstream in-processing debiasing methods,\nour proposed framework can be regarded as a model-agnostic debiasing strategy\nthat eliminates biases and discrimination before downstream learning algorithms\nare involved. Experimental results on multiple real-world datasets demonstrate\nthat our framework achieves a good trade-off between utility maximization and\nfairness promotion.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 02:38:05 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Xing", "Xiaoying", ""], ["Liu", "Hongfu", ""], ["Chen", "Chen", ""], ["Li", "Jundong", ""]]}, {"id": "2106.02225", "submitter": "Shufeng Kong", "authors": "Shufeng Kong, Dan Guevarra, Carla P. Gomes, John M. Gregoire", "title": "Materials Representation and Transfer Learning for Multi-Property\n  Prediction", "comments": "This is accepted at the Applied Physics Reviews journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The adoption of machine learning in materials science has rapidly transformed\nmaterials property prediction. Hurdles limiting full capitalization of recent\nadvancements in machine learning include the limited development of methods to\nlearn the underlying interactions of multiple elements, as well as the\nrelationships among multiple properties, to facilitate property prediction in\nnew composition spaces. To address these issues, we introduce the Hierarchical\nCorrelation Learning for Multi-property Prediction (H-CLMP) framework that\nseamlessly integrates (i) prediction using only a material's composition, (ii)\nlearning and exploitation of correlations among target properties in\nmulti-target regression, and (iii) leveraging training data from tangential\ndomains via generative transfer learning. The model is demonstrated for\nprediction of spectral optical absorption of complex metal oxides spanning 69\n3-cation metal oxide composition spaces. H-CLMP accurately predicts non-linear\ncomposition-property relationships in composition spaces for which no training\ndata is available, which broadens the purview of machine learning to the\ndiscovery of materials with exceptional properties. This achievement results\nfrom the principled integration of latent embedding learning, property\ncorrelation learning, generative transfer learning, and attention models. The\nbest performance is obtained using H-CLMP with Transfer learning (H-CLMP(T))\nwherein a generative adversarial network is trained on computational density of\nstates data and deployed in the target domain to augment prediction of optical\nabsorption from composition. H-CLMP(T) aggregates multiple knowledge sources\nwith a framework that is well-suited for multi-target regression across the\nphysical sciences.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 03:00:34 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 05:36:36 GMT"}, {"version": "v3", "created": "Fri, 18 Jun 2021 03:03:23 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Kong", "Shufeng", ""], ["Guevarra", "Dan", ""], ["Gomes", "Carla P.", ""], ["Gregoire", "John M.", ""]]}, {"id": "2106.02227", "submitter": "Zekang Li", "authors": "Zekang Li, Jinchao Zhang, Zhengcong Fei, Yang Feng, Jie Zhou", "title": "Conversations Are Not Flat: Modeling the Dynamic Information Flow across\n  Dialogue Utterances", "comments": "ACL2021 main conference (long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, open-domain dialogue models can generate acceptable responses\naccording to the historical context based on the large-scale pre-trained\nlanguage models. However, they generally concatenate the dialogue history\ndirectly as the model input to predict the response, which we named as the flat\npattern and ignores the dynamic information flow across dialogue utterances. In\nthis work, we propose the DialoFlow model, in which we introduce a dynamic flow\nmechanism to model the context flow, and design three training objectives to\ncapture the information dynamics across dialogue utterances by addressing the\nsemantic influence brought about by each utterance in large-scale pre-training.\nExperiments on the multi-reference Reddit Dataset and DailyDialog Dataset\ndemonstrate that our DialoFlow significantly outperforms the DialoGPT on the\ndialogue generation task. Besides, we propose the Flow score, an effective\nautomatic metric for evaluating interactive human-bot conversation quality\nbased on the pre-trained DialoFlow, which presents high chatbot-level\ncorrelation ($r=0.9$) with human ratings among 11 chatbots. Code and\npre-trained models will be public.\n\\footnote{\\url{https://github.com/ictnlp/DialoFlow}}\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 03:04:06 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Li", "Zekang", ""], ["Zhang", "Jinchao", ""], ["Fei", "Zhengcong", ""], ["Feng", "Yang", ""], ["Zhou", "Jie", ""]]}, {"id": "2106.02228", "submitter": "Zekang Li", "authors": "Zekang Li, Jinchao Zhang, Zhengcong Fei, Yang Feng, Jie Zhou", "title": "Addressing Inquiries about History: An Efficient and Practical Framework\n  for Evaluating Open-domain Chatbot Consistency", "comments": "Findings of ACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A good open-domain chatbot should avoid presenting contradictory responses\nabout facts or opinions in a conversational session, known as its consistency\ncapacity. However, evaluating the consistency capacity of a chatbot is still\nchallenging. Employing human judges to interact with chatbots on purpose to\ncheck their capacities is costly and low-efficient, and difficult to get rid of\nsubjective bias. In this paper, we propose the Addressing Inquiries about\nHistory (AIH), an efficient and practical framework for the consistency\nevaluation. At the conversation stage, AIH attempts to address appropriate\ninquiries about the dialogue history to induce the chatbot to redeclare the\nhistorical facts or opinions. We carry out the conversation between chatbots,\nwhich is more efficient than the human-bot interaction and can also alleviate\nthe subjective bias. In this way, we manage to rapidly obtain a dialog session\nthat contains responses with high contradiction possibilities. At the\ncontradiction recognition stage, we can either employ human judges or a natural\nlanguage inference (NLI) model to recognize whether the answers to the\ninquiries are contradictory with history. Finally, we are able to rank chatbots\naccording to the contradiction statistics. Experiments on open-domain chatbots\nshow that our approach can efficiently and reliably assess the consistency\ncapacity of chatbots and achieve a high ranking correlation with the human\nevaluation. We release the framework and hope to help improve the consistency\ncapacity of chatbots. \\footnote{\\url{https://github.com/ictnlp/AIH}}\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 03:04:13 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Li", "Zekang", ""], ["Zhang", "Jinchao", ""], ["Fei", "Zhengcong", ""], ["Feng", "Yang", ""], ["Zhou", "Jie", ""]]}, {"id": "2106.02229", "submitter": "Xingyou Song", "authors": "Yingjie Miao, Xingyou Song, Daiyi Peng, Summer Yue, Eugene Brevdo,\n  Aleksandra Faust", "title": "RL-DARTS: Differentiable Architecture Search for Reinforcement Learning", "comments": "19 pages total, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce RL-DARTS, one of the first applications of Differentiable\nArchitecture Search (DARTS) in reinforcement learning (RL) to search for\nconvolutional cells, applied to the Procgen benchmark. We outline the initial\ndifficulties of applying neural architecture search techniques in RL, and\ndemonstrate that by simply replacing the image encoder with a DARTS supernet,\nour search method is sample-efficient, requires minimal extra compute\nresources, and is also compatible with off-policy and on-policy RL algorithms,\nneeding only minor changes in preexisting code. Surprisingly, we find that the\nsupernet can be used as an actor for inference to generate replay data in\nstandard RL training loops, and thus train end-to-end. Throughout this training\nprocess, we show that the supernet gradually learns better cells, leading to\nalternative architectures which can be highly competitive against manually\ndesigned policies, but also verify previous design choices for RL policies.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 03:08:43 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Miao", "Yingjie", ""], ["Song", "Xingyou", ""], ["Peng", "Daiyi", ""], ["Yue", "Summer", ""], ["Brevdo", "Eugene", ""], ["Faust", "Aleksandra", ""]]}, {"id": "2106.02232", "submitter": "Qianlan Ying", "authors": "Qianlan Ying, Payal Bajaj, Budhaditya Deb, Yu Yang, Wei Wang, Bojia\n  Lin, Milad Shokouhi, Xia Song, Yang Yang, and Daxin Jiang", "title": "Language Scaling for Universal Suggested Replies Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of scaling automated suggested replies for Outlook\nemail system to multiple languages. Faced with increased compute requirements\nand low resources for language expansion, we build a single universal model for\nimproving the quality and reducing run-time costs of our production system.\nHowever, restricted data movement across regional centers prevents joint\ntraining across languages. To this end, we propose a multi-task continual\nlearning framework, with auxiliary tasks and language adapters to learn\nuniversal language representation across regions. The experimental results show\npositive cross-lingual transfer across languages while reducing catastrophic\nforgetting across regions. Our online results on real user traffic show\nsignificant gains in CTR and characters saved, as well as 65% training cost\nreduction compared with per-language models. As a consequence, we have scaled\nthe feature in multiple languages including low-resource markets.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 03:15:52 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Ying", "Qianlan", ""], ["Bajaj", "Payal", ""], ["Deb", "Budhaditya", ""], ["Yang", "Yu", ""], ["Wang", "Wei", ""], ["Lin", "Bojia", ""], ["Shokouhi", "Milad", ""], ["Song", "Xia", ""], ["Yang", "Yang", ""], ["Jiang", "Daxin", ""]]}, {"id": "2106.02237", "submitter": "Lei Liu", "authors": "Lei Liu, Shunqi Huang, Brian M. Kurkoski", "title": "Memory Approximate Message Passing", "comments": "6 pages, 5 figures, accepted by IEEE ISIT 2021. arXiv admin note:\n  substantial text overlap with arXiv:2012.10861", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI eess.SP math.IT math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Approximate message passing (AMP) is a low-cost iterative\nparameter-estimation technique for certain high-dimensional linear systems with\nnon-Gaussian distributions. However, AMP only applies to independent\nidentically distributed (IID) transform matrices, but may become unreliable for\nother matrix ensembles, especially for ill-conditioned ones. To handle this\ndifficulty, orthogonal/vector AMP (OAMP/VAMP) was proposed for general\nright-unitarily-invariant matrices. However, the Bayes-optimal OAMP/VAMP\nrequires high-complexity linear minimum mean square error estimator. To solve\nthe disadvantages of AMP and OAMP/VAMP, this paper proposes a memory AMP\n(MAMP), in which a long-memory matched filter is proposed for interference\nsuppression. The complexity of MAMP is comparable to AMP. The asymptotic\nGaussianity of estimation errors in MAMP is guaranteed by the orthogonality\nprinciple. A state evolution is derived to asymptotically characterize the\nperformance of MAMP. Based on the state evolution, the relaxation parameters\nand damping vector in MAMP are optimized. For all right-unitarily-invariant\nmatrices, the optimized MAMP converges to OAMP/VAMP, and thus is Bayes-optimal\nif it has a unique fixed point. Finally, simulations are provided to verify the\nvalidity and accuracy of the theoretical results.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 03:37:14 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Liu", "Lei", ""], ["Huang", "Shunqi", ""], ["Kurkoski", "Brian M.", ""]]}, {"id": "2106.02248", "submitter": "Muhao Chen", "authors": "Zequn Sun, Muhao Chen, Wei Hu", "title": "Knowing the No-match: Entity Alignment with Dangling Cases", "comments": "ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper studies a new problem setting of entity alignment for knowledge\ngraphs (KGs). Since KGs possess different sets of entities, there could be\nentities that cannot find alignment across them, leading to the problem of\ndangling entities. As the first attempt to this problem, we construct a new\ndataset and design a multi-task learning framework for both entity alignment\nand dangling entity detection. The framework can opt to abstain from predicting\nalignment for the detected dangling entities. We propose three techniques for\ndangling entity detection that are based on the distribution of\nnearest-neighbor distances, i.e., nearest neighbor classification, marginal\nranking and background ranking. After detecting and removing dangling entities,\nan incorporated entity alignment model in our framework can provide more robust\nalignment for remaining entities. Comprehensive experiments and analyses\ndemonstrate the effectiveness of our framework. We further discover that the\ndangling entity detection module can, in turn, improve alignment learning and\nthe final performance. The contributed resource is publicly available to foster\nfurther research.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 04:28:36 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Sun", "Zequn", ""], ["Chen", "Muhao", ""], ["Hu", "Wei", ""]]}, {"id": "2106.02252", "submitter": "Vainavi Viswanath", "authors": "Vainavi Viswanath, Jennifer Grannen, Priya Sundaresan, Brijen\n  Thananjeyan, Ashwin Balakrishna, Ellen Novoseller, Jeffrey Ichnowski, Michael\n  Laskey, Joseph E. Gonzalez, Ken Goldberg", "title": "Disentangling Dense Multi-Cable Knots", "comments": "First three authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disentangling two or more cables requires many steps to remove crossings\nbetween and within cables. We formalize the problem of disentangling multiple\ncables and present an algorithm, Iterative Reduction Of Non-planar Multiple\ncAble kNots (IRON-MAN), that outputs robot actions to remove crossings from\nmulti-cable knotted structures. We instantiate this algorithm with a learned\nperception system, inspired by prior work in single-cable untying that given an\nimage input, can disentangle two-cable twists, three-cable braids, and knots of\ntwo or three cables, such as overhand, square, carrick bend, sheet bend, crown,\nand fisherman's knots. IRON-MAN keeps track of task-relevant keypoints\ncorresponding to target cable endpoints and crossings and iteratively\ndisentangles the cables by identifying and undoing crossings that are critical\nto knot structure. Using a da Vinci surgical robot, we experimentally evaluate\nthe effectiveness of IRON-MAN on untangling multi-cable knots of types that\nappear in the training data, as well as generalizing to novel classes of\nmulti-cable knots. Results suggest that IRON-MAN is effective in disentangling\nknots involving up to three cables with 80.5% success and generalizing to knot\ntypes that are not present during training, with cables of both distinct or\nidentical colors.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 04:31:59 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Viswanath", "Vainavi", ""], ["Grannen", "Jennifer", ""], ["Sundaresan", "Priya", ""], ["Thananjeyan", "Brijen", ""], ["Balakrishna", "Ashwin", ""], ["Novoseller", "Ellen", ""], ["Ichnowski", "Jeffrey", ""], ["Laskey", "Michael", ""], ["Gonzalez", "Joseph E.", ""], ["Goldberg", "Ken", ""]]}, {"id": "2106.02256", "submitter": "Yihong Zhang", "authors": "Yihong Zhang, Takuya Maekawa, and Takahiro Hara", "title": "Using Social Media Background to Improve Cold-start Recommendation Deep\n  Models", "comments": "Accepted for presentation in IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recommender systems, a cold-start problem occurs when there is no past\ninteraction record associated with the user or item. Typical solutions to the\ncold-start problem make use of contextual information, such as user demographic\nattributes or product descriptions. A group of works have shown that social\nmedia background can help predicting temporal phenomenons such as product sales\nand stock price movements. In this work, our goal is to investigate whether\nsocial media background can be used as extra contextual information to improve\nrecommendation models. Based on an existing deep neural network model, we\nproposed a method to represent temporal social media background as embeddings\nand fuse them as an extra component in the model. We conduct experimental\nevaluations on a real-world e-commerce dataset and a Twitter dataset. The\nresults show that our method of fusing social media background with the\nexisting model does generally improve recommendation performance. In some cases\nthe recommendation accuracy measured by hit-rate@K doubles after fusing with\nsocial media background. Our findings can be beneficial for future recommender\nsystem designs that consider complex temporal information representing social\ninterests.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 04:46:29 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Zhang", "Yihong", ""], ["Maekawa", "Takuya", ""], ["Hara", "Takahiro", ""]]}, {"id": "2106.02257", "submitter": "Jiayi Wei", "authors": "Jiayi Wei, Xilian Li, Yi Zhang, Xin Wang", "title": "Visual Question Rewriting for Increasing Response Rate", "comments": null, "journal-ref": null, "doi": "10.1145/3404835.3463114", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When a human asks questions online, or when a conversational virtual agent\nasks human questions, questions triggering emotions or with details might more\nlikely to get responses or answers. we explore how to automatically rewrite\nnatural language questions to improve the response rate from people. In\nparticular, a new task of Visual Question Rewriting(VQR) task is introduced to\nexplore how visual information can be used to improve the new questions. A data\nset containing around 4K bland questions, attractive questions and images\ntriples is collected. We developed some baseline sequence to sequence models\nand more advanced transformer based models, which take a bland question and a\nrelated image as input and output a rewritten question that is expected to be\nmore attractive. Offline experiments and mechanical Turk based evaluations show\nthat it is possible to rewrite bland questions in a more detailed and\nattractive way to increase the response rate, and images can be helpful.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 04:46:47 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Wei", "Jiayi", ""], ["Li", "Xilian", ""], ["Zhang", "Yi", ""], ["Wang", "Xin", ""]]}, {"id": "2106.02260", "submitter": "Johannes Lederer", "authors": "Leni Ven and Johannes Lederer", "title": "Regularization and Reparameterization Avoid Vanishing Gradients in\n  Sigmoid-Type Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning requires several design choices, such as the nodes' activation\nfunctions and the widths, types, and arrangements of the layers. One\nconsideration when making these choices is the vanishing-gradient problem,\nwhich is the phenomenon of algorithms getting stuck at suboptimal points due to\nsmall gradients. In this paper, we revisit the vanishing-gradient problem in\nthe context of sigmoid-type activation. We use mathematical arguments to\nhighlight two different sources of the phenomenon, namely large individual\nparameters and effects across layers, and to illustrate two simple remedies,\nnamely regularization and rescaling. We then demonstrate the effectiveness of\nthe two remedies in practice. In view of the vanishing-gradient problem being a\nmain reason why tanh and other sigmoid-type activation has become much less\npopular than relu-type activation, our results bring sigmoid-type activation\nback to the table.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 04:53:22 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Ven", "Leni", ""], ["Lederer", "Johannes", ""]]}, {"id": "2106.02266", "submitter": "Soroosh Shahtalebi", "authors": "Soroosh Shahtalebi, Jean-Christophe Gagnon-Audet, Touraj Laleh,\n  Mojtaba Faramarzi, Kartik Ahuja, Irina Rish", "title": "SAND-mask: An Enhanced Gradient Masking Strategy for the Discovery of\n  Invariances in Domain Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A major bottleneck in the real-world applications of machine learning models\nis their failure in generalizing to unseen domains whose data distribution is\nnot i.i.d to the training domains. This failure often stems from learning\nnon-generalizable features in the training domains that are spuriously\ncorrelated with the label of data. To address this shortcoming, there has been\na growing surge of interest in learning good explanations that are hard to\nvary, which is studied under the notion of Out-of-Distribution (OOD)\nGeneralization. The search for good explanations that are \\textit{invariant}\nacross different domains can be seen as finding local (global) minimas in the\nloss landscape that hold true across all of the training domains. In this\npaper, we propose a masking strategy, which determines a continuous weight\nbased on the agreement of gradients that flow in each edge of network, in order\nto control the amount of update received by the edge in each step of\noptimization. Particularly, our proposed technique referred to as \"Smoothed-AND\n(SAND)-masking\", not only validates the agreement in the direction of gradients\nbut also promotes the agreement among their magnitudes to further ensure the\ndiscovery of invariances across training domains. SAND-mask is validated over\nthe Domainbed benchmark for domain generalization and significantly improves\nthe state-of-the-art accuracy on the Colored MNIST dataset while providing\ncompetitive results on other domain generalization datasets.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 05:20:54 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Shahtalebi", "Soroosh", ""], ["Gagnon-Audet", "Jean-Christophe", ""], ["Laleh", "Touraj", ""], ["Faramarzi", "Mojtaba", ""], ["Ahuja", "Kartik", ""], ["Rish", "Irina", ""]]}, {"id": "2106.02302", "submitter": "Zhong Meng", "authors": "Zhong Meng, Yu Wu, Naoyuki Kanda, Liang Lu, Xie Chen, Guoli Ye, Eric\n  Sun, Jinyu Li, Yifan Gong", "title": "Minimum Word Error Rate Training with Language Model Fusion for\n  End-to-End Speech Recognition", "comments": "5 pages, Interspeech 2021", "journal-ref": "Interspeech 2021, Brno, Czech Republic", "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Integrating external language models (LMs) into end-to-end (E2E) models\nremains a challenging task for domain-adaptive speech recognition. Recently,\ninternal language model estimation (ILME)-based LM fusion has shown significant\nword error rate (WER) reduction from Shallow Fusion by subtracting a weighted\ninternal LM score from an interpolation of E2E model and external LM scores\nduring beam search. However, on different test sets, the optimal LM\ninterpolation weights vary over a wide range and have to be tuned extensively\non well-matched validation sets. In this work, we perform LM fusion in the\nminimum WER (MWER) training of an E2E model to obviate the need for LM weights\ntuning during inference. Besides MWER training with Shallow Fusion (MWER-SF),\nwe propose a novel MWER training with ILME (MWER-ILME) where the ILME-based\nfusion is conducted to generate N-best hypotheses and their posteriors.\nAdditional gradient is induced when internal LM is engaged in MWER-ILME loss\ncomputation. During inference, LM weights pre-determined in MWER training\nenable robust LM integrations on test sets from different domains. Experimented\nwith 30K-hour trained transformer transducers, MWER-ILME achieves on average\n8.8% and 5.8% relative WER reductions from MWER and MWER-SF training,\nrespectively, on 6 different test sets\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 07:24:49 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Meng", "Zhong", ""], ["Wu", "Yu", ""], ["Kanda", "Naoyuki", ""], ["Lu", "Liang", ""], ["Chen", "Xie", ""], ["Ye", "Guoli", ""], ["Sun", "Eric", ""], ["Li", "Jinyu", ""], ["Gong", "Yifan", ""]]}, {"id": "2106.02310", "submitter": "Sung Kuk Shyn", "authors": "Sung Kuk Shyn, Donghee Kim, and Kwangsu Kim", "title": "FedCCEA : A Practical Approach of Client Contribution Evaluation for\n  Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Client contribution evaluation, also known as data valuation, is a crucial\napproach in federated learning(FL) for client selection and incentive\nallocation. However, due to restrictions of accessibility of raw data, only\nlimited information such as local weights and local data size of each client is\nopen for quantifying the client contribution. Using data size from available\ninformation, we introduce an empirical evaluation method called Federated\nClient Contribution Evaluation through Accuracy Approximation(FedCCEA). This\nmethod builds the Accuracy Approximation Model(AAM), which estimates a\nsimulated test accuracy using inputs of sampled data size and extracts the\nclients' data quality and data size to measure client contribution. FedCCEA\nstrengthens some advantages: (1) enablement of data size selection to the\nclients, (2) feasible evaluation time regardless of the number of clients, and\n(3) precise estimation in non-IID settings. We demonstrate the superiority of\nFedCCEA compared to previous methods through several experiments: client\ncontribution distribution, client removal, and robustness test to partial\nparticipation.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 07:42:56 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Shyn", "Sung Kuk", ""], ["Kim", "Donghee", ""], ["Kim", "Kwangsu", ""]]}, {"id": "2106.02328", "submitter": "Torsten Sch\\\"on", "authors": "Thangapavithraa Balaji, Patrick Blies, Georg G\\\"ori, Raphael Mitsch,\n  Marcel Wasserer, Torsten Sch\\\"on", "title": "Temporally coherent video anonymization through GAN inpainting", "comments": "Preprint of our FG2021 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work tackles the problem of temporally coherent face anonymization in\nnatural video streams.We propose JaGAN, a two-stage system starting with\ndetecting and masking out faces with black image patches in all individual\nframes of the video. The second stage leverages a privacy-preserving Video\nGenerative Adversarial Network designed to inpaint the missing image patches\nwith artificially generated faces. Our initial experiments reveal that image\nbased generative models are not capable of inpainting patches showing temporal\ncoherent appearance across neighboring video frames. To address this issue we\nintroduce a newly curated video collection, which is made publicly available\nfor the research community along with this paper. We also introduce the\nIdentity Invariance Score IdI as a means to quantify temporal coherency between\nneighboring frames.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 08:19:44 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Balaji", "Thangapavithraa", ""], ["Blies", "Patrick", ""], ["G\u00f6ri", "Georg", ""], ["Mitsch", "Raphael", ""], ["Wasserer", "Marcel", ""], ["Sch\u00f6n", "Torsten", ""]]}, {"id": "2106.02340", "submitter": "Abhilash Nandy", "authors": "Abhilash Nandy, Sayantan Adak, Tanurima Halder, Sai Mahesh Pokala", "title": "cs60075_team2 at SemEval-2021 Task 1 : Lexical Complexity Prediction\n  using Transformer-based Language Models pre-trained on various text corpora", "comments": "6 pages, 1 figure, Semeval-2021 Task 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper describes the performance of the team cs60075_team2 at SemEval\n2021 Task 1 - Lexical Complexity Prediction. The main contribution of this\npaper is to fine-tune transformer-based language models pre-trained on several\ntext corpora, some being general (E.g., Wikipedia, BooksCorpus), some being the\ncorpora from which the CompLex Dataset was extracted, and others being from\nother specific domains such as Finance, Law, etc. We perform ablation studies\non selecting the transformer models and how their individual complexity scores\nare aggregated to get the resulting complexity scores. Our method achieves a\nbest Pearson Correlation of $0.784$ in sub-task 1 (single word) and $0.836$ in\nsub-task 2 (multiple word expressions).\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 08:42:00 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Nandy", "Abhilash", ""], ["Adak", "Sayantan", ""], ["Halder", "Tanurima", ""], ["Pokala", "Sai Mahesh", ""]]}, {"id": "2106.02359", "submitter": "Zhijing Jin", "authors": "Zhijing Jin, Geeticka Chauhan, Brian Tse, Mrinmaya Sachan, Rada\n  Mihalcea", "title": "How Good Is NLP? A Sober Look at NLP Tasks through the Lens of Social\n  Impact", "comments": "Findings of ACL 2021; also accepted at the NLP for Positive Impact\n  workshop@ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent years have seen many breakthroughs in natural language processing\n(NLP), transitioning it from a mostly theoretical field to one with many\nreal-world applications. Noting the rising number of applications of other\nmachine learning and AI techniques with pervasive societal impact, we\nanticipate the rising importance of developing NLP technologies for social\ngood. Inspired by theories in moral philosophy and global priorities research,\nwe aim to promote a guideline for social good in the context of NLP. We lay the\nfoundations via the moral philosophy definition of social good, propose a\nframework to evaluate the direct and indirect real-world impact of NLP tasks,\nand adopt the methodology of global priorities research to identify priority\ncauses for NLP research. Finally, we use our theoretical framework to provide\nsome practical guidelines for future NLP research for social good. Our data and\ncode are available at http://github.com/zhijing-jin/nlp4sg_acl2021. In\naddition, we curate a list of papers and resources on NLP for social good at\nhttps://github.com/zhijing-jin/NLP4SocialGood_Papers.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 09:17:15 GMT"}, {"version": "v2", "created": "Sat, 24 Jul 2021 19:26:38 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Jin", "Zhijing", ""], ["Chauhan", "Geeticka", ""], ["Tse", "Brian", ""], ["Sachan", "Mrinmaya", ""], ["Mihalcea", "Rada", ""]]}, {"id": "2106.02377", "submitter": "Larissa Triess", "authors": "Larissa T. Triess and Mariella Dreissig and Christoph B. Rist and J.\n  Marius Z\\\"ollner", "title": "A Survey on Deep Domain Adaptation for LiDAR Perception", "comments": "Accepted at IEEE Intelligent Vehicles Symposium (IV) 2021 Workshop on\n  Autonomy at Scale. 8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scalable systems for automated driving have to reliably cope with an\nopen-world setting. This means, the perception systems are exposed to drastic\ndomain shifts, like changes in weather conditions, time-dependent aspects, or\ngeographic regions. Covering all domains with annotated data is impossible\nbecause of the endless variations of domains and the time-consuming and\nexpensive annotation process. Furthermore, fast development cycles of the\nsystem additionally introduce hardware changes, such as sensor types and\nvehicle setups, and the required knowledge transfer from simulation. To enable\nscalable automated driving, it is therefore crucial to address these domain\nshifts in a robust and efficient manner. Over the last years, a vast amount of\ndifferent domain adaptation techniques evolved. There already exists a number\nof survey papers for domain adaptation on camera images, however, a survey for\nLiDAR perception is absent. Nevertheless, LiDAR is a vital sensor for automated\ndriving that provides detailed 3D scans of the vehicle's surroundings. To\nstimulate future research, this paper presents a comprehensive review of recent\nprogress in domain adaptation methods and formulates interesting research\nquestions specifically targeted towards LiDAR perception.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 09:42:51 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 06:42:57 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Triess", "Larissa T.", ""], ["Dreissig", "Mariella", ""], ["Rist", "Christoph B.", ""], ["Z\u00f6llner", "J. Marius", ""]]}, {"id": "2106.02390", "submitter": "Alejandro Daniel Noel", "authors": "Alejandro Daniel Noel (1), Charel van Hoof (1), Beren Millidge (2)\n  ((1) Delft University of Technology, (2) University of Oxford)", "title": "Online reinforcement learning with sparse rewards through an active\n  inference capsule", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intelligent agents must pursue their goals in complex environments with\npartial information and often limited computational capacity. Reinforcement\nlearning methods have achieved great success by creating agents that optimize\nengineered reward functions, but which often struggle to learn in sparse-reward\nenvironments, generally require many environmental interactions to perform\nwell, and are typically computationally very expensive. Active inference is a\nmodel-based approach that directs agents to explore uncertain states while\nadhering to a prior model of their goal behaviour. This paper introduces an\nactive inference agent which minimizes the novel free energy of the expected\nfuture. Our model is capable of solving sparse-reward problems with a very high\nsample efficiency due to its objective function, which encourages directed\nexploration of uncertain states. Moreover, our model is computationally very\nlight and can operate in a fully online manner while achieving comparable\nperformance to offline RL methods. We showcase the capabilities of our model by\nsolving the mountain car problem, where we demonstrate its superior exploration\nproperties and its robustness to observation noise, which in fact improves\nperformance. We also introduce a novel method for approximating the prior model\nfrom the reward function, which simplifies the expression of complex objectives\nand improves performance over previous active inference approaches.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 10:03:36 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Noel", "Alejandro Daniel", "", "Delft University of Technology"], ["van Hoof", "Charel", "", "Delft University of Technology"], ["Millidge", "Beren", "", "University of Oxford"]]}, {"id": "2106.02401", "submitter": "Shan Yang", "authors": "Shan Yang, Yongfei Zhang, Guanglin Niu, Qinghua Zhao, Shiliang Pu", "title": "Entity Concept-enhanced Few-shot Relation Extraction", "comments": "Accepted at ACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot relation extraction (FSRE) is of great importance in long-tail\ndistribution problem, especially in special domain with low-resource data. Most\nexisting FSRE algorithms fail to accurately classify the relations merely based\non the information of the sentences together with the recognized entity pairs,\ndue to limited samples and lack of knowledge. To address this problem, in this\npaper, we proposed a novel entity CONCEPT-enhanced FEw-shot Relation Extraction\nscheme (ConceptFERE), which introduces the inherent concepts of entities to\nprovide clues for relation prediction and boost the relations classification\nperformance. Firstly, a concept-sentence attention module is developed to\nselect the most appropriate concept from multiple concepts of each entity by\ncalculating the semantic similarity between sentences and concepts. Secondly, a\nself-attention based fusion module is presented to bridge the gap of concept\nembedding and sentence embedding from different semantic spaces. Extensive\nexperiments on the FSRE benchmark dataset FewRel have demonstrated the\neffectiveness and the superiority of the proposed ConceptFERE scheme as\ncompared to the state-of-the-art baselines. Code is available at\nhttps://github.com/LittleGuoKe/ConceptFERE.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 10:36:49 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Yang", "Shan", ""], ["Zhang", "Yongfei", ""], ["Niu", "Guanglin", ""], ["Zhao", "Qinghua", ""], ["Pu", "Shiliang", ""]]}, {"id": "2106.02484", "submitter": "Adam Yala", "authors": "Adam Yala, Homa Esfahanizadeh, Rafael G. L. D' Oliveira, Ken R. Duffy,\n  Manya Ghobadi, Tommi S. Jaakkola, Vinod Vaikuntanathan, Regina Barzilay,\n  Muriel Medard", "title": "NeuraCrypt: Hiding Private Health Data via Random Neural Networks for\n  Public Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Balancing the needs of data privacy and predictive utility is a central\nchallenge for machine learning in healthcare. In particular, privacy concerns\nhave led to a dearth of public datasets, complicated the construction of\nmulti-hospital cohorts and limited the utilization of external machine learning\nresources. To remedy this, new methods are required to enable data owners, such\nas hospitals, to share their datasets publicly, while preserving both patient\nprivacy and modeling utility. We propose NeuraCrypt, a private encoding scheme\nbased on random deep neural networks. NeuraCrypt encodes raw patient data using\na randomly constructed neural network known only to the data-owner, and\npublishes both the encoded data and associated labels publicly. From a\ntheoretical perspective, we demonstrate that sampling from a sufficiently rich\nfamily of encoding functions offers a well-defined and meaningful notion of\nprivacy against a computationally unbounded adversary with full knowledge of\nthe underlying data-distribution. We propose to approximate this family of\nencoding functions through random deep neural networks. Empirically, we\ndemonstrate the robustness of our encoding to a suite of adversarial attacks\nand show that NeuraCrypt achieves competitive accuracy to non-private baselines\non a variety of x-ray tasks. Moreover, we demonstrate that multiple hospitals,\nusing independent private encoders, can collaborate to train improved x-ray\nmodels. Finally, we release a challenge dataset to encourage the development of\nnew attacks on NeuraCrypt.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 13:42:21 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Yala", "Adam", ""], ["Esfahanizadeh", "Homa", ""], ["Oliveira", "Rafael G. L. D'", ""], ["Duffy", "Ken R.", ""], ["Ghobadi", "Manya", ""], ["Jaakkola", "Tommi S.", ""], ["Vaikuntanathan", "Vinod", ""], ["Barzilay", "Regina", ""], ["Medard", "Muriel", ""]]}, {"id": "2106.02494", "submitter": "Aly Sabri Abdalla", "authors": "Talha F. Rahman, Aly S. Abdalla, Keith Powell, Walaa AlQwider, and Vuk\n  Marojevic", "title": "Network and Physical Layer Attacks and countermeasures to AI-Enabled 6G\n  O-RAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Artificial intelligence (AI) will play an increasing role in cellular network\ndeployment, configuration and management. This paper examines the security\nimplications of AI-driven 6G radio access networks (RANs). While the expected\ntimeline for 6G standardization is still several years out, pre-standardization\nefforts related to 6G security are already ongoing and will benefit from\nfundamental and experimental research. The Open RAN (O-RAN) describes an\nindustry-driven open architecture and interfaces for building next generation\nRANs with AI control. Considering this architecture, we identify the critical\nthreats to data driven network and physical layer elements, the corresponding\ncountermeasures, and the research directions.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 16:36:37 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Rahman", "Talha F.", ""], ["Abdalla", "Aly S.", ""], ["Powell", "Keith", ""], ["AlQwider", "Walaa", ""], ["Marojevic", "Vuk", ""]]}, {"id": "2106.02497", "submitter": "Debjit Paul", "authors": "Debjit Paul and Anette Frank", "title": "COINS: Dynamically Generating COntextualized Inference Rules for\n  Narrative Story Completion", "comments": "ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite recent successes of large pre-trained language models in solving\nreasoning tasks, their inference capabilities remain opaque. We posit that such\nmodels can be made more interpretable by explicitly generating interim\ninference rules, and using them to guide the generation of task-specific\ntextual outputs. In this paper we present COINS, a recursive inference\nframework that i) iteratively reads context sentences, ii) dynamically\ngenerates contextualized inference rules, encodes them, and iii) uses them to\nguide task-specific output generation. We apply COINS to a Narrative Story\nCompletion task that asks a model to complete a story with missing sentences,\nto produce a coherent story with plausible logical connections, causal\nrelationships, and temporal dependencies. By modularizing inference and\nsentence generation steps in a recurrent model, we aim to make reasoning steps\nand their effects on next sentence generation transparent. Our automatic and\nmanual evaluations show that the model generates better story sentences than\nSOTA baselines, especially in terms of coherence. We further demonstrate\nimproved performance over strong pre-trained LMs in generating commonsense\ninference rules. The recursive nature of COINS holds the potential for\ncontrolled generation of longer sequences.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 14:06:33 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Paul", "Debjit", ""], ["Frank", "Anette", ""]]}, {"id": "2106.02498", "submitter": "Tatiana Tommasi", "authors": "Tatiana Tommasi, Silvia Bucci, Barbara Caputo, Pietro Asinari", "title": "Towards Fairness Certification in Artificial Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thanks to the great progress of machine learning in the last years, several\nArtificial Intelligence (AI) techniques have been increasingly moving from the\ncontrolled research laboratory settings to our everyday life. AI is clearly\nsupportive in many decision-making scenarios, but when it comes to sensitive\nareas such as health care, hiring policies, education, banking or justice, with\nmajor impact on individuals and society, it becomes crucial to establish\nguidelines on how to design, develop, deploy and monitor this technology.\nIndeed the decision rules elaborated by machine learning models are data-driven\nand there are multiple ways in which discriminatory biases can seep into data.\nAlgorithms trained on those data incur the risk of amplifying prejudices and\nsocietal stereotypes by over associating protected attributes such as gender,\nethnicity or disabilities with the prediction task. Starting from the extensive\nexperience of the National Metrology Institute on measurement standards and\ncertification roadmaps, and of Politecnico di Torino on machine learning as\nwell as methods for domain bias evaluation and mastering, we propose a first\njoint effort to define the operational steps needed for AI fairness\ncertification. Specifically we will overview the criteria that should be met by\nan AI system before coming into official service and the conformity assessment\nprocedures useful to monitor its functioning for fair decisions.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 14:12:12 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Tommasi", "Tatiana", ""], ["Bucci", "Silvia", ""], ["Caputo", "Barbara", ""], ["Asinari", "Pietro", ""]]}, {"id": "2106.02516", "submitter": "Thomas Conley", "authors": "Thomas Conley, Jack St. Clair, Jugal Kalita", "title": "Improving Computer Generated Dialog with Auxiliary Loss Functions and\n  Custom Evaluation Metrics", "comments": null, "journal-ref": "Proceedings of ICON-2018, Patiala, India. December 2018, pages\n  143--149", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although people have the ability to engage in vapid dialogue without effort,\nthis may not be a uniquely human trait. Since the 1960's researchers have been\ntrying to create agents that can generate artificial conversation. These\nprograms are commonly known as chatbots. With increasing use of neural networks\nfor dialog generation, some conclude that this goal has been achieved. This\nresearch joins the quest by creating a dialog generating Recurrent Neural\nNetwork (RNN) and by enhancing the ability of this network with auxiliary loss\nfunctions and a beam search. Our custom loss functions achieve better cohesion\nand coherence by including calculations of Maximum Mutual Information (MMI) and\nentropy. We demonstrate the effectiveness of this system by using a set of\ncustom evaluation metrics inspired by an abundance of previous research and\nbased on tried-and-true principles of Natural Language Processing.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 14:35:05 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Conley", "Thomas", ""], ["Clair", "Jack St.", ""], ["Kalita", "Jugal", ""]]}, {"id": "2106.02523", "submitter": "Osman Semih Kayhan", "authors": "Osman Semih Kayhan, Bart Vredebregt and Jan C. van Gemert", "title": "Hallucination In Object Detection -- A Study In Visual Part Verification", "comments": "ICIP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that object detectors can hallucinate and detect missing objects;\npotentially even accurately localized at their expected, but non-existing,\nposition. This is particularly problematic for applications that rely on visual\npart verification: detecting if an object part is present or absent. We show\nhow popular object detectors hallucinate objects in a visual part verification\ntask and introduce the first visual part verification dataset: DelftBikes,\nwhich has 10,000 bike photographs, with 22 densely annotated parts per image,\nwhere some parts may be missing. We explicitly annotated an extra object state\nlabel for each part to reflect if a part is missing or intact. We propose to\nevaluate visual part verification by relying on recall and compare popular\nobject detectors on DelftBikes.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 14:47:11 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Kayhan", "Osman Semih", ""], ["Vredebregt", "Bart", ""], ["van Gemert", "Jan C.", ""]]}, {"id": "2106.02531", "submitter": "Georgios Batzolis", "authors": "Georgios Batzolis, Marcello Carioni, Christian Etmann, Soroosh\n  Afyouni, Zoe Kourtzi, Carola Bibiane Sch\\\"onlieb", "title": "CAFLOW: Conditional Autoregressive Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce CAFLOW, a new diverse image-to-image translation model that\nsimultaneously leverages the power of auto-regressive modeling and the modeling\nefficiency of conditional normalizing flows. We transform the conditioning\nimage into a sequence of latent encodings using a multi-scale normalizing flow\nand repeat the process for the conditioned image. We model the conditional\ndistribution of the latent encodings by modeling the auto-regressive\ndistributions with an efficient multi-scale normalizing flow, where each\nconditioning factor affects image synthesis at its respective resolution scale.\nOur proposed framework performs well on a range of image-to-image translation\ntasks. It outperforms former designs of conditional flows because of its\nexpressive auto-regressive structure.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 14:57:41 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Batzolis", "Georgios", ""], ["Carioni", "Marcello", ""], ["Etmann", "Christian", ""], ["Afyouni", "Soroosh", ""], ["Kourtzi", "Zoe", ""], ["Sch\u00f6nlieb", "Carola Bibiane", ""]]}, {"id": "2106.02552", "submitter": "Heinrich Jiang", "authors": "Heinrich Jiang, Afshin Rostamizadeh", "title": "Active Covering", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We analyze the problem of active covering, where the learner is given an\nunlabeled dataset and can sequentially label query examples. The objective is\nto label query all of the positive examples in the fewest number of total label\nqueries. We show under standard non-parametric assumptions that a classical\nsupport estimator can be repurposed as an offline algorithm attaining an excess\nquery cost of $\\widetilde{\\Theta}(n^{D/(D+1)})$ compared to the optimal\nlearner, where $n$ is the number of datapoints and $D$ is the dimension. We\nthen provide a simple active learning method that attains an improved excess\nquery cost of $\\widetilde{O}(n^{(D-1)/D})$. Furthermore, the proposed\nalgorithms only require access to the positive labeled examples, which in\ncertain settings provides additional computational and privacy benefits.\nFinally, we show that the active learning method consistently outperforms\noffline methods as well as a variety of baselines on a wide range of benchmark\nimage-based datasets.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 15:32:39 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Jiang", "Heinrich", ""], ["Rostamizadeh", "Afshin", ""]]}, {"id": "2106.02567", "submitter": "Elahe Arani", "authors": "Ratnajit Mukherjee, Haris Iqbal, Shabbir Marzban, Ahmed Badar, Terence\n  Brouns, Shruthi Gowda, Elahe Arani and Bahram Zonooz", "title": "AI Driven Road Maintenance Inspection", "comments": "accepted at 27th ITS World Congress, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Road infrastructure maintenance inspection is typically a labour-intensive\nand critical task to ensure the safety of all the road users. In this work, we\npropose a detailed methodology to use state-of-the-art techniques in artificial\nintelligence and computer vision to automate a sizeable portion of the\nmaintenance inspection subtasks and reduce the labour costs. The proposed\nmethodology uses state-of-the-art computer vision techniques such as object\ndetection and semantic segmentation to automate inspections on primary road\nstructures such as the road surface, markings, barriers (guardrails) and\ntraffic signs. The models are mostly trained on commercially viable datasets\nand augmented with proprietary data. We demonstrate that our AI models can not\nonly automate and scale maintenance inspections on primary road structures but\nalso result in higher recall compared to traditional manual inspections.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 15:59:46 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Mukherjee", "Ratnajit", ""], ["Iqbal", "Haris", ""], ["Marzban", "Shabbir", ""], ["Badar", "Ahmed", ""], ["Brouns", "Terence", ""], ["Gowda", "Shruthi", ""], ["Arani", "Elahe", ""], ["Zonooz", "Bahram", ""]]}, {"id": "2106.02578", "submitter": "Gavin Abercrombie", "authors": "Gavin Abercrombie, Amanda Cercas Curry, Mugdha Pandya, Verena Rieser", "title": "Alexa, Google, Siri: What are Your Pronouns? Gender and Anthropomorphism\n  in the Design and Perception of Conversational Assistants", "comments": "To be presented at the 3rd Workshop on Gender Bias in Natural\n  Language Processing (GeBNLP 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Technology companies have produced varied responses to concerns about the\neffects of the design of their conversational AI systems. Some have claimed\nthat their voice assistants are in fact not gendered or human-like -- despite\ndesign features suggesting the contrary. We compare these claims to user\nperceptions by analysing the pronouns they use when referring to AI assistants.\nWe also examine systems' responses and the extent to which they generate output\nwhich is gendered and anthropomorphic. We find that, while some companies\nappear to be addressing the ethical concerns raised, in some cases, their\nclaims do not seem to hold true. In particular, our results show that system\noutputs are ambiguous as to the humanness of the systems, and that users tend\nto personify and gender them as a result.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 16:19:40 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Abercrombie", "Gavin", ""], ["Curry", "Amanda Cercas", ""], ["Pandya", "Mugdha", ""], ["Rieser", "Verena", ""]]}, {"id": "2106.02596", "submitter": "Svetlana Kiritchenko", "authors": "Kathleen C. Fraser, Isar Nejadgholi, Svetlana Kiritchenko", "title": "Understanding and Countering Stereotypes: A Computational Approach to\n  the Stereotype Content Model", "comments": "In Proceedings of the Joint Conference of the 59th Annual Meeting of\n  the Association for Computational Linguistics and the 11th International\n  Joint Conference on Natural Language Processing (ACL-IJCNLP 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stereotypical language expresses widely-held beliefs about different social\ncategories. Many stereotypes are overtly negative, while others may appear\npositive on the surface, but still lead to negative consequences. In this work,\nwe present a computational approach to interpreting stereotypes in text through\nthe Stereotype Content Model (SCM), a comprehensive causal theory from social\npsychology. The SCM proposes that stereotypes can be understood along two\nprimary dimensions: warmth and competence. We present a method for defining\nwarmth and competence axes in semantic embedding space, and show that the four\nquadrants defined by this subspace accurately represent the warmth and\ncompetence concepts, according to annotated lexicons. We then apply our\ncomputational SCM model to textual stereotype data and show that it compares\nfavourably with survey-based studies in the psychological literature.\nFurthermore, we explore various strategies to counter stereotypical beliefs\nwith anti-stereotypes. It is known that countering stereotypes with\nanti-stereotypical examples is one of the most effective ways to reduce biased\nthinking, yet the problem of generating anti-stereotypes has not been\npreviously studied. Thus, a better understanding of how to generate realistic\nand effective anti-stereotypes can contribute to addressing pressing societal\nconcerns of stereotyping, prejudice, and discrimination.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 16:53:37 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Fraser", "Kathleen C.", ""], ["Nejadgholi", "Isar", ""], ["Kiritchenko", "Svetlana", ""]]}, {"id": "2106.02607", "submitter": "Anusua Trivedi", "authors": "Anusua Trivedi, Alyssa Suhm, Prathamesh Mahankal, Subhiksha\n  Mukuntharaj, Meghana D. Parab, Malvika Mohan, Meredith Berger, Arathi\n  Sethumadhavan, Ashish Jaiman, Rahul Dodhia", "title": "Defending Democracy: Using Deep Learning to Identify and Prevent\n  Misinformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The rise in online misinformation in recent years threatens democracies by\ndistorting authentic public discourse and causing confusion, fear, and even, in\nextreme cases, violence. There is a need to understand the spread of false\ncontent through online networks for developing interventions that disrupt\nmisinformation before it achieves virality. Using a Deep Bidirectional\nTransformer for Language Understanding (BERT) and propagation graphs, this\nstudy classifies and visualizes the spread of misinformation on a social media\nnetwork using publicly available Twitter data. The results confirm prior\nresearch around user clusters and the virality of false content while improving\nthe precision of deep learning models for misinformation detection. The study\nfurther demonstrates the suitability of BERT for providing a scalable model for\nfalse information detection, which can contribute to the development of more\ntimely and accurate interventions to slow the spread of misinformation in\nonline environments.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 16:34:54 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Trivedi", "Anusua", ""], ["Suhm", "Alyssa", ""], ["Mahankal", "Prathamesh", ""], ["Mukuntharaj", "Subhiksha", ""], ["Parab", "Meghana D.", ""], ["Mohan", "Malvika", ""], ["Berger", "Meredith", ""], ["Sethumadhavan", "Arathi", ""], ["Jaiman", "Ashish", ""], ["Dodhia", "Rahul", ""]]}, {"id": "2106.02617", "submitter": "Rodrigo Toro Icarte", "authors": "Parand Alizadeh Alamdari, Toryn Q. Klassen, Rodrigo Toro Icarte,\n  Sheila A. McIlraith", "title": "Be Considerate: Objectives, Side Effects, and Deciding How to Act", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in AI safety has highlighted that in sequential decision making,\nobjectives are often underspecified or incomplete. This gives discretion to the\nacting agent to realize the stated objective in ways that may result in\nundesirable outcomes. We contend that to learn to act safely, a reinforcement\nlearning (RL) agent should include contemplation of the impact of its actions\non the wellbeing and agency of others in the environment, including other\nacting agents and reactive processes. We endow RL agents with the ability to\ncontemplate such impact by augmenting their reward based on expectation of\nfuture return by others in the environment, providing different criteria for\ncharacterizing impact. We further endow these agents with the ability to\ndifferentially factor this impact into their decision making, manifesting\nbehavior that ranges from self-centred to self-less, as demonstrated by\nexperiments in gridworld environments.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 17:32:15 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Alamdari", "Parand Alizadeh", ""], ["Klassen", "Toryn Q.", ""], ["Icarte", "Rodrigo Toro", ""], ["McIlraith", "Sheila A.", ""]]}, {"id": "2106.02626", "submitter": "Gabriel B\\'ena", "authors": "Gabriel B\\'ena, Dan F. M. Goodman", "title": "Extreme sparsity gives rise to functional specialization", "comments": "12 pages, 4 figures, Preprint (submitted to Neurips 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modularity of neural networks -- both biological and artificial -- can be\nthought of either structurally or functionally, and the relationship between\nthese is an open question. We show that enforcing structural modularity via\nsparse connectivity between two dense sub-networks which need to communicate to\nsolve the task leads to functional specialization of the sub-networks, but only\nat extreme levels of sparsity. With even a moderate number of interconnections,\nthe sub-networks become functionally entangled. Defining functional\nspecialization is in itself a challenging problem without a universally agreed\nsolution. To address this, we designed three different measures of\nspecialization (based on weight masks, retraining and correlation) and found\nthem to qualitatively agree. Our results have implications in both neuroscience\nand machine learning. For neuroscience, it shows that we cannot conclude that\nthere is functional modularity simply by observing moderate levels of\nstructural modularity: knowing the brain's connectome is not sufficient for\nunderstanding how it breaks down into functional modules. For machine learning,\nusing structure to promote functional modularity -- which may be important for\nrobustness and generalization -- may require extremely narrow bottlenecks\nbetween modules.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 17:39:36 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["B\u00e9na", "Gabriel", ""], ["Goodman", "Dan F. M.", ""]]}, {"id": "2106.02634", "submitter": "Vincent Sitzmann", "authors": "Vincent Sitzmann, Semon Rezchikov, William T. Freeman, Joshua B.\n  Tenenbaum, Fredo Durand", "title": "Light Field Networks: Neural Scene Representations with\n  Single-Evaluation Rendering", "comments": "First two authors contributed equally. Project website:\n  https://vsitzmann.github.io/lfns/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring representations of 3D scenes from 2D observations is a fundamental\nproblem of computer graphics, computer vision, and artificial intelligence.\nEmerging 3D-structured neural scene representations are a promising approach to\n3D scene understanding. In this work, we propose a novel neural scene\nrepresentation, Light Field Networks or LFNs, which represent both geometry and\nappearance of the underlying 3D scene in a 360-degree, four-dimensional light\nfield parameterized via a neural implicit representation. Rendering a ray from\nan LFN requires only a *single* network evaluation, as opposed to hundreds of\nevaluations per ray for ray-marching or volumetric based renderers in\n3D-structured neural scene representations. In the setting of simple scenes, we\nleverage meta-learning to learn a prior over LFNs that enables multi-view\nconsistent light field reconstruction from as little as a single image\nobservation. This results in dramatic reductions in time and memory complexity,\nand enables real-time rendering. The cost of storing a 360-degree light field\nvia an LFN is two orders of magnitude lower than conventional methods such as\nthe Lumigraph. Utilizing the analytical differentiability of neural implicit\nrepresentations and a novel parameterization of light space, we further\ndemonstrate the extraction of sparse depth maps from LFNs.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 17:54:49 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Sitzmann", "Vincent", ""], ["Rezchikov", "Semon", ""], ["Freeman", "William T.", ""], ["Tenenbaum", "Joshua B.", ""], ["Durand", "Fredo", ""]]}, {"id": "2106.02654", "submitter": "Heinrich Jiang", "authors": "Heinrich Jiang, Harikrishna Narasimhan, Dara Bahri, Andrew Cotter,\n  Afshin Rostamizadeh", "title": "Churn Reduction via Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In real-world systems, models are frequently updated as more data becomes\navailable, and in addition to achieving high accuracy, the goal is to also\nmaintain a low difference in predictions compared to the base model (i.e.\npredictive ``churn''). If model retraining results in vastly different\nbehavior, then it could cause negative effects in downstream systems,\nespecially if this churn can be avoided with limited impact on model accuracy.\nIn this paper, we show an equivalence between training with distillation using\nthe base model as the teacher and training with an explicit constraint on the\npredictive churn. We then show that distillation performs strongly for low\nchurn training against a number of recent baselines on a wide range of datasets\nand model architectures, including fully-connected networks, convolutional\nnetworks, and transformers.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 18:03:31 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Jiang", "Heinrich", ""], ["Narasimhan", "Harikrishna", ""], ["Bahri", "Dara", ""], ["Cotter", "Andrew", ""], ["Rostamizadeh", "Afshin", ""]]}, {"id": "2106.02658", "submitter": "Patrick Huber", "authors": "Patrick Huber, Wen Xiao and Giuseppe Carenini", "title": "W-RST: Towards a Weighted RST-style Discourse Framework", "comments": "9 pages, Accepted at ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aiming for a better integration of data-driven and linguistically-inspired\napproaches, we explore whether RST Nuclearity, assigning a binary assessment of\nimportance between text segments, can be replaced by automatically generated,\nreal-valued scores, in what we call a Weighted-RST framework. In particular, we\nfind that weighted discourse trees from auxiliary tasks can benefit key NLP\ndownstream applications, compared to nuclearity-centered approaches. We further\nshow that real-valued importance distributions partially and interestingly\nalign with the assessment and uncertainty of human annotators.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 18:12:09 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Huber", "Patrick", ""], ["Xiao", "Wen", ""], ["Carenini", "Giuseppe", ""]]}, {"id": "2106.02668", "submitter": "Jesse Mu", "authors": "Jesse Mu, Noah Goodman", "title": "Emergent Communication of Generalizations", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To build agents that can collaborate effectively with others, recent research\nhas trained artificial agents to communicate with each other in Lewis-style\nreferential games. However, this often leads to successful but uninterpretable\ncommunication. We argue that this is due to the game objective: communicating\nabout a single object in a shared visual context is prone to overfitting and\ndoes not encourage language useful beyond concrete reference. In contrast,\nhuman language conveys a rich variety of abstract ideas. To promote such\nskills, we propose games that require communicating generalizations over sets\nof objects representing abstract visual concepts, optionally with separate\ncontexts for each agent. We find that these games greatly improve systematicity\nand interpretability of the learned languages, according to several metrics in\nthe literature. Finally, we propose a method for identifying logical operations\nembedded in the emergent languages by learning an approximate compositional\nreconstruction of the language.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 19:02:18 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Mu", "Jesse", ""], ["Goodman", "Noah", ""]]}, {"id": "2106.02669", "submitter": "Jafar Pourbemany", "authors": "Jafar Pourbemany, Almabrok Essa, and Ye Zhu", "title": "Real Time Video based Heart and Respiration Rate Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In recent years, research about monitoring vital signs by smartphones grows\nsignificantly. There are some special sensors like Electrocardiogram (ECG) and\nPhotoplethysmographic (PPG) to detect heart rate (HR) and respiration rate\n(RR). Smartphone cameras also can measure HR by detecting and processing\nimaging Photoplethysmographic (iPPG) signals from the video of a user's face.\nIndeed, the variation in the intensity of the green channel can be measured by\nthe iPPG signals of the video. This study aimed to provide a method to extract\nheart rate and respiration rate using the video of individuals' faces. The\nproposed method is based on measuring fluctuations in the Hue, and can\ntherefore extract both HR and RR from the video of a user's face. The proposed\nmethod is evaluated by performing on 25 healthy individuals. For each subject,\n20 seconds video of his/her face is recorded. Results show that the proposed\napproach of measuring iPPG using Hue gives more accurate rates than the Green\nchannel.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 19:03:21 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Pourbemany", "Jafar", ""], ["Essa", "Almabrok", ""], ["Zhu", "Ye", ""]]}, {"id": "2106.02674", "submitter": "Ferdinando Fioretto", "authors": "Cuong Tran, My H. Dinh, Ferdinando Fioretto", "title": "Differentially Private Deep Learning under the Fairness Lens", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential Privacy (DP) is an important privacy-enhancing technology for\nprivate machine learning systems. It allows to measure and bound the risk\nassociated with an individual participation in a computation. However, it was\nrecently observed that DP learning systems may exacerbate bias and unfairness\nfor different groups of individuals. This paper builds on these important\nobservations and sheds light on the causes of the disparate impacts arising in\nthe problem of differentially private empirical risk minimization. It focuses\non the accuracy disparity arising among groups of individuals in two\nwell-studied DP learning methods: output perturbation and differentially\nprivate stochastic gradient descent. The paper analyzes which data and model\nproperties are responsible for the disproportionate impacts, why these aspects\nare affecting different groups disproportionately and proposes guidelines to\nmitigate these effects. The proposed approach is evaluated on several datasets\nand settings.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 19:10:09 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Tran", "Cuong", ""], ["Dinh", "My H.", ""], ["Fioretto", "Ferdinando", ""]]}, {"id": "2106.02679", "submitter": "Joel Lamy-Poirier", "authors": "Joel Lamy-Poirier", "title": "Layered gradient accumulation and modular pipeline parallelism: fast and\n  efficient training of large language models", "comments": "22 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.DC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The advent of the transformer has sparked a quick growth in the size of\nlanguage models, far outpacing hardware improvements. (Dense) transformers are\nexpected to reach the trillion-parameter scale in the near future, for which\ntraining requires thousands or even tens of thousands of GPUs. We investigate\nthe challenges of training at this scale and beyond on commercially available\nhardware. In particular, we analyse the shortest possible training time for\ndifferent configurations of distributed training, leveraging empirical scaling\nlaws for language models to estimate the optimal (critical) batch size.\nContrary to popular belief, we find no evidence for a memory wall, and instead\nargue that the real limitation -- other than the cost -- lies in the training\nduration.\n  In addition to this analysis, we introduce two new methods, \\textit{layered\ngradient accumulation} and \\textit{modular pipeline parallelism}, which\ntogether cut the shortest training time by half. The methods also reduce data\nmovement, lowering the network requirement to a point where a fast InfiniBand\nconnection is not necessary. This increased network efficiency also improve on\nthe methods introduced with the ZeRO optimizer, reducing the memory usage to a\ntiny fraction of the available GPU memory.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 19:21:49 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Lamy-Poirier", "Joel", ""]]}, {"id": "2106.02702", "submitter": "Jakub Marecek", "authors": "Quan Zhou and Jakub Marecek and Robert N. Shorten", "title": "Subgroup Fairness in Two-Sided Markets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that two-sided markets are unfair in a number of ways. For\ninstance, female workers at Uber earn less than their male colleagues per mile\ndriven. Similar observations have been made for other minority subgroups in\nother two-sided markets. Here, we suggest a novel market-clearing mechanism for\ntwo-sided markets, which promotes equalisation of the pay per hour worked\nacross multiple subgroups, as well as within each subgroup. In the process, we\nintroduce a novel notion of subgroup fairness (which we call Inter-fairness),\nwhich can be combined with other notions of fairness within each subgroup\n(called Intra-fairness), and the utility for the customers (Customer-Care) in\nthe objective of the market-clearing problem. While the novel non-linear terms\nin the objective complicate market clearing by making the problem non-convex,\nwe show that a certain non-convex augmented Lagrangian relaxation can be\napproximated to any precision in time polynomial in the number of market\nparticipants using semi-definite programming. This makes it possible to\nimplement the market-clearing mechanism efficiently. On the example of\ndriver-ride assignment in an Uber-like system, we demonstrate the efficacy and\nscalability of the approach, and trade-offs between Inter- and Intra-fairness.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 20:26:16 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Zhou", "Quan", ""], ["Marecek", "Jakub", ""], ["Shorten", "Robert N.", ""]]}, {"id": "2106.02708", "submitter": "Venkata Sriram Siddhardh Nadendla", "authors": "Sainath Sanga and Venkata Sriram Siddhardh Nadendla", "title": "On the Design of Strategic Task Recommendations for Sustainable\n  Crowdsourcing-Based Content Moderation", "comments": "Presented at International Workshop on Autonomous Agents for Social\n  Good (AASG), May 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsourcing-based content moderation is a platform that hosts content\nmoderation tasks for crowd workers to review user submissions (e.g. text,\nimages and videos) and make decisions regarding the admissibility of the posted\ncontent, along with a gamut of other tasks such as image labeling and\nspeech-to-text conversion. In an attempt to reduce cognitive overload at the\nworkers and improve system efficiency, these platforms offer personalized task\nrecommendations according to the worker's preferences. However, the current\nstate-of-the-art recommendation systems disregard the effects on worker's\nmental health, especially when they are repeatedly exposed to content\nmoderation tasks with extreme content (e.g. violent images, hate-speech). In\nthis paper, we propose a novel, strategic recommendation system for the\ncrowdsourcing platform that recommends jobs based on worker's mental status.\nSpecifically, this paper models interaction between the crowdsourcing\nplatform's recommendation system (leader) and the worker (follower) as a\nBayesian Stackelberg game where the type of the follower corresponds to the\nworker's cognitive atrophy rate and task preferences. We discuss how rewards\nand costs should be designed to steer the game towards desired outcomes in\nterms of maximizing the platform's productivity, while simultaneously improving\nthe working conditions of crowd workers.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 20:35:14 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Sanga", "Sainath", ""], ["Nadendla", "Venkata Sriram Siddhardh", ""]]}, {"id": "2106.02711", "submitter": "Wamiq Reyaz Para", "authors": "Wamiq Reyaz Para, Shariq Farooq Bhat, Paul Guerrero, Tom Kelly, Niloy\n  Mitra, Leonidas Guibas, Peter Wonka", "title": "SketchGen: Generating Constrained CAD Sketches", "comments": "21 pages, 12 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.GR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Computer-aided design (CAD) is the most widely used modeling approach for\ntechnical design. The typical starting point in these designs is 2D sketches\nwhich can later be extruded and combined to obtain complex three-dimensional\nassemblies. Such sketches are typically composed of parametric primitives, such\nas points, lines, and circular arcs, augmented with geometric constraints\nlinking the primitives, such as coincidence, parallelism, or orthogonality.\nSketches can be represented as graphs, with the primitives as nodes and the\nconstraints as edges. Training a model to automatically generate CAD sketches\ncan enable several novel workflows, but is challenging due to the complexity of\nthe graphs and the heterogeneity of the primitives and constraints. In\nparticular, each type of primitive and constraint may require a record of\ndifferent size and parameter types. We propose SketchGen as a generative model\nbased on a transformer architecture to address the heterogeneity problem by\ncarefully designing a sequential language for the primitives and constraints\nthat allows distinguishing between different primitive or constraint types and\ntheir parameters, while encouraging our model to re-use information across\nrelated parameters, encoding shared structure. A particular highlight of our\nwork is the ability to produce primitives linked via constraints that enables\nthe final output to be further regularized via a constraint solver. We evaluate\nour model by demonstrating constraint prediction for given sets of primitives\nand full sketch generation from scratch, showing that our approach\nsignificantly out performs the state-of-the-art in CAD sketch generation.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 20:45:03 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Para", "Wamiq Reyaz", ""], ["Bhat", "Shariq Farooq", ""], ["Guerrero", "Paul", ""], ["Kelly", "Tom", ""], ["Mitra", "Niloy", ""], ["Guibas", "Leonidas", ""], ["Wonka", "Peter", ""]]}, {"id": "2106.02745", "submitter": "Yaodong Yang Mr.", "authors": "Xidong Feng, Oliver Slumbers, Yaodong Yang, Ziyu Wan, Bo Liu, Stephen\n  McAleer, Ying Wen, Jun Wang", "title": "Discovering Multi-Agent Auto-Curricula in Two-Player Zero-Sum Games", "comments": "corresponding to <yaodong.yang@outlook.com>", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When solving two-player zero-sum games, multi-agent reinforcement learning\n(MARL) algorithms often create populations of agents where, at each iteration,\na new agent is discovered as the best response to a mixture over the opponent\npopulation. Within such a process, the update rules of \"who to compete with\"\n(i.e., the opponent mixture) and \"how to beat them\" (i.e., finding best\nresponses) are underpinned by manually developed game theoretical principles\nsuch as fictitious play and Double Oracle. In this paper we introduce a\nframework, LMAC, based on meta-gradient descent that automates the discovery of\nthe update rule without explicit human design. Specifically, we parameterise\nthe opponent selection module by neural networks and the best-response module\nby optimisation subroutines, and update their parameters solely via interaction\nwith the game engine, where both players aim to minimise their exploitability.\nSurprisingly, even without human design, the discovered MARL algorithms achieve\ncompetitive or even better performance with the state-of-the-art\npopulation-based game solvers (e.g., PSRO) on Games of Skill, differentiable\nLotto, non-transitive Mixture Games, Iterated Matching Pennies, and Kuhn Poker.\nAdditionally, we show that LMAC is able to generalise from small games to large\ngames, for example training on Kuhn Poker and outperforming PSRO on Leduc\nPoker. Our work inspires a promising future direction to discover general MARL\nalgorithms solely from data.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 22:30:25 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Feng", "Xidong", ""], ["Slumbers", "Oliver", ""], ["Yang", "Yaodong", ""], ["Wan", "Ziyu", ""], ["Liu", "Bo", ""], ["McAleer", "Stephen", ""], ["Wen", "Ying", ""], ["Wang", "Jun", ""]]}, {"id": "2106.02750", "submitter": "Gokce Keskin", "authors": "Gokce Keskin, Minhua Wu, Brian King, Harish Mallidi, Yang Gao, Jasha\n  Droppo, Ariya Rastrow, Roland Maas", "title": "Do You Listen with One or Two Microphones? A Unified ASR Model for\n  Single and Multi-Channel Audio", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speech recognition (ASR) models are typically designed to operate\non a single input data type, e.g. a single or multi-channel audio streamed from\na device. This design decision assumes the primary input data source does not\nchange and if an additional (auxiliary) data source is occasionally available,\nit cannot be used. An ASR model that operates on both primary and auxiliary\ndata can achieve better accuracy compared to a primary-only solution; and a\nmodel that can serve both primary-only (PO) and primary-plus-auxiliary (PPA)\nmodes is highly desirable. In this work, we propose a unified ASR model that\ncan serve both modes. We demonstrate its efficacy in a realistic scenario where\na set of devices typically stream a single primary audio channel, and two\nadditional auxiliary channels only when upload bandwidth allows it. The\narchitecture enables a unique methodology that uses both types of input audio\nduring training time. Our proposed approach achieves up to 12.5% relative\nword-error-rate reduction (WERR) compared to a PO baseline, and up to 16.0%\nrelative WERR in low-SNR conditions. The unique training methodology achieves\nup to 2.5% relative WERR compared to a PPA baseline.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 22:58:42 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 23:56:42 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Keskin", "Gokce", ""], ["Wu", "Minhua", ""], ["King", "Brian", ""], ["Mallidi", "Harish", ""], ["Gao", "Yang", ""], ["Droppo", "Jasha", ""], ["Rastrow", "Ariya", ""], ["Maas", "Roland", ""]]}, {"id": "2106.02757", "submitter": "Ching-An Cheng", "authors": "Ching-An Cheng, Andrey Kolobov, Adith Swaminathan", "title": "Heuristic-Guided Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a framework for accelerating reinforcement learning (RL)\nalgorithms by heuristics constructed from domain knowledge or offline data.\nTabula rasa RL algorithms require environment interactions or computation that\nscales with the horizon of the sequential decision-making task. Using our\nframework, we show how heuristic-guided RL induces a much shorter-horizon\nsubproblem that provably solves the original task. Our framework can be viewed\nas a horizon-based regularization for controlling bias and variance in RL under\na finite interaction budget. On the theoretical side, we characterize\nproperties of a good heuristic and its impact on RL acceleration. In\nparticular, we introduce the novel concept of an \"improvable heuristic\" -- a\nheuristic that allows an RL agent to extrapolate beyond its prior knowledge. On\nthe empirical side, we instantiate our framework to accelerate several\nstate-of-the-art algorithms in simulated robotic control tasks and procedurally\ngenerated games. Our framework complements the rich literature on warm-starting\nRL with expert demonstrations or exploratory datasets, and introduces a\nprincipled method for injecting prior knowledge into RL.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 00:04:09 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Cheng", "Ching-An", ""], ["Kolobov", "Andrey", ""], ["Swaminathan", "Adith", ""]]}, {"id": "2106.02782", "submitter": "Fei Wen", "authors": "Zeyu Yan, Fei Wen, Rendong Ying, Chao Ma, and Peilin Liu", "title": "On Perceptual Lossy Compression: The Cost of Perceptual Reconstruction\n  and An Optimal Training Framework", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": "Accepted by ICML 2021", "categories": "cs.IT cs.AI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lossy compression algorithms are typically designed to achieve the lowest\npossible distortion at a given bit rate. However, recent studies show that\npursuing high perceptual quality would lead to increase of the lowest\nachievable distortion (e.g., MSE). This paper provides nontrivial results\ntheoretically revealing that, \\textit{1}) the cost of achieving perfect\nperception quality is exactly a doubling of the lowest achievable MSE\ndistortion, \\textit{2}) an optimal encoder for the \"classic\" rate-distortion\nproblem is also optimal for the perceptual compression problem, \\textit{3})\ndistortion loss is unnecessary for training a perceptual decoder. Further, we\npropose a novel training framework to achieve the lowest MSE distortion under\nperfect perception constraint at a given bit rate. This framework uses a GAN\nwith discriminator conditioned on an MSE-optimized encoder, which is superior\nover the traditional framework using distortion plus adversarial loss.\nExperiments are provided to verify the theoretical finding and demonstrate the\nsuperiority of the proposed training framework.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 02:53:38 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Yan", "Zeyu", ""], ["Wen", "Fei", ""], ["Ying", "Rendong", ""], ["Ma", "Chao", ""], ["Liu", "Peilin", ""]]}, {"id": "2106.02791", "submitter": "Jacob John Johnson", "authors": "Jacob J. Johnson, Linjun Li, Ahmed H. Qureshi, and Michael C. Yip", "title": "Motion Planning Transformers: One Model to Plan Them All", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Transformers have become the powerhouse of natural language processing and\nrecently found use in computer vision tasks. Their effective use of attention\ncan be used in other contexts as well, and in this paper, we propose a\ntransformer-based approach for efficiently solving the complex motion planning\nproblems. Traditional neural network-based motion planning uses convolutional\nnetworks to encode the planning space, but these methods are limited to fixed\nmap sizes, which is often not realistic in the real-world. Our approach first\nidentifies regions on the map using transformers to provide attention to map\nareas likely to include the best path, and then applies local planners to\ngenerate the final collision-free path. We validate our method on a variety of\nrandomly generated environments with different map sizes, demonstrating\nreduction in planning complexity and achieving comparable accuracy to\ntraditional planners.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 04:29:16 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Johnson", "Jacob J.", ""], ["Li", "Linjun", ""], ["Qureshi", "Ahmed H.", ""], ["Yip", "Michael C.", ""]]}, {"id": "2106.02793", "submitter": "Guruprasad Raghavan", "authors": "Guruprasad Raghavan, Matt Thomson", "title": "Solving hybrid machine learning tasks by traversing weight space\n  geodesics", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning problems have an intrinsic geometric structure as central\nobjects including a neural network's weight space and the loss function\nassociated with a particular task can be viewed as encoding the intrinsic\ngeometry of a given machine learning problem. Therefore, geometric concepts can\nbe applied to analyze and understand theoretical properties of machine learning\nstrategies as well as to develop new algorithms. In this paper, we address\nthree seemingly unrelated open questions in machine learning by viewing them\nthrough a unified framework grounded in differential geometry. Specifically, we\nview the weight space of a neural network as a manifold endowed with a\nRiemannian metric that encodes performance on specific tasks. By defining a\nmetric, we can construct geodesic, minimum length, paths in weight space that\nrepresent sets of networks of equivalent or near equivalent functional\nperformance on a specific task. We, then, traverse geodesic paths while\nidentifying networks that satisfy a second objective. Inspired by the geometric\ninsight, we apply our geodesic framework to 3 major applications: (i) Network\nsparsification (ii) Mitigating catastrophic forgetting by constructing networks\nwith high performance on a series of objectives and (iii) Finding high-accuracy\npaths connecting distinct local optima of deep networks in the non-convex loss\nlandscape. Our results are obtained on a wide range of network architectures\n(MLP, VGG11/16) trained on MNIST, CIFAR-10/100. Broadly, we introduce a\ngeometric framework that unifies a range of machine learning objectives and\nthat can be applied to multiple classes of neural network architectures.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 04:37:03 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Raghavan", "Guruprasad", ""], ["Thomson", "Matt", ""]]}, {"id": "2106.02795", "submitter": "Yang Li", "authors": "Yang Li, Si Si, Gang Li, Cho-Jui Hsieh, Samy Bengio", "title": "Learnable Fourier Features for Multi-Dimensional Spatial Positional\n  Encoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attentional mechanisms are order-invariant. Positional encoding is a crucial\ncomponent to allow attention-based deep model architectures such as Transformer\nto address sequences or images where the position of information matters. In\nthis paper, we propose a novel positional encoding method based on learnable\nFourier features. Instead of hard-coding each position as a token or a vector,\nwe represent each position, which can be multi-dimensional, as a trainable\nencoding based on learnable Fourier feature mapping, modulated with a\nmulti-layer perceptron. The representation is particularly advantageous for a\nspatial multi-dimensional position, e.g., pixel positions on an image, where\n$L_2$ distances or more complex positional relationships need to be captured.\nOur experiments based on several public benchmark tasks show that our learnable\nFourier feature representation for multi-dimensional positional encoding\noutperforms existing methods by both improving the accuracy and allowing faster\nconvergence.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 04:40:18 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 19:32:53 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Li", "Yang", ""], ["Si", "Si", ""], ["Li", "Gang", ""], ["Hsieh", "Cho-Jui", ""], ["Bengio", "Samy", ""]]}, {"id": "2106.02801", "submitter": "Yashwanth Kumar Nakka", "authors": "Yashwanth Kumar Nakka and Soon-Jo Chung", "title": "Trajectory Optimization of Chance-Constrained Nonlinear Stochastic\n  Systems for Motion Planning and Control", "comments": "submitted to IEEE Transactions on Robotics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY eess.SY math.OC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present gPC-SCP: Generalized Polynomial Chaos-based Sequential Convex\nProgramming method to compute a sub-optimal solution for a continuous-time\nchance-constrained stochastic nonlinear optimal control problem (SNOC) problem.\nThe approach enables motion planning and control of robotic systems under\nuncertainty. The proposed method involves two steps. The first step is to\nderive a deterministic nonlinear optimal control problem (DNOC) with convex\nconstraints that are surrogate to the SNOC by using gPC expansion and the\ndistributionally-robust convex subset of the chance constraints. The second\nstep is to solve the DNOC problem using sequential convex programming (SCP) for\ntrajectory generation and control. We prove that in the unconstrained case, the\noptimal value of the DNOC converges to that of SNOC asymptotically and that any\nfeasible solution of the constrained DNOC is a feasible solution of the\nchance-constrained SNOC. We derive a stable stochastic model predictive\ncontroller using the gPC-SCP for tracking a trajectory in the presence of\nuncertainty. We empirically demonstrate the efficacy of the gPC-SCP method for\nthe following three test cases: 1) collision checking under uncertainty in\nactuation, 2) collision checking with stochastic obstacle model, and 3) safe\ntrajectory tracking under uncertainty in the dynamics and obstacle location by\nusing a receding horizon control approach. We validate the effectiveness of the\ngPC-SCP method on the robotic spacecraft testbed.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 05:15:05 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Nakka", "Yashwanth Kumar", ""], ["Chung", "Soon-Jo", ""]]}, {"id": "2106.02817", "submitter": "Liang Qu", "authors": "Liang Qu, Huaisheng Zhu, Ruiqi Zheng, Yuhui Shi, Hongzhi Yin", "title": "ImGAGN:Imbalanced Network Embedding via Generative Adversarial Graph\n  Networks", "comments": "to be published in KDD'2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imbalanced classification on graphs is ubiquitous yet challenging in many\nreal-world applications, such as fraudulent node detection. Recently, graph\nneural networks (GNNs) have shown promising performance on many network\nanalysis tasks. However, most existing GNNs have almost exclusively focused on\nthe balanced networks, and would get unappealing performance on the imbalanced\nnetworks. To bridge this gap, in this paper, we present a generative\nadversarial graph network model, called ImGAGN to address the imbalanced\nclassification problem on graphs. It introduces a novel generator for graph\nstructure data, named GraphGenerator, which can simulate both the minority\nclass nodes' attribute distribution and network topological structure\ndistribution by generating a set of synthetic minority nodes such that the\nnumber of nodes in different classes can be balanced. Then a graph\nconvolutional network (GCN) discriminator is trained to discriminate between\nreal nodes and fake (i.e., generated) nodes, and also between minority nodes\nand majority nodes on the synthetic balanced network. To validate the\neffectiveness of the proposed method, extensive experiments are conducted on\nfour real-world imbalanced network datasets. Experimental results demonstrate\nthat the proposed method ImGAGN outperforms state-of-the-art algorithms for\nsemi-supervised imbalanced node classification task.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 06:56:37 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Qu", "Liang", ""], ["Zhu", "Huaisheng", ""], ["Zheng", "Ruiqi", ""], ["Shi", "Yuhui", ""], ["Yin", "Hongzhi", ""]]}, {"id": "2106.02820", "submitter": "Zaixi Zhang", "authors": "Zaixi Zhang, Qi Liu, Zhenya Huang, Hao Wang, Chengqiang Lu, Chuanren\n  Liu, Enhong Chen", "title": "GraphMI: Extracting Private Graph Data from Graph Neural Networks", "comments": "7 pages, 6 figures, accepted by IJCAI'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning becomes more widely used for critical applications, the\nneed to study its implications in privacy turns to be urgent. Given access to\nthe target model and auxiliary information, the model inversion attack aims to\ninfer sensitive features of the training dataset, which leads to great privacy\nconcerns. Despite its success in grid-like domains, directly applying model\ninversion techniques on non-grid domains such as graph achieves poor attack\nperformance due to the difficulty to fully exploit the intrinsic properties of\ngraphs and attributes of nodes used in Graph Neural Networks (GNN). To bridge\nthis gap, we present \\textbf{Graph} \\textbf{M}odel \\textbf{I}nversion attack\n(GraphMI), which aims to extract private graph data of the training graph by\ninverting GNN, one of the state-of-the-art graph analysis tools. Specifically,\nwe firstly propose a projected gradient module to tackle the discreteness of\ngraph edges while preserving the sparsity and smoothness of graph features.\nThen we design a graph auto-encoder module to efficiently exploit graph\ntopology, node attributes, and target model parameters for edge inference. With\nthe proposed methods, we study the connection between model inversion risk and\nedge influence and show that edges with greater influence are more likely to be\nrecovered. Extensive experiments over several public datasets demonstrate the\neffectiveness of our method. We also show that differential privacy in its\ncanonical form can hardly defend our attack while preserving decent utility.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 07:07:52 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Zhang", "Zaixi", ""], ["Liu", "Qi", ""], ["Huang", "Zhenya", ""], ["Wang", "Hao", ""], ["Lu", "Chengqiang", ""], ["Liu", "Chuanren", ""], ["Chen", "Enhong", ""]]}, {"id": "2106.02835", "submitter": "Jie Qiao", "authors": "Ruichu Cai, Weilin Chen, Jie Qiao, Zhifeng Hao", "title": "On the Role of Entropy-based Loss for Learning Causal Structures with\n  Continuous Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Causal discovery from observational data is an important but challenging task\nin many scientific fields. Recently, NOTEARS [Zheng et al., 2018] formulates\nthe causal structure learning problem as a continuous optimization problem\nusing least-square loss with an acyclicity constraint. Though the least-square\nloss function is well justified under the standard Gaussian noise assumption,\nit is limited if the assumption does not hold. In this work, we theoretically\nshow that the violation of the Gaussian noise assumption will hinder the causal\ndirection identification, making the causal orientation fully determined by the\ncausal strength as well as the variances of noises in the linear case and the\nnoises of strong non-Gaussianity in the nonlinear case. Consequently, we\npropose a more general entropy-based loss that is theoretically consistent with\nthe likelihood score under any noise distribution. We run extensive empirical\nevaluations on both synthetic data and real-world data to validate the\neffectiveness of the proposed method and show that our method achieves the best\nin Structure Hamming Distance, False Discovery Rate, and True Positive Rate\nmatrices.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 08:29:51 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 08:07:53 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Cai", "Ruichu", ""], ["Chen", "Weilin", ""], ["Qiao", "Jie", ""], ["Hao", "Zhifeng", ""]]}, {"id": "2106.02856", "submitter": "Sharmin Pathan", "authors": "Sharmin Pathan, Vyom Shrivastava", "title": "Reinforcement Learning for Assignment Problem with Time Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an end-to-end framework for the Assignment Problem with multiple\ntasks mapped to a group of workers, using reinforcement learning while\npreserving many constraints. Tasks and workers have time constraints and there\nis a cost associated with assigning a worker to a task. Each worker can perform\nmultiple tasks until it exhausts its allowed time units (capacity). We train a\nreinforcement learning agent to find near optimal solutions to the problem by\nminimizing total cost associated with the assignments while maintaining hard\nconstraints. We use proximal policy optimization to optimize model parameters.\nThe model generates a sequence of actions in real-time which correspond to task\nassignment to workers, without having to retrain for changes in the dynamic\nstate of the environment. In our problem setting reward is computed as negative\nof the assignment cost. We also demonstrate our results on bin packing and\ncapacitated vehicle routing problem, using the same framework. Our results\noutperform Google OR-Tools using MIP and CP-SAT solvers with large problem\ninstances, in terms of solution quality and computation time.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 10:10:52 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Pathan", "Sharmin", ""], ["Shrivastava", "Vyom", ""]]}, {"id": "2106.02864", "submitter": "Suvidha Tripathi Dr", "authors": "Suvidha Tripathi, Satish Kumar Singh, Hwee Kuan Lee", "title": "An End-to-End Breast Tumour Classification Model Using Context-Based\n  Patch Modelling- A BiLSTM Approach for Image Classification", "comments": "36 pages, 5 figures, 9 tables. Published in Computerized Medical\n  Imaging and Graphics", "journal-ref": "Computerized Medical Imaging and Graphics, 87, 101838 (2021)", "doi": "10.1016/j.compmedimag.2020.101838", "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers working on computational analysis of Whole Slide Images (WSIs) in\nhistopathology have primarily resorted to patch-based modelling due to large\nresolution of each WSI. The large resolution makes WSIs infeasible to be fed\ndirectly into the machine learning models due to computational constraints.\nHowever, due to patch-based analysis, most of the current methods fail to\nexploit the underlying spatial relationship among the patches. In our work, we\nhave tried to integrate this relationship along with feature-based correlation\namong the extracted patches from the particular tumorous region. For the given\ntask of classification, we have used BiLSTMs to model both forward and backward\ncontextual relationship. RNN based models eliminate the limitation of sequence\nsize by allowing the modelling of variable size images within a deep learning\nmodel. We have also incorporated the effect of spatial continuity by exploring\ndifferent scanning techniques used to sample patches. To establish the\nefficiency of our approach, we trained and tested our model on two datasets,\nmicroscopy images and WSI tumour regions. After comparing with contemporary\nliterature we achieved the better performance with accuracy of 90% for\nmicroscopy image dataset. For WSI tumour region dataset, we compared the\nclassification results with deep learning networks such as ResNet, DenseNet,\nand InceptionV3 using maximum voting technique. We achieved the highest\nperformance accuracy of 84%. We found out that BiLSTMs with CNN features have\nperformed much better in modelling patches into an end-to-end Image\nclassification network. Additionally, the variable dimensions of WSI tumour\nregions were used for classification without the need for resizing. This\nsuggests that our method is independent of tumour image size and can process\nlarge dimensional images without losing the resolution details.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 10:43:58 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Tripathi", "Suvidha", ""], ["Singh", "Satish Kumar", ""], ["Lee", "Hwee Kuan", ""]]}, {"id": "2106.02921", "submitter": "Mikhail Jacob", "authors": "Mikhail Jacob, Brian Magerko", "title": "Empirically Evaluating Creative Arc Negotiation for Improvisational\n  Decision-making", "comments": "10 pages, 5 figures, 8 tables, accepted to ACM Creativity & Cognition\n  2021, Best Paper Award", "journal-ref": null, "doi": "10.1145/3450741.3465263", "report-no": null, "categories": "cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Action selection from many options with few constraints is crucial for\nimprovisation and co-creativity. Our previous work proposed creative arc\nnegotiation to solve this problem, i.e., selecting actions to follow an\nauthor-defined `creative arc' or trajectory over estimates of novelty,\nunexpectedness, and quality for potential actions. The CARNIVAL agent\narchitecture demonstrated this approach for playing the Props game from improv\ntheatre in the Robot Improv Circus installation. This article evaluates the\ncreative arc negotiation experience with CARNIVAL through two crowdsourced\nobserver studies and one improviser laboratory study. The studies focus on\nsubjects' ability to identify creative arcs in performance and their preference\nfor creative arc negotiation compared to a random selection baseline. Our\nresults show empirically that observers successfully identified creative arcs\nin performances. Both groups also preferred creative arc negotiation in agent\ncreativity and logical coherence, while observers enjoyed it more too.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 15:20:36 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Jacob", "Mikhail", ""], ["Magerko", "Brian", ""]]}, {"id": "2106.02926", "submitter": "Won-Yong Shin", "authors": "Cong Tran, Won-Yong Shin, Andreas Spitz", "title": "IM-META: Influence Maximization Using Node Metadata in Networks With\n  Unknown Topology", "comments": "14 pages, 12 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.IT cs.LG cs.NE math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In real-world applications of influence maximization (IM), the network\nstructure is often unknown. In this case, we may identify the most influential\nseed nodes by exploring only a part of the underlying network given a small\nbudget for node queries. Motivated by the fact that collecting node metadata is\nmore cost-effective than investigating the relationship between nodes via\nqueried nodes, we develop IM-META, an end-to-end solution to IM in networks\nwith unknown topology by retrieving information from both queries and node\nmetadata. However, using such metadata to aid the IM process is not without\nrisk due to the noisy nature of metadata and uncertainties in connectivity\ninference. To tackle these challenges, we formulate an IM problem that aims to\nfind two sets, i.e., seed nodes and queried nodes. We propose an effective\nmethod that iteratively performs three steps: 1) we learn the relationship\nbetween collected metadata and edges via a Siamese neural network model, 2) we\nselect a number of inferred influential edges to construct a reinforced graph\nused for discovering an optimal seed set, and 3) we identify the next node to\nquery by maximizing the inferred influence spread using a topology-aware\nranking strategy. By querying only 5% of nodes, IM-META reaches 93% of the\nupper bound performance.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 16:11:02 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Tran", "Cong", ""], ["Shin", "Won-Yong", ""], ["Spitz", "Andreas", ""]]}, {"id": "2106.02930", "submitter": "Jiachen Li", "authors": "Defu Cao and Jiachen Li and Hengbo Ma and Masayoshi Tomizuka", "title": "Spectral Temporal Graph Neural Network for Trajectory Prediction", "comments": "ICRA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An effective understanding of the contextual environment and accurate motion\nforecasting of surrounding agents is crucial for the development of autonomous\nvehicles and social mobile robots. This task is challenging since the behavior\nof an autonomous agent is not only affected by its own intention, but also by\nthe static environment and surrounding dynamically interacting agents. Previous\nworks focused on utilizing the spatial and temporal information in time domain\nwhile not sufficiently taking advantage of the cues in frequency domain. To\nthis end, we propose a Spectral Temporal Graph Neural Network (SpecTGNN), which\ncan capture inter-agent correlations and temporal dependency simultaneously in\nfrequency domain in addition to time domain. SpecTGNN operates on both an agent\ngraph with dynamic state information and an environment graph with the features\nextracted from context images in two streams. The model integrates graph\nFourier transform, spectral graph convolution and temporal gated convolution to\nencode history information and forecast future trajectories. Moreover, we\nincorporate a multi-head spatio-temporal attention mechanism to mitigate the\neffect of error propagation in a long time horizon. We demonstrate the\nperformance of SpecTGNN on two public trajectory prediction benchmark datasets,\nwhich achieves state-of-the-art performance in terms of prediction accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 16:51:54 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Cao", "Defu", ""], ["Li", "Jiachen", ""], ["Ma", "Hengbo", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "2106.02940", "submitter": "Samuel Kessler", "authors": "Samuel Kessler, Jack Parker-Holder, Philip Ball, Stefan Zohren,\n  Stephen J. Roberts", "title": "Same State, Different Task: Continual Reinforcement Learning without\n  Interference", "comments": "20 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Continual Learning (CL) considers the problem of training an agent\nsequentially on a set of tasks while seeking to retain performance on all\nprevious tasks. A key challenge in CL is catastrophic forgetting, which arises\nwhen performance on a previously mastered task is reduced when learning a new\ntask. While a variety of methods exist to combat forgetting, in some cases\ntasks are fundamentally incompatible with each other and thus cannot be learnt\nby a single policy. This can occur, in reinforcement learning (RL) when an\nagent may be rewarded for achieving different goals from the same observation.\nIn this paper we formalize this ``interference'' as distinct from the problem\nof forgetting. We show that existing CL methods based on single neural network\npredictors with shared replay buffers fail in the presence of interference.\nInstead, we propose a simple method, OWL, to address this challenge. OWL learns\na factorized policy, using shared feature extraction layers, but separate\nheads, each specializing on a new task. The separate heads in OWL are used to\nprevent interference. At test time, we formulate policy selection as a\nmulti-armed bandit problem, and show it is possible to select the best policy\nfor an unknown task using feedback from the environment. The use of bandit\nalgorithms allows the OWL agent to constructively re-use different continually\nlearnt policies at different times during an episode. We show in multiple RL\nenvironments that existing replay based CL methods fail, while OWL is able to\nachieve close to optimal performance when training sequentially.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 17:55:10 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Kessler", "Samuel", ""], ["Parker-Holder", "Jack", ""], ["Ball", "Philip", ""], ["Zohren", "Stefan", ""], ["Roberts", "Stephen J.", ""]]}, {"id": "2106.02948", "submitter": "Yu Takagi", "authors": "Yu Takagi, Laurence T. Hunt, Ryu Ohata, Hiroshi Imamizu, Jun-ichiro\n  Hirayama", "title": "Neural dSCA: demixing multimodal interaction among brain areas during\n  naturalistic experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-regional interaction among neuronal populations underlies the brain's\nprocessing of rich sensory information in our daily lives. Recent neuroscience\nand neuroimaging studies have increasingly used naturalistic stimuli and\nexperimental design to identify such realistic sensory computation in the\nbrain. However, existing methods for cross-areal interaction analysis with\ndimensionality reduction, such as reduced-rank regression and canonical\ncorrelation analysis, have limited applicability and interpretability in\nnaturalistic settings because they usually do not appropriately 'demix' neural\ninteractions into those associated with different types of task parameters or\nstimulus features (e.g., visual or audio). In this paper, we develop a new\nmethod for cross-areal interaction analysis that uses the rich task or stimulus\nparameters to reveal how and what types of information are shared by different\nneural populations. The proposed neural demixed shared component analysis\ncombines existing dimensionality reduction methods with a practical neural\nnetwork implementation of functional analysis of variance with latent\nvariables, thereby efficiently demixing nonlinear effects of continuous and\nmultimodal stimuli. We also propose a simplifying alternative under the\nassumptions of linear effects and unimodal stimuli. To demonstrate our methods,\nwe analyzed two human neuroimaging datasets of participants watching\nnaturalistic videos of movies and dance movements. The results demonstrate that\nour methods provide new insights into multi-regional interaction in the brain\nduring naturalistic sensory inputs, which cannot be captured by conventional\ntechniques.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 19:16:21 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Takagi", "Yu", ""], ["Hunt", "Laurence T.", ""], ["Ohata", "Ryu", ""], ["Imamizu", "Hiroshi", ""], ["Hirayama", "Jun-ichiro", ""]]}, {"id": "2106.02951", "submitter": "Ismail Alkhouri", "authors": "Alvaro Velasquez, Ashutosh Trivedi, Ismail Alkhouri, Andre Beckus, and\n  George Atia", "title": "Controller Synthesis for Omega-Regular and Steady-State Specifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a Markov decision process (MDP) and a linear-time ($\\omega$-regular or\nLTL) specification, the controller synthesis problem aims to compute the\noptimal policy that satisfies the specification. More recently, problems that\nreason over the asymptotic behavior of systems have been proposed through the\nlens of steady-state planning. This entails finding a control policy for an MDP\nsuch that the Markov chain induced by the solution policy satisfies a given set\nof constraints on its steady-state distribution. This paper studies a\ngeneralization of the controller synthesis problem for a linear-time\nspecification under steady-state constraints on the asymptotic behavior. We\npresent an algorithm to find a deterministic policy satisfying $\\omega$-regular\nand steady-state constraints by characterizing the solutions as an integer\nlinear program, and experimentally evaluate our approach.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 19:34:22 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Velasquez", "Alvaro", ""], ["Trivedi", "Ashutosh", ""], ["Alkhouri", "Ismail", ""], ["Beckus", "Andre", ""], ["Atia", "George", ""]]}, {"id": "2106.02972", "submitter": "Prasoon Goyal", "authors": "Prasoon Goyal, Raymond J. Mooney, Scott Niekum", "title": "Zero-shot Task Adaptation using Natural Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning and instruction-following are two common approaches to\ncommunicate a user's intent to a learning agent. However, as the complexity of\ntasks grows, it could be beneficial to use both demonstrations and language to\ncommunicate with an agent. In this work, we propose a novel setting where an\nagent is given both a demonstration and a description, and must combine\ninformation from both the modalities. Specifically, given a demonstration for a\ntask (the source task), and a natural language description of the differences\nbetween the demonstrated task and a related but different task (the target\ntask), our goal is to train an agent to complete the target task in a zero-shot\nsetting, that is, without any demonstrations for the target task. To this end,\nwe introduce Language-Aided Reward and Value Adaptation (LARVA) which, given a\nsource demonstration and a linguistic description of how the target task\ndiffers, learns to output a reward / value function that accurately describes\nthe target task. Our experiments show that on a diverse set of adaptations, our\napproach is able to complete more than 95% of target tasks when using\ntemplate-based descriptions, and more than 70% when using free-form natural\nlanguage.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 21:39:04 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Goyal", "Prasoon", ""], ["Mooney", "Raymond J.", ""], ["Niekum", "Scott", ""]]}, {"id": "2106.02997", "submitter": "Atticus Geiger", "authors": "Atticus Geiger, Hanson Lu, Thomas Icard, Christopher Potts", "title": "Causal Abstractions of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Structural analysis methods (e.g., probing and feature attribution) are\nincreasingly important tools for neural network analysis. We propose a new\nstructural analysis method grounded in a formal theory of \\textit{causal\nabstraction} that provides rich characterizations of model-internal\nrepresentations and their roles in input/output behavior. In this method,\nneural representations are aligned with variables in interpretable causal\nmodels, and then \\textit{interchange interventions} are used to experimentally\nverify that the neural representations have the causal properties of their\naligned variables. We apply this method in a case study to analyze neural\nmodels trained on Multiply Quantified Natural Language Inference (MQNLI)\ncorpus, a highly complex NLI dataset that was constructed with a\ntree-structured natural logic causal model. We discover that a BERT-based model\nwith state-of-the-art performance successfully realizes the approximate causal\nstructure of the natural logic causal model, whereas a simpler baseline model\nfails to show any such structure, demonstrating that neural representations\nencode the compositional structure of MQNLI examples.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 01:07:43 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Geiger", "Atticus", ""], ["Lu", "Hanson", ""], ["Icard", "Thomas", ""], ["Potts", "Christopher", ""]]}, {"id": "2106.03016", "submitter": "Satoru Watanabe", "authors": "Satoru Watanabe, Hayato Yamana", "title": "Topological Measurement of Deep Neural Networks Using Persistent\n  Homology", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inner representation of deep neural networks (DNNs) is indecipherable,\nwhich makes it difficult to tune DNN models, control their training process,\nand interpret their outputs. In this paper, we propose a novel approach to\ninvestigate the inner representation of DNNs through topological data analysis\n(TDA). Persistent homology (PH), one of the outstanding methods in TDA, was\nemployed for investigating the complexities of trained DNNs. We constructed\nclique complexes on trained DNNs and calculated the one-dimensional PH of DNNs.\nThe PH reveals the combinational effects of multiple neurons in DNNs at\ndifferent resolutions, which is difficult to be captured without using PH.\nEvaluations were conducted using fully connected networks (FCNs) and networks\ncombining FCNs and convolutional neural networks (CNNs) trained on the MNIST\nand CIFAR-10 data sets. Evaluation results demonstrate that the PH of DNNs\nreflects both the excess of neurons and problem difficulty, making PH one of\nthe prominent methods for investigating the inner representation of DNNs.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 03:06:15 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Watanabe", "Satoru", ""], ["Yamana", "Hayato", ""]]}, {"id": "2106.03028", "submitter": "Raghavendra Addanki", "authors": "Raghavendra Addanki, Shiva Prasad Kasiviswanathan", "title": "Collaborative Causal Discovery with Atomic Interventions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new Collaborative Causal Discovery problem, through which we\nmodel a common scenario in which we have multiple independent entities each\nwith their own causal graph, and the goal is to simultaneously learn all these\ncausal graphs. We study this problem without the causal sufficiency assumption,\nusing Maximal Ancestral Graphs (MAG) to model the causal graphs, and assuming\nthat we have the ability to actively perform independent single vertex (or\natomic) interventions on the entities. If the $M$ underlying (unknown) causal\ngraphs of the entities satisfy a natural notion of clustering, we give\nalgorithms that leverage this property and recovers all the causal graphs using\nroughly logarithmic in $M$ number of atomic interventions per entity. These are\nsignificantly fewer than $n$ atomic interventions per entity required to learn\neach causal graph separately, where $n$ is the number of observable nodes in\nthe causal graph. We complement our results with a lower bound and discuss\nvarious extensions of our collaborative setting.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 04:30:29 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Addanki", "Raghavendra", ""], ["Kasiviswanathan", "Shiva Prasad", ""]]}, {"id": "2106.03035", "submitter": "Koya Ishikawa", "authors": "Koya Ishikawa and Kazuhide Nakata", "title": "Online Trading Models in the Forex Market Considering Transaction Costs", "comments": "7 pages, 2 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, a wide range of investment models have been created using\nartificial intelligence. Automatic trading by artificial intelligence can\nexpand the range of trading methods, such as by conferring the ability to\noperate 24 hours a day and the ability to trade with high frequency. Automatic\ntrading can also be expected to trade with more information than is available\nto humans if it can sufficiently consider past data. In this paper, we propose\nan investment agent based on a deep reinforcement learning model, which is an\nartificial intelligence model. The model considers the transaction costs\ninvolved in actual trading and creates a framework for trading over a long\nperiod of time so that it can make a large profit on a single trade. In doing\nso, it can maximize the profit while keeping transaction costs low. In\naddition, in consideration of actual operations, we use online learning so that\nthe system can continue to learn by constantly updating the latest online data\ninstead of learning with static data. This makes it possible to trade in\nnon-stationary financial markets by always incorporating current market trend\ninformation.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 05:36:12 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Ishikawa", "Koya", ""], ["Nakata", "Kazuhide", ""]]}, {"id": "2106.03036", "submitter": "Ritu Gala", "authors": "Ritu Gala, Revathi Vijayaraghavan, Valmik Nikam, Arvind Kiwelekar", "title": "Real-Time Cognitive Evaluation of Online Learners through Automatically\n  Generated Questions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  With the increased adoption of E-learning platforms, keeping online learners\nengaged throughout a lesson is challenging. One approach to tackle this\nchallenge is to probe learn-ers periodically by asking questions. The paper\npresents an approach to generate questions from a given video lecture\nautomatically. The generated questions are aimed to evaluate learners'\nlower-level cognitive abilities. The approach automatically extracts text from\nvideo lectures to generates wh-kinds of questions. When learners respond with\nan answer, the proposed approach further evaluates the response and provides\nfeedback. Besides enhancing learner's engagement, this approach's main benefits\nare that it frees instructors from design-ing questions to check the\ncomprehension of a topic. Thus, instructors can spend this time productively on\nother activities.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 05:45:56 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Gala", "Ritu", ""], ["Vijayaraghavan", "Revathi", ""], ["Nikam", "Valmik", ""], ["Kiwelekar", "Arvind", ""]]}, {"id": "2106.03041", "submitter": "John Cai", "authors": "John Cai, Bill Cai, Shengmei Shen", "title": "DAMSL: Domain Agnostic Meta Score-based Learning", "comments": "Accepted to CVPR 2021 L2ID Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Domain Agnostic Meta Score-based Learning (DAMSL),\na novel, versatile and highly effective solution that delivers significant\nout-performance over state-of-the-art methods for cross-domain few-shot\nlearning. We identify key problems in previous meta-learning methods\nover-fitting to the source domain, and previous transfer-learning methods\nunder-utilizing the structure of the support set. The core idea behind our\nmethod is that instead of directly using the scores from a fine-tuned feature\nencoder, we use these scores to create input coordinates for a domain agnostic\nmetric space. A graph neural network is applied to learn an embedding and\nrelation function over these coordinates to process all information contained\nin the score distribution of the support set. We test our model on both\nestablished CD-FSL benchmarks and new domains and show that our method\novercomes the limitations of previous meta-learning and transfer-learning\nmethods to deliver substantial improvements in accuracy across both smaller and\nlarger domain shifts.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 06:08:05 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Cai", "John", ""], ["Cai", "Bill", ""], ["Shen", "Shengmei", ""]]}, {"id": "2106.03044", "submitter": "Jiayi Liu", "authors": "Wei Wei, Jiayi Liu, Xianling Mao, Guibing Guo, Feida Zhu, Pan Zhou,\n  Yuchong Hu", "title": "Emotion-aware Chat Machine: Automatic Emotional Response Generation for\n  Human-like Emotional Interaction", "comments": "Accepted at CIKM 2019. arXiv admin note: substantial text overlap\n  with arXiv:2011.07432", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The consistency of a response to a given post at semantic-level and\nemotional-level is essential for a dialogue system to deliver human-like\ninteractions. However, this challenge is not well addressed in the literature,\nsince most of the approaches neglect the emotional information conveyed by a\npost while generating responses. This article addresses this problem by\nproposing a unifed end-to-end neural architecture, which is capable of\nsimultaneously encoding the semantics and the emotions in a post for generating\nmore intelligent responses with appropriately expressed emotions. Extensive\nexperiments on real-world data demonstrate that the proposed method outperforms\nthe state-of-the-art methods in terms of both content coherence and emotion\nappropriateness.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 06:26:15 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Wei", "Wei", ""], ["Liu", "Jiayi", ""], ["Mao", "Xianling", ""], ["Guo", "Guibing", ""], ["Zhu", "Feida", ""], ["Zhou", "Pan", ""], ["Hu", "Yuchong", ""]]}, {"id": "2106.03046", "submitter": "Fuli Feng", "authors": "Fuli Feng, Jizhi Zhang, Xiangnan He, Hanwang Zhang, Tat-Seng Chua", "title": "Empowering Language Understanding with Counterfactual Reasoning", "comments": "Accepted by Findings of ACL'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Present language understanding methods have demonstrated extraordinary\nability of recognizing patterns in texts via machine learning. However,\nexisting methods indiscriminately use the recognized patterns in the testing\nphase that is inherently different from us humans who have counterfactual\nthinking, e.g., to scrutinize for the hard testing samples. Inspired by this,\nwe propose a Counterfactual Reasoning Model, which mimics the counterfactual\nthinking by learning from few counterfactual samples. In particular, we devise\na generation module to generate representative counterfactual samples for each\nfactual sample, and a retrospective module to retrospect the model prediction\nby comparing the counterfactual and factual samples. Extensive experiments on\nsentiment analysis (SA) and natural language inference (NLI) validate the\neffectiveness of our method.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 06:36:52 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Feng", "Fuli", ""], ["Zhang", "Jizhi", ""], ["He", "Xiangnan", ""], ["Zhang", "Hanwang", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "2106.03048", "submitter": "Nadav Borenstein", "authors": "Chen Shani, Nadav Borenstein, Dafna Shahaf", "title": "How Did This Get Funded?! Automatically Identifying Quirky Scientific\n  Achievements", "comments": "To be published in the main conference of ACL-IJCNLP2021. Code and\n  dataset can be found here: https://github.com/nadavborenstein/Iggy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Humor is an important social phenomenon, serving complex social and\npsychological functions. However, despite being studied for millennia humor is\ncomputationally not well understood, often considered an AI-complete problem.\nIn this work, we introduce a novel setting in humor mining: automatically\ndetecting funny and unusual scientific papers. We are inspired by the Ig Nobel\nprize, a satirical prize awarded annually to celebrate funny scientific\nachievements (example past winner: \"Are cows more likely to lie down the longer\nthey stand?\"). This challenging task has unique characteristics that make it\nparticularly suitable for automatic learning. We construct a dataset containing\nthousands of funny papers and use it to learn classifiers, combining findings\nfrom psychology and linguistics with recent advances in NLP. We use our models\nto identify potentially funny papers in a large dataset of over 630,000\narticles. The results demonstrate the potential of our methods, and more\nbroadly the utility of integrating state-of-the-art NLP methods with insights\nfrom more traditional disciplines.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 06:54:40 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Shani", "Chen", ""], ["Borenstein", "Nadav", ""], ["Shahaf", "Dafna", ""]]}, {"id": "2106.03051", "submitter": "Junyoung Park", "authors": "Junyoung Park, Sanjar Bakhtiyar, Jinkyoo Park", "title": "ScheduleNet: Learn to solve multi-agent scheduling problems with\n  reinforcement learning", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose ScheduleNet, a RL-based real-time scheduler, that can solve\nvarious types of multi-agent scheduling problems. We formulate these problems\nas a semi-MDP with episodic reward (makespan) and learn ScheduleNet, a\ndecentralized decision-making policy that can effectively coordinate multiple\nagents to complete tasks. The decision making procedure of ScheduleNet\nincludes: (1) representing the state of a scheduling problem with the\nagent-task graph, (2) extracting node embeddings for agent and tasks nodes, the\nimportant relational information among agents and tasks, by employing the\ntype-aware graph attention (TGA), and (3) computing the assignment probability\nwith the computed node embeddings. We validate the effectiveness of ScheduleNet\nas a general learning-based scheduler for solving various types of multi-agent\nscheduling tasks, including multiple salesman traveling problem (mTSP) and job\nshop scheduling problem (JSP).\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 07:08:58 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Park", "Junyoung", ""], ["Bakhtiyar", "Sanjar", ""], ["Park", "Jinkyoo", ""]]}, {"id": "2106.03097", "submitter": "Gihun Lee", "authors": "Gihun Lee, Yongjin Shin, Minchan Jeong, Se-Young Yun", "title": "Preservation of the Global Knowledge by Not-True Self Knowledge\n  Distillation in Federated Learning", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In Federated Learning (FL), a strong global model is collaboratively learned\nby aggregating the clients' locally trained models. Although this allows no\nneed to access clients' data directly, the global model's convergence often\nsuffers from data heterogeneity. This paper suggests that forgetting could be\nthe bottleneck of global convergence. We observe that fitting on biased local\ndistribution shifts the feature on global distribution and results in\nforgetting of global knowledge. We consider this phenomenon as an analogy to\nContinual Learning, which also faces catastrophic forgetting when fitted on the\nnew task distribution. Based on our findings, we hypothesize that tackling down\nthe forgetting in local training relives the data heterogeneity problem. To\nthis end, we propose a simple yet effective framework Federated Local\nSelf-Distillation (FedLSD), which utilizes the global knowledge on locally\navailable data. By following the global perspective on local data, FedLSD\nencourages the learned features to preserve global knowledge and have\nconsistent views across local models, thus improving convergence without\ncompromising data privacy. Under our framework, we further extend FedLSD to\nFedLS-NTD, which only considers the not-true class signals to compensate noisy\nprediction of the global model. We validate that both FedLSD and FedLS-NTD\nsignificantly improve the performance in standard FL benchmarks in various\nsetups, especially in the extreme data heterogeneity cases.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 11:51:47 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Lee", "Gihun", ""], ["Shin", "Yongjin", ""], ["Jeong", "Minchan", ""], ["Yun", "Se-Young", ""]]}, {"id": "2106.03099", "submitter": "Kevin Roth", "authors": "Kevin Roth", "title": "A Primer on Multi-Neuron Relaxation-based Adversarial Robustness\n  Certification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The existence of adversarial examples poses a real danger when deep neural\nnetworks are deployed in the real world. The go-to strategy to quantify this\nvulnerability is to evaluate the model against specific attack algorithms. This\napproach is however inherently limited, as it says little about the robustness\nof the model against more powerful attacks not included in the evaluation. We\ndevelop a unified mathematical framework to describe relaxation-based\nrobustness certification methods, which go beyond adversary-specific robustness\nevaluation and instead provide provable robustness guarantees against attacks\nby any adversary. We discuss the fundamental limitations posed by single-neuron\nrelaxations and show how the recent ``k-ReLU'' multi-neuron relaxation\nframework of Singh et al. (2019) obtains tighter correlation-aware activation\nbounds by leveraging additional relational constraints among groups of neurons.\nSpecifically, we show how additional pre-activation bounds can be mapped to\ncorresponding post-activation bounds and how they can in turn be used to obtain\ntighter robustness certificates. We also present an intuitive way to visualize\ndifferent relaxation-based certification methods. By approximating multiple\nnon-linearities jointly instead of separately, the k-ReLU method is able to\nbypass the convex barrier imposed by single neuron relaxations.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 11:59:27 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Roth", "Kevin", ""]]}, {"id": "2106.03121", "submitter": "Ananay Agarwal", "authors": "Ananye Agarwal, Pradeep Shenoy, Mausam", "title": "End-to-End Neuro-Symbolic Architecture for Image-to-Image Reasoning\n  Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural models and symbolic algorithms have recently been combined for tasks\nrequiring both perception and reasoning. Neural models ground perceptual input\ninto a conceptual vocabulary, on which a classical reasoning algorithm is\napplied to generate output. A key limitation is that such neural-to-symbolic\nmodels can only be trained end-to-end for tasks where the output space is\nsymbolic. In this paper, we study neural-symbolic-neural models for reasoning\ntasks that require a conversion from an image input (e.g., a partially filled\nsudoku) to an image output (e.g., the image of the completed sudoku). While\ndesigning such a three-step hybrid architecture may be straightforward, the key\ntechnical challenge is end-to-end training -- how to backpropagate without\nintermediate supervision through the symbolic component. We propose NSNnet, an\narchitecture that combines an image reconstruction loss with a novel output\nencoder to generate a supervisory signal, develops update algorithms that\nleverage policy gradient methods for supervision, and optimizes loss using a\nnovel subsampling heuristic. We experiment on problem settings where symbolic\nalgorithms are easily specified: a visual maze solving task and a visual Sudoku\nsolver where the supervision is in image form. Experiments show high accuracy\nwith significantly less data compared to purely neural approaches.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 13:27:33 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Agarwal", "Ananye", ""], ["Shenoy", "Pradeep", ""], ["Mausam", "", ""]]}, {"id": "2106.03129", "submitter": "Khoi Khac Nguyen", "authors": "Khoi Khac Nguyen and Trung Q. Duong and Tan Do-Duy and Holger Claussen\n  and and Lajos Hanzo", "title": "3D UAV Trajectory and Data Collection Optimisation via Deep\n  Reinforcement Learning", "comments": "30 pages, UAV-assisted wireless network, trajectory, data collection,\n  and deep reinforcement learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unmanned aerial vehicles (UAVs) are now beginning to be deployed for\nenhancing the network performance and coverage in wireless communication.\nHowever, due to the limitation of their on-board power and flight time, it is\nchallenging to obtain an optimal resource allocation scheme for the\nUAV-assisted Internet of Things (IoT). In this paper, we design a new\nUAV-assisted IoT systems relying on the shortest flight path of the UAVs while\nmaximising the amount of data collected from IoT devices. Then, a deep\nreinforcement learning-based technique is conceived for finding the optimal\ntrajectory and throughput in a specific coverage area. After training, the UAV\nhas the ability to autonomously collect all the data from user nodes at a\nsignificant total sum-rate improvement while minimising the associated\nresources used. Numerical results are provided to highlight how our techniques\nstrike a balance between the throughput attained, trajectory, and the time\nspent. More explicitly, we characterise the attainable performance in terms of\nthe UAV trajectory, the expected reward and the total sum-rate.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 14:08:41 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Nguyen", "Khoi Khac", ""], ["Duong", "Trung Q.", ""], ["Do-Duy", "Tan", ""], ["Claussen", "Holger", ""], ["Hanzo", "and Lajos", ""]]}, {"id": "2106.03136", "submitter": "Ravi Shekhar Tiwari Mr.", "authors": "Ravi Shekhar Tiwari, Supraja P, Rijo Jackson Tom", "title": "3D Convolution Neural Network based Person Identification using Gait\n  cycles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Human identification plays a prominent role in terms of security. In modern\ntimes security is becoming the key term for an individual or a country,\nespecially for countries which are facing internal or external threats. Gait\nanalysis is interpreted as the systematic study of the locomotive in humans. It\ncan be used to extract the exact walking features of individuals. Walking\nfeatures depends on biological as well as the physical feature of the object;\nhence, it is unique to every individual. In this work, gait features are used\nto identify an individual. The steps involve object detection, background\nsubtraction, silhouettes extraction, skeletonization, and training 3D\nConvolution Neural Network on these gait features. The model is trained and\nevaluated on the dataset acquired by CASIA B Gait, which consists of 15000\nvideos of 124 subjects walking pattern captured from 11 different angles\ncarrying objects such as bag and coat. The proposed method focuses more on the\nlower body part to extract features such as the angle between knee and thighs,\nhip angle, angle of contact, and many other features. The experimental results\nare compared with amongst accuracies of silhouettes as datasets for training\nand skeletonized image as training data. The results show that extracting the\ninformation from skeletonized data yields improved accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 14:27:06 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Tiwari", "Ravi Shekhar", ""], ["P", "Supraja", ""], ["Tom", "Rijo Jackson", ""]]}, {"id": "2106.03151", "submitter": "Qianren Mao", "authors": "Qianren Mao, Xi Li, Hao Peng, Bang Liu, Shu Guo, Jianxin Li, Lihong\n  Wang, Philip S. Yu", "title": "Attend and Select: A Segment Attention based Selection Mechanism for\n  Microblog Hashtag Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic microblog hashtag generation can help us better and faster\nunderstand or process the critical content of microblog posts.\n  Conventional sequence-to-sequence generation methods can produce phrase-level\nhashtags and have achieved remarkable performance on this task. However, they\nare incapable of filtering out secondary information and not good at capturing\nthe discontinuous semantics among crucial tokens.\n  A hashtag is formed by tokens or phrases that may originate from various\nfragmentary segments of the original text.\n  In this work, we propose an end-to-end Transformer-based generation model\nwhich consists of three phases: encoding, segments-selection, and decoding. The\nmodel transforms discontinuous semantic segments from the source text into a\nsequence of hashtags.\n  Specifically, we introduce a novel Segments Selection Mechanism (SSM) for\nTransformer to obtain segmental representations tailored to phrase-level\nhashtag generation.\n  Besides, we introduce two large-scale hashtag generation datasets, which are\nnewly collected from Chinese Weibo and English Twitter.\n  Extensive evaluations on the two datasets reveal our approach's superiority\nwith significant improvements to extraction and generation baselines. The code\nand datasets are available at \\url{https://github.com/OpenSUM/HashtagGen}.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 15:13:58 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Mao", "Qianren", ""], ["Li", "Xi", ""], ["Peng", "Hao", ""], ["Liu", "Bang", ""], ["Guo", "Shu", ""], ["Li", "Jianxin", ""], ["Wang", "Lihong", ""], ["Yu", "Philip S.", ""]]}, {"id": "2106.03155", "submitter": "Mingfei Sun", "authors": "Mingfei Sun, Anuj Mahajan, Katja Hofmann, Shimon Whiteson", "title": "SoftDICE for Imitation Learning: Rethinking Off-policy Distribution\n  Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present SoftDICE, which achieves state-of-the-art performance for\nimitation learning. SoftDICE fixes several key problems in ValueDICE, an\noff-policy distribution matching approach for sample-efficient imitation\nlearning. Specifically, the objective of ValueDICE contains logarithms and\nexponentials of expectations, for which the mini-batch gradient estimate is\nalways biased. Second, ValueDICE regularizes the objective with replay buffer\nsamples when expert demonstrations are limited in number, which however changes\nthe original distribution matching problem. Third, the re-parametrization trick\nused to derive the off-policy objective relies on an implicit assumption that\nrarely holds in training. We leverage a novel formulation of distribution\nmatching and consider an entropy-regularized off-policy objective, which yields\na completely offline algorithm called SoftDICE. Our empirical results show that\nSoftDICE recovers the expert policy with only one demonstration trajectory and\nno further on-policy/off-policy samples. SoftDICE also stably outperforms\nValueDICE and other baselines in terms of sample efficiency on Mujoco benchmark\ntasks.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 15:37:11 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Sun", "Mingfei", ""], ["Mahajan", "Anuj", ""], ["Hofmann", "Katja", ""], ["Whiteson", "Shimon", ""]]}, {"id": "2106.03170", "submitter": "Nadine Ruecker", "authors": "Nadine Ruecker, Andreas Maier", "title": "FlexParser -- the adaptive log file parser for continuous results in a\n  changing world", "comments": "18 pages, 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Any modern system writes events into files, called log files. Those contain\ncrucial information which are subject to various analyses. Examples range from\ncybersecurity, intrusion detection over usage analyses to trouble shooting.\nBefore data analysis is possible, desired information needs to be extracted\nfirst out of the semi-structured log messages. State of the art event parsing\noften assumes static log events. However, any modern system is updated\nconsistently and with updates also log file structures can change. We call\nthose changes 'mutations' and study parsing performance for different mutation\ncases. Latest research discovers mutations using anomaly detection post mortem,\nhowever, does not cover actual continuous parsing. Thus, we propose a novel,\nflexible parser, called FlexParser which can extract desired values despite\ngradual changes in the log messages. It implies basic text preprocessing\nfollowed by a supervised Deep Learning method. We train a stateful LSTM on\nparsing one event per data set. Statefulness enforces the model to learn log\nmessage structures across several messages. Our model was tested on seven\ndifferent, publicly available log file data sets and various kinds of\nmutations. Exhibiting an average F1-Score of 0.98, it outperforms other Deep\nLearning methods as well as state-of-the-art unsupervised parsers.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 16:30:01 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Ruecker", "Nadine", ""], ["Maier", "Andreas", ""]]}, {"id": "2106.03178", "submitter": "Heyang Gong", "authors": "Heyang Gong, Ke Zhu", "title": "Path-specific Effects Based on Information Accounts of Causality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.OT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Path-specific effects in mediation analysis provide a useful tool for\nfairness analysis, which is mostly based on nested counterfactuals. However,\nthe dictum ``no causation without manipulation'' implies that path-specific\neffects might be induced by certain interventions. This paper proposes a new\npath intervention inspired by information accounts of causality, and develops\nthe corresponding intervention diagrams and $\\pi$-formula. Compared with the\ninterventionist approach of Robins et al.(2020) based on nested\ncounterfactuals, our proposed path intervention method explicitly describes the\nmanipulation in structural causal model with a simple information transferring\ninterpretation, and does not require the non-existence of recanting witness to\nidentify path-specific effects. Hence, it could serve useful communications and\ntheoretical focus for mediation analysis.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 16:50:06 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Gong", "Heyang", ""], ["Zhu", "Ke", ""]]}, {"id": "2106.03181", "submitter": "Katsuma Inoue", "authors": "Katsuma Inoue, Soh Ohara, Yasuo Kuniyoshi, and Kohei Nakajima", "title": "Transient Chaos in BERT", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG math.DS nlin.CD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Language is an outcome of our complex and dynamic human-interactions and the\ntechnique of natural language processing (NLP) is hence built on human\nlinguistic activities. Bidirectional Encoder Representations from Transformers\n(BERT) has recently gained its popularity by establishing the state-of-the-art\nscores in several NLP benchmarks. A Lite BERT (ALBERT) is literally\ncharacterized as a lightweight version of BERT, in which the number of BERT\nparameters is reduced by repeatedly applying the same neural network called\nTransformer's encoder layer. By pre-training the parameters with a massive\namount of natural language data, ALBERT can convert input sentences into\nversatile high-dimensional vectors potentially capable of solving multiple NLP\ntasks. In that sense, ALBERT can be regarded as a well-designed\nhigh-dimensional dynamical system whose operator is the Transformer's encoder,\nand essential structures of human language are thus expected to be encapsulated\nin its dynamics. In this study, we investigated the embedded properties of\nALBERT to reveal how NLP tasks are effectively solved by exploiting its\ndynamics. We thereby aimed to explore the nature of human language from the\ndynamical expressions of the NLP model. Our short-term analysis clarified that\nthe pre-trained model stably yields trajectories with higher dimensionality,\nwhich would enhance the expressive capacity required for NLP tasks. Also, our\nlong-term analysis revealed that ALBERT intrinsically shows transient chaos, a\ntypical nonlinear phenomenon showing chaotic dynamics only in its transient,\nand the pre-trained ALBERT model tends to produce the chaotic trajectory for a\nsignificantly longer time period compared to a randomly-initialized one. Our\nresults imply that local chaoticity would contribute to improving NLP\nperformance, uncovering a novel aspect in the role of chaotic dynamics in human\nlanguage behaviors.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 17:02:29 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 02:25:34 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Inoue", "Katsuma", ""], ["Ohara", "Soh", ""], ["Kuniyoshi", "Yasuo", ""], ["Nakajima", "Kohei", ""]]}, {"id": "2106.03193", "submitter": "Angela Fan", "authors": "Naman Goyal, Cynthia Gao, Vishrav Chaudhary, Peng-Jen Chen, Guillaume\n  Wenzek, Da Ju, Sanjana Krishnan, Marc'Aurelio Ranzato, Francisco Guzman,\n  Angela Fan", "title": "The FLORES-101 Evaluation Benchmark for Low-Resource and Multilingual\n  Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the biggest challenges hindering progress in low-resource and\nmultilingual machine translation is the lack of good evaluation benchmarks.\nCurrent evaluation benchmarks either lack good coverage of low-resource\nlanguages, consider only restricted domains, or are low quality because they\nare constructed using semi-automatic procedures. In this work, we introduce the\nFLORES-101 evaluation benchmark, consisting of 3001 sentences extracted from\nEnglish Wikipedia and covering a variety of different topics and domains. These\nsentences have been translated in 101 languages by professional translators\nthrough a carefully controlled process. The resulting dataset enables better\nassessment of model quality on the long tail of low-resource languages,\nincluding the evaluation of many-to-many multilingual translation systems, as\nall translations are multilingually aligned. By publicly releasing such a\nhigh-quality and high-coverage dataset, we hope to foster progress in the\nmachine translation community and beyond.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 17:58:12 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Goyal", "Naman", ""], ["Gao", "Cynthia", ""], ["Chaudhary", "Vishrav", ""], ["Chen", "Peng-Jen", ""], ["Wenzek", "Guillaume", ""], ["Ju", "Da", ""], ["Krishnan", "Sanjana", ""], ["Ranzato", "Marc'Aurelio", ""], ["Guzman", "Francisco", ""], ["Fan", "Angela", ""]]}, {"id": "2106.03195", "submitter": "Jonas Rothfuss", "authors": "Jonas Rothfuss, Dominique Heyn, Jinfan Chen, Andreas Krause", "title": "Meta-Learning Reliable Priors in the Function Space", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Meta-Learning promises to enable more data-efficient inference by harnessing\nprevious experience from related learning tasks. While existing meta-learning\nmethods help us to improve the accuracy of our predictions in face of data\nscarcity, they fail to supply reliable uncertainty estimates, often being\ngrossly overconfident in their predictions. Addressing these shortcomings, we\nintroduce a novel meta-learning framework, called F-PACOH, that treats\nmeta-learned priors as stochastic processes and performs meta-level\nregularization directly in the function space. This allows us to directly steer\nthe probabilistic predictions of the meta-learner towards high epistemic\nuncertainty in regions of insufficient meta-training data and, thus, obtain\nwell-calibrated uncertainty estimates. Finally, we showcase how our approach\ncan be integrated with sequential decision making, where reliable uncertainty\nquantification is imperative. In our benchmark study on meta-learning for\nBayesian Optimization (BO), F-PACOH significantly outperforms all other\nmeta-learners and standard baselines. Even in a challenging lifelong BO\nsetting, where optimization tasks arrive one at a time and the meta-learner\nneeds to build up informative prior knowledge incrementally, our proposed\nmethod demonstrates strong positive transfer.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 18:07:49 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Rothfuss", "Jonas", ""], ["Heyn", "Dominique", ""], ["Chen", "Jinfan", ""], ["Krause", "Andreas", ""]]}, {"id": "2106.03213", "submitter": "Hesham Mostafa", "authors": "Hesham Mostafa, Marcel Nassar, Somdeb Majumdar", "title": "On Local Aggregation in Heterophilic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many recent works have studied the performance of Graph Neural Networks\n(GNNs) in the context of graph homophily - a label-dependent measure of\nconnectivity. Traditional GNNs generate node embeddings by aggregating\ninformation from a node's neighbors in the graph. Recent results in node\nclassification tasks show that this local aggregation approach performs poorly\nin graphs with low homophily (heterophilic graphs). Several mechanisms have\nbeen proposed to improve the accuracy of GNNs on such graphs by increasing the\naggregation range of a GNN layer, either through multi-hop aggregation, or\nthrough long-range aggregation from distant nodes. In this paper, we show that\nproperly tuned classical GNNs and multi-layer perceptrons match or exceed the\naccuracy of recent long-range aggregation methods on heterophilic graphs. Thus,\nour results highlight the need for alternative datasets to benchmark long-range\nGNN aggregation mechanisms. We also show that homophily is a poor measure of\nthe information in a node's local neighborhood and propose the Neighborhood\nInformation Content(NIC) metric, which is a novel information-theoretic graph\nmetric. We argue that NIC is more relevant for local aggregation methods as\nused by GNNs. We show that, empirically, it correlates better with GNN accuracy\nin node classification tasks than homophily.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 19:12:31 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Mostafa", "Hesham", ""], ["Nassar", "Marcel", ""], ["Majumdar", "Somdeb", ""]]}, {"id": "2106.03215", "submitter": "Neehar Peri", "authors": "Neehar Peri, Michael J. Curry, Samuel Dooley, John P. Dickerson", "title": "PreferenceNet: Encoding Human Preferences in Auction Design with Deep\n  Learning", "comments": "First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The design of optimal auctions is a problem of interest in economics, game\ntheory and computer science. Despite decades of effort, strategyproof,\nrevenue-maximizing auction designs are still not known outside of restricted\nsettings. However, recent methods using deep learning have shown some success\nin approximating optimal auctions, recovering several known solutions and\noutperforming strong baselines when optimal auctions are not known. In addition\nto maximizing revenue, auction mechanisms may also seek to encourage socially\ndesirable constraints such as allocation fairness or diversity. However, these\nphilosophical notions neither have standardization nor do they have widely\naccepted formal definitions. In this paper, we propose PreferenceNet, an\nextension of existing neural-network-based auction mechanisms to encode\nconstraints using (potentially human-provided) exemplars of desirable\nallocations. In addition, we introduce a new metric to evaluate an auction\nallocations' adherence to such socially desirable constraints and demonstrate\nthat our proposed method is competitive with current state-of-the-art\nneural-network based auction designs. We validate our approach through human\nsubject research and show that we are able to effectively capture real human\npreferences. Our code is available at\nhttps://github.com/neeharperi/PreferenceNet\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 19:29:40 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Peri", "Neehar", ""], ["Curry", "Michael J.", ""], ["Dooley", "Samuel", ""], ["Dickerson", "John P.", ""]]}, {"id": "2106.03220", "submitter": "Devesh Jha", "authors": "Arvind U. Raghunathan, Devesh K. Jha, Diego Romeres", "title": "PYROBOCOP : Python-based Robotic Control & Optimization Package for\n  Manipulation and Collision Avoidance", "comments": "Under review at IJRR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  PYROBOCOP is a lightweight Python-based package for control and optimization\nof robotic systems described by nonlinear Differential Algebraic Equations\n(DAEs). In particular, the package can handle systems with contacts that are\ndescribed by complementarity constraints and provides a general framework for\nspecifying obstacle avoidance constraints. The package performs direct\ntranscription of the DAEs into a set of nonlinear equations by performing\northogonal collocation on finite elements. The resulting optimization problem\nbelongs to the class of Mathematical Programs with Complementarity Constraints\n(MPCCs). MPCCs fail to satisfy commonly assumed constraint qualifications and\nrequire special handling of the complementarity constraints in order for\nNonLinear Program (NLP) solvers to solve them effectively. PYROBOCOP provides\nautomatic reformulation of the complementarity constraints that enables NLP\nsolvers to perform optimization of robotic systems. The package is interfaced\nwith ADOLC for obtaining sparse derivatives by automatic differentiation and\nIPOPT for performing optimization. We demonstrate the effectiveness of our\napproach in terms of speed and flexibility. We provide several numerical\nexamples for several robotic systems with collision avoidance as well as\ncontact constraints represented using complementarity constraints. We provide\ncomparisons with other open source optimization packages like CasADi and Pyomo .\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 19:46:29 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Raghunathan", "Arvind U.", ""], ["Jha", "Devesh K.", ""], ["Romeres", "Diego", ""]]}, {"id": "2106.03221", "submitter": "Brijen Thananjeyan", "authors": "Brijen Thananjeyan, Kirthevasan Kandasamy, Ion Stoica, Michael I.\n  Jordan, Ken Goldberg, Joseph E. Gonzalez", "title": "PAC Best Arm Identification Under a Deadline", "comments": "In submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study $(\\epsilon, \\delta)$-PAC best arm identification, where a\ndecision-maker must identify an $\\epsilon$-optimal arm with probability at\nleast $1 - \\delta$, while minimizing the number of arm pulls (samples). Most of\nthe work on this topic is in the sequential setting, where there is no\nconstraint on the time taken to identify such an arm; this allows the\ndecision-maker to pull one arm at a time. In this work, the decision-maker is\ngiven a deadline of $T$ rounds, where, on each round, it can adaptively choose\nwhich arms to pull and how many times to pull them; this distinguishes the\nnumber of decisions made (i.e., time or number of rounds) from the number of\nsamples acquired (cost). Such situations occur in clinical trials, where one\nmay need to identify a promising treatment under a deadline while minimizing\nthe number of test subjects, or in simulation-based studies run on the cloud,\nwhere we can elastically scale up or down the number of virtual machines to\nconduct as many experiments as we wish, but need to pay for the resource-time\nused. As the decision-maker can only make $T$ decisions, she may need to pull\nsome arms excessively relative to a sequential algorithm in order to perform\nwell on all possible problems. We formalize this added difficulty with two\nhardness results that indicate that unlike sequential settings, the ability to\nadapt to the problem difficulty is constrained by the finite deadline. We\npropose Elastic Batch Racing (EBR), a novel algorithm for this setting and\nbound its sample complexity, showing that EBR is optimal with respect to both\nhardness results. We present simulations evaluating EBR in this setting, where\nit outperforms baselines by several orders of magnitude.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 19:48:32 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 01:35:09 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Thananjeyan", "Brijen", ""], ["Kandasamy", "Kirthevasan", ""], ["Stoica", "Ion", ""], ["Jordan", "Michael I.", ""], ["Goldberg", "Ken", ""], ["Gonzalez", "Joseph E.", ""]]}, {"id": "2106.03225", "submitter": "Tianlong Chen", "authors": "Zhenyu Zhang, Xuxi Chen, Tianlong Chen, Zhangyang Wang", "title": "Efficient Lottery Ticket Finding: Less Data is More", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lottery ticket hypothesis (LTH) reveals the existence of winning tickets\n(sparse but critical subnetworks) for dense networks, that can be trained in\nisolation from random initialization to match the latter's accuracies. However,\nfinding winning tickets requires burdensome computations in the\ntrain-prune-retrain process, especially on large-scale datasets (e.g.,\nImageNet), restricting their practical benefits. This paper explores a new\nperspective on finding lottery tickets more efficiently, by doing so only with\na specially selected subset of data, called Pruning-Aware Critical set (PrAC\nset), rather than using the full training set. The concept of PrAC set was\ninspired by the recent observation, that deep networks have samples that are\neither hard to memorize during training, or easy to forget during pruning. A\nPrAC set is thus hypothesized to capture those most challenging and informative\nexamples for the dense model. We observe that a high-quality winning ticket can\nbe found with training and pruning the dense network on the very compact PrAC\nset, which can substantially save training iterations for the ticket finding\nprocess. Extensive experiments validate our proposal across diverse datasets\nand network architectures. Specifically, on CIFAR-10, CIFAR-100, and Tiny\nImageNet, we locate effective PrAC sets at 35.32%~78.19% of their training set\nsizes. On top of them, we can obtain the same competitive winning tickets for\nthe corresponding dense networks, yet saving up to 82.85%~92.77%,\n63.54%~74.92%, and 76.14%~86.56% training iterations, respectively. Crucially,\nwe show that a PrAC set found is reusable across different network\narchitectures, which can amortize the extra cost of finding PrAC sets, yielding\na practical regime for efficient lottery ticket finding.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 19:58:17 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Zhang", "Zhenyu", ""], ["Chen", "Xuxi", ""], ["Chen", "Tianlong", ""], ["Wang", "Zhangyang", ""]]}, {"id": "2106.03228", "submitter": "Thibaut Theate", "authors": "Thibaut Th\\'eate, Antoine Wehenkel, Adrien Bolland, Gilles Louppe and\n  Damien Ernst", "title": "Distributional Reinforcement Learning with Unconstrained Monotonic\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The distributional reinforcement learning (RL) approach advocates for\nrepresenting the complete probability distribution of the random return instead\nof only modelling its expectation. A distributional RL algorithm may be\ncharacterised by two main components, namely the representation and\nparameterisation of the distribution and the probability metric defining the\nloss. This research considers the unconstrained monotonic neural network (UMNN)\narchitecture, a universal approximator of continuous monotonic functions which\nis particularly well suited for modelling different representations of a\ndistribution (PDF, CDF, quantile function). This property enables the\ndecoupling of the effect of the function approximator class from that of the\nprobability metric. The paper firstly introduces a methodology for learning\ndifferent representations of the random return distribution. Secondly, a novel\ndistributional RL algorithm named unconstrained monotonic deep Q-network\n(UMDQN) is presented. Lastly, in light of this new algorithm, an empirical\ncomparison is performed between three probability quasimetrics, namely the\nKullback-Leibler divergence, Cramer distance and Wasserstein distance. The\nresults call for a reconsideration of all probability metrics in distributional\nRL, which contrasts with the dominance of the Wasserstein distance in recent\npublications.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 20:03:50 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Th\u00e9ate", "Thibaut", ""], ["Wehenkel", "Antoine", ""], ["Bolland", "Adrien", ""], ["Louppe", "Gilles", ""], ["Ernst", "Damien", ""]]}, {"id": "2106.03233", "submitter": "Gunjan Mahindre", "authors": "Gunjan Mahindre and Randy Paffenroth and Anura Jayasumana and Rasika\n  Karkare", "title": "A Pre-training Oracle for Predicting Distances in Social Networks", "comments": "KDD conference 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a novel method to make distance predictions in\nreal-world social networks. As predicting missing distances is a difficult\nproblem, we take a two-stage approach. Structural parameters for families of\nsynthetic networks are first estimated from a small set of measurements of a\nreal-world network and these synthetic networks are then used to pre-train the\npredictive neural networks. Since our model first searches for the most\nsuitable synthetic graph parameters which can be used as an \"oracle\" to create\narbitrarily large training data sets, we call our approach \"Oracle Search\nPre-training\" (OSP). For example, many real-world networks exhibit a Power law\nstructure in their node degree distribution, so a Power law model can provide a\nfoundation for the desired oracle to generate synthetic pre-training networks,\nif the appropriate Power law graph parameters can be estimated. Accordingly, we\nconduct experiments on real-world Facebook, Email, and Train Bombing networks\nand show that OSP outperforms models without pre-training, models pre-trained\nwith inaccurate parameters, and other distance prediction schemes such as\nLow-rank Matrix Completion. In particular, we achieve a prediction error of\nless than one hop with only 1% of sampled distances from the social network.\nOSP can be easily extended to other domains such as random networks by choosing\nan appropriate model to generate synthetic training data, and therefore\npromises to impact many different network learning problems.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 20:06:44 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Mahindre", "Gunjan", ""], ["Paffenroth", "Randy", ""], ["Jayasumana", "Anura", ""], ["Karkare", "Rasika", ""]]}, {"id": "2106.03234", "submitter": "Pranava Madhyastha", "authors": "Chunyang Xiao, Pranava Madhyastha", "title": "A call for better unit testing for invariant risk minimisation", "comments": "Manuscript v1.0", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we present a controlled study on the linearized IRM framework\n(IRMv1) introduced in Arjovsky et al. (2020). We show that IRMv1 (and its\nvariants) framework can be potentially unstable under small changes to the\noptimal regressor. This can, notably, lead to worse generalisation to new\nenvironments, even compared with ERM which converges simply to the global\nminimum for all training environments mixed up all together. We also highlight\nthe isseus of scaling in the the IRMv1 setup. These observations highlight the\nimportance of rigorous evaluation and importance of unit-testing for measuring\nprogress towards IRM.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 20:07:46 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Xiao", "Chunyang", ""], ["Madhyastha", "Pranava", ""]]}, {"id": "2106.03242", "submitter": "Elahe Arani", "authors": "Ahmed Badar, Arnav Varma, Adrian Staniec, Mahmoud Gamal, Omar Magdy,\n  Haris Iqbal, Elahe Arani and Bahram Zonooz", "title": "Highlighting the Importance of Reducing Research Bias and Carbon\n  Emissions in CNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Convolutional neural networks (CNNs) have become commonplace in addressing\nmajor challenges in computer vision. Researchers are not only coming up with\nnew CNN architectures but are also researching different techniques to improve\nthe performance of existing architectures. However, there is a tendency to\nover-emphasize performance improvement while neglecting certain important\nvariables such as simplicity, versatility, the fairness of comparisons, and\nenergy efficiency. Overlooking these variables in architectural design and\nevaluation has led to research bias and a significantly negative environmental\nimpact. Furthermore, this can undermine the positive impact of research in\nusing deep learning models to tackle climate change. Here, we perform an\nextensive and fair empirical study of a number of proposed techniques to gauge\nthe utility of each technique for segmentation and classification. Our findings\nrestate the importance of favoring simplicity over complexity in model design\n(Occam's Razor). Furthermore, our results indicate that simple standardized\npractices can lead to a significant reduction in environmental impact with\nlittle drop in performance. We highlight that there is a need to rethink the\ndesign and evaluation of CNNs to alleviate the issue of research bias and\ncarbon emissions.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 20:42:00 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Badar", "Ahmed", ""], ["Varma", "Arnav", ""], ["Staniec", "Adrian", ""], ["Gamal", "Mahmoud", ""], ["Magdy", "Omar", ""], ["Iqbal", "Haris", ""], ["Arani", "Elahe", ""], ["Zonooz", "Bahram", ""]]}, {"id": "2106.03246", "submitter": "Athar Sefid", "authors": "Athar Sefid, Jian Wu, Prasenjit Mitra, Lee Giles", "title": "Extractive Research Slide Generation Using Windowed Labeling Ranking", "comments": null, "journal-ref": "NAACL/Proceedings of the Second Workshop on Scholarly Document\n  Processing 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Presentation slides describing the content of scientific and technical papers\nare an efficient and effective way to present that work. However, manually\ngenerating presentation slides is labor intensive. We propose a method to\nautomatically generate slides for scientific papers based on a corpus of 5000\npaper-slide pairs compiled from conference proceedings websites. The sentence\nlabeling module of our method is based on SummaRuNNer, a neural sequence model\nfor extractive summarization. Instead of ranking sentences based on semantic\nsimilarities in the whole document, our algorithm measures importance and\nnovelty of sentences by combining semantic and lexical features within a\nsentence window. Our method outperforms several baseline methods including\nSummaRuNNer by a significant margin in terms of ROUGE score.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 20:56:43 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Sefid", "Athar", ""], ["Wu", "Jian", ""], ["Mitra", "Prasenjit", ""], ["Giles", "Lee", ""]]}, {"id": "2106.03270", "submitter": "Shang-Wen Li", "authors": "Hongyin Luo, Shuyan Dong, Yung-Sung Chuang, Shang-Wen Li", "title": "Meta-learning for downstream aware and agnostic pretraining", "comments": "Extended abstract", "journal-ref": "Meta Learning and Its Applications to Natural Language Processing\n  workshop at ACL 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural network pretraining is gaining attention due to its outstanding\nperformance in natural language processing applications. However, pretraining\nusually leverages predefined task sequences to learn general linguistic clues.\nThe lack of mechanisms in choosing proper tasks during pretraining makes the\nlearning and knowledge encoding inefficient. We thus propose using\nmeta-learning to select tasks that provide the most informative learning\nsignals in each episode of pretraining. With the proposed method, we aim to\nachieve better efficiency in computation and memory usage for the pretraining\nprocess and resulting networks while maintaining the performance. In this\npreliminary work, we discuss the algorithm of the method and its two variants,\ndownstream-aware and downstream-agnostic pretraining. Our experiment plan is\nalso summarized, while empirical results will be shared in our future works.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 23:08:09 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Luo", "Hongyin", ""], ["Dong", "Shuyan", ""], ["Chuang", "Yung-Sung", ""], ["Li", "Shang-Wen", ""]]}, {"id": "2106.03273", "submitter": "Evgenii Nikishin", "authors": "Evgenii Nikishin, Romina Abachi, Rishabh Agarwal, Pierre-Luc Bacon", "title": "Control-Oriented Model-Based Reinforcement Learning with Implicit\n  Differentiation", "comments": "Code at https://github.com/evgenii-nikishin/omd", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The shortcomings of maximum likelihood estimation in the context of\nmodel-based reinforcement learning have been highlighted by an increasing\nnumber of papers. When the model class is misspecified or has a limited\nrepresentational capacity, model parameters with high likelihood might not\nnecessarily result in high performance of the agent on a downstream control\ntask. To alleviate this problem, we propose an end-to-end approach for model\nlearning which directly optimizes the expected returns using implicit\ndifferentiation. We treat a value function that satisfies the Bellman\noptimality operator induced by the model as an implicit function of model\nparameters and show how to differentiate the function. We provide theoretical\nand empirical evidence highlighting the benefits of our approach in the model\nmisspecification regime compared to likelihood-based methods.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 23:15:49 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Nikishin", "Evgenii", ""], ["Abachi", "Romina", ""], ["Agarwal", "Rishabh", ""], ["Bacon", "Pierre-Luc", ""]]}, {"id": "2106.03275", "submitter": "Richard Allmendinger", "authors": "Richard Allmendinger, Andrzej Jaszkiewicz, Arnaud Liefooghe,\n  Christiane Tammer", "title": "What if we Increase the Number of Objectives? Theoretical and Empirical\n  Implications for Many-objective Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The difficulty of solving a multi-objective optimization problem is impacted\nby the number of objectives to be optimized. The presence of many objectives\ntypically introduces a number of challenges that affect the choice/design of\noptimization algorithms. This paper investigates the drivers of these\nchallenges from two angles: (i) the influence of the number of objectives on\nproblem characteristics and (ii) the practical behavior of commonly used\nprocedures and algorithms for coping with many objectives. In addition to\nreviewing various drivers, the paper makes theoretical contributions by\nquantifying some drivers and/or verifying these drivers empirically by carrying\nout experiments on multi-objective NK landscapes and other typical benchmarks.\nWe then make use of our theoretical and empirical findings to derive practical\nrecommendations to support algorithm design. Finally, we discuss remaining\ntheoretical gaps and opportunities for future research in the area of multi-\nand many-objective optimization.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 23:25:35 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Allmendinger", "Richard", ""], ["Jaszkiewicz", "Andrzej", ""], ["Liefooghe", "Arnaud", ""], ["Tammer", "Christiane", ""]]}, {"id": "2106.03310", "submitter": "Zi Wang", "authors": "Zi Wang", "title": "Zero-Shot Knowledge Distillation from a Decision-Based Black-Box Model", "comments": "Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge distillation (KD) is a successful approach for deep neural network\nacceleration, with which a compact network (student) is trained by mimicking\nthe softmax output of a pre-trained high-capacity network (teacher). In\ntradition, KD usually relies on access to the training samples and the\nparameters of the white-box teacher to acquire the transferred knowledge.\nHowever, these prerequisites are not always realistic due to storage costs or\nprivacy issues in real-world applications. Here we propose the concept of\ndecision-based black-box (DB3) knowledge distillation, with which the student\nis trained by distilling the knowledge from a black-box teacher (parameters are\nnot accessible) that only returns classes rather than softmax outputs. We start\nwith the scenario when the training set is accessible. We represent a sample's\nrobustness against other classes by computing its distances to the teacher's\ndecision boundaries and use it to construct the soft label for each training\nsample. After that, the student can be trained via standard KD. We then extend\nthis approach to a more challenging scenario in which even accessing the\ntraining data is not feasible. We propose to generate pseudo samples\ndistinguished by the teacher's decision boundaries to the largest extent and\nconstruct soft labels for them, which are used as the transfer set. We evaluate\nour approaches on various benchmark networks and datasets and experiment\nresults demonstrate their effectiveness. Codes are available at:\nhttps://github.com/zwang84/zsdb3kd.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 02:46:31 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Wang", "Zi", ""]]}, {"id": "2106.03324", "submitter": "Izack Cohen", "authors": "Izack Cohen and Avigdor Gal", "title": "Uncertain Process Data with Probabilistic Knowledge: Problem\n  Characterization and Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Motivated by the abundance of uncertain event data from multiple sources\nincluding physical devices and sensors, this paper presents the task of\nrelating a stochastic process observation to a process model that can be\nrendered from a dataset. In contrast to previous research that suggested to\ntransform a stochastically known event log into a less informative uncertain\nlog with upper and lower bounds on activity frequencies, we consider the\nchallenge of accommodating the probabilistic knowledge into conformance\nchecking techniques. Based on a taxonomy that captures the spectrum of\nconformance checking cases under stochastic process observations, we present\nthree types of challenging cases. The first includes conformance checking of a\nstochastically known log with respect to a given process model. The second case\nextends the first to classify a stochastically known log into one of several\nprocess models. The third case extends the two previous ones into settings in\nwhich process models are only stochastically known. The suggested problem\ncaptures the increasingly growing number of applications in which sensors\nprovide probabilistic process information.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 03:56:14 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Cohen", "Izack", ""], ["Gal", "Avigdor", ""]]}, {"id": "2106.03352", "submitter": "Qinghua Liu", "authors": "Chi Jin, Qinghua Liu, Tiancheng Yu", "title": "The Power of Exploiter: Provable Multi-Agent RL in Large State Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern reinforcement learning (RL) commonly engages practical problems with\nlarge state spaces, where function approximation must be deployed to\napproximate either the value function or the policy. While recent progresses in\nRL theory address a rich set of RL problems with general function\napproximation, such successes are mostly restricted to the single-agent\nsetting. It remains elusive how to extend these results to multi-agent RL,\nespecially due to the new challenges arising from its game-theoretical nature.\nThis paper considers two-player zero-sum Markov Games (MGs). We propose a new\nalgorithm that can provably find the Nash equilibrium policy using a polynomial\nnumber of samples, for any MG with low multi-agent Bellman-Eluder dimension --\na new complexity measure adapted from its single-agent version (Jin et al.,\n2021). A key component of our new algorithm is the exploiter, which facilitates\nthe learning of the main player by deliberately exploiting her weakness. Our\ntheoretical framework is generic, which applies to a wide range of models\nincluding but not limited to tabular MGs, MGs with linear or kernel function\napproximation, and MGs with rich observations.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 05:39:09 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Jin", "Chi", ""], ["Liu", "Qinghua", ""], ["Yu", "Tiancheng", ""]]}, {"id": "2106.03356", "submitter": "Fengtong Xiao", "authors": "Fengtong Xiao, Lin Li, Weinan Xu, Jingyu Zhao, Xiaofeng Yang, Jun\n  Lang, Hao Wang", "title": "DMBGN: Deep Multi-Behavior Graph Networks for Voucher Redemption Rate\n  Prediction", "comments": "9 pages, 5 figures, accepted full paper SIGKDD'21 applied data\n  science track", "journal-ref": null, "doi": "10.1145/3447548.3467191", "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In E-commerce, vouchers are important marketing tools to enhance users'\nengagement and boost sales and revenue. The likelihood that a user redeems a\nvoucher is a key factor in voucher distribution decision. User-item\nClick-Through-Rate (CTR) models are often applied to predict the user-voucher\nredemption rate. However, the voucher scenario involves more complicated\nrelations among users, items and vouchers. The users' historical behavior in a\nvoucher collection activity reflects users' voucher usage patterns, which is\nnevertheless overlooked by the CTR-based solutions. In this paper, we propose a\nDeep Multi-behavior Graph Networks (DMBGN) to shed light on this field for the\nvoucher redemption rate prediction. The complex structural user-voucher-item\nrelationships are captured by a User-Behavior Voucher Graph (UVG). User\nbehavior happening both before and after voucher collection is taken into\nconsideration, and a high-level representation is extracted by Higher-order\nGraph Neural Networks. On top of a sequence of UVGs, an attention network is\nbuilt which can help to learn users' long-term voucher redemption preference.\nExtensive experiments on three large-scale production datasets demonstrate the\nproposed DMBGN model is effective, with 10% to 16% relative AUC improvement\nover Deep Neural Networks (DNN), and 2% to 4% AUC improvement over Deep\nInterest Network (DIN). Source code and a sample dataset are made publicly\navailable to facilitate future research.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 06:16:49 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Xiao", "Fengtong", ""], ["Li", "Lin", ""], ["Xu", "Weinan", ""], ["Zhao", "Jingyu", ""], ["Yang", "Xiaofeng", ""], ["Lang", "Jun", ""], ["Wang", "Hao", ""]]}, {"id": "2106.03379", "submitter": "Hongyu Gong", "authors": "Hongyu Gong, Vishrav Chaudhary, Yuqing Tang, Francisco Guzm\\'an", "title": "LAWDR: Language-Agnostic Weighted Document Representations from\n  Pre-trained Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cross-lingual document representations enable language understanding in\nmultilingual contexts and allow transfer learning from high-resource to\nlow-resource languages at the document level. Recently large pre-trained\nlanguage models such as BERT, XLM and XLM-RoBERTa have achieved great success\nwhen fine-tuned on sentence-level downstream tasks. It is tempting to apply\nthese cross-lingual models to document representation learning. However, there\nare two challenges: (1) these models impose high costs on long document\nprocessing and thus many of them have strict length limit; (2) model\nfine-tuning requires extra data and computational resources, which is not\npractical in resource-limited settings. In this work, we address these\nchallenges by proposing unsupervised Language-Agnostic Weighted Document\nRepresentations (LAWDR). We study the geometry of pre-trained sentence\nembeddings and leverage it to derive document representations without\nfine-tuning. Evaluated on cross-lingual document alignment, LAWDR demonstrates\ncomparable performance to state-of-the-art models on benchmark datasets.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 07:14:00 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Gong", "Hongyu", ""], ["Chaudhary", "Vishrav", ""], ["Tang", "Yuqing", ""], ["Guzm\u00e1n", "Francisco", ""]]}, {"id": "2106.03394", "submitter": "Dai Hai Nguyen", "authors": "Dai Hai Nguyen and Koji Tsuda", "title": "A generative model for molecule generation based on chemical reaction\n  trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models have been shown powerful in generating novel molecules\nwith desired chemical properties via their representations such as strings,\ntrees or graphs. However, these models are limited in recommending synthetic\nroutes for the generated molecules in practice. We propose a generative model\nto generate molecules via multi-step chemical reaction trees. Specifically, our\nmodel first propose a chemical reaction tree with predicted reaction templates\nand commercially available molecules (starting molecules), and then perform\nforward synthetic steps to obtain product molecules. Experiments show that our\nmodel can generate chemical reactions whose product molecules are with desired\nchemical properties. Also, the complete synthetic routes for these product\nmolecules are provided.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 07:47:18 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Nguyen", "Dai Hai", ""], ["Tsuda", "Koji", ""]]}, {"id": "2106.03400", "submitter": "Xiaoteng Ma", "authors": "Yiqin Yang, Xiaoteng Ma, Chenghao Li, Zewu Zheng, Qiyuan Zhang, Gao\n  Huang, Jun Yang, Qianchuan Zhao", "title": "Believe What You See: Implicit Constraint Approach for Offline\n  Multi-Agent Reinforcement Learning", "comments": "The first two authors contributed equally to the work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Learning from datasets without interaction with environments (Offline\nLearning) is an essential step to apply Reinforcement Learning (RL) algorithms\nin real-world scenarios. However, compared with the single-agent counterpart,\noffline multi-agent RL introduces more agents with the larger state and action\nspace, which is more challenging but attracts little attention. We demonstrate\ncurrent offline RL algorithms are ineffective in multi-agent systems due to the\naccumulated extrapolation error. In this paper, we propose a novel offline RL\nalgorithm, named Implicit Constraint Q-learning (ICQ), which effectively\nalleviates the extrapolation error by only trusting the state-action pairs\ngiven in the dataset for value estimation. Moreover, we extend ICQ to\nmulti-agent tasks by decomposing the joint-policy under the implicit\nconstraint. Experimental results demonstrate that the extrapolation error is\nreduced to almost zero and insensitive to the number of agents. We further show\nthat ICQ achieves the state-of-the-art performance in the challenging\nmulti-agent offline tasks (StarCraft II).\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 08:02:31 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Yang", "Yiqin", ""], ["Ma", "Xiaoteng", ""], ["Li", "Chenghao", ""], ["Zheng", "Zewu", ""], ["Zhang", "Qiyuan", ""], ["Huang", "Gao", ""], ["Yang", "Jun", ""], ["Zhao", "Qianchuan", ""]]}, {"id": "2106.03415", "submitter": "Zhuoxuan Jiang", "authors": "Sanshi Yu and Zhuoxuan Jiang and Dong-Dong Chen and Shanshan Feng and\n  Dongsheng Li and Qi Liu and Jinfeng Yi", "title": "Leveraging Tripartite Interaction Information from Live Stream\n  E-Commerce for Improving Product Recommendation", "comments": "To appear in KDD'21 ADS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a new form of online shopping becomes more and more popular, which\ncombines live streaming with E-Commerce activity. The streamers introduce\nproducts and interact with their audiences, and hence greatly improve the\nperformance of selling products. Despite of the successful applications in\nindustries, the live stream E-commerce has not been well studied in the data\nscience community. To fill this gap, we investigate this brand-new scenario and\ncollect a real-world Live Stream E-Commerce (LSEC) dataset. Different from\nconventional E-commerce activities, the streamers play a pivotal role in the\nLSEC events. Hence, the key is to make full use of rich interaction information\namong streamers, users, and products. We first conduct data analysis on the\ntripartite interaction data and quantify the streamer's influence on users'\npurchase behavior. Based on the analysis results, we model the tripartite\ninformation as a heterogeneous graph, which can be decomposed to multiple\nbipartite graphs in order to better capture the influence. We propose a novel\nLive Stream E-Commerce Graph Neural Network framework (LSEC-GNN) to learn the\nnode representations of each bipartite graph, and further design a multi-task\nlearning approach to improve product recommendation. Extensive experiments on\ntwo real-world datasets with different scales show that our method can\nsignificantly outperform various baseline approaches.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 08:32:19 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Yu", "Sanshi", ""], ["Jiang", "Zhuoxuan", ""], ["Chen", "Dong-Dong", ""], ["Feng", "Shanshan", ""], ["Li", "Dongsheng", ""], ["Liu", "Qi", ""], ["Yi", "Jinfeng", ""]]}, {"id": "2106.03427", "submitter": "Yichi Zhang", "authors": "Yichi Zhang and Joyce Chai", "title": "Hierarchical Task Learning from Language Instructions with Unified\n  Transformers and Self-Monitoring", "comments": "Accepted by ACL 2021 Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent progress, learning new tasks through language instructions\nremains an extremely challenging problem. On the ALFRED benchmark for task\nlearning, the published state-of-the-art system only achieves a task success\nrate of less than 10% in an unseen environment, compared to the human\nperformance of over 90%. To address this issue, this paper takes a closer look\nat task learning. In a departure from a widely applied end-to-end architecture,\nwe decomposed task learning into three sub-problems: sub-goal planning, scene\nnavigation, and object manipulation; and developed a model HiTUT (stands for\nHierarchical Tasks via Unified Transformers) that addresses each sub-problem in\na unified manner to learn a hierarchical task structure. On the ALFRED\nbenchmark, HiTUT has achieved the best performance with a remarkably higher\ngeneralization ability. In the unseen environment, HiTUT achieves over 160%\nperformance gain in success rate compared to the previous state of the art. The\nexplicit representation of task structures also enables an in-depth\nunderstanding of the nature of the problem and the ability of the agent, which\nprovides insight for future benchmark development and evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 08:48:44 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Zhang", "Yichi", ""], ["Chai", "Joyce", ""]]}, {"id": "2106.03442", "submitter": "Xiaoteng Ma", "authors": "Xiaoteng Ma, Xiaohang Tang, Li Xia, Jun Yang, Qianchuan Zhao", "title": "Average-Reward Reinforcement Learning with Trust Region Methods", "comments": "Accepted by IJCAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Most of reinforcement learning algorithms optimize the discounted criterion\nwhich is beneficial to accelerate the convergence and reduce the variance of\nestimates. Although the discounted criterion is appropriate for certain tasks\nsuch as financial related problems, many engineering problems treat future\nrewards equally and prefer a long-run average criterion. In this paper, we\nstudy the reinforcement learning problem with the long-run average criterion.\nFirstly, we develop a unified trust region theory with discounted and average\ncriteria. With the average criterion, a novel performance bound within the\ntrust region is derived with the Perturbation Analysis (PA) theory. Secondly,\nwe propose a practical algorithm named Average Policy Optimization (APO), which\nimproves the value estimation with a novel technique named Average Value\nConstraint. To the best of our knowledge, our work is the first one to study\nthe trust region approach with the average criterion and it complements the\nframework of reinforcement learning beyond the discounted criterion. Finally,\nexperiments are conducted in the continuous control environment MuJoCo. In most\ntasks, APO performs better than the discounted PPO, which demonstrates the\neffectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 09:19:42 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Ma", "Xiaoteng", ""], ["Tang", "Xiaohang", ""], ["Xia", "Li", ""], ["Yang", "Jun", ""], ["Zhao", "Qianchuan", ""]]}, {"id": "2106.03471", "submitter": "Lisa Beinborn", "authors": "Nora Hollenstein and Lisa Beinborn", "title": "Relative Importance in Sentence Processing", "comments": "accepted at ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Determining the relative importance of the elements in a sentence is a key\nfactor for effortless natural language understanding. For human language\nprocessing, we can approximate patterns of relative importance by measuring\nreading fixations using eye-tracking technology. In neural language models,\ngradient-based saliency methods indicate the relative importance of a token for\nthe target objective. In this work, we compare patterns of relative importance\nin English language processing by humans and models and analyze the underlying\nlinguistic patterns. We find that human processing patterns in English\ncorrelate strongly with saliency-based importance in language models and not\nwith attention-based importance. Our results indicate that saliency could be a\ncognitively more plausible metric for interpreting neural language models. The\ncode is available on GitHub: https://github.com/beinborn/relative_importance\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 09:56:18 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Hollenstein", "Nora", ""], ["Beinborn", "Lisa", ""]]}, {"id": "2106.03518", "submitter": "Hanqi Yan", "authors": "Hanqi Yan, Lin Gui, Gabriele Pergola, Yulan He", "title": "Position Bias Mitigation: A Knowledge-Aware Graph Model for Emotion\n  Cause Extraction", "comments": "ACL2021 Main Conference Long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Emotion Cause Extraction (ECE)} task aims to identify clauses which\ncontain emotion-evoking information for a particular emotion expressed in text.\nWe observe that a widely-used ECE dataset exhibits a bias that the majority of\nannotated cause clauses are either directly before their associated emotion\nclauses or are the emotion clauses themselves. Existing models for ECE tend to\nexplore such relative position information and suffer from the dataset bias. To\ninvestigate the degree of reliance of existing ECE models on clause relative\npositions, we propose a novel strategy to generate adversarial examples in\nwhich the relative position information is no longer the indicative feature of\ncause clauses. We test the performance of existing models on such adversarial\nexamples and observe a significant performance drop. To address the dataset\nbias, we propose a novel graph-based method to explicitly model the emotion\ntriggering paths by leveraging the commonsense knowledge to enhance the\nsemantic dependencies between a candidate clause and an emotion clause.\nExperimental results show that our proposed approach performs on par with the\nexisting state-of-the-art methods on the original ECE dataset, and is more\nrobust against adversarial attacks compared to existing models.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 11:14:58 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 10:27:00 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Yan", "Hanqi", ""], ["Gui", "Lin", ""], ["Pergola", "Gabriele", ""], ["He", "Yulan", ""]]}, {"id": "2106.03530", "submitter": "Yan Xu", "authors": "Etsuko Ishii, Yan Xu, Genta Indra Winata, Zhaojiang Lin, Andrea\n  Madotto, Zihan Liu, Peng Xu, Pascale Fung", "title": "CAiRE in DialDoc21: Data Augmentation for Information-Seeking Dialogue\n  System", "comments": "Accepted in DialDoc21 Workshop in ACL 2021. Etsuko Ishii and Yan Xu\n  contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information-seeking dialogue systems, including knowledge identification and\nresponse generation, aim to respond to users with fluent, coherent, and\ninformative responses based on users' needs, which. To tackle this challenge,\nwe utilize data augmentation methods and several training techniques with the\npre-trained language models to learn a general pattern of the task and thus\nachieve promising performance. In DialDoc21 competition, our system achieved\n74.95 F1 score and 60.74 Exact Match score in subtask 1, and 37.72 SacreBLEU\nscore in subtask 2. Empirical analysis is provided to explain the effectiveness\nof our approaches.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 11:40:55 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 03:07:02 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Ishii", "Etsuko", ""], ["Xu", "Yan", ""], ["Winata", "Genta Indra", ""], ["Lin", "Zhaojiang", ""], ["Madotto", "Andrea", ""], ["Liu", "Zihan", ""], ["Xu", "Peng", ""], ["Fung", "Pascale", ""]]}, {"id": "2106.03546", "submitter": "Anirban Santara", "authors": "Anirban Santara, Claudio Gentile, Gaurav Aggarwal, Shuai Li", "title": "On Learning to Rank Long Sequences with Contextual Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Motivated by problems of learning to rank long item sequences, we introduce a\nvariant of the cascading bandit model that considers flexible length sequences\nwith varying rewards and losses. We formulate two generative models for this\nproblem within the generalized linear setting, and design and analyze upper\nconfidence algorithms for it. Our analysis delivers tight regret bounds which,\nwhen specialized to vanilla cascading bandits, results in sharper guarantees\nthan previously available in the literature. We evaluate our algorithms on a\nnumber of real-world datasets, and show significantly improved empirical\nperformance as compared to known cascading bandit baselines.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 12:16:34 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Santara", "Anirban", ""], ["Gentile", "Claudio", ""], ["Aggarwal", "Gaurav", ""], ["Li", "Shuai", ""]]}, {"id": "2106.03548", "submitter": "Gauthier Picard", "authors": "Gauthier Picard", "title": "Auction-based and Distributed Optimization Approaches for Scheduling\n  Observations in Satellite Constellations with Exclusive Orbit Portions", "comments": null, "journal-ref": "International Workshop on Planning and Scheduling for Space\n  (IWPSS'21), Jul 2021, virtuel, United States", "doi": null, "report-no": null, "categories": "cs.AI cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the use of multi-agent allocation techniques on problems\nrelated to Earth observation scenarios with multiple users and satellites. We\nfocus on the problem of coordinating users having reserved exclusive orbit\nportions and one central planner having several requests that may use some\nintervals of these exclusives. We define this problem as Earth Observation\nSatellite Constellation Scheduling Problem (EOSCSP) and map it to a Mixed\nInteger Linear Program. As to solve EOSCSP, we propose market-based techniques\nand a distributed problem solving technique based on Distributed Constraint\nOptimization (DCOP), where agents cooperate to allocate requests without\nsharing their own schedules. These contributions are experimentally evaluated\non randomly generated EOSCSP instances based on real large-scale or highly\nconflicting observation order books.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 09:34:20 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 09:30:47 GMT"}, {"version": "v3", "created": "Tue, 27 Jul 2021 06:33:47 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Picard", "Gauthier", ""]]}, {"id": "2106.03567", "submitter": "Biswanath Dutta Dr.", "authors": "Biswanath Dutta and Jyotima Patel", "title": "AMV : Algorithm Metadata Vocabulary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Metadata vocabularies are used in various domains of study. It provides an\nin-depth description of the resources. In this work, we develop Algorithm\nMetadata Vocabulary (AMV), a vocabulary for capturing and storing the metadata\nabout the algorithms (a procedure or a set of rules that is followed\nstep-by-step to solve a problem, especially by a computer). The snag faced by\nthe researchers in the current time is the failure of getting relevant results\nwhen searching for algorithms in any search engine. AMV is represented as a\nsemantic model and produced OWL file, which can be directly used by anyone\ninterested to create and publish algorithm metadata as a knowledge graph, or to\nprovide metadata service through SPARQL endpoint. To design the vocabulary, we\npropose a well-defined methodology, which considers real issues faced by the\nalgorithm users and the practitioners. The evaluation shows a promising result.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 20:09:42 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Dutta", "Biswanath", ""], ["Patel", "Jyotima", ""]]}, {"id": "2106.03593", "submitter": "Xiangyu Liu", "authors": "Xiangyu Liu, Chuan Yu, Zhilin Zhang, Zhenzhe Zheng, Yu Rong, Hongtao\n  Lv, Da Huo, Yiqing Wang, Dagui Chen, Jian Xu, Fan Wu, Guihai Chen and\n  Xiaoqiang Zhu", "title": "Neural Auction: End-to-End Learning of Auction Mechanisms for E-Commerce\n  Advertising", "comments": "To appear in the Proceedings of the 27th ACM SIGKDD Conference on\n  Knowledge Discovery and Data Mining (KDD), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In e-commerce advertising, it is crucial to jointly consider various\nperformance metrics, e.g., user experience, advertiser utility, and platform\nrevenue. Traditional auction mechanisms, such as GSP and VCG auctions, can be\nsuboptimal due to their fixed allocation rules to optimize a single performance\nmetric (e.g., revenue or social welfare). Recently, data-driven auctions,\nlearned directly from auction outcomes to optimize multiple performance\nmetrics, have attracted increasing research interests. However, the procedure\nof auction mechanisms involves various discrete calculation operations, making\nit challenging to be compatible with continuous optimization pipelines in\nmachine learning. In this paper, we design \\underline{D}eep \\underline{N}eural\n\\underline{A}uctions (DNAs) to enable end-to-end auction learning by proposing\na differentiable model to relax the discrete sorting operation, a key component\nin auctions. We optimize the performance metrics by developing deep models to\nefficiently extract contexts from auctions, providing rich features for auction\ndesign. We further integrate the game theoretical conditions within the model\ndesign, to guarantee the stability of the auctions. DNAs have been successfully\ndeployed in the e-commerce advertising system at Taobao. Experimental\nevaluation results on both large-scale data set as well as online A/B test\ndemonstrated that DNAs significantly outperformed other mechanisms widely\nadopted in industry.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 13:20:40 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 03:16:56 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Liu", "Xiangyu", ""], ["Yu", "Chuan", ""], ["Zhang", "Zhilin", ""], ["Zheng", "Zhenzhe", ""], ["Rong", "Yu", ""], ["Lv", "Hongtao", ""], ["Huo", "Da", ""], ["Wang", "Yiqing", ""], ["Chen", "Dagui", ""], ["Xu", "Jian", ""], ["Wu", "Fan", ""], ["Chen", "Guihai", ""], ["Zhu", "Xiaoqiang", ""]]}, {"id": "2106.03598", "submitter": "Long Phan", "authors": "Long N. Phan, James T. Anibal, Hieu Tran, Shaurya Chanana, Erol\n  Bahadroglu, Alec Peltekian, Gr\\'egoire Altan-Bonnet", "title": "SciFive: a text-to-text transformer model for biomedical literature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this report, we introduce SciFive, a domain-specific T5 model that has\nbeen pre-trained on large biomedical corpora. Our model outperforms the current\nSOTA methods (i.e. BERT, BioBERT, Base T5) on tasks in named entity relation,\nrelation extraction, natural language inference, and question-answering. We\nshow that text-generation methods have significant potential in a broad array\nof biomedical NLP tasks, particularly those requiring longer, more complex\noutputs. Our results support the exploration of more difficult text generation\ntasks and the development of new methods in this area\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 06:09:23 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Phan", "Long N.", ""], ["Anibal", "James T.", ""], ["Tran", "Hieu", ""], ["Chanana", "Shaurya", ""], ["Bahadroglu", "Erol", ""], ["Peltekian", "Alec", ""], ["Altan-Bonnet", "Gr\u00e9goire", ""]]}, {"id": "2106.03613", "submitter": "Jianlei Yang", "authors": "Xin Guo, Jianlei Yang, Haoyi Zhou, Xucheng Ye, Jianxin Li", "title": "RoSearch: Search for Robust Student Architectures When Distilling\n  Pre-trained Language Models", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained language models achieve outstanding performance in NLP tasks.\nVarious knowledge distillation methods have been proposed to reduce the heavy\ncomputation and storage requirements of pre-trained language models. However,\nfrom our observations, student models acquired by knowledge distillation suffer\nfrom adversarial attacks, which limits their usage in security sensitive\nscenarios. In order to overcome these security problems, RoSearch is proposed\nas a comprehensive framework to search the student models with better\nadversarial robustness when performing knowledge distillation. A directed\nacyclic graph based search space is built and an evolutionary search strategy\nis utilized to guide the searching approach. Each searched architecture is\ntrained by knowledge distillation on pre-trained language model and then\nevaluated under a robustness-, accuracy- and efficiency-aware metric as\nenvironmental fitness. Experimental results show that RoSearch can improve\nrobustness of student models from 7%~18% up to 45.8%~47.8% on different\ndatasets with comparable weight compression ratio to existing distillation\nmethods (4.6$\\times$~6.5$\\times$ improvement from teacher model BERT_BASE) and\nlow accuracy drop. In addition, we summarize the relationship between student\narchitecture and robustness through statistics of searched models.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 13:38:16 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Guo", "Xin", ""], ["Yang", "Jianlei", ""], ["Zhou", "Haoyi", ""], ["Ye", "Xucheng", ""], ["Li", "Jianxin", ""]]}, {"id": "2106.03619", "submitter": "Hao Guo", "authors": "Hao Guo, Jiuyang Tang, Weixin Zeng, Xiang Zhao, Li Liu", "title": "Multi-modal Entity Alignment in Hyperbolic Space", "comments": "24 pages,5 figures;", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many AI-related tasks involve the interactions of data in multiple\nmodalities. It has been a new trend to merge multi-modal information into\nknowledge graph(KG), resulting in multi-modal knowledge graphs (MMKG). However,\nMMKGs usually suffer from low coverage and incompleteness. To mitigate this\nproblem, a viable approach is to integrate complementary knowledge from other\nMMKGs. To this end, although existing entity alignment approaches could be\nadopted, they operate in the Euclidean space, and the resulting Euclidean\nentity representations can lead to large distortion of KG's hierarchical\nstructure. Besides, the visual information has yet not been well exploited. In\nresponse to these issues, in this work, we propose a novel multi-modal entity\nalignment approach, Hyperbolic multi-modal entity alignment(HMEA), which\nextends the Euclidean representation to hyperboloid manifold. We first adopt\nthe Hyperbolic Graph Convolutional Networks (HGCNs) to learn structural\nrepresentations of entities. Regarding the visual information, we generate\nimage embeddings using the densenet model, which are also projected into the\nhyperbolic space using HGCNs. Finally, we combine the structure and visual\nrepresentations in the hyperbolic space and use the aggregated embeddings to\npredict potential alignment results. Extensive experiments and ablation studies\ndemonstrate the effectiveness of our proposed model and its components.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 13:45:03 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Guo", "Hao", ""], ["Tang", "Jiuyang", ""], ["Zeng", "Weixin", ""], ["Zhao", "Xiang", ""], ["Liu", "Li", ""]]}, {"id": "2106.03630", "submitter": "Patrick Emami", "authors": "Patrick Emami, Pan He, Sanjay Ranka, Anand Rangarajan", "title": "Efficient Iterative Amortized Inference for Learning Symmetric and\n  Disentangled Multi-Object Representations", "comments": "Published in ICML'21. Code and data:\n  https://github.com/pemami4911/EfficientMORL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Unsupervised multi-object representation learning depends on inductive biases\nto guide the discovery of object-centric representations that generalize.\nHowever, we observe that methods for learning these representations are either\nimpractical due to long training times and large memory consumption or forego\nkey inductive biases. In this work, we introduce EfficientMORL, an efficient\nframework for the unsupervised learning of object-centric representations. We\nshow that optimization challenges caused by requiring both symmetry and\ndisentanglement can in fact be addressed by high-cost iterative amortized\ninference by designing the framework to minimize its dependence on it. We take\na two-stage approach to inference: first, a hierarchical variational\nautoencoder extracts symmetric and disentangled representations through\nbottom-up inference, and second, a lightweight network refines the\nrepresentations with top-down feedback. The number of refinement steps taken\nduring training is reduced following a curriculum, so that at test time with\nzero steps the model achieves 99.1% of the refined decomposition performance.\nWe demonstrate strong object decomposition and disentanglement on the standard\nmulti-object benchmark while achieving nearly an order of magnitude faster\ntraining and test time inference over the previous state-of-the-art model.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 14:02:49 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Emami", "Patrick", ""], ["He", "Pan", ""], ["Ranka", "Sanjay", ""], ["Rangarajan", "Anand", ""]]}, {"id": "2106.03632", "submitter": "Guojun Zhang", "authors": "Guojun Zhang, Han Zhao, Yaoliang Yu, Pascal Poupart", "title": "Quantifying and Improving Transferability in Domain Generalization", "comments": "36 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Out-of-distribution generalization is one of the key challenges when\ntransferring a model from the lab to the real world. Existing efforts mostly\nfocus on building invariant features among source and target domains. Based on\ninvariant features, a high-performing classifier on source domains could\nhopefully behave equally well on a target domain. In other words, the invariant\nfeatures are \\emph{transferable}. However, in practice, there are no perfectly\ntransferable features, and some algorithms seem to learn ''more transferable''\nfeatures than others. How can we understand and quantify such\n\\emph{transferability}? In this paper, we formally define transferability that\none can quantify and compute in domain generalization. We point out the\ndifference and connection with common discrepancy measures between domains,\nsuch as total variation and Wasserstein distance. We then prove that our\ntransferability can be estimated with enough samples and give a new upper bound\nfor the target error based on our transferability. Empirically, we evaluate the\ntransferability of the feature embeddings learned by existing algorithms for\ndomain generalization. Surprisingly, we find that many algorithms are not quite\nlearning transferable features, although few could still survive. In light of\nthis, we propose a new algorithm for learning transferable features and test it\nover various benchmark datasets, including RotatedMNIST, PACS, Office-Home and\nWILDS-FMoW. Experimental results show that the proposed algorithm achieves\nconsistent improvement over many state-of-the-art algorithms, corroborating our\ntheoretical findings.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 14:04:32 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Zhang", "Guojun", ""], ["Zhao", "Han", ""], ["Yu", "Yaoliang", ""], ["Poupart", "Pascal", ""]]}, {"id": "2106.03635", "submitter": "Lei Shen", "authors": "Lei Shen, Fandong Meng, Jinchao Zhang, Yang Feng, Jie Zhou", "title": "GTM: A Generative Triple-Wise Model for Conversational Question\n  Generation", "comments": "To appear at ACL 2021 main conference (long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating some appealing questions in open-domain conversations is an\neffective way to improve human-machine interactions and lead the topic to a\nbroader or deeper direction. To avoid dull or deviated questions, some\nresearchers tried to utilize answer, the \"future\" information, to guide\nquestion generation. However, they separate a post-question-answer (PQA) triple\ninto two parts: post-question (PQ) and question-answer (QA) pairs, which may\nhurt the overall coherence. Besides, the QA relationship is modeled as a\none-to-one mapping that is not reasonable in open-domain conversations. To\ntackle these problems, we propose a generative triple-wise model with\nhierarchical variations for open-domain conversational question generation\n(CQG). Latent variables in three hierarchies are used to represent the shared\nbackground of a triple and one-to-many semantic mappings in both PQ and QA\npairs. Experimental results on a large-scale CQG dataset show that our method\nsignificantly improves the quality of questions in terms of fluency, coherence\nand diversity over competitive baselines.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 14:07:07 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Shen", "Lei", ""], ["Meng", "Fandong", ""], ["Zhang", "Jinchao", ""], ["Feng", "Yang", ""], ["Zhou", "Jie", ""]]}, {"id": "2106.03669", "submitter": "Joshua Pearce", "authors": "Kanlayanee Kaweesinsakul, Siranee Nuchitprasitchai and Joshua M.\n  Pearce", "title": "Open source disease analysis system of cactus by artificial intelligence\n  and image processing", "comments": "Preprint for IAIT2021", "journal-ref": null, "doi": "10.1145/3468784.3469075", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  There is a growing interest in cactus cultivation because of numerous cacti\nuses from houseplants to food and medicinal applications. Various diseases\nimpact the growth of cacti. To develop an automated model for the analysis of\ncactus disease and to be able to quickly treat and prevent damage to the\ncactus. The Faster R-CNN and YOLO algorithm technique were used to analyze\ncactus diseases automatically distributed into six groups: 1) anthracnose, 2)\ncanker, 3) lack of care, 4) aphid, 5) rusts and 6) normal group. Based on the\nexperimental results the YOLOv5 algorithm was found to be more effective at\ndetecting and identifying cactus disease than the Faster R-CNN algorithm. Data\ntraining and testing with YOLOv5S model resulted in a precision of 89.7% and an\naccuracy (recall) of 98.5%, which is effective enough for further use in a\nnumber of applications in cactus cultivation. Overall the YOLOv5 algorithm had\na test time per image of only 26 milliseconds. Therefore, the YOLOv5 algorithm\nwas found to suitable for mobile applications and this model could be further\ndeveloped into a program for analyzing cactus disease.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 14:46:23 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Kaweesinsakul", "Kanlayanee", ""], ["Nuchitprasitchai", "Siranee", ""], ["Pearce", "Joshua M.", ""]]}, {"id": "2106.03684", "submitter": "Hal Ashton", "authors": "Hal Ashton", "title": "Extending counterfactual accounts of intent to include oblique intent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  One approach to defining Intention is to use the counterfactual tools\ndeveloped to define Causality. Direct Intention is considered the highest level\nof intent in the common law, and is a sufficient component for the most serious\ncrimes to be committed. Loosely defined it is the commission of actions to\nbring about a desired or targeted outcome. Direct Intention is not always\nnecessary for the most serious category of crimes because society has also\nfound it necessary to develop a theory of intention around side-effects, known\nas oblique intent or indirect intent. This is to prevent moral harms from going\nunpunished which were not the aim of the actor, but were natural consequences\nnevertheless. This paper uses a canonical example of a plane owner, planting a\nbomb on their own plane in order to collect insurance, to illustrate how two\naccounts of counterfactual intent do not conclude that murder of the plane's\npassengers and crew were directly intended. We extend both frameworks to\ninclude a definition of oblique intent developed in Ashton (2021)\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 15:00:20 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Ashton", "Hal", ""]]}, {"id": "2106.03699", "submitter": "Anshuman Suri", "authors": "Anshuman Suri and David Evans", "title": "Formalizing Distribution Inference Risks", "comments": "ICML 2021 Workshop on Theory and Practice of Differential Privacy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Property inference attacks reveal statistical properties about a training set\nbut are difficult to distinguish from the primary purposes of statistical\nmachine learning, which is to produce models that capture statistical\nproperties about a distribution. Motivated by Yeom et al.'s membership\ninference framework, we propose a formal and generic definition of property\ninference attacks. The proposed notion describes attacks that can distinguish\nbetween possible training distributions, extending beyond previous property\ninference attacks that infer the ratio of a particular type of data in the\ntraining data set. In this paper, we show how our definition captures previous\nproperty inference attacks as well as a new attack that reveals the average\ndegree of nodes of a training graph and report on experiments giving insight\ninto the potential risks of property inference attacks.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 15:10:06 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 21:07:57 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Suri", "Anshuman", ""], ["Evans", "David", ""]]}, {"id": "2106.03706", "submitter": "Yi-Ting Yeh", "authors": "Yi-Ting Yeh, Maxine Eskenazi, Shikib Mehri", "title": "A Comprehensive Assessment of Dialog Evaluation Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic evaluation metrics are a crucial component of dialog systems\nresearch. Standard language evaluation metrics are known to be ineffective for\nevaluating dialog. As such, recent research has proposed a number of novel,\ndialog-specific metrics that correlate better with human judgements. Due to the\nfast pace of research, many of these metrics have been assessed on different\ndatasets and there has as yet been no time for a systematic comparison between\nthem. To this end, this paper provides a comprehensive assessment of recently\nproposed dialog evaluation metrics on a number of datasets. In this paper, 23\ndifferent automatic evaluation metrics are evaluated on 10 different datasets.\nFurthermore, the metrics are assessed in different settings, to better qualify\ntheir respective strengths and weaknesses. Metrics are assessed (1) on both the\nturn level and the dialog level, (2) for different dialog lengths, (3) for\ndifferent dialog qualities (e.g., coherence, engaging), (4) for different types\nof response generation models (i.e., generative, retrieval, simple models and\nstate-of-the-art models), (5) taking into account the similarity of different\nmetrics and (6) exploring combinations of different metrics. This comprehensive\nassessment offers several takeaways pertaining to dialog evaluation metrics in\ngeneral. It also suggests how to best assess evaluation metrics and indicates\npromising directions for future work.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 15:17:03 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 17:07:04 GMT"}, {"version": "v3", "created": "Fri, 2 Jul 2021 18:31:56 GMT"}, {"version": "v4", "created": "Wed, 7 Jul 2021 20:33:02 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Yeh", "Yi-Ting", ""], ["Eskenazi", "Maxine", ""], ["Mehri", "Shikib", ""]]}, {"id": "2106.03730", "submitter": "Raheel Qader", "authors": "Melissa Ailem, Jinghsu Liu, Raheel Qader", "title": "Encouraging Neural Machine Translation to Satisfy Terminology\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a new approach to encourage neural machine translation to satisfy\nlexical constraints. Our method acts at the training step and thereby avoiding\nthe introduction of any extra computational overhead at inference step. The\nproposed method combines three main ingredients. The first one consists in\naugmenting the training data to specify the constraints. Intuitively, this\nencourages the model to learn a copy behavior when it encounters constraint\nterms. Compared to previous work, we use a simplified augmentation strategy\nwithout source factors. The second ingredient is constraint token masking,\nwhich makes it even easier for the model to learn the copy behavior and\ngeneralize better. The third one, is a modification of the standard cross\nentropy loss to bias the model towards assigning high probabilities to\nconstraint words. Empirical results show that our method improves upon related\nbaselines in terms of both BLEU score and the percentage of generated\nconstraint terms.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 15:46:07 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Ailem", "Melissa", ""], ["Liu", "Jinghsu", ""], ["Qader", "Raheel", ""]]}, {"id": "2106.03736", "submitter": "Cristobal Donoso-Oliva", "authors": "C. Donoso-Oliva, G. Cabrera-Vives, P. Protopapas, R. Carrasco-Davis,\n  and P.A. Estevez", "title": "The effect of phased recurrent units in the classification of multiple\n  catalogs of astronomical lightcurves", "comments": null, "journal-ref": null, "doi": "10.1093/mnras/stab1598", "report-no": null, "categories": "astro-ph.IM cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In the new era of very large telescopes, where data is crucial to expand\nscientific knowledge, we have witnessed many deep learning applications for the\nautomatic classification of lightcurves. Recurrent neural networks (RNNs) are\none of the models used for these applications, and the LSTM unit stands out for\nbeing an excellent choice for the representation of long time series. In\ngeneral, RNNs assume observations at discrete times, which may not suit the\nirregular sampling of lightcurves. A traditional technique to address irregular\nsequences consists of adding the sampling time to the network's input, but this\nis not guaranteed to capture sampling irregularities during training.\nAlternatively, the Phased LSTM unit has been created to address this problem by\nupdating its state using the sampling times explicitly. In this work, we study\nthe effectiveness of the LSTM and Phased LSTM based architectures for the\nclassification of astronomical lightcurves. We use seven catalogs containing\nperiodic and nonperiodic astronomical objects. Our findings show that LSTM\noutperformed PLSTM on 6/7 datasets. However, the combination of both units\nenhances the results in all datasets.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 16:01:38 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Donoso-Oliva", "C.", ""], ["Cabrera-Vives", "G.", ""], ["Protopapas", "P.", ""], ["Carrasco-Davis", "R.", ""], ["Estevez", "P. A.", ""]]}, {"id": "2106.03748", "submitter": "William Guss", "authors": "William Hebgen Guss, Stephanie Milani, Nicholay Topin, Brandon\n  Houghton, Sharada Mohanty, Andrew Melnik, Augustin Harter, Benoit Buschmaas,\n  Bjarne Jaster, Christoph Berganski, Dennis Heitkamp, Marko Henning, Helge\n  Ritter, Chengjie Wu, Xiaotian Hao, Yiming Lu, Hangyu Mao, Yihuan Mao, Chao\n  Wang, Michal Opanowicz, Anssi Kanervisto, Yanick Schraner, Christian\n  Scheller, Xiren Zhou, Lu Liu, Daichi Nishio, Toi Tsuneda, Karolis\n  Ramanauskas, Gabija Juceviciute", "title": "Towards robust and domain agnostic reinforcement learning competitions", "comments": "20 pages, several figures, published PMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning competitions have formed the basis for standard\nresearch benchmarks, galvanized advances in the state-of-the-art, and shaped\nthe direction of the field. Despite this, a majority of challenges suffer from\nthe same fundamental problems: participant solutions to the posed challenge are\nusually domain-specific, biased to maximally exploit compute resources, and not\nguaranteed to be reproducible. In this paper, we present a new framework of\ncompetition design that promotes the development of algorithms that overcome\nthese barriers. We propose four central mechanisms for achieving this end:\nsubmission retraining, domain randomization, desemantization through domain\nobfuscation, and the limitation of competition compute and environment-sample\nbudget. To demonstrate the efficacy of this design, we proposed, organized, and\nran the MineRL 2020 Competition on Sample-Efficient Reinforcement Learning. In\nthis work, we describe the organizational outcomes of the competition and show\nthat the resulting participant submissions are reproducible, non-specific to\nthe competition environment, and sample/resource efficient, despite the\ndifficult competition task.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 16:15:46 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Guss", "William Hebgen", ""], ["Milani", "Stephanie", ""], ["Topin", "Nicholay", ""], ["Houghton", "Brandon", ""], ["Mohanty", "Sharada", ""], ["Melnik", "Andrew", ""], ["Harter", "Augustin", ""], ["Buschmaas", "Benoit", ""], ["Jaster", "Bjarne", ""], ["Berganski", "Christoph", ""], ["Heitkamp", "Dennis", ""], ["Henning", "Marko", ""], ["Ritter", "Helge", ""], ["Wu", "Chengjie", ""], ["Hao", "Xiaotian", ""], ["Lu", "Yiming", ""], ["Mao", "Hangyu", ""], ["Mao", "Yihuan", ""], ["Wang", "Chao", ""], ["Opanowicz", "Michal", ""], ["Kanervisto", "Anssi", ""], ["Schraner", "Yanick", ""], ["Scheller", "Christian", ""], ["Zhou", "Xiren", ""], ["Liu", "Lu", ""], ["Nishio", "Daichi", ""], ["Tsuneda", "Toi", ""], ["Ramanauskas", "Karolis", ""], ["Juceviciute", "Gabija", ""]]}, {"id": "2106.03775", "submitter": "Jeff Druce", "authors": "Jeff Druce, Michael Harradon, James Tittle", "title": "Explainable Artificial Intelligence (XAI) for Increasing User Trust in\n  Deep Reinforcement Learning Driven Autonomous Systems", "comments": "NeurIPS Deep RL workshop, Conference on Neural Information Processing\n  Systems (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of providing users of deep Reinforcement Learning\n(RL) based systems with a better understanding of when their output can be\ntrusted. We offer an explainable artificial intelligence (XAI) framework that\nprovides a three-fold explanation: a graphical depiction of the systems\ngeneralization and performance in the current game state, how well the agent\nwould play in semantically similar environments, and a narrative explanation of\nwhat the graphical information implies. We created a user-interface for our XAI\nframework and evaluated its efficacy via a human-user experiment. The results\ndemonstrate a statistically significant increase in user trust and acceptance\nof the AI system with explanation, versus the AI system without explanation.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 16:38:43 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Druce", "Jeff", ""], ["Harradon", "Michael", ""], ["Tittle", "James", ""]]}, {"id": "2106.03777", "submitter": "Zihan Liu", "authors": "Zihan Liu, Genta Indra Winata, Peng Xu, Pascale Fung", "title": "X2Parser: Cross-Lingual and Cross-Domain Framework for Task-Oriented\n  Compositional Semantic Parsing", "comments": "Accepted in RepL4NLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-oriented compositional semantic parsing (TCSP) handles complex nested\nuser queries and serves as an essential component of virtual assistants.\nCurrent TCSP models rely on numerous training data to achieve decent\nperformance but fail to generalize to low-resource target languages or domains.\nIn this paper, we present X2Parser, a transferable Cross-lingual and\nCross-domain Parser for TCSP. Unlike previous models that learn to generate the\nhierarchical representations for nested intents and slots, we propose to\npredict flattened intents and slots representations separately and cast both\nprediction tasks into sequence labeling problems. After that, we further\npropose a fertility-based slot predictor that first learns to dynamically\ndetect the number of labels for each token, and then predicts the slot types.\nExperimental results illustrate that our model can significantly outperform\nexisting strong baselines in cross-lingual and cross-domain settings, and our\nmodel can also achieve a good generalization ability on target languages of\ntarget domains. Furthermore, our model tackles the problem in an efficient\nnon-autoregressive way that reduces the latency by up to 66% compared to the\ngenerative model.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 16:40:05 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Liu", "Zihan", ""], ["Winata", "Genta Indra", ""], ["Xu", "Peng", ""], ["Fung", "Pascale", ""]]}, {"id": "2106.03780", "submitter": "Stefano Massaroli", "authors": "Stefano Massaroli, Michael Poli, Stefano Peluchetti, Jinkyoo Park,\n  Atsushi Yamashita and Hajime Asama", "title": "Learning Stochastic Optimal Policies via Gradient Descent", "comments": null, "journal-ref": "IEEE Control Systems Letters, 2021", "doi": "10.1109/LCSYS.2021.3086672.", "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We systematically develop a learning-based treatment of stochastic optimal\ncontrol (SOC), relying on direct optimization of parametric control policies.\nWe propose a derivation of adjoint sensitivity results for stochastic\ndifferential equations through direct application of variational calculus.\nThen, given an objective function for a predetermined task specifying the\ndesiderata for the controller, we optimize their parameters via iterative\ngradient descent methods. In doing so, we extend the range of applicability of\nclassical SOC techniques, often requiring strict assumptions on the functional\nform of system and control. We verify the performance of the proposed approach\non a continuous-time, finite horizon portfolio optimization with proportional\ntransaction costs.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 16:43:07 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Massaroli", "Stefano", ""], ["Poli", "Michael", ""], ["Peluchetti", "Stefano", ""], ["Park", "Jinkyoo", ""], ["Yamashita", "Atsushi", ""], ["Asama", "Hajime", ""]]}, {"id": "2106.03797", "submitter": "Hoang D. Nguyen", "authors": "Alex To, Maican Liu, Muhammad Hazeeq Bin Muhammad Hairul, Joseph G.\n  Davis, Jeannie S.A. Lee, Henrik Hesse and Hoang D. Nguyen", "title": "Drone-based AI and 3D Reconstruction for Digital Twin Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital Twin is an emerging technology at the forefront of Industry 4.0, with\nthe ultimate goal of combining the physical space and the virtual space. To\ndate, the Digital Twin concept has been applied in many engineering fields,\nproviding useful insights in the areas of engineering design, manufacturing,\nautomation, and construction industry. While the nexus of various technologies\nopens up new opportunities with Digital Twin, the technology requires a\nframework to integrate the different technologies, such as the Building\nInformation Model used in the Building and Construction industry. In this work,\nan Information Fusion framework is proposed to seamlessly fuse heterogeneous\ncomponents in a Digital Twin framework from the variety of technologies\ninvolved. This study aims to augment Digital Twin in buildings with the use of\nAI and 3D reconstruction empowered by unmanned aviation vehicles. We proposed a\ndrone-based Digital Twin augmentation framework with reusable and customisable\ncomponents. A proof of concept is also developed, and extensive evaluation is\nconducted for 3D reconstruction and applications of AI for defect detection.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 03:31:15 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["To", "Alex", ""], ["Liu", "Maican", ""], ["Hairul", "Muhammad Hazeeq Bin Muhammad", ""], ["Davis", "Joseph G.", ""], ["Lee", "Jeannie S. A.", ""], ["Hesse", "Henrik", ""], ["Nguyen", "Hoang D.", ""]]}, {"id": "2106.03799", "submitter": "Ary Naim", "authors": "Aryan Naim, Joseph Bowkett, Sisir Karumanchi, Peyman Tavallali, Brett\n  Kennedy", "title": "Deterministic Iteratively Built KD-Tree with KNN Search for Exact\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.DS cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  K-Nearest Neighbors (KNN) search is a fundamental algorithm in artificial\nintelligence software with applications in robotics, and autonomous vehicles.\nThese wide-ranging applications utilize KNN either directly for simple\nclassification or combine KNN results as input to other algorithms such as\nLocally Weighted Learning (LWL). Similar to binary trees, kd-trees become\nunbalanced as new data is added in online applications which can lead to rapid\ndegradation in search performance unless the tree is rebuilt. Although\napproximate methods are suitable for graphics applications, which prioritize\nquery speed over query accuracy, they are unsuitable for certain applications\nin autonomous systems, aeronautics, and robotic manipulation where exact\nsolutions are desired. In this paper, we will attempt to assess the performance\nof non-recursive deterministic kd-tree functions and KNN functions. We will\nalso present a \"forest of interval kd-trees\" which reduces the number of tree\nrebuilds, without compromising the exactness of query results.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 17:09:22 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Naim", "Aryan", ""], ["Bowkett", "Joseph", ""], ["Karumanchi", "Sisir", ""], ["Tavallali", "Peyman", ""], ["Kennedy", "Brett", ""]]}, {"id": "2106.03801", "submitter": "Razvan Caramalau", "authors": "Razvan Caramalau, Binod Bhattarai, Tae-Kyun Kim", "title": "Visual Transformer for Task-aware Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pool-based sampling in active learning (AL) represents a key framework for\nan-notating informative data when dealing with deep learning models. In this\npaper, we present a novel pipeline for pool-based Active Learning. Unlike most\nprevious works, our method exploits accessible unlabelled examples during\ntraining to estimate their co-relation with the labelled examples. Another\ncontribution of this paper is to adapt Visual Transformer as a sampler in the\nAL pipeline. Visual Transformer models non-local visual concept dependency\nbetween labelled and unlabelled examples, which is crucial to identifying the\ninfluencing unlabelled examples. Also, compared to existing methods where the\nlearner and the sampler are trained in a multi-stage manner, we propose to\ntrain them in a task-aware jointly manner which enables transforming the latent\nspace into two separate tasks: one that classifies the labelled examples; the\nother that distinguishes the labelling direction. We evaluated our work on four\ndifferent challenging benchmarks of classification and detection tasks viz.\nCIFAR10, CIFAR100,FashionMNIST, RaFD, and Pascal VOC 2007. Our extensive\nempirical and qualitative evaluations demonstrate the superiority of our method\ncompared to the existing methods. Code available:\nhttps://github.com/razvancaramalau/Visual-Transformer-for-Task-aware-Active-Learning\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 17:13:59 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Caramalau", "Razvan", ""], ["Bhattarai", "Binod", ""], ["Kim", "Tae-Kyun", ""]]}, {"id": "2106.03806", "submitter": "Shinhyeok Oh", "authors": "Shinhyeok Oh, Dongyub Lee, Taesun Whang, IlNam Park, Gaeun Seo,\n  EungGyun Kim and Harksoo Kim", "title": "Deep Context- and Relation-Aware Learning for Aspect-based Sentiment\n  Analysis", "comments": "Accepted to ACL-IJCNLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing works for aspect-based sentiment analysis (ABSA) have adopted a\nunified approach, which allows the interactive relations among subtasks.\nHowever, we observe that these methods tend to predict polarities based on the\nliteral meaning of aspect and opinion terms and mainly consider relations\nimplicitly among subtasks at the word level. In addition, identifying multiple\naspect-opinion pairs with their polarities is much more challenging. Therefore,\na comprehensive understanding of contextual information w.r.t. the aspect and\nopinion are further required in ABSA. In this paper, we propose Deep\nContextualized Relation-Aware Network (DCRAN), which allows interactive\nrelations among subtasks with deep contextual information based on two modules\n(i.e., Aspect and Opinion Propagation and Explicit Self-Supervised Strategies).\nEspecially, we design novel self-supervised strategies for ABSA, which have\nstrengths in dealing with multiple aspects. Experimental results show that\nDCRAN significantly outperforms previous state-of-the-art methods by large\nmargins on three widely used benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 17:16:15 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Oh", "Shinhyeok", ""], ["Lee", "Dongyub", ""], ["Whang", "Taesun", ""], ["Park", "IlNam", ""], ["Seo", "Gaeun", ""], ["Kim", "EungGyun", ""], ["Kim", "Harksoo", ""]]}, {"id": "2106.03816", "submitter": "Akash Kumar Mohankumar", "authors": "Akash Kumar Mohankumar, Nikit Begwani, Amit Singh", "title": "Diversity driven Query Rewriting in Search Advertising", "comments": "Accepted in KDD 2021, 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retrieving keywords (bidwords) with the same intent as query, referred to as\nclose variant keywords, is of prime importance for effective targeted search\nadvertising. For head and torso search queries, sponsored search engines use a\nhuge repository of same intent queries and keywords, mined ahead of time.\nOnline, this repository is used to rewrite the query and then lookup the\nrewrite in a repository of bid keywords contributing to significant revenue.\nRecently generative retrieval models have been shown to be effective at the\ntask of generating such query rewrites. We observe two main limitations of such\ngenerative models. First, rewrites generated by these models exhibit low\nlexical diversity, and hence the rewrites fail to retrieve relevant keywords\nthat have diverse linguistic variations. Second, there is a misalignment\nbetween the training objective - the likelihood of training data, v/s what we\ndesire - improved quality and coverage of rewrites. In this work, we introduce\nCLOVER, a framework to generate both high-quality and diverse rewrites by\noptimizing for human assessment of rewrite quality using our diversity-driven\nreinforcement learning algorithm. We use an evaluation model, trained to\npredict human judgments, as the reward function to finetune the generation\npolicy. We empirically show the effectiveness of our proposed approach through\noffline experiments on search queries across geographies spanning three major\nlanguages. We also perform online A/B experiments on Bing, a large commercial\nsearch engine, which shows (i) better user engagement with an average increase\nin clicks by 12.83% accompanied with an average defect reduction by 13.97%, and\n(ii) improved revenue by 21.29%.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 17:30:45 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Mohankumar", "Akash Kumar", ""], ["Begwani", "Nikit", ""], ["Singh", "Amit", ""]]}, {"id": "2106.03826", "submitter": "Mo Yu", "authors": "Xiangyang Mou, Chenghao Yang, Mo Yu, Bingsheng Yao, Xiaoxiao Guo,\n  Saloni Potdar, Hui Su", "title": "Narrative Question Answering with Cutting-Edge Open-Domain QA\n  Techniques: A Comprehensive Study", "comments": "Accepted to TACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advancements in open-domain question answering (ODQA), i.e., finding\nanswers from large open-domain corpus like Wikipedia, have led to human-level\nperformance on many datasets. However, progress in QA over book stories (Book\nQA) lags behind despite its similar task formulation to ODQA. This work\nprovides a comprehensive and quantitative analysis about the difficulty of Book\nQA: (1) We benchmark the research on the NarrativeQA dataset with extensive\nexperiments with cutting-edge ODQA techniques. This quantifies the challenges\nBook QA poses, as well as advances the published state-of-the-art with a\n$\\sim$7\\% absolute improvement on Rouge-L. (2) We further analyze the detailed\nchallenges in Book QA through human\nstudies.\\footnote{\\url{https://github.com/gorov/BookQA}.} Our findings indicate\nthat the event-centric questions dominate this task, which exemplifies the\ninability of existing QA models to handle event-oriented scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 17:46:09 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Mou", "Xiangyang", ""], ["Yang", "Chenghao", ""], ["Yu", "Mo", ""], ["Yao", "Bingsheng", ""], ["Guo", "Xiaoxiao", ""], ["Potdar", "Saloni", ""], ["Su", "Hui", ""]]}, {"id": "2106.03833", "submitter": "Yan Zhang", "authors": "Chenyu Liu, Yan Zhang, Yi Shen and Michael M. Zavlanos", "title": "Learning without Knowing: Unobserved Context in Continuous Transfer\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a transfer Reinforcement Learning (RL) problem in\ncontinuous state and action spaces, under unobserved contextual information.\nFor example, the context can represent the mental view of the world that an\nexpert agent has formed through past interactions with this world. We assume\nthat this context is not accessible to a learner agent who can only observe the\nexpert data. Then, our goal is to use the context-aware expert data to learn an\noptimal context-unaware policy for the learner using only a few new data\nsamples. Such problems are typically solved using imitation learning that\nassumes that both the expert and learner agents have access to the same\ninformation. However, if the learner does not know the expert context, using\nthe expert data alone will result in a biased learner policy and will require\nmany new data samples to improve. To address this challenge, in this paper, we\nformulate the learning problem as a causal bound-constrained Multi-Armed-Bandit\n(MAB) problem. The arms of this MAB correspond to a set of basis policy\nfunctions that can be initialized in an unsupervised way using the expert data\nand represent the different expert behaviors affected by the unobserved\ncontext. On the other hand, the MAB constraints correspond to causal bounds on\nthe accumulated rewards of these basis policy functions that we also compute\nfrom the expert data. The solution to this MAB allows the learner agent to\nselect the best basis policy and improve it online. And the use of causal\nbounds reduces the exploration variance and, therefore, improves the learning\nrate. We provide numerical experiments on an autonomous driving example that\nshow that our proposed transfer RL method improves the learner's policy faster\ncompared to existing imitation learning methods and enjoys much lower variance\nduring training.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 17:49:22 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Liu", "Chenyu", ""], ["Zhang", "Yan", ""], ["Shen", "Yi", ""], ["Zavlanos", "Michael M.", ""]]}, {"id": "2106.03837", "submitter": "Siddharth Bhatia", "authors": "Siddharth Bhatia, Arjit Jain, Shivin Srivastava, Kenji Kawaguchi,\n  Bryan Hooi", "title": "MemStream: Memory-Based Anomaly Detection in Multi-Aspect Streams with\n  Concept Drift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given a stream of entries over time in a multi-aspect data setting where\nconcept drift is present, how can we detect anomalous activities? Most of the\nexisting unsupervised anomaly detection approaches seek to detect anomalous\nevents in an offline fashion and require a large amount of data for training.\nThis is not practical in real-life scenarios where we receive the data in a\nstreaming manner and do not know the size of the stream beforehand. Thus, we\nneed a data-efficient method that can detect and adapt to changing data trends,\nor concept drift, in an online manner. In this work, we propose MemStream, a\nstreaming multi-aspect anomaly detection framework, allowing us to detect\nunusual events as they occur while being resilient to concept drift. We\nleverage the power of a denoising autoencoder to learn representations and a\nmemory module to learn the dynamically changing trend in data without the need\nfor labels. We prove the optimum memory size required for effective drift\nhandling. Furthermore, MemStream makes use of two architecture design choices\nto be robust to memory poisoning. Experimental results show the effectiveness\nof our approach compared to state-of-the-art streaming baselines using 2\nsynthetic datasets and 11 real-world datasets.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 17:54:57 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Bhatia", "Siddharth", ""], ["Jain", "Arjit", ""], ["Srivastava", "Shivin", ""], ["Kawaguchi", "Kenji", ""], ["Hooi", "Bryan", ""]]}, {"id": "2106.03894", "submitter": "Matthew Fontaine", "authors": "Matthew C. Fontaine, Stefanos Nikolaidis", "title": "Differentiable Quality Diversity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quality diversity (QD) is a growing branch of stochastic optimization\nresearch that studies the problem of generating an archive of solutions that\nmaximize a given objective function but are also diverse with respect to a set\nof specified measure functions. However, even when these functions are\ndifferentiable, QD algorithms treat them as \"black boxes\", ignoring gradient\ninformation. We present the differentiable quality diversity (DQD) problem, a\nspecial case of QD, where both the objective and measure functions are first\norder differentiable. We then present MAP-Elites via Gradient Arborescence\n(MEGA), a DQD algorithm that leverages gradient information to efficiently\nexplore the joint range of the objective and measure functions. Results in two\nQD benchmark domains and in searching the latent space of a StyleGAN show that\nMEGA significantly outperforms state-of-the-art QD algorithms, highlighting\nDQD's promise for efficient quality diversity optimization when gradient\ninformation is available. Source code is available at\nhttps://github.com/icaros-usc/dqd.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 18:11:53 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Fontaine", "Matthew C.", ""], ["Nikolaidis", "Stefanos", ""]]}, {"id": "2106.03904", "submitter": "Harshavardhan Kamarthi", "authors": "Harshavardhan Kamarthi, Lingkai Kong, Alexander Rodr\\'iguez, Chao\n  Zhang, B. Aditya Prakash", "title": "When in Doubt: Neural Non-Parametric Uncertainty Quantification for\n  Epidemic Forecasting", "comments": "16 pages, 12 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Accurate and trustworthy epidemic forecasting is an important problem that\nhas impact on public health planning and disease mitigation. Most existing\nepidemic forecasting models disregard uncertainty quantification, resulting in\nmis-calibrated predictions. Recent works in deep neural models for\nuncertainty-aware time-series forecasting also have several limitations; e.g.\nit is difficult to specify meaningful priors in Bayesian NNs, while methods\nlike deep ensembling are computationally expensive in practice. In this paper,\nwe fill this important gap. We model the forecasting task as a probabilistic\ngenerative process and propose a functional neural process model called EPIFNP,\nwhich directly models the probability density of the forecast value. EPIFNP\nleverages a dynamic stochastic correlation graph to model the correlations\nbetween sequences in a non-parametric way, and designs different stochastic\nlatent variables to capture functional uncertainty from different perspectives.\nOur extensive experiments in a real-time flu forecasting setting show that\nEPIFNP significantly outperforms previous state-of-the-art models in both\naccuracy and calibration metrics, up to 2.5x in accuracy and 2.4x in\ncalibration. Additionally, due to properties of its generative process,EPIFNP\nlearns the relations between the current season and similar patterns of\nhistorical seasons,enabling interpretable forecasts. Beyond epidemic\nforecasting, the EPIFNP can be of independent interest for advancing principled\nuncertainty quantification in deep sequential models for predictive analytics\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 18:31:47 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Kamarthi", "Harshavardhan", ""], ["Kong", "Lingkai", ""], ["Rodr\u00edguez", "Alexander", ""], ["Zhang", "Chao", ""], ["Prakash", "B. Aditya", ""]]}, {"id": "2106.03906", "submitter": "Ibrahim Abdelaziz", "authors": "Ibrahim Abdelaziz, Maxwell Crouse, Bassem Makni, Vernon Austil,\n  Cristina Cornelio, Shajith Ikbal, Pavan Kapanipathi, Ndivhuwo Makondo,\n  Kavitha Srinivas, Michael Witbrock, Achille Fokoue", "title": "Learning to Guide a Saturation-Based Theorem Prover", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional automated theorem provers have relied on manually tuned\nheuristics to guide how they perform proof search. Recently, however, there has\nbeen a surge of interest in the design of learning mechanisms that can be\nintegrated into theorem provers to improve their performance automatically. In\nthis work, we introduce TRAIL, a deep learning-based approach to theorem\nproving that characterizes core elements of saturation-based theorem proving\nwithin a neural framework. TRAIL leverages (a) an effective graph neural\nnetwork for representing logical formulas, (b) a novel neural representation of\nthe state of a saturation-based theorem prover in terms of processed clauses\nand available actions, and (c) a novel representation of the inference\nselection process as an attention-based action policy. We show through a\nsystematic analysis that these components allow TRAIL to significantly\noutperform previous reinforcement learning-based theorem provers on two\nstandard benchmark datasets (up to 36% more theorems proved). In addition, to\nthe best of our knowledge, TRAIL is the first reinforcement learning-based\napproach to exceed the performance of a state-of-the-art traditional theorem\nprover on a standard theorem proving benchmark (solving up to 17% more\nproblems).\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 18:35:57 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Abdelaziz", "Ibrahim", ""], ["Crouse", "Maxwell", ""], ["Makni", "Bassem", ""], ["Austil", "Vernon", ""], ["Cornelio", "Cristina", ""], ["Ikbal", "Shajith", ""], ["Kapanipathi", "Pavan", ""], ["Makondo", "Ndivhuwo", ""], ["Srinivas", "Kavitha", ""], ["Witbrock", "Michael", ""], ["Fokoue", "Achille", ""]]}, {"id": "2106.03911", "submitter": "Kevin Zakka", "authors": "Kevin Zakka, Andy Zeng, Pete Florence, Jonathan Tompson, Jeannette\n  Bohg, Debidatta Dwibedi", "title": "XIRL: Cross-embodiment Inverse Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the visual cross-embodiment imitation setting, in which agents\nlearn policies from videos of other agents (such as humans) demonstrating the\nsame task, but with stark differences in their embodiments -- shape, actions,\nend-effector dynamics, etc. In this work, we demonstrate that it is possible to\nautomatically discover and learn vision-based reward functions from\ncross-embodiment demonstration videos that are robust to these differences.\nSpecifically, we present a self-supervised method for Cross-embodiment Inverse\nReinforcement Learning (XIRL) that leverages temporal cycle-consistency\nconstraints to learn deep visual embeddings that capture task progression from\noffline videos of demonstrations across multiple expert agents, each performing\nthe same task differently due to embodiment differences. Prior to our work,\nproducing rewards from self-supervised embeddings has typically required\nalignment with a reference trajectory, which may be difficult to acquire. We\nshow empirically that if the embeddings are aware of task-progress, simply\ntaking the negative distance between the current state and goal state in the\nlearned embedding space is useful as a reward for training policies with\nreinforcement learning. We find our learned reward function not only works for\nembodiments seen during training, but also generalizes to entirely new\nembodiments. We also find that XIRL policies are more sample efficient than\nbaselines, and in some cases exceed the sample efficiency of the same agent\ntrained with ground truth sparse rewards.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 18:45:07 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Zakka", "Kevin", ""], ["Zeng", "Andy", ""], ["Florence", "Pete", ""], ["Tompson", "Jonathan", ""], ["Bohg", "Jeannette", ""], ["Dwibedi", "Debidatta", ""]]}, {"id": "2106.03921", "submitter": "Piotr Pi\\k{e}kos", "authors": "Piotr Pi\\k{e}kos, Henryk Michalewski, Mateusz Malinowski", "title": "Measuring and Improving BERT's Mathematical Abilities by Predicting the\n  Order of Reasoning", "comments": "The paper has been accepted to the ACL-IJCNLP 2021 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Imagine you are in a supermarket. You have two bananas in your basket and\nwant to buy four apples. How many fruits do you have in total? This seemingly\nstraightforward question can be challenging for data-driven language models,\neven if trained at scale. However, we would expect such generic language models\nto possess some mathematical abilities in addition to typical linguistic\ncompetence. Towards this goal, we investigate if a commonly used language\nmodel, BERT, possesses such mathematical abilities and, if so, to what degree.\nFor that, we fine-tune BERT on a popular dataset for word math problems,\nAQuA-RAT, and conduct several tests to understand learned representations\nbetter. Since we teach models trained on natural language to do formal\nmathematics, we hypothesize that such models would benefit from training on\nsemi-formal steps that explain how math results are derived. To better\naccommodate such training, we also propose new pretext tasks for learning\nmathematical rules. We call them (Neighbor) Reasoning Order Prediction (ROP or\nNROP). With this new model, we achieve significantly better outcomes than\ndata-driven baselines and even on-par with more tailored models. We also show\nhow to reduce positional bias in such models.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 19:08:29 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Pi\u0119kos", "Piotr", ""], ["Michalewski", "Henryk", ""], ["Malinowski", "Mateusz", ""]]}, {"id": "2106.03926", "submitter": "Andrea Baisero", "authors": "Andrea Baisero and Christopher Amato", "title": "Reconciling Rewards with Predictive State Representations", "comments": "IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Predictive state representations (PSRs) are models of controlled non-Markov\nobservation sequences which exhibit the same generative process governing POMDP\nobservations without relying on an underlying latent state. In that respect, a\nPSR is indistinguishable from the corresponding POMDP. However, PSRs\nnotoriously ignore the notion of rewards, which undermines the general utility\nof PSR models for control, planning, or reinforcement learning. Therefore, we\ndescribe a sufficient and necessary accuracy condition which determines whether\na PSR is able to accurately model POMDP rewards, we show that rewards can be\napproximated even when the accuracy condition is not satisfied, and we find\nthat a non-trivial number of POMDPs taken from a well-known third-party\nrepository do not satisfy the accuracy condition. We propose reward-predictive\nstate representations (R-PSRs), a generalization of PSRs which accurately\nmodels both observations and rewards, and develop value iteration for R-PSRs.\nWe show that there is a mismatch between optimal POMDP policies and the optimal\nPSR policies derived from approximate rewards. On the other hand, optimal R-PSR\npolicies perfectly match optimal POMDP policies, reconfirming R-PSRs as\naccurate state-less generative models of observations and rewards.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 19:32:08 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Baisero", "Andrea", ""], ["Amato", "Christopher", ""]]}, {"id": "2106.03927", "submitter": "Stephen McAleer", "authors": "Stephen McAleer, John Lanier, Michael Dennis, Pierre Baldi, Roy Fox", "title": "Improving Social Welfare While Preserving Autonomy via a Pareto Mediator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning algorithms often make decisions on behalf of agents with\nvaried and sometimes conflicting interests. In domains where agents can choose\nto take their own action or delegate their action to a central mediator, an\nopen question is how mediators should take actions on behalf of delegating\nagents. The main existing approach uses delegating agents to punish\nnon-delegating agents in an attempt to get all agents to delegate, which tends\nto be costly for all. We introduce a Pareto Mediator which aims to improve\noutcomes for delegating agents without making any of them worse off. Our\nexperiments in random normal form games, a restaurant recommendation game, and\na reinforcement learning sequential social dilemma show that the Pareto\nMediator greatly increases social welfare. Also, even when the Pareto Mediator\nis based on an incorrect model of agent utility, performance gracefully\ndegrades to the pre-intervention level, due to the individual autonomy\npreserved by the voluntary mediator.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 19:34:42 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["McAleer", "Stephen", ""], ["Lanier", "John", ""], ["Dennis", "Michael", ""], ["Baldi", "Pierre", ""], ["Fox", "Roy", ""]]}, {"id": "2106.03931", "submitter": "Argenis Arriojas", "authors": "Argenis Arriojas, Stas Tiomkin and Rahul V. Kulkarni", "title": "Closed-Form Analytical Results for Maximum Entropy Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.stat-mech cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We introduce a mapping between Maximum Entropy Reinforcement Learning (MaxEnt\nRL) and Markovian processes conditioned on rare events. In the long time limit,\nthis mapping allows us to derive analytical expressions for the optimal policy,\ndynamics and initial state distributions for the general case of stochastic\ndynamics in MaxEnt RL. We find that soft-$\\mathcal{Q}$ functions in MaxEnt RL\ncan be obtained from the Perron-Frobenius eigenvalue and the corresponding left\neigenvector of a regular, non-negative matrix derived from the underlying\nMarkov Decision Process (MDP). The results derived lead to novel algorithms for\nmodel-based and model-free MaxEnt RL, which we validate by numerical\nsimulations. The mapping established in this work opens further avenues for the\napplication of novel analytical and computational approaches to problems in\nMaxEnt RL. We make our code available at:\nhttps://github.com/argearriojas/maxent-rl-mdp-scripts\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 19:42:06 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Arriojas", "Argenis", ""], ["Tiomkin", "Stas", ""], ["Kulkarni", "Rahul V.", ""]]}, {"id": "2106.03934", "submitter": "Anton Dereventsov", "authors": "Anton Dereventsov and Joseph D. Daws Jr. and Clayton Webster", "title": "Offline Policy Comparison under Limited Historical Agent-Environment\n  Interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the challenge of policy evaluation in real-world applications of\nreinforcement learning systems where the available historical data is limited\ndue to ethical, practical, or security considerations. This constrained\ndistribution of data samples often leads to biased policy evaluation estimates.\nTo remedy this, we propose that instead of policy evaluation, one should\nperform policy comparison, i.e. to rank the policies of interest in terms of\ntheir value based on available historical data. In addition we present the\nLimited Data Estimator (LDE) as a simple method for evaluating and comparing\npolicies from a small number of interactions with the environment. According to\nour theoretical analysis, the LDE is shown to be statistically reliable on\npolicy comparison tasks under mild assumptions on the distribution of the\nhistorical data. Additionally, our numerical experiments compare the LDE to\nother policy evaluation methods on the task of policy ranking and demonstrate\nits advantage in various settings.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 19:51:00 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Dereventsov", "Anton", ""], ["Daws", "Joseph D.", "Jr."], ["Webster", "Clayton", ""]]}, {"id": "2106.03954", "submitter": "Gean Pereira", "authors": "Geand Trindade Pereira, Moises Rocha dos Santos, Andre Carlos Ponce de\n  Leon Ferreira de Carvalho", "title": "Evaluating Meta-Feature Selection for the Algorithm Recommendation\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the popularity of Machine Learning (ML) solutions, algorithms and data\nhave been released faster than the capacity of processing them. In this\ncontext, the problem of Algorithm Recommendation (AR) is receiving a\nsignificant deal of attention recently. This problem has been addressed in the\nliterature as a learning task, often as a Meta-Learning problem where the aim\nis to recommend the best alternative for a specific dataset. For such, datasets\nencoded by meta-features are explored by ML algorithms that try to learn the\nmapping between meta-representations and the best technique to be used. One of\nthe challenges for the successful use of ML is to define which features are the\nmost valuable for a specific dataset since several meta-features can be used,\nwhich increases the meta-feature dimension. This paper presents an empirical\nanalysis of Feature Selection and Feature Extraction in the meta-level for the\nAR problem. The present study was focused on three criteria: predictive\nperformance, dimensionality reduction, and pipeline runtime. As we verified,\napplying Dimensionality Reduction (DR) methods did not improve predictive\nperformances in general. However, DR solutions reduced about 80% of the\nmeta-features, obtaining pretty much the same performance as the original setup\nbut with lower runtimes. The only exception was PCA, which presented about the\nsame runtime as the original meta-features. Experimental results also showed\nthat various datasets have many non-informative meta-features and that it is\npossible to obtain high predictive performance using around 20% of the original\nmeta-features. Therefore, due to their natural trend for high dimensionality,\nDR methods should be used for Meta-Feature Selection and Meta-Feature\nExtraction.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 20:36:47 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 19:36:20 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Pereira", "Geand Trindade", ""], ["Santos", "Moises Rocha dos", ""], ["de Carvalho", "Andre Carlos Ponce de Leon Ferreira", ""]]}, {"id": "2106.03962", "submitter": "Sahil Verma", "authors": "Sahil Verma, Keegan Hines, John P. Dickerson", "title": "Amortized Generation of Sequential Counterfactual Explanations for\n  Black-box Models", "comments": "19 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Explainable machine learning (ML) has gained traction in recent years due to\nthe increasing adoption of ML-based systems in many sectors. Counterfactual\nexplanations (CFEs) provide ``what if'' feedback of the form ``if an input\ndatapoint were $x'$ instead of $x$, then an ML-based system's output would be\n$y'$ instead of $y$.'' CFEs are attractive due to their actionable feedback,\namenability to existing legal frameworks, and fidelity to the underlying ML\nmodel. Yet, current CFE approaches are single shot -- that is, they assume $x$\ncan change to $x'$ in a single time period. We propose a novel\nstochastic-control-based approach that generates sequential CFEs, that is, CFEs\nthat allow $x$ to move stochastically and sequentially across intermediate\nstates to a final state $x'$. Our approach is model agnostic and black box.\nFurthermore, calculation of CFEs is amortized such that once trained, it\napplies to multiple datapoints without the need for re-optimization. In\naddition to these primary characteristics, our approach admits optional\ndesiderata such as adherence to the data manifold, respect for causal\nrelations, and sparsity -- identified by past research as desirable properties\nof CFEs. We evaluate our approach using three real-world datasets and show\nsuccessful generation of sequential CFEs that respect other counterfactual\ndesiderata.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 20:54:48 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Verma", "Sahil", ""], ["Hines", "Keegan", ""], ["Dickerson", "John P.", ""]]}, {"id": "2106.03970", "submitter": "Hadi Daneshmand", "authors": "Hadi Daneshmand, Amir Joudaki, Francis Bach", "title": "Batch Normalization Orthogonalizes Representations in Deep Random\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper underlines a subtle property of batch-normalization (BN):\nSuccessive batch normalizations with random linear transformations make hidden\nrepresentations increasingly orthogonal across layers of a deep neural network.\nWe establish a non-asymptotic characterization of the interplay between depth,\nwidth, and the orthogonality of deep representations. More precisely, under a\nmild assumption, we prove that the deviation of the representations from\northogonality rapidly decays with depth up to a term inversely proportional to\nthe network width. This result has two main implications: 1) Theoretically, as\nthe depth grows, the distribution of the representation -- after the linear\nlayers -- contracts to a Wasserstein-2 ball around an isotropic Gaussian\ndistribution. Furthermore, the radius of this Wasserstein ball shrinks with the\nwidth of the network. 2) In practice, the orthogonality of the representations\ndirectly influences the performance of stochastic gradient descent (SGD). When\nrepresentations are initially aligned, we observe SGD wastes many iterations to\northogonalize representations before the classification. Nevertheless, we\nexperimentally show that starting optimization from orthogonal representations\nis sufficient to accelerate SGD, with no need for BN.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 21:14:59 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Daneshmand", "Hadi", ""], ["Joudaki", "Amir", ""], ["Bach", "Francis", ""]]}, {"id": "2106.03973", "submitter": "Debjit Paul", "authors": "Debjit Paul and Anette Frank", "title": "Generating Hypothetical Events for Abductive Inference", "comments": "Proceedings of The Tenth Joint Conference on Lexical and\n  Computational Semantics (STARSEM 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Abductive reasoning starts from some observations and aims at finding the\nmost plausible explanation for these observations. To perform abduction, humans\noften make use of temporal and causal inferences, and knowledge about how some\nhypothetical situation can result in different outcomes. This work offers the\nfirst study of how such knowledge impacts the Abductive NLI task -- which\nconsists in choosing the more likely explanation for given observations. We\ntrain a specialized language model LMI that is tasked to generate what could\nhappen next from a hypothetical scenario that evolves from a given event. We\nthen propose a multi-task model MTL to solve the Abductive NLI task, which\npredicts a plausible explanation by a) considering different possible events\nemerging from candidate hypotheses -- events generated by LMI -- and b)\nselecting the one that is most similar to the observed outcome. We show that\nour MTL model improves over prior vanilla pre-trained LMs fine-tuned on\nAbductive NLI. Our manual evaluation and analysis suggest that learning about\npossible next events from different hypothetical scenarios supports abductive\ninference.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 21:34:11 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Paul", "Debjit", ""], ["Frank", "Anette", ""]]}, {"id": "2106.03983", "submitter": "Hai Hu", "authors": "Hai Hu, He Zhou, Zuoyu Tian, Yiwen Zhang, Yina Ma, Yanting Li, Yixin\n  Nie, Kyle Richardson", "title": "Investigating Transfer Learning in Multilingual Pre-trained Language\n  Models through Chinese Natural Language Inference", "comments": "accepted to ACL Findings 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual transformers (XLM, mT5) have been shown to have remarkable\ntransfer skills in zero-shot settings. Most transfer studies, however, rely on\nautomatically translated resources (XNLI, XQuAD), making it hard to discern the\nparticular linguistic knowledge that is being transferred, and the role of\nexpert annotated monolingual datasets when developing task-specific models. We\ninvestigate the cross-lingual transfer abilities of XLM-R for Chinese and\nEnglish natural language inference (NLI), with a focus on the recent\nlarge-scale Chinese dataset OCNLI. To better understand linguistic transfer, we\ncreated 4 categories of challenge and adversarial tasks (totaling 17 new\ndatasets) for Chinese that build on several well-known resources for English\n(e.g., HANS, NLI stress-tests). We find that cross-lingual models trained on\nEnglish NLI do transfer well across our Chinese tasks (e.g., in 3/4 of our\nchallenge categories, they perform as well/better than the best monolingual\nmodels, even on 3/5 uniquely Chinese linguistic phenomena such as idioms, pro\ndrop). These results, however, come with important caveats: cross-lingual\nmodels often perform best when trained on a mixture of English and high-quality\nmonolingual NLI data (OCNLI), and are often hindered by automatically\ntranslated resources (XNLI-zh). For many phenomena, all models continue to\nstruggle, highlighting the need for our new diagnostics to help benchmark\nChinese and cross-lingual models. All new datasets/code are released at\nhttps://github.com/huhailinguist/ChineseNLIProbing.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 22:00:18 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Hu", "Hai", ""], ["Zhou", "He", ""], ["Tian", "Zuoyu", ""], ["Zhang", "Yiwen", ""], ["Ma", "Yina", ""], ["Li", "Yanting", ""], ["Nie", "Yixin", ""], ["Richardson", "Kyle", ""]]}, {"id": "2106.04011", "submitter": "AkshatKumar Nigam Mr", "authors": "AkshatKumar Nigam, Robert Pollice, Alan Aspuru-Guzik", "title": "JANUS: Parallel Tempered Genetic Algorithm Guided by Deep Neural\n  Networks for Inverse Molecular Design", "comments": "20 pages, 12 figures, 4 tables. Comments are welcome! (code will be\n  uploaded when paper is formally published)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse molecular design, i.e., designing molecules with specific target\nproperties, can be posed as an optimization problem. High-dimensional\noptimization tasks in the natural sciences are commonly tackled via\npopulation-based metaheuristic optimization algorithms such as evolutionary\nalgorithms. However, expensive property evaluation, which is often required,\ncan limit the widespread use of such approaches as the associated cost can\nbecome prohibitive. Herein, we present JANUS, a genetic algorithm that is\ninspired by parallel tempering. It propagates two populations, one for\nexploration and another for exploitation, improving optimization by reducing\nexpensive property evaluations. Additionally, JANUS is augmented by a deep\nneural network that approximates molecular properties via active learning for\nenhanced sampling of the chemical space. Our method uses the SELFIES molecular\nrepresentation and the STONED algorithm for the efficient generation of\nstructures, and outperforms other generative models in common inverse molecular\ndesign tasks achieving state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 23:41:34 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Nigam", "AkshatKumar", ""], ["Pollice", "Robert", ""], ["Aspuru-Guzik", "Alan", ""]]}, {"id": "2106.04021", "submitter": "Pedro Silva MSc.", "authors": "P. H. O. Silva, A. S. Cerqueira, E. G. Nepomuceno", "title": "Hybrid Method Based on NARX models and Machine Learning for Pattern\n  Recognition", "comments": "In English. SBAI 2021 - Brazilian Symposium on Intelligent Automation\n  (SBAI - Simposio Brasileiro de Automacao Inteligente). 6 pages. 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a novel technique that integrates the methodologies of\nmachine learning and system identification to solve multiclass problems. Such\nan approach allows to extract and select sets of representative features with\nreduced dimensionality, as well as predicts categorical outputs. The efficiency\nof the method was tested by running case studies investigated in machine\nlearning, obtaining better absolute results when compared with classical\nclassification algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 00:17:36 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Silva", "P. H. O.", ""], ["Cerqueira", "A. S.", ""], ["Nepomuceno", "E. G.", ""]]}, {"id": "2106.04026", "submitter": "Dae-Hyeok Lee", "authors": "Dae-Hyeok Lee, Dong-Kyun Han, Sung-Jin Kim, Ji-Hoon Jeong, and\n  Seong-Whan Lee", "title": "Subject-Independent Brain-Computer Interface for Decoding High-Level\n  Visual Imagery Tasks", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI eess.IV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain-computer interface (BCI) is used for communication between humans and\ndevices by recognizing status and intention of humans. Communication between\nhumans and a drone using electroencephalogram (EEG) signals is one of the most\nchallenging issues in the BCI domain. In particular, the control of drone\nswarms (the direction and formation) has more advantages compared to the\ncontrol of a drone. The visual imagery (VI) paradigm is that subjects visually\nimagine specific objects or scenes. Reduction of the variability among EEG\nsignals of subjects is essential for practical BCI-based systems. In this\nstudy, we proposed the subepoch-wise feature encoder (SEFE) to improve the\nperformances in the subject-independent tasks by using the VI dataset. This\nstudy is the first attempt to demonstrate the possibility of generalization\namong subjects in the VI-based BCI. We used the leave-one-subject-out\ncross-validation for evaluating the performances. We obtained higher\nperformances when including our proposed module than excluding our proposed\nmodule. The DeepConvNet with SEFE showed the highest performance of 0.72 among\nsix different decoding models. Hence, we demonstrated the feasibility of\ndecoding the VI dataset in the subject-independent task with robust\nperformances by using our proposed module.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 00:39:31 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Lee", "Dae-Hyeok", ""], ["Han", "Dong-Kyun", ""], ["Kim", "Sung-Jin", ""], ["Jeong", "Ji-Hoon", ""], ["Lee", "Seong-Whan", ""]]}, {"id": "2106.04033", "submitter": "Ellen Vitercik", "authors": "Maria-Florina Balcan, Siddharth Prasad, Tuomas Sandholm, Ellen\n  Vitercik", "title": "Sample Complexity of Tree Search Configuration: Cutting Planes and\n  Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cutting-plane methods have enabled remarkable successes in integer\nprogramming over the last few decades. State-of-the-art solvers integrate a\nmyriad of cutting-plane techniques to speed up the underlying tree-search\nalgorithm used to find optimal solutions. In this paper we prove the first\nguarantees for learning high-performing cut-selection policies tailored to the\ninstance distribution at hand using samples. We first bound the sample\ncomplexity of learning cutting planes from the canonical family of\nChv\\'atal-Gomory cuts. Our bounds handle any number of waves of any number of\ncuts and are fine tuned to the magnitudes of the constraint coefficients. Next,\nwe prove sample complexity bounds for more sophisticated cut selection policies\nthat use a combination of scoring rules to choose from a family of cuts.\nFinally, beyond the realm of cutting planes for integer programming, we develop\na general abstraction of tree search that captures key components such as node\nselection and variable selection. For this abstraction, we bound the sample\ncomplexity of learning a good policy for building the search tree.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 00:57:59 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Balcan", "Maria-Florina", ""], ["Prasad", "Siddharth", ""], ["Sandholm", "Tuomas", ""], ["Vitercik", "Ellen", ""]]}, {"id": "2106.04051", "submitter": "Haoxuan You", "authors": "Yang Hu, Haoxuan You, Zhecan Wang, Zhicheng Wang, Erjin Zhou, Yue Gao", "title": "Graph-MLP: Node Classification without Message Passing in Graph", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Network (GNN) has been demonstrated its effectiveness in dealing\nwith non-Euclidean structural data. Both spatial-based and spectral-based GNNs\nare relying on adjacency matrix to guide message passing among neighbors during\nfeature aggregation. Recent works have mainly focused on powerful message\npassing modules, however, in this paper, we show that none of the message\npassing modules is necessary. Instead, we propose a pure\nmultilayer-perceptron-based framework, Graph-MLP with the supervision signal\nleveraging graph structure, which is sufficient for learning discriminative\nnode representation. In model-level, Graph-MLP only includes multi-layer\nperceptrons, activation function, and layer normalization. In the loss level,\nwe design a neighboring contrastive (NContrast) loss to bridge the gap between\nGNNs and MLPs by utilizing the adjacency information implicitly. This design\nallows our model to be lighter and more robust when facing large-scale graph\ndata and corrupted adjacency information. Extensive experiments prove that even\nwithout adjacency information in testing phase, our framework can still reach\ncomparable and even superior performance against the state-of-the-art models in\nthe graph node classification task.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 02:07:21 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Hu", "Yang", ""], ["You", "Haoxuan", ""], ["Wang", "Zhecan", ""], ["Wang", "Zhicheng", ""], ["Zhou", "Erjin", ""], ["Gao", "Yue", ""]]}, {"id": "2106.04066", "submitter": "Wenhao Ding", "authors": "Wenhao Ding, Bo Li, Kim Ji Eun, Ding Zhao", "title": "Semantically Controllable Scene Generation with Guidance of Explicit\n  Knowledge", "comments": "14 pages, 6 figures, Submitted to NeurIPS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Generative Models (DGMs) are known for their superior capability in\ngenerating realistic data. Extending purely data-driven approaches, recent\nspecialized DGMs may satisfy additional controllable requirements such as\nembedding a traffic sign in a driving scene, by manipulating patterns\n\\textit{implicitly} in the neuron or feature level. In this paper, we introduce\na novel method to incorporate domain knowledge \\textit{explicitly} in the\ngeneration process to achieve semantically controllable scene generation. We\ncategorize our knowledge into two types to be consistent with the composition\nof natural scenes, where the first type represents the property of objects and\nthe second type represents the relationship among objects. We then propose a\ntree-structured generative model to learn complex scene representation, whose\nnodes and edges are naturally corresponding to the two types of knowledge\nrespectively. Knowledge can be explicitly integrated to enable semantically\ncontrollable scene generation by imposing semantic rules on properties of nodes\nand edges in the tree structure. We construct a synthetic example to illustrate\nthe controllability and explainability of our method in a clean setting. We\nfurther extend the synthetic example to realistic autonomous vehicle driving\nenvironments and conduct extensive experiments to show that our method\nefficiently identifies adversarial traffic scenes against different\nstate-of-the-art 3D point cloud segmentation models satisfying the traffic\nrules specified as the explicit knowledge.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 02:51:33 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 20:30:13 GMT"}, {"version": "v3", "created": "Tue, 27 Jul 2021 19:08:51 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Ding", "Wenhao", ""], ["Li", "Bo", ""], ["Eun", "Kim Ji", ""], ["Zhao", "Ding", ""]]}, {"id": "2106.04072", "submitter": "Otilia Stretcu", "authors": "Otilia Stretcu, Emmanouil Antonios Platanios, Tom M. Mitchell,\n  Barnab\\'as P\\'oczos", "title": "Coarse-to-Fine Curriculum Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When faced with learning challenging new tasks, humans often follow sequences\nof steps that allow them to incrementally build up the necessary skills for\nperforming these new tasks. However, in machine learning, models are most often\ntrained to solve the target tasks directly.Inspired by human learning, we\npropose a novel curriculum learning approach which decomposes challenging tasks\ninto sequences of easier intermediate goals that are used to pre-train a model\nbefore tackling the target task. We focus on classification tasks, and design\nthe intermediate tasks using an automatically constructed label hierarchy. We\ntrain the model at each level of the hierarchy, from coarse labels to fine\nlabels, transferring acquired knowledge across these levels. For instance, the\nmodel will first learn to distinguish animals from objects, and then use this\nacquired knowledge when learning to classify among more fine-grained classes\nsuch as cat, dog, car, and truck. Most existing curriculum learning algorithms\nfor supervised learning consist of scheduling the order in which the training\nexamples are presented to the model. In contrast, our approach focuses on the\noutput space of the model. We evaluate our method on several established\ndatasets and show significant performance gains especially on classification\nproblems with many labels. We also evaluate on a new synthetic dataset which\nallows us to study multiple aspects of our method.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 03:09:38 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Stretcu", "Otilia", ""], ["Platanios", "Emmanouil Antonios", ""], ["Mitchell", "Tom M.", ""], ["P\u00f3czos", "Barnab\u00e1s", ""]]}, {"id": "2106.04075", "submitter": "Hongchang Wu", "authors": "Ziyu Guan, Hongchang Wu, Qingyu Cao, Hao Liu, Wei Zhao, Sheng Li, Cai\n  Xu, Guang Qiu, Jian Xu, Bo Zheng", "title": "Multi-Agent Cooperative Bidding Games for Multi-Objective Optimization\n  in e-Commercial Sponsored Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bid optimization for online advertising from single advertiser's perspective\nhas been thoroughly investigated in both academic research and industrial\npractice. However, existing work typically assume competitors do not change\ntheir bids, i.e., the wining price is fixed, leading to poor performance of the\nderived solution. Although a few studies use multi-agent reinforcement learning\nto set up a cooperative game, they still suffer the following drawbacks: (1)\nThey fail to avoid collusion solutions where all the advertisers involved in an\nauction collude to bid an extremely low price on purpose. (2) Previous works\ncannot well handle the underlying complex bidding environment, leading to poor\nmodel convergence. This problem could be amplified when handling multiple\nobjectives of advertisers which are practical demands but not considered by\nprevious work. In this paper, we propose a novel multi-objective cooperative\nbid optimization formulation called Multi-Agent Cooperative bidding Games\n(MACG). MACG sets up a carefully designed multi-objective optimization\nframework where different objectives of advertisers are incorporated. A global\nobjective to maximize the overall profit of all advertisements is added in\norder to encourage better cooperation and also to protect self-bidding\nadvertisers. To avoid collusion, we also introduce an extra platform revenue\nconstraint. We analyze the optimal functional form of the bidding formula\ntheoretically and design a policy network accordingly to generate auction-level\nbids. Then we design an efficient multi-agent evolutionary strategy for model\noptimization. Offline experiments and online A/B tests conducted on the Taobao\nplatform indicate both single advertiser's objective and global profit have\nbeen significantly improved compared to state-of-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 03:18:28 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Guan", "Ziyu", ""], ["Wu", "Hongchang", ""], ["Cao", "Qingyu", ""], ["Liu", "Hao", ""], ["Zhao", "Wei", ""], ["Li", "Sheng", ""], ["Xu", "Cai", ""], ["Qiu", "Guang", ""], ["Xu", "Jian", ""], ["Zheng", "Bo", ""]]}, {"id": "2106.04127", "submitter": "Sixing Yin", "authors": "Sixing Yin, Yameng Han, Shufang Li", "title": "Left Ventricle Contouring in Cardiac Images Based on Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Medical image segmentation is one of the important tasks of computer-aided\ndiagnosis in medical image analysis. Since most medical images have the\ncharacteristics of blurred boundaries and uneven intensity distribution,\nthrough existing segmentation methods, the discontinuity within the target area\nand the discontinuity of the target boundary are likely to lead to rough or\neven erroneous boundary delineation. In this paper, we propose a new iterative\nrefined interactive segmentation method for medical images based on agent\nreinforcement learning, which focuses on the problem of target segmentation\nboundaries. We model the dynamic process of drawing the target contour in a\ncertain order as a Markov Decision Process (MDP) based on a deep reinforcement\nlearning method. In the dynamic process of continuous interaction between the\nagent and the image, the agent tracks the boundary point by point in order\nwithin a limited length range until the contour of the target is completely\ndrawn. In this process, the agent can quickly improve the segmentation\nperformance by exploring an interactive policy in the image. The method we\nproposed is simple and effective. At the same time, we evaluate our method on\nthe cardiac MRI scan data set. Experimental results show that our method has a\nbetter segmentation effect on the left ventricle in a small number of medical\nimage data sets, especially in terms of segmentation boundaries, this method is\nbetter than existing methods. Based on our proposed method, the dynamic\ngeneration process of the predicted contour trajectory of the left ventricle\nwill be displayed online at https://github.com/H1997ym/LV-contour-trajectory.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 06:30:32 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Yin", "Sixing", ""], ["Han", "Yameng", ""], ["Li", "Shufang", ""]]}, {"id": "2106.04134", "submitter": "Hoang Nguyen Hung Van", "authors": "Hoang Van, Vikas Yadav, Mihai Surdeanu", "title": "Cheap and Good? Simple and Effective Data Augmentation for Low Resource\n  Machine Reading", "comments": "5 pages, 1 figure, SIGIR 2021", "journal-ref": null, "doi": "10.1145/3404835.3463099", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple and effective strategy for data augmentation for\nlow-resource machine reading comprehension (MRC). Our approach first pretrains\nthe answer extraction components of a MRC system on the augmented data that\ncontains approximate context of the correct answers, before training it on the\nexact answer spans. The approximate context helps the QA method components in\nnarrowing the location of the answers. We demonstrate that our simple strategy\nsubstantially improves both document retrieval and answer extraction\nperformance by providing larger context of the answers and additional training\ndata. In particular, our method significantly improves the performance of BERT\nbased retriever (15.12\\%), and answer extractor (4.33\\% F1) on TechQA, a\ncomplex, low-resource MRC task. Further, our data augmentation strategy yields\nsignificant improvements of up to 3.9\\% exact match (EM) and 2.7\\% F1 for\nanswer extraction on PolicyQA, another practical but moderate sized QA dataset\nthat also contains long answer spans.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 06:46:50 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Van", "Hoang", ""], ["Yadav", "Vikas", ""], ["Surdeanu", "Mihai", ""]]}, {"id": "2106.04146", "submitter": "Ayoosh Bansal", "authors": "Ayoosh Bansal, Jayati Singh, Micaela Verucchi, Marco Caccamo and Lui\n  Sha", "title": "Risk Ranked Recall: Collision Safety Metric for Object Detection Systems\n  in Autonomous Vehicles", "comments": "Cyber-Physical Systems and Internet-of-Things 2021", "journal-ref": "2021 10th Mediterranean Conference on Embedded Computing (MECO)", "doi": "10.1109/MECO52532.2021.9460196", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonly used metrics for evaluation of object detection systems (precision,\nrecall, mAP) do not give complete information about their suitability of use in\nsafety critical tasks, like obstacle detection for collision avoidance in\nAutonomous Vehicles (AV). This work introduces the Risk Ranked Recall ($R^3$)\nmetrics for object detection systems. The $R^3$ metrics categorize objects\nwithin three ranks. Ranks are assigned based on an objective cyber-physical\nmodel for the risk of collision. Recall is measured for each rank.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 07:30:43 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Bansal", "Ayoosh", ""], ["Singh", "Jayati", ""], ["Verucchi", "Micaela", ""], ["Caccamo", "Marco", ""], ["Sha", "Lui", ""]]}, {"id": "2106.04148", "submitter": "Nils Thoma", "authors": "Nils Thoma, Zhongjie Yu, Fabrizio Ventola, Kristian Kersting", "title": "RECOWNs: Probabilistic Circuits for Trustworthy Time Series Forecasting", "comments": "Accepted for the 4th Workshop on Tractable Probabilistic Modeling\n  (TPM 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series forecasting is a relevant task that is performed in several\nreal-world scenarios such as product sales analysis and prediction of energy\ndemand. Given their accuracy performance, currently, Recurrent Neural Networks\n(RNNs) are the models of choice for this task. Despite their success in time\nseries forecasting, less attention has been paid to make the RNNs trustworthy.\nFor example, RNNs can not naturally provide an uncertainty measure to their\npredictions. This could be extremely useful in practice in several cases e.g.\nto detect when a prediction might be completely wrong due to an unusual pattern\nin the time series. Whittle Sum-Product Networks (WSPNs), prominent deep\ntractable probabilistic circuits (PCs) for time series, can assist an RNN with\nproviding meaningful probabilities as uncertainty measure. With this aim, we\npropose RECOWN, a novel architecture that employs RNNs and a discriminant\nvariant of WSPNs called Conditional WSPNs (CWSPNs). We also formulate a\nLog-Likelihood Ratio Score as better estimation of uncertainty that is tailored\nto time series and Whittle likelihoods. In our experiments, we show that\nRECOWNs are accurate and trustworthy time series predictors, able to \"know when\nthey do not know\".\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 07:32:12 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 12:23:00 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Thoma", "Nils", ""], ["Yu", "Zhongjie", ""], ["Ventola", "Fabrizio", ""], ["Kersting", "Kristian", ""]]}, {"id": "2106.04151", "submitter": "Jingjing Li", "authors": "Zhekai Du, Jingjing Li, Hongzu Su, Lei Zhu, Ke Lu", "title": "Cross-Domain Gradient Discrepancy Minimization for Unsupervised Domain\n  Adaptation", "comments": "Accepted to CVPR 2021, Codes are avaliable at\n  https://github.com/lijin118/CGDM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unsupervised Domain Adaptation (UDA) aims to generalize the knowledge learned\nfrom a well-labeled source domain to an unlabeled target domain. Recently,\nadversarial domain adaptation with two distinct classifiers (bi-classifier) has\nbeen introduced into UDA which is effective to align distributions between\ndifferent domains. Previous bi-classifier adversarial learning methods only\nfocus on the similarity between the outputs of two distinct classifiers.\nHowever, the similarity of the outputs cannot guarantee the accuracy of target\nsamples, i.e., target samples may match to wrong categories even if the\ndiscrepancy between two classifiers is small. To challenge this issue, in this\npaper, we propose a cross-domain gradient discrepancy minimization (CGDM)\nmethod which explicitly minimizes the discrepancy of gradients generated by\nsource samples and target samples. Specifically, the gradient gives a cue for\nthe semantic information of target samples so it can be used as a good\nsupervision to improve the accuracy of target samples. In order to compute the\ngradient signal of target samples, we further obtain target pseudo labels\nthrough a clustering-based self-supervised learning. Extensive experiments on\nthree widely used UDA datasets show that our method surpasses many previous\nstate-of-the-arts. Codes are available at https://github.com/lijin118/CGDM.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 07:35:40 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Du", "Zhekai", ""], ["Li", "Jingjing", ""], ["Su", "Hongzu", ""], ["Zhu", "Lei", ""], ["Lu", "Ke", ""]]}, {"id": "2106.04169", "submitter": "Salman Khan Dr.", "authors": "Muzammal Naseer, Kanchana Ranasinghe, Salman Khan, Fahad Shahbaz Khan,\n  Fatih Porikli", "title": "On Improving Adversarial Transferability of Vision Transformers", "comments": "Code: https://git.io/JZmG3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision transformers (ViTs) process input images as sequences of patches via\nself-attention; a radically different architecture than convolutional neural\nnetworks (CNNs). This makes it interesting to study the adversarial feature\nspace of ViT models and their transferability. In particular, we observe that\nadversarial patterns found via conventional adversarial attacks show very low\nblack-box transferability even for large ViT models. However, we show that this\nphenomenon is only due to the sub-optimal attack procedures that do not\nleverage the true representation potential of ViTs. A deep ViT is composed of\nmultiple blocks, with a consistent architecture comprising of self-attention\nand feed-forward layers, where each block is capable of independently producing\na class token. Formulating an attack using only the last class token\n(conventional approach) does not directly leverage the discriminative\ninformation stored in the earlier tokens, leading to poor adversarial\ntransferability of ViTs. Using the compositional nature of ViT models, we\nenhance the transferability of existing attacks by introducing two novel\nstrategies specific to the architecture of ViT models. (i) Self-Ensemble: We\npropose a method to find multiple discriminative pathways by dissecting a\nsingle ViT model into an ensemble of networks. This allows explicitly utilizing\nclass-specific information at each ViT block. (ii) Token Refinement: We then\npropose to refine the tokens to further enhance the discriminative capacity at\neach block of ViT. Our token refinement systematically combines the class\ntokens with structural information preserved within the patch tokens. An\nadversarial attack, when applied to such refined tokens within the ensemble of\nclassifiers found in a single vision transformer, has significantly higher\ntransferability.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 08:20:38 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Naseer", "Muzammal", ""], ["Ranasinghe", "Kanchana", ""], ["Khan", "Salman", ""], ["Khan", "Fahad Shahbaz", ""], ["Porikli", "Fatih", ""]]}, {"id": "2106.04174", "submitter": "Zijun Yao", "authors": "Zijun Yao, Chengjiang Li, Tiansi Dong, Xin Lv, Jifan Yu, Lei Hou,\n  Juanzi Li, Yichi Zhang, Zelin Dai", "title": "Interpretable and Low-Resource Entity Matching via Decoupling Feature\n  Learning from Decision Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity Matching (EM) aims at recognizing entity records that denote the same\nreal-world object. Neural EM models learn vector representation of entity\ndescriptions and match entities end-to-end. Though robust, these methods\nrequire many resources for training, and lack of interpretability. In this\npaper, we propose a novel EM framework that consists of Heterogeneous\nInformation Fusion (HIF) and Key Attribute Tree (KAT) Induction to decouple\nfeature representation from matching decision. Using self-supervised learning\nand mask mechanism in pre-trained language modeling, HIF learns the embeddings\nof noisy attribute values by inter-attribute attention with unlabeled data.\nUsing a set of comparison features and a limited amount of annotated data, KAT\nInduction learns an efficient decision tree that can be interpreted by\ngenerating entity matching rules whose structure is advocated by domain\nexperts. Experiments on 6 public datasets and 3 industrial datasets show that\nour method is highly efficient and outperforms SOTA EM models in most cases.\nOur codes and datasets can be obtained from https://github.com/THU-KEG/HIF-KAT.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 08:27:31 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Yao", "Zijun", ""], ["Li", "Chengjiang", ""], ["Dong", "Tiansi", ""], ["Lv", "Xin", ""], ["Yu", "Jifan", ""], ["Hou", "Lei", ""], ["Li", "Juanzi", ""], ["Zhang", "Yichi", ""], ["Dai", "Zelin", ""]]}, {"id": "2106.04180", "submitter": "Chenfeng Xu", "authors": "Chenfeng Xu, Shijia Yang, Bohan Zhai, Bichen Wu, Xiangyu Yue, Wei\n  Zhan, Peter Vajda, Kurt Keutzer, Masayoshi Tomizuka", "title": "Image2Point: 3D Point-Cloud Understanding with Pretrained 2D ConvNets", "comments": "The code is avaliable at:\n  \\url{https://github.com/chenfengxu714/image2point}", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D point-clouds and 2D images are different visual representations of the\nphysical world. While human vision can understand both representations,\ncomputer vision models designed for 2D image and 3D point-cloud understanding\nare quite different. Our paper investigates the potential for transferability\nbetween these two representations by empirically investigating whether this\napproach works, what factors affect the transfer performance, and how to make\nit work even better. We discovered that we can indeed use the same neural net\nmodel architectures to understand both images and point-clouds. Moreover, we\ncan transfer pretrained weights from image models to point-cloud models with\nminimal effort. Specifically, based on a 2D ConvNet pretrained on an image\ndataset, we can transfer the image model to a point-cloud model by\n\\textit{inflating} 2D convolutional filters to 3D then finetuning its input,\noutput, and optionally normalization layers. The transferred model can achieve\ncompetitive performance on 3D point-cloud classification, indoor and driving\nscene segmentation, even beating a wide range of point-cloud models that adopt\ntask-specific architectures and use a variety of tricks.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 08:42:55 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Xu", "Chenfeng", ""], ["Yang", "Shijia", ""], ["Zhai", "Bohan", ""], ["Wu", "Bichen", ""], ["Yue", "Xiangyu", ""], ["Zhan", "Wei", ""], ["Vajda", "Peter", ""], ["Keutzer", "Kurt", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "2106.04193", "submitter": "Louis Filstroff", "authors": "Louis Filstroff, Iiris Sundin, Petrus Mikkola, Aleksei Tiulpin, Juuso\n  Kylm\\\"aoja, Samuel Kaski", "title": "Targeted Active Learning for Bayesian Decision-Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning is usually applied to acquire labels of informative data\npoints in supervised learning, to maximize accuracy in a sample-efficient way.\nHowever, maximizing the accuracy is not the end goal when the results are used\nfor decision-making, for example in personalized medicine or economics. We\nargue that when acquiring samples sequentially, separating learning and\ndecision-making is sub-optimal, and we introduce a novel active learning\nstrategy which takes the down-the-line decision problem into account.\nSpecifically, we introduce a novel active learning criterion which maximizes\nthe expected information gain on the posterior distribution of the optimal\ndecision. We compare our decision-making-aware active learning strategy to\nexisting alternatives on both simulated and real data, and show improved\nperformance in decision-making accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 09:05:43 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Filstroff", "Louis", ""], ["Sundin", "Iiris", ""], ["Mikkola", "Petrus", ""], ["Tiulpin", "Aleksei", ""], ["Kylm\u00e4oja", "Juuso", ""], ["Kaski", "Samuel", ""]]}, {"id": "2106.04195", "submitter": "Pengpeng Liu", "authors": "Pengpeng Liu and Michael R. Lyu and Irwin King and Jia Xu", "title": "Learning by Distillation: A Self-Supervised Learning Framework for\n  Optical Flow Estimation", "comments": "TPAMI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DistillFlow, a knowledge distillation approach to learning optical\nflow. DistillFlow trains multiple teacher models and a student model, where\nchallenging transformations are applied to the input of the student model to\ngenerate hallucinated occlusions as well as less confident predictions. Then, a\nself-supervised learning framework is constructed: confident predictions from\nteacher models are served as annotations to guide the student model to learn\noptical flow for those less confident predictions. The self-supervised learning\nframework enables us to effectively learn optical flow from unlabeled data, not\nonly for non-occluded pixels, but also for occluded pixels. DistillFlow\nachieves state-of-the-art unsupervised learning performance on both KITTI and\nSintel datasets. Our self-supervised pre-trained model also provides an\nexcellent initialization for supervised fine-tuning, suggesting an alternate\ntraining paradigm in contrast to current supervised learning methods that\nhighly rely on pre-training on synthetic data. At the time of writing, our\nfine-tuned models ranked 1st among all monocular methods on the KITTI 2015\nbenchmark, and outperform all published methods on the Sintel Final benchmark.\nMore importantly, we demonstrate the generalization capability of DistillFlow\nin three aspects: framework generalization, correspondence generalization and\ncross-dataset generalization.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 09:13:34 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Liu", "Pengpeng", ""], ["Lyu", "Michael R.", ""], ["King", "Irwin", ""], ["Xu", "Jia", ""]]}, {"id": "2106.04216", "submitter": "Mark Anderson", "authors": "Mark Anderson and Carlos G\\'omez Rodr\\'iguez", "title": "A Modest Pareto Optimisation Analysis of Dependency Parsers in 2021", "comments": "To be published in proceedings of the 17th International Conference\n  on Parsing Technologies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We evaluate three leading dependency parser systems from different paradigms\non a small yet diverse subset of languages in terms of their\naccuracy-efficiency Pareto front. As we are interested in efficiency, we\nevaluate core parsers without pretrained language models (as these are\ntypically huge networks and would constitute most of the compute time) or other\naugmentations that can be transversally applied to any of them. Biaffine\nparsing emerges as a well-balanced default choice, with sequence-labelling\nparsing being preferable if inference speed (but not training energy cost) is\nthe priority.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 09:55:47 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 09:48:21 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Anderson", "Mark", ""], ["Rodr\u00edguez", "Carlos G\u00f3mez", ""]]}, {"id": "2106.04217", "submitter": "Ghada Sokar", "authors": "Ghada Sokar, Elena Mocanu, Decebal Constantin Mocanu, Mykola\n  Pechenizkiy, Peter Stone", "title": "Dynamic Sparse Training for Deep Reinforcement Learning", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has achieved significant success in many\ndecision-making tasks in various fields. However, it requires a large training\ntime of dense neural networks to obtain a good performance. This hinders its\napplicability on low-resource devices where memory and computation are strictly\nconstrained. In a step towards enabling deep reinforcement learning agents to\nbe applied to low-resource devices, in this work, we propose for the first time\nto dynamically train deep reinforcement learning agents with sparse neural\nnetworks from scratch. We adopt the evolution principles of dynamic sparse\ntraining in the reinforcement learning paradigm and introduce a training\nalgorithm that optimizes the sparse topology and the weight values jointly to\ndynamically fit the incoming data. Our approach is easy to be integrated into\nexisting deep reinforcement learning algorithms and has many favorable\nadvantages. First, it allows for significant compression of the network size\nwhich reduces the memory and computation costs substantially. This would\naccelerate not only the agent inference but also its training process. Second,\nit speeds up the agent learning process and allows for reducing the number of\nrequired training steps. Third, it can achieve higher performance than training\nthe dense counterpart network. We evaluate our approach on OpenAI gym\ncontinuous control tasks. The experimental results show the effectiveness of\nour approach in achieving higher performance than one of the state-of-art\nbaselines with a 50\\% reduction in the network size and floating-point\noperations (FLOPs). Moreover, our proposed approach can reach the same\nperformance achieved by the dense network with a 40-50\\% reduction in the\nnumber of training steps.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 09:57:20 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Sokar", "Ghada", ""], ["Mocanu", "Elena", ""], ["Mocanu", "Decebal Constantin", ""], ["Pechenizkiy", "Mykola", ""], ["Stone", "Peter", ""]]}, {"id": "2106.04219", "submitter": "Shayegan Omidshafiei", "authors": "Shayegan Omidshafiei, Daniel Hennes, Marta Garnelo, Eugene Tarassov,\n  Zhe Wang, Romuald Elie, Jerome T. Connor, Paul Muller, Ian Graham, William\n  Spearman, Karl Tuyls", "title": "Time-series Imputation of Temporally-occluded Multiagent Trajectories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multiagent environments, several decision-making individuals interact\nwhile adhering to the dynamics constraints imposed by the environment. These\ninteractions, combined with the potential stochasticity of the agents'\ndecision-making processes, make such systems complex and interesting to study\nfrom a dynamical perspective. Significant research has been conducted on\nlearning models for forward-direction estimation of agent behaviors, for\nexample, pedestrian predictions used for collision-avoidance in self-driving\ncars. However, in many settings, only sporadic observations of agents may be\navailable in a given trajectory sequence. For instance, in football, subsets of\nplayers may come in and out of view of broadcast video footage, while\nunobserved players continue to interact off-screen. In this paper, we study the\nproblem of multiagent time-series imputation, where available past and future\nobservations of subsets of agents are used to estimate missing observations for\nother agents. Our approach, called the Graph Imputer, uses forward- and\nbackward-information in combination with graph networks and variational\nautoencoders to enable learning of a distribution of imputed trajectories. We\nevaluate our approach on a dataset of football matches, using a projective\ncamera module to train and evaluate our model for the off-screen player state\nestimation setting. We illustrate that our method outperforms several\nstate-of-the-art approaches, including those hand-crafted for football.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 09:58:43 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Omidshafiei", "Shayegan", ""], ["Hennes", "Daniel", ""], ["Garnelo", "Marta", ""], ["Tarassov", "Eugene", ""], ["Wang", "Zhe", ""], ["Elie", "Romuald", ""], ["Connor", "Jerome T.", ""], ["Muller", "Paul", ""], ["Graham", "Ian", ""], ["Spearman", "William", ""], ["Tuyls", "Karl", ""]]}, {"id": "2106.04232", "submitter": "Thierry Deruyttere", "authors": "Thierry Deruyttere, Victor Milewski, Marie-Francine Moens", "title": "Giving Commands to a Self-Driving Car: How to Deal with Uncertain\n  Situations?", "comments": "Accepted in Engineering Applications of Artificial Intelligence\n  (EAAI) journal", "journal-ref": null, "doi": "10.1016/j.engappai.2021.104257", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Current technology for autonomous cars primarily focuses on getting the\npassenger from point A to B. Nevertheless, it has been shown that passengers\nare afraid of taking a ride in self-driving cars. One way to alleviate this\nproblem is by allowing the passenger to give natural language commands to the\ncar. However, the car can misunderstand the issued command or the visual\nsurroundings which could lead to uncertain situations. It is desirable that the\nself-driving car detects these situations and interacts with the passenger to\nsolve them. This paper proposes a model that detects uncertain situations when\na command is given and finds the visual objects causing it. Optionally, a\nquestion generated by the system describing the uncertain objects is included.\nWe argue that if the car could explain the objects in a human-like way,\npassengers could gain more confidence in the car's abilities. Thus, we\ninvestigate how to (1) detect uncertain situations and their underlying causes,\nand (2) how to generate clarifying questions for the passenger. When evaluating\non the Talk2Car dataset, we show that the proposed model, \\acrfull{pipeline},\nimproves \\gls{m:ambiguous-absolute-increase} in terms of $IoU_{.5}$ compared to\nnot using \\gls{pipeline}. Furthermore, we designed a referring expression\ngenerator (REG) \\acrfull{reg_model} tailored to a self-driving car setting\nwhich yields a relative improvement of \\gls{m:meteor-relative} METEOR and\n\\gls{m:rouge-relative} ROUGE-l compared with state-of-the-art REG models, and\nis three times faster.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 10:21:11 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Deruyttere", "Thierry", ""], ["Milewski", "Victor", ""], ["Moens", "Marie-Francine", ""]]}, {"id": "2106.04233", "submitter": "Gra\\c{c}aliz Dimuro Prof. Dr.", "authors": "Tiago da Cruz Asmus, Gra\\c{c}aliz Pereira Dimuro, Benjam\\'in Bedregal,\n  Jos\\'e Antonio Sanz, Radko Mesiar and Humberto Bustince", "title": "Towards interval uncertainty propagation control in bivariate\n  aggregation processes and the introduction of width-limited interval-valued\n  overlap functions", "comments": "submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overlap functions are a class of aggregation functions that measure the\noverlapping degree between two values. Interval-valued overlap functions were\ndefined as an extension to express the overlapping of interval-valued data, and\nthey have been usually applied when there is uncertainty regarding the\nassignment of membership degrees. The choice of a total order for intervals can\nbe significant, which motivated the recent developments on interval-valued\naggregation functions and interval-valued overlap functions that are increasing\nto a given admissible order, that is, a total order that refines the usual\npartial order for intervals. Also, width preservation has been considered on\nthese recent works, in an intent to avoid the uncertainty increase and\nguarantee the information quality, but no deeper study was made regarding the\nrelation between the widths of the input intervals and the output interval,\nwhen applying interval-valued functions, or how one can control such\nuncertainty propagation based on this relation. Thus, in this paper we: (i)\nintroduce and develop the concepts of width-limited interval-valued functions\nand width limiting functions, presenting a theoretical approach to analyze the\nrelation between the widths of the input and output intervals of bivariate\ninterval-valued functions, with special attention to interval-valued\naggregation functions; (ii) introduce the concept of $(a,b)$-ultramodular\naggregation functions, a less restrictive extension of one-dimension convexity\nfor bivariate aggregation functions, which have an important predictable\nbehaviour with respect to the width when extended to the interval-valued\ncontext; (iii) define width-limited interval-valued overlap functions, taking\ninto account a function that controls the width of the output interval; (iv)\npresent and compare three construction methods for these width-limited\ninterval-valued overlap functions.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 10:22:31 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Asmus", "Tiago da Cruz", ""], ["Dimuro", "Gra\u00e7aliz Pereira", ""], ["Bedregal", "Benjam\u00edn", ""], ["Sanz", "Jos\u00e9 Antonio", ""], ["Mesiar", "Radko", ""], ["Bustince", "Humberto", ""]]}, {"id": "2106.04235", "submitter": "Hal Ashton", "authors": "Hal Ashton", "title": "Definitions of intent suitable for algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Intent modifies an actor's culpability of many types wrongdoing. Autonomous\nAlgorithmic Agents have the capability of causing harm, and whilst their\ncurrent lack of legal personhood precludes them from committing crimes, it is\nuseful for a number of parties to understand under what type of intentional\nmode an algorithm might transgress. From the perspective of the creator or\nowner they would like ensure that their algorithms never intend to cause harm\nby doing things that would otherwise be labelled criminal if committed by a\nlegal person. Prosecutors might have an interest in understanding whether the\nactions of an algorithm were internally intended according to a transparent\ndefinition of the concept. The presence or absence of intention in the\nalgorithmic agent might inform the court as to the complicity of its owner.\nThis article introduces definitions for direct, oblique (or indirect) and\nulterior intent which can be used to test for intent in an algorithmic actor.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 10:30:29 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Ashton", "Hal", ""]]}, {"id": "2106.04258", "submitter": "Roberto Dess\\`i", "authors": "Roberto Dess\\`i, Eugene Kharitonov, Marco Baroni", "title": "Interpretable agent communication from scratch(with a generic visual\n  processor emerging on the side)", "comments": "9 pages main text, 13 pages total", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  As deep networks begin to be deployed as autonomous agents, the issue of how\nthey can communicate with each other becomes important. Here, we train two deep\nnets from scratch to perform realistic referent identification through\nunsupervised emergent communication. We show that the largely interpretable\nemergent protocol allows the nets to successfully communicate even about object\ntypes they did not see at training time. The visual representations induced as\na by-product of our training regime, moreover, show comparable quality, when\nre-used as generic visual features, to a recent self-supervised learning model.\nOur results provide concrete evidence of the viability of (interpretable)\nemergent deep net communication in a more realistic scenario than previously\nconsidered, as well as establishing an intriguing link between this field and\nself-supervised visual learning.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 11:32:11 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Dess\u00ec", "Roberto", ""], ["Kharitonov", "Eugene", ""], ["Baroni", "Marco", ""]]}, {"id": "2106.04260", "submitter": "Alexander Meinke", "authors": "Alexander Meinke, Julian Bitterwolf, Matthias Hein", "title": "Provably Robust Detection of Out-of-distribution Data (almost) for free", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When applying machine learning in safety-critical systems, a reliable\nassessment of the uncertainy of a classifier is required. However, deep neural\nnetworks are known to produce highly overconfident predictions on\nout-of-distribution (OOD) data and even if trained to be non-confident on OOD\ndata one can still adversarially manipulate OOD data so that the classifer\nagain assigns high confidence to the manipulated samples. In this paper we\npropose a novel method where from first principles we combine a certifiable OOD\ndetector with a standard classifier into an OOD aware classifier. In this way\nwe achieve the best of two worlds: certifiably adversarially robust OOD\ndetection, even for OOD samples close to the in-distribution, without loss in\nprediction accuracy and close to state-of-the-art OOD detection performance for\nnon-manipulated OOD data. Moreover, due to the particular construction our\nclassifier provably avoids the asymptotic overconfidence problem of standard\nneural networks.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 11:40:49 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Meinke", "Alexander", ""], ["Bitterwolf", "Julian", ""], ["Hein", "Matthias", ""]]}, {"id": "2106.04262", "submitter": "Megha Srivastava", "authors": "Megha Srivastava and Noah Goodman", "title": "Question Generation for Adaptive Education", "comments": "10 pages, 3 figures, ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intelligent and adaptive online education systems aim to make high-quality\neducation available for a diverse range of students. However, existing systems\nusually depend on a pool of hand-made questions, limiting how fine-grained and\nopen-ended they can be in adapting to individual students. We explore targeted\nquestion generation as a controllable sequence generation task. We first show\nhow to fine-tune pre-trained language models for deep knowledge tracing\n(LM-KT). This model accurately predicts the probability of a student answering\na question correctly, and generalizes to questions not seen in training. We\nthen use LM-KT to specify the objective and data for training a model to\ngenerate questions conditioned on the student and target difficulty. Our\nresults show we succeed at generating novel, well-calibrated language\ntranslation questions for second language learners from a real online education\nplatform.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 11:46:59 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Srivastava", "Megha", ""], ["Goodman", "Noah", ""]]}, {"id": "2106.04267", "submitter": "Stefan Rass", "authors": "Stefan Rass, Sandra K\\\"onig, Jasmin Wachter, Manuel Egger, Manuel\n  Hobisch", "title": "Supervised Machine Learning with Plausible Deniability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the question of how well machine learning (ML) models trained on a\ncertain data set provide privacy for the training data, or equivalently,\nwhether it is possible to reverse-engineer the training data from a given ML\nmodel. While this is easy to answer negatively in the most general case, it is\ninteresting to note that the protection extends over non-recoverability towards\nplausible deniability: Given an ML model $f$, we show that one can take a set\nof purely random training data, and from this define a suitable ``learning\nrule'' that will produce a ML model that is exactly $f$. Thus, any speculation\nabout which data has been used to train $f$ is deniable upon the claim that any\nother data could have led to the same results. We corroborate our theoretical\nfinding with practical examples, and open source implementations of how to find\nthe learning rules for a chosen set of raining data.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 11:54:51 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Rass", "Stefan", ""], ["K\u00f6nig", "Sandra", ""], ["Wachter", "Jasmin", ""], ["Egger", "Manuel", ""], ["Hobisch", "Manuel", ""]]}, {"id": "2106.04275", "submitter": "Max W. Y. Lam", "authors": "Max W. Y. Lam, Jun Wang, Chao Weng, Dan Su, Dong Yu", "title": "Raw Waveform Encoder with Multi-Scale Globally Attentive Locally\n  Recurrent Networks for End-to-End Speech Recognition", "comments": "Accepted in Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end speech recognition generally uses hand-engineered acoustic\nfeatures as input and excludes the feature extraction module from its joint\noptimization. To extract learnable and adaptive features and mitigate\ninformation loss, we propose a new encoder that adopts globally attentive\nlocally recurrent (GALR) networks and directly takes raw waveform as input. We\nobserve improved ASR performance and robustness by applying GALR on different\nwindow lengths to aggregate fine-grain temporal information into multi-scale\nacoustic features. Experiments are conducted on a benchmark dataset AISHELL-2\nand two large-scale Mandarin speech corpus of 5,000 hours and 21,000 hours.\nWith faster speed and comparable model size, our proposed multi-scale GALR\nwaveform encoder achieved consistent character error rate reductions (CERRs)\nfrom 7.9% to 28.1% relative over strong baselines, including Conformer and\nTDNN-Conformer. In particular, our approach demonstrated notable robustness\nthan the traditional handcrafted features and outperformed the baseline\nMFCC-based TDNN-Conformer model by a 15.2% CERR on a music-mixed real-world\nspeech test set.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 12:12:33 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Lam", "Max W. Y.", ""], ["Wang", "Jun", ""], ["Weng", "Chao", ""], ["Su", "Dan", ""], ["Yu", "Dong", ""]]}, {"id": "2106.04283", "submitter": "Marc Tyndel", "authors": "Rayhane Mama, Marc S. Tyndel, Hashiam Kadhim, Cole Clifford, Ragavan\n  Thurairatnam", "title": "NWT: Towards natural audio-to-video generation with representation\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.CV cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we introduce NWT, an expressive speech-to-video model. Unlike\napproaches that use domain-specific intermediate representations such as pose\nkeypoints, NWT learns its own latent representations, with minimal assumptions\nabout the audio and video content. To this end, we propose a novel discrete\nvariational autoencoder with adversarial loss, dVAE-Adv, which learns a new\ndiscrete latent representation we call Memcodes. Memcodes are straightforward\nto implement, require no additional loss terms, are stable to train compared\nwith other approaches, and show evidence of interpretability. To predict on the\nMemcode space, we use an autoregressive encoder-decoder model conditioned on\naudio. Additionally, our model can control latent attributes in the generated\nvideo that are not annotated in the data. We train NWT on clips from HBO's Last\nWeek Tonight with John Oliver. NWT consistently scores above other approaches\nin Mean Opinion Score (MOS) on tests of overall video naturalness, facial\nnaturalness and expressiveness, and lipsync quality. This work sets a strong\nbaseline for generalized audio-to-video synthesis. Samples are available at\nhttps://next-week-tonight.github.io/NWT/.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 12:22:29 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Mama", "Rayhane", ""], ["Tyndel", "Marc S.", ""], ["Kadhim", "Hashiam", ""], ["Clifford", "Cole", ""], ["Thurairatnam", "Ragavan", ""]]}, {"id": "2106.04302", "submitter": "Prakhar Gupta", "authors": "Prakhar Gupta and Martin Jaggi", "title": "Obtaining Better Static Word Embeddings Using Contextual Embedding\n  Models", "comments": "ACL 2021 accept", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The advent of contextual word embeddings -- representations of words which\nincorporate semantic and syntactic information from their context -- has led to\ntremendous improvements on a wide variety of NLP tasks. However, recent\ncontextual models have prohibitively high computational cost in many use-cases\nand are often hard to interpret. In this work, we demonstrate that our proposed\ndistillation method, which is a simple extension of CBOW-based training, allows\nto significantly improve computational efficiency of NLP applications, while\noutperforming the quality of existing static embeddings trained from scratch as\nwell as those distilled from previously proposed methods. As a side-effect, our\napproach also allows a fair comparison of both contextual and static embeddings\nvia standard lexical evaluation tasks.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 12:59:32 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Gupta", "Prakhar", ""], ["Jaggi", "Martin", ""]]}, {"id": "2106.04306", "submitter": "Alireza Ranjbar", "authors": "Alireza Ranjbar, Ngo Anh Vien, Hanna Ziesche, Joschka Boedecker,\n  Gerhard Neumann", "title": "Residual Feedback Learning for Contact-Rich Manipulation Tasks with\n  Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  While classic control theory offers state of the art solutions in many\nproblem scenarios, it is often desired to improve beyond the structure of such\nsolutions and surpass their limitations. To this end, \\emph{\\gls{rpl}} offers a\nformulation to improve existing controllers with reinforcement learning (RL) by\nlearning an additive \"residual\" to the output of a given controller. However,\nthe applicability of such an approach highly depends on the structure of the\ncontroller. Often, internal feedback signals of the controller limit an RL\nalgorithm to adequately change the policy and, hence, learn the task. We\npropose a new formulation that addresses these limitations by also modifying\nthe feedback signals to the controller with an RL policy and show superior\nperformance of our approach on a contact-rich peg-insertion task under position\nand orientation uncertainty. In addition, we use a recent impedance control\narchitecture as control framework and show the difficulties of standard RPL.\nFurthermore, we introduce an adaptive curriculum for the given task to\ngradually increase the task difficulty in terms of position and orientation\nuncertainty. A video showing the results can be found at\nhttps://youtu.be/SAZm_Krze7U .\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 13:06:35 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Ranjbar", "Alireza", ""], ["Vien", "Ngo Anh", ""], ["Ziesche", "Hanna", ""], ["Boedecker", "Joschka", ""], ["Neumann", "Gerhard", ""]]}, {"id": "2106.04315", "submitter": "Hadi Beik-Mohammadi", "authors": "Hadi Beik-Mohammadi, S{\\o}ren Hauberg, Georgios Arvanitidis, Gerhard\n  Neumann and Leonel Rozo", "title": "Learning Riemannian Manifolds for Geodesic Motion Skills", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For robots to work alongside humans and perform in unstructured environments,\nthey must learn new motion skills and adapt them to unseen situations on the\nfly. This demands learning models that capture relevant motion patterns, while\noffering enough flexibility to adapt the encoded skills to new requirements,\nsuch as dynamic obstacle avoidance. We introduce a Riemannian manifold\nperspective on this problem, and propose to learn a Riemannian manifold from\nhuman demonstrations on which geodesics are natural motion skills. We realize\nthis with a variational autoencoder (VAE) over the space of position and\norientations of the robot end-effector. Geodesic motion skills let a robot plan\nmovements from and to arbitrary points on the data manifold. They also provide\na straightforward method to avoid obstacles by redefining the ambient metric in\nan online fashion. Moreover, geodesics naturally exploit the manifold resulting\nfrom multiple--mode tasks to design motions that were not explicitly\ndemonstrated previously. We test our learning framework using a 7-DoF robotic\nmanipulator, where the robot satisfactorily learns and reproduces realistic\nskills featuring elaborated motion patterns, avoids previously unseen\nobstacles, and generates novel movements in multiple-mode settings.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 13:24:54 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 10:32:18 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Beik-Mohammadi", "Hadi", ""], ["Hauberg", "S\u00f8ren", ""], ["Arvanitidis", "Georgios", ""], ["Neumann", "Gerhard", ""], ["Rozo", "Leonel", ""]]}, {"id": "2106.04316", "submitter": "Noor Sajid", "authors": "Noor Sajid, Panagiotis Tigas, Alexey Zakharov, Zafeirios Fountas and\n  Karl Friston", "title": "Exploration and preference satisfaction trade-off in reward-free\n  learning", "comments": "23 pages, 15 figures", "journal-ref": "Proceedings of the Unsupervised Reinforcement Learning Workshop\n  ICML 2021", "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Biological agents have meaningful interactions with their environment despite\nthe absence of immediate reward signals. In such instances, the agent can learn\npreferred modes of behaviour that lead to predictable states -- necessary for\nsurvival. In this paper, we pursue the notion that this learnt behaviour can be\na consequence of reward-free preference learning that ensures an appropriate\ntrade-off between exploration and preference satisfaction. For this, we\nintroduce a model-based Bayesian agent equipped with a preference learning\nmechanism (pepper) using conjugate priors. These conjugate priors are used to\naugment the expected free energy planner for learning preferences over states\n(or outcomes) across time. Importantly, our approach enables the agent to learn\npreferences that encourage adaptive behaviour at test time. We illustrate this\nin the OpenAI Gym FrozenLake and the 3D mini-world environments -- with and\nwithout volatility. Given a constant environment, these agents learn confident\n(i.e., precise) preferences and act to satisfy them. Conversely, in a volatile\nsetting, perpetual preference uncertainty maintains exploratory behaviour. Our\nexperiments suggest that learnable (reward-free) preferences entail a trade-off\nbetween exploration and preference satisfaction. Pepper offers a\nstraightforward framework suitable for designing adaptive agents when reward\nfunctions cannot be predefined as in real environments.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 13:24:58 GMT"}, {"version": "v2", "created": "Sun, 18 Jul 2021 18:41:52 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Sajid", "Noor", ""], ["Tigas", "Panagiotis", ""], ["Zakharov", "Alexey", ""], ["Fountas", "Zafeirios", ""], ["Friston", "Karl", ""]]}, {"id": "2106.04319", "submitter": "Muhammet Balcilar Dr.", "authors": "Muhammet Balcilar, Pierre H\\'eroux, Benoit Ga\\\"uz\\`ere, Pascal\n  Vasseur, S\\'ebastien Adam, Paul Honeine", "title": "Breaking the Limits of Message Passing Graph Neural Networks", "comments": "18 pages, 6 figures", "journal-ref": "The Thirty-eighth International Conference on Machine Learning,\n  ICML2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since the Message Passing (Graph) Neural Networks (MPNNs) have a linear\ncomplexity with respect to the number of nodes when applied to sparse graphs,\nthey have been widely implemented and still raise a lot of interest even though\ntheir theoretical expressive power is limited to the first order\nWeisfeiler-Lehman test (1-WL). In this paper, we show that if the graph\nconvolution supports are designed in spectral-domain by a non-linear custom\nfunction of eigenvalues and masked with an arbitrary large receptive field, the\nMPNN is theoretically more powerful than the 1-WL test and experimentally as\npowerful as a 3-WL existing models, while remaining spatially localized.\nMoreover, by designing custom filter functions, outputs can have various\nfrequency components that allow the convolution process to learn different\nrelationships between a given input graph signal and its associated properties.\nSo far, the best 3-WL equivalent graph neural networks have a computational\ncomplexity in $\\mathcal{O}(n^3)$ with memory usage in $\\mathcal{O}(n^2)$,\nconsider non-local update mechanism and do not provide the spectral richness of\noutput profile. The proposed method overcomes all these aforementioned problems\nand reaches state-of-the-art results in many downstream tasks.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 13:26:56 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Balcilar", "Muhammet", ""], ["H\u00e9roux", "Pierre", ""], ["Ga\u00fcz\u00e8re", "Benoit", ""], ["Vasseur", "Pascal", ""], ["Adam", "S\u00e9bastien", ""], ["Honeine", "Paul", ""]]}, {"id": "2106.04335", "submitter": "Ping-Chun Hsieh", "authors": "Bing-Jing Hsieh, Ping-Chun Hsieh, Xi Liu", "title": "Reinforced Few-Shot Acquisition Function Learning for Bayesian\n  Optimization", "comments": "21 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) conventionally relies on handcrafted acquisition\nfunctions (AFs) to sequentially determine the sample points. However, it has\nbeen widely observed in practice that the best-performing AF in terms of regret\ncan vary significantly under different types of black-box functions. It has\nremained a challenge to design one AF that can attain the best performance over\na wide variety of black-box functions. This paper aims to attack this challenge\nthrough the perspective of reinforced few-shot AF learning (FSAF).\nSpecifically, we first connect the notion of AFs with Q-functions and view a\ndeep Q-network (DQN) as a surrogate differentiable AF. While it serves as a\nnatural idea to combine DQN and an existing few-shot learning method, we\nidentify that such a direct combination does not perform well due to severe\noverfitting, which is particularly critical in BO due to the need of a\nversatile sampling policy. To address this, we present a Bayesian variant of\nDQN with the following three features: (i) It learns a distribution of\nQ-networks as AFs based on the Kullback-Leibler regularization framework. This\ninherently provides the uncertainty required in sampling for BO and mitigates\noverfitting. (ii) For the prior of the Bayesian DQN, we propose to use a demo\npolicy induced by an off-the-shelf AF for better training stability. (iii) On\nthe meta-level, we leverage the meta-loss of Bayesian model-agnostic\nmeta-learning, which serves as a natural companion to the proposed FSAF.\nMoreover, with the proper design of the Q-networks, FSAF is general-purpose in\nthat it is agnostic to the dimension and the cardinality of the input domain.\nThrough extensive experiments, we demonstrate that the FSAF achieves comparable\nor better regrets than the state-of-the-art benchmarks on a wide variety of\nsynthetic and real-world test functions.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 13:46:46 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Hsieh", "Bing-Jing", ""], ["Hsieh", "Ping-Chun", ""], ["Liu", "Xi", ""]]}, {"id": "2106.04377", "submitter": "Aditya Sarkar", "authors": "Aditya Sarkar, Arnav Bhavsar", "title": "Virtual Screening of Pharmaceutical Compounds with hERG Inhibitory\n  Activity (Cardiotoxicity) using Ensemble Learning", "comments": "23 pages, 2 figures, 5 tables", "journal-ref": "Proceedings of the 14th International Joint Conference on\n  Biomedical Engineering Systems and Technologies (BIOSTEC 2021) - Volume 2:\n  BIOIMAGING,", "doi": "10.5220/0010267701520159", "report-no": null, "categories": "q-bio.QM cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In silico prediction of cardiotoxicity with high sensitivity and specificity\nfor potential drug molecules can be of immense value. Hence, building machine\nlearning classification models, based on some features extracted from the\nmolecular structure of drugs, which are capable of efficiently predicting\ncardiotoxicity is critical. In this paper, we consider the application of\nvarious machine learning approaches, and then propose an ensemble classifier\nfor the prediction of molecular activity on a Drug Discovery Hackathon (DDH)\n(1st reference) dataset. We have used only 2-D descriptors of SMILE notations\nfor our prediction. Our ensemble classification uses 5 classifiers (2 Random\nForest Classifiers, 2 Support Vector Machines and a Dense Neural Network) and\nuses Max-Voting technique and Weighted-Average technique for final decision.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 16:57:35 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Sarkar", "Aditya", ""], ["Bhavsar", "Arnav", ""]]}, {"id": "2106.04379", "submitter": "Cameron Allen", "authors": "Cameron Allen, Neev Parikh, Omer Gottesman, George Konidaris", "title": "Learning Markov State Abstractions for Deep Reinforcement Learning", "comments": "Code available at\n  https://github.com/camall3n/markov-state-abstractions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fundamental assumption of reinforcement learning in Markov decision\nprocesses (MDPs) is that the relevant decision process is, in fact, Markov.\nHowever, when MDPs have rich observations, agents typically learn by way of an\nabstract state representation, and such representations are not guaranteed to\npreserve the Markov property. We introduce a novel set of conditions and prove\nthat they are sufficient for learning a Markov abstract state representation.\nWe then describe a practical training procedure that combines inverse model\nestimation and temporal contrastive learning to learn an abstraction that\napproximately satisfies these conditions. Our novel training objective is\ncompatible with both online and offline training: it does not require a reward\nsignal, but agents can capitalize on reward information when available. We\nempirically evaluate our approach on a visual gridworld domain and a set of\ncontinuous control benchmarks. Our approach learns representations that capture\nthe underlying structure of the domain and lead to improved sample efficiency\nover state-of-the-art deep reinforcement learning with visual features -- often\nmatching or exceeding the performance achieved with hand-designed compact state\ninformation.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 14:12:36 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Allen", "Cameron", ""], ["Parikh", "Neev", ""], ["Gottesman", "Omer", ""], ["Konidaris", "George", ""]]}, {"id": "2106.04392", "submitter": "Yihong Dong", "authors": "Yihong Dong, Ying Peng, Muqiao Yang, Songtao Lu and Qingjiang Shi", "title": "Signal Transformer: Complex-valued Attention and Meta-Learning for\n  Signal Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been shown as a class of useful tools for\naddressing signal recognition issues in recent years, especially for\nidentifying the nonlinear feature structures of signals. However, this power of\nmost deep learning techniques heavily relies on an abundant amount of training\ndata, so the performance of classic neural nets decreases sharply when the\nnumber of training data samples is small or unseen data are presented in the\ntesting phase. This calls for an advanced strategy, i.e., model-agnostic\nmeta-learning (MAML), which is able to capture the invariant representation of\nthe data samples or signals. In this paper, inspired by the special structure\nof the signal, i.e., real and imaginary parts consisted in practical\ntime-series signals, we propose a Complex-valued Attentional MEta Learner\n(CAMEL) for the problem of few-shot signal recognition by leveraging attention\nand meta-learning in the complex domain. To the best of our knowledge, this is\nalso the first complex-valued MAML that can find the first-order stationary\npoints of general nonconvex problems with theoretical convergence guarantees.\nExtensive experiments results showcase the superiority of the proposed CAMEL\ncompared with the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 03:57:41 GMT"}, {"version": "v2", "created": "Sat, 12 Jun 2021 03:36:38 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Dong", "Yihong", ""], ["Peng", "Ying", ""], ["Yang", "Muqiao", ""], ["Lu", "Songtao", ""], ["Shi", "Qingjiang", ""]]}, {"id": "2106.04411", "submitter": "Sangwon Jung", "authors": "Sangwon Jung, Donggyu Lee, Taeeon Park and Taesup Moon", "title": "Fair Feature Distillation for Visual Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness is becoming an increasingly crucial issue for computer vision,\nespecially in the human-related decision systems. However, achieving\nalgorithmic fairness, which makes a model produce indiscriminative outcomes\nagainst protected groups, is still an unresolved problem. In this paper, we\ndevise a systematic approach which reduces algorithmic biases via feature\ndistillation for visual recognition tasks, dubbed as MMD-based Fair\nDistillation (MFD). While the distillation technique has been widely used in\ngeneral to improve the prediction accuracy, to the best of our knowledge, there\nhas been no explicit work that also tries to improve fairness via distillation.\nFurthermore, We give a theoretical justification of our MFD on the effect of\nknowledge distillation and fairness. Throughout the extensive experiments, we\nshow our MFD significantly mitigates the bias against specific minorities\nwithout any loss of the accuracy on both synthetic and real-world face\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 18:00:07 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 13:55:34 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Jung", "Sangwon", ""], ["Lee", "Donggyu", ""], ["Park", "Taeeon", ""], ["Moon", "Taesup", ""]]}, {"id": "2106.04419", "submitter": "Joseph Gesnouin Mr.", "authors": "Rapha\\\"el Rozenberg, Joseph Gesnouin and Fabien Moutarde", "title": "Asymmetrical Bi-RNN for pedestrian trajectory encoding", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Pedestrian motion behavior involves a combination of individual goals and\nsocial interactions with other agents. In this article, we present an\nasymmetrical bidirectional recurrent neural network architecture called U-RNN\nto encode pedestrian trajectories and evaluate its relevance to replace LSTMs\nfor various forecasting models. Experimental results on the Trajnet++ benchmark\nshow that the U-LSTM variant yields better results regarding every available\nmetrics (ADE, FDE, Collision rate) than common trajectory encoders for a\nvariety of approaches and interaction modules, suggesting that the proposed\napproach is a viable alternative to the de facto sequence encoding RNNs.\n  Our implementation of the asymmetrical Bi-RNNs for the Trajnet++ benchmark is\navailable at:\ngithub.com/JosephGesnouin/Asymmetrical-Bi-RNNs-to-encode-pedestrian-trajectories\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 12:05:15 GMT"}, {"version": "v2", "created": "Sat, 19 Jun 2021 12:33:47 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Rozenberg", "Rapha\u00ebl", ""], ["Gesnouin", "Joseph", ""], ["Moutarde", "Fabien", ""]]}, {"id": "2106.04420", "submitter": "Harshavardhan Kamarthi", "authors": "Harshavardhan Kamarthi, Alexander Rodr\\'iguez, B. Aditya Prakash", "title": "Back2Future: Leveraging Backfill Dynamics for Improving Real-time\n  Predictions in Future", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In real-time forecasting in public health, data collection is a non-trivial\nand demanding task. Often after initially released, it undergoes several\nrevisions later (maybe due to human or technical constraints) - as a result, it\nmay take weeks until the data reaches to a stable value. This so-called\n'backfill' phenomenon and its effect on model performance has been barely\nstudied in the prior literature. In this paper, we introduce the multi-variate\nbackfill problem using COVID-19 as the motivating example. We construct a\ndetailed dataset composed of relevant signals over the past year of the\npandemic. We then systematically characterize several patterns in backfill\ndynamics and leverage our observations for formulating a novel problem and\nneural framework Back2Future that aims to refines a given model's predictions\nin real-time. Our extensive experiments demonstrate that our method refines the\nperformance of top models for COVID-19 forecasting, in contrast to non-trivial\nbaselines, yielding 18% improvement over baselines, enabling us obtain a new\nSOTA performance. In addition, we show that our model improves model evaluation\ntoo; hence policy-makers can better understand the true accuracy of forecasting\nmodels in real-time.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 14:48:20 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Kamarthi", "Harshavardhan", ""], ["Rodr\u00edguez", "Alexander", ""], ["Prakash", "B. Aditya", ""]]}, {"id": "2106.04434", "submitter": "Yuxin Deng", "authors": "Jiayi Ma and Yuxin Deng", "title": "SDGMNet: Statistic-based Dynamic Gradient Modulation for Local\n  Descriptor Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modifications on triplet loss that rescale the back-propagated gradients of\nspecial pairs have made significant progress on local descriptor learning.\nHowever, current gradient modulation strategies are mainly static so that they\nwould suffer from changes of training phases or datasets. In this paper, we\npropose a dynamic gradient modulation, named SDGMNet, to improve triplet loss\nfor local descriptor learning. The core of our method is formulating modulation\nfunctions with statistical characteristics which are estimated dynamically.\nFirstly, we perform deep analysis on back propagation of general triplet-based\nloss and introduce included angle for distance measure. On this basis,\nauto-focus modulation is employed to moderate the impact of statistically\nuncommon individual pairs in stochastic gradient descent optimization;\nprobabilistic margin cuts off the gradients of proportional Siamese pairs that\nare believed to reach the optimum; power adjustment balances the total weights\nof negative pairs and positive pairs. Extensive experiments demonstrate that\nour novel descriptor surpasses previous state-of-the-arts on standard\nbenchmarks including patch verification, matching and retrieval tasks.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 15:10:31 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 12:45:28 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Ma", "Jiayi", ""], ["Deng", "Yuxin", ""]]}, {"id": "2106.04461", "submitter": "Kasey Jones", "authors": "Kasey Jones, Emily Hadley, Sandy Preiss, Caroline Kery, Peter\n  Baumgartner, Marie Stoner, Sarah Rhea", "title": "North Carolina COVID-19 Agent-Based Model Framework for Hospitalization\n  Forecasting Overview, Design Concepts, and Details Protocol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA stat.AP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This Overview, Design Concepts, and Details Protocol (ODD) provides a\ndetailed description of an agent-based model (ABM) that was developed to\nsimulate hospitalizations during the COVID-19 pandemic. Using the descriptions\nof submodels, provided parameters, and the links to data sources, modelers will\nbe able to replicate the creation and results of this model.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 15:43:02 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Jones", "Kasey", ""], ["Hadley", "Emily", ""], ["Preiss", "Sandy", ""], ["Kery", "Caroline", ""], ["Baumgartner", "Peter", ""], ["Stoner", "Marie", ""], ["Rhea", "Sarah", ""]]}, {"id": "2106.04462", "submitter": "Karim Lounici", "authors": "Karim Lounici and Katia Meziani and Benjamin Riu", "title": "Muddling Label Regularization: Deep Learning for Tabular Datasets", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL) is considered the state-of-the-art in computer vision,\nspeech recognition and natural language processing. Until recently, it was also\nwidely accepted that DL is irrelevant for learning tasks on tabular data,\nespecially in the small sample regime where ensemble methods are acknowledged\nas the gold standard. We present a new end-to-end differentiable method to\ntrain a standard FFNN. Our method, \\textbf{Muddling labels for Regularization}\n(\\texttt{MLR}), penalizes memorization through the generation of uninformative\nlabels and the application of a differentiable close-form regularization scheme\non the last hidden layer during training. \\texttt{MLR} outperforms classical NN\nand the gold standard (GBDT, RF) for regression and classification tasks on\nseveral datasets from the UCI database and Kaggle covering a large range of\nsample sizes and feature to sample ratios. Researchers and practitioners can\nuse \\texttt{MLR} on its own as an off-the-shelf \\DL{} solution or integrate it\ninto the most advanced ML pipelines.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 15:44:02 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 17:10:09 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Lounici", "Karim", ""], ["Meziani", "Katia", ""], ["Riu", "Benjamin", ""]]}, {"id": "2106.04480", "submitter": "Johan Ferret", "authors": "Nathan Grinsztajn, Johan Ferret, Olivier Pietquin, Philippe Preux,\n  Matthieu Geist", "title": "There Is No Turning Back: A Self-Supervised Approach for\n  Reversibility-Aware Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose to learn to distinguish reversible from irreversible actions for\nbetter informed decision-making in Reinforcement Learning (RL). From\ntheoretical considerations, we show that approximate reversibility can be\nlearned through a simple surrogate task: ranking randomly sampled trajectory\nevents in chronological order. Intuitively, pairs of events that are always\nobserved in the same order are likely to be separated by an irreversible\nsequence of actions. Conveniently, learning the temporal order of events can be\ndone in a fully self-supervised way, which we use to estimate the reversibility\nof actions from experience, without any priors. We propose two different\nstrategies that incorporate reversibility in RL agents, one strategy for\nexploration (RAE) and one strategy for control (RAC). We demonstrate the\npotential of reversibility-aware agents in several environments, including the\nchallenging Sokoban game. In synthetic tasks, we show that we can learn control\npolicies that never fail and reduce to zero the side-effects of interactions,\neven without access to the reward function.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 16:07:10 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 10:55:31 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Grinsztajn", "Nathan", ""], ["Ferret", "Johan", ""], ["Pietquin", "Olivier", ""], ["Preux", "Philippe", ""], ["Geist", "Matthieu", ""]]}, {"id": "2106.04486", "submitter": "Siddharth Bhatia", "authors": "Siddharth Bhatia, Mohit Wadhwa, Philip S. Yu, Bryan Hooi", "title": "Sketch-Based Streaming Anomaly Detection in Dynamic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given a stream of graph edges from a dynamic graph, how can we assign anomaly\nscores to edges and subgraphs in an online manner, for the purpose of detecting\nunusual behavior, using constant time and memory? For example, in intrusion\ndetection, existing work seeks to detect either anomalous edges or anomalous\nsubgraphs, but not both. In this paper, we first extend the count-min sketch\ndata structure to a higher-order sketch. This higher-order sketch has the\nuseful property of preserving the dense subgraph structure (dense subgraphs in\nthe input turn into dense submatrices in the data structure). We then propose\nfour online algorithms that utilize this enhanced data structure, which (a)\ndetect both edge and graph anomalies; (b) process each edge and graph in\nconstant memory and constant update time per newly arriving edge, and; (c)\noutperform state-of-the-art baselines on four real-world datasets. Our method\nis the first streaming approach that incorporates dense subgraph search to\ndetect graph anomalies in constant memory and time.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 16:10:36 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Bhatia", "Siddharth", ""], ["Wadhwa", "Mohit", ""], ["Yu", "Philip S.", ""], ["Hooi", "Bryan", ""]]}, {"id": "2106.04493", "submitter": "Xiaocheng Tang", "authors": "Xiaocheng Tang, Zhiwei Qin, Fan Zhang, Zhaodong Wang, Zhe Xu, Yintai\n  Ma, Hongtu Zhu, Jieping Ye", "title": "A Deep Value-network Based Approach for Multi-Driver Order Dispatching", "comments": "KDD 2019 Oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recent works on ride-sharing order dispatching have highlighted the\nimportance of taking into account both the spatial and temporal dynamics in the\ndispatching process for improving the transportation system efficiency. At the\nsame time, deep reinforcement learning has advanced to the point where it\nachieves superhuman performance in a number of fields. In this work, we propose\na deep reinforcement learning based solution for order dispatching and we\nconduct large scale online A/B tests on DiDi's ride-dispatching platform to\nshow that the proposed method achieves significant improvement on both total\ndriver income and user experience related metrics. In particular, we model the\nride dispatching problem as a Semi Markov Decision Process to account for the\ntemporal aspect of the dispatching actions. To improve the stability of the\nvalue iteration with nonlinear function approximators like neural networks, we\npropose Cerebellar Value Networks (CVNet) with a novel distributed state\nrepresentation layer. We further derive a regularized policy evaluation scheme\nfor CVNet that penalizes large Lipschitz constant of the value network for\nadditional robustness against adversarial perturbation and noises. Finally, we\nadapt various transfer learning methods to CVNet for increased learning\nadaptability and efficiency across multiple cities. We conduct extensive\noffline simulations based on real dispatching data as well as online AB tests\nthrough the DiDi's platform. Results show that CVNet consistently outperforms\nother recently proposed dispatching methods. We finally show that the\nperformance can be further improved through the efficient use of transfer\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 16:27:04 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Tang", "Xiaocheng", ""], ["Qin", "Zhiwei", ""], ["Zhang", "Fan", ""], ["Wang", "Zhaodong", ""], ["Xu", "Zhe", ""], ["Ma", "Yintai", ""], ["Zhu", "Hongtu", ""], ["Ye", "Jieping", ""]]}, {"id": "2106.04499", "submitter": "Riley Simmons-Edler", "authors": "Vyacheslav Alipov, Riley Simmons-Edler, Nikita Putintsev, Pavel\n  Kalinin, Dmitry Vetrov", "title": "Towards Practical Credit Assignment for Deep Reinforcement Learning", "comments": "9 pages plus 7 page appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Credit assignment is a fundamental problem in reinforcement learning, the\nproblem of measuring an action's influence on future rewards. Improvements in\ncredit assignment methods have the potential to boost the performance of RL\nalgorithms on many tasks, but thus far have not seen widespread adoption.\nRecently, a family of methods called Hindsight Credit Assignment (HCA) was\nproposed, which explicitly assign credit to actions in hindsight based on the\nprobability of the action having led to an observed outcome. This approach is\nappealing as a means to more efficient data usage, but remains a largely\ntheoretical idea applicable to a limited set of tabular RL tasks, and it is\nunclear how to extend HCA to Deep RL environments. In this work, we explore the\nuse of HCA-style credit in a deep RL context. We first describe the limitations\nof existing HCA algorithms in deep RL, then propose several\ntheoretically-justified modifications to overcome them. Based on this\nexploration, we present a new algorithm, Credit-Constrained Advantage\nActor-Critic (C2A2C), which ignores policy updates for actions which don't\naffect future outcomes based on credit in hindsight, while updating the policy\nas normal for those that do. We find that C2A2C outperforms Advantage\nActor-Critic (A2C) on the Arcade Learning Environment (ALE) benchmark, showing\nbroad improvements over A2C and motivating further work on credit-constrained\nupdate rules for deep RL methods.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 16:35:05 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Alipov", "Vyacheslav", ""], ["Simmons-Edler", "Riley", ""], ["Putintsev", "Nikita", ""], ["Kalinin", "Pavel", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "2106.04502", "submitter": "Mikhail Khodak", "authors": "Mikhail Khodak, Renbo Tu, Tian Li, Liam Li, Maria-Florina Balcan,\n  Virginia Smith, Ameet Talwalkar", "title": "Federated Hyperparameter Tuning: Challenges, Baselines, and Connections\n  to Weight-Sharing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tuning hyperparameters is a crucial but arduous part of the machine learning\npipeline. Hyperparameter optimization is even more challenging in federated\nlearning, where models are learned over a distributed network of heterogeneous\ndevices; here, the need to keep data on device and perform local training makes\nit difficult to efficiently train and evaluate configurations. In this work, we\ninvestigate the problem of federated hyperparameter tuning. We first identify\nkey challenges and show how standard approaches may be adapted to form\nbaselines for the federated setting. Then, by making a novel connection to the\nneural architecture search technique of weight-sharing, we introduce a new\nmethod, FedEx, to accelerate federated hyperparameter tuning that is applicable\nto widely-used federated optimization methods such as FedAvg and recent\nvariants. Theoretically, we show that a FedEx variant correctly tunes the\non-device learning rate in the setting of online convex optimization across\ndevices. Empirically, we show that FedEx can outperform natural baselines for\nfederated hyperparameter tuning by several percentage points on the\nShakespeare, FEMNIST, and CIFAR-10 benchmarks, obtaining higher accuracy using\nthe same training budget.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 16:42:37 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Khodak", "Mikhail", ""], ["Tu", "Renbo", ""], ["Li", "Tian", ""], ["Li", "Liam", ""], ["Balcan", "Maria-Florina", ""], ["Smith", "Virginia", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "2106.04513", "submitter": "Sharmin Pathan", "authors": "Sharmin Pathan, Vyom Shrivastava", "title": "Identifying Linked Fraudulent Activities Using GraphConvolution Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel approach to identify linked fraudulent\nactivities or actors sharing similar attributes, using Graph Convolution\nNetwork (GCN). These linked fraudulent activities can be visualized as graphs\nwith abstract concepts like relationships and interactions, which makes GCNs an\nideal solution to identify the graph edges which serve as links between\nfraudulent nodes. Traditional approaches like community detection require\nstrong links between fraudulent attempts like shared attributes to find\ncommunities and the supervised solutions require large amount of training data\nwhich may not be available in fraud scenarios and work best to provide binary\nseparation between fraudulent and non fraudulent activities. Our approach\novercomes the drawbacks of traditional methods as GCNs simply learn\nsimilarities between fraudulent nodes to identify clusters of similar attempts\nand require much smaller dataset to learn. We demonstrate our results on linked\naccounts with both strong and weak links to identify fraud rings with high\nconfidence. Our results outperform label propagation community detection and\nsupervised GBTs algorithms in terms of solution quality and computation time.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 09:56:08 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Pathan", "Sharmin", ""], ["Shrivastava", "Vyom", ""]]}, {"id": "2106.04516", "submitter": "Matthew W. Hoffman", "authors": "Fan Yang, Gabriel Barth-Maron, Piotr Sta\\'nczyk, Matthew Hoffman, Siqi\n  Liu, Manuel Kroiss, Aedan Pope, Alban Rrustemi", "title": "Launchpad: A Programming Model for Distributed Machine Learning Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major driver behind the success of modern machine learning algorithms has\nbeen their ability to process ever-larger amounts of data. As a result, the use\nof distributed systems in both research and production has become increasingly\nprevalent as a means to scale to this growing data. At the same time, however,\ndistributing the learning process can drastically complicate the implementation\nof even simple algorithms. This is especially problematic as many machine\nlearning practitioners are not well-versed in the design of distributed\nsystems, let alone those that have complicated communication topologies. In\nthis work we introduce Launchpad, a programming model that simplifies the\nprocess of defining and launching distributed systems that is specifically\ntailored towards a machine learning audience. We describe our framework, its\ndesign philosophy and implementation, and give a number of examples of common\nlearning algorithms whose designs are greatly simplified by this approach.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 17:02:10 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Yang", "Fan", ""], ["Barth-Maron", "Gabriel", ""], ["Sta\u0144czyk", "Piotr", ""], ["Hoffman", "Matthew", ""], ["Liu", "Siqi", ""], ["Kroiss", "Manuel", ""], ["Pope", "Aedan", ""], ["Rrustemi", "Alban", ""]]}, {"id": "2106.04525", "submitter": "Jimin Tan", "authors": "Jimin Tan, Jianan Yang, Sai Wu, Gang Chen, Jake Zhao (Junbo)", "title": "A critical look at the current train/test split in machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The randomized or cross-validated split of training and testing sets has been\nadopted as the gold standard of machine learning for decades. The establishment\nof these split protocols are based on two assumptions: (i)-fixing the dataset\nto be eternally static so we could evaluate different machine learning\nalgorithms or models; (ii)-there is a complete set of annotated data available\nto researchers or industrial practitioners. However, in this article, we intend\nto take a closer and critical look at the split protocol itself and point out\nits weakness and limitation, especially for industrial applications. In many\nreal-world problems, we must acknowledge that there are numerous situations\nwhere assumption (ii) does not hold. For instance, for interdisciplinary\napplications like drug discovery, it often requires real lab experiments to\nannotate data which poses huge costs in both time and financial considerations.\nIn other words, it can be very difficult or even impossible to satisfy\nassumption (ii). In this article, we intend to access this problem and\nreiterate the paradigm of active learning, and investigate its potential on\nsolving problems under unconventional train/test split protocols. We further\npropose a new adaptive active learning architecture (AAL) which involves an\nadaptation policy, in comparison with the traditional active learning that only\nunidirectionally adds data points to the training pool. We primarily justify\nour points by extensively investigating an interdisciplinary drug-protein\nbinding problem. We additionally evaluate AAL on more conventional machine\nlearning benchmarking datasets like CIFAR-10 to demonstrate the\ngeneralizability and efficacy of the new framework.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 17:07:20 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Tan", "Jimin", "", "Junbo"], ["Yang", "Jianan", "", "Junbo"], ["Wu", "Sai", "", "Junbo"], ["Chen", "Gang", "", "Junbo"], ["Zhao", "Jake", "", "Junbo"]]}, {"id": "2106.04533", "submitter": "Tianlong Chen", "authors": "Tianlong Chen, Yu Cheng, Zhe Gan, Lu Yuan, Lei Zhang, Zhangyang Wang", "title": "Chasing Sparsity in Vision Transformers: An End-to-End Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision transformers (ViTs) have recently received explosive popularity, but\ntheir enormous model sizes and training costs remain daunting. Conventional\npost-training pruning often incurs higher training budgets. In contrast, this\npaper aims to trim down both the training memory overhead and the inference\ncomplexity, without sacrificing the achievable accuracy. We launch and report\nthe first-of-its-kind comprehensive exploration, on taking a unified approach\nof integrating sparsity in ViTs \"from end to end\". Specifically, instead of\ntraining full ViTs, we dynamically extract and train sparse subnetworks, while\nsticking to a fixed small parameter budget. Our approach jointly optimizes\nmodel parameters and explores connectivity throughout training, ending up with\none sparse network as the final output. The approach is seamlessly extended\nfrom unstructured to structured sparsity, the latter by considering to guide\nthe prune-and-grow of self-attention heads inside ViTs. For additional\nefficiency gains, we further co-explore data and architecture sparsity, by\nplugging in a novel learnable token selector to adaptively determine the\ncurrently most vital patches. Extensive results on ImageNet with diverse ViT\nbackbones validate the effectiveness of our proposals which obtain\nsignificantly reduced computational cost and almost unimpaired generalization.\nPerhaps most surprisingly, we find that the proposed sparse (co-)training can\neven improve the ViT accuracy rather than compromising it, making sparsity a\ntantalizing \"free lunch\". For example, our sparsified DeiT-Small at (5%, 50%)\nsparsity for (data, architecture), improves 0.28% top-1 accuracy, and meanwhile\nenjoys 49.32% FLOPs and 4.40% running time savings. Our codes are available at\nhttps://github.com/VITA-Group/SViTE.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 17:18:00 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 22:28:31 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Chen", "Tianlong", ""], ["Cheng", "Yu", ""], ["Gan", "Zhe", ""], ["Yuan", "Lu", ""], ["Zhang", "Lei", ""], ["Wang", "Zhangyang", ""]]}, {"id": "2106.04537", "submitter": "Avi Schwarzschild", "authors": "Avi Schwarzschild, Eitan Borgnia, Arjun Gupta, Furong Huang, Uzi\n  Vishkin, Micah Goldblum, Tom Goldstein", "title": "Can You Learn an Algorithm? Generalizing from Easy to Hard Problems with\n  Recurrent Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks are powerful machines for visual pattern recognition,\nbut reasoning tasks that are easy for humans may still be difficult for neural\nmodels. Humans possess the ability to extrapolate reasoning strategies learned\non simple problems to solve harder examples, often by thinking for longer. For\nexample, a person who has learned to solve small mazes can easily extend the\nvery same search techniques to solve much larger mazes by spending more time.\nIn computers, this behavior is often achieved through the use of algorithms,\nwhich scale to arbitrarily hard problem instances at the cost of more\ncomputation. In contrast, the sequential computing budget of feed-forward\nneural networks is limited by their depth, and networks trained on simple\nproblems have no way of extending their reasoning to accommodate harder\nproblems. In this work, we show that recurrent networks trained to solve simple\nproblems with few recurrent steps can indeed solve much more complex problems\nsimply by performing additional recurrences during inference. We demonstrate\nthis algorithmic behavior of recurrent networks on prefix sum computation,\nmazes, and chess. In all three domains, networks trained on simple problem\ninstances are able to extend their reasoning abilities at test time simply by\n\"thinking for longer.\"\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 17:19:48 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Schwarzschild", "Avi", ""], ["Borgnia", "Eitan", ""], ["Gupta", "Arjun", ""], ["Huang", "Furong", ""], ["Vishkin", "Uzi", ""], ["Goldblum", "Micah", ""], ["Goldstein", "Tom", ""]]}, {"id": "2106.04538", "submitter": "Yu Huang", "authors": "Yu Huang, Chenzhuang Du, Zihui Xue, Xuanyao Chen, Hang Zhao, Longbo\n  Huang", "title": "What Makes Multimodal Learning Better than Single (Provably)", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The world provides us with data of multiple modalities. Intuitively, models\nfusingdata from different modalities outperform unimodal models, since more\ninformationis aggregated. Recently, joining the success of deep learning, there\nis an influentialline of work on deep multimodal learning, which has remarkable\nempirical resultson various applications. However, theoretical justifications\nin this field are notablylacking.Can multimodal provably perform better than\nunimodal? In this paper, we answer this question under a most popular\nmultimodal learningframework, which firstly encodes features from different\nmodalities into a commonlatent space and seamlessly maps the latent\nrepresentations into the task space. Weprove that learning with multiple\nmodalities achieves a smaller population risk thanonly using its subset of\nmodalities. The main intuition is that the former has moreaccurate estimate of\nthe latent space representation. To the best of our knowledge,this is the first\ntheoretical treatment to capture important qualitative phenomenaobserved in\nreal multimodal applications. Combining with experiment results, weshow that\nmultimodal learning does possess an appealing formal guarantee.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 17:20:02 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Huang", "Yu", ""], ["Du", "Chenzhuang", ""], ["Xue", "Zihui", ""], ["Chen", "Xuanyao", ""], ["Zhao", "Hang", ""], ["Huang", "Longbo", ""]]}, {"id": "2106.04540", "submitter": "Jordan Lei", "authors": "Jordan Lei, Ari S. Benjamin, Konrad P. Kording", "title": "Object Based Attention Through Internal Gating", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Object-based attention is a key component of the visual system, relevant for\nperception, learning, and memory. Neurons tuned to features of attended objects\ntend to be more active than those associated with non-attended objects. There\nis a rich set of models of this phenomenon in computational neuroscience.\nHowever, there is currently a divide between models that successfully match\nphysiological data but can only deal with extremely simple problems and models\nof attention used in computer vision. For example, attention in the brain is\nknown to depend on top-down processing, whereas self-attention in deep learning\ndoes not. Here, we propose an artificial neural network model of object-based\nattention that captures the way in which attention is both top-down and\nrecurrent. Our attention model works well both on simple test stimuli, such as\nthose using images of handwritten digits, and on more complex stimuli, such as\nnatural images drawn from the COCO dataset. We find that our model replicates a\nrange of findings from neuroscience, including attention-invariant tuning,\ninhibition of return, and attention-mediated scaling of activity. Understanding\nobject based attention is both computationally interesting and a key problem\nfor computational neuroscience.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 17:20:50 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Lei", "Jordan", ""], ["Benjamin", "Ari S.", ""], ["Kording", "Konrad P.", ""]]}, {"id": "2106.04546", "submitter": "Yuan Yin", "authors": "Yuan Yin, Ibrahim Ayed, Emmanuel de B\\'ezenac, Nicolas Baskiotis,\n  Patrick Gallinari", "title": "LEADS: Learning Dynamical Systems that Generalize Across Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When modeling dynamical systems from real-world data samples, the\ndistribution of data often changes according to the environment in which they\nare captured, and the dynamics of the system itself vary from one environment\nto another. Generalizing across environments thus challenges the conventional\nframeworks. The classical settings suggest either considering data as i.i.d.\nand learning a single model to cover all situations or learning\nenvironment-specific models. Both are sub-optimal: the former disregards the\ndiscrepancies between environments leading to biased solutions, while the\nlatter does not exploit their potential commonalities and is prone to scarcity\nproblems. We propose LEADS, a novel framework that leverages the commonalities\nand discrepancies among known environments to improve model generalization.\nThis is achieved with a tailored training formulation aiming at capturing\ncommon dynamics within a shared model while additional terms capture\nenvironment-specific dynamics. We ground our approach in theory, exhibiting a\ndecrease in sample complexity with our approach and corroborate these results\nempirically, instantiating it for linear dynamics. Moreover, we concretize this\nframework for neural networks and evaluate it experimentally on representative\nfamilies of nonlinear dynamics. We show that this new setting can exploit\nknowledge extracted from environment-dependent data and improves generalization\nfor both known and novel environments.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 17:28:19 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Yin", "Yuan", ""], ["Ayed", "Ibrahim", ""], ["de B\u00e9zenac", "Emmanuel", ""], ["Baskiotis", "Nicolas", ""], ["Gallinari", "Patrick", ""]]}, {"id": "2106.04554", "submitter": "Tianyang Lin", "authors": "Tianyang Lin, Yuxin Wang, Xiangyang Liu, Xipeng Qiu", "title": "A Survey of Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers have achieved great success in many artificial intelligence\nfields, such as natural language processing, computer vision, and audio\nprocessing. Therefore, it is natural to attract lots of interest from academic\nand industry researchers. Up to the present, a great variety of Transformer\nvariants (a.k.a. X-formers) have been proposed, however, a systematic and\ncomprehensive literature review on these Transformer variants is still missing.\nIn this survey, we provide a comprehensive review of various X-formers. We\nfirst briefly introduce the vanilla Transformer and then propose a new taxonomy\nof X-formers. Next, we introduce the various X-formers from three perspectives:\narchitectural modification, pre-training, and applications. Finally, we outline\nsome potential directions for future research.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 17:43:08 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 07:56:19 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Lin", "Tianyang", ""], ["Wang", "Yuxin", ""], ["Liu", "Xiangyang", ""], ["Qiu", "Xipeng", ""]]}, {"id": "2106.04560", "submitter": "Xiaohua Zhai", "authors": "Xiaohua Zhai, Alexander Kolesnikov, Neil Houlsby, Lucas Beyer", "title": "Scaling Vision Transformers", "comments": "Xiaohua, Alex, and Lucas contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based neural networks such as the Vision Transformer (ViT) have\nrecently attained state-of-the-art results on many computer vision benchmarks.\nScale is a primary ingredient in attaining excellent results, therefore,\nunderstanding a model's scaling properties is a key to designing future\ngenerations effectively. While the laws for scaling Transformer language models\nhave been studied, it is unknown how Vision Transformers scale. To address\nthis, we scale ViT models and data, both up and down, and characterize the\nrelationships between error rate, data, and compute. Along the way, we refine\nthe architecture and training of ViT, reducing memory consumption and\nincreasing accuracy the resulting models. As a result, we successfully train a\nViT model with two billion parameters, which attains a new state-of-the-art on\nImageNet of 90.45% top-1 accuracy. The model also performs well on few-shot\nlearning, for example, attaining 84.86% top-1 accuracy on ImageNet with only 10\nexamples per class.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 17:47:39 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Zhai", "Xiaohua", ""], ["Kolesnikov", "Alexander", ""], ["Houlsby", "Neil", ""], ["Beyer", "Lucas", ""]]}, {"id": "2106.04561", "submitter": "Kasra Mokhtari", "authors": "Kasra Mokhtari, Alan R. Wagner", "title": "Safe Deep Q-Network for Autonomous Vehicles at Unsignalized Intersection", "comments": "11 pages, 6 figures, 5 Tables. arXiv admin note: text overlap with\n  arXiv:2105.00153", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a safe DRL approach for autonomous vehicle (AV) navigation through\ncrowds of pedestrians while making a left turn at an unsignalized intersection.\nOur method uses two long-short term memory (LSTM) models that are trained to\ngenerate the perceived state of the environment and the future trajectories of\npedestrians given noisy observations of their movement. A future collision\nprediction algorithm based on the future trajectories of the ego vehicle and\npedestrians is used to mask unsafe actions if the system predicts a collision.\nThe performance of our approach is evaluated in two experiments using the\nhigh-fidelity CARLA simulation environment. The first experiment tests the\nperformance of our method at intersections that are similar to the training\nintersection and the second experiment tests our method at intersections with a\ndifferent topology. For both experiments, our methods do not result in a\ncollision with a pedestrian while still navigating the intersection at a\nreasonable speed.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 17:48:56 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Mokhtari", "Kasra", ""], ["Wagner", "Alan R.", ""]]}, {"id": "2106.04563", "submitter": "Subhabrata Mukherjee", "authors": "Subhabrata Mukherjee, Ahmed Hassan Awadallah, Jianfeng Gao", "title": "XtremeDistilTransformers: Task Transfer for Task-agnostic Distillation", "comments": "Code and checkpoints released (links in draft)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While deep and large pre-trained models are the state-of-the-art for various\nnatural language processing tasks, their huge size poses significant challenges\nfor practical uses in resource constrained settings. Recent works in knowledge\ndistillation propose task-agnostic as well as task-specific methods to compress\nthese models, with task-specific ones often yielding higher compression rate.\nIn this work, we develop a new task-agnostic distillation framework\nXtremeDistilTransformers that leverages the advantage of task-specific methods\nfor learning a small universal model that can be applied to arbitrary tasks and\nlanguages. To this end, we study the transferability of several source tasks,\naugmentation resources and model architecture for distillation. We evaluate our\nmodel performance on multiple tasks, including the General Language\nUnderstanding Evaluation (GLUE) benchmark, SQuAD question answering dataset and\na massive multi-lingual NER dataset with 41 languages. We release three\ndistilled task-agnostic checkpoints with 13MM, 22MM and 33MM parameters\nobtaining SOTA performance in several tasks.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 17:49:33 GMT"}, {"version": "v2", "created": "Sat, 12 Jun 2021 03:59:31 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Mukherjee", "Subhabrata", ""], ["Awadallah", "Ahmed Hassan", ""], ["Gao", "Jianfeng", ""]]}, {"id": "2106.04564", "submitter": "Jianguo Zhang", "authors": "Jian-Guo Zhang, Kazuma Hashimoto, Yao Wan, Ye Liu, Caiming Xiong,\n  Philip S. Yu", "title": "Are Pretrained Transformers Robust in Intent Classification? A Missing\n  Ingredient in Evaluation of Out-of-Scope Intent Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pretrained Transformer-based models were reported to be robust in intent\nclassification. In this work, we first point out the importance of in-domain\nout-of-scope detection in few-shot intent recognition tasks and then illustrate\nthe vulnerability of pretrained Transformer-based models against samples that\nare in-domain but out-of-scope (ID-OOS). We empirically show that pretrained\nmodels do not perform well on both ID-OOS examples and general out-of-scope\nexamples, especially on fine-grained few-shot intent detection tasks. To figure\nout how the models mistakenly classify ID-OOS intents as in-scope intents, we\nfurther conduct analysis on confidence scores and the overlapping keywords and\nprovide several prospective directions for future work. We release the relevant\nresources to facilitate future research.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 17:51:12 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Zhang", "Jian-Guo", ""], ["Hashimoto", "Kazuma", ""], ["Wan", "Yao", ""], ["Liu", "Ye", ""], ["Xiong", "Caiming", ""], ["Yu", "Philip S.", ""]]}, {"id": "2106.04565", "submitter": "Juri Opitz", "authors": "Sarah Uhrig, Yoalli Rezepka Garcia, Juri Opitz, Anette Frank", "title": "Translate, then Parse! A strong baseline for Cross-Lingual AMR Parsing", "comments": "IWPT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cross-lingual Abstract Meaning Representation (AMR) parsing, researchers\ndevelop models that project sentences from various languages onto their AMRs to\ncapture their essential semantic structures: given a sentence in any language,\nwe aim to capture its core semantic content through concepts connected by\nmanifold types of semantic relations. Methods typically leverage large silver\ntraining data to learn a single model that is able to project non-English\nsentences to AMRs. However, we find that a simple baseline tends to be\nover-looked: translating the sentences to English and projecting their AMR with\na monolingual AMR parser (translate+parse,T+P). In this paper, we revisit this\nsimple two-step base-line, and enhance it with a strong NMT system and a strong\nAMR parser. Our experiments show that T+P outperforms a recent state-of-the-art\nsystem across all tested languages: German, Italian, Spanish and Mandarin with\n+14.6, +12.6, +14.3 and +16.0 Smatch points.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 17:52:48 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Uhrig", "Sarah", ""], ["Garcia", "Yoalli Rezepka", ""], ["Opitz", "Juri", ""], ["Frank", "Anette", ""]]}, {"id": "2106.04569", "submitter": "Nataniel Ruiz", "authors": "Nataniel Ruiz, Adam Kortylewski, Weichao Qiu, Cihang Xie, Sarah Adel\n  Bargal, Alan Yuille, Stan Sclaroff", "title": "Simulated Adversarial Testing of Face Recognition Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most machine learning models are validated and tested on fixed datasets. This\ncan give an incomplete picture of the capabilities and weaknesses of the model.\nSuch weaknesses can be revealed at test time in the real world. The risks\ninvolved in such failures can be loss of profits, loss of time or even loss of\nlife in certain critical applications. In order to alleviate this issue,\nsimulators can be controlled in a fine-grained manner using interpretable\nparameters to explore the semantic image manifold. In this work, we propose a\nframework for learning how to test machine learning algorithms using simulators\nin an adversarial manner in order to find weaknesses in the model before\ndeploying it in critical scenarios. We apply this model in a face recognition\nscenario. We are the first to show that weaknesses of models trained on real\ndata can be discovered using simulated samples. Using our proposed method, we\ncan find adversarial synthetic faces that fool contemporary face recognition\nmodels. This demonstrates the fact that these models have weaknesses that are\nnot measured by commonly used validation datasets. We hypothesize that this\ntype of adversarial examples are not isolated, but usually lie in connected\ncomponents in the latent space of the simulator. We present a method to find\nthese adversarial regions as opposed to the typical adversarial points found in\nthe adversarial example literature.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 17:58:10 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Ruiz", "Nataniel", ""], ["Kortylewski", "Adam", ""], ["Qiu", "Weichao", ""], ["Xie", "Cihang", ""], ["Bargal", "Sarah Adel", ""], ["Yuille", "Alan", ""], ["Sclaroff", "Stan", ""]]}, {"id": "2106.04570", "submitter": "Canwen Xu", "authors": "Wangchunshu Zhou and Canwen Xu and Julian McAuley", "title": "Meta Learning for Knowledge Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Meta Learning for Knowledge Distillation (MetaDistil), a simple\nyet effective alternative to traditional knowledge distillation (KD) methods\nwhere the teacher model is fixed during training. We show the teacher network\ncan learn to better transfer knowledge to the student network (i.e., learning\nto teach) with the feedback from the performance of the distilled student\nnetwork in a meta learning framework. Moreover, we introduce a pilot update\nmechanism to improve the alignment between the inner-learner and meta-learner\nin meta learning algorithms that focus on an improved inner-learner.\nExperiments on various benchmarks show that MetaDistil can yield significant\nimprovements compared with traditional KD algorithms and is less sensitive to\nthe choice of different student capacity and hyperparameters, facilitating the\nuse of KD on different tasks and models. The code is available at\nhttps://github.com/JetRunner/MetaDistil\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 17:59:03 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Zhou", "Wangchunshu", ""], ["Xu", "Canwen", ""], ["McAuley", "Julian", ""]]}, {"id": "2106.04615", "submitter": "Sherjil Ozair", "authors": "Sherjil Ozair, Yazhe Li, Ali Razavi, Ioannis Antonoglou, A\\\"aron van\n  den Oord, Oriol Vinyals", "title": "Vector Quantized Models for Planning", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recent developments in the field of model-based RL have proven successful in\na range of environments, especially ones where planning is essential. However,\nsuch successes have been limited to deterministic fully-observed environments.\nWe present a new approach that handles stochastic and partially-observable\nenvironments. Our key insight is to use discrete autoencoders to capture the\nmultiple possible effects of an action in a stochastic environment. We use a\nstochastic variant of Monte Carlo tree search to plan over both the agent's\nactions and the discrete latent variables representing the environment's\nresponse. Our approach significantly outperforms an offline version of MuZero\non a stochastic interpretation of chess where the opponent is considered part\nof the environment. We also show that our approach scales to DeepMind Lab, a\nfirst-person 3D environment with large visual observations and partial\nobservability.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 18:12:32 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 07:02:41 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Ozair", "Sherjil", ""], ["Li", "Yazhe", ""], ["Razavi", "Ali", ""], ["Antonoglou", "Ioannis", ""], ["Oord", "A\u00e4ron van den", ""], ["Vinyals", "Oriol", ""]]}, {"id": "2106.04619", "submitter": "Julius von K\\\"ugelgen", "authors": "Julius von K\\\"ugelgen, Yash Sharma, Luigi Gresele, Wieland Brendel,\n  Bernhard Sch\\\"olkopf, Michel Besserve, Francesco Locatello", "title": "Self-Supervised Learning with Data Augmentations Provably Isolates\n  Content from Style", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised representation learning has shown remarkable success in a\nnumber of domains. A common practice is to perform data augmentation via\nhand-crafted transformations intended to leave the semantics of the data\ninvariant. We seek to understand the empirical success of this approach from a\ntheoretical perspective. We formulate the augmentation process as a latent\nvariable model by postulating a partition of the latent representation into a\ncontent component, which is assumed invariant to augmentation, and a style\ncomponent, which is allowed to change. Unlike prior work on disentanglement and\nindependent component analysis, we allow for both nontrivial statistical and\ncausal dependencies in the latent space. We study the identifiability of the\nlatent representation based on pairs of views of the observations and prove\nsufficient conditions that allow us to identify the invariant content partition\nup to an invertible mapping in both generative and discriminative settings. We\nfind numerical simulations with dependent latent variables are consistent with\nour theory. Lastly, we introduce Causal3DIdent, a dataset of high-dimensional,\nvisually complex images with rich causal dependencies, which we use to study\nthe effect of data augmentations performed in practice.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 18:18:09 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["von K\u00fcgelgen", "Julius", ""], ["Sharma", "Yash", ""], ["Gresele", "Luigi", ""], ["Brendel", "Wieland", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Besserve", "Michel", ""], ["Locatello", "Francesco", ""]]}, {"id": "2106.04624", "submitter": "Mirco Ravanelli", "authors": "Mirco Ravanelli, Titouan Parcollet, Peter Plantinga, Aku Rouhe,\n  Samuele Cornell, Loren Lugosch, Cem Subakan, Nauman Dawalatabad, Abdelwahab\n  Heba, Jianyuan Zhong, Ju-Chieh Chou, Sung-Lin Yeh, Szu-Wei Fu, Chien-Feng\n  Liao, Elena Rastorgueva, Fran\\c{c}ois Grondin, William Aris, Hwidong Na, Yan\n  Gao, Renato De Mori, Yoshua Bengio", "title": "SpeechBrain: A General-Purpose Speech Toolkit", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SpeechBrain is an open-source and all-in-one speech toolkit. It is designed\nto facilitate the research and development of neural speech processing\ntechnologies by being simple, flexible, user-friendly, and well-documented.\nThis paper describes the core architecture designed to support several tasks of\ncommon interest, allowing users to naturally conceive, compare and share novel\nspeech processing pipelines. SpeechBrain achieves competitive or\nstate-of-the-art performance in a wide range of speech benchmarks. It also\nprovides training recipes, pretrained models, and inference scripts for popular\nspeech datasets, as well as tutorials which allow anyone with basic Python\nproficiency to familiarize themselves with speech technologies.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 18:22:56 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Ravanelli", "Mirco", ""], ["Parcollet", "Titouan", ""], ["Plantinga", "Peter", ""], ["Rouhe", "Aku", ""], ["Cornell", "Samuele", ""], ["Lugosch", "Loren", ""], ["Subakan", "Cem", ""], ["Dawalatabad", "Nauman", ""], ["Heba", "Abdelwahab", ""], ["Zhong", "Jianyuan", ""], ["Chou", "Ju-Chieh", ""], ["Yeh", "Sung-Lin", ""], ["Fu", "Szu-Wei", ""], ["Liao", "Chien-Feng", ""], ["Rastorgueva", "Elena", ""], ["Grondin", "Fran\u00e7ois", ""], ["Aris", "William", ""], ["Na", "Hwidong", ""], ["Gao", "Yan", ""], ["De Mori", "Renato", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2106.04625", "submitter": "Kasra Mokhtari", "authors": "Kasra Mokhtari, Alan R. Wagner", "title": "Don't Get Yourself into Trouble! Risk-aware Decision-Making for\n  Autonomous Vehicles", "comments": "8 pages, 4 Figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Risk is traditionally described as the expected likelihood of an undesirable\noutcome, such as collisions for autonomous vehicles. Accurately predicting risk\nor potentially risky situations is critical for the safe operation of\nautonomous vehicles. In our previous work, we showed that risk could be\ncharacterized by two components: 1) the probability of an undesirable outcome\nand 2) an estimate of how undesirable the outcome is (loss). This paper is an\nextension to our previous work. In this paper, using our trained deep\nreinforcement learning model for navigating around crowds, we developed a\nrisk-based decision-making framework for the autonomous vehicle that integrates\nthe high-level risk-based path planning with the reinforcement learning-based\nlow-level control. We evaluated our method in a high-fidelity simulation such\nas CARLA. This work can improve safety by allowing an autonomous vehicle to one\nday avoid and react to risky situations.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 18:24:02 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Mokhtari", "Kasra", ""], ["Wagner", "Alan R.", ""]]}, {"id": "2106.04627", "submitter": "Matej Grcic", "authors": "Matej Grci\\'c, Ivan Grubi\\v{s}i\\'c, Sini\\v{s}a \\v{S}egvi\\'c", "title": "Densely connected normalizing flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Normalizing flows are bijective mappings between inputs and latent\nrepresentations with a fully factorized distribution. They are very attractive\ndue to exact likelihood evaluation and efficient sampling. However, their\neffective capacity is often insufficient since the bijectivity constraint\nlimits the model width. We address this issue by incrementally padding\nintermediate representations with noise. We precondition the noise in\naccordance with previous invertible units, which we describe as cross-unit\ncoupling. Our invertible glow-like modules express intra-unit affine coupling\nas a fusion of a densely connected block and Nystr\\\"om self-attention. We refer\nto our architecture as DenseFlow since both cross-unit and intra-unit couplings\nrely on dense connectivity. Experiments show significant improvements due to\nthe proposed contributions, and reveal state-of-the-art density estimation\namong all generative models under moderate computing budgets.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 18:24:41 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Grci\u0107", "Matej", ""], ["Grubi\u0161i\u0107", "Ivan", ""], ["\u0160egvi\u0107", "Sini\u0161a", ""]]}, {"id": "2106.04641", "submitter": "Shohreh Shaghaghian Ms", "authors": "Nicolai Pogrebnyakov, Shohreh Shaghaghian", "title": "Predicting the Success of Domain Adaptation in Text Similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning methods, and in particular domain adaptation, help exploit\nlabeled data in one domain to improve the performance of a certain task in\nanother domain. However, it is still not clear what factors affect the success\nof domain adaptation. This paper models adaptation success and selection of the\nmost suitable source domains among several candidates in text similarity. We\nuse descriptive domain information and cross-domain similarity metrics as\npredictive features. While mostly positive, the results also point to some\ndomains where adaptation success was difficult to predict.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 19:02:15 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 19:19:40 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Pogrebnyakov", "Nicolai", ""], ["Shaghaghian", "Shohreh", ""]]}, {"id": "2106.04662", "submitter": "Kerstin Bach", "authors": "Kerstin Bach and Paul Jarle Mork", "title": "On the Explanation of Similarity for Developing and Deploying CBR\n  Systems", "comments": "5 pages, 5 figures, Proceedings of the Thirty-Third International\n  Florida Artificial Intelligence Research Society Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the early stages of developing Case-Based Reasoning (CBR) systems the\ndefinition of similarity measures is challenging since this task requires\ntransferring implicit knowledge of domain experts into knowledge\nrepresentations. While an entire CBR system is very explanatory, the similarity\nmeasure determines the ranking but do not necessarily show which features\ncontribute to high (or low) rankings. In this paper we present our work on\nopening the knowledge engineering process for similarity modelling. This work\npresent is a result of an interdisciplinary research collaboration between AI\nand public health researchers developing e-Health applications. During this\nwork explainability and transparency of the development process is crucial to\nallow in-depth quality assurance of the by the domain experts.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 08:43:27 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Bach", "Kerstin", ""], ["Mork", "Paul Jarle", ""]]}, {"id": "2106.04668", "submitter": "Daphney-Stavroula Zois", "authors": "Yasitha Warahena Liyanage, Daphney-Stavroula Zois, Charalampos Chelmis", "title": "Dynamic Instance-Wise Classification in Correlated Feature Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a typical supervised machine learning setting, the predictions on all test\ninstances are based on a common subset of features discovered during model\ntraining. However, using a different subset of features that is most\ninformative for each test instance individually may not only improve prediction\naccuracy, but also the overall interpretability of the model. At the same time,\nfeature selection methods for classification have been known to be the most\neffective when many features are irrelevant and/or uncorrelated. In fact,\nfeature selection ignoring correlations between features can lead to poor\nclassification performance. In this work, a Bayesian network is utilized to\nmodel feature dependencies. Using the dependency network, a new method is\nproposed that sequentially selects the best feature to evaluate for each test\ninstance individually, and stops the selection process to make a prediction\nonce it determines that no further improvement can be achieved with respect to\nclassification accuracy. The optimum number of features to acquire and the\noptimum classification strategy are derived for each test instance. The\ntheoretical properties of the optimum solution are analyzed, and a new\nalgorithm is proposed that takes advantage of these properties to implement a\nrobust and scalable solution for high dimensional settings. The effectiveness,\ngeneralizability, and scalability of the proposed method is illustrated on a\nvariety of real-world datasets from diverse application domains.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 20:20:36 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Liyanage", "Yasitha Warahena", ""], ["Zois", "Daphney-Stavroula", ""], ["Chelmis", "Charalampos", ""]]}, {"id": "2106.04678", "submitter": "Erdem B{\\i}y{\\i}k", "authors": "Erdem B{\\i}y{\\i}k, Daniel A. Lazar, Ramtin Pedarsani, Dorsa Sadigh", "title": "Incentivizing Efficient Equilibria in Traffic Networks with Mixed\n  Autonomy", "comments": "12 pages, 7 figures, 2 tables. To appear at IEEE Transactions on\n  Control of Network Systems (TCNS). arXiv admin note: substantial text overlap\n  with arXiv:1904.02209", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic congestion has large economic and social costs. The introduction of\nautonomous vehicles can potentially reduce this congestion by increasing road\ncapacity via vehicle platooning and by creating an avenue for influencing\npeople's choice of routes. We consider a network of parallel roads with two\nmodes of transportation: (i) human drivers, who will choose the quickest route\navailable to them, and (ii) a ride hailing service, which provides an array of\nautonomous vehicle route options, each with different prices, to users. We\nformalize a model of vehicle flow in mixed autonomy and a model of how\nautonomous service users make choices between routes with different prices and\nlatencies. Developing an algorithm to learn the preferences of the users, we\nformulate a planning optimization that chooses prices to maximize a social\nobjective. We demonstrate the benefit of the proposed scheme by comparing the\nresults to theoretical benchmarks which we show can be efficiently calculated.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 03:01:46 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["B\u0131y\u0131k", "Erdem", ""], ["Lazar", "Daniel A.", ""], ["Pedarsani", "Ramtin", ""], ["Sadigh", "Dorsa", ""]]}, {"id": "2106.04679", "submitter": "Qin Yang", "authors": "Qin Yang", "title": "Self-Adaptive Swarm System (SASS)", "comments": "The preprint for IJCAI 2021 Doctoral Consortium (The Final Version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed artificial intelligence (DAI) studies artificial intelligence\nentities working together to reason, plan, solve problems, organize behaviors\nand strategies, make collective decisions and learn. This Ph.D. research\nproposes a principled Multi-Agent Systems (MAS) cooperation framework,\nSelf-Adaptive Swarm System (SASS), to bridge the fourth level automation gap\nbetween perception, communication, planning, execution, decision-making, and\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 22:46:36 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 02:54:53 GMT"}, {"version": "v3", "created": "Fri, 2 Jul 2021 20:14:29 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Yang", "Qin", ""]]}, {"id": "2106.04682", "submitter": "Aryan Deshwal", "authors": "Aryan Deshwal, Syrine Belakaria, Janardhan Rao Doppa", "title": "Bayesian Optimization over Hybrid Spaces", "comments": "14 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of optimizing hybrid structures (mixture of discrete\nand continuous input variables) via expensive black-box function evaluations.\nThis problem arises in many real-world applications. For example, in materials\ndesign optimization via lab experiments, discrete and continuous variables\ncorrespond to the presence/absence of primitive elements and their relative\nconcentrations respectively. The key challenge is to accurately model the\ncomplex interactions between discrete and continuous variables. In this paper,\nwe propose a novel approach referred as Hybrid Bayesian Optimization (HyBO) by\nutilizing diffusion kernels, which are naturally defined over continuous and\ndiscrete variables. We develop a principled approach for constructing diffusion\nkernels over hybrid spaces by utilizing the additive kernel formulation, which\nallows additive interactions of all orders in a tractable manner. We\ntheoretically analyze the modeling strength of additive hybrid kernels and\nprove that it has the universal approximation property. Our experiments on\nsynthetic and six diverse real-world benchmarks show that HyBO significantly\noutperforms the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 20:47:21 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Deshwal", "Aryan", ""], ["Belakaria", "Syrine", ""], ["Doppa", "Janardhan Rao", ""]]}, {"id": "2106.04683", "submitter": "Mani A", "authors": "A. Mani", "title": "General Rough Modeling of Cluster Analysis", "comments": "Preprint of paper In IFSA-EUSFLAT 2021 Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research, a general theoretical framework for clustering is proposed\nover specific partial algebraic systems by the present author. Her theory helps\nin isolating minimal assumptions necessary for different concepts of clustering\ninformation in any form to be realized in a situation (and therefore in a\nsemantics). \\emph{It is well-known that of the limited number of proofs in the\ntheory of hard and soft clustering that are known to exist, most involve\nstatistical assumptions}. Many methods seem to work because they seem to work\nin specific empirical practice. A new general rough method of analyzing\nclusterings is invented, and this opens the subject to clearer conceptions and\ncontamination-free theoretical proofs. Numeric ideas of validation are also\nproposed to be replaced by those based on general rough approximation. The\nessence of the approach is explained in brief and supported by an example.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 20:54:10 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Mani", "A.", ""]]}, {"id": "2106.04684", "submitter": "Scott Cheng-Hsin Yang", "authors": "Tomas Folke, Scott Cheng-Hsin Yang, Sean Anderson, and Patrick Shafto", "title": "Explainable AI for medical imaging: Explaining pneumothorax diagnoses\n  with Bayesian Teaching", "comments": null, "journal-ref": "Proc. SPIE 11746, Artificial Intelligence and Machine Learning for\n  Multi-Domain Operations Applications III, 117462J (2021)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Limited expert time is a key bottleneck in medical imaging. Due to advances\nin image classification, AI can now serve as decision-support for medical\nexperts, with the potential for great gains in radiologist productivity and, by\nextension, public health. However, these gains are contingent on building and\nmaintaining experts' trust in the AI agents. Explainable AI may build such\ntrust by helping medical experts to understand the AI decision processes behind\ndiagnostic judgements. Here we introduce and evaluate explanations based on\nBayesian Teaching, a formal account of explanation rooted in the cognitive\nscience of human learning. We find that medical experts exposed to explanations\ngenerated by Bayesian Teaching successfully predict the AI's diagnostic\ndecisions and are more likely to certify the AI for cases when the AI is\ncorrect than when it is wrong, indicating appropriate trust. These results show\nthat Explainable AI can be used to support human-AI collaboration in medical\nimaging.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 20:49:11 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Folke", "Tomas", ""], ["Yang", "Scott Cheng-Hsin", ""], ["Anderson", "Sean", ""], ["Shafto", "Patrick", ""]]}, {"id": "2106.04696", "submitter": "Adish Singla", "authors": "Gaurav Yengera, Rati Devidze, Parameswaran Kamalaruban, Adish Singla", "title": "Curriculum Design for Teaching via Demonstrations: Theory and\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of teaching via demonstrations in sequential\ndecision-making settings. In particular, we study how to design a personalized\ncurriculum over demonstrations to speed up the learner's convergence. We\nprovide a unified curriculum strategy for two popular learner models: Maximum\nCausal Entropy Inverse Reinforcement Learning (MaxEnt-IRL) and Cross-Entropy\nBehavioral Cloning (CrossEnt-BC). Our unified strategy induces a ranking over\ndemonstrations based on a notion of difficulty scores computed w.r.t. the\nteacher's optimal policy and the learner's current policy. Compared to the\nstate of the art, our strategy doesn't require access to the learner's internal\ndynamics and still enjoys similar convergence guarantees under mild technical\nconditions. Furthermore, we adapt our curriculum strategy to teach a learner\nusing domain knowledge in the form of task-specific difficulty scores when the\nteacher's optimal policy is unknown. Experiments on a car driving simulator\nenvironment and shortest path problems in a grid-world environment demonstrate\nthe effectiveness of our proposed curriculum strategy.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 21:15:00 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Yengera", "Gaurav", ""], ["Devidze", "Rati", ""], ["Kamalaruban", "Parameswaran", ""], ["Singla", "Adish", ""]]}, {"id": "2106.04715", "submitter": "John Mern", "authors": "John Mern, Mykel J. Kochenderfer", "title": "Measurable Monte Carlo Search Error Bounds", "comments": "9 pages, submitted to NeurIPS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Monte Carlo planners can often return sub-optimal actions, even if they are\nguaranteed to converge in the limit of infinite samples. Known asymptotic\nregret bounds do not provide any way to measure confidence of a recommended\naction at the conclusion of search. In this work, we prove bounds on the\nsub-optimality of Monte Carlo estimates for non-stationary bandits and Markov\ndecision processes. These bounds can be directly computed at the conclusion of\nthe search and do not require knowledge of the true action-value. The presented\nbound holds for general Monte Carlo solvers meeting mild convergence\nconditions. We empirically test the tightness of the bounds through experiments\non a multi-armed bandit and a discrete Markov decision process for both a\nsimple solver and Monte Carlo tree search.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 22:20:14 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Mern", "John", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2106.04729", "submitter": "Amin Asadi", "authors": "Amin Asadi and Sarah Nurre Pinkley", "title": "Drones for Medical Delivery Considering Different Demands Classes: A\n  Markov Decision Process Approach for Managing Health Centers Dispatching\n  Medical Products", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We consider the problem of optimizing the distribution operations of a hub\nusing drones to deliver medical supplies to different geographic regions.\nDrones are an innovative method with many benefits including low-contact\ndelivery thereby reducing the spread of pandemic and vaccine-preventable\ndiseases. While we focus on medical supply delivery for this work, it is\napplicable to drone delivery for many other applications, including food,\npostal items, and e-commerce delivery. In this paper, our goal is to address\ndrone delivery challenges by optimizing the distribution operations at a drone\nhub that dispatch drones to different geographic locations generating\nstochastic demands for medical supplies. By considering different geographic\nlocations, we consider different classes of demand that require different\nflight ranges, which is directly related to the amount of charge held in a\ndrone battery. We classify the stochastic demands based on their distance from\nthe drone hub, use a Markov decision process to model the problem, and perform\ncomputational tests using realistic data representing a prominent drone\ndelivery company. We solve the problem using a reinforcement learning method\nand show its high performance compared with the exact solution found using\ndynamic programming. Finally, we analyze the results and provide insights for\nmanaging the drone hub operations.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 23:20:31 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Asadi", "Amin", ""], ["Pinkley", "Sarah Nurre", ""]]}, {"id": "2106.04732", "submitter": "Rebecca Roelofs", "authors": "David Berthelot, Rebecca Roelofs, Kihyuk Sohn, Nicholas Carlini, Alex\n  Kurakin", "title": "AdaMatch: A Unified Approach to Semi-Supervised Learning and Domain\n  Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend semi-supervised learning to the problem of domain adaptation to\nlearn significantly higher-accuracy models that train on one data distribution\nand test on a different one. With the goal of generality, we introduce\nAdaMatch, a method that unifies the tasks of unsupervised domain adaptation\n(UDA), semi-supervised learning (SSL), and semi-supervised domain adaptation\n(SSDA). In an extensive experimental study, we compare its behavior with\nrespective state-of-the-art techniques from SSL, SSDA, and UDA on vision\nclassification tasks. We find AdaMatch either matches or significantly exceeds\nthe state-of-the-art in each case using the same hyper-parameters regardless of\nthe dataset or task. For example, AdaMatch nearly doubles the accuracy compared\nto that of the prior state-of-the-art on the UDA task for DomainNet and even\nexceeds the accuracy of the prior state-of-the-art obtained with pre-training\nby 6.4% when AdaMatch is trained completely from scratch. Furthermore, by\nproviding AdaMatch with just one labeled example per class from the target\ndomain (i.e., the SSDA setting), we increase the target accuracy by an\nadditional 6.1%, and with 5 labeled examples, by 13.6%.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 23:39:12 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Berthelot", "David", ""], ["Roelofs", "Rebecca", ""], ["Sohn", "Kihyuk", ""], ["Carlini", "Nicholas", ""], ["Kurakin", "Alex", ""]]}, {"id": "2106.04751", "submitter": "Chang Lu", "authors": "Chang Lu, Chandan K. Reddy, Yue Ning", "title": "Self-Supervised Graph Learning with Hyperbolic Embedding for Temporal\n  Health Event Prediction", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic Health Records (EHR) have been heavily used in modern healthcare\nsystems for recording patients' admission information to hospitals. Many\ndata-driven approaches employ temporal features in EHR for predicting specific\ndiseases, readmission times, or diagnoses of patients. However, most existing\npredictive models cannot fully utilize EHR data, due to an inherent lack of\nlabels in supervised training for some temporal events. Moreover, it is hard\nfor existing works to simultaneously provide generic and personalized\ninterpretability. To address these challenges, we first propose a hyperbolic\nembedding method with information flow to pre-train medical code\nrepresentations in a hierarchical structure. We incorporate these pre-trained\nrepresentations into a graph neural network to detect disease complications,\nand design a multi-level attention method to compute the contributions of\nparticular diseases and admissions, thus enhancing personalized\ninterpretability. We present a new hierarchy-enhanced historical prediction\nproxy task in our self-supervised learning framework to fully utilize EHR data\nand exploit medical domain knowledge. We conduct a comprehensive set of\nexperiments and case studies on widely used publicly available EHR datasets to\nverify the effectiveness of our model. The results demonstrate our model's\nstrengths in both predictive tasks and interpretable abilities.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 00:42:44 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Lu", "Chang", ""], ["Reddy", "Chandan K.", ""], ["Ning", "Yue", ""]]}, {"id": "2106.04753", "submitter": "Wei Zhang", "authors": "Wei Zhang, Ziming Huang, Yada Zhu, Guangnan Ye, Xiaodong Cui, Fan\n  Zhang", "title": "On Sample Based Explanation Methods for NLP:Efficiency, Faithfulness,\n  and Semantic Evaluation", "comments": "13 pages; Accepted to ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the recent advances of natural language processing, the scale of the\nstate-of-the-art models and datasets is usually extensive, which challenges the\napplication of sample-based explanation methods in many aspects, such as\nexplanation interpretability, efficiency, and faithfulness. In this work, for\nthe first time, we can improve the interpretability of explanations by allowing\narbitrary text sequences as the explanation unit. On top of this, we implement\na hessian-free method with a model faithfulness guarantee. Finally, to compare\nour method with the others, we propose a semantic-based evaluation metric that\ncan better align with humans' judgment of explanations than the widely adopted\ndiagnostic or re-training measures. The empirical results on multiple real data\nsets demonstrate the proposed method's superior performance to popular\nexplanation techniques such as Influence Function or TracIn on semantic\nevaluation.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 00:49:56 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Zhang", "Wei", ""], ["Huang", "Ziming", ""], ["Zhu", "Yada", ""], ["Ye", "Guangnan", ""], ["Cui", "Xiaodong", ""], ["Zhang", "Fan", ""]]}, {"id": "2106.04765", "submitter": "Yair Schiff", "authors": "Yair Schiff, Brian Quanz, Payel Das, Pin-Yu Chen", "title": "Predicting Deep Neural Network Generalization with Perturbation Response\n  Curves", "comments": "arXiv admin note: substantial text overlap with arXiv:2104.03469", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of Deep Learning is rich with empirical evidence of human-like\nperformance on a variety of prediction tasks. However, despite these successes,\nthe recent Predicting Generalization in Deep Learning (PGDL) NeurIPS 2020\ncompetition suggests that there is a need for more robust and efficient\nmeasures of network generalization. In this work, we propose a new framework\nfor evaluating the generalization capabilities of trained networks. We use\nperturbation response (PR) curves that capture the accuracy change of a given\nnetwork as a function of varying levels of training sample perturbation. From\nthese PR curves, we derive novel statistics that capture generalization\ncapability. Specifically, we introduce two new measures for accurately\npredicting generalization gaps: the Gi-score and Pal-score, that are inspired\nby the Gini coefficient and Palma ratio (measures of income inequality), that\naccurately predict generalization gaps. Using our framework applied to intra\nand inter class sample mixup, we attain better predictive scores than the\ncurrent state-of-the-art measures on a majority of tasks in the PGDL\ncompetition. In addition, we show that our framework and the proposed\nstatistics can be used to capture to what extent a trained network is invariant\nto a given parametric input transformation, such as rotation or translation.\nTherefore, these generalization gap prediction statistics also provide a useful\nmeans for selecting the optimal network architectures and hyperparameters that\nare invariant to a certain perturbation.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 01:37:36 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Schiff", "Yair", ""], ["Quanz", "Brian", ""], ["Das", "Payel", ""], ["Chen", "Pin-Yu", ""]]}, {"id": "2106.04771", "submitter": "Henrique Santos", "authors": "Henrique Santos, James P. McCusker, Deborah L. McGuinness", "title": "Geospatial Reasoning with Shapefiles for Supporting Policy Decisions", "comments": "4th International Workshop on Geospatial Linked Data (GeoLD 2021) at\n  ESWC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Policies are authoritative assets that are present in multiple domains to\nsupport decision-making. They describe what actions are allowed or recommended\nwhen domain entities and their attributes satisfy certain criteria. It is\ncommon to find policies that contain geographical rules, including distance and\ncontainment relationships among named locations. These locations' polygons can\noften be found encoded in geospatial datasets. We present an approach to\ntransform data from geospatial datasets into Linked Data using the OWL, PROV-O,\nand GeoSPARQL standards, and to leverage this representation to support\nautomated ontology-based policy decisions. We applied our approach to\nlocation-sensitive radio spectrum policies to identify relationships between\nradio transmitters coordinates and policy-regulated regions in Census.gov\ndatasets. Using a policy evaluation pipeline that mixes OWL reasoning and\nGeoSPARQL, our approach implements the relevant geospatial relationships,\naccording to a set of requirements elicited by radio spectrum domain experts.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 02:19:01 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Santos", "Henrique", ""], ["McCusker", "James P.", ""], ["McGuinness", "Deborah L.", ""]]}, {"id": "2106.04775", "submitter": "Luis Torres-Trevi\\~no PhD", "authors": "Luis Torres-Trevi\\~no", "title": "A 2020 taxonomy of algorithms inspired on living beings behavior", "comments": "a collection of algorithms names, 24 pages, two figures, 9 tables, a\n  recompilation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Taking the role of a computer naturalist, a journey is taken through bio\ninspired algorithms taking account on algorithms which are inspired on living\nbeing behaviors. A compilation of algorithms is made considering several\nreviews or surveys of bio-inspired heuristics and swarm intelligence until 2020\nyear. A classification is made considering kingdoms as used by biologists\ngenerating several branches for animalia, bacteria, plants, fungi and protista\nto develop a taxonomy.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 02:37:46 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Torres-Trevi\u00f1o", "Luis", ""]]}, {"id": "2106.04776", "submitter": "Hao Sun", "authors": "Lele Luan, Yang Liu, Hao Sun", "title": "Uncovering Closed-form Governing Equations of Nonlinear Dynamics from\n  Videos", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distilling analytical models from data has the potential to advance our\nunderstanding and prediction of nonlinear dynamics. Although discovery of\ngoverning equations based on observed system states (e.g., trajectory time\nseries) has revealed success in a wide range of nonlinear dynamics, uncovering\nthe closed-form equations directly from raw videos still remains an open\nchallenge. To this end, we introduce a novel end-to-end unsupervised deep\nlearning framework to uncover the mathematical structure of equations that\ngoverns the dynamics of moving objects in videos. Such an architecture consists\nof (1) an encoder-decoder network that learns low-dimensional spatial/pixel\ncoordinates of the moving object, (2) a learnable Spatial-Physical\nTransformation component that creates mapping between the extracted\nspatial/pixel coordinates and the latent physical states of dynamics, and (3) a\nnumerical integrator-based sparse regression module that uncovers the\nparsimonious closed-form governing equations of learned physical states and,\nmeanwhile, serves as a constraint to the autoencoder. The efficacy of the\nproposed method is demonstrated by uncovering the governing equations of a\nvariety of nonlinear dynamical systems depicted by moving objects in videos.\nThe resulting computational framework enables discovery of parsimonious\ninterpretable model in a flexible and accessible sensing environment where only\nvideos are available.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 02:50:11 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Luan", "Lele", ""], ["Liu", "Yang", ""], ["Sun", "Hao", ""]]}, {"id": "2106.04823", "submitter": "Sina Mohseni", "authors": "Sina Mohseni and Haotao Wang and Zhiding Yu and Chaowei Xiao and\n  Zhangyang Wang and Jay Yadawa", "title": "Practical Machine Learning Safety: A Survey and Primer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The open-world deployment of Machine Learning (ML) algorithms in\nsafety-critical applications such as autonomous vehicles needs to address a\nvariety of ML vulnerabilities such as interpretability, verifiability, and\nperformance limitations. Research explores different approaches to improve ML\ndependability by proposing new models and training techniques to reduce\ngeneralization error, achieve domain adaptation, and detect outlier examples\nand adversarial attacks. In this paper, we review and organize practical ML\ntechniques that can improve the safety and dependability of ML algorithms and\ntherefore ML-based software. Our organization maps state-of-the-art ML\ntechniques to safety strategies in order to enhance the dependability of the ML\nalgorithm from different aspects, and discuss research gaps as well as\npromising solutions.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 05:56:42 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Mohseni", "Sina", ""], ["Wang", "Haotao", ""], ["Yu", "Zhiding", ""], ["Xiao", "Chaowei", ""], ["Wang", "Zhangyang", ""], ["Yadawa", "Jay", ""]]}, {"id": "2106.04866", "submitter": "Nir Lipovetzky", "authors": "Nir Lipovetzky", "title": "Planning for Novelty: Width-Based Algorithms for Common Problems in\n  Control, Planning and Reinforcement Learning", "comments": null, "journal-ref": "IJCAI 2021 Early Career Spotlight Talk", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Width-based algorithms search for solutions through a general definition of\nstate novelty. These algorithms have been shown to result in state-of-the-art\nperformance in classical planning, and have been successfully applied to\nmodel-based and model-free settings where the dynamics of the problem are given\nthrough simulation engines. Width-based algorithms performance is understood\ntheoretically through the notion of planning width, providing polynomial\nguarantees on their runtime and memory consumption. To facilitate synergies\nacross research communities, this paper summarizes the area of width-based\nplanning, and surveys current and future research directions.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 07:46:19 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Lipovetzky", "Nir", ""]]}, {"id": "2106.04887", "submitter": "Tengyang Xie", "authors": "Tengyang Xie, John Langford, Paul Mineiro, Ida Momennejad", "title": "Interaction-Grounded Learning", "comments": "Published in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a prosthetic arm, learning to adapt to its user's control signals.\nWe propose Interaction-Grounded Learning for this novel setting, in which a\nlearner's goal is to interact with the environment with no grounding or\nexplicit reward to optimize its policies. Such a problem evades common RL\nsolutions which require an explicit reward. The learning agent observes a\nmultidimensional context vector, takes an action, and then observes a\nmultidimensional feedback vector. This multidimensional feedback vector has no\nexplicit reward information. In order to succeed, the algorithm must learn how\nto evaluate the feedback vector to discover a latent reward signal, with which\nit can ground its policies without supervision. We show that in an\nInteraction-Grounded Learning setting, with certain natural assumptions, a\nlearner can discover the latent reward and ground its policy for successful\ninteraction. We provide theoretical guarantees and a proof-of-concept empirical\nevaluation to demonstrate the effectiveness of our proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 08:13:29 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 23:24:08 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Xie", "Tengyang", ""], ["Langford", "John", ""], ["Mineiro", "Paul", ""], ["Momennejad", "Ida", ""]]}, {"id": "2106.04905", "submitter": "Kun Zhang", "authors": "Kun Zhang, Guangyi Lv, Meng Wang, and Enhong Chen", "title": "DGA-Net Dynamic Gaussian Attention Network for Sentence Semantic\n  Matching", "comments": "Accepted by CICAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sentence semantic matching requires an agent to determine the semantic\nrelation between two sentences, where much recent progress has been made by the\nadvancement of representation learning techniques and inspiration of human\nbehaviors. Among all these methods, attention mechanism plays an essential role\nby selecting important parts effectively. However, current attention methods\neither focus on all the important parts in a static way or only select one\nimportant part at one attention step dynamically, which leaves a large space\nfor further improvement. To this end, in this paper, we design a novel Dynamic\nGaussian Attention Network (DGA-Net) to combine the advantages of current\nstatic and dynamic attention methods. More specifically, we first leverage\npre-trained language model to encode the input sentences and construct semantic\nrepresentations from a global perspective. Then, we develop a Dynamic Gaussian\nAttention (DGA) to dynamically capture the important parts and corresponding\nlocal contexts from a detailed perspective. Finally, we combine the global\ninformation and detailed local information together to decide the semantic\nrelation of sentences comprehensively and precisely. Extensive experiments on\ntwo popular sentence semantic matching tasks demonstrate that our proposed\nDGA-Net is effective in improving the ability of attention mechanism.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 08:43:04 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Zhang", "Kun", ""], ["Lv", "Guangyi", ""], ["Wang", "Meng", ""], ["Chen", "Enhong", ""]]}, {"id": "2106.04908", "submitter": "Alexander Schindler", "authors": "Sch\\\"utz Mina, Boeck Jaqueline, Liakhovets Daria, Slijep\\v{c}evi\\'c\n  Djordje, Kirchknopf Armin, Hecht Manuel, Bogensperger Johannes, Schlarb Sven,\n  Schindler Alexander, Zeppelzauer Matthias", "title": "Automatic Sexism Detection with Multilingual Transformer Models", "comments": "Technical Report to the AIT_FHSTP EXIST 2021 Challenge contribution\n  (under review) http://nlp.uned.es/exist2021/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sexism has become an increasingly major problem on social networks during the\nlast years. The first shared task on sEXism Identification in Social neTworks\n(EXIST) at IberLEF 2021 is an international competition in the field of Natural\nLanguage Processing (NLP) with the aim to automatically identify sexism in\nsocial media content by applying machine learning methods. Thereby sexism\ndetection is formulated as a coarse (binary) classification problem and a\nfine-grained classification task that distinguishes multiple types of sexist\ncontent (e.g., dominance, stereotyping, and objectification). This paper\npresents the contribution of the AIT_FHSTP team at the EXIST2021 benchmark for\nboth tasks. To solve the tasks we applied two multilingual transformer models,\none based on multilingual BERT and one based on XLM-R. Our approach uses two\ndifferent strategies to adapt the transformers to the detection of sexist\ncontent: first, unsupervised pre-training with additional data and second,\nsupervised fine-tuning with additional and augmented data. For both tasks our\nbest model is XLM-R with unsupervised pre-training on the EXIST data and\nadditional datasets and fine-tuning on the provided dataset. The best run for\nthe binary classification (task 1) achieves a macro F1-score of 0.7752 and\nscores 5th rank in the benchmark; for the multiclass classification (task 2)\nour best submission scores 6th rank with a macro F1-score of 0.5589.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 08:45:51 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Mina", "Sch\u00fctz", ""], ["Jaqueline", "Boeck", ""], ["Daria", "Liakhovets", ""], ["Djordje", "Slijep\u010devi\u0107", ""], ["Armin", "Kirchknopf", ""], ["Manuel", "Hecht", ""], ["Johannes", "Bogensperger", ""], ["Sven", "Schlarb", ""], ["Alexander", "Schindler", ""], ["Matthias", "Zeppelzauer", ""]]}, {"id": "2106.04919", "submitter": "Nibaran Das", "authors": "Hritam Basak, Rohit Kundu, Sukanta Chakraborty, Nibaran Das", "title": "Cervical Cytology Classification Using PCA & GWO Enhanced Deep Features\n  Selection", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cervical cancer is one of the most deadly and common diseases among women\nworldwide. It is completely curable if diagnosed in an early stage, but the\ntedious and costly detection procedure makes it unviable to conduct\npopulation-wise screening. Thus, to augment the effort of the clinicians, in\nthis paper, we propose a fully automated framework that utilizes Deep Learning\nand feature selection using evolutionary optimization for cytology image\nclassification. The proposed framework extracts Deep feature from several\nConvolution Neural Network models and uses a two-step feature reduction\napproach to ensure reduction in computation cost and faster convergence. The\nfeatures extracted from the CNN models form a large feature space whose\ndimensionality is reduced using Principal Component Analysis while preserving\n99% of the variance. A non-redundant, optimal feature subset is selected from\nthis feature space using an evolutionary optimization algorithm, the Grey Wolf\nOptimizer, thus improving the classification performance. Finally, the selected\nfeature subset is used to train an SVM classifier for generating the final\npredictions. The proposed framework is evaluated on three publicly available\nbenchmark datasets: Mendeley Liquid Based Cytology (4-class) dataset, Herlev\nPap Smear (7-class) dataset, and the SIPaKMeD Pap Smear (5-class) dataset\nachieving classification accuracies of 99.47%, 98.32% and 97.87% respectively,\nthus justifying the reliability of the approach. The relevant codes for the\nproposed approach can be found in:\nhttps://github.com/DVLP-CMATERJU/Two-Step-Feature-Enhancement\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 08:57:22 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Basak", "Hritam", ""], ["Kundu", "Rohit", ""], ["Chakraborty", "Sukanta", ""], ["Das", "Nibaran", ""]]}, {"id": "2106.04920", "submitter": "Benjamin Maschler", "authors": "Benjamin Maschler, Tim Knodel and Michael Weyrich", "title": "Towards Deep Industrial Transfer Learning for Anomaly Detection on Time\n  Series Data", "comments": "8 pages, 5 figures, 5 tables. Accepted for publication at IEEE ETFA\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning promises performant anomaly detection on time-variant datasets,\nbut greatly suffers from low availability of suitable training datasets and\nfrequently changing tasks. Deep transfer learning offers mitigation by letting\nalgorithms built upon previous knowledge from different tasks or locations. In\nthis article, a modular deep learning algorithm for anomaly detection on time\nseries datasets is presented that allows for an easy integration of such\ntransfer learning capabilities. It is thoroughly tested on a dataset from a\ndiscrete manufacturing process in order to prove its fundamental adequacy\ntowards deep industrial transfer learning - the transfer of knowledge in\nindustrial applications' special environment.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 08:58:56 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Maschler", "Benjamin", ""], ["Knodel", "Tim", ""], ["Weyrich", "Michael", ""]]}, {"id": "2106.04935", "submitter": "Sara Meftah", "authors": "Sara Meftah, Nasredine Semmar, Youssef Tamaazousti, Hassane Essafi,\n  Fatiha Sadat", "title": "Neural Supervised Domain Adaptation by Augmenting Pre-trained Models\n  with Random Units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural Transfer Learning (TL) is becoming ubiquitous in Natural Language\nProcessing (NLP), thanks to its high performance on many tasks, especially in\nlow-resourced scenarios. Notably, TL is widely used for neural domain\nadaptation to transfer valuable knowledge from high-resource to low-resource\ndomains. In the standard fine-tuning scheme of TL, a model is initially\npre-trained on a source domain and subsequently fine-tuned on a target domain\nand, therefore, source and target domains are trained using the same\narchitecture. In this paper, we show through interpretation methods that such\nscheme, despite its efficiency, is suffering from a main limitation. Indeed,\nalthough capable of adapting to new domains, pre-trained neurons struggle with\nlearning certain patterns that are specific to the target domain. Moreover, we\nshed light on the hidden negative transfer occurring despite the high\nrelatedness between source and target domains, which may mitigate the final\ngain brought by transfer learning. To address these problems, we propose to\naugment the pre-trained model with normalised, weighted and randomly\ninitialised units that foster a better adaptation while maintaining the\nvaluable source knowledge. We show that our approach exhibits significant\nimprovements to the standard fine-tuning scheme for neural domain adaptation\nfrom the news domain to the social media domain on four NLP tasks:\npart-of-speech tagging, chunking, named entity recognition and morphosyntactic\ntagging.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 09:29:11 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Meftah", "Sara", ""], ["Semmar", "Nasredine", ""], ["Tamaazousti", "Youssef", ""], ["Essafi", "Hassane", ""], ["Sadat", "Fatiha", ""]]}, {"id": "2106.04939", "submitter": "Mohammad Reza Feizi Derakhshi", "authors": "Narjes Nikzad-Khasmakhi, Mohammad-Reza Feizi-Derakhshi, Meysam\n  Asgari-Chenaghlu, Mohammad-Ali Balafar, Ali-Reza Feizi-Derakhshi, Taymaz\n  Rahkar-Farshi, Majid Ramezani, Zoleikha Jahanbakhsh-Nagadeh, Elnaz\n  Zafarani-Moattar, Mehrdad Ranjbar-Khadivi", "title": "Phraseformer: Multimodal Key-phrase Extraction using Transformer and\n  Graph Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Background: Keyword extraction is a popular research topic in the field of\nnatural language processing. Keywords are terms that describe the most relevant\ninformation in a document. The main problem that researchers are facing is how\nto efficiently and accurately extract the core keywords from a document.\nHowever, previous keyword extraction approaches have utilized the text and\ngraph features, there is the lack of models that can properly learn and combine\nthese features in a best way.\n  Methods: In this paper, we develop a multimodal Key-phrase extraction\napproach, namely Phraseformer, using transformer and graph embedding\ntechniques. In Phraseformer, each keyword candidate is presented by a vector\nwhich is the concatenation of the text and structure learning representations.\nPhraseformer takes the advantages of recent researches such as BERT and ExEm to\npreserve both representations. Also, the Phraseformer treats the key-phrase\nextraction task as a sequence labeling problem solved using classification\ntask.\n  Results: We analyze the performance of Phraseformer on three datasets\nincluding Inspec, SemEval2010 and SemEval 2017 by F1-score. Also, we\ninvestigate the performance of different classifiers on Phraseformer method\nover Inspec dataset. Experimental results demonstrate the effectiveness of\nPhraseformer method over the three datasets used. Additionally, the Random\nForest classifier gain the highest F1-score among all classifiers.\n  Conclusions: Due to the fact that the combination of BERT and ExEm is more\nmeaningful and can better represent the semantic of words. Hence, Phraseformer\nsignificantly outperforms single-modality methods.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 09:32:17 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Nikzad-Khasmakhi", "Narjes", ""], ["Feizi-Derakhshi", "Mohammad-Reza", ""], ["Asgari-Chenaghlu", "Meysam", ""], ["Balafar", "Mohammad-Ali", ""], ["Feizi-Derakhshi", "Ali-Reza", ""], ["Rahkar-Farshi", "Taymaz", ""], ["Ramezani", "Majid", ""], ["Jahanbakhsh-Nagadeh", "Zoleikha", ""], ["Zafarani-Moattar", "Elnaz", ""], ["Ranjbar-Khadivi", "Mehrdad", ""]]}, {"id": "2106.04944", "submitter": "Danial Dervovic", "authors": "Danial Dervovic, Parisa Hassanzadeh, Samuel Assefa, Prashant Reddy", "title": "Non-Parametric Stochastic Sequential Assignment With Random Arrival\n  Times", "comments": "Accepted to IJCAI '21, full version with Supplementary Material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a problem wherein jobs arrive at random times and assume random\nvalues. Upon each job arrival, the decision-maker must decide immediately\nwhether or not to accept the job and gain the value on offer as a reward, with\nthe constraint that they may only accept at most $n$ jobs over some reference\ntime period. The decision-maker only has access to $M$ independent realisations\nof the job arrival process. We propose an algorithm, Non-Parametric Sequential\nAllocation (NPSA), for solving this problem. Moreover, we prove that the\nexpected reward returned by the NPSA algorithm converges in probability to\noptimality as $M$ grows large. We demonstrate the effectiveness of the\nalgorithm empirically on synthetic data and on public fraud-detection datasets,\nfrom where the motivation for this work is derived.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 09:41:38 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Dervovic", "Danial", ""], ["Hassanzadeh", "Parisa", ""], ["Assefa", "Samuel", ""], ["Reddy", "Prashant", ""]]}, {"id": "2106.04958", "submitter": "Ying Wen", "authors": "Xiangyu Liu, Hangtian Jia, Ying Wen, Yaodong Yang, Yujing Hu, Yingfeng\n  Chen, Changjie Fan, Zhipeng Hu", "title": "Unifying Behavioral and Response Diversity for Open-ended Learning in\n  Zero-sum Games", "comments": "We investigate a new perspective on unifying diversity measures for\n  open-ended learning in zero-sum games, which shapes an auto-curriculum to\n  induce diverse yet effective behaviors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Measuring and promoting policy diversity is critical for solving games with\nstrong non-transitive dynamics where strategic cycles exist, and there is no\nconsistent winner (e.g., Rock-Paper-Scissors). With that in mind, maintaining a\npool of diverse policies via open-ended learning is an attractive solution,\nwhich can generate auto-curricula to avoid being exploited. However, in\nconventional open-ended learning algorithms, there are no widely accepted\ndefinitions for diversity, making it hard to construct and evaluate the diverse\npolicies. In this work, we summarize previous concepts of diversity and work\ntowards offering a unified measure of diversity in multi-agent open-ended\nlearning to include all elements in Markov games, based on both Behavioral\nDiversity (BD) and Response Diversity (RD). At the trajectory distribution\nlevel, we re-define BD in the state-action space as the discrepancies of\noccupancy measures. For the reward dynamics, we propose RD to characterize\ndiversity through the responses of policies when encountering different\nopponents. We also show that many current diversity measures fall in one of the\ncategories of BD or RD but not both. With this unified diversity measure, we\ndesign the corresponding diversity-promoting objective and population\neffectivity when seeking the best responses in open-ended learning. We validate\nour methods in both relatively simple games like matrix game, non-transitive\nmixture model, and the complex \\textit{Google Research Football} environment.\nThe population found by our methods reveals the lowest exploitability, highest\npopulation effectivity in matrix game and non-transitive mixture model, as well\nas the largest goal difference when interacting with opponents of various\nlevels in \\textit{Google Research Football}.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 10:11:06 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 16:00:18 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Liu", "Xiangyu", ""], ["Jia", "Hangtian", ""], ["Wen", "Ying", ""], ["Yang", "Yaodong", ""], ["Hu", "Yujing", ""], ["Chen", "Yingfeng", ""], ["Fan", "Changjie", ""], ["Hu", "Zhipeng", ""]]}, {"id": "2106.04967", "submitter": "Jens Petersen", "authors": "Jens Petersen, Gregor K\\\"ohler, David Zimmerer, Fabian Isensee, Paul\n  F. J\\\"ager, Klaus H. Maier-Hein", "title": "GP-ConvCNP: Better Generalization for Convolutional Conditional Neural\n  Processes on Time Series Data", "comments": "UAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural Processes (NPs) are a family of conditional generative models that are\nable to model a distribution over functions, in a way that allows them to\nperform predictions at test time conditioned on a number of context points. A\nrecent addition to this family, Convolutional Conditional Neural Processes\n(ConvCNP), have shown remarkable improvement in performance over prior art, but\nwe find that they sometimes struggle to generalize when applied to time series\ndata. In particular, they are not robust to distribution shifts and fail to\nextrapolate observed patterns into the future. By incorporating a Gaussian\nProcess into the model, we are able to remedy this and at the same time improve\nperformance within distribution. As an added benefit, the Gaussian Process\nreintroduces the possibility to sample from the model, a key feature of other\nmembers in the NP family.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 10:26:39 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 13:46:13 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Petersen", "Jens", ""], ["K\u00f6hler", "Gregor", ""], ["Zimmerer", "David", ""], ["Isensee", "Fabian", ""], ["J\u00e4ger", "Paul F.", ""], ["Maier-Hein", "Klaus H.", ""]]}, {"id": "2106.04972", "submitter": "Tim Pearce", "authors": "Tim Pearce, Alexandra Brintrup, Jun Zhu", "title": "Understanding Softmax Confidence and Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is often remarked that neural networks fail to increase their uncertainty\nwhen predicting on data far from the training distribution. Yet naively using\nsoftmax confidence as a proxy for uncertainty achieves modest success in tasks\nexclusively testing for this, e.g., out-of-distribution (OOD) detection. This\npaper investigates this contradiction, identifying two implicit biases that do\nencourage softmax confidence to correlate with epistemic uncertainty: 1)\nApproximately optimal decision boundary structure, and 2) Filtering effects of\ndeep networks. It describes why low-dimensional intuitions about softmax\nconfidence are misleading. Diagnostic experiments quantify reasons softmax\nconfidence can fail, finding that extrapolations are less to blame than overlap\nbetween training and OOD data in final-layer representations.\nPre-trained/fine-tuned networks reduce this overlap.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 10:37:29 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Pearce", "Tim", ""], ["Brintrup", "Alexandra", ""], ["Zhu", "Jun", ""]]}, {"id": "2106.04984", "submitter": "Matteo Pozzi", "authors": "Shuo Li, Matteo Pozzi", "title": "Information Avoidance and Overvaluation in Sequential Decision Making\n  under Epistemic Constraints", "comments": "submitted to Rel. Eng. Sys. Saf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT cs.MA cs.SY eess.SY math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Decision makers involved in the management of civil assets and systems\nusually take actions under constraints imposed by societal regulations. Some of\nthese constraints are related to epistemic quantities, as the probability of\nfailure events and the corresponding risks. Sensors and inspectors can provide\nuseful information supporting the control process (e.g. the maintenance process\nof an asset), and decisions about collecting this information should rely on an\nanalysis of its cost and value. When societal regulations encode an economic\nperspective that is not aligned with that of the decision makers, the Value of\nInformation (VoI) can be negative (i.e., information sometimes hurts), and\nalmost irrelevant information can even have a significant value (either\npositive or negative), for agents acting under these epistemic constraints. We\nrefer to these phenomena as Information Avoidance (IA) and Information\nOverValuation (IOV). In this paper, we illustrate how to assess VoI in\nsequential decision making under epistemic constraints (as those imposed by\nsocietal regulations), by modeling a Partially Observable Markov Decision\nProcesses (POMDP) and evaluating non optimal policies via Finite State\nControllers (FSCs). We focus on the value of collecting information at current\ntime, and on that of collecting sequential information, we illustrate how these\nvalues are related and we discuss how IA and IOV can occur in those settings.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 11:05:13 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Li", "Shuo", ""], ["Pozzi", "Matteo", ""]]}, {"id": "2106.05003", "submitter": "Guanchen Ding", "authors": "Jingyuan Chen, Guanchen Ding, Yuchen Yang, Wenwei Han, Kangmin Xu,\n  Tianyi Gao, Zhe Zhang, Wanping Ouyang, Hao Cai, Zhenzhong Chen", "title": "Dual-Modality Vehicle Anomaly Detection via Bilateral Trajectory Tracing", "comments": "9 pages, 5 figures, accepted to CVPRW 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic anomaly detection has played a crucial role in Intelligent\nTransportation System (ITS). The main challenges of this task lie in the highly\ndiversified anomaly scenes and variational lighting conditions. Although much\nwork has managed to identify the anomaly in homogenous weather and scene, few\nresolved to cope with complex ones. In this paper, we proposed a dual-modality\nmodularized methodology for the robust detection of abnormal vehicles. We\nintroduced an integrated anomaly detection framework comprising the following\nmodules: background modeling, vehicle tracking with detection, mask\nconstruction, Region of Interest (ROI) backtracking, and dual-modality tracing.\nConcretely, we employed background modeling to filter the motion information\nand left the static information for later vehicle detection. For the vehicle\ndetection and tracking module, we adopted YOLOv5 and multi-scale tracking to\nlocalize the anomalies. Besides, we utilized the frame difference and tracking\nresults to identify the road and obtain the mask. In addition, we introduced\nmultiple similarity estimation metrics to refine the anomaly period via\nbacktracking. Finally, we proposed a dual-modality bilateral tracing module to\nrefine the time further. The experiments conducted on the Track 4 testset of\nthe NVIDIA 2021 AI City Challenge yielded a result of 0.9302 F1-Score and\n3.4039 root mean square error (RMSE), indicating the effectiveness of our\nframework.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 12:04:25 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Chen", "Jingyuan", ""], ["Ding", "Guanchen", ""], ["Yang", "Yuchen", ""], ["Han", "Wenwei", ""], ["Xu", "Kangmin", ""], ["Gao", "Tianyi", ""], ["Zhang", "Zhe", ""], ["Ouyang", "Wanping", ""], ["Cai", "Hao", ""], ["Chen", "Zhenzhong", ""]]}, {"id": "2106.05037", "submitter": "Andrea Apicella", "authors": "Andrea Apicella, Francesco Isgr\\`o, Roberto Prevete", "title": "A general approach for Explanations in terms of Middle Level Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, it is growing interest to make Machine Learning (ML) systems more\nunderstandable and trusting to general users. Thus, generating explanations for\nML system behaviours that are understandable to human beings is a central\nscientific and technological issue addressed by the rapidly growing research\narea of eXplainable Artificial Intelligence (XAI). Recently, it is becoming\nmore and more evident that new directions to create better explanations should\ntake into account what a good explanation is to a human user, and consequently,\ndevelop XAI solutions able to provide user-centred explanations. This paper\nsuggests taking advantage of developing an XAI general approach that allows\nproducing explanations for an ML system behaviour in terms of different and\nuser-selected input features, i.e., explanations composed of input properties\nthat the human user can select according to his background knowledge and goals.\nTo this end, we propose an XAI general approach which is able: 1) to construct\nexplanations in terms of input features that represent more salient and\nunderstandable input properties for a user, which we call here Middle-Level\ninput Features (MLFs), 2) to be applied to different types of MLFs. We\nexperimentally tested our approach on two different datasets and using three\ndifferent types of MLFs. The results seem encouraging.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 12:51:40 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 09:00:35 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Apicella", "Andrea", ""], ["Isgr\u00f2", "Francesco", ""], ["Prevete", "Roberto", ""]]}, {"id": "2106.05065", "submitter": "Xutong Liu", "authors": "Xutong Liu, Jinhang Zuo, Xiaowei Chen, Wei Chen, John C.S. Lui", "title": "Multi-layered Network Exploration via Random Walks: From Offline\n  Optimization to Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-layered network exploration (MuLaNE) problem is an important problem\nabstracted from many applications. In MuLaNE, there are multiple network layers\nwhere each node has an importance weight and each layer is explored by a random\nwalk. The MuLaNE task is to allocate total random walk budget $B$ into each\nnetwork layer so that the total weights of the unique nodes visited by random\nwalks are maximized. We systematically study this problem from offline\noptimization to online learning. For the offline optimization setting where the\nnetwork structure and node weights are known, we provide greedy based\nconstant-ratio approximation algorithms for overlapping networks, and greedy or\ndynamic-programming based optimal solutions for non-overlapping networks. For\nthe online learning setting, neither the network structure nor the node weights\nare known initially. We adapt the combinatorial multi-armed bandit framework\nand design algorithms to learn random walk related parameters and node weights\nwhile optimizing the budget allocation in multiple rounds, and prove that they\nachieve logarithmic regret bounds. Finally, we conduct experiments on a\nreal-world social network dataset to validate our theoretical results.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 13:35:39 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Liu", "Xutong", ""], ["Zuo", "Jinhang", ""], ["Chen", "Xiaowei", ""], ["Chen", "Wei", ""], ["Lui", "John C. S.", ""]]}, {"id": "2106.05091", "submitter": "Kimin Lee", "authors": "Kimin Lee, Laura Smith, Pieter Abbeel", "title": "PEBBLE: Feedback-Efficient Interactive Reinforcement Learning via\n  Relabeling Experience and Unsupervised Pre-training", "comments": "ICML 2021. First two authors contributed equally. Website:\n  https://sites.google.com/view/icml21pebble Code:\n  https://github.com/pokaxpoka/B_Pref", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conveying complex objectives to reinforcement learning (RL) agents can often\nbe difficult, involving meticulous design of reward functions that are\nsufficiently informative yet easy enough to provide. Human-in-the-loop RL\nmethods allow practitioners to instead interactively teach agents through\ntailored feedback; however, such approaches have been challenging to scale\nsince human feedback is very expensive. In this work, we aim to make this\nprocess more sample- and feedback-efficient. We present an off-policy,\ninteractive RL algorithm that capitalizes on the strengths of both feedback and\noff-policy learning. Specifically, we learn a reward model by actively querying\na teacher's preferences between two clips of behavior and use it to train an\nagent. To enable off-policy learning, we relabel all the agent's past\nexperience when its reward model changes. We additionally show that\npre-training our agents with unsupervised exploration substantially increases\nthe mileage of its queries. We demonstrate that our approach is capable of\nlearning tasks of higher complexity than previously considered by\nhuman-in-the-loop methods, including a variety of locomotion and robotic\nmanipulation skills. We also show that our method is able to utilize real-time\nhuman feedback to effectively prevent reward exploitation and learn new\nbehaviors that are difficult to specify with standard reward functions.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 14:10:50 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Lee", "Kimin", ""], ["Smith", "Laura", ""], ["Abbeel", "Pieter", ""]]}, {"id": "2106.05093", "submitter": "Zhaopeng Tu", "authors": "Cunxiao Du and Zhaopeng Tu and Jing Jiang", "title": "Order-Agnostic Cross Entropy for Non-Autoregressive Machine Translation", "comments": "ICML 2021 (Oral), Code at\n  https://github.com/tencent-ailab/ICML21_OAXE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a new training objective named order-agnostic cross entropy (OaXE)\nfor fully non-autoregressive translation (NAT) models. OaXE improves the\nstandard cross-entropy loss to ameliorate the effect of word reordering, which\nis a common source of the critical multimodality problem in NAT. Concretely,\nOaXE removes the penalty for word order errors, and computes the cross entropy\nloss based on the best possible alignment between model predictions and target\ntokens. Since the log loss is very sensitive to invalid references, we leverage\ncross entropy initialization and loss truncation to ensure the model focuses on\na good part of the search space. Extensive experiments on major WMT benchmarks\nshow that OaXE substantially improves translation performance, setting new\nstate of the art for fully NAT models. Further analyses show that OaXE\nalleviates the multimodality problem by reducing token repetitions and\nincreasing prediction confidence. Our code, data, and trained models are\navailable at https://github.com/tencent-ailab/ICML21_OAXE.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 14:15:12 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Du", "Cunxiao", ""], ["Tu", "Zhaopeng", ""], ["Jiang", "Jing", ""]]}, {"id": "2106.05126", "submitter": "Andr\\'e Hottung", "authors": "Andr\\'e Hottung, Yeong-Dae Kwon, Kevin Tierney", "title": "Efficient Active Search for Combinatorial Optimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently numerous machine learning based methods for combinatorial\noptimization problems have been proposed that learn to construct solutions in a\nsequential decision process via reinforcement learning. While these methods can\nbe easily combined with search strategies like sampling and beam search, it is\nnot straightforward to integrate them into a high-level search procedure\noffering strong search guidance. Bello et al. (2016) propose active search,\nwhich adjusts the weights of a (trained) model with respect to a single\ninstance at test time using reinforcement learning. While active search is\nsimple to implement, it is not competitive with state-of-the-art methods\nbecause adjusting all model weights for each test instance is very time and\nmemory intensive. Instead of updating all model weights, we propose and\nevaluate three efficient active search strategies that only update a subset of\nparameters during the search. The proposed methods offer a simple way to\nsignificantly improve the search performance of a given model and outperform\nstate-of-the-art machine learning based methods on combinatorial problems, even\nsurpassing the well-known heuristic solver LKH3 on the capacitated vehicle\nrouting problem. Finally, we show that (efficient) active search enables\nlearned models to effectively solve instances that are much larger than those\nseen during training.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 15:08:03 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Hottung", "Andr\u00e9", ""], ["Kwon", "Yeong-Dae", ""], ["Tierney", "Kevin", ""]]}, {"id": "2106.05188", "submitter": "Shyni Thomas", "authors": "Shyni Thomas, M. Narasimha Murty", "title": "Decentralised Approach for Multi Agent Path Finding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Multi Agent Path Finding (MAPF) requires identification of conflict free\npaths for agents which could be point-sized or with dimensions. In this paper,\nwe propose an approach for MAPF for spatially-extended agents. These find\napplication in real world problems like Convoy Movement Problem, Train\nScheduling etc. Our proposed approach, Decentralised Multi Agent Path Finding\n(DeMAPF), handles MAPF as a sequence of pathplanning and allocation problems\nwhich are solved by two sets of agents Travellers and Routers respectively,\nover multiple iterations. The approach being decentralised allows an agent to\nsolve the problem pertinent to itself, without being aware of other agents in\nthe same set. This allows the agents to be executed on independent machines,\nthereby leading to scalability to handle large sized problems. We prove, by\ncomparison with other distributed approaches, that the approach leads to a\nfaster convergence to a conflict-free solution, which may be suboptimal, with\nlesser memory requirement.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 18:07:26 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Thomas", "Shyni", ""], ["Murty", "M. Narasimha", ""]]}, {"id": "2106.05193", "submitter": "Wadii Boulila Prof.", "authors": "Zouhayra Ayadi, Wadii Boulila, Imed Riadh Farah", "title": "A Hybrid APM-CPGSO Approach for Constraint Satisfaction Problem Solving:\n  Application to Remote Sensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Constraint satisfaction problem (CSP) has been actively used for modeling and\nsolving a wide range of complex real-world problems. However, it has been\nproven that developing efficient methods for solving CSP, especially for large\nproblems, is very difficult and challenging. Existing complete methods for\nproblem-solving are in most cases unsuitable. Therefore, proposing hybrid\nCSP-based methods for problem-solving has been of increasing interest in the\nlast decades. This paper aims at proposing a novel approach that combines\nincomplete and complete CSP methods for problem-solving. The proposed approach\ntakes advantage of the group search algorithm (GSO) and the constraint\npropagation (CP) methods to solve problems related to the remote sensing field.\nTo the best of our knowledge, this paper represents the first study that\nproposes a hybridization between an improved version of GSO and CP in the\nresolution of complex constraint-based problems. Experiments have been\nconducted for the resolution of object recognition problems in satellite\nimages. Results show good performances in terms of convergence and running time\nof the proposed CSP-based method compared to existing state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 22:05:22 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Ayadi", "Zouhayra", ""], ["Boulila", "Wadii", ""], ["Farah", "Imed Riadh", ""]]}, {"id": "2106.05194", "submitter": "Yixuan He", "authors": "Yixuan He and Gesine Reinert and Mihai Cucuringu", "title": "DIGRAC: Digraph Clustering with Flow Imbalance", "comments": "33 pages (10 pages for main text)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Node clustering is a powerful tool in the analysis of networks. Here, we\nintroduce a graph neural network framework with a novel scalable Directed Mixed\nPath Aggregation(DIMPA) scheme to obtain node embeddings for directed networks\nin a self-supervised manner, including a novel probabilistic imbalance loss.\nThe method is end-to-end in combining embedding generation and clustering\nwithout an intermediate step. In contrast to standard approaches in the\nliterature, in this paper, directionality is not treated as a nuisance, but\nrather contains the main signal. In particular, we leverage the recently\nintroduced cut flow imbalance measure, which is tightly related to\ndirectionality; cut flow imbalance is optimized without resorting to spectral\nmethods or cluster labels. Experimental results on synthetic data, in the form\nof directed stochastic block models and real-world data at different scales,\ndemonstrate that our method attains state-of-the-art results on directed\nclustering, for a wide range of noise and sparsity levels, as well as graph\nstructures.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 16:33:13 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["He", "Yixuan", ""], ["Reinert", "Gesine", ""], ["Cucuringu", "Mihai", ""]]}, {"id": "2106.05200", "submitter": "Julius von K\\\"ugelgen", "authors": "Luigi Gresele, Julius von K\\\"ugelgen, Vincent Stimper, Bernhard\n  Sch\\\"olkopf, Michel Besserve", "title": "Independent mechanism analysis, a new concept?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Independent component analysis provides a principled framework for\nunsupervised representation learning, with solid theory on the identifiability\nof the latent code that generated the data, given only observations of mixtures\nthereof. Unfortunately, when the mixing is nonlinear, the model is provably\nnonidentifiable, since statistical independence alone does not sufficiently\nconstrain the problem. Identifiability can be recovered in settings where\nadditional, typically observed variables are included in the generative\nprocess. We investigate an alternative path and consider instead including\nassumptions reflecting the principle of independent causal mechanisms exploited\nin the field of causality. Specifically, our approach is motivated by thinking\nof each source as independently influencing the mixing process. This gives rise\nto a framework which we term independent mechanism analysis. We provide\ntheoretical and empirical evidence that our approach circumvents a number of\nnonidentifiability issues arising in nonlinear blind source separation.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 16:45:00 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Gresele", "Luigi", ""], ["von K\u00fcgelgen", "Julius", ""], ["Stimper", "Vincent", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Besserve", "Michel", ""]]}, {"id": "2106.05209", "submitter": "Shuxuan Guo", "authors": "Shuxuan Guo and Jose M. Alvarez and Mathieu Salzmann", "title": "Distilling Image Classifiers in Object Detectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge distillation constitutes a simple yet effective way to improve the\nperformance of a compact student network by exploiting the knowledge of a more\npowerful teacher. Nevertheless, the knowledge distillation literature remains\nlimited to the scenario where the student and the teacher tackle the same task.\nHere, we investigate the problem of transferring knowledge not only across\narchitectures but also across tasks. To this end, we study the case of object\ndetection and, instead of following the standard detector-to-detector\ndistillation approach, introduce a classifier-to-detector knowledge transfer\nframework. In particular, we propose strategies to exploit the classification\nteacher to improve both the detector's recognition accuracy and localization\nperformance. Our experiments on several detectors with different backbones\ndemonstrate the effectiveness of our approach, allowing us to outperform the\nstate-of-the-art detector-to-detector distillation methods.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 16:50:10 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Guo", "Shuxuan", ""], ["Alvarez", "Jose M.", ""], ["Salzmann", "Mathieu", ""]]}, {"id": "2106.05221", "submitter": "Shuoran Jiang", "authors": "Shuoran Jiang, Qingcai Chen, Xin Liu, Baotian Hu, Lisai Zhang", "title": "Multi-hop Graph Convolutional Network with High-order Chebyshev\n  Approximation for Text Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional network (GCN) has become popular in various natural\nlanguage processing (NLP) tasks with its superiority in long-term and\nnon-consecutive word interactions. However, existing single-hop graph reasoning\nin GCN may miss some important non-consecutive dependencies. In this study, we\ndefine the spectral graph convolutional network with the high-order dynamic\nChebyshev approximation (HDGCN), which augments the multi-hop graph reasoning\nby fusing messages aggregated from direct and long-term dependencies into one\nconvolutional layer. To alleviate the over-smoothing in high-order Chebyshev\napproximation, a multi-vote-based cross-attention (MVCAttn) with linear\ncomputation complexity is also proposed. The empirical results on four\ntransductive and inductive NLP tasks and the ablation study verify the efficacy\nof the proposed model. Our source code is available at\nhttps://github.com/MathIsAll/HDGCN-pytorch.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 07:49:43 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Jiang", "Shuoran", ""], ["Chen", "Qingcai", ""], ["Liu", "Xin", ""], ["Hu", "Baotian", ""], ["Zhang", "Lisai", ""]]}, {"id": "2106.05223", "submitter": "Chuizheng Meng", "authors": "Chuizheng Meng, Sirisha Rambhatla, Yan Liu", "title": "Cross-Node Federated Graph Neural Network for Spatio-Temporal Data\n  Modeling", "comments": "To be published in the 27th ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining (KDD 21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Vast amount of data generated from networks of sensors, wearables, and the\nInternet of Things (IoT) devices underscores the need for advanced modeling\ntechniques that leverage the spatio-temporal structure of decentralized data\ndue to the need for edge computation and licensing (data access) issues. While\nfederated learning (FL) has emerged as a framework for model training without\nrequiring direct data sharing and exchange, effectively modeling the complex\nspatio-temporal dependencies to improve forecasting capabilities still remains\nan open problem. On the other hand, state-of-the-art spatio-temporal\nforecasting models assume unfettered access to the data, neglecting constraints\non data sharing. To bridge this gap, we propose a federated spatio-temporal\nmodel -- Cross-Node Federated Graph Neural Network (CNFGNN) -- which explicitly\nencodes the underlying graph structure using graph neural network (GNN)-based\narchitecture under the constraint of cross-node federated learning, which\nrequires that data in a network of nodes is generated locally on each node and\nremains decentralized. CNFGNN operates by disentangling the temporal dynamics\nmodeling on devices and spatial dynamics on the server, utilizing alternating\noptimization to reduce the communication cost, facilitating computations on the\nedge devices. Experiments on the traffic flow forecasting task show that CNFGNN\nachieves the best forecasting performance in both transductive and inductive\nlearning settings with no extra computation cost on edge devices, while\nincurring modest communication cost.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 17:12:43 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Meng", "Chuizheng", ""], ["Rambhatla", "Sirisha", ""], ["Liu", "Yan", ""]]}, {"id": "2106.05234", "submitter": "Shuxin Zheng", "authors": "Chengxuan Ying, Tianle Cai, Shengjie Luo, Shuxin Zheng, Guolin Ke, Di\n  He, Yanming Shen and Tie-Yan Liu", "title": "Do Transformers Really Perform Bad for Graph Representation?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The Transformer architecture has become a dominant choice in many domains,\nsuch as natural language processing and computer vision. Yet, it has not\nachieved competitive performance on popular leaderboards of graph-level\nprediction compared to mainstream GNN variants. Therefore, it remains a mystery\nhow Transformers could perform well for graph representation learning. In this\npaper, we solve this mystery by presenting Graphormer, which is built upon the\nstandard Transformer architecture, and could attain excellent results on a\nbroad range of graph representation learning tasks, especially on the recent\nOGB Large-Scale Challenge. Our key insight to utilizing Transformer in the\ngraph is the necessity of effectively encoding the structural information of a\ngraph into the model. To this end, we propose several simple yet effective\nstructural encoding methods to help Graphormer better model graph-structured\ndata. Besides, we mathematically characterize the expressive power of\nGraphormer and exhibit that with our ways of encoding the structural\ninformation of graphs, many popular GNN variants could be covered as the\nspecial cases of Graphormer.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 17:18:52 GMT"}, {"version": "v2", "created": "Sun, 13 Jun 2021 02:12:29 GMT"}, {"version": "v3", "created": "Thu, 17 Jun 2021 11:36:47 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Ying", "Chengxuan", ""], ["Cai", "Tianle", ""], ["Luo", "Shengjie", ""], ["Zheng", "Shuxin", ""], ["Ke", "Guolin", ""], ["He", "Di", ""], ["Shen", "Yanming", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2106.05237", "submitter": "Xiaohua Zhai", "authors": "Lucas Beyer, Xiaohua Zhai, Am\\'elie Royer, Larisa Markeeva, Rohan\n  Anil, Alexander Kolesnikov", "title": "Knowledge distillation: A good teacher is patient and consistent", "comments": "Lucas, Xiaohua, Am\\'elie, Larisa, and Alex contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing discrepancy in computer vision between large-scale models\nthat achieve state-of-the-art performance and models that are affordable in\npractical applications. In this paper we address this issue and significantly\nbridge the gap between these two types of models. Throughout our empirical\ninvestigation we do not aim to necessarily propose a new method, but strive to\nidentify a robust and effective recipe for making state-of-the-art large scale\nmodels affordable in practice. We demonstrate that, when performed correctly,\nknowledge distillation can be a powerful tool for reducing the size of large\nmodels without compromising their performance. In particular, we uncover that\nthere are certain implicit design choices, which may drastically affect the\neffectiveness of distillation. Our key contribution is the explicit\nidentification of these design choices, which were not previously articulated\nin the literature. We back up our findings by a comprehensive empirical study,\ndemonstrate compelling results on a wide range of vision datasets and, in\nparticular, obtain a state-of-the-art ResNet-50 model for ImageNet, which\nachieves 82.8\\% top-1 accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 17:20:40 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Beyer", "Lucas", ""], ["Zhai", "Xiaohua", ""], ["Royer", "Am\u00e9lie", ""], ["Markeeva", "Larisa", ""], ["Anil", "Rohan", ""], ["Kolesnikov", "Alexander", ""]]}, {"id": "2106.05268", "submitter": "Denis Kleyko", "authors": "Denis Kleyko, Mike Davies, E. Paxon Frady, Pentti Kanerva, Spencer J.\n  Kent, Bruno A. Olshausen, Evgeny Osipov, Jan M. Rabaey, Dmitri A.\n  Rachkovskij, Abbas Rahimi, Friedrich T. Sommer", "title": "Vector Symbolic Architectures as a Computing Framework for Nanoscale\n  Hardware", "comments": "28 pages, 15 figures, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article reviews recent progress in the development of the computing\nframework Vector Symbolic Architectures (also known as Hyperdimensional\nComputing). This framework is well suited for implementation in stochastic,\nnanoscale hardware and it naturally expresses the types of cognitive operations\nrequired for Artificial Intelligence (AI). We demonstrate in this article that\nthe ring-like algebraic structure of Vector Symbolic Architectures offers\nsimple but powerful operations on high-dimensional vectors that can support all\ndata structures and manipulations relevant in modern computing. In addition, we\nillustrate the distinguishing feature of Vector Symbolic Architectures,\n\"computing in superposition,\" which sets it apart from conventional computing.\nThis latter property opens the door to efficient solutions to the difficult\ncombinatorial search problems inherent in AI applications. Vector Symbolic\nArchitectures are Turing complete, as we show, and we see them acting as a\nframework for computing with distributed representations in myriad AI settings.\nThis paper serves as a reference for computer architects by illustrating\ntechniques and philosophy of VSAs for distributed computing and relevance to\nemerging computing hardware, such as neuromorphic computing.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 23:38:39 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Kleyko", "Denis", ""], ["Davies", "Mike", ""], ["Frady", "E. Paxon", ""], ["Kanerva", "Pentti", ""], ["Kent", "Spencer J.", ""], ["Olshausen", "Bruno A.", ""], ["Osipov", "Evgeny", ""], ["Rabaey", "Jan M.", ""], ["Rachkovskij", "Dmitri A.", ""], ["Rahimi", "Abbas", ""], ["Sommer", "Friedrich T.", ""]]}, {"id": "2106.05303", "submitter": "Jonathan Crabb\\'e", "authors": "Jonathan Crabb\\'e, Mihaela van der Schaar", "title": "Explaining Time Series Predictions with Dynamic Masks", "comments": "Presented at the Thirty-eighth International Conference on Machine\n  Learning (ICML 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  How can we explain the predictions of a machine learning model? When the data\nis structured as a multivariate time series, this question induces additional\ndifficulties such as the necessity for the explanation to embody the time\ndependency and the large number of inputs. To address these challenges, we\npropose dynamic masks (Dynamask). This method produces instance-wise importance\nscores for each feature at each time step by fitting a perturbation mask to the\ninput sequence. In order to incorporate the time dependency of the data,\nDynamask studies the effects of dynamic perturbation operators. In order to\ntackle the large number of inputs, we propose a scheme to make the feature\nselection parsimonious (to select no more feature than necessary) and legible\n(a notion that we detail by making a parallel with information theory). With\nsynthetic and real-world data, we demonstrate that the dynamic underpinning of\nDynamask, together with its parsimony, offer a neat improvement in the\nidentification of feature importance over time. The modularity of Dynamask\nmakes it ideal as a plug-in to increase the transparency of a wide range of\nmachine learning models in areas such as medicine and finance, where time\nseries are abundant.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 18:01:09 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Crabb\u00e9", "Jonathan", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2106.05316", "submitter": "M. Hamed Mozaffari", "authors": "M. Hamed Mozaffari and Li-Lin Tay", "title": "Raman spectral analysis of mixtures with one-dimensional convolutional\n  neural network", "comments": "9 pages, 5 tables, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the combination of robust one-dimensional convolutional neural\nnetworks (1-D CNNs) and Raman spectroscopy has shown great promise in rapid\nidentification of unknown substances with good accuracy. Using this technique,\nresearchers can recognize a pure compound and distinguish it from unknown\nsubstances in a mixture. The novelty of this approach is that the trained\nneural network operates automatically without any pre- or post-processing of\ndata. Some studies have attempted to extend this technique to the\nclassification of pure compounds in an unknown mixture. However, the\napplication of 1-D CNNs has typically been restricted to binary classifications\nof pure compounds. Here we will highlight a new approach in spectral\nrecognition and quantification of chemical components in a multicomponent\nmixture. Two 1-D CNN models, RaMixNet I and II, have been developed for this\npurpose. The former is for rapid classification of components in a mixture\nwhile the latter is for quantitative determination of those constituents. In\nthe proposed method, there is no limit to the number of compounds in a mixture.\nA data augmentation method is also introduced by adding random baselines to the\nRaman spectra. The experimental results revealed that the classification\naccuracy of RaMixNet I and II is 100% for analysis of unknown test mixtures; at\nthe same time, the RaMixNet II model may achieve a regression accuracy of 88%\nfor the quantification of each component.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 16:23:30 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Mozaffari", "M. Hamed", ""], ["Tay", "Li-Lin", ""]]}, {"id": "2106.05325", "submitter": "Christopher Strong", "authors": "Christopher A. Strong, Sydney M. Katz, Anthony L. Corso, Mykel J.\n  Kochenderfer", "title": "ZoPE: A Fast Optimizer for ReLU Networks with Low-Dimensional Inputs", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks often lack the safety and robustness guarantees needed\nto be deployed in safety critical systems. Formal verification techniques can\nbe used to prove input-output safety properties of networks, but when\nproperties are difficult to specify, we rely on the solution to various\noptimization problems. In this work, we present an algorithm called ZoPE that\nsolves optimization problems over the output of feedforward ReLU networks with\nlow-dimensional inputs. The algorithm eagerly splits the input space, bounding\nthe objective using zonotope propagation at each step, and improves\ncomputational efficiency compared to existing mixed integer programming\napproaches. We demonstrate how to formulate and solve three types of\noptimization problems: (i) minimization of any convex function over the output\nspace, (ii) minimization of a convex function over the output of two networks\nin series with an adversarial perturbation in the layer between them, and (iii)\nmaximization of the difference in output between two networks. Using ZoPE, we\nobserve a $25\\times$ speedup on property 1 of the ACAS Xu neural network\nverification benchmark and an $85\\times$ speedup on a set of linear\noptimization problems. We demonstrate the versatility of the optimizer in\nanalyzing networks by projecting onto the range of a generative adversarial\nnetwork and visualizing the differences between a compressed and uncompressed\nnetwork.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 18:36:41 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Strong", "Christopher A.", ""], ["Katz", "Sydney M.", ""], ["Corso", "Anthony L.", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2106.05346", "submitter": "Devendra Singh Sachan", "authors": "Devendra Singh Sachan and Siva Reddy and William Hamilton and Chris\n  Dyer and Dani Yogatama", "title": "End-to-End Training of Multi-Document Reader and Retriever for\n  Open-Domain Question Answering", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an end-to-end differentiable training method for\nretrieval-augmented open-domain question answering systems that combine\ninformation from multiple retrieved documents when generating answers. We model\nretrieval decisions as latent variables over sets of relevant documents. Since\nmarginalizing over sets of retrieved documents is computationally hard, we\napproximate this using an expectation-maximization algorithm. We iteratively\nestimate the value of our latent variable (the set of relevant documents for a\ngiven question) and then use this estimate to update the retriever and reader\nparameters. We hypothesize that such end-to-end training allows training\nsignals to flow to the reader and then to the retriever better than staged-wise\ntraining. This results in a retriever that is able to select more relevant\ndocuments for a question and a reader that is trained on more accurate\ndocuments to generate an answer. Experiments on three benchmark datasets\ndemonstrate that our proposed method outperforms all existing approaches of\ncomparable size by 2-3% absolute exact match points, achieving new\nstate-of-the-art results. Our results also demonstrate the feasibility of\nlearning to retrieve to improve answer generation without explicit supervision\nof retrieval decisions.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 19:25:37 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Sachan", "Devendra Singh", ""], ["Reddy", "Siva", ""], ["Hamilton", "William", ""], ["Dyer", "Chris", ""], ["Yogatama", "Dani", ""]]}, {"id": "2106.05348", "submitter": "Pawe{\\l} Matyszok", "authors": "Marek Sikora (1), Pawe{\\l} Matyszok (1), {\\L}ukasz Wr\\'obel (1)((1)\n  Faculty of Automatic Control, Electronics and Computer Science, Silesian\n  University of Technology, Akademicka 16, 44-100 Gliwice, Poland)", "title": "SCARI: Separate and Conquer Algorithm for Action Rules and\n  Recommendations Induction", "comments": "47 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes an action rule induction algorithm based on a\nsequential covering approach. Two variants of the algorithm are presented. The\nalgorithm allows the action rule induction from a source and a target decision\nclass point of view. The application of rule quality measures enables the\ninduction of action rules that meet various quality criteria. The article also\npresents a method for recommendation induction. The recommendations indicate\nthe actions to be taken to move a given test example, representing the source\nclass, to the target one. The recommendation method is based on a set of\ninduced action rules. The experimental part of the article presents the results\nof the algorithm operation on sixteen data sets. As a result of the conducted\nresearch the Ac-Rules package was made available.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 19:27:30 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Sikora", "Marek", ""], ["Matyszok", "Pawe\u0142", ""], ["Wr\u00f3bel", "\u0141ukasz", ""]]}, {"id": "2106.05365", "submitter": "Weijia Shi", "authors": "Weijia Shi, Mandar Joshi, Luke Zettlemoyer", "title": "DESCGEN: A Distantly Supervised Dataset for Generating Abstractive\n  Entity Descriptions", "comments": null, "journal-ref": "ACL-IJCNLP 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Short textual descriptions of entities provide summaries of their key\nattributes and have been shown to be useful sources of background knowledge for\ntasks such as entity linking and question answering. However, generating entity\ndescriptions, especially for new and long-tail entities, can be challenging\nsince relevant information is often scattered across multiple sources with\nvaried content and style. We introduce DESCGEN: given mentions spread over\nmultiple documents, the goal is to generate an entity summary description.\nDESCGEN consists of 37K entity descriptions from Wikipedia and Fandom, each\npaired with nine evidence documents on average. The documents were collected\nusing a combination of entity linking and hyperlinks to the Wikipedia and\nFandom entity pages, which together provide high-quality distant supervision.\nThe resulting summaries are more abstractive than those found in existing\ndatasets and provide a better proxy for the challenge of describing new and\nemerging entities. We also propose a two-stage extract-then-generate baseline\nand show that there exists a large gap (19.9% in ROUGE-L) between\nstate-of-the-art models and human performance, suggesting that the data will\nsupport significant future work.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 20:10:48 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 21:53:58 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Shi", "Weijia", ""], ["Joshi", "Mandar", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "2106.05386", "submitter": "Zhibo Yang", "authors": "Jianyuan Deng, Zhibo Yang, Iwao Ojima, Dimitris Samaras, Fusheng Wang", "title": "Artificial Intelligence in Drug Discovery: Applications and Techniques", "comments": "Minor text revisions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Artificial intelligence (AI) has been transforming the practice of drug\ndiscovery in the past decade. Various AI techniques have been used in a wide\nrange of applications, such as virtual screening and drug design. In this\nsurvey, we first give an overview on drug discovery and discuss related\napplications, which can be reduced to two major tasks, i.e., molecular property\nprediction and molecule generation. We then discuss common data resources,\nmolecule representations and benchmark platforms. Furthermore, to summarize the\nprogress of AI in drug discovery, we present the relevant AI techniques\nincluding model architectures and learning paradigms in the papers surveyed. We\nexpect that this survey will serve as a guide for researchers who are\ninterested in working at the interface of artificial intelligence and drug\ndiscovery. We also provide a GitHub repository\n(https://github.com/dengjianyuan/Survey_AI_Drug_Discovery) with the collection\nof papers and codes, if applicable, as a learning resource, which is regularly\nupdated.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 20:46:44 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 00:57:41 GMT"}, {"version": "v3", "created": "Mon, 12 Jul 2021 23:15:44 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Deng", "Jianyuan", ""], ["Yang", "Zhibo", ""], ["Ojima", "Iwao", ""], ["Samaras", "Dimitris", ""], ["Wang", "Fusheng", ""]]}, {"id": "2106.05430", "submitter": "Xin Ma", "authors": "Xin Ma and Won Hwa Kim", "title": "Very Compact Clusters with Structural Regularization via Similarity and\n  Connectivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering algorithms have significantly improved along with Deep Neural\nNetworks which provide effective representation of data. Existing methods are\nbuilt upon deep autoencoder and self-training process that leverages the\ndistribution of cluster assignments of samples. However, as the fundamental\nobjective of the autoencoder is focused on efficient data reconstruction, the\nlearnt space may be sub-optimal for clustering. Moreover, it requires highly\neffective codes (i.e., representation) of data, otherwise the initial cluster\ncenters often cause stability issues during self-training. Many\nstate-of-the-art clustering algorithms use convolution operation to extract\nefficient codes but their applications are limited to image data. In this\nregard, we propose an end-to-end deep clustering algorithm, i.e., Very Compact\nClusters (VCC), for the general datasets, which takes advantage of\ndistributions of local relationships of samples near the boundary of clusters,\nso that they can be properly separated and pulled to cluster centers to form\ncompact clusters. Experimental results on various datasets illustrate that our\nproposed approach achieves better clustering performance over most of the\nstate-of-the-art clustering methods, and the data embeddings learned by VCC\nwithout convolution for image data are even comparable with specialized\nconvolutional methods.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 23:22:03 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 15:07:53 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Ma", "Xin", ""], ["Kim", "Won Hwa", ""]]}, {"id": "2106.05434", "submitter": "Chandra Thapa", "authors": "Chandra Thapa and Kallol Krishna Karmakar and Alberto Huertas Celdran\n  and Seyit Camtepe and Vijay Varadharajan and Surya Nepal", "title": "FedDICE: A ransomware spread detection in a distributed integrated\n  clinical environment using federated learning and SDN based mitigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  An integrated clinical environment (ICE) enables the connection and\ncoordination of the internet of medical things around the care of patients in\nhospitals. However, ransomware attacks and their spread on hospital\ninfrastructures, including ICE, are rising. Often the adversaries are targeting\nmultiple hospitals with the same ransomware attacks. These attacks are detected\nby using machine learning algorithms. But the challenge is devising the\nanti-ransomware learning mechanisms and services under the following\nconditions: (1) provide immunity to other hospitals if one of them got the\nattack, (2) hospitals are usually distributed over geographical locations, and\n(3) direct data sharing is avoided due to privacy concerns. In this regard,\nthis paper presents a federated distributed integrated clinical environment,\naka. FedDICE. FedDICE integrates federated learning (FL), which is\nprivacy-preserving learning, to SDN-oriented security architecture to enable\ncollaborative learning, detection, and mitigation of ransomware attacks. We\ndemonstrate the importance of FedDICE in a collaborative environment with up to\nfour hospitals and four popular ransomware families, namely WannaCry, Petya,\nBadRabbit, and PowerGhost. Our results find that in both IID and non-IID data\nsetups, FedDICE achieves the centralized baseline performance that needs direct\ndata sharing for detection. However, as a trade-off to data privacy, FedDICE\nobserves overhead in the anti-ransomware model training, e.g., 28x for the\nlogistic regression model. Besides, FedDICE utilizes SDN's dynamic network\nprogrammability feature to remove the infected devices in ICE.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 23:59:18 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Thapa", "Chandra", ""], ["Karmakar", "Kallol Krishna", ""], ["Celdran", "Alberto Huertas", ""], ["Camtepe", "Seyit", ""], ["Varadharajan", "Vijay", ""], ["Nepal", "Surya", ""]]}, {"id": "2106.05455", "submitter": "Liang Zeng", "authors": "Liang Zeng, Jin Xu, Zijun Yao, Yanqiao Zhu, Jian Li", "title": "Graph Symbiosis Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a framework for learning from multiple generated graph views,\nnamed graph symbiosis learning (GraphSym). In GraphSym, graph neural networks\n(GNN) developed in multiple generated graph views can adaptively exchange\nparameters with each other and fuse information stored in linkage structures\nand node features. Specifically, we propose a novel adaptive exchange method to\niteratively substitute redundant channels in the weight matrix of one GNN with\ninformative channels of another GNN in a layer-by-layer manner. GraphSym does\nnot rely on specific methods to generate multiple graph views and GNN\narchitectures. Thus, existing GNNs can be seamlessly integrated into our\nframework. On 3 semi-supervised node classification datasets, GraphSym\noutperforms previous single-graph and multiple-graph GNNs without knowledge\ndistillation, and achieves new state-of-the-art results. We also conduct a\nseries of experiments on 15 public benchmarks, 8 popular GNN models, and 3\ngraph tasks -- node classification, graph classification, and edge prediction\n-- and show that GraphSym consistently achieves better performance than\nexisting popular GNNs by 1.9\\%$\\sim$3.9\\% on average and their ensembles.\nExtensive ablation studies and experiments on the few-shot setting also\ndemonstrate the effectiveness of GraphSym.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 02:00:26 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Zeng", "Liang", ""], ["Xu", "Jin", ""], ["Yao", "Zijun", ""], ["Zhu", "Yanqiao", ""], ["Li", "Jian", ""]]}, {"id": "2106.05470", "submitter": "Wei Jin", "authors": "Wei Jin, Xiaorui Liu, Xiangyu Zhao, Yao Ma, Neil Shah, Jiliang Tang", "title": "Automated Self-Supervised Learning for Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph self-supervised learning has gained increasing attention due to its\ncapacity to learn expressive node representations. Many pretext tasks, or loss\nfunctions have been designed from distinct perspectives. However, we observe\nthat different pretext tasks affect downstream tasks differently cross\ndatasets, which suggests that searching pretext tasks is crucial for graph\nself-supervised learning. Different from existing works focusing on designing\nsingle pretext tasks, this work aims to investigate how to automatically\nleverage multiple pretext tasks effectively. Nevertheless, evaluating\nrepresentations derived from multiple pretext tasks without direct access to\nground truth labels makes this problem challenging. To address this obstacle,\nwe make use of a key principle of many real-world graphs, i.e., homophily, or\nthe principle that ``like attracts like,'' as the guidance to effectively\nsearch various self-supervised pretext tasks. We provide theoretical\nunderstanding and empirical evidence to justify the flexibility of homophily in\nthis search task. Then we propose the AutoSSL framework which can automatically\nsearch over combinations of various self-supervised tasks. By evaluating the\nframework on 7 real-world datasets, our experimental results show that AutoSSL\ncan significantly boost the performance on downstream tasks including node\nclustering and node classification compared with training under individual\ntasks. Code will be released at https://github.com/ChandlerBang/AutoSSL.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 03:09:20 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 12:59:03 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Jin", "Wei", ""], ["Liu", "Xiaorui", ""], ["Zhao", "Xiangyu", ""], ["Ma", "Yao", ""], ["Shah", "Neil", ""], ["Tang", "Jiliang", ""]]}, {"id": "2106.05506", "submitter": "Jeff Druce", "authors": "Jeff Druce, James Niehaus, Vanessa Moody, David Jensen, Michael L.\n  Littman", "title": "Brittle AI, Causal Confusion, and Bad Mental Models: Challenges and\n  Successes in the XAI Program", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The advances in artificial intelligence enabled by deep learning\narchitectures are undeniable. In several cases, deep neural network driven\nmodels have surpassed human level performance in benchmark autonomy tasks. The\nunderlying policies for these agents, however, are not easily interpretable. In\nfact, given their underlying deep models, it is impossible to directly\nunderstand the mapping from observations to actions for any reasonably complex\nagent. Producing this supporting technology to \"open the black box\" of these AI\nsystems, while not sacrificing performance, was the fundamental goal of the\nDARPA XAI program. In our journey through this program, we have several \"big\npicture\" takeaways: 1) Explanations need to be highly tailored to their\nscenario; 2) many seemingly high performing RL agents are extremely brittle and\nare not amendable to explanation; 3) causal models allow for rich explanations,\nbut how to present them isn't always straightforward; and 4) human subjects\nconjure fantastically wrong mental models for AIs, and these models are often\nhard to break. This paper discusses the origins of these takeaways, provides\namplifying information, and suggestions for future work.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 05:21:10 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Druce", "Jeff", ""], ["Niehaus", "James", ""], ["Moody", "Vanessa", ""], ["Jensen", "David", ""], ["Littman", "Michael L.", ""]]}, {"id": "2106.05508", "submitter": "Jiankai Sun", "authors": "Jiankai Sun and Xin Yang and Yuanshun Yao and Aonan Zhang and Weihao\n  Gao and Junyuan Xie and Chong Wang", "title": "Vertical Federated Learning without Revealing Intersection Membership", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vertical Federated Learning (vFL) allows multiple parties that own different\nattributes (e.g. features and labels) of the same data entity (e.g. a person)\nto jointly train a model. To prepare the training data, vFL needs to identify\nthe common data entities shared by all parties. It is usually achieved by\nPrivate Set Intersection (PSI) which identifies the intersection of training\nsamples from all parties by using personal identifiable information (e.g.\nemail) as sample IDs to align data instances. As a result, PSI would make\nsample IDs of the intersection visible to all parties, and therefore each party\ncan know that the data entities shown in the intersection also appear in the\nother parties, i.e. intersection membership. However, in many real-world\nprivacy-sensitive organizations, e.g. banks and hospitals, revealing membership\nof their data entities is prohibited. In this paper, we propose a vFL framework\nbased on Private Set Union (PSU) that allows each party to keep sensitive\nmembership information to itself. Instead of identifying the intersection of\nall training samples, our PSU protocol generates the union of samples as\ntraining instances. In addition, we propose strategies to generate synthetic\nfeatures and labels to handle samples that belong to the union but not the\nintersection. Through extensive experiments on two real-world datasets, we show\nour framework can protect the privacy of the intersection membership while\nmaintaining the model utility.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 05:26:50 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Sun", "Jiankai", ""], ["Yang", "Xin", ""], ["Yao", "Yuanshun", ""], ["Zhang", "Aonan", ""], ["Gao", "Weihao", ""], ["Xie", "Junyuan", ""], ["Wang", "Chong", ""]]}, {"id": "2106.05521", "submitter": "Michael Thrun PhD", "authors": "Michael C. Thrun and Alfred Ultsch", "title": "Swarm Intelligence for Self-Organized Clustering", "comments": "54 pages, 21 figures", "journal-ref": "Artificial intelligence, Vol. 290, pp. 103237. 2021", "doi": "10.1016/j.artint.2020.103237", "report-no": null, "categories": "cs.NE cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms implementing populations of agents which interact with one another\nand sense their environment may exhibit emergent behavior such as\nself-organization and swarm intelligence. Here a swarm system, called\nDatabionic swarm (DBS), is introduced which is able to adapt itself to\nstructures of high-dimensional data characterized by distance and/or\ndensity-based structures in the data space. By exploiting the interrelations of\nswarm intelligence, self-organization and emergence, DBS serves as an\nalternative approach to the optimization of a global objective function in the\ntask of clustering. The swarm omits the usage of a global objective function\nand is parameter-free because it searches for the Nash equilibrium during its\nannealing process. To our knowledge, DBS is the first swarm combining these\napproaches. Its clustering can outperform common clustering methods such as\nK-means, PAM, single linkage, spectral clustering, model-based clustering, and\nWard, if no prior knowledge about the data is available. A central problem in\nclustering is the correct estimation of the number of clusters. This is\naddressed by a DBS visualization called topographic map which allows assessing\nthe number of clusters. It is known that all clustering algorithms construct\nclusters, irrespective of the data set contains clusters or not. In contrast to\nmost other clustering algorithms, the topographic map identifies, that\nclustering of the data is meaningless if the data contains no (natural)\nclusters. The performance of DBS is demonstrated on a set of benchmark data,\nwhich are constructed to pose difficult clustering problems and in two\nreal-world applications.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 06:21:48 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Thrun", "Michael C.", ""], ["Ultsch", "Alfred", ""]]}, {"id": "2106.05527", "submitter": "Dongjun Kim", "authors": "Dongjun Kim, Seungjae Shin, Kyungwoo Song, Wanmo Kang, Il-Chul Moon", "title": "Score Matching Model for Unbounded Data Score", "comments": "24 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advance in score-based models incorporates the stochastic differential\nequation (SDE), which brings the state-of-the art performance on image\ngeneration tasks. This paper improves such score-based models by analyzing the\nmodel at the zero perturbation noise. In real datasets, the score function\ndiverges as the perturbation noise ($\\sigma$) decreases to zero, and this\nobservation leads an argument that the score estimation fails at $\\sigma=0$\nwith any neural network structure. Subsequently, we introduce Unbounded Noise\nConditional Score Network (UNCSN) that resolves the score diverging problem\nwith an easily applicable modification to any noise conditional score-based\nmodels. Additionally, we introduce a new type of SDE, so the exact log\nlikelihood can be calculated from the newly suggested SDE. On top of that, the\nassociated loss function mitigates the loss imbalance issue in a mini-batch,\nand we present a theoretic analysis on the proposed loss to uncover the behind\nmechanism of the data distribution modeling by the score-based models.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 06:30:16 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Kim", "Dongjun", ""], ["Shin", "Seungjae", ""], ["Song", "Kyungwoo", ""], ["Kang", "Wanmo", ""], ["Moon", "Il-Chul", ""]]}, {"id": "2106.05528", "submitter": "Rui Wang", "authors": "Rui Wang, Zuxuan Wu, Zejia Weng, Jingjing Chen, Guo-Jun Qi, Yu-Gang\n  Jiang", "title": "Cross-domain Contrastive Learning for Unsupervised Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unsupervised domain adaptation (UDA) aims to transfer knowledge learned from\na fully-labeled source domain to a different unlabeled target domain. Most\nexisting UDA methods learn domain-invariant feature representations by\nminimizing feature distances across domains. In this work, we build upon\ncontrastive self-supervised learning to align features so as to reduce the\ndomain discrepancy between training and testing sets. Exploring the same set of\ncategories shared by both domains, we introduce a simple yet effective\nframework CDCL, for domain alignment. In particular, given an anchor image from\none domain, we minimize its distances to cross-domain samples from the same\nclass relative to those from different categories. Since target labels are\nunavailable, we use a clustering-based approach with carefully initialized\ncenters to produce pseudo labels. In addition, we demonstrate that CDCL is a\ngeneral framework and can be adapted to the data-free setting, where the source\ndata are unavailable during training, with minimal modification. We conduct\nexperiments on two widely used domain adaptation benchmarks, i.e., Office-31\nand VisDA-2017, and demonstrate that CDCL achieves state-of-the-art performance\non both datasets.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 06:32:30 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Wang", "Rui", ""], ["Wu", "Zuxuan", ""], ["Weng", "Zejia", ""], ["Chen", "Jingjing", ""], ["Qi", "Guo-Jun", ""], ["Jiang", "Yu-Gang", ""]]}, {"id": "2106.05532", "submitter": "Anjana Arunkumar", "authors": "Swaroop Mishra, Anjana Arunkumar", "title": "How Robust are Model Rankings: A Leaderboard Customization Approach for\n  Equitable Evaluation", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models that top leaderboards often perform unsatisfactorily when deployed in\nreal world applications; this has necessitated rigorous and expensive\npre-deployment model testing. A hitherto unexplored facet of model performance\nis: Are our leaderboards doing equitable evaluation? In this paper, we\nintroduce a task-agnostic method to probe leaderboards by weighting samples\nbased on their `difficulty' level. We find that leaderboards can be\nadversarially attacked and top performing models may not always be the best\nmodels. We subsequently propose alternate evaluation metrics. Our experiments\non 10 models show changes in model ranking and an overall reduction in\npreviously reported performance -- thus rectifying the overestimation of AI\nsystems' capabilities. Inspired by behavioral testing principles, we further\ndevelop a prototype of a visual analytics tool that enables leaderboard\nrevamping through customization, based on an end user's focus area. This helps\nusers analyze models' strengths and weaknesses, and guides them in the\nselection of a model best suited for their application scenario. In a user\nstudy, members of various commercial product development teams, covering 5\nfocus areas, find that our prototype reduces pre-deployment development and\ntesting effort by 41% on average.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 06:47:35 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Mishra", "Swaroop", ""], ["Arunkumar", "Anjana", ""]]}, {"id": "2106.05542", "submitter": "Eun-Soo Jung Ph.D.", "authors": "Eun-Soo Jung, HyeongGwan Son, Kyusam Oh, Yongkeun Yun, Soonhwan Kwon,\n  Min Soo Kim", "title": "DUET: Detection Utilizing Enhancement for Text in Scanned or Captured\n  Documents", "comments": null, "journal-ref": "2020 25th International Conference on Pattern Recognition (ICPR)", "doi": "10.1109/ICPR48806.2021.9412928", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel deep neural model for text detection in document images.\nFor robust text detection in noisy scanned documents, the advantages of\nmulti-task learning are adopted by adding an auxiliary task of text\nenhancement. Namely, our proposed model is designed to perform noise reduction\nand text region enhancement as well as text detection. Moreover, we enrich the\ntraining data for the model with synthesized document images that are fully\nlabeled for text detection and enhancement, thus overcome the insufficiency of\nlabeled document image data. For the effective exploitation of the synthetic\nand real data, the training process is separated in two phases. The first phase\nis training only synthetic data in a fully-supervised manner. Then real data\nwith only detection labels are added in the second phase. The enhancement task\nfor the real data is weakly-supervised with information from their detection\nlabels. Our methods are demonstrated in a real document dataset with\nperformances exceeding those of other text detection methods. Moreover,\nablations are conducted and the results confirm the effectiveness of the\nsynthetic data, auxiliary task, and weak-supervision. Whereas the existing text\ndetection studies mostly focus on the text in scenes, our proposed method is\noptimized to the applications for the text in scanned documents.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 07:08:31 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Jung", "Eun-Soo", ""], ["Son", "HyeongGwan", ""], ["Oh", "Kyusam", ""], ["Yun", "Yongkeun", ""], ["Kwon", "Soonhwan", ""], ["Kim", "Min Soo", ""]]}, {"id": "2106.05608", "submitter": "Joey Hong", "authors": "Joey Hong, Branislav Kveton, Manzil Zaheer, Mohammad Ghavamzadeh,\n  Craig Boutilier", "title": "Thompson Sampling with a Mixture Prior", "comments": "22 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study Thompson sampling (TS) in online decision-making problems where the\nuncertain environment is sampled from a mixture distribution. This is relevant\nto multi-task settings, where a learning agent is faced with different classes\nof problems. We incorporate this structure in a natural way by initializing TS\nwith a mixture prior -- dubbed MixTS -- and develop a novel, general technique\nfor analyzing the regret of TS with such priors. We apply this technique to\nderive Bayes regret bounds for MixTS in both linear bandits and tabular Markov\ndecision processes (MDPs). Our regret bounds reflect the structure of the\nproblem and depend on the number of components and confidence width of each\ncomponent of the prior. Finally, we demonstrate the empirical effectiveness of\nMixTS in both synthetic and real-world experiments.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 09:21:07 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Hong", "Joey", ""], ["Kveton", "Branislav", ""], ["Zaheer", "Manzil", ""], ["Ghavamzadeh", "Mohammad", ""], ["Boutilier", "Craig", ""]]}, {"id": "2106.05610", "submitter": "Laxman Dhulipala", "authors": "Laxman Dhulipala, David Eisenstat, Jakub {\\L}\\k{a}cki, Vahab Mirrokni,\n  Jessica Shi", "title": "Hierarchical Agglomerative Graph Clustering in Nearly-Linear Time", "comments": "This is the full version of the paper appearing in ICML'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the widely used hierarchical agglomerative clustering (HAC)\nalgorithm on edge-weighted graphs. We define an algorithmic framework for\nhierarchical agglomerative graph clustering that provides the first efficient\n$\\tilde{O}(m)$ time exact algorithms for classic linkage measures, such as\ncomplete- and WPGMA-linkage, as well as other measures. Furthermore, for\naverage-linkage, arguably the most popular variant of HAC, we provide an\nalgorithm that runs in $\\tilde{O}(n\\sqrt{m})$ time. For this variant, this is\nthe first exact algorithm that runs in subquadratic time, as long as\n$m=n^{2-\\epsilon}$ for some constant $\\epsilon > 0$. We complement this result\nwith a simple $\\epsilon$-close approximation algorithm for average-linkage in\nour framework that runs in $\\tilde{O}(m)$ time. As an application of our\nalgorithms, we consider clustering points in a metric space by first using\n$k$-NN to generate a graph from the point set, and then running our algorithms\non the resulting weighted graph. We validate the performance of our algorithms\non publicly available datasets, and show that our approach can speed up\nclustering of point datasets by a factor of 20.7--76.5x.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 09:29:05 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Dhulipala", "Laxman", ""], ["Eisenstat", "David", ""], ["\u0141\u0105cki", "Jakub", ""], ["Mirrokni", "Vahab", ""], ["Shi", "Jessica", ""]]}, {"id": "2106.05648", "submitter": "Luca Grillotti", "authors": "Luca Grillotti and Antoine Cully", "title": "Unsupervised Behaviour Discovery with Quality-Diversity Optimisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quality-Diversity algorithms refer to a class of evolutionary algorithms\ndesigned to find a collection of diverse and high-performing solutions to a\ngiven problem. In robotics, such algorithms can be used for generating a\ncollection of controllers covering most of the possible behaviours of a robot.\nTo do so, these algorithms associate a behavioural descriptor to each of these\nbehaviours. Each behavioural descriptor is used for estimating the novelty of\none behaviour compared to the others. In most existing algorithms, the\nbehavioural descriptor needs to be hand-coded, thus requiring prior knowledge\nabout the task to solve. In this paper, we introduce: Autonomous Robots\nRealising their Abilities, an algorithm that uses a dimensionality reduction\ntechnique to automatically learn behavioural descriptors based on raw sensory\ndata. The performance of this algorithm is assessed on three robotic tasks in\nsimulation. The experimental results show that it performs similarly to\ntraditional hand-coded approaches without the requirement to provide any\nhand-coded behavioural descriptor. In the collection of diverse and\nhigh-performing solutions, it also manages to find behaviours that are novel\nwith respect to more features than its hand-coded baselines. Finally, we\nintroduce a variant of the algorithm which is robust to the dimensionality of\nthe behavioural descriptor space.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 10:40:18 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Grillotti", "Luca", ""], ["Cully", "Antoine", ""]]}, {"id": "2106.05654", "submitter": "Felix Binder", "authors": "Felix J Binder, Marcelo M Mattar, David Kirsh, Judith E Fan", "title": "Visual scoping operations for physical assembly", "comments": null, "journal-ref": "Proceedings for the 43nd Annual Meeting of the Cognitive Science\n  Society 2021", "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Planning is hard. The use of subgoals can make planning more tractable, but\nselecting these subgoals is computationally costly. What algorithms might\nenable us to reap the benefits of planning using subgoals while minimizing the\ncomputational overhead of selecting them? We propose visual scoping, a strategy\nthat interleaves planning and acting by alternately defining a spatial region\nas the next subgoal and selecting actions to achieve it. We evaluated our\nvisual scoping algorithm on a variety of physical assembly problems against two\nbaselines: planning all subgoals in advance and planning without subgoals. We\nfound that visual scoping achieves comparable task performance to the subgoal\nplanner while requiring only a fraction of the total computational cost.\nTogether, these results contribute to our understanding of how humans might\nmake efficient use of cognitive resources to solve complex planning problems.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 10:50:35 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Binder", "Felix J", ""], ["Mattar", "Marcelo M", ""], ["Kirsh", "David", ""], ["Fan", "Judith E", ""]]}, {"id": "2106.05657", "submitter": "Shashank Kotyan", "authors": "Shashank Kotyan and Danilo Vasconcellos Vargas", "title": "Deep neural network loses attention to adversarial images", "comments": "Accepted in Workshop on Artificial Intelligence Safety (AISafety\n  2021), IJCAI-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adversarial algorithms have shown to be effective against neural networks for\na variety of tasks. Some adversarial algorithms perturb all the pixels in the\nimage minimally for the image classification task in image classification. In\ncontrast, some algorithms perturb few pixels strongly. However, very little\ninformation is available regarding why these adversarial samples so diverse\nfrom each other exist. Recently, Vargas et al. showed that the existence of\nthese adversarial samples might be due to conflicting saliency within the\nneural network. We test this hypothesis of conflicting saliency by analysing\nthe Saliency Maps (SM) and Gradient-weighted Class Activation Maps (Grad-CAM)\nof original and few different types of adversarial samples. We also analyse how\ndifferent adversarial samples distort the attention of the neural network\ncompared to original samples. We show that in the case of Pixel Attack,\nperturbed pixels either calls the network attention to themselves or divert the\nattention from them. Simultaneously, the Projected Gradient Descent Attack\nperturbs pixels so that intermediate layers inside the neural network lose\nattention for the correct class. We also show that both attacks affect the\nsaliency map and activation maps differently. Thus, shedding light on why some\ndefences successful against some attacks remain vulnerable against other\nattacks. We hope that this analysis will improve understanding of the existence\nand the effect of adversarial samples and enable the community to develop more\nrobust neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 11:06:17 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Kotyan", "Shashank", ""], ["Vargas", "Danilo Vasconcellos", ""]]}, {"id": "2106.05658", "submitter": "Tianlin Xu", "authors": "Tianlin Xu and Beatrice Acciaio", "title": "Quantized Conditional COT-GAN for Video Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Causal Optimal Transport (COT) results from imposing a temporal causality\nconstraint on classic optimal transport problems, which naturally generates a\nnew concept of distances between distributions on path spaces. The first\napplication of the COT theory for sequential learning was given in Xu et al.\n(2020), where COT-GAN was introduced as an adversarial algorithm to train\nimplicit generative models optimized for producing sequential data. Relying on\nXu et al. (2020), the contribution of the present paper is twofold. First, we\ndevelop a conditional version of COT-GAN suitable for sequence prediction. This\nmeans that the dataset is now used in order to learn how a sequence will evolve\ngiven the observation of its past evolution. Second, we improve on the\nconvergence results by working with modifications of the empirical measures via\na specific type of quantization due to Backhoff et al. (2020). The resulting\nquantized conditional COT-GAN algorithm is illustrated with an application for\nvideo prediction.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 11:10:53 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Xu", "Tianlin", ""], ["Acciaio", "Beatrice", ""]]}, {"id": "2106.05659", "submitter": "Athanasios Vlontzos", "authors": "Athanasios Vlontzos, Gabriel Sutherland, Siddha Ganju, Frank\n  Soboczenski", "title": "Next-Gen Machine Learning Supported Diagnostic Systems for Spacecraft", "comments": "Accepted in the AI for Spacecraft Longevity Workshop at IJCAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Future short or long-term space missions require a new generation of\nmonitoring and diagnostic systems due to communication impasses as well as\nlimitations in specialized crew and equipment. Machine learning supported\ndiagnostic systems present a viable solution for medical and technical\napplications. We discuss challenges and applicability of such systems in light\nof upcoming missions and outline an example use case for a next-generation\nmedical diagnostic system for future space operations. Additionally, we present\napproach recommendations and constraints for the successful generation and use\nof machine learning models aboard a spacecraft.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 11:12:41 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Vlontzos", "Athanasios", ""], ["Sutherland", "Gabriel", ""], ["Ganju", "Siddha", ""], ["Soboczenski", "Frank", ""]]}, {"id": "2106.05664", "submitter": "Rishav Hada", "authors": "Rishav Hada, Sohi Sudhir, Pushkar Mishra, Helen Yannakoudakis, Saif M.\n  Mohammad, Ekaterina Shutova", "title": "Ruddit: Norms of Offensiveness for English Reddit Comments", "comments": "Camera-ready version in ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On social media platforms, hateful and offensive language negatively impact\nthe mental well-being of users and the participation of people from diverse\nbackgrounds. Automatic methods to detect offensive language have largely relied\non datasets with categorical labels. However, comments can vary in their degree\nof offensiveness. We create the first dataset of English language Reddit\ncomments that has fine-grained, real-valued scores between -1 (maximally\nsupportive) and 1 (maximally offensive). The dataset was annotated using\nBest--Worst Scaling, a form of comparative annotation that has been shown to\nalleviate known biases of using rating scales. We show that the method produces\nhighly reliable offensiveness scores. Finally, we evaluate the ability of\nwidely-used neural models to predict offensiveness scores on this new dataset.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 11:27:47 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 07:41:58 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Hada", "Rishav", ""], ["Sudhir", "Sohi", ""], ["Mishra", "Pushkar", ""], ["Yannakoudakis", "Helen", ""], ["Mohammad", "Saif M.", ""], ["Shutova", "Ekaterina", ""]]}, {"id": "2106.05682", "submitter": "Youngtaek Oh", "authors": "Youngtaek Oh, Dong-Jin Kim, In So Kweon", "title": "Distribution-Aware Semantics-Oriented Pseudo-label for Imbalanced\n  Semi-Supervised Learning", "comments": "\"Code: https://github.com/ytaek-oh/daso\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The capability of the traditional semi-supervised learning (SSL) methods is\nfar from real-world application since they do not consider (1) class imbalance\nand (2) class distribution mismatch between labeled and unlabeled data. This\npaper addresses such a relatively under-explored problem, imbalanced\nsemi-supervised learning, where heavily biased pseudo-labels can harm the model\nperformance. Interestingly, we find that the semantic pseudo-labels from a\nsimilarity-based classifier in feature space and the traditional pseudo-labels\nfrom the linear classifier show the complementary property. To this end, we\npropose a general pseudo-labeling framework to address the bias motivated by\nthis observation. The key idea is to class-adaptively blend the semantic\npseudo-label to the linear one, depending on the current pseudo-label\ndistribution. Thereby, the increased semantic pseudo-label component suppresses\nthe false positives in the majority classes and vice versa. We term the novel\npseudo-labeling framework for imbalanced SSL as Distribution-Aware\nSemantics-Oriented (DASO) Pseudo-label. Extensive evaluation on CIFAR10/100-LT\nand STL10-LT shows that DASO consistently outperforms both recently proposed\nre-balancing methods for label and pseudo-label. Moreover, we demonstrate that\ntypical SSL algorithms can effectively benefit from unlabeled data with DASO,\nespecially when (1) class imbalance and (2) class distribution mismatch exist\nand even on recent real-world Semi-Aves benchmark.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 11:58:25 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Oh", "Youngtaek", ""], ["Kim", "Dong-Jin", ""], ["Kweon", "In So", ""]]}, {"id": "2106.05686", "submitter": "Mattias Nilsson", "authors": "Mattias Nilsson, Foteini Liwicki, and Fredrik Sandin", "title": "Spatiotemporal Spike-Pattern Selectivity in Single Mixed-Signal Neurons\n  with Balanced Synapses", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Realizing the potential of mixed-signal neuromorphic processors for\nultra-low-power inference and learning requires efficient use of their\ninhomogeneous analog circuitry as well as sparse, time-based information\nencoding and processing. Here, we investigate spike-timing-based spatiotemporal\nreceptive fields of output-neurons in the Spatiotemporal Correlator (STC)\nnetwork, for which we used excitatory-inhibitory balanced disynaptic inputs\ninstead of dedicated axonal or neuronal delays. We present hardware-in-the-loop\nexperiments with a mixed-signal DYNAP-SE neuromorphic processor, in which\nfive-dimensional receptive fields of hardware neurons were mapped by randomly\nsampling input spike-patterns from a uniform distribution. We find that, when\nthe balanced disynaptic elements are randomly programmed, some of the neurons\ndisplay distinct receptive fields. Furthermore, we demonstrate how a neuron was\ntuned to detect a particular spatiotemporal feature, to which it initially was\nnon-selective, by activating a different subset of the inhomogeneous analog\nsynaptic circuits. The energy dissipation of the balanced synaptic elements is\none order of magnitude lower per lateral connection (0.65 nJ vs 9.3 nJ per\nspike) than former delay-based neuromorphic hardware implementations. Thus, we\nshow how the inhomogeneous synaptic circuits could be utilized for\nresource-efficient implementation of STC network layers, in a way that enables\nsynapse-address reprogramming as a discrete mechanism for feature tuning.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 12:04:03 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Nilsson", "Mattias", ""], ["Liwicki", "Foteini", ""], ["Sandin", "Fredrik", ""]]}, {"id": "2106.05688", "submitter": "Sallam Abualhaija", "authors": "Orlando Amaral, Sallam Abualhaija, Damiano Torre, Mehrdad Sabetzadeh,\n  Lionel C. Briand", "title": "AI-enabled Automation for Completeness Checking of Privacy Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technological advances in information sharing have raised concerns about data\nprotection. Privacy policies contain privacy-related requirements about how the\npersonal data of individuals will be handled by an organization or a software\nsystem (e.g., a web service or an app). In Europe, privacy policies are subject\nto compliance with the General Data Protection Regulation (GDPR). A\nprerequisite for GDPR compliance checking is to verify whether the content of a\nprivacy policy is complete according to the provisions of GDPR. Incomplete\nprivacy policies might result in large fines on violating organization as well\nas incomplete privacy-related software specifications. Manual completeness\nchecking is both time-consuming and error-prone. In this paper, we propose\nAI-based automation for the completeness checking of privacy policies. Through\nsystematic qualitative methods, we first build two artifacts to characterize\nthe privacy-related provisions of GDPR, namely a conceptual model and a set of\ncompleteness criteria. Then, we develop an automated solution on top of these\nartifacts by leveraging a combination of natural language processing and\nsupervised machine learning. Specifically, we identify the GDPR-relevant\ninformation content in privacy policies and subsequently check them against the\ncompleteness criteria. To evaluate our approach, we collected 234 real privacy\npolicies from the fund industry. Over a set of 48 unseen privacy policies, our\napproach detected 300 of the total of 334 violations of some completeness\ncriteria correctly, while producing 23 false positives. The approach thus has a\nprecision of 92.9% and recall of 89.8%. Compared to a baseline that applies\nkeyword search only, our approach results in an improvement of 24.5% in\nprecision and 38% in recall.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 12:10:51 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Amaral", "Orlando", ""], ["Abualhaija", "Sallam", ""], ["Torre", "Damiano", ""], ["Sabetzadeh", "Mehrdad", ""], ["Briand", "Lionel C.", ""]]}, {"id": "2106.05701", "submitter": "Jiying Zhang", "authors": "Jiying Zhang, Yuzhao Chen, Xi Xiao, Runiu Lu, Shu-Tao Xia", "title": "Learnable Hypergraph Laplacian for Hypergraph Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  HyperGraph Convolutional Neural Networks (HGCNNs) have demonstrated their\npotential in modeling high-order relations preserved in graph structured data.\nHowever, most existing convolution filters are localized and determined by the\npre-defined initial hypergraph topology, neglecting to explore implicit and\nlong-ange relations in real-world data. In this paper, we propose the first\nlearning-based method tailored for constructing adaptive hypergraph structure,\ntermed HypERgrAph Laplacian aDaptor (HERALD), which serves as a generic\nplug-in-play module for improving the representational power of HGCNNs.\nSpecifically, HERALD adaptively optimizes the adjacency relationship between\nhypernodes and hyperedges in an end-to-end manner and thus the task-aware\nhypergraph is learned. Furthermore, HERALD employs the self-attention mechanism\nto capture the non-local paired-nodes relation. Extensive experiments on\nvarious popular hypergraph datasets for node classification and graph\nclassification tasks demonstrate that our approach obtains consistent and\nconsiderable performance enhancement, proving its effectiveness and\ngeneralization ability.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 12:37:55 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Zhang", "Jiying", ""], ["Chen", "Yuzhao", ""], ["Xiao", "Xi", ""], ["Lu", "Runiu", ""], ["Xia", "Shu-Tao", ""]]}, {"id": "2106.05727", "submitter": "Niko Grupen", "authors": "Niko A. Grupen, Bart Selman, Daniel D. Lee", "title": "Fairness for Cooperative Multi-Agent Learning with Equivariant Policies", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study fairness through the lens of cooperative multi-agent learning. Our\nwork is motivated by empirical evidence that naive maximization of team reward\nyields unfair outcomes for individual team members. To address fairness in\nmulti-agent contexts, we introduce team fairness, a group-based fairness\nmeasure for multi-agent learning. We then incorporate team fairness into policy\noptimization -- introducing Fairness through Equivariance (Fair-E), a novel\nlearning strategy that achieves provably fair reward distributions. We then\nintroduce Fairness through Equivariance Regularization (Fair-ER) as a\nsoft-constraint version of Fair-E and show that Fair-ER reaches higher levels\nof utility than Fair-E and fairer outcomes than policies with no equivariance.\nFinally, we investigate the fairness-utility trade-off in multi-agent settings.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 13:17:46 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Grupen", "Niko A.", ""], ["Selman", "Bart", ""], ["Lee", "Daniel D.", ""]]}, {"id": "2106.05752", "submitter": "Sourav Das", "authors": "Sourav Das and Anup Kumar Kolya", "title": "Parallel Deep Learning-Driven Sarcasm Detection from Pop Culture Text\n  and English Humor Literature", "comments": "10 pages, 2 figures, 4 tables", "journal-ref": "In RAAI 2020. Advances in Intelligent Systems and Computing, vol\n  1355 (2021)", "doi": "10.1007/978-981-16-1543-6_6", "report-no": null, "categories": "cs.CL cs.AI cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Sarcasm is a sophisticated way of wrapping any immanent truth, mes-sage, or\neven mockery within a hilarious manner. The advent of communications using\nsocial networks has mass-produced new avenues of socialization. It can be\nfurther said that humor, irony, sarcasm, and wit are the four chariots of being\nsocially funny in the modern days. In this paper, we manually extract the\nsarcastic word distribution features of a benchmark pop culture sarcasm corpus,\ncontaining sarcastic dialogues and monologues. We generate input sequences\nformed of the weighted vectors from such words. We further propose an\namalgamation of four parallel deep long-short term networks (pLSTM), each with\ndistinctive activation classifier. These modules are primarily aimed at\nsuccessfully detecting sarcasm from the text corpus. Our proposed model for\ndetecting sarcasm peaks a training accuracy of 98.95% when trained with the\ndiscussed dataset. Consecutively, it obtains the highest of 98.31% overall\nvalidation accuracy on two handpicked Project Gutenberg English humor\nliterature among all the test cases. Our approach transcends previous\nstate-of-the-art works on several sarcasm corpora and results in a new gold\nstandard performance for sarcasm detection.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 14:01:07 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Das", "Sourav", ""], ["Kolya", "Anup Kumar", ""]]}, {"id": "2106.05764", "submitter": "Norman Meuschke", "authors": "Norman Meuschke", "title": "Analyzing Non-Textual Content Elements to Detect Academic Plagiarism", "comments": "Ph.D. Thesis, University of Konstanz", "journal-ref": null, "doi": "10.5281/zenodo.4913345", "report-no": null, "categories": "cs.IR cs.AI cs.DL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Identifying academic plagiarism is a pressing problem, among others, for\nresearch institutions, publishers, and funding organizations. Detection\napproaches proposed so far analyze lexical, syntactical, and semantic text\nsimilarity. These approaches find copied, moderately reworded, and literally\ntranslated text. However, reliably detecting disguised plagiarism, such as\nstrong paraphrases, sense-for-sense translations, and the reuse of non-textual\ncontent and ideas, is an open research problem.\n  The thesis addresses this problem by proposing plagiarism detection\napproaches that implement a different concept: analyzing non-textual content in\nacademic documents, specifically citations, images, and mathematical content.\n  To validate the effectiveness of the proposed detection approaches, the\nthesis presents five evaluations that use real cases of academic plagiarism and\nexploratory searches for unknown cases.\n  The evaluation results show that non-textual content elements contain a high\ndegree of semantic information, are language-independent, and largely immutable\nto the alterations that authors typically perform to conceal plagiarism.\nAnalyzing non-textual content complements text-based detection approaches and\nincreases the detection effectiveness, particularly for disguised forms of\nacademic plagiarism.\n  To demonstrate the benefit of combining non-textual and text-based detection\nmethods, the thesis describes the first plagiarism detection system that\nintegrates the analysis of citation-based, image-based, math-based, and\ntext-based document similarity. The system's user interface employs\nvisualizations that significantly reduce the effort and time users must invest\nin examining content similarity.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 14:11:52 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Meuschke", "Norman", ""]]}, {"id": "2106.05784", "submitter": "Tal Schuster", "authors": "Tal Schuster, Ashwin Kalyan, Oleksandr Polozov, Adam Tauman Kalai", "title": "Programming Puzzles", "comments": "The puzzles repo:\n  https://github.com/microsoft/PythonProgrammingPuzzles", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new type of programming challenge called programming puzzles,\nas an objective and comprehensive evaluation of program synthesis, and release\nan open-source dataset of Python Programming Puzzles (P3). Each puzzle is\ndefined by a short Python program $f$, and the goal is to find an input $x$\nwhich makes $f$ output \"True\". The puzzles are objective in that each one is\nspecified entirely by the source code of its verifier $f$, so evaluating $f(x)$\nis all that is needed to test a candidate solution $x$. They do not require an\nanswer key or input/output examples, nor do they depend on natural language\nunderstanding. The dataset is comprehensive in that it spans problems of a\nrange of difficulties and domains, ranging from trivial string manipulation\nproblems that are immediately obvious to human programmers (but not necessarily\nto AI), to classic programming puzzles (e.g., Towers of Hanoi), to\ninterview/competitive-programming problems (e.g., dynamic programming), to\nlongstanding open problems in algorithms and mathematics (e.g., factoring). The\nobjective nature of P3 readily supports self-supervised bootstrapping. We\ndevelop baseline enumerative program synthesis and GPT-3 solvers that are\ncapable of solving easy puzzles -- even without access to any reference\nsolutions -- by learning from their own past solutions. Based on a small user\nstudy, we find puzzle difficulty to correlate between human programmers and the\nbaseline AI solvers.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 14:37:28 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Schuster", "Tal", ""], ["Kalyan", "Ashwin", ""], ["Polozov", "Oleksandr", ""], ["Kalai", "Adam Tauman", ""]]}, {"id": "2106.05786", "submitter": "Hezheng Lin", "authors": "Hezheng Lin, Xing Cheng, Xiangyu Wu, Fan Yang, Dong Shen, Zhongyuan\n  Wang, Qing Song, Wei Yuan", "title": "CAT: Cross Attention in Vision Transformer", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since Transformer has found widespread use in NLP, the potential of\nTransformer in CV has been realized and has inspired many new approaches.\nHowever, the computation required for replacing word tokens with image patches\nfor Transformer after the tokenization of the image is vast(e.g., ViT), which\nbottlenecks model training and inference. In this paper, we propose a new\nattention mechanism in Transformer termed Cross Attention, which alternates\nattention inner the image patch instead of the whole image to capture local\ninformation and apply attention between image patches which are divided from\nsingle-channel feature maps capture global information. Both operations have\nless computation than standard self-attention in Transformer. By alternately\napplying attention inner patch and between patches, we implement cross\nattention to maintain the performance with lower computational cost and build a\nhierarchical network called Cross Attention Transformer(CAT) for other vision\ntasks. Our base model achieves state-of-the-arts on ImageNet-1K, and improves\nthe performance of other methods on COCO and ADE20K, illustrating that our\nnetwork has the potential to serve as general backbones. The code and models\nare available at \\url{https://github.com/linhezheng19/CAT}.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 14:38:32 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Lin", "Hezheng", ""], ["Cheng", "Xing", ""], ["Wu", "Xiangyu", ""], ["Yang", "Fan", ""], ["Shen", "Dong", ""], ["Wang", "Zhongyuan", ""], ["Song", "Qing", ""], ["Yuan", "Wei", ""]]}, {"id": "2106.05802", "submitter": "Zongqing Lu", "authors": "Yifan Yu, Haobin Jiang, Zongqing Lu", "title": "Informative Policy Representations in Multi-Agent Reinforcement Learning\n  via Joint-Action Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In multi-agent reinforcement learning, the inherent non-stationarity of the\nenvironment caused by other agents' actions posed significant difficulties for\nan agent to learn a good policy independently. One way to deal with\nnon-stationarity is agent modeling, by which the agent takes into consideration\nthe influence of other agents' policies. Most existing work relies on\npredicting other agents' actions or goals, or discriminating between their\npolicies. However, such modeling fails to capture the similarities and\ndifferences between policies simultaneously and thus cannot provide useful\ninformation when generalizing to unseen policies. To address this, we propose a\ngeneral method to learn representations of other agents' policies via the\njoint-action distributions sampled in interactions. The similarities and\ndifferences between policies are naturally captured by the policy distance\ninferred from the joint-action distributions and deliberately reflected in the\nlearned representations. Agents conditioned on the policy representations can\nwell generalize to unseen agents. We empirically demonstrate that our method\noutperforms existing work in multi-agent tasks when facing unseen agents.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 15:09:33 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Yu", "Yifan", ""], ["Jiang", "Haobin", ""], ["Lu", "Zongqing", ""]]}, {"id": "2106.05810", "submitter": "Xavier Renard", "authors": "Rafael Poyiadzi, Xavier Renard, Thibault Laugel, Raul\n  Santos-Rodriguez, Marcin Detyniecki", "title": "On the overlooked issue of defining explanation objectives for\n  local-surrogate explainers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local surrogate approaches for explaining machine learning model predictions\nhave appealing properties, such as being model-agnostic and flexible in their\nmodelling. Several methods exist that fit this description and share this goal.\nHowever, despite their shared overall procedure, they set out different\nobjectives, extract different information from the black-box, and consequently\nproduce diverse explanations, that are -- in general -- incomparable. In this\nwork we review the similarities and differences amongst multiple methods, with\na particular focus on what information they extract from the model, as this has\nlarge impact on the output: the explanation. We discuss the implications of the\nlack of agreement, and clarity, amongst the methods' objectives on the research\nand practice of explainability.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 15:24:49 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Poyiadzi", "Rafael", ""], ["Renard", "Xavier", ""], ["Laugel", "Thibault", ""], ["Santos-Rodriguez", "Raul", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "2106.05819", "submitter": "Susheel Suresh", "authors": "Susheel Suresh, Pan Li, Cong Hao, Jennifer Neville", "title": "Adversarial Graph Augmentation to Improve Graph Contrastive Learning", "comments": "link to code is added (https://github.com/susheels/adgcl)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-supervised learning of graph neural networks (GNN) is in great need\nbecause of the widespread label scarcity issue in real-world graph/network\ndata. Graph contrastive learning (GCL), by training GNNs to maximize the\ncorrespondence between the representations of the same graph in its different\naugmented forms, may yield robust and transferable GNNs even without using\nlabels. However, GNNs trained by traditional GCL often risk capturing redundant\ngraph features and thus may be brittle and provide sub-par performance in\ndownstream tasks. Here, we propose a novel principle, termed adversarial-GCL\n(AD-GCL), which enables GNNs to avoid capturing redundant information during\nthe training by optimizing adversarial graph augmentation strategies used in\nGCL. We pair AD-GCL with theoretical explanations and design a practical\ninstantiation based on trainable edge-dropping graph augmentation. We\nexperimentally validate AD-GCL by comparing with the state-of-the-art GCL\nmethods and achieve performance gains of up-to $14\\%$ in unsupervised, $6\\%$ in\ntransfer, and $3\\%$ in semi-supervised learning settings overall with 18\ndifferent benchmark datasets for the tasks of molecule property regression and\nclassification, and social network classification.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 15:34:26 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 18:23:07 GMT"}, {"version": "v3", "created": "Fri, 25 Jun 2021 07:10:56 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Suresh", "Susheel", ""], ["Li", "Pan", ""], ["Hao", "Cong", ""], ["Neville", "Jennifer", ""]]}, {"id": "2106.05842", "submitter": "Gowtham Reddy Abbavaram", "authors": "Abbavaram Gowtham Reddy", "title": "Causality in Neural Networks -- An Extended Abstract", "comments": null, "journal-ref": null, "doi": "10.1145/3461702.3462467", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Causal reasoning is the main learning and explanation tool used by humans. AI\nsystems should possess causal reasoning capabilities to be deployed in the real\nworld with trust and reliability. Introducing the ideas of causality to machine\nlearning helps in providing better learning and explainable models.\nExplainability, causal disentanglement are some important aspects of any\nmachine learning model. Causal explanations are required to believe in a\nmodel's decision and causal disentanglement learning is important for transfer\nlearning applications. We exploit the ideas of causality to be used in deep\nlearning models to achieve better and causally explainable models that are\nuseful in fairness, disentangled representation, etc.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 09:52:36 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Reddy", "Abbavaram Gowtham", ""]]}, {"id": "2106.05864", "submitter": "Cyrus Neary", "authors": "Cyrus Neary, Christos Verginis, Murat Cubuktepe, Ufuk Topcu", "title": "Verifiable and Compositional Reinforcement Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel framework for verifiable and compositional reinforcement\nlearning (RL) in which a collection of RL sub-systems, each of which learns to\naccomplish a separate sub-task, are composed to achieve an overall task. The\nframework consists of a high-level model, represented as a parametric Markov\ndecision process (pMDP) which is used to plan and to analyze compositions of\nsub-systems, and of the collection of low-level sub-systems themselves. By\ndefining interfaces between the sub-systems, the framework enables automatic\ndecompositons of task specifications, e.g., reach a target set of states with a\nprobability of at least 0.95, into individual sub-task specifications, i.e.\nachieve the sub-system's exit conditions with at least some minimum\nprobability, given that its entry conditions are met. This in turn allows for\nthe independent training and testing of the sub-systems; if they each learn a\npolicy satisfying the appropriate sub-task specification, then their\ncomposition is guaranteed to satisfy the overall task specification.\nConversely, if the sub-task specifications cannot all be satisfied by the\nlearned policies, we present a method, formulated as the problem of finding an\noptimal set of parameters in the pMDP, to automatically update the sub-task\nspecifications to account for the observed shortcomings. The result is an\niterative procedure for defining sub-task specifications, and for training the\nsub-systems to meet them. As an additional benefit, this procedure allows for\nparticularly challenging or important components of an overall task to be\ndetermined automatically, and focused on, during training. Experimental results\ndemonstrate the presented framework's novel capabilities.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 17:05:14 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Neary", "Cyrus", ""], ["Verginis", "Christos", ""], ["Cubuktepe", "Murat", ""], ["Topcu", "Ufuk", ""]]}, {"id": "2106.05870", "submitter": "Kanil Patel", "authors": "Kanil Patel, William Beluch, Kilian Rambach, Adriana-Eliza Cozma,\n  Michael Pfeiffer and Bin Yang", "title": "Investigation of Uncertainty of Deep Learning-based Object\n  Classification on Radar Spectra", "comments": "6 pages", "journal-ref": "IEEE Radar Conference 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) has recently attracted increasing interest to improve\nobject type classification for automotive radar.In addition to high accuracy,\nit is crucial for decision making in autonomous vehicles to evaluate the\nreliability of the predictions; however, decisions of DL networks are\nnon-transparent. Current DL research has investigated how uncertainties of\npredictions can be quantified, and in this article, we evaluate the potential\nof these methods for safe, automotive radar perception. In particular we\nevaluate how uncertainty quantification can support radar perception under (1)\ndomain shift, (2) corruptions of input signals, and (3) in the presence of\nunknown objects. We find that in agreement with phenomena observed in the\nliterature,deep radar classifiers are overly confident, even in their wrong\npredictions. This raises concerns about the use of the confidence values for\ndecision making under uncertainty, as the model fails to notify when it cannot\nhandle an unknown situation. Accurate confidence values would allow optimal\nintegration of multiple information sources, e.g. via sensor fusion. We show\nthat by applying state-of-the-art post-hoc uncertainty calibration, the quality\nof confidence measures can be significantly improved,thereby partially\nresolving the over-confidence problem. Our investigation shows that further\nresearch into training and calibrating DL networks is necessary and offers\ngreat potential for safe automotive object classification with radar sensors.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 09:50:19 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Patel", "Kanil", ""], ["Beluch", "William", ""], ["Rambach", "Kilian", ""], ["Cozma", "Adriana-Eliza", ""], ["Pfeiffer", "Michael", ""], ["Yang", "Bin", ""]]}, {"id": "2106.05876", "submitter": "Hugues Moreau", "authors": "Hugues Moreau and Andr\\'ea Vassilev and Liming Chen", "title": "Data Fusion for Deep Learning on Transport Mode Detection: A Case Study", "comments": "12 pages, 2 figures, 4 tables Code avaible at\n  https://github.com/HuguesMoreau/TMD_fusion_benchmark", "journal-ref": "Proceedings of the Engineering Applications of Neural Networks\n  Conference, 2021, pp. 141-152", "doi": "10.1007/978-3-030-80568-5_12", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In Transport Mode Detection, a great diversity of methodologies exist\naccording to the choice made on sensors, preprocessing, model used, etc. In\nthis domain, the comparisons between each option are not always complete.\nExperiments on a public, real-life dataset are led here to evaluate carefully\neach of the choices that were made, with a specific emphasis on data fusion\nmethods. Our most surprising finding is that none of the methods we implemented\nfrom the literature is better than a simple late fusion. Two important\ndecisions are the choice of a sensor and the choice of a representation for the\ndata: we found that using 2D convolutions on spectrograms with a logarithmic\naxis for the frequencies was better than 1-dimensional temporal\nrepresentations.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 08:35:25 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 10:23:53 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Moreau", "Hugues", ""], ["Vassilev", "Andr\u00e9a", ""], ["Chen", "Liming", ""]]}, {"id": "2106.05891", "submitter": "Jiayuan Mao", "authors": "Jiayuan Mao, Zhezheng Luo, Chuang Gan, Joshua B. Tenenbaum, Jiajun Wu,\n  Leslie Pack Kaelbling, Tomer D. Ullman", "title": "Temporal and Object Quantification Networks", "comments": "IJCAI 2021. First two authors contributed equally. Project page:\n  http://toqnet.csail.mit.edu/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Temporal and Object Quantification Networks (TOQ-Nets), a new\nclass of neuro-symbolic networks with a structural bias that enables them to\nlearn to recognize complex relational-temporal events. This is done by\nincluding reasoning layers that implement finite-domain quantification over\nobjects and time. The structure allows them to generalize directly to input\ninstances with varying numbers of objects in temporal sequences of varying\nlengths. We evaluate TOQ-Nets on input domains that require recognizing\nevent-types in terms of complex temporal relational patterns. We demonstrate\nthat TOQ-Nets can generalize from small amounts of data to scenarios containing\nmore objects than were present during training and to temporal warpings of\ninput sequences.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 16:18:21 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Mao", "Jiayuan", ""], ["Luo", "Zhezheng", ""], ["Gan", "Chuang", ""], ["Tenenbaum", "Joshua B.", ""], ["Wu", "Jiajun", ""], ["Kaelbling", "Leslie Pack", ""], ["Ullman", "Tomer D.", ""]]}, {"id": "2106.05905", "submitter": "Fanlin Meng Dr", "authors": "Fanlin Meng, Qian Ma, Zixu Liu, Xiao-Jun Zeng", "title": "Multiple Dynamic Pricing for Demand Response with Adaptive\n  Clustering-based Customer Segmentation in Smart Grids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a realistic multiple dynamic pricing approach to\ndemand response in the retail market. First, an adaptive clustering-based\ncustomer segmentation framework is proposed to categorize customers into\ndifferent groups to enable the effective identification of usage patterns.\nSecond, customized demand models with important market constraints which\ncapture the price-demand relationship explicitly, are developed for each group\nof customers to improve the model accuracy and enable meaningful pricing.\nThird, the multiple pricing based demand response is formulated as a profit\nmaximization problem subject to realistic market constraints. The overall aim\nof the proposed scalable and practical method aims to achieve 'right' prices\nfor 'right' customers so as to benefit various stakeholders in the system such\nas grid operators, customers and retailers. The proposed multiple pricing\nframework is evaluated via simulations based on real-world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 16:47:15 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Meng", "Fanlin", ""], ["Ma", "Qian", ""], ["Liu", "Zixu", ""], ["Zeng", "Xiao-Jun", ""]]}, {"id": "2106.05923", "submitter": "Sophia Bano", "authors": "Sophia Bano, Alessandro Casella, Francisco Vasconcelos, Sara Moccia,\n  George Attilakos, Ruwan Wimalasundera, Anna L. David, Dario Paladini, Jan\n  Deprest, Elena De Momi, Leonardo S. Mattos, Danail Stoyanov", "title": "FetReg: Placental Vessel Segmentation and Registration in Fetoscopy\n  Challenge Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Fetoscopy laser photocoagulation is a widely used procedure for the treatment\nof Twin-to-Twin Transfusion Syndrome (TTTS), that occur in mono-chorionic\nmultiple pregnancies due to placental vascular anastomoses. This procedure is\nparticularly challenging due to limited field of view, poor manoeuvrability of\nthe fetoscope, poor visibility due to fluid turbidity, variability in light\nsource, and unusual position of the placenta. This may lead to increased\nprocedural time and incomplete ablation, resulting in persistent TTTS.\nComputer-assisted intervention may help overcome these challenges by expanding\nthe fetoscopic field of view through video mosaicking and providing better\nvisualization of the vessel network. However, the research and development in\nthis domain remain limited due to unavailability of high-quality data to encode\nthe intra- and inter-procedure variability. Through the \\textit{Fetoscopic\nPlacental Vessel Segmentation and Registration (FetReg)} challenge, we present\na large-scale multi-centre dataset for the development of generalized and\nrobust semantic segmentation and video mosaicking algorithms for the fetal\nenvironment with a focus on creating drift-free mosaics from long duration\nfetoscopy videos. In this paper, we provide an overview of the FetReg dataset,\nchallenge tasks, evaluation metrics and baseline methods for both segmentation\nand registration. Baseline methods results on the FetReg dataset shows that our\ndataset poses interesting challenges, offering large opportunity for the\ncreation of novel methods and models through a community effort initiative\nguided by the FetReg challenge.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 17:14:27 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 10:15:08 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Bano", "Sophia", ""], ["Casella", "Alessandro", ""], ["Vasconcelos", "Francisco", ""], ["Moccia", "Sara", ""], ["Attilakos", "George", ""], ["Wimalasundera", "Ruwan", ""], ["David", "Anna L.", ""], ["Paladini", "Dario", ""], ["Deprest", "Jan", ""], ["De Momi", "Elena", ""], ["Mattos", "Leonardo S.", ""], ["Stoyanov", "Danail", ""]]}, {"id": "2106.05937", "submitter": "Mislav Balunovic", "authors": "Mislav Balunovi\\'c, Anian Ruoss, Martin Vechev", "title": "Fair Normalizing Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fair representation learning is an attractive approach that promises fairness\nof downstream predictors by encoding sensitive data. Unfortunately, recent work\nhas shown that strong adversarial predictors can still exhibit unfairness by\nrecovering sensitive attributes from these representations. In this work, we\npresent Fair Normalizing Flows (FNF), a new approach offering more rigorous\nfairness guarantees for learned representations. Specifically, we consider a\npractical setting where we can estimate the probability density for sensitive\ngroups. The key idea is to model the encoder as a normalizing flow trained to\nminimize the statistical distance between the latent representations of\ndifferent groups. The main advantage of FNF is that its exact likelihood\ncomputation allows us to obtain guarantees on the maximum unfairness of any\npotentially adversarial downstream predictor. We experimentally demonstrate the\neffectiveness of FNF in enforcing various group fairness notions, as well as\nother attractive properties such as interpretability and transfer learning, on\na variety of challenging real-world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 17:35:59 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Balunovi\u0107", "Mislav", ""], ["Ruoss", "Anian", ""], ["Vechev", "Martin", ""]]}, {"id": "2106.05963", "submitter": "Jonas Wulff", "authors": "Manel Baradad, Jonas Wulff, Tongzhou Wang, Phillip Isola, Antonio\n  Torralba", "title": "Learning to See by Looking at Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current vision systems are trained on huge datasets, and these datasets come\nwith costs: curation is expensive, they inherit human biases, and there are\nconcerns over privacy and usage rights. To counter these costs, interest has\nsurged in learning from cheaper data sources, such as unlabeled images. In this\npaper we go a step further and ask if we can do away with real image datasets\nentirely, instead learning from noise processes. We investigate a suite of\nimage generation models that produce images from simple random processes. These\nare then used as training data for a visual representation learner with a\ncontrastive loss. We study two types of noise processes, statistical image\nmodels and deep generative models under different random initializations. Our\nfindings show that it is important for the noise to capture certain structural\nproperties of real data but that good performance can be achieved even with\nprocesses that are far from realistic. We also find that diversity is a key\nproperty to learn good representations. Datasets, models, and code are\navailable at https://mbaradad.github.io/learning_with_noise.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 17:56:46 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Baradad", "Manel", ""], ["Wulff", "Jonas", ""], ["Wang", "Tongzhou", ""], ["Isola", "Phillip", ""], ["Torralba", "Antonio", ""]]}, {"id": "2106.05964", "submitter": "Anay Mehrotra", "authors": "L. Elisa Celis, Anay Mehrotra, Nisheeth K. Vishnoi", "title": "Fair Classification with Adversarial Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study fair classification in the presence of an omniscient adversary that,\ngiven an $\\eta$, is allowed to choose an arbitrary $\\eta$-fraction of the\ntraining samples and arbitrarily perturb their protected attributes. The\nmotivation comes from settings in which protected attributes can be incorrect\ndue to strategic misreporting, malicious actors, or errors in imputation; and\nprior approaches that make stochastic or independence assumptions on errors may\nnot satisfy their guarantees in this adversarial setting. Our main contribution\nis an optimization framework to learn fair classifiers in this adversarial\nsetting that comes with provable guarantees on accuracy and fairness. Our\nframework works with multiple and non-binary protected attributes, is designed\nfor the large class of linear-fractional fairness metrics, and can also handle\nperturbations besides protected attributes. We prove near-tightness of our\nframework's guarantees for natural hypothesis classes: no algorithm can have\nsignificantly better accuracy and any algorithm with better fairness must have\nlower accuracy. Empirically, we evaluate the classifiers produced by our\nframework for statistical rate on real-world and synthetic datasets for a\nfamily of adversaries.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 17:56:59 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Celis", "L. Elisa", ""], ["Mehrotra", "Anay", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "2106.05966", "submitter": "Jimuyang Zhang", "authors": "Jimuyang Zhang and Eshed Ohn-Bar", "title": "Learning by Watching", "comments": "CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When in a new situation or geographical location, human drivers have an\nextraordinary ability to watch others and learn maneuvers that they themselves\nmay have never performed. In contrast, existing techniques for learning to\ndrive preclude such a possibility as they assume direct access to an\ninstrumented ego-vehicle with fully known observations and expert driver\nactions. However, such measurements cannot be directly accessed for the non-ego\nvehicles when learning by watching others. Therefore, in an application where\ndata is regarded as a highly valuable asset, current approaches completely\ndiscard the vast portion of the training data that can be potentially obtained\nthrough indirect observation of surrounding vehicles. Motivated by this key\ninsight, we propose the Learning by Watching (LbW) framework which enables\nlearning a driving policy without requiring full knowledge of neither the state\nnor expert actions. To increase its data, i.e., with new perspectives and\nmaneuvers, LbW makes use of the demonstrations of other vehicles in a given\nscene by (1) transforming the ego-vehicle's observations to their points of\nview, and (2) inferring their expert actions. Our LbW agent learns more robust\ndriving policies while enabling data-efficient learning, including quick\nadaptation of the policy to rare and novel scenarios. In particular, LbW drives\nrobustly even with a fraction of available driving data required by existing\nmethods, achieving an average success rate of 92% on the original CARLA\nbenchmark with only 30 minutes of total driving data and 82% with only 10\nminutes.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 17:58:34 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Zhang", "Jimuyang", ""], ["Ohn-Bar", "Eshed", ""]]}, {"id": "2106.05968", "submitter": "Adrian Bulat", "authors": "Adrian Bulat and Juan-Manuel Perez-Rua and Swathikiran Sudhakaran and\n  Brais Martinez and Georgios Tzimiropoulos", "title": "Space-time Mixing Attention for Video Transformer", "comments": "Updated results on SSv2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is on video recognition using Transformers. Very recent attempts\nin this area have demonstrated promising results in terms of recognition\naccuracy, yet they have been also shown to induce, in many cases, significant\ncomputational overheads due to the additional modelling of the temporal\ninformation. In this work, we propose a Video Transformer model the complexity\nof which scales linearly with the number of frames in the video sequence and\nhence induces no overhead compared to an image-based Transformer model. To\nachieve this, our model makes two approximations to the full space-time\nattention used in Video Transformers: (a) It restricts time attention to a\nlocal temporal window and capitalizes on the Transformer's depth to obtain full\ntemporal coverage of the video sequence. (b) It uses efficient space-time\nmixing to attend jointly spatial and temporal locations without inducing any\nadditional cost on top of a spatial-only attention model. We also show how to\nintegrate 2 very lightweight mechanisms for global temporal-only attention\nwhich provide additional accuracy improvements at minimal computational cost.\nWe demonstrate that our model produces very high recognition accuracy on the\nmost popular video recognition datasets while at the same time being\nsignificantly more efficient than other Video Transformer models. Code will be\nmade available.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 17:59:14 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 12:06:04 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Bulat", "Adrian", ""], ["Perez-Rua", "Juan-Manuel", ""], ["Sudhakaran", "Swathikiran", ""], ["Martinez", "Brais", ""], ["Tzimiropoulos", "Georgios", ""]]}, {"id": "2106.05969", "submitter": "Zhengyi Luo", "authors": "Zhengyi Luo, Ryo Hachiuma, Ye Yuan, Kris Kitani", "title": "Dynamics-Regulated Kinematic Policy for Egocentric Pose Estimation", "comments": "Project page: https://zhengyiluo.github.io/projects/kin_poly/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a method for object-aware 3D egocentric pose estimation that\ntightly integrates kinematics modeling, dynamics modeling, and scene object\ninformation. Unlike prior kinematics or dynamics-based approaches where the two\ncomponents are used disjointly, we synergize the two approaches via\ndynamics-regulated training. At each timestep, a kinematic model is used to\nprovide a target pose using video evidence and simulation state. Then, a\nprelearned dynamics model attempts to mimic the kinematic pose in a physics\nsimulator. By comparing the pose instructed by the kinematic model against the\npose generated by the dynamics model, we can use their misalignment to further\nimprove the kinematic model. By factoring in the 6DoF pose of objects (e.g.,\nchairs, boxes) in the scene, we demonstrate for the first time, the ability to\nestimate physically-plausible 3D human-object interactions using a single\nwearable camera. We evaluate our egocentric pose estimation method in both\ncontrolled laboratory settings and real-world scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 17:59:50 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Luo", "Zhengyi", ""], ["Hachiuma", "Ryo", ""], ["Yuan", "Ye", ""], ["Kitani", "Kris", ""]]}, {"id": "2106.05970", "submitter": "Wanrong Zhu", "authors": "Wanrong Zhu, Xin Eric Wang, An Yan, Miguel Eckstein, William Yang Wang", "title": "ImaginE: An Imagination-Based Automatic Evaluation Metric for Natural\n  Language Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic evaluations for natural language generation (NLG) conventionally\nrely on token-level or embedding-level comparisons with the text references.\nThis is different from human language processing, for which visual imaginations\noften improve comprehension. In this work, we propose ImaginE, an\nimagination-based automatic evaluation metric for natural language generation.\nWith the help of CLIP and DALL-E, two cross-modal models pre-trained on\nlarge-scale image-text pairs, we automatically generate an image as the\nembodied imagination for the text snippet and compute the imagination\nsimilarity using contextual embeddings. Experiments spanning several text\ngeneration tasks demonstrate that adding imagination with our ImaginE displays\ngreat potential in introducing multi-modal information into NLG evaluation, and\nimproves existing automatic metrics' correlations with human similarity\njudgments in many circumstances.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 17:59:52 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Zhu", "Wanrong", ""], ["Wang", "Xin Eric", ""], ["Yan", "An", ""], ["Eckstein", "Miguel", ""], ["Wang", "William Yang", ""]]}, {"id": "2106.05996", "submitter": "Haifeng Qian", "authors": "Haifeng Qian", "title": "An Ensemble Approach Towards Adversarial Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a known phenomenon that adversarial robustness comes at a cost to\nnatural accuracy. To improve this trade-off, this paper proposes an ensemble\napproach that divides a complex robust-classification task into simpler\nsubtasks. Specifically, fractal divide derives multiple training sets from the\ntraining data, and fractal aggregation combines inference outputs from multiple\nclassifiers that are trained on those sets. The resulting ensemble classifiers\nhave a unique property that ensures robustness for an input if certain\ndon't-care conditions are met. The new techniques are evaluated on MNIST and\nFashion-MNIST, with no adversarial training. The MNIST classifier has 99%\nnatural accuracy, 70% measured robustness and 36.9% provable robustness, within\nL2 distance of 2. The Fashion-MNIST classifier has 90% natural accuracy, 54.5%\nmeasured robustness and 28.2% provable robustness, within L2 distance of 1.5.\nBoth results are new state of the art, and we also present new state-of-the-art\nbinary results on challenging label-pairs.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 18:25:15 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Qian", "Haifeng", ""]]}, {"id": "2106.06009", "submitter": "Youri Coppens", "authors": "Youri Coppens, Denis Steckelmacher, Catholijn M. Jonker, Ann Now\\'e", "title": "Synthesising Reinforcement Learning Policies through Set-Valued\n  Inductive Rule Learning", "comments": "17 pages, 4 figures. The final authenticated publication is available\n  online at https://doi.org/10.1007/978-3-030-73959-1_15", "journal-ref": "Trustworthy AI - Integrating Learning, Optimization and Reasoning\n  (2021), Lecture Notes in Computer Science, vol. 12641, pp. 163-179", "doi": "10.1007/978-3-030-73959-1_15", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Today's advanced Reinforcement Learning algorithms produce black-box\npolicies, that are often difficult to interpret and trust for a person. We\nintroduce a policy distilling algorithm, building on the CN2 rule mining\nalgorithm, that distills the policy into a rule-based decision system. At the\ncore of our approach is the fact that an RL process does not just learn a\npolicy, a mapping from states to actions, but also produces extra\nmeta-information, such as action values indicating the quality of alternative\nactions. This meta-information can indicate whether more than one action is\nnear-optimal for a certain state. We extend CN2 to make it able to leverage\nknowledge about equally-good actions to distill the policy into fewer rules,\nincreasing its interpretability by a person. Then, to ensure that the rules\nexplain a valid, non-degenerate policy, we introduce a refinement algorithm\nthat fine-tunes the rules to obtain good performance when executed in the\nenvironment. We demonstrate the applicability of our algorithm on the Mario AI\nbenchmark, a complex task that requires modern reinforcement learning\nalgorithms including neural networks. The explanations we produce capture the\nlearned policy in only a few rules, that allow a person to understand what the\nblack-box agent learned. Source code:\nhttps://gitlab.ai.vub.ac.be/yocoppen/svcn2\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 19:06:28 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Coppens", "Youri", ""], ["Steckelmacher", "Denis", ""], ["Jonker", "Catholijn M.", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "2106.06027", "submitter": "Tianlong Chen", "authors": "Mingkang Zhu, Tianlong Chen, Zhangyang Wang", "title": "Sparse and Imperceptible Adversarial Attack via a Homotopy Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse adversarial attacks can fool deep neural networks (DNNs) by only\nperturbing a few pixels (regularized by l_0 norm). Recent efforts combine it\nwith another l_infty imperceptible on the perturbation magnitudes. The\nresultant sparse and imperceptible attacks are practically relevant, and\nindicate an even higher vulnerability of DNNs that we usually imagined.\nHowever, such attacks are more challenging to generate due to the optimization\ndifficulty by coupling the l_0 regularizer and box constraints with a\nnon-convex objective. In this paper, we address this challenge by proposing a\nhomotopy algorithm, to jointly tackle the sparsity and the perturbation bound\nin one unified framework. Each iteration, the main step of our algorithm is to\noptimize an l_0-regularized adversarial loss, by leveraging the nonmonotone\nAccelerated Proximal Gradient Method (nmAPG) for nonconvex programming; it is\nfollowed by an l_0 change control step, and an optional post-attack step\ndesigned to escape bad local minima. We also extend the algorithm to handling\nthe structural sparsity regularizer. We extensively examine the effectiveness\nof our proposed homotopy attack for both targeted and non-targeted attack\nscenarios, on CIFAR-10 and ImageNet datasets. Compared to state-of-the-art\nmethods, our homotopy attack leads to significantly fewer perturbations, e.g.,\nreducing 42.91% on CIFAR-10 and 75.03% on ImageNet (average case, targeted\nattack), at similar maximal perturbation magnitudes, when still achieving 100%\nattack success rates. Our codes are available at:\nhttps://github.com/VITA-Group/SparseADV_Homotopy.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 20:11:36 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Zhu", "Mingkang", ""], ["Chen", "Tianlong", ""], ["Wang", "Zhangyang", ""]]}, {"id": "2106.06038", "submitter": "Jishnu Ray Chowdhury", "authors": "Jishnu Ray Chowdhury, Cornelia Caragea", "title": "Modeling Hierarchical Structures with Continuous Recursive Neural\n  Networks", "comments": "Accepted in ICML 2021 (long talk)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recursive Neural Networks (RvNNs), which compose sequences according to their\nunderlying hierarchical syntactic structure, have performed well in several\nnatural language processing tasks compared to similar models without structural\nbiases. However, traditional RvNNs are incapable of inducing the latent\nstructure in a plain text sequence on their own. Several extensions have been\nproposed to overcome this limitation. Nevertheless, these extensions tend to\nrely on surrogate gradients or reinforcement learning at the cost of higher\nbias or variance. In this work, we propose Continuous Recursive Neural Network\n(CRvNN) as a backpropagation-friendly alternative to address the aforementioned\nlimitations. This is done by incorporating a continuous relaxation to the\ninduced structure. We demonstrate that CRvNN achieves strong performance in\nchallenging synthetic tasks such as logical inference and ListOps. We also show\nthat CRvNN performs comparably or better than prior latent structure models on\nreal-world tasks such as sentiment analysis and natural language inference.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 20:42:05 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Chowdhury", "Jishnu Ray", ""], ["Caragea", "Cornelia", ""]]}, {"id": "2106.06039", "submitter": "Yunyu Liu", "authors": "Yunyu Liu, Jianzhu Ma, Pan Li", "title": "Neural Higher-order Pattern (Motif) Prediction in Temporal Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic systems that consist of a set of interacting elements can be\nabstracted as temporal networks. Recently, higher-order patterns that involve\nmultiple interacting nodes have been found crucial to indicate domain-specific\nlaws of different temporal networks. This posts us the challenge of designing\nmore sophisticated hypergraph models for these higher-order patterns and the\nassociated new learning algorithms. Here, we propose the first model, named\nHIT, for higher-order pattern prediction in temporal hypergraphs. Particularly,\nwe focus on predicting three types of common but important interaction patterns\ninvolving three interacting elements in temporal networks, which could be\nextended to even higher-order patterns. HIT extracts the structural\nrepresentation of a node triplet of interest on the temporal hypergraph and\nuses it to tell what type of, when, and why the interaction expansion could\nhappen in this triplet. HIT could achieve significant improvement(averaged 20%\nAUC gain to identify the interaction type, uniformly more accurate time\nestimation) compared to both heuristic and other neural-network-based baselines\non 5 real-world large temporal hypergraphs. Moreover, HIT provides a certain\ndegree of interpretability by identifying the most discriminatory structural\nfeatures on the temporal hypergraphs for predicting different higher-order\npatterns.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 20:42:41 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Liu", "Yunyu", ""], ["Ma", "Jianzhu", ""], ["Li", "Pan", ""]]}, {"id": "2106.06046", "submitter": "Mohit Kumar", "authors": "Mohit Kumar, Bernhard A. Moser, Lukas Fischer, Bernhard Freudenthaler", "title": "Information Theoretic Evaluation of Privacy-Leakage, Interpretability,\n  and Transferability for a Novel Trustworthy AI Framework", "comments": "arXiv admin note: text overlap with arXiv:2105.04615,\n  arXiv:2104.07060", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Guidelines and principles of trustworthy AI should be adhered to in practice\nduring the development of AI systems. This work suggests a novel information\ntheoretic trustworthy AI framework based on the hypothesis that information\ntheory enables taking into account the ethical AI principles during the\ndevelopment of machine learning and deep learning models via providing a way to\nstudy and optimize the inherent tradeoffs between trustworthy AI principles.\nUnder the proposed framework, a unified approach to ``privacy-preserving\ninterpretable and transferable learning'' is considered to introduce the\ninformation theoretic measures for privacy-leakage, interpretability, and\ntransferability. A technique based on variational optimization, employing\n\\emph{conditionally deep autoencoders}, is developed for practically\ncalculating the defined information theoretic measures for privacy-leakage,\ninterpretability, and transferability.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 09:47:06 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 05:11:58 GMT"}, {"version": "v3", "created": "Tue, 13 Jul 2021 10:42:00 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Kumar", "Mohit", ""], ["Moser", "Bernhard A.", ""], ["Fischer", "Lukas", ""], ["Freudenthaler", "Bernhard", ""]]}, {"id": "2106.06049", "submitter": "Sowmya S Sundaram", "authors": "Deepak P, Sowmya S Sundaram", "title": "FiSH: Fair Spatial Hotspots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pervasiveness of tracking devices and enhanced availability of spatially\nlocated data has deepened interest in using them for various policy\ninterventions, through computational data analysis tasks such as spatial hot\nspot detection. In this paper, we consider, for the first time to our best\nknowledge, fairness in detecting spatial hot spots. We motivate the need for\nensuring fairness through statistical parity over the collective population\ncovered across chosen hot spots. We then characterize the task of identifying a\ndiverse set of solutions in the noteworthiness-fairness trade-off spectrum, to\nempower the user to choose a trade-off justified by the policy domain. Being a\nnovel task formulation, we also develop a suite of evaluation metrics for fair\nhot spots, motivated by the need to evaluate pertinent aspects of the task. We\nillustrate the computational infeasibility of identifying fair hot spots using\nnaive and/or direct approaches and devise a method, codenamed {\\it FiSH}, for\nefficiently identifying high-quality, fair and diverse sets of spatial hot\nspots. FiSH traverses the tree-structured search space using heuristics that\nguide it towards identifying effective and fair sets of spatial hot spots.\nThrough an extensive empirical analysis over a real-world dataset from the\ndomain of human development, we illustrate that FiSH generates high-quality\nsolutions at fast response times.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 10:29:03 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["P", "Deepak", ""], ["Sundaram", "Sowmya S", ""]]}, {"id": "2106.06052", "submitter": "Douwe Kiela", "authors": "Zhiyi Ma, Kawin Ethayarajh, Tristan Thrush, Somya Jain, Ledell Wu,\n  Robin Jia, Christopher Potts, Adina Williams, Douwe Kiela", "title": "Dynaboard: An Evaluation-As-A-Service Platform for Holistic\n  Next-Generation Benchmarking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Dynaboard, an evaluation-as-a-service framework for hosting\nbenchmarks and conducting holistic model comparison, integrated with the\nDynabench platform. Our platform evaluates NLP models directly instead of\nrelying on self-reported metrics or predictions on a single dataset. Under this\nparadigm, models are submitted to be evaluated in the cloud, circumventing the\nissues of reproducibility, accessibility, and backwards compatibility that\noften hinder benchmarking in NLP. This allows users to interact with uploaded\nmodels in real time to assess their quality, and permits the collection of\nadditional metrics such as memory use, throughput, and robustness, which --\ndespite their importance to practitioners -- have traditionally been absent\nfrom leaderboards. On each task, models are ranked according to the Dynascore,\na novel utility-based aggregation of these statistics, which users can\ncustomize to better reflect their preferences, placing more/less weight on a\nparticular axis of evaluation or dataset. As state-of-the-art NLP models push\nthe limits of traditional benchmarks, Dynaboard offers a standardized solution\nfor a more diverse and comprehensive evaluation of model quality.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 01:17:52 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Ma", "Zhiyi", ""], ["Ethayarajh", "Kawin", ""], ["Thrush", "Tristan", ""], ["Jain", "Somya", ""], ["Wu", "Ledell", ""], ["Jia", "Robin", ""], ["Potts", "Christopher", ""], ["Williams", "Adina", ""], ["Kiela", "Douwe", ""]]}, {"id": "2106.06057", "submitter": "Johannes Schneider", "authors": "Johannes Schneider", "title": "Domain Transformer: Predicting Samples of Unseen, Future Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data distribution commonly evolves over time leading to problems such as\nconcept drift that often decrease classifier performance. We seek to predict\nunseen data (and their labels) allowing us to tackle challenges due to a\nnon-constant data distribution in a \\emph{proactive} manner rather than\ndetecting and reacting to already existing changes that might already have led\nto errors. To this end, we learn a domain transformer in an unsupervised manner\nthat allows generating data of unseen domains. Our approach first matches\nindependently learned latent representations of two given domains obtained from\nan auto-encoder using a Cycle-GAN. In turn, a transformation of the original\nsamples can be learned that can be applied iteratively to extrapolate to unseen\ndomains. Our evaluation on CNNs on image data confirms the usefulness of the\napproach. It also achieves very good results on the well-known problem of\nunsupervised domain adaption, where labels but not samples have to be\npredicted.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 21:20:00 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Schneider", "Johannes", ""]]}, {"id": "2106.06060", "submitter": "Panayiotis Danassis", "authors": "Panayiotis Danassis, Aris Filos-Ratsikas, Boi Faltings", "title": "Achieving Diverse Objectives with AI-driven Prices in Deep Reinforcement\n  Learning Multi-agent Markets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a practical approach to computing market prices and allocations\nvia a deep reinforcement learning policymaker agent, operating in an\nenvironment of other learning agents. Compared to the idealized market\nequilibrium outcome -- which we use as a benchmark -- our policymaker is much\nmore flexible, allowing us to tune the prices with regard to diverse objectives\nsuch as sustainability and resource wastefulness, fairness, buyers' and\nsellers' welfare, etc. To evaluate our approach, we design a realistic market\nwith multiple and diverse buyers and sellers. Additionally, the sellers, which\nare deep learning agents themselves, compete for resources in a common-pool\nappropriation environment based on bio-economic models of commercial fisheries.\n  We demonstrate that: (a) The introduced policymaker is able to achieve\ncomparable performance to the market equilibrium, showcasing the potential of\nsuch approaches in markets where the equilibrium prices can not be efficiently\ncomputed. (b) Our policymaker can notably outperform the equilibrium solution\non certain metrics, while at the same time maintaining comparable performance\nfor the remaining ones. (c) As a highlight of our findings, our policymaker is\nsignificantly more successful in maintaining resource sustainability, compared\nto the market outcome, in scarce resource environments.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 21:26:17 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Danassis", "Panayiotis", ""], ["Filos-Ratsikas", "Aris", ""], ["Faltings", "Boi", ""]]}, {"id": "2106.06061", "submitter": "Daniel Harrold", "authors": "Daniel J. B. Harrold, Jun Cao, and Zhong Fan", "title": "Data-driven battery operation for energy arbitrage using rainbow deep\n  reinforcement learning", "comments": "13 pages, 9 figures (17 counting each subfigure)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As the world seeks to become more sustainable, intelligent solutions are\nneeded to increase the penetration of renewable energy. In this paper, the\nmodel-free deep reinforcement learning algorithm Rainbow Deep Q-Networks is\nused to control a battery in a small microgrid to perform energy arbitrage and\nmore efficiently utilise solar and wind energy sources. The grid operates with\nits own demand and renewable generation based on a dataset collected at Keele\nUniversity, as well as using dynamic energy pricing from a real wholesale\nenergy market. Four scenarios are tested including using demand and price\nforecasting produced with local weather data. The algorithm and its\nsubcomponents are evaluated against two continuous control benchmarks with\nRainbow able to outperform all other method. This research shows the importance\nof using the distributional approach for reinforcement learning when working\nwith complex environments and reward functions, as well as how it can be used\nto visualise and contextualise the agent's behaviour for real-world\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 21:27:35 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Harrold", "Daniel J. B.", ""], ["Cao", "Jun", ""], ["Fan", "Zhong", ""]]}, {"id": "2106.06080", "submitter": "Samira Abnar", "authors": "Samira Abnar, Rianne van den Berg, Golnaz Ghiasi, Mostafa Dehghani,\n  Nal Kalchbrenner, Hanie Sedghi", "title": "Gradual Domain Adaptation in the Wild:When Intermediate Distributions\n  are Absent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the problem of domain adaptation when the goal is shifting the\nmodel towards the target distribution, rather than learning domain invariant\nrepresentations. It has been shown that under the following two assumptions:\n(a) access to samples from intermediate distributions, and (b) samples being\nannotated with the amount of change from the source distribution, self-training\ncan be successfully applied on gradually shifted samples to adapt the model\ntoward the target distribution. We hypothesize having (a) is enough to enable\niterative self-training to slowly adapt the model to the target distribution,\nby making use of an implicit curriculum. In the case where (a) does not hold,\nwe observe that iterative self-training falls short. We propose GIFT, a method\nthat creates virtual samples from intermediate distributions by interpolating\nrepresentations of examples from source and target domains. We evaluate an\niterative-self-training method on datasets with natural distribution shifts,\nand show that when applied on top of other domain adaptation methods, it\nimproves the performance of the model on the target dataset. We run an analysis\non a synthetic dataset to show that in the presence of (a)\niterative-self-training naturally forms a curriculum of samples. Furthermore,\nwe show that when (a) does not hold, GIFT performs better than iterative\nself-training.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 22:47:06 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 09:13:55 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Abnar", "Samira", ""], ["Berg", "Rianne van den", ""], ["Ghiasi", "Golnaz", ""], ["Dehghani", "Mostafa", ""], ["Kalchbrenner", "Nal", ""], ["Sedghi", "Hanie", ""]]}, {"id": "2106.06085", "submitter": "Thomas Helmuth", "authors": "Thomas Helmuth and Lee Spector", "title": "Problem-solving benefits of down-sampled lexicase selection", "comments": "to be published in Artificial Life Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In genetic programming, an evolutionary method for producing computer\nprograms that solve specified computational problems, parent selection is\nordinarily based on aggregate measures of performance across an entire training\nset. Lexicase selection, by contrast, selects on the basis of performance on\nrandom sequences of training cases; this has been shown to enhance\nproblem-solving power in many circumstances. Lexicase selection can also be\nseen as better reflecting biological evolution, by modeling sequences of\nchallenges that organisms face over their lifetimes. Recent work has\ndemonstrated that the advantages of lexicase selection can be amplified by\ndown-sampling, meaning that only a random subsample of the training cases is\nused each generation. This can be seen as modeling the fact that individual\norganisms encounter only subsets of the possible environments, and that\nenvironments change over time. Here we provide the most extensive benchmarking\nof down-sampled lexicase selection to date, showing that its benefits hold up\nto increased scrutiny. The reasons that down-sampling helps, however, are not\nyet fully understood. Hypotheses include that down-sampling allows for more\ngenerations to be processed with the same budget of program evaluations; that\nthe variation of training data across generations acts as a changing\nenvironment, encouraging adaptation; or that it reduces overfitting, leading to\nmore general solutions. We systematically evaluate these hypotheses, finding\nevidence against all three, and instead draw the conclusion that down-sampled\nlexicase selection's main benefit stems from the fact that it allows the\nevolutionary process to examine more individuals within the same computational\nbudget, even though each individual is examined less completely.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 23:42:09 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Helmuth", "Thomas", ""], ["Spector", "Lee", ""]]}, {"id": "2106.06089", "submitter": "Maximilian Lam", "authors": "Maximilian Lam, Gu-Yeon Wei, David Brooks, Vijay Janapa Reddi, Michael\n  Mitzenmacher", "title": "Gradient Disaggregation: Breaking Privacy in Federated Learning by\n  Reconstructing the User Participant Matrix", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that aggregated model updates in federated learning may be insecure.\nAn untrusted central server may disaggregate user updates from sums of updates\nacross participants given repeated observations, enabling the server to recover\nprivileged information about individual users' private training data via\ntraditional gradient inference attacks. Our method revolves around\nreconstructing participant information (e.g: which rounds of training users\nparticipated in) from aggregated model updates by leveraging summary\ninformation from device analytics commonly used to monitor, debug, and manage\nfederated learning systems. Our attack is parallelizable and we successfully\ndisaggregate user updates on settings with up to thousands of participants. We\nquantitatively and qualitatively demonstrate significant improvements in the\ncapability of various inference attacks on the disaggregated updates. Our\nattack enables the attribution of learned properties to individual users,\nviolating anonymity, and shows that a determined central server may undermine\nthe secure aggregation protocol to break individual users' data privacy in\nfederated learning.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 23:55:28 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Lam", "Maximilian", ""], ["Wei", "Gu-Yeon", ""], ["Brooks", "David", ""], ["Reddi", "Vijay Janapa", ""], ["Mitzenmacher", "Michael", ""]]}, {"id": "2106.06091", "submitter": "Manoj Alwani", "authors": "Manoj Alwani, Vashisht Madhavan, Yang Wang", "title": "DECORE: Deep Compression with Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has become an increasingly popular and powerful option for\nmodern pattern recognition systems. However, many deep neural networks have\nmillions to billions of parameters, making them untenable for real-world\napplications with constraints on memory or latency. As a result, powerful\nnetwork compression techniques are a must for the widespread adoption of deep\nlearning. We present DECORE, a reinforcement learning approach to automate the\nnetwork compression process. Using a simple policy gradient method to learn\nwhich neurons or channels to keep or remove, we are able to achieve compression\nrates 3x to 5x greater than contemporary approaches. In contrast with other\narchitecture search methods, DECORE is simple and quick to train, requiring\nonly a few hours of training on 1 GPU. When applied to standard network\narchitectures on different datasets, our approach achieves 11x to 103x\ncompression on different architectures while maintaining accuracies similar to\nthose of the original, large networks.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 00:03:41 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Alwani", "Manoj", ""], ["Madhavan", "Vashisht", ""], ["Wang", "Yang", ""]]}, {"id": "2106.06098", "submitter": "Guanya Shi", "authors": "Guanya Shi, Kamyar Azizzadenesheli, Soon-Jo Chung, Yisong Yue", "title": "Meta-Adaptive Nonlinear Control: Theory and Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an online multi-task learning approach for adaptive nonlinear\ncontrol, which we call Online Meta-Adaptive Control (OMAC). The goal is to\ncontrol a nonlinear system subject to adversarial disturbance and unknown\n$\\textit{environment-dependent}$ nonlinear dynamics, under the assumption that\nthe environment-dependent dynamics can be well captured with some shared\nrepresentation. Our approach is motivated by robot control, where a robotic\nsystem encounters a sequence of new environmental conditions that it must\nquickly adapt to. A key emphasis is to integrate online representation learning\nwith established methods from control theory, in order to arrive at a unified\nframework that yields both control-theoretic and learning-theoretic guarantees.\nWe provide instantiations of our approach under varying conditions, leading to\nthe first non-asymptotic end-to-end convergence guarantee for multi-task\nadaptive nonlinear control. OMAC can also be integrated with deep\nrepresentation learning. Experiments show that OMAC significantly outperforms\nconventional adaptive control approaches which do not learn the shared\nrepresentation.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 00:39:07 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 21:11:31 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Shi", "Guanya", ""], ["Azizzadenesheli", "Kamyar", ""], ["Chung", "Soon-Jo", ""], ["Yue", "Yisong", ""]]}, {"id": "2106.06114", "submitter": "Megan Tjandrasuwita", "authors": "Megan Tjandrasuwita, Jennifer J. Sun, Ann Kennedy, Swarat Chaudhuri,\n  Yisong Yue", "title": "Interpreting Expert Annotation Differences in Animal Behavior", "comments": "4 pages, 5 figures, presented as a poster at CV4Animals workshop @\n  CVPR21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hand-annotated data can vary due to factors such as subjective differences,\nintra-rater variability, and differing annotator expertise. We study\nannotations from different experts who labelled the same behavior classes on a\nset of animal behavior videos, and observe a variation in annotation styles. We\npropose a new method using program synthesis to help interpret annotation\ndifferences for behavior analysis. Our model selects relevant trajectory\nfeatures and learns a temporal filter as part of a program, which corresponds\nto estimated importance an annotator places on that feature at each timestamp.\nOur experiments on a dataset from behavioral neuroscience demonstrate that\ncompared to baseline approaches, our method is more accurate at capturing\nannotator labels and learns interpretable temporal filters. We believe that our\nmethod can lead to greater reproducibility of behavior annotations used in\nscientific studies. We plan to release our code.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 01:36:03 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Tjandrasuwita", "Megan", ""], ["Sun", "Jennifer J.", ""], ["Kennedy", "Ann", ""], ["Chaudhuri", "Swarat", ""], ["Yue", "Yisong", ""]]}, {"id": "2106.06135", "submitter": "Daochen Zha", "authors": "Daochen Zha, Jingru Xie, Wenye Ma, Sheng Zhang, Xiangru Lian, Xia Hu,\n  Ji Liu", "title": "DouZero: Mastering DouDizhu with Self-Play Deep Reinforcement Learning", "comments": "Accepted by ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Games are abstractions of the real world, where artificial agents learn to\ncompete and cooperate with other agents. While significant achievements have\nbeen made in various perfect- and imperfect-information games, DouDizhu (a.k.a.\nFighting the Landlord), a three-player card game, is still unsolved. DouDizhu\nis a very challenging domain with competition, collaboration, imperfect\ninformation, large state space, and particularly a massive set of possible\nactions where the legal actions vary significantly from turn to turn.\nUnfortunately, modern reinforcement learning algorithms mainly focus on simple\nand small action spaces, and not surprisingly, are shown not to make\nsatisfactory progress in DouDizhu. In this work, we propose a conceptually\nsimple yet effective DouDizhu AI system, namely DouZero, which enhances\ntraditional Monte-Carlo methods with deep neural networks, action encoding, and\nparallel actors. Starting from scratch in a single server with four GPUs,\nDouZero outperformed all the existing DouDizhu AI programs in days of training\nand was ranked the first in the Botzone leaderboard among 344 AI agents.\nThrough building DouZero, we show that classic Monte-Carlo methods can be made\nto deliver strong results in a hard domain with a complex action space. The\ncode and an online demo are released at https://github.com/kwai/DouZero with\nthe hope that this insight could motivate future work.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 02:45:51 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Zha", "Daochen", ""], ["Xie", "Jingru", ""], ["Ma", "Wenye", ""], ["Zhang", "Sheng", ""], ["Lian", "Xiangru", ""], ["Hu", "Xia", ""], ["Liu", "Ji", ""]]}, {"id": "2106.06139", "submitter": "Kristen Moore", "authors": "Kristen Moore, Shenjun Zhong, Zhen He, Torsten Rudolf, Nils Fisher,\n  Brandon Victor, Neha Jindal", "title": "A comprehensive solution to retrieval-based chatbot construction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper we present the results of our experiments in training and\ndeploying a self-supervised retrieval-based chatbot trained with contrastive\nlearning for assisting customer support agents. In contrast to most existing\nresearch papers in this area where the focus is on solving just one component\nof a deployable chatbot, we present an end-to-end set of solutions to take the\nreader from an unlabelled chatlogs to a deployed chatbot. This set of solutions\nincludes creating a self-supervised dataset and a weakly labelled dataset from\nchatlogs, as well as a systematic approach to selecting a fixed list of canned\nresponses. We present a hierarchical-based RNN architecture for the response\nselection model, chosen for its ability to cache intermediate utterance\nembeddings, which helped to meet deployment inference speed requirements. We\ncompare the performance of this architecture across 3 different learning\nobjectives: self-supervised contrastive learning, binary classification, and\nmulti-class classification. We find that using a self-supervised contrastive\nlearning model outperforms training the binary and multi-class classification\nmodels on a weakly labelled dataset. Our results validate that the\nself-supervised contrastive learning approach can be effectively used for a\nreal-world chatbot scenario.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 02:54:33 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Moore", "Kristen", ""], ["Zhong", "Shenjun", ""], ["He", "Zhen", ""], ["Rudolf", "Torsten", ""], ["Fisher", "Nils", ""], ["Victor", "Brandon", ""], ["Jindal", "Neha", ""]]}, {"id": "2106.06153", "submitter": "Jiaye Teng", "authors": "Jiaye Teng, Jianhao Ma, Yang Yuan", "title": "Towards Understanding Generalization via Decomposing Excess Risk\n  Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization is one of the critical issues in machine learning. However,\ntraditional methods like uniform convergence are not powerful enough to fully\nexplain generalization because they may yield vacuous bounds even in\noverparameterized linear regression regimes. An alternative solution is to\nanalyze the generalization dynamics to derive algorithm-dependent bounds, e.g.,\nstability. Unfortunately, the stability-based bound is still far from\nexplaining the remarkable generalization ability of neural networks due to the\ncoarse-grained analysis of the signal and noise. Inspired by the observation\nthat neural networks show a slow convergence rate when fitting noise, we\npropose decomposing the excess risk dynamics and applying stability-based bound\nonly on the variance part (which measures how the model performs on pure\nnoise). We provide two applications for the framework, including a linear case\n(overparameterized linear regression with gradient descent) and a non-linear\ncase (matrix recovery with gradient flow). Under the decomposition framework,\nthe new bound accords better with the theoretical and empirical evidence\ncompared to the stability-based bound and uniform convergence bound.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 03:42:45 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Teng", "Jiaye", ""], ["Ma", "Jianhao", ""], ["Yuan", "Yang", ""]]}, {"id": "2106.06157", "submitter": "Yejin Bang", "authors": "Yejin Bang, Nayeon Lee, Etsuko Ishii, Andrea Madotto, Pascale Fung", "title": "Assessing Political Prudence of Open-domain Chatbots", "comments": "SIGDIAL 2021 - Safety for E2E Conversational AI (Camera-ready\n  Version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Politically sensitive topics are still a challenge for open-domain chatbots.\nHowever, dealing with politically sensitive content in a responsible,\nnon-partisan, and safe behavior way is integral for these chatbots. Currently,\nthe main approach to handling political sensitivity is by simply changing such\na topic when it is detected. This is safe but evasive and results in a chatbot\nthat is less engaging. In this work, as a first step towards a politically safe\nchatbot, we propose a group of metrics for assessing their political prudence.\nWe then conduct political prudence analysis of various chatbots and discuss\ntheir behavior from multiple angles through our automatic metric and human\nevaluation metrics. The testsets and codebase are released to promote research\nin this area.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 04:03:53 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Bang", "Yejin", ""], ["Lee", "Nayeon", ""], ["Ishii", "Etsuko", ""], ["Madotto", "Andrea", ""], ["Fung", "Pascale", ""]]}, {"id": "2106.06162", "submitter": "Saehoon Kim", "authors": "Saehoon Kim, Sungwoong Kim, Juho Lee", "title": "Hybrid Generative-Contrastive Representation Learning", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised representation learning has recently received lots of interest\ndue to its powerful generalizability through effectively leveraging large-scale\nunlabeled data. There are two prevalent approaches for this, contrastive\nlearning and generative pre-training, where the former learns representations\nfrom instance-wise discrimination tasks and the latter learns them from\nestimating the likelihood. These seemingly orthogonal approaches have their own\nstrengths and weaknesses. Contrastive learning tends to extract semantic\ninformation and discards details irrelevant for classifying objects, making the\nrepresentations effective for discriminative tasks while degrading robustness\nto out-of-distribution data. On the other hand, the generative pre-training\ndirectly estimates the data distribution, so the representations tend to be\nrobust but not optimal for discriminative tasks. In this paper, we show that we\ncould achieve the best of both worlds by a hybrid training scheme.\nSpecifically, we demonstrated that a transformer-based encoder-decoder\narchitecture trained with both contrastive and generative losses can learn\nhighly discriminative and robust representations without hurting the generative\nperformance. We extensively validate our approach on various tasks.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 04:23:48 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Kim", "Saehoon", ""], ["Kim", "Sungwoong", ""], ["Lee", "Juho", ""]]}, {"id": "2106.06165", "submitter": "Ziwei Fan", "authors": "Ziwei Fan, Zhiwei Liu, Lei Zheng, Shen Wang, Philip S. Yu", "title": "Modeling Sequences as Distributions with Uncertainty for Sequential\n  Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The sequential patterns within the user interactions are pivotal for\nrepresenting the user's preference and capturing latent relationships among\nitems. The recent advancements of sequence modeling by Transformers advocate\nthe community to devise more effective encoders for the sequential\nrecommendation. Most existing sequential methods assume users are\ndeterministic. However, item-item transitions might fluctuate significantly in\nseveral item aspects and exhibit randomness of user interests. This\n\\textit{stochastic characteristics} brings up a solid demand to include\nuncertainties in representing sequences and items. Additionally, modeling\nsequences and items with uncertainties expands users' and items' interaction\nspaces, thus further alleviating cold-start problems.\n  In this work, we propose a Distribution-based Transformer for Sequential\nRecommendation (DT4SR), which injects uncertainties into sequential modeling.\nWe use Elliptical Gaussian distributions to describe items and sequences with\nuncertainty. We describe the uncertainty in items and sequences as Elliptical\nGaussian distribution. And we adopt Wasserstein distance to measure the\nsimilarity between distributions. We devise two novel Trans-formers for\nmodeling mean and covariance, which guarantees the positive-definite property\nof distributions. The proposed method significantly outperforms the\nstate-of-the-art methods. The experiments on three benchmark datasets also\ndemonstrate its effectiveness in alleviating cold-start issues. The code is\navailable inhttps://github.com/DyGRec/DT4SR.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 04:35:21 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Fan", "Ziwei", ""], ["Liu", "Zhiwei", ""], ["Zheng", "Lei", ""], ["Wang", "Shen", ""], ["Yu", "Philip S.", ""]]}, {"id": "2106.06169", "submitter": "Haoyu Song", "authors": "Haoyu Song, Yan Wang, Kaiyan Zhang, Wei-Nan Zhang, Ting Liu", "title": "BoB: BERT Over BERT for Training Persona-based Dialogue Models from\n  Limited Personalized Data", "comments": "ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maintaining consistent personas is essential for dialogue agents. Although\ntremendous advancements have been brought, the limited-scale of annotated\npersona-dense data are still barriers towards training robust and consistent\npersona-based dialogue models. In this work, we show how the challenges can be\naddressed by disentangling persona-based dialogue generation into two sub-tasks\nwith a novel BERT-over-BERT (BoB) model. Specifically, the model consists of a\nBERT-based encoder and two BERT-based decoders, where one decoder is for\nresponse generation, and another is for consistency understanding. In\nparticular, to learn the ability of consistency understanding from large-scale\nnon-dialogue inference data, we train the second decoder in an unlikelihood\nmanner. Under different limited data settings, both automatic and human\nevaluations demonstrate that the proposed model outperforms strong baselines in\nresponse quality and persona consistency.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 05:02:05 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 01:52:30 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Song", "Haoyu", ""], ["Wang", "Yan", ""], ["Zhang", "Kaiyan", ""], ["Zhang", "Wei-Nan", ""], ["Liu", "Ting", ""]]}, {"id": "2106.06218", "submitter": "Seongjun Yun", "authors": "Seongjun Yun, Minbyul Jeong, Sungdong Yoo, Seunghun Lee, Sean S. Yi,\n  Raehyun Kim, Jaewoo Kang, Hyunwoo J. Kim", "title": "Graph Transformer Networks: Learning Meta-path Graphs to Improve GNNs", "comments": "arXiv admin note: text overlap with arXiv:1911.06455", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph Neural Networks (GNNs) have been widely applied to various fields due\nto their powerful representations of graph-structured data. Despite the success\nof GNNs, most existing GNNs are designed to learn node representations on the\nfixed and homogeneous graphs. The limitations especially become problematic\nwhen learning representations on a misspecified graph or a heterogeneous graph\nthat consists of various types of nodes and edges. To address this limitations,\nwe propose Graph Transformer Networks (GTNs) that are capable of generating new\ngraph structures, which preclude noisy connections and include useful\nconnections (e.g., meta-paths) for tasks, while learning effective node\nrepresentations on the new graphs in an end-to-end fashion. We further propose\nenhanced version of GTNs, Fast Graph Transformer Networks (FastGTNs), that\nimprove scalability of graph transformations. Compared to GTNs, FastGTNs are\n230x faster and use 100x less memory while allowing the identical graph\ntransformations as GTNs. In addition, we extend graph transformations to the\nsemantic proximity of nodes allowing non-local operations beyond meta-paths.\nExtensive experiments on both homogeneous graphs and heterogeneous graphs show\nthat GTNs and FastGTNs with non-local operations achieve the state-of-the-art\nperformance for node classification tasks. The code is available:\nhttps://github.com/seongjunyun/Graph_Transformer_Networks\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 07:56:55 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Yun", "Seongjun", ""], ["Jeong", "Minbyul", ""], ["Yoo", "Sungdong", ""], ["Lee", "Seunghun", ""], ["Yi", "Sean S.", ""], ["Kim", "Raehyun", ""], ["Kang", "Jaewoo", ""], ["Kim", "Hyunwoo J.", ""]]}, {"id": "2106.06224", "submitter": "Chao Wen", "authors": "Chao Wen, Miao Xu, Zhilin Zhang, Zhenzhe Zheng, Yuhui Wang, Xiangyu\n  Liu, Yu Rong, Dong Xie, Xiaoyang Tan, Chuan Yu, Jian Xu, Fan Wu, Guihai Chen,\n  Xiaoqiang Zhu", "title": "A Cooperative-Competitive Multi-Agent Framework for Auto-bidding in\n  Online Advertising", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In online advertising, auto-bidding has become an essential tool for\nadvertisers to optimize their preferred ad performance metrics by simply\nexpressing the high-level campaign objectives and constraints. Previous works\nconsider the design of auto-bidding agents from the single-agent view without\nmodeling the mutual influence between agents. In this paper, we instead\nconsider this problem from the perspective of a distributed multi-agent system,\nand propose a general Multi-Agent reinforcement learning framework for\nAuto-Bidding, namely MAAB, to learn the auto-bidding strategies. First, we\ninvestigate the competition and cooperation relation among auto-bidding agents,\nand propose temperature-regularized credit assignment for establishing a mixed\ncooperative-competitive paradigm. By carefully making a competition and\ncooperation trade-off among the agents, we can reach an equilibrium state that\nguarantees not only individual advertiser's utility but also the system\nperformance (social welfare). Second, due to the observed collusion behaviors\nof bidding low prices underlying the cooperation, we further propose bar agents\nto set a personalized bidding bar for each agent, and then to alleviate the\ndegradation of revenue. Third, to deploy MAAB to the large-scale advertising\nsystem with millions of advertisers, we propose a mean-field approach. By\ngrouping advertisers with the same objective as a mean auto-bidding agent, the\ninteractions among advertisers are greatly simplified, making it practical to\ntrain MAAB efficiently. Extensive experiments on the offline industrial dataset\nand Alibaba advertising platform demonstrate that our approach outperforms\nseveral baseline methods in terms of social welfare and guarantees the ad\nplatform's revenue.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 08:07:14 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Wen", "Chao", ""], ["Xu", "Miao", ""], ["Zhang", "Zhilin", ""], ["Zheng", "Zhenzhe", ""], ["Wang", "Yuhui", ""], ["Liu", "Xiangyu", ""], ["Rong", "Yu", ""], ["Xie", "Dong", ""], ["Tan", "Xiaoyang", ""], ["Yu", "Chuan", ""], ["Xu", "Jian", ""], ["Wu", "Fan", ""], ["Chen", "Guihai", ""], ["Zhu", "Xiaoqiang", ""]]}, {"id": "2106.06230", "submitter": "Ren\\'e Peinl", "authors": "Ren\\'e Peinl", "title": "Sprachsynthese -- State-of-the-Art in englischer und deutscher Sprache", "comments": "in German", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Reading text aloud is an important feature for modern computer applications.\nIt not only facilitates access to information for visually impaired people, but\nis also a pleasant convenience for non-impaired users. In this article, the\nstate of the art of speech synthesis is presented separately for\nmel-spectrogram generation and vocoders. It concludes with an overview of\navailable data sets for English and German with a discussion of the\ntransferability of the good speech synthesis results from English to German\nlanguage.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 08:25:08 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Peinl", "Ren\u00e9", ""]]}, {"id": "2106.06232", "submitter": "Jiajun Fan", "authors": "Jiajun Fan, Changnan Xiao, Yue Huang", "title": "GDI: Rethinking What Makes Reinforcement Learning Different From\n  Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Q Network (DQN) firstly kicked the door of deep reinforcement learning\n(DRL) via combining deep learning (DL) with reinforcement learning (RL), which\nhas noticed that the distribution of the acquired data would change during the\ntraining process. DQN found this property might cause instability for training,\nso it proposed effective methods to handle the downside of the property.\nInstead of focusing on the unfavourable aspects, we find it critical for RL to\nease the gap between the estimated data distribution and the ground truth data\ndistribution while supervised learning (SL) fails to do so. From this new\nperspective, we extend the basic paradigm of RL called the Generalized Policy\nIteration (GPI) into a more generalized version, which is called the\nGeneralized Data Distribution Iteration (GDI). We see massive RL algorithms and\ntechniques can be unified into the GDI paradigm, which can be considered as one\nof the special cases of GDI. We provide theoretical proof of why GDI is better\nthan GPI and how it works. Several practical algorithms based on GDI have been\nproposed to verify the effectiveness and extensiveness of it. Empirical\nexperiments prove our state-of-the-art (SOTA) performance on Arcade Learning\nEnvironment (ALE), wherein our algorithm has achieved 9620.98% mean human\nnormalized score (HNS), 1146.39% median HNS and 22 human world record\nbreakthroughs (HWRB) using only 200M training frames. Our work aims to lead the\nRL research to step into the journey of conquering the human world records and\nseek real superhuman agents on both performance and efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 08:31:12 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 04:44:24 GMT"}, {"version": "v3", "created": "Tue, 13 Jul 2021 07:17:36 GMT"}, {"version": "v4", "created": "Mon, 26 Jul 2021 09:35:35 GMT"}, {"version": "v5", "created": "Wed, 28 Jul 2021 07:11:02 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Fan", "Jiajun", ""], ["Xiao", "Changnan", ""], ["Huang", "Yue", ""]]}, {"id": "2106.06243", "submitter": "Sevvandi Kandanaarachchi", "authors": "Sevvandi Kandanaarachchi", "title": "Unsupervised Anomaly Detection Ensembles using Item Response Theory", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Constructing an ensemble from a heterogeneous set of unsupervised anomaly\ndetection methods is challenging because the class labels or the ground truth\nis unknown. Thus, traditional ensemble techniques that use the response\nvariable or the class labels cannot be used to construct an ensemble for\nunsupervised anomaly detection.\n  We use Item Response Theory (IRT) -- a class of models used in educational\npsychometrics to assess student and test question characteristics -- to\nconstruct an unsupervised anomaly detection ensemble. IRT's latent trait\ncomputation lends itself to anomaly detection because the latent trait can be\nused to uncover the hidden ground truth. Using a novel IRT mapping to the\nanomaly detection problem, we construct an ensemble that can downplay noisy,\nnon-discriminatory methods and accentuate sharper methods. We demonstrate the\neffectiveness of the IRT ensemble on an extensive data repository, by comparing\nits performance to other ensemble techniques.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 08:51:26 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Kandanaarachchi", "Sevvandi", ""]]}, {"id": "2106.06247", "submitter": "Jean Lee", "authors": "Jean Lee, Hoyoul Luis Youn, Nicholas Stevens, Josiah Poon, Soyeon\n  Caren Han", "title": "FedNLP: An interpretable NLP System to Decode Federal Reserve\n  Communications", "comments": "Accepted by SIGIR 2021", "journal-ref": null, "doi": "10.1145/3404835.3462785", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Federal Reserve System (the Fed) plays a significant role in affecting\nmonetary policy and financial conditions worldwide. Although it is important to\nanalyse the Fed's communications to extract useful information, it is generally\nlong-form and complex due to the ambiguous and esoteric nature of content. In\nthis paper, we present FedNLP, an interpretable multi-component Natural\nLanguage Processing system to decode Federal Reserve communications. This\nsystem is designed for end-users to explore how NLP techniques can assist their\nholistic understanding of the Fed's communications with NO coding. Behind the\nscenes, FedNLP uses multiple NLP models from traditional machine learning\nalgorithms to deep neural network architectures in each downstream task. The\ndemonstration shows multiple results at once including sentiment analysis,\nsummary of the document, prediction of the Federal Funds Rate movement and\nvisualization for interpreting the prediction model's result.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 08:58:36 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Lee", "Jean", ""], ["Youn", "Hoyoul Luis", ""], ["Stevens", "Nicholas", ""], ["Poon", "Josiah", ""], ["Han", "Soyeon Caren", ""]]}, {"id": "2106.06300", "submitter": "Maxime Vono", "authors": "Vincent Plassier, Maxime Vono, Alain Durmus and Eric Moulines", "title": "DG-LMC: A Turn-key and Scalable Synchronous Distributed MCMC Algorithm\n  via Langevin Monte Carlo within Gibbs", "comments": "77 pages. Accepted for publication at ICML 2021, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Performing reliable Bayesian inference on a big data scale is becoming a\nkeystone in the modern era of machine learning. A workhorse class of methods to\nachieve this task are Markov chain Monte Carlo (MCMC) algorithms and their\ndesign to handle distributed datasets has been the subject of many works.\nHowever, existing methods are not completely either reliable or computationally\nefficient. In this paper, we propose to fill this gap in the case where the\ndataset is partitioned and stored on computing nodes within a cluster under a\nmaster/slaves architecture. We derive a user-friendly centralised distributed\nMCMC algorithm with provable scaling in high-dimensional settings. We\nillustrate the relevance of the proposed methodology on both synthetic and real\ndata experiments.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 10:37:14 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 14:21:51 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Plassier", "Vincent", ""], ["Vono", "Maxime", ""], ["Durmus", "Alain", ""], ["Moulines", "Eric", ""]]}, {"id": "2106.06307", "submitter": "Usman Nazir", "authors": "Usman Nazir, He Wang and Murtaza Taj", "title": "Survey of Image Based Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this survey paper, we analyze image based graph neural networks and\npropose a three-step classification approach. We first convert the image into\nsuperpixels using the Quickshift algorithm so as to reduce 30% of the input\ndata. The superpixels are subsequently used to generate a region adjacency\ngraph. Finally, the graph is passed through a state-of-art graph convolutional\nneural network to get classification scores. We also analyze the spatial and\nspectral convolution filtering techniques in graph neural networks.\nSpectral-based models perform better than spatial-based models and classical\nCNN with lesser compute cost.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 10:56:43 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Nazir", "Usman", ""], ["Wang", "He", ""], ["Taj", "Murtaza", ""]]}, {"id": "2106.06363", "submitter": "Thomas Scialom", "authors": "Thomas Scialom, Paul-Alexis Dray, Sylvain Lamprier, Benjamin\n  Piwowarski, Jacopo Staiano", "title": "To Beam Or Not To Beam: That is a Question of Cooperation for Language\n  GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the discrete nature of words, language GANs require to be optimized\nfrom rewards provided by discriminator networks, via reinforcement learning\nmethods. This is a much harder setting than for continuous tasks, which enjoy\ngradient flows from discriminators to generators, usually leading to dramatic\nlearning instabilities. However, we claim that this can be solved by making\ndiscriminator and generator networks cooperate to produce output sequences\nduring training. These cooperative outputs, inherently built to obtain higher\ndiscrimination scores, not only provide denser rewards for training, but also\nform a more compact artificial set for discriminator training, hence improving\nits accuracy and stability. In this paper, we show that our SelfGAN framework,\nbuilt on this cooperative principle, outperforms Teacher Forcing and obtains\nstate-of-the-art results on two challenging tasks, Summarization and Question\nGeneration.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 13:04:42 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Scialom", "Thomas", ""], ["Dray", "Paul-Alexis", ""], ["Lamprier", "Sylvain", ""], ["Piwowarski", "Benjamin", ""], ["Staiano", "Jacopo", ""]]}, {"id": "2106.06403", "submitter": "Christiane Plociennik", "authors": "Hooman Tavakoli, Snehal Walunj, Parsha Pahlevannejad, Christiane\n  Plociennik, and Martin Ruskowski", "title": "Small Object Detection for Near Real-Time Egocentric Perception in a\n  Manual Assembly Scenario", "comments": "Accepted for presentation at EPIC@CVPR2021 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting small objects in video streams of head-worn augmented reality\ndevices in near real-time is a huge challenge: training data is typically\nscarce, the input video stream can be of limited quality, and small objects are\nnotoriously hard to detect. In industrial scenarios, however, it is often\npossible to leverage contextual knowledge for the detection of small objects.\nFurthermore, CAD data of objects are typically available and can be used to\ngenerate synthetic training data. We describe a near real-time small object\ndetection pipeline for egocentric perception in a manual assembly scenario: We\ngenerate a training data set based on CAD data and realistic backgrounds in\nUnity. We then train a YOLOv4 model for a two-stage detection process: First,\nthe context is recognized, then the small object of interest is detected. We\nevaluate our pipeline on the augmented reality device Microsoft Hololens 2.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 13:59:44 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Tavakoli", "Hooman", ""], ["Walunj", "Snehal", ""], ["Pahlevannejad", "Parsha", ""], ["Plociennik", "Christiane", ""], ["Ruskowski", "Martin", ""]]}, {"id": "2106.06410", "submitter": "Yang Hu Dr.", "authors": "Yang Hu, Adriane Chapman, Guihua Wen and Dame Wendy Hall", "title": "What Can Knowledge Bring to Machine Learning? -- A Survey of Low-shot\n  Learning for Structured Data", "comments": "41 pages, 280 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised machine learning has several drawbacks that make it difficult to\nuse in many situations. Drawbacks include: heavy reliance on massive training\ndata, limited generalizability and poor expressiveness of high-level semantics.\nLow-shot Learning attempts to address these drawbacks. Low-shot learning allows\nthe model to obtain good predictive power with very little or no training data,\nwhere structured knowledge plays a key role as a high-level semantic\nrepresentation of human. This article will review the fundamental factors of\nlow-shot learning technologies, with a focus on the operation of structured\nknowledge under different low-shot conditions. We also introduce other\ntechniques relevant to low-shot learning. Finally, we point out the limitations\nof low-shot learning, the prospects and gaps of industrial applications, and\nfuture research directions.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 14:07:07 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Hu", "Yang", ""], ["Chapman", "Adriane", ""], ["Wen", "Guihua", ""], ["Hall", "Dame Wendy", ""]]}, {"id": "2106.06411", "submitter": "Mahdi Namazifar", "authors": "Devamanyu Hazarika, Mahdi Namazifar, Dilek Hakkani-T\\\"ur", "title": "Zero-Shot Controlled Generation with Encoder-Decoder Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Controlling neural network-based models for natural language generation (NLG)\nhas broad applications in numerous areas such as machine translation, document\nsummarization, and dialog systems. Approaches that enable such control in a\nzero-shot manner would be of great importance as, among other reasons, they\nremove the need for additional annotated data and training. In this work, we\npropose novel approaches for controlling encoder-decoder transformer-based NLG\nmodels in zero-shot. This is done by introducing three control knobs, namely,\nattention biasing, decoder mixing, and context augmentation, that are applied\nto these models at generation time. These knobs control the generation process\nby directly manipulating trained NLG models (e.g., biasing cross-attention\nlayers) to realize the desired attributes in the generated outputs. We show\nthat not only are these NLG models robust to such manipulations, but also their\nbehavior could be controlled without an impact on their generation performance.\nThese results, to the best of our knowledge, are the first of their kind.\nThrough these control knobs, we also investigate the role of transformer\ndecoder's self-attention module and show strong evidence that its primary role\nis maintaining fluency of sentences generated by these models. Based on this\nhypothesis, we show that alternative architectures for transformer decoders\ncould be viable options. We also study how this hypothesis could lead to more\nefficient ways for training encoder-decoder transformer models.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 14:07:19 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 16:25:11 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Hazarika", "Devamanyu", ""], ["Namazifar", "Mahdi", ""], ["Hakkani-T\u00fcr", "Dilek", ""]]}, {"id": "2106.06480", "submitter": "Matteo Castiglioni", "authors": "Matteo Castiglioni, Alberto Marchesi, Andrea Celli, Nicola Gatti", "title": "Multi-Receiver Online Bayesian Persuasion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian persuasion studies how an informed sender should partially disclose\ninformation to influence the behavior of a self-interested receiver. Classical\nmodels make the stringent assumption that the sender knows the receiver's\nutility. This can be relaxed by considering an online learning framework in\nwhich the sender repeatedly faces a receiver of an unknown, adversarially\nselected type. We study, for the first time, an online Bayesian persuasion\nsetting with multiple receivers. We focus on the case with no externalities and\nbinary actions, as customary in offline models. Our goal is to design no-regret\nalgorithms for the sender with polynomial per-iteration running time. First, we\nprove a negative result: for any $0 < \\alpha \\leq 1$, there is no\npolynomial-time no-$\\alpha$-regret algorithm when the sender's utility function\nis supermodular or anonymous. Then, we focus on the case of submodular sender's\nutility functions and we show that, in this case, it is possible to design a\npolynomial-time no-$(1 - \\frac{1}{e})$-regret algorithm. To do so, we introduce\na general online gradient descent scheme to handle online learning problems\nwith a finite number of possible loss functions. This requires the existence of\nan approximate projection oracle. We show that, in our setting, there exists\none such projection oracle which can be implemented in polynomial time.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 16:05:31 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Castiglioni", "Matteo", ""], ["Marchesi", "Alberto", ""], ["Celli", "Andrea", ""], ["Gatti", "Nicola", ""]]}, {"id": "2106.06499", "submitter": "Daniel Brown", "authors": "Zaynah Javed, Daniel S. Brown, Satvik Sharma, Jerry Zhu, Ashwin\n  Balakrishna, Marek Petrik, Anca D. Dragan, Ken Goldberg", "title": "Policy Gradient Bayesian Robust Optimization for Imitation Learning", "comments": "In proceedings of the International Conference on Machine Learning\n  (ICML) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The difficulty in specifying rewards for many real-world problems has led to\nan increased focus on learning rewards from human feedback, such as\ndemonstrations. However, there are often many different reward functions that\nexplain the human feedback, leaving agents with uncertainty over what the true\nreward function is. While most policy optimization approaches handle this\nuncertainty by optimizing for expected performance, many applications demand\nrisk-averse behavior. We derive a novel policy gradient-style robust\noptimization approach, PG-BROIL, that optimizes a soft-robust objective that\nbalances expected performance and risk. To the best of our knowledge, PG-BROIL\nis the first policy optimization algorithm robust to a distribution of reward\nhypotheses which can scale to continuous MDPs. Results suggest that PG-BROIL\ncan produce a family of behaviors ranging from risk-neutral to risk-averse and\noutperforms state-of-the-art imitation learning algorithms when learning from\nambiguous demonstrations by hedging against uncertainty, rather than seeking to\nuniquely identify the demonstrator's reward function.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 16:49:15 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 22:27:50 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Javed", "Zaynah", ""], ["Brown", "Daniel S.", ""], ["Sharma", "Satvik", ""], ["Zhu", "Jerry", ""], ["Balakrishna", "Ashwin", ""], ["Petrik", "Marek", ""], ["Dragan", "Anca D.", ""], ["Goldberg", "Ken", ""]]}, {"id": "2106.06508", "submitter": "Nishanth Anand", "authors": "Nishanth Anand, Doina Precup", "title": "Preferential Temporal Difference Learning", "comments": "Accepted at the 38th International Conference on Machine Learning\n  (ICML, 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Temporal-Difference (TD) learning is a general and very useful tool for\nestimating the value function of a given policy, which in turn is required to\nfind good policies. Generally speaking, TD learning updates states whenever\nthey are visited. When the agent lands in a state, its value can be used to\ncompute the TD-error, which is then propagated to other states. However, it may\nbe interesting, when computing updates, to take into account other information\nthan whether a state is visited or not. For example, some states might be more\nimportant than others (such as states which are frequently seen in a successful\ntrajectory). Or, some states might have unreliable value estimates (for\nexample, due to partial observability or lack of data), making their values\nless desirable as targets. We propose an approach to re-weighting states used\nin TD updates, both when they are the input and when they provide the target\nfor the update. We prove that our approach converges with linear function\napproximation and illustrate its desirable empirical behaviour compared to\nother TD-style methods.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 17:05:15 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Anand", "Nishanth", ""], ["Precup", "Doina", ""]]}, {"id": "2106.06526", "submitter": "Shiji Zhou", "authors": "Shiji Zhou, Han Zhao, Shanghang Zhang, Lianzhe Wang, Heng Chang, Zhi\n  Wang, Wenwu Zhu", "title": "Online Continual Adaptation with Active Self-Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models trained with offline data often suffer from continual distribution\nshifts and expensive labeling in changing environments. This calls for a new\nonline learning paradigm where the learner can continually adapt to changing\nenvironments with limited labels. In this paper, we propose a new online\nsetting -- Online Active Continual Adaptation, where the learner aims to\ncontinually adapt to changing distributions using both unlabeled samples and\nactive queries of limited labels. To this end, we propose Online Self-Adaptive\nMirror Descent (OSAMD), which adopts an online teacher-student structure to\nenable online self-training from unlabeled data, and a margin-based criterion\nthat decides whether to query the labels to track changing distributions.\nTheoretically, we show that, in the separable case, OSAMD has an $O({T}^{1/2})$\ndynamic regret bound under mild assumptions, which is even tighter than the\nlower bound $\\Omega(T^{2/3})$ of traditional online learning with full labels.\nIn the general case, we show a regret bound of $O({\\alpha^*}^{1/3} {T}^{2/3} +\n\\alpha^* T)$, where $\\alpha^*$ denotes the separability of domains and is\nusually small. Our theoretical results show that OSAMD can fast adapt to\nchanging environments with active queries. Empirically, we demonstrate that\nOSAMD achieves favorable regrets under changing environments with limited\nlabels on both simulated and real-world data, which corroborates our\ntheoretical findings.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 17:51:25 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Zhou", "Shiji", ""], ["Zhao", "Han", ""], ["Zhang", "Shanghang", ""], ["Wang", "Lianzhe", ""], ["Chang", "Heng", ""], ["Wang", "Zhi", ""], ["Zhu", "Wenwu", ""]]}, {"id": "2106.06533", "submitter": "Anand Bhattad", "authors": "Anand Bhattad, Aysegul Dundar, Guilin Liu, Andrew Tao, Bryan Catanzaro", "title": "View Generalization for Single Image Textured 3D Models", "comments": "CVPR 2021. Project website:\n  https://nv-adlr.github.io/view-generalization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans can easily infer the underlying 3D geometry and texture of an object\nonly from a single 2D image. Current computer vision methods can do this, too,\nbut suffer from view generalization problems - the models inferred tend to make\npoor predictions of appearance in novel views. As for generalization problems\nin machine learning, the difficulty is balancing single-view accuracy (cf.\ntraining error; bias) with novel view accuracy (cf. test error; variance). We\ndescribe a class of models whose geometric rigidity is easily controlled to\nmanage this tradeoff. We describe a cycle consistency loss that improves view\ngeneralization (roughly, a model from a generated view should predict the\noriginal view well). View generalization of textures requires that models share\ntexture information, so a car seen from the back still has headlights because\nother cars have headlights. We describe a cycle consistency loss that\nencourages model textures to be aligned, so as to encourage sharing. We compare\nour method against the state-of-the-art method and show both qualitative and\nquantitative improvements.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 17:59:57 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Bhattad", "Anand", ""], ["Dundar", "Aysegul", ""], ["Liu", "Guilin", ""], ["Tao", "Andrew", ""], ["Catanzaro", "Bryan", ""]]}, {"id": "2106.06596", "submitter": "Kevin Roth", "authors": "Lorenzo Noci, Kevin Roth, Gregor Bachmann, Sebastian Nowozin and\n  Thomas Hofmann", "title": "Disentangling the Roles of Curation, Data-Augmentation and the Prior in\n  the Cold Posterior Effect", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \"cold posterior effect\" (CPE) in Bayesian deep learning describes the\nuncomforting observation that the predictive performance of Bayesian neural\nnetworks can be significantly improved if the Bayes posterior is artificially\nsharpened using a temperature parameter T<1. The CPE is problematic in theory\nand practice and since the effect was identified many researchers have proposed\nhypotheses to explain the phenomenon. However, despite this intensive research\neffort the effect remains poorly understood. In this work we provide novel and\nnuanced evidence relevant to existing explanations for the cold posterior\neffect, disentangling three hypotheses: 1. The dataset curation hypothesis of\nAitchison (2020): we show empirically that the CPE does not arise in a real\ncurated data set but can be produced in a controlled experiment with varying\ncuration strength. 2. The data augmentation hypothesis of Izmailov et al.\n(2021) and Fortuin et al. (2021): we show empirically that data augmentation is\nsufficient but not necessary for the CPE to be present. 3. The bad prior\nhypothesis of Wenzel et al. (2020): we use a simple experiment evaluating the\nrelative importance of the prior and the likelihood, strongly linking the CPE\nto the prior. Our results demonstrate how the CPE can arise in isolation from\nsynthetic curation, data augmentation, and bad priors. Cold posteriors observed\n\"in the wild\" are therefore unlikely to arise from a single simple cause; as a\nresult, we do not expect a simple \"fix\" for cold posteriors.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 20:04:20 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Noci", "Lorenzo", ""], ["Roth", "Kevin", ""], ["Bachmann", "Gregor", ""], ["Nowozin", "Sebastian", ""], ["Hofmann", "Thomas", ""]]}, {"id": "2106.06613", "submitter": "Johannes Treutlein", "authors": "Johannes Treutlein, Michael Dennis, Caspar Oesterheld, Jakob Foerster", "title": "A New Formalism, Method and Open Issues for Zero-Shot Coordination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In many coordination problems, independently reasoning humans are able to\ndiscover mutually compatible policies. In contrast, independently trained\nself-play policies are often mutually incompatible. Zero-shot coordination\n(ZSC) has recently been proposed as a new frontier in multi-agent reinforcement\nlearning to address this fundamental issue. Prior work approaches the ZSC\nproblem by assuming players can agree on a shared learning algorithm but not on\nlabels for actions and observations, and proposes other-play as an optimal\nsolution. However, until now, this \"label-free\" problem has only been\ninformally defined. We formalize this setting as the label-free coordination\n(LFC) problem by defining the label-free coordination game. We show that\nother-play is not an optimal solution to the LFC problem as it fails to\nconsistently break ties between incompatible maximizers of the other-play\nobjective. We introduce an extension of the algorithm, other-play with\ntie-breaking, and prove that it is optimal in the LFC problem and an\nequilibrium in the LFC game. Since arbitrary tie-breaking is precisely what the\nZSC setting aims to prevent, we conclude that the LFC problem does not reflect\nthe aims of ZSC. To address this, we introduce an alternative informal\noperationalization of ZSC as a starting point for future work.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 21:06:04 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 12:41:27 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Treutlein", "Johannes", ""], ["Dennis", "Michael", ""], ["Oesterheld", "Caspar", ""], ["Foerster", "Jakob", ""]]}, {"id": "2106.06621", "submitter": "Sam Greydanus", "authors": "Sam Greydanus, Stefan Lee, Alan Fern", "title": "Piecewise-constant Neural ODEs", "comments": "8 pages, 5 figures (not counting appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural networks are a popular tool for modeling sequential data but they\ngenerally do not treat time as a continuous variable. Neural ODEs represent an\nimportant exception: they parameterize the time derivative of a hidden state\nwith a neural network and then integrate over arbitrary amounts of time. But\nthese parameterizations, which have arbitrary curvature, can be hard to\nintegrate and thus train and evaluate. In this paper, we propose making a\npiecewise-constant approximation to Neural ODEs to mitigate these issues. Our\nmodel can be integrated exactly via Euler integration and can generate\nautoregressive samples in 3-20 times fewer steps than comparable RNN and\nODE-RNN models. We evaluate our model on several synthetic physics tasks and a\nplanning task inspired by the game of billiards. We find that it matches the\nperformance of baseline approaches while requiring less time to train and\nevaluate.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 21:46:55 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Greydanus", "Sam", ""], ["Lee", "Stefan", ""], ["Fern", "Alan", ""]]}, {"id": "2106.06680", "submitter": "Mridul Agarwal", "authors": "Mridul Agarwal, Qinbo Bai, and Vaneet Aggarwal", "title": "Markov Decision Processes with Long-Term Average Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of constrained Markov Decision Process (CMDP) where\nan agent interacts with a unichain Markov Decision Process. At every\ninteraction, the agent obtains a reward. Further, there are $K$ cost functions.\nThe agent aims to maximize the long-term average reward while simultaneously\nkeeping the $K$ long-term average costs lower than a certain threshold. In this\npaper, we propose CMDP-PSRL, a posterior sampling based algorithm using which\nthe agent can learn optimal policies to interact with the CMDP. Further, for\nMDP with $S$ states, $A$ actions, and diameter $D$, we prove that following\nCMDP-PSRL algorithm, the agent can bound the regret of not accumulating rewards\nfrom optimal policy by $\\Tilde{O}(poly(DSA)\\sqrt{T})$. Further, we show that\nthe violations for any of the $K$ constraints is also bounded by\n$\\Tilde{O}(poly(DSA)\\sqrt{T})$. To the best of our knowledge, this is the first\nwork which obtains a $\\Tilde{O}(\\sqrt{T})$ regret bounds for ergodic MDPs with\nlong-term average constraints.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 03:44:50 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Agarwal", "Mridul", ""], ["Bai", "Qinbo", ""], ["Aggarwal", "Vaneet", ""]]}, {"id": "2106.06683", "submitter": "Jialu Wang", "authors": "Jialu Wang, Yang Liu, Xin Eric Wang", "title": "Assessing Multilingual Fairness in Pre-trained Multimodal\n  Representations", "comments": "12 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently pre-trained multimodal models, such as CLIP, have received a surge\nof attention for their exceptional capabilities towards connecting images and\nnatural language. The textual representations in English can be desirably\ntransferred to multilingualism and support promising downstream multimodal\ntasks for different languages. Nevertheless, previous fairness discourse in\nvision-and-language learning mainly focuses on monolingual representational\nbiases, and rarely scrutinizes the principles of multilingual fairness in this\nmultimodal setting, where one language is equated to a group of individuals and\nimages provide the universal grounding for bridging different languages.\n  In this paper, we provide a nuanced understanding of individual fairness and\ngroup fairness by viewing language as the recipient of fairness notions. We\ndefine new fairness notions within multilingual context and analytically\narticulate that, pre-trained vision-and-language representations are\nindividually fair across languages but not guaranteed to group fairness.\nFurthermore, we conduct extensive experiments to explore the prevalent group\ndisparity across languages and protected groups including race, gender and age.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 03:57:05 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Wang", "Jialu", ""], ["Liu", "Yang", ""], ["Wang", "Xin Eric", ""]]}, {"id": "2106.06697", "submitter": "Francesco Ventura", "authors": "Francesco Ventura, Salvatore Greco, Daniele Apiletti, Tania\n  Cerquitelli", "title": "Explaining the Deep Natural Language Processing by Mining Textual\n  Interpretable Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the high accuracy offered by state-of-the-art deep natural-language\nmodels (e.g. LSTM, BERT), their application in real-life settings is still\nwidely limited, as they behave like a black-box to the end-user. Hence,\nexplainability is rapidly becoming a fundamental requirement of\nfuture-generation data-driven systems based on deep-learning approaches.\nSeveral attempts to fulfill the existing gap between accuracy and\ninterpretability have been done. However, robust and specialized xAI\n(Explainable Artificial Intelligence) solutions tailored to deep\nnatural-language models are still missing. We propose a new framework, named\nT-EBAnO, which provides innovative prediction-local and class-based\nmodel-global explanation strategies tailored to black-box deep natural-language\nmodels. Given a deep NLP model and the textual input data, T-EBAnO provides an\nobjective, human-readable, domain-specific assessment of the reasons behind the\nautomatic decision-making process. Specifically, the framework extracts sets of\ninterpretable features mining the inner knowledge of the model. Then, it\nquantifies the influence of each feature during the prediction process by\nexploiting the novel normalized Perturbation Influence Relation index at the\nlocal level and the novel Global Absolute Influence and Global Relative\nInfluence indexes at the global level. The effectiveness and the quality of the\nlocal and global explanations obtained with T-EBAnO are proved on (i) a\nsentiment analysis task performed by a fine-tuned BERT model, and (ii) a toxic\ncomment classification task performed by an LSTM model.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 06:25:09 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Ventura", "Francesco", ""], ["Greco", "Salvatore", ""], ["Apiletti", "Daniele", ""], ["Cerquitelli", "Tania", ""]]}, {"id": "2106.06713", "submitter": "Xiangyu Zhao", "authors": "Xiangyu Zhao, Haochen Liu, Wenqi Fan, Hui Liu, Jiliang Tang, Chong\n  Wang", "title": "AutoLoss: Automated Loss Function Search in Recommendations", "comments": "Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery\n  and Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Designing an effective loss function plays a crucial role in training deep\nrecommender systems. Most existing works often leverage a predefined and fixed\nloss function that could lead to suboptimal recommendation quality and training\nefficiency. Some recent efforts rely on exhaustively or manually searched\nweights to fuse a group of candidate loss functions, which is exceptionally\ncostly in computation and time. They also neglect the various convergence\nbehaviors of different data examples. In this work, we propose an AutoLoss\nframework that can automatically and adaptively search for the appropriate loss\nfunction from a set of candidates. To be specific, we develop a novel\ncontroller network, which can dynamically adjust the loss probabilities in a\ndifferentiable manner. Unlike existing algorithms, the proposed controller can\nadaptively generate the loss probabilities for different data examples\naccording to their varied convergence behaviors. Such design improves the\nmodel's generalizability and transferability between deep recommender systems\nand datasets. We evaluate the proposed framework on two benchmark datasets. The\nresults show that AutoLoss outperforms representative baselines. Further\nexperiments have been conducted to deepen our understandings of AutoLoss,\nincluding its transferability, components and training efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 08:15:00 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Zhao", "Xiangyu", ""], ["Liu", "Haochen", ""], ["Fan", "Wenqi", ""], ["Liu", "Hui", ""], ["Tang", "Jiliang", ""], ["Wang", "Chong", ""]]}, {"id": "2106.06718", "submitter": "Nicol\\`o Oreste Pinciroli Vago", "authors": "Nicol\\`o Oreste Pinciroli Vago, Ibrahim A. Hameed and Michael\n  Kachelriess", "title": "Using Convolutional Neural Networks for the Helicity Classification of\n  Magnetic Fields", "comments": "14 pages, extended version of a contribution to the proceedings of\n  the 37.th ICRC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.HE cs.AI cs.CV cs.LG hep-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presence of non-zero helicity in intergalactic magnetic fields is a\nsmoking gun for their primordial origin since they have to be generated by\nprocesses that break CP invariance. As an experimental signature for the\npresence of helical magnetic fields, an estimator $Q$ based on the triple\nscalar product of the wave-vectors of photons generated in electromagnetic\ncascades from, e.g., TeV blazars, has been suggested previously. We propose to\napply deep learning to helicity classification employing Convolutional Neural\nNetworks and show that this method outperforms the $Q$ estimator.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 08:48:25 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Vago", "Nicol\u00f2 Oreste Pinciroli", ""], ["Hameed", "Ibrahim A.", ""], ["Kachelriess", "Michael", ""]]}, {"id": "2106.06739", "submitter": "L Siddharth", "authors": "L Siddharth, Lucienne T.M. Blessing, Kristin L. Wood, Jianxi Luo", "title": "Engineering Knowledge Graph from Patent Database", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a large, scalable engineering knowledge graph, comprising sets of\n(entity, relationship, entity) triples that are real-world engineering facts\nfound in the patent database. We apply a set of rules based on the syntactic\nand lexical properties of claims in a patent document to extract facts. We\naggregate these facts within each patent document and integrate the aggregated\nsets of facts across the patent database to obtain the engineering knowledge\ngraph. Such a knowledge graph is expected to support inference, reasoning, and\nrecalling in various engineering tasks. The knowledge graph has a greater size\nand coverage in comparison with the previously used knowledge graphs and\nsemantic networks in the engineering literature.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 10:54:31 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Siddharth", "L", ""], ["Blessing", "Lucienne T. M.", ""], ["Wood", "Kristin L.", ""], ["Luo", "Jianxi", ""]]}, {"id": "2106.06762", "submitter": "Victor-Alexandru Darvariu", "authors": "Victor-Alexandru Darvariu, Stephen Hailes, Mirco Musolesi", "title": "Solving Graph-based Public Good Games with Tree Search and Imitation\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public goods games represent insightful settings for studying incentives for\nindividual agents to make contributions that, while costly for each of them,\nbenefit the wider society. In this work, we adopt the perspective of a central\nplanner with a global view of a network of self-interested agents and the goal\nof maximizing some desired property in the context of a best-shot public goods\ngame. Existing algorithms for this known NP-complete problem find solutions\nthat are sub-optimal and cannot optimize for criteria other than social\nwelfare.\n  In order to efficiently solve public goods games, our proposed method\ndirectly exploits the correspondence between equilibria and the Maximal\nIndependent Set (mIS) structural property of graphs. In particular, we define a\nMarkov Decision Process, which incrementally generates an mIS, and adopt a\nplanning method to search for equilibria, outperforming existing methods.\nFurthermore, we devise an imitation learning technique that uses demonstrations\nof the search to obtain a graph neural network parametrized policy which\nquickly generalizes to unseen game instances. Our evaluation results show that\nthis policy is able to reach 99.5% of the performance of the planning method\nwhile being approximately three orders of magnitude faster to evaluate on the\nlargest graphs tested. The methods presented in this work can be applied to a\nlarge class of public goods games of potentially high societal impact.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 12:46:44 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Darvariu", "Victor-Alexandru", ""], ["Hailes", "Stephen", ""], ["Musolesi", "Mirco", ""]]}, {"id": "2106.06768", "submitter": "Victor-Alexandru Darvariu", "authors": "Victor-Alexandru Darvariu, Stephen Hailes, Mirco Musolesi", "title": "Planning Spatial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of goal-directed graph construction: given a starting\ngraph, a global objective function (e.g., communication efficiency), and a\nbudget of modifications, the aim is to find a set of edges whose addition to\nthe graph maximally improves the objective. This problem emerges in many\nnetworks of great importance for society such as transportation and critical\ninfrastructure networks. We identify two significant shortcomings with present\nmethods. Firstly, they focus exclusively on network topology while ignoring\nspatial information; however, in many real-world networks, nodes are embedded\nin space, which yields different global objectives and governs the range and\ndensity of realizable connections. Secondly, existing RL methods scale poorly\nto large networks due to the high cost of training a model and the scaling\nfactors of the action space and global objectives.\n  In this work, we formulate the problem of goal-directed construction of\nspatial networks as a deterministic MDP. We adopt the Monte Carlo Tree Search\nframework for planning in this domain, prioritizing the optimality of final\nsolutions over the speed of policy evaluation. We propose several improvements\nover the standard UCT algorithm for this family of problems, addressing their\nsingle-agent nature, the trade-off between the costs of edges and their\ncontribution to the objective, and an action space linear in the number of\nnodes. We demonstrate the suitability of this approach for improving the global\nefficiency and attack resilience of a variety of synthetic and real-world\nnetworks, including Internet backbone networks and metro systems. We obtain 24%\nbetter solutions on average compared to UCT on the largest networks tested, and\nscalability superior to previous methods.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 13:01:11 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Darvariu", "Victor-Alexandru", ""], ["Hailes", "Stephen", ""], ["Musolesi", "Mirco", ""]]}, {"id": "2106.06770", "submitter": "Guillermo Ortiz-Jimenez", "authors": "Guillermo Ortiz-Jim\\'enez, Seyed-Mohsen Moosavi-Dezfooli, Pascal\n  Frossard", "title": "What can linearized neural networks actually say about generalization?", "comments": "17 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For certain infinitely-wide neural networks, the neural tangent kernel (NTK)\ntheory fully characterizes generalization. However, for the networks used in\npractice, the empirical NTK represents only a rough first-order approximation\nof these architectures. Still, a growing body of work keeps leveraging this\napproximation to successfully analyze important deep learning phenomena and\nderive algorithms for new applications. In our work, we provide strong\nempirical evidence to determine the practical validity of such approximation by\nconducting a systematic comparison of the behaviour of different neural\nnetworks and their linear approximations on different tasks. We show that the\nlinear approximations can indeed rank the learning complexity of certain tasks\nfor neural networks, albeit with important nuances. Specifically, we discover\nthat, in contrast to what was previously observed, neural networks do not\nalways perform better than their kernel approximations, and reveal that their\nperformance gap heavily depends on architecture, number of samples and training\ntask. In fact, we show that during training, deep networks increase the\nalignment of their empirical NTK with the target task, which explains why\nlinear approximations at the end of training can better explain the dynamics of\ndeep networks. Overall, our work provides concrete examples of novel deep\nlearning phenomena which can inspire future theoretical research, as well as\nprovides a new perspective on the use of the NTK approximation in deep\nlearning.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 13:05:11 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Ortiz-Jim\u00e9nez", "Guillermo", ""], ["Moosavi-Dezfooli", "Seyed-Mohsen", ""], ["Frossard", "Pascal", ""]]}, {"id": "2106.06780", "submitter": "Stefania  Costantini", "authors": "Pedro Cabalar and Stefania Costantini and Giovanni De Gasperis and\n  Andrea Formisano", "title": "Multi-Context Systems: Dynamics and Evolution (Pre-Print of\n  \"Multi-context systems in dynamic environments\")", "comments": "35 pages 2 figures", "journal-ref": "Annals of Mathematics and Artificial Intelligence 86, 87-120\n  (2019)", "doi": "10.1007/s10472-019-09622-0", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Context Systems (MCS) model in Computational Logic distributed systems\ncomposed of heterogeneous sources, or \"contexts\", interacting via special rules\ncalled \"bridge rules\". In this paper, we consider how to enhance flexibility\nand generality in bridge-rules definition and application. In particular, we\nintroduce and discuss some formal extensions of MCSs useful for a practical use\nin dynamic environments, and we try to provide guidelines for implementations\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 13:52:49 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Cabalar", "Pedro", ""], ["Costantini", "Stefania", ""], ["De Gasperis", "Giovanni", ""], ["Formisano", "Andrea", ""]]}, {"id": "2106.06788", "submitter": "Qiufeng Wang", "authors": "Qiufeng Wang, Xin Geng, Shuxia Lin, Shiyu Xia, Lei Qi, Ning Xu", "title": "Learngene: From Open-World to Your Learning Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep learning has made significant progress on fixed large-scale\ndatasets, it typically encounters challenges regarding improperly detecting\nnew/unseen classes in the open-world classification, over-parametrized, and\noverfitting small samples. In contrast, biological systems can overcome the\nabove difficulties very well. Individuals inherit an innate gene from\ncollective creatures that have evolved over hundreds of millions of years, and\ncan learn new skills through a few examples. Inspired by this, we propose a\npractical collective-individual paradigm where open-world tasks are trained in\nsequence using an evolution (expandable) network. To be specific, we\ninnovatively introduce learngene that inherits the meta-knowledge from the\ncollective model and reconstructs a new lightweight individual model for the\ntarget task, to realize the collective-individual paradigm. Particularly, we\npresent a novel criterion that can discover the learngene in the collective\nmodel, according to the gradient information. Finally, the individual model is\ntrained only with a few samples in the absence of the source data. We\ndemonstrate the effectiveness of our approach in an extensive empirical study\nand theoretical analysis.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 14:46:27 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Wang", "Qiufeng", ""], ["Geng", "Xin", ""], ["Lin", "Shuxia", ""], ["Xia", "Shiyu", ""], ["Qi", "Lei", ""], ["Xu", "Ning", ""]]}, {"id": "2106.06795", "submitter": "Pravendra Singh", "authors": "Mohammed Asad Karim, Vinay Kumar Verma, Pravendra Singh, Vinay\n  Namboodiri, Piyush Rai", "title": "Knowledge Consolidation based Class Incremental Online Learning with\n  Limited Data", "comments": "International Joint Conference on Artificial Intelligence\n  (IJCAI-2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel approach for class incremental online learning in a\nlimited data setting. This problem setting is challenging because of the\nfollowing constraints: (1) Classes are given incrementally, which necessitates\na class incremental learning approach; (2) Data for each class is given in an\nonline fashion, i.e., each training example is seen only once during training;\n(3) Each class has very few training examples; and (4) We do not use or assume\naccess to any replay/memory to store data from previous classes. Therefore, in\nthis setting, we have to handle twofold problems of catastrophic forgetting and\noverfitting. In our approach, we learn robust representations that are\ngeneralizable across tasks without suffering from the problems of catastrophic\nforgetting and overfitting to accommodate future classes with limited samples.\nOur proposed method leverages the meta-learning framework with knowledge\nconsolidation. The meta-learning framework helps the model for rapid learning\nwhen samples appear in an online fashion. Simultaneously, knowledge\nconsolidation helps to learn a robust representation against forgetting under\nonline updates to facilitate future learning. Our approach significantly\noutperforms other methods on several benchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 15:18:29 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Karim", "Mohammed Asad", ""], ["Verma", "Vinay Kumar", ""], ["Singh", "Pravendra", ""], ["Namboodiri", "Vinay", ""], ["Rai", "Piyush", ""]]}, {"id": "2106.06799", "submitter": "Hongkai Wen", "authors": "Lichuan Xiang, {\\L}ukasz Dudziak, Mohamed S. Abdelfattah, Thomas Chau,\n  Nicholas D. Lane, Hongkai Wen", "title": "Zero-Cost Proxies Meet Differentiable Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Differentiable neural architecture search (NAS) has attracted significant\nattention in recent years due to its ability to quickly discover promising\narchitectures of deep neural networks even in very large search spaces. Despite\nits success, DARTS lacks robustness in certain cases, e.g. it may degenerate to\ntrivial architectures with excessive parametric-free operations such as skip\nconnection or random noise, leading to inferior performance. In particular,\noperation selection based on the magnitude of architectural parameters was\nrecently proven to be fundamentally wrong showcasing the need to rethink this\naspect. On the other hand, zero-cost proxies have been recently studied in the\ncontext of sample-based NAS showing promising results -- speeding up the search\nprocess drastically in some cases but also failing on some of the large search\nspaces typical for differentiable NAS. In this work we propose a novel\noperation selection paradigm in the context of differentiable NAS which\nutilises zero-cost proxies. Our perturbation-based zero-cost operation\nselection (Zero-Cost-PT) improves searching time and, in many cases, accuracy\ncompared to the best available differentiable architecture search, regardless\nof the search space size. Specifically, we are able to find comparable\narchitectures to DARTS-PT on the DARTS CNN search space while being over 40x\nfaster (total searching time 25 minutes on a single GPU).\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 15:33:36 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Xiang", "Lichuan", ""], ["Dudziak", "\u0141ukasz", ""], ["Abdelfattah", "Mohamed S.", ""], ["Chau", "Thomas", ""], ["Lane", "Nicholas D.", ""], ["Wen", "Hongkai", ""]]}, {"id": "2106.06804", "submitter": "Pietro Barbiero", "authors": "Pietro Barbiero, Gabriele Ciravegna, Francesco Giannini, Pietro Li\\'o,\n  Marco Gori, Stefano Melacci", "title": "Entropy-based Logic Explanations of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable artificial intelligence has rapidly emerged since lawmakers have\nstarted requiring interpretable models for safety-critical domains.\nConcept-based neural networks have arisen as explainable-by-design methods as\nthey leverage human-understandable symbols (i.e. concepts) to predict class\nmemberships. However, most of these approaches focus on the identification of\nthe most relevant concepts but do not provide concise, formal explanations of\nhow such concepts are leveraged by the classifier to make predictions. In this\npaper, we propose a novel end-to-end differentiable approach enabling the\nextraction of logic explanations from neural networks using the formalism of\nFirst-Order Logic. The method relies on an entropy-based criterion which\nautomatically identifies the most relevant concepts. We consider four different\ncase studies to demonstrate that: (i) this entropy-based criterion enables the\ndistillation of concise logic explanations in safety-critical domains from\nclinical data to computer vision; (ii) the proposed approach outperforms\nstate-of-the-art white-box models in terms of classification accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 15:50:47 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 09:52:47 GMT"}, {"version": "v3", "created": "Tue, 22 Jun 2021 14:06:17 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Barbiero", "Pietro", ""], ["Ciravegna", "Gabriele", ""], ["Giannini", "Francesco", ""], ["Li\u00f3", "Pietro", ""], ["Gori", "Marco", ""], ["Melacci", "Stefano", ""]]}, {"id": "2106.06815", "submitter": "Tom Hanika", "authors": "Tom Hanika and Johannes Hirth", "title": "Quantifying the Conceptual Error in Dimensionality Reduction", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimension reduction of data sets is a standard problem in the realm of\nmachine learning and knowledge reasoning. They affect patterns in and\ndependencies on data dimensions and ultimately influence any decision-making\nprocesses. Therefore, a wide variety of reduction procedures are in use, each\npursuing different objectives. A so far not considered criterion is the\nconceptual continuity of the reduction mapping, i.e., the preservation of the\nconceptual structure with respect to the original data set. Based on the notion\nscale-measure from formal concept analysis we present in this work a) the\ntheoretical foundations to detect and quantify conceptual errors in data\nscalings; b) an experimental investigation of our approach on eleven data sets\nthat were respectively treated with a variant of non-negative matrix\nfactorization.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 16:28:19 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Hanika", "Tom", ""], ["Hirth", "Johannes", ""]]}, {"id": "2106.06819", "submitter": "Jiaming Song", "authors": "Abhishek Sinha, Jiaming Song, Chenlin Meng, Stefano Ermon", "title": "D2C: Diffusion-Denoising Models for Few-shot Conditional Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional generative models of high-dimensional images have many\napplications, but supervision signals from conditions to images can be\nexpensive to acquire. This paper describes Diffusion-Decoding models with\nContrastive representations (D2C), a paradigm for training unconditional\nvariational autoencoders (VAEs) for few-shot conditional image generation. D2C\nuses a learned diffusion-based prior over the latent representations to improve\ngeneration and contrastive self-supervised learning to improve representation\nquality. D2C can adapt to novel generation tasks conditioned on labels or\nmanipulation constraints, by learning from as few as 100 labeled examples. On\nconditional generation from new labels, D2C achieves superior performance over\nstate-of-the-art VAEs and diffusion models. On conditional image manipulation,\nD2C generations are two orders of magnitude faster to produce over StyleGAN2\nones and are preferred by 50% - 60% of the human evaluators in a double-blind\nstudy.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 16:32:30 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Sinha", "Abhishek", ""], ["Song", "Jiaming", ""], ["Meng", "Chenlin", ""], ["Ermon", "Stefano", ""]]}, {"id": "2106.06823", "submitter": "Bhargavi Paranjape", "authors": "Bhargavi Paranjape, Julian Michael, Marjan Ghazvininejad, Luke\n  Zettlemoyer and Hannaneh Hajishirzi", "title": "Prompting Contrastive Explanations for Commonsense Reasoning Tasks", "comments": "ACL 2021 Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many commonsense reasoning NLP tasks involve choosing between one or more\npossible answers to a question or prompt based on knowledge that is often\nimplicit. Large pretrained language models (PLMs) can achieve near-human\nperformance on such tasks, while providing little human-interpretable evidence\nof the underlying reasoning they use. In this work, we show how to use these\nsame models to generate such evidence: inspired by the contrastive nature of\nhuman explanations, we use PLMs to complete explanation prompts which contrast\nalternatives according to the key attribute(s) required to justify the correct\nanswer (for example, peanuts are usually salty while raisins are sweet).\nConditioning model decisions on these explanations improves performance on two\ncommonsense reasoning benchmarks, as compared to previous non-contrastive\nalternatives. These explanations are also judged by humans to be more relevant\nfor solving the task, and facilitate a novel method to evaluate explanation\nfaithfulfness.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 17:06:13 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Paranjape", "Bhargavi", ""], ["Michael", "Julian", ""], ["Ghazvininejad", "Marjan", ""], ["Zettlemoyer", "Luke", ""], ["Hajishirzi", "Hannaneh", ""]]}, {"id": "2106.06828", "submitter": "Ying Wen", "authors": "Ying Wen, Hui Chen, Yaodong Yang, Zheng Tian, Minne Li, Xu Chen, Jun\n  Wang", "title": "A Game-Theoretic Approach to Multi-Agent Trust Region Optimization", "comments": "A Multi-Agent Trust Region Learning (MATRL) algorithm that augments\n  the single-agent trust region policy optimization with a weak stable fixed\n  point approximated by the policy-space meta-game", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Trust region methods are widely applied in single-agent reinforcement\nlearning problems due to their monotonic performance-improvement guarantee at\nevery iteration. Nonetheless, when applied in multi-agent settings, the\nguarantee of trust region methods no longer holds because an agent's payoff is\nalso affected by other agents' adaptive behaviors. To tackle this problem, we\nconduct a game-theoretical analysis in the policy space, and propose a\nmulti-agent trust region learning method (MATRL), which enables trust region\noptimization for multi-agent learning. Specifically, MATRL finds a stable\nimprovement direction that is guided by the solution concept of Nash\nequilibrium at the meta-game level. We derive the monotonic improvement\nguarantee in multi-agent settings and empirically show the local convergence of\nMATRL to stable fixed points in the two-player rotational differential game. To\ntest our method, we evaluate MATRL in both discrete and continuous multiplayer\ngeneral-sum games including checker and switch grid worlds, multi-agent MuJoCo,\nand Atari games. Results suggest that MATRL significantly outperforms strong\nmulti-agent reinforcement learning baselines.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 18:21:26 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Wen", "Ying", ""], ["Chen", "Hui", ""], ["Yang", "Yaodong", ""], ["Tian", "Zheng", ""], ["Li", "Minne", ""], ["Chen", "Xu", ""], ["Wang", "Jun", ""]]}, {"id": "2106.06842", "submitter": "Elad Sarafian", "authors": "Shai Keynan, Elad Sarafian and Sarit Kraus", "title": "Recomposing the Reinforcement Learning Building Blocks with\n  Hypernetworks", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Reinforcement Learning (RL) building blocks, i.e. Q-functions and policy\nnetworks, usually take elements from the cartesian product of two domains as\ninput. In particular, the input of the Q-function is both the state and the\naction, and in multi-task problems (Meta-RL) the policy can take a state and a\ncontext. Standard architectures tend to ignore these variables' underlying\ninterpretations and simply concatenate their features into a single vector. In\nthis work, we argue that this choice may lead to poor gradient estimation in\nactor-critic algorithms and high variance learning steps in Meta-RL algorithms.\nTo consider the interaction between the input variables, we suggest using a\nHypernetwork architecture where a primary network determines the weights of a\nconditional dynamic network. We show that this approach improves the gradient\napproximation and reduces the learning step variance, which both accelerates\nlearning and improves the final performance. We demonstrate a consistent\nimprovement across different locomotion tasks and different algorithms both in\nRL (TD3 and SAC) and in Meta-RL (MAML and PEARL).\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 19:43:12 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Keynan", "Shai", ""], ["Sarafian", "Elad", ""], ["Kraus", "Sarit", ""]]}, {"id": "2106.06854", "submitter": "Scott Fujimoto", "authors": "Scott Fujimoto, David Meger, Doina Precup", "title": "A Deep Reinforcement Learning Approach to Marginalized Importance\n  Sampling with the Successor Representation", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Marginalized importance sampling (MIS), which measures the density ratio\nbetween the state-action occupancy of a target policy and that of a sampling\ndistribution, is a promising approach for off-policy evaluation. However,\ncurrent state-of-the-art MIS methods rely on complex optimization tricks and\nsucceed mostly on simple toy problems. We bridge the gap between MIS and deep\nreinforcement learning by observing that the density ratio can be computed from\nthe successor representation of the target policy. The successor representation\ncan be trained through deep reinforcement learning methodology and decouples\nthe reward optimization from the dynamics of the environment, making the\nresulting algorithm stable and applicable to high-dimensional domains. We\nevaluate the empirical performance of our approach on a variety of challenging\nAtari and MuJoCo environments.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 20:21:38 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Fujimoto", "Scott", ""], ["Meger", "David", ""], ["Precup", "Doina", ""]]}, {"id": "2106.06860", "submitter": "Scott Fujimoto", "authors": "Scott Fujimoto, Shixiang Shane Gu", "title": "A Minimalist Approach to Offline Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Offline reinforcement learning (RL) defines the task of learning from a fixed\nbatch of data. Due to errors in value estimation from out-of-distribution\nactions, most offline RL algorithms take the approach of constraining or\nregularizing the policy with the actions contained in the dataset. Built on\npre-existing RL algorithms, modifications to make an RL algorithm work offline\ncomes at the cost of additional complexity. Offline RL algorithms introduce new\nhyperparameters and often leverage secondary components such as generative\nmodels, while adjusting the underlying RL algorithm. In this paper we aim to\nmake a deep RL algorithm work while making minimal changes. We find that we can\nmatch the performance of state-of-the-art offline RL algorithms by simply\nadding a behavior cloning term to the policy update of an online RL algorithm\nand normalizing the data. The resulting algorithm is a simple to implement and\ntune baseline, while more than halving the overall run time by removing the\nadditional computational overheads of previous methods.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 20:38:59 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Fujimoto", "Scott", ""], ["Gu", "Shixiang Shane", ""]]}, {"id": "2106.06895", "submitter": "Tolulope Odetola", "authors": "Tolulope Odetola, Faiq Khalid, Travis Sandefur, Hawzhin Mohammed and\n  Syed Rafay Hasan", "title": "FeSHI: Feature Map Based Stealthy Hardware Intrinsic Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNN) have shown impressive performance in\ncomputer vision, natural language processing, and many other applications, but\nthey exhibit high computations and substantial memory requirements. To address\nthese limitations, especially in resource-constrained devices, the use of cloud\ncomputing for CNNs is becoming more popular. This comes with privacy and\nlatency concerns that have motivated the designers to develop embedded hardware\naccelerators for CNNs. However, designing a specialized accelerator increases\nthe time-to-market and cost of production. Therefore, to reduce the\ntime-to-market and access to state-of-the-art techniques, CNN hardware mapping\nand deployment on embedded accelerators are often outsourced to untrusted third\nparties, which is going to be more prevalent in futuristic artificial\nintelligence of things (AIoT) systems. These AIoT systems anticipate horizontal\ncollaboration among different resource-constrained AIoT node devices, where CNN\nlayers are partitioned and these devices collaboratively compute complex CNN\ntasks Therefore, there is a dire need to explore this attack surface for\ndesigning secure embedded hardware accelerators for CNNs. Towards this goal, in\nthis paper, we exploited this attack surface to propose an HT-based attack\ncalled FeSHI. This attack exploits the statistical distribution i.e., Gaussian\ndistribution, of the layer-by-layer feature maps of the CNN to design two\ntriggers for stealthy HT with a very low probability of triggering. To\nillustrate the effectiveness of the proposed attack, we deployed the LeNet and\nLeNet-3D on PYNQ to classify the MNIST and CIFAR-10 datasets, respectively, and\ntested FeSHI. The experimental results show that FeSHI utilizes up to 2% extra\nLUTs, and the overall resource overhead is less than 1% compared to the\noriginal designs\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 01:50:34 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Odetola", "Tolulope", ""], ["Khalid", "Faiq", ""], ["Sandefur", "Travis", ""], ["Mohammed", "Hawzhin", ""], ["Hasan", "Syed Rafay", ""]]}, {"id": "2106.06907", "submitter": "Linan Huang", "authors": "Linan Huang and Quanyan Zhu", "title": "INADVERT: An Interactive and Adaptive Counterdeception Platform for\n  Attention Enhancement and Phishing Prevention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deceptive attacks exploiting the innate and the acquired vulnerabilities of\nhuman users have posed severe threats to information and infrastructure\nsecurity. This work proposes INADVERT, a systematic solution that generates\ninteractive visual aids in real-time to prevent users from inadvertence and\ncounter visual-deception attacks. Based on the eye-tracking outcomes and proper\ndata compression, the INADVERT platform automatically adapts the visual aids to\nthe user's varying attention status captured by the gaze location and duration.\nWe extract system-level metrics to evaluate the user's average attention level\nand characterize the magnitude and frequency of the user's mind-wandering\nbehaviors. These metrics contribute to an adaptive enhancement of the user's\nattention through reinforcement learning. To determine the optimal\nhyper-parameters in the attention enhancement mechanism, we develop an\nalgorithm based on Bayesian optimization to efficiently update the design of\nthe INADVERT platform and maximize the accuracy of the users' phishing\nrecognition.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 03:52:55 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Huang", "Linan", ""], ["Zhu", "Quanyan", ""]]}, {"id": "2106.06908", "submitter": "Chenxin Li", "authors": "Chenxin Li, Qi Qi, Xinghao Ding, Yue Huang, Dong Liang and Yizhou Yu", "title": "Domain Generalization on Medical Imaging Classification using Episodic\n  Training with Task Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Medical imaging datasets usually exhibit domain shift due to the variations\nof scanner vendors, imaging protocols, etc. This raises the concern about the\ngeneralization capacity of machine learning models. Domain generalization (DG),\nwhich aims to learn a model from multiple source domains such that it can be\ndirectly generalized to unseen test domains, seems particularly promising to\nmedical imaging community. To address DG, recent model-agnostic meta-learning\n(MAML) has been introduced, which transfers the knowledge from previous\ntraining tasks to facilitate the learning of novel testing tasks. However, in\nclinical practice, there are usually only a few annotated source domains\navailable, which decreases the capacity of training task generation and thus\nincreases the risk of overfitting to training tasks in the paradigm. In this\npaper, we propose a novel DG scheme of episodic training with task augmentation\non medical imaging classification. Based on meta-learning, we develop the\nparadigm of episodic training to construct the knowledge transfer from episodic\ntraining-task simulation to the real testing task of DG. Motivated by the\nlimited number of source domains in real-world medical deployment, we consider\nthe unique task-level overfitting and we propose task augmentation to enhance\nthe variety during training task generation to alleviate it. With the\nestablished learning framework, we further exploit a novel meta-objective to\nregularize the deep embedding of training domains. To validate the\neffectiveness of the proposed method, we perform experiments on\nhistopathological images and abdominal CT images.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 03:56:59 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Li", "Chenxin", ""], ["Qi", "Qi", ""], ["Ding", "Xinghao", ""], ["Huang", "Yue", ""], ["Liang", "Dong", ""], ["Yu", "Yizhou", ""]]}, {"id": "2106.06926", "submitter": "Tengyang Xie", "authors": "Tengyang Xie, Ching-An Cheng, Nan Jiang, Paul Mineiro, Alekh Agarwal", "title": "Bellman-consistent Pessimism for Offline Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of pessimism, when reasoning about datasets lacking exhaustive\nexploration has recently gained prominence in offline reinforcement learning.\nDespite the robustness it adds to the algorithm, overly pessimistic reasoning\ncan be equally damaging in precluding the discovery of good policies, which is\nan issue for the popular bonus-based pessimism. In this paper, we introduce the\nnotion of Bellman-consistent pessimism for general function approximation:\ninstead of calculating a point-wise lower bound for the value function, we\nimplement pessimism at the initial state over the set of functions consistent\nwith the Bellman equations. Our theoretical guarantees only require Bellman\nclosedness as standard in the exploratory setting, in which case bonus-based\npessimism fails to provide guarantees. Even in the special case of linear MDPs\nwhere stronger function-approximation assumptions hold, our result improves\nupon a recent bonus-based approach by $\\mathcal{O}(d)$ in its sample complexity\nwhen the action space is finite. Remarkably, our algorithms automatically adapt\nto the best bias-variance tradeoff in the hindsight, whereas most prior\napproaches require tuning extra hyperparameters a priori.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 05:50:36 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 21:58:54 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Xie", "Tengyang", ""], ["Cheng", "Ching-An", ""], ["Jiang", "Nan", ""], ["Mineiro", "Paul", ""], ["Agarwal", "Alekh", ""]]}, {"id": "2106.06931", "submitter": "Min Zhang", "authors": "Peng Jin, Min Zhang, Jianwen Li, Li Han, Xuejun Wen", "title": "Learning on Abstract Domains: A New Approach for Verifiable Guarantee in\n  Reinforcement Learning", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Formally verifying Deep Reinforcement Learning (DRL) systems is a challenging\ntask due to the dynamic continuity of system behaviors and the black-box\nfeature of embedded neural networks. In this paper, we propose a novel\nabstraction-based approach to train DRL systems on finite abstract domains\ninstead of concrete system states. It yields neural networks whose input states\nare finite, making hosting DRL systems directly verifiable using model checking\ntechniques. Our approach is orthogonal to existing DRL algorithms and\noff-the-shelf model checkers. We implement a resulting prototype training and\nverification framework and conduct extensive experiments on the\nstate-of-the-art benchmark. The results show that the systems trained in our\napproach can be verified more efficiently while they retain comparable\nperformance against those that are trained without abstraction.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 06:28:40 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Jin", "Peng", ""], ["Zhang", "Min", ""], ["Li", "Jianwen", ""], ["Han", "Li", ""], ["Wen", "Xuejun", ""]]}, {"id": "2106.06932", "submitter": "Junfeng Wen", "authors": "Junfeng Wen, Saurabh Kumar, Ramki Gummadi, Dale Schuurmans", "title": "Characterizing the Gap Between Actor-Critic and Policy Gradient", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Actor-critic (AC) methods are ubiquitous in reinforcement learning. Although\nit is understood that AC methods are closely related to policy gradient (PG),\ntheir precise connection has not been fully characterized previously. In this\npaper, we explain the gap between AC and PG methods by identifying the exact\nadjustment to the AC objective/gradient that recovers the true policy gradient\nof the cumulative reward objective (PG). Furthermore, by viewing the AC method\nas a two-player Stackelberg game between the actor and critic, we show that the\nStackelberg policy gradient can be recovered as a special case of our more\ngeneral analysis. Based on these results, we develop practical algorithms,\nResidual Actor-Critic and Stackelberg Actor-Critic, for estimating the\ncorrection between AC and PG and use these to modify the standard AC algorithm.\nExperiments on popular tabular and continuous environments show the proposed\ncorrections can improve both the sample efficiency and final performance of\nexisting AC methods.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 06:35:42 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Wen", "Junfeng", ""], ["Kumar", "Saurabh", ""], ["Gummadi", "Ramki", ""], ["Schuurmans", "Dale", ""]]}, {"id": "2106.06933", "submitter": "Amin Shahraki", "authors": "Amin Shahraki, Mahmoud Abbasi, Amir Taherkordi and Anca Delia Jurcut", "title": "Active Learning for Network Traffic Classification: A Technical Survey", "comments": "This work has been submitted to the IEEE Transactions on Cognitive\n  Communications and Networking journal for possible publication. Copyright may\n  be transferred without notice, after which this version may no longer be\n  accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Network Traffic Classification (NTC) has become an important component in a\nwide variety of network management operations, e.g., Quality of Service (QoS)\nprovisioning and security purposes. Machine Learning (ML) algorithms as a\ncommon approach for NTC methods can achieve reasonable accuracy and handle\nencrypted traffic. However, ML-based NTC techniques suffer from the shortage of\nlabeled traffic data which is the case in many real-world applications. This\nstudy investigates the applicability of an active form of ML, called Active\nLearning (AL), which reduces the need for a high number of labeled examples by\nactively choosing the instances that should be labeled. The study first\nprovides an overview of NTC and its fundamental challenges along with surveying\nthe literature in the field of using ML techniques in NTC. Then, it introduces\nthe concepts of AL, discusses it in the context of NTC, and review the\nliterature in this field. Further, challenges and open issues in the use of AL\nfor NTC are discussed. Additionally, as a technical survey, some experiments\nare conducted to show the broad applicability of AL in NTC. The simulation\nresults show that AL can achieve high accuracy with a small amount of data.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 06:37:50 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Shahraki", "Amin", ""], ["Abbasi", "Mahmoud", ""], ["Taherkordi", "Amir", ""], ["Jurcut", "Anca Delia", ""]]}, {"id": "2106.06937", "submitter": "Bill Yuchen Lin", "authors": "Bill Yuchen Lin, Seyeon Lee, Xiaoyang Qiao, Xiang Ren", "title": "Common Sense Beyond English: Evaluating and Improving Multilingual\n  Language Models for Commonsense Reasoning", "comments": "Accepted to ACL-IJCNLP 2021 (long paper at main conference). Project\n  website: https://inklab.usc.edu/XCSR/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Commonsense reasoning research has so far been limited to English. We aim to\nevaluate and improve popular multilingual language models (ML-LMs) to help\nadvance commonsense reasoning (CSR) beyond English. We collect the Mickey\nCorpus, consisting of 561k sentences in 11 different languages, which can be\nused for analyzing and improving ML-LMs. We propose Mickey Probe, a\nlanguage-agnostic probing task for fairly evaluating the common sense of\npopular ML-LMs across different languages. In addition, we also create two new\ndatasets, X-CSQA and X-CODAH, by translating their English versions to 15 other\nlanguages, so that we can evaluate popular ML-LMs for cross-lingual commonsense\nreasoning. To improve the performance beyond English, we propose a simple yet\neffective method -- multilingual contrastive pre-training (MCP). It\nsignificantly enhances sentence representations, yielding a large performance\ngain on both benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 07:14:03 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Lin", "Bill Yuchen", ""], ["Lee", "Seyeon", ""], ["Qiao", "Xiaoyang", ""], ["Ren", "Xiang", ""]]}, {"id": "2106.06944", "submitter": "Furao Shen", "authors": "Hua Yan, Feng Han, Junyi An, Weikang Xiao, Jian Zhao, Furao Shen", "title": "SASICM A Multi-Task Benchmark For Subtext Recognition", "comments": "34 pages, 6 figures, 6 tables. Submitted to the journal of artificial\n  intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subtext is a kind of deep semantics which can be acquired after one or more\nrounds of expression transformation. As a popular way of expressing one's\nintentions, it is well worth studying. In this paper, we try to make computers\nunderstand whether there is a subtext by means of machine learning. We build a\nChinese dataset whose source data comes from the popular social media (e.g.\nWeibo, Netease Music, Zhihu, and Bilibili). In addition, we also build a\nbaseline model called SASICM to deal with subtext recognition. The F1 score of\nSASICMg, whose pretrained model is GloVe, is as high as 64.37%, which is 3.97%\nhigher than that of BERT based model, 12.7% higher than that of traditional\nmethods on average, including support vector machine, logistic regression\nclassifier, maximum entropy classifier, naive bayes classifier and decision\ntree and 2.39% higher than that of the state-of-the-art, including MARIN and\nBTM. The F1 score of SASICMBERT, whose pretrained model is BERT, is 65.12%,\nwhich is 0.75% higher than that of SASICMg. The accuracy rates of SASICMg and\nSASICMBERT are 71.16% and 70.76%, respectively, which can compete with those of\nother methods which are mentioned before.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 08:29:15 GMT"}, {"version": "v2", "created": "Sun, 4 Jul 2021 02:13:57 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Yan", "Hua", ""], ["Han", "Feng", ""], ["An", "Junyi", ""], ["Xiao", "Weikang", ""], ["Zhao", "Jian", ""], ["Shen", "Furao", ""]]}, {"id": "2106.06946", "submitter": "Mikl\\'os Z. Horv\\'ath", "authors": "Mikl\\'os Z. Horv\\'ath, Mark Niklas M\\\"uller, Marc Fischer, Martin\n  Vechev", "title": "Boosting Randomized Smoothing with Variance Reduced Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Randomized Smoothing (RS) is a promising method for obtaining robustness\ncertificates by evaluating a base model under noise. In this work we: (i)\ntheoretically motivate why ensembles are a particularly suitable choice as base\nmodels for RS, and (ii) empirically confirm this choice, obtaining state of the\nart results in multiple settings. The key insight of our work is that the\nreduced variance of ensembles over the perturbations introduced in RS leads to\nsignificantly more consistent classifications for a given input, in turn\nleading to substantially increased certifiable radii for difficult samples. We\nalso introduce key optimizations which enable an up to 50-fold decrease in\nsample complexity of RS, thus drastically reducing its computational overhead.\nExperimentally, we show that ensembles of only 3 to 10 classifiers consistently\nimprove on the strongest single model with respect to their average certified\nradius (ACR) by 5% to 21% on both CIFAR-10 and ImageNet. On the latter, we\nachieve a state-of-the-art ACR of 1.11. We release all code and models required\nto reproduce our results upon publication.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 08:40:27 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Horv\u00e1th", "Mikl\u00f3s Z.", ""], ["M\u00fcller", "Mark Niklas", ""], ["Fischer", "Marc", ""], ["Vechev", "Martin", ""]]}, {"id": "2106.06947", "submitter": "Ailin Deng", "authors": "Ailin Deng, Bryan Hooi", "title": "Graph Neural Network-Based Anomaly Detection in Multivariate Time Series", "comments": "Accepted at AAAI Conference on Artificial Intelligence (AAAI), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given high-dimensional time series data (e.g., sensor data), how can we\ndetect anomalous events, such as system faults and attacks? More challengingly,\nhow can we do this in a way that captures complex inter-sensor relationships,\nand detects and explains anomalies which deviate from these relationships?\nRecently, deep learning approaches have enabled improvements in anomaly\ndetection in high-dimensional datasets; however, existing methods do not\nexplicitly learn the structure of existing relationships between variables, or\nuse them to predict the expected behavior of time series. Our approach combines\na structure learning approach with graph neural networks, additionally using\nattention weights to provide explainability for the detected anomalies.\nExperiments on two real-world sensor datasets with ground truth anomalies show\nthat our method detects anomalies more accurately than baseline approaches,\naccurately captures correlations between sensors, and allows users to deduce\nthe root cause of a detected anomaly.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 09:07:30 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Deng", "Ailin", ""], ["Hooi", "Bryan", ""]]}, {"id": "2106.06972", "submitter": "Yapeng Jasper Hu", "authors": "Yapeng Jasper Hu, Ralph van Gurp, Ashay Somai, Hugo Kooijman and Jan\n  S. Rellermeyer (Distributed Systems Group, Delft University of Technology)", "title": "RCURRENCY: Live Digital Asset Trading Using a Recurrent Neural\n  Network-based Forecasting System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consistent alpha generation, i.e., maintaining an edge over the market,\nunderpins the ability of asset traders to reliably generate profits. Technical\nindicators and trading strategies are commonly used tools to determine when to\nbuy/hold/sell assets, yet these are limited by the fact that they operate on\nknown values. Over the past decades, multiple studies have investigated the\npotential of artificial intelligence in stock trading in conventional markets,\nwith some success. In this paper, we present RCURRENCY, an RNN-based trading\nengine to predict data in the highly volatile digital asset market which is\nable to successfully manage an asset portfolio in a live environment. By\ncombining asset value prediction and conventional trading tools, RCURRENCY\ndetermines whether to buy, hold or sell digital currencies at a given point in\ntime. Experimental results show that, given the data of an interval $t$, a\nprediction with an error of less than 0.5\\% of the data at the subsequent\ninterval $t+1$ can be obtained. Evaluation of the system through backtesting\nshows that RCURRENCY can be used to successfully not only maintain a stable\nportfolio of digital assets in a simulated live environment using real\nhistorical trading data but even increase the portfolio value over time.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 11:58:36 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Hu", "Yapeng Jasper", "", "Distributed Systems Group, Delft University of Technology"], ["van Gurp", "Ralph", "", "Distributed Systems Group, Delft University of Technology"], ["Somai", "Ashay", "", "Distributed Systems Group, Delft University of Technology"], ["Kooijman", "Hugo", "", "Distributed Systems Group, Delft University of Technology"], ["Rellermeyer", "Jan S.", "", "Distributed Systems Group, Delft University of Technology"]]}, {"id": "2106.06976", "submitter": "Monireh Mohebbi", "authors": "Monireh Mohebbi Moghadam, Bahar Boroomand, Mohammad Jalali, Arman\n  Zareian, Alireza DaeiJavad, and Mohammad Hossein Manshaei", "title": "Game of GANs: Game Theoretical Models for Generative Adversarial\n  Networks", "comments": "16 pages, 5 Tables, 2 Figures, Review paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative Adversarial Network, as a promising research direction in the AI\ncommunity, recently attracts considerable attention due to its ability to\ngenerating high-quality realistic data. GANs are a competing game between two\nneural networks trained in an adversarial manner to reach a Nash equilibrium.\nDespite the improvement accomplished in GANs in the last years, there remain\nseveral issues to solve. In this way, how to tackle these issues and make\nadvances leads to rising research interests. This paper reviews literature that\nleverages the game theory in GANs and addresses how game models can relieve\nspecific generative models' challenges and improve the GAN's performance. In\nparticular, we firstly review some preliminaries, including the basic GAN model\nand some game theory backgrounds. After that, we present our taxonomy to\nsummarize the state-of-the-art solutions into three significant categories:\nmodified game model, modified architecture, and modified learning method. The\nclassification is based on the modifications made in the basic model by the\nproposed approaches from the game-theoretic perspective. We further classify\neach category into several subcategories. Following the proposed taxonomy, we\nexplore the main objective of each class and review the recent work in each\ngroup. Finally, we discuss the remaining challenges in this field and present\nthe potential future research topics.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 12:45:07 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 07:20:01 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Moghadam", "Monireh Mohebbi", ""], ["Boroomand", "Bahar", ""], ["Jalali", "Mohammad", ""], ["Zareian", "Arman", ""], ["DaeiJavad", "Alireza", ""], ["Manshaei", "Mohammad Hossein", ""]]}, {"id": "2106.06991", "submitter": "Nianhui Guo", "authors": "Nianhui Guo, Joseph Bethge, Haojin Yang, Kai Zhong, Xuefei Ning,\n  Christoph Meinel and Yu Wang", "title": "BoolNet: Minimizing The Energy Consumption of Binary Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works on Binary Neural Networks (BNNs) have made promising progress in\nnarrowing the accuracy gap of BNNs to their 32-bit counterparts. However, the\naccuracy gains are often based on specialized model designs using additional\n32-bit components. Furthermore, almost all previous BNNs use 32-bit for feature\nmaps and the shortcuts enclosing the corresponding binary convolution blocks,\nwhich helps to effectively maintain the accuracy, but is not friendly to\nhardware accelerators with limited memory, energy, and computing resources.\nThus, we raise the following question: How can accuracy and energy consumption\nbe balanced in a BNN network design? We extensively study this fundamental\nproblem in this work and propose a novel BNN architecture without most commonly\nused 32-bit components: \\textit{BoolNet}. Experimental results on ImageNet\ndemonstrate that BoolNet can achieve 4.6x energy reduction coupled with 1.2\\%\nhigher accuracy than the commonly used BNN architecture Bi-RealNet. Code and\ntrained models are available at: https://github.com/hpi-xnor/BoolNet.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 13:37:31 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Guo", "Nianhui", ""], ["Bethge", "Joseph", ""], ["Yang", "Haojin", ""], ["Zhong", "Kai", ""], ["Ning", "Xuefei", ""], ["Meinel", "Christoph", ""], ["Wang", "Yu", ""]]}, {"id": "2106.07003", "submitter": "Ammar Abbas", "authors": "Ammar N. Abbas, Muhammad Asad Irshad, and Hossam Hassan Ammar", "title": "Experimental Analysis of Trajectory Control Using Computer Vision and\n  Artificial Intelligence for Autonomous Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perception of the lane boundaries is crucial for the tasks related to\nautonomous trajectory control. In this paper, several methodologies for lane\ndetection are discussed with an experimental illustration: Hough\ntransformation, Blob analysis, and Bird's eye view. Following the abstraction\nof lane marks from the boundary, the next approach is applying a control law\nbased on the perception to control steering and speed control. In the\nfollowing, a comparative analysis is made between an open-loop response, PID\ncontrol, and a neural network control law through graphical statistics. To get\nthe perception of the surrounding a wireless streaming camera connected to\nRaspberry Pi is used. After pre-processing the signal received by the camera\nthe output is sent back to the Raspberry Pi that processes the input and\ncommunicates the control to the motors through Arduino via serial\ncommunication.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 14:23:18 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Abbas", "Ammar N.", ""], ["Irshad", "Muhammad Asad", ""], ["Ammar", "Hossam Hassan", ""]]}, {"id": "2106.07015", "submitter": "Ammar Abbas", "authors": "Ammar N. Abbas and David Moser", "title": "Siamese Network Training Using Sampled Triplets and Image Transformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The device used in this work detects the objects over the surface of the\nwater using two thermal cameras which aid the users to detect and avoid the\nobjects in scenarios where the human eyes cannot (night, fog, etc.). To avoid\nthe obstacle collision autonomously, it is required to track the objects in\nreal-time and assign a specific identity to each object to determine its\ndynamics (trajectory, velocity, etc.) for making estimated collision\npredictions. In the following work, a Machine Learning (ML) approach for\nComputer Vision (CV) called Convolutional Neural Network (CNN) was used using\nTensorFlow as the high-level programming environment in Python. To validate the\nalgorithm a test set was generated using an annotation tool that was created\nduring the work for proper evaluation. Once validated, the algorithm was\ndeployed on the platform and tested with the sequence generated by the test\nboat.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 14:47:52 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Abbas", "Ammar N.", ""], ["Moser", "David", ""]]}, {"id": "2106.07016", "submitter": "Yunzhe Hao", "authors": "Yunzhe Hao, Jiaming Xu, Peng Zhang, Bo Xu", "title": "WASE: Learning When to Attend for Speaker Extraction in Cocktail Party\n  Environments", "comments": "Accepted by ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.SD eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the speaker extraction problem, it is found that additional information\nfrom the target speaker contributes to the tracking and extraction of the\ntarget speaker, which includes voiceprint, lip movement, facial expression, and\nspatial information. However, no one cares for the cue of sound onset, which\nhas been emphasized in the auditory scene analysis and psychology. Inspired by\nit, we explicitly modeled the onset cue and verified the effectiveness in the\nspeaker extraction task. We further extended to the onset/offset cues and got\nperformance improvement. From the perspective of tasks, our onset/offset-based\nmodel completes the composite task, a complementary combination of speaker\nextraction and speaker-dependent voice activity detection. We also combined\nvoiceprint with onset/offset cues. Voiceprint models voice characteristics of\nthe target while onset/offset models the start/end information of the speech.\nFrom the perspective of auditory scene analysis, the combination of two\nperception cues can promote the integrity of the auditory object. The\nexperiment results are also close to state-of-the-art performance, using nearly\nhalf of the parameters. We hope that this work will inspire communities of\nspeech processing and psychology, and contribute to communication between them.\nOur code will be available in https://github.com/aispeech-lab/wase/.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 14:56:05 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Hao", "Yunzhe", ""], ["Xu", "Jiaming", ""], ["Zhang", "Peng", ""], ["Xu", "Bo", ""]]}, {"id": "2106.07030", "submitter": "Alpha Renner", "authors": "Alpha Renner, Forrest Sheldon, Anatoly Zlotnik, Louis Tao, Andrew\n  Sornborger", "title": "The Backpropagation Algorithm Implemented on Spiking Neuromorphic\n  Hardware", "comments": "20 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": "LA-UR-21-24457", "categories": "cs.NE cs.AI cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The capabilities of natural neural systems have inspired new generations of\nmachine learning algorithms as well as neuromorphic very large-scale integrated\n(VLSI) circuits capable of fast, low-power information processing. However,\nmost modern machine learning algorithms are not neurophysiologically plausible\nand thus are not directly implementable in neuromorphic hardware. In\nparticular, the workhorse of modern deep learning, the backpropagation\nalgorithm, has proven difficult to translate to neuromorphic hardware. In this\nstudy, we present a neuromorphic, spiking backpropagation algorithm based on\npulse-gated dynamical information coordination and processing, implemented on\nIntel's Loihi neuromorphic research processor. We demonstrate a\nproof-of-principle three-layer circuit that learns to classify digits from the\nMNIST dataset. This implementation shows a path for using massively parallel,\nlow-power, low-latency neuromorphic processors in modern deep learning\napplications.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 15:56:40 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Renner", "Alpha", ""], ["Sheldon", "Forrest", ""], ["Zlotnik", "Anatoly", ""], ["Tao", "Louis", ""], ["Sornborger", "Andrew", ""]]}, {"id": "2106.07039", "submitter": "Haipeng Chen", "authors": "Haipeng Chen, Wei Qiu, Han-Ching Ou, Bo An, Milind Tambe", "title": "Contingency-Aware Influence Maximization: A Reinforcement Learning\n  Approach", "comments": "11 pages; accepted for publication at UAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The influence maximization (IM) problem aims at finding a subset of seed\nnodes in a social network that maximize the spread of influence. In this study,\nwe focus on a sub-class of IM problems, where whether the nodes are willing to\nbe the seeds when being invited is uncertain, called contingency-aware IM. Such\ncontingency aware IM is critical for applications for non-profit organizations\nin low resource communities (e.g., spreading awareness of disease prevention).\nDespite the initial success, a major practical obstacle in promoting the\nsolutions to more communities is the tremendous runtime of the greedy\nalgorithms and the lack of high performance computing (HPC) for the non-profits\nin the field -- whenever there is a new social network, the non-profits usually\ndo not have the HPCs to recalculate the solutions. Motivated by this and\ninspired by the line of works that use reinforcement learning (RL) to address\ncombinatorial optimization on graphs, we formalize the problem as a Markov\nDecision Process (MDP), and use RL to learn an IM policy over historically seen\nnetworks, and generalize to unseen networks with negligible runtime at test\nphase. To fully exploit the properties of our targeted problem, we propose two\ntechnical innovations that improve the existing methods, including\nstate-abstraction and theoretically grounded reward shaping. Empirical results\nshow that our method achieves influence as high as the state-of-the-art methods\nfor contingency-aware IM, while having negligible runtime at test phase.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 16:42:22 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Chen", "Haipeng", ""], ["Qiu", "Wei", ""], ["Ou", "Han-Ching", ""], ["An", "Bo", ""], ["Tambe", "Milind", ""]]}, {"id": "2106.07053", "submitter": "Qingyun Sun", "authors": "Qingyun Sun and David Donoho", "title": "Convex Sparse Blind Deconvolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.SY eess.SY math.IT math.ST stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the blind deconvolution problem, we observe the convolution of an unknown\nfilter and unknown signal and attempt to reconstruct the filter and signal. The\nproblem seems impossible in general, since there are seemingly many more\nunknowns than knowns . Nevertheless, this problem arises in many application\nfields; and empirically, some of these fields have had success using heuristic\nmethods -- even economically very important ones, in wireless communications\nand oil exploration. Today's fashionable heuristic formulations pose non-convex\noptimization problems which are then attacked heuristically as well. The fact\nthat blind deconvolution can be solved under some repeatable and\nnaturally-occurring circumstances poses a theoretical puzzle.\n  To bridge the gulf between reported successes and theory's limited\nunderstanding, we exhibit a convex optimization problem that -- assuming signal\nsparsity -- can convert a crude approximation to the true filter into a\nhigh-accuracy recovery of the true filter. Our proposed formulation is based on\nL1 minimization of inverse filter outputs. We give sharp guarantees on\nperformance of the minimizer assuming sparsity of signal, showing that our\nproposal precisely recovers the true inverse filter, up to shift and rescaling.\nThere is a sparsity/initial accuracy tradeoff: the less accurate the initial\napproximation, the greater we rely on sparsity to enable exact recovery. To our\nknowledge this is the first reported tradeoff of this kind. We consider it\nsurprising that this tradeoff is independent of dimension.\n  We also develop finite-$N$ guarantees, for highly accurate reconstruction\nunder $N\\geq O(k \\log(k) )$ with high probability. We further show stable\napproximation when the true inverse filter is infinitely long and extend our\nguarantees to the case where the observations are contaminated by stochastic or\nadversarial noise.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 17:39:26 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Sun", "Qingyun", ""], ["Donoho", "David", ""]]}, {"id": "2106.07055", "submitter": "Shikib Mehri", "authors": "Shikib Mehri, Maxine Eskenazi", "title": "GenSF: Simultaneous Adaptation of Generative Pre-trained Models and Slot\n  Filling", "comments": "Accepted at SIGDial 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In transfer learning, it is imperative to achieve strong alignment between a\npre-trained model and a downstream task. Prior work has done this by proposing\ntask-specific pre-training objectives, which sacrifices the inherent\nscalability of the transfer learning paradigm. We instead achieve strong\nalignment by simultaneously modifying both the pre-trained model and the\nformulation of the downstream task, which is more efficient and preserves the\nscalability of transfer learning. We present GenSF (Generative Slot Filling),\nwhich leverages a generative pre-trained open-domain dialog model for slot\nfilling. GenSF (1) adapts the pre-trained model by incorporating inductive\nbiases about the task and (2) adapts the downstream task by reformulating slot\nfilling to better leverage the pre-trained model's capabilities. GenSF achieves\nstate-of-the-art results on two slot filling datasets with strong gains in\nfew-shot and zero-shot settings. We achieve a 9 F1 score improvement in\nzero-shot slot filling. This highlights the value of strong alignment between\nthe pre-trained model and the downstream task.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 17:44:17 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Mehri", "Shikib", ""], ["Eskenazi", "Maxine", ""]]}, {"id": "2106.07056", "submitter": "Shikib Mehri", "authors": "Shikib Mehri, Maxine Eskenazi", "title": "Schema-Guided Paradigm for Zero-Shot Dialog", "comments": "Accepted at SIGDial 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Developing mechanisms that flexibly adapt dialog systems to unseen tasks and\ndomains is a major challenge in dialog research. Neural models implicitly\nmemorize task-specific dialog policies from the training data. We posit that\nthis implicit memorization has precluded zero-shot transfer learning. To this\nend, we leverage the schema-guided paradigm, wherein the task-specific dialog\npolicy is explicitly provided to the model. We introduce the Schema Attention\nModel (SAM) and improved schema representations for the STAR corpus. SAM\nobtains significant improvement in zero-shot settings, with a +22 F1 score\nimprovement over prior work. These results validate the feasibility of\nzero-shot generalizability in dialog. Ablation experiments are also presented\nto demonstrate the efficacy of SAM.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 17:44:45 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Mehri", "Shikib", ""], ["Eskenazi", "Maxine", ""]]}, {"id": "2106.07088", "submitter": "Mohsen Annabestani", "authors": "Mohsen Annabestani, Ali Abedi, Mohammad Reza Nematollahi, and Mohammad\n  Bagher Naghibi Sis-tani", "title": "A new soft computing method for integration of expert's knowledge in\n  reinforcement learn-ing problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel fuzzy action selection method to leverage human\nknowledge in reinforcement learning problems. Based on the estimates of the\nmost current action-state values, the proposed fuzzy nonlinear mapping as-signs\neach member of the action set to its probability of being chosen in the next\nstep. A user tunable parameter is introduced to control the action selection\npolicy, which determines the agent's greedy behavior throughout the learning\nprocess. This parameter resembles the role of the temperature parameter in the\nsoftmax action selection policy, but its tuning process can be more\nknowledge-oriented since this parameter reflects the human knowledge into the\nlearning agent by making modifications in the fuzzy rule base. Simulation\nresults indicate that including fuzzy logic within the reinforcement learning\nin the proposed manner improves the learning algorithm's convergence rate, and\nprovides superior performance.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 20:41:29 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Annabestani", "Mohsen", ""], ["Abedi", "Ali", ""], ["Nematollahi", "Mohammad Reza", ""], ["Sis-tani", "Mohammad Bagher Naghibi", ""]]}, {"id": "2106.07091", "submitter": "Ramin Hasani", "authors": "Zahra Babaiee, Ramin Hasani, Mathias Lechner, Daniela Rus, Radu Grosu", "title": "On-Off Center-Surround Receptive Fields for Accurate and Robust Image\n  Classification", "comments": "21 Pages. Accepted for publication in the proceedings of the 38th\n  International Conference on Machine Learning (ICML) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Robustness to variations in lighting conditions is a key objective for any\ndeep vision system. To this end, our paper extends the receptive field of\nconvolutional neural networks with two residual components, ubiquitous in the\nvisual processing system of vertebrates: On-center and off-center pathways,\nwith excitatory center and inhibitory surround; OOCS for short. The on-center\npathway is excited by the presence of a light stimulus in its center but not in\nits surround, whereas the off-center one is excited by the absence of a light\nstimulus in its center but not in its surround. We design OOCS pathways via a\ndifference of Gaussians, with their variance computed analytically from the\nsize of the receptive fields. OOCS pathways complement each other in their\nresponse to light stimuli, ensuring this way a strong edge-detection\ncapability, and as a result, an accurate and robust inference under challenging\nlighting conditions. We provide extensive empirical evidence showing that\nnetworks supplied with the OOCS edge representation gain accuracy and\nillumination-robustness compared to standard deep models.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 20:55:16 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Babaiee", "Zahra", ""], ["Hasani", "Ramin", ""], ["Lechner", "Mathias", ""], ["Rus", "Daniela", ""], ["Grosu", "Radu", ""]]}, {"id": "2106.07112", "submitter": "Clarice Wang", "authors": "Clarice Wang, Kathryn Wang, Andrew Bian, Rashidul Islam, Kamrun Naher\n  Keya, James Foulds, Shimei Pan", "title": "User Acceptance of Gender Stereotypes in Automated Career\n  Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Currently, there is a surge of interest in fair Artificial Intelligence (AI)\nand Machine Learning (ML) research which aims to mitigate discriminatory bias\nin AI algorithms, e.g. along lines of gender, age, and race. While most\nresearch in this domain focuses on developing fair AI algorithms, in this work,\nwe show that a fair AI algorithm on its own may be insufficient to achieve its\nintended results in the real world. Using career recommendation as a case\nstudy, we build a fair AI career recommender by employing gender debiasing\nmachine learning techniques. Our offline evaluation showed that the debiased\nrecommender makes fairer career recommendations without sacrificing its\naccuracy. Nevertheless, an online user study of more than 200 college students\nrevealed that participants on average prefer the original biased system over\nthe debiased system. Specifically, we found that perceived gender disparity is\na determining factor for the acceptance of a recommendation. In other words,\nour results demonstrate we cannot fully address the gender bias issue in AI\nrecommendations without addressing the gender bias in humans.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 23:27:45 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 14:16:22 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Wang", "Clarice", ""], ["Wang", "Kathryn", ""], ["Bian", "Andrew", ""], ["Islam", "Rashidul", ""], ["Keya", "Kamrun Naher", ""], ["Foulds", "James", ""], ["Pan", "Shimei", ""]]}, {"id": "2106.07114", "submitter": "Jingwei Huang", "authors": "Jingwei Huang, Wael Khallouli, Ghaith Rabadi, Mamadou Seck", "title": "Intelligent Agent for Hurricane Emergency Identification and Text\n  Information Extraction from Streaming Social Media Big Data", "comments": "16 pages, 3 figures, and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents our research on leveraging social media Big Data and AI\nto support hurricane disaster emergency response. The current practice of\nhurricane emergency response for rescue highly relies on emergency call\ncentres. The more recent Hurricane Harvey event reveals the limitations of the\ncurrent systems. We use Hurricane Harvey and the associated Houston flooding as\nthe motivating scenario to conduct research and develop a prototype as a\nproof-of-concept of using an intelligent agent as a complementary role to\nsupport emergency centres in hurricane emergency response. This intelligent\nagent is used to collect real-time streaming tweets during a natural disaster\nevent, to identify tweets requesting rescue, to extract key information such as\naddress and associated geocode, and to visualize the extracted information in\nan interactive map in decision supports. Our experiment shows promising\noutcomes and the potential application of the research in support of hurricane\nemergency response.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 00:12:27 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Huang", "Jingwei", ""], ["Khallouli", "Wael", ""], ["Rabadi", "Ghaith", ""], ["Seck", "Mamadou", ""]]}, {"id": "2106.07115", "submitter": "Qi Lyu", "authors": "Qi Lyu, Xiao Fu, Weiran Wang and Songtao Lu", "title": "Latent Correlation-Based Multiview Learning and Self-Supervision: A\n  Unifying Perspective", "comments": "fixed some typos in the proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multiple views of data, both naturally acquired (e.g., image and audio) and\nartificially produced (e.g., via adding different noise to data samples), have\nproven useful in enhancing representation learning. Natural views are often\nhandled by multiview analysis tools, e.g., (deep) canonical correlation\nanalysis [(D)CCA], while the artificial ones are frequently used in\nself-supervised learning (SSL) paradigms, e.g., SimCLR and Barlow Twins. Both\ntypes of approaches often involve learning neural feature extractors such that\nthe embeddings of data exhibit high cross-view correlations. Although\nintuitive, the effectiveness of correlation-based neural embedding is only\nempirically validated. This work puts forth a theory-backed framework for\nunsupervised multiview learning. Our development starts with proposing a\nmultiview model, where each view is a nonlinear mixture of shared and private\ncomponents. Consequently, the learning problem boils down to shared/private\ncomponent identification and disentanglement. Under this model, latent\ncorrelation maximization is shown to guarantee the extraction of the shared\ncomponents across views (up to certain ambiguities). In addition, the private\ninformation in each view can be provably disentangled from the shared using\nproper regularization design. The method is tested on a series of tasks, e.g.,\ndownstream clustering, which all show promising performance. Our development\nalso provides a unifying perspective for understanding various DCCA and SSL\nschemes.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 00:12:36 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 16:51:29 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Lyu", "Qi", ""], ["Fu", "Xiao", ""], ["Wang", "Weiran", ""], ["Lu", "Songtao", ""]]}, {"id": "2106.07131", "submitter": "Alberto Olmo", "authors": "Alberto Olmo, Sarath Sreedharan, Subbarao Kambhampati", "title": "GPT3-to-plan: Extracting plans from text using GPT-3", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Operations in many essential industries including finance and banking are\noften characterized by the need to perform repetitive sequential tasks. Despite\ntheir criticality to the business, workflows are rarely fully automated or even\nformally specified, though there may exist a number of natural language\ndocuments describing these procedures for the employees of the company. Plan\nextraction methods provide us with the possibility of extracting structure\nplans from such natural language descriptions of the plans/workflows, which\ncould then be leveraged by an automated system. In this paper, we investigate\nthe utility of generalized language models in performing such extractions\ndirectly from such texts. Such models have already been shown to be quite\neffective in multiple translation tasks, and our initial results seem to point\nto their effectiveness also in the context of plan extractions. Particularly,\nwe show that GPT-3 is able to generate plan extraction results that are\ncomparable to many of the current state of the art plan extraction methods.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 01:45:47 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Olmo", "Alberto", ""], ["Sreedharan", "Sarath", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "2106.07139", "submitter": "Han Xu", "authors": "Xu Han, Zhengyan Zhang, Ning Ding, Yuxian Gu, Xiao Liu, Yuqi Huo,\n  Jiezhong Qiu, Liang Zhang, Wentao Han, Minlie Huang, Qin Jin, Yanyan Lan,\n  Yang Liu, Zhiyuan Liu, Zhiwu Lu, Xipeng Qiu, Ruihua Song, Jie Tang, Ji-Rong\n  Wen, Jinhui Yuan, Wayne Xin Zhao, Jun Zhu", "title": "Pre-Trained Models: Past, Present and Future", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale pre-trained models (PTMs) such as BERT and GPT have recently\nachieved great success and become a milestone in the field of artificial\nintelligence (AI). Owing to sophisticated pre-training objectives and huge\nmodel parameters, large-scale PTMs can effectively capture knowledge from\nmassive labeled and unlabeled data. By storing knowledge into huge parameters\nand fine-tuning on specific tasks, the rich knowledge implicitly encoded in\nhuge parameters can benefit a variety of downstream tasks, which has been\nextensively demonstrated via experimental verification and empirical analysis.\nIt is now the consensus of the AI community to adopt PTMs as backbone for\ndownstream tasks rather than learning models from scratch. In this paper, we\ntake a deep look into the history of pre-training, especially its special\nrelation with transfer learning and self-supervised learning, to reveal the\ncrucial position of PTMs in the AI development spectrum. Further, we\ncomprehensively review the latest breakthroughs of PTMs. These breakthroughs\nare driven by the surge of computational power and the increasing availability\nof data, towards four important directions: designing effective architectures,\nutilizing rich contexts, improving computational efficiency, and conducting\ninterpretation and theoretical analysis. Finally, we discuss a series of open\nproblems and research directions of PTMs, and hope our view can inspire and\nadvance the future study of PTMs.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 02:40:32 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 07:08:31 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Han", "Xu", ""], ["Zhang", "Zhengyan", ""], ["Ding", "Ning", ""], ["Gu", "Yuxian", ""], ["Liu", "Xiao", ""], ["Huo", "Yuqi", ""], ["Qiu", "Jiezhong", ""], ["Zhang", "Liang", ""], ["Han", "Wentao", ""], ["Huang", "Minlie", ""], ["Jin", "Qin", ""], ["Lan", "Yanyan", ""], ["Liu", "Yang", ""], ["Liu", "Zhiyuan", ""], ["Lu", "Zhiwu", ""], ["Qiu", "Xipeng", ""], ["Song", "Ruihua", ""], ["Tang", "Jie", ""], ["Wen", "Ji-Rong", ""], ["Yuan", "Jinhui", ""], ["Zhao", "Wayne Xin", ""], ["Zhu", "Jun", ""]]}, {"id": "2106.07156", "submitter": "Tung Nguyen", "authors": "Tung Nguyen, Rui Shu, Tuan Pham, Hung Bui, Stefano Ermon", "title": "Temporal Predictive Coding For Model-Based Planning In Latent Space", "comments": "International Conference on Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional observations are a major challenge in the application of\nmodel-based reinforcement learning (MBRL) to real-world environments. To handle\nhigh-dimensional sensory inputs, existing approaches use representation\nlearning to map high-dimensional observations into a lower-dimensional latent\nspace that is more amenable to dynamics estimation and planning. In this work,\nwe present an information-theoretic approach that employs temporal predictive\ncoding to encode elements in the environment that can be predicted across time.\nSince this approach focuses on encoding temporally-predictable information, we\nimplicitly prioritize the encoding of task-relevant components over nuisance\ninformation within the environment that are provably task-irrelevant. By\nlearning this representation in conjunction with a recurrent state space model,\nwe can then perform planning in latent space. We evaluate our model on a\nchallenging modification of standard DMControl tasks where the background is\nreplaced with natural videos that contain complex but irrelevant information to\nthe planning task. Our experiments show that our model is superior to existing\nmethods in the challenging complex-background setting while remaining\ncompetitive with current state-of-the-art models in the standard setting.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 04:31:15 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Nguyen", "Tung", ""], ["Shu", "Rui", ""], ["Pham", "Tuan", ""], ["Bui", "Hung", ""], ["Ermon", "Stefano", ""]]}, {"id": "2106.07160", "submitter": "Kim Hammar", "authors": "Kim Hammar and Rolf Stadler", "title": "Learning Intrusion Prevention Policies through Optimal Stopping", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We study automated intrusion prevention using reinforcement learning. In a\nnovel approach, we formulate the problem of intrusion prevention as an optimal\nstopping problem. This formulation allows us insight into the structure of the\noptimal policies, which turn out to be threshold based. Since the computation\nof the optimal defender policy using dynamic programming is not feasible for\npractical cases, we approximate the optimal policy through reinforcement\nlearning in a simulation environment. To define the dynamics of the simulation,\nwe emulate the target infrastructure and collect measurements. Our evaluations\nshow that the learned policies are close to optimal and that they indeed can be\nexpressed using thresholds.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 04:45:37 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Hammar", "Kim", ""], ["Stadler", "Rolf", ""]]}, {"id": "2106.07162", "submitter": "Em\\=ils Ozoli\\c{n}\\v{s}", "authors": "Emils Ozolins, Karlis Freivalds, Andis Draguns, Eliza Gaile, Ronalds\n  Zakovskis, Sergejs Kozlovics", "title": "Goal-Aware Neural SAT Solver", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern neural networks obtain information about the problem and calculate the\noutput solely from the input values. We argue that it is not always optimal,\nand the network's performance can be significantly improved by augmenting it\nwith a query mechanism that allows the network to make several solution trials\nat run time and get feedback on the loss value on each trial. To demonstrate\nthe capabilities of the query mechanism, we formulate an unsupervised (not\ndependant on labels) loss function for Boolean Satisfiability Problem (SAT) and\ntheoretically show that it allows the network to extract rich information about\nthe problem. We then propose a neural SAT solver with a query mechanism called\nQuerySAT and show that it outperforms the neural baseline on a wide range of\nSAT tasks and the classical baselines on SHA-1 preimage attack and 3-SAT task.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 04:51:24 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Ozolins", "Emils", ""], ["Freivalds", "Karlis", ""], ["Draguns", "Andis", ""], ["Gaile", "Eliza", ""], ["Zakovskis", "Ronalds", ""], ["Kozlovics", "Sergejs", ""]]}, {"id": "2106.07171", "submitter": "Chunting Zhou", "authors": "Chunting Zhou, Xuezhe Ma, Paul Michel, Graham Neubig", "title": "Examining and Combating Spurious Features under Distribution Shift", "comments": "Accepted by ICML2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central goal of machine learning is to learn robust representations that\ncapture the causal relationship between inputs features and output labels.\nHowever, minimizing empirical risk over finite or biased datasets often results\nin models latching on to spurious correlations between the training\ninput/output pairs that are not fundamental to the problem at hand. In this\npaper, we define and analyze robust and spurious representations using the\ninformation-theoretic concept of minimal sufficient statistics. We prove that\neven when there is only bias of the input distribution (i.e. covariate shift),\nmodels can still pick up spurious features from their training data. Group\ndistributionally robust optimization (DRO) provides an effective tool to\nalleviate covariate shift by minimizing the worst-case training loss over a set\nof pre-defined groups. Inspired by our analysis, we demonstrate that group DRO\ncan fail when groups do not directly account for various spurious correlations\nthat occur in the data. To address this, we further propose to minimize the\nworst-case losses over a more flexible set of distributions that are defined on\nthe joint distribution of groups and instances, instead of treating each group\nas a whole at optimization time. Through extensive experiments on one image and\ntwo language tasks, we show that our model is significantly more robust than\ncomparable baselines under various partitions. Our code is available at\nhttps://github.com/violet-zct/group-conditional-DRO.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 05:39:09 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Zhou", "Chunting", ""], ["Ma", "Xuezhe", ""], ["Michel", "Paul", ""], ["Neubig", "Graham", ""]]}, {"id": "2106.07176", "submitter": "Ru He", "authors": "Yifei Xu, Jingqiao Zhang, Ru He, Liangzhu Ge, Chao Yang, Cheng Yang,\n  Ying Nian Wu", "title": "SAS: Self-Augmented Strategy for Language Model Pre-training", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The core of a self-supervised learning method for pre-training language\nmodels includes the design of appropriate data augmentation and corresponding\npre-training task(s). Most data augmentations in language model pre-training\nare context-independent. The seminal contextualized augmentation recently\nproposed by the ELECTRA requires a separate generator, which leads to extra\ncomputation cost as well as the challenge in adjusting the capability of its\ngenerator relative to that of the other model component(s). We propose a\nself-augmented strategy (SAS) that uses a single forward pass through the model\nto augment the input data for model training in the next epoch. Essentially our\nstrategy eliminates a separate generator network and uses only one network to\ngenerate the data augmentation and undertake two pre-training tasks (the MLM\ntask and the RTD task) jointly, which naturally avoids the challenge in\nadjusting the generator's capability as well as reduces the computation cost.\nAdditionally, our SAS is a general strategy such that it can seamlessly\nincorporate many new techniques emerging recently or in the future, such as the\ndisentangled attention mechanism recently proposed by the DeBERTa model. Our\nexperiments show that our SAS is able to outperform the ELECTRA and other\nstate-of-the-art models in the GLUE tasks with the same or less computation\ncost.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 05:57:46 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Xu", "Yifei", ""], ["Zhang", "Jingqiao", ""], ["He", "Ru", ""], ["Ge", "Liangzhu", ""], ["Yang", "Chao", ""], ["Yang", "Cheng", ""], ["Wu", "Ying Nian", ""]]}, {"id": "2106.07185", "submitter": "Donsuk Lee", "authors": "Donsuk Lee, Denizhan Pak, Justin N. Wood", "title": "Modeling Object Recognition in Newborn Chicks using Deep Neural Networks", "comments": "Presented at CogSci 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, the brain and cognitive sciences have made great strides\ndeveloping a mechanistic understanding of object recognition in mature brains.\nDespite this progress, fundamental questions remain about the origins and\ncomputational foundations of object recognition. What learning algorithms\nunderlie object recognition in newborn brains? Since newborn animals learn\nlargely through unsupervised learning, we explored whether unsupervised\nlearning algorithms can be used to predict the view-invariant object\nrecognition behavior of newborn chicks. Specifically, we used feature\nrepresentations derived from unsupervised deep neural networks (DNNs) as inputs\nto cognitive models of categorization. We show that features derived from\nunsupervised DNNs make competitive predictions about chick behavior compared to\nsupervised features. More generally, we argue that linking controlled-rearing\nstudies to image-computable DNN models opens new experimental avenues for\nstudying the origins and computational basis of object recognition in newborn\nanimals.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 06:24:49 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Lee", "Donsuk", ""], ["Pak", "Denizhan", ""], ["Wood", "Justin N.", ""]]}, {"id": "2106.07186", "submitter": "Usman Cheema", "authors": "Usman Cheema and Seungbin Moon", "title": "Sejong Face Database: A Multi-Modal Disguise Face Database", "comments": "Database Access Link:\n  https://github.com/usmancheema89/SejongFaceDatabase", "journal-ref": "Computer Vision and Image Understanding, Volumes 208-209, 2021", "doi": "10.1016/j.cviu.2021.103218", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commercial application of facial recognition demands robustness to a variety\nof challenges such as illumination, occlusion, spoofing, disguise, etc.\nDisguised face recognition is one of the emerging issues for access control\nsystems, such as security checkpoints at the borders. However, the lack of\navailability of face databases with a variety of disguise addons limits the\ndevelopment of academic research in the area. In this paper, we present a\nmultimodal disguised face dataset to facilitate the disguised face recognition\nresearch. The presented database contains 8 facial add-ons and 7 additional\ncombinations of these add-ons to create a variety of disguised face images.\nEach facial image is captured in visible, visible plus infrared, infrared, and\nthermal spectra. Specifically, the database contains 100 subjects divided into\nsubset-A (30 subjects, 1 image per modality) and subset-B (70 subjects, 5 plus\nimages per modality). We also present baseline face detection results performed\non the proposed database to provide reference results and compare the\nperformance in different modalities. Qualitative and quantitative analysis is\nperformed to evaluate the challenging nature of disguise addons. The dataset\nwill be publicly available with the acceptance of the research article. The\ndatabase is available at: https://github.com/usmancheema89/SejongFaceDatabase.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 06:29:41 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Cheema", "Usman", ""], ["Moon", "Seungbin", ""]]}, {"id": "2106.07190", "submitter": "Young-Ju Choi", "authors": "Young-Ju Choi, Young-Woon Lee, Byung-Gyu Kim", "title": "Group-based Bi-Directional Recurrent Wavelet Neural Networks for Video\n  Super-Resolution", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video super-resolution (VSR) aims to estimate a high-resolution (HR) frame\nfrom a low-resolution (LR) frames. The key challenge for VSR lies in the\neffective exploitation of spatial correlation in an intra-frame and temporal\ndependency between consecutive frames. However, most of the previous methods\ntreat different types of the spatial features identically and extract spatial\nand temporal features from the separated modules. It leads to lack of obtaining\nmeaningful information and enhancing the fine details. In VSR, there are three\ntypes of temporal modeling frameworks: 2D convolutional neural networks (CNN),\n3D CNN, and recurrent neural networks (RNN). Among them, the RNN-based approach\nis suitable for sequential data. Thus the SR performance can be greatly\nimproved by using the hidden states of adjacent frames. However, at each of\ntime step in a recurrent structure, the RNN-based previous works utilize the\nneighboring features restrictively. Since the range of accessible motion per\ntime step is narrow, there are still limitations to restore the missing details\nfor dynamic or large motion. In this paper, we propose a group-based\nbi-directional recurrent wavelet neural networks (GBR-WNN) to exploit the\nsequential data and spatio-temporal information effectively for VSR. The\nproposed group-based bi-directional RNN (GBR) temporal modeling framework is\nbuilt on the well-structured process with the group of pictures (GOP). We\npropose a temporal wavelet attention (TWA) module, in which attention is\nadopted for both spatial and temporal features. Experimental results\ndemonstrate that the proposed method achieves superior performance compared\nwith state-of-the-art methods in both of quantitative and qualitative\nevaluations.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 06:36:13 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Choi", "Young-Ju", ""], ["Lee", "Young-Woon", ""], ["Kim", "Byung-Gyu", ""]]}, {"id": "2106.07197", "submitter": "Yue Yu", "authors": "Yue Yu, Tian Gao, Naiyu Yin, Qiang Ji", "title": "DAGs with No Curl: An Efficient DAG Structure Learning Approach", "comments": "ICML2021, Code is available at\n  https://github.com/fishmoon1234/DAG-NoCurl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recently directed acyclic graph (DAG) structure learning is formulated as a\nconstrained continuous optimization problem with continuous acyclicity\nconstraints and was solved iteratively through subproblem optimization. To\nfurther improve efficiency, we propose a novel learning framework to model and\nlearn the weighted adjacency matrices in the DAG space directly. Specifically,\nwe first show that the set of weighted adjacency matrices of DAGs are\nequivalent to the set of weighted gradients of graph potential functions, and\none may perform structure learning by searching in this equivalent set of DAGs.\nTo instantiate this idea, we propose a new algorithm, DAG-NoCurl, which solves\nthe optimization problem efficiently with a two-step procedure: 1) first we\nfind an initial cyclic solution to the optimization problem, and 2) then we\nemploy the Hodge decomposition of graphs and learn an acyclic graph by\nprojecting the cyclic graph to the gradient of a potential function.\nExperimental studies on benchmark datasets demonstrate that our method provides\ncomparable accuracy but better efficiency than baseline DAG structure learning\nmethods on both linear and generalized structural equation models, often by\nmore than one order of magnitude.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 07:11:36 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Yu", "Yue", ""], ["Gao", "Tian", ""], ["Yin", "Naiyu", ""], ["Ji", "Qiang", ""]]}, {"id": "2106.07203", "submitter": "Dingwen Kong", "authors": "Dingwen Kong, Ruslan Salakhutdinov, Ruosong Wang, Lin F. Yang", "title": "Online Sub-Sampling for Reinforcement Learning with General Function\n  Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing provably efficient algorithms with general function approximation\nis an important open problem in reinforcement learning. Recently, Wang et\nal.~[2020c] establish a value-based algorithm with general function\napproximation that enjoys\n$\\widetilde{O}(\\mathrm{poly}(dH)\\sqrt{K})$\\footnote{Throughout the paper, we\nuse $\\widetilde{O}(\\cdot)$ to suppress logarithm factors. } regret bound, where\n$d$ depends on the complexity of the function class, $H$ is the planning\nhorizon, and $K$ is the total number of episodes. However, their algorithm\nrequires $\\Omega(K)$ computation time per round, rendering the algorithm\ninefficient for practical use. In this paper, by applying online sub-sampling\ntechniques, we develop an algorithm that takes\n$\\widetilde{O}(\\mathrm{poly}(dH))$ computation time per round on average, and\nenjoys nearly the same regret bound. Furthermore, the algorithm achieves low\nswitching cost, i.e., it changes the policy only\n$\\widetilde{O}(\\mathrm{poly}(dH))$ times during its execution, making it\nappealing to be implemented in real-life scenarios. Moreover, by using an\nupper-confidence based exploration-driven reward function, the algorithm\nprovably explores the environment in the reward-free setting. In particular,\nafter $\\widetilde{O}(\\mathrm{poly}(dH))/\\epsilon^2$ rounds of exploration, the\nalgorithm outputs an $\\epsilon$-optimal policy for any given reward function.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 07:36:25 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Kong", "Dingwen", ""], ["Salakhutdinov", "Ruslan", ""], ["Wang", "Ruosong", ""], ["Yang", "Lin F.", ""]]}, {"id": "2106.07211", "submitter": "Renlong Jie", "authors": "Renlong Jie and Junbin Gao", "title": "Differentiable Neural Architecture Search with Morphism-based\n  Transformable Backbone Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study aims at making the architecture search process more adaptive for\none-shot or online training. It is extended from the existing study on\ndifferentiable neural architecture search, and we made the backbone\narchitecture transformable rather than fixed during the training process. As is\nknown, differentiable neural architecture search (DARTS) requires a pre-defined\nover-parameterized backbone architecture, while its size is to be determined\nmanually. Also, in DARTS backbone, Hadamard product of two elements is not\nintroduced, which exists in both LSTM and GRU cells for recurrent nets. This\nstudy introduces a growing mechanism for differentiable neural architecture\nsearch based on network morphism. It enables growing of the cell structures\nfrom small size towards large size ones with one-shot training. Two modes can\nbe applied in integrating the growing and original pruning process. We also\nimplement a recently proposed two-input backbone architecture for recurrent\nneural networks. Initial experimental results indicate that our approach and\nthe two-input backbone structure can be quite effective compared with other\nbaseline architectures including LSTM, in a variety of learning tasks including\nmulti-variate time series forecasting and language modeling. On the other hand,\nwe find that dynamic network transformation is promising in improving the\nefficiency of differentiable architecture search.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 07:56:33 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Jie", "Renlong", ""], ["Gao", "Junbin", ""]]}, {"id": "2106.07217", "submitter": "Seulki Park", "authors": "Seulki Park, Dae Ung Jo, and Jin Young Choi", "title": "Over-Fit: Noisy-Label Detection based on the Overfitted Model Property", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the increasing need to handle the noisy label problem in a massive\ndataset, learning with noisy labels has received much attention in recent\nyears. As a promising approach, there have been recent studies to select clean\ntraining data by finding small-loss instances before a deep neural network\noverfits the noisy-label data. However, it is challenging to prevent\noverfitting. In this paper, we propose a novel noisy-label detection algorithm\nby employing the property of overfitting on individual data points. To this\nend, we present two novel criteria that statistically measure how much each\ntraining sample abnormally affects the model and clean validation data. Using\nthe criteria, our iterative algorithm removes noisy-label samples and retrains\nthe model alternately until no further performance improvement is made. In\nexperiments on multiple benchmark datasets, we demonstrate the validity of our\nalgorithm and show that our algorithm outperforms the state-of-the-art methods\nwhen the exact noise rates are not given. Furthermore, we show that our method\ncan not only be expanded to a real-world video dataset but also can be viewed\nas a regularization method to solve problems caused by overfitting.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 08:04:18 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Park", "Seulki", ""], ["Jo", "Dae Ung", ""], ["Choi", "Jin Young", ""]]}, {"id": "2106.07221", "submitter": "Guillaume Vidot", "authors": "Guillaume Vidot (IRIT-ARGOS), Christophe Gabreau, Ileana Ober\n  (IRIT-ARGOS), Iulian Ober (IRIT-ARGOS)", "title": "Certification of embedded systems based on Machine Learning: A survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in machine learning (ML) open the way to innovating functions in the\navionic domain, such as navigation/surveillance assistance (e.g. vision-based\nnavigation, obstacle sensing, virtual sensing), speechto-text applications,\nautonomous flight, predictive maintenance or cockpit assistance. Current\ncertification standards and practices, which were defined and refined decades\nover decades with classical programming in mind, do not however support this\nnew development paradigm. This article provides an overview of the main\nchallenges raised by the use ML in the demonstration of compliance with\nregulation requirements, and a survey of literature relevant to these\nchallenges, with particular focus on the issues of robustness and\nexplainability of ML results.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 08:12:05 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Vidot", "Guillaume", "", "IRIT-ARGOS"], ["Gabreau", "Christophe", "", "IRIT-ARGOS"], ["Ober", "Ileana", "", "IRIT-ARGOS"], ["Ober", "Iulian", "", "IRIT-ARGOS"]]}, {"id": "2106.07237", "submitter": "Arthur Jacobs M", "authors": "Arthur M. Jacobs and Annette Kinder", "title": "Is Einstein more agreeable and less neurotic than Hitler? A\n  computational exploration of the emotional and personality profiles of\n  historical persons", "comments": "20 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent progress in distributed semantic models (DSM) offers new ways to\nestimate personality traits of both fictive and real people. In this\nexploratory study we applied an extended version of the algorithm developed in\nJacobs (2019) to compute the likeability scores, emotional figure profiles and\nBIG5 personality traits for 100 historical persons from the arts, politics or\nscience domains whose names are rather unique (e.g., Einstein, Kahlo, Picasso).\nWe compared the results produced by static (word2vec) and dynamic (BERT)\nlanguage model representations in four studies. The results show both the\npotential and limitations of such DSM-based computations of personality\nprofiles and point ways to further develop this approach to become a useful\ntool in data science, psychology or computational and neurocognitive poetics\n(Jacobs, 2015).\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 08:45:49 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Jacobs", "Arthur M.", ""], ["Kinder", "Annette", ""]]}, {"id": "2106.07257", "submitter": "Abhishek Kaushik Mr.", "authors": "Mahak Sharma (1), Abhishek Kaushik (2), Rajesh Kumar (3), Sushant\n  Kumar Rai (3), Harshada Hanumant Desai (3) and Sargam Yadav (3) ((1) Vidhya\n  Bhawan Gandhiyan Institute of Educational Studies,(2) Dublin City University,\n  Ireland,(3) Dublin Business School, Dublin, Ireland)", "title": "Communication is the universal solvent: atreya bot -- an interactive bot\n  for chemical scientists", "comments": "IFIP 9.4 2021 1st Virtual Conference Conference Theme: Resilient\n  ICT4D May 25th 28th, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Conversational agents are a recent trend in human-computer interaction,\ndeployed in multidisciplinary applications to assist the users. In this paper,\nwe introduce \"Atreya\", an interactive bot for chemistry enthusiasts,\nresearchers, and students to study the ChEMBL database. Atreya is hosted by\nTelegram, a popular cloud-based instant messaging application. This\nuser-friendly bot queries the ChEMBL database, retrieves the drug details for a\nparticular disease, targets associated with that drug, etc. This paper explores\nthe potential of using a conversational agent to assist chemistry students and\nchemical scientist in complex information seeking process.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 09:20:44 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Sharma", "Mahak", ""], ["Kaushik", "Abhishek", ""], ["Kumar", "Rajesh", ""], ["Rai", "Sushant Kumar", ""], ["Desai", "Harshada Hanumant", ""], ["Yadav", "Sargam", ""]]}, {"id": "2106.07275", "submitter": "David Thulke", "authors": "Nico Daheim, David Thulke, Christian Dugast, Hermann Ney", "title": "Cascaded Span Extraction and Response Generation for Document-Grounded\n  Dialog", "comments": "Accepted by 1st DialDoc Workshop at ACL-IJCNLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper summarizes our entries to both subtasks of the first DialDoc\nshared task which focuses on the agent response prediction task in\ngoal-oriented document-grounded dialogs. The task is split into two subtasks:\npredicting a span in a document that grounds an agent turn and generating an\nagent response based on a dialog and grounding document. In the first subtask,\nwe restrict the set of valid spans to the ones defined in the dataset, use a\nbiaffine classifier to model spans, and finally use an ensemble of different\nmodels. For the second subtask, we use a cascaded model which grounds the\nresponse prediction on the predicted span instead of the full document. With\nthese approaches, we obtain significant improvements in both subtasks compared\nto the baseline.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 10:04:53 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Daheim", "Nico", ""], ["Thulke", "David", ""], ["Dugast", "Christian", ""], ["Ney", "Hermann", ""]]}, {"id": "2106.07278", "submitter": "Kate Rakelly", "authors": "Kate Rakelly, Abhishek Gupta, Carlos Florensa, Sergey Levine", "title": "Which Mutual-Information Representation Learning Objectives are\n  Sufficient for Control?", "comments": "18 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mutual information maximization provides an appealing formalism for learning\nrepresentations of data. In the context of reinforcement learning (RL), such\nrepresentations can accelerate learning by discarding irrelevant and redundant\ninformation, while retaining the information necessary for control. Much of the\nprior work on these methods has addressed the practical difficulties of\nestimating mutual information from samples of high-dimensional observations,\nwhile comparatively less is understood about which mutual information\nobjectives yield representations that are sufficient for RL from a theoretical\nperspective. In this paper, we formalize the sufficiency of a state\nrepresentation for learning and representing the optimal policy, and study\nseveral popular mutual-information based objectives through this lens.\nSurprisingly, we find that two of these objectives can yield insufficient\nrepresentations given mild and common assumptions on the structure of the MDP.\nWe corroborate our theoretical results with empirical experiments on a\nsimulated game environment with visual observations.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 10:12:34 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Rakelly", "Kate", ""], ["Gupta", "Abhishek", ""], ["Florensa", "Carlos", ""], ["Levine", "Sergey", ""]]}, {"id": "2106.07285", "submitter": "Israa Alghanmi", "authors": "Israa Alghanmi, Luis Espinosa-Anke, Steven Schockaert", "title": "Probing Pre-Trained Language Models for Disease Knowledge", "comments": "Accepted by ACL 2021 Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pre-trained language models such as ClinicalBERT have achieved impressive\nresults on tasks such as medical Natural Language Inference. At first glance,\nthis may suggest that these models are able to perform medical reasoning tasks,\nsuch as mapping symptoms to diseases. However, we find that standard benchmarks\nsuch as MedNLI contain relatively few examples that require such forms of\nreasoning. To better understand the medical reasoning capabilities of existing\nlanguage models, in this paper we introduce DisKnE, a new benchmark for Disease\nKnowledge Evaluation. To construct this benchmark, we annotated each positive\nMedNLI example with the types of medical reasoning that are needed. We then\ncreated negative examples by corrupting these positive examples in an\nadversarial way. Furthermore, we define training-test splits per disease,\nensuring that no knowledge about test diseases can be learned from the training\ndata, and we canonicalize the formulation of the hypotheses to avoid the\npresence of artefacts. This leads to a number of binary classification\nproblems, one for each type of reasoning and each disease. When analysing\npre-trained models for the clinical/biomedical domain on the proposed\nbenchmark, we find that their performance drops considerably.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 10:31:25 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Alghanmi", "Israa", ""], ["Espinosa-Anke", "Luis", ""], ["Schockaert", "Steven", ""]]}, {"id": "2106.07288", "submitter": "Xijun Li", "authors": "Yingtian Tang, Han Lu, Xijun Li, Lei Chen, Mingxuan Yuan and Jia Zeng", "title": "Learning-Aided Heuristics Design for Storage System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Computer systems such as storage systems normally require transparent\nwhite-box algorithms that are interpretable for human experts. In this work, we\npropose a learning-aided heuristic design method, which automatically generates\nhuman-readable strategies from Deep Reinforcement Learning (DRL) agents. This\nmethod benefits from the power of deep learning but avoids the shortcoming of\nits black-box property. Besides the white-box advantage, experiments in our\nstorage productions resource allocation scenario also show that this solution\noutperforms the systems default settings and the elaborately handcrafted\nstrategy by human experts.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 10:35:11 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Tang", "Yingtian", ""], ["Lu", "Han", ""], ["Li", "Xijun", ""], ["Chen", "Lei", ""], ["Yuan", "Mingxuan", ""], ["Zeng", "Jia", ""]]}, {"id": "2106.07296", "submitter": "Rafel Palliser Sans", "authors": "Rafel Palliser-Sans", "title": "RRULES: An improvement of the RULES rule-based classifier", "comments": "6 pages, 2 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  RRULES is presented as an improvement and optimization over RULES, a simple\ninductive learning algorithm for extracting IF-THEN rules from a set of\ntraining examples. RRULES optimizes the algorithm by implementing a more\neffective mechanism to detect irrelevant rules, at the same time that checks\nthe stopping conditions more often. This results in a more compact rule set\ncontaining more general rules which prevent overfitting the training set and\nobtain a higher test accuracy. Moreover, the results show that RRULES\noutperforms the original algorithm by reducing the coverage rate up to a factor\nof 7 while running twice or three times faster consistently over several\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 10:42:12 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Palliser-Sans", "Rafel", ""]]}, {"id": "2106.07297", "submitter": "Ralph Abboud", "authors": "Ralph Abboud, \\.Ismail \\.Ilkan Ceylan", "title": "Node Classification Meets Link Prediction on Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Node classification and link prediction are widely studied tasks in graph\nrepresentation learning. While both transductive node classification and link\nprediction operate over a single input graph, they are studied in isolation so\nfar, which leads to discrepancies. Node classification models take as input a\ngraph with node features and incomplete node labels, and implicitly assume that\nthe input graph is relationally complete, i.e., no edges are missing from the\ninput graph. This is in sharp contrast with link prediction models that are\nsolely motivated by the relational incompleteness of the input graph which does\nnot have any node features. We propose a unifying perspective and study the\nproblems of (i) transductive node classification over incomplete graphs and\n(ii) link prediction over graphs with node features. We propose an extension to\nan existing box embedding model, and show that this model is fully expressive,\nand can solve both of these tasks in an end-to-end fashion. To empirically\nevaluate our model, we construct a knowledge graph with node features, which is\nchallenging both for node classification and link prediction. Our model\nperforms very strongly when compared to the respective state-of-the-art models\nfor node classification and link prediction on this dataset and shows the\nimportance of a unified perspective for node classification and link prediction\non knowledge graphs.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 10:52:52 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Abboud", "Ralph", ""], ["Ceylan", "\u0130smail \u0130lkan", ""]]}, {"id": "2106.07307", "submitter": "Shahid Alam", "authors": "Shahid Alam, Juvariya Khan", "title": "A Recipe for Social Media Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Ubiquitous nature of smartphones has significantly increased the use of\nsocial media platforms, such as Facebook, Twitter, TikTok, and LinkedIn, etc.,\namong the public, government, and businesses. Facebook generated ~70 billion\nUSD in 2019 in advertisement revenues alone, a ~27% increase from the previous\nyear. Social media has also played a strong role in outbreaks of social\nprotests responsible for political changes in different countries. As we can\nsee from the above examples, social media plays a big role in business\nintelligence and international politics. In this paper, we present and discuss\na high-level functional intelligence model (recipe) of Social Media Analysis\n(SMA). This model synthesizes the input data and uses operational intelligence\nto provide actionable recommendations. In addition, it also matches the\nsynthesized function of the experiences and learning gained from the\nenvironment. The SMA model presented is independent of the application domain,\nand can be applied to different domains, such as Education, Healthcare and\nGovernment, etc. Finally, we also present some of the challenges faced by SMA\nand how the SMA model presented in this paper solves them.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 11:27:33 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Alam", "Shahid", ""], ["Khan", "Juvariya", ""]]}, {"id": "2106.07317", "submitter": "Alexandru-Ionut Imbrea", "authors": "Alexandru-Ionut Imbrea", "title": "Automated Machine Learning Techniques for Data Streams", "comments": "11 pages, 14 figures, Originally published as\n  https://essay.utwente.nl/80548 at the 32nd Twente Student Conference on IT\n  Jan. 31st, 2019, Enschede, The Netherlands, Supervised by: dr. Doina Bucur,\n  dr. Claudio Pinho Rebelo de S\\'a", "journal-ref": null, "doi": null, "report-no": "UTwente Essay no: 80548", "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automated machine learning techniques benefited from tremendous research\nprogress in recently. These developments and the continuous-growing demand for\nmachine learning experts led to the development of numerous AutoML tools.\nHowever, these tools assume that the entire training dataset is available\nupfront and that the underlying distribution does not change over time. These\nassumptions do not hold in a data stream mining setting where an unbounded\nstream of data cannot be stored and is likely to manifest concept drift.\nIndustry applications of machine learning on streaming data become more popular\ndue to the increasing adoption of real-time streaming patterns in IoT,\nmicroservices architectures, web analytics, and other fields. The research\nsummarized in this paper surveys the state-of-the-art open-source AutoML tools,\napplies them to data collected from streams, and measures how their performance\nchanges over time. For comparative purposes, batch, batch incremental and\ninstance incremental estimators are applied and compared. Moreover, a\nmeta-learning technique for online algorithm selection based on meta-feature\nextraction is proposed and compared while model replacement and continual\nAutoML techniques are discussed. The results show that off-the-shelf AutoML\ntools can provide satisfactory results but in the presence of concept drift,\ndetection or adaptation techniques have to be applied to maintain the\npredictive accuracy over time.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 11:42:46 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Imbrea", "Alexandru-Ionut", ""]]}, {"id": "2106.07329", "submitter": "Yiming Zhang", "authors": "Yiming Zhang, Keith W. Ross", "title": "On-Policy Deep Reinforcement Learning for the Average-Reward Criterion", "comments": "International Conference on Machine Learning (ICML) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We develop theory and algorithms for average-reward on-policy Reinforcement\nLearning (RL). We first consider bounding the difference of the long-term\naverage reward for two policies. We show that previous work based on the\ndiscounted return (Schulman et al., 2015; Achiam et al., 2017) results in a\nnon-meaningful bound in the average-reward setting. By addressing the\naverage-reward criterion directly, we then derive a novel bound which depends\non the average divergence between the two policies and Kemeny's constant. Based\non this bound, we develop an iterative procedure which produces a sequence of\nmonotonically improved policies for the average reward criterion. This\niterative procedure can then be combined with classic DRL (Deep Reinforcement\nLearning) methods, resulting in practical DRL algorithms that target the\nlong-run average reward criterion. In particular, we demonstrate that\nAverage-Reward TRPO (ATRPO), which adapts the on-policy TRPO algorithm to the\naverage-reward criterion, significantly outperforms TRPO in the most\nchallenging MuJuCo environments.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 12:12:09 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Zhang", "Yiming", ""], ["Ross", "Keith W.", ""]]}, {"id": "2106.07338", "submitter": "Nidhika Yadav", "authors": "Nidhika Yadav", "title": "Neighborhood Rough Set based Multi-document Summarization", "comments": "7 pages, original paper not submitted anywhere else", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This research paper proposes a novel Neighbourhood Rough Set based approach\nfor supervised Multi-document Text Summarization (MDTS) with analysis and\nimpact on the summarization results for MDTS. Here, Rough Set based LERS\nalgorithm is improved using Neighborhood Rough Set which is itself a novel\ncombination called Neighborhood-LERS to be experimented for evaluations of\nefficacy and efficiency. In this paper, we shall apply and evaluate the\nproposed Neighborhood-LERS for Multi-document Summarization which here is\nproved experimentally to be superior to the base LERS technique for MDTS.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 00:43:20 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Yadav", "Nidhika", ""]]}, {"id": "2106.07340", "submitter": "Jia Shen", "authors": "Jia Tracy Shen, Michiharu Yamashita, Ethan Prihar, Neil Heffernan,\n  Xintao Wu, Dongwon Lee", "title": "MathBERT: A Pre-trained Language Model for General NLP Tasks in\n  Mathematics Education", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Due to the transfer learning nature of BERT model, researchers have achieved\nbetter performance than base BERT by further pre-training the original BERT on\na huge domain-specific corpus. Due to the special nature of mathematical texts\nwhich often contain math equations and symbols, the original BERT model\npre-trained on general English context will not fit Natural Language Processing\n(NLP) tasks in mathematical education well. Therefore, we propose MathBERT, a\nBERT pre-trained on large mathematical corpus including pre-k to graduate level\nmathematical content to tackle math-specific tasks. In addition, We generate a\ncustomized mathematical vocabulary to pre-train with MathBERT and compare the\nperformance to the MathBERT pre-trained with the original BERT vocabulary. We\nselect three important tasks in mathematical education such as knowledge\ncomponent, auto-grading, and knowledge tracing prediction to evaluate the\nperformance of MathBERT. Our experiments show that MathBERT outperforms the\nbase BERT by 2-9\\% margin. In some cases, MathBERT pre-trained with\nmathematical vocabulary is better than MathBERT trained with original\nvocabulary.To our best knowledge, MathBERT is the first pre-trained model for\ngeneral purpose mathematics education tasks.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 02:43:18 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Shen", "Jia Tracy", ""], ["Yamashita", "Michiharu", ""], ["Prihar", "Ethan", ""], ["Heffernan", "Neil", ""], ["Wu", "Xintao", ""], ["Lee", "Dongwon", ""]]}, {"id": "2106.07343", "submitter": "Yutai Hou", "authors": "Yutai Hou, Yongkui Lai, Cheng Chen, Wanxiang Che, Ting Liu", "title": "Learning to Bridge Metric Spaces: Few-shot Joint Learning of Intent\n  Detection and Slot Filling", "comments": "Accepted by ACL 2021 findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate few-shot joint learning for dialogue language\nunderstanding. Most existing few-shot models learn a single task each time with\nonly a few examples. However, dialogue language understanding contains two\nclosely related tasks, i.e., intent detection and slot filling, and often\nbenefits from jointly learning the two tasks. This calls for new few-shot\nlearning techniques that are able to capture task relations from only a few\nexamples and jointly learn multiple tasks. To achieve this, we propose a\nsimilarity-based few-shot learning scheme, named Contrastive Prototype Merging\nnetwork (ConProm), that learns to bridge metric spaces of intent and slot on\ndata-rich domains, and then adapt the bridged metric space to the specific\nfew-shot domain. Experiments on two public datasets, Snips and FewJoint, show\nthat our model significantly outperforms the strong baselines in one and five\nshots settings.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 15:07:11 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Hou", "Yutai", ""], ["Lai", "Yongkui", ""], ["Chen", "Cheng", ""], ["Che", "Wanxiang", ""], ["Liu", "Ting", ""]]}, {"id": "2106.07345", "submitter": "Taeuk Kim", "authors": "Taeuk Kim, Kang Min Yoo, Sang-goo Lee", "title": "Self-Guided Contrastive Learning for BERT Sentence Representations", "comments": "ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although BERT and its variants have reshaped the NLP landscape, it still\nremains unclear how best to derive sentence embeddings from such pre-trained\nTransformers. In this work, we propose a contrastive learning method that\nutilizes self-guidance for improving the quality of BERT sentence\nrepresentations. Our method fine-tunes BERT in a self-supervised fashion, does\nnot rely on data augmentation, and enables the usual [CLS] token embeddings to\nfunction as sentence vectors. Moreover, we redesign the contrastive learning\nobjective (NT-Xent) and apply it to sentence representation learning. We\ndemonstrate with extensive experiments that our approach is more effective than\ncompetitive baselines on diverse sentence-related tasks. We also show it is\nefficient at inference and robust to domain shifts.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 05:52:43 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Kim", "Taeuk", ""], ["Yoo", "Kang Min", ""], ["Lee", "Sang-goo", ""]]}, {"id": "2106.07350", "submitter": "Zhe Liu", "authors": "Zhe Liu and Yibin Xu", "title": "THG: Transformer with Hyperbolic Geometry", "comments": "6 pages,3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer model architectures have become an indispensable staple in deep\nlearning lately for their effectiveness across a range of tasks. Recently, a\nsurge of \"X-former\" models have been proposed which improve upon the original\nTransformer architecture. However, most of these variants make changes only\naround the quadratic time and memory complexity of self-attention, i.e. the dot\nproduct between the query and the key. What's more, they are calculate solely\nin Euclidean space. In this work, we propose a novel Transformer with\nHyperbolic Geometry (THG) model, which take the advantage of both Euclidean\nspace and Hyperbolic space. THG makes improvements in linear transformations of\nself-attention, which are applied on the input sequence to get the query and\nthe key, with the proposed hyperbolic linear. Extensive experiments on sequence\nlabeling task, machine reading comprehension task and classification task\ndemonstrate the effectiveness and generalizability of our model. It also\ndemonstrates THG could alleviate overfitting.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 14:09:33 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Liu", "Zhe", ""], ["Xu", "Yibin", ""]]}, {"id": "2106.07353", "submitter": "Yifan Ding", "authors": "Yifan Ding, Nicholas Botzer, Tim Weninger", "title": "Posthoc Verification and the Fallibility of the Ground Truth", "comments": "12 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Classifiers commonly make use of pre-annotated datasets, wherein a model is\nevaluated by pre-defined metrics on a held-out test set typically made of\nhuman-annotated labels. Metrics used in these evaluations are tied to the\navailability of well-defined ground truth labels, and these metrics typically\ndo not allow for inexact matches. These noisy ground truth labels and strict\nevaluation metrics may compromise the validity and realism of evaluation\nresults. In the present work, we discuss these concerns and conduct a\nsystematic posthoc verification experiment on the entity linking (EL) task.\nUnlike traditional methodologies, which asks annotators to provide free-form\nannotations, we ask annotators to verify the correctness of annotations after\nthe fact (i.e., posthoc). Compared to pre-annotation evaluation,\nstate-of-the-art EL models performed extremely well according to the posthoc\nevaluation methodology. Posthoc validation also permits the validation of the\nground truth dataset. Surprisingly, we find predictions from EL models had a\nsimilar or higher verification rate than the ground truth. We conclude with a\ndiscussion on these findings and recommendations for future evaluations.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 17:57:09 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Ding", "Yifan", ""], ["Botzer", "Nicholas", ""], ["Weninger", "Tim", ""]]}, {"id": "2106.07378", "submitter": "Marco Cinelli", "authors": "Marco Cinelli, Mi{\\l}osz Kadzi\\'nski, Grzegorz Miebs, Michael\n  Gonzalez, Roman S{\\l}owi\\'nski", "title": "Recommending Multiple Criteria Decision Analysis Methods with A New\n  Taxonomy-based Decision Support System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.OH", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present the Multiple Criteria Decision Analysis Methods Selection Software\n(MCDA-MSS). This decision support system helps analysts answering a recurring\nquestion in decision science: Which is the most suitable Multiple Criteria\nDecision Analysis method (or a subset of MCDA methods) that should be used for\na given Decision-Making Problem (DMP)?. The MCDA-MSS includes guidance to lead\ndecision-making processes and choose among an extensive collection (over 200)\nof MCDA methods. These are assessed according to an original comprehensive set\nof problem characteristics. The accounted features concern problem formulation,\npreference elicitation and types of preference information, desired features of\na preference model, and construction of the decision recommendation. The\napplicability of the MCDA-MSS has been tested on several case studies. The\nMCDA-MSS includes the capabilities of (i) covering from very simple to very\ncomplex DMPs, (ii) offering recommendations for DMPs that do not match any\nmethod from the collection, (iii) helping analysts prioritize efforts for\nreducing gaps in the description of the DMPs, and (iv) unveiling methodological\nmistakes that occur in the selection of the methods. A community-wide\ninitiative involving experts in MCDA methodology, analysts using these methods,\nand decision-makers receiving decision recommendations will contribute to\nexpansion of the MCDA-MSS.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 16:03:45 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Cinelli", "Marco", ""], ["Kadzi\u0144ski", "Mi\u0142osz", ""], ["Miebs", "Grzegorz", ""], ["Gonzalez", "Michael", ""], ["S\u0142owi\u0144ski", "Roman", ""]]}, {"id": "2106.07381", "submitter": "Li Dong", "authors": "Li Dong, Matthew C. Spencer, Amir Biagi", "title": "A Semi-supervised Multi-task Learning Approach to Classify Customer\n  Contact Intents", "comments": "To be published in ACL-IJCNLP 2021 workshop ECNLP", "journal-ref": "https://aclanthology.org/2021.ecnlp-1.7/", "doi": "10.18653/v1/2021.ecnlp-1.7", "report-no": "2021.ecnlp-1.7", "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the area of customer support, understanding customers' intents is a\ncrucial step. Machine learning plays a vital role in this type of intent\nclassification. In reality, it is typical to collect confirmation from customer\nsupport representatives (CSRs) regarding the intent prediction, though it can\nunnecessarily incur prohibitive cost to ask CSRs to assign existing or new\nintents to the mis-classified cases. Apart from the confirmed cases with and\nwithout intent labels, there can be a number of cases with no human curation.\nThis data composition (Positives + Unlabeled + multiclass Negatives) creates\nunique challenges for model development. In response to that, we propose a\nsemi-supervised multi-task learning paradigm. In this manuscript, we share our\nexperience in building text-based intent classification models for a customer\nsupport service on an E-commerce website. We improve the performance\nsignificantly by evolving the model from multiclass classification to\nsemi-supervised multi-task learning by leveraging the negative cases, domain-\nand task-adaptively pretrained ALBERT on customer contact texts, and a number\nof un-curated data with no labels. In the evaluation, the final model boosts\nthe average AUC ROC by almost 20 points compared to the baseline finetuned\nmulticlass classification ALBERT model.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 16:13:05 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Dong", "Li", ""], ["Spencer", "Matthew C.", ""], ["Biagi", "Amir", ""]]}, {"id": "2106.07385", "submitter": "Jennifer D'Souza", "authors": "Jennifer D'Souza, S\\\"oren Auer and Ted Pedersen", "title": "SemEval-2021 Task 11: NLPContributionGraph -- Structuring Scholarly NLP\n  Contributions for a Research Knowledge Graph", "comments": "13 pages, 5 figures, 8 tables, In Proceedings of the Fifteenth\n  Workshop on Semantic Evaluation SemEval-2021 (to appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  There is currently a gap between the natural language expression of scholarly\npublications and their structured semantic content modeling to enable\nintelligent content search. With the volume of research growing exponentially\nevery year, a search feature operating over semantically structured content is\ncompelling. The SemEval-2021 Shared Task NLPContributionGraph (a.k.a. 'the NCG\ntask') tasks participants to develop automated systems that structure\ncontributions from NLP scholarly articles in the English language. Being the\nfirst-of-its-kind in the SemEval series, the task released structured data from\nNLP scholarly articles at three levels of information granularity, i.e. at\nsentence-level, phrase-level, and phrases organized as triples toward Knowledge\nGraph (KG) building. The sentence-level annotations comprised the few sentences\nabout the article's contribution. The phrase-level annotations were scientific\nterm and predicate phrases from the contribution sentences. Finally, the\ntriples constituted the research overview KG. For the Shared Task,\nparticipating systems were then expected to automatically classify contribution\nsentences, extract scientific terms and relations from the sentences, and\norganize them as KG triples.\n  Overall, the task drew a strong participation demographic of seven teams and\n27 participants. The best end-to-end task system classified contribution\nsentences at 57.27% F1, phrases at 46.41% F1, and triples at 22.28% F1. While\nthe absolute performance to generate triples remains low, in the conclusion of\nthis article, the difficulty of producing such data and as a consequence of\nmodeling it is highlighted.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 13:43:47 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 09:26:11 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["D'Souza", "Jennifer", ""], ["Auer", "S\u00f6ren", ""], ["Pedersen", "Ted", ""]]}, {"id": "2106.07387", "submitter": "Sabino Roselli", "authors": "Sabino Francesco Roselli and Martin Fabian and Knut {\\AA}kesson", "title": "An SMT Based Compositional Algorithm to Solve a Conflict-Free Electric\n  Vehicle Routing Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Vehicle Routing Problem (VRP) is the combinatorial optimization problem\nof designing routes for vehicles to visit customers in such a fashion that a\ncost function, typically the number of vehicles, or the total travelled\ndistance is minimized. The problem finds applications in industrial scenarios,\nfor example where Automated Guided Vehicles run through the plant to deliver\ncomponents from the warehouse. This specific problem, henceforth called the\nElectric Conflict-Free Vehicle Routing Problem (CF-EVRP), involves constraints\nsuch as limited operating range of the vehicles, time windows on the delivery\nto the customers, and limited capacity on the number of vehicles the road\nsegments can accommodate at the same time. Such a complex system results in a\nlarge model that cannot easily be solved to optimality in reasonable time. We\ntherefore developed a compositional model that breaks down the problem into\nsmaller and simpler sub-problems and provides sub-optimal, feasible solutions\nto the original problem. The algorithm exploits the strengths of SMT solvers,\nwhich proved in our previous work to be an efficient approach to deal with\nscheduling problems. Compared to a monolithic model for the CF-EVRP, written in\nthe SMT standard language and solved using a state-of-the-art SMT solver the\ncompositional model was found to be significantly faster.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 20:37:46 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 07:18:03 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Roselli", "Sabino Francesco", ""], ["Fabian", "Martin", ""], ["\u00c5kesson", "Knut", ""]]}, {"id": "2106.07393", "submitter": "Ka Wong", "authors": "Ka Wong, Praveen Paritosh, Lora Aroyo", "title": "Cross-replication Reliability -- An Empirical Approach to Interpreting\n  Inter-rater Reliability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.AI cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a new approach to interpreting IRR that is empirical and\ncontextualized. It is based upon benchmarking IRR against baseline measures in\na replication, one of which is a novel cross-replication reliability (xRR)\nmeasure based on Cohen's kappa. We call this approach the xRR framework. We\nopensource a replication dataset of 4 million human judgements of facial\nexpressions and analyze it with the proposed framework. We argue this framework\ncan be used to measure the quality of crowdsourced datasets.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 16:15:46 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Wong", "Ka", ""], ["Paritosh", "Praveen", ""], ["Aroyo", "Lora", ""]]}, {"id": "2106.07410", "submitter": "Nengfeng Zhou", "authors": "Shafie Gholizadeh and Nengfeng Zhou", "title": "Model Explainability in Deep Learning Based Natural Language Processing", "comments": "12 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) model explainability has received growing attention,\nespecially in the area related to model risk and regulations. In this paper, we\nreviewed and compared some popular ML model explainability methodologies,\nespecially those related to Natural Language Processing (NLP) models. We then\napplied one of the NLP explainability methods Layer-wise Relevance Propagation\n(LRP) to a NLP classification model. We used the LRP method to derive a\nrelevance score for each word in an instance, which is a local explainability.\nThe relevance scores are then aggregated together to achieve global variable\nimportance of the model. Through the case study, we also demonstrated how to\napply the local explainability method to false positive and false negative\ninstances to discover the weakness of a NLP model. These analysis can help us\nto understand NLP models better and reduce the risk due to the black-box nature\nof NLP models. We also identified some common issues due to the special natures\nof NLP models and discussed how explainability analysis can act as a control to\ndetect these issues after the model has been trained.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 13:23:20 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Gholizadeh", "Shafie", ""], ["Zhou", "Nengfeng", ""]]}, {"id": "2106.07411", "submitter": "Robert Geirhos", "authors": "Robert Geirhos, Kantharaju Narayanappa, Benjamin Mitzkus, Tizian\n  Thieringer, Matthias Bethge, Felix A. Wichmann, Wieland Brendel", "title": "Partial success in closing the gap between human and machine vision", "comments": "A preliminary version of this work was presented as Oral at the 2020\n  NeurIPS workshop on \"Shared Visual Representations in Human & Machine\n  Intelligence\" (arXiv:2010.08377)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A few years ago, the first CNN surpassed human performance on ImageNet.\nHowever, it soon became clear that machines lack robustness on more challenging\ntest cases, a major obstacle towards deploying machines \"in the wild\" and\ntowards obtaining better computational models of human visual perception. Here\nwe ask: Are we making progress in closing the gap between human and machine\nvision? To answer this question, we tested human observers on a broad range of\nout-of-distribution (OOD) datasets, adding the \"missing human baseline\" by\nrecording 85,120 psychophysical trials across 90 participants. We then\ninvestigated a range of promising machine learning developments that crucially\ndeviate from standard supervised CNNs along three axes: objective function\n(self-supervised, adversarially trained, CLIP language-image training),\narchitecture (e.g. vision transformers), and dataset size (ranging from 1M to\n1B). Our findings are threefold. (1.) The longstanding robustness gap between\nhumans and CNNs is closing, with the best models now matching or exceeding\nhuman performance on most OOD datasets. (2.) There is still a substantial\nimage-level consistency gap, meaning that humans make different errors than\nmodels. In contrast, most models systematically agree in their categorisation\nerrors, even substantially different ones like contrastive self-supervised vs.\nstandard supervised models. (3.) In many cases, human-to-model consistency\nimproves when training dataset size is increased by one to three orders of\nmagnitude. Our results give reason for cautious optimism: While there is still\nmuch room for improvement, the behavioural difference between human and machine\nvision is narrowing. In order to measure future progress, 17 OOD datasets with\nimage-level human behavioural data are provided as a benchmark here:\nhttps://github.com/bethgelab/model-vs-human/\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 13:23:35 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Geirhos", "Robert", ""], ["Narayanappa", "Kantharaju", ""], ["Mitzkus", "Benjamin", ""], ["Thieringer", "Tizian", ""], ["Bethge", "Matthias", ""], ["Wichmann", "Felix A.", ""], ["Brendel", "Wieland", ""]]}, {"id": "2106.07447", "submitter": "Wei-Ning Hsu", "authors": "Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia,\n  Ruslan Salakhutdinov, Abdelrahman Mohamed", "title": "HuBERT: Self-Supervised Speech Representation Learning by Masked\n  Prediction of Hidden Units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised approaches for speech representation learning are challenged\nby three unique problems: (1) there are multiple sound units in each input\nutterance, (2) there is no lexicon of input sound units during the pre-training\nphase, and (3) sound units have variable lengths with no explicit segmentation.\nTo deal with these three problems, we propose the Hidden-Unit BERT (HuBERT)\napproach for self-supervised speech representation learning, which utilizes an\noffline clustering step to provide aligned target labels for a BERT-like\nprediction loss. A key ingredient of our approach is applying the prediction\nloss over the masked regions only, which forces the model to learn a combined\nacoustic and language model over the continuous inputs. HuBERT relies primarily\non the consistency of the unsupervised clustering step rather than the\nintrinsic quality of the assigned cluster labels. Starting with a simple\nk-means teacher of 100 clusters, and using two iterations of clustering, the\nHuBERT model either matches or improves upon the state-of-the-art wav2vec 2.0\nperformance on the Librispeech (960h) and Libri-light (60,000h) benchmarks with\n10min, 1h, 10h, 100h, and 960h fine-tuning subsets. Using a 1B parameter model,\nHuBERT shows up to 19% and 13% relative WER reduction on the more challenging\ndev-other and test-other evaluation subsets.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 14:14:28 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Hsu", "Wei-Ning", ""], ["Bolte", "Benjamin", ""], ["Tsai", "Yao-Hung Hubert", ""], ["Lakhotia", "Kushal", ""], ["Salakhutdinov", "Ruslan", ""], ["Mohamed", "Abdelrahman", ""]]}, {"id": "2106.07448", "submitter": "Eysan Mehrbani", "authors": "Ezsan Mehrbani, Sezedeh Fatemeh Mirhoseini, Noushin Riahi", "title": "A Novel mapping for visual to auditory sensory substitution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.CV eess.AS eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  visual information can be converted into audio stream via sensory\nsubstitution devices in order to give visually impaired people the chance of\nperception of their surrounding easily and simultaneous to performing everyday\ntasks. In this study, visual environmental features namely, coordinate, type of\nobjects and their size are assigned to audio features related to music tones\nsuch as frequency, time duration and note permutations. Results demonstrated\nthat this new method has more training time efficiency in comparison with our\nprevious method named VBTones which sinusoidal tones were applied. Moreover,\nresults in blind object recognition for real objects was achieved 88.05 on\naverage.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 14:14:50 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Mehrbani", "Ezsan", ""], ["Mirhoseini", "Sezedeh Fatemeh", ""], ["Riahi", "Noushin", ""]]}, {"id": "2106.07453", "submitter": "Quanming Yao", "authors": "Chen Gao and Quanming Yao and Depeng Jin and Yong Li", "title": "Efficient Data-specific Model Search for Collaborative Filtering", "comments": "KDD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Collaborative filtering (CF), as a fundamental approach for recommender\nsystems, is usually built on the latent factor model with learnable parameters\nto predict users' preferences towards items. However, designing a proper CF\nmodel for a given data is not easy, since the properties of datasets are highly\ndiverse. In this paper, motivated by the recent advances in automated machine\nlearning (AutoML), we propose to design a data-specific CF model by AutoML\ntechniques. The key here is a new framework that unifies state-of-the-art\n(SOTA) CF methods and splits them into disjoint stages of input encoding,\nembedding function, interaction function, and prediction function. We further\ndevelop an easy-to-use, robust, and efficient search strategy, which utilizes\nrandom search and a performance predictor for efficient searching within the\nabove framework. In this way, we can combinatorially generalize data-specific\nCF models, which have not been visited in the literature, from SOTA ones.\nExtensive experiments on five real-world datasets demonstrate that our method\ncan consistently outperform SOTA ones for various CF tasks. Further experiments\nverify the rationality of the proposed framework and the efficiency of the\nsearch strategy. The searched CF models can also provide insights for exploring\nmore effective methods in the future\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 14:30:32 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Gao", "Chen", ""], ["Yao", "Quanming", ""], ["Jin", "Depeng", ""], ["Li", "Yong", ""]]}, {"id": "2106.07454", "submitter": "Minghan Yang", "authors": "Minghan Yang, Dong Xu, Qiwen Cui, Zaiwen Wen and Pengxiang Xu", "title": "NG+ : A Multi-Step Matrix-Product Natural Gradient Method for Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a novel second-order method called NG+ is proposed. By\nfollowing the rule ``the shape of the gradient equals the shape of the\nparameter\", we define a generalized fisher information matrix (GFIM) using the\nproducts of gradients in the matrix form rather than the traditional\nvectorization. Then, our generalized natural gradient direction is simply the\ninverse of the GFIM multiplies the gradient in the matrix form. Moreover, the\nGFIM and its inverse keeps the same for multiple steps so that the\ncomputational cost can be controlled and is comparable with the first-order\nmethods. A global convergence is established under some mild conditions and a\nregret bound is also given for the online learning setting. Numerical results\non image classification with ResNet50, quantum chemistry modeling with Schnet,\nneural machine translation with Transformer and recommendation system with DLRM\nillustrate that GN+ is competitive with the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 14:31:31 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Yang", "Minghan", ""], ["Xu", "Dong", ""], ["Cui", "Qiwen", ""], ["Wen", "Zaiwen", ""], ["Xu", "Pengxiang", ""]]}, {"id": "2106.07464", "submitter": "Stassa Patsantzis", "authors": "Stassa Patsantzis and Stephen H. Muggleton", "title": "Meta-Interpretive Learning as Metarule Specialisation", "comments": "24 pages. Submitted to the Machine Learning Journal Special Issue on\n  Learning and Reasoning on June 1st, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Meta-Interpretive Learning (MIL) the metarules, second-order datalog\nclauses acting as inductive bias, are manually defined by the user. In this\nwork we show that second-order metarules for MIL can be learned by MIL. We\ndefine a generality ordering of metarules by $\\theta$-subsumption and show that\nuser-defined sort metarules are derivable by specialisation of the most-general\nmatrix metarules in a language class; and that these matrix metarules are in\nturn derivable by specialisation of third-order punch metarules with variables\nthat range over the set of second-order literals and for which only an upper\nbound on their number of literals need be user-defined. We show that the\ncardinality of a metarule language is polynomial in the number of literals in\npunch metarules. We re-frame MIL as metarule specialisation by resolution. We\nmodify the MIL metarule specialisation operator to return new metarules rather\nthan first-order clauses and prove the correctness of the new operator. We\nimplement the new operator as TOIL, a sub-system of the MIL system Louise. Our\nexperiments show that as user-defined sort metarules are progressively replaced\nby sort metarules learned by TOIL, Louise's predictive accuracy is maintained\nat the cost of a small increase in training times. We conclude that\nautomatically derived metarules can replace user-defined metarules.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 16:01:27 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Patsantzis", "Stassa", ""], ["Muggleton", "Stephen H.", ""]]}, {"id": "2106.07475", "submitter": "Narine Kokhlikyan", "authors": "Narine Kokhlikyan, Vivek Miglani, Bilal Alsallakh, Miguel Martin and\n  Orion Reblitz-Richardson", "title": "Investigating sanity checks for saliency maps with image and text\n  classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Saliency maps have shown to be both useful and misleading for explaining\nmodel predictions especially in the context of images. In this paper, we\nperform sanity checks for text modality and show that the conclusions made for\nimage do not directly transfer to text. We also analyze the effects of the\ninput multiplier in certain saliency maps using similarity scores,\nmax-sensitivity and infidelity evaluation metrics. Our observations reveal that\nthe input multiplier carries input's structural patterns in explanation maps,\nthus leading to similar results regardless of the choice of model parameters.\nWe also show that the smoothness of a Neural Network (NN) function can affect\nthe quality of saliency-based explanations. Our investigations reveal that\nreplacing ReLUs with Softplus and MaxPool with smoother variants such as\nLogSumExp (LSE) can lead to explanations that are more reliable based on the\ninfidelity evaluation metric.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 23:23:42 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Kokhlikyan", "Narine", ""], ["Miglani", "Vivek", ""], ["Alsallakh", "Bilal", ""], ["Martin", "Miguel", ""], ["Reblitz-Richardson", "Orion", ""]]}, {"id": "2106.07476", "submitter": "Guohao Li", "authors": "Guohao Li, Matthias M\\\"uller, Bernard Ghanem, Vladlen Koltun", "title": "Training Graph Neural Networks with 1000 Layers", "comments": "Accepted at ICML'2021. Code available at\n  https://www.deepgcns.org/arch/gnn1000. Work done during Guohao Li's\n  internship at Intel Intelligent Systems Lab", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep graph neural networks (GNNs) have achieved excellent results on various\ntasks on increasingly large graph datasets with millions of nodes and edges.\nHowever, memory complexity has become a major obstacle when training deep GNNs\nfor practical applications due to the immense number of nodes, edges, and\nintermediate activations. To improve the scalability of GNNs, prior works\npropose smart graph sampling or partitioning strategies to train GNNs with a\nsmaller set of nodes or sub-graphs. In this work, we study reversible\nconnections, group convolutions, weight tying, and equilibrium models to\nadvance the memory and parameter efficiency of GNNs. We find that reversible\nconnections in combination with deep network architectures enable the training\nof overparameterized GNNs that significantly outperform existing methods on\nmultiple datasets. Our models RevGNN-Deep (1001 layers with 80 channels each)\nand RevGNN-Wide (448 layers with 224 channels each) were both trained on a\nsingle commodity GPU and achieve an ROC-AUC of $87.74 \\pm 0.13$ and $88.24 \\pm\n0.15$ on the ogbn-proteins dataset. To the best of our knowledge, RevGNN-Deep\nis the deepest GNN in the literature by one order of magnitude. Please visit\nour project website https://www.deepgcns.org/arch/gnn1000 for more information.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 15:03:00 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 03:26:23 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Li", "Guohao", ""], ["M\u00fcller", "Matthias", ""], ["Ghanem", "Bernard", ""], ["Koltun", "Vladlen", ""]]}, {"id": "2106.07477", "submitter": "Ping Li", "authors": "Tan Yu, Xu Li, Yunfeng Cai, Mingming Sun, Ping Li", "title": "S$^2$-MLP: Spatial-Shift MLP Architecture for Vision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, visual Transformer (ViT) and its following works abandon the\nconvolution and exploit the self-attention operation, attaining a comparable or\neven higher accuracy than CNNs. More recently, MLP-Mixer abandons both the\nconvolution and the self-attention operation, proposing an architecture\ncontaining only MLP layers. To achieve cross-patch communications, it devises\nan additional token-mixing MLP besides the channel-mixing MLP. It achieves\npromising results when training on an extremely large-scale dataset. But it\ncannot achieve as outstanding performance as its CNN and ViT counterparts when\ntraining on medium-scale datasets such as ImageNet1K and ImageNet21K. The\nperformance drop of MLP-Mixer motivates us to rethink the token-mixing MLP. We\ndiscover that the token-mixing MLP is a variant of the depthwise convolution\nwith a global reception field and spatial-specific configuration. But the\nglobal reception field and the spatial-specific property make token-mixing MLP\nprone to over-fitting. In this paper, we propose a novel pure MLP architecture,\nspatial-shift MLP (S$^2$-MLP). Different from MLP-Mixer, our S$^2$-MLP only\ncontains channel-mixing MLP. We utilize a spatial-shift operation for\ncommunications between patches. It has a local reception field and is\nspatial-agnostic. It is parameter-free and efficient for computation. The\nproposed S$^2$-MLP attains higher recognition accuracy than MLP-Mixer when\ntraining on ImageNet-1K dataset. Meanwhile, S$^2$-MLP accomplishes as excellent\nperformance as ViT on ImageNet-1K dataset with considerably simpler\narchitecture and fewer FLOPs and parameters.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 15:05:11 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 17:58:04 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Yu", "Tan", ""], ["Li", "Xu", ""], ["Cai", "Yunfeng", ""], ["Sun", "Mingming", ""], ["Li", "Ping", ""]]}, {"id": "2106.07479", "submitter": "Rudrasis Chakraborty Dr.", "authors": "Zihang Meng, Rudrasis Chakraborty, Vikas Singh", "title": "An Online Riemannian PCA for Stochastic Canonical Correlation Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present an efficient stochastic algorithm (RSG+) for canonical correlation\nanalysis (CCA) using a reparametrization of the projection matrices. We show\nhow this reparametrization (into structured matrices), simple in hindsight,\ndirectly presents an opportunity to repurpose/adjust mature techniques for\nnumerical optimization on Riemannian manifolds. Our developments nicely\ncomplement existing methods for this problem which either require $O(d^3)$ time\ncomplexity per iteration with $O(\\frac{1}{\\sqrt{t}})$ convergence rate (where\n$d$ is the dimensionality) or only extract the top $1$ component with\n$O(\\frac{1}{t})$ convergence rate. In contrast, our algorithm offers a strict\nimprovement for this classical problem: it achieves $O(d^2k)$ runtime\ncomplexity per iteration for extracting the top $k$ canonical components with\n$O(\\frac{1}{t})$ convergence rate. While the paper primarily focuses on the\nformulation and technical analysis of its properties, our experiments show that\nthe empirical behavior on common datasets is quite promising. We also explore a\npotential application in training fair models where the label of protected\nattribute is missing or otherwise unavailable.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 23:38:29 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Meng", "Zihang", ""], ["Chakraborty", "Rudrasis", ""], ["Singh", "Vikas", ""]]}, {"id": "2106.07483", "submitter": "Kiana Alikhademi", "authors": "Kiana Alikhademi, Brianna Richardson, Emma Drobina, and Juan E.\n  Gilbert", "title": "Can Explainable AI Explain Unfairness? A Framework for Evaluating\n  Explainable AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Many ML models are opaque to humans, producing decisions too complex for\nhumans to easily understand. In response, explainable artificial intelligence\n(XAI) tools that analyze the inner workings of a model have been created.\nDespite these tools' strength in translating model behavior, critiques have\nraised concerns about the impact of XAI tools as a tool for `fairwashing` by\nmisleading users into trusting biased or incorrect models. In this paper, we\ncreated a framework for evaluating explainable AI tools with respect to their\ncapabilities for detecting and addressing issues of bias and fairness as well\nas their capacity to communicate these results to their users clearly. We found\nthat despite their capabilities in simplifying and explaining model behavior,\nmany prominent XAI tools lack features that could be critical in detecting\nbias. Developers can use our framework to suggest modifications needed in their\ntoolkits to reduce issues likes fairwashing.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 15:14:03 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Alikhademi", "Kiana", ""], ["Richardson", "Brianna", ""], ["Drobina", "Emma", ""], ["Gilbert", "Juan E.", ""]]}, {"id": "2106.07487", "submitter": "Nuri Cingillioglu", "authors": "Nuri Cingillioglu, Alessandra Russo", "title": "pix2rule: End-to-end Neuro-symbolic Rule Learning", "comments": "41 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Humans have the ability to seamlessly combine low-level visual input with\nhigh-level symbolic reasoning often in the form of recognising objects,\nlearning relations between them and applying rules. Neuro-symbolic systems aim\nto bring a unifying approach to connectionist and logic-based principles for\nvisual processing and abstract reasoning respectively. This paper presents a\ncomplete neuro-symbolic method for processing images into objects, learning\nrelations and logical rules in an end-to-end fashion. The main contribution is\na differentiable layer in a deep learning architecture from which symbolic\nrelations and rules can be extracted by pruning and thresholding. We evaluate\nour model using two datasets: subgraph isomorphism task for symbolic rule\nlearning and an image classification domain with compound relations for\nlearning objects, relations and rules. We demonstrate that our model scales\nbeyond state-of-the-art symbolic learners and outperforms deep relational\nneural network architectures.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 15:19:06 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Cingillioglu", "Nuri", ""], ["Russo", "Alessandra", ""]]}, {"id": "2106.07499", "submitter": "Jiaao Chen", "authors": "Jiaao Chen, Derek Tam, Colin Raffel, Mohit Bansal and Diyi Yang", "title": "An Empirical Survey of Data Augmentation for Limited Data Learning in\n  NLP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  NLP has achieved great progress in the past decade through the use of neural\nmodels and large labeled datasets. The dependence on abundant data prevents NLP\nmodels from being applied to low-resource settings or novel tasks where\nsignificant time, money, or expertise is required to label massive amounts of\ntextual data. Recently, data augmentation methods have been explored as a means\nof improving data efficiency in NLP. To date, there has been no systematic\nempirical overview of data augmentation for NLP in the limited labeled data\nsetting, making it difficult to understand which methods work in which\nsettings. In this paper, we provide an empirical survey of recent progress on\ndata augmentation for NLP in the limited labeled data setting, summarizing the\nlandscape of methods (including token-level augmentations, sentence-level\naugmentations, adversarial augmentations, and hidden-space augmentations) and\ncarrying out experiments on 11 datasets covering topics/news classification,\ninference tasks, paraphrasing tasks, and single-sentence tasks. Based on the\nresults, we draw several conclusions to help practitioners choose appropriate\naugmentations in different settings and discuss the current challenges and\nfuture directions for limited data learning in NLP.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 15:27:22 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Chen", "Jiaao", ""], ["Tam", "Derek", ""], ["Raffel", "Colin", ""], ["Bansal", "Mohit", ""], ["Yang", "Diyi", ""]]}, {"id": "2106.07542", "submitter": "Himanshu Thapliyal", "authors": "Joseph Clark, Rajdeep Kumar Nath, Himanshu Thapliyal", "title": "Machine Learning Based Prediction of Future Stress Events in a Driving\n  Scenario", "comments": "4 Pages, IEEE 7th World Forum on Internet of Things 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a model for predicting a driver's stress level up to one\nminute in advance. Successfully predicting future stress would allow stress\nmitigation to begin before the subject becomes stressed, reducing or possibly\navoiding the performance penalties of stress. The proposed model takes features\nextracted from Galvanic Skin Response (GSR) signals on the foot and hand and\nRespiration and Electrocardiogram (ECG) signals from the chest of the driver.\nThe data used to train the model was retrieved from an existing database and\nthen processed to create statistical and frequency features. A total of 42\nfeatures were extracted from the data and then expanded into a total of 252\nfeatures by grouping the data and taking six statistical measurements of each\ngroup for each feature. A Random Forest Classifier was trained and evaluated\nusing a leave-one-subject-out testing approach. The model achieved 94% average\naccuracy on the test data. Results indicate that the model performs well and\ncould be used as part of a vehicle stress prevention system.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 20:12:38 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Clark", "Joseph", ""], ["Nath", "Rajdeep Kumar", ""], ["Thapliyal", "Himanshu", ""]]}, {"id": "2106.07544", "submitter": "Rong-Ching Chang", "authors": "Rong-Ching Chang, Chun-Ming Lai, Kai-Lai Chang, Chu-Hsing Lin", "title": "Dataset of Propaganda Techniques of the State-Sponsored Information\n  Operation of the People's Republic of China", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The digital media, identified as computational propaganda provides a pathway\nfor propaganda to expand its reach without limit. State-backed propaganda aims\nto shape the audiences' cognition toward entities in favor of a certain\npolitical party or authority. Furthermore, it has become part of modern\ninformation warfare used in order to gain an advantage over opponents. Most of\nthe current studies focus on using machine learning, quantitative, and\nqualitative methods to distinguish if a certain piece of information on social\nmedia is propaganda. Mainly conducted on English content, but very little\nresearch addresses Chinese Mandarin content. From propaganda detection, we want\nto go one step further to provide more fine-grained information on propaganda\ntechniques that are applied. In this research, we aim to bridge the information\ngap by providing a multi-labeled propaganda techniques dataset in Mandarin\nbased on a state-backed information operation dataset provided by Twitter. In\naddition to presenting the dataset, we apply a multi-label text classification\nusing fine-tuned BERT. Potentially this could help future research in detecting\nstate-backed propaganda online especially in a cross-lingual context and cross\nplatforms identity consolidation.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 16:11:13 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Chang", "Rong-Ching", ""], ["Lai", "Chun-Ming", ""], ["Chang", "Kai-Lai", ""], ["Lin", "Chu-Hsing", ""]]}, {"id": "2106.07549", "submitter": "Sung Hwan Jeon", "authors": "Sung Hwan Jeon and Sungzoon Cho", "title": "Named Entity Normalization Model Using Edge Weight Updating Neural\n  Network: Assimilation Between Knowledge-Driven Graph and Data-Driven Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Discriminating the matched named entity pairs or identifying the entities'\ncanonical forms are critical in text mining tasks. More precise named entity\nnormalization in text mining will benefit other subsequent text analytic\napplications. We built the named entity normalization model with a novel Edge\nWeight Updating Neural Network. Our proposed model when tested on four\ndifferent datasets achieved state-of-the-art results. We, next, verify our\nmodel's performance on NCBI Disease, BC5CDR Disease, and BC5CDR Chemical\ndatabases, which are widely used named entity normalization datasets in the\nbioinformatics field. We also tested our model with our own financial named\nentity normalization dataset to validate the efficacy for more general\napplications. Using the constructed dataset, we differentiate named entity\npairs. Our model achieved the highest named entity normalization performances\nin terms of various evaluation metrics.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 16:14:58 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Jeon", "Sung Hwan", ""], ["Cho", "Sungzoon", ""]]}, {"id": "2106.07550", "submitter": "Abdul Mueed Hafiz Dr.", "authors": "Abdul Mueed Hafiz, Shabir Ahmad Parah, Rouf Ul Alam Bhat", "title": "Attention mechanisms and deep learning for machine vision: A survey of\n  the state of the art", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of state of the art nature-inspired pure attention based\nmodels i.e. transformers, and their success in natural language processing\n(NLP), their extension to machine vision (MV) tasks was inevitable and much\nfelt. Subsequently, vision transformers (ViTs) were introduced which are giving\nquite a challenge to the established deep learning based machine vision\ntechniques. However, pure attention based models/architectures like\ntransformers require huge data, large training times and large computational\nresources. Some recent works suggest that combinations of these two varied\nfields can prove to build systems which have the advantages of both these\nfields. Accordingly, this state of the art survey paper is introduced which\nhopefully will help readers get useful information about this interesting and\npotential research area. A gentle introduction to attention mechanisms is\ngiven, followed by a discussion of the popular attention based deep\narchitectures. Subsequently, the major categories of the intersection of\nattention mechanisms and deep learning for machine vision (MV) based are\ndiscussed. Afterwards, the major algorithms, issues and trends within the scope\nof the paper are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 10:23:32 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Hafiz", "Abdul Mueed", ""], ["Parah", "Shabir Ahmad", ""], ["Bhat", "Rouf Ul Alam", ""]]}, {"id": "2106.07551", "submitter": "Ming Zhou", "authors": "Ming Zhou, Ziyu Wan, Hanjing Wang, Muning Wen, Runzhe Wu, Ying Wen,\n  Yaodong Yang, Weinan Zhang, Jun Wang", "title": "MALib: A Parallel Framework for Population-based Multi-agent\n  Reinforcement Learning", "comments": "24 pages, 17 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Population-based multi-agent reinforcement learning (PB-MARL) refers to the\nseries of methods nested with reinforcement learning (RL) algorithms, which\nproduces a self-generated sequence of tasks arising from the coupled population\ndynamics. By leveraging auto-curricula to induce a population of distinct\nemergent strategies, PB-MARL has achieved impressive success in tackling\nmulti-agent tasks. Despite remarkable prior arts of distributed RL frameworks,\nPB-MARL poses new challenges for parallelizing the training frameworks due to\nthe additional complexity of multiple nested workloads between sampling,\ntraining and evaluation involved with heterogeneous policy interactions. To\nsolve these problems, we present MALib, a scalable and efficient computing\nframework for PB-MARL. Our framework is comprised of three key components: (1)\na centralized task dispatching model, which supports the self-generated tasks\nand scalable training with heterogeneous policy combinations; (2) a programming\narchitecture named Actor-Evaluator-Learner, which achieves high parallelism for\nboth training and sampling, and meets the evaluation requirement of\nauto-curriculum learning; (3) a higher-level abstraction of MARL training\nparadigms, which enables efficient code reuse and flexible deployments on\ndifferent distributed computing paradigms. Experiments on a series of complex\ntasks such as multi-agent Atari Games show that MALib achieves throughput\nhigher than 40K FPS on a single machine with $32$ CPU cores; 5x speedup than\nRLlib and at least 3x speedup than OpenSpiel in multi-agent training tasks.\nMALib is publicly available at https://github.com/sjtu-marl/malib.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 03:27:08 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Zhou", "Ming", ""], ["Wan", "Ziyu", ""], ["Wang", "Hanjing", ""], ["Wen", "Muning", ""], ["Wu", "Runzhe", ""], ["Wen", "Ying", ""], ["Yang", "Yaodong", ""], ["Zhang", "Weinan", ""], ["Wang", "Jun", ""]]}, {"id": "2106.07553", "submitter": "Sara Kingsley", "authors": "Sara Kingsley", "title": "A Cognitive Science perspective for learning how to design meaningful\n  user experiences and human-centered technology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper reviews literature in cognitive science, human-computer\ninteraction (HCI) and natural-language processing (NLP) to consider how\nanalogical reasoning (AR) could help inform the design of communication and\nlearning technologies, as well as online communities and digital platforms.\nFirst, analogical reasoning (AR) is defined, and use-cases of AR in the\ncomputing sciences are presented. The concept of schema is introduced, along\nwith use-cases in computing. Finally, recommendations are offered for future\nwork on using analogical reasoning and schema methods in the computing\nsciences.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 15:00:50 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Kingsley", "Sara", ""]]}, {"id": "2106.07555", "submitter": "S\\'ebastien Lall\\'e", "authors": "S\\'ebastien Lall\\'e and Cristina Conati", "title": "A Framework to Counteract Suboptimal User-Behaviors in Exploratory\n  Learning Environments: an Application to MOOCs", "comments": "The AAAI 2019 Workshop on Plan, Activity, and Intent Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While there is evidence that user-adaptive support can greatly enhance the\neffectiveness of educational systems, designing such support for exploratory\nlearning environments (e.g., simulations) is still challenging due to the\nopen-ended nature of their interaction. In particular, there is little a priori\nknowledge of which student's behaviors can be detrimental to learning in such\nenvironments. To address this problem, we focus on a data-driven user-modeling\nframework that uses logged interaction data to learn which behavioral or\nactivity patterns should trigger help during interaction with a specific\nlearning environment. This framework has been successfully used to provide\nadaptive support in interactive learning simulations. Here we present a novel\napplication of this framework we are working on, namely to Massive Open Online\nCourses (MOOCs), a form of exploratory environment that could greatly benefit\nfrom adaptive support due to the large diversity of their users, but typically\nlack of such adaptation. We describe an experiment aimed at investigating the\nvalue of our framework to identify student's behaviors that can justify\nadapting to, and report some preliminary results.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 16:16:33 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Lall\u00e9", "S\u00e9bastien", ""], ["Conati", "Cristina", ""]]}, {"id": "2106.07556", "submitter": "Sravani Teeparthi", "authors": "Sravani Teeparthi", "title": "Long Term Object Detection and Tracking in Collaborative Learning\n  Environments", "comments": "Master's thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human activity recognition in videos is a challenging problem that has drawn\na lot of interest, particularly when the goal requires the analysis of a large\nvideo database. AOLME project provides a collaborative learning environment for\nmiddle school students to explore mathematics, computer science, and\nengineering by processing digital images and videos. As part of this project,\naround 2200 hours of video data was collected for analysis. Because of the size\nof the dataset, it is hard to analyze all the videos of the dataset manually.\nThus, there is a huge need for reliable computer-based methods that can detect\nactivities of interest. My thesis is focused on the development of accurate\nmethods for detecting and tracking objects in long videos. All the models are\nvalidated on videos from 7 different sessions, ranging from 45 minutes to 90\nminutes. The keyboard detector achieved a very high average precision (AP) of\n92% at 0.5 intersection over union (IoU). Furthermore, a combined system of the\ndetector with a fast tracker KCF (159fps) was developed so that the algorithm\nruns significantly faster without sacrificing accuracy. For a video of 23\nminutes having resolution 858X480 @ 30 fps, the detection alone runs at 4.7Xthe\nreal-time, and the combined algorithm runs at 21Xthe real-time for an average\nIoU of 0.84 and 0.82, respectively. The hand detector achieved average\nprecision (AP) of 72% at 0.5 IoU. The detection results were improved to 81%\nusing optimal data augmentation parameters. The hand detector runs at 4.7Xthe\nreal-time with AP of 81% at 0.5 IoU. The hand detection method was integrated\nwith projections and clustering for accurate proposal generation. This approach\nreduced the number of false-positive hand detections by 80%. The overall hand\ndetection system runs at 4Xthe real-time, capturing all the activity regions of\nthe current collaborative group.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 20:15:14 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Teeparthi", "Sravani", ""]]}, {"id": "2106.07562", "submitter": "Xr L", "authors": "Xiangri Lu, Hongbin Ma, Jingcheng Zhang", "title": "Neural Network Structure Design based on N-Gauss Activation Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that the activation function of the convolutional\nneural network can meet the Lipschitz condition, then the corresponding\nconvolutional neural network structure can be constructed according to the\nscale of the data set, and the data set can be trained more deeply, more\naccurately and more effectively. In this article, we have accepted the\nexperimental results and introduced the core block N-Gauss, N-Gauss, and Swish\n(Conv1, Conv2, FC1) neural network structure design to train MNIST, CIFAR10,\nand CIFAR100 respectively. Experiments show that N-Gauss gives full play to the\nmain role of nonlinear modeling of activation functions, so that deep\nconvolutional neural networks have hierarchical nonlinear mapping learning\ncapabilities. At the same time, the training ability of N-Gauss on simple\none-dimensional channel small data sets is equivalent to the performance of\nReLU and Swish.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 11:16:37 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Lu", "Xiangri", ""], ["Ma", "Hongbin", ""], ["Zhang", "Jingcheng", ""]]}, {"id": "2106.07608", "submitter": "Xinzi He", "authors": "Xinzi He, Jia Guo, Xuzhe Zhang, Hanwen Bi, Sarah Gerard, David Kaczka,\n  Amin Motahari, Eric Hoffman, Joseph Reinhardt, R. Graham Barr, Elsa Angelini,\n  Andrew Laine", "title": "Recursive Refinement Network for Deformable Lung Registration between\n  Exhale and Inhale CT Scans", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Unsupervised learning-based medical image registration approaches have\nwitnessed rapid development in recent years. We propose to revisit a commonly\nignored while simple and well-established principle: recursive refinement of\ndeformation vector fields across scales. We introduce a recursive refinement\nnetwork (RRN) for unsupervised medical image registration, to extract\nmulti-scale features, construct normalized local cost correlation volume and\nrecursively refine volumetric deformation vector fields. RRN achieves state of\nthe art performance for 3D registration of expiratory-inspiratory pairs of CT\nlung scans. On DirLab COPDGene dataset, RRN returns an average Target\nRegistration Error (TRE) of 0.83 mm, which corresponds to a 13% error reduction\nfrom the best result presented in the leaderboard. In addition to comparison\nwith conventional methods, RRN leads to 89% error reduction compared to\ndeep-learning-based peer approaches.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 17:14:17 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["He", "Xinzi", ""], ["Guo", "Jia", ""], ["Zhang", "Xuzhe", ""], ["Bi", "Hanwen", ""], ["Gerard", "Sarah", ""], ["Kaczka", "David", ""], ["Motahari", "Amin", ""], ["Hoffman", "Eric", ""], ["Reinhardt", "Joseph", ""], ["Barr", "R. Graham", ""], ["Angelini", "Elsa", ""], ["Laine", "Andrew", ""]]}, {"id": "2106.07611", "submitter": "Santiago Miret", "authors": "Santiago Miret, Vui Seng Chua, Mattias Marder, Mariano Phielipp,\n  Nilesh Jain, Somdeb Majumdar", "title": "Neuroevolution-Enhanced Multi-Objective Optimization for Mixed-Precision\n  Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mixed-precision quantization is a powerful tool to enable memory and compute\nsavings of neural network workloads by deploying different sets of bit-width\nprecisions on separate compute operations. Recent research has shown\nsignificant progress in applying mixed-precision quantization techniques to\nreduce the memory footprint of various workloads, while also preserving task\nperformance. Prior work, however, has often ignored additional objectives, such\nas bit-operations, that are important for deployment of workloads on hardware.\nHere we present a flexible and scalable framework for automated mixed-precision\nquantization that optimizes multiple objectives. Our framework relies on\nNeuroevolution-Enhanced Multi-Objective Optimization (NEMO), a novel search\nmethod, to find Pareto optimal mixed-precision configurations for memory and\nbit-operations objectives. Within NEMO, a population is divided into\nstructurally distinct sub-populations (species) which jointly form the Pareto\nfrontier of solutions for the multi-objective problem. At each generation,\nspecies are re-sized in proportion to the goodness of their contribution to the\nPareto frontier. This allows NEMO to leverage established search techniques and\nneuroevolution methods to continually improve the goodness of the Pareto\nfrontier. In our experiments we apply a graph-based representation to describe\nthe underlying workload, enabling us to deploy graph neural networks trained by\nNEMO to find Pareto optimal configurations for various workloads trained on\nImageNet. Compared to the state-of-the-art, we achieve competitive results on\nmemory compression and superior results for compute compression for\nMobileNet-V2, ResNet50 and ResNeXt-101-32x8d. A deeper analysis of the results\nobtained by NEMO also shows that both the graph representation and the\nspecies-based approach are critical in finding effective configurations for all\nworkloads.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 17:15:15 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Miret", "Santiago", ""], ["Chua", "Vui Seng", ""], ["Marder", "Mattias", ""], ["Phielipp", "Mariano", ""], ["Jain", "Nilesh", ""], ["Majumdar", "Somdeb", ""]]}, {"id": "2106.07635", "submitter": "Yashas Annadani", "authors": "Yashas Annadani, Jonas Rothfuss, Alexandre Lacoste, Nino Scherrer,\n  Anirudh Goyal, Yoshua Bengio, Stefan Bauer", "title": "Variational Causal Networks: Approximate Bayesian Inference over Causal\n  Structures", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning the causal structure that underlies data is a crucial step towards\nrobust real-world decision making. The majority of existing work in causal\ninference focuses on determining a single directed acyclic graph (DAG) or a\nMarkov equivalence class thereof. However, a crucial aspect to acting\nintelligently upon the knowledge about causal structure which has been inferred\nfrom finite data demands reasoning about its uncertainty. For instance,\nplanning interventions to find out more about the causal mechanisms that govern\nour data requires quantifying epistemic uncertainty over DAGs. While Bayesian\ncausal inference allows to do so, the posterior over DAGs becomes intractable\neven for a small number of variables. Aiming to overcome this issue, we propose\na form of variational inference over the graphs of Structural Causal Models\n(SCMs). To this end, we introduce a parametric variational family modelled by\nan autoregressive distribution over the space of discrete DAGs. Its number of\nparameters does not grow exponentially with the number of variables and can be\ntractably learned by maximising an Evidence Lower Bound (ELBO). In our\nexperiments, we demonstrate that the proposed variational posterior is able to\nprovide a good approximation of the true posterior.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 17:52:49 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Annadani", "Yashas", ""], ["Rothfuss", "Jonas", ""], ["Lacoste", "Alexandre", ""], ["Scherrer", "Nino", ""], ["Goyal", "Anirudh", ""], ["Bengio", "Yoshua", ""], ["Bauer", "Stefan", ""]]}, {"id": "2106.07636", "submitter": "Danica J. Sutherland", "authors": "Feng Liu and Wenkai Xu and Jie Lu and Danica J. Sutherland", "title": "Meta Two-Sample Testing: Learning Kernels for Testing with Limited Data", "comments": "Code is available from https://github.com/fengliu90/MetaTesting", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern kernel-based two-sample tests have shown great success in\ndistinguishing complex, high-dimensional distributions with appropriate learned\nkernels. Previous work has demonstrated that this kernel learning procedure\nsucceeds, assuming a considerable number of observed samples from each\ndistribution. In realistic scenarios with very limited numbers of data samples,\nhowever, it can be challenging to identify a kernel powerful enough to\ndistinguish complex distributions. We address this issue by introducing the\nproblem of meta two-sample testing (M2ST), which aims to exploit (abundant)\nauxiliary data on related tasks to find an algorithm that can quickly identify\na powerful test on new target tasks. We propose two specific algorithms for\nthis task: a generic scheme which improves over baselines and amore tailored\napproach which performs even better. We provide both theoretical justification\nand empirical evidence that our proposed meta-testing schemes out-perform\nlearning kernel-based tests directly from scarce observations, and identify\nwhen such schemes will be successful.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 17:52:50 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Liu", "Feng", ""], ["Xu", "Wenkai", ""], ["Lu", "Jie", ""], ["Sutherland", "Danica J.", ""]]}, {"id": "2106.07677", "submitter": "Aviva Prins", "authors": "Christine Herlihy, Aviva Prins, Aravind Srinivasan, and John Dickerson", "title": "Planning to Fairly Allocate: Probabilistic Fairness in the Restless\n  Bandit Setting", "comments": "27 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restless and collapsing bandits are commonly used to model constrained\nresource allocation in settings featuring arms with action-dependent transition\nprobabilities, such as allocating health interventions among patients [Whittle,\n1988; Mate et al., 2020]. However, state-of-the-art Whittle-index-based\napproaches to this planning problem either do not consider fairness among arms,\nor incentivize fairness without guaranteeing it [Mate et al., 2021].\nAdditionally, their optimality guarantees only apply when arms are indexable\nand threshold-optimal. We demonstrate that the incorporation of hard fairness\nconstraints necessitates the coupling of arms, which undermines the\ntractability, and by extension, indexability of the problem. We then introduce\nProbFair, a probabilistically fair stationary policy that maximizes total\nexpected reward and satisfies the budget constraint, while ensuring a strictly\npositive lower bound on the probability of being pulled at each timestep. We\nevaluate our algorithm on a real-world application, where interventions support\ncontinuous positive airway pressure (CPAP) therapy adherence among obstructive\nsleep apnea (OSA) patients, as well as simulations on a broader class of\nsynthetic transition matrices.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 18:01:08 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Herlihy", "Christine", ""], ["Prins", "Aviva", ""], ["Srinivasan", "Aravind", ""], ["Dickerson", "John", ""]]}, {"id": "2106.07691", "submitter": "Animesh Nighojkar", "authors": "Animesh Nighojkar and John Licato", "title": "Improving Paraphrase Detection with the Adversarial Paraphrasing Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  If two sentences have the same meaning, it should follow that they are\nequivalent in their inferential properties, i.e., each sentence should\ntextually entail the other. However, many paraphrase datasets currently in\nwidespread use rely on a sense of paraphrase based on word overlap and syntax.\nCan we teach them instead to identify paraphrases in a way that draws on the\ninferential properties of the sentences, and is not over-reliant on lexical and\nsyntactic similarities of a sentence pair? We apply the adversarial paradigm to\nthis question, and introduce a new adversarial method of dataset creation for\nparaphrase identification: the Adversarial Paraphrasing Task (APT), which asks\nparticipants to generate semantically equivalent (in the sense of mutually\nimplicative) but lexically and syntactically disparate paraphrases. These\nsentence pairs can then be used both to test paraphrase identification models\n(which get barely random accuracy) and then improve their performance. To\naccelerate dataset generation, we explore automation of APT using T5, and show\nthat the resulting dataset also improves accuracy. We discuss implications for\nparaphrase detection and release our dataset in the hope of making paraphrase\ndetection models better able to detect sentence-level meaning equivalence.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 18:15:20 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Nighojkar", "Animesh", ""], ["Licato", "John", ""]]}, {"id": "2106.07696", "submitter": "Athira Nambiar Ph.D.", "authors": "Sinzith Tatikonda, Athira Nambiar and Anurag Mittal", "title": "Face Age Progression With Attribute Manipulation", "comments": "-", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Face is one of the predominant means of person recognition. In the process of\nageing, human face is prone to many factors such as time, attributes, weather\nand other subject specific variations. The impact of these factors were not\nwell studied in the literature of face aging. In this paper, we propose a novel\nholistic model in this regard viz., ``Face Age progression With Attribute\nManipulation (FAWAM)\", i.e. generating face images at different ages while\nsimultaneously varying attributes and other subject specific characteristics.\nWe address the task in a bottom-up manner, as two submodules i.e. face age\nprogression and face attribute manipulation. For face aging, we use an\nattribute-conscious face aging model with a pyramidal generative adversarial\nnetwork that can model age-specific facial changes while maintaining intrinsic\nsubject specific characteristics. For facial attribute manipulation, the age\nprocessed facial image is manipulated with desired attributes while preserving\nother details unchanged, leveraging an attribute generative adversarial network\narchitecture. We conduct extensive analysis in standard large scale datasets\nand our model achieves significant performance both quantitatively and\nqualitatively.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 18:26:48 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Tatikonda", "Sinzith", ""], ["Nambiar", "Athira", ""], ["Mittal", "Anurag", ""]]}, {"id": "2106.07708", "submitter": "Geoffrey H Tison", "authors": "Robert Avram, Jeffrey E. Olgin, Alvin Wan, Zeeshan Ahmed, Louis\n  Verreault-Julien, Sean Abreau, Derek Wan, Joseph E. Gonzalez, Derek Y. So,\n  Krishan Soni, Geoffrey H. Tison", "title": "CathAI: Fully Automated Interpretation of Coronary Angiograms Using\n  Neural Networks", "comments": "62 pages, 3 main figures, 2 main tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV eess.IV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Coronary heart disease (CHD) is the leading cause of adult death in the\nUnited States and worldwide, and for which the coronary angiography procedure\nis the primary gateway for diagnosis and clinical management decisions. The\nstandard-of-care for interpretation of coronary angiograms depends upon ad-hoc\nvisual assessment by the physician operator. However, ad-hoc visual\ninterpretation of angiograms is poorly reproducible, highly variable and bias\nprone. Here we show for the first time that fully-automated angiogram\ninterpretation to estimate coronary artery stenosis is possible using a\nsequence of deep neural network algorithms. The algorithmic pipeline we\ndeveloped--called CathAI--achieves state-of-the art performance across the\nsequence of tasks required to accomplish automated interpretation of\nunselected, real-world angiograms. CathAI (Algorithms 1-2) demonstrated\npositive predictive value, sensitivity and F1 score of >=90% to identify the\nprojection angle overall and >=93% for left or right coronary artery angiogram\ndetection, the primary anatomic structures of interest. To predict obstructive\ncoronary artery stenosis (>=70% stenosis), CathAI (Algorithm 4) exhibited an\narea under the receiver operating characteristic curve (AUC) of 0.862 (95% CI:\n0.843-0.880). When externally validated in a healthcare system in another\ncountry, CathAI AUC was 0.869 (95% CI: 0.830-0.907) to predict obstructive\ncoronary artery stenosis. Our results demonstrate that multiple purpose-built\nneural networks can function in sequence to accomplish the complex series of\ntasks required for automated analysis of real-world angiograms. Deployment of\nCathAI may serve to increase standardization and reproducibility in coronary\nstenosis assessment, while providing a robust foundation to accomplish future\ntasks for algorithmic angiographic interpretation.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 18:58:09 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Avram", "Robert", ""], ["Olgin", "Jeffrey E.", ""], ["Wan", "Alvin", ""], ["Ahmed", "Zeeshan", ""], ["Verreault-Julien", "Louis", ""], ["Abreau", "Sean", ""], ["Wan", "Derek", ""], ["Gonzalez", "Joseph E.", ""], ["So", "Derek Y.", ""], ["Soni", "Krishan", ""], ["Tison", "Geoffrey H.", ""]]}, {"id": "2106.07714", "submitter": "Gianni Franchi", "authors": "Yufei Hu, Nacim Belkhir, Jesus Angulo, Angela Yao, Gianni Franchi", "title": "Learning Deep Morphological Networks with Neural Architecture Search", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Neural Networks (DNNs) are generated by sequentially performing linear\nand non-linear processes. Using a combination of linear and non-linear\nprocedures is critical for generating a sufficiently deep feature space. The\nmajority of non-linear operators are derivations of activation functions or\npooling functions. Mathematical morphology is a branch of mathematics that\nprovides non-linear operators for a variety of image processing problems. We\ninvestigate the utility of integrating these operations in an end-to-end deep\nlearning framework in this paper. DNNs are designed to acquire a realistic\nrepresentation for a particular job. Morphological operators give topological\ndescriptors that convey salient information about the shapes of objects\ndepicted in images. We propose a method based on meta-learning to incorporate\nmorphological operators into DNNs. The learned architecture demonstrates how\nour novel morphological operations significantly increase DNN performance on\nvarious tasks, including picture classification and edge detection.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 19:19:48 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Hu", "Yufei", ""], ["Belkhir", "Nacim", ""], ["Angulo", "Jesus", ""], ["Yao", "Angela", ""], ["Franchi", "Gianni", ""]]}, {"id": "2106.07722", "submitter": "Jiarun Cao", "authors": "Jiarun Cao, Elke M van Veen, Niels Peek, Andrew G Renehan, Sophia\n  Ananiadou", "title": "EPICURE Ensemble Pretrained Models for Extracting Cancer Mutations from\n  Literature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To interpret the genetic profile present in a patient sample, it is necessary\nto know which mutations have important roles in the development of the\ncorresponding cancer type. Named entity recognition is a core step in the text\nmining pipeline which facilitates mining valuable cancer information from the\nscientific literature. However, due to the scarcity of related datasets,\nprevious NER attempts in this domain either suffer from low performance when\ndeep learning based models are deployed, or they apply feature based machine\nlearning models or rule based models to tackle this problem, which requires\nintensive efforts from domain experts, and limit the model generalization\ncapability. In this paper, we propose EPICURE, an ensemble pre trained model\nequipped with a conditional random field pattern layer and a span prediction\npattern layer to extract cancer mutations from text. We also adopt a data\naugmentation strategy to expand our training set from multiple datasets.\nExperimental results on three benchmark datasets show competitive results\ncompared to the baseline models.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 09:08:15 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Cao", "Jiarun", ""], ["van Veen", "Elke M", ""], ["Peek", "Niels", ""], ["Renehan", "Andrew G", ""], ["Ananiadou", "Sophia", ""]]}, {"id": "2106.07728", "submitter": "Minae Kwon", "authors": "Minae Kwon, Siddharth Karamcheti, Mariano-Florentino Cuellar, Dorsa\n  Sadigh", "title": "Targeted Data Acquisition for Evolving Negotiation Agents", "comments": "The Thirty-eighth International Conference on Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Successful negotiators must learn how to balance optimizing for self-interest\nand cooperation. Yet current artificial negotiation agents often heavily depend\non the quality of the static datasets they were trained on, limiting their\ncapacity to fashion an adaptive response balancing self-interest and\ncooperation. For this reason, we find that these agents can achieve either high\nutility or cooperation, but not both. To address this, we introduce a targeted\ndata acquisition framework where we guide the exploration of a reinforcement\nlearning agent using annotations from an expert oracle. The guided exploration\nincentivizes the learning agent to go beyond its static dataset and develop new\nnegotiation strategies. We show that this enables our agents to obtain\nhigher-reward and more Pareto-optimal solutions when negotiating with both\nsimulated and human partners compared to standard supervised learning and\nreinforcement learning methods. This trend additionally holds when comparing\nagents using our targeted data acquisition framework to variants of agents\ntrained with a mix of supervised learning and reinforcement learning, or to\nagents using tailored reward functions that explicitly optimize for utility and\nPareto-optimality.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 19:45:59 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 17:49:13 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Kwon", "Minae", ""], ["Karamcheti", "Siddharth", ""], ["Cuellar", "Mariano-Florentino", ""], ["Sadigh", "Dorsa", ""]]}, {"id": "2106.07754", "submitter": "Daniele Regoli", "authors": "Riccardo Crupi, Alessandro Castelnovo, Daniele Regoli, Beatriz San\n  Miguel Gonzalez", "title": "Counterfactual Explanations as Interventions in Latent Space", "comments": "34 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Explainable Artificial Intelligence (XAI) is a set of techniques that allows\nthe understanding of both technical and non-technical aspects of Artificial\nIntelligence (AI) systems. XAI is crucial to help satisfying the increasingly\nimportant demand of \\emph{trustworthy} Artificial Intelligence, characterized\nby fundamental characteristics such as respect of human autonomy, prevention of\nharm, transparency, accountability, etc. Within XAI techniques, counterfactual\nexplanations aim to provide to end users a set of features (and their\ncorresponding values) that need to be changed in order to achieve a desired\noutcome. Current approaches rarely take into account the feasibility of actions\nneeded to achieve the proposed explanations, and in particular they fall short\nof considering the causal impact of such actions. In this paper, we present\nCounterfactual Explanations as Interventions in Latent Space (CEILS), a\nmethodology to generate counterfactual explanations capturing by design the\nunderlying causal relations from the data, and at the same time to provide\nfeasible recommendations to reach the proposed profile. Moreover, our\nmethodology has the advantage that it can be set on top of existing\ncounterfactuals generator algorithms, thus minimising the complexity of\nimposing additional causal constrains. We demonstrate the effectiveness of our\napproach with a set of different experiments using synthetic and real datasets\n(including a proprietary dataset of the financial domain).\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 20:48:48 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Crupi", "Riccardo", ""], ["Castelnovo", "Alessandro", ""], ["Regoli", "Daniele", ""], ["Gonzalez", "Beatriz San Miguel", ""]]}, {"id": "2106.07756", "submitter": "Sahil Verma", "authors": "Sahil Verma, John Dickerson, Keegan Hines", "title": "Counterfactual Explanations for Machine Learning: Challenges Revisited", "comments": "Presented at CHI HCXAI 2021 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual explanations (CFEs) are an emerging technique under the\numbrella of interpretability of machine learning (ML) models. They provide\n``what if'' feedback of the form ``if an input datapoint were $x'$ instead of\n$x$, then an ML model's output would be $y'$ instead of $y$.'' Counterfactual\nexplainability for ML models has yet to see widespread adoption in industry. In\nthis short paper, we posit reasons for this slow uptake. Leveraging recent work\noutlining desirable properties of CFEs and our experience running the ML wing\nof a model monitoring startup, we identify outstanding obstacles hindering CFE\ndeployment in industry.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 20:56:37 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Verma", "Sahil", ""], ["Dickerson", "John", ""], ["Hines", "Keegan", ""]]}, {"id": "2106.07758", "submitter": "Sahil Verma", "authors": "Sahil Verma, Aditya Lahiri, John P. Dickerson, Su-In Lee", "title": "Pitfalls of Explainable ML: An Industry Perspective", "comments": "Presented at JOURNE workshop at MLSYS 2021\n  (https://sites.google.com/view/workshop-journe/home)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning (ML) systems take a more prominent and central role in\ncontributing to life-impacting decisions, ensuring their trustworthiness and\naccountability is of utmost importance. Explanations sit at the core of these\ndesirable attributes of a ML system. The emerging field is frequently called\n``Explainable AI (XAI)'' or ``Explainable ML.'' The goal of explainable ML is\nto intuitively explain the predictions of a ML system, while adhering to the\nneeds to various stakeholders. Many explanation techniques were developed with\ncontributions from both academia and industry. However, there are several\nexisting challenges that have not garnered enough interest and serve as\nroadblocks to widespread adoption of explainable ML. In this short paper, we\nenumerate challenges in explainable ML from an industry perspective. We hope\nthese challenges will serve as promising future research directions, and would\ncontribute to democratizing explainable ML.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 21:05:05 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Verma", "Sahil", ""], ["Lahiri", "Aditya", ""], ["Dickerson", "John P.", ""], ["Lee", "Su-In", ""]]}, {"id": "2106.07760", "submitter": "Krishnateja Killamsetty", "authors": "Krishnateja Killamsetty, Xujiang Zhao, Feng Chen, Rishabh Iyer", "title": "RETRIEVE: Coreset Selection for Efficient and Robust Semi-Supervised\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Semi-supervised learning (SSL) algorithms have had great success in recent\nyears in limited labeled data regimes. However, the current state-of-the-art\nSSL algorithms are computationally expensive and entail significant compute\ntime and energy requirements. This can prove to be a huge limitation for many\nsmaller companies and academic groups. Our main insight is that training on a\nsubset of unlabeled data instead of entire unlabeled data enables the current\nSSL algorithms to converge faster, thereby reducing the computational costs\nsignificantly. In this work, we propose RETRIEVE, a coreset selection framework\nfor efficient and robust semi-supervised learning. RETRIEVE selects the coreset\nby solving a mixed discrete-continuous bi-level optimization problem such that\nthe selected coreset minimizes the labeled set loss. We use a one-step gradient\napproximation and show that the discrete optimization problem is approximately\nsubmodular, thereby enabling simple greedy algorithms to obtain the coreset. We\nempirically demonstrate on several real-world datasets that existing SSL\nalgorithms like VAT, Mean-Teacher, FixMatch, when used with RETRIEVE, achieve\na) faster training times, b) better performance when unlabeled data consists of\nOut-of-Distribution(OOD) data and imbalance. More specifically, we show that\nwith minimal accuracy degradation, RETRIEVE achieves a speedup of around 3X in\nthe traditional SSL setting and achieves a speedup of 5X compared to\nstate-of-the-art (SOTA) robust SSL algorithms in the case of imbalance and OOD\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 21:18:47 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Killamsetty", "Krishnateja", ""], ["Zhao", "Xujiang", ""], ["Chen", "Feng", ""], ["Iyer", "Rishabh", ""]]}, {"id": "2106.07814", "submitter": "Dhruv Malik", "authors": "Dhruv Malik, Aldo Pacchiano, Vishwak Srinivasan, Yuanzhi Li", "title": "Sample Efficient Reinforcement Learning In Continuous State Spaces: A\n  Perspective Beyond Linearity", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is empirically successful in complex nonlinear\nMarkov decision processes (MDPs) with continuous state spaces. By contrast, the\nmajority of theoretical RL literature requires the MDP to satisfy some form of\nlinear structure, in order to guarantee sample efficient RL. Such efforts\ntypically assume the transition dynamics or value function of the MDP are\ndescribed by linear functions of the state features. To resolve this\ndiscrepancy between theory and practice, we introduce the Effective Planning\nWindow (EPW) condition, a structural condition on MDPs that makes no linearity\nassumptions. We demonstrate that the EPW condition permits sample efficient RL,\nby providing an algorithm which provably solves MDPs satisfying this condition.\nOur algorithm requires minimal assumptions on the policy class, which can\ninclude multi-layer neural networks with nonlinear activation functions.\nNotably, the EPW condition is directly motivated by popular gaming benchmarks,\nand we show that many classic Atari games satisfy this condition. We\nadditionally show the necessity of conditions like EPW, by demonstrating that\nsimple MDPs with slight nonlinearities cannot be solved sample efficiently.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 00:06:59 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Malik", "Dhruv", ""], ["Pacchiano", "Aldo", ""], ["Srinivasan", "Vishwak", ""], ["Li", "Yuanzhi", ""]]}, {"id": "2106.07822", "submitter": "David McNeely-White", "authors": "David McNeely-White, Ben Sattelberg, Nathaniel Blanchard, Ross\n  Beveridge", "title": "Canonical Face Embeddings", "comments": "10 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present evidence that many common convolutional neural networks (CNNs)\ntrained for face verification learn functions that are nearly equivalent under\nrotation. More specifically, we demonstrate that one face verification model's\nembeddings (i.e. last--layer activations) can be compared directly to another\nmodel's embeddings after only a rotation or linear transformation, with little\nperformance penalty. This finding is demonstrated using IJB-C 1:1 verification\nacross the combinations of ten modern off-the-shelf CNN-based face verification\nmodels which vary in training dataset, CNN architecture, way of using angular\nloss, or some combination of the 3, and achieve a mean true accept rate of 0.96\nat a false accept rate of 0.01. When instead evaluating embeddings generated\nfrom two CNNs, where one CNN's embeddings are mapped with a linear\ntransformation, the mean true accept rate drops to 0.95 using the same\nverification paradigm. Restricting these linear maps to only perform rotation\nproduces a mean true accept rate of 0.91. These mappings' existence suggests\nthat a common representation is learned by models with variation in training or\nstructure. A discovery such as this likely has broad implications, and we\nprovide an application in which face embeddings can be de-anonymized using a\nlimited number of samples.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 00:52:05 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 20:24:30 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["McNeely-White", "David", ""], ["Sattelberg", "Ben", ""], ["Blanchard", "Nathaniel", ""], ["Beveridge", "Ross", ""]]}, {"id": "2106.07824", "submitter": "Yewen Pu", "authors": "Samuel Acquaviva, Yewen Pu, Marta Kryven, Catherine Wong, Gabrielle E\n  Ecanow, Maxwell Nye, Theodoros Sechopoulos, Michael Henry Tessler, Joshua B.\n  Tenenbaum", "title": "Communicating Natural Programs to Humans and Machines", "comments": "equal contributions: (author 3, 4), (author 5,6,7)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Abstraction and Reasoning Corpus (ARC) is a set of tasks that tests an\nagent's ability to flexibly solve novel problems. While most ARC tasks are easy\nfor humans, they are challenging for state-of-the-art AI. How do we build\nintelligent systems that can generalize to novel situations and understand\nhuman instructions in domains such as ARC? We posit that the answer may be\nfound by studying how humans communicate to each other in solving these tasks.\nWe present LARC, the Language-annotated ARC: a collection of natural language\ndescriptions by a group of human participants, unfamiliar both with ARC and\nwith each other, who instruct each other on how to solve ARC tasks. LARC\ncontains successful instructions for 88\\% of the ARC tasks. We analyze the\ncollected instructions as `natural programs', finding that most natural program\nconcepts have analogies in typical computer programs. However, unlike how one\nprecisely programs a computer, we find that humans both anticipate and exploit\nambiguities to communicate effectively. We demonstrate that a state-of-the-art\nprogram synthesis technique, which leverages the additional language\nannotations, outperforms its language-free counterpart.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 01:05:04 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Acquaviva", "Samuel", ""], ["Pu", "Yewen", ""], ["Kryven", "Marta", ""], ["Wong", "Catherine", ""], ["Ecanow", "Gabrielle E", ""], ["Nye", "Maxwell", ""], ["Sechopoulos", "Theodoros", ""], ["Tessler", "Michael Henry", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "2106.07825", "submitter": "Maryam Mashayekhi", "authors": "Maryam Mashayekhi, Itzel Ramirez Tapia, Anjali Balagopal, Xinran\n  Zhong, Azar Sadeghnejad Barkousaraie, Rafe McBeth, Mu-Han Lin, Steve Jiang,\n  Dan Nguyen", "title": "Site-Agnostic 3D Dose Distribution Prediction with Deep Learning Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typically, the current dose prediction models are limited to small amounts of\ndata and require re-training for a specific site, often leading to suboptimal\nperformance. We propose a site-agnostic, 3D dose distribution prediction model\nusing deep learning that can leverage data from any treatment site, thus\nincreasing the total data available to train the model. Applying our proposed\nmodel to a new target treatment site requires only a brief fine-tuning of the\nmodel to the new data and involves no modifications to the model input channels\nor its parameters. Thus, it can be efficiently adapted to a different treatment\nsite, even with a small training dataset.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 01:14:10 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Mashayekhi", "Maryam", ""], ["Tapia", "Itzel Ramirez", ""], ["Balagopal", "Anjali", ""], ["Zhong", "Xinran", ""], ["Barkousaraie", "Azar Sadeghnejad", ""], ["McBeth", "Rafe", ""], ["Lin", "Mu-Han", ""], ["Jiang", "Steve", ""], ["Nguyen", "Dan", ""]]}, {"id": "2106.07832", "submitter": "Priyank Jaini", "authors": "Priyank Jaini, Lars Holdijk and Max Welling", "title": "Learning Equivariant Energy Based Models with Equivariant Stein\n  Variational Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We focus on the problem of efficient sampling and learning of probability\ndensities by incorporating symmetries in probabilistic models. We first\nintroduce Equivariant Stein Variational Gradient Descent algorithm -- an\nequivariant sampling method based on Stein's identity for sampling from\ndensities with symmetries. Equivariant SVGD explicitly incorporates symmetry\ninformation in a density through equivariant kernels which makes the resultant\nsampler efficient both in terms of sample complexity and the quality of\ngenerated samples. Subsequently, we define equivariant energy based models to\nmodel invariant densities that are learned using contrastive divergence. By\nutilizing our equivariant SVGD for training equivariant EBMs, we propose new\nways of improving and scaling up training of energy based models. We apply\nthese equivariant energy models for modelling joint densities in regression and\nclassification tasks for image datasets, many-body particle systems and\nmolecular structure generation.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 01:35:17 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 14:44:17 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Jaini", "Priyank", ""], ["Holdijk", "Lars", ""], ["Welling", "Max", ""]]}, {"id": "2106.07847", "submitter": "Yujia Bao", "authors": "Yujia Bao, Shiyu Chang, Regina Barzilay", "title": "Learning Stable Classifiers by Transferring Unstable Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study transfer learning in the presence of spurious correlations. We\nexperimentally demonstrate that directly transferring the stable feature\nextractor learned on the source task may not eliminate these biases for the\ntarget task. However, we hypothesize that the unstable features in the source\ntask and those in the target task are directly related. By explicitly informing\nthe target classifier of the source task's unstable features, we can regularize\nthe biases in the target task. Specifically, we derive a representation that\nencodes the unstable features by contrasting different data environments in the\nsource task. On the target task, we cluster data from this representation, and\nachieve robustness by minimizing the worst-case risk across all clusters. We\nevaluate our method on both text and image classifications. Empirical results\ndemonstrate that our algorithm is able to maintain robustness on the target\ntask, outperforming the best baseline by 22.9% in absolute accuracy across 12\ntransfer settings. Our code is available at https://github.com/YujiaBao/Tofu.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 02:41:12 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Bao", "Yujia", ""], ["Chang", "Shiyu", ""], ["Barzilay", "Regina", ""]]}, {"id": "2106.07849", "submitter": "Cody Blakeney", "authors": "Cody Blakeney, Nathaniel Huish, Yan Yan, Ziliang Zong", "title": "Simon Says: Evaluating and Mitigating Bias in Pruned Neural Networks\n  with Knowledge Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In recent years the ubiquitous deployment of AI has posed great concerns in\nregards to algorithmic bias, discrimination, and fairness. Compared to\ntraditional forms of bias or discrimination caused by humans, algorithmic bias\ngenerated by AI is more abstract and unintuitive therefore more difficult to\nexplain and mitigate. A clear gap exists in the current literature on\nevaluating and mitigating bias in pruned neural networks. In this work, we\nstrive to tackle the challenging issues of evaluating, mitigating, and\nexplaining induced bias in pruned neural networks. Our paper makes three\ncontributions. First, we propose two simple yet effective metrics, Combined\nError Variance (CEV) and Symmetric Distance Error (SDE), to quantitatively\nevaluate the induced bias prevention quality of pruned models. Second, we\ndemonstrate that knowledge distillation can mitigate induced bias in pruned\nneural networks, even with unbalanced datasets. Third, we reveal that model\nsimilarity has strong correlations with pruning induced bias, which provides a\npowerful method to explain why bias occurs in pruned neural networks. Our code\nis available at https://github.com/codestar12/pruning-distilation-bias\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 02:59:32 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Blakeney", "Cody", ""], ["Huish", "Nathaniel", ""], ["Yan", "Yan", ""], ["Zong", "Ziliang", ""]]}, {"id": "2106.07854", "submitter": "Duzhen Zhang", "authors": "Duzhen Zhang, Tielin Zhang, Shuncheng Jia, Xiang Cheng and Bo Xu", "title": "Population-coding and Dynamic-neurons improved Spiking Actor Network for\n  Reinforcement Learning", "comments": "27 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  With the Deep Neural Networks (DNNs) as a powerful function approximator,\nDeep Reinforcement Learning (DRL) has been excellently demonstrated on robotic\ncontrol tasks. Compared to DNNs with vanilla artificial neurons, the\nbiologically plausible Spiking Neural Network (SNN) contains a diverse\npopulation of spiking neurons, making it naturally powerful on state\nrepresentation with spatial and temporal information. Based on a hybrid\nlearning framework, where a spike actor-network infers actions from states and\na deep critic network evaluates the actor, we propose a Population-coding and\nDynamic-neurons improved Spiking Actor Network (PDSAN) for efficient state\nrepresentation from two different scales: input coding and neuronal coding. For\ninput coding, we apply population coding with dynamically receptive fields to\ndirectly encode each input state component. For neuronal coding, we propose\ndifferent types of dynamic-neurons (containing 1st-order and 2nd-order neuronal\ndynamics) to describe much more complex neuronal dynamics. Finally, the PDSAN\nis trained in conjunction with deep critic networks using the Twin Delayed Deep\nDeterministic policy gradient algorithm (TD3-PDSAN). Extensive experimental\nresults show that our TD3-PDSAN model achieves better performance than\nstate-of-the-art models on four OpenAI gym benchmark tasks. It is an important\nattempt to improve RL with SNN towards the effective computation satisfying\nbiological plausibility.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 03:14:41 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 08:54:31 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Zhang", "Duzhen", ""], ["Zhang", "Tielin", ""], ["Jia", "Shuncheng", ""], ["Cheng", "Xiang", ""], ["Xu", "Bo", ""]]}, {"id": "2106.07857", "submitter": "Bin Li", "authors": "Bin Li, Bin Sun (Member, IEEE) and Shutao Li (Fellow, IEEE)", "title": "Bilateral Personalized Dialogue Generation with Dynamic Persona-Aware\n  Fusion", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating personalized responses is one of the major challenges in natural\nhuman-robot interaction. Current researches in this field mainly focus on\ngenerating responses consistent with the robot's pre-assigned persona, while\nignoring the user's persona. Such responses may be inappropriate or even\noffensive, which may lead to the bad user experience. Therefore, we propose a\nbilateral personalized dialogue generation (BPDG) method with dynamic\npersona-aware fusion via multi-task transfer learning to generate responses\nconsistent with both personas. The proposed method aims to accomplish three\nlearning tasks: 1) an encoder is trained with dialogue utterances added with\ncorresponded personalized attributes and relative position (language model\ntask), 2) a dynamic persona-aware fusion module predicts the persona presence\nto adaptively fuse the contextual and bilateral personas encodings (persona\nprediction task) and 3) a decoder generates natural, fluent and personalized\nresponses (dialogue generation task). To make the generated responses more\npersonalized and bilateral persona-consistent, the Conditional Mutual\nInformation Maximum (CMIM) criterion is adopted to select the final response\nfrom the generated candidates. The experimental results show that the proposed\nmethod outperforms several state-of-the-art methods in terms of both automatic\nand manual evaluations.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 03:21:19 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Li", "Bin", "", "Member, IEEE"], ["Sun", "Bin", "", "Member, IEEE"], ["Li", "Shutao", "", "Fellow, IEEE"]]}, {"id": "2106.07873", "submitter": "Vishal Asnani", "authors": "Vishal Asnani, Xi Yin, Tal Hassner, Xiaoming Liu", "title": "Reverse Engineering of Generative Models: Inferring Model\n  Hyperparameters from Generated Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  State-of-the-art (SOTA) Generative Models (GMs) can synthesize\nphoto-realistic images that are hard for humans to distinguish from genuine\nphotos. We propose to perform reverse engineering of GMs to infer the model\nhyperparameters from the images generated by these models. We define a novel\nproblem, \"model parsing\", as estimating GM network architectures and training\nloss functions by examining their generated images -- a task seemingly\nimpossible for human beings. To tackle this problem, we propose a framework\nwith two components: a Fingerprint Estimation Network (FEN), which estimates a\nGM fingerprint from a generated image by training with four constraints to\nencourage the fingerprint to have desired properties, and a Parsing Network\n(PN), which predicts network architecture and loss functions from the estimated\nfingerprints. To evaluate our approach, we collect a fake image dataset with\n$100$K images generated by $100$ GMs. Extensive experiments show encouraging\nresults in parsing the hyperparameters of the unseen models. Finally, our\nfingerprint estimation can be leveraged for deepfake detection and image\nattribution, as we show by reporting SOTA results on both the recent Celeb-DF\nand image attribution benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 04:19:26 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Asnani", "Vishal", ""], ["Yin", "Xi", ""], ["Hassner", "Tal", ""], ["Liu", "Xiaoming", ""]]}, {"id": "2106.07892", "submitter": "Juan Rojas", "authors": "Guanglin Ji, Junyan Yan, Jingxin Du, Wanquan Yan, Jibiao Chen,\n  Yongkang Lu, Juan Rojas, and Shing Shin Cheng", "title": "Towards Safe Control of Continuum Manipulator Using Shielded Multiagent\n  Reinforcement Learning", "comments": "8 pages, 12 figs, 1 table, 2 pseudo-code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Continuum robotic manipulators are increasingly adopted in minimal invasive\nsurgery. However, their nonlinear behavior is challenging to model accurately,\nespecially when subject to external interaction, potentially leading to poor\ncontrol performance. In this letter, we investigate the feasibility of adopting\na model-free multiagent reinforcement learning (RL), namely multiagent deep Q\nnetwork (MADQN), to control a 2-degree of freedom (DoF) cable-driven continuum\nsurgical manipulator. The control of the robot is formulated as a one-DoF, one\nagent problem in the MADQN framework to improve the learning efficiency.\nCombined with a shielding scheme that enables dynamic variation of the action\nset boundary, MADQN leads to efficient and importantly safer control of the\nrobot. Shielded MADQN enabled the robot to perform point and trajectory\ntracking with submillimeter root mean square errors under external loads, soft\nobstacles, and rigid collision, which are common interaction scenarios\nencountered by surgical manipulators. The controller was further proven to be\neffective in a miniature continuum robot with high structural nonlinearitiy,\nachieving trajectory tracking with submillimeter accuracy under external\npayload.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 05:55:05 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Ji", "Guanglin", ""], ["Yan", "Junyan", ""], ["Du", "Jingxin", ""], ["Yan", "Wanquan", ""], ["Chen", "Jibiao", ""], ["Lu", "Yongkang", ""], ["Rojas", "Juan", ""], ["Cheng", "Shing Shin", ""]]}, {"id": "2106.07905", "submitter": "Ziheng Jiao", "authors": "Rui Zhang and Ziheng Jiao and Hongyuan Zhang and Xuelong Li", "title": "Non-Gradient Manifold Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network (DNN) generally takes thousands of iterations to optimize\nvia gradient descent and thus has a slow convergence. In addition, softmax, as\na decision layer, may ignore the distribution information of the data during\nclassification. Aiming to tackle the referred problems, we propose a novel\nmanifold neural network based on non-gradient optimization, i.e., the\nclosed-form solutions. Considering that the activation function is generally\ninvertible, we reconstruct the network via forward ridge regression and low\nrank backward approximation, which achieve the rapid convergence. Moreover, by\nunifying the flexible Stiefel manifold and adaptive support vector machine, we\ndevise the novel decision layer which efficiently fits the manifold structure\nof the data and label information. Consequently, a jointly non-gradient\noptimization method is designed to generate the network with closed-form\nresults. Eventually, extensive experiments validate the superior performance of\nthe model.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 06:39:13 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Zhang", "Rui", ""], ["Jiao", "Ziheng", ""], ["Zhang", "Hongyuan", ""], ["Li", "Xuelong", ""]]}, {"id": "2106.07921", "submitter": "Niklas Muennighoff", "authors": "Niklas Muennighoff", "title": "Diagnosing the Impact of AI on Radiology in China", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence will significantly impact the work environment of\nradiologists. I suggest that up to 50% of a radiologists work in 2021 will be\nperformed by AI-models in 2025. However, it won't increase beyond that 50%\nlevel, as radiologists remain key for human-centered aspects of their job. I\nproject that few to no radiologists will be laid off in China due to the\nexisting supply shortage of radiology services in 2021. The application of AI\nin radiology could contribute 1.7 billion USD to China's GDP in 2025. It will\nfurther allow radiologists to start productive work up to four years earlier.\nAI in radiology will positively impact the health of patients and radiologists\nthemselves.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 07:18:07 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Muennighoff", "Niklas", ""]]}, {"id": "2106.07924", "submitter": "Elad Denenberg", "authors": "Elad Denenberg, Amanda Coles, and Derek Long", "title": "Improving Search by Utilizing State Information in OPTIC Planners\n  Compilation to LP", "comments": "8 pages, 3 figures. Preprint, last submitted to the International\n  Conference on Automated Planning and Scheduling (ICAPS 2021) at 21.01.2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automated planners are computer tools that allow autonomous agents to make\nstrategies and decisions by determining a set of actions for the agent that to\ntake, which will carry a system from a given initial state to the desired goal\nstate. Many planners are domain-independent, allowing their deployment in a\nvariety of domains. Such is the broad family of OPTIC planners. These planners\nperform Forward Search and call a Linear Programming (LP) solver multiple times\nat every state to check for consistency and to set bounds on the numeric\nvariables. These checks can be computationally costly, especially in real-life\napplications. This paper suggests a method for identifying information about\nthe specific state being evaluated, allowing the formulation of the equations\nto facilitate better solver selection and faster LP solving. The usefulness of\nthe method is demonstrated in six domains and is shown to enhance performance\nsignificantly.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 07:23:31 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Denenberg", "Elad", ""], ["Coles", "Amanda", ""], ["Long", "Derek", ""]]}, {"id": "2106.07925", "submitter": "Byunggill Joe", "authors": "Byunggill Joe, Akshay Mehra, Insik Shin, and Jihun Hamm", "title": "Machine Learning with Electronic Health Records is vulnerable to\n  Backdoor Trigger Attacks", "comments": null, "journal-ref": "AAAI 2021 Workshop on Trustworthy AI for Healthcare", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic Health Records (EHRs) provide a wealth of information for machine\nlearning algorithms to predict the patient outcome from the data including\ndiagnostic information, vital signals, lab tests, drug administration, and\ndemographic information. Machine learning models can be built, for example, to\nevaluate patients based on their predicted mortality or morbidity and to\npredict required resources for efficient resource management in hospitals. In\nthis paper, we demonstrate that an attacker can manipulate the machine learning\npredictions with EHRs easily and selectively at test time by backdoor attacks\nwith the poisoned training data. Furthermore, the poison we create has\nstatistically similar features to the original data making it hard to detect,\nand can also attack multiple machine learning models without any knowledge of\nthe models. With less than 5% of the raw EHR data poisoned, we achieve average\nattack success rates of 97% on mortality prediction tasks with MIMIC-III\ndatabase against Logistic Regression, Multilayer Perceptron, and Long\nShort-term Memory models simultaneously.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 07:27:39 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Joe", "Byunggill", ""], ["Mehra", "Akshay", ""], ["Shin", "Insik", ""], ["Hamm", "Jihun", ""]]}, {"id": "2106.07932", "submitter": "Yoo Yongmin", "authors": "Tak-Sung Heo, Yongmin Yoo, Yeongjoon Park, Byeong-Cheol Jo, Kyungsun\n  Kim", "title": "Medical Code Prediction from Discharge Summary: Document to Sequence\n  BERT using Sequence Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical notes are unstructured text generated by clinicians during patient\nencounters. Clinical notes are usually accompanied by a set of metadata codes\nfrom the International Classification of Diseases(ICD). ICD code is an\nimportant code used in various operations, including insurance, reimbursement,\nmedical diagnosis, etc. Therefore, it is important to classify ICD codes\nquickly and accurately. However, annotating these codes is costly and\ntime-consuming. So we propose a model based on bidirectional encoder\nrepresentations from transformers (BERT) using the sequence attention method\nfor automatic ICD code assignment. We evaluate our approach on the medical\ninformation mart for intensive care III (MIMIC-III) benchmark dataset. Our\nmodel achieved performance of macro-averaged F1: 0.62898 and micro-averaged F1:\n0.68555 and is performing better than a performance of the state-of-the-art\nmodel using the MIMIC-III dataset. The contribution of this study proposes a\nmethod of using BERT that can be applied to documents and a sequence attention\nmethod that can capture important sequence in-formation appearing in documents.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 07:35:50 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 05:26:19 GMT"}, {"version": "v3", "created": "Mon, 5 Jul 2021 06:44:14 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Heo", "Tak-Sung", ""], ["Yoo", "Yongmin", ""], ["Park", "Yeongjoon", ""], ["Jo", "Byeong-Cheol", ""], ["Kim", "Kyungsun", ""]]}, {"id": "2106.07959", "submitter": "Yibo Guo", "authors": "Yibo Guo, Yiming Fan, Zhiyang Xiang, Haidi Wang, Wenhua Meng,\n  Mingliang Xu", "title": "Zero-sample surface defect detection and classification based on\n  semantic feedback neural network", "comments": "28 pages 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Defect detection and classification technology has changed from traditional\nartificial visual inspection to current intelligent automated inspection, but\nmost of the current defect detection methods are training related detection\nmodels based on a data-driven approach, taking into account the difficulty of\ncollecting some sample data in the industrial field. We apply zero-shot\nlearning technology to the industrial field. Aiming at the problem of the\nexisting \"Latent Feature Guide Attribute Attention\" (LFGAA) zero-shot image\nclassification network, the output latent attributes and artificially defined\nattributes are different in the semantic space, which leads to the problem of\nmodel performance degradation, proposed an LGFAA network based on semantic\nfeedback, and improved model performance by constructing semantic embedded\nmodules and feedback mechanisms. At the same time, for the common domain shift\nproblem in zero-shot learning, based on the idea of co-training algorithm using\nthe difference information between different views of data to learn from each\nother, we propose an Ensemble Co-training algorithm, which adaptively reduces\nthe prediction error in image tag embedding from multiple angles. Various\nexperiments conducted on the zero-shot dataset and the cylinder liner dataset\nin the industrial field provide competitive results.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 08:26:36 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Guo", "Yibo", ""], ["Fan", "Yiming", ""], ["Xiang", "Zhiyang", ""], ["Wang", "Haidi", ""], ["Meng", "Wenhua", ""], ["Xu", "Mingliang", ""]]}, {"id": "2106.07967", "submitter": "Jan Philip Wahle", "authors": "Jan Philip Wahle and Terry Ruas and Norman Meuschke and Bela Gipp", "title": "Incorporating Word Sense Disambiguation in Neural Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present two supervised (pre-)training methods to incorporate gloss\ndefinitions from lexical resources into neural language models (LMs). The\ntraining improves our models' performance for Word Sense Disambiguation (WSD)\nbut also benefits general language understanding tasks while adding almost no\nparameters. We evaluate our techniques with seven different neural LMs and find\nthat XLNet is more suitable for WSD than BERT. Our best-performing methods\nexceeds state-of-the-art WSD techniques on the SemCor 3.0 dataset by 0.5% F1\nand increase BERT's performance on the GLUE benchmark by 1.1% on average.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 08:44:08 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Wahle", "Jan Philip", ""], ["Ruas", "Terry", ""], ["Meuschke", "Norman", ""], ["Gipp", "Bela", ""]]}, {"id": "2106.08007", "submitter": "Masaru Isonuma", "authors": "Masaru Isonuma, Junichiro Mori, Danushka Bollegala, Ichiro Sakata", "title": "Unsupervised Abstractive Opinion Summarization by Generating Sentences\n  with Tree-Structured Topic Guidance", "comments": "accepted to TACL, pre-MIT Press publication version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a novel unsupervised abstractive summarization method for\nopinionated texts. While the basic variational autoencoder-based models assume\na unimodal Gaussian prior for the latent code of sentences, we alternate it\nwith a recursive Gaussian mixture, where each mixture component corresponds to\nthe latent code of a topic sentence and is mixed by a tree-structured topic\ndistribution. By decoding each Gaussian component, we generate sentences with\ntree-structured topic guidance, where the root sentence conveys generic\ncontent, and the leaf sentences describe specific topics. Experimental results\ndemonstrate that the generated topic sentences are appropriate as a summary of\nopinionated texts, which are more informative and cover more input contents\nthan those generated by the recent unsupervised summarization model\n(Bra\\v{z}inskas et al., 2020). Furthermore, we demonstrate that the variance of\nlatent Gaussians represents the granularity of sentences, analogous to Gaussian\nword embedding (Vilnis and McCallum, 2015).\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 09:37:04 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Isonuma", "Masaru", ""], ["Mori", "Junichiro", ""], ["Bollegala", "Danushka", ""], ["Sakata", "Ichiro", ""]]}, {"id": "2106.08021", "submitter": "Soumyasis Gun", "authors": "Prathyusha Akundi, Soumyasis Gun, Jayanthi Sivaswamy", "title": "A Clinically Inspired Approach for Melanoma classification", "comments": "5 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Melanoma is a leading cause of deaths due to skin cancer deaths and hence,\nearly and effective diagnosis of melanoma is of interest. Current approaches\nfor automated diagnosis of melanoma either use pattern recognition or\nanalytical recognition like ABCDE (asymmetry, border, color, diameter and\nevolving) criterion. In practice however, a differential approach wherein\noutliers (ugly duckling) are detected and used to evaluate nevi/lesions.\nIncorporation of differential recognition in Computer Aided Diagnosis (CAD)\nsystems has not been explored but can be beneficial as it can provide a\nclinical justification for the derived decision. We present a method for\nidentifying and quantifying ugly ducklings by performing Intra-Patient\nComparative Analysis (IPCA) of neighboring nevi. This is then incorporated in a\nCAD system design for melanoma detection. This design ensures flexibility to\nhandle cases where IPCA is not possible. Our experiments on a public dataset\nshow that the outlier information helps boost the sensitivity of detection by\nat least 4.1 % and specificity by 4.0 % to 8.9 %, depending on the use of a\nstrong (EfficientNet) or moderately strong (VGG or ResNet) classifier.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 10:12:24 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Akundi", "Prathyusha", ""], ["Gun", "Soumyasis", ""], ["Sivaswamy", "Jayanthi", ""]]}, {"id": "2106.08022", "submitter": "Jialong Wang", "authors": "Zheng Wang, Jialong Wang, Yuchen Guo, Zhiguo Gong", "title": "Zero-shot Node Classification with Decomposed Graph Prototype Network", "comments": "Accepted by KDD 2021", "journal-ref": null, "doi": "10.1145/3447548.3467230", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Node classification is a central task in graph data analysis. Scarce or even\nno labeled data of emerging classes is a big challenge for existing methods. A\nnatural question arises: can we classify the nodes from those classes that have\nnever been seen? In this paper, we study this zero-shot node classification\n(ZNC) problem which has a two-stage nature: (1) acquiring high-quality class\nsemantic descriptions (CSDs) for knowledge transfer, and (2) designing a well\ngeneralized graph-based learning model. For the first stage, we give a novel\nquantitative CSDs evaluation strategy based on estimating the real class\nrelationships, so as to get the \"best\" CSDs in a completely automatic way. For\nthe second stage, we propose a novel Decomposed Graph Prototype Network (DGPN)\nmethod, following the principles of locality and compositionality for zero-shot\nmodel generalization. Finally, we conduct extensive experiments to demonstrate\nthe effectiveness of our solutions.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 10:13:20 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Wang", "Zheng", ""], ["Wang", "Jialong", ""], ["Guo", "Yuchen", ""], ["Gong", "Zhiguo", ""]]}, {"id": "2106.08027", "submitter": "Peter Pfeiffer", "authors": "Peter Pfeiffer, Johannes Lahann and Peter Fettke", "title": "Multivariate Business Process Representation Learning utilizing Gramian\n  Angular Fields and Convolutional Neural Networks", "comments": "Accepted at the Business Process Management Conference 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning meaningful representations of data is an important aspect of machine\nlearning and has recently been successfully applied to many domains like\nlanguage understanding or computer vision. Instead of training a model for one\nspecific task, representation learning is about training a model to capture all\nuseful information in the underlying data and make it accessible for a\npredictor. For predictive process analytics, it is essential to have all\nexplanatory characteristics of a process instance available when making\npredictions about the future, as well as for clustering and anomaly detection.\nDue to the large variety of perspectives and types within business process\ndata, generating a good representation is a challenging task. In this paper, we\npropose a novel approach for representation learning of business process\ninstances which can process and combine most perspectives in an event log. In\nconjunction with a self-supervised pre-training method, we show the\ncapabilities of the approach through a visualization of the representation\nspace and case retrieval. Furthermore, the pre-trained model is fine-tuned to\nmultiple process prediction tasks and demonstrates its effectiveness in\ncomparison with existing approaches.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 10:21:14 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Pfeiffer", "Peter", ""], ["Lahann", "Johannes", ""], ["Fettke", "Peter", ""]]}, {"id": "2106.08053", "submitter": "Rui Lu", "authors": "Rui Lu, Gao Huang, Simon S. Du", "title": "On the Power of Multitask Representation Learning in Linear MDP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While multitask representation learning has become a popular approach in\nreinforcement learning (RL), theoretical understanding of why and when it works\nremains limited. This paper presents analyses for the statistical benefit of\nmultitask representation learning in linear Markov Decision Process (MDP) under\na generative model. In this paper, we consider an agent to learn a\nrepresentation function $\\phi$ out of a function class $\\Phi$ from $T$ source\ntasks with $N$ data per task, and then use the learned $\\hat{\\phi}$ to reduce\nthe required number of sample for a new task. We first discover a\n\\emph{Least-Activated-Feature-Abundance} (LAFA) criterion, denoted as $\\kappa$,\nwith which we prove that a straightforward least-square algorithm learns a\npolicy which is $\\tilde{O}(H^2\\sqrt{\\frac{\\mathcal{C}(\\Phi)^2 \\kappa\nd}{NT}+\\frac{\\kappa d}{n}})$ sub-optimal. Here $H$ is the planning horizon,\n$\\mathcal{C}(\\Phi)$ is $\\Phi$'s complexity measure, $d$ is the dimension of the\nrepresentation (usually $d\\ll \\mathcal{C}(\\Phi)$) and $n$ is the number of\nsamples for the new task. Thus the required $n$ is $O(\\kappa d H^4)$ for the\nsub-optimality to be close to zero, which is much smaller than\n$O(\\mathcal{C}(\\Phi)^2\\kappa d H^4)$ in the setting without multitask\nrepresentation learning, whose sub-optimality gap is\n$\\tilde{O}(H^2\\sqrt{\\frac{\\kappa \\mathcal{C}(\\Phi)^2d}{n}})$. This\ntheoretically explains the power of multitask representation learning in\nreducing sample complexity. Further, we note that to ensure high sample\nefficiency, the LAFA criterion $\\kappa$ should be small. In fact, $\\kappa$\nvaries widely in magnitude depending on the different sampling distribution for\nnew task. This indicates adaptive sampling technique is important to make\n$\\kappa$ solely depend on $d$. Finally, we provide empirical results of a noisy\ngrid-world environment to corroborate our theoretical findings.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 11:21:06 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Lu", "Rui", ""], ["Huang", "Gao", ""], ["Du", "Simon S.", ""]]}, {"id": "2106.08060", "submitter": "Antoine Boutet", "authors": "Th\\'eo Jourdan, Antoine Boutet, Carole Frindel", "title": "Privacy Assessment of Federated Learning using Private Personalized\n  Layers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) is a collaborative scheme to train a learning model\nacross multiple participants without sharing data. While FL is a clear step\nforward towards enforcing users' privacy, different inference attacks have been\ndeveloped. In this paper, we quantify the utility and privacy trade-off of a FL\nscheme using private personalized layers. While this scheme has been proposed\nas local adaptation to improve the accuracy of the model through local\npersonalization, it has also the advantage to minimize the information about\nthe model exchanged with the server. However, the privacy of such a scheme has\nnever been quantified. Our evaluations using motion sensor dataset show that\npersonalized layers speed up the convergence of the model and slightly improve\nthe accuracy for all users compared to a standard FL scheme while better\npreventing both attribute and membership inferences compared to a FL scheme\nusing local differential privacy.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 11:40:16 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Jourdan", "Th\u00e9o", ""], ["Boutet", "Antoine", ""], ["Frindel", "Carole", ""]]}, {"id": "2106.08062", "submitter": "Soyoung Yoon", "authors": "Soyoung Yoon, Gyuwan Kim, Kyumin Park", "title": "SSMix: Saliency-Based Span Mixup for Text Classification", "comments": "Findings of ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation with mixup has shown to be effective on various computer\nvision tasks. Despite its great success, there has been a hurdle to apply mixup\nto NLP tasks since text consists of discrete tokens with variable length. In\nthis work, we propose SSMix, a novel mixup method where the operation is\nperformed on input text rather than on hidden vectors like previous approaches.\nSSMix synthesizes a sentence while preserving the locality of two original\ntexts by span-based mixing and keeping more tokens related to the prediction\nrelying on saliency information. With extensive experiments, we empirically\nvalidate that our method outperforms hidden-level mixup methods on a wide range\nof text classification benchmarks, including textual entailment, sentiment\nclassification, and question-type classification. Our code is available at\nhttps://github.com/clovaai/ssmix.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 11:40:23 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Yoon", "Soyoung", ""], ["Kim", "Gyuwan", ""], ["Park", "Kyumin", ""]]}, {"id": "2106.08064", "submitter": "Johannes Rabold", "authors": "Johannes Rabold, Michael Siebers, Ute Schmid", "title": "Generating Contrastive Explanations for Inductive Logic Programming\n  Based on a Near Miss Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent research, human-understandable explanations of machine learning\nmodels have received a lot of attention. Often explanations are given in form\nof model simplifications or visualizations. However, as shown in cognitive\nscience as well as in early AI research, concept understanding can also be\nimproved by the alignment of a given instance for a concept with a similar\ncounterexample. Contrasting a given instance with a structurally similar\nexample which does not belong to the concept highlights what characteristics\nare necessary for concept membership. Such near misses have been proposed by\nWinston (1970) as efficient guidance for learning in relational domains. We\nintroduce an explanation generation algorithm for relational concepts learned\nwith Inductive Logic Programming (\\textsc{GeNME}). The algorithm identifies\nnear miss examples from a given set of instances and ranks these examples by\ntheir degree of closeness to a specific positive instance. A modified rule\nwhich covers the near miss but not the original instance is given as an\nexplanation. We illustrate \\textsc{GeNME} with the well known family domain\nconsisting of kinship relations, the visual relational Winston arches domain\nand a real-world domain dealing with file management. We also present a\npsychological experiment comparing human preferences of rule-based,\nexample-based, and near miss explanations in the family and the arches domains.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 11:42:05 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Rabold", "Johannes", ""], ["Siebers", "Michael", ""], ["Schmid", "Ute", ""]]}, {"id": "2106.08117", "submitter": "Dongsheng Wang", "authors": "Dongsheng Wang", "title": "Semantic Representation and Inference for NLP", "comments": "PhD thesis, the University of Copenhagen", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Semantic representation and inference is essential for Natural Language\nProcessing (NLP). The state of the art for semantic representation and\ninference is deep learning, and particularly Recurrent Neural Networks (RNNs),\nConvolutional Neural Networks (CNNs), and transformer Self-Attention models.\nThis thesis investigates the use of deep learning for novel semantic\nrepresentation and inference, and makes contributions in the following three\nareas: creating training data, improving semantic representations and extending\ninference learning. In terms of creating training data, we contribute the\nlargest publicly available dataset of real-life factual claims for the purpose\nof automatic claim verification (MultiFC), and we present a novel inference\nmodel composed of multi-scale CNNs with different kernel sizes that learn from\nexternal sources to infer fact checking labels. In terms of improving semantic\nrepresentations, we contribute a novel model that captures non-compositional\nsemantic indicators. By definition, the meaning of a non-compositional phrase\ncannot be inferred from the individual meanings of its composing words (e.g.,\nhot dog). Motivated by this, we operationalize the compositionality of a phrase\ncontextually by enriching the phrase representation with external word\nembeddings and knowledge graphs. Finally, in terms of inference learning, we\npropose a series of novel deep learning architectures that improve inference by\nusing syntactic dependencies, by ensembling role guided attention heads,\nincorporating gating layers, and concatenating multiple heads in novel and\neffective ways. This thesis consists of seven publications (five published and\ntwo under review).\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 13:22:48 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Wang", "Dongsheng", ""]]}, {"id": "2106.08166", "submitter": "Dimitrios Alivanistos", "authors": "Dimitrios Alivanistos and Max Berrendorf and Michael Cochez and\n  Mikhail Galkin", "title": "Query Embedding on Hyper-relational Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop logical reasoning is an established problem in the field of\nrepresentation learning on knowledge graphs (KGs). It subsumes both one-hop\nlink prediction as well as other more complex types of logical queries.\nExisting algorithms operate only on classical, triple-based graphs, whereas\nmodern KGs often employ a hyper-relational modeling paradigm. In this paradigm,\ntyped edges may have several key-value pairs known as qualifiers that provide\nfine-grained context for facts. In queries, this context modifies the meaning\nof relations, and usually reduces the answer set. Hyper-relational queries are\noften observed in real-world KG applications, and existing approaches for\napproximate query answering cannot make use of qualifier pairs. In this work,\nwe bridge this gap and extend the multi-hop reasoning problem to\nhyper-relational KGs allowing to tackle this new type of complex queries.\nBuilding upon recent advancements in Graph Neural Networks and query embedding\ntechniques, we study how to embed and answer hyper-relational conjunctive\nqueries. Besides that, we propose a method to answer such queries and\ndemonstrate in our experiments that qualifiers improve query answering on a\ndiverse set of query patterns.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 14:08:50 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 13:53:13 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Alivanistos", "Dimitrios", ""], ["Berrendorf", "Max", ""], ["Cochez", "Michael", ""], ["Galkin", "Mikhail", ""]]}, {"id": "2106.08187", "submitter": "Zehong Hu Mr.", "authors": "Long Yang, Zhao Li, Zehong Hu, Shasha Ruan, Shijian Li, Gang Pan,\n  Hongyang Chen", "title": "Thompson Sampling for Unimodal Bandits", "comments": "There are some technical parts need to be improved. We will fix these\n  places and provide an updated version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a Thompson Sampling algorithm for \\emph{unimodal}\nbandits, where the expected reward is unimodal over the partially ordered arms.\nTo exploit the unimodal structure better, at each step, instead of exploration\nfrom the entire decision space, our algorithm makes decision according to\nposterior distribution only in the neighborhood of the arm that has the highest\nempirical mean estimate. We theoretically prove that, for Bernoulli rewards,\nthe regret of our algorithm reaches the lower bound of unimodal bandits, thus\nit is asymptotically optimal. For Gaussian rewards, the regret of our algorithm\nis $\\mathcal{O}(\\log T)$, which is far better than standard Thompson Sampling\nalgorithms. Extensive experiments demonstrate the effectiveness of the proposed\nalgorithm on both synthetic data sets and the real-world applications.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 14:40:34 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 04:51:04 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Yang", "Long", ""], ["Li", "Zhao", ""], ["Hu", "Zehong", ""], ["Ruan", "Shasha", ""], ["Li", "Shijian", ""], ["Pan", "Gang", ""], ["Chen", "Hongyang", ""]]}, {"id": "2106.08188", "submitter": "Dawood Al Chanti", "authors": "Dawood Al Chanti and Diana Mateus", "title": "Optimal Latent Vector Alignment for Unsupervised Domain Adaptation in\n  Medical Image Segmentation", "comments": "10 pages, 3 figures, conference MICCAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper addresses the domain shift problem for segmentation. As a\nsolution, we propose OLVA, a novel and lightweight unsupervised domain\nadaptation method based on a Variational Auto-Encoder (VAE) and Optimal\nTransport (OT) theory. Thanks to the VAE, our model learns a shared\ncross-domain latent space that follows a normal distribution, which reduces the\ndomain shift. To guarantee valid segmentations, our shared latent space is\ndesigned to model the shape rather than the intensity variations. We further\nrely on an OT loss to match and align the remaining discrepancy between the two\ndomains in the latent space. We demonstrate OLVA's effectiveness for the\nsegmentation of multiple cardiac structures on the public Multi-Modality Whole\nHeart Segmentation (MM-WHS) dataset, where the source domain consists of\nannotated 3D MR images and the unlabelled target domain of 3D CTs. Our results\nshow remarkable improvements with an additional margin of 12.5\\% dice score\nover concurrent generative training approaches.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 14:41:09 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Chanti", "Dawood Al", ""], ["Mateus", "Diana", ""]]}, {"id": "2106.08229", "submitter": "Pablo Samuel Castro", "authors": "Pablo Samuel Castro and Tyler Kastner and Prakash Panangaden and Mark\n  Rowland", "title": "MICo: Learning improved representations via sampling-based state\n  similarity for Markov decision processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new behavioural distance over the state space of a Markov\ndecision process, and demonstrate the use of this distance as an effective\nmeans of shaping the learnt representations of deep reinforcement learning\nagents. While existing notions of state similarity are typically difficult to\nlearn at scale due to high computational cost and lack of sample-based\nalgorithms, our newly-proposed distance addresses both of these issues. In\naddition to providing detailed theoretical analysis, we provide empirical\nevidence that learning this distance alongside the value function yields\nstructured and informative representations, including strong results on the\nArcade Learning Environment benchmark.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 14:24:12 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Castro", "Pablo Samuel", ""], ["Kastner", "Tyler", ""], ["Panangaden", "Prakash", ""], ["Rowland", "Mark", ""]]}, {"id": "2106.08253", "submitter": "Qihao Zhu", "authors": "Qihao Zhu, Wenjie Zhang", "title": "Code Generation Based on Deep Learning: a Brief Review", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic software development has been a research hot spot in the field of\nsoftware engineering (SE) in the past decade. In particular, deep learning (DL)\nhas been applied and achieved a lot of progress in various SE tasks. Among all\napplications, automatic code generation by machines as a general concept,\nincluding code completion and code synthesis, is a common expectation in the\nfield of SE, which may greatly reduce the development burden of the software\ndevelopers and improves the efficiency and quality of the software development\nprocess to a certain extent. Code completion is an important part of modern\nintegrated development environments (IDEs). Code completion technology\neffectively helps programmers complete code class names, method names, and\nkey-words, etc., which improves the efficiency of program development and\nreduces spelling errors in the coding process. Such tools use static analysis\non the code and provide candidates for completion arranged in alphabetical\norder. Code synthesis is implemented from two aspects, one based on\ninput-output samples and the other based on functionality description. In this\nstudy, we introduce existing techniques of these two aspects and the\ncorresponding DL techniques, and present some possible future research\ndirections.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 16:01:51 GMT"}, {"version": "v2", "created": "Sun, 20 Jun 2021 16:04:25 GMT"}, {"version": "v3", "created": "Thu, 1 Jul 2021 07:15:40 GMT"}, {"version": "v4", "created": "Sun, 4 Jul 2021 14:30:27 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Zhu", "Qihao", ""], ["Zhang", "Wenjie", ""]]}, {"id": "2106.08259", "submitter": "Falaah Arif Khan", "authors": "Falaah Arif Khan, Eleni Manis, Julia Stoyanovich", "title": "Fairness as Equality of Opportunity: Normative Guidance from Political\n  Philosophy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Recent interest in codifying fairness in Automated Decision Systems (ADS) has\nresulted in a wide range of formulations of what it means for an algorithmic\nsystem to be fair. Most of these propositions are inspired by, but inadequately\ngrounded in, political philosophy scholarship. This paper aims to correct that\ndeficit. We introduce a taxonomy of fairness ideals using doctrines of Equality\nof Opportunity (EOP) from political philosophy, clarifying their conceptions in\nphilosophy and the proposed codification in fair machine learning. We arrange\nthese fairness ideals onto an EOP spectrum, which serves as a useful frame to\nguide the design of a fair ADS in a given context.\n  We use our fairness-as-EOP framework to re-interpret the impossibility\nresults from a philosophical perspective, as the in-compatibility between\ndifferent value systems, and demonstrate the utility of the framework with\nseveral real-world and hypothetical examples. Through our EOP-framework we hope\nto answer what it means for an ADS to be fair from a moral and political\nphilosophy standpoint, and to pave the way for similar scholarship from ethics\nand legal experts.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 16:07:58 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Khan", "Falaah Arif", ""], ["Manis", "Eleni", ""], ["Stoyanovich", "Julia", ""]]}, {"id": "2106.08261", "submitter": "Daniel Bear", "authors": "Daniel M. Bear, Elias Wang, Damian Mrowca, Felix J. Binder, Hsiau-Yu\n  Fish Tung, R.T. Pramod, Cameron Holdaway, Sirui Tao, Kevin Smith, Fan-Yun\n  Sun, Li Fei-Fei, Nancy Kanwisher, Joshua B. Tenenbaum, Daniel L.K. Yamins,\n  Judith E. Fan", "title": "Physion: Evaluating Physical Prediction from Vision in Humans and\n  Machines", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While machine learning algorithms excel at many challenging visual tasks, it\nis unclear that they can make predictions about commonplace real world physical\nevents. Here, we present a visual and physical prediction benchmark that\nprecisely measures this capability. In realistically simulating a wide variety\nof physical phenomena -- rigid and soft-body collisions, stable multi-object\nconfigurations, rolling and sliding, projectile motion -- our dataset presents\na more comprehensive challenge than existing benchmarks. Moreover, we have\ncollected human responses for our stimuli so that model predictions can be\ndirectly compared to human judgments. We compare an array of algorithms --\nvarying in their architecture, learning objective, input-output structure, and\ntraining data -- on their ability to make diverse physical predictions. We find\nthat graph neural networks with access to the physical state best capture human\nbehavior, whereas among models that receive only visual input, those with\nobject-centric representations or pretraining do best but fall far short of\nhuman accuracy. This suggests that extracting physically meaningful\nrepresentations of scenes is the main bottleneck to achieving human-like visual\nprediction. We thus demonstrate how our benchmark can identify areas for\nimprovement and measure progress on this key aspect of physical understanding.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 16:13:39 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 17:20:27 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Bear", "Daniel M.", ""], ["Wang", "Elias", ""], ["Mrowca", "Damian", ""], ["Binder", "Felix J.", ""], ["Tung", "Hsiau-Yu Fish", ""], ["Pramod", "R. T.", ""], ["Holdaway", "Cameron", ""], ["Tao", "Sirui", ""], ["Smith", "Kevin", ""], ["Sun", "Fan-Yun", ""], ["Fei-Fei", "Li", ""], ["Kanwisher", "Nancy", ""], ["Tenenbaum", "Joshua B.", ""], ["Yamins", "Daniel L. K.", ""], ["Fan", "Judith E.", ""]]}, {"id": "2106.08295", "submitter": "Marios Fournarakis", "authors": "Markus Nagel, Marios Fournarakis, Rana Ali Amjad, Yelysei Bondarenko,\n  Mart van Baalen, Tijmen Blankevoort", "title": "A White Paper on Neural Network Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While neural networks have advanced the frontiers in many applications, they\noften come at a high computational cost. Reducing the power and latency of\nneural network inference is key if we want to integrate modern networks into\nedge devices with strict power and compute requirements. Neural network\nquantization is one of the most effective ways of achieving these savings but\nthe additional noise it induces can lead to accuracy degradation. In this white\npaper, we introduce state-of-the-art algorithms for mitigating the impact of\nquantization noise on the network's performance while maintaining low-bit\nweights and activations. We start with a hardware motivated introduction to\nquantization and then consider two main classes of algorithms: Post-Training\nQuantization (PTQ) and Quantization-Aware-Training (QAT). PTQ requires no\nre-training or labelled data and is thus a lightweight push-button approach to\nquantization. In most cases, PTQ is sufficient for achieving 8-bit quantization\nwith close to floating-point accuracy. QAT requires fine-tuning and access to\nlabeled training data but enables lower bit quantization with competitive\nresults. For both solutions, we provide tested pipelines based on existing\nliterature and extensive experimentation that lead to state-of-the-art\nperformance for common deep learning models and tasks.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 17:12:42 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Nagel", "Markus", ""], ["Fournarakis", "Marios", ""], ["Amjad", "Rana Ali", ""], ["Bondarenko", "Yelysei", ""], ["van Baalen", "Mart", ""], ["Blankevoort", "Tijmen", ""]]}, {"id": "2106.08298", "submitter": "Jason R.C. Nurse Dr", "authors": "Suraj Sharma and Joseph Brennan and Jason R. C. Nurse", "title": "StockBabble: A Conversational Financial Agent to support Stock Market\n  Investors", "comments": "CUI 2021 - 3rd Conference on Conversational User Interfaces", "journal-ref": null, "doi": "10.1145/3469595.3469620", "report-no": null, "categories": "cs.HC cs.AI cs.CL cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce StockBabble, a conversational agent designed to support\nunderstanding and engagement with the stock market. StockBabble's value and\nnovelty is in its ability to empower retail investors -- many of which may be\nnew to investing -- and supplement their informational needs using a\nuser-friendly agent. Users have the ability to query information on companies\nto retrieve a general and financial overview of a stock, including accessing\nthe latest news and trading recommendations. They can also request charts which\ncontain live prices and technical investment indicators, and add shares to a\npersonal portfolio to allow performance monitoring over time. To evaluate our\nagent's potential, we conducted a user study with 15 participants. In total,\n73% (11/15) of respondents said that they felt more confident in investing\nafter using StockBabble, and all 15 would consider recommending it to others.\nThese results are encouraging and suggest a wider appeal for such agents.\nMoreover, we believe this research can help to inform the design and\ndevelopment of future intelligent, financial personal assistants.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 17:19:30 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Sharma", "Suraj", ""], ["Brennan", "Joseph", ""], ["Nurse", "Jason R. C.", ""]]}, {"id": "2106.08301", "submitter": "Sheng Lin", "authors": "Sheng Lin, Wei Jiang, Wei Wang, Kaidi Xu, Yanzhi Wang, Shan Liu and\n  Songnan Li", "title": "Efficient Micro-Structured Weight Unification and Pruning for Neural\n  Network Compression", "comments": "10 pages, 3 figures and 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressing Deep Neural Network (DNN) models to alleviate the storage and\ncomputation requirements is essential for practical applications, especially\nfor resource limited devices. Although capable of reducing a reasonable amount\nof model parameters, previous unstructured or structured weight pruning methods\ncan hardly truly accelerate inference, either due to the poor hardware\ncompatibility of the unstructured sparsity or due to the low sparse rate of the\nstructurally pruned network. Aiming at reducing both storage and computation,\nas well as preserving the original task performance, we propose a generalized\nweight unification framework at a hardware compatible micro-structured level to\nachieve high amount of compression and acceleration. Weight coefficients of a\nselected micro-structured block are unified to reduce the storage and\ncomputation of the block without changing the neuron connections, which turns\nto a micro-structured pruning special case when all unified coefficients are\nset to zero, where neuron connections (hence storage and computation) are\ncompletely removed. In addition, we developed an effective training framework\nbased on the alternating direction method of multipliers (ADMM), which converts\nour complex constrained optimization into separately solvable subproblems.\nThrough iteratively optimizing the subproblems, the desired micro-structure can\nbe ensured with high compression ratio and low performance degradation. We\nextensively evaluated our method using a variety of benchmark models and\ndatasets for different applications. Experimental results demonstrate\nstate-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 17:22:59 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 16:43:08 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Lin", "Sheng", ""], ["Jiang", "Wei", ""], ["Wang", "Wei", ""], ["Xu", "Kaidi", ""], ["Wang", "Yanzhi", ""], ["Liu", "Shan", ""], ["Li", "Songnan", ""]]}, {"id": "2106.08314", "submitter": "Ramin Hasani", "authors": "Charles Vorbach, Ramin Hasani, Alexander Amini, Mathias Lechner,\n  Daniela Rus", "title": "Causal Navigation by Continuous-time Neural Networks", "comments": "23 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Imitation learning enables high-fidelity, vision-based learning of policies\nwithin rich, photorealistic environments. However, such techniques often rely\non traditional discrete-time neural models and face difficulties in\ngeneralizing to domain shifts by failing to account for the causal\nrelationships between the agent and the environment. In this paper, we propose\na theoretical and experimental framework for learning causal representations\nusing continuous-time neural networks, specifically over their discrete-time\ncounterparts. We evaluate our method in the context of visual-control learning\nof drones over a series of complex tasks, ranging from short- and long-term\nnavigation, to chasing static and dynamic objects through photorealistic\nenvironments. Our results demonstrate that causal continuous-time deep models\ncan perform robust navigation tasks, where advanced recurrent models fail.\nThese models learn complex causal control representations directly from raw\nvisual inputs and scale to solve a variety of tasks using imitation learning.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 17:45:32 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Vorbach", "Charles", ""], ["Hasani", "Ramin", ""], ["Amini", "Alexander", ""], ["Lechner", "Mathias", ""], ["Rus", "Daniela", ""]]}, {"id": "2106.08320", "submitter": "Danica J. Sutherland", "authors": "Yazhe Li and Roman Pogodin and Danica J. Sutherland and Arthur Gretton", "title": "Self-Supervised Learning with Kernel Dependence Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We approach self-supervised learning of image representations from a\nstatistical dependence perspective, proposing Self-Supervised Learning with the\nHilbert-Schmidt Independence Criterion (SSL-HSIC). SSL-HSIC maximizes\ndependence between representations of transformed versions of an image and the\nimage identity, while minimizing the kernelized variance of those features.\nThis self-supervised learning framework yields a new understanding of InfoNCE,\na variational lower bound on the mutual information (MI) between different\ntransformations. While the MI itself is known to have pathologies which can\nresult in meaningless representations being learned, its bound is much better\nbehaved: we show that it implicitly approximates SSL-HSIC (with a slightly\ndifferent regularizer). Our approach also gives us insight into BYOL, since\nSSL-HSIC similarly learns local neighborhoods of samples. SSL-HSIC allows us to\ndirectly optimize statistical dependence in time linear in the batch size,\nwithout restrictive data assumptions or indirect mutual information estimators.\nTrained with or without a target network, SSL-HSIC matches the current\nstate-of-the-art for standard linear evaluation on ImageNet, semi-supervised\nlearning and transfer to other classification and vision tasks such as semantic\nsegmentation, depth estimation and object recognition.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 17:51:16 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Li", "Yazhe", ""], ["Pogodin", "Roman", ""], ["Sutherland", "Danica J.", ""], ["Gretton", "Arthur", ""]]}, {"id": "2106.08365", "submitter": "Xu Ji", "authors": "Xu Ji, Razvan Pascanu, Devon Hjelm, Andrea Vedaldi, Balaji\n  Lakshminarayanan, Yoshua Bengio", "title": "Predicting Unreliable Predictions by Shattering a Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Piecewise linear neural networks can be split into subfunctions, each with\nits own activation pattern, domain, and empirical error. Empirical error for\nthe full network can be written as an expectation over empirical error of\nsubfunctions. Constructing a generalization bound on subfunction empirical\nerror indicates that the more densely a subfunction is surrounded by training\nsamples in representation space, the more reliable its predictions are.\nFurther, it suggests that models with fewer activation regions generalize\nbetter, and models that abstract knowledge to a greater degree generalize\nbetter, all else equal. We propose not only a theoretical framework to reason\nabout subfunction error bounds but also a pragmatic way of approximately\nevaluating it, which we apply to predicting which samples the network will not\nsuccessfully generalize to. We test our method on detection of\nmisclassification and out-of-distribution samples, finding that it performs\ncompetitively in both cases. In short, some network activation patterns are\nassociated with higher reliability than others, and these can be identified\nusing subfunction error bounds.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 18:34:41 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Ji", "Xu", ""], ["Pascanu", "Razvan", ""], ["Hjelm", "Devon", ""], ["Vedaldi", "Andrea", ""], ["Lakshminarayanan", "Balaji", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2106.08371", "submitter": "Ivan Bravi", "authors": "Ivan Bravi and Simon Lucas", "title": "Rinascimento: searching the behaviour space of Splendor", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The use of Artificial Intelligence (AI) for play-testing is still on the\nsidelines of main applications of AI in games compared to performance-oriented\ngame-playing. One of the main purposes of play-testing a game is gathering data\non the gameplay, highlighting good and bad features of the design of the game,\nproviding useful insight to the game designers for improving the design. Using\nAI agents has the potential of speeding the process dramatically. The purpose\nof this research is to map the behavioural space (BSpace) of a game by using a\ngeneral method. Using the MAP-Elites algorithm we search the hyperparameter\nspace Rinascimento AI agents and map it to the BSpace defined by several\nbehavioural metrics. This methodology was able to highlight both exemplary and\ndegenerated behaviours in the original game design of Splendor and two\nvariations. In particular, the use of event-value functions has generally shown\na remarkable improvement in the coverage of the BSpace compared to agents based\non classic score-based reward signals.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 18:46:57 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Bravi", "Ivan", ""], ["Lucas", "Simon", ""]]}, {"id": "2106.08376", "submitter": "Zachariah Carmichael", "authors": "Zachariah Carmichael, Walter J. Scheirer", "title": "On the Objective Evaluation of Post Hoc Explainers", "comments": "14 pages, 4 figures. Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many applications of data-driven models demand transparency of decisions,\nespecially in health care, criminal justice, and other high-stakes\nenvironments. Modern trends in machine learning research have led to algorithms\nthat are increasingly intricate to the degree that they are considered to be\nblack boxes. In an effort to reduce the opacity of decisions, methods have been\nproposed to construe the inner workings of such models in a\nhuman-comprehensible manner. These post hoc techniques are described as being\nuniversal explainers - capable of faithfully augmenting decisions with\nalgorithmic insight. Unfortunately, there is little agreement about what\nconstitutes a \"good\" explanation. Moreover, current methods of explanation\nevaluation are derived from either subjective or proxy means. In this work, we\npropose a framework for the evaluation of post hoc explainers on ground truth\nthat is directly derived from the additive structure of a model. We demonstrate\nthe efficacy of the framework in understanding explainers by evaluating popular\nexplainers on thousands of synthetic and several real-world tasks. The\nframework unveils that explanations may be accurate but misattribute the\nimportance of individual features.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 19:06:51 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Carmichael", "Zachariah", ""], ["Scheirer", "Walter J.", ""]]}, {"id": "2106.08409", "submitter": "Aurora Saibene", "authors": "Francesca Gasparini, Giulia Rizzi, Aurora Saibene, Elisabetta Fersini", "title": "Benchmark dataset of memes with text transcriptions for automatic\n  detection of multi-modal misogynistic content", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper we present a benchmark dataset generated as part of a project\nfor automatic identification of misogyny within online content, which focuses\nin particular on memes. The benchmark here described is composed of 800 memes\ncollected from the most popular social media platforms, such as Facebook,\nTwitter, Instagram and Reddit, and consulting websites dedicated to collection\nand creation of memes. To gather misogynistic memes, specific keywords that\nrefer to misogynistic content have been considered as search criterion,\nconsidering different manifestations of hatred against women, such as body\nshaming, stereotyping, objectification and violence. In parallel, memes with no\nmisogynist content have been manually downloaded from the same web sources.\nAmong all the collected memes, three domain experts have selected a dataset of\n800 memes equally balanced between misogynistic and non-misogynistic ones. This\ndataset has been validated through a crowdsourcing platform, involving 60\nsubjects for the labelling process, in order to collect three evaluations for\neach instance. Two further binary labels have been collected from both the\nexperts and the crowdsourcing platform, for memes evaluated as misogynistic,\nconcerning aggressiveness and irony. Finally for each meme, the text has been\nmanually transcribed. The dataset provided is thus composed of the 800 memes,\nthe labels given by the experts and those obtained by the crowdsourcing\nvalidation, and the transcribed texts. This data can be used to approach the\nproblem of automatic detection of misogynistic content on the Web relying on\nboth textual and visual cues, facing phenomenons that are growing every day\nsuch as cybersexism and technology-facilitated violence.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 20:01:28 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Gasparini", "Francesca", ""], ["Rizzi", "Giulia", ""], ["Saibene", "Aurora", ""], ["Fersini", "Elisabetta", ""]]}, {"id": "2106.08413", "submitter": "Lily Xu", "authors": "Lily Xu, Andrew Perrault, Fei Fang, Haipeng Chen, Milind Tambe", "title": "Robust Reinforcement Learning Under Minimax Regret for Green Security", "comments": "Accepted at the Conference on Uncertainty in Artificial Intelligence\n  (UAI) 2021. 11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Green security domains feature defenders who plan patrols in the face of\nuncertainty about the adversarial behavior of poachers, illegal loggers, and\nillegal fishers. Importantly, the deterrence effect of patrols on adversaries'\nfuture behavior makes patrol planning a sequential decision-making problem.\nTherefore, we focus on robust sequential patrol planning for green security\nfollowing the minimax regret criterion, which has not been considered in the\nliterature. We formulate the problem as a game between the defender and nature\nwho controls the parameter values of the adversarial behavior and design an\nalgorithm MIRROR to find a robust policy. MIRROR uses two reinforcement\nlearning-based oracles and solves a restricted game considering limited\ndefender strategies and parameter values. We evaluate MIRROR on real-world\npoaching data.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 20:11:12 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Xu", "Lily", ""], ["Perrault", "Andrew", ""], ["Fang", "Fei", ""], ["Chen", "Haipeng", ""], ["Tambe", "Milind", ""]]}, {"id": "2106.08414", "submitter": "Amrit Singh Bedi", "authors": "Amrit Singh Bedi, Anjaly Parayil, Junyu Zhang, Mengdi Wang, Alec\n  Koppel", "title": "On the Sample Complexity and Metastability of Heavy-tailed Policy Search\n  in Continuous Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is a framework for interactive decision-making with\nincentives sequentially revealed across time without a system dynamics model.\nDue to its scaling to continuous spaces, we focus on policy search where one\niteratively improves a parameterized policy with stochastic policy gradient\n(PG) updates. In tabular Markov Decision Problems (MDPs), under persistent\nexploration and suitable parameterization, global optimality may be obtained.\nBy contrast, in continuous space, the non-convexity poses a pathological\nchallenge as evidenced by existing convergence results being mostly limited to\nstationarity or arbitrary local extrema. To close this gap, we step towards\npersistent exploration in continuous space through policy parameterizations\ndefined by distributions of heavier tails defined by tail-index parameter\nalpha, which increases the likelihood of jumping in state space. Doing so\ninvalidates smoothness conditions of the score function common to PG. Thus, we\nestablish how the convergence rate to stationarity depends on the policy's tail\nindex alpha, a Holder continuity parameter, integrability conditions, and an\nexploration tolerance parameter introduced here for the first time. Further, we\ncharacterize the dependence of the set of local maxima on the tail index\nthrough an exit and transition time analysis of a suitably defined Markov\nchain, identifying that policies associated with Levy Processes of a heavier\ntail converge to wider peaks. This phenomenon yields improved stability to\nperturbations in supervised learning, which we corroborate also manifests in\nimproved performance of policy search, especially when myopic and farsighted\nincentives are misaligned.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 20:12:44 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Bedi", "Amrit Singh", ""], ["Parayil", "Anjaly", ""], ["Zhang", "Junyu", ""], ["Wang", "Mengdi", ""], ["Koppel", "Alec", ""]]}, {"id": "2106.08415", "submitter": "Kevin Moran Ph.D.", "authors": "Junayed Mahmud, Fahim Faisal, Raihan Islam Arnob, Antonios\n  Anastasopoulos, Kevin Moran", "title": "Code to Comment Translation: A Comparative Study on Model Effectiveness\n  & Errors", "comments": "Accepted to the 2021 NLP4Prog Workshop co-located with The Joint\n  Conference of the 59th Annual Meeting of the Association for Computational\n  Linguistics and the 11th International Joint Conference on Natural Language\n  Processing (ACL-IJCNLP 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated source code summarization is a popular software engineering\nresearch topic wherein machine translation models are employed to \"translate\"\ncode snippets into relevant natural language descriptions. Most evaluations of\nsuch models are conducted using automatic reference-based metrics. However,\ngiven the relatively large semantic gap between programming languages and\nnatural language, we argue that this line of research would benefit from a\nqualitative investigation into the various error modes of current\nstate-of-the-art models. Therefore, in this work, we perform both a\nquantitative and qualitative comparison of three recently proposed source code\nsummarization models. In our quantitative evaluation, we compare the models\nbased on the smoothed BLEU-4, METEOR, and ROUGE-L machine translation metrics,\nand in our qualitative evaluation, we perform a manual open-coding of the most\ncommon errors committed by the models when compared to ground truth captions.\nOur investigation reveals new insights into the relationship between\nmetric-based performance and model prediction errors grounded in an empirically\nderived error taxonomy that can be used to drive future research efforts\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 20:13:14 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Mahmud", "Junayed", ""], ["Faisal", "Fahim", ""], ["Arnob", "Raihan Islam", ""], ["Anastasopoulos", "Antonios", ""], ["Moran", "Kevin", ""]]}, {"id": "2106.08446", "submitter": "Wilkie Olin-Ammentorp", "authors": "Wilkie Olin-Ammentorp, Maxim Bazhenov", "title": "Bridge Networks: Relating Inputs through Vector-Symbolic Manipulations", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite rapid progress, current deep learning methods face a number of\ncritical challenges. These include high energy consumption, catastrophic\nforgetting, dependance on global losses, and an inability to reason\nsymbolically. By combining concepts from information bottleneck theory and\nvector-symbolic architectures, we propose and implement a novel information\nprocessing architecture, the 'Bridge network.' We show this architecture\nprovides unique advantages which can address the problem of global losses and\ncatastrophic forgetting. Furthermore, we argue that it provides a further basis\nfor increasing energy efficiency of execution and the ability to reason\nsymbolically.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 21:39:34 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 22:29:26 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Olin-Ammentorp", "Wilkie", ""], ["Bazhenov", "Maxim", ""]]}, {"id": "2106.08452", "submitter": "Matthias Knorr", "authors": "Ricardo Ferreira, Carolina Lopes, Ricardo Gon\\c{c}alves, Matthias\n  Knorr, Ludwig Krippahl, Jo\\~ao Leite", "title": "Deep Neural Networks for Approximating Stream Reasoning with C-SPARQL", "comments": "Accepted at the 20th EPIA Conference on Artificial Intelligence, EPIA\n  2021; update on previous version - data on optimizer and loss added for CNNs\n  in the appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The amount of information produced, whether by newspapers, blogs and social\nnetworks, or by monitoring systems, is increasing rapidly. Processing all this\ndata in real-time, while taking into consideration advanced knowledge about the\nproblem domain, is challenging, but required in scenarios where assessing\npotential risks in a timely fashion is critical. C-SPARQL, a language for\ncontinuous queries over streams of RDF data, is one of the more prominent\napproaches in stream reasoning that provides such continuous inference\ncapabilities over dynamic data that go beyond mere stream processing. However,\nit has been shown that, in the presence of huge amounts of data, C-SPARQL may\nnot be able to answer queries in time, in particular when the frequency of\nincoming data is higher than the time required for reasoning with that data. In\nthis paper, we investigate whether reasoning with C-SPARQL can be approximated\nusing Recurrent Neural Networks and Convolutional Neural Networks, two neural\nnetwork architectures that have been shown to be well-suited for time series\nforecasting and time series classification, to leverage on their higher\nprocessing speed once the network has been trained. We consider a variety of\ndifferent kinds of queries and obtain overall positive results with high\naccuracies while improving processing time often by several orders of\nmagnitude.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 21:51:47 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 11:42:29 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Ferreira", "Ricardo", ""], ["Lopes", "Carolina", ""], ["Gon\u00e7alves", "Ricardo", ""], ["Knorr", "Matthias", ""], ["Krippahl", "Ludwig", ""], ["Leite", "Jo\u00e3o", ""]]}, {"id": "2106.08457", "submitter": "Ricardo Gon\\c{c}alves", "authors": "Jo\\~ao Ferreira, Diogo Lavado, Ricardo Gon\\c{c}alves, Matthias Knorr,\n  Ludwig Krippahl, and Jo\\~ao Leite", "title": "Faster than LASER -- Towards Stream Reasoning with Deep Neural Networks", "comments": "Extended version of EPIA 21 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the constant increase of available data in various domains, such as the\nInternet of Things, Social Networks or Smart Cities, it has become fundamental\nthat agents are able to process and reason with such data in real time. Whereas\nreasoning over time-annotated data with background knowledge may be\nchallenging, due to the volume and velocity in which such data is being\nproduced, such complex reasoning is necessary in scenarios where agents need to\ndiscover potential problems and this cannot be done with simple stream\nprocessing techniques. Stream Reasoners aim at bridging this gap between\nreasoning and stream processing and LASER is such a stream reasoner designed to\nanalyse and perform complex reasoning over streams of data. It is based on\nLARS, a rule-based logical language extending Answer Set Programming, and it\nhas shown better runtime results than other state-of-the-art stream reasoning\nsystems. Nevertheless, for high levels of data throughput even LASER may be\nunable to compute answers in a timely fashion. In this paper, we study whether\nConvolutional and Recurrent Neural Networks, which have shown to be\nparticularly well-suited for time series forecasting and classification, can be\ntrained to approximate reasoning with LASER, so that agents can benefit from\ntheir high processing speed.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 22:06:12 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Ferreira", "Jo\u00e3o", ""], ["Lavado", "Diogo", ""], ["Gon\u00e7alves", "Ricardo", ""], ["Knorr", "Matthias", ""], ["Krippahl", "Ludwig", ""], ["Leite", "Jo\u00e3o", ""]]}, {"id": "2106.08458", "submitter": "Min Hun Lee", "authors": "Min Hun Lee, Daniel P. Siewiorek, Asim Smailagic, Alexandre\n  Bernardino, Sergi Berm\\'udez i Badia", "title": "Enabling AI and Robotic Coaches for Physical Rehabilitation Therapy:\n  Iterative Design and Evaluation with Therapists and Post-Stroke Survivors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Artificial intelligence (AI) and robotic coaches promise the improved\nengagement of patients on rehabilitation exercises through social interaction.\nWhile previous work explored the potential of automatically monitoring\nexercises for AI and robotic coaches, the deployment of these systems remains a\nchallenge. Previous work described the lack of involving stakeholders to design\nsuch functionalities as one of the major causes. In this paper, we present our\nefforts on eliciting the detailed design specifications on how AI and robotic\ncoaches could interact with and guide patient's exercises in an effective and\nacceptable way with four therapists and five post-stroke survivors. Through\niterative questionnaires and interviews, we found that both post-stroke\nsurvivors and therapists appreciated the potential benefits of AI and robotic\ncoaches to achieve more systematic management and improve their self-efficacy\nand motivation on rehabilitation therapy. In addition, our evaluation sheds\nlight on several practical concerns (e.g. a possible difficulty with the\ninteraction for people with cognitive impairment, system failures, etc.). We\ndiscuss the value of early involvement of stakeholders and interactive\ntechniques that complement system failures, but also support a personalized\ntherapy session for the better deployment of AI and robotic exercise coaches.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 22:06:39 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Lee", "Min Hun", ""], ["Siewiorek", "Daniel P.", ""], ["Smailagic", "Asim", ""], ["Bernardino", "Alexandre", ""], ["Badia", "Sergi Berm\u00fadez i", ""]]}, {"id": "2106.08482", "submitter": "Varun Kumar Vijay", "authors": "Varun Kumar Vijay and Hassam Sheikh and Somdeb Majumdar and Mariano\n  Phielipp", "title": "Minimizing Communication while Maximizing Performance in Multi-Agent\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Inter-agent communication can significantly increase performance in\nmulti-agent tasks that require co-ordination to achieve a shared goal. Prior\nwork has shown that it is possible to learn inter-agent communication protocols\nusing multi-agent reinforcement learning and message-passing network\narchitectures. However, these models use an unconstrained broadcast\ncommunication model, in which an agent communicates with all other agents at\nevery step, even when the task does not require it. In real-world applications,\nwhere communication may be limited by system constraints like bandwidth, power\nand network capacity, one might need to reduce the number of messages that are\nsent. In this work, we explore a simple method of minimizing communication\nwhile maximizing performance in multi-task learning: simultaneously optimizing\na task-specific objective and a communication penalty. We show that the\nobjectives can be optimized using Reinforce and the Gumbel-Softmax\nreparameterization. We introduce two techniques to stabilize training: 50%\ntraining and message forwarding. Training with the communication penalty on\nonly 50% of the episodes prevents our models from turning off their outgoing\nmessages. Second, repeating messages received previously helps models retain\ninformation, and further improves performance. With these techniques, we show\nthat we can reduce communication by 75% with no loss of performance.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 23:13:51 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 19:49:32 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Vijay", "Varun Kumar", ""], ["Sheikh", "Hassam", ""], ["Majumdar", "Somdeb", ""], ["Phielipp", "Mariano", ""]]}, {"id": "2106.08492", "submitter": "Mythreyi Velmurugan", "authors": "Mythreyi Velmurugan and Chun Ouyang and Catarina Moreira and Renuka\n  Sindhgatta", "title": "Developing a Fidelity Evaluation Approach for Interpretable Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Although modern machine learning and deep learning methods allow for complex\nand in-depth data analytics, the predictive models generated by these methods\nare often highly complex, and lack transparency. Explainable AI (XAI) methods\nare used to improve the interpretability of these complex models, and in doing\nso improve transparency. However, the inherent fitness of these explainable\nmethods can be hard to evaluate. In particular, methods to evaluate the\nfidelity of the explanation to the underlying black box require further\ndevelopment, especially for tabular data. In this paper, we (a) propose a three\nphase approach to developing an evaluation method; (b) adapt an existing\nevaluation method primarily for image and text data to evaluate models trained\non tabular data; and (c) evaluate two popular explainable methods using this\nevaluation method. Our evaluations suggest that the internal mechanism of the\nunderlying predictive model, the internal mechanism of the explainable method\nused and model and data complexity all affect explanation fidelity. Given that\nexplanation fidelity is so sensitive to context and tools and data used, we\ncould not clearly identify any specific explainable method as being superior to\nanother.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 00:21:16 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Velmurugan", "Mythreyi", ""], ["Ouyang", "Chun", ""], ["Moreira", "Catarina", ""], ["Sindhgatta", "Renuka", ""]]}, {"id": "2106.08499", "submitter": "Celso A. M. Lopes Junior", "authors": "Celso A. M. Lopes Junior, Ricardo B. das Neves Junior, Byron L. D.\n  Bezerra, Alejandro H. Toselli, Donato Impedovo", "title": "ICDAR 2021 Competition on Components Segmentation Task of Document\n  Photos", "comments": "15 pages; 5 figures; Accepted at ICDAR 2021: 16th International\n  Conference on Document Analysis and Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper describes the short-term competition on the Components\nSegmentation Task of Document Photos that was prepared in the context of the\n16th International Conference on Document Analysis and Recognition (ICDAR\n2021). This competition aims to bring together researchers working in the field\nof identification document image processing and provides them a suitable\nbenchmark to compare their techniques on the component segmentation task of\ndocument images. Three challenge tasks were proposed entailing different\nsegmentation assignments to be performed on a provided dataset. The collected\ndata are from several types of Brazilian ID documents, whose personal\ninformation was conveniently replaced. There were 16 participants whose results\nobtained for some or all the three tasks show different rates for the adopted\nmetrics, like Dice Similarity Coefficient ranging from 0.06 to 0.99. Different\nDeep Learning models were applied by the entrants with diverse strategies to\nachieve the best results in each of the tasks. Obtained results show that the\ncurrently applied methods for solving one of the proposed tasks (document\nboundary detection) are already well established. However, for the other two\nchallenge tasks (text zone and handwritten sign detection) research and\ndevelopment of more robust approaches are still required to achieve acceptable\nresults.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 00:49:58 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 01:40:34 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Junior", "Celso A. M. Lopes", ""], ["Junior", "Ricardo B. das Neves", ""], ["Bezerra", "Byron L. D.", ""], ["Toselli", "Alejandro H.", ""], ["Impedovo", "Donato", ""]]}, {"id": "2106.08500", "submitter": "Loc Hoang", "authors": "Loc Hoang and Udit Agarwal and Gurbinder Gill and Roshan Dathathri and\n  Abhik Seal and Brian Martin and Keshav Pingali", "title": "Optimizing Graph Transformer Networks with Graph-based Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph transformer networks (GTN) are a variant of graph convolutional\nnetworks (GCN) that are targeted to heterogeneous graphs in which nodes and\nedges have associated type information that can be exploited to improve\ninference accuracy. GTNs learn important metapaths in the graph, create\nweighted edges for these metapaths, and use the resulting graph in a GCN.\nCurrently, the only available implementation of GTNs uses dense matrix\nmultiplication to find metapaths. Unfortunately, the space overhead of this\napproach can be large, so in practice it is used only for small graphs. In\naddition, the matrix-based implementation is not fine-grained enough to use\nrandom-walk based methods to optimize metapath finding. In this paper, we\npresent a graph-based formulation and implementation of the GTN metapath\nfinding problem. This graph-based formulation has two advantages over the\nmatrix-based approach. First, it is more space efficient than the original GTN\nimplementation and more compute-efficient for metapath sizes of practical\ninterest. Second, it permits us to implement a sampling method that reduces the\nnumber of metapaths that must be enumerated, allowing the implementation to be\nused for larger graphs and larger metapath sizes. Experimental results show\nthat our implementation is $6.5\\times$ faster than the original GTN\nimplementation on average for a metapath length of 4, and our sampling\nimplementation is $155\\times$ faster on average than this implementation\nwithout compromising on the accuracy of the GTN.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 00:54:24 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Hoang", "Loc", ""], ["Agarwal", "Udit", ""], ["Gill", "Gurbinder", ""], ["Dathathri", "Roshan", ""], ["Seal", "Abhik", ""], ["Martin", "Brian", ""], ["Pingali", "Keshav", ""]]}, {"id": "2106.08523", "submitter": "Chaofan Chen", "authors": "Chaofan Chen, Xiaoshan Yang, Changsheng Xu, Xuhui Huang, Zhe Ma", "title": "ECKPN: Explicit Class Knowledge Propagation Network for Transductive\n  Few-shot Learning", "comments": "Accepted by CVPR2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the transductive graph-based methods have achieved great success in\nthe few-shot classification task. However, most existing methods ignore\nexploring the class-level knowledge that can be easily learned by humans from\njust a handful of samples. In this paper, we propose an Explicit Class\nKnowledge Propagation Network (ECKPN), which is composed of the comparison,\nsqueeze and calibration modules, to address this problem. Specifically, we\nfirst employ the comparison module to explore the pairwise sample relations to\nlearn rich sample representations in the instance-level graph. Then, we squeeze\nthe instance-level graph to generate the class-level graph, which can help\nobtain the class-level visual knowledge and facilitate modeling the relations\nof different classes. Next, the calibration module is adopted to characterize\nthe relations of the classes explicitly to obtain the more discriminative\nclass-level knowledge representations. Finally, we combine the class-level\nknowledge with the instance-level sample representations to guide the inference\nof the query samples. We conduct extensive experiments on four few-shot\nclassification benchmarks, and the experimental results show that the proposed\nECKPN significantly outperforms the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 02:29:43 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Chen", "Chaofan", ""], ["Yang", "Xiaoshan", ""], ["Xu", "Changsheng", ""], ["Huang", "Xuhui", ""], ["Ma", "Zhe", ""]]}, {"id": "2106.08541", "submitter": "Yi Luo", "authors": "Yi Luo, Aiguo Chen, Ke Yan, Ling Tian", "title": "Distilling Self-Knowledge From Contrastive Links to Classify Graph Nodes\n  Without Passing Messages", "comments": "9 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, Graph Neural Networks (GNNs) following the Message Passing paradigm\nbecome the dominant way to learn on graphic data. Models in this paradigm have\nto spend extra space to look up adjacent nodes with adjacency matrices and\nextra time to aggregate multiple messages from adjacent nodes. To address this\nissue, we develop a method called LinkDist that distils self-knowledge from\nconnected node pairs into a Multi-Layer Perceptron (MLP) without the need to\naggregate messages. Experiment with 8 real-world datasets shows the MLP derived\nfrom LinkDist can predict the label of a node without knowing its adjacencies\nbut achieve comparable accuracy against GNNs in the contexts of semi- and\nfull-supervised node classification. Moreover, LinkDist benefits from its\nNon-Message Passing paradigm that we can also distil self-knowledge from\narbitrarily sampled node pairs in a contrastive way to further boost the\nperformance of LinkDist.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 03:56:03 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Luo", "Yi", ""], ["Chen", "Aiguo", ""], ["Yan", "Ke", ""], ["Tian", "Ling", ""]]}, {"id": "2106.08556", "submitter": "Zhengyuan Liu", "authors": "Zhengyuan Liu, Ke Shi, Nancy F. Chen", "title": "Coreference-Aware Dialogue Summarization", "comments": "accepted for presentation at SIGDIAL-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Summarizing conversations via neural approaches has been gaining research\ntraction lately, yet it is still challenging to obtain practical solutions.\nExamples of such challenges include unstructured information exchange in\ndialogues, informal interactions between speakers, and dynamic role changes of\nspeakers as the dialogue evolves. Many of such challenges result in complex\ncoreference links. Therefore, in this work, we investigate different approaches\nto explicitly incorporate coreference information in neural abstractive\ndialogue summarization models to tackle the aforementioned challenges.\nExperimental results show that the proposed approaches achieve state-of-the-art\nperformance, implying it is useful to utilize coreference information in\ndialogue summarization. Evaluation results on factual correctness suggest such\ncoreference-aware models are better at tracing the information flow among\ninterlocutors and associating accurate status/actions with the corresponding\ninterlocutors and person mentions.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 05:18:50 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Liu", "Zhengyuan", ""], ["Shi", "Ke", ""], ["Chen", "Nancy F.", ""]]}, {"id": "2106.08569", "submitter": "Dipankar Sarkar", "authors": "Dipankar Sarkar, Mukur Gupta", "title": "TSO: Curriculum Generation using continuous optimization", "comments": "10 pages, along with all experiment details", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The training of deep learning models poses vast challenges of including\nparameter tuning and ordering of training data. Significant research has been\ndone in Curriculum learning for optimizing the sequence of training data.\nRecent works have focused on using complex reinforcement learning techniques to\nfind the optimal data ordering strategy to maximize learning for a given\nnetwork. In this paper, we present a simple and efficient technique based on\ncontinuous optimization. We call this new approach Training Sequence\nOptimization (TSO). There are three critical components in our proposed\napproach: (a) An encoder network maps/embeds training sequence into continuous\nspace. (b) A predictor network uses the continuous representation of a strategy\nas input and predicts the accuracy for fixed network architecture. (c) A\ndecoder further maps a continuous representation of a strategy to the ordered\ntraining dataset. The performance predictor and encoder enable us to perform\ngradient-based optimization in the continuous space to find the embedding of\noptimal training data ordering with potentially better accuracy. Experiments\nshow that we can gain 2AP with our generated optimal curriculum strategy over\nthe random strategy using the CIFAR-100 dataset and have better boosts than the\nstate of the art CL algorithms. We do an ablation study varying the\narchitecture, dataset and sample sizes showcasing our approach's robustness.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 06:32:21 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Sarkar", "Dipankar", ""], ["Gupta", "Mukur", ""]]}, {"id": "2106.08574", "submitter": "Rikunari Sagara", "authors": "Rikunari Sagara (1), Ryo Taguchi (1), Akira Taniguchi (2), Tadahiro\n  Taniguchi (2), Koosuke Hattori (3), Masahiro Hoguro (3), Taizo Umezaki (3)\n  ((1) Nagoya Institute of Technology, (2) Ritsumeikan University, (3) Chubu\n  University)", "title": "Unsupervised Lexical Acquisition of Relative Spatial Concepts Using\n  Spoken User Utterances", "comments": "27 pages, 12 figures, submitted to Advanced Robotics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes methods for unsupervised lexical acquisition for relative\nspatial concepts using spoken user utterances. A robot with a flexible spoken\ndialog system must be able to acquire linguistic representation and its meaning\nspecific to an environment through interactions with humans as children do.\nSpecifically, relative spatial concepts (e.g., front and right) are widely used\nin our daily lives, however, it is not obvious which object is a reference\nobject when a robot learns relative spatial concepts. Therefore, we propose\nmethods by which a robot without prior knowledge of words can learn relative\nspatial concepts. The methods are formulated using a probabilistic model to\nestimate the proper reference objects and distributions representing concepts\nsimultaneously. The experimental results show that relative spatial concepts\nand a phoneme sequence representing each concept can be learned under the\ncondition that the robot does not know which located object is the reference\nobject. Additionally, we show that two processes in the proposed method improve\nthe estimation accuracy of the concepts: generating candidate word sequences by\nclass n-gram and selecting word sequences using location information.\nFurthermore, we show that clues to reference objects improve accuracy even\nthough the number of candidate reference objects increases.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 06:44:27 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Sagara", "Rikunari", ""], ["Taguchi", "Ryo", ""], ["Taniguchi", "Akira", ""], ["Taniguchi", "Tadahiro", ""], ["Hattori", "Koosuke", ""], ["Hoguro", "Masahiro", ""], ["Umezaki", "Taizo", ""]]}, {"id": "2106.08599", "submitter": "Hankyu Moon", "authors": "Hankyu Moon, Heng Hao, Sima Didari, Jae Oh Woo, Patrick Bangert", "title": "PatchNet: Unsupervised Object Discovery based on Patch Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We demonstrate that frequently appearing objects can be discovered by\ntraining randomly sampled patches from a small number of images (100 to 200) by\nself-supervision. Key to this approach is the pattern space, a latent space of\npatterns that represents all possible sub-images of the given image data. The\ndistance structure in the pattern space captures the co-occurrence of patterns\ndue to the frequent objects. The pattern space embedding is learned by\nminimizing the contrastive loss between randomly generated adjacent patches. To\nprevent the embedding from learning the background, we modulate the contrastive\nloss by color-based object saliency and background dissimilarity. The learned\ndistance structure serves as object memory, and the frequent objects are simply\ndiscovered by clustering the pattern vectors from the random patches sampled\nfor inference. Our image representation based on image patches naturally\nhandles the position and scale invariance property that is crucial to\nmulti-object discovery. The method has been proven surprisingly effective, and\nsuccessfully applied to finding multiple human faces and bodies from natural\nimages.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 07:56:19 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Moon", "Hankyu", ""], ["Hao", "Heng", ""], ["Didari", "Sima", ""], ["Woo", "Jae Oh", ""], ["Bangert", "Patrick", ""]]}, {"id": "2106.08624", "submitter": "Wenqing Zheng", "authors": "Wenqing Zheng, Jiyang Xie, Weidong Liu, Zhanyu Ma", "title": "Structured DropConnect for Uncertainty Inference in Image Classification", "comments": "5 pages,1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the complexity of the network structure, uncertainty inference has\nbecome an important task to improve the classification accuracy for artificial\nintelligence systems. For image classification tasks, we propose a structured\nDropConnect (SDC) framework to model the output of a deep neural network by a\nDirichlet distribution. We introduce a DropConnect strategy on weights in the\nfully connected layers during training. In test, we split the network into\nseveral sub-networks, and then model the Dirichlet distribution by match its\nmoments with the mean and variance of the outputs of these sub-networks. The\nentropy of the estimated Dirichlet distribution is finally utilized for\nuncertainty inference. In this paper, this framework is implemented on LeNet$5$\nand VGG$16$ models for misclassification detection and out-of-distribution\ndetection on MNIST and CIFAR-$10$ datasets. Experimental results show that the\nperformance of the proposed SDC can be comparable to other uncertainty\ninference methods. Furthermore, the SDC is adapted well to different network\nstructures with certain generalization capabilities and research prospects.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 08:31:14 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Zheng", "Wenqing", ""], ["Xie", "Jiyang", ""], ["Liu", "Weidong", ""], ["Ma", "Zhanyu", ""]]}, {"id": "2106.08652", "submitter": "Francesco Bonchi", "authors": "David Garcia-Soriano and Francesco Bonchi", "title": "Maxmin-Fair Ranking: Individual Fairness under Group-Fairness\n  Constraints", "comments": "In proceedings of KDD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a novel problem of fairness in ranking aimed at minimizing the\namount of individual unfairness introduced when enforcing group-fairness\nconstraints. Our proposal is rooted in the distributional maxmin fairness\ntheory, which uses randomization to maximize the expected satisfaction of the\nworst-off individuals. We devise an exact polynomial-time algorithm to find\nmaxmin-fair distributions of general search problems (including, but not\nlimited to, ranking), and show that our algorithm can produce rankings which,\nwhile satisfying the given group-fairness constraints, ensure that the maximum\npossible value is brought to individuals.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 09:27:12 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 09:10:05 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Garcia-Soriano", "David", ""], ["Bonchi", "Francesco", ""]]}, {"id": "2106.08658", "submitter": "Shengli Wu", "authors": "Shengli Wu, Weimin Ding", "title": "A Dataset-Level Geometric Framework for Ensemble Classifiers", "comments": "number of pages: 32 number of figures: 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ensemble classifiers have been investigated by many in the artificial\nintelligence and machine learning community. Majority voting and weighted\nmajority voting are two commonly used combination schemes in ensemble learning.\nHowever, understanding of them is incomplete at best, with some properties even\nmisunderstood. In this paper, we present a group of properties of these two\nschemes formally under a dataset-level geometric framework. Two key factors,\nevery component base classifier's performance and dissimilarity between each\npair of component classifiers are evaluated by the same metric - the Euclidean\ndistance. Consequently, ensembling becomes a deterministic problem and the\nperformance of an ensemble can be calculated directly by a formula. We prove\nseveral theorems of interest and explain their implications for ensembles. In\nparticular, we compare and contrast the effect of the number of component\nclassifiers on these two types of ensemble schemes. Empirical investigation is\nalso conducted to verify the theoretical results when other metrics such as\naccuracy are used. We believe that the results from this paper are very useful\nfor us to understand the fundamental properties of these two combination\nschemes and the principles of ensemble classifiers in general. The results are\nalso helpful for us to investigate some issues in ensemble classifiers, such as\nensemble performance prediction, selecting a small number of base classifiers\nto obtain efficient and effective ensembles.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 09:48:12 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Wu", "Shengli", ""], ["Ding", "Weimin", ""]]}, {"id": "2106.08670", "submitter": "Vimukthini Pinto", "authors": "Vimukthini Pinto, Cheng Xue, Chathura Nagoda Gamage and Jochen Renz", "title": "The Difficulty of Novelty Detection in Open-World Physical Domains: An\n  Application to Angry Birds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting and responding to novel situations in open-world environments is a\nkey capability of human cognition. Current artificial intelligence (AI)\nresearchers strive to develop systems that can perform in open-world\nenvironments. Novelty detection is an important ability of such AI systems. In\nan open-world, novelties appear in various forms and the difficulty to detect\nthem varies. Therefore, to accurately evaluate the detection capability of AI\nsystems, it is necessary to investigate the difficulty to detect novelties. In\nthis paper, we propose a qualitative physics-based method to quantify the\ndifficulty of novelty detection focusing on open-world physical domains. We\napply our method in a popular physics simulation game, Angry Birds. We conduct\nan experiment with human players with different novelties in Angry Birds to\nvalidate our method. Results indicate that the calculated difficulty values are\nin line with the detection difficulty of the human players.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 10:14:09 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Pinto", "Vimukthini", ""], ["Xue", "Cheng", ""], ["Gamage", "Chathura Nagoda", ""], ["Renz", "Jochen", ""]]}, {"id": "2106.08678", "submitter": "Aaron Sim", "authors": "Aaron Sim, Maciej Wiatrak, Angus Brayne, P\\'aid\\'i Creed, Saee Paliwal", "title": "Directed Graph Embeddings in Pseudo-Riemannian Manifolds", "comments": "Accepted at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The inductive biases of graph representation learning algorithms are often\nencoded in the background geometry of their embedding space. In this paper, we\nshow that general directed graphs can be effectively represented by an\nembedding model that combines three components: a pseudo-Riemannian metric\nstructure, a non-trivial global topology, and a unique likelihood function that\nexplicitly incorporates a preferred direction in embedding space. We\ndemonstrate the representational capabilities of this method by applying it to\nthe task of link prediction on a series of synthetic and real directed graphs\nfrom natural language applications and biology. In particular, we show that\nlow-dimensional cylindrical Minkowski and anti-de Sitter spacetimes can produce\nequal or better graph representations than curved Riemannian manifolds of\nhigher dimensions.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 10:31:37 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Sim", "Aaron", ""], ["Wiatrak", "Maciej", ""], ["Brayne", "Angus", ""], ["Creed", "P\u00e1id\u00ed", ""], ["Paliwal", "Saee", ""]]}, {"id": "2106.08680", "submitter": "Krithika Ramesh", "authors": "Gauri Gupta, Krithika Ramesh and Sanjay Singh", "title": "Evaluating Gender Bias in Hindi-English Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With language models being deployed increasingly in the real world, it is\nessential to address the issue of the fairness of their outputs. The word\nembedding representations of these language models often implicitly draw\nunwanted associations that form a social bias within the model. The nature of\ngendered languages like Hindi, poses an additional problem to the\nquantification and mitigation of bias, owing to the change in the form of the\nwords in the sentence, based on the gender of the subject. Additionally, there\nis sparse work done in the realm of measuring and debiasing systems for Indic\nlanguages. In our work, we attempt to evaluate and quantify the gender bias\nwithin a Hindi-English machine translation system. We implement a modified\nversion of the existing TGBI metric based on the grammatical considerations for\nHindi. We also compare and contrast the resulting bias measurements across\nmultiple metrics for pre-trained embeddings and the ones learned by our machine\ntranslation model.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 10:35:51 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Gupta", "Gauri", ""], ["Ramesh", "Krithika", ""], ["Singh", "Sanjay", ""]]}, {"id": "2106.08692", "submitter": "Andras Gazdag", "authors": "Irina Chiscop, Andr\\'as Gazdag, Joost Bosman, Gergely Bicz\\'ok", "title": "Detecting message modification attacks on the CAN bus with Temporal\n  Convolutional Networks", "comments": null, "journal-ref": null, "doi": "10.5220/0010445504880496", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Multiple attacks have shown that in-vehicle networks have vulnerabilities\nwhich can be exploited. Securing the Controller Area Network (CAN) for modern\nvehicles has become a necessary task for car manufacturers. Some attacks inject\npotentially large amount of fake messages into the CAN network; however, such\nattacks are relatively easy to detect. In more sophisticated attacks, the\noriginal messages are modified, making the detection a more complex problem. In\nthis paper, we present a novel machine learning based intrusion detection\nmethod for CAN networks. We focus on detecting message modification attacks,\nwhich do not change the timing patterns of communications. Our proposed\ntemporal convolutional network-based solution can learn the normal behavior of\nCAN signals and differentiate them from malicious ones. The method is evaluated\non multiple CAN-bus message IDs from two public datasets including different\ntypes of attacks. Performance results show that our lightweight approach\ncompares favorably to the state-of-the-art unsupervised learning approach,\nachieving similar or better accuracy for a wide range of scenarios with a\nsignificantly lower false positive rate.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 10:51:58 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Chiscop", "Irina", ""], ["Gazdag", "Andr\u00e1s", ""], ["Bosman", "Joost", ""], ["Bicz\u00f3k", "Gergely", ""]]}, {"id": "2106.08710", "submitter": "Jacky Cao", "authors": "Jacky Cao, Kit-Yung Lam, Lik-Hang Lee, Xiaoli Liu, Pan Hui, Xiang Su", "title": "Mobile Augmented Reality: User Interfaces, Frameworks, and Intelligence", "comments": "This work is currently under review in an international journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CV cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile Augmented Reality (MAR) integrates computer-generated virtual objects\nwith physical environments for mobile devices. MAR systems enable users to\ninteract with MAR devices, such as smartphones and head-worn wearables, and\nperforms seamless transitions from the physical world to a mixed world with\ndigital entities. These MAR systems support user experiences by using MAR\ndevices to provide universal accessibility to digital contents. Over the past\n20 years, a number of MAR systems have been developed, however, the studies and\ndesign of MAR frameworks have not yet been systematically reviewed from the\nperspective of user-centric design. This article presents the first effort of\nsurveying existing MAR frameworks (count: 37) and further discusses the latest\nstudies on MAR through a top-down approach: 1) MAR applications; 2) MAR\nvisualisation techniques adaptive to user mobility and contexts; 3) systematic\nevaluation of MAR frameworks including supported platforms and corresponding\nfeatures such as tracking, feature extraction plus sensing capabilities; and 4)\nunderlying machine learning approaches supporting intelligent operations within\nMAR systems. Finally, we summarise the development of emerging research fields,\ncurrent state-of-the-art, and discuss the important open challenges and\npossible theoretical and technical directions. This survey aims to benefit both\nresearchers and MAR system developers alike.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 11:26:37 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Cao", "Jacky", ""], ["Lam", "Kit-Yung", ""], ["Lee", "Lik-Hang", ""], ["Liu", "Xiaoli", ""], ["Hui", "Pan", ""], ["Su", "Xiang", ""]]}, {"id": "2106.08717", "submitter": "Julia Grosse", "authors": "Julia Grosse, Cheng Zhang, Philipp Hennig", "title": "Probabilistic DAG Search", "comments": "10 pages, 8 figures, to be published at the Conference on Uncertainty\n  in Artificial Intelligence (UAI) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Exciting contemporary machine learning problems have recently been phrased in\nthe classic formalism of tree search -- most famously, the game of Go.\nInterestingly, the state-space underlying these sequential decision-making\nproblems often posses a more general latent structure than can be captured by a\ntree. In this work, we develop a probabilistic framework to exploit a search\nspace's latent structure and thereby share information across the search tree.\nThe method is based on a combination of approximate inference in jointly\nGaussian models for the explored part of the problem, and an abstraction for\nthe unexplored part that imposes a reduction of complexity ad hoc. We\nempirically find our algorithm to compare favorably to existing\nnon-probabilistic alternatives in Tic-Tac-Toe and a feature selection\napplication.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 11:35:19 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Grosse", "Julia", ""], ["Zhang", "Cheng", ""], ["Hennig", "Philipp", ""]]}, {"id": "2106.08732", "submitter": "Li Xiao", "authors": "Hao Chen, Fuzhen Zhuang, Li Xiao, Ling Ma, Haiyan Liu, Ruifang Zhang,\n  Huiqin Jiang, Qing He", "title": "AMA-GCN: Adaptive Multi-layer Aggregation Graph Convolutional Network\n  for Disease Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Recently, Graph Convolutional Networks (GCNs) have proven to be a powerful\nmean for Computer Aided Diagnosis (CADx). This approach requires building a\npopulation graph to aggregate structural information, where the graph adjacency\nmatrix represents the relationship between nodes. Until now, this adjacency\nmatrix is usually defined manually based on phenotypic information. In this\npaper, we propose an encoder that automatically selects the appropriate\nphenotypic measures according to their spatial distribution, and uses the text\nsimilarity awareness mechanism to calculate the edge weights between nodes. The\nencoder can automatically construct the population graph using phenotypic\nmeasures which have a positive impact on the final results, and further\nrealizes the fusion of multimodal information. In addition, a novel graph\nconvolution network architecture using multi-layer aggregation mechanism is\nproposed. The structure can obtain deep structure information while suppressing\nover-smooth, and increase the similarity between the same type of nodes.\nExperimental results on two databases show that our method can significantly\nimprove the diagnostic accuracy for Autism spectrum disorder and breast cancer,\nindicating its universality in leveraging multimodal data for disease\nprediction.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 12:13:23 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Chen", "Hao", ""], ["Zhuang", "Fuzhen", ""], ["Xiao", "Li", ""], ["Ma", "Ling", ""], ["Liu", "Haiyan", ""], ["Zhang", "Ruifang", ""], ["Jiang", "Huiqin", ""], ["He", "Qing", ""]]}, {"id": "2106.08746", "submitter": "Buse Gul Atli", "authors": "Buse G.A. Tekgul, Shelly Wang, Samuel Marchal, N. Asokan", "title": "Real-time Attacks Against Deep Reinforcement Learning Policies", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent work has discovered that deep reinforcement learning (DRL) policies\nare vulnerable to adversarial examples. These attacks mislead the policy of DRL\nagents by perturbing the state of the environment observed by agents. They are\nfeasible in principle but too slow to fool DRL policies in real time. We\npropose a new attack to fool DRL policies that is both effective and efficient\nenough to be mounted in real time. We utilize the Universal Adversarial\nPerturbation (UAP) method to compute effective perturbations independent of the\nindividual inputs to which they are applied. Via an extensive evaluation using\nAtari 2600 games, we show that our technique is effective, as it fully degrades\nthe performance of both deterministic and stochastic policies (up to 100%, even\nwhen the $l_\\infty$ bound on the perturbation is as small as 0.005). We also\nshow that our attack is efficient, incurring an online computational cost of\n0.027ms on average. It is faster compared to the response time (0.6ms on\naverage) of agents with different DRL policies, and considerably faster than\nprior attacks (2.7ms on average). Furthermore, we demonstrate that known\ndefenses are ineffective against universal perturbations. We propose an\neffective detection technique which can form the basis for robust defenses\nagainst attacks based on universal perturbations.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 12:44:59 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Tekgul", "Buse G. A.", ""], ["Wang", "Shelly", ""], ["Marchal", "Samuel", ""], ["Asokan", "N.", ""]]}, {"id": "2106.08769", "submitter": "Mohammad Emtiyaz Khan", "authors": "Mohammad Emtiyaz Khan, Siddharth Swaroop", "title": "Knowledge-Adaptation Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Humans and animals have a natural ability to quickly adapt to their\nsurroundings, but machine-learning models, when subjected to changes, often\nrequire a complete retraining from scratch. We present Knowledge-adaptation\npriors (K-priors) to reduce the cost of retraining by enabling quick and\naccurate adaptation for a wide-variety of tasks and models. This is made\npossible by a combination of weight and function-space priors to reconstruct\nthe gradients of the past, which recovers and generalizes many existing, but\nseemingly-unrelated, adaptation strategies. Training with simple first-order\ngradient methods can often recover the exact retrained model to an arbitrary\naccuracy by choosing a sufficiently large memory of the past data. Empirical\nresults confirm that the adaptation can be cheap and accurate, and a promising\nalternative to retraining.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 13:27:22 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Khan", "Mohammad Emtiyaz", ""], ["Swaroop", "Siddharth", ""]]}, {"id": "2106.08771", "submitter": "Kimang Khun", "authors": "Nicolas Gast (POLARIS), Bruno Gaujal (POLARIS), Kimang Khun (POLARIS)", "title": "Reinforcement Learning for Markovian Bandits: Is Posterior Sampling more\n  Scalable than Optimism?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study learning algorithms for the classical Markovian bandit problem with\ndiscount. We explain how to adapt PSRL [24] and UCRL2 [2] to exploit the\nproblem structure. These variants are called MB-PSRL and MB-UCRL2. While the\nregret bound and runtime of vanilla implementations of PSRL and UCRL2 are\nexponential in the number of bandits, we show that the episodic regret of\nMB-PSRL and MB-UCRL2 is $\\tilde O(S\\sqrt{nK})$ where $K$ is the number of\nepisodes, n is the number of bandits and S is the number of states of each\nbandit (the exact bound in $S$, $n$ and $K$ is given in the paper). Up to a\nfactor $\\sqrt S$, this matches the lower bound of $\\Omega(\\sqrt{SnK}$) that we\nalso derive in the paper. MB-PSRL is also computationally efficient: its\nruntime is linear in the number of bandits. We further show that this linear\nruntime cannot be achieved by adapting classical non-Bayesian algorithms such\nas UCRL2 or UCBVI to Markovian bandit problems. Finally, we perform numerical\nexperiments that confirm that MB-PSRL outperforms other existing algorithms in\npractice, both in terms of regret and of computation time.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 13:29:12 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Gast", "Nicolas", "", "POLARIS"], ["Gaujal", "Bruno", "", "POLARIS"], ["Khun", "Kimang", "", "POLARIS"]]}, {"id": "2106.08785", "submitter": "Zaijing Li", "authors": "Zaijing Li, Fengxiao Tang, Tieyu Sun, Yusen Zhu, Ming Zhao", "title": "SEOVER: Sentence-level Emotion Orientation Vector based Conversation\n  Emotion Recognition Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the task of conversation emotion recognition, recent works focus on\nspeaker relationship modeling but ignore the role of utterance's emotional\ntendency.In this paper, we propose a new expression paradigm of sentence-level\nemotion orientation vector to model the potential correlation of emotions\nbetween sentence vectors. Based on it, we design an emotion recognition model,\nwhich extracts the sentence-level emotion orientation vectors from the language\nmodel and jointly learns from the dialogue sentiment analysis model and\nextracted sentence-level emotion orientation vectors to identify the speaker's\nemotional orientation during the conversation. We conduct experiments on two\nbenchmark datasets and compare them with the five baseline models.The\nexperimental results show that our model has better performance on all data\nsets.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 13:44:03 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Li", "Zaijing", ""], ["Tang", "Fengxiao", ""], ["Sun", "Tieyu", ""], ["Zhu", "Yusen", ""], ["Zhao", "Ming", ""]]}, {"id": "2106.08796", "submitter": "Alex Church", "authors": "Alex Church, John Lloyd, Raia Hadsell and Nathan F. Lepora", "title": "Optical Tactile Sim-to-Real Policy Transfer via Real-to-Sim Tactile\n  Image Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation has recently become key for deep reinforcement learning to safely\nand efficiently acquire general and complex control policies from visual and\nproprioceptive inputs. Tactile information is not usually considered despite\nits direct relation to environment interaction. In this work, we present a\nsuite of simulated environments tailored towards tactile robotics and\nreinforcement learning. A simple and fast method of simulating optical tactile\nsensors is provided, where high-resolution contact geometry is represented as\ndepth images. Proximal Policy Optimisation (PPO) is used to learn successful\npolicies across all considered tasks. A data-driven approach enables\ntranslation of the current state of a real tactile sensor to corresponding\nsimulated depth images. This policy is implemented within a real-time control\nloop on a physical robot to demonstrate zero-shot sim-to-real policy transfer\non several physically-interactive tasks requiring a sense of touch.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 13:58:35 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Church", "Alex", ""], ["Lloyd", "John", ""], ["Hadsell", "Raia", ""], ["Lepora", "Nathan F.", ""]]}, {"id": "2106.08798", "submitter": "Jongmin Yu", "authors": "Jongmin Yu and Hyeontaek Oh", "title": "Unsupervised Person Re-identification via Multi-Label Prediction and\n  Classification based on Graph-Structural Insight", "comments": "submitted to ICCV", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper addresses unsupervised person re-identification (Re-ID) using\nmulti-label prediction and classification based on graph-structural insight.\nOur method extracts features from person images and produces a graph that\nconsists of the features and a pairwise similarity of them as nodes and edges,\nrespectively. Based on the graph, the proposed graph structure based\nmulti-label prediction (GSMLP) method predicts multi-labels by considering the\npairwise similarity and the adjacency node distribution of each node. The\nmulti-labels created by GSMLP are applied to the proposed selective multi-label\nclassification (SMLC) loss. SMLC integrates a hard-sample mining scheme and a\nmulti-label classification. The proposed GSMLP and SMLC boost the performance\nof unsupervised person Re-ID without any pre-labelled dataset. Experimental\nresults justify the superiority of the proposed method in unsupervised person\nRe-ID by producing state-of-the-art performance. The source code for this paper\nis publicly available on 'https://github.com/uknownpioneer/GSMLP-SMLC.git'.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 14:00:40 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Yu", "Jongmin", ""], ["Oh", "Hyeontaek", ""]]}, {"id": "2106.08801", "submitter": "Ziheng Zhang", "authors": "Zhiyuan Qi, Ziheng Zhang, Jiaoyan Chen, Xi Chen, Yefeng Zheng", "title": "PRASEMap: A Probabilistic Reasoning and Semantic Embedding based\n  Knowledge Graph Alignment System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge Graph (KG) alignment aims at finding equivalent entities and\nrelations (i.e., mappings) between two KGs. The existing approaches utilize\neither reasoning-based or semantic embedding-based techniques, but few studies\nexplore their combination. In this demonstration, we present PRASEMap, an\nunsupervised KG alignment system that iteratively computes the Mappings with\nboth Probabilistic Reasoning (PR) And Semantic Embedding (SE) techniques.\nPRASEMap can support various embedding-based KG alignment approaches as the SE\nmodule, and enables easy human computer interaction that additionally provides\nan option for users to feed the mapping annotations back to the system for\nbetter results. The demonstration showcases these features via a stand-alone\nWeb application with user friendly interfaces.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 14:06:09 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Qi", "Zhiyuan", ""], ["Zhang", "Ziheng", ""], ["Chen", "Jiaoyan", ""], ["Chen", "Xi", ""], ["Zheng", "Yefeng", ""]]}, {"id": "2106.08812", "submitter": "Han Zhao", "authors": "Han Zhao", "title": "Costs and Benefits of Wasserstein Fair Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world applications of machine learning tools in high-stakes domains are\noften regulated to be fair, in the sense that the predicted target should\nsatisfy some quantitative notion of parity with respect to a protected\nattribute. However, the exact tradeoff between fairness and accuracy with a\nreal-valued target is not clear. In this paper, we characterize the inherent\ntradeoff between statistical parity and accuracy in the regression setting by\nproviding a lower bound on the error of any fair regressor. Our lower bound is\nsharp, algorithm-independent, and admits a simple interpretation: when the\nmoments of the target differ between groups, any fair algorithm has to make a\nlarge error on at least one of the groups. We further extend this result to\ngive a lower bound on the joint error of any (approximately) fair algorithm,\nusing the Wasserstein distance to measure the quality of the approximation. On\nthe upside, we establish the first connection between individual fairness,\naccuracy parity, and the Wasserstein distance by showing that if a regressor is\nindividually fair, it also approximately verifies the accuracy parity, where\nthe gap is given by the Wasserstein distance between the two groups. Inspired\nby our theoretical results, we develop a practical algorithm for fair\nregression through the lens of representation learning, and conduct experiments\non a real-world dataset to corroborate our findings.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 14:24:44 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Zhao", "Han", ""]]}, {"id": "2106.08826", "submitter": "John Beasley E", "authors": "J.E. Beasley", "title": "A discrete optimisation approach for target path planning whilst evading\n  sensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper we deal with a practical problem that arises in military\nsituations. The problem is to plan a path for one (or more) agents to reach a\ntarget without being detected by enemy sensors.\n  Agents are not passive, rather they can (within limits) initiate actions\nwhich aid evasion, namely knockout (completely disable sensors) and confusion\n(reduce sensor detection probabilities). Agent actions are path dependent and\ntime limited. Here by path dependent we mean that an agent needs to be\nsufficiently close to a sensor to knock it out. By time limited we mean that a\nlimit is imposed on how long a sensor is knocked out or confused before it\nreverts back to its original operating state.\n  The approach adopted breaks the continuous space in which agents move into a\ndiscrete space. This enables the problem to be represented (formulated)\nmathematically as a zero-one integer program with linear constraints. The\nadvantage of representing the problem in this manner is that powerful\ncommercial software optimisation packages exist to solve the problem to proven\nglobal optimality.\n  Computational results are presented for a number of randomly generated test\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 14:42:52 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Beasley", "J. E.", ""]]}, {"id": "2106.08846", "submitter": "Fu-Ming Guo", "authors": "Fu-Ming Guo, Austin Huang", "title": "Algorithm to Compilation Co-design: An Integrated View of Neural Network\n  Sparsity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Reducing computation cost, inference latency, and memory footprint of neural\nnetworks are frequently cited as research motivations for pruning and sparsity.\nHowever, operationalizing those benefits and understanding the end-to-end\neffect of algorithm design and regularization on the runtime execution is not\noften examined in depth.\n  Here we apply structured and unstructured pruning to attention weights of\ntransformer blocks of the BERT language model, while also expanding block\nsparse representation (BSR) operations in the TVM compiler. Integration of BSR\noperations enables the TVM runtime execution to leverage structured pattern\nsparsity induced by model regularization.\n  This integrated view of pruning algorithms enables us to study relationships\nbetween modeling decisions and their direct impact on sparsity-enhanced\nexecution. Our main findings are: 1) we validate that performance benefits of\nstructured sparsity block regularization must be enabled by the BSR\naugmentations to TVM, with 4x speedup relative to vanilla PyTorch and 2.2x\nspeedup relative to standard TVM compilation (without expanded BSR support). 2)\nfor BERT attention weights, the end-to-end optimal block sparsity shape in this\nCPU inference context is not a square block (as in \\cite{gray2017gpu}) but\nrather a linear 32x1 block 3) the relationship between performance and block\nsize / shape is is suggestive of how model regularization parameters interact\nwith task scheduler optimizations resulting in the observed end-to-end\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 15:13:26 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 04:03:11 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Guo", "Fu-Ming", ""], ["Huang", "Austin", ""]]}, {"id": "2106.08858", "submitter": "Tristan Karch", "authors": "Tristan Karch, Laetitia Teodorescu, Katja Hofmann, Cl\\'ement\n  Moulin-Frier and Pierre-Yves Oudeyer", "title": "Grounding Spatio-Temporal Language with Transformers", "comments": "Contains main article and supplementaries", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language is an interface to the outside world. In order for embodied agents\nto use it, language must be grounded in other, sensorimotor modalities. While\nthere is an extended literature studying how machines can learn grounded\nlanguage, the topic of how to learn spatio-temporal linguistic concepts is\nstill largely uncharted. To make progress in this direction, we here introduce\na novel spatio-temporal language grounding task where the goal is to learn the\nmeaning of spatio-temporal descriptions of behavioral traces of an embodied\nagent. This is achieved by training a truth function that predicts if a\ndescription matches a given history of observations. The descriptions involve\ntime-extended predicates in past and present tense as well as spatio-temporal\nreferences to objects in the scene. To study the role of architectural biases\nin this task, we train several models including multimodal Transformer\narchitectures; the latter implement different attention computations between\nwords and objects across space and time. We test models on two classes of\ngeneralization: 1) generalization to randomly held-out sentences; 2)\ngeneralization to grammar primitives. We observe that maintaining object\nidentity in the attention computation of our Transformers is instrumental to\nachieving good performance on generalization overall, and that summarizing\nobject traces in a single token has little influence on performance. We then\ndiscuss how this opens new perspectives for language-guided autonomous embodied\nagents. We also release our code under open-source license as well as\npretrained models and datasets to encourage the wider community to build upon\nand extend our work in the future.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 15:28:22 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Karch", "Tristan", ""], ["Teodorescu", "Laetitia", ""], ["Hofmann", "Katja", ""], ["Moulin-Frier", "Cl\u00e9ment", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "2106.08888", "submitter": "Guido Petri", "authors": "Guido Petri, Michael H. Stanley, Alec B. Hon, Alexander Dong, Peter\n  Xenopoulos, Cl\\'audio Silva", "title": "Bandit Modeling of Map Selection in Counter-Strike: Global Offensive", "comments": "6 pages, 3 figures, IJCAI-AISA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many esports use a pick and ban process to define the parameters of a match\nbefore it starts. In Counter-Strike: Global Offensive (CSGO) matches, two teams\nfirst pick and ban maps, or virtual worlds, to play. Teams typically ban and\npick maps based on a variety of factors, such as banning maps which they do not\npractice, or choosing maps based on the team's recent performance. We introduce\na contextual bandit framework to tackle the problem of map selection in CSGO\nand to investigate teams' pick and ban decision-making. Using a data set of\nover 3,500 CSGO matches and over 25,000 map selection decisions, we consider\ndifferent framings for the problem, different contexts, and different reward\nmetrics. We find that teams have suboptimal map choice policies with respect to\nboth picking and banning. We also define an approach for rewarding bans, which\nhas not been explored in the bandit setting, and find that incorporating ban\nrewards improves model performance. Finally, we determine that usage of our\nmodel could improve teams' predicted map win probability by up to 11% and raise\noverall match win probabilities by 19.8% for evenly-matched teams.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 23:47:36 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Petri", "Guido", ""], ["Stanley", "Michael H.", ""], ["Hon", "Alec B.", ""], ["Dong", "Alexander", ""], ["Xenopoulos", "Peter", ""], ["Silva", "Cl\u00e1udio", ""]]}, {"id": "2106.08890", "submitter": "Yuanchun Li", "authors": "Yuanchun Li, Ziqi Zhang, Bingyan Liu, Ziyue Yang, and Yunxin Liu", "title": "ModelDiff: Testing-Based DNN Similarity Comparison for Model Reuse\n  Detection", "comments": "ISSTA 2021", "journal-ref": null, "doi": "10.1145/3460319.3464816", "report-no": null, "categories": "cs.LG cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The knowledge of a deep learning model may be transferred to a student model,\nleading to intellectual property infringement or vulnerability propagation.\nDetecting such knowledge reuse is nontrivial because the suspect models may not\nbe white-box accessible and/or may serve different tasks. In this paper, we\npropose ModelDiff, a testing-based approach to deep learning model similarity\ncomparison. Instead of directly comparing the weights, activations, or outputs\nof two models, we compare their behavioral patterns on the same set of test\ninputs. Specifically, the behavioral pattern of a model is represented as a\ndecision distance vector (DDV), in which each element is the distance between\nthe model's reactions to a pair of inputs. The knowledge similarity between two\nmodels is measured with the cosine similarity between their DDVs. To evaluate\nModelDiff, we created a benchmark that contains 144 pairs of models that cover\nmost popular model reuse methods, including transfer learning, model\ncompression, and model stealing. Our method achieved 91.7% correctness on the\nbenchmark, which demonstrates the effectiveness of using ModelDiff for model\nreuse detection. A study on mobile deep learning apps has shown the feasibility\nof ModelDiff on real-world models.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 15:16:18 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Li", "Yuanchun", ""], ["Zhang", "Ziqi", ""], ["Liu", "Bingyan", ""], ["Yang", "Ziyue", ""], ["Liu", "Yunxin", ""]]}, {"id": "2106.08892", "submitter": "Masato Kiyama", "authors": "Masato Kiyama and Motoki Amagasaki and Masahiro Iida", "title": "Development of Quantized DNN Library for Exact Hardware Emulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantization is used to speed up execution time and save power when runnning\nDeep neural networks (DNNs) on edge devices like AI chips. To investigate the\neffect of quantization, we need performing inference after quantizing the\nweights of DNN with 32-bit floating-point precision by a some bit width, and\nthen quantizing them back to 32-bit floating-point precision. This is because\nthe DNN library can only handle floating-point numbers. However, the accuracy\nof the emulation does not provide accurate precision. We need accurate\nprecision to detect overflow in MAC operations or to verify the operation on\nedge de vices. We have developed PyParch, a DNN library that executes quantized\nDNNs (QNNs) with exactly the same be havior as hardware. In this paper, we\ndescribe a new proposal and implementation of PyParch. As a result of the\nevaluation, the accuracy of QNNs with arbitrary bit widths can be estimated for\nla rge and complex DNNs such as YOLOv5, and the overflow can be detected. We\nevaluated the overhead of the emulation time and found that it was 5.6 times\nslower for QNN and 42\n  times slower for QNN with overflow detection compared to the normal DNN\nexecution time.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 17:42:40 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Kiyama", "Masato", ""], ["Amagasaki", "Motoki", ""], ["Iida", "Masahiro", ""]]}, {"id": "2106.08977", "submitter": "Haoming Jiang", "authors": "Haoming Jiang, Danqing Zhang, Tianyu Cao, Bing Yin, Tuo Zhao", "title": "Named Entity Recognition with Small Strongly Labeled and Large Weakly\n  Labeled Data", "comments": "The 59th Annual Meeting of the Association for Computational\n  Linguistics (ACL 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weak supervision has shown promising results in many natural language\nprocessing tasks, such as Named Entity Recognition (NER). Existing work mainly\nfocuses on learning deep NER models only with weak supervision, i.e., without\nany human annotation, and shows that by merely using weakly labeled data, one\ncan achieve good performance, though still underperforms fully supervised NER\nwith manually/strongly labeled data. In this paper, we consider a more\npractical scenario, where we have both a small amount of strongly labeled data\nand a large amount of weakly labeled data. Unfortunately, we observe that\nweakly labeled data does not necessarily improve, or even deteriorate the model\nperformance (due to the extensive noise in the weak labels) when we train deep\nNER models over a simple or weighted combination of the strongly labeled and\nweakly labeled data. To address this issue, we propose a new multi-stage\ncomputational framework -- NEEDLE with three essential ingredients: (1) weak\nlabel completion, (2) noise-aware loss function, and (3) final fine-tuning over\nthe strongly labeled data. Through experiments on E-commerce query NER and\nBiomedical NER, we demonstrate that NEEDLE can effectively suppress the noise\nof the weak labels and outperforms existing methods. In particular, we achieve\nnew SOTA F1-scores on 3 Biomedical NER datasets: BC5CDR-chem 93.74,\nBC5CDR-disease 90.69, NCBI-disease 92.28.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 17:18:14 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Jiang", "Haoming", ""], ["Zhang", "Danqing", ""], ["Cao", "Tianyu", ""], ["Yin", "Bing", ""], ["Zhao", "Tuo", ""]]}, {"id": "2106.08981", "submitter": "Domingos Salazar", "authors": "Domingos S. P. Salazar", "title": "Nonequilibrium thermodynamics of self-supervised learning", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-supervised learning (SSL) of energy based models has an intuitive\nrelation to equilibrium thermodynamics because the softmax layer, mapping\nenergies to probabilities, is a Gibbs distribution. However, in what way SSL is\na thermodynamic process? We show that some SSL paradigms behave as a\nthermodynamic composite system formed by representations and self-labels in\ncontact with a nonequilibrium reservoir. Moreover, this system is subjected to\nusual thermodynamic cycles, such as adiabatic expansion and isochoric heating,\nresulting in a generalized Gibbs ensemble (GGE). In this picture, we show that\nlearning is seen as a demon that operates in cycles using feedback measurements\nto extract negative work from the system. As applications, we examine some SSL\nalgorithms using this idea.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 17:21:59 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Salazar", "Domingos S. P.", ""]]}, {"id": "2106.08995", "submitter": "Birgitta Dresp-Langley", "authors": "Birgitta Dresp-Langley, Rongrong Liu, John M. Wandeto", "title": "Surgical task expertise detected by a self-organizing neural network map", "comments": "Conference on Automation in Medical Engineering AUTOMED21, University\n  Hospital Basel, Switzerland, 2021, June 8-9", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individual grip force profiling of bimanual simulator task performance of\nexperts and novices using a robotic control device designed for endoscopic\nsurgery permits defining benchmark criteria that tell true expert task skills\nfrom the skills of novices or trainee surgeons. Grip force variability in a\ntrue expert and a complete novice executing a robot assisted surgical simulator\ntask reveal statistically significant differences as a function of task\nexpertise. Here we show that the skill specific differences in local grip\nforces are predicted by the output metric of a Self Organizing neural network\nMap (SOM) with a bio inspired functional architecture that maps the functional\nconnectivity of somatosensory neural networks in the primate brain.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 10:48:10 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Dresp-Langley", "Birgitta", ""], ["Liu", "Rongrong", ""], ["Wandeto", "John M.", ""]]}, {"id": "2106.09009", "submitter": "Michael Saxon", "authors": "Michael Saxon, Samridhi Choudhary, Joseph P. McKenna, Athanasios\n  Mouchtaris", "title": "End-to-End Spoken Language Understanding for Generalized Voice\n  Assistants", "comments": "Accepted to Interspeech 2021; 5 pages, 2 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end (E2E) spoken language understanding (SLU) systems predict\nutterance semantics directly from speech using a single model. Previous work in\nthis area has focused on targeted tasks in fixed domains, where the output\nsemantic structure is assumed a priori and the input speech is of limited\ncomplexity. In this work we present our approach to developing an E2E model for\ngeneralized SLU in commercial voice assistants (VAs). We propose a fully\ndifferentiable, transformer-based, hierarchical system that can be pretrained\nat both the ASR and NLU levels. This is then fine-tuned on both transcription\nand semantic classification losses to handle a diverse set of intent and\nargument combinations. This leads to an SLU system that achieves significant\nimprovements over baselines on a complex internal generalized VA dataset with a\n43% improvement in accuracy, while still meeting the 99% accuracy benchmark on\nthe popular Fluent Speech Commands dataset. We further evaluate our model on a\nhard test set, exclusively containing slot arguments unseen in training, and\ndemonstrate a nearly 20% improvement, showing the efficacy of our approach in\ntruly demanding VA scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 17:56:47 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 23:11:04 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Saxon", "Michael", ""], ["Choudhary", "Samridhi", ""], ["McKenna", "Joseph P.", ""], ["Mouchtaris", "Athanasios", ""]]}, {"id": "2106.09013", "submitter": "Yachen Tang", "authors": "Yachen Tang, Haiyun Han, Xianmao Yu, Jing Zhao, Guangyi Liu, and\n  Longfei Wei", "title": "An Intelligent Question Answering System based on Power Knowledge Graph", "comments": "5 pages,6 figures, IEEE General Meeting 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The intelligent question answering (IQA) system can accurately capture users'\nsearch intention by understanding the natural language questions, searching\nrelevant content efficiently from a massive knowledge-base, and returning the\nanswer directly to the user. Since the IQA system can save inestimable time and\nworkforce in data search and reasoning, it has received more and more attention\nin data science and artificial intelligence. This article introduced a domain\nknowledge graph using the graph database and graph computing technologies from\nmassive heterogeneous data in electric power. It then proposed an IQA system\nbased on the electrical power knowledge graph to extract the intent and\nconstraints of natural interrogation based on the natural language processing\n(NLP) method, to construct graph data query statements via knowledge reasoning,\nand to complete the accurate knowledge search and analysis to provide users\nwith an intuitive visualization. This method thoroughly combined knowledge\ngraph and graph computing characteristics, realized high-speed multi-hop\nknowledge correlation reasoning analysis in tremendous knowledge. The proposed\nwork can also provide a basis for the context-aware intelligent question and\nanswer.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 17:57:51 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Tang", "Yachen", ""], ["Han", "Haiyun", ""], ["Yu", "Xianmao", ""], ["Zhao", "Jing", ""], ["Liu", "Guangyi", ""], ["Wei", "Longfei", ""]]}, {"id": "2106.09018", "submitter": "Zheng Zhang", "authors": "Mengde Xu, Zheng Zhang, Han Hu, Jianfeng Wang, Lijuan Wang, Fangyun\n  Wei, Xiang Bai, Zicheng Liu", "title": "End-to-End Semi-Supervised Object Detection with Soft Teacher", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents an end-to-end semi-supervised object detection approach,\nin contrast to previous more complex multi-stage methods. The end-to-end\ntraining gradually improves pseudo label qualities during the curriculum, and\nthe more and more accurate pseudo labels in turn benefit object detection\ntraining. We also propose two simple yet effective techniques within this\nframework: a soft teacher mechanism where the classification loss of each\nunlabeled bounding box is weighed by the classification score produced by the\nteacher network; a box jittering approach to select reliable pseudo boxes for\nthe learning of box regression. On COCO benchmark, the proposed approach\noutperforms previous methods by a large margin under various labeling ratios,\ni.e. 1\\%, 5\\% and 10\\%. Moreover, our approach proves to perform also well when\nthe amount of labeled data is relatively large. For example, it can improve a\n40.9 mAP baseline detector trained using the full COCO training set by +3.6\nmAP, reaching 44.5 mAP, by leveraging the 123K unlabeled images of COCO. On the\nstate-of-the-art Swin Transformer-based object detector (58.9 mAP on test-dev),\nit can still significantly improve the detection accuracy by +1.5 mAP, reaching\n60.4 mAP, and improve the instance segmentation accuracy by +1.2 mAP, reaching\n52.4 mAP, pushing the new state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 17:59:30 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 16:59:32 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Xu", "Mengde", ""], ["Zhang", "Zheng", ""], ["Hu", "Han", ""], ["Wang", "Jianfeng", ""], ["Wang", "Lijuan", ""], ["Wei", "Fangyun", ""], ["Bai", "Xiang", ""], ["Liu", "Zicheng", ""]]}, {"id": "2106.09019", "submitter": "Xingyuan Sun", "authors": "Xingyuan Sun, Tianju Xue, Szymon M. Rusinkiewicz, Ryan P. Adams", "title": "Amortized Synthesis of Constrained Configurations Using a Differentiable\n  Surrogate", "comments": "16 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In design, fabrication, and control problems, we are often faced with the\ntask of synthesis, in which we must generate an object or configuration that\nsatisfies a set of constraints while maximizing one or more objective\nfunctions. The synthesis problem is typically characterized by a physical\nprocess in which many different realizations may achieve the goal. This\nmany-to-one map presents challenges to the supervised learning of feed-forward\nsynthesis, as the set of viable designs may have a complex structure. In\naddition, the non-differentiable nature of many physical simulations prevents\ndirect optimization. We address both of these problems with a two-stage neural\nnetwork architecture that we may consider to be an autoencoder. We first learn\nthe decoder: a differentiable surrogate that approximates the many-to-one\nphysical realization process. We then learn the encoder, which maps from goal\nto design, while using the fixed decoder to evaluate the quality of the\nrealization. We evaluate the approach on two case studies: extruder path\nplanning in additive manufacturing and constrained soft robot inverse\nkinematics. We compare our approach to direct optimization of design using the\nlearned surrogate, and to supervised learning of the synthesis problem. We find\nthat our approach produces higher quality solutions than supervised learning,\nwhile being competitive in quality with direct optimization, at a greatly\nreduced computational cost.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 17:59:45 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Sun", "Xingyuan", ""], ["Xue", "Tianju", ""], ["Rusinkiewicz", "Szymon M.", ""], ["Adams", "Ryan P.", ""]]}, {"id": "2106.09051", "submitter": "Paul Henderson", "authors": "Paul Henderson, Christoph H. Lampert, Bernd Bickel", "title": "Unsupervised Video Prediction from a Single Frame by Estimating 3D\n  Dynamic Scene Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal in this work is to generate realistic videos given just one initial\nframe as input. Existing unsupervised approaches to this task do not consider\nthe fact that a video typically shows a 3D environment, and that this should\nremain coherent from frame to frame even as the camera and objects move. We\naddress this by developing a model that first estimates the latent 3D structure\nof the scene, including the segmentation of any moving objects. It then\npredicts future frames by simulating the object and camera dynamics, and\nrendering the resulting views. Importantly, it is trained end-to-end using only\nthe unsupervised objective of predicting future frames, without any 3D\ninformation nor segmentation annotations. Experiments on two challenging\ndatasets of natural videos show that our model can estimate 3D structure and\nmotion segmentation from a single frame, and hence generate plausible and\nvaried predictions.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 18:00:12 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Henderson", "Paul", ""], ["Lampert", "Christoph H.", ""], ["Bickel", "Bernd", ""]]}, {"id": "2106.09086", "submitter": "Hengyuan Hu", "authors": "Hengyuan Hu, Adam Lerer, Noam Brown, Jakob Foerster", "title": "Learned Belief Search: Efficiently Improving Policies in Partially\n  Observable Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Search is an important tool for computing effective policies in single- and\nmulti-agent environments, and has been crucial for achieving superhuman\nperformance in several benchmark fully and partially observable games. However,\none major limitation of prior search approaches for partially observable\nenvironments is that the computational cost scales poorly with the amount of\nhidden information. In this paper we present \\emph{Learned Belief Search}\n(LBS), a computationally efficient search procedure for partially observable\nenvironments. Rather than maintaining an exact belief distribution, LBS uses an\napproximate auto-regressive counterfactual belief that is learned as a\nsupervised task. In multi-agent settings, LBS uses a novel public-private model\narchitecture for underlying policies in order to efficiently evaluate these\npolicies during rollouts. In the benchmark domain of Hanabi, LBS can obtain 55%\n~ 91% of the benefit of exact search while reducing compute requirements by\n$35.8 \\times$ ~ $4.6 \\times$, allowing it to scale to larger settings that were\ninaccessible to previous search methods.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 19:00:53 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Hu", "Hengyuan", ""], ["Lerer", "Adam", ""], ["Brown", "Noam", ""], ["Foerster", "Jakob", ""]]}, {"id": "2106.09106", "submitter": "Scott Cheng-Hsin Yang", "authors": "Tomas Folke, ZhaoBin Li, Ravi B. Sojitra, Scott Cheng-Hsin Yang, and\n  Patrick Shafto", "title": "Explainable AI for Natural Adversarial Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adversarial images highlight how vulnerable modern image classifiers are to\nperturbations outside of their training set. Human oversight might mitigate\nthis weakness, but depends on humans understanding the AI well enough to\npredict when it is likely to make a mistake. In previous work we have found\nthat humans tend to assume that the AI's decision process mirrors their own.\nHere we evaluate if methods from explainable AI can disrupt this assumption to\nhelp participants predict AI classifications for adversarial and standard\nimages. We find that both saliency maps and examples facilitate catching AI\nerrors, but their effects are not additive, and saliency maps are more\neffective than examples.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 20:19:04 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Folke", "Tomas", ""], ["Li", "ZhaoBin", ""], ["Sojitra", "Ravi B.", ""], ["Yang", "Scott Cheng-Hsin", ""], ["Shafto", "Patrick", ""]]}, {"id": "2106.09146", "submitter": "Gabriel Poesia", "authors": "Gabriel Poesia, WenXin Dong, Noah Goodman", "title": "Contrastive Reinforcement Learning of Symbolic Reasoning Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Abstract symbolic reasoning, as required in domains such as mathematics and\nlogic, is a key component of human intelligence. Solvers for these domains have\nimportant applications, especially to computer-assisted education. But learning\nto solve symbolic problems is challenging for machine learning algorithms.\nExisting models either learn from human solutions or use hand-engineered\nfeatures, making them expensive to apply in new domains. In this paper, we\ninstead consider symbolic domains as simple environments where states and\nactions are given as unstructured text, and binary rewards indicate whether a\nproblem is solved. This flexible setup makes it easy to specify new domains,\nbut search and planning become challenging. We introduce four environments\ninspired by the Mathematics Common Core Curriculum, and observe that existing\nReinforcement Learning baselines perform poorly. We then present a novel\nlearning algorithm, Contrastive Policy Learning (ConPoLe) that explicitly\noptimizes the InfoNCE loss, which lower bounds the mutual information between\nthe current state and next states that continue on a path to the solution.\nConPoLe successfully solves all four domains. Moreover, problem representations\nlearned by ConPoLe enable accurate prediction of the categories of problems in\na real mathematics curriculum. Our results suggest new directions for\nreinforcement learning in symbolic domains, as well as applications to\nmathematics education.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 21:46:07 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Poesia", "Gabriel", ""], ["Dong", "WenXin", ""], ["Goodman", "Noah", ""]]}, {"id": "2106.09164", "submitter": "Dmitri Soshnikov", "authors": "Dmitry Soshnikov and Yana Valieva", "title": "mPyPl: Python Monadic Pipeline Library for Complex Functional Data\n  Processing", "comments": "Published in Microsoft Journal of Applied Research, Dec.2019., Vol.\n  12", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new Python library called mPyPl, which is\nintended to simplify complex data processing tasks using functional approach.\nThis library defines operations on lazy data streams of named dictionaries\nrepresented as generators (so-called multi-field datastreams), and allows\nenriching those data streams with more 'fields' in the process of data\npreparation and feature extraction. Thus, most data preparation tasks can be\nexpressed in the form of neat linear 'pipeline', similar in syntax to UNIX\npipes, or |> functional composition operator in F#.\n  We define basic operations on multi-field data streams, which resemble\nclassical monadic operations, and show similarity of the proposed approach to\nmonads in functional programming. We also show how the library was used in\ncomplex deep learning tasks of event detection in video, and discuss different\nevaluation strategies that allow for different compromises in terms of memory\nand performance.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 22:34:01 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Soshnikov", "Dmitry", ""], ["Valieva", "Yana", ""]]}, {"id": "2106.09166", "submitter": "Geng Yuan", "authors": "Geng Yuan, Zhiheng Liao, Xiaolong Ma, Yuxuan Cai, Zhenglun Kong, Xuan\n  Shen, Jingyan Fu, Zhengang Li, Chengming Zhang, Hongwu Peng, Ning Liu, Ao\n  Ren, Jinhui Wang, Yanzhi Wang", "title": "Improving DNN Fault Tolerance using Weight Pruning and Differential\n  Crossbar Mapping for ReRAM-based Edge AI", "comments": "In Proceedings of the 22nd International Symposium on Quality\n  Electronic Design (ISQED), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent research demonstrated the promise of using resistive random access\nmemory (ReRAM) as an emerging technology to perform inherently parallel analog\ndomain in-situ matrix-vector multiplication -- the intensive and key\ncomputation in deep neural networks (DNNs). However, hardware failure, such as\nstuck-at-fault defects, is one of the main concerns that impedes the ReRAM\ndevices to be a feasible solution for real implementations. The existing\nsolutions to address this issue usually require an optimization to be conducted\nfor each individual device, which is impractical for mass-produced products\n(e.g., IoT devices). In this paper, we rethink the value of weight pruning in\nReRAM-based DNN design from the perspective of model fault tolerance. And a\ndifferential mapping scheme is proposed to improve the fault tolerance under a\nhigh stuck-on fault rate. Our method can tolerate almost an order of magnitude\nhigher failure rate than the traditional two-column method in representative\nDNN tasks. More importantly, our method does not require extra hardware cost\ncompared to the traditional two-column mapping scheme. The improvement is\nuniversal and does not require the optimization process for each individual\ndevice.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 22:38:04 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 22:27:16 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Yuan", "Geng", ""], ["Liao", "Zhiheng", ""], ["Ma", "Xiaolong", ""], ["Cai", "Yuxuan", ""], ["Kong", "Zhenglun", ""], ["Shen", "Xuan", ""], ["Fu", "Jingyan", ""], ["Li", "Zhengang", ""], ["Zhang", "Chengming", ""], ["Peng", "Hongwu", ""], ["Liu", "Ning", ""], ["Ren", "Ao", ""], ["Wang", "Jinhui", ""], ["Wang", "Yanzhi", ""]]}, {"id": "2106.09174", "submitter": "Di Jin", "authors": "Di Jin, Seokhwan Kim, Dilek Hakkani-Tur", "title": "Can I Be of Further Assistance? Using Unstructured Knowledge Access to\n  Improve Task-oriented Conversational Modeling", "comments": "Presented as a DIALDOC workshop paper at ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Most prior work on task-oriented dialogue systems are restricted to limited\ncoverage of domain APIs. However, users oftentimes have requests that are out\nof the scope of these APIs. This work focuses on responding to these\nbeyond-API-coverage user turns by incorporating external, unstructured\nknowledge sources. Our approach works in a pipelined manner with\nknowledge-seeking turn detection, knowledge selection, and response generation\nin sequence. We introduce novel data augmentation methods for the first two\nsteps and demonstrate that the use of information extracted from dialogue\ncontext improves the knowledge selection and end-to-end performances. Through\nexperiments, we achieve state-of-the-art performance for both automatic and\nhuman evaluation metrics on the DSTC9 Track 1 benchmark dataset, validating the\neffectiveness of our contributions.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 23:31:42 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Jin", "Di", ""], ["Kim", "Seokhwan", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "2106.09179", "submitter": "Yuxin Xiao", "authors": "Yuxin Xiao, Eric P. Xing, Willie Neiswanger", "title": "Amortized Auto-Tuning: Cost-Efficient Transfer Optimization for\n  Hyperparameter Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the surge in the number of hyperparameters and training times of modern\nmachine learning models, hyperparameter tuning is becoming increasingly\nexpensive. Although methods have been proposed to speed up tuning via knowledge\ntransfer, they typically require the final performance of hyperparameters and\ndo not focus on low-fidelity information. Nevertheless, this common practice is\nsuboptimal and can incur an unnecessary use of resources. It is more\ncost-efficient to instead leverage the low-fidelity tuning observations to\nmeasure inter-task similarity and transfer knowledge from existing to new tasks\naccordingly. However, performing multi-fidelity tuning comes with its own\nchallenges in the transfer setting: the noise in the additional observations\nand the need for performance forecasting. Therefore, we conduct a thorough\nanalysis of the multi-task multi-fidelity Bayesian optimization framework,\nwhich leads to the best instantiation--amortized auto-tuning (AT2). We further\npresent an offline-computed 27-task hyperparameter recommendation (HyperRec)\ndatabase to serve the community. Extensive experiments on HyperRec and other\nreal-world databases illustrate the effectiveness of our AT2 method.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 00:01:18 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Xiao", "Yuxin", ""], ["Xing", "Eric P.", ""], ["Neiswanger", "Willie", ""]]}, {"id": "2106.09212", "submitter": "Jue Wang", "authors": "Jue Wang, Gedas Bertasius, Du Tran, Lorenzo Torresani", "title": "Long-Short Temporal Contrastive Learning of Video Transformers", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Video transformers have recently emerged as a competitive alternative to 3D\nCNNs for video understanding. However, due to their large number of parameters\nand reduced inductive biases, these models require supervised pretraining on\nlarge-scale image datasets to achieve top performance. In this paper, we\nempirically demonstrate that self-supervised pretraining of video transformers\non video-only datasets can lead to action recognition results that are on par\nor better than those obtained with supervised pretraining on large-scale image\ndatasets, even massive ones such as ImageNet-21K. Since transformer-based\nmodels are effective at capturing dependencies over extended temporal spans, we\npropose a simple learning procedure that forces the model to match a long-term\nview to a short-term view of the same video. Our approach, named Long-Short\nTemporal Contrastive Learning (LSTCL), enables video transformers to learn an\neffective clip-level representation by predicting temporal context captured\nfrom a longer temporal extent. To demonstrate the generality of our findings,\nwe implement and validate our approach under three different self-supervised\ncontrastive learning frameworks (MoCo v3, BYOL, SimSiam) using two distinct\nvideo-transformer architectures, including an improved variant of the Swin\nTransformer augmented with space-time attention. We conduct a thorough ablation\nstudy and show that LSTCL achieves competitive performance on multiple video\nbenchmarks and represents a convincing alternative to supervised image-based\npretraining.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 02:30:26 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 01:13:15 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Wang", "Jue", ""], ["Bertasius", "Gedas", ""], ["Tran", "Du", ""], ["Torresani", "Lorenzo", ""]]}, {"id": "2106.09225", "submitter": "Monireh Ebrahimi", "authors": "Monireh Ebrahimi, Aaron Eberhart, Pascal Hitzler", "title": "On the Capabilities of Pointer Networks for Deep Deductive Reasoning", "comments": "14 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The importance of building neural networks that can learn to reason has been\nwell recognized in the neuro-symbolic community. In this paper, we apply neural\npointer networks for conducting reasoning over symbolic knowledge bases. In\ndoing so, we explore the benefits and limitations of encoder-decoder\narchitectures in general and pointer networks in particular for developing\naccurate, generalizable and robust neuro-symbolic reasoners. Based on our\nexperimental results, pointer networks performs remarkably well across multiple\nreasoning tasks while outperforming the previously reported state of the art by\na significant margin. We observe that the Pointer Networks preserve their\nperformance even when challenged with knowledge graphs of the domain/vocabulary\nit has never encountered before. To the best of our knowledge, this is the\nfirst study on neuro-symbolic reasoning using Pointer Networks. We hope our\nimpressive results on these reasoning problems will encourage broader\nexploration of pointer networks' capabilities for reasoning over more complex\nlogics and for other neuro-symbolic problems.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 03:25:20 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Ebrahimi", "Monireh", ""], ["Eberhart", "Aaron", ""], ["Hitzler", "Pascal", ""]]}, {"id": "2106.09230", "submitter": "Bla\\v{z} \\v{S}krlj", "authors": "Timen Stepi\\v{s}nik Perdih, Senja Pollak, Bla\\v{z} \\v{Skrlj}", "title": "JSI at the FinSim-2 task: Ontology-Augmented Financial Concept\n  Classification", "comments": null, "journal-ref": null, "doi": "10.1145/3442442.3451383", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontologies are increasingly used for machine reasoning over the last few\nyears. They can provide explanations of concepts or be used for concept\nclassification if there exists a mapping from the desired labels to the\nrelevant ontology. Another advantage of using ontologies is that they do not\nneed a learning process, meaning that we do not need the train data or time\nbefore using them. This paper presents a practical use of an ontology for a\nclassification problem from the financial domain. It first transforms a given\nontology to a graph and proceeds with generalization with the aim to find\ncommon semantic descriptions of the input sets of financial concepts.\n  We present a solution to the shared task on Learning Semantic Similarities\nfor the Financial Domain (FinSim-2 task). The task is to design a system that\ncan automatically classify concepts from the Financial domain into the most\nrelevant hypernym concept in an external ontology - the Financial Industry\nBusiness Ontology. We propose a method that maps given concepts to the\nmentioned ontology and performs a graph search for the most relevant hypernyms.\nWe also employ a word vectorization method and a machine learning classifier to\nsupplement the method with a ranked list of labels for each concept.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 03:56:15 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Perdih", "Timen Stepi\u0161nik", ""], ["Pollak", "Senja", ""], ["\\v{Skrlj}", "Bla\u017e", ""]]}, {"id": "2106.09231", "submitter": "Hongyu Lin", "authors": "Boxi Cao, Hongyu Lin, Xianpei Han, Le Sun, Lingyong Yan, Meng Liao,\n  Tong Xue, Jin Xu", "title": "Knowledgeable or Educated Guess? Revisiting Language Models as Knowledge\n  Bases", "comments": "Accepted to ACL2021(main conference)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Previous literatures show that pre-trained masked language models (MLMs) such\nas BERT can achieve competitive factual knowledge extraction performance on\nsome datasets, indicating that MLMs can potentially be a reliable knowledge\nsource. In this paper, we conduct a rigorous study to explore the underlying\npredicting mechanisms of MLMs over different extraction paradigms. By\ninvestigating the behaviors of MLMs, we find that previous decent performance\nmainly owes to the biased prompts which overfit dataset artifacts. Furthermore,\nincorporating illustrative cases and external contexts improve knowledge\nprediction mainly due to entity type guidance and golden answer leakage. Our\nfindings shed light on the underlying predicting mechanisms of MLMs, and\nstrongly question the previous conclusion that current MLMs can potentially\nserve as reliable factual knowledge bases.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 03:59:45 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Cao", "Boxi", ""], ["Lin", "Hongyu", ""], ["Han", "Xianpei", ""], ["Sun", "Le", ""], ["Yan", "Lingyong", ""], ["Liao", "Meng", ""], ["Xue", "Tong", ""], ["Xu", "Jin", ""]]}, {"id": "2106.09241", "submitter": "Cheng-Te Li", "authors": "I-Chung Hsieh, Cheng-Te Li", "title": "CoANE: Modeling Context Co-occurrence for Attributed Network Embedding", "comments": "Accepted to IEEE TKDE 2021. Code can be accessed via\n  https://github.com/ICHproject/CoANE/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attributed network embedding (ANE) is to learn low-dimensional vectors so\nthat not only the network structure but also node attributes can be preserved\nin the embedding space. Existing ANE models do not consider the specific\ncombination between graph structure and attributes. While each node has its\nstructural characteristics, such as highly-interconnected neighbors along with\ntheir certain patterns of attribute distribution, each node's neighborhood\nshould be not only depicted by multi-hop nodes, but consider certain clusters\nor social circles. To model such information, in this paper, we propose a novel\nANE model, Context Co-occurrence-aware Attributed Network Embedding (CoANE).\nThe basic idea of CoANE is to model the context attributes that each node's\ninvolved diverse patterns, and apply the convolutional mechanism to encode\npositional information by treating each attribute as a channel. The learning of\ncontext co-occurrence can capture the latent social circles of each node. To\nbetter encode structural and semantic knowledge of nodes, we devise a three-way\nobjective function, consisting of positive graph likelihood, contextual\nnegative sampling, and attribute reconstruction. We conduct experiments on five\nreal datasets in the tasks of link prediction, node label classification, and\nnode clustering. The results exhibit that CoANE can significantly outperform\nstate-of-the-art ANE models.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 04:31:02 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Hsieh", "I-Chung", ""], ["Li", "Cheng-Te", ""]]}, {"id": "2106.09256", "submitter": "Xinqiang Cai", "authors": "Xin-Qiang Cai, Yao-Xiang Ding, Zi-Xuan Chen, Yuan Jiang, Masashi\n  Sugiyama, Zhi-Hua Zhou", "title": "Seeing Differently, Acting Similarly: Imitation Learning with\n  Heterogeneous Observations", "comments": "17 pages, 25 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world imitation learning tasks, the demonstrator and the learner\nhave to act in different but full observation spaces. This situation generates\nsignificant obstacles for existing imitation learning approaches to work, even\nwhen they are combined with traditional space adaptation techniques. The main\nchallenge lies in bridging expert's occupancy measures to learner's dynamically\nchanging occupancy measures under the different observation spaces. In this\nwork, we model the above learning problem as Heterogeneous Observations\nImitation Learning (HOIL). We propose the Importance Weighting with REjection\n(IWRE) algorithm based on the techniques of importance-weighting, learning with\nrejection, and active querying to solve the key challenge of occupancy measure\nmatching. Experimental results show that IWRE can successfully solve HOIL\ntasks, including the challenging task of transforming the vision-based\ndemonstrations to random access memory (RAM)-based policies under the Atari\ndomain.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 05:44:04 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Cai", "Xin-Qiang", ""], ["Ding", "Yao-Xiang", ""], ["Chen", "Zi-Xuan", ""], ["Jiang", "Yuan", ""], ["Sugiyama", "Masashi", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "2106.09258", "submitter": "Konstantinos Kotis", "authors": "Evangelos Paparidis and Konstantinos Kotis", "title": "Knowledge Graphs and Machine Learning in biased C4I applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces our position on the critical issue of bias that\nrecently appeared in AI applications. Specifically, we discuss the combination\nof current technologies used in AI applications i.e., Machine Learning and\nKnowledge Graphs, and point to their involvement in (de)biased applications of\nthe C4I domain. Although this is a wider problem that currently emerges from\ndifferent application domains, bias appears more critical in C4I than in others\ndue to its security-related nature. While proposing certain actions to be taken\ntowards debiasing C4I applications, we acknowledge the immature aspect of this\ntopic within the Knowledge Graph and Semantic Web communities.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 05:53:46 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Paparidis", "Evangelos", ""], ["Kotis", "Konstantinos", ""]]}, {"id": "2106.09259", "submitter": "Yun-Hao Cao", "authors": "Yun-Hao Cao and Jianxin Wu", "title": "A Random CNN Sees Objects: One Inductive Bias of CNN and Its\n  Applications", "comments": "17 pages, 9 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper starts by revealing a surprising finding: without any learning, a\nrandomly initialized CNN can localize objects surprisingly well. That is, a CNN\nhas an inductive bias to naturally focus on objects, named as Tobias (``The\nobject is at sight'') in this paper. This empirical inductive bias is further\nanalyzed and successfully applied to self-supervised learning. A CNN is\nencouraged to learn representations that focus on the foreground object, by\ntransforming every image into various versions with different backgrounds,\nwhere the foreground and background separation is guided by Tobias.\nExperimental results show that the proposed Tobias significantly improves\ndownstream tasks, especially for object detection. This paper also shows that\nTobias has consistent improvements on training sets of different sizes, and is\nmore resilient to changes in image augmentations. Our codes will be available\nat https://github.com/CupidJay/Tobias.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 06:07:49 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Cao", "Yun-Hao", ""], ["Wu", "Jianxin", ""]]}, {"id": "2106.09269", "submitter": "Daiki Chijiwa", "authors": "Daiki Chijiwa, Shin'ya Yamaguchi, Yasutoshi Ida, Kenji Umakoshi,\n  Tomohiro Inoue", "title": "Pruning Randomly Initialized Neural Networks with Iterative\n  Randomization", "comments": "Code will be available at https://github.com/dchiji-ntt/iterand", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pruning the weights of randomly initialized neural networks plays an\nimportant role in the context of lottery ticket hypothesis. Ramanujan et al.\n(2020) empirically showed that only pruning the weights can achieve remarkable\nperformance instead of optimizing the weight values. However, to achieve the\nsame level of performance as the weight optimization, the pruning approach\nrequires more parameters in the networks before pruning and thus more memory\nspace. To overcome this parameter inefficiency, we introduce a novel framework\nto prune randomly initialized neural networks with iteratively randomizing\nweight values (IteRand). Theoretically, we prove an approximation theorem in\nour framework, which indicates that the randomizing operations are provably\neffective to reduce the required number of the parameters. We also empirically\ndemonstrate the parameter efficiency in multiple experiments on CIFAR-10 and\nImageNet.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 06:32:57 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Chijiwa", "Daiki", ""], ["Yamaguchi", "Shin'ya", ""], ["Ida", "Yasutoshi", ""], ["Umakoshi", "Kenji", ""], ["Inoue", "Tomohiro", ""]]}, {"id": "2106.09274", "submitter": "Xiang Tan", "authors": "Xiang Tan, Li Zhou, Haijun Wang, Yuli Sun, Haitao Zhao, Boon-Chong\n  Seet, Jibo Wei and Victor C.M. Leung", "title": "Cooperative Multi-Agent Reinforcement Learning Based Distributed Dynamic\n  Spectrum Access in Cognitive Radio Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of the 5G and Internet of Things, amounts of wireless\ndevices need to share the limited spectrum resources. Dynamic spectrum access\n(DSA) is a promising paradigm to remedy the problem of inefficient spectrum\nutilization brought upon by the historical command-and-control approach to\nspectrum allocation. In this paper, we investigate the distributed DSA problem\nfor multi-user in a typical multi-channel cognitive radio network. The problem\nis formulated as a decentralized partially observable Markov decision process\n(Dec-POMDP), and we proposed a centralized off-line training and distributed\non-line execution framework based on cooperative multi-agent reinforcement\nlearning (MARL). We employ the deep recurrent Q-network (DRQN) to address the\npartial observability of the state for each cognitive user. The ultimate goal\nis to learn a cooperative strategy which maximizes the sum throughput of\ncognitive radio network in distributed fashion without coordination information\nexchange between cognitive users. Finally, we validate the proposed algorithm\nin various settings through extensive experiments. From the simulation results,\nwe can observe that the proposed algorithm can converge fast and achieve almost\nthe optimal performance.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 06:52:21 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Tan", "Xiang", ""], ["Zhou", "Li", ""], ["Wang", "Haijun", ""], ["Sun", "Yuli", ""], ["Zhao", "Haitao", ""], ["Seet", "Boon-Chong", ""], ["Wei", "Jibo", ""], ["Leung", "Victor C. M.", ""]]}, {"id": "2106.09281", "submitter": "Haile Haile Misgna", "authors": "Haile Misgna, Moges Ahmed and Anubhav Kumar", "title": "MatES: Web-based Forward Chaining Expert System for Maternal Care", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The solution to prevent maternal complications are known and preventable by\ntrained health professionals. But in countries like Ethiopia where the patient\nto physician ratio is 1 doctor to 1000 patients, maternal mortality and\nmorbidity rate is high. To fill the gap of highly trained health professionals,\nEthiopia introduced health extension programs. Task shifting to health\nextension workers (HEWs) contributed in decreasing mortality and morbidity rate\nin Ethiopia. Knowledge-gap has been one of the major challenges to HEWs. The\nreasons are trainings are not given in regular manner, there is no midwife,\ngynecologists or doctors around for consultation, and all guidelines are\npaper-based which are easily exposed to damage. In this paper, we describe the\ndesign and implementation of a web-based expert system for maternal care. We\nonly targeted the major 10 diseases and complication of maternal health issues\nseen in Sub-Saharan Africa. The expert system can be accessed through the use\nof web browsers from computers as well as smart phones. Forward chaining\nrule-based expert system is used in order to give suggestions and create a new\nknowledge from the knowledge-base. This expert system can be used to train HEWs\nin the field of maternal health.\n  Keywords: expert system, maternal care, forward-chaining, rule-based expert\nsystem, PHLIPS\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 07:06:58 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Misgna", "Haile", ""], ["Ahmed", "Moges", ""], ["Kumar", "Anubhav", ""]]}, {"id": "2106.09289", "submitter": "Yundong Sun", "authors": "Dongjie Zhu, Yundong Sun, Haiwen Du and Zhaoshuo Tian", "title": "MHNF: Multi-hop Heterogeneous Neighborhood information Fusion graph\n  representation learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanism enables the Graph Neural Networks(GNNs) to learn the\nattention weights between the target node and its one-hop neighbors, the\nperformance is further improved. However, the most existing GNNs are oriented\nto homogeneous graphs and each layer can only aggregate the information of\none-hop neighbors. Stacking multi-layer networks will introduce a lot of noise\nand easily lead to over smoothing. We propose a Multi-hop Heterogeneous\nNeighborhood information Fusion graph representation learning method (MHNF).\nSpecifically, we first propose a hybrid metapath autonomous extraction model to\nefficiently extract multi-hop hybrid neighbors. Then, we propose a hop-level\nheterogeneous Information aggregation model, which selectively aggregates\ndifferent-hop neighborhood information within the same hybrid metapath.\nFinally, a hierarchical semantic attention fusion model (HSAF) is proposed,\nwhich can efficiently integrate different-hop and different-path neighborhood\ninformation respectively. This paper can solve the problem of aggregating the\nmulti-hop neighborhood information and can learn hybrid metapaths for target\ntask, reducing the limitation of manually specifying metapaths. In addition,\nHSAF can extract the internal node information of the metapaths and better\nintegrate the semantic information of different levels. Experimental results on\nreal datasets show that MHNF is superior to state-of-the-art methods in node\nclassification and clustering tasks (10.94% - 69.09% and 11.58% - 394.93%\nrelative improvement on average, respectively).\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 07:51:45 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Zhu", "Dongjie", ""], ["Sun", "Yundong", ""], ["Du", "Haiwen", ""], ["Tian", "Zhaoshuo", ""]]}, {"id": "2106.09296", "submitter": "C.-H. Huck Yang", "authors": "Chao-Han Huck Yang, Yun-Yun Tsai, Pin-Yu Chen", "title": "Voice2Series: Reprogramming Acoustic Models for Time Series\n  Classification", "comments": "Accepted to ICML 2021, 16 Pages", "journal-ref": "Proceedings of the 38th International Conference on Machine\n  Learning 2021", "doi": null, "report-no": "11808--11819", "categories": "cs.LG cs.AI cs.NE cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Learning to classify time series with limited data is a practical yet\nchallenging problem. Current methods are primarily based on hand-designed\nfeature extraction rules or domain-specific data augmentation. Motivated by the\nadvances in deep speech processing models and the fact that voice data are\nunivariate temporal signals, in this paper, we propose Voice2Series (V2S), a\nnovel end-to-end approach that reprograms acoustic models for time series\nclassification, through input transformation learning and output label mapping.\nLeveraging the representation learning power of a large-scale pre-trained\nspeech processing model, on 30 different time series tasks we show that V2S\neither outperforms or is tied with state-of-the-art methods on 20 tasks, and\nimproves their average accuracy by 1.84%. We further provide a theoretical\njustification of V2S by proving its population risk is upper bounded by the\nsource risk and a Wasserstein distance accounting for feature alignment via\nreprogramming. Our results offer new and effective means to time series\nclassification.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 07:59:15 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Yang", "Chao-Han Huck", ""], ["Tsai", "Yun-Yun", ""], ["Chen", "Pin-Yu", ""]]}, {"id": "2106.09305", "submitter": "Liu Minhao", "authors": "Minhao Liu, Ailing Zeng, Qiuxia Lai, Qiang Xu", "title": "Time Series is a Special Sequence: Forecasting with Sample Convolution\n  and Interaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Time series is a special type of sequence data, a set of observations\ncollected at even intervals of time and ordered chronologically. Existing deep\nlearning techniques use generic sequence models (e.g., recurrent neural\nnetwork, Transformer model, or temporal convolutional network) for time series\nanalysis, which ignore some of its unique properties. For example, the\ndownsampling of time series data often preserves most of the information in the\ndata, while this is not true for general sequence data such as text sequence\nand DNA sequence. Motivated by the above, in this paper, we propose a novel\nneural network architecture and apply it for the time series forecasting\nproblem, wherein we conduct sample convolution and interaction at multiple\nresolutions for temporal modeling. The proposed architecture, namelySCINet,\nfacilitates extracting features with enhanced predictability. Experimental\nresults show that SCINet achieves significant prediction accuracy improvement\nover existing solutions across various real-world time series forecasting\ndatasets. In particular, it can achieve high fore-casting accuracy for those\ntemporal-spatial datasets without using sophisticated spatial modeling\ntechniques. Our codes and data are presented in the supplemental material.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 08:15:04 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Liu", "Minhao", ""], ["Zeng", "Ailing", ""], ["Lai", "Qiuxia", ""], ["Xu", "Qiang", ""]]}, {"id": "2106.09306", "submitter": "Dou Hu", "authors": "Dou Hu, Lingwei Wei, Wei Zhou, Xiaoyong Huai, Zhiqi Fang, Songlin Hu", "title": "PEN4Rec: Preference Evolution Networks for Session-based Recommendation", "comments": "12 pages, accepted by KSEM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Session-based recommendation aims to predict user the next action based on\nhistorical behaviors in an anonymous session. For better recommendations, it is\nvital to capture user preferences as well as their dynamics. Besides, user\npreferences evolve over time dynamically and each preference has its own\nevolving track. However, most previous works neglect the evolving trend of\npreferences and can be easily disturbed by the effect of preference drifting.\nIn this paper, we propose a novel Preference Evolution Networks for\nsession-based Recommendation (PEN4Rec) to model preference evolving process by\na two-stage retrieval from historical contexts. Specifically, the first-stage\nprocess integrates relevant behaviors according to recent items. Then, the\nsecond-stage process models the preference evolving trajectory over time\ndynamically and infer rich preferences. The process can strengthen the effect\nof relevant sequential behaviors during the preference evolution and weaken the\ndisturbance from preference drifting. Extensive experiments on three public\ndatasets demonstrate the effectiveness and superiority of the proposed model.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 08:18:52 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Hu", "Dou", ""], ["Wei", "Lingwei", ""], ["Zhou", "Wei", ""], ["Huai", "Xiaoyong", ""], ["Fang", "Zhiqi", ""], ["Hu", "Songlin", ""]]}, {"id": "2106.09325", "submitter": "Mohammad Mohammadamini", "authors": "Zhila Amini, Mohammad Mohammadamini (LIA), Hawre Hosseini, Mehran\n  Mansouri, Daban Jaff", "title": "Central Kurdish machine translation: First large scale parallel corpus\n  and experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the computational processing of Kurdish has experienced a relative\nincrease, the machine translation of this language seems to be lacking a\nconsiderable body of scientific work. This is in part due to the lack of\nresources especially curated for this task. In this paper, we present the first\nlarge scale parallel corpus of Central Kurdish-English, Awta, containing\n229,222 pairs of manually aligned translations. Our corpus is collected from\ndifferent text genres and domains in an attempt to build more robust and\nreal-world applications of machine translation. We make a portion of this\ncorpus publicly available in order to foster research in this area. Further, we\nbuild several neural machine translation models in order to benchmark the task\nof Kurdish machine translation. Additionally, we perform extensive experimental\nanalysis of results in order to identify the major challenges that Central\nKurdish machine translation faces. These challenges include language-dependent\nand-independent ones as categorized in this paper, the first group of which are\naware of Central Kurdish linguistic properties on different morphological,\nsyntactic and semantic levels. Our best performing systems achieve 22.72 and\n16.81 in BLEU score for Ku$\\rightarrow$EN and En$\\rightarrow$Ku, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 08:41:53 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Amini", "Zhila", "", "LIA"], ["Mohammadamini", "Mohammad", "", "LIA"], ["Hosseini", "Hawre", ""], ["Mansouri", "Mehran", ""], ["Jaff", "Daban", ""]]}, {"id": "2106.09326", "submitter": "Ni Wang", "authors": "Ni Wang, Ozan Catal, Tim Verbelen, Matthias Hartmann, Bart Dhoedt", "title": "Towards bio-inspired unsupervised representation learning for indoor\n  aerial navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Aerial navigation in GPS-denied, indoor environments, is still an open\nchallenge. Drones can perceive the environment from a richer set of viewpoints,\nwhile having more stringent compute and energy constraints than other\nautonomous platforms. To tackle that problem, this research displays a\nbiologically inspired deep-learning algorithm for simultaneous localization and\nmapping (SLAM) and its application in a drone navigation system. We propose an\nunsupervised representation learning method that yields low-dimensional latent\nstate descriptors, that mitigates the sensitivity to perceptual aliasing, and\nworks on power-efficient, embedded hardware. The designed algorithm is\nevaluated on a dataset collected in an indoor warehouse environment, and\ninitial results show the feasibility for robust indoor aerial navigation.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 08:42:38 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Wang", "Ni", ""], ["Catal", "Ozan", ""], ["Verbelen", "Tim", ""], ["Hartmann", "Matthias", ""], ["Dhoedt", "Bart", ""]]}, {"id": "2106.09344", "submitter": "Claire Palmer Dr", "authors": "Claire Palmer, Ben Roullier, Muhammad Aamir, Leonardo Stella, Uchenna\n  Diala, Ashiq Anjum, Frank Mcquade, Keith Cox and Alex Calvert", "title": "Virtual Reality based Digital Twin System for remote laboratories and\n  online practical learning", "comments": "6 pages, 4 figures, accepted for publication ICMR2021 18th\n  International Conference in Manufacturing Research Virtual Conference hosted\n  by the University of Derby, UK 7 - 10 September 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  There is a need for remote learning and virtual learning applications such as\nvirtual reality (VR) and tablet-based solutions which the current pandemic has\ndemonstrated. Creating complex learning scenarios by developers is highly\ntime-consuming and can take over a year. There is a need to provide a simple\nmethod to enable lecturers to create their own content for their laboratory\ntutorials. Research is currently being undertaken into developing generic\nmodels to enable the semi-automatic creation of a virtual learning application.\nA case study describing the creation of a virtual learning application for an\nelectrical laboratory tutorial is presented.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 09:38:24 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Palmer", "Claire", ""], ["Roullier", "Ben", ""], ["Aamir", "Muhammad", ""], ["Stella", "Leonardo", ""], ["Diala", "Uchenna", ""], ["Anjum", "Ashiq", ""], ["Mcquade", "Frank", ""], ["Cox", "Keith", ""], ["Calvert", "Alex", ""]]}, {"id": "2106.09373", "submitter": "Jilin Hu", "authors": "Sean Bin Yang, Chenjuan Guo, Jilin Hu, Jian Tang, Bin Yang", "title": "Unsupervised Path Representation Learning with Curriculum Negative\n  Sampling", "comments": "This paper has been accepted by IJCAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Path representations are critical in a variety of transportation\napplications, such as estimating path ranking in path recommendation systems\nand estimating path travel time in navigation systems. Existing studies often\nlearn task-specific path representations in a supervised manner, which require\na large amount of labeled training data and generalize poorly to other tasks.\nWe propose an unsupervised learning framework Path InfoMax (PIM) to learn\ngeneric path representations that work for different downstream tasks. We first\npropose a curriculum negative sampling method, for each input path, to generate\na small amount of negative paths, by following the principles of curriculum\nlearning. Next, \\emph{PIM} employs mutual information maximization to learn\npath representations from both a global and a local view. In the global view,\nPIM distinguishes the representations of the input paths from those of the\nnegative paths. In the local view, \\emph{PIM} distinguishes the input path\nrepresentations from the representations of the nodes that appear only in the\nnegative paths. This enables the learned path representations to encode both\nglobal and local information at different scales. Extensive experiments on two\ndownstream tasks, ranking score estimation and travel time estimation, using\ntwo road network datasets suggest that PIM significantly outperforms other\nunsupervised methods and is also able to be used as a pre-training method to\nenhance supervised path representation learning.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 10:47:19 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Yang", "Sean Bin", ""], ["Guo", "Chenjuan", ""], ["Hu", "Jilin", ""], ["Tang", "Jian", ""], ["Yang", "Bin", ""]]}, {"id": "2106.09388", "submitter": "Yongchun Zhu", "authors": "Yongchun Zhu, Fuzhen Zhuang, Jindong Wang, Guolin Ke, Jingwu Chen,\n  Jiang Bian, Hui Xiong and Qing He", "title": "Deep Subdomain Adaptation Network for Image Classification", "comments": "published on TNNLS", "journal-ref": null, "doi": "10.1109/TNNLS.2020.2988928", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a target task where labeled data is unavailable, domain adaptation can\ntransfer a learner from a different source domain. Previous deep domain\nadaptation methods mainly learn a global domain shift, i.e., align the global\nsource and target distributions without considering the relationships between\ntwo subdomains within the same category of different domains, leading to\nunsatisfying transfer learning performance without capturing the fine-grained\ninformation. Recently, more and more researchers pay attention to Subdomain\nAdaptation which focuses on accurately aligning the distributions of the\nrelevant subdomains. However, most of them are adversarial methods which\ncontain several loss functions and converge slowly. Based on this, we present\nDeep Subdomain Adaptation Network (DSAN) which learns a transfer network by\naligning the relevant subdomain distributions of domain-specific layer\nactivations across different domains based on a local maximum mean discrepancy\n(LMMD). Our DSAN is very simple but effective which does not need adversarial\ntraining and converges fast. The adaptation can be achieved easily with most\nfeed-forward network models by extending them with LMMD loss, which can be\ntrained efficiently via back-propagation. Experiments demonstrate that DSAN can\nachieve remarkable results on both object recognition tasks and digit\nclassification tasks. Our code will be available at:\nhttps://github.com/easezyc/deep-transfer-learning\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 11:07:21 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Zhu", "Yongchun", ""], ["Zhuang", "Fuzhen", ""], ["Wang", "Jindong", ""], ["Ke", "Guolin", ""], ["Chen", "Jingwu", ""], ["Bian", "Jiang", ""], ["Xiong", "Hui", ""], ["He", "Qing", ""]]}, {"id": "2106.09402", "submitter": "Konda Reddy Mopuri", "authors": "Harsh Rangwani, Konda Reddy Mopuri, and R. Venkatesh Babu", "title": "Class Balancing GAN with a Classifier in the Loop", "comments": "UAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Generative Adversarial Networks (GANs) have swiftly evolved to imitate\nincreasingly complex image distributions. However, majority of the developments\nfocus on performance of GANs on balanced datasets. We find that the existing\nGANs and their training regimes which work well on balanced datasets fail to be\neffective in case of imbalanced (i.e. long-tailed) datasets. In this work we\nintroduce a novel theoretically motivated Class Balancing regularizer for\ntraining GANs. Our regularizer makes use of the knowledge from a pre-trained\nclassifier to ensure balanced learning of all the classes in the dataset. This\nis achieved via modelling the effective class frequency based on the\nexponential forgetting observed in neural networks and encouraging the GAN to\nfocus on underrepresented classes. We demonstrate the utility of our\nregularizer in learning representations for long-tailed distributions via\nachieving better performance than existing approaches over multiple datasets.\nSpecifically, when applied to an unconditional GAN, it improves the FID from\n$13.03$ to $9.01$ on the long-tailed iNaturalist-$2019$ dataset.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 11:41:30 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Rangwani", "Harsh", ""], ["Mopuri", "Konda Reddy", ""], ["Babu", "R. Venkatesh", ""]]}, {"id": "2106.09422", "submitter": "Chongkai Gao", "authors": "Chongkai Gao, Haichuan Gao, Shangqi Guo, Tianren Zhang, and Feng Chen", "title": "CRIL: Continual Robot Imitation Learning via Generative and Prediction\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Imitation learning (IL) algorithms have shown promising results for robots to\nlearn skills from expert demonstrations. However, they need multi-task\ndemonstrations to be provided at once for acquiring diverse skills, which is\ndifficult in real world. In this work we study how to realize continual\nimitation learning ability that empowers robots to continually learn new tasks\none by one, thus reducing the burden of multi-task IL and accelerating the\nprocess of new task learning at the same time. We propose a novel trajectory\ngeneration model that employs both a generative adversarial network and a\ndynamics-aware prediction model to generate pseudo trajectories from all\nlearned tasks in the new task learning process. Our experiments on both\nsimulation and real-world manipulation tasks demonstrate the effectiveness of\nour method.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 12:15:57 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 07:17:10 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Gao", "Chongkai", ""], ["Gao", "Haichuan", ""], ["Guo", "Shangqi", ""], ["Zhang", "Tianren", ""], ["Chen", "Feng", ""]]}, {"id": "2106.09424", "submitter": "Jacques Fleuriot", "authors": "Colleen E. Charlton and Michael Tin Chung Poon and Paul M. Brennan and\n  Jacques D. Fleuriot", "title": "Interpretable Machine Learning Classifiers for Brain Tumour Survival\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction of survival in patients diagnosed with a brain tumour is\nchallenging because of heterogeneous tumour behaviours and responses to\ntreatment. Better estimations of prognosis would support treatment planning and\npatient support. Advances in machine learning have informed development of\nclinical predictive models, but their integration into clinical practice is\nalmost non-existent. One reasons for this is the lack of interpretability of\nmodels. In this paper, we use a novel brain tumour dataset to compare two\ninterpretable rule list models against popular machine learning approaches for\nbrain tumour survival prediction. All models are quantitatively evaluated using\nstandard performance metrics. The rule lists are also qualitatively assessed\nfor their interpretability and clinical utility. The interpretability of the\nblack box machine learning models is evaluated using two post-hoc explanation\ntechniques, LIME and SHAP. Our results show that the rule lists were only\nslightly outperformed by the black box models. We demonstrate that rule list\nalgorithms produced simple decision lists that align with clinical expertise.\nBy comparison, post-hoc interpretability methods applied to black box models\nmay produce unreliable explanations of local model predictions. Model\ninterpretability is essential for understanding differences in predictive\nperformance and for integration into clinical practice.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 12:17:10 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Charlton", "Colleen E.", ""], ["Poon", "Michael Tin Chung", ""], ["Brennan", "Paul M.", ""], ["Fleuriot", "Jacques D.", ""]]}, {"id": "2106.09433", "submitter": "Zichen Ma", "authors": "Zichen Ma, Yu Lu, Zihan Lu, Wenye Li, Jinfeng Yi, Shuguang Cui", "title": "Towards Heterogeneous Clients with Elastic Federated Learning", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning involves training machine learning models over devices or\ndata silos, such as edge processors or data warehouses, while keeping the data\nlocal. Training in heterogeneous and potentially massive networks introduces\nbias into the system, which is originated from the non-IID data and the low\nparticipation rate in reality. In this paper, we propose Elastic Federated\nLearning (EFL), an unbiased algorithm to tackle the heterogeneity in the\nsystem, which makes the most informative parameters less volatile during\ntraining, and utilizes the incomplete local updates. It is an efficient and\neffective algorithm that compresses both upstream and downstream\ncommunications. Theoretically, the algorithm has convergence guarantee when\ntraining on the non-IID data at the low participation rate. Empirical\nexperiments corroborate the competitive performance of EFL framework on the\nrobustness and the efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 12:30:40 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Ma", "Zichen", ""], ["Lu", "Yu", ""], ["Lu", "Zihan", ""], ["Li", "Wenye", ""], ["Yi", "Jinfeng", ""], ["Cui", "Shuguang", ""]]}, {"id": "2106.09435", "submitter": "Luke Marris", "authors": "Luke Marris, Paul Muller, Marc Lanctot, Karl Tuyls, Thore Graepel", "title": "Multi-Agent Training beyond Zero-Sum with Correlated Equilibrium\n  Meta-Solvers", "comments": "ICML 2021, 9 pages, coded implementation available in\n  https://github.com/deepmind/open_spiel/ (jpsro.py in examples)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-player, constant-sum games are well studied in the literature, but there\nhas been limited progress outside of this setting. We propose Joint\nPolicy-Space Response Oracles (JPSRO), an algorithm for training agents in\nn-player, general-sum extensive form games, which provably converges to an\nequilibrium. We further suggest correlated equilibria (CE) as promising\nmeta-solvers, and propose a novel solution concept Maximum Gini Correlated\nEquilibrium (MGCE), a principled and computationally efficient family of\nsolutions for solving the correlated equilibrium selection problem. We conduct\nseveral experiments using CE meta-solvers for JPSRO and demonstrate convergence\non n-player, general-sum games.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 12:34:18 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 16:43:13 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Marris", "Luke", ""], ["Muller", "Paul", ""], ["Lanctot", "Marc", ""], ["Tuyls", "Karl", ""], ["Graepel", "Thore", ""]]}, {"id": "2106.09455", "submitter": "Annette Knoedler", "authors": "Michael Arnemann, Per Olof Beckemeier, Thomas Bertram, Michael Eder,\n  Maximilian Erschig, Matthias Feiner, Francisco Javier Fernandez Garcia,\n  Frederic Foerster, Ruediger Haas, Martin Kipfmueller, Jan Kotschenreuther,\n  Bernd Langer, Ivan Lozada Rodriguez, Thomas Meibert, Simon Ottenhaus, Stefan\n  Paschek, Lars Pfotzer, Michael Roth, Tim Schanz, Philip Scherer, Janine\n  Schwienke, Robin Tenscher-Philipp", "title": "Conference proceedings KI4Industry AI for SMEs -- the online congress\n  for practical entry into AI for SMEs", "comments": "Editors: Matthias Feiner and Manuel Schoellhorn, 72 pages, 48\n  figures, in German, Conference proceedings Ki4 Industry 79 pages in total", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Institute of Materials and Processes, IMP, of the University of Applied\nSciences in Karlsruhe, Germany in cooperation with VDI Verein Deutscher\nIngenieure e.V, AEN Automotive Engineering Network and their cooperation\npartners present their competences of AI-based solution approaches in the\nproduction engineering field. The online congress KI 4 Industry on November 12\nand 13, 2020, showed what opportunities the use of artificial intelligence\noffers for medium-sized manufacturing companies, SMEs, and where potential\nfields of application lie. The main purpose of KI 4 Industry is to increase the\ntransfer of knowledge, research and technology from universities to small and\nmedium-sized enterprises, to demystify the term AI and to encourage companies\nto use AI-based solutions in their own value chain or in their products.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 15:08:01 GMT"}, {"version": "v2", "created": "Mon, 5 Jul 2021 16:36:48 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Arnemann", "Michael", ""], ["Beckemeier", "Per Olof", ""], ["Bertram", "Thomas", ""], ["Eder", "Michael", ""], ["Erschig", "Maximilian", ""], ["Feiner", "Matthias", ""], ["Garcia", "Francisco Javier Fernandez", ""], ["Foerster", "Frederic", ""], ["Haas", "Ruediger", ""], ["Kipfmueller", "Martin", ""], ["Kotschenreuther", "Jan", ""], ["Langer", "Bernd", ""], ["Rodriguez", "Ivan Lozada", ""], ["Meibert", "Thomas", ""], ["Ottenhaus", "Simon", ""], ["Paschek", "Stefan", ""], ["Pfotzer", "Lars", ""], ["Roth", "Michael", ""], ["Schanz", "Tim", ""], ["Scherer", "Philip", ""], ["Schwienke", "Janine", ""], ["Tenscher-Philipp", "Robin", ""]]}, {"id": "2106.09461", "submitter": "Neel Gandhi Gandhi", "authors": "Neel Gandhi, Shakti Mishra", "title": "Modelling resource allocation in uncertain system environment through\n  deep reinforcement learning", "comments": "Accepted at IRMAS'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.RO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Reinforcement Learning has applications in field of mechatronics, robotics,\nand other resource-constrained control system. Problem of resource allocation\nis primarily solved using traditional predefined techniques and modern deep\nlearning methods. The drawback of predefined and most deep learning methods for\nresource allocation is failing to meet the requirements in cases of uncertain\nsystem environment. We can approach problem of resource allocation in uncertain\nsystem environment alongside following certain criteria using deep\nreinforcement learning. Also, reinforcement learning has ability for adapting\nto new uncertain environment for prolonged period of time. The paper provides a\ndetailed comparative analysis on various deep reinforcement learning methods by\napplying different components to modify architecture of reinforcement learning\nwith use of noisy layers, prioritized replay, bagging, duelling networks, and\nother related combination to obtain improvement in terms of performance and\nreduction of computational cost. The paper identifies problem of resource\nallocation in uncertain environment could be effectively solved using Noisy\nBagging duelling double deep Q network achieving efficiency of 97.7% by\nmaximizing reward with significant exploration in given simulated environment\nfor resource allocation.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 13:13:34 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Gandhi", "Neel", ""], ["Mishra", "Shakti", ""]]}, {"id": "2106.09474", "submitter": "Joseph Aylett-Bullock", "authors": "Joseph Aylett-Bullock, Simon Badger, Ryan Moodie", "title": "Optimising simulations for diphoton production at hadron colliders using\n  amplitude neural networks", "comments": "31 pages, 12 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-ph cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning technology has the potential to dramatically optimise event\ngeneration and simulations. We continue to investigate the use of neural\nnetworks to approximate matrix elements for high-multiplicity scattering\nprocesses. We focus on the case of loop-induced diphoton production through\ngluon fusion and develop a realistic simulation method that can be applied to\nhadron collider observables. Neural networks are trained using the one-loop\namplitudes implemented in the NJet C++ library and interfaced to the Sherpa\nMonte Carlo event generator where we perform a detailed study for $2\\to3$ and\n$2\\to4$ scattering problems. We also consider how the trained networks perform\nwhen varying the kinematic cuts effecting the phase space and the reliability\nof the neural network simulations.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 13:24:36 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 10:25:05 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Aylett-Bullock", "Joseph", ""], ["Badger", "Simon", ""], ["Moodie", "Ryan", ""]]}, {"id": "2106.09526", "submitter": "Mats Richter", "authors": "Mats L. Richter, Leila Malihi, Anne-Kathrin Patricia Windler, Ulf\n  Krumnack", "title": "Exploring the Properties and Evolution of Neural Network Eigenspaces\n  during Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we explore the information processing inside neural networks\nusing logistic regression probes \\cite{probes} and the saturation metric\n\\cite{featurespace_saturation}. We show that problem difficulty and neural\nnetwork capacity affect the predictive performance in an antagonistic manner,\nopening the possibility of detecting over- and under-parameterization of neural\nnetworks for a given task. We further show that the observed effects are\nindependent from previously reported pathological patterns like the ``tail\npattern'' described in \\cite{featurespace_saturation}. Finally we are able to\nshow that saturation patterns converge early during training, allowing for a\nquicker cycle time during analysis\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 14:18:12 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 07:44:38 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Richter", "Mats L.", ""], ["Malihi", "Leila", ""], ["Windler", "Anne-Kathrin Patricia", ""], ["Krumnack", "Ulf", ""]]}, {"id": "2106.09538", "submitter": "Johannes Kruse", "authors": "Johannes Kruse, Benjamin Sch\\\"afer, Dirk Witthaut", "title": "Exploring deterministic frequency deviations with explainable AI", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY physics.data-an", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deterministic frequency deviations (DFDs) critically affect power grid\nfrequency quality and power system stability. A better understanding of these\nevents is urgently needed as frequency deviations have been growing in the\nEuropean grid in recent years. DFDs are partially explained by the rapid\nadjustment of power generation following the intervals of electricity trading,\nbut this intuitive picture fails especially before and around noonday. In this\narticle, we provide a detailed analysis of DFDs and their relation to external\nfeatures using methods from explainable Artificial Intelligence. We establish a\nmachine learning model that well describes the daily cycle of DFDs and\nelucidate key interdependencies using SHapley Additive exPlanations (SHAP).\nThereby, we identify solar ramps as critical to explain patterns in the Rate of\nChange of Frequency (RoCoF).\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 08:30:33 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Kruse", "Johannes", ""], ["Sch\u00e4fer", "Benjamin", ""], ["Witthaut", "Dirk", ""]]}, {"id": "2106.09564", "submitter": "Pietro Gori", "authors": "Minhao Hu, Matthis Maillard, Ya Zhang, Tommaso Ciceri, Giammarco La\n  Barbera, Isabelle Bloch, Pietro Gori", "title": "Knowledge distillation from multi-modal to mono-modal segmentation\n  networks", "comments": "MICCAI 2020", "journal-ref": "MICCAI 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The joint use of multiple imaging modalities for medical image segmentation\nhas been widely studied in recent years. The fusion of information from\ndifferent modalities has demonstrated to improve the segmentation accuracy,\nwith respect to mono-modal segmentations, in several applications. However,\nacquiring multiple modalities is usually not possible in a clinical setting due\nto a limited number of physicians and scanners, and to limit costs and scan\ntime. Most of the time, only one modality is acquired. In this paper, we\npropose KD-Net, a framework to transfer knowledge from a trained multi-modal\nnetwork (teacher) to a mono-modal one (student). The proposed method is an\nadaptation of the generalized distillation framework where the student network\nis trained on a subset (1 modality) of the teacher's inputs (n modalities). We\nillustrate the effectiveness of the proposed framework in brain tumor\nsegmentation with the BraTS 2018 dataset. Using different architectures, we\nshow that the student network effectively learns from the teacher and always\noutperforms the baseline mono-modal network in terms of segmentation accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 14:46:57 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Hu", "Minhao", ""], ["Maillard", "Matthis", ""], ["Zhang", "Ya", ""], ["Ciceri", "Tommaso", ""], ["La Barbera", "Giammarco", ""], ["Bloch", "Isabelle", ""], ["Gori", "Pietro", ""]]}, {"id": "2106.09578", "submitter": "Prithviraj Ammanabrolu", "authors": "Prithviraj Ammanabrolu, Mark O. Riedl", "title": "Modeling Worlds in Text", "comments": "Preprint. Under review. Benchmark can be found at\n  https://github.com/JerichoWorld/JerichoWorld", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a dataset that enables the creation of learning agents that can\nbuild knowledge graph-based world models of interactive narratives. Interactive\nnarratives -- or text-adventure games -- are partially observable environments\nstructured as long puzzles or quests in which an agent perceives and interacts\nwith the world purely through textual natural language. Each individual game\ntypically contains hundreds of locations, characters, and objects -- each with\ntheir own unique descriptions -- providing an opportunity to study the problem\nof giving language-based agents the structured memory necessary to operate in\nsuch worlds. Our dataset provides 24198 mappings between rich natural language\nobservations and: (1) knowledge graphs that reflect the world state in the form\nof a map; (2) natural language actions that are guaranteed to cause a change in\nthat particular world state. The training data is collected across 27 games in\nmultiple genres and contains a further 7836 heldout instances over 9 additional\ngames in the test set. We further provide baseline models using rules-based,\nquestion-answering, and sequence learning approaches in addition to an analysis\nof the data and corresponding learning tasks.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 15:02:16 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Ammanabrolu", "Prithviraj", ""], ["Riedl", "Mark O.", ""]]}, {"id": "2106.09608", "submitter": "Prithviraj Ammanabrolu", "authors": "Prithviraj Ammanabrolu, Mark O. Riedl", "title": "Learning Knowledge Graph-based World Models of Textual Environments", "comments": "Preprint. Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  World models improve a learning agent's ability to efficiently operate in\ninteractive and situated environments. This work focuses on the task of\nbuilding world models of text-based game environments. Text-based games, or\ninteractive narratives, are reinforcement learning environments in which agents\nperceive and interact with the world using textual natural language. These\nenvironments contain long, multi-step puzzles or quests woven through a world\nthat is filled with hundreds of characters, locations, and objects. Our world\nmodel learns to simultaneously: (1) predict changes in the world caused by an\nagent's actions when representing the world as a knowledge graph; and (2)\ngenerate the set of contextually relevant natural language actions required to\noperate in the world. We frame this task as a Set of Sequences generation\nproblem by exploiting the inherent structure of knowledge graphs and actions\nand introduce both a transformer-based multi-task architecture and a loss\nfunction to train it. A zero-shot ablation study on never-before-seen textual\nworlds shows that our methodology significantly outperforms existing textual\nworld modeling techniques as well as the importance of each of our\ncontributions.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 15:45:54 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Ammanabrolu", "Prithviraj", ""], ["Riedl", "Mark O.", ""]]}, {"id": "2106.09643", "submitter": "Arpit Bansal", "authors": "Arpit Bansal, Micah Goldblum, Valeriia Cherepanova, Avi Schwarzschild,\n  C. Bayan Bruss, Tom Goldstein", "title": "MetaBalance: High-Performance Neural Networks for Class-Imbalanced Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class-imbalanced data, in which some classes contain far more samples than\nothers, is ubiquitous in real-world applications. Standard techniques for\nhandling class-imbalance usually work by training on a re-weighted loss or on\nre-balanced data. Unfortunately, training overparameterized neural networks on\nsuch objectives causes rapid memorization of minority class data. To avoid this\ntrap, we harness meta-learning, which uses both an ''outer-loop'' and an\n''inner-loop'' loss, each of which may be balanced using different strategies.\nWe evaluate our method, MetaBalance, on image classification, credit-card fraud\ndetection, loan default prediction, and facial recognition tasks with severely\nimbalanced data, and we find that MetaBalance outperforms a wide array of\npopular re-sampling strategies.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 16:42:50 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Bansal", "Arpit", ""], ["Goldblum", "Micah", ""], ["Cherepanova", "Valeriia", ""], ["Schwarzschild", "Avi", ""], ["Bruss", "C. Bayan", ""], ["Goldstein", "Tom", ""]]}, {"id": "2106.09645", "submitter": "Shuai Lin", "authors": "Shuai Lin, Pan Zhou, Zi-Yuan Hu, Shuojia Wang, Ruihui Zhao, Yefeng\n  Zheng, Liang Lin, Eric Xing, Xiaodan Liang", "title": "Prototypical Graph Contrastive Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Graph-level representations are critical in various real-world applications,\nsuch as predicting the properties of molecules. But in practice, precise graph\nannotations are generally very expensive and time-consuming. To address this\nissue, graph contrastive learning constructs instance discrimination task which\npulls together positive pairs (augmentation pairs of the same graph) and pushes\naway negative pairs (augmentation pairs of different graphs) for unsupervised\nrepresentation learning. However, since for a query, its negatives are\nuniformly sampled from all graphs, existing methods suffer from the critical\nsampling bias issue, i.e., the negatives likely having the same semantic\nstructure with the query, leading to performance degradation. To mitigate this\nsampling bias issue, in this paper, we propose a Prototypical Graph Contrastive\nLearning (PGCL) approach. Specifically, PGCL models the underlying semantic\nstructure of the graph data via clustering semantically similar graphs into the\nsame group, and simultaneously encourages the clustering consistency for\ndifferent augmentations of the same graph. Then given a query, it performs\nnegative sampling via drawing the graphs from those clusters that differ from\nthe cluster of query, which ensures the semantic difference between query and\nits negative samples. Moreover, for a query, PGCL further reweights its\nnegative samples based on the distance between their prototypes (cluster\ncentroids) and the query prototype such that those negatives having moderate\nprototype distance enjoy relatively large weights. This reweighting strategy is\nproved to be more effective than uniform sampling. Experimental results on\nvarious graph benchmarks testify the advantages of our PGCL over\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 16:45:31 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Lin", "Shuai", ""], ["Zhou", "Pan", ""], ["Hu", "Zi-Yuan", ""], ["Wang", "Shuojia", ""], ["Zhao", "Ruihui", ""], ["Zheng", "Yefeng", ""], ["Lin", "Liang", ""], ["Xing", "Eric", ""], ["Liang", "Xiaodan", ""]]}, {"id": "2106.09663", "submitter": "Zhize Li", "authors": "Zhize Li", "title": "A Short Note of PAGE: Optimal Convergence Rates for Nonconvex\n  Optimization", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we first recall the nonconvex problem setting and introduce the\noptimal PAGE algorithm (Li et al., ICML'21). Then we provide a simple and clean\nconvergence analysis of PAGE for achieving optimal convergence rates. Moreover,\nPAGE and its analysis can be easily adopted and generalized to other works. We\nhope that this note provides the insights and is helpful for future works.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 17:11:57 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Li", "Zhize", ""]]}, {"id": "2106.09671", "submitter": "Alexander Peysakhovich", "authors": "Alexander Peysakhovich, Leon Bottou", "title": "An Attract-Repel Decomposition of Undirected Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dot product latent space embedding is a common form of representation\nlearning in undirected graphs (e.g. social networks, co-occurrence networks).\nWe show that such models have problems dealing with 'intransitive' situations\nwhere A is linked to B, B is linked to C but A is not linked to C. Such\nsituations occur in social networks when opposites attract (heterophily) and in\nco-occurrence networks when there are substitute nodes (e.g. the presence of\nPepsi or Coke, but rarely both, in otherwise similar purchase baskets). We\npresent a simple expansion which we call the attract-repel (AR) decomposition:\na set of latent attributes on which similar nodes attract and another set of\nlatent attributes on which similar nodes repel. We demonstrate the AR\ndecomposition in real social networks and show that it can be used to measure\nthe amount of latent homophily and heterophily. In addition, it can be applied\nto co-occurrence networks to discover roles in teams and find substitutable\ningredients in recipes.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 17:23:56 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Peysakhovich", "Alexander", ""], ["Bottou", "Leon", ""]]}, {"id": "2106.09677", "submitter": "Mehdi Ghatee Dr.", "authors": "Mohammad Mahdi Bejani, Mehdi Ghatee", "title": "Adaptive Low-Rank Regularization with Damping Sequences to Restrict Lazy\n  Weights in Deep Networks", "comments": "Preprint of a paper submitted in Neural Networks, 27 Pages, 4 Tables\n  and 6 Figures. arXiv admin note: text overlap with arXiv:2005.01995", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Overfitting is one of the critical problems in deep neural networks. Many\nregularization schemes try to prevent overfitting blindly. However, they\ndecrease the convergence speed of training algorithms. Adaptive regularization\nschemes can solve overfitting more intelligently. They usually do not affect\nthe entire network weights. This paper detects a subset of the weighting layers\nthat cause overfitting. The overfitting recognizes by matrix and tensor\ncondition numbers. An adaptive regularization scheme entitled Adaptive Low-Rank\n(ALR) is proposed that converges a subset of the weighting layers to their\nLow-Rank Factorization (LRF). It happens by minimizing a new Tikhonov-based\nloss function. ALR also encourages lazy weights to contribute to the\nregularization when epochs grow up. It uses a damping sequence to increment\nlayer selection likelihood in the last generations. Thus before falling the\ntraining accuracy, ALR reduces the lazy weights and regularizes the network\nsubstantially. The experimental results show that ALR regularizes the deep\nnetworks well with high training speed and low resource usage.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 17:28:14 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Bejani", "Mohammad Mahdi", ""], ["Ghatee", "Mehdi", ""]]}, {"id": "2106.09678", "submitter": "Linxi Fan", "authors": "Linxi Fan, Guanzhi Wang, De-An Huang, Zhiding Yu, Li Fei-Fei, Yuke\n  Zhu, Anima Anandkumar", "title": "SECANT: Self-Expert Cloning for Zero-Shot Generalization of Visual\n  Policies", "comments": "ICML 2021. Website: https://linxifan.github.io/secant-site/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization has been a long-standing challenge for reinforcement learning\n(RL). Visual RL, in particular, can be easily distracted by irrelevant factors\nin high-dimensional observation space. In this work, we consider robust policy\nlearning which targets zero-shot generalization to unseen visual environments\nwith large distributional shift. We propose SECANT, a novel self-expert cloning\ntechnique that leverages image augmentation in two stages to decouple robust\nrepresentation learning from policy optimization. Specifically, an expert\npolicy is first trained by RL from scratch with weak augmentations. A student\nnetwork then learns to mimic the expert policy by supervised learning with\nstrong augmentations, making its representation more robust against visual\nvariations compared to the expert. Extensive experiments demonstrate that\nSECANT significantly advances the state of the art in zero-shot generalization\nacross 4 challenging domains. Our average reward improvements over prior SOTAs\nare: DeepMind Control (+26.5%), robotic manipulation (+337.8%), vision-based\nautonomous driving (+47.7%), and indoor object navigation (+15.8%). Code\nrelease and video are available at https://linxifan.github.io/secant-site/.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 17:28:18 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Fan", "Linxi", ""], ["Wang", "Guanzhi", ""], ["Huang", "De-An", ""], ["Yu", "Zhiding", ""], ["Fei-Fei", "Li", ""], ["Zhu", "Yuke", ""], ["Anandkumar", "Anima", ""]]}, {"id": "2106.09685", "submitter": "Edward J. Hu", "authors": "Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi\n  Li, Shean Wang, Weizhu Chen", "title": "LoRA: Low-Rank Adaptation of Large Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dominant paradigm of natural language processing consists of large-scale\npre-training on general domain data and adaptation to particular tasks or\ndomains. As we pre-train larger models, conventional fine-tuning, which\nretrains all model parameters, becomes less feasible. Using GPT-3 175B as an\nexample, deploying many independent instances of fine-tuned models, each with\n175B parameters, is extremely expensive. We propose Low-Rank Adaptation, or\nLoRA, which freezes the pre-trained model weights and injects trainable rank\ndecomposition matrices into each layer of the Transformer architecture, greatly\nreducing the number of trainable parameters for downstream tasks. For GPT-3,\nLoRA can reduce the number of trainable parameters by 10,000 times and the\ncomputation hardware requirement by 3 times compared to full fine-tuning. LoRA\nperforms on-par or better than fine-tuning in model quality on both GPT-3 and\nGPT-2, despite having fewer trainable parameters, a higher training throughput,\nand no additional inference latency. We also provide an empirical investigation\ninto rank-deficiency in language model adaptations, which sheds light on the\nefficacy of LoRA. We release our implementation in GPT-2 at\nhttps://github.com/microsoft/LoRA .\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 17:37:18 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Hu", "Edward J.", ""], ["Shen", "Yelong", ""], ["Wallis", "Phillip", ""], ["Allen-Zhu", "Zeyuan", ""], ["Li", "Yuanzhi", ""], ["Wang", "Shean", ""], ["Chen", "Weizhu", ""]]}, {"id": "2106.09686", "submitter": "Chengrun Yang", "authors": "Chengrun Yang, Ziyang Wu, Jerry Chee, Christopher De Sa, Madeleine\n  Udell", "title": "How Low Can We Go: Trading Memory for Error in Low-Precision Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Low-precision arithmetic trains deep learning models using less energy, less\nmemory and less time. However, we pay a price for the savings: lower precision\nmay yield larger round-off error and hence larger prediction error. As\napplications proliferate, users must choose which precision to use to train a\nnew model, and chip manufacturers must decide which precisions to manufacture.\nWe view these precision choices as a hyperparameter tuning problem, and borrow\nideas from meta-learning to learn the tradeoff between memory and error. In\nthis paper, we introduce Pareto Estimation to Pick the Perfect Precision\n(PEPPP). We use matrix factorization to find non-dominated configurations (the\nPareto frontier) with a limited number of network evaluations. For any given\nmemory budget, the precision that minimizes error is a point on this frontier.\nPractitioners can use the frontier to trade memory for error and choose the\nbest precision for their goals.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 17:38:07 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 04:55:09 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Yang", "Chengrun", ""], ["Wu", "Ziyang", ""], ["Chee", "Jerry", ""], ["De Sa", "Christopher", ""], ["Udell", "Madeleine", ""]]}, {"id": "2106.09692", "submitter": "Chathura Gamage", "authors": "Cheng Xue, Vimukthini Pinto, Chathura Gamage, Peng Zhang and Jochen\n  Renz", "title": "Hi-Phy: A Benchmark for Hierarchical Physical Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning about the behaviour of physical objects is a key capability of\nagents operating in physical worlds. Humans are very experienced in physical\nreasoning while it remains a major challenge for AI. To facilitate research\naddressing this problem, several benchmarks have been proposed recently.\nHowever, these benchmarks do not enable us to measure an agent's granular\nphysical reasoning capabilities when solving a complex reasoning task. In this\npaper, we propose a new benchmark for physical reasoning that allows us to test\nindividual physical reasoning capabilities. Inspired by how humans acquire\nthese capabilities, we propose a general hierarchy of physical reasoning\ncapabilities with increasing complexity. Our benchmark tests capabilities\naccording to this hierarchy through generated physical reasoning tasks in the\nvideo game Angry Birds. This benchmark enables us to conduct a comprehensive\nagent evaluation by measuring the agent's granular physical reasoning\ncapabilities. We conduct an evaluation with human players, learning agents, and\nheuristic agents and determine their capabilities. Our evaluation shows that\nlearning agents, with good local generalization ability, still struggle to\nlearn the underlying physical reasoning capabilities and perform worse than\ncurrent state-of-the-art heuristic agents and humans. We believe that this\nbenchmark will encourage researchers to develop intelligent agents with\nadvanced, human-like physical reasoning capabilities. URL:\nhttps://github.com/Cheng-Xue/Hi-Phy\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 17:46:50 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Xue", "Cheng", ""], ["Pinto", "Vimukthini", ""], ["Gamage", "Chathura", ""], ["Zhang", "Peng", ""], ["Renz", "Jochen", ""]]}, {"id": "2106.09693", "submitter": "Koushik Biswas", "authors": "Koushik Biswas, Shilpak Banerjee, Ashish Kumar Pandey", "title": "Orthogonal-Pad\\'e Activation Functions: Trainable Activation functions\n  for smooth and faster convergence in deep networks", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have proposed orthogonal-Pad\\'e activation functions, which are trainable\nactivation functions and show that they have faster learning capability and\nimproves the accuracy in standard deep learning datasets and models. Based on\nour experiments, we have found two best candidates out of six orthogonal-Pad\\'e\nactivations, which we call safe Hermite-Pade (HP) activation functions, namely\nHP-1 and HP-2. When compared to ReLU, HP-1 and HP-2 has an increment in top-1\naccuracy by 5.06% and 4.63% respectively in PreActResNet-34, by 3.02% and 2.75%\nrespectively in MobileNet V2 model on CIFAR100 dataset while on CIFAR10 dataset\ntop-1 accuracy increases by 2.02% and 1.78% respectively in PreActResNet-34, by\n2.24% and 2.06% respectively in LeNet, by 2.15% and 2.03% respectively in\nEfficientnet B0.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 17:47:01 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Biswas", "Koushik", ""], ["Banerjee", "Shilpak", ""], ["Pandey", "Ashish Kumar", ""]]}, {"id": "2106.09749", "submitter": "Teshan Liyanage", "authors": "Teshan Liyanage, Subha Fernando", "title": "Optimizing robotic swarm based construction tasks", "comments": "4 pages, 3 figures, submitted to 2021 7th International Conference on\n  Control, Automation and Robotics (ICCAR) Singapore", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social insects in nature such as ants, termites and bees construct their\ncolonies collaboratively in a very efficient process. In these swarms, each\ninsect contributes to the construction task individually showing redundant and\nparallel behavior of individual entities. But the robotics adaptations of these\nswarm's behaviors haven't yet made it to the real world at a large enough scale\nof commonly being used due to the limitations in the existing approaches to the\nswarm robotics construction. This paper presents an approach that combines the\nexisting swarm construction approaches which results in a swarm robotic system,\ncapable of constructing a given 2 dimensional shape in an optimized manner.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 18:07:01 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Liyanage", "Teshan", ""], ["Fernando", "Subha", ""]]}, {"id": "2106.09756", "submitter": "Haiping Lu", "authors": "Haiping Lu, Xianyuan Liu, Robert Turner, Peizhen Bai, Raivo E Koot,\n  Shuo Zhou, Mustafa Chasmai, Lawrence Schobs", "title": "PyKale: Knowledge-Aware Machine Learning from Multiple Sources in Python", "comments": "This library is available at https://github.com/pykale/pykale", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is a general-purpose technology holding promises for many\ninterdisciplinary research problems. However, significant barriers exist in\ncrossing disciplinary boundaries when most machine learning tools are developed\nin different areas separately. We present Pykale - a Python library for\nknowledge-aware machine learning on graphs, images, texts, and videos to enable\nand accelerate interdisciplinary research. We formulate new green machine\nlearning guidelines based on standard software engineering practices and\npropose a novel pipeline-based application programming interface (API). PyKale\nfocuses on leveraging knowledge from multiple sources for accurate and\ninterpretable prediction, thus supporting multimodal learning and transfer\nlearning (particularly domain adaptation) with latest deep learning and\ndimensionality reduction models. We build PyKale on PyTorch and leverage the\nrich PyTorch ecosystem. Our pipeline-based API design enforces standardization\nand minimalism, embracing green machine learning concepts via reducing\nrepetitions and redundancy, reusing existing resources, and recycling learning\nmodels across areas. We demonstrate its interdisciplinary nature via examples\nin bioinformatics, knowledge graph, image/video recognition, and medical\nimaging.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 18:35:37 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Lu", "Haiping", ""], ["Liu", "Xianyuan", ""], ["Turner", "Robert", ""], ["Bai", "Peizhen", ""], ["Koot", "Raivo E", ""], ["Zhou", "Shuo", ""], ["Chasmai", "Mustafa", ""], ["Schobs", "Lawrence", ""]]}, {"id": "2106.09757", "submitter": "Imme Ebert-Uphoff", "authors": "Imme Ebert-Uphoff, Ryan Lagerquist, Kyle Hilburn, Yoonjin Lee,\n  Katherine Haynes, Jason Stock, Christina Kumler, and Jebb Q. Stewart", "title": "CIRA Guide to Custom Loss Functions for Neural Networks in Environmental\n  Sciences -- Version 1", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI physics.ao-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural networks are increasingly used in environmental science applications.\nFurthermore, neural network models are trained by minimizing a loss function,\nand it is crucial to choose the loss function very carefully for environmental\nscience applications, as it determines what exactly is being optimized.\nStandard loss functions do not cover all the needs of the environmental\nsciences, which makes it important for scientists to be able to develop their\nown custom loss functions so that they can implement many of the classic\nperformance measures already developed in environmental science, including\nmeasures developed for spatial model verification. However, there are very few\nresources available that cover the basics of custom loss function development\ncomprehensively, and to the best of our knowledge none that focus on the needs\nof environmental scientists. This document seeks to fill this gap by providing\na guide on how to write custom loss functions targeted toward environmental\nscience applications. Topics include the basics of writing custom loss\nfunctions, common pitfalls, functions to use in loss functions, examples such\nas fractions skill score as loss function, how to incorporate physical\nconstraints, discrete and soft discretization, and concepts such as focal,\nrobust, and adaptive loss. While examples are currently provided in this guide\nfor Python with Keras and the TensorFlow backend, the basic concepts also apply\nto other environments, such as Python with PyTorch. Similarly, while the sample\nloss functions provided here are from meteorology, these are just examples of\nhow to create custom loss functions. Other fields in the environmental sciences\nhave very similar needs for custom loss functions, e.g., for evaluating spatial\nforecasts effectively, and the concepts discussed here can be applied there as\nwell. All code samples are provided in a GitHub repository.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 18:37:50 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Ebert-Uphoff", "Imme", ""], ["Lagerquist", "Ryan", ""], ["Hilburn", "Kyle", ""], ["Lee", "Yoonjin", ""], ["Haynes", "Katherine", ""], ["Stock", "Jason", ""], ["Kumler", "Christina", ""], ["Stewart", "Jebb Q.", ""]]}, {"id": "2106.09761", "submitter": "Miles Cranmer", "authors": "Miles Cranmer (Princeton), Peter Melchior (Princeton), Brian Nord\n  (Fermilab)", "title": "Unsupervised Resource Allocation with Graph Neural Networks", "comments": "Accepted to PMLR/contributed oral at NeurIPS 2020 Pre-registration\n  Workshop. Code at https://github.com/MilesCranmer/gnn_resource_allocation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG astro-ph.CO astro-ph.IM cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach for maximizing a global utility function by learning\nhow to allocate resources in an unsupervised way. We expect interactions\nbetween allocation targets to be important and therefore propose to learn the\nreward structure for near-optimal allocation policies with a GNN. By relaxing\nthe resource constraint, we can employ gradient-based optimization in contrast\nto more standard evolutionary algorithms. Our algorithm is motivated by a\nproblem in modern astronomy, where one needs to select-based on limited initial\ninformation-among $10^9$ galaxies those whose detailed measurement will lead to\noptimal inference of the composition of the universe. Our technique presents a\nway of flexibly learning an allocation strategy by only requiring forward\nsimulators for the physics of interest and the measurement process. We\nanticipate that our technique will also find applications in a range of\nresource allocation problems.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 18:44:04 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Cranmer", "Miles", "", "Princeton"], ["Melchior", "Peter", "", "Princeton"], ["Nord", "Brian", "", "Fermilab"]]}, {"id": "2106.09762", "submitter": "Gianluca Detommaso", "authors": "Gianluca Detommaso, Michael Br\\\"uckner, Philip Schulz, Victor\n  Chernozhukov", "title": "Causal Bias Quantification for Continuous Treatment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we develop a novel characterization of marginal causal effect\nand causal bias in the continuous treatment setting. We show they can be\nexpressed as an expectation with respect to a conditional probability\ndistribution, which can be estimated via standard statistical and probabilistic\nmethods. All terms in the expectations can be computed via automatic\ndifferentiation, also for highly non-linear models. We further develop a new\ncomplete criterion for identifiability of causal effects via covariate\nadjustment, showing the bias equals zero if the criterion is met. We study the\neffectiveness of our framework in three different scenarios: linear models\nunder confounding, overcontrol and endogenous selection bias; a non-linear\nmodel where full identifiability cannot be achieved because of missing data; a\nsimulated medical study of statins and atherosclerotic cardiovascular disease.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 18:44:48 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Detommaso", "Gianluca", ""], ["Br\u00fcckner", "Michael", ""], ["Schulz", "Philip", ""], ["Chernozhukov", "Victor", ""]]}, {"id": "2106.09764", "submitter": "F.P.J. Nijweide", "authors": "R.R. Mauritz, F.P.J. Nijweide, J. Goseling, M. van Keulen", "title": "Autoencoder-based cleaning in probabilistic databases", "comments": "Submitted to ACM Journal of Data and Information Quality, Special\n  Issue on Deep Learning for Data Quality", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of data integration, data quality problems are often encountered\nwhen extracting, combining, and merging data. The probabilistic data\nintegration approach represents information about such problems as\nuncertainties in a probabilistic database. In this paper, we propose a\ndata-cleaning autoencoder capable of near-automatic data quality improvement.\nIt learns the structure and dependencies in the data to identify and correct\ndoubtful values. A theoretical framework is provided, and experiments show that\nit can remove significant amounts of noise from categorical and numeric\nprobabilistic data. Our method does not require clean data. We do, however,\nshow that manually cleaning a small fraction of the data significantly improves\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 18:46:56 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Mauritz", "R. R.", ""], ["Nijweide", "F. P. J.", ""], ["Goseling", "J.", ""], ["van Keulen", "M.", ""]]}, {"id": "2106.09776", "submitter": "John Martin Jr", "authors": "John D. Martin and Joseph Modayil", "title": "Adapting the Function Approximation Architecture in Online Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of a reinforcement learning (RL) system depends on the\ncomputational architecture used to approximate a value function. Deep learning\nmethods provide both optimization techniques and architectures for\napproximating nonlinear functions from noisy, high-dimensional observations.\nHowever, prevailing optimization techniques are not designed for\nstrictly-incremental online updates. Nor are standard architectures designed\nfor observations with an a priori unknown structure: for example, light sensors\nrandomly dispersed in space. This paper proposes an online RL prediction\nalgorithm with an adaptive architecture that efficiently finds useful nonlinear\nfeatures. The algorithm is evaluated in a spatial domain with high-dimensional,\nstochastic observations. The algorithm outperforms non-adaptive baseline\narchitectures and approaches the performance of an architecture given\nside-channel information. These results are a step towards scalable RL\nalgorithms for more general problems, where the observation structure is not\navailable.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 19:33:26 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Martin", "John D.", ""], ["Modayil", "Joseph", ""]]}, {"id": "2106.09785", "submitter": "Chunyuan Li", "authors": "Chunyuan Li, Jianwei Yang, Pengchuan Zhang, Mei Gao, Bin Xiao, Xiyang\n  Dai, Lu Yuan, Jianfeng Gao", "title": "Efficient Self-supervised Vision Transformers for Representation\n  Learning", "comments": "24 pages, 12 figures, file size 13.6MB", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates two techniques for developing efficient\nself-supervised vision transformers (EsViT) for visual representation learning.\nFirst, we show through a comprehensive empirical study that multi-stage\narchitectures with sparse self-attentions can significantly reduce modeling\ncomplexity but with a cost of losing the ability to capture fine-grained\ncorrespondences between image regions. Second, we propose a new pre-training\ntask of region matching which allows the model to capture fine-grained region\ndependencies and as a result significantly improves the quality of the learned\nvision representations. Our results show that combining the two techniques,\nEsViT achieves 81.3% top-1 on the ImageNet linear probe evaluation,\noutperforming prior arts with around an order magnitude of higher throughput.\nWhen transferring to downstream linear classification tasks, EsViT outperforms\nits supervised counterpart on 17 out of 18 datasets. The code and models will\nbe publicly available.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 19:57:33 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Li", "Chunyuan", ""], ["Yang", "Jianwei", ""], ["Zhang", "Pengchuan", ""], ["Gao", "Mei", ""], ["Xiao", "Bin", ""], ["Dai", "Xiyang", ""], ["Yuan", "Lu", ""], ["Gao", "Jianfeng", ""]]}, {"id": "2106.09790", "submitter": "Elsbeth Turcan", "authors": "Elsbeth Turcan, Shuai Wang, Rishita Anubhai, Kasturi Bhattacharjee,\n  Yaser Al-Onaizan, Smaranda Muresan", "title": "Multi-Task Learning and Adapted Knowledge Models for Emotion-Cause\n  Extraction", "comments": "15 pages, 6 figures. Findings of ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting what emotions are expressed in text is a well-studied problem in\nnatural language processing. However, research on finer grained emotion\nanalysis such as what causes an emotion is still in its infancy. We present\nsolutions that tackle both emotion recognition and emotion cause detection in a\njoint fashion. Considering that common-sense knowledge plays an important role\nin understanding implicitly expressed emotions and the reasons for those\nemotions, we propose novel methods that combine common-sense knowledge via\nadapted knowledge models with multi-task learning to perform joint emotion\nclassification and emotion cause tagging. We show performance improvement on\nboth tasks when including common-sense reasoning and a multitask framework. We\nprovide a thorough analysis to gain insights into model performance.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 20:11:04 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Turcan", "Elsbeth", ""], ["Wang", "Shuai", ""], ["Anubhai", "Rishita", ""], ["Bhattacharjee", "Kasturi", ""], ["Al-Onaizan", "Yaser", ""], ["Muresan", "Smaranda", ""]]}, {"id": "2106.09795", "submitter": "Sairam Gurajada", "authors": "Hang Jiang, Sairam Gurajada, Qiuhao Lu, Sumit Neelam, Lucian Popa,\n  Prithviraj Sen, Yunyao Li, Alexander Gray", "title": "LNN-EL: A Neuro-Symbolic Approach to Short-text Entity Linking", "comments": "Accepted to ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity linking (EL), the task of disambiguating mentions in text by linking\nthem to entities in a knowledge graph, is crucial for text understanding,\nquestion answering or conversational systems. Entity linking on short text\n(e.g., single sentence or question) poses particular challenges due to limited\ncontext. While prior approaches use either heuristics or black-box neural\nmethods, here we propose LNN-EL, a neuro-symbolic approach that combines the\nadvantages of using interpretable rules based on first-order logic with the\nperformance of neural learning. Even though constrained to using rules, LNN-EL\nperforms competitively against SotA black-box neural approaches, with the added\nbenefits of extensibility and transferability. In particular, we show that we\ncan easily blend existing rule templates given by a human expert, with multiple\ntypes of features (priors, BERT encodings, box embeddings, etc), and even\nscores resulting from previous EL methods, thus improving on such methods. For\ninstance, on the LC-QuAD-1.0 dataset, we show more than $4$\\% increase in F1\nscore over previous SotA. Finally, we show that the inductive bias offered by\nusing logic results in learned rules that transfer well across datasets, even\nwithout fine tuning, while maintaining high accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 20:22:45 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Jiang", "Hang", ""], ["Gurajada", "Sairam", ""], ["Lu", "Qiuhao", ""], ["Neelam", "Sumit", ""], ["Popa", "Lucian", ""], ["Sen", "Prithviraj", ""], ["Li", "Yunyao", ""], ["Gray", "Alexander", ""]]}, {"id": "2106.09812", "submitter": "Hrithwik Shalu", "authors": "Joseph Stember, Hrithwik Shalu", "title": "Deep reinforcement learning with automated label extraction from\n  clinical reports accurately classifies 3D MRI brain volumes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: Image classification is perhaps the most fundamental task in imaging\nAI. However, labeling images is time-consuming and tedious. We have recently\ndemonstrated that reinforcement learning (RL) can classify 2D slices of MRI\nbrain images with high accuracy. Here we make two important steps toward\nspeeding image classification: Firstly, we automatically extract class labels\nfrom the clinical reports. Secondly, we extend our prior 2D classification work\nto fully 3D image volumes from our institution. Hence, we proceed as follows:\nin Part 1, we extract labels from reports automatically using the SBERT natural\nlanguage processing approach. Then, in Part 2, we use these labels with RL to\ntrain a classification Deep-Q Network (DQN) for 3D image volumes.\n  Methods: For Part 1, we trained SBERT with 90 radiology report impressions.\nWe then used the trained SBERT to predict class labels for use in Part 2. In\nPart 2, we applied multi-step image classification to allow for combined Deep-Q\nlearning using 3D convolutions and TD(0) Q learning. We trained on a set of 90\nimages. We tested on a separate set of 61 images, again using the classes\npredicted from patient reports by the trained SBERT in Part 1. For comparison,\nwe also trained and tested a supervised deep learning classification network on\nthe same set of training and testing images using the same labels.\n  Results: Part 1: Upon training with the corpus of radiology reports, the\nSBERT model had 100% accuracy for both normal and metastasis-containing scans.\nPart 2: Then, using these labels, whereas the supervised approach quickly\noverfit the training data and as expected performed poorly on the testing set\n(66% accuracy, just over random guessing), the reinforcement learning approach\nachieved an accuracy of 92%. The results were found to be statistically\nsignificant, with a p-value of 3.1 x 10^-5.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 20:53:41 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Stember", "Joseph", ""], ["Shalu", "Hrithwik", ""]]}, {"id": "2106.09825", "submitter": "Keyang He", "authors": "Keyang He, Prashant Doshi, Bikramjit Banerjee", "title": "Many Agent Reinforcement Learning Under Partial Observability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent renewed interest in multi-agent reinforcement learning (MARL) has\ngenerated an impressive array of techniques that leverage deep reinforcement\nlearning, primarily actor-critic architectures, and can be applied to a limited\nrange of settings in terms of observability and communication. However, a\ncontinuing limitation of much of this work is the curse of dimensionality when\nit comes to representations based on joint actions, which grow exponentially\nwith the number of agents. In this paper, we squarely focus on this challenge\nof scalability. We apply the key insight of action anonymity, which leads to\npermutation invariance of joint actions, to two recently presented deep MARL\nalgorithms, MADDPG and IA2C, and compare these instantiations to another recent\ntechnique that leverages action anonymity, viz., mean-field MARL. We show that\nour instantiations can learn the optimal behavior in a broader class of agent\nnetworks than the mean-field method, using a recently introduced pragmatic\ndomain.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 21:24:29 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["He", "Keyang", ""], ["Doshi", "Prashant", ""], ["Banerjee", "Bikramjit", ""]]}, {"id": "2106.09847", "submitter": "Shehroze Khan", "authors": "Shehroze Khan and James R. Wright", "title": "Disinformation, Stochastic Harm, and Costly Filtering: A Principal-Agent\n  Analysis of Regulating Social Media Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spread of disinformation on social media platforms such as Facebook is\nharmful to society. This harm can take the form of a gradual degradation of\npublic discourse; but it can also take the form of sudden dramatic events such\nas the recent insurrection on Capitol Hill. The platforms themselves are in the\nbest position to prevent the spread of disinformation, as they have the best\naccess to relevant data and the expertise to use it. However, filtering\ndisinformation is costly, not only for implementing filtering algorithms or\nemploying manual filtering effort, but also because removing such highly viral\ncontent impacts user growth and thus potential advertising revenue. Since the\ncosts of harmful content are borne by other entities, the platform will\ntherefore have no incentive to filter at a socially-optimal level. This problem\nis similar to the problem of environmental regulation, in which the costs of\nadverse events are not directly borne by a firm, the mitigation effort of a\nfirm is not observable, and the causal link between a harmful consequence and a\nspecific failure is difficult to prove. In the environmental regulation domain,\none solution to this issue is to perform costly monitoring to ensure that the\nfirm takes adequate precautions according a specified rule. However,\nclassifying disinformation is performative, and thus a fixed rule becomes less\neffective over time. Encoding our domain as a Markov decision process, we\ndemonstrate that no penalty based on a static rule, no matter how large, can\nincentivize adequate filtering by the platform. Penalties based on an adaptive\nrule can incentivize optimal effort, but counterintuitively, only if the\nregulator sufficiently overreacts to harmful events by requiring a\ngreater-than-optimal level of filtering.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 23:27:43 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Khan", "Shehroze", ""], ["Wright", "James R.", ""]]}, {"id": "2106.09857", "submitter": "Xiaolong Ma", "authors": "Xiaolong Ma, Minghai Qin, Fei Sun, Zejiang Hou, Kun Yuan, Yi Xu,\n  Yanzhi Wang, Yen-Kuang Chen, Rong Jin, Yuan Xie", "title": "Effective Model Sparsification by Scheduled Grow-and-Prune Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks (DNNs) are effective in solving many real-world\nproblems. Larger DNN models usually exhibit better quality (e.g., accuracy) but\ntheir excessive computation results in long training and inference time. Model\nsparsification can reduce the computation and memory cost while maintaining\nmodel quality. Most existing sparsification algorithms unidirectionally remove\nweights, while others randomly or greedily explore a small subset of weights in\neach layer. The inefficiency of the algorithms reduces the achievable sparsity\nlevel. In addition, many algorithms still require pre-trained dense models and\nthus suffer from large memory footprint and long training time. In this paper,\nwe propose a novel scheduled grow-and-prune (GaP) methodology without\npre-training the dense models. It addresses the shortcomings of the previous\nworks by repeatedly growing a subset of layers to dense and then pruning back\nto sparse after some training. Experiments have shown that such models can\nmatch or beat the quality of highly optimized dense models at 80% sparsity on a\nvariety of tasks, such as image classification, objective detection, 3D object\npart segmentation, and translation. They also outperform other state-of-the-art\n(SOTA) pruning methods, including pruning from pre-trained dense models. As an\nexample, a 90% sparse ResNet-50 obtained via GaP achieves 77.9% top-1 accuracy\non ImageNet, improving the SOTA results by 1.5%.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 01:03:13 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Ma", "Xiaolong", ""], ["Qin", "Minghai", ""], ["Sun", "Fei", ""], ["Hou", "Zejiang", ""], ["Yuan", "Kun", ""], ["Xu", "Yi", ""], ["Wang", "Yanzhi", ""], ["Chen", "Yen-Kuang", ""], ["Jin", "Rong", ""], ["Xie", "Yuan", ""]]}, {"id": "2106.09874", "submitter": "Zhao Kang", "authors": "Zhengrui Ma, Zhao Kang, Guangchun Luo, Ling Tian", "title": "Towards Clustering-friendly Representations: Subspace Clustering via\n  Graph Filtering", "comments": "Published in ACM Multimedia 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Finding a suitable data representation for a specific task has been shown to\nbe crucial in many applications. The success of subspace clustering depends on\nthe assumption that the data can be separated into different subspaces.\nHowever, this simple assumption does not always hold since the raw data might\nnot be separable into subspaces. To recover the ``clustering-friendly''\nrepresentation and facilitate the subsequent clustering, we propose a graph\nfiltering approach by which a smooth representation is achieved. Specifically,\nit injects graph similarity into data features by applying a low-pass filter to\nextract useful data representations for clustering. Extensive experiments on\nimage and document clustering datasets demonstrate that our method improves\nupon state-of-the-art subspace clustering techniques. Especially, its\ncomparable performance with deep learning methods emphasizes the effectiveness\nof the simple graph filtering scheme for many real-world applications. An\nablation study shows that graph filtering can remove noise, preserve structure\nin the image, and increase the separability of classes.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 02:21:36 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Ma", "Zhengrui", ""], ["Kang", "Zhao", ""], ["Luo", "Guangchun", ""], ["Tian", "Ling", ""]]}, {"id": "2106.09875", "submitter": "Zhao Kang", "authors": "Peng Chen, Liang Liu, Zhengrui Ma, Zhao Kang", "title": "Smoothed Multi-View Subspace Clustering", "comments": "Accepted by International Conference on Neural Computing for Advanced\n  Applications 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In recent years, multi-view subspace clustering has achieved impressive\nperformance due to the exploitation of complementary imformation across\nmultiple views. However, multi-view data can be very complicated and are not\neasy to cluster in real-world applications. Most existing methods operate on\nraw data and may not obtain the optimal solution. In this work, we propose a\nnovel multi-view clustering method named smoothed multi-view subspace\nclustering (SMVSC) by employing a novel technique, i.e., graph filtering, to\nobtain a smooth representation for each view, in which similar data points have\nsimilar feature values. Specifically, it retains the graph geometric features\nthrough applying a low-pass filter. Consequently, it produces a\n``clustering-friendly\" representation and greatly facilitates the downstream\nclustering task. Extensive experiments on benchmark datasets validate the\nsuperiority of our approach. Analysis shows that graph filtering increases the\nseparability of classes.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 02:24:19 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Chen", "Peng", ""], ["Liu", "Liang", ""], ["Ma", "Zhengrui", ""], ["Kang", "Zhao", ""]]}, {"id": "2106.09885", "submitter": "Ruchao Fan", "authors": "Ruchao Fan, Wei Chu, Peng Chang, Jing Xiao and Abeer Alwan", "title": "An Improved Single Step Non-autoregressive Transformer for Automatic\n  Speech Recognition", "comments": "Accepted to Interspeech2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-autoregressive mechanisms can significantly decrease inference time for\nspeech transformers, especially when the single step variant is applied.\nPrevious work on CTC alignment-based single step non-autoregressive transformer\n(CASS-NAT) has shown a large real time factor (RTF) improvement over\nautoregressive transformers (AT). In this work, we propose several methods to\nimprove the accuracy of the end-to-end CASS-NAT, followed by performance\nanalyses. First, convolution augmented self-attention blocks are applied to\nboth the encoder and decoder modules. Second, we propose to expand the trigger\nmask (acoustic boundary) for each token to increase the robustness of CTC\nalignments. In addition, iterated loss functions are used to enhance the\ngradient update of low-layer parameters. Without using an external language\nmodel, the WERs of the improved CASS-NAT, when using the three methods, are\n3.1%/7.2% on Librispeech test clean/other sets and the CER is 5.4% on the\nAishell1 test set, achieving a 7%~21% relative WER/CER improvement. For the\nanalyses, we plot attention weight distributions in the decoders to visualize\nthe relationships between token-level acoustic embeddings. When the acoustic\nembeddings are visualized, we find that they have a similar behavior to word\nembeddings, which explains why the improved CASS-NAT performs similarly to AT.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 02:58:30 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 00:56:50 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Fan", "Ruchao", ""], ["Chu", "Wei", ""], ["Chang", "Peng", ""], ["Xiao", "Jing", ""], ["Alwan", "Abeer", ""]]}, {"id": "2106.09910", "submitter": "Xing Gao", "authors": "Xing Gao, Wenrui Dai, Chenglin Li, Junni Zou, Hongkai Xiong, Pascal\n  Frossard", "title": "Message Passing in Graph Convolution Networks via Adaptive Filter Banks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolution networks, like message passing graph convolution networks\n(MPGCNs), have been a powerful tool in representation learning of networked\ndata. However, when data is heterogeneous, most architectures are limited as\nthey employ a single strategy to handle multi-channel graph signals and they\ntypically focus on low-frequency information. In this paper, we present a novel\ngraph convolution operator, termed BankGCN, which keeps benefits of message\npassing models, but extends their capabilities beyond `low-pass' features. It\ndecomposes multi-channel signals on graphs into subspaces and handles\nparticular information in each subspace with an adapted filter. The filters of\nall subspaces have different frequency responses and together form a filter\nbank. Furthermore, each filter in the spectral domain corresponds to a message\npassing scheme, and diverse schemes are implemented via the filter bank.\nImportantly, the filter bank and the signal decomposition are jointly learned\nto adapt to the spectral characteristics of data and to target applications.\nFurthermore, this is implemented almost without extra parameters in comparison\nwith most existing MPGCNs. Experimental results show that the proposed\nconvolution operator permits to achieve excellent performance in graph\nclassification on a collection of benchmark graph datasets.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 04:23:34 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Gao", "Xing", ""], ["Dai", "Wenrui", ""], ["Li", "Chenglin", ""], ["Zou", "Junni", ""], ["Xiong", "Hongkai", ""], ["Frossard", "Pascal", ""]]}, {"id": "2106.09920", "submitter": "Richard Nock", "authors": "Richard Nock, Tyler Sypherd, Lalitha Sankar", "title": "Being Properly Improper", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In today's ML, data can be twisted (changed) in various ways, either for bad\nor good intent. Such twisted data challenges the founding theory of properness\nfor supervised losses which form the basis for many popular losses for class\nprobability estimation. Unfortunately, at its core, properness ensures that the\noptimal models also learn the twist. In this paper, we analyse such class\nprobability-based losses when they are stripped off the mandatory properness;\nwe define twist-proper losses as losses formally able to retrieve the optimum\n(untwisted) estimate off the twists, and show that a natural extension of a\nhalf-century old loss introduced by S. Arimoto is twist proper. We then turn to\na theory that has provided some of the best off-the-shelf algorithms for proper\nlosses, boosting. Boosting can require access to the derivative of the convex\nconjugate of a loss to compute examples weights. Such a function can be hard to\nget, for computational or mathematical reasons; this turns out to be the case\nfor Arimoto's loss. We bypass this difficulty by inverting the problem as\nfollows: suppose a blueprint boosting algorithm is implemented with a general\nweight update function. What are the losses for which boosting-compliant\nminimisation happens? Our answer comes as a general boosting algorithm which\nmeets the optimal boosting dependence on the number of calls to the weak\nlearner; when applied to Arimoto's loss, it leads to a simple optimisation\nalgorithm whose performances are showcased on several domains and twists.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 05:00:15 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Nock", "Richard", ""], ["Sypherd", "Tyler", ""], ["Sankar", "Lalitha", ""]]}, {"id": "2106.09923", "submitter": "Soroush Vosoughi Dr", "authors": "Lili Wang, Chongyang Gao, Chenghan Huang, Ruibo Liu, Weicheng Ma,\n  Soroush Vosoughi", "title": "Embedding Heterogeneous Networks into Hyperbolic Space Without Meta-path", "comments": "In proceedings of the 35th AAAI Conference on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Networks found in the real-world are numerous and varied. A common type of\nnetwork is the heterogeneous network, where the nodes (and edges) can be of\ndifferent types. Accordingly, there have been efforts at learning\nrepresentations of these heterogeneous networks in low-dimensional space.\nHowever, most of the existing heterogeneous network embedding methods suffer\nfrom the following two drawbacks: (1) The target space is usually Euclidean.\nConversely, many recent works have shown that complex networks may have\nhyperbolic latent anatomy, which is non-Euclidean. (2) These methods usually\nrely on meta-paths, which require domain-specific prior knowledge for meta-path\nselection. Additionally, different down-streaming tasks on the same network\nmight require different meta-paths in order to generate task-specific\nembeddings. In this paper, we propose a novel self-guided random walk method\nthat does not require meta-path for embedding heterogeneous networks into\nhyperbolic space. We conduct thorough experiments for the tasks of network\nreconstruction and link prediction on two public datasets, showing that our\nmodel outperforms a variety of well-known baselines across all tasks.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 05:24:13 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Wang", "Lili", ""], ["Gao", "Chongyang", ""], ["Huang", "Chenghan", ""], ["Liu", "Ruibo", ""], ["Ma", "Weicheng", ""], ["Vosoughi", "Soroush", ""]]}, {"id": "2106.09938", "submitter": "Dongqi Han", "authors": "Dongqi Han, Kenji Doya and Jun Tani", "title": "Goal-Directed Planning by Reinforcement Learning and Active Inference", "comments": "Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What is the difference between goal-directed and habitual behavior? We\npropose a novel computational framework of decision making with Bayesian\ninference, in which everything is integrated as an entire neural network model.\nThe model learns to predict environmental state transitions by self-exploration\nand generating motor actions by sampling stochastic internal states ${z}$.\nHabitual behavior, which is obtained from the prior distribution of ${z}$, is\nacquired by reinforcement learning. Goal-directed behavior is determined from\nthe posterior distribution of ${z}$ by planning, using active inference which\noptimizes the past, current and future ${z}$ by minimizing the variational free\nenergy for the desired future observation constrained by the observed sensory\nsequence. We demonstrate the effectiveness of the proposed framework by\nexperiments in a sensorimotor navigation task with camera observations and\ncontinuous motor actions.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 06:41:01 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 10:14:01 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Han", "Dongqi", ""], ["Doya", "Kenji", ""], ["Tani", "Jun", ""]]}, {"id": "2106.09946", "submitter": "Sauptik Dhar", "authors": "Sauptik Dhar, Javad Heydari, Samarth Tripathi, Unmesh Kurup, Mohak\n  Shah", "title": "Evolving GANs: When Contradictions Turn into Compliance", "comments": "Generative Adversarial Networks, Universum Learning, Semi-Supervised\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Limited availability of labeled-data makes any supervised learning problem\nchallenging. Alternative learning settings like semi-supervised and universum\nlearning alleviate the dependency on labeled data, but still require a large\namount of unlabeled data, which may be unavailable or expensive to acquire.\nGAN-based synthetic data generation methods have recently shown promise by\ngenerating synthetic samples to improve task at hand. However, these samples\ncannot be used for other purposes. In this paper, we propose a GAN game which\nprovides improved discriminator accuracy under limited data settings, while\ngenerating realistic synthetic data. This provides the added advantage that now\nthe generated data can be used for other similar tasks. We provide the\ntheoretical guarantees and empirical results in support of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 06:51:35 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Dhar", "Sauptik", ""], ["Heydari", "Javad", ""], ["Tripathi", "Samarth", ""], ["Kurup", "Unmesh", ""], ["Shah", "Mohak", ""]]}, {"id": "2106.09951", "submitter": "I\\~nigo Martinez", "authors": "I\\~nigo Martinez and Elisabeth Viles and I\\~naki Cabrejas", "title": "Labelling Drifts in a Fault Detection System for Wind Turbine\n  Maintenance", "comments": "11 pages, 2 figures, 1 table", "journal-ref": "Intelligent Distributed Computing XII, 2018,", "doi": "10.1007/978-3-319-99626-4_13", "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A failure detection system is the first step towards predictive maintenance\nstrategies. A popular data-driven method to detect incipient failures and\nanomalies is the training of normal behaviour models by applying a machine\nlearning technique like feed-forward neural networks (FFNN) or extreme learning\nmachines (ELM). However, the performance of any of these modelling techniques\ncan be deteriorated by the unexpected rise of non-stationarities in the dynamic\nenvironment in which industrial assets operate. This unpredictable statistical\nchange in the measured variable is known as concept drift. In this article a\nwind turbine maintenance case is presented, where non-stationarities of various\nkinds can happen unexpectedly. Such concept drift events are desired to be\ndetected by means of statistical detectors and window-based approaches.\nHowever, in real complex systems, concept drifts are not as clear and evident\nas in artificially generated datasets. In order to evaluate the effectiveness\nof current drift detectors and also to design an appropriate novel technique\nfor this specific industrial application, it is essential to dispose beforehand\nof a characterization of the existent drifts. Under the lack of information in\nthis regard, a methodology for labelling concept drift events in the lifetime\nof wind turbines is proposed. This methodology will facilitate the creation of\na drift database that will serve both as a training ground for concept drift\ndetectors and as a valuable information to enhance the knowledge about\nmaintenance of complex systems.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 07:14:14 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Martinez", "I\u00f1igo", ""], ["Viles", "Elisabeth", ""], ["Cabrejas", "I\u00f1aki", ""]]}, {"id": "2106.09958", "submitter": "Chengwei Chen", "authors": "Chengwei Chen, Yuan Xie, Shaohui Lin, Ruizhi Qiao, Jian Zhou, Xin Tan,\n  Yi Zhang and Lizhuang Ma", "title": "Novelty Detection via Contrastive Learning with Negative Data\n  Augmentation", "comments": null, "journal-ref": "IJCAI2021", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novelty detection is the process of determining whether a query example\ndiffers from the learned training distribution. Previous methods attempt to\nlearn the representation of the normal samples via generative adversarial\nnetworks (GANs). However, they will suffer from instability training, mode\ndropping, and low discriminative ability. Recently, various pretext tasks (e.g.\nrotation prediction and clustering) have been proposed for self-supervised\nlearning in novelty detection. However, the learned latent features are still\nlow discriminative. We overcome such problems by introducing a novel\ndecoder-encoder framework. Firstly, a generative network (a.k.a. decoder)\nlearns the representation by mapping the initialized latent vector to an image.\nIn particular, this vector is initialized by considering the entire\ndistribution of training data to avoid the problem of mode-dropping. Secondly,\na contrastive network (a.k.a. encoder) aims to ``learn to compare'' through\nmutual information estimation, which directly helps the generative network to\nobtain a more discriminative representation by using a negative data\naugmentation strategy. Extensive experiments show that our model has\nsignificant superiority over cutting-edge novelty detectors and achieves new\nstate-of-the-art results on some novelty detection benchmarks, e.g. CIFAR10 and\nDCASE. Moreover, our model is more stable for training in a non-adversarial\nmanner, compared to other adversarial based novelty detection methods.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 07:26:15 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Chen", "Chengwei", ""], ["Xie", "Yuan", ""], ["Lin", "Shaohui", ""], ["Qiao", "Ruizhi", ""], ["Zhou", "Jian", ""], ["Tan", "Xin", ""], ["Zhang", "Yi", ""], ["Ma", "Lizhuang", ""]]}, {"id": "2106.09973", "submitter": "Chenjun Xiao", "authors": "Chenjun Xiao, Ilbin Lee, Bo Dai, Dale Schuurmans, Csaba Szepesvari", "title": "On the Sample Complexity of Batch Reinforcement Learning with\n  Policy-Induced Data", "comments": "26 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the fundamental question of the sample complexity of learning a good\npolicy in finite Markov decision processes (MDPs) when the data available for\nlearning is obtained by following a logging policy that must be chosen without\nknowledge of the underlying MDP. Our main results show that the sample\ncomplexity, the minimum number of transitions necessary and sufficient to\nobtain a good policy, is an exponential function of the relevant quantities\nwhen the planning horizon $H$ is finite. In particular, we prove that the\nsample complexity of obtaining $\\epsilon$-optimal policies is at least\n$\\Omega(\\mathrm{A}^{\\min(\\mathrm{S}-1, H+1)})$ for $\\gamma$-discounted\nproblems, where $\\mathrm{S}$ is the number of states, $\\mathrm{A}$ is the\nnumber of actions, and $H$ is the effective horizon defined as $H=\\lfloor\n\\tfrac{\\ln(1/\\epsilon)}{\\ln(1/\\gamma)} \\rfloor$; and it is at least\n$\\Omega(\\mathrm{A}^{\\min(\\mathrm{S}-1, H)}/\\varepsilon^2)$ for finite horizon\nproblems, where $H$ is the planning horizon of the problem. This lower bound is\nessentially matched by an upper bound. For the average-reward setting we show\nthat there is no algorithm finding $\\epsilon$-optimal policies with a finite\namount of data.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 07:54:23 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Xiao", "Chenjun", ""], ["Lee", "Ilbin", ""], ["Dai", "Bo", ""], ["Schuurmans", "Dale", ""], ["Szepesvari", "Csaba", ""]]}, {"id": "2106.09992", "submitter": "Martin Pawelczyk", "authors": "Martin Pawelczyk, Shalmali Joshi, Chirag Agarwal, Sohini Upadhyay,\n  Himabindu Lakkaraju", "title": "On the Connections between Counterfactual Explanations and Adversarial\n  Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Counterfactual explanations and adversarial examples have emerged as critical\nresearch areas for addressing the explainability and robustness goals of\nmachine learning (ML). While counterfactual explanations were developed with\nthe goal of providing recourse to individuals adversely impacted by algorithmic\ndecisions, adversarial examples were designed to expose the vulnerabilities of\nML models. While prior research has hinted at the commonalities between these\nframeworks, there has been little to no work on systematically exploring the\nconnections between the literature on counterfactual explanations and\nadversarial examples. In this work, we make one of the first attempts at\nformalizing the connections between counterfactual explanations and adversarial\nexamples. More specifically, we theoretically analyze salient counterfactual\nexplanation and adversarial example generation methods, and highlight the\nconditions under which they behave similarly. Our analysis demonstrates that\nseveral popular counterfactual explanation and adversarial example generation\nmethods such as the ones proposed by Wachter et. al. and Carlini and Wagner\n(with mean squared error loss), and C-CHVAE and natural adversarial examples by\nZhao et. al. are equivalent. We also bound the distance between counterfactual\nexplanations and adversarial examples generated by Wachter et. al. and DeepFool\nmethods for linear models. Finally, we empirically validate our theoretical\nfindings using extensive experimentation with synthetic and real world\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 08:22:24 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Pawelczyk", "Martin", ""], ["Joshi", "Shalmali", ""], ["Agarwal", "Chirag", ""], ["Upadhyay", "Sohini", ""], ["Lakkaraju", "Himabindu", ""]]}, {"id": "2106.10015", "submitter": "Anil Yaman", "authors": "Anil Yaman, Nicolas Bredeche, Onur \\c{C}aylak, Joel Z. Leibo, Sang Wan\n  Lee", "title": "Meta-control of social learning strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social learning, copying other's behavior without actual experience, offers a\ncost-effective means of knowledge acquisition. However, it raises the\nfundamental question of which individuals have reliable information: successful\nindividuals versus the majority. The former and the latter are known\nrespectively as success-based and conformist social learning strategies. We\nshow here that while the success-based strategy fully exploits the benign\nenvironment of low uncertainly, it fails in uncertain environments. On the\nother hand, the conformist strategy can effectively mitigate this adverse\neffect. Based on these findings, we hypothesized that meta-control of\nindividual and social learning strategies provides effective and\nsample-efficient learning in volatile and uncertain environments. Simulations\non a set of environments with various levels of volatility and uncertainty\nconfirmed our hypothesis. The results imply that meta-control of social\nlearning affords agents the leverage to resolve environmental uncertainty with\nminimal exploration cost, by exploiting others' learning as an external\nknowledge base.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 09:17:21 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Yaman", "Anil", ""], ["Bredeche", "Nicolas", ""], ["\u00c7aylak", "Onur", ""], ["Leibo", "Joel Z.", ""], ["Lee", "Sang Wan", ""]]}, {"id": "2106.10060", "submitter": "Chintan Trivedi", "authors": "Chintan Trivedi, Antonios Liapis and Georgios N. Yannakakis", "title": "Contrastive Learning of Generalized Game Representations", "comments": "8 pages, 7 figures, CoG", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representing games through their pixels offers a promising approach for\nbuilding general-purpose and versatile game models. While games are not merely\nimages, neural network models trained on game pixels often capture differences\nof the visual style of the image rather than the content of the game. As a\nresult, such models cannot generalize well even within similar games of the\nsame genre. In this paper we build on recent advances in contrastive learning\nand showcase its benefits for representation learning in games. Learning to\ncontrast images of games not only classifies games in a more efficient manner;\nit also yields models that separate games in a more meaningful fashion by\nignoring the visual style and focusing, instead, on their content. Our results\nin a large dataset of sports video games containing 100k images across 175\ngames and 10 game genres suggest that contrastive learning is better suited for\nlearning generalized game representations compared to conventional supervised\nlearning. The findings of this study bring us closer to universal visual\nencoders for games that can be reused across previously unseen games without\nrequiring retraining or fine-tuning.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 11:17:54 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Trivedi", "Chintan", ""], ["Liapis", "Antonios", ""], ["Yannakakis", "Georgios N.", ""]]}, {"id": "2106.10075", "submitter": "Stefan Sylvius Wagner", "authors": "Stefan Wagner and Michael Janschek and Tobias Uelwer and Stefan\n  Harmeling", "title": "Learning to Plan via a Multi-Step Policy Regression Method", "comments": "Accepted at the 30th International Conference on Artificial Neural\n  Networks (ICANN 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach to increase inference performance in environments\nthat require a specific sequence of actions in order to be solved. This is for\nexample the case for maze environments where ideally an optimal path is\ndetermined. Instead of learning a policy for a single step, we want to learn a\npolicy that can predict n actions in advance. Our proposed method called policy\nhorizon regression (PHR) uses knowledge of the environment sampled by A2C to\nlearn an n dimensional policy vector in a policy distillation setup which\nyields n sequential actions per observation. We test our method on the MiniGrid\nand Pong environments and show drastic speedup during inference time by\nsuccessfully predicting sequences of actions on a single observation.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 11:51:49 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Wagner", "Stefan", ""], ["Janschek", "Michael", ""], ["Uelwer", "Tobias", ""], ["Harmeling", "Stefan", ""]]}, {"id": "2106.10076", "submitter": "Rui Song", "authors": "Rui Song, Xingbing Chen, Zelong Liu, Haining An, Zhiqi Zhang,\n  Xiaoguang Wang, Hao Xu", "title": "Label Mask for Multi-Label Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": "21", "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the key problems in multi-label text classification is how to take\nadvantage of the correlation among labels. However, it is very challenging to\ndirectly model the correlations among labels in a complex and unknown label\nspace. In this paper, we propose a Label Mask multi-label text classification\nmodel (LM-MTC), which is inspired by the idea of cloze questions of language\nmodel. LM-MTC is able to capture implicit relationships among labels through\nthe powerful ability of pre-train language models. On the basis, we assign a\ndifferent token to each potential label, and randomly mask the token with a\ncertain probability to build a label based Masked Language Model (MLM). We\ntrain the MTC and MLM together, further improving the generalization ability of\nthe model. A large number of experiments on multiple datasets demonstrate the\neffectiveness of our method.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 11:54:33 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Song", "Rui", ""], ["Chen", "Xingbing", ""], ["Liu", "Zelong", ""], ["An", "Haining", ""], ["Zhang", "Zhiqi", ""], ["Wang", "Xiaoguang", ""], ["Xu", "Hao", ""]]}, {"id": "2106.10090", "submitter": "Ayush K. Rai", "authors": "Ayush K Rai, Tarun Krishna, Julia Dietlmeier, Kevin McGuinness, Alan F\n  Smeaton, Noel E O'Connor", "title": "Discerning Generic Event Boundaries in Long-Form Wild Videos", "comments": "Technical Report for Generic Event Boundary Challenge - LOVEU\n  Challenge (CVPR 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Detecting generic, taxonomy-free event boundaries invideos represents a major\nstride forward towards holisticvideo understanding. In this paper we present a\ntechnique forgeneric event boundary detection based on a two stream in-flated\n3D convolutions architecture, which can learn spatio-temporal features from\nvideos. Our work is inspired from theGeneric Event Boundary Detection Challenge\n(part of CVPR2021 Long Form Video Understanding- LOVEU Workshop).Throughout the\npaper we provide an in-depth analysis ofthe experiments performed along with an\ninterpretation ofthe results obtained.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 12:28:19 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Rai", "Ayush K", ""], ["Krishna", "Tarun", ""], ["Dietlmeier", "Julia", ""], ["McGuinness", "Kevin", ""], ["Smeaton", "Alan F", ""], ["O'Connor", "Noel E", ""]]}, {"id": "2106.10110", "submitter": "Fangwei Zhong", "authors": "Fangwei Zhong, Peng Sun, Wenhan Luo, Tingyun Yan, Yizhou Wang", "title": "Towards Distraction-Robust Active Visual Tracking", "comments": "To appear in ICML2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In active visual tracking, it is notoriously difficult when distracting\nobjects appear, as distractors often mislead the tracker by occluding the\ntarget or bringing a confusing appearance. To address this issue, we propose a\nmixed cooperative-competitive multi-agent game, where a target and multiple\ndistractors form a collaborative team to play against a tracker and make it\nfail to follow. Through learning in our game, diverse distracting behaviors of\nthe distractors naturally emerge, thereby exposing the tracker's weakness,\nwhich helps enhance the distraction-robustness of the tracker. For effective\nlearning, we then present a bunch of practical methods, including a reward\nfunction for distractors, a cross-modal teacher-student learning strategy, and\na recurrent attention mechanism for the tracker. The experimental results show\nthat our tracker performs desired distraction-robust active visual tracking and\ncan be well generalized to unseen environments. We also show that the\nmulti-agent game can be used to adversarially test the robustness of trackers.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 13:05:25 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Zhong", "Fangwei", ""], ["Sun", "Peng", ""], ["Luo", "Wenhan", ""], ["Yan", "Tingyun", ""], ["Wang", "Yizhou", ""]]}, {"id": "2106.10138", "submitter": "Jaco Van De Pol", "authors": "Irfansha Shaik, Jaco van de Pol", "title": "Classical Planning as QBF without Grounding (extended version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most classical planners use grounding as a preprocessing step, reducing\nplanning to propositional logic. However, grounding comes with a severe cost in\nmemory, resulting in large encodings for SAT/QBF based planners. Despite the\noptimisations in SAT/QBF encodings such as action splitting, compact encodings\nand using parallel plans, the memory usage due to grounding remains a\nbottleneck when actions have many parameters, such as in the Organic Synthesis\nproblems from the IPC 2018 planning competition (in its original non-split\nform).\n  In this paper, we provide a compact QBF encoding that is logarithmic in the\nnumber of objects and avoids grounding completely by using universal\nquantification for object combinations. We compare the ungrounded QBF encoding\nwith the simple SAT encoding and also show that we can solve some of the\nOrganic Synthesis problems, which could not be handled before by any SAT/QBF\nbased planners due to grounding.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 14:06:57 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Shaik", "Irfansha", ""], ["van de Pol", "Jaco", ""]]}, {"id": "2106.10156", "submitter": "Rosana Rego", "authors": "Rosana C. B. Rego, Ver\\^onica M. L. Silva", "title": "Predicting gender of Brazilian names using deep learning", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting gender by the name is not a simple task. In many applications,\nespecially in the natural language processing (NLP) field, this task may be\nnecessary, mainly when considering foreign names. Some machine learning\nalgorithms can satisfactorily perform the prediction. In this paper, we\nexamined and implemented feedforward and recurrent deep neural network models,\nsuch as MLP, RNN, GRU, CNN, and BiLSTM, to classify gender through the first\nname. A dataset of Brazilian names is used to train and evaluate the models. We\nanalyzed the accuracy, recall, precision, and confusion matrix to measure the\nmodels' performances. The results indicate that the gender prediction can be\nperformed from the feature extraction strategy looking at the names as a set of\nstrings. Some models accurately predict the gender in more than 90% of the\ncases. The recurrent models overcome the feedforward models in this binary\nclassification problem.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 14:45:59 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Rego", "Rosana C. B.", ""], ["Silva", "Ver\u00f4nica M. L.", ""]]}, {"id": "2106.10160", "submitter": "Jibinraj Antony", "authors": "Jibinraj Antony, Dr. Florian Schlather, Georgij Safronov, Markus\n  Schmitz, Prof. Dr. Kristof Van Laerhoven", "title": "Toward Fault Detection in Industrial Welding Processes with Deep\n  Learning and Data Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the rise of deep learning models in the field of computer vision, new\npossibilities for their application in industrial processes proves to return\ngreat benefits. Nevertheless, the actual fit of machine learning for highly\nstandardised industrial processes is still under debate. This paper addresses\nthe challenges on the industrial realization of the AI tools, considering the\nuse case of Laser Beam Welding quality control as an example. We use object\ndetection algorithms from the TensorFlow object detection API and adapt them to\nour use case using transfer learning. The baseline models we develop are used\nas benchmarks and evaluated and compared to models that undergo dataset scaling\nand hyperparameter tuning. We find that moderate scaling of the dataset via\nimage augmentation leads to improvements in intersection over union (IoU) and\nrecall, whereas high levels of augmentation and scaling may lead to\ndeterioration of results. Finally, we put our results into perspective of the\nunderlying use case and evaluate their fit.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 14:52:49 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Antony", "Jibinraj", ""], ["Schlather", "Dr. Florian", ""], ["Safronov", "Georgij", ""], ["Schmitz", "Markus", ""], ["Van Laerhoven", "Prof. Dr. Kristof", ""]]}, {"id": "2106.10165", "submitter": "Sho Yaida", "authors": "Daniel A. Roberts, Sho Yaida, Boris Hanin", "title": "The Principles of Deep Learning Theory", "comments": "451 pages, to be published by Cambridge University Press", "journal-ref": null, "doi": null, "report-no": "MIT-CTP/5306", "categories": "cs.LG cs.AI hep-th stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This book develops an effective theory approach to understanding deep neural\nnetworks of practical relevance. Beginning from a first-principles\ncomponent-level picture of networks, we explain how to determine an accurate\ndescription of the output of trained networks by solving layer-to-layer\niteration equations and nonlinear learning dynamics. A main result is that the\npredictions of networks are described by nearly-Gaussian distributions, with\nthe depth-to-width aspect ratio of the network controlling the deviations from\nthe infinite-width Gaussian description. We explain how these effectively-deep\nnetworks learn nontrivial representations from training and more broadly\nanalyze the mechanism of representation learning for nonlinear models. From a\nnearly-kernel-methods perspective, we find that the dependence of such models'\npredictions on the underlying learning algorithm can be expressed in a simple\nand universal way. To obtain these results, we develop the notion of\nrepresentation group flow (RG flow) to characterize the propagation of signals\nthrough the network. By tuning networks to criticality, we give a practical\nsolution to the exploding and vanishing gradient problem. We further explain\nhow RG flow leads to near-universal behavior and lets us categorize networks\nbuilt from different activation functions into universality classes.\nAltogether, we show that the depth-to-width ratio governs the effective model\ncomplexity of the ensemble of trained networks. By using information-theoretic\ntechniques, we estimate the optimal aspect ratio at which we expect the network\nto be practically most useful and show how residual connections can be used to\npush this scale to arbitrary depths. With these tools, we can learn in detail\nabout the inductive bias of architectures, hyperparameters, and optimizers.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 15:00:00 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Roberts", "Daniel A.", ""], ["Yaida", "Sho", ""], ["Hanin", "Boris", ""]]}, {"id": "2106.10176", "submitter": "Shu Cheng Li", "authors": "Shucheng Li, Fengyuan Xu, Runchuan Wang, Sheng Zhong", "title": "Self-supervised Incremental Deep Graph Learning for Ethereum Phishing\n  Scam Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, phishing scams have become the crime type with the largest\nmoney involved on Ethereum, the second-largest blockchain platform. Meanwhile,\ngraph neural network (GNN) has shown promising performance in various node\nclassification tasks. However, for Ethereum transaction data, which could be\nnaturally abstracted to a real-world complex graph, the scarcity of labels and\nthe huge volume of transaction data make it difficult to take advantage of GNN\nmethods. Here in this paper, to address the two challenges, we propose a\nSelf-supervised Incremental deep Graph learning model (SIEGE), for the phishing\nscam detection problem on Ethereum. In our model, two pretext tasks designed\nfrom spatial and temporal perspectives help us effectively learn useful node\nembedding from the huge amount of unlabelled transaction data. And the\nincremental paradigm allows us to efficiently handle large-scale transaction\ndata and help the model maintain good performance when the data distribution is\ndrastically changing. We collect transaction records about half a year from\nEthereum and our extensive experiments show that our model consistently\noutperforms strong baselines in both transductive and inductive settings.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 15:06:26 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Li", "Shucheng", ""], ["Xu", "Fengyuan", ""], ["Wang", "Runchuan", ""], ["Zhong", "Sheng", ""]]}, {"id": "2106.10191", "submitter": "David Watson", "authors": "David S. Watson", "title": "Rational Shapley Values", "comments": "20 pages, 3 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Explaining the predictions of opaque machine learning algorithms is an\nimportant and challenging task, especially as complex models are increasingly\nused to assist in high-stakes decisions such as those arising in healthcare and\nfinance. Most popular tools for post-hoc explainable artificial intelligence\n(XAI) are either insensitive to context (e.g., feature attributions) or\ndifficult to summarize (e.g., counterfactuals). In this paper, I introduce\n\\emph{rational Shapley values}, a novel XAI method that synthesizes and extends\nthese seemingly incompatible approaches in a rigorous, flexible manner. I\nleverage tools from decision theory and causal modeling to formalize and\nimplement a pragmatic approach that resolves a number of known challenges in\nXAI. By pairing the distribution of random variables with the appropriate\nreference class for a given explanation task, I illustrate through theory and\nexperiments how user goals and knowledge can inform and constrain the solution\nset in an iterative fashion. The method compares favorably to state of the art\nXAI tools in a range of quantitative and qualitative comparisons.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 15:45:21 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Watson", "David S.", ""]]}, {"id": "2106.10192", "submitter": "Muhammad Najib", "authors": "Julian Gutierrez, Muhammad Najib, Giuseppe Perelli, Michael Wooldridge", "title": "Equilibrium Design for Concurrent Games", "comments": "CONCUR 2019 with appendix", "journal-ref": "Vol. 140, 2019, 22:1--22:16", "doi": "10.4230/LIPIcs.CONCUR.2019.22", "report-no": null, "categories": "cs.GT cs.AI cs.LO cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In game theory, mechanism design is concerned with the design of incentives\nso that a desired outcome of the game can be achieved. In this paper, we study\nthe design of incentives so that a desirable equilibrium is obtained, for\ninstance, an equilibrium satisfying a given temporal logic property -- a\nproblem that we call equilibrium design. We base our study on a framework where\nsystem specifications are represented as temporal logic formulae, games as\nquantitative concurrent game structures, and players' goals as mean-payoff\nobjectives. In particular, we consider system specifications given by LTL and\nGR(1) formulae, and show that implementing a mechanism to ensure that a given\ntemporal logic property is satisfied on some/every Nash equilibrium of the\ngame, whenever such a mechanism exists, can be done in PSPACE for LTL\nproperties and in NP/$\\Sigma^{P}_{2}$ for GR(1) specifications. We also study\nthe complexity of various related decision and optimisation problems, such as\noptimality and uniqueness of solutions, and show that the complexities of all\nsuch problems lie within the polynomial hierarchy. As an application,\nequilibrium design can be used as an alternative solution to the rational\nsynthesis and verification problems for concurrent games with mean-payoff\nobjectives whenever no solution exists, or as a technique to repair, whenever\npossible, concurrent games with undesirable rational outcomes (Nash equilibria)\nin an optimal way.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 15:45:45 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Gutierrez", "Julian", ""], ["Najib", "Muhammad", ""], ["Perelli", "Giuseppe", ""], ["Wooldridge", "Michael", ""]]}, {"id": "2106.10197", "submitter": "Muhammad Monjurul Karim", "authors": "Muhammad Monjurul Karim, Yu Li, Ruwen Qin, Zhaozheng Yin", "title": "A Dynamic Spatial-temporal Attention Network for Early Anticipation of\n  Traffic Accidents", "comments": "10 pages, 4 figures, submitted to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, autonomous vehicles and those equipped with an Advanced Driver\nAssistance System (ADAS) are emerging. They share the road with regular ones\noperated by human drivers entirely. To ensure guaranteed safety for passengers\nand other road users, it becomes essential for autonomous vehicles and ADAS to\nanticipate traffic accidents from natural driving scenes. The dynamic\nspatial-temporal interaction of the traffic agents is complex, and visual cues\nfor predicting a future accident are embedded deeply in dashcam video data.\nTherefore, early anticipation of traffic accidents remains a challenge. To this\nend, the paper presents a dynamic spatial-temporal attention (DSTA) network for\nearly anticipation of traffic accidents from dashcam videos. The proposed\nDSTA-network learns to select discriminative temporal segments of a video\nsequence with a module named Dynamic Temporal Attention (DTA). It also learns\nto focus on the informative spatial regions of frames with another module named\nDynamic Spatial Attention (DSA). The spatial-temporal relational features of\naccidents, along with scene appearance features, are learned jointly with a\nGated Recurrent Unit (GRU) network. The experimental evaluation of the\nDSTA-network on two benchmark datasets confirms that it has exceeded the\nstate-of-the-art performance. A thorough ablation study evaluates the\ncontributions of individual components of the DSTA-network, revealing how the\nnetwork achieves such performance. Furthermore, this paper proposes a new\nstrategy that fuses the prediction scores from two complementary models and\nverifies its effectiveness in further boosting the performance of early\naccident anticipation.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 15:58:53 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Karim", "Muhammad Monjurul", ""], ["Li", "Yu", ""], ["Qin", "Ruwen", ""], ["Yin", "Zhaozheng", ""]]}, {"id": "2106.10202", "submitter": "Florian Beck", "authors": "Florian Beck and Johannes F\\\"urnkranz", "title": "An Investigation into Mini-Batch Rule Learning", "comments": null, "journal-ref": "2nd Workshop on Deep Continuous-Discrete Machine Learning\n  (DeCoDeML), ECML-PKDD 2020, Ghent, Belgium", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate whether it is possible to learn rule sets efficiently in a\nnetwork structure with a single hidden layer using iterative refinements over\nmini-batches of examples. A first rudimentary version shows an acceptable\nperformance on all but one dataset, even though it does not yet reach the\nperformance levels of Ripper.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 16:10:23 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Beck", "Florian", ""], ["F\u00fcrnkranz", "Johannes", ""]]}, {"id": "2106.10213", "submitter": "Bin-Bin Gao", "authors": "Feng Luo, Bin-Bin Gao, Jiangpeng Yan, Xiu Li", "title": "A Coarse-to-Fine Instance Segmentation Network with Learning Boundary\n  Representation", "comments": "8 pages, Accepted by IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boundary-based instance segmentation has drawn much attention since of its\nattractive efficiency. However, existing methods suffer from the difficulty in\nlong-distance regression. In this paper, we propose a coarse-to-fine module to\naddress the problem. Approximate boundary points are generated at the coarse\nstage and then features of these points are sampled and fed to a refined\nregressor for fine prediction. It is end-to-end trainable since differential\nsampling operation is well supported in the module. Furthermore, we design a\nholistic boundary-aware branch and introduce instance-agnostic supervision to\nassist regression. Equipped with ResNet-101, our approach achieves 31.7\\% mask\nAP on COCO dataset with single-scale training and testing, outperforming the\nbaseline 1.3\\% mask AP with less than 1\\% additional parameters and GFLOPs.\nExperiments also show that our proposed method achieves competitive performance\ncompared to existing boundary-based methods with a lightweight design and a\nsimple pipeline.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 16:37:28 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Luo", "Feng", ""], ["Gao", "Bin-Bin", ""], ["Yan", "Jiangpeng", ""], ["Li", "Xiu", ""]]}, {"id": "2106.10251", "submitter": "Yutian Chen", "authors": "Ksenia Konyushkova, Yutian Chen, Thomas Paine, Caglar Gulcehre, Cosmin\n  Paduraru, Daniel J Mankowitz, Misha Denil, Nando de Freitas", "title": "Active Offline Policy Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper addresses the problem of policy selection in domains with abundant\nlogged data, but with a very restricted interaction budget. Solving this\nproblem would enable safe evaluation and deployment of offline reinforcement\nlearning policies in industry, robotics, and healthcare domain among others.\nSeveral off-policy evaluation (OPE) techniques have been proposed to assess the\nvalue of policies using only logged data. However, there is still a big gap\nbetween the evaluation by OPE and the full online evaluation in the real\nenvironment. To reduce this gap, we introduce a novel \\emph{active offline\npolicy selection} problem formulation, which combined logged data and limited\nonline interactions to identify the best policy. We rely on the advances in OPE\nto warm start the evaluation. We build upon Bayesian optimization to\niteratively decide which policies to evaluate in order to utilize the limited\nenvironment interactions wisely. Many candidate policies could be proposed,\nthus, we focus on making our approach scalable and introduce a kernel function\nto model similarity between policies. We use several benchmark environments to\nshow that the proposed approach improves upon state-of-the-art OPE estimates\nand fully online policy evaluation with limited budget. Additionally, we show\nthat each component of the proposed method is important, it works well with\nvarious number and quality of OPE estimates and even with a large number of\ncandidate policies.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 17:33:13 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Konyushkova", "Ksenia", ""], ["Chen", "Yutian", ""], ["Paine", "Thomas", ""], ["Gulcehre", "Caglar", ""], ["Paduraru", "Cosmin", ""], ["Mankowitz", "Daniel J", ""], ["Denil", "Misha", ""], ["de Freitas", "Nando", ""]]}, {"id": "2106.10252", "submitter": "Kerem \\\"Ozfatura", "authors": "Emre Ozfatura and Muhammad Zaid Hameed and Kerem Ozfatura and Deniz\n  Gunduz", "title": "Less is More: Feature Selection for Adversarial Robustness with\n  Compressive Counter-Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common observation regarding adversarial attacks is that they mostly give\nrise to false activation at the penultimate layer to fool the classifier.\nAssuming that these activation values correspond to certain features of the\ninput, the objective becomes choosing the features that are most useful for\nclassification. Hence, we propose a novel approach to identify the important\nfeatures by employing counter-adversarial attacks, which highlights the\nconsistency at the penultimate layer with respect to perturbations on input\nsamples. First, we empirically show that there exist a subset of features,\nclassification based in which bridge the gap between the clean and robust\naccuracy. Second, we propose a simple yet efficient mechanism to identify those\nfeatures by searching the neighborhood of input sample. We then select features\nby observing the consistency of the activation values at the penultimate layer.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 17:39:05 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Ozfatura", "Emre", ""], ["Hameed", "Muhammad Zaid", ""], ["Ozfatura", "Kerem", ""], ["Gunduz", "Deniz", ""]]}, {"id": "2106.10254", "submitter": "Florian Beck", "authors": "Florian Beck and Johannes F\\\"urnkranz", "title": "An Empirical Investigation into Deep and Shallow Rule Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Inductive rule learning is arguably among the most traditional paradigms in\nmachine learning. Although we have seen considerable progress over the years in\nlearning rule-based theories, all state-of-the-art learners still learn\ndescriptions that directly relate the input features to the target concept. In\nthe simplest case, concept learning, this is a disjunctive normal form (DNF)\ndescription of the positive class. While it is clear that this is sufficient\nfrom a logical point of view because every logical expression can be reduced to\nan equivalent DNF expression, it could nevertheless be the case that more\nstructured representations, which form deep theories by forming intermediate\nconcepts, could be easier to learn, in very much the same way as deep neural\nnetworks are able to outperform shallow networks, even though the latter are\nalso universal function approximators. In this paper, we empirically compare\ndeep and shallow rule learning with a uniform general algorithm, which relies\non greedy mini-batch based optimization. Our experiments on both artificial and\nreal-world benchmark data indicate that deep rule networks outperform shallow\nnetworks.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 17:43:17 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Beck", "Florian", ""], ["F\u00fcrnkranz", "Johannes", ""]]}, {"id": "2106.10258", "submitter": "Marco Fornoni", "authors": "Marco Fornoni, Chaochao Yan, Liangchen Luo, Kimberly Wilber, Alex\n  Stark, Yin Cui, Boqing Gong, Andrew Howard", "title": "Bridging the Gap Between Object Detection and User Intent via\n  Query-Modulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When interacting with objects through cameras, or pictures, users often have\na specific intent. For example, they may want to perform a visual search.\nHowever, most object detection models ignore the user intent, relying on image\npixels as their only input. This often leads to incorrect results, such as lack\nof a high-confidence detection on the object of interest, or detection with a\nwrong class label. In this paper we investigate techniques to modulate standard\nobject detectors to explicitly account for the user intent, expressed as an\nembedding of a simple query. Compared to standard object detectors,\nquery-modulated detectors show superior performance at detecting objects for a\ngiven label of interest. Thanks to large-scale training data synthesized from\nstandard object detection annotations, query-modulated detectors can also\noutperform specialized referring expression recognition systems. Furthermore,\nthey can be simultaneously trained to solve for both query-modulated detection\nand standard object detection.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 17:47:53 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Fornoni", "Marco", ""], ["Yan", "Chaochao", ""], ["Luo", "Liangchen", ""], ["Wilber", "Kimberly", ""], ["Stark", "Alex", ""], ["Cui", "Yin", ""], ["Gong", "Boqing", ""], ["Howard", "Andrew", ""]]}, {"id": "2106.10268", "submitter": "Paria Rashidinejad", "authors": "Tianjun Zhang, Paria Rashidinejad, Jiantao Jiao, Yuandong Tian, Joseph\n  Gonzalez, Stuart Russell", "title": "MADE: Exploration via Maximizing Deviation from Explored Regions", "comments": "28 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In online reinforcement learning (RL), efficient exploration remains\nparticularly challenging in high-dimensional environments with sparse rewards.\nIn low-dimensional environments, where tabular parameterization is possible,\ncount-based upper confidence bound (UCB) exploration methods achieve minimax\nnear-optimal rates. However, it remains unclear how to efficiently implement\nUCB in realistic RL tasks that involve non-linear function approximation. To\naddress this, we propose a new exploration approach via \\textit{maximizing} the\ndeviation of the occupancy of the next policy from the explored regions. We add\nthis term as an adaptive regularizer to the standard RL objective to balance\nexploration vs. exploitation. We pair the new objective with a provably\nconvergent algorithm, giving rise to a new intrinsic reward that adjusts\nexisting bonuses. The proposed intrinsic reward is easy to implement and\ncombine with other existing RL algorithms to conduct exploration. As a proof of\nconcept, we evaluate the new intrinsic reward on tabular examples across a\nvariety of model-based and model-free algorithms, showing improvements over\ncount-only exploration strategies. When tested on navigation and locomotion\ntasks from MiniGrid and DeepMind Control Suite benchmarks, our approach\nsignificantly improves sample efficiency over state-of-the-art methods. Our\ncode is available at https://github.com/tianjunz/MADE.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 17:57:00 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Zhang", "Tianjun", ""], ["Rashidinejad", "Paria", ""], ["Jiao", "Jiantao", ""], ["Tian", "Yuandong", ""], ["Gonzalez", "Joseph", ""], ["Russell", "Stuart", ""]]}, {"id": "2106.10270", "submitter": "Xiaohua Zhai", "authors": "Andreas Steiner, Alexander Kolesnikov, Xiaohua Zhai, Ross Wightman,\n  Jakob Uszkoreit, Lucas Beyer", "title": "How to train your ViT? Data, Augmentation, and Regularization in Vision\n  Transformers", "comments": "Andreas, Alex, Xiaohua and Lucas contributed equally. We release more\n  than 50'000 ViT models trained under diverse settings on various datasets. We\n  believe this to be a treasure trove for model analysis. Available at\n  https://github.com/google-research/vision_transformer and\n  https://github.com/rwightman/pytorch-image-models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision Transformers (ViT) have been shown to attain highly competitive\nperformance for a wide range of vision applications, such as image\nclassification, object detection and semantic image segmentation. In comparison\nto convolutional neural networks, the Vision Transformer's weaker inductive\nbias is generally found to cause an increased reliance on model regularization\nor data augmentation (``AugReg'' for short) when training on smaller training\ndatasets. We conduct a systematic empirical study in order to better understand\nthe interplay between the amount of training data, AugReg, model size and\ncompute budget. As one result of this study we find that the combination of\nincreased compute and AugReg can yield models with the same performance as\nmodels trained on an order of magnitude more training data: we train ViT models\nof various sizes on the public ImageNet-21k dataset which either match or\noutperform their counterparts trained on the larger, but not publicly available\nJFT-300M dataset.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 17:58:20 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Steiner", "Andreas", ""], ["Kolesnikov", "Alexander", ""], ["Zhai", "Xiaohua", ""], ["Wightman", "Ross", ""], ["Uszkoreit", "Jakob", ""], ["Beyer", "Lucas", ""]]}, {"id": "2106.10302", "submitter": "Salva R\\\"uhling Cachay", "authors": "Salva R\\\"uhling Cachay, Benedikt Boecking, Artur Dubrawski", "title": "Dependency Structure Misspecification in Multi-Source Weak Supervision\n  Models", "comments": "Oral presentation at the Workshop on Weakly Supervised Learning at\n  ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data programming (DP) has proven to be an attractive alternative to costly\nhand-labeling of data.\n  In DP, users encode domain knowledge into \\emph{labeling functions} (LF),\nheuristics that label a subset of the data noisily and may have complex\ndependencies. A label model is then fit to the LFs to produce an estimate of\nthe unknown class label.\n  The effects of label model misspecification on test set performance of a\ndownstream classifier are understudied. This presents a serious awareness gap\nto practitioners, in particular since the dependency structure among LFs is\nfrequently ignored in field applications of DP.\n  We analyse modeling errors due to structure over-specification.\n  We derive novel theoretical bounds on the modeling error and empirically show\nthat this error can be substantial, even when modeling a seemingly sensible\nstructure.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 18:15:44 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Cachay", "Salva R\u00fchling", ""], ["Boecking", "Benedikt", ""], ["Dubrawski", "Artur", ""]]}, {"id": "2106.10305", "submitter": "Stefanos Antaris", "authors": "Stefanos Antaris and Dimitrios Rafailidis and Romina Arriaza", "title": "Multi-Task Learning for User Engagement and Adoption in Live Video\n  Streaming Events", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nowadays, live video streaming events have become a mainstay in viewer's\ncommunication in large international enterprises. Provided that viewers are\ndistributed worldwide, the main challenge resides on how to schedule the\noptimal event's time so as to improve both the viewer's engagement and\nadoption. In this paper we present a multi-task deep reinforcement learning\nmodel to select the time of a live video streaming event, aiming to optimize\nthe viewer's engagement and adoption at the same time. We consider the\nengagement and adoption of the viewers as independent tasks and formulate a\nunified loss function to learn a common policy. In addition, we account for the\nfact that each task might have different contribution to the training strategy\nof the agent. Therefore, to determine the contribution of each task to the\nagent's training, we design a Transformer's architecture for the state-action\ntransitions of each task. We evaluate our proposed model on four real-world\ndatasets, generated by the live video streaming events of four large\nenterprises spanning from January 2019 until March 2021. Our experiments\ndemonstrate the effectiveness of the proposed model when compared with several\nstate-of-the-art strategies. For reproduction purposes, our evaluation datasets\nand implementation are publicly available at\nhttps://github.com/stefanosantaris/merlin.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 18:30:22 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Antaris", "Stefanos", ""], ["Rafailidis", "Dimitrios", ""], ["Arriaza", "Romina", ""]]}, {"id": "2106.10309", "submitter": "Peri Akiva", "authors": "Peri Akiva and Kristin Dana", "title": "Towards Single Stage Weakly Supervised Semantic Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The costly process of obtaining semantic segmentation labels has driven\nresearch towards weakly supervised semantic segmentation (WSSS) methods, using\nonly image-level, point, or box labels. The lack of dense scene representation\nrequires methods to increase complexity to obtain additional semantic\ninformation about the scene, often done through multiple stages of training and\nrefinement. Current state-of-the-art (SOTA) models leverage image-level labels\nto produce class activation maps (CAMs) which go through multiple stages of\nrefinement before they are thresholded to make pseudo-masks for supervision.\nThe multi-stage approach is computationally expensive, and dependency on\nimage-level labels for CAMs generation lacks generalizability to more complex\nscenes. In contrary, our method offers a single-stage approach generalizable to\narbitrary dataset, that is trainable from scratch, without any dependency on\npre-trained backbones, classification, or separate refinement tasks. We utilize\npoint annotations to generate reliable, on-the-fly pseudo-masks through refined\nand filtered features. While our method requires point annotations that are\nonly slightly more expensive than image-level annotations, we are to\ndemonstrate SOTA performance on benchmark datasets (PascalVOC 2012), as well as\nsignificantly outperform other SOTA WSSS methods on recent real-world datasets\n(CRAID, CityPersons, IAD).\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 18:34:50 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 15:23:42 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Akiva", "Peri", ""], ["Dana", "Kristin", ""]]}, {"id": "2106.10316", "submitter": "Christopher Grimm", "authors": "Christopher Grimm, Andr\\'e Barreto, Gregory Farquhar, David Silver,\n  Satinder Singh", "title": "Proper Value Equivalence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the main challenges in model-based reinforcement learning (RL) is to\ndecide which aspects of the environment should be modeled. The\nvalue-equivalence (VE) principle proposes a simple answer to this question: a\nmodel should capture the aspects of the environment that are relevant for\nvalue-based planning. Technically, VE distinguishes models based on a set of\npolicies and a set of functions: a model is said to be VE to the environment if\nthe Bellman operators it induces for the policies yield the correct result when\napplied to the functions. As the number of policies and functions increase, the\nset of VE models shrinks, eventually collapsing to a single point corresponding\nto a perfect model. A fundamental question underlying the VE principle is thus\nhow to select the smallest sets of policies and functions that are sufficient\nfor planning. In this paper we take an important step towards answering this\nquestion. We start by generalizing the concept of VE to order-$k$ counterparts\ndefined with respect to $k$ applications of the Bellman operator. This leads to\na family of VE classes that increase in size as $k \\rightarrow \\infty$. In the\nlimit, all functions become value functions, and we have a special\ninstantiation of VE which we call proper VE or simply PVE. Unlike VE, the PVE\nclass may contain multiple models even in the limit when all value functions\nare used. Crucially, all these models are sufficient for planning, meaning that\nthey will yield an optimal policy despite the fact that they may ignore many\naspects of the environment. We construct a loss function for learning PVE\nmodels and argue that popular algorithms such as MuZero and Muesli can be\nunderstood as minimizing an upper bound for this loss. We leverage this\nconnection to propose a modification to MuZero and show that it can lead to\nimproved performance in practice.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 19:05:20 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Grimm", "Christopher", ""], ["Barreto", "Andr\u00e9", ""], ["Farquhar", "Gregory", ""], ["Silver", "David", ""], ["Singh", "Satinder", ""]]}, {"id": "2106.10318", "submitter": "Bobak Hamed Baghi", "authors": "Bobak H. Baghi, Gregory Dudek", "title": "Sample Efficient Social Navigation Using Inverse Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an algorithm to efficiently learn\nsocially-compliant navigation policies from observations of human trajectories.\nAs mobile robots come to inhabit and traffic social spaces, they must account\nfor social cues and behave in a socially compliant manner. We focus on learning\nsuch cues from examples. We describe an inverse reinforcement learning based\nalgorithm which learns from human trajectory observations without knowing their\nspecific actions. We increase the sample-efficiency of our approach over\nalternative methods by leveraging the notion of a replay buffer (found in many\noff-policy reinforcement learning methods) to eliminate the additional sample\ncomplexity associated with inverse reinforcement learning. We evaluate our\nmethod by training agents using publicly available pedestrian motion data sets\nand compare it to related methods. We show that our approach yields better\nperformance while also decreasing training time and sample complexity.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 19:07:41 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Baghi", "Bobak H.", ""], ["Dudek", "Gregory", ""]]}, {"id": "2106.10319", "submitter": "Muhammad Monjurul Karim", "authors": "Muhammad Monjurul Karim, Yu Li, Ruwen Qin, Zhaozheng Yin", "title": "A system of vision sensor based deep neural networks for complex driving\n  scene analysis in support of crash risk assessment and prevention", "comments": "11 Pages, 8 Figures, Presented in TRB conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To assist human drivers and autonomous vehicles in assessing crash risks,\ndriving scene analysis using dash cameras on vehicles and deep learning\nalgorithms is of paramount importance. Although these technologies are\nincreasingly available, driving scene analysis for this purpose still remains a\nchallenge. This is mainly due to the lack of annotated large image datasets for\nanalyzing crash risk indicators and crash likelihood, and the lack of an\neffective method to extract lots of required information from complex driving\nscenes. To fill the gap, this paper develops a scene analysis system. The\nMulti-Net of the system includes two multi-task neural networks that perform\nscene classification to provide four labels for each scene. The DeepLab v3 and\nYOLO v3 are combined by the system to detect and locate risky pedestrians and\nthe nearest vehicles. All identified information can provide the situational\nawareness to autonomous vehicles or human drivers for identifying crash risks\nfrom the surrounding traffic. To address the scarcity of annotated image\ndatasets for studying traffic crashes, two completely new datasets have been\ndeveloped by this paper and made available to the public, which were proved to\nbe effective in training the proposed deep neural networks. The paper further\nevaluates the performance of the Multi-Net and the efficiency of the developed\nsystem. Comprehensive scene analysis is further illustrated with representative\nexamples. Results demonstrate the effectiveness of the developed system and\ndatasets for driving scene analysis, and their supportiveness for crash risk\nassessment and crash prevention.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 19:07:59 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Karim", "Muhammad Monjurul", ""], ["Li", "Yu", ""], ["Qin", "Ruwen", ""], ["Yin", "Zhaozheng", ""]]}, {"id": "2106.10349", "submitter": "Chris Cameron", "authors": "Chris Cameron, Jason Hartford, Taylor Lundy, Kevin Leyton-Brown", "title": "The Perils of Learning Before Optimizing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Formulating real-world optimization problems often begins with making\npredictions from historical data (e.g., an optimizer that aims to recommend\nfast routes relies upon travel-time predictions). Typically, learning the\nprediction model used to generate the optimization problem and solving that\nproblem are performed in two separate stages. Recent work has showed how such\nprediction models can be learned end-to-end by differentiating through the\noptimization task. Such methods often yield empirical improvements, which are\ntypically attributed to end-to-end making better error tradeoffs than the\nstandard loss function used in a two-stage solution. We refine this explanation\nand more precisely characterize when end-to-end can improve performance. When\nprediction targets are stochastic, a two-stage solution must make an a priori\nchoice about which statistics of the target distribution to model -- we\nconsider expectations over prediction targets -- while an end-to-end solution\ncan make this choice adaptively. We show that the performance gap between a\ntwo-stage and end-to-end approach is closely related to the \\emph{price of\ncorrelation} concept in stochastic optimization and show the implications of\nsome existing POC results for our predict-then-optimize problem. We then\nconsider a novel and particularly practical setting, where coefficients in the\nobjective function depend on multiple prediction targets. We give explicit\nconstructions where (1) two-stage performs unboundedly worse than end-to-end;\nand (2) two-stage is optimal. We identify a large set of real-world\napplications whose objective functions rely on multiple prediction targets but\nwhich nevertheless deploy two-stage solutions. We also use simulations to\nexperimentally quantify performance gaps.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 20:43:47 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Cameron", "Chris", ""], ["Hartford", "Jason", ""], ["Lundy", "Taylor", ""], ["Leyton-Brown", "Kevin", ""]]}, {"id": "2106.10365", "submitter": "Azad Salam", "authors": "Abdus Salam Azad, Edward Kim, Qiancheng Wu, Kimin Lee, Ion Stoica,\n  Pieter Abbeel, and Sanjit A. Seshia", "title": "Scenic4RL: Programmatic Modeling and Generation of Reinforcement\n  Learning Environments", "comments": "First two authors contributed equally. Currently Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The capability of reinforcement learning (RL) agent directly depends on the\ndiversity of learning scenarios the environment generates and how closely it\ncaptures real-world situations. However, existing environments/simulators lack\nthe support to systematically model distributions over initial states and\ntransition dynamics. Furthermore, in complex domains such as soccer, the space\nof possible scenarios is infinite, which makes it impossible for one research\ngroup to provide a comprehensive set of scenarios to train, test, and benchmark\nRL algorithms. To address this issue, for the first time, we adopt an existing\nformal scenario specification language, SCENIC, to intuitively model and\ngenerate interactive scenarios. We interfaced SCENIC to Google Research Soccer\nenvironment to create a platform called SCENIC4RL. Using this platform, we\nprovide a dataset consisting of 36 scenario programs encoded in SCENIC and\ndemonstration data generated from a subset of them. We share our experimental\nresults to show the effectiveness of our dataset and the platform to train,\ntest, and benchmark RL algorithms. More importantly, we open-source our\nplatform to enable RL community to collectively contribute to constructing a\ncomprehensive set of scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 21:49:46 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Azad", "Abdus Salam", ""], ["Kim", "Edward", ""], ["Wu", "Qiancheng", ""], ["Lee", "Kimin", ""], ["Stoica", "Ion", ""], ["Abbeel", "Pieter", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "2106.10370", "submitter": "Rajat Sen", "authors": "Pranjal Awasthi, Abhimanyu Das, Rajat Sen, Ananda Theertha Suresh", "title": "On the benefits of maximum likelihood estimation for Regression and\n  Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We advocate for a practical Maximum Likelihood Estimation (MLE) approach for\nregression and forecasting, as an alternative to the typical approach of\nEmpirical Risk Minimization (ERM) for a specific target metric. This approach\nis better suited to capture inductive biases such as prior domain knowledge in\ndatasets, and can output post-hoc estimators at inference time that can\noptimize different types of target metrics. We present theoretical results to\ndemonstrate that our approach is always competitive with any estimator for the\ntarget metric under some general conditions, and in many practical settings\n(such as Poisson Regression) can actually be much superior to ERM. We\ndemonstrate empirically that our method instantiated with a well-designed\ngeneral purpose mixture likelihood family can obtain superior performance over\nERM for a variety of tasks across time-series forecasting and regression\ndatasets with different data distributions.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 22:10:43 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Das", "Abhimanyu", ""], ["Sen", "Rajat", ""], ["Suresh", "Ananda Theertha", ""]]}, {"id": "2106.10394", "submitter": "Cassidy Laidlaw", "authors": "Cassidy Laidlaw and Stuart Russell", "title": "Learning the Preferences of Uncertain Humans with Inverse Decision\n  Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing observational approaches for learning human preferences, such as\ninverse reinforcement learning, usually make strong assumptions about the\nobservability of the human's environment. However, in reality, people make many\nimportant decisions under uncertainty. To better understand preference learning\nin these cases, we study the setting of inverse decision theory (IDT), a\npreviously proposed framework where a human is observed making non-sequential\nbinary decisions under uncertainty. In IDT, the human's preferences are\nconveyed through their loss function, which expresses a tradeoff between\ndifferent types of mistakes. We give the first statistical analysis of IDT,\nproviding conditions necessary to identify these preferences and characterizing\nthe sample complexity -- the number of decisions that must be observed to learn\nthe tradeoff the human is making to a desired precision. Interestingly, we show\nthat it is actually easier to identify preferences when the decision problem is\nmore uncertain. Furthermore, uncertain decision problems allow us to relax the\nunrealistic assumption that the human is an optimal decision maker but still\nidentify their exact preferences; we give sample complexities in this\nsuboptimal case as well. Our analysis contradicts the intuition that partial\nobservability should make preference learning more difficult. It also provides\na first step towards understanding and improving preference learning methods\nfor uncertain and suboptimal humans.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 00:11:13 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Laidlaw", "Cassidy", ""], ["Russell", "Stuart", ""]]}, {"id": "2106.10411", "submitter": "Hua Wei", "authors": "Hua Wei, Deheng Ye, Zhao Liu, Hao Wu, Bo Yuan, Qiang Fu, Wei Yang,\n  Zhenhui Li", "title": "Boosting Offline Reinforcement Learning with Residual Generative\n  Modeling", "comments": "Accepted by IJCAI 2021, appendix included, 9 pages, 4 figures, 2\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offline reinforcement learning (RL) tries to learn the near-optimal policy\nwith recorded offline experience without online exploration. Current offline RL\nresearch includes: 1) generative modeling, i.e., approximating a policy using\nfixed data; and 2) learning the state-action value function. While most\nresearch focuses on the state-action function part through reducing the\nbootstrapping error in value function approximation induced by the distribution\nshift of training data, the effects of error propagation in generative modeling\nhave been neglected. In this paper, we analyze the error in generative\nmodeling. We propose AQL (action-conditioned Q-learning), a residual generative\nmodel to reduce policy approximation error for offline RL. We show that our\nmethod can learn more accurate policy approximations in different benchmark\ndatasets. In addition, we show that the proposed offline RL method can learn\nmore competitive AI agents in complex control tasks under the multiplayer\nonline battle arena (MOBA) game Honor of Kings.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 03:41:14 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 02:27:38 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Wei", "Hua", ""], ["Ye", "Deheng", ""], ["Liu", "Zhao", ""], ["Wu", "Hao", ""], ["Yuan", "Bo", ""], ["Fu", "Qiang", ""], ["Yang", "Wei", ""], ["Li", "Zhenhui", ""]]}, {"id": "2106.10419", "submitter": "Enyu Yu", "authors": "En-Yu Yu, Yan Fu, Jun-Lin Zhou, Hong-Liang Sun, Duan-Bing Chen", "title": "Predicting Critical Nodes in Temporal Networks by Dynamic Graph\n  Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world systems can be expressed in temporal networks with nodes\nplaying far different roles in structure and function and edges representing\nthe relationships between nodes. Identifying critical nodes can help us control\nthe spread of public opinions or epidemics, predict leading figures in\nacademia, conduct advertisements for various commodities, and so on. However,\nit is rather difficult to identify critical nodes because the network structure\nchanges over time in temporal networks. In this paper, considering the sequence\ntopological information of temporal networks, a novel and effective learning\nframework based on the combination of special GCNs and RNNs is proposed to\nidentify nodes with the best spreading ability. The effectiveness of the\napproach is evaluated by weighted Susceptible-Infected-Recovered model.\nExperimental results on four real-world temporal networks demonstrate that the\nproposed method outperforms both traditional and deep learning benchmark\nmethods in terms of the Kendall $\\tau$ coefficient and top $k$ hit rate.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 04:16:18 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 10:47:33 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Yu", "En-Yu", ""], ["Fu", "Yan", ""], ["Zhou", "Jun-Lin", ""], ["Sun", "Hong-Liang", ""], ["Chen", "Duan-Bing", ""]]}, {"id": "2106.10421", "submitter": "Feihong Shen", "authors": "Feihong Shen and Jun Liu", "title": "QFCNN: Quantum Fourier Convolutional Neural Network", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The neural network and quantum computing are both significant and appealing\nfields, with their interactive disciplines promising for large-scale computing\ntasks that are untackled by conventional computers. However, both developments\nare restricted by the scope of the hardware development. Nevertheless, many\nneural network algorithms had been proposed before GPUs become powerful enough\nfor running very deep models. Similarly, quantum algorithms can also be\nproposed as knowledge reserves before real quantum computers are easily\naccessible. Specifically, taking advantage of both the neural networks and\nquantum computation and designing quantum deep neural networks (QDNNs) for\nacceleration on Noisy Intermediate-Scale Quantum (NISQ) processors is also an\nimportant research problem. As one of the most widely used neural network\narchitectures, convolutional neural network (CNN) remains to be accelerated by\nquantum mechanisms, with only a few attempts have been demonstrated. In this\npaper, we propose a new hybrid quantum-classical circuit, namely Quantum\nFourier Convolutional Network (QFCN). Our model achieves exponential speed-up\ncompared with classical CNN theoretically and improves over the existing best\nresult of quantum CNN. We demonstrate the potential of this architecture by\napplying it to different deep learning tasks, including traffic prediction and\nimage classification.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 04:37:39 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Shen", "Feihong", ""], ["Liu", "Jun", ""]]}, {"id": "2106.10424", "submitter": "Yang Yu", "authors": "Tian Xu, Ziniu Li, Yang Yu", "title": "Nearly Minimax Optimal Adversarial Imitation Learning with Known and\n  Unknown Transitions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper is dedicated to designing provably efficient adversarial imitation\nlearning (AIL) algorithms that directly optimize policies from expert\ndemonstrations. Firstly, we develop a transition-aware AIL algorithm named TAIL\nwith an expert sample complexity of $\\tilde{O}(H^{3/2} |S|/\\varepsilon)$ under\nthe known transition setting, where $H$ is the planning horizon, $|S|$ is the\nstate space size and $\\varepsilon$ is desired policy value gap. This improves\nupon the previous best bound of $\\tilde{O}(H^2 |S| / \\varepsilon^2)$ for AIL\nmethods and matches the lower bound of $\\tilde{\\Omega} (H^{3/2}\n|S|/\\varepsilon)$ in [Rajaraman et al., 2021] up to a logarithmic factor. The\nkey ingredient of TAIL is a fine-grained estimator for expert state-action\ndistribution, which explicitly utilizes the transition function information.\nSecondly, considering practical settings where the transition functions are\nusually unknown but environment interaction is allowed, we accordingly develop\na model-based transition-aware AIL algorithm named MB-TAIL. In particular,\nMB-TAIL builds an empirical transition model by interacting with the\nenvironment and performs imitation under the recovered empirical model. The\ninteraction complexity of MB-TAIL is $\\tilde{O} (H^3 |S|^2 |A| /\n\\varepsilon^2)$, which improves the best known result of $\\tilde{O} (H^4 |S|^2\n|A| / \\varepsilon^2)$ in [Shani et al., 2021]. Finally, our theoretical results\nare supported by numerical evaluation and detailed analysis on two challenging\nMDPs.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 04:41:33 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Xu", "Tian", ""], ["Li", "Ziniu", ""], ["Yu", "Yang", ""]]}, {"id": "2106.10446", "submitter": "Gicheon Kang", "authors": "Ahjeong Seo, Gi-Cheon Kang, Joonhan Park, Byoung-Tak Zhang", "title": "Attend What You Need: Motion-Appearance Synergistic Networks for Video\n  Question Answering", "comments": "ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video Question Answering is a task which requires an AI agent to answer\nquestions grounded in video. This task entails three key challenges: (1)\nunderstand the intention of various questions, (2) capturing various elements\nof the input video (e.g., object, action, causality), and (3) cross-modal\ngrounding between language and vision information. We propose Motion-Appearance\nSynergistic Networks (MASN), which embed two cross-modal features grounded on\nmotion and appearance information and selectively utilize them depending on the\nquestion's intentions. MASN consists of a motion module, an appearance module,\nand a motion-appearance fusion module. The motion module computes the\naction-oriented cross-modal joint representations, while the appearance module\nfocuses on the appearance aspect of the input video. Finally, the\nmotion-appearance fusion module takes each output of the motion module and the\nappearance module as input, and performs question-guided fusion. As a result,\nMASN achieves new state-of-the-art performance on the TGIF-QA and MSVD-QA\ndatasets. We also conduct qualitative analysis by visualizing the inference\nresults of MASN. The code is available at\nhttps://github.com/ahjeongseo/MASN-pytorch.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 07:48:55 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Seo", "Ahjeong", ""], ["Kang", "Gi-Cheon", ""], ["Park", "Joonhan", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "2106.10466", "submitter": "Zhihan Yue", "authors": "Zhihan Yue, Yujing Wang, Juanyong Duan, Tianmeng Yang, Congrui Huang,\n  Bixiong Xu", "title": "Learning Timestamp-Level Representations for Time Series with\n  Hierarchical Contrastive Loss", "comments": "20 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents TS2Vec, a universal framework for learning\ntimestamp-level representations of time series. Unlike existing methods, TS2Vec\nperforms timestamp-wise discrimination, which learns a contextual\nrepresentation vector directly for each timestamp. We find that the learned\nrepresentations have superior predictive ability. A linear regression trained\non top of the learned representations outperforms previous SOTAs for supervised\ntime series forecasting. Also, the instance-level representations can be simply\nobtained by applying a max pooling layer on top of learned representations of\nall timestamps. We conduct extensive experiments on time series classification\ntasks to evaluate the quality of instance-level representations. As a result,\nTS2Vec achieves significant improvement compared with existing SOTAs of\nunsupervised time series representation on 125 UCR datasets and 29 UEA\ndatasets. The source code is publicly available at\nhttps://github.com/yuezhihan/ts2vec.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 10:24:13 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Yue", "Zhihan", ""], ["Wang", "Yujing", ""], ["Duan", "Juanyong", ""], ["Yang", "Tianmeng", ""], ["Huang", "Congrui", ""], ["Xu", "Bixiong", ""]]}, {"id": "2106.10479", "submitter": "Yang Tan", "authors": "Yang Tan, Yang Li, Shao-Lun Huang", "title": "Practical Transferability Estimation for Image Classification Tasks", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transferability estimation is an essential problem in transfer learning to\npredict how good the performance is when transferring a source model (or source\ntask) to a target task. Recent analytical transferability metrics have been\nwidely used for source model selection and multi-task learning. A major\nchallenge is how to make transfereability estimation robust under the\ncross-domain cross-task settings. The recently proposed OTCE score solves this\nproblem by considering both domain and task differences, with the help of\ntransfer experiences on auxiliary tasks, which causes an efficiency overhead.\nIn this work, we propose a practical transferability metric called JC-NCE score\nthat dramatically improves the robustness of the task difference estimation in\nOTCE, thus removing the need for auxiliary tasks. Specifically, we build the\njoint correspondences between source and target data via solving an optimal\ntransport problem with a ground cost considering both the sample distance and\nlabel distance, and then compute the transferability score as the negative\nconditional entropy of the matched labels. Extensive validations under the\nintra-dataset and inter-dataset transfer settings demonstrate that our JC-NCE\nscore outperforms the auxiliary-task free version of OTCE for 7% and 12%,\nrespectively, and is also more robust than other existing transferability\nmetrics on average.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 11:59:11 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 10:26:37 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Tan", "Yang", ""], ["Li", "Yang", ""], ["Huang", "Shao-Lun", ""]]}, {"id": "2106.10481", "submitter": "Mohammed Salah Al-Radhi PhD", "authors": "Mohammed Salah Al-Radhi, Tam\\'as G\\'abor Csap\\'o, and G\\'eza N\\'emeth", "title": "Advances in Speech Vocoding for Text-to-Speech with Continuous\n  Parameters", "comments": "6 pages, 3 figures, International Conference on Artificial\n  Intelligence and Speech Technology (AIST2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Vocoders received renewed attention as main components in statistical\nparametric text-to-speech (TTS) synthesis and speech transformation systems.\nEven though there are vocoding techniques give almost accepted synthesized\nspeech, their high computational complexity and irregular structures are still\nconsidered challenging concerns, which yield a variety of voice quality\ndegradation. Therefore, this paper presents new techniques in a continuous\nvocoder, that is all features are continuous and presents a flexible speech\nsynthesis system. First, a new continuous noise masking based on the phase\ndistortion is proposed to eliminate the perceptual impact of the residual noise\nand letting an accurate reconstruction of noise characteristics. Second, we\naddressed the need of neural sequence to sequence modeling approach for the\ntask of TTS based on recurrent networks. Bidirectional long short-term memory\n(LSTM) and gated recurrent unit (GRU) are studied and applied to model\ncontinuous parameters for more natural-sounding like a human. The evaluation\nresults proved that the proposed model achieves the state-of-the-art\nperformance of the speech synthesis compared with the other traditional\nmethods.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 12:05:01 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Al-Radhi", "Mohammed Salah", ""], ["Csap\u00f3", "Tam\u00e1s G\u00e1bor", ""], ["N\u00e9meth", "G\u00e9za", ""]]}, {"id": "2106.10499", "submitter": "Gordon E. Moon", "authors": "Gordon E. Moon, Hyoukjun Kwon, Geonhwa Jeong, Prasanth Chatarasi,\n  Sivasankaran Rajamanickam, Tushar Krishna", "title": "Evaluating Spatial Accelerator Architectures with Tiled Matrix-Matrix\n  Multiplication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There is a growing interest in custom spatial accelerators for machine\nlearning applications. These accelerators employ a spatial array of processing\nelements (PEs) interacting via custom buffer hierarchies and networks-on-chip.\nThe efficiency of these accelerators comes from employing optimized dataflow\n(i.e., spatial/temporal partitioning of data across the PEs and fine-grained\nscheduling) strategies to optimize data reuse. The focus of this work is to\nevaluate these accelerator architectures using a tiled general matrix-matrix\nmultiplication (GEMM) kernel. To do so, we develop a framework that finds\noptimized mappings (dataflow and tile sizes) for a tiled GEMM for a given\nspatial accelerator and workload combination, leveraging an analytical cost\nmodel for runtime and energy. Our evaluations over five spatial accelerators\ndemonstrate that the tiled GEMM mappings systematically generated by our\nframework achieve high performance on various GEMM workloads and accelerators.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 13:53:58 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Moon", "Gordon E.", ""], ["Kwon", "Hyoukjun", ""], ["Jeong", "Geonhwa", ""], ["Chatarasi", "Prasanth", ""], ["Rajamanickam", "Sivasankaran", ""], ["Krishna", "Tushar", ""]]}, {"id": "2106.10502", "submitter": "Pei Ke", "authors": "Pei Ke, Haozhe Ji, Yu Ran, Xin Cui, Liwei Wang, Linfeng Song, Xiaoyan\n  Zhu, Minlie Huang", "title": "JointGT: Graph-Text Joint Representation Learning for Text Generation\n  from Knowledge Graphs", "comments": "ACL 2021 (Findings)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing pre-trained models for knowledge-graph-to-text (KG-to-text)\ngeneration simply fine-tune text-to-text pre-trained models such as BART or T5\non KG-to-text datasets, which largely ignore the graph structure during\nencoding and lack elaborate pre-training tasks to explicitly model graph-text\nalignments. To tackle these problems, we propose a graph-text joint\nrepresentation learning model called JointGT. During encoding, we devise a\nstructure-aware semantic aggregation module which is plugged into each\nTransformer layer to preserve the graph structure. Furthermore, we propose\nthree new pre-training tasks to explicitly enhance the graph-text alignment\nincluding respective text / graph reconstruction, and graph-text alignment in\nthe embedding space via Optimal Transport. Experiments show that JointGT\nobtains new state-of-the-art performance on various KG-to-text datasets.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 14:10:10 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Ke", "Pei", ""], ["Ji", "Haozhe", ""], ["Ran", "Yu", ""], ["Cui", "Xin", ""], ["Wang", "Liwei", ""], ["Song", "Linfeng", ""], ["Zhu", "Xiaoyan", ""], ["Huang", "Minlie", ""]]}, {"id": "2106.10517", "submitter": "Youngchul Sung", "authors": "Seungyul Han and Youngchul Sung", "title": "A Max-Min Entropy Framework for Reinforcement Learning", "comments": "Submitted to NIPS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a max-min entropy framework for reinforcement\nlearning (RL) to overcome the limitation of the maximum entropy RL framework in\nmodel-free sample-based learning. Whereas the maximum entropy RL framework\nguides learning for policies to reach states with high entropy in the future,\nthe proposed max-min entropy framework aims to learn to visit states with low\nentropy and maximize the entropy of these low-entropy states to promote\nexploration. For general Markov decision processes (MDPs), an efficient\nalgorithm is constructed under the proposed max-min entropy framework based on\ndisentanglement of exploration and exploitation. Numerical results show that\nthe proposed algorithm yields drastic performance improvement over the current\nstate-of-the-art RL algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 15:30:21 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Han", "Seungyul", ""], ["Sung", "Youngchul", ""]]}, {"id": "2106.10532", "submitter": "Amit Verma Dr.", "authors": "Amit Verma and Mark Lewis", "title": "QUBO transformation using Eigenvalue Decomposition", "comments": "Preprint submitted to Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.ET", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Quadratic Unconstrained Binary Optimization (QUBO) is a general-purpose\nmodeling framework for combinatorial optimization problems and is a requirement\nfor quantum annealers. This paper utilizes the eigenvalue decomposition of the\nunderlying Q matrix to alter and improve the search process by extracting the\ninformation from dominant eigenvalues and eigenvectors to implicitly guide the\nsearch towards promising areas of the solution landscape. Computational results\non benchmark datasets illustrate the efficacy of our routine demonstrating\nsignificant performance improvements on problems with dominant eigenvalues.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 16:58:15 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Verma", "Amit", ""], ["Lewis", "Mark", ""]]}, {"id": "2106.10535", "submitter": "Kulin Shah", "authors": "Kulin Shah, Amit Deshpande, Navin Goyal", "title": "Learning and Generalization in Overparameterized Normalizing Flows", "comments": "80 pages, 79 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In supervised learning, it is known that overparameterized neural networks\nwith one hidden layer provably and efficiently learn and generalize, when\ntrained using stochastic gradient descent with sufficiently small learning rate\nand suitable initialization. In contrast, the benefit of overparameterization\nin unsupervised learning is not well understood. Normalizing flows (NFs)\nconstitute an important class of models in unsupervised learning for sampling\nand density estimation. In this paper, we theoretically and empirically analyze\nthese models when the underlying neural network is one-hidden-layer\noverparameterized network. Our main contributions are two-fold: (1) On the one\nhand, we provide theoretical and empirical evidence that for a class of NFs\ncontaining most of the existing NF models, overparametrization hurts training.\n(2) On the other hand, we prove that unconstrained NFs, a recently introduced\nmodel, can efficiently learn any reasonable data distribution under minimal\nassumptions when the underlying network is overparametrized.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 17:11:42 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Shah", "Kulin", ""], ["Deshpande", "Amit", ""], ["Goyal", "Navin", ""]]}, {"id": "2106.10544", "submitter": "Kevin Yang", "authors": "Kevin Yang, Tianjun Zhang, Chris Cummins, Brandon Cui, Benoit Steiner,\n  Linnan Wang, Joseph E. Gonzalez, Dan Klein, Yuandong Tian", "title": "Learning Space Partitions for Path Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Path planning, the problem of efficiently discovering high-reward\ntrajectories, often requires optimizing a high-dimensional and multimodal\nreward function. Popular approaches like CEM and CMA-ES greedily focus on\npromising regions of the search space and may get trapped in local maxima. DOO\nand VOOT balance exploration and exploitation, but use space partitioning\nstrategies independent of the reward function to be optimized. Recently, LaMCTS\nempirically learns to partition the search space in a reward-sensitive manner\nfor black-box optimization. In this paper, we develop a novel formal regret\nanalysis for when and why such an adaptive region partitioning scheme works. We\nalso propose a new path planning method PlaLaM which improves the function\nvalue estimation within each sub-region, and uses a latent representation of\nthe search space. Empirically, PlaLaM outperforms existing path planning\nmethods in 2D navigation tasks, especially in the presence of\ndifficult-to-escape local optima, and shows benefits when plugged into\nmodel-based RL with planning components such as PETS. These gains transfer to\nhighly multimodal real-world tasks, where we outperform strong baselines in\ncompiler phase ordering by up to 245% and in molecular design by up to 0.4 on\nproperties on a 0-1 scale. Code is available at\nhttps://github.com/yangkevin2/plalam.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 18:06:11 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 23:40:14 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Yang", "Kevin", ""], ["Zhang", "Tianjun", ""], ["Cummins", "Chris", ""], ["Cui", "Brandon", ""], ["Steiner", "Benoit", ""], ["Wang", "Linnan", ""], ["Gonzalez", "Joseph E.", ""], ["Klein", "Dan", ""], ["Tian", "Yuandong", ""]]}, {"id": "2106.10561", "submitter": "Reza Bagherian Azhiri", "authors": "Reza Bagherian Azhiri, Mohammad Esmaeili, Mohsen Jafarzadeh, and\n  Mehrdad Nourani", "title": "EMG Signal Classification Using Reflection Coefficients and Extreme\n  Value Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electromyography is a promising approach to the gesture recognition of humans\nif an efficient classifier with high accuracy is available. In this paper, we\npropose to utilize Extreme Value Machine (EVM) as a high-performance algorithm\nfor the classification of EMG signals. We employ reflection coefficients\nobtained from an Autoregressive (AR) model to train a set of classifiers. Our\nexperimental results indicate that EVM has better accuracy in comparison to the\nconventional classifiers approved in the literature based on K-Nearest\nNeighbors (KNN) and Support Vector Machine (SVM).\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 19:12:59 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Azhiri", "Reza Bagherian", ""], ["Esmaeili", "Mohammad", ""], ["Jafarzadeh", "Mohsen", ""], ["Nourani", "Mehrdad", ""]]}, {"id": "2106.10562", "submitter": "Leopoldo Bertossi", "authors": "Leopoldo Bertossi", "title": "Score-Based Explanations in Data Management and Machine Learning: An\n  Answer-Set Programming Approach to Counterfactual Analysis", "comments": "Paper associated to forthcoming short course at Fall School. arXiv\n  admin note: text overlap with arXiv:2007.12799", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe some recent approaches to score-based explanations for query\nanswers in databases and outcomes from classification models in machine\nlearning. The focus is on work done by the author and collaborators. Special\nemphasis is placed on declarative approaches based on answer-set programming to\nthe use of counterfactual reasoning for score specification and computation.\nSeveral examples that illustrate the flexibility of these methods are shown.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 19:21:48 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Bertossi", "Leopoldo", ""]]}, {"id": "2106.10566", "submitter": "Mengdi Xu", "authors": "Mengdi Xu, Peide Huang, Fengpei Li, Jiacheng Zhu, Xuewei Qi, Kentaro\n  Oguchi, Zhiyuan Huang, Henry Lam, Ding Zhao", "title": "Accelerated Policy Evaluation: Learning Adversarial Environments with\n  Adaptive Importance Sampling", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evaluation of rare but high-stakes events remains one of the main\ndifficulties in obtaining reliable policies from intelligent agents, especially\nin large or continuous state/action spaces where limited scalability enforces\nthe use of a prohibitively large number of testing iterations. On the other\nhand, a biased or inaccurate policy evaluation in a safety-critical system\ncould potentially cause unexpected catastrophic failures during deployment. In\nthis paper, we propose the Accelerated Policy Evaluation (APE) method, which\nsimultaneously uncovers rare events and estimates the rare event probability in\nMarkov decision processes. The APE method treats the environment nature as an\nadversarial agent and learns towards, through adaptive importance sampling, the\nzero-variance sampling distribution for the policy evaluation. Moreover, APE is\nscalable to large discrete or continuous spaces by incorporating function\napproximators. We investigate the convergence properties of proposed algorithms\nunder suitable regularity conditions. Our empirical studies show that APE\nestimates rare event probability with a smaller variance while only using\norders of magnitude fewer samples compared to baseline methods in both\nmulti-agent and single-agent environments.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 20:03:26 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Xu", "Mengdi", ""], ["Huang", "Peide", ""], ["Li", "Fengpei", ""], ["Zhu", "Jiacheng", ""], ["Qi", "Xuewei", ""], ["Oguchi", "Kentaro", ""], ["Huang", "Zhiyuan", ""], ["Lam", "Henry", ""], ["Zhao", "Ding", ""]]}, {"id": "2106.10598", "submitter": "Wenyuan Xue", "authors": "Wenyuan Xue and Baosheng Yu and Wen Wang and Dacheng Tao and Qingyong\n  Li", "title": "TGRNet: A Table Graph Reconstruction Network for Table Structure\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A table arranging data in rows and columns is a very effective data\nstructure, which has been widely used in business and scientific research.\nConsidering large-scale tabular data in online and offline documents, automatic\ntable recognition has attracted increasing attention from the document analysis\ncommunity. Though human can easily understand the structure of tables, it\nremains a challenge for machines to understand that, especially due to a\nvariety of different table layouts and styles. Existing methods usually model a\ntable as either the markup sequence or the adjacency matrix between different\ntable cells, failing to address the importance of the logical location of table\ncells, e.g., a cell is located in the first row and the second column of the\ntable. In this paper, we reformulate the problem of table structure recognition\nas the table graph reconstruction, and propose an end-to-end trainable table\ngraph reconstruction network (TGRNet) for table structure recognition.\nSpecifically, the proposed method has two main branches, a cell detection\nbranch and a cell logical location branch, to jointly predict the spatial\nlocation and the logical location of different cells. Experimental results on\nthree popular table recognition datasets and a new dataset with table graph\nannotations (TableGraph-350K) demonstrate the effectiveness of the proposed\nTGRNet for table structure recognition. Code and annotations will be made\npublicly available.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 01:57:05 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 03:08:37 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Xue", "Wenyuan", ""], ["Yu", "Baosheng", ""], ["Wang", "Wen", ""], ["Tao", "Dacheng", ""], ["Li", "Qingyong", ""]]}, {"id": "2106.10600", "submitter": "Tharindu Cyril Weerasooriya", "authors": "Tharindu Cyril Weerasooriya, Alexander G. Ororbia, Christopher M.\n  Homan", "title": "Improving Label Quality by Jointly Modeling Items and Annotators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a fully Bayesian framework for learning ground truth labels from\nnoisy annotators.\n  Our framework ensures scalability by factoring a generative, Bayesian soft\nclustering model over label distributions into the classic David and Skene\njoint annotator-data model. Earlier research along these lines has neither\nfully incorporated label distributions nor explored clustering by annotators\nonly or data only. Our framework incorporates all of these properties as:\n  (1) a graphical model designed to provide better ground truth estimates of\nannotator responses as input to \\emph{any} black box supervised learning\nalgorithm, and\n  (2) a standalone neural model whose internal structure captures many of the\nproperties of the graphical model.\n  We conduct supervised learning experiments using both models and compare them\nto the performance of one baseline and a state-of-the-art model.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 02:15:20 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Weerasooriya", "Tharindu Cyril", ""], ["Ororbia", "Alexander G.", ""], ["Homan", "Christopher M.", ""]]}, {"id": "2106.10606", "submitter": "Naveed Akhtar Dr.", "authors": "Naveed Akhtar, Muhammad A. A. K. Jalwana, Mohammed Bennamoun, Ajmal\n  Mian", "title": "Attack to Fool and Explain Deep Networks", "comments": "To appear in IEEE TPAMI. arXiv admin note: text overlap with\n  arXiv:1905.11544", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep visual models are susceptible to adversarial perturbations to inputs.\nAlthough these signals are carefully crafted, they still appear noise-like\npatterns to humans. This observation has led to the argument that deep visual\nrepresentation is misaligned with human perception. We counter-argue by\nproviding evidence of human-meaningful patterns in adversarial perturbations.\nWe first propose an attack that fools a network to confuse a whole category of\nobjects (source class) with a target label. Our attack also limits the\nunintended fooling by samples from non-sources classes, thereby circumscribing\nhuman-defined semantic notions for network fooling. We show that the proposed\nattack not only leads to the emergence of regular geometric patterns in the\nperturbations, but also reveals insightful information about the decision\nboundaries of deep models. Exploring this phenomenon further, we alter the\n`adversarial' objective of our attack to use it as a tool to `explain' deep\nvisual representation. We show that by careful channeling and projection of the\nperturbations computed by our method, we can visualize a model's understanding\nof human-defined semantic notions. Finally, we exploit the explanability\nproperties of our perturbations to perform image generation, inpainting and\ninteractive image manipulation by attacking adversarialy robust\n`classifiers'.In all, our major contribution is a novel pragmatic adversarial\nattack that is subsequently transformed into a tool to interpret the visual\nmodels. The article also makes secondary contributions in terms of establishing\nthe utility of our attack beyond the adversarial objective with multiple\ninteresting applications.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 03:07:36 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Akhtar", "Naveed", ""], ["Jalwana", "Muhammad A. A. K.", ""], ["Bennamoun", "Mohammed", ""], ["Mian", "Ajmal", ""]]}, {"id": "2106.10610", "submitter": "Anna Trella", "authors": "Anna L. Trella, Peniel N. Argaw, Michelle M. Li, James A. Hay", "title": "Discrepancies in Epidemiological Modeling of Aggregated Heterogeneous\n  Data", "comments": "Accepted to IJCAI 2021 Workshop on Artificial Intelligence for Social\n  Good", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.PE stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Within epidemiological modeling, the majority of analyses assume a single\nepidemic process for generating ground-truth data. However, this assumed data\ngeneration process can be unrealistic, since data sources for epidemics are\noften aggregated across geographic regions and communities. As a result,\nstate-of-the-art models for estimating epidemiological parameters,\ne.g.~transmission rates, can be inappropriate when faced with complex systems.\nOur work empirically demonstrates some limitations of applying epidemiological\nmodels to aggregated datasets. We generate three complex outbreak scenarios by\ncombining incidence curves from multiple epidemics that are independently\nsimulated via SEIR models with different sets of parameters. Using these\nscenarios, we assess the robustness of a state-of-the-art Bayesian inference\nmethod that estimates the epidemic trajectory from viral load surveillance\ndata. We evaluate two data-generating models within this Bayesian inference\nframework: a simple exponential growth model and a highly flexible Gaussian\nprocess prior model. Our results show that both models generate accurate\ntransmission rate estimates for the combined incidence curve at the cost of\ngenerating biased estimates for each underlying epidemic, reflecting highly\nheterogeneous underlying population dynamics. The exponential growth model,\nwhile interpretable, is unable to capture the complexity of the underlying\nepidemics. With sufficient surveillance data, the Gaussian process prior model\ncaptures the shape of complex trajectories, but is imprecise for periods of low\ndata coverage. Thus, our results highlight the potential pitfalls of neglecting\ncomplexity and heterogeneity in the data generation process, which can mask\nunderlying location- and population-specific epidemic dynamics.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 03:41:19 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Trella", "Anna L.", ""], ["Argaw", "Peniel N.", ""], ["Li", "Michelle M.", ""], ["Hay", "James A.", ""]]}, {"id": "2106.10649", "submitter": "Naveed Akhtar Dr.", "authors": "Mohammad A. A. K. Jalwana, Naveed Akhtar, Mohammed Bennamoun, Ajmal\n  Mian", "title": "CAMERAS: Enhanced Resolution And Sanity preserving Class Activation\n  Mapping for image saliency", "comments": "IEEE CVPR 2021 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backpropagation image saliency aims at explaining model predictions by\nestimating model-centric importance of individual pixels in the input. However,\nclass-insensitivity of the earlier layers in a network only allows saliency\ncomputation with low resolution activation maps of the deeper layers, resulting\nin compromised image saliency. Remedifying this can lead to sanity failures. We\npropose CAMERAS, a technique to compute high-fidelity backpropagation saliency\nmaps without requiring any external priors and preserving the map sanity. Our\nmethod systematically performs multi-scale accumulation and fusion of the\nactivation maps and backpropagated gradients to compute precise saliency maps.\nFrom accurate image saliency to articulation of relative importance of input\nfeatures for different models, and precise discrimination between model\nperception of visually similar objects, our high-resolution mapping offers\nmultiple novel insights into the black-box deep visual models, which are\npresented in the paper. We also demonstrate the utility of our saliency maps in\nadversarial setup by drastically reducing the norm of attack signals by\nfocusing them on the precise regions identified by our maps. Our method also\ninspires new evaluation metrics and a sanity check for this developing research\ndirection. Code is available here https://github.com/VisMIL/CAMERAS\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 08:20:56 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Jalwana", "Mohammad A. A. K.", ""], ["Akhtar", "Naveed", ""], ["Bennamoun", "Mohammed", ""], ["Mian", "Ajmal", ""]]}, {"id": "2106.10679", "submitter": "Carmel Wenga", "authors": "Carmel Wenga, Majirus Fansi, S\\'ebastien Chabrier, Jean-Martial Mari,\n  Alban Gabillon", "title": "A Comprehensive Review on Non-Neural Networks Collaborative Filtering\n  Recommendation Systems", "comments": "29 pages, 7 tables and 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past two decades, recommender systems have attracted a lot of\ninterest due to the explosion in the amount of data in online applications. A\nparticular attention has been paid to collaborative filtering, which is the\nmost widely used in applications that involve information recommendations.\nCollaborative filtering (CF) uses the known preference of a group of users to\nmake predictions and recommendations about the unknown preferences of other\nusers (recommendations are made based on the past behavior of users). First\nintroduced in the 1990s, a wide variety of increasingly successful models have\nbeen proposed. Due to the success of machine learning techniques in many areas,\nthere has been a growing emphasis on the application of such algorithms in\nrecommendation systems. In this article, we present an overview of the CF\napproaches for recommender systems, their two main categories, and their\nevaluation metrics. We focus on the application of classical Machine Learning\nalgorithms to CF recommender systems by presenting their evolution from their\nfirst use-cases to advanced Machine Learning models. We attempt to provide a\ncomprehensive and comparative overview of CF systems (with python\nimplementations) that can serve as a guideline for research and practice in\nthis area.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 11:13:33 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 17:52:30 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Wenga", "Carmel", ""], ["Fansi", "Majirus", ""], ["Chabrier", "S\u00e9bastien", ""], ["Mari", "Jean-Martial", ""], ["Gabillon", "Alban", ""]]}, {"id": "2106.10681", "submitter": "Jiapeng Wang", "authors": "Jiapeng Wang, Tianwei Wang, Guozhi Tang, Lianwen Jin, Weihong Ma, Kai\n  Ding, Yichao Huang", "title": "Tag, Copy or Predict: A Unified Weakly-Supervised Learning Framework for\n  Visual Information Extraction using Sequences", "comments": "IJCAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual information extraction (VIE) has attracted increasing attention in\nrecent years. The existing methods usually first organized optical character\nrecognition (OCR) results into plain texts and then utilized token-level entity\nannotations as supervision to train a sequence tagging model. However, it\nexpends great annotation costs and may be exposed to label confusion, and the\nOCR errors will also significantly affect the final performance. In this paper,\nwe propose a unified weakly-supervised learning framework called TCPN (Tag,\nCopy or Predict Network), which introduces 1) an efficient encoder to\nsimultaneously model the semantic and layout information in 2D OCR results; 2)\na weakly-supervised training strategy that utilizes only key information\nsequences as supervision; and 3) a flexible and switchable decoder which\ncontains two inference modes: one (Copy or Predict Mode) is to output key\ninformation sequences of different categories by copying a token from the input\nor predicting one in each time step, and the other (Tag Mode) is to directly\ntag the input sequence in a single forward pass. Our method shows new\nstate-of-the-art performance on several public benchmarks, which fully proves\nits effectiveness.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 11:56:46 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Wang", "Jiapeng", ""], ["Wang", "Tianwei", ""], ["Tang", "Guozhi", ""], ["Jin", "Lianwen", ""], ["Ma", "Weihong", ""], ["Ding", "Kai", ""], ["Huang", "Yichao", ""]]}, {"id": "2106.10683", "submitter": "Jia-Xin Zhuang", "authors": "Yuqiao Xian, Jia-Xin Zhuang, Fufu Yu", "title": "Solution for Large-scale Long-tailed Recognition with Noisy Labels", "comments": "3 pages", "journal-ref": "CVPR 2021 AliProducts Challenge: CVPR 2021 AliProducts\n  Challenge:Large-scale Product Recognition, Technical Report", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a technical report for CVPR 2021 AliProducts Challenge. AliProducts\nChallenge is a competition proposed for studying the large-scale and\nfine-grained commodity image recognition problem encountered by worldleading\necommerce companies. The large-scale product recognition simultaneously meets\nthe challenge of noisy annotations, imbalanced (long-tailed) data distribution\nand fine-grained classification. In our solution, we adopt stateof-the-art\nmodel architectures of both CNNs and Transformer, including ResNeSt,\nEfficientNetV2, and DeiT. We found that iterative data cleaning, classifier\nweight normalization, high-resolution finetuning, and test time augmentation\nare key components to improve the performance of training with the noisy and\nimbalanced dataset. Finally, we obtain 6.4365% mean class error rate in the\nleaderboard with our ensemble model.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 12:09:38 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Xian", "Yuqiao", ""], ["Zhuang", "Jia-Xin", ""], ["Yu", "Fufu", ""]]}, {"id": "2106.10684", "submitter": "Toni Mancini", "authors": "Stefano Sinisi, Vadim Alimguzhin, Toni Mancini, Enrico Tronci,\n  Federico Mari, Brigitte Leeners", "title": "Optimal personalised treatment computation through in silico clinical\n  trials on patient digital twins", "comments": "31 pages, 9 figures", "journal-ref": "Fundamenta Informaticae, 174(3-4):283-310, 2020", "doi": "10.3233/FI-2020-1943", "report-no": null, "categories": "cs.AI q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In Silico Clinical Trials (ISTC), i.e., clinical experimental campaigns\ncarried out by means of computer simulations, hold the promise to decrease time\nand cost for the safety and efficacy assessment of pharmacological treatments,\nreduce the need for animal and human testing, and enable precision medicine. In\nthis paper we present methods and an algorithm that, by means of extensive\ncomputer simulation--based experimental campaigns (ISTC) guided by intelligent\nsearch, optimise a pharmacological treatment for an individual patient\n(precision medicine). e show the effectiveness of our approach on a case study\ninvolving a real pharmacological treatment, namely the downregulation phase of\na complex clinical protocol for assisted reproduction in humans.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 12:12:36 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Sinisi", "Stefano", ""], ["Alimguzhin", "Vadim", ""], ["Mancini", "Toni", ""], ["Tronci", "Enrico", ""], ["Mari", "Federico", ""], ["Leeners", "Brigitte", ""]]}, {"id": "2106.10685", "submitter": "Toni Mancini", "authors": "Quian Matteo Chen, Alberto Finzi, Toni Mancini, Igor Melatti, Enrico\n  Tronci", "title": "MILP, pseudo-boolean, and OMT solvers for optimal fault-tolerant\n  placements of relay nodes in mission critical wireless networks", "comments": "33 pages, 11 figures", "journal-ref": "Fundamenta Informaticae, 174(3-4):229-258, 2020", "doi": "10.3233/FI-2020-1941", "report-no": null, "categories": "cs.AI cs.DC cs.LO cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In critical infrastructures like airports, much care has to be devoted in\nprotecting radio communication networks from external electromagnetic\ninterference. Protection of such mission-critical radio communication networks\nis usually tackled by exploiting radiogoniometers: at least three suitably\ndeployed radiogoniometers, and a gateway gathering information from them,\npermit to monitor and localise sources of electromagnetic emissions that are\nnot supposed to be present in the monitored area. Typically, radiogoniometers\nare connected to the gateway through relay nodes. As a result, some degree of\nfault-tolerance for the network of relay nodes is essential in order to offer a\nreliable monitoring. On the other hand, deployment of relay nodes is typically\nquite expensive. As a result, we have two conflicting requirements: minimise\ncosts while guaranteeing a given fault-tolerance. In this paper, we address the\nproblem of computing a deployment for relay nodes that minimises the relay node\nnetwork cost while at the same time guaranteeing proper working of the network\neven when some of the relay nodes (up to a given maximum number) become faulty\n(fault-tolerance). We show that, by means of a computation-intensive\npre-processing on a HPC infrastructure, the above optimisation problem can be\nencoded as a 0/1 Linear Program, becoming suitable to be approached with\nstandard Artificial Intelligence reasoners like MILP, PB-SAT, and SMT/OMT\nsolvers. Our problem formulation enables us to present experimental results\ncomparing the performance of these three solving technologies on a real case\nstudy of a relay node network deployment in areas of the Leonardo da Vinci\nAirport in Rome, Italy.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 12:14:36 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Chen", "Quian Matteo", ""], ["Finzi", "Alberto", ""], ["Mancini", "Toni", ""], ["Melatti", "Igor", ""], ["Tronci", "Enrico", ""]]}, {"id": "2106.10693", "submitter": "Ling Zhang", "authors": "Ling Zhang, Jack Juang, Zurab Kiguradze, Bo Pu, Shuai Jin, Songping\n  Wu, Zhiping Yang, Chulsoon Hwang", "title": "Fast PDN Impedance Prediction Using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling and simulating a power distribution network (PDN) for printed\ncircuit boards (PCBs) with irregular board shapes and multi-layer stackup is\ncomputationally inefficient using full-wave simulations. This paper presents a\nnew concept of using deep learning for PDN impedance prediction. A boundary\nelement method (BEM) is applied to efficiently calculate the impedance for\narbitrary board shape and stackup. Then over one million boards with different\nshapes, stackup, IC location, and decap placement are randomly generated to\ntrain a deep neural network (DNN). The trained DNN can predict the impedance\naccurately for new board configurations that have not been used for training.\nThe consumed time using the trained DNN is only 0.1 seconds, which is over 100\ntimes faster than the BEM method and 5000 times faster than full-wave\nsimulations.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 13:12:43 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Zhang", "Ling", ""], ["Juang", "Jack", ""], ["Kiguradze", "Zurab", ""], ["Pu", "Bo", ""], ["Jin", "Shuai", ""], ["Wu", "Songping", ""], ["Yang", "Zhiping", ""], ["Hwang", "Chulsoon", ""]]}, {"id": "2106.10698", "submitter": "Pranesh Kulkarni", "authors": "Pranesh Kulkarni, Atharva Karwande, Tejas Kolhe, Soham Kamble, Akshay\n  Joshi, Medha Wyawahare", "title": "Plant Disease Detection Using Image Processing and Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  One of the important and tedious task in agricultural practices is the\ndetection of the disease on crops. It requires huge time as well as skilled\nlabor. This paper proposes a smart and efficient technique for detection of\ncrop disease which uses computer vision and machine learning techniques. The\nproposed system is able to detect 20 different diseases of 5 common plants with\n93% accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 14:11:24 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Kulkarni", "Pranesh", ""], ["Karwande", "Atharva", ""], ["Kolhe", "Tejas", ""], ["Kamble", "Soham", ""], ["Joshi", "Akshay", ""], ["Wyawahare", "Medha", ""]]}, {"id": "2106.10731", "submitter": "Zhun Zhong", "authors": "Zhun Zhong, Enrico Fini, Subhankar Roy, Zhiming Luo, Elisa Ricci, Nicu\n  Sebe", "title": "Neighborhood Contrastive Learning for Novel Class Discovery", "comments": "CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we address Novel Class Discovery (NCD), the task of unveiling\nnew classes in a set of unlabeled samples given a labeled dataset with known\nclasses. We exploit the peculiarities of NCD to build a new framework, named\nNeighborhood Contrastive Learning (NCL), to learn discriminative\nrepresentations that are important to clustering performance. Our contribution\nis twofold. First, we find that a feature extractor trained on the labeled set\ngenerates representations in which a generic query sample and its neighbors are\nlikely to share the same class. We exploit this observation to retrieve and\naggregate pseudo-positive pairs with contrastive learning, thus encouraging the\nmodel to learn more discriminative representations. Second, we notice that most\nof the instances are easily discriminated by the network, contributing less to\nthe contrastive loss. To overcome this issue, we propose to generate hard\nnegatives by mixing labeled and unlabeled samples in the feature space. We\nexperimentally demonstrate that these two ingredients significantly contribute\nto clustering performance and lead our model to outperform state-of-the-art\nmethods by a large margin (e.g., clustering accuracy +13% on CIFAR-100 and +8%\non ImageNet).\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 17:34:55 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Zhong", "Zhun", ""], ["Fini", "Enrico", ""], ["Roy", "Subhankar", ""], ["Luo", "Zhiming", ""], ["Ricci", "Elisa", ""], ["Sebe", "Nicu", ""]]}, {"id": "2106.10734", "submitter": "Jiyue Huang", "authors": "Jiyue Huang, Chi Hong, Lydia Y. Chen, Stefanie Roos", "title": "Is Shapley Value fair? Improving Client Selection for Mavericks in\n  Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Shapley Value is commonly adopted to measure and incentivize client\nparticipation in federated learning. In this paper, we show -- theoretically\nand through simulations -- that Shapley Value underestimates the contribution\nof a common type of client: the Maverick. Mavericks are clients that differ\nboth in data distribution and data quantity and can be the sole owners of\ncertain types of data. Selecting the right clients at the right moment is\nimportant for federated learning to reduce convergence times and improve\naccuracy. We propose FedEMD, an adaptive client selection strategy based on the\nWasserstein distance between the local and global data distributions. As FedEMD\nadapts the selection probability such that Mavericks are preferably selected\nwhen the model benefits from improvement on rare classes, it consistently\nensures the fast convergence in the presence of different types of Mavericks.\nCompared to existing strategies, including Shapley Value-based ones, FedEMD\nimproves the convergence of neural network classifiers by at least 26.9% for\nFedAvg aggregation compared with the state of the art.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 18:01:15 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Huang", "Jiyue", ""], ["Hong", "Chi", ""], ["Chen", "Lydia Y.", ""], ["Roos", "Stefanie", ""]]}, {"id": "2106.10766", "submitter": "Satyaki Chakraborty", "authors": "Satyaki Chakraborty, Martial Hebert", "title": "Learning to Track Object Position through Occlusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Occlusion is one of the most significant challenges encountered by object\ndetectors and trackers. While both object detection and tracking has received a\nlot of attention in the past, most existing methods in this domain do not\ntarget detecting or tracking objects when they are occluded. However, being\nable to detect or track an object of interest through occlusion has been a long\nstanding challenge for different autonomous tasks. Traditional methods that\nemploy visual object trackers with explicit occlusion modeling experience drift\nand make several fundamental assumptions about the data. We propose to address\nthis with a `tracking-by-detection` approach that builds upon the success of\nregion based video object detectors. Our video level object detector uses a\nnovel recurrent computational unit at its core that enables long term\npropagation of object features even under occlusion. Finally, we compare our\napproach with existing state-of-the-art video object detectors and show that\nour approach achieves superior results on a dataset of furniture assembly\nvideos collected from the internet, where small objects like screws, nuts, and\nbolts often get occluded from the camera viewpoint.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 22:29:46 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Chakraborty", "Satyaki", ""], ["Hebert", "Martial", ""]]}, {"id": "2106.10783", "submitter": "Wonseok Jeon", "authors": "Jongmin Lee, Wonseok Jeon, Byung-Jun Lee, Joelle Pineau, Kee-Eung Kim", "title": "OptiDICE: Offline Policy Optimization via Stationary Distribution\n  Correction Estimation", "comments": "26 pages, 11 figures, Accepted at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We consider the offline reinforcement learning (RL) setting where the agent\naims to optimize the policy solely from the data without further environment\ninteractions. In offline RL, the distributional shift becomes the primary\nsource of difficulty, which arises from the deviation of the target policy\nbeing optimized from the behavior policy used for data collection. This\ntypically causes overestimation of action values, which poses severe problems\nfor model-free algorithms that use bootstrapping. To mitigate the problem,\nprior offline RL algorithms often used sophisticated techniques that encourage\nunderestimation of action values, which introduces an additional set of\nhyperparameters that need to be tuned properly. In this paper, we present an\noffline RL algorithm that prevents overestimation in a more principled way. Our\nalgorithm, OptiDICE, directly estimates the stationary distribution corrections\nof the optimal policy and does not rely on policy-gradients, unlike previous\noffline RL algorithms. Using an extensive set of benchmark datasets for offline\nRL, we show that OptiDICE performs competitively with the state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 00:43:30 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Lee", "Jongmin", ""], ["Jeon", "Wonseok", ""], ["Lee", "Byung-Jun", ""], ["Pineau", "Joelle", ""], ["Kim", "Kee-Eung", ""]]}, {"id": "2106.10785", "submitter": "Jiaqi Ma", "authors": "Jiaqi Ma, Junwei Deng, Qiaozhu Mei", "title": "Adversarial Attack on Graph Neural Networks as An Influence Maximization\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have attracted increasing interests. With broad\ndeployments of GNNs in real-world applications, there is an urgent need for\nunderstanding the robustness of GNNs under adversarial attacks, especially in\nrealistic setups. In this work, we study the problem of attacking GNNs in a\nrestricted and realistic setup, by perturbing the features of a small set of\nnodes, with no access to model parameters and model predictions. Our formal\nanalysis draws a connection between this type of attacks and an influence\nmaximization problem on the graph. This connection not only enhances our\nunderstanding on the problem of adversarial attack on GNNs, but also allows us\nto propose a group of effective and practical attack strategies. Our\nexperiments verify that the proposed attack strategies significantly degrade\nthe performance of three popular GNN models and outperform baseline adversarial\nattack strategies.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 00:47:44 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Ma", "Jiaqi", ""], ["Deng", "Junwei", ""], ["Mei", "Qiaozhu", ""]]}, {"id": "2106.10811", "submitter": "Yizhak Ben-Shabat", "authors": "Yizhak Ben-Shabat, Chamin Hewa Koneputugodage, Stephen Gould", "title": "DiGS : Divergence guided shape implicit neural representation for\n  unoriented point clouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural shape representations have recently shown to be effective in shape\nanalysis and reconstruction tasks. Existing neural network methods require\npoint coordinates and corresponding normal vectors to learn the implicit level\nsets of the shape. Normal vectors are often not provided as raw data,\ntherefore, approximation and reorientation are required as pre-processing\nstages, both of which can introduce noise. In this paper, we propose a\ndivergence guided shape representation learning approach that does not require\nnormal vectors as input. We show that incorporating a soft constraint on the\ndivergence of the distance function favours smooth solutions that reliably\norients gradients to match the unknown normal at each point, in some cases even\nbetter than approaches that use ground truth normal vectors directly.\nAdditionally, we introduce a novel geometric initialization method for\nsinusoidal shape representation networks that further improves convergence to\nthe desired solution. We evaluate the effectiveness of our approach on the task\nof surface reconstruction and show state-of-the-art performance compared to\nother unoriented methods and on-par performance compared to oriented methods.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 02:10:03 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Ben-Shabat", "Yizhak", ""], ["Koneputugodage", "Chamin Hewa", ""], ["Gould", "Stephen", ""]]}, {"id": "2106.10832", "submitter": "Stefan Sarkadi", "authors": "OHAAI Collaboration: Andreas Brannstrom, Federico Castagna, Theo\n  Duchatelle, Matt Foulis, Timotheus Kampik, Isabelle Kuhlmann, Lars Malmqvist,\n  Mariela Morveli-Espinoza, Jack Mumford, Stipe Pandzic, Robin Schaefer, Luke\n  Thorburn, Andreas Xydis, Antonio Yuste-Ginel, Heng Zheng", "title": "Online Handbook of Argumentation for AI: Volume 2", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This volume contains revised versions of the papers selected for the second\nvolume of the Online Handbook of Argumentation for AI (OHAAI). Previously,\nformal theories of argument and argument interaction have been proposed and\nstudied, and this has led to the more recent study of computational models of\nargument. Argumentation, as a field within artificial intelligence (AI), is\nhighly relevant for researchers interested in symbolic representations of\nknowledge and defeasible reasoning. The purpose of this handbook is to provide\nan open access and curated anthology for the argumentation research community.\nOHAAI is designed to serve as a research hub to keep track of the latest and\nupcoming PhD-driven research on the theory and application of argumentation in\nall areas related to AI.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 13:34:13 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 11:24:19 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["OHAAI Collaboration", "", ""], ["Brannstrom", "Andreas", ""], ["Castagna", "Federico", ""], ["Duchatelle", "Theo", ""], ["Foulis", "Matt", ""], ["Kampik", "Timotheus", ""], ["Kuhlmann", "Isabelle", ""], ["Malmqvist", "Lars", ""], ["Morveli-Espinoza", "Mariela", ""], ["Mumford", "Jack", ""], ["Pandzic", "Stipe", ""], ["Schaefer", "Robin", ""], ["Thorburn", "Luke", ""], ["Xydis", "Andreas", ""], ["Yuste-Ginel", "Antonio", ""], ["Zheng", "Heng", ""]]}, {"id": "2106.10840", "submitter": "Hongyu Gong", "authors": "Hongyu Gong, Yun Tang, Juan Pino, Xian Li", "title": "Pay Better Attention to Attention: Head Selection in Multilingual and\n  Multi-Domain Sequence Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-head attention has each of the attention heads collect salient\ninformation from different parts of an input sequence, making it a powerful\nmechanism for sequence modeling. Multilingual and multi-domain learning are\ncommon scenarios for sequence modeling, where the key challenge is to maximize\npositive transfer and mitigate negative transfer across languages and domains.\nIn this paper, we find that non-selective attention sharing is sub-optimal for\nachieving good generalization across all languages and domains. We further\npropose attention sharing strategies to facilitate parameter sharing and\nspecialization in multilingual and multi-domain sequence modeling. Our approach\nautomatically learns shared and specialized attention heads for different\nlanguages and domains to mitigate their interference. Evaluated in various\ntasks including speech recognition, text-to-text and speech-to-text\ntranslation, the proposed attention sharing strategies consistently bring gains\nto sequence models built upon multi-head attention. For speech-to-text\ntranslation, our approach yields an average of $+2.0$ BLEU over $13$ language\ndirections in multilingual setting and $+2.0$ BLEU over $3$ domains in\nmulti-domain setting.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 04:03:23 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Gong", "Hongyu", ""], ["Tang", "Yun", ""], ["Pino", "Juan", ""], ["Li", "Xian", ""]]}, {"id": "2106.10846", "submitter": "Guizhong Liu", "authors": "Jianyi Li and Guizhong Liu", "title": "Trainable Class Prototypes for Few-Shot Learning", "comments": "8 pages, 2 figures,and 3 Tables. arXiv admin note: substantial text\n  overlap with arXiv:2008.09942", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Metric learning is a widely used method for few shot learning in which the\nquality of prototypes plays a key role in the algorithm. In this paper we\npropose the trainable prototypes for distance measure instead of the artificial\nones within the meta-training and task-training framework. Also to avoid the\ndisadvantages that the episodic meta-training brought, we adopt non-episodic\nmeta-training based on self-supervised learning. Overall we solve the few-shot\ntasks in two phases: meta-training a transferable feature extractor via\nself-supervised learning and training the prototypes for metric classification.\nIn addition, the simple attention mechanism is used in both meta-training and\ntask-training. Our method achieves state-of-the-art performance in a variety of\nestablished few-shot tasks on the standard few-shot visual classification\ndataset, with about 20% increase compared to the available unsupervised\nfew-shot learning methods.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 04:19:56 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Li", "Jianyi", ""], ["Liu", "Guizhong", ""]]}, {"id": "2106.10853", "submitter": "Stefanos Nikolaidis", "authors": "Matthew C. Fontaine, Ya-Chuan Hsu, Yulun Zhang, Bryon Tjanaka and\n  Stefanos Nikolaidis", "title": "On the Importance of Environments in Human-Robot Coordination", "comments": "Accepted to Robotics: Science and Systems (RSS) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When studying robots collaborating with humans, much of the focus has been on\nrobot policies that coordinate fluently with human teammates in collaborative\ntasks. However, less emphasis has been placed on the effect of the environment\non coordination behaviors. To thoroughly explore environments that result in\ndiverse behaviors, we propose a framework for procedural generation of\nenvironments that are (1) stylistically similar to human-authored environments,\n(2) guaranteed to be solvable by the human-robot team, and (3) diverse with\nrespect to coordination measures. We analyze the procedurally generated\nenvironments in the Overcooked benchmark domain via simulation and an online\nuser study. Results show that the environments result in qualitatively\ndifferent emerging behaviors and statistically significant differences in\ncollaborative fluency metrics, even when the robot runs the same planning\nalgorithm.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 04:39:55 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 20:44:45 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Fontaine", "Matthew C.", ""], ["Hsu", "Ya-Chuan", ""], ["Zhang", "Yulun", ""], ["Tjanaka", "Bryon", ""], ["Nikolaidis", "Stefanos", ""]]}, {"id": "2106.10876", "submitter": "Hao Tang", "authors": "Hao Tang, Nicu Sebe", "title": "Total Generate: Cycle in Cycle Generative Adversarial Networks for\n  Generating Human Faces, Hands, Bodies, and Natural Scenes", "comments": "Accepted to TMM, an extended version of a paper published in ACM MM\n  2019. arXiv admin note: substantial text overlap with arXiv:1908.00999", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel and unified Cycle in Cycle Generative Adversarial Network\n(C2GAN) for generating human faces, hands, bodies, and natural scenes. Our\nproposed C2GAN is a cross-modal model exploring the joint exploitation of the\ninput image data and guidance data in an interactive manner. C2GAN contains two\ndifferent generators, i.e., an image-generation generator and a\nguidance-generation generator. Both generators are mutually connected and\ntrained in an end-to-end fashion and explicitly form three cycled subnets,\ni.e., one image generation cycle and two guidance generation cycles. Each cycle\naims at reconstructing the input domain and simultaneously produces a useful\noutput involved in the generation of another cycle. In this way, the cycles\nconstrain each other implicitly providing complementary information from both\nimage and guidance modalities and bringing an extra supervision gradient across\nthe cycles, facilitating a more robust optimization of the whole model.\nExtensive results on four guided image-to-image translation subtasks\ndemonstrate that the proposed C2GAN is effective in generating more realistic\nimages compared with state-of-the-art models. The code is available at\nhttps://github.com/Ha0Tang/C2GAN.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 06:20:16 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Tang", "Hao", ""], ["Sebe", "Nicu", ""]]}, {"id": "2106.10886", "submitter": "EPTCS", "authors": "Joseph Halpern (Cornell University), Andr\\'es Perea (Maastricht\n  University)", "title": "Proceedings Eighteenth Conference on Theoretical Aspects of Rationality\n  and Knowledge", "comments": null, "journal-ref": "EPTCS 335, 2021", "doi": "10.4204/EPTCS.335", "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The TARK conference (Theoretical Aspects of Rationality and Knowledge) is a\nbiannual conference that aims to bring together researchers from a wide variety\nof fields, including computer science, artificial intelligence, game theory,\ndecision theory, philosophy, logic, linguistics, and cognitive science. Its\ngoal is to further our understanding of interdisciplinary issues involving\nreasoning about rationality and knowledge.\n  Topics of interest include, but are not limited to, semantic models for\nknowledge, belief, awareness and uncertainty, bounded rationality and\nresource-bounded reasoning, commonsense epistemic reasoning, epistemic logic,\nepistemic game theory, knowledge and action, applications of reasoning about\nknowledge and other mental states, belief revision, and foundations of\nmulti-agent systems.\n  These proceedings contain the papers that have been accepted for presentation\nat the Eighteenth Conference on Theoretical Aspects of Rationality and\nKnowledge (TARK 2021), held between June 25 and June 27, 2021, at Tsinghua\nUniversity at Beijing, China.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 07:01:14 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Halpern", "Joseph", "", "Cornell University"], ["Perea", "Andr\u00e9s", "", "Maastricht\n  University"]]}, {"id": "2106.10891", "submitter": "Hongxin Wei", "authors": "Hongxin Wei, Lue Tao, Renchunzi Xie, Bo An", "title": "Open-set Label Noise Can Improve Robustness Against Inherent Label Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning with noisy labels is a practically challenging problem in weakly\nsupervised learning. In the existing literature, open-set noises are always\nconsidered to be poisonous for generalization, similar to closed-set noises. In\nthis paper, we empirically show that open-set noisy labels can be non-toxic and\neven benefit the robustness against inherent noisy labels. Inspired by the\nobservations, we propose a simple yet effective regularization by introducing\nOpen-set samples with Dynamic Noisy Labels (ODNL) into training. With ODNL, the\nextra capacity of the neural network can be largely consumed in a way that does\nnot interfere with learning patterns from clean data. Through the lens of SGD\nnoise, we show that the noises induced by our method are random-direction,\nconflict-free and biased, which may help the model converge to a flat minimum\nwith superior stability and enforce the model to produce conservative\npredictions on Out-of-Distribution instances. Extensive experimental results on\nbenchmark datasets with various types of noisy labels demonstrate that the\nproposed method not only enhances the performance of many existing robust\nalgorithms but also achieves significant improvement on Out-of-Distribution\ndetection tasks even in the label noise setting.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 07:15:50 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Wei", "Hongxin", ""], ["Tao", "Lue", ""], ["Xie", "Renchunzi", ""], ["An", "Bo", ""]]}, {"id": "2106.10928", "submitter": "Nawshad Farruque", "authors": "Nawshad Farruque, Randy Goebel, Osmar Zaiane, Sudhakar Sivapalan", "title": "STEP-EZ: Syntax Tree guided semantic ExPlanation for Explainable\n  Zero-shot modeling of clinical depression symptoms from text", "comments": "Fixed an algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We focus on exploring various approaches of Zero-Shot Learning (ZSL) and\ntheir explainability for a challenging yet important supervised learning task\nnotorious for training data scarcity, i.e. Depression Symptoms Detection (DSD)\nfrom text. We start with a comprehensive synthesis of different components of\nour ZSL modeling and analysis of our ground truth samples and Depression\nsymptom clues curation process with the help of a practicing clinician. We next\nanalyze the accuracy of various state-of-the-art ZSL models and their potential\nenhancements for our task. Further, we sketch a framework for the use of ZSL\nfor hierarchical text-based explanation mechanism, which we call, Syntax\nTree-Guided Semantic Explanation (STEP). Finally, we summarize experiments from\nwhich we conclude that we can use ZSL models and achieve reasonable accuracy\nand explainability, measured by a proposed Explainability Index (EI). This work\nis, to our knowledge, the first work to exhaustively explore the efficacy of\nZSL models for DSD task, both in terms of accuracy and explainability.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 08:57:22 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 07:06:06 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Farruque", "Nawshad", ""], ["Goebel", "Randy", ""], ["Zaiane", "Osmar", ""], ["Sivapalan", "Sudhakar", ""]]}, {"id": "2106.10935", "submitter": "Yoan Russac", "authors": "Dorian Baudry (Inria, CRIStAL, CNRS), Yoan Russac (DI-ENS, CNRS,\n  VALDA), Olivier Capp\\'e (DI-ENS, CNRS, VALDA)", "title": "On Limited-Memory Subsampling Strategies for Bandits", "comments": null, "journal-ref": "ICML 2021- International Conference on Machine Learning, Jul 2021,\n  Vienna- Virtual, Austria", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a recent surge of interest in nonparametric bandit algorithms\nbased on subsampling. One drawback however of these approaches is the\nadditional complexity required by random subsampling and the storage of the\nfull history of rewards. Our first contribution is to show that a simple\ndeterministic subsampling rule, proposed in the recent work of Baudry et al.\n(2020) under the name of ''last-block subsampling'', is asymptotically optimal\nin one-parameter exponential families. In addition, we prove that these\nguarantees also hold when limiting the algorithm memory to a polylogarithmic\nfunction of the time horizon. These findings open up new perspectives, in\nparticular for non-stationary scenarios in which the arm distributions evolve\nover time. We propose a variant of the algorithm in which only the most recent\nobservations are used for subsampling, achieving optimal regret guarantees\nunder the assumption of a known number of abrupt changes. Extensive numerical\nsimulations highlight the merits of this approach, particularly when the\nchanges are not only affecting the means of the rewards.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 09:11:22 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Baudry", "Dorian", "", "Inria, CRIStAL, CNRS"], ["Russac", "Yoan", "", "DI-ENS, CNRS,\n  VALDA"], ["Capp\u00e9", "Olivier", "", "DI-ENS, CNRS, VALDA"]]}, {"id": "2106.10944", "submitter": "Bartosz W\\'ojcik", "authors": "Bartosz W\\'ojcik, Mateusz \\.Zarski, Kamil Ksi\\k{a}\\.zek, Jaros{\\l}aw\n  Adam Miszczak, Miros{\\l}aw Jan Skibniewski", "title": "Hard hat wearing detection based on head keypoint localization", "comments": "15 pages, 9 figures and 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, a lot of attention is paid to deep learning methods in the\ncontext of vision-based construction site safety systems, especially regarding\npersonal protective equipment. However, despite all this attention, there is\nstill no reliable way to establish the relationship between workers and their\nhard hats. To answer this problem a combination of deep learning, object\ndetection and head keypoint localization, with simple rule-based reasoning is\nproposed in this article. In tests, this solution surpassed the previous\nmethods based on the relative bounding box position of different instances, as\nwell as direct detection of hard hat wearers and non-wearers. The results show\nthat the conjunction of novel deep learning methods with humanly-interpretable\nrule-based systems can result in a solution that is both reliable and can\nsuccessfully mimic manual, on-site supervision. This work is the next step in\nthe development of fully autonomous construction site safety systems and shows\nthat there is still room for improvement in this area.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 09:31:33 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["W\u00f3jcik", "Bartosz", ""], ["\u017barski", "Mateusz", ""], ["Ksi\u0105\u017cek", "Kamil", ""], ["Miszczak", "Jaros\u0142aw Adam", ""], ["Skibniewski", "Miros\u0142aw Jan", ""]]}, {"id": "2106.10946", "submitter": "Michael Maher", "authors": "Michael J. Maher", "title": "Defeasible Reasoning via Datalog$^\\neg$", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We address the problem of compiling defeasible theories to Datalog$^\\neg$\nprograms. We prove the correctness of this compilation, for the defeasible\nlogic $DL(\\partial_{||})$, but the techniques we use apply to many other\ndefeasible logics. Structural properties of $DL(\\partial_{||})$ are identified\nthat support efficient implementation and/or approximation of the conclusions\nof defeasible theories in the logic, compared with other defeasible logics. We\nalso use previously well-studied structural properties of logic programs to\nadapt to incomplete Datalog$^\\neg$ implementations.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 09:38:06 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Maher", "Michael J.", ""]]}, {"id": "2106.10978", "submitter": "Dominik D\\\"urrschnabel", "authors": "Dominik D\\\"urrschnabel, Maren Koyda, Gerd Stumme", "title": "Attribute Selection using Contranominal Scales", "comments": "17 pages, 2 figures, 3 tables, 1 algorithm, 26th International\n  Conference on Conceptual Structures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal Concept Analysis (FCA) allows to analyze binary data by deriving\nconcepts and ordering them in lattices. One of the main goals of FCA is to\nenable humans to comprehend the information that is encapsulated in the data;\nhowever, the large size of concept lattices is a limiting factor for the\nfeasibility of understanding the underlying structural properties. The size of\nsuch a lattice depends on the number of subcontexts in the corresponding formal\ncontext that are isomorphic to a contranominal scale of high dimension. In this\nwork, we propose the algorithm ContraFinder that enables the computation of all\ncontranominal scales of a given formal context. Leveraging this algorithm, we\nintroduce delta-adjusting, a novel approach in order to decrease the number of\ncontranominal scales in a formal context by the selection of an appropriate\nattribute subset. We demonstrate that delta-adjusting a context reduces the\nsize of the hereby emerging sub-semilattice and that the implication set is\nrestricted to meaningful implications. This is evaluated with respect to its\nassociated knowledge by means of a classification task. Hence, our proposed\ntechnique strongly improves understandability while preserving important\nconceptual structures.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 10:53:50 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 10:41:49 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["D\u00fcrrschnabel", "Dominik", ""], ["Koyda", "Maren", ""], ["Stumme", "Gerd", ""]]}, {"id": "2106.10989", "submitter": "Jiaming Zhang", "authors": "Jiaming Zhang, Jitao Sang, Qi Yi, Huiwen Dong, Jian Yu", "title": "Pre-training also Transfers Non-Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-training has enabled many state-of-the-art results on many tasks. In\nspite of its recognized contribution to generalization, we observed in this\nstudy that pre-training also transfers the non-robustness from pre-trained\nmodel into the fine-tuned model. Using image classification as an example, we\nfirst conducted experiments on various datasets and network backbones to\nexplore the factors influencing robustness. Further analysis is conducted on\nexamining the difference between the fine-tuned model and standard model to\nuncover the reason leading to the non-robustness transfer. Finally, we\nintroduce a simple robust pre-training solution by regularizing the difference\nbetween target and source tasks. Results validate the effectiveness in\nalleviating non-robustness and preserving generalization.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 11:16:13 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Zhang", "Jiaming", ""], ["Sang", "Jitao", ""], ["Yi", "Qi", ""], ["Dong", "Huiwen", ""], ["Yu", "Jian", ""]]}, {"id": "2106.10994", "submitter": "Mingguo He", "authors": "Mingguo He, Zhewei Wei, Zengfeng Huang, Hongteng Xu", "title": "BernNet: Learning Arbitrary Graph Spectral Filters via Bernstein\n  Approximation", "comments": "14 pages, 31 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many representative graph neural networks, $e.g.$, GPR-GNN and ChebyNet,\napproximate graph convolutions with graph spectral filters. However, existing\nwork either applies predefined filter weights or learns them without necessary\nconstraints, which may lead to oversimplified or ill-posed filters. To overcome\nthese issues, we propose $\\textit{BernNet}$, a novel graph neural network with\ntheoretical support that provides a simple but effective scheme for designing\nand learning arbitrary graph spectral filters. In particular, for any filter\nover the normalized Laplacian spectrum of a graph, our BernNet estimates it by\nan order-$K$ Bernstein polynomial approximation and designs its spectral\nproperty by setting the coefficients of the Bernstein basis. Moreover, we can\nlearn the coefficients (and the corresponding filter weights) based on observed\ngraphs and their associated signals and thus achieve the BernNet specialized\nfor the data. Our experiments demonstrate that BernNet can learn arbitrary\nspectral filters, including complicated band-rejection and comb filters, and it\nachieves superior performance in real-world graph modeling tasks.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 11:26:06 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["He", "Mingguo", ""], ["Wei", "Zhewei", ""], ["Huang", "Zengfeng", ""], ["Xu", "Hongteng", ""]]}, {"id": "2106.11008", "submitter": "Nikhil Garg", "authors": "Lizy Kanungo, Nikhil Garg, Anish Bhobe, Smit Rajguru, Veeky Baths", "title": "Wheelchair automation by a hybrid BCI system using SSVEP and eye blinks", "comments": "Accepted to 2021 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND\n  CYBERNETICS (SMC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a hybrid Brain Computer Interface system for the\nautomation of a wheelchair for the disabled. Herein a working prototype of a\nBCI-based wheelchair is detailed that can navigate inside a typical home\nenvironment with minimum structural modification and without any visual\nobstruction and discomfort to the user. The prototype is based on a combined\nmechanism of steady-state visually evoked potential and eye blinks. To elicit\nSSVEP, LEDs flickering at 13Hz and 15Hz were used to select the left and right\ndirection, respectively, and EEG data was recorded. In addition, the occurrence\nof three continuous blinks was used as an indicator for stopping an ongoing\naction. The wavelet packet denoising method was applied, followed by feature\nextraction methods such as Wavelet Packet Decomposition and Canonical\nCorrelation Analysis over narrowband reconstructed EEG signals. Bayesian\noptimization was used to obtain 5 fold cross-validations to optimize the\nhyperparameters of the Support Vector Machine. The resulting new model was\ntested and the average cross-validation accuracy 89.65% + 6.6% (SD) and testing\naccuracy 83.53% + 8.59% (SD) were obtained. The wheelchair was controlled by\nRaspberryPi through WiFi. The developed prototype demonstrated an average of\n86.97% success rate for all trials with 4.015s for each command execution. The\nprototype can be used efficiently in a home environment without causing any\ndiscomfort to the user.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 08:02:31 GMT"}, {"version": "v2", "created": "Sun, 25 Jul 2021 07:22:48 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Kanungo", "Lizy", ""], ["Garg", "Nikhil", ""], ["Bhobe", "Anish", ""], ["Rajguru", "Smit", ""], ["Baths", "Veeky", ""]]}, {"id": "2106.11022", "submitter": "Roel Dobbe", "authors": "Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz", "title": "Hard Choices in Artificial Intelligence", "comments": "Pre-print. Shorter versions published at Neurips 2019 Workshop on AI\n  for Social Good and Conference on AI, Ethics and Society 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As AI systems are integrated into high stakes social domains, researchers now\nexamine how to design and operate them in a safe and ethical manner. However,\nthe criteria for identifying and diagnosing safety risks in complex social\ncontexts remain unclear and contested. In this paper, we examine the vagueness\nin debates about the safety and ethical behavior of AI systems. We show how\nthis vagueness cannot be resolved through mathematical formalism alone, instead\nrequiring deliberation about the politics of development as well as the context\nof deployment. Drawing from a new sociotechnical lexicon, we redefine vagueness\nin terms of distinct design challenges at key stages in AI system development.\nThe resulting framework of Hard Choices in Artificial Intelligence (HCAI)\nempowers developers by 1) identifying points of overlap between design\ndecisions and major sociotechnical challenges; 2) motivating the creation of\nstakeholder feedback channels so that safety issues can be exhaustively\naddressed. As such, HCAI contributes to a timely debate about the status of AI\ndevelopment in democratic societies, arguing that deliberation should be the\ngoal of AI Safety, not just the procedure by which it is ensured.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 09:49:34 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Dobbe", "Roel", ""], ["Gilbert", "Thomas Krendl", ""], ["Mintz", "Yonatan", ""]]}, {"id": "2106.11034", "submitter": "Tapani Toivonen Dr.", "authors": "Matti Tedre, Tapani Toivonen, Juho Kaihila, Henriikka Vartiainen,\n  Teemu Valtonen, Ilkka Jormanainen, and Arnold Pears", "title": "Teaching Machine Learning in K-12 Computing Education: Potential and\n  Pitfalls", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the past decades, numerous practical applications of machine learning\ntechniques have shown the potential of data-driven approaches in a large number\nof computing fields. Machine learning is increasingly included in computing\ncurricula in higher education, and a quickly growing number of initiatives are\nexpanding it in K-12 computing education, too. As machine learning enters K-12\ncomputing education, understanding how intuition and agency in the context of\nsuch systems is developed becomes a key research area. But as schools and\nteachers are already struggling with integrating traditional computational\nthinking and traditional artificial intelligence into school curricula,\nunderstanding the challenges behind teaching machine learning in K-12 is an\neven more daunting challenge for computing education research. Despite the\ncentral position of machine learning in the field of modern computing, the\ncomputing education research body of literature contains remarkably few studies\nof how people learn to train, test, improve, and deploy machine learning\nsystems. This is especially true of the K-12 curriculum space. This article\ncharts the emerging trajectories in educational practice, theory, and\ntechnology related to teaching machine learning in K-12 education. The article\nsituates the existing work in the context of computing education in general,\nand describes some differences that K-12 computing educators should take into\naccount when facing this challenge. The article focuses on key aspects of the\nparadigm shift that will be required in order to successfully integrate machine\nlearning into the broader K-12 computing curricula. A crucial step is\nabandoning the belief that rule-based \"traditional\" programming is a central\naspect and building block in developing next generation computational thinking.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 10:45:47 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Tedre", "Matti", ""], ["Toivonen", "Tapani", ""], ["Kaihila", "Juho", ""], ["Vartiainen", "Henriikka", ""], ["Valtonen", "Teemu", ""], ["Jormanainen", "Ilkka", ""], ["Pears", "Arnold", ""]]}, {"id": "2106.11036", "submitter": "Mary Roszel", "authors": "Mary Roszel, Robert Norvill, Jean Hilger, Radu State", "title": "Know Your Model (KYM): Increasing Trust in AI and Machine Learning", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread utilization of AI systems has drawn attention to the potential\nimpacts of such systems on society. Of particular concern are the consequences\nthat prediction errors may have on real-world scenarios, and the trust humanity\nplaces in AI systems. It is necessary to understand how we can evaluate\ntrustworthiness in AI and how individuals and entities alike can develop\ntrustworthy AI systems. In this paper, we analyze each element of\ntrustworthiness and provide a set of 20 guidelines that can be leveraged to\nensure optimal AI functionality while taking into account the greater ethical,\ntechnical, and practical impacts to humanity. Moreover, the guidelines help\nensure that trustworthiness is provable and can be demonstrated, they are\nimplementation agnostic, and they can be applied to any AI system in any\nsector.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 14:08:22 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Roszel", "Mary", ""], ["Norvill", "Robert", ""], ["Hilger", "Jean", ""], ["State", "Radu", ""]]}, {"id": "2106.11039", "submitter": "Carina Prunkl", "authors": "Carina Prunkl, Carolyn Ashurst, Markus Anderljung, Helena Webb, Jan\n  Leike, Allan Dafoe", "title": "Institutionalising Ethics in AI through Broader Impact Requirements", "comments": null, "journal-ref": "Nature Machine Intelligence 3.2 (2021): 104-110", "doi": "10.1038/s42256-021-00298-y", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Turning principles into practice is one of the most pressing challenges of\nartificial intelligence (AI) governance. In this article, we reflect on a novel\ngovernance initiative by one of the world's largest AI conferences. In 2020,\nthe Conference on Neural Information Processing Systems (NeurIPS) introduced a\nrequirement for submitting authors to include a statement on the broader\nsocietal impacts of their research. Drawing insights from similar governance\ninitiatives, including institutional review boards (IRBs) and impact\nrequirements for funding applications, we investigate the risks, challenges and\npotential benefits of such an initiative. Among the challenges, we list a lack\nof recognised best practice and procedural transparency, researcher opportunity\ncosts, institutional and social pressures, cognitive biases, and the inherently\ndifficult nature of the task. The potential benefits, on the other hand,\ninclude improved anticipation and identification of impacts, better\ncommunication with policy and governance experts, and a general strengthening\nof the norms around responsible research. To maximise the chance of success, we\nrecommend measures to increase transparency, improve guidance, create\nincentives to engage earnestly with the process, and facilitate public\ndeliberation on the requirement's merits and future. Perhaps the most important\ncontribution from this analysis are the insights we can gain regarding\neffective community-based governance and the role and responsibility of the AI\nresearch community more broadly.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 12:36:43 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Prunkl", "Carina", ""], ["Ashurst", "Carolyn", ""], ["Anderljung", "Markus", ""], ["Webb", "Helena", ""], ["Leike", "Jan", ""], ["Dafoe", "Allan", ""]]}, {"id": "2106.11053", "submitter": "Catherine Wong", "authors": "Catherine Wong and Kevin Ellis and Joshua B. Tenenbaum and Jacob\n  Andreas", "title": "Leveraging Language to Learn Program Abstractions and Search Heuristics", "comments": "appeared in Thirty-eighth International Conference on Machine\n  Learning (ICML 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Inductive program synthesis, or inferring programs from examples of desired\nbehavior, offers a general paradigm for building interpretable, robust, and\ngeneralizable machine learning systems. Effective program synthesis depends on\ntwo key ingredients: a strong library of functions from which to build\nprograms, and an efficient search strategy for finding programs that solve a\ngiven task. We introduce LAPS (Language for Abstraction and Program Search), a\ntechnique for using natural language annotations to guide joint learning of\nlibraries and neurally-guided search models for synthesis. When integrated into\na state-of-the-art library learning system (DreamCoder), LAPS produces\nhigher-quality libraries and improves search efficiency and generalization on\nthree domains -- string editing, image composition, and abstract reasoning\nabout scenes -- even when no natural language hints are available at test time.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 15:08:47 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Wong", "Catherine", ""], ["Ellis", "Kevin", ""], ["Tenenbaum", "Joshua B.", ""], ["Andreas", "Jacob", ""]]}, {"id": "2106.11054", "submitter": "Witold Oleszkiewicz", "authors": "Witold Oleszkiewicz, Dominika Basaj, Igor Sieradzki, Micha{\\l}\n  G\\'orszczak, Barbara Rychalska, Koryna Lewandowska, Tomasz Trzci\\'nski,\n  Bartosz Zieli\\'nski", "title": "Visual Probing: Cognitive Framework for Explaining Self-Supervised Image\n  Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recently introduced self-supervised methods for image representation learning\nprovide on par or superior results to their fully supervised competitors, yet\nthe corresponding efforts to explain the self-supervised approaches lag behind.\nMotivated by this observation, we introduce a novel visual probing framework\nfor explaining the self-supervised models by leveraging probing tasks employed\npreviously in natural language processing. The probing tasks require knowledge\nabout semantic relationships between image parts. Hence, we propose a\nsystematic approach to obtain analogs of natural language in vision, such as\nvisual words, context, and taxonomy. Our proposal is grounded in Marr's\ncomputational theory of vision and concerns features like textures, shapes, and\nlines. We show the effectiveness and applicability of those analogs in the\ncontext of explaining self-supervised representations. Our key findings\nemphasize that relations between language and vision can serve as an effective\nyet intuitive tool for discovering how machine learning models work,\nindependently of data modality. Our work opens a plethora of research pathways\ntowards more explainable and transparent AI.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 12:40:31 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Oleszkiewicz", "Witold", ""], ["Basaj", "Dominika", ""], ["Sieradzki", "Igor", ""], ["G\u00f3rszczak", "Micha\u0142", ""], ["Rychalska", "Barbara", ""], ["Lewandowska", "Koryna", ""], ["Trzci\u0144ski", "Tomasz", ""], ["Zieli\u0144ski", "Bartosz", ""]]}, {"id": "2106.11055", "submitter": "Mersha Nigus", "authors": "Mersha Nigus and Dorsewamy", "title": "Performance Evaluation of Classification Models for Household Income,\n  Consumption and Expenditure Data Set", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Food security is more prominent on the policy agenda today than it has been\nin the past, thanks to recent food shortages at both the regional and global\nlevels as well as renewed promises from major donor countries to combat chronic\nhunger. One field where machine learning can be used is in the classification\nof household food insecurity. In this study, we establish a robust methodology\nto categorize whether or not a household is being food secure and food insecure\nby machine learning algorithms. In this study, we have used ten machine\nlearning algorithms to classify the food security status of the Household.\nGradient Boosting (GB), Random Forest (RF), Extra Tree (ET), Bagging, K-Nearest\nNeighbor (KNN), Decision Tree (DT), Support Vector Machine (SVM), Logistic\nRegression (LR), Ada Boost (AB) and Naive Bayes were the classification\nalgorithms used throughout this study (NB). Then, we perform classification\ntasks from developing data set for household food security status by gathering\ndata from HICE survey data and validating it by Domain Experts. The performance\nof all classifiers has better results for all performance metrics. The\nperformance of the Random Forest and Gradient Boosting models are outstanding\nwith a testing accuracy of 0.9997 and the other classifier such as Bagging,\nDecision tree, Ada Boost, Extra tree, K-nearest neighbor, Logistic Regression,\nSVM and Naive Bayes are scored 0.9996, 0.09996, 0.9994, 0.95675, 0.9415,\n0.8915, 0.7853 and 0.7595, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 12:00:48 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Nigus", "Mersha", ""], ["Dorsewamy", "", ""]]}, {"id": "2106.11056", "submitter": "Alessandro Sebastianelli", "authors": "Alessandro Sebastianelli, Maria Pia Del Rosso, Pierre Philippe\n  Mathieu, Silvia Liberata Ullo", "title": "Paradigm selection for Data Fusion of SAR and Multispectral Sentinel\n  data applied to Land-Cover Classification", "comments": "This work has been submitted to the IEEE Geoscience and Remote\n  Sensing Letters for possible publication. Copyright may be transferred\n  without notice, after which this version may no longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data fusion is a well-known technique, becoming more and more popular in the\nArtificial Intelligence for Earth Observation (AI4EO) domain mainly due to its\nability of reinforcing AI4EO applications by combining multiple data sources\nand thus bringing better results. On the other hand, like other methods for\nsatellite data analysis, data fusion itself is also benefiting and evolving\nthanks to the integration of Artificial Intelligence (AI). In this letter, four\ndata fusion paradigms, based on Convolutional Neural Networks (CNNs), are\nanalyzed and implemented. The goals are to provide a systematic procedure for\nchoosing the best data fusion framework, resulting in the best classification\nresults, once the basic structure for the CNN has been defined, and to help\ninterested researchers in their work when data fusion applied to remote sensing\nis involved. The procedure has been validated for land-cover classification but\nit can be transferred to other cases.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 11:36:54 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Sebastianelli", "Alessandro", ""], ["Del Rosso", "Maria Pia", ""], ["Mathieu", "Pierre Philippe", ""], ["Ullo", "Silvia Liberata", ""]]}, {"id": "2106.11057", "submitter": "Alejandro Moreo Fern\\'andez", "authors": "Alejandro Moreo, Andrea Esuli, Fabrizio Sebastiani", "title": "QuaPy: A Python-Based Framework for Quantification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  QuaPy is an open-source framework for performing quantification (a.k.a.\nsupervised prevalence estimation), written in Python. Quantification is the\ntask of training quantifiers via supervised learning, where a quantifier is a\npredictor that estimates the relative frequencies (a.k.a. prevalence values) of\nthe classes of interest in a sample of unlabelled data. While quantification\ncan be trivially performed by applying a standard classifier to each unlabelled\ndata item and counting how many data items have been assigned to each class, it\nhas been shown that this \"classify and count\" method is outperformed by methods\nspecifically designed for quantification. QuaPy provides implementations of a\nnumber of baseline methods and advanced quantification methods, of routines for\nquantification-oriented model selection, of several broadly accepted evaluation\nmeasures, and of robust evaluation protocols routinely used in the field. QuaPy\nalso makes available datasets commonly used for testing quantifiers, and offers\nvisualization tools for facilitating the analysis and interpretation of the\nresults. The software is open-source and publicly available under a BSD-3\nlicence via https://github.com/HLT-ISTI/QuaPy, and can be installed via pip\n(https://pypi.org/project/QuaPy/)\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 13:57:11 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Moreo", "Alejandro", ""], ["Esuli", "Andrea", ""], ["Sebastiani", "Fabrizio", ""]]}, {"id": "2106.11072", "submitter": "Sever Topan", "authors": "Sever Topan, David Rolnick, Xujie Si", "title": "Techniques for Symbol Grounding with SATNet", "comments": "Code available at https://github.com/SeverTopan/SATNet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many experts argue that the future of artificial intelligence is limited by\nthe field's ability to integrate symbolic logical reasoning into deep learning\narchitectures. The recently proposed differentiable MAXSAT solver, SATNet, was\na breakthrough in its capacity to integrate with a traditional neural network\nand solve visual reasoning problems. For instance, it can learn the rules of\nSudoku purely from image examples. Despite its success, SATNet was shown to\nsuccumb to a key challenge in neurosymbolic systems known as the Symbol\nGrounding Problem: the inability to map visual inputs to symbolic variables\nwithout explicit supervision (\"label leakage\"). In this work, we present a\nself-supervised pre-training pipeline that enables SATNet to overcome this\nlimitation, thus broadening the class of problems that SATNet architectures can\nsolve to include datasets where no intermediary labels are available at all. We\ndemonstrate that our method allows SATNet to attain full accuracy even with a\nharder problem setup that prevents any label leakage. We additionally introduce\na proofreading method that further improves the performance of SATNet\narchitectures, beating the state-of-the-art on Visual Sudoku.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 18:42:12 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Topan", "Sever", ""], ["Rolnick", "David", ""], ["Si", "Xujie", ""]]}, {"id": "2106.11075", "submitter": "Omid Ghahabi", "authors": "Omid Ghahabi, Volker Fischer", "title": "EML Online Speech Activity Detection for the Fearless Steps Challenge\n  Phase-III", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Speech Activity Detection (SAD), locating speech segments within an audio\nrecording, is a main part of most speech technology applications. Robust SAD is\nusually more difficult in noisy conditions with varying signal-to-noise ratios\n(SNR). The Fearless Steps challenge has recently provided such data from the\nNASA Apollo-11 mission for different speech processing tasks including SAD.\nMost audio recordings are degraded by different kinds and levels of noise\nvarying within and between channels. This paper describes the EML online\nalgorithm for the most recent phase of this challenge. The proposed algorithm\ncan be trained both in a supervised and unsupervised manner and assigns speech\nand non-speech labels at runtime approximately every 0.1 sec. The experimental\nresults show a competitive accuracy on both development and evaluation datasets\nwith a real-time factor of about 0.002 using a single CPU machine.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 12:55:51 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Ghahabi", "Omid", ""], ["Fischer", "Volker", ""]]}, {"id": "2106.11111", "submitter": "Eduardo Rodrigues", "authors": "Eduardo Rodrigues, Bianca Zadrozny, Campbell Watson, David Gold", "title": "Decadal Forecasts with ResDMD: a Residual DMD Neural Network", "comments": "Accepted to ICML 2021 Workshop Tackling Climate Change with Machine\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Operational forecasting centers are investing in decadal (1-10 year) forecast\nsystems to support long-term decision making for a more climate-resilient\nsociety. One method that has previously been employed is the Dynamic Mode\nDecomposition (DMD) algorithm - also known as the Linear Inverse Model - which\nfits linear dynamical models to data. While the DMD usually approximates\nnon-linear terms in the true dynamics as a linear system with random noise, we\ninvestigate an extension to the DMD that explicitly represents the non-linear\nterms as a neural network. Our weight initialization allows the network to\nproduce sensible results before training and then improve the prediction after\ntraining as data becomes available. In this short paper, we evaluate the\nproposed architecture for simulating global sea surface temperatures and\ncompare the results with the standard DMD and seasonal forecasts produced by\nthe state-of-the-art dynamical model, CFSv2.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 13:49:43 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Rodrigues", "Eduardo", ""], ["Zadrozny", "Bianca", ""], ["Watson", "Campbell", ""], ["Gold", "David", ""]]}, {"id": "2106.11133", "submitter": "Lirong Wu", "authors": "Lirong Wu, Haitao Lin, Zhangyang Gao, Cheng Tan, Stan.Z.Li", "title": "GraphMixup: Improving Class-Imbalanced Node Classification on Graphs by\n  Self-supervised Context Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed great success in handling node classification\ntasks with Graph Neural Networks (GNNs). However, most existing GNNs are based\non the assumption that node samples for different classes are balanced, while\nfor many real-world graphs, there exists the problem of class imbalance, i.e.,\nsome classes may have much fewer samples than others. In this case, directly\ntraining a GNN classifier with raw data would under-represent samples from\nthose minority classes and result in sub-optimal performance. This paper\npresents GraphMixup, a novel mixup-based framework for improving\nclass-imbalanced node classification on graphs. However, directly performing\nmixup in the input space or embedding space may produce out-of-domain samples\ndue to the extreme sparsity of minority classes; hence we construct semantic\nrelation spaces that allows the Feature Mixup to be performed at the semantic\nlevel. Moreover, we apply two context-based self-supervised techniques to\ncapture both local and global information in the graph structure and then\npropose Edge Mixup specifically for graph data. Finally, we develop a\n\\emph{Reinforcement Mixup} mechanism to adaptively determine how many samples\nare to be generated by mixup for those minority classes. Extensive experiments\non three real-world datasets show that GraphMixup yields truly encouraging\nresults for class-imbalanced node classification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 14:12:16 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Wu", "Lirong", ""], ["Lin", "Haitao", ""], ["Gao", "Zhangyang", ""], ["Tan", "Cheng", ""], ["Li", "Stan. Z.", ""]]}, {"id": "2106.11156", "submitter": "Niko Grupen", "authors": "Niko A. Grupen, Daniel D. Lee, Bart Selman", "title": "Curriculum-Driven Multi-Agent Learning and the Role of Implicit\n  Communication in Teamwork", "comments": "18 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a curriculum-driven learning strategy for solving difficult\nmulti-agent coordination tasks. Our method is inspired by a study of animal\ncommunication, which shows that two straightforward design features (mutual\nreward and decentralization) support a vast spectrum of communication protocols\nin nature. We highlight the importance of similarly interpreting emergent\ncommunication as a spectrum. We introduce a toroidal, continuous-space\npursuit-evasion environment and show that naive decentralized learning does not\nperform well. We then propose a novel curriculum-driven strategy for\nmulti-agent learning. Experiments with pursuit-evasion show that our approach\nenables decentralized pursuers to learn to coordinate and capture a superior\nevader, significantly outperforming sophisticated analytical policies. We argue\nthrough additional quantitative analysis -- including influence-based measures\nsuch as Instantaneous Coordination -- that emergent implicit communication\nplays a large role in enabling superior levels of coordination.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 14:54:07 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Grupen", "Niko A.", ""], ["Lee", "Daniel D.", ""], ["Selman", "Bart", ""]]}, {"id": "2106.11170", "submitter": "Yonghao Song", "authors": "Yonghao Song, Xueyu Jia, Lie Yang, Longhan Xie", "title": "Transformer-based Spatial-Temporal Feature Learning for EEG Decoding", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At present, people usually use some methods based on convolutional neural\nnetworks (CNNs) for Electroencephalograph (EEG) decoding. However, CNNs have\nlimitations in perceiving global dependencies, which is not adequate for common\nEEG paradigms with a strong overall relationship. Regarding this issue, we\npropose a novel EEG decoding method that mainly relies on the attention\nmechanism. The EEG data is firstly preprocessed and spatially filtered. And\nthen, we apply attention transforming on the feature-channel dimension so that\nthe model can enhance more relevant spatial features. The most crucial step is\nto slice the data in the time dimension for attention transforming, and finally\nobtain a highly distinguishable representation. At this time, global averaging\npooling and a simple fully-connected layer are used to classify different\ncategories of EEG data. Experiments on two public datasets indicate that the\nstrategy of attention transforming effectively utilizes spatial and temporal\nfeatures. And we have reached the level of the state-of-the-art in\nmulti-classification of EEG, with fewer parameters. As far as we know, it is\nthe first time that a detailed and complete method based on the transformer\nidea has been proposed in this field. It has good potential to promote the\npracticality of brain-computer interface (BCI). The source code can be found\nat: \\textit{https://github.com/anranknight/EEG-Transformer}.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 00:48:18 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Song", "Yonghao", ""], ["Jia", "Xueyu", ""], ["Yang", "Lie", ""], ["Xie", "Longhan", ""]]}, {"id": "2106.11171", "submitter": "Minsu Kang", "authors": "Minsu Kang, Sungjae Kim and Injung Kim", "title": "UniTTS: Residual Learning of Unified Embedding Space for Speech Style\n  Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.LG cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel high-fidelity expressive speech synthesis model, UniTTS,\nthat learns and controls overlapping style attributes avoiding interference.\nUniTTS represents multiple style attributes in a single unified embedding space\nby the residuals between the phoneme embeddings before and after applying the\nattributes. The proposed method is especially effective in controlling multiple\nattributes that are difficult to separate cleanly, such as speaker ID and\nemotion, because it minimizes redundancy when adding variance in speaker ID and\nemotion, and additionally, predicts duration, pitch, and energy based on the\nspeaker ID and emotion. In experiments, the visualization results exhibit that\nthe proposed methods learned multiple attributes harmoniously in a manner that\ncan be easily separated again. As well, UniTTS synthesized high-fidelity speech\nsignals controlling multiple style attributes. The synthesized speech samples\nare presented at https://jackson-kang.github.io/paper_works/UniTTS/demos.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 15:07:09 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Kang", "Minsu", ""], ["Kim", "Sungjae", ""], ["Kim", "Injung", ""]]}, {"id": "2106.11175", "submitter": "Zhan Zhao", "authors": "Yuebing Liang, Zhan Zhao", "title": "Vehicle Trajectory Prediction in City-scale Road Networks using a\n  Direction-based Sequence-to-Sequence Model with Spatiotemporal Attention\n  Mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trajectory prediction of vehicles at the city scale is of great importance to\nvarious location-based applications such as vehicle navigation, traffic\nmanagement, and location-based recommendations. Existing methods typically\nrepresent a trajectory as a sequence of grid cells, road segments or intention\nsets. None of them is ideal, as the cell-based representation ignores the road\nnetwork structures and the other two are less efficient in analyzing city-scale\nroad networks. In addition, most models focus on predicting the immediate next\nposition, and are difficult to generalize for longer sequences. To address\nthese problems, we propose a novel sequence-to-sequence model named D-LSTM\n(Direction-based Long Short-Term Memory), which represents each trajectory as a\nsequence of intersections and associated movement directions, and then feeds\nthem into a LSTM encoder-decoder network for future trajectory generation.\nFurthermore, we introduce a spatial attention mechanism to capture dynamic\nspatial dependencies in road networks, and a temporal attention mechanism with\na sliding context window to capture both short- and long-term temporal\ndependencies in trajectory data. Extensive experiments based on two real-world\nlarge-scale taxi trajectory datasets show that D-LSTM outperforms the existing\nstate-of-the-art methods for vehicle trajectory prediction, validating the\neffectiveness of the proposed trajectory representation method and\nspatiotemporal attention mechanisms.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 15:14:28 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Liang", "Yuebing", ""], ["Zhao", "Zhan", ""]]}, {"id": "2106.11182", "submitter": "Rahul Kumar Sevakula", "authors": "Rahul Kumar Sevakula, Nishchal Kumar Verma, Hisao Ishibuchi", "title": "On fine-tuning of Autoencoders for Fuzzy rule classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent discoveries in Deep Neural Networks are allowing researchers to tackle\nsome very complex problems such as image classification and audio\nclassification, with improved theoretical and empirical justifications. This\npaper presents a novel scheme to incorporate the use of autoencoders in Fuzzy\nrule classifiers (FRC). Autoencoders when stacked can learn the complex\nnon-linear relationships amongst data, and the proposed framework built towards\nFRC can allow users to input expert knowledge to the system. This paper further\nintroduces four novel fine-tuning strategies for autoencoders to improve the\nFRC's classification and rule reduction performance. The proposed framework has\nbeen tested across five real-world benchmark datasets. Elaborate comparisons\nwith over 15 previous studies, and across 10-fold cross validation performance,\nsuggest that the proposed methods are capable of building FRCs which can\nprovide state of the art accuracies.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 15:20:37 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Sevakula", "Rahul Kumar", ""], ["Verma", "Nishchal Kumar", ""], ["Ishibuchi", "Hisao", ""]]}, {"id": "2106.11197", "submitter": "Binzong Geng", "authors": "Binzong Geng, Min Yang, Fajie Yuan, Shupeng Wang, Xiang Ao, Ruifeng Xu", "title": "Iterative Network Pruning with Uncertainty Regularization for Lifelong\n  Sentiment Classification", "comments": "Accepted by the 44th International ACM SIGIR Conference on Research\n  and Development in Information Retrieval (SIGIR), 2021", "journal-ref": null, "doi": "10.1145/3404835.3462902", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lifelong learning capabilities are crucial for sentiment classifiers to\nprocess continuous streams of opinioned information on the Web. However,\nperforming lifelong learning is non-trivial for deep neural networks as\ncontinually training of incrementally available information inevitably results\nin catastrophic forgetting or interference. In this paper, we propose a novel\niterative network pruning with uncertainty regularization method for lifelong\nsentiment classification (IPRLS), which leverages the principles of network\npruning and weight regularization. By performing network pruning with\nuncertainty regularization in an iterative manner, IPRLS can adapta single BERT\nmodel to work with continuously arriving data from multiple domains while\navoiding catastrophic forgetting and interference. Specifically, we leverage an\niterative pruning method to remove redundant parameters in large deep networks\nso that the freed-up space can then be employed to learn new tasks, tackling\nthe catastrophic forgetting problem. Instead of keeping the old-tasks fixed\nwhen learning new tasks, we also use an uncertainty regularization based on the\nBayesian online learning framework to constrain the update of old tasks weights\nin BERT, which enables positive backward transfer, i.e. learning new tasks\nimproves performance on past tasks while protecting old knowledge from being\nlost. In addition, we propose a task-specific low-dimensional residual function\nin parallel to each layer of BERT, which makes IPRLS less prone to losing the\nknowledge saved in the base BERT network when learning a new task. Extensive\nexperiments on 16 popular review corpora demonstrate that the proposed IPRLS\nmethod sig-nificantly outperforms the strong baselines for lifelong sentiment\nclassification. For reproducibility, we submit the code and data\nat:https://github.com/siat-nlp/IPRLS.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 15:34:13 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Geng", "Binzong", ""], ["Yang", "Min", ""], ["Yuan", "Fajie", ""], ["Wang", "Shupeng", ""], ["Ao", "Xiang", ""], ["Xu", "Ruifeng", ""]]}, {"id": "2106.11220", "submitter": "Yifang Chen", "authors": "Yifang Chen, Simon S. Du, Kevin Jamieson", "title": "Corruption Robust Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conduct theoretical studies on streaming-based active learning for binary\nclassification under unknown adversarial label corruptions. In this setting,\nevery time before the learner observes a sample, the adversary decides whether\nto corrupt the label or not. First, we show that, in a benign corruption\nsetting (which includes the misspecification setting as a special case), with a\nslight enlargement on the hypothesis elimination threshold, the classical\nRobustCAL framework can (surprisingly) achieve nearly the same label complexity\nguarantee as in the non-corrupted setting. However, this algorithm can fail in\nthe general corruption setting. To resolve this drawback, we propose a new\nalgorithm which is provably correct without any assumptions on the presence of\ncorruptions. Furthermore, this algorithm enjoys the minimax label complexity in\nthe non-corrupted setting (which is achieved by RobustCAL) and only requires\n$\\tilde{\\mathcal{O}}(C_{\\mathrm{total}})$ additional labels in the corrupted\nsetting to achieve $\\mathcal{O}(\\varepsilon + \\frac{C_{\\mathrm{total}}}{n})$,\nwhere $\\varepsilon$ is the target accuracy, $C_{\\mathrm{total}}$ is the total\nnumber of corruptions and $n$ is the total number of unlabeled samples.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 16:06:38 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Chen", "Yifang", ""], ["Du", "Simon S.", ""], ["Jamieson", "Kevin", ""]]}, {"id": "2106.11236", "submitter": "Sara Beery", "authors": "Sara Beery, Elizabeth Bondi", "title": "Can poachers find animals from public camera trap images?", "comments": "CV4Animals Workshop at CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To protect the location of camera trap data containing sensitive, high-target\nspecies, many ecologists randomly obfuscate the latitude and longitude of the\ncamera when publishing their data. For example, they may publish a random\nlocation within a 1km radius of the true camera location for each camera in\ntheir network. In this paper, we investigate the robustness of geo-obfuscation\nfor maintaining camera trap location privacy, and show via a case study that a\nfew simple, intuitive heuristics and publicly available satellite rasters can\nbe used to reduce the area likely to contain the camera by 87% (assuming random\nobfuscation within 1km), demonstrating that geo-obfuscation may be less\neffective than previously believed.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 16:31:47 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Beery", "Sara", ""], ["Bondi", "Elizabeth", ""]]}, {"id": "2106.11250", "submitter": "Hao Tan", "authors": "Hao Tan, Jie Lei, Thomas Wolf, Mohit Bansal", "title": "VIMPAC: Video Pre-Training via Masked Token Prediction and Contrastive\n  Learning", "comments": "Under review, 23 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video understanding relies on perceiving the global content and modeling its\ninternal connections (e.g., causality, movement, and spatio-temporal\ncorrespondence). To learn these interactions, we apply a mask-then-predict\npre-training task on discretized video tokens generated via VQ-VAE. Unlike\nlanguage, where the text tokens are more independent, neighboring video tokens\ntypically have strong correlations (e.g., consecutive video frames usually look\nvery similar), and hence uniformly masking individual tokens will make the task\ntoo trivial to learn useful representations. To deal with this issue, we\npropose a block-wise masking strategy where we mask neighboring video tokens in\nboth spatial and temporal domains. We also add an augmentation-free contrastive\nlearning method to further capture the global content by predicting whether the\nvideo clips are sampled from the same video. We pre-train our model on\nuncurated videos and show that our pre-trained model can reach state-of-the-art\nresults on several video understanding datasets (e.g., SSV2, Diving48). Lastly,\nwe provide detailed analyses on model scalability and pre-training method\ndesign. Code is released at https://github.com/airsplay/vimpac.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 16:48:19 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Tan", "Hao", ""], ["Lei", "Jie", ""], ["Wolf", "Thomas", ""], ["Bansal", "Mohit", ""]]}, {"id": "2106.11299", "submitter": "Andreas Mayr", "authors": "Andreas Mayr, Sebastian Lehner, Arno Mayrhofer, Christoph Kloss, Sepp\n  Hochreiter, Johannes Brandstetter", "title": "Boundary Graph Neural Networks for 3D Simulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The abundance of data has given machine learning huge momentum in natural\nsciences and engineering. However, the modeling of simulated physical processes\nremains difficult. A key problem in doing so is the correct handling of\ngeometric boundaries. While triangularized geometric boundaries are very common\nin engineering applications, they are notoriously difficult to model by machine\nlearning approaches due to their heterogeneity with respect to size and\norientation. In this work, we introduce Boundary Graph Neural Networks (BGNNs),\nwhich dynamically modify graph structures to address boundary conditions.\nBoundary graph structures are constructed via modifying edges, augmenting node\nfeatures, and dynamically inserting virtual nodes. The new BGNNs are tested on\ncomplex 3D granular flow processes of hoppers and rotating drums which are\nstandard parts of industrial machinery. Using precise simulations that are\nobtained by an expensive and complex discrete element method, BGNNs are\nevaluated in terms of computational efficiency as well as prediction accuracy\nof particle flows and mixing entropies. Even if complex boundaries are present,\nBGNNs are able to accurately reproduce 3D granular flows within simulation\nuncertainties over hundreds of thousands of simulation timesteps, and most\nnotably particles completely stay within the geometric objects without using\nhandcrafted conditions or restrictions.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 17:56:07 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Mayr", "Andreas", ""], ["Lehner", "Sebastian", ""], ["Mayrhofer", "Arno", ""], ["Kloss", "Christoph", ""], ["Hochreiter", "Sepp", ""], ["Brandstetter", "Johannes", ""]]}, {"id": "2106.11309", "submitter": "Zechun Liu", "authors": "Zechun Liu, Zhiqiang Shen, Shichao Li, Koen Helwegen, Dong Huang,\n  Kwang-Ting Cheng", "title": "How Do Adam and Training Strategies Help BNNs Optimization?", "comments": "ICML 2021. Code and models are available at\n  https://github.com/liuzechun/AdamBNN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The best performing Binary Neural Networks (BNNs) are usually attained using\nAdam optimization and its multi-step training variants. However, to the best of\nour knowledge, few studies explore the fundamental reasons why Adam is superior\nto other optimizers like SGD for BNN optimization or provide analytical\nexplanations that support specific training strategies. To address this, in\nthis paper we first investigate the trajectories of gradients and weights in\nBNNs during the training process. We show the regularization effect of\nsecond-order momentum in Adam is crucial to revitalize the weights that are\ndead due to the activation saturation in BNNs. We find that Adam, through its\nadaptive learning rate strategy, is better equipped to handle the rugged loss\nsurface of BNNs and reaches a better optimum with higher generalization\nability. Furthermore, we inspect the intriguing role of the real-valued weights\nin binary networks, and reveal the effect of weight decay on the stability and\nsluggishness of BNN optimization. Through extensive experiments and analysis,\nwe derive a simple training scheme, building on existing Adam-based\noptimization, which achieves 70.5% top-1 accuracy on the ImageNet dataset using\nthe same architecture as the state-of-the-art ReActNet while achieving 1.1%\nhigher accuracy. Code and models are available at\nhttps://github.com/liuzechun/AdamBNN.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 17:59:51 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Liu", "Zechun", ""], ["Shen", "Zhiqiang", ""], ["Li", "Shichao", ""], ["Helwegen", "Koen", ""], ["Huang", "Dong", ""], ["Cheng", "Kwang-Ting", ""]]}, {"id": "2106.11322", "submitter": "J\\'er\\'emy Lebreton", "authors": "J\\'er\\'emy Lebreton, Roland Brochard, Matthieu Baudry, Gr\\'egory\n  Jonniaux, Adrien Hadj Salah, Keyvan Kanani, Matthieu Le Goff, Aurore Masson,\n  Nicolas Ollagnier, Paolo Panicucci, Amsha Proag, Cyril Robin", "title": "Image simulation for space applications with the SurRender software", "comments": "11th International ESA Conference on Guidance, Navigation & Control\n  Systems, 22 - 25 June 2021 16 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.EP astro-ph.IM cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image Processing algorithms for vision-based navigation require reliable\nimage simulation capacities. In this paper we explain why traditional rendering\nengines may present limitations that are potentially critical for space\napplications. We introduce Airbus SurRender software v7 and provide details on\nfeatures that make it a very powerful space image simulator. We show how\nSurRender is at the heart of the development processes of our computer vision\nsolutions and we provide a series of illustrations of rendered images for\nvarious use cases ranging from Moon and Solar System exploration, to in orbit\nrendezvous and planetary robotics.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 18:00:01 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Lebreton", "J\u00e9r\u00e9my", ""], ["Brochard", "Roland", ""], ["Baudry", "Matthieu", ""], ["Jonniaux", "Gr\u00e9gory", ""], ["Salah", "Adrien Hadj", ""], ["Kanani", "Keyvan", ""], ["Goff", "Matthieu Le", ""], ["Masson", "Aurore", ""], ["Ollagnier", "Nicolas", ""], ["Panicucci", "Paolo", ""], ["Proag", "Amsha", ""], ["Robin", "Cyril", ""]]}, {"id": "2106.11335", "submitter": "Anurag Kumar", "authors": "Anurag Kumar, Yun Wang, Vamsi Krishna Ithapu, Christian Fuegen", "title": "Do sound event representations generalize to other audio tasks? A case\n  study in audio transfer learning", "comments": "Accepted Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning is critical for efficient information transfer across\nmultiple related learning problems. A simple, yet effective transfer learning\napproach utilizes deep neural networks trained on a large-scale task for\nfeature extraction. Such representations are then used to learn related\ndownstream tasks. In this paper, we investigate transfer learning capacity of\naudio representations obtained from neural networks trained on a large-scale\nsound event detection dataset. We build and evaluate these representations\nacross a wide range of other audio tasks, via a simple linear classifier\ntransfer mechanism. We show that such simple linear transfer is already\npowerful enough to achieve high performance on the downstream tasks. We also\nprovide insights into the attributes of sound event representations that enable\nsuch efficient information transfer.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 18:04:59 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Kumar", "Anurag", ""], ["Wang", "Yun", ""], ["Ithapu", "Vamsi Krishna", ""], ["Fuegen", "Christian", ""]]}, {"id": "2106.11342", "submitter": "Aston Zhang", "authors": "Aston Zhang, Zachary C. Lipton, Mu Li, Alexander J. Smola", "title": "Dive into Deep Learning", "comments": "(HTML) https://D2L.ai (GitHub) https://github.com/d2l-ai/d2l-en/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This open-source book represents our attempt to make deep learning\napproachable, teaching readers the concepts, the context, and the code. The\nentire book is drafted in Jupyter notebooks, seamlessly integrating exposition\nfigures, math, and interactive examples with self-contained code. Our goal is\nto offer a resource that could (i) be freely available for everyone; (ii) offer\nsufficient technical depth to provide a starting point on the path to actually\nbecoming an applied machine learning scientist; (iii) include runnable code,\nshowing readers how to solve problems in practice; (iv) allow for rapid\nupdates, both by us and also by the community at large; (v) be complemented by\na forum for interactive discussion of technical details and to answer\nquestions.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 18:19:46 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 16:51:30 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Zhang", "Aston", ""], ["Lipton", "Zachary C.", ""], ["Li", "Mu", ""], ["Smola", "Alexander J.", ""]]}, {"id": "2106.11344", "submitter": "David Acuna", "authors": "David Acuna, Guojun Zhang, Marc T. Law, Sanja Fidler", "title": "f-Domain-Adversarial Learning: Theory and Algorithms", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation is used in many machine learning applications\nwhere, during training, a model has access to unlabeled data in the target\ndomain, and a related labeled dataset. In this paper, we introduce a novel and\ngeneral domain-adversarial framework. Specifically, we derive a novel\ngeneralization bound for domain adaptation that exploits a new measure of\ndiscrepancy between distributions based on a variational characterization of\nf-divergences. It recovers the theoretical results from Ben-David et al.\n(2010a) as a special case and supports divergences used in practice. Based on\nthis bound, we derive a new algorithmic framework that introduces a key\ncorrection in the original adversarial training method of Ganin et al. (2016).\nWe show that many regularizers and ad-hoc objectives introduced over the last\nyears in this framework are then not required to achieve performance comparable\nto (if not better than) state-of-the-art domain-adversarial methods.\nExperimental analysis conducted on real-world natural language and computer\nvision datasets show that our framework outperforms existing baselines, and\nobtains the best results for f-divergences that were not considered previously\nin domain-adversarial learning.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 18:21:09 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Acuna", "David", ""], ["Zhang", "Guojun", ""], ["Law", "Marc T.", ""], ["Fidler", "Sanja", ""]]}, {"id": "2106.11345", "submitter": "Clod\\'eric Mars", "authors": "AI Redefined, Sai Krishna Gottipati, Sagar Kurandwad, Clod\\'eric Mars,\n  Gregory Szriftgiser and Fran\\c{c}ois Chabot", "title": "Cogment: Open Source Framework For Distributed Multi-actor Training,\n  Deployment & Operations", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Involving humans directly for the benefit of AI agents' training is getting\ntraction thanks to several advances in reinforcement learning and\nhuman-in-the-loop learning. Humans can provide rewards to the agent,\ndemonstrate tasks, design a curriculum, or act in the environment, but these\nbenefits also come with architectural, functional design and engineering\ncomplexities. We present Cogment, a unifying open-source framework that\nintroduces an actor formalism to support a variety of humans-agents\ncollaboration typologies and training approaches. It is also scalable out of\nthe box thanks to a distributed micro service architecture, and offers\nsolutions to the aforementioned complexities.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 18:21:26 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Redefined", "AI", ""], ["Gottipati", "Sai Krishna", ""], ["Kurandwad", "Sagar", ""], ["Mars", "Clod\u00e9ric", ""], ["Szriftgiser", "Gregory", ""], ["Chabot", "Fran\u00e7ois", ""]]}, {"id": "2106.11359", "submitter": "Trisha Singhal", "authors": "Trisha Singhal, Junhua Liu, Lucienne T. M. Blessing, Kwan Hui Lim", "title": "Photozilla: A Large-Scale Photography Dataset and Visual Embedding for\n  20 Photography Styles", "comments": "In the Proceedings of the IEEE/CVF Conference on Computer Vision and\n  Pattern Recognition Workshops, 2021. (Poster)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of social media platforms has been a catalyst for the development\nof digital photography that engendered a boom in vision applications. With this\nmotivation, we introduce a large-scale dataset termed 'Photozilla', which\nincludes over 990k images belonging to 10 different photographic styles. The\ndataset is then used to train 3 classification models to automatically classify\nthe images into the relevant style which resulted in an accuracy of ~96%. With\nthe rapid evolution of digital photography, we have seen new types of\nphotography styles emerging at an exponential rate. On that account, we present\na novel Siamese-based network that uses the trained classification models as\nthe base architecture to adapt and classify unseen styles with only 25 training\nsamples. We report an accuracy of over 68% for identifying 10 other distinct\ntypes of photography styles. This dataset can be found at\nhttps://trisha025.github.io/Photozilla/\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 18:45:06 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Singhal", "Trisha", ""], ["Liu", "Junhua", ""], ["Blessing", "Lucienne T. M.", ""], ["Lim", "Kwan Hui", ""]]}, {"id": "2106.11365", "submitter": "Hang Ma", "authors": "Ziyuan Ma, Yudong Luo, Hang Ma", "title": "Distributed Heuristic Multi-Agent Path Finding with Communication", "comments": "Published at ICRA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Agent Path Finding (MAPF) is essential to large-scale robotic systems.\nRecent methods have applied reinforcement learning (RL) to learn decentralized\npolices in partially observable environments. A fundamental challenge of\nobtaining collision-free policy is that agents need to learn cooperation to\nhandle congested situations. This paper combines communication with deep\nQ-learning to provide a novel learning based method for MAPF, where agents\nachieve cooperation via graph convolution. To guide RL algorithm on\nlong-horizon goal-oriented tasks, we embed the potential choices of shortest\npaths from single source as heuristic guidance instead of using a specific path\nas in most existing works. Our method treats each agent independently and\ntrains the model from a single agent's perspective. The final trained policy is\napplied to each agent for decentralized execution. The whole system is\ndistributed during training and is trained under a curriculum learning\nstrategy. Empirical evaluation in obstacle-rich environment indicates the high\nsuccess rate with low average step of our method.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 18:50:58 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Ma", "Ziyuan", ""], ["Luo", "Yudong", ""], ["Ma", "Hang", ""]]}, {"id": "2106.11375", "submitter": "Junjie Hu", "authors": "Junjie Hu and Graham Neubig", "title": "Phrase-level Active Learning for Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) is sensitive to domain shift. In this paper,\nwe address this problem in an active learning setting where we can spend a\ngiven budget on translating in-domain data, and gradually fine-tune a\npre-trained out-of-domain NMT model on the newly translated data. Existing\nactive learning methods for NMT usually select sentences based on uncertainty\nscores, but these methods require costly translation of full sentences even\nwhen only one or two key phrases within the sentence are informative. To\naddress this limitation, we re-examine previous work from the phrase-based\nmachine translation (PBMT) era that selected not full sentences, but rather\nindividual phrases. However, while incorporating these phrases into PBMT\nsystems was relatively simple, it is less trivial for NMT systems, which need\nto be trained on full sequences to capture larger structural properties of\nsentences unique to the new domain. To overcome these hurdles, we propose to\nselect both full sentences and individual phrases from unlabelled data in the\nnew domain for routing to human translators. In a German-English translation\ntask, our active learning approach achieves consistent improvements over\nuncertainty-based sentence selection methods, improving up to 1.2 BLEU score\nover strong active learning baselines.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 19:20:42 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Hu", "Junjie", ""], ["Neubig", "Graham", ""]]}, {"id": "2106.11384", "submitter": "Huseyin Inan", "authors": "Saeed Mahloujifar, Huseyin A. Inan, Melissa Chase, Esha Ghosh,\n  Marcello Hasegawa", "title": "Membership Inference on Word Embedding and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the text processing context, most ML models are built on word embeddings.\nThese embeddings are themselves trained on some datasets, potentially\ncontaining sensitive data. In some cases this training is done independently,\nin other cases, it occurs as part of training a larger, task-specific model. In\neither case, it is of interest to consider membership inference attacks based\non the embedding layer as a way of understanding sensitive information leakage.\nBut, somewhat surprisingly, membership inference attacks on word embeddings and\ntheir effect in other natural language processing (NLP) tasks that use these\nembeddings, have remained relatively unexplored.\n  In this work, we show that word embeddings are vulnerable to black-box\nmembership inference attacks under realistic assumptions. Furthermore, we show\nthat this leakage persists through two other major NLP applications:\nclassification and text-generation, even when the embedding layer is not\nexposed to the attacker. We show that our MI attack achieves high attack\naccuracy against a classifier model and an LSTM-based language model. Indeed,\nour attack is a cheaper membership inference attack on text-generative models,\nwhich does not require the knowledge of the target model or any expensive\ntraining of text-generative models as shadow models.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 19:37:06 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Mahloujifar", "Saeed", ""], ["Inan", "Huseyin A.", ""], ["Chase", "Melissa", ""], ["Ghosh", "Esha", ""], ["Hasegawa", "Marcello", ""]]}, {"id": "2106.11394", "submitter": "Felix Biessmann", "authors": "Felix Biessmann and Viktor Treu", "title": "A Turing Test for Transparency", "comments": "Published in Proceedings of the ICML Workshop on Theoretical\n  Foundations, Criticism, and Application Trends of Explainable AI held in\n  conjunction with the 38th International Conference on Machine Learning (ICML)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A central goal of explainable artificial intelligence (XAI) is to improve the\ntrust relationship in human-AI interaction. One assumption underlying research\nin transparent AI systems is that explanations help to better assess\npredictions of machine learning (ML) models, for instance by enabling humans to\nidentify wrong predictions more efficiently. Recent empirical evidence however\nshows that explanations can have the opposite effect: When presenting\nexplanations of ML predictions humans often tend to trust ML predictions even\nwhen these are wrong. Experimental evidence suggests that this effect can be\nattributed to how intuitive, or human, an AI or explanation appears. This\neffect challenges the very goal of XAI and implies that responsible usage of\ntransparent AI methods has to consider the ability of humans to distinguish\nmachine generated from human explanations. Here we propose a quantitative\nmetric for XAI methods based on Turing's imitation game, a Turing Test for\nTransparency. A human interrogator is asked to judge whether an explanation was\ngenerated by a human or by an XAI method. Explanations of XAI methods that can\nnot be detected by humans above chance performance in this binary\nclassification task are passing the test. Detecting such explanations is a\nrequirement for assessing and calibrating the trust relationship in human-AI\ninteraction. We present experimental results on a crowd-sourced text\nclassification task demonstrating that even for basic ML models and XAI\napproaches most participants were not able to differentiate human from machine\ngenerated explanations. We discuss ethical and practical implications of our\nresults for applications of transparent ML.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 20:09:40 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Biessmann", "Felix", ""], ["Treu", "Viktor", ""]]}, {"id": "2106.11397", "submitter": "Arman Dehpanah", "authors": "Arman Dehpanah, Muheeb Faizan Ghori, Jonathan Gemmell, Bamshad\n  Mobasher", "title": "Evaluating Team Skill Aggregation in Online Competitive Games", "comments": "Accepted in IEEE Conference on Games 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main goals of online competitive games is increasing player\nengagement by ensuring fair matches. These games use rating systems for\ncreating balanced match-ups. Rating systems leverage statistical estimation to\nrate players' skills and use skill ratings to predict rank before matching\nplayers. Skill ratings of individual players can be aggregated to compute the\nskill level of a team. While research often aims to improve the accuracy of\nskill estimation and fairness of match-ups, less attention has been given to\nhow the skill level of a team is calculated from the skill level of its\nmembers. In this paper, we propose two new aggregation methods and compare them\nwith a standard approach extensively used in the research literature. We\npresent an exhaustive analysis of the impact of these methods on the predictive\nperformance of rating systems. We perform our experiments using three popular\nrating systems, Elo, Glicko, and TrueSkill, on three real-world datasets\nincluding over 100,000 battle royale and head-to-head matches. Our evaluations\nshow the superiority of the MAX method over the other two methods in the\nmajority of the tested cases, implying that the overall performance of a team\nis best determined by the performance of its most skilled member. The results\nof this study highlight the necessity of devising more elaborated methods for\ncalculating a team's performance -- methods covering different aspects of\nplayers' behavior such as skills, strategy, or goals.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 20:17:36 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Dehpanah", "Arman", ""], ["Ghori", "Muheeb Faizan", ""], ["Gemmell", "Jonathan", ""], ["Mobasher", "Bamshad", ""]]}, {"id": "2106.11426", "submitter": "Zichang Liu", "authors": "Zichang Liu, Benjamin Coleman, Anshumali Shrivastava", "title": "Efficient Inference via Universal LSH Kernel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Large machine learning models achieve unprecedented performance on various\ntasks and have evolved as the go-to technique. However, deploying these compute\nand memory hungry models on resource constraint environments poses new\nchallenges. In this work, we propose mathematically provable Representer\nSketch, a concise set of count arrays that can approximate the inference\nprocedure with simple hashing computations and aggregations. Representer Sketch\nbuilds upon the popular Representer Theorem from kernel literature, hence the\nname, providing a generic fundamental alternative to the problem of efficient\ninference that goes beyond the popular approach such as quantization, iterative\npruning and knowledge distillation. A neural network function is transformed to\nits weighted kernel density representation, which can be very efficiently\nestimated with our sketching algorithm. Empirically, we show that Representer\nSketch achieves up to 114x reduction in storage requirement and 59x reduction\nin computation complexity without any drop in accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 22:06:32 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Liu", "Zichang", ""], ["Coleman", "Benjamin", ""], ["Shrivastava", "Anshumali", ""]]}, {"id": "2106.11454", "submitter": "Hang Ma", "authors": "Hang Ma", "title": "A Competitive Analysis of Online Multi-Agent Path Finding", "comments": "Published at ICAPS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study online Multi-Agent Path Finding (MAPF), where new agents are\nconstantly revealed over time and all agents must find collision-free paths to\ntheir given goal locations. We generalize existing complexity results of\n(offline) MAPF to online MAPF. We classify online MAPF algorithms into\ndifferent categories based on (1) controllability (the set of agents that they\ncan plan paths for at each time) and (2) rationality (the quality of paths they\nplan) and study the relationships between them. We perform a competitive\nanalysis for each category of online MAPF algorithms with respect to\ncommonly-used objective functions. We show that a naive algorithm that routes\nnewly-revealed agents one at a time in sequence achieves a competitive ratio\nthat is asymptotically bounded from both below and above by the number of\nagents with respect to flowtime and makespan. We then show a counter-intuitive\nresult that, if rerouting of previously-revealed agents is not allowed, any\nrational online MAPF algorithms, including ones that plan optimal paths for all\nnewly-revealed agents, have the same asymptotic competitive ratio as the naive\nalgorithm, even on 2D 4-neighbor grids. We also derive constant lower bounds on\nthe competitive ratio of any rational online MAPF algorithms that allow\nrerouting. The results thus provide theoretical insights into the effectiveness\nof using MAPF algorithms in an online setting for the first time.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 00:05:29 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Ma", "Hang", ""]]}, {"id": "2106.11455", "submitter": "Chia-Hsuan Lee", "authors": "Chia-Hsuan Lee, Oleksandr Polozov, Matthew Richardson", "title": "KaggleDBQA: Realistic Evaluation of Text-to-SQL Parsers", "comments": "Published as a conference paper at ACL-IJCNLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DB cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of database question answering is to enable natural language\nquerying of real-life relational databases in diverse application domains.\nRecently, large-scale datasets such as Spider and WikiSQL facilitated novel\nmodeling techniques for text-to-SQL parsing, improving zero-shot generalization\nto unseen databases. In this work, we examine the challenges that still prevent\nthese techniques from practical deployment. First, we present KaggleDBQA, a new\ncross-domain evaluation dataset of real Web databases, with domain-specific\ndata types, original formatting, and unrestricted questions. Second, we\nre-examine the choice of evaluation tasks for text-to-SQL parsers as applied in\nreal-life settings. Finally, we augment our in-domain evaluation task with\ndatabase documentation, a naturally occurring source of implicit domain\nknowledge. We show that KaggleDBQA presents a challenge to state-of-the-art\nzero-shot parsers but a more realistic evaluation setting and creative use of\nassociated database documentation boosts their accuracy by over 13.2%, doubling\ntheir performance.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 00:08:03 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Lee", "Chia-Hsuan", ""], ["Polozov", "Oleksandr", ""], ["Richardson", "Matthew", ""]]}, {"id": "2106.11456", "submitter": "Marcelo Arenas", "authors": "Marcelo Arenas and Claudio Gutierrez and Juan F. Sequeda", "title": "Querying in the Age of Graph Databases and Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs have become the best way we know of representing knowledge. The\ncomputing community has investigated and developed the support for managing\ngraphs by means of digital technology. Graph databases and knowledge graphs\nsurface as the most successful solutions to this program. The goal of this\ndocument is to provide a conceptual map of the data management tasks underlying\nthese developments, paying particular attention to data models and query\nlanguages for graphs.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 00:17:06 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 03:18:36 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Arenas", "Marcelo", ""], ["Gutierrez", "Claudio", ""], ["Sequeda", "Juan F.", ""]]}, {"id": "2106.11463", "submitter": "Gang Wang", "authors": "Gang Wang", "title": "A Logical Neural Network Structure With More Direct Mapping From Logical\n  Relations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logical relations widely exist in human activities. Human use them for making\njudgement and decision according to various conditions, which are embodied in\nthe form of \\emph{if-then} rules. As an important kind of cognitive\nintelligence, it is prerequisite of representing and storing logical relations\nrightly into computer systems so as to make automatic judgement and decision,\nespecially for high-risk domains like medical diagnosis. However, current\nnumeric ANN (Artificial Neural Network) models are good at perceptual\nintelligence such as image recognition while they are not good at cognitive\nintelligence such as logical representation, blocking the further application\nof ANN. To solve it, researchers have tried to design logical ANN models to\nrepresent and store logical relations. Although there are some advances in this\nresearch area, recent works still have disadvantages because the structures of\nthese logical ANN models still don't map more directly with logical relations\nwhich will cause the corresponding logical relations cannot be read out from\ntheir network structures. Therefore, in order to represent logical relations\nmore clearly by the neural network structure and to read out logical relations\nfrom it, this paper proposes a novel logical ANN model by designing the new\nlogical neurons and links in demand of logical representation. Compared with\nthe recent works on logical ANN models, this logical ANN model has more clear\ncorresponding with logical relations using the more direct mapping method\nherein, thus logical relations can be read out following the connection\npatterns of the network structure. Additionally, less neurons are used.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 00:53:08 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Wang", "Gang", ""]]}, {"id": "2106.11481", "submitter": "Sourav Garg", "authors": "Sourav Garg and Michael Milford", "title": "SeqNetVLAD vs PointNetVLAD: Image Sequence vs 3D Point Clouds for\n  Day-Night Place Recognition", "comments": "Accepted to CVPR 2021 Workshop on 3D Vision and Robotics (3DVR).\n  https://sites.google.com/view/cvpr2021-3d-vision-robotics/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IR cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Place Recognition is a crucial capability for mobile robot localization and\nnavigation. Image-based or Visual Place Recognition (VPR) is a challenging\nproblem as scene appearance and camera viewpoint can change significantly when\nplaces are revisited. Recent VPR methods based on ``sequential\nrepresentations'' have shown promising results as compared to traditional\nsequence score aggregation or single image based techniques. In parallel to\nthese endeavors, 3D point clouds based place recognition is also being explored\nfollowing the advances in deep learning based point cloud processing. However,\na key question remains: is an explicit 3D structure based place representation\nalways superior to an implicit ``spatial'' representation based on sequence of\nRGB images which can inherently learn scene structure. In this extended\nabstract, we attempt to compare these two types of methods by considering a\nsimilar ``metric span'' to represent places. We compare a 3D point cloud based\nmethod (PointNetVLAD) with image sequence based methods (SeqNet and others) and\nshowcase that image sequence based techniques approach, and can even surpass,\nthe performance achieved by point cloud based methods for a given metric span.\nThese performance variations can be attributed to differences in data richness\nof input sensors as well as data accumulation strategies for a mobile robot.\nWhile a perfect apple-to-apple comparison may not be feasible for these two\ndifferent modalities, the presented comparison takes a step in the direction of\nanswering deeper questions regarding spatial representations, relevant to\nseveral applications like Autonomous Driving and Augmented/Virtual Reality.\nSource code available publicly https://github.com/oravus/seqNet.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 02:05:32 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Garg", "Sourav", ""], ["Milford", "Michael", ""]]}, {"id": "2106.11485", "submitter": "Yutong He", "authors": "Yutong He, Dingjie Wang, Nicholas Lai, William Zhang, Chenlin Meng,\n  Marshall Burke, David B. Lobell, Stefano Ermon", "title": "Spatial-Temporal Super-Resolution of Satellite Imagery via Conditional\n  Pixel Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  High-resolution satellite imagery has proven useful for a broad range of\ntasks, including measurement of global human population, local economic\nlivelihoods, and biodiversity, among many others. Unfortunately,\nhigh-resolution imagery is both infrequently collected and expensive to\npurchase, making it hard to efficiently and effectively scale these downstream\ntasks over both time and space. We propose a new conditional pixel synthesis\nmodel that uses abundant, low-cost, low-resolution imagery to generate accurate\nhigh-resolution imagery at locations and times in which it is unavailable. We\nshow that our model attains photo-realistic sample quality and outperforms\ncompeting baselines on a key downstream task -- object counting -- particularly\nin geographic locations where conditions on the ground are changing rapidly.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 02:16:24 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["He", "Yutong", ""], ["Wang", "Dingjie", ""], ["Lai", "Nicholas", ""], ["Zhang", "William", ""], ["Meng", "Chenlin", ""], ["Burke", "Marshall", ""], ["Lobell", "David B.", ""], ["Ermon", "Stefano", ""]]}, {"id": "2106.11496", "submitter": "EPTCS", "authors": "Weiwei Chen (Institute of Logic and Cognition and Department of\n  Philosophy, Sun Yat-sen University)", "title": "Collective Argumentation: The Case of Aggregating Support-Relations of\n  Bipolar Argumentation Frameworks", "comments": "In Proceedings TARK 2021, arXiv:2106.10886. Accepted by the 18th\n  conference on theoretical aspects of rationality and knowledge (TARK-2021)", "journal-ref": "EPTCS 335, 2021, pp. 87-102", "doi": "10.4204/EPTCS.335.8", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In many real-life situations that involve exchanges of arguments, individuals\nmay differ on their assessment of which supports between the arguments are in\nfact justified, i.e., they put forward different support-relations. When\nconfronted with such situations, we may wish to aggregate individuals'\nargumentation views on support-relations into a collective view, which is\nacceptable to the group. In this paper, we assume that under bipolar\nargumentation frameworks, individuals are equipped with a set of arguments and\na set of attacks between arguments, but with possibly different\nsupport-relations. Using the methodology in social choice theory, we analyze\nwhat semantic properties of bipolar argumentation frameworks can be preserved\nby aggregation rules during the aggregation of support-relations.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 02:45:10 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Chen", "Weiwei", "", "Institute of Logic and Cognition and Department of\n  Philosophy, Sun Yat-sen University"]]}, {"id": "2106.11497", "submitter": "EPTCS", "authors": "Michael Cohen (Stanford University), Wen Tang (Peking University),\n  Yanjing Wang (Peking University)", "title": "De Re Updates", "comments": "In Proceedings TARK 2021, arXiv:2106.10886", "journal-ref": "EPTCS 335, 2021, pp. 103-117", "doi": "10.4204/EPTCS.335.9", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a lightweight yet powerful dynamic epistemic logic\nthat captures not only the distinction between de dicto and de re knowledge but\nalso the distinction between de dicto and de re updates. The logic is based on\nthe dynamified version of an epistemic language extended with the assignment\noperator borrowed from dynamic logic, following the work of Wang and Seligman\n(Proc. AiML 2018). We obtain complete axiomatizations for the counterparts of\npublic announcement logic and event-model-based DEL based on new reduction\naxioms taking care of the interactions between dynamics and assignments.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 02:45:25 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Cohen", "Michael", "", "Stanford University"], ["Tang", "Wen", "", "Peking University"], ["Wang", "Yanjing", "", "Peking University"]]}, {"id": "2106.11500", "submitter": "EPTCS", "authors": "Satoshi Fukuda (Department of Decision Sciences and IGIER, Bocconi\n  University)", "title": "Are the Players in an Interactive Belief Model Meta-certain of the Model\n  Itself?", "comments": "In Proceedings TARK 2021, arXiv:2106.10886", "journal-ref": "EPTCS 335, 2021, pp. 155-170", "doi": "10.4204/EPTCS.335.14", "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In an interactive belief model, are the players \"commonly meta-certain\" of\nthe model itself? This paper formalizes such implicit \"common meta-certainty\"\nassumption. To that end, the paper expands the objects of players' beliefs from\nevents to functions defined on the underlying states. Then, the paper defines a\nplayer's belief-generating map: it associates, with each state, whether a\nplayer believes each event at that state. The paper formalizes what it means\nby: \"a player is (meta-)certain of her own belief-generating map\" or \"the\nplayers are (meta-)certain of the profile of belief-generating maps (i.e., the\nmodel).\" The paper shows: a player is (meta-)certain of her own\nbelief-generating map if and only if her beliefs are introspective. The players\nare commonly (meta-)certain of the model if and only if, for any event which\nsome player i believes at some state, it is common belief at the state that\nplayer i believes the event. This paper then asks whether the \"common\nmeta-certainty\" assumption is needed for an epistemic characterization of\ngame-theoretic solution concepts. The paper shows: if each player is logical\nand (meta-)certain of her own strategy and belief-generating map, then each\nplayer correctly believes her own rationality. Consequently, common belief in\nrationality alone leads to actions that survive iterated elimination of\nstrictly dominated actions.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 02:46:07 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Fukuda", "Satoshi", "", "Department of Decision Sciences and IGIER, Bocconi\n  University"]]}, {"id": "2106.11501", "submitter": "EPTCS", "authors": "Jeremy Goodman, Bernhard Salow", "title": "Knowledge from Probability", "comments": "In Proceedings TARK 2021, arXiv:2106.10886", "journal-ref": "EPTCS 335, 2021, pp. 171-186", "doi": "10.4204/EPTCS.335.15", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We give a probabilistic analysis of inductive knowledge and belief and\nexplore its predictions concerning knowledge about the future, about laws of\nnature, and about the values of inexactly measured quantities. The analysis\ncombines a theory of knowledge and belief formulated in terms of relations of\ncomparative normality with a probabilistic reduction of those relations. It\npredicts that only highly probable propositions are believed, and that many\nwidely held principles of belief-revision fail.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 02:46:22 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Goodman", "Jeremy", ""], ["Salow", "Bernhard", ""]]}, {"id": "2106.11503", "submitter": "EPTCS", "authors": "Gabriel Istrate (West University of Timisoara, Romania)", "title": "Game-Theoretic Models of Moral and Other-Regarding Agents (extended\n  abstract)", "comments": "In Proceedings TARK 2021, arXiv:2106.10886. This is the extended\n  abstract that appears in the Proceedings of TARK 2021. A longer, more\n  complete, version of the paper is available as preprint arXiv:2012.09759", "journal-ref": "EPTCS 335, 2021, pp. 213-227", "doi": "10.4204/EPTCS.335.19", "report-no": null, "categories": "cs.GT cs.AI cs.MA cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate Kantian equilibria in finite normal form games, a class of\nnon-Nashian, morally motivated courses of action that was recently proposed in\nthe economics literature. We highlight a number of problems with such\nequilibria, including computational intractability, a high price of\nmiscoordination, and problematic extension to general normal form games. We\ngive such a generalization based on concept of program equilibria, and point\nout that that a practically relevant generalization may not exist. To remedy\nthis we propose some general, intuitive, computationally tractable,\nother-regarding equilibria that are special cases Kantian equilibria, as well\nas a class of courses of action that interpolates between purely self-regarding\nand Kantian behavior.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 02:46:52 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Istrate", "Gabriel", "", "West University of Timisoara, Romania"]]}, {"id": "2106.11504", "submitter": "EPTCS", "authors": "Yanjun Li (Nankai University), Yanjing Wang (Peking University)", "title": "Knowing How to Plan", "comments": "In Proceedings TARK 2021, arXiv:2106.10886", "journal-ref": "EPTCS 335, 2021, pp. 233-247", "doi": "10.4204/EPTCS.335.22", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Various planning-based know-how logics have been studied in the recent\nliterature. In this paper, we use such a logic to do know-how-based planning\nvia model checking. In particular, we can handle the higher-order epistemic\nplanning involving know-how formulas as the goal, e.g., find a plan to make\nsure p such that the adversary does not know how to make p false in the future.\nWe give a PTIME algorithm for the model checking problem over finite epistemic\ntransition systems and axiomatize the logic under the assumption of perfect\nrecall.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 02:47:06 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Li", "Yanjun", "", "Nankai University"], ["Wang", "Yanjing", "", "Peking University"]]}, {"id": "2106.11514", "submitter": "Yizhou Wang", "authors": "Yizhou Wang, Yue Kang, Can Qin, Yi Xu, Huan Wang, Yulun Zhang, Yun Fu", "title": "Adapting Stepsizes by Momentumized Gradients Improves Optimization and\n  Generalization", "comments": "40 pages, 27 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adaptive gradient methods, such as \\textsc{Adam}, have achieved tremendous\nsuccess in machine learning. Scaling gradients by square roots of the running\naverages of squared past gradients, such methods are able to attain rapid\ntraining of modern deep neural networks. Nevertheless, they are observed to\ngeneralize worse than stochastic gradient descent (\\textsc{SGD}) and tend to be\ntrapped in local minima at an early stage during training. Intriguingly, we\ndiscover that substituting the gradient in the preconditioner term with the\nmomentumized version in \\textsc{Adam} can well solve the issues. The intuition\nis that gradient with momentum contains more accurate directional information\nand therefore its second moment estimation is a better choice for scaling than\nraw gradient's. Thereby we propose \\textsc{AdaMomentum} as a new optimizer\nreaching the goal of training faster while generalizing better. We further\ndevelop a theory to back up the improvement in optimization and generalization\nand provide convergence guarantee under both convex and nonconvex settings.\nExtensive experiments on various models and tasks demonstrate that\n\\textsc{AdaMomentum} exhibits comparable performance to \\textsc{SGD} on vision\ntasks, and achieves state-of-the-art results consistently on other tasks\nincluding language processing.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 03:13:23 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Wang", "Yizhou", ""], ["Kang", "Yue", ""], ["Qin", "Can", ""], ["Xu", "Yi", ""], ["Wang", "Huan", ""], ["Zhang", "Yulun", ""], ["Fu", "Yun", ""]]}, {"id": "2106.11516", "submitter": "Lin Li", "authors": "Lin Li, Xin Kong, Xiangrui Zhao, Wanlong Li, Feng Wen, Hongbo Zhang\n  and Yong Liu", "title": "SA-LOAM: Semantic-aided LiDAR SLAM with Loop Closure", "comments": "8 pages. Accepted by ICRA-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  LiDAR-based SLAM system is admittedly more accurate and stable than others,\nwhile its loop closure detection is still an open issue. With the development\nof 3D semantic segmentation for point cloud, semantic information can be\nobtained conveniently and steadily, essential for high-level intelligence and\nconductive to SLAM. In this paper, we present a novel semantic-aided LiDAR SLAM\nwith loop closure based on LOAM, named SA-LOAM, which leverages semantics in\nodometry as well as loop closure detection. Specifically, we propose a\nsemantic-assisted ICP, including semantically matching, downsampling and plane\nconstraint, and integrates a semantic graph-based place recognition method in\nour loop closure detection module. Benefitting from semantics, we can improve\nthe localization accuracy, detect loop closures effectively, and construct a\nglobal consistent semantic map even in large-scale scenes. Extensive\nexperiments on KITTI and Ford Campus dataset show that our system significantly\nimproves baseline performance, has generalization ability to unseen data and\nachieves competitive results compared with state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 03:14:20 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 06:56:19 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Li", "Lin", ""], ["Kong", "Xin", ""], ["Zhao", "Xiangrui", ""], ["Li", "Wanlong", ""], ["Wen", "Feng", ""], ["Zhang", "Hongbo", ""], ["Liu", "Yong", ""]]}, {"id": "2106.11519", "submitter": "Ayush Sekhari", "authors": "Christoph Dann, Yishay Mansour, Mehryar Mohri, Ayush Sekhari and\n  Karthik Sridharan", "title": "Agnostic Reinforcement Learning with Low-Rank MDPs and Rich Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There have been many recent advances on provably efficient Reinforcement\nLearning (RL) in problems with rich observation spaces. However, all these\nworks share a strong realizability assumption about the optimal value function\nof the true MDP. Such realizability assumptions are often too strong to hold in\npractice. In this work, we consider the more realistic setting of agnostic RL\nwith rich observation spaces and a fixed class of policies $\\Pi$ that may not\ncontain any near-optimal policy. We provide an algorithm for this setting whose\nerror is bounded in terms of the rank $d$ of the underlying MDP. Specifically,\nour algorithm enjoys a sample complexity bound of $\\widetilde{O}\\left((H^{4d}\nK^{3d} \\log |\\Pi|)/\\epsilon^2\\right)$ where $H$ is the length of episodes, $K$\nis the number of actions and $\\epsilon>0$ is the desired sub-optimality. We\nalso provide a nearly matching lower bound for this agnostic setting that shows\nthat the exponential dependence on rank is unavoidable, without further\nassumptions.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 03:20:40 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Dann", "Christoph", ""], ["Mansour", "Yishay", ""], ["Mohri", "Mehryar", ""], ["Sekhari", "Ayush", ""], ["Sridharan", "Karthik", ""]]}, {"id": "2106.11528", "submitter": "Gyeongho Kim", "authors": "Gyeongho Kim", "title": "Recent Deep Semi-supervised Learning Approaches and Related Works", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The author of this work proposes an overview of the recent semi-supervised\nlearning approaches and related works. Despite the remarkable success of neural\nnetworks in various applications, there exist few formidable constraints\nincluding the need for a large amount of labeled data. Therefore,\nsemi-supervised learning, which is a learning scheme in which the scarce labels\nand a larger amount of unlabeled data are utilized to train models (e.g., deep\nneural networks) is getting more important. Based on the key assumptions of\nsemi-supervised learning, which are the manifold assumption, cluster\nassumption, and continuity assumption, the work reviews the recent\nsemi-supervised learning approaches. In particular, the methods in regard to\nusing deep neural networks in a semi-supervised learning setting are primarily\ndiscussed. In addition, the existing works are first classified based on the\nunderlying idea and explained, and then the holistic approaches that unify the\naforementioned ideas are detailed.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 03:44:03 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Kim", "Gyeongho", ""]]}, {"id": "2106.11531", "submitter": "Yang Li", "authors": "Yang Li, Wei Zhao, Erik Cambria, Suhang Wang, Steffen Eger", "title": "Graph Routing between Capsules", "comments": null, "journal-ref": "Neural Network 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Routing methods in capsule networks often learn a hierarchical relationship\nfor capsules in successive layers, but the intra-relation between capsules in\nthe same layer is less studied, while this intra-relation is a key factor for\nthe semantic understanding in text data. Therefore, in this paper, we introduce\na new capsule network with graph routing to learn both relationships, where\ncapsules in each layer are treated as the nodes of a graph. We investigate\nstrategies to yield adjacency and degree matrix with three different distances\nfrom a layer of capsules, and propose the graph routing mechanism between those\ncapsules. We validate our approach on five text classification datasets, and\nour findings suggest that the approach combining bottom-up routing and top-down\nattention performs the best. Such an approach demonstrates generalization\ncapability across datasets. Compared to the state-of-the-art routing methods,\nthe improvements in accuracy in the five datasets we used were 0.82, 0.39,\n0.07, 1.01, and 0.02, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 04:00:57 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Li", "Yang", ""], ["Zhao", "Wei", ""], ["Cambria", "Erik", ""], ["Wang", "Suhang", ""], ["Eger", "Steffen", ""]]}, {"id": "2106.11533", "submitter": "Peifeng Wang", "authors": "Peifeng Wang, Filip Ilievski, Muhao Chen, Xiang Ren", "title": "Do Language Models Perform Generalizable Commonsense Inference?", "comments": "8 pages, 4 figures. Accepted to ACL'21 Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by evidence that pretrained language models (LMs) encode commonsense\nknowledge, recent work has applied LMs to automatically populate commonsense\nknowledge graphs (CKGs). However, there is a lack of understanding on their\ngeneralization to multiple CKGs, unseen relations, and novel entities. This\npaper analyzes the ability of LMs to perform generalizable commonsense\ninference, in terms of knowledge capacity, transferability, and induction. Our\nexperiments with these three aspects show that: (1) LMs can adapt to different\nschemas defined by multiple CKGs but fail to reuse the knowledge to generalize\nto new relations. (2) Adapted LMs generalize well to unseen subjects, but less\nso on novel objects. Future work should investigate how to improve the\ntransferability and induction of commonsense mining from LMs.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 04:17:19 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Wang", "Peifeng", ""], ["Ilievski", "Filip", ""], ["Chen", "Muhao", ""], ["Ren", "Xiang", ""]]}, {"id": "2106.11575", "submitter": "Gangwoo Kim", "authors": "Gangwoo Kim, Hyunjae Kim, Jungsoo Park, Jaewoo Kang", "title": "Learn to Resolve Conversational Dependency: A Consistency Training\n  Framework for Conversational Question Answering", "comments": "12 pages, ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main challenges in conversational question answering (CQA) is to\nresolve the conversational dependency, such as anaphora and ellipsis. However,\nexisting approaches do not explicitly train QA models on how to resolve the\ndependency, and thus these models are limited in understanding human dialogues.\nIn this paper, we propose a novel framework, ExCorD (Explicit guidance on how\nto resolve Conversational Dependency) to enhance the abilities of QA models in\ncomprehending conversational context. ExCorD first generates self-contained\nquestions that can be understood without the conversation history, then trains\na QA model with the pairs of original and self-contained questions using a\nconsistency-based regularizer. In our experiments, we demonstrate that ExCorD\nsignificantly improves the QA models' performance by up to 1.2 F1 on QuAC, and\n5.2 F1 on CANARD, while addressing the limitations of the existing approaches.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 07:16:45 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Kim", "Gangwoo", ""], ["Kim", "Hyunjae", ""], ["Park", "Jungsoo", ""], ["Kang", "Jaewoo", ""]]}, {"id": "2106.11576", "submitter": "Boris Chidlovskii", "authors": "Chidlovskii Boris, Assem Sadek, Christian Wolf", "title": "Universal Domain Adaptation in Ordinal Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address the problem of universal domain adaptation (UDA) in ordinal\nregression (OR), which attempts to solve classification problems in which\nlabels are not independent, but follow a natural order. We show that the UDA\ntechniques developed for classification and based on the clustering assumption,\nunder-perform in OR settings. We propose a method that complements the OR\nclassifier with an auxiliary task of order learning, which plays the double\nrole of discriminating between common and private instances, and expanding\nclass labels to the private target images via ranking. Combined with\nadversarial domain discrimination, our model is able to address the closed set,\npartial and open set configurations. We evaluate our method on three face age\nestimation datasets, and show that it outperforms the baseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 07:23:39 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Boris", "Chidlovskii", ""], ["Sadek", "Assem", ""], ["Wolf", "Christian", ""]]}, {"id": "2106.11581", "submitter": "Michael Poli", "authors": "Michael Poli, Stefano Massaroli, Clayton M. Rabideau, Junyoung Park,\n  Atsushi Yamashita, Hajime Asama, Jinkyoo Park", "title": "Continuous-Depth Neural Models for Dynamic Graph Prediction", "comments": "Extended version of the workshop paper \"Graph Neural Ordinary\n  Differential Equations\". arXiv admin note: substantial text overlap with\n  arXiv:1911.07532", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the framework of continuous-depth graph neural networks (GNNs).\nNeural graph differential equations (Neural GDEs) are formalized as the\ncounterpart to GNNs where the input-output relationship is determined by a\ncontinuum of GNN layers, blending discrete topological structures and\ndifferential equations. The proposed framework is shown to be compatible with\nstatic GNN models and is extended to dynamic and stochastic settings through\nhybrid dynamical system theory. Here, Neural GDEs improve performance by\nexploiting the underlying dynamics geometry, further introducing the ability to\naccommodate irregularly sampled data. Results prove the effectiveness of the\nproposed models across applications, such as traffic forecasting or prediction\nin genetic regulatory networks.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 07:30:35 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Poli", "Michael", ""], ["Massaroli", "Stefano", ""], ["Rabideau", "Clayton M.", ""], ["Park", "Junyoung", ""], ["Yamashita", "Atsushi", ""], ["Asama", "Hajime", ""], ["Park", "Jinkyoo", ""]]}, {"id": "2106.11593", "submitter": "Xiang Ni", "authors": "Xiang Ni, Xiaolong Xu, Lingjuan Lyu, Changhua Meng, Weiqiang Wang", "title": "A Vertical Federated Learning Framework for Graph Convolutional Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Recently, Graph Neural Network (GNN) has achieved remarkable success in\nvarious real-world problems on graph data. However in most industries, data\nexists in the form of isolated islands and the data privacy and security is\nalso an important issue. In this paper, we propose FedVGCN, a federated GCN\nlearning paradigm for privacy-preserving node classification task under data\nvertically partitioned setting, which can be generalized to existing GCN\nmodels. Specifically, we split the computation graph data into two parts. For\neach iteration of the training process, the two parties transfer intermediate\nresults to each other under homomorphic encryption. We conduct experiments on\nbenchmark data and the results demonstrate the effectiveness of FedVGCN in the\ncase of GraphSage.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 07:57:46 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Ni", "Xiang", ""], ["Xu", "Xiaolong", ""], ["Lyu", "Lingjuan", ""], ["Meng", "Changhua", ""], ["Wang", "Weiqiang", ""]]}, {"id": "2106.11595", "submitter": "Philippe Mary", "authors": "Philippe Mary, Visa Koivunen, Christophe Moy", "title": "Reinforcement Learning for Physical Layer Communications", "comments": "Machine Learning and Wireless Communications, In press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter, we will give comprehensive examples of applying RL in\noptimizing the physical layer of wireless communications by defining different\nclass of problems and the possible solutions to handle them. In Section 9.2, we\npresent all the basic theory needed to address a RL problem, i.e. Markov\ndecision process (MDP), Partially observable Markov decision process (POMDP),\nbut also two very important and widely used algorithms for RL, i.e. the\nQ-learning and SARSA algorithms. We also introduce the deep reinforcement\nlearning (DRL) paradigm and the section ends with an introduction to the\nmulti-armed bandits (MAB) framework. Section 9.3 focuses on some toy examples\nto illustrate how the basic concepts of RL are employed in communication\nsystems. We present applications extracted from literature with simplified\nsystem models using similar notation as in Section 9.2 of this Chapter. In\nSection 9.3, we also focus on modeling RL problems, i.e. how action and state\nspaces and rewards are chosen. The Chapter is concluded in Section 9.4 with a\nprospective thought on RL trends and it ends with a review of a broader state\nof the art in Section 9.5.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 08:02:06 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 16:20:43 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Mary", "Philippe", ""], ["Koivunen", "Visa", ""], ["Moy", "Christophe", ""]]}, {"id": "2106.11596", "submitter": "Jun Huang", "authors": "Xiwen Qu, Hao Che, Jun Huang, Linchuan Xu, Xiao Zheng", "title": "Multi-layered Semantic Representation Network for Multi-label Image\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label image classification (MLIC) is a fundamental and practical task,\nwhich aims to assign multiple possible labels to an image. In recent years,\nmany deep convolutional neural network (CNN) based approaches have been\nproposed which model label correlations to discover semantics of labels and\nlearn semantic representations of images. This paper advances this research\ndirection by improving both the modeling of label correlations and the learning\nof semantic representations. On the one hand, besides the local semantics of\neach label, we propose to further explore global semantics shared by multiple\nlabels. On the other hand, existing approaches mainly learn the semantic\nrepresentations at the last convolutional layer of a CNN. But it has been noted\nthat the image representations of different layers of CNN capture different\nlevels or scales of features and have different discriminative abilities. We\nthus propose to learn semantic representations at multiple convolutional\nlayers. To this end, this paper designs a Multi-layered Semantic Representation\nNetwork (MSRN) which discovers both local and global semantics of labels\nthrough modeling label correlations and utilizes the label semantics to guide\nthe semantic representations learning at multiple layers through an attention\nmechanism. Extensive experiments on four benchmark datasets including VOC 2007,\nCOCO, NUS-WIDE, and Apparel show a competitive performance of the proposed MSRN\nagainst state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 08:04:22 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Qu", "Xiwen", ""], ["Che", "Hao", ""], ["Huang", "Jun", ""], ["Xu", "Linchuan", ""], ["Zheng", "Xiao", ""]]}, {"id": "2106.11613", "submitter": "Chen Jingye", "authors": "Jingye Chen, Bin Li, Xiangyang Xue", "title": "Zero-Shot Chinese Character Recognition with Stroke-Level Decomposition", "comments": "7 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Chinese character recognition has attracted much research interest due to its\nwide applications. Although it has been studied for many years, some issues in\nthis field have not been completely resolved yet, e.g. the zero-shot problem.\nPrevious character-based and radical-based methods have not fundamentally\naddressed the zero-shot problem since some characters or radicals in test sets\nmay not appear in training sets under a data-hungry condition. Inspired by the\nfact that humans can generalize to know how to write characters unseen before\nif they have learned stroke orders of some characters, we propose a\nstroke-based method by decomposing each character into a sequence of strokes,\nwhich are the most basic units of Chinese characters. However, we observe that\nthere is a one-to-many relationship between stroke sequences and Chinese\ncharacters. To tackle this challenge, we employ a matching-based strategy to\ntransform the predicted stroke sequence to a specific character. We evaluate\nthe proposed method on handwritten characters, printed artistic characters, and\nscene characters. The experimental results validate that the proposed method\noutperforms existing methods on both character zero-shot and radical zero-shot\ntasks. Moreover, the proposed method can be easily generalized to other\nlanguages whose characters can be decomposed into strokes.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 08:49:03 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Chen", "Jingye", ""], ["Li", "Bin", ""], ["Xue", "Xiangyang", ""]]}, {"id": "2106.11652", "submitter": "Zhiwei Xu", "authors": "Zhiwei Xu, Dapeng Li, Yunpeng Bai, Guoliang Fan", "title": "MMD-MIX: Value Function Factorisation with Maximum Mean Discrepancy for\n  Cooperative Multi-Agent Reinforcement Learning", "comments": "7 pages, 2 figures, 2 tables. Accepted by IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the real world, many tasks require multiple agents to cooperate with each\nother under the condition of local observations. To solve such problems, many\nmulti-agent reinforcement learning methods based on Centralized Training with\nDecentralized Execution have been proposed. One representative class of work is\nvalue decomposition, which decomposes the global joint Q-value $Q_\\text{jt}$\ninto individual Q-values $Q_a$ to guide individuals' behaviors, e.g. VDN\n(Value-Decomposition Networks) and QMIX. However, these baselines often ignore\nthe randomness in the situation. We propose MMD-MIX, a method that combines\ndistributional reinforcement learning and value decomposition to alleviate the\nabove weaknesses. Besides, to improve data sampling efficiency, we were\ninspired by REM (Random Ensemble Mixture) which is a robust RL algorithm to\nexplicitly introduce randomness into the MMD-MIX. The experiments demonstrate\nthat MMD-MIX outperforms prior baselines in the StarCraft Multi-Agent Challenge\n(SMAC) environment.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 10:21:00 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Xu", "Zhiwei", ""], ["Li", "Dapeng", ""], ["Bai", "Yunpeng", ""], ["Fan", "Guoliang", ""]]}, {"id": "2106.11655", "submitter": "Kaitlin Maile", "authors": "Kaitlin Maile, Erwan Lecarpentier, Herv\\'e Luga, Dennis G. Wilson", "title": "On Constrained Optimization in Differentiable Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Differentiable Architecture Search (DARTS) is a recently proposed neural\narchitecture search (NAS) method based on a differentiable relaxation. Due to\nits success, numerous variants analyzing and improving parts of the DARTS\nframework have recently been proposed. By considering the problem as a\nconstrained bilevel optimization, we propose and analyze three improvements to\narchitectural weight competition, update scheduling, and regularization towards\ndiscretization. First, we introduce a new approach to the activation of\narchitecture weights, which prevents confounding competition within an edge and\nallows for fair comparison across edges to aid in discretization. Next, we\npropose a dynamic schedule based on per-minibatch network information to make\narchitecture updates more informed. Finally, we consider two regularizations,\nbased on proximity to discretization and the Alternating Directions Method of\nMultipliers (ADMM) algorithm, to promote early discretization. Our results show\nthat this new activation scheme reduces final architecture size and the\nregularizations improve reliability in search results while maintaining\ncomparable performance to state-of-the-art in NAS, especially when used with\nour new dynamic informed schedule.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 10:22:31 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2021 08:52:17 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Maile", "Kaitlin", ""], ["Lecarpentier", "Erwan", ""], ["Luga", "Herv\u00e9", ""], ["Wilson", "Dennis G.", ""]]}, {"id": "2106.11735", "submitter": "Wen-Chi Yang", "authors": "Wen-Chi Yang, Jean-Fran\\c{c}ois Raskin and Luc De Raedt", "title": "Lifted Model Checking for Relational MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Model checking has been developed for verifying the behaviour of systems with\nstochastic and non-deterministic behavior. It is used to provide guarantees\nabout such systems. While most model checking methods focus on propositional\nmodels, various probabilistic planning and reinforcement frameworks deal with\nrelational domains, for instance, STRIPS planning and relational Markov\nDecision Processes. Using propositional model checking in relational settings\nrequires one to ground the model, which leads to the well known state explosion\nproblem and intractability. We present pCTL-REBEL, a lifted model checking\napproach for verifying pCTL properties on relational MDPs. It extends REBEL,\nthe relational Bellman update operator, which is a lifted value iteration\napproach for model-based relational reinforcement learning, toward relational\nmodel-checking. PCTL-REBEL is lifted, which means that rather than grounding,\nthe model exploits symmetries and reasons at an abstract relational level.\nTheoretically, we show that the pCTL model checking approach is decidable for\nrelational MDPs even for possibly infinite domains provided that the states\nhave a bounded size. Practically, we contribute algorithms and an\nimplementation of lifted relational model checking, and we show that the lifted\napproach improves the scalability of the model checking approach.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 13:12:36 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Yang", "Wen-Chi", ""], ["Raskin", "Jean-Fran\u00e7ois", ""], ["De Raedt", "Luc", ""]]}, {"id": "2106.11740", "submitter": "Weihao Yu", "authors": "Weihao Yu, Zihang Jiang, Fei Chen, Qibin Hou and Jiashi Feng", "title": "LV-BERT: Exploiting Layer Variety for BERT", "comments": "Accepted to Findings of ACL 2021. The code and pre-trained models are\n  available at https://github.com/yuweihao/LV-BERT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern pre-trained language models are mostly built upon backbones stacking\nself-attention and feed-forward layers in an interleaved order. In this paper,\nbeyond this stereotyped layer pattern, we aim to improve pre-trained models by\nexploiting layer variety from two aspects: the layer type set and the layer\norder. Specifically, besides the original self-attention and feed-forward\nlayers, we introduce convolution into the layer type set, which is\nexperimentally found beneficial to pre-trained models. Furthermore, beyond the\noriginal interleaved order, we explore more layer orders to discover more\npowerful architectures. However, the introduced layer variety leads to a large\narchitecture space of more than billions of candidates, while training a single\ncandidate model from scratch already requires huge computation cost, making it\nnot affordable to search such a space by directly training large amounts of\ncandidate models. To solve this problem, we first pre-train a supernet from\nwhich the weights of all candidate models can be inherited, and then adopt an\nevolutionary algorithm guided by pre-training accuracy to find the optimal\narchitecture. Extensive experiments show that LV-BERT model obtained by our\nmethod outperforms BERT and its variants on various downstream tasks. For\nexample, LV-BERT-small achieves 79.8 on the GLUE testing set, 1.8 higher than\nthe strong baseline ELECTRA-small.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 13:20:14 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 03:58:57 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Yu", "Weihao", ""], ["Jiang", "Zihang", ""], ["Chen", "Fei", ""], ["Hou", "Qibin", ""], ["Feng", "Jiashi", ""]]}, {"id": "2106.11756", "submitter": "C. V. Krishnakumar Iyer", "authors": "C.V.Krishnakumar Iyer, Feili Hou, Henry Wang, Yonghong Wang, Kay Oh,\n  Swetava Ganguli, Vipul Pandey", "title": "Trinity: A No-Code AI platform for complex spatial datasets", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present a no-code Artificial Intelligence (AI) platform called Trinity\nwith the main design goal of enabling both machine learning researchers and\nnon-technical geospatial domain experts to experiment with domain-specific\nsignals and datasets for solving a variety of complex problems on their own.\nThis versatility to solve diverse problems is achieved by transforming complex\nSpatio-temporal datasets to make them consumable by standard deep learning\nmodels, in this case, Convolutional Neural Networks (CNNs), and giving the\nability to formulate disparate problems in a standard way, eg. semantic\nsegmentation. With an intuitive user interface, a feature store that hosts\nderivatives of complex feature engineering, a deep learning kernel, and a\nscalable data processing mechanism, Trinity provides a powerful platform for\ndomain experts to share the stage with scientists and engineers in solving\nbusiness-critical problems. It enables quick prototyping, rapid experimentation\nand reduces the time to production by standardizing model building and\ndeployment. In this paper, we present our motivation behind Trinity and its\ndesign along with showcasing sample applications to motivate the idea of\nlowering the bar to using AI.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 08:28:34 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 03:39:10 GMT"}, {"version": "v3", "created": "Thu, 24 Jun 2021 04:49:58 GMT"}, {"version": "v4", "created": "Mon, 28 Jun 2021 18:43:48 GMT"}, {"version": "v5", "created": "Thu, 1 Jul 2021 06:22:23 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Iyer", "C. V. Krishnakumar", ""], ["Hou", "Feili", ""], ["Wang", "Henry", ""], ["Wang", "Yonghong", ""], ["Oh", "Kay", ""], ["Ganguli", "Swetava", ""], ["Pandey", "Vipul", ""]]}, {"id": "2106.11759", "submitter": "Vikramjit Mitra", "authors": "Vikramjit Mitra, Zifang Huang, Colin Lea, Lauren Tooley, Sarah Wu,\n  Darren Botten, Ashwini Palekar, Shrinath Thelapurath, Panayiotis Georgiou,\n  Sachin Kajarekar, Jefferey Bigham", "title": "Analysis and Tuning of a Voice Assistant System for Dysfluent Speech", "comments": "5 pages, 1 page reference, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.CV cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dysfluencies and variations in speech pronunciation can severely degrade\nspeech recognition performance, and for many individuals with\nmoderate-to-severe speech disorders, voice operated systems do not work.\nCurrent speech recognition systems are trained primarily with data from fluent\nspeakers and as a consequence do not generalize well to speech with\ndysfluencies such as sound or word repetitions, sound prolongations, or audible\nblocks. The focus of this work is on quantitative analysis of a consumer speech\nrecognition system on individuals who stutter and production-oriented\napproaches for improving performance for common voice assistant tasks (i.e.,\n\"what is the weather?\"). At baseline, this system introduces a significant\nnumber of insertion and substitution errors resulting in intended speech Word\nError Rates (isWER) that are 13.64\\% worse (absolute) for individuals with\nfluency disorders. We show that by simply tuning the decoding parameters in an\nexisting hybrid speech recognition system one can improve isWER by 24\\%\n(relative) for individuals with fluency disorders. Tuning these parameters\ntranslates to 3.6\\% better domain recognition and 1.7\\% better intent\nrecognition relative to the default setup for the 18 study participants across\nall stuttering severities.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 20:58:34 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Mitra", "Vikramjit", ""], ["Huang", "Zifang", ""], ["Lea", "Colin", ""], ["Tooley", "Lauren", ""], ["Wu", "Sarah", ""], ["Botten", "Darren", ""], ["Palekar", "Ashwini", ""], ["Thelapurath", "Shrinath", ""], ["Georgiou", "Panayiotis", ""], ["Kajarekar", "Sachin", ""], ["Bigham", "Jefferey", ""]]}, {"id": "2106.11760", "submitter": "GuanLin Li", "authors": "Li Guanlin, Guo Shangwei, Wang Run, Xu Guowen, Zhang Tianwei", "title": "A Stealthy and Robust Fingerprinting Scheme for Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a novel fingerprinting methodology for the Intellectual\nProperty protection of generative models. Prior solutions for discriminative\nmodels usually adopt adversarial examples as the fingerprints, which give\nanomalous inference behaviors and prediction results. Hence, these methods are\nnot stealthy and can be easily recognized by the adversary. Our approach\nleverages the invisible backdoor technique to overcome the above limitation.\nSpecifically, we design verification samples, whose model outputs look normal\nbut can trigger a backdoor classifier to make abnormal predictions. We propose\na new backdoor embedding approach with Unique-Triplet Loss and fine-grained\ncategorization to enhance the effectiveness of our fingerprints. Extensive\nevaluations show that this solution can outperform other strategies with higher\nrobustness, uniqueness and stealthiness for various GAN models.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 06:25:10 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Guanlin", "Li", ""], ["Shangwei", "Guo", ""], ["Run", "Wang", ""], ["Guowen", "Xu", ""], ["Tianwei", "Zhang", ""]]}, {"id": "2106.11791", "submitter": "Soujanya Poria", "authors": "Navonil Majumder, Deepanway Ghosal, Devamanyu Hazarika, Alexander\n  Gelbukh, Rada Mihalcea, Soujanya Poria", "title": "Exemplars-guided Empathetic Response Generation Controlled by the\n  Elements of Human Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The majority of existing methods for empathetic response generation rely on\nthe emotion of the context to generate empathetic responses. However, empathy\nis much more than generating responses with an appropriate emotion. It also\noften entails subtle expressions of understanding and personal resonance with\nthe situation of the other interlocutor. Unfortunately, such qualities are\ndifficult to quantify and the datasets lack the relevant annotations. To\naddress this issue, in this paper we propose an approach that relies on\nexemplars to cue the generative model on fine stylistic properties that signal\nempathy to the interlocutor. To this end, we employ dense passage retrieval to\nextract relevant exemplary responses from the training set. Three elements of\nhuman communication -- emotional presence, interpretation, and exploration, and\nsentiment are additionally introduced using synthetic labels to guide the\ngeneration towards empathy. The human evaluation is also extended by these\nelements of human communication. We empirically show that these approaches\nyield significant improvements in empathetic response quality in terms of both\nautomated and human-evaluated metrics. The implementation is available at\nhttps://github.com/declare-lab/exemplary-empathy.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 14:02:33 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Majumder", "Navonil", ""], ["Ghosal", "Deepanway", ""], ["Hazarika", "Devamanyu", ""], ["Gelbukh", "Alexander", ""], ["Mihalcea", "Rada", ""], ["Poria", "Soujanya", ""]]}, {"id": "2106.11804", "submitter": "Antonio Mora Dr.", "authors": "A.M. Mora and A.I. Esparcia-Alc\\'azar", "title": "Evo* 2021 -- Late-Breaking Abstracts Volume", "comments": "LBAs accepted in Evo* 2021. Part of the Conference Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Volume with the Late-Breaking Abstracts submitted to the Evo* 2021\nConference, held online from 7 to 9 of April 2021. These papers present ongoing\nresearch and preliminary results investigating on the application of different\napproaches of Bioinspired Methods (mainly Evolutionary Computation) to\ndifferent problems, most of them real world ones.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 22:21:46 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Mora", "A. M.", ""], ["Esparcia-Alc\u00e1zar", "A. I.", ""]]}, {"id": "2106.11823", "submitter": "Xuyang Yan", "authors": "Xuyang Yan, Abdollah Homaifar, Mrinmoy Sarkar, Abenezer Girma, and\n  Edward Tunstel", "title": "A Clustering-based Framework for Classifying Data Streams", "comments": "This paper has been accepted by IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The non-stationary nature of data streams strongly challenges traditional\nmachine learning techniques. Although some solutions have been proposed to\nextend traditional machine learning techniques for handling data streams, these\napproaches either require an initial label set or rely on specialized design\nparameters. The overlap among classes and the labeling of data streams\nconstitute other major challenges for classifying data streams. In this paper,\nwe proposed a clustering-based data stream classification framework to handle\nnon-stationary data streams without utilizing an initial label set. A\ndensity-based stream clustering procedure is used to capture novel concepts\nwith a dynamic threshold and an effective active label querying strategy is\nintroduced to continuously learn the new concepts from the data streams. The\nsub-cluster structure of each cluster is explored to handle the overlap among\nclasses. Experimental results and quantitative comparison studies reveal that\nthe proposed method provides statistically better or comparable performance\nthan the existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 14:37:52 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Yan", "Xuyang", ""], ["Homaifar", "Abdollah", ""], ["Sarkar", "Mrinmoy", ""], ["Girma", "Abenezer", ""], ["Tunstel", "Edward", ""]]}, {"id": "2106.11828", "submitter": "Gustavo de Rosa", "authors": "Gustavo H. de Rosa, Jo\\~ao Paulo Papa", "title": "Speeding Up OPFython with Numba", "comments": "12 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A graph-inspired classifier, known as Optimum-Path Forest (OPF), has proven\nto be a state-of-the-art algorithm comparable to Logistic Regressors, Support\nVector Machines in a wide variety of tasks. Recently, its Python-based version,\ndenoted as OPFython, has been proposed to provide a more friendly framework and\na faster prototyping environment. Nevertheless, Python-based algorithms are\nslower than their counterpart C-based algorithms, impacting their performance\nwhen confronted with large amounts of data. Therefore, this paper proposed a\nsimple yet highly efficient speed up using the Numba package, which accelerates\nNumpy-based calculations and attempts to increase the algorithm's overall\nperformance. Experimental results showed that the proposed approach achieved\nbetter results than the na\\\"ive Python-based OPF and speeded up its distance\nmeasurement calculation.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 14:39:32 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["de Rosa", "Gustavo H.", ""], ["Papa", "Jo\u00e3o Paulo", ""]]}, {"id": "2106.11849", "submitter": "Julius von K\\\"ugelgen", "authors": "Julius von K\\\"ugelgen, Nikita Agarwal, Jakob Zeitler, Afsaneh\n  Mastouri, Bernhard Sch\\\"olkopf", "title": "Algorithmic Recourse in Partially and Fully Confounded Settings Through\n  Bounding Counterfactual Effects", "comments": "Preliminary workshop version; work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic recourse aims to provide actionable recommendations to\nindividuals to obtain a more favourable outcome from an automated\ndecision-making system. As it involves reasoning about interventions performed\nin the physical world, recourse is fundamentally a causal problem. Existing\nmethods compute the effect of recourse actions using a causal model learnt from\ndata under the assumption of no hidden confounding and modelling assumptions\nsuch as additive noise. Building on the seminal work of Balke and Pearl (1994),\nwe propose an alternative approach for discrete random variables which relaxes\nthese assumptions and allows for unobserved confounding and arbitrary\nstructural equations. The proposed approach only requires specification of the\ncausal graph and confounding structure and bounds the expected counterfactual\neffect of recourse actions. If the lower bound is above a certain threshold,\ni.e., on the other side of the decision boundary, recourse is guaranteed in\nexpectation.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 15:07:49 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["von K\u00fcgelgen", "Julius", ""], ["Agarwal", "Nikita", ""], ["Zeitler", "Jakob", ""], ["Mastouri", "Afsaneh", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2106.11853", "submitter": "Julian Lienen", "authors": "Julian Lienen, Eyke H\\\"ullermeier", "title": "Credal Self-Supervised Learning", "comments": "17 pages, 1 figure, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-training is an effective approach to semi-supervised learning. The key\nidea is to let the learner itself iteratively generate \"pseudo-supervision\" for\nunlabeled instances based on its current hypothesis. In combination with\nconsistency regularization, pseudo-labeling has shown promising performance in\nvarious domains, for example in computer vision. To account for the\nhypothetical nature of the pseudo-labels, these are commonly provided in the\nform of probability distributions. Still, one may argue that even a probability\ndistribution represents an excessive level of informedness, as it suggests that\nthe learner precisely knows the ground-truth conditional probabilities. In our\napproach, we therefore allow the learner to label instances in the form of\ncredal sets, that is, sets of (candidate) probability distributions. Thanks to\nthis increased expressiveness, the learner is able to represent uncertainty and\na lack of knowledge in a more flexible and more faithful manner. To learn from\nweakly labeled data of that kind, we leverage methods that have recently been\nproposed in the realm of so-called superset learning. In an exhaustive\nempirical evaluation, we compare our methodology to state-of-the-art\nself-supervision approaches, showing competitive to superior performance\nespecially in low-label scenarios incorporating a high degree of uncertainty.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 15:19:04 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Lienen", "Julian", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "2106.11864", "submitter": "Balaji Ganesan", "authors": "Vanya BK, Balaji Ganesan, Aniket Saxena, Devbrat Sharma, Arvind\n  Agarwal", "title": "Towards Automated Evaluation of Explanations in Graph Neural Networks", "comments": "5 pages, 4 figures, XAI Workshop at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explaining Graph Neural Networks predictions to end users of AI applications\nin easily understandable terms remains an unsolved problem. In particular, we\ndo not have well developed methods for automatically evaluating explanations,\nin ways that are closer to how users consume those explanations. Based on\nrecent application trends and our own experiences in real world problems, we\npropose automatic evaluation approaches for GNN Explanations.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 15:32:32 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["BK", "Vanya", ""], ["Ganesan", "Balaji", ""], ["Saxena", "Aniket", ""], ["Sharma", "Devbrat", ""], ["Agarwal", "Arvind", ""]]}, {"id": "2106.11878", "submitter": "Xinlu Zhang", "authors": "Xinlu Zhang, Yun Zhao, Rachael Callcut, Linda Petzold", "title": "Multiple Organ Failure Prediction with Classifier-Guided Generative\n  Adversarial Imputation Networks", "comments": "BioKDD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multiple organ failure (MOF) is a severe syndrome with a high mortality rate\namong Intensive Care Unit (ICU) patients. Early and precise detection is\ncritical for clinicians to make timely decisions. An essential challenge in\napplying machine learning models to electronic health records (EHRs) is the\npervasiveness of missing values. Most existing imputation methods are involved\nin the data preprocessing phase, failing to capture the relationship between\ndata and outcome for downstream predictions. In this paper, we propose\nclassifier-guided generative adversarial imputation networks Classifier-GAIN)\nfor MOF prediction to bridge this gap, by incorporating both observed data and\nlabel information. Specifically, the classifier takes imputed values from the\ngenerator(imputer) to predict task outcomes and provides additional supervision\nsignals to the generator by joint training. The classifier-guide generator\nimputes missing values with label-awareness during training, improving the\nclassifier's performance during inference. We conduct extensive experiments\nshowing that our approach consistently outperforms classical and state-of-art\nneural baselines across a range of missing data scenarios and evaluation\nmetrics.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 15:49:01 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Zhang", "Xinlu", ""], ["Zhao", "Yun", ""], ["Callcut", "Rachael", ""], ["Petzold", "Linda", ""]]}, {"id": "2106.11902", "submitter": "Mohammad Arif Ul Alam", "authors": "Mohammad Arif Ul Alam, Md Mahmudur Rahman, Jared Q Widberg", "title": "PALMAR: Towards Adaptive Multi-inhabitant Activity Recognition in\n  Point-Cloud Technology", "comments": "Accepted in IEEE International Conference on Computer Communications\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  With the advancement of deep neural networks and computer vision-based Human\nActivity Recognition, employment of Point-Cloud Data technologies (LiDAR,\nmmWave) has seen a lot interests due to its privacy preserving nature. Given\nthe high promise of accurate PCD technologies, we develop, PALMAR, a\nmultiple-inhabitant activity recognition system by employing efficient signal\nprocessing and novel machine learning techniques to track individual person\ntowards developing an adaptive multi-inhabitant tracking and HAR system. More\nspecifically, we propose (i) a voxelized feature representation-based real-time\nPCD fine-tuning method, (ii) efficient clustering (DBSCAN and BIRCH), Adaptive\nOrder Hidden Markov Model based multi-person tracking and crossover ambiguity\nreduction techniques and (iii) novel adaptive deep learning-based domain\nadaptation technique to improve the accuracy of HAR in presence of data\nscarcity and diversity (device, location and population diversity). We\nexperimentally evaluate our framework and systems using (i) a real-time PCD\ncollected by three devices (3D LiDAR and 79 GHz mmWave) from 6 participants,\n(ii) one publicly available 3D LiDAR activity data (28 participants) and (iii)\nan embedded hardware prototype system which provided promising HAR performances\nin multi-inhabitants (96%) scenario with a 63% improvement of multi-person\ntracking than state-of-art framework without losing significant system\nperformances in the edge computing device.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 16:17:50 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Alam", "Mohammad Arif Ul", ""], ["Rahman", "Md Mahmudur", ""], ["Widberg", "Jared Q", ""]]}, {"id": "2106.11929", "submitter": "Zhiqiang Gong", "authors": "Zhiqiang Gong and Weien Zhou and Jun Zhang and Wei Peng and Wen Yao", "title": "Physics-Informed Deep Reversible Regression Model for Temperature Field\n  Reconstruction of Heat-Source Systems", "comments": "Submitted to IEEE TIE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Temperature monitoring during the life time of heat source components in\nengineering systems becomes essential to guarantee the normal work and the\nworking life of these components. However, prior methods, which mainly use the\ninterpolate estimation to reconstruct the temperature field from limited\nmonitoring points, require large amounts of temperature tensors for an accurate\nestimation. This may decrease the availability and reliability of the system\nand sharply increase the monitoring cost. To solve this problem, this work\ndevelops a novel physics-informed deep reversible regression models for\ntemperature field reconstruction of heat-source systems (TFR-HSS), which can\nbetter reconstruct the temperature field with limited monitoring points\nunsupervisedly. First, we define the TFR-HSS task mathematically, and\nnumerically model the task, and hence transform the task as an image-to-image\nregression problem. Then this work develops the deep reversible regression\nmodel which can better learn the physical information, especially over the\nboundary. Finally, considering the physical characteristics of heat conduction\nas well as the boundary conditions, this work proposes the physics-informed\nreconstruction loss including four training losses and jointly learns the deep\nsurrogate model with these losses unsupervisedly. Experimental studies have\nconducted over typical two-dimensional heat-source systems to demonstrate the\neffectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 17:01:53 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 03:25:01 GMT"}, {"version": "v3", "created": "Mon, 5 Jul 2021 02:58:16 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Gong", "Zhiqiang", ""], ["Zhou", "Weien", ""], ["Zhang", "Jun", ""], ["Peng", "Wei", ""], ["Yao", "Wen", ""]]}, {"id": "2106.11963", "submitter": "Yuxin Fang", "authors": "Shusheng Yang, Yuxin Fang, Xinggang Wang, Yu Li, Ying Shan, Bin Feng,\n  Wenyu Liu", "title": "Tracking Instances as Queries", "comments": "Preprint. Work in progress", "journal-ref": "CVPR 2021 Workshop. 2nd Place Solution for YouTube-VOS Challenge\n  2021: Video Instance Segmentation", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, query based deep networks catch lots of attention owing to their\nend-to-end pipeline and competitive results on several fundamental computer\nvision tasks, such as object detection, semantic segmentation, and instance\nsegmentation. However, how to establish a query based video instance\nsegmentation (VIS) framework with elegant architecture and strong performance\nremains to be settled. In this paper, we present \\textbf{QueryTrack} (i.e.,\ntracking instances as queries), a unified query based VIS framework fully\nleveraging the intrinsic one-to-one correspondence between instances and\nqueries in QueryInst. The proposed method obtains 52.7 / 52.3 AP on\nYouTube-VIS-2019 / 2021 datasets, which wins the 2-nd place in the YouTube-VIS\nChallenge at CVPR 2021 \\textbf{with a single online end-to-end model, single\nscale testing \\& modest amount of training data}. We also provide\nQueryTrack-ResNet-50 baseline results on YouTube-VIS-2021 val set as references\nfor the VIS community.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 17:59:12 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 15:02:24 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Yang", "Shusheng", ""], ["Fang", "Yuxin", ""], ["Wang", "Xinggang", ""], ["Li", "Yu", ""], ["Shan", "Ying", ""], ["Feng", "Bin", ""], ["Liu", "Wenyu", ""]]}, {"id": "2106.11988", "submitter": "Chenhao Tan", "authors": "Chenhao Tan", "title": "On the Diversity and Limits of Human Explanations", "comments": "15 pages, 12 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A growing effort in NLP aims to build datasets of human explanations.\nHowever, the term explanation encompasses a broad range of notions, each with\ndifferent properties and ramifications. Our goal is to provide an overview of\ndiverse types of explanations and human limitations, and discuss implications\nfor collecting and using explanations in NLP. Inspired by prior work in\npsychology and cognitive sciences, we group existing human explanations in NLP\ninto three categories: proximal mechanism, evidence, and procedure. These three\ntypes differ in nature and have implications for the resultant explanations.\nFor instance, procedure is not considered explanations in psychology and\nconnects with a rich body of work on learning from instructions. The diversity\nof explanations is further evidenced by proxy questions that are needed for\nannotators to interpret and answer open-ended why questions. Finally,\nexplanations may require different, often deeper, understandings than\npredictions, which casts doubt on whether humans can provide useful\nexplanations in some tasks.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 18:00:07 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Tan", "Chenhao", ""]]}, {"id": "2106.12005", "submitter": "Maroun Haddad", "authors": "Maroun Haddad and Mohamed Bouguessa", "title": "Exploring the Representational Power of Graph Autoencoder", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2021.06.034", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  While representation learning has yielded a great success on many graph\nlearning tasks, there is little understanding behind the structures that are\nbeing captured by these embeddings. For example, we wonder if the topological\nfeatures, such as the Triangle Count, the Degree of the node and other\ncentrality measures are concretely encoded in the embeddings. Furthermore, we\nask if the presence of these structures in the embeddings is necessary for a\nbetter performance on the downstream tasks, such as clustering and\nclassification. To address these questions, we conduct an extensive empirical\nstudy over three classes of unsupervised graph embedding models and seven\ndifferent variants of Graph Autoencoders. Our results show that five\ntopological features: the Degree, the Local Clustering Score, the Betweenness\nCentrality, the Eigenvector Centrality, and Triangle Count are concretely\npreserved in the first layer of the graph autoencoder that employs the SUM\naggregation rule, under the condition that the model preserves the second-order\nproximity. We supplement further evidence for the presence of these features by\nrevealing a hierarchy in the distribution of the topological features in the\nembeddings of the aforementioned model. We also show that a model with such\nproperties can outperform other models on certain downstream tasks, especially\nwhen the preserved features are relevant to the task at hand. Finally, we\nevaluate the suitability of our findings through a test case study related to\nsocial influence prediction.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 18:23:26 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Haddad", "Maroun", ""], ["Bouguessa", "Mohamed", ""]]}, {"id": "2106.12024", "submitter": "Jackson Killian", "authors": "Jackson A. Killian, Arpita Biswas, Sanket Shah, Milind Tambe", "title": "Q-Learning Lagrange Policies for Multi-Action Restless Bandits", "comments": "13 pages, 6 figures, to be published in Proceedings of the 27th ACM\n  SIGKDD Conference on Knowledge Discovery and Data", "journal-ref": null, "doi": "10.1145/3447548.3467370", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-action restless multi-armed bandits (RMABs) are a powerful framework\nfor constrained resource allocation in which $N$ independent processes are\nmanaged. However, previous work only study the offline setting where problem\ndynamics are known. We address this restrictive assumption, designing the first\nalgorithms for learning good policies for Multi-action RMABs online using\ncombinations of Lagrangian relaxation and Q-learning. Our first approach,\nMAIQL, extends a method for Q-learning the Whittle index in binary-action RMABs\nto the multi-action setting. We derive a generalized update rule and\nconvergence proof and establish that, under standard assumptions, MAIQL\nconverges to the asymptotically optimal multi-action RMAB policy as\n$t\\rightarrow{}\\infty$. However, MAIQL relies on learning Q-functions and\nindexes on two timescales which leads to slow convergence and requires problem\nstructure to perform well. Thus, we design a second algorithm, LPQL, which\nlearns the well-performing and more general Lagrange policy for multi-action\nRMABs by learning to minimize the Lagrange bound through a variant of\nQ-learning. To ensure fast convergence, we take an approximation strategy that\nenables learning on a single timescale, then give a guarantee relating the\napproximation's precision to an upper bound of LPQL's return as\n$t\\rightarrow{}\\infty$. Finally, we show that our approaches always outperform\nbaselines across multiple settings, including one derived from real-world\nmedication adherence data.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 19:20:09 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Killian", "Jackson A.", ""], ["Biswas", "Arpita", ""], ["Shah", "Sanket", ""], ["Tambe", "Milind", ""]]}, {"id": "2106.12026", "submitter": "R. Kenny Jones", "authors": "R. Kenny Jones and Rana Hanocka and Daniel Ritchie", "title": "The Neurally-Guided Shape Parser: A Monte Carlo Method for Hierarchical\n  Labeling of Over-segmented 3D Shapes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many learning-based 3D shape semantic segmentation methods assign labels to\nshape atoms (e.g. points in a point cloud or faces in a mesh) with a\nsingle-pass approach trained in an end-to-end fashion. Such methods achieve\nimpressive performance but require large amounts of labeled training data. This\nparadigm entangles two separable subproblems: (1) decomposing a shape into\nregions and (2) assigning semantic labels to these regions. We claim that\ndisentangling these subproblems reduces the labeled data burden: (1) region\ndecomposition requires no semantic labels and could be performed in an\nunsupervised fashion, and (2) labeling shape regions instead of atoms results\nin a smaller search space and should be learnable with less labeled training\ndata. In this paper, we investigate this second claim by presenting the\nNeurally-Guided Shape Parser (NGSP), a method that learns how to assign\nsemantic labels to regions of an over-segmented 3D shape. We solve this problem\nvia MAP inference, modeling the posterior probability of a labeling assignment\nconditioned on an input shape. We employ a Monte Carlo importance sampling\napproach guided by a neural proposal network, a search-based approach made\nfeasible by assuming the input shape is decomposed into discrete regions. We\nevaluate NGSP on the task of hierarchical semantic segmentation on manufactured\n3D shapes from PartNet. We find that NGSP delivers significant performance\nimprovements over baselines that learn to label shape atoms and then aggregate\npredictions for each shape region, especially in low-data regimes. Finally, we\ndemonstrate that NGSP is robust to region granularity, as it maintains strong\nsegmentation performance even as the regions undergo significant corruption.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 19:26:01 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Jones", "R. Kenny", ""], ["Hanocka", "Rana", ""], ["Ritchie", "Daniel", ""]]}, {"id": "2106.12027", "submitter": "Yanjun Gao", "authors": "Yanjun Gao, Ting-hao Huang, Rebecca J. Passonneau", "title": "ABCD: A Graph Framework to Convert Complex Sentences to a Covering Set\n  of Simple Sentences", "comments": "To appear in the proceeding of 59th Annual Meeting of the Association\n  for Computational Linguistics (ACL 2021) Main Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Atomic clauses are fundamental text units for understanding complex\nsentences. Identifying the atomic sentences within complex sentences is\nimportant for applications such as summarization, argument mining, discourse\nanalysis, discourse parsing, and question answering. Previous work mainly\nrelies on rule-based methods dependent on parsing. We propose a new task to\ndecompose each complex sentence into simple sentences derived from the tensed\nclauses in the source, and a novel problem formulation as a graph edit task.\nOur neural model learns to Accept, Break, Copy or Drop elements of a graph that\ncombines word adjacency and grammatical dependencies. The full processing\npipeline includes modules for graph construction, graph editing, and sentence\ngeneration from the output graph. We introduce DeSSE, a new dataset designed to\ntrain and evaluate complex sentence decomposition, and MinWiki, a subset of\nMinWikiSplit. ABCD achieves comparable performance as two parsing baselines on\nMinWiki. On DeSSE, which has a more even balance of complex sentence types, our\nmodel achieves higher accuracy on the number of atomic sentences than an\nencoder-decoder baseline. Results include a detailed error analysis.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 19:31:28 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Gao", "Yanjun", ""], ["Huang", "Ting-hao", ""], ["Passonneau", "Rebecca J.", ""]]}, {"id": "2106.12056", "submitter": "Chenhao Tan", "authors": "Madhusudhan Aithal and Chenhao Tan", "title": "On Positivity Bias in Negative Reviews", "comments": "11 pages, 17 figures, ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Prior work has revealed that positive words occur more frequently than\nnegative words in human expressions, which is typically attributed to\npositivity bias, a tendency for people to report positive views of reality. But\nwhat about the language used in negative reviews? Consistent with prior work,\nwe show that English negative reviews tend to contain more positive words than\nnegative words, using a variety of datasets. We reconcile this observation with\nprior findings on the pragmatics of negation, and show that negations are\ncommonly associated with positive words in negative reviews. Furthermore, in\nnegative reviews, the majority of sentences with positive words express\nnegative opinions based on sentiment classifiers, indicating some form of\nnegation.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 21:04:25 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Aithal", "Madhusudhan", ""], ["Tan", "Chenhao", ""]]}, {"id": "2106.12070", "submitter": "Navid Kardan", "authors": "Navid Kardan, Ankit Sharma and Kenneth O. Stanley", "title": "Towards Consistent Predictive Confidence through Fitted Ensembles", "comments": "IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are behind many of the recent successes in machine\nlearning applications. However, these models can produce overconfident\ndecisions while encountering out-of-distribution (OOD) examples or making a\nwrong prediction. This inconsistent predictive confidence limits the\nintegration of independently-trained learning models into a larger system. This\npaper introduces separable concept learning framework to realistically measure\nthe performance of classifiers in presence of OOD examples. In this setup,\nseveral instances of a classifier are trained on different parts of a partition\nof the set of classes. Later, the performance of the combination of these\nmodels is evaluated on a separate test set. Unlike current OOD detection\ntechniques, this framework does not require auxiliary OOD datasets and does not\nseparate classification from detection performance. Furthermore, we present a\nnew strong baseline for more consistent predictive confidence in deep models,\ncalled fitted ensembles, where overconfident predictions are rectified by\ntransformed versions of the original classification task. Fitted ensembles can\nnaturally detect OOD examples without requiring auxiliary data by observing\ncontradicting predictions among its components. Experiments on MNIST, SVHN,\nCIFAR-10/100, and ImageNet show fitted ensemble significantly outperform\nconventional ensembles on OOD examples and are possible to scale.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 21:32:31 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Kardan", "Navid", ""], ["Sharma", "Ankit", ""], ["Stanley", "Kenneth O.", ""]]}, {"id": "2106.12086", "submitter": "Jinjin Xu", "authors": "Jinjin Xu, Yaochu Jin, Wenli Du", "title": "A Federated Data-Driven Evolutionary Algorithm for Expensive\n  Multi/Many-objective Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven optimization has found many successful applications in the real\nworld and received increased attention in the field of evolutionary\noptimization. Most existing algorithms assume that the data used for\noptimization is always available on a central server for construction of\nsurrogates. This assumption, however, may fail to hold when the data must be\ncollected in a distributed way and is subject to privacy restrictions. This\npaper aims to propose a federated data-driven evolutionary\nmulti-/many-objective optimization algorithm. To this end, we leverage\nfederated learning for surrogate construction so that multiple clients\ncollaboratively train a radial-basis-function-network as the global surrogate.\nThen a new federated acquisition function is proposed for the central server to\napproximate the objective values using the global surrogate and estimate the\nuncertainty level of the approximated objective values based on the local\nmodels. The performance of the proposed algorithm is verified on a series of\nmulti/many-objective benchmark problems by comparing it with two\nstate-of-the-art surrogate-assisted multi-objective evolutionary algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 22:33:24 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Xu", "Jinjin", ""], ["Jin", "Yaochu", ""], ["Du", "Wenli", ""]]}, {"id": "2106.12113", "submitter": "Reuth Mirsky", "authors": "Reuth Mirsky and Xuesu Xiao and Justin Hart and Peter Stone", "title": "Prevention and Resolution of Conflicts in Social Navigation -- a Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  With the approaching goal of having robots collaborate in shared human-robot\nenvironments, navigation in this context becomes both crucial and desirable.\nRecent developments in robotics have encountered and tackled some of the\nchallenges of navigating in mixed human-robot environments, and in recent years\nwe observe a surge of related work that specifically targets the question of\nhow to handle conflicts between agents in social navigation. These\ncontributions offer models, algorithms, and evaluation metrics, however as this\nresearch area is inherently interdisciplinary, many of the relevant papers are\nnot comparable and there is no standard vocabulary between the researchers.\n  The main goal of this survey is to bridge this gap by proposing such a common\nlanguage, using it to survey existing work, and highlighting open problems. It\nstarts by defining a conflict in social navigation, and offers a detailed\ntaxonomy of its components. This survey then maps existing work while\ndiscussing papers using the framing of the proposed taxonomy. Finally, this\npaper propose some future directions and problems that are currently in the\nfrontier of social navigation to help focus research efforts.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 01:10:22 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Mirsky", "Reuth", ""], ["Xiao", "Xuesu", ""], ["Hart", "Justin", ""], ["Stone", "Peter", ""]]}, {"id": "2106.12121", "submitter": "Ang Li", "authors": "Ang Li, Judea Pearl", "title": "Bounds on Causal Effects and Application to High Dimensional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper addresses the problem of estimating causal effects when adjustment\nvariables in the back-door or front-door criterion are partially observed. For\nsuch scenarios, we derive bounds on the causal effects by solving two\nnon-linear optimization problems, and demonstrate that the bounds are\nsufficient. Using this optimization method, we propose a framework for\ndimensionality reduction that allows one to trade bias for estimation power,\nand demonstrate its performance using simulation studies.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 01:47:38 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Li", "Ang", ""], ["Pearl", "Judea", ""]]}, {"id": "2106.12123", "submitter": "Xin Luo", "authors": "Xin Luo, Wei Chen, Yusong Tan, Chen Li, Yulin He, Xiaogang Jia", "title": "Exploiting Negative Learning for Implicit Pseudo Label Rectification in\n  Source-Free Domain Adaptive Semantic Segmentation", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is desirable to transfer the knowledge stored in a well-trained source\nmodel onto non-annotated target domain in the absence of source data. However,\nstate-of-the-art methods for source free domain adaptation (SFDA) are subject\nto strict limits: 1) access to internal specifications of source models is a\nmust; and 2) pseudo labels should be clean during self-training, making\ncritical tasks relying on semantic segmentation unreliable. Aiming at these\npitfalls, this study develops a domain adaptive solution to semantic\nsegmentation with pseudo label rectification (namely \\textit{PR-SFDA}), which\noperates in two phases: 1) \\textit{Confidence-regularized unsupervised\nlearning}: Maximum squares loss applies to regularize the target model to\nensure the confidence in prediction; and 2) \\textit{Noise-aware pseudo label\nlearning}: Negative learning enables tolerance to noisy pseudo labels in\ntraining, meanwhile positive learning achieves fast convergence. Extensive\nexperiments have been performed on domain adaptive semantic segmentation\nbenchmark, \\textit{GTA5 $\\to$ Cityscapes}. Overall, \\textit{PR-SFDA} achieves a\nperformance of 49.0 mIoU, which is very close to that of the state-of-the-art\ncounterparts. Note that the latter demand accesses to the source model's\ninternal specifications, whereas the \\textit{PR-SFDA} solution needs none as a\nsharp contrast.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 02:20:31 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Luo", "Xin", ""], ["Chen", "Wei", ""], ["Tan", "Yusong", ""], ["Li", "Chen", ""], ["He", "Yulin", ""], ["Jia", "Xiaogang", ""]]}, {"id": "2106.12125", "submitter": "Shubham Negi", "authors": "Shubham Negi, Indranil Chakraborty, Aayush Ankit, Kaushik Roy", "title": "NAX: Co-Designing Neural Network and Hardware Architecture for\n  Memristive Xbar based Computing Systems", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AI cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In-Memory Computing (IMC) hardware using Memristive Crossbar Arrays (MCAs)\nare gaining popularity to accelerate Deep Neural Networks (DNNs) since it\nalleviates the \"memory wall\" problem associated with von-Neumann architecture.\nThe hardware efficiency (energy, latency and area) as well as application\naccuracy (considering device and circuit non-idealities) of DNNs mapped to such\nhardware are co-dependent on network parameters, such as kernel size, depth\netc. and hardware architecture parameters such as crossbar size. However,\nco-optimization of both network and hardware parameters presents a challenging\nsearch space comprising of different kernel sizes mapped to varying crossbar\nsizes. To that effect, we propose NAX -- an efficient neural architecture\nsearch engine that co-designs neural network and IMC based hardware\narchitecture. NAX explores the aforementioned search space to determine kernel\nand corresponding crossbar sizes for each DNN layer to achieve optimal\ntradeoffs between hardware efficiency and application accuracy. Our results\nfrom NAX show that the networks have heterogeneous crossbar sizes across\ndifferent network layers, and achieves optimal hardware efficiency and accuracy\nconsidering the non-idealities in crossbars. On CIFAR-10 and Tiny ImageNet, our\nmodels achieve 0.8%, 0.2% higher accuracy, and 17%, 4% lower EDAP\n(energy-delay-area product) compared to a baseline ResNet-20 and ResNet-18\nmodels, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 02:27:00 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Negi", "Shubham", ""], ["Chakraborty", "Indranil", ""], ["Ankit", "Aayush", ""], ["Roy", "Kaushik", ""]]}, {"id": "2106.12139", "submitter": "Fangyuan Lei", "authors": "Fangyuan Lei, Da Huang, Jianjian Jiang, Ruijun Ma, Senhong Wang,\n  Jiangzhong Cao, Yusen Lin and Qingyun Dai", "title": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel\n  Industrial Goods Image Database", "comments": "12 pages,7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In deep learning area, large-scale image datasets bring a breakthrough in the\nsuccess of object recognition and retrieval. Nowadays, as the embodiment of\ninnovation, the diversity of the industrial goods is significantly larger, in\nwhich the incomplete multiview, multimodal and multilabel are different from\nthe traditional dataset. In this paper, we introduce an industrial goods\ndataset, namely PatentNet, with numerous highly diverse, accurate and detailed\nannotations of industrial goods images, and corresponding texts. In PatentNet,\nthe images and texts are sourced from design patent. Within over 6M images and\ncorresponding texts of industrial goods labeled manually checked by\nprofessionals, PatentNet is the first ongoing industrial goods image database\nwhose varieties are wider than industrial goods datasets used previously for\nbenchmarking. PatentNet organizes millions of images into 32 classes and 219\nsubclasses based on the Locarno Classification Agreement. Through extensive\nexperiments on image classification, image retrieval and incomplete multiview\nclustering, we demonstrate that our PatentNet is much more diverse, complex,\nand challenging, enjoying higher potentials than existing industrial image\ndatasets. Furthermore, the characteristics of incomplete multiview, multimodal\nand multilabel in PatentNet are able to offer unparalleled opportunities in the\nartificial intelligence community and beyond.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 03:22:52 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Lei", "Fangyuan", ""], ["Huang", "Da", ""], ["Jiang", "Jianjian", ""], ["Ma", "Ruijun", ""], ["Wang", "Senhong", ""], ["Cao", "Jiangzhong", ""], ["Lin", "Yusen", ""], ["Dai", "Qingyun", ""]]}, {"id": "2106.12142", "submitter": "Divyansh Garg", "authors": "Divyansh Garg, Shuvam Chakraborty, Chris Cundy, Jiaming Song, Stefano\n  Ermon", "title": "IQ-Learn: Inverse soft-Q Learning for Imitation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many sequential decision-making problems (e.g., robotics control, game\nplaying, sequential prediction), human or expert data is available containing\nuseful information about the task. However, imitation learning (IL) from a\nsmall amount of expert data can be challenging in high-dimensional environments\nwith complex dynamics. Behavioral cloning is a simple method that is widely\nused due to its simplicity of implementation and stable convergence but doesn't\nutilize any information involving the environment's dynamics. Many existing\nmethods that exploit dynamics information are difficult to train in practice\ndue to an adversarial optimization process over reward and policy approximators\nor biased, high variance gradient estimators. We introduce a method for\ndynamics-aware IL which avoids adversarial training by learning a single\nQ-function, implicitly representing both reward and policy. On standard\nbenchmarks, the implicitly learned rewards show a high positive correlation\nwith the ground-truth rewards, illustrating our method can also be used for\ninverse reinforcement learning (IRL). Our method, Inverse soft-Q learning\n(IQ-Learn) obtains state-of-the-art results in offline and online imitation\nlearning settings, surpassing existing methods both in the number of required\nenvironment interactions and scalability in high-dimensional spaces.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 03:43:10 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Garg", "Divyansh", ""], ["Chakraborty", "Shuvam", ""], ["Cundy", "Chris", ""], ["Song", "Jiaming", ""], ["Ermon", "Stefano", ""]]}, {"id": "2106.12144", "submitter": "Mikhail Galkin", "authors": "Mikhail Galkin, Jiapeng Wu, Etienne Denis, William L. Hamilton", "title": "NodePiece: Compositional and Parameter-Efficient Representations of\n  Large Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional representation learning algorithms for knowledge graphs (KG) map\neach entity to a unique embedding vector. Such a shallow lookup results in a\nlinear growth of memory consumption for storing the embedding matrix and incurs\nhigh computational costs when working with real-world KGs. Drawing parallels\nwith subword tokenization commonly used in NLP, we explore the landscape of\nmore parameter-efficient node embedding strategies with possibly sublinear\nmemory requirements. To this end, we propose NodePiece, an anchor-based\napproach to learn a fixed-size entity vocabulary. In NodePiece, a vocabulary of\nsubword/sub-entity units is constructed from anchor nodes in a graph with known\nrelation types. Given such a fixed-size vocabulary, it is possible to bootstrap\nan encoding and embedding for any entity, including those unseen during\ntraining. Experiments show that NodePiece performs competitively in node\nclassification, link prediction, and relation prediction tasks while retaining\nless than 10% of explicit nodes in a graph as anchors and often having 10x\nfewer parameters.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 03:51:03 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Galkin", "Mikhail", ""], ["Wu", "Jiapeng", ""], ["Denis", "Etienne", ""], ["Hamilton", "William L.", ""]]}, {"id": "2106.12151", "submitter": "Stefan O'Toole", "authors": "Stefan O'Toole, Nir Lipovetzky, Miquel Ramirez, Adrian Pearce", "title": "Width-based Lookaheads with Learnt Base Policies and Heuristics Over the\n  Atari-2600 Benchmark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose new width-based planning and learning algorithms applied over the\nAtari-2600 benchmark. The algorithms presented are inspired from a careful\nanalysis of the design decisions made by previous width-based planners. We\nbenchmark our new algorithms over the Atari-2600 games and show that our best\nperforming algorithm, RIW$_C$+CPV, outperforms previously introduced\nwidth-based planning and learning algorithms $\\pi$-IW(1), $\\pi$-IW(1)+ and\n$\\pi$-HIW(n, 1). Furthermore, we present a taxonomy of the set of Atari-2600\ngames according to some of their defining characteristics. This analysis of the\ngames provides further insight into the behaviour and performance of the\nwidth-based algorithms introduced. Namely, for games with large branching\nfactors, and games with sparse meaningful rewards, RIW$_C$+CPV outperforms\n$\\pi$-IW, $\\pi$-IW(1)+ and $\\pi$-HIW(n, 1).\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 04:27:55 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["O'Toole", "Stefan", ""], ["Lipovetzky", "Nir", ""], ["Ramirez", "Miquel", ""], ["Pearce", "Adrian", ""]]}, {"id": "2106.12154", "submitter": "Gilles Hacheme", "authors": "Gilles Hacheme, Noureini Sayouti", "title": "Neural Fashion Image Captioning : Accounting for Data Diversity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Image captioning has increasingly large domains of application, and fashion\nis not an exception. Having automatic item descriptions is of great interest\nfor fashion web platforms hosting sometimes hundreds of thousands of images.\nThis paper is one of the first tackling image captioning for fashion images. To\ncontribute addressing dataset diversity issues, we introduced the InFashAIv1\ndataset containing almost 16.000 African fashion item images with their titles,\nprices and general descriptions. We also used the well known DeepFashion\ndataset in addition to InFashAIv1. Captions are generated using the Show and\nTell model made of CNN encoder and RNN Decoder. We showed that jointly training\nthe model on both datasets improves captions quality for African style fashion\nimages, suggesting a transfer learning from Western style data. The InFashAIv1\ndataset is released on Github to encourage works with more diversity inclusion.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 04:39:26 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 04:14:17 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Hacheme", "Gilles", ""], ["Sayouti", "Noureini", ""]]}, {"id": "2106.12169", "submitter": "Boyuan Feng", "authors": "Boyuan Feng, Yuke Wang, Tong Geng, Ang Li, Yufei Ding", "title": "APNN-TC: Accelerating Arbitrary Precision Neural Networks on Ampere GPU\n  Tensor Cores", "comments": "Accepted by SC'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.AR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the years, accelerating neural networks with quantization has been\nwidely studied. Unfortunately, prior efforts with diverse precisions (e.g.,\n1-bit weights and 2-bit activations) are usually restricted by limited\nprecision support on GPUs (e.g., int1 and int4). To break such restrictions, we\nintroduce the first Arbitrary Precision Neural Network framework (APNN-TC) to\nfully exploit quantization benefits on Ampere GPU Tensor Cores. Specifically,\nAPNN-TC first incorporates a novel emulation algorithm to support arbitrary\nshort bit-width computation with int1 compute primitives and XOR/AND Boolean\noperations. Second, APNN-TC integrates arbitrary precision layer designs to\nefficiently map our emulation algorithm to Tensor Cores with novel batching\nstrategies and specialized memory organization. Third, APNN-TC embodies a novel\narbitrary precision NN design to minimize memory access across layers and\nfurther improve performance. Extensive evaluations show that APNN-TC can\nachieve significant speedup over CUTLASS kernels and various NN models, such as\nResNet and VGG.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 05:39:34 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Feng", "Boyuan", ""], ["Wang", "Yuke", ""], ["Geng", "Tong", ""], ["Li", "Ang", ""], ["Ding", "Yufei", ""]]}, {"id": "2106.12183", "submitter": "Nirmalya Thakur", "authors": "Nirmalya Thakur and Chia Y. Han", "title": "A Review of Assistive Technologies for Activities of Daily Living of\n  Elderly", "comments": null, "journal-ref": "Book chapter in: Assisted Living: Current Issues and Challenges,\n  ISBN: 978-1-53618-446-4, 2020 Nova Science Publishers, Pp. 61 - 84", "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the distinct features of this century has been the population of older\nadults which has been on a constant rise. Elderly people have several needs and\nrequirements due to physical disabilities, cognitive issues, weakened memory\nand disorganized behavior, that they face with increasing age. The extent of\nthese limitations also differs according to the varying diversities in elderly,\nwhich include age, gender, background, experience, skills, knowledge and so on.\nThese varying needs and challenges with increasing age, limits abilities of\nolder adults to perform Activities of Daily Living (ADLs) in an independent\nmanner. To add to it, the shortage of caregivers creates a looming need for\ntechnology-based services for elderly people, to assist them in performing\ntheir daily routine tasks to sustain their independent living and active aging.\nTo address these needs, this work consists of making three major contributions\nin this field. First, it provides a rather comprehensive review of assisted\nliving technologies aimed at helping elderly people to perform ADLs. Second,\nthe work discusses the challenges identified through this review, that\ncurrently exist in the context of implementation of assisted living services\nfor elderly care in Smart Homes and Smart Cities. Finally, the work also\noutlines an approach for implementation, extension and integration of the\nexisting works in this field for development of a much-needed framework that\ncan provide personalized assistance and user-centered behavior interventions to\nelderly as per their varying and ever-changing needs.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 06:17:49 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Thakur", "Nirmalya", ""], ["Han", "Chia Y.", ""]]}, {"id": "2106.12207", "submitter": "Utkarsh Soni", "authors": "Utkarsh Soni, Sarath Sreedharan, Subbarao Kambhampati", "title": "Not all users are the same: Providing personalized explanations for\n  sequential decision making problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing interest in designing autonomous agents that can work\nalongside humans. Such agents will undoubtedly be expected to explain their\nbehavior and decisions. While generating explanations is an actively researched\ntopic, most works tend to focus on methods that generate explanations that are\none size fits all. As in the specifics of the user-model are completely\nignored. The handful of works that look at tailoring their explanation to the\nuser's background rely on having specific models of the users (either analytic\nmodels or learned labeling models). The goal of this work is thus to propose an\nend-to-end adaptive explanation generation system that begins by learning the\ndifferent types of users that the agent could interact with. Then during the\ninteraction with the target user, it is tasked with identifying the type on the\nfly and adjust its explanations accordingly. The former is achieved by a\ndata-driven clustering approach while for the latter, we compile our\nexplanation generation problem into a POMDP. We demonstrate the usefulness of\nour system on two domains using state-of-the-art POMDP solvers. We also report\nthe results of a user study that investigates the benefits of providing\npersonalized explanations in a human-robot interaction setting.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 07:46:19 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Soni", "Utkarsh", ""], ["Sreedharan", "Sarath", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "2106.12226", "submitter": "Alessandro Sebastianelli", "authors": "Alessandro Sebastianelli, Artur Nowakowski, Erika Puglisi, Maria Pia\n  Del Rosso, Jamila Mifdal, Fiora Pirri, Pierre Philippe Mathieu and Silvia\n  Liberata Ullo", "title": "Spatio-Temporal SAR-Optical Data Fusion for Cloud Removal via a Deep\n  Hierarchical Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The abundance of clouds, located both spatially and temporally, often makes\nremote sensing (RS) applications with optical images difficult or even\nimpossible to perform. Traditional cloud removing techniques have been studied\nfor years, and recently, Machine Learning (ML)-based approaches have also been\nconsidered. In this manuscript, a novel method for the restoration of\nclouds-corrupted optical images is presented, able to generate the whole\noptical scene of interest, not only the cloudy pixels, and based on a Joint\nData Fusion paradigm, where three deep neural networks are hierarchically\ncombined. Spatio-temporal features are separately extracted by a conditional\nGenerative Adversarial Network (cGAN) and by a Convolutional Long Short-Term\nMemory (ConvLSTM), from Synthetic Aperture Radar (SAR) data and optical\ntime-series of data respectively, and then combined with a U-shaped network.\nThe use of time-series of data has been rarely explored in the state of the art\nfor this peculiar objective, and moreover existing models do not combine both\nspatio-temporal domains and SAR-optical imagery. Quantitative and qualitative\nresults have shown a good ability of the proposed method in producing\ncloud-free images, by also preserving the details and outperforming the cGAN\nand the ConvLSTM when individually used. Both the code and the dataset have\nbeen implemented from scratch and made available to interested researchers for\nfurther analysis and investigation.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 08:15:01 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 09:35:50 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Sebastianelli", "Alessandro", ""], ["Nowakowski", "Artur", ""], ["Puglisi", "Erika", ""], ["Del Rosso", "Maria Pia", ""], ["Mifdal", "Jamila", ""], ["Pirri", "Fiora", ""], ["Mathieu", "Pierre Philippe", ""], ["Ullo", "Silvia Liberata", ""]]}, {"id": "2106.12242", "submitter": "Gilles Stoltz", "authors": "Evgenii Chzhen (LMO, CELESTE), Christophe Giraud (LMO, CELESTE),\n  Gilles Stoltz (LMO, CELESTE)", "title": "A Unified Approach to Fair Online Learning via Blackwell Approachability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a setting and a general approach to fair online learning with\nstochastic sensitive and non-sensitive contexts. The setting is a repeated game\nbetween the Player and Nature, where at each stage both pick actions based on\nthe contexts. Inspired by the notion of unawareness, we assume that the Player\ncan only access the non-sensitive context before making a decision, while we\ndiscuss both cases of Nature accessing the sensitive contexts and Nature\nunaware of the sensitive contexts. Adapting Blackwell's approachability theory\nto handle the case of an unknown contexts' distribution, we provide a general\nnecessary and sufficient condition for learning objectives to be compatible\nwith some fairness constraints. This condition is instantiated on (group-wise)\nno-regret and (group-wise) calibration objectives, and on demographic parity as\nan additional constraint. When the objective is not compatible with the\nconstraint, the provided framework permits to characterise the optimal\ntrade-off between the two.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 09:00:12 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Chzhen", "Evgenii", "", "LMO, CELESTE"], ["Giraud", "Christophe", "", "LMO, CELESTE"], ["Stoltz", "Gilles", "", "LMO, CELESTE"]]}, {"id": "2106.12248", "submitter": "Louis Rouillard", "authors": "Louis Rouillard (PARIETAL, Inria, CEA), Demian Wassermann (PARIETAL,\n  Inria, CEA)", "title": "ADAVI: Automatic Dual Amortized Variational Inference Applied To\n  Pyramidal Bayesian Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frequently, population studies feature pyramidally-organized data represented\nusing Hierarchical Bayesian Models (HBM) enriched with plates. These models can\nbecome prohibitively large in settings such as neuroimaging, where a sample is\ncomposed of a functional MRI signal measured on 64 thousand brain locations,\nacross 4 measurement sessions, and at least tens of subjects. Even a reduced\nexample on a specific cortical region of 300 brain locations features around 1\nmillion parameters, hampering the usage of modern density estimation techniques\nsuch as Simulation-Based Inference (SBI). To infer parameter posterior\ndistributions in this challenging class of problems, we designed a novel\nmethodology that automatically produces a variational family dual to a target\nHBM. This variatonal family, represented as a neural network, consists in the\ncombination of an attention-based hierarchical encoder feeding summary\nstatistics to a set of normalizing flows. Our automatically-derived neural\nnetwork exploits exchangeability in the plate-enriched HBM and factorizes its\nparameter space. The resulting architecture reduces by orders of magnitude its\nparameterization with respect to that of a typical SBI representation, while\nmaintaining expressivity. Our method performs inference on the specified HBM in\nan amortized setup: once trained, it can readily be applied to a new data\nsample to compute the parameters' full posterior. We demonstrate the capability\nof our method on simulated data, as well as a challenging high-dimensional\nbrain parcellation experiment. We also open up several questions that lie at\nthe intersection between SBI techniques and structured Variational Inference.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 09:09:01 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Rouillard", "Louis", "", "PARIETAL, Inria, CEA"], ["Wassermann", "Demian", "", "PARIETAL,\n  Inria, CEA"]]}, {"id": "2106.12269", "submitter": "George Katsirelos", "authors": "Fulya Tr\\\"osser (MIAT INRA), Simon de Givry (MIAT INRA), George\n  Katsirelos (MIA-Paris)", "title": "Improved Acyclicity Reasoning for Bayesian Network Structure Learning\n  with Constraint Programming", "comments": null, "journal-ref": "30th International Joint Conference on Artificial Intelligence\n  (IJCAI-21), Aug 2021, Montreal, Canada", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian networks are probabilistic graphical models with a wide range of\napplication areas including gene regulatory networks inference, risk analysis\nand image processing. Learning the structure of a Bayesian network (BNSL) from\ndiscrete data is known to be an NP-hard task with a superexponential search\nspace of directed acyclic graphs. In this work, we propose a new polynomial\ntime algorithm for discovering a subset of all possible cluster cuts, a greedy\nalgorithm for approximately solving the resulting linear program, and a\ngeneralised arc consistency algorithm for the acyclicity constraint. We embed\nthese in the constraint programmingbased branch-and-bound solver CPBayes and\nshow that, despite being suboptimal, they improve performance by orders of\nmagnitude. The resulting solver also compares favourably with GOBNILP, a\nstate-of-the-art solver for the BNSL problem which solves an NP-hard problem to\ndiscover each cut and solves the linear program exactly.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 09:46:11 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Tr\u00f6sser", "Fulya", "", "MIAT INRA"], ["de Givry", "Simon", "", "MIAT INRA"], ["Katsirelos", "George", "", "MIA-Paris"]]}, {"id": "2106.12271", "submitter": "Xiaoyu Bie", "authors": "Xiaoyu Bie, Simon Leglaive, Xavier Alameda-Pineda, Laurent Girin", "title": "Unsupervised Speech Enhancement using Dynamical Variational\n  Auto-Encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamical variational auto-encoders (DVAEs) are a class of deep generative\nmodels with latent variables, dedicated to time series data modeling. DVAEs can\nbe considered as extensions of the variational autoencoder (VAE) that include\nthe modeling of temporal dependencies between successive observed and/or latent\nvectors in data sequences. Previous work has shown the interest of DVAEs and\ntheir better performance over the VAE for speech signals (spectrogram)\nmodeling. Independently, the VAE has been successfully applied to speech\nenhancement in noise, in an unsupervised noise-agnostic set-up that does not\nrequire the use of a parallel dataset of clean and noisy speech samples for\ntraining, but only requires clean speech signals. In this paper, we extend\nthose works to DVAE-based single-channel unsupervised speech enhancement, hence\nexploiting both speech signals unsupervised representation learning and\ndynamics modeling. We propose an unsupervised speech enhancement algorithm\nbased on the most general form of DVAEs, that we then adapt to three specific\nDVAE models to illustrate the versatility of the framework. More precisely, we\ncombine DVAE-based speech priors with a noise model based on nonnegative matrix\nfactorization, and we derive a variational expectation-maximization (VEM)\nalgorithm to perform speech enhancement. Experimental results show that the\nproposed approach based on DVAEs outperforms its VAE counterpart and a\nsupervised speech enhancement baseline.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 09:48:38 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Bie", "Xiaoyu", ""], ["Leglaive", "Simon", ""], ["Alameda-Pineda", "Xavier", ""], ["Girin", "Laurent", ""]]}, {"id": "2106.12284", "submitter": "Yanye Lu", "authors": "Mengdi Gao, Ximeng Feng, Mufeng Geng, Zhe Jiang, Lei Zhu, Xiangxi\n  Meng, Chuanqing Zhou, Qiushi Ren and Yanye Lu", "title": "A Label Management Mechanism for Retinal Fundus Image Classification of\n  Diabetic Retinopathy", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Diabetic retinopathy (DR) remains the most prevalent cause of vision\nimpairment and irreversible blindness in the working-age adults. Due to the\nrenaissance of deep learning (DL), DL-based DR diagnosis has become a promising\ntool for the early screening and severity grading of DR. However, training deep\nneural networks (DNNs) requires an enormous amount of carefully labeled data.\nNoisy label data may be introduced when labeling plenty of data, degrading the\nperformance of models. In this work, we propose a novel label management\nmechanism (LMM) for the DNN to overcome overfitting on the noisy data. LMM\nutilizes maximum posteriori probability (MAP) in the Bayesian statistic and\ntime-weighted technique to selectively correct the labels of unclean data,\nwhich gradually purify the training data and improve classification\nperformance. Comprehensive experiments on both synthetic noise data (Messidor\n\\& our collected DR dataset) and real-world noise data (ANIMAL-10N)\ndemonstrated that LMM could boost performance of models and is superior to\nthree state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 10:05:47 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Gao", "Mengdi", ""], ["Feng", "Ximeng", ""], ["Geng", "Mufeng", ""], ["Jiang", "Zhe", ""], ["Zhu", "Lei", ""], ["Meng", "Xiangxi", ""], ["Zhou", "Chuanqing", ""], ["Ren", "Qiushi", ""], ["Lu", "Yanye", ""]]}, {"id": "2106.12302", "submitter": "Stylianos Ploumpis", "authors": "Stylianos Ploumpis, Stylianos Moschoglou, Vasileios Triantafyllou,\n  Stefanos Zafeiriou", "title": "3D human tongue reconstruction from single \"in-the-wild\" images", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  3D face reconstruction from a single image is a task that has garnered\nincreased interest in the Computer Vision community, especially due to its\nbroad use in a number of applications such as realistic 3D avatar creation,\npose invariant face recognition and face hallucination. Since the introduction\nof the 3D Morphable Model in the late 90's, we witnessed an explosion of\nresearch aiming at particularly tackling this task. Nevertheless, despite the\nincreasing level of detail in the 3D face reconstructions from single images\nmainly attributed to deep learning advances, finer and highly deformable\ncomponents of the face such as the tongue are still absent from all 3D face\nmodels in the literature, although being very important for the realness of the\n3D avatar representations. In this work we present the first, to the best of\nour knowledge, end-to-end trainable pipeline that accurately reconstructs the\n3D face together with the tongue. Moreover, we make this pipeline robust in\n\"in-the-wild\" images by introducing a novel GAN method tailored for 3D tongue\nsurface generation. Finally, we make publicly available to the community the\nfirst diverse tongue dataset, consisting of 1,800 raw scans of 700 individuals\nvarying in gender, age, and ethnicity backgrounds. As we demonstrate in an\nextensive series of quantitative as well as qualitative experiments, our model\nproves to be robust and realistically captures the 3D tongue structure, even in\nadverse \"in-the-wild\" conditions.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 10:49:34 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Ploumpis", "Stylianos", ""], ["Moschoglou", "Stylianos", ""], ["Triantafyllou", "Vasileios", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "2106.12307", "submitter": "Mats Richter", "authors": "Mats L. Richter, Julius Sch\\\"oning, Ulf Krumnack", "title": "Should You Go Deeper? Optimizing Convolutional Neural Network\n  Architectures without Training by Receptive Field Analysis", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Applying artificial neural networks (ANN) to specific tasks, researchers,\nprogrammers, and other specialists usually overshot the number of convolutional\nlayers in their designs. By implication, these ANNs hold too many parameters,\nwhich needed unnecessarily trained without impacting the result. The features,\na convolutional layer can process, are strictly limited by its receptive field.\nBy layer-wise analyzing the expansion of the receptive fields, we can reliably\npredict sequences of layers that will not contribute qualitatively to the\ninference in thegiven ANN architecture. Based on these analyses, we propose\ndesign strategies to resolve these inefficiencies, optimizing the\nexplainability and the computational performance of ANNs. Since neither the\nstrategies nor the analysis requires training of the actual model, these\ninsights allow for a very efficient design process of ANNs architectures which\nmight be automated in the future.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 11:04:16 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Richter", "Mats L.", ""], ["Sch\u00f6ning", "Julius", ""], ["Krumnack", "Ulf", ""]]}, {"id": "2106.12373", "submitter": "Jiajie Zou", "authors": "Jiajie Zou, Yuran Zhang, Peiqing Jin, Cheng Luo, Xunyi Pan, Nai Ding", "title": "PALRACE: Reading Comprehension Dataset with Human Data and Labeled\n  Rationales", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pre-trained language models achieves high performance on machine reading\ncomprehension (MRC) tasks but the results are hard to explain. An appealing\napproach to make models explainable is to provide rationales for its decision.\nTo facilitate supervised learning of human rationales, here we present PALRACE\n(Pruned And Labeled RACE), a new MRC dataset with human labeled rationales for\n800 passages selected from the RACE dataset. We further classified the question\nto each passage into 6 types. Each passage was read by at least 26\nparticipants, who labeled their rationales to answer the question. Besides, we\nconducted a rationale evaluation session in which participants were asked to\nanswering the question solely based on labeled rationales, confirming that the\nlabeled rationales were of high quality and can sufficiently support question\nanswering.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 13:12:40 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Zou", "Jiajie", ""], ["Zhang", "Yuran", ""], ["Jin", "Peiqing", ""], ["Luo", "Cheng", ""], ["Pan", "Xunyi", ""], ["Ding", "Nai", ""]]}, {"id": "2106.12379", "submitter": "Adrian Vladu", "authors": "Alexandra Peste, Eugenia Iofinova, Adrian Vladu, Dan Alistarh", "title": "AC/DC: Alternating Compressed/DeCompressed Training of Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing computational requirements of deep neural networks (DNNs) have\nled to significant interest in obtaining DNN models that are sparse, yet\naccurate. Recent work has investigated the even harder case of sparse training,\nwhere the DNN weights are, for as much as possible, already sparse to reduce\ncomputational costs during training.\n  Existing sparse training methods are mainly empirical and often have lower\naccuracy relative to the dense baseline. In this paper, we present a general\napproach called Alternating Compressed/DeCompressed (AC/DC) training of DNNs,\ndemonstrate convergence for a variant of the algorithm, and show that AC/DC\noutperforms existing sparse training methods in accuracy at similar\ncomputational budgets; at high sparsity levels, AC/DC even outperforms existing\nmethods that rely on accurate pre-trained dense models. An important property\nof AC/DC is that it allows co-training of dense and sparse models, yielding\naccurate sparse-dense model pairs at the end of the training process. This is\nuseful in practice, where compressed variants may be desirable for deployment\nin resource-constrained settings without re-doing the entire training flow, and\nalso provides us with insights into the accuracy gap between dense and\ncompressed models.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 13:23:00 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Peste", "Alexandra", ""], ["Iofinova", "Eugenia", ""], ["Vladu", "Adrian", ""], ["Alistarh", "Dan", ""]]}, {"id": "2106.12387", "submitter": "Esther Puyol-Anton Dr", "authors": "Esther Puyol-Anton, Bram Ruijsink, Stefan K. Piechnik, Stefan\n  Neubauer, Steffen E. Petersen, Reza Razavi, and Andrew P. King", "title": "Fairness in Cardiac MR Image Analysis: An Investigation of Bias Due to\n  Data Imbalance in Deep Learning Based Segmentation", "comments": "MICCAI 2021 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The subject of \"fairness\" in artificial intelligence (AI) refers to assessing\nAI algorithms for potential bias based on demographic characteristics such as\nrace and gender, and the development of algorithms to address this bias. Most\napplications to date have been in computer vision, although some work in\nhealthcare has started to emerge. The use of deep learning (DL) in cardiac MR\nsegmentation has led to impressive results in recent years, and such techniques\nare starting to be translated into clinical practice. However, no work has yet\ninvestigated the fairness of such models. In this work, we perform such an\nanalysis for racial/gender groups, focusing on the problem of training data\nimbalance, using a nnU-Net model trained and evaluated on cine short axis\ncardiac MR data from the UK Biobank dataset, consisting of 5,903 subjects from\n6 different racial groups. We find statistically significant differences in\nDice performance between different racial groups. To reduce the racial bias, we\ninvestigated three strategies: (1) stratified batch sampling, in which batch\nsampling is stratified to ensure balance between racial groups; (2) fair\nmeta-learning for segmentation, in which a DL classifier is trained to classify\nrace and jointly optimized with the segmentation model; and (3) protected group\nmodels, in which a different segmentation model is trained for each racial\ngroup. We also compared the results to the scenario where we have a perfectly\nbalanced database. To assess fairness we used the standard deviation (SD) and\nskewed error ratio (SER) of the average Dice values. Our results demonstrate\nthat the racial bias results from the use of imbalanced training data, and that\nall proposed bias mitigation strategies improved fairness, with the best SD and\nSER resulting from the use of protected group models.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 13:27:35 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 07:56:18 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Puyol-Anton", "Esther", ""], ["Ruijsink", "Bram", ""], ["Piechnik", "Stefan K.", ""], ["Neubauer", "Stefan", ""], ["Petersen", "Steffen E.", ""], ["Razavi", "Reza", ""], ["King", "Andrew P.", ""]]}, {"id": "2106.12423", "submitter": "Samuli Laine", "authors": "Tero Karras, Miika Aittala, Samuli Laine, Erik H\\\"ark\\\"onen, Janne\n  Hellsten, Jaakko Lehtinen, Timo Aila", "title": "Alias-Free Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We observe that despite their hierarchical convolutional nature, the\nsynthesis process of typical generative adversarial networks depends on\nabsolute pixel coordinates in an unhealthy manner. This manifests itself as,\ne.g., detail appearing to be glued to image coordinates instead of the surfaces\nof depicted objects. We trace the root cause to careless signal processing that\ncauses aliasing in the generator network. Interpreting all signals in the\nnetwork as continuous, we derive generally applicable, small architectural\nchanges that guarantee that unwanted information cannot leak into the\nhierarchical synthesis process. The resulting networks match the FID of\nStyleGAN2 but differ dramatically in their internal representations, and they\nare fully equivariant to translation and rotation even at subpixel scales. Our\nresults pave the way for generative models better suited for video and\nanimation.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 14:20:01 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 14:43:18 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Karras", "Tero", ""], ["Aittala", "Miika", ""], ["Laine", "Samuli", ""], ["H\u00e4rk\u00f6nen", "Erik", ""], ["Hellsten", "Janne", ""], ["Lehtinen", "Jaakko", ""], ["Aila", "Timo", ""]]}, {"id": "2106.12430", "submitter": "Hananeh Aliee", "authors": "Hananeh Aliee, Fabian J. Theis, Niki Kilbertus", "title": "Beyond Predictions in Neural ODEs: Identification and Interventions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spurred by tremendous success in pattern matching and prediction tasks,\nresearchers increasingly resort to machine learning to aid original scientific\ndiscovery. Given large amounts of observational data about a system, can we\nuncover the rules that govern its evolution? Solving this task holds the great\npromise of fully understanding the causal interactions and being able to make\nreliable predictions about the system's behavior under interventions. We take a\nstep towards answering this question for time-series data generated from\nsystems of ordinary differential equations (ODEs). While the governing ODEs\nmight not be identifiable from data alone, we show that combining simple\nregularization schemes with flexible neural ODEs can robustly recover the\ndynamics and causal structures from time-series data. Our results on a variety\nof (non)-linear first and second order systems as well as real data validate\nour method. We conclude by showing that we can also make accurate predictions\nunder interventions on variables or the system itself.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 14:35:38 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Aliee", "Hananeh", ""], ["Theis", "Fabian J.", ""], ["Kilbertus", "Niki", ""]]}, {"id": "2106.12447", "submitter": "Judy Borowski", "authors": "Roland S. Zimmermann, Judy Borowski, Robert Geirhos, Matthias Bethge,\n  Thomas S. A. Wallis, Wieland Brendel", "title": "How Well do Feature Visualizations Support Causal Understanding of CNN\n  Activations?", "comments": "ICML 2021 XAI workshop version. Joint first and last authors. Project\n  website at\n  https://brendel-group.github.io/causal-understanding-via-visualizations/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One widely used approach towards understanding the inner workings of deep\nconvolutional neural networks is to visualize unit responses via activation\nmaximization. Feature visualizations via activation maximization are thought to\nprovide humans with precise information about the image features that cause a\nunit to be activated. If this is indeed true, these synthetic images should\nenable humans to predict the effect of an intervention, such as whether\noccluding a certain patch of the image (say, a dog's head) changes a unit's\nactivation. Here, we test this hypothesis by asking humans to predict which of\ntwo square occlusions causes a larger change to a unit's activation. Both a\nlarge-scale crowdsourced experiment and measurements with experts show that on\naverage, the extremely activating feature visualizations by Olah et al. (2017)\nindeed help humans on this task ($67 \\pm 4\\%$ accuracy; baseline performance\nwithout any visualizations is $60 \\pm 3\\%$). However, they do not provide any\nsignificant advantage over other visualizations (such as e.g. dataset samples),\nwhich yield similar performance ($66 \\pm 3\\%$ to $67 \\pm 3\\%$ accuracy). Taken\ntogether, we propose an objective psychophysical task to quantify the benefit\nof unit-level interpretability methods for humans, and find no evidence that\nfeature visualizations provide humans with better \"causal understanding\" than\nsimple alternative visualizations.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 14:52:23 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Zimmermann", "Roland S.", ""], ["Borowski", "Judy", ""], ["Geirhos", "Robert", ""], ["Bethge", "Matthias", ""], ["Wallis", "Thomas S. A.", ""], ["Brendel", "Wieland", ""]]}, {"id": "2106.12479", "submitter": "Charaf Eddine  Benarab", "authors": "Charaf Eddine Benarab", "title": "Classifying Textual Data with Pre-trained Vision Models through Transfer\n  Learning and Data Transformations", "comments": "Paper contains: 8 pages, 9 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Knowledge is acquired by humans through experience, and no boundary is set\nbetween the kinds of knowledge or skill levels we can achieve on different\ntasks at the same time. When it comes to Neural Networks, that is not the case,\nthe major breakthroughs in the field are extremely task and domain specific.\nVision and language are dealt with in separate manners, using separate methods\nand different datasets. In this work, we propose to use knowledge acquired by\nbenchmark Vision Models which are trained on ImageNet to help a much smaller\narchitecture learn to classify text. After transforming the textual data\ncontained in the IMDB dataset to gray scale images. An analysis of different\ndomains and the Transfer Learning method is carried out. Despite the challenge\nposed by the very different datasets, promising results are achieved. The main\ncontribution of this work is a novel approach which links large pretrained\nmodels on both language and vision to achieve state-of-the-art results in\ndifferent sub-fields from the original task. Without needing high compute\ncapacity resources. Specifically, Sentiment Analysis is achieved after\ntransferring knowledge between vision and language models. BERT embeddings are\ntransformed into grayscale images, these images are then used as training\nexamples for pre-trained vision models such as VGG16 and ResNet\n  Index Terms: BERT, Convolutional Neural Networks, Domain Adaptation, image\nclassification, Natural Language Processing, t-SNE, text classification,\nTransfer Learning\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 15:53:38 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 09:58:03 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Benarab", "Charaf Eddine", ""]]}, {"id": "2106.12497", "submitter": "Xiaofeng Liu", "authors": "Xiaofeng Liu, Fangxu Xing, Chao Yang, Georges El Fakhri, Jonghye Woo", "title": "Adapting Off-the-Shelf Source Segmenter for Target Medical Image\n  Segmentation", "comments": "To appear in MICCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unsupervised domain adaptation (UDA) aims to transfer knowledge learned from\na labeled source domain to an unlabeled and unseen target domain, which is\nusually trained on data from both domains. Access to the source domain data at\nthe adaptation stage, however, is often limited, due to data storage or privacy\nissues. To alleviate this, in this work, we target source free UDA for\nsegmentation, and propose to adapt an ``off-the-shelf\" segmentation model\npre-trained in the source domain to the target domain, with an adaptive\nbatch-wise normalization statistics adaptation framework. Specifically, the\ndomain-specific low-order batch statistics, i.e., mean and variance, are\ngradually adapted with an exponential momentum decay scheme, while the\nconsistency of domain shareable high-order batch statistics, i.e., scaling and\nshifting parameters, is explicitly enforced by our optimization objective. The\ntransferability of each channel is adaptively measured first from which to\nbalance the contribution of each channel. Moreover, the proposed source free\nUDA framework is orthogonal to unsupervised learning methods, e.g.,\nself-entropy minimization, which can thus be simply added on top of our\nframework. Extensive experiments on the BraTS 2018 database show that our\nsource free UDA framework outperformed existing source-relaxed UDA methods for\nthe cross-subtype UDA segmentation task and yielded comparable results for the\ncross-modality UDA segmentation task, compared with a supervised UDA methods\nwith the source data.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 16:16:55 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Liu", "Xiaofeng", ""], ["Xing", "Fangxu", ""], ["Yang", "Chao", ""], ["Fakhri", "Georges El", ""], ["Woo", "Jonghye", ""]]}, {"id": "2106.12499", "submitter": "Xiaofeng Liu", "authors": "Xiaofeng Liu, Fangxu Xing, Maureen Stone, Jiachen Zhuo, Reese Timothy,\n  Jerry L. Prince, Georges El Fakhri, Jonghye Woo", "title": "Generative Self-training for Cross-domain Unsupervised Tagged-to-Cine\n  MRI Synthesis", "comments": "MICCAI 2021 (early accept <13%)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-training based unsupervised domain adaptation (UDA) has shown great\npotential to address the problem of domain shift, when applying a trained deep\nlearning model in a source domain to unlabeled target domains. However, while\nthe self-training UDA has demonstrated its effectiveness on discriminative\ntasks, such as classification and segmentation, via the reliable pseudo-label\nselection based on the softmax discrete histogram, the self-training UDA for\ngenerative tasks, such as image synthesis, is not fully investigated. In this\nwork, we propose a novel generative self-training (GST) UDA framework with\ncontinuous value prediction and regression objective for cross-domain image\nsynthesis. Specifically, we propose to filter the pseudo-label with an\nuncertainty mask, and quantify the predictive confidence of generated images\nwith practical variational Bayes learning. The fast test-time adaptation is\nachieved by a round-based alternative optimization scheme. We validated our\nframework on the tagged-to-cine magnetic resonance imaging (MRI) synthesis\nproblem, where datasets in the source and target domains were acquired from\ndifferent scanners or centers. Extensive validations were carried out to verify\nour framework against popular adversarial training UDA methods. Results show\nthat our GST, with tagged MRI of test subjects in new target domains, improved\nthe synthesis quality by a large margin, compared with the adversarial training\nUDA methods.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 16:19:00 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Liu", "Xiaofeng", ""], ["Xing", "Fangxu", ""], ["Stone", "Maureen", ""], ["Zhuo", "Jiachen", ""], ["Timothy", "Reese", ""], ["Prince", "Jerry L.", ""], ["Fakhri", "Georges El", ""], ["Woo", "Jonghye", ""]]}, {"id": "2106.12534", "submitter": "Stephen James", "authors": "Stephen James, Kentaro Wada, Tristan Laidlow, Andrew J. Davison", "title": "Coarse-to-Fine Q-attention: Efficient Learning for Visual Robotic\n  Manipulation via Discretisation", "comments": "Videos and code found at\n  https://sites.google.com/view/c2f-q-attention", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reflecting on the last few years, the biggest breakthroughs in deep\nreinforcement learning (RL) have been in the discrete action domain. Robotic\nmanipulation, however, is inherently a continuous control environment, but\nthese continuous control reinforcement learning algorithms often depend on\nactor-critic methods that are sample-inefficient and inherently difficult to\ntrain, due to the joint optimisation of the actor and critic. To that end, we\nexplore how we can bring the stability of discrete action RL algorithms to the\nrobot manipulation domain. We extend the recently released ARM algorithm, by\nreplacing the continuous next-best pose agent with a discrete next-best pose\nagent. Discretisation of rotation is trivial given its bounded nature, while\ntranslation is inherently unbounded, making discretisation difficult. We\nformulate the translation prediction as the voxel prediction problem by\ndiscretising the 3D space; however, voxelisation of a large workspace is memory\nintensive and would not work with a high density of voxels, crucial to\nobtaining the resolution needed for robotic manipulation. We therefore propose\nto apply this voxel prediction in a coarse-to-fine manner by gradually\nincreasing the resolution. In each step, we extract the highest valued voxel as\nthe predicted location, which is then used as the centre of the\nhigher-resolution voxelisation in the next step. This coarse-to-fine prediction\nis applied over several steps, giving a near-lossless prediction of the\ntranslation. We show that our new coarse-to-fine algorithm is able to\naccomplish RLBench tasks much more efficiently than the continuous control\nequivalent, and even train some real-world tasks, tabular rasa, in less than 7\nminutes, with only 3 demonstrations. Moreover, we show that by moving to a\nvoxel representation, we are able to easily incorporate observations from\nmultiple cameras.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 16:57:16 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["James", "Stephen", ""], ["Wada", "Kentaro", ""], ["Laidlow", "Tristan", ""], ["Davison", "Andrew J.", ""]]}, {"id": "2106.12543", "submitter": "Colin White", "authors": "Yang Liu, Sujay Khandagale, Colin White, Willie Neiswanger", "title": "Synthetic Benchmarks for Scientific Research in Explainable Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning models grow more complex and their applications become\nmore high-stakes, tools for explaining model predictions have become\nincreasingly important. Despite the widespread use of explainability\ntechniques, evaluating and comparing different feature attribution methods\nremains challenging: evaluations ideally require human studies, and empirical\nevaluation metrics are often computationally prohibitive on real-world\ndatasets. In this work, we address this issue by releasing XAI-Bench: a suite\nof synthetic datasets along with a library for benchmarking feature attribution\nalgorithms. Unlike real-world datasets, synthetic datasets allow the efficient\ncomputation of conditional expected values that are needed to evaluate\nground-truth Shapley values and other metrics. The synthetic datasets we\nrelease offer a wide variety of parameters that can be configured to simulate\nreal-world data. We demonstrate the power of our library by benchmarking\npopular explainability techniques across several evaluation metrics and\nidentifying failure modes for popular explainers. The efficiency of our library\nwill help bring new explainability methods from development to deployment.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 17:10:21 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Liu", "Yang", ""], ["Khandagale", "Sujay", ""], ["White", "Colin", ""], ["Neiswanger", "Willie", ""]]}, {"id": "2106.12548", "submitter": "Sai Sukruth Bezugam", "authors": "Sai Sukruth Bezugam", "title": "Multi-Class Classification of Blood Cells -- End to End Computer Vision\n  based diagnosis case study", "comments": "18 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI q-bio.CB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The diagnosis of blood-based diseases often involves identifying and\ncharacterizing patient blood samples. Automated methods to detect and classify\nblood cell subtypes have important medical applications. Automated medical\nimage processing and analysis offers a powerful tool for medical diagnosis. In\nthis work we tackle the problem of white blood cell classification based on the\nmorphological characteristics of their outer contour, color. The work we would\nexplore a set of preprocessing and segmentation (Color-based segmentation,\nMorphological processing, contouring) algorithms along with a set of features\nextraction methods (Corner detection algorithms and Histogram of\nGradients(HOG)), dimensionality reduction algorithms (Principal Component\nAnalysis(PCA)) that are able to recognize and classify through various\nUnsupervised(k-nearest neighbors) and Supervised (Support Vector Machine,\nDecision Trees, Linear Discriminant Analysis, Quadratic Discriminant Analysis,\nNaive Bayes) algorithms different categories of white blood cells to\nEosinophil, Lymphocyte, Monocyte, and Neutrophil. We even take a step forwards\nto explore various Deep Convolutional Neural network architecture (Sqeezent,\nMobilenetV1,MobilenetV2, InceptionNet etc.) without preprocessing/segmentation\nand with preprocessing. We would like to explore many algorithms to identify\nthe robust algorithm with least time complexity and low resource requirement.\nThe outcome of this work can be a cue to selection of algorithms as per\nrequirement for automated blood cell classification.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 17:18:19 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Bezugam", "Sai Sukruth", ""]]}, {"id": "2106.12569", "submitter": "Amy Widdicombe", "authors": "Amy Widdicombe, Simon J. Julier", "title": "Gradient-Based Interpretability Methods and Binarized Neural Networks", "comments": "Accepted at the ICML 2021 Workshop on Theoretic Foundation, Criticism\n  & Application Trend of Explainable AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binarized Neural Networks (BNNs) have the potential to revolutionize the way\nthat deep learning is carried out in edge computing platforms. However, the\neffectiveness of interpretability methods on these networks has not been\nassessed.\n  In this paper, we compare the performance of several widely used saliency\nmap-based interpretabilty techniques (Gradient, SmoothGrad and GradCAM), when\napplied to Binarized or Full Precision Neural Networks (FPNNs). We found that\nthe basic Gradient method produces very similar-looking maps for both types of\nnetwork. However, SmoothGrad produces significantly noisier maps for BNNs.\nGradCAM also produces saliency maps which differ between network types, with\nsome of the BNNs having seemingly nonsensical explanations. We comment on\npossible reasons for these differences in explanations and present it as an\nexample of why interpretability techniques should be tested on a wider range of\nnetwork types.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 17:53:18 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Widdicombe", "Amy", ""], ["Julier", "Simon J.", ""]]}, {"id": "2106.12574", "submitter": "Thomas Winters", "authors": "Thomas Winters, Giuseppe Marra, Robin Manhaeve, Luc De Raedt", "title": "DeepStochLog: Neural Stochastic Logic Programming", "comments": "Thomas Winters and Giuseppe Marra contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in neural symbolic learning, such as DeepProbLog, extend\nprobabilistic logic programs with neural predicates. Like graphical models,\nthese probabilistic logic programs define a probability distribution over\npossible worlds, for which inference is computationally hard. We propose\nDeepStochLog, an alternative neural symbolic framework based on stochastic\ndefinite clause grammars, a type of stochastic logic program, which defines a\nprobability distribution over possible derivations. More specifically, we\nintroduce neural grammar rules into stochastic definite clause grammars to\ncreate a framework that can be trained end-to-end. We show that inference and\nlearning in neural stochastic logic programming scale much better than for\nneural probabilistic logic programs. Furthermore, the experimental evaluation\nshows that DeepStochLog achieves state-of-the-art results on challenging neural\nsymbolic learning tasks.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 17:59:04 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Winters", "Thomas", ""], ["Marra", "Giuseppe", ""], ["Manhaeve", "Robin", ""], ["De Raedt", "Luc", ""]]}, {"id": "2106.12576", "submitter": "Sahib Singh", "authors": "Archit Uniyal, Rakshit Naidu, Sasikanth Kotti, Sahib Singh, Patrik\n  Joslin Kenfack, Fatemehsadat Mireshghallah, Andrew Trask", "title": "DP-SGD vs PATE: Which Has Less Disparate Impact on Model Accuracy?", "comments": "4 pages, 3 images", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances in differentially private deep learning have demonstrated\nthat application of differential privacy, specifically the DP-SGD algorithm,\nhas a disparate impact on different sub-groups in the population, which leads\nto a significantly high drop-in model utility for sub-populations that are\nunder-represented (minorities), compared to well-represented ones. In this\nwork, we aim to compare PATE, another mechanism for training deep learning\nmodels using differential privacy, with DP-SGD in terms of fairness. We show\nthat PATE does have a disparate impact too, however, it is much less severe\nthan DP-SGD. We draw insights from this observation on what might be promising\ndirections in achieving better fairness-privacy trade-offs.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 20:37:12 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Uniyal", "Archit", ""], ["Naidu", "Rakshit", ""], ["Kotti", "Sasikanth", ""], ["Singh", "Sahib", ""], ["Kenfack", "Patrik Joslin", ""], ["Mireshghallah", "Fatemehsadat", ""], ["Trask", "Andrew", ""]]}, {"id": "2106.12611", "submitter": "Yeshwanth Cherapanamjeri", "authors": "Peter L. Bartlett, S\\'ebastien Bubeck and Yeshwanth Cherapanamjeri", "title": "Adversarial Examples in Multi-Layer Random ReLU Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the phenomenon of adversarial examples in ReLU networks with\nindependent gaussian parameters. For networks of constant depth and with a\nlarge range of widths (for instance, it suffices if the width of each layer is\npolynomial in that of any other layer), small perturbations of input vectors\nlead to large changes of outputs. This generalizes results of Daniely and\nSchacham (2020) for networks of rapidly decreasing width and of Bubeck et al\n(2021) for two-layer networks. The proof shows that adversarial examples arise\nin these networks because the functions that they compute are very close to\nlinear. Bottleneck layers in the network play a key role: the minimal width up\nto some point in the network determines scales and sensitivities of mappings\ncomputed up to that point. The main result is for networks with constant depth,\nbut we also show that some constraint on depth is necessary for a result of\nthis kind, because there are suitably deep networks that, with constant\nprobability, compute a function that is close to constant.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 18:16:34 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Bartlett", "Peter L.", ""], ["Bubeck", "S\u00e9bastien", ""], ["Cherapanamjeri", "Yeshwanth", ""]]}, {"id": "2106.12614", "submitter": "Samay Pashine", "authors": "Samay Pashine, Ritik Dixit, and Rishika Kushwah", "title": "Handwritten Digit Recognition using Machine and Deep Learning Algorithms", "comments": "6 Pages, 13 figures, and 1 table", "journal-ref": "International Journal of Computer Applications, Volume 176 -\n  Number 42, 2020", "doi": "10.5120/ijca2020920550", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The reliance of humans over machines has never been so high such that from\nobject classification in photographs to adding sound to silent movies\neverything can be performed with the help of deep learning and machine learning\nalgorithms. Likewise, Handwritten text recognition is one of the significant\nareas of research and development with a streaming number of possibilities that\ncould be attained. Handwriting recognition (HWR), also known as Handwritten\nText Recognition (HTR), is the ability of a computer to receive and interpret\nintelligible handwritten input from sources such as paper documents,\nphotographs, touch-screens and other devices [1]. Apparently, in this paper, we\nhave performed handwritten digit recognition with the help of MNIST datasets\nusing Support Vector Machines (SVM), Multi-Layer Perceptron (MLP) and\nConvolution Neural Network (CNN) models. Our main objective is to compare the\naccuracy of the models stated above along with their execution time to get the\nbest possible model for digit recognition.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 18:23:01 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Pashine", "Samay", ""], ["Dixit", "Ritik", ""], ["Kushwah", "Rishika", ""]]}, {"id": "2106.12658", "submitter": "Xianlong Zeng", "authors": "Xianlong Zeng, Simon Lin, Chang Liu", "title": "Transformer-based unsupervised patient representation learning based on\n  medical claims for risk stratification and analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The claims data, containing medical codes, services information, and incurred\nexpenditure, can be a good resource for estimating an individual's health\ncondition and medical risk level. In this study, we developed Transformer-based\nMultimodal AutoEncoder (TMAE), an unsupervised learning framework that can\nlearn efficient patient representation by encoding meaningful information from\nthe claims data. TMAE is motivated by the practical needs in healthcare to\nstratify patients into different risk levels for improving care delivery and\nmanagement. Compared to previous approaches, TMAE is able to 1) model\ninpatient, outpatient, and medication claims collectively, 2) handle irregular\ntime intervals between medical events, 3) alleviate the sparsity issue of the\nrare medical codes, and 4) incorporate medical expenditure information. We\ntrained TMAE using a real-world pediatric claims dataset containing more than\n600,000 patients and compared its performance with various approaches in two\nclustering tasks. Experimental results demonstrate that TMAE has superior\nperformance compared to all baselines. Multiple downstream applications are\nalso conducted to illustrate the effectiveness of our framework. The promising\nresults confirm that the TMAE framework is scalable to large claims data and is\nable to generate efficient patient embeddings for risk stratification and\nanalysis.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 21:29:50 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Zeng", "Xianlong", ""], ["Lin", "Simon", ""], ["Liu", "Chang", ""]]}, {"id": "2106.12662", "submitter": "Peter Harrington", "authors": "Peter Harrington, Mustafa Mustafa, Max Dornfest, Benjamin Horowitz,\n  Zarija Luki\\'c", "title": "Fast, high-fidelity Lyman $\\alpha$ forests with convolutional neural\n  networks", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.CO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Full-physics cosmological simulations are powerful tools for studying the\nformation and evolution of structure in the universe but require extreme\ncomputational resources. Here, we train a convolutional neural network to use a\ncheaper N-body-only simulation to reconstruct the baryon hydrodynamic variables\n(density, temperature, and velocity) on scales relevant to the Lyman-$\\alpha$\n(Ly$\\alpha$) forest, using data from Nyx simulations. We show that our method\nenables rapid estimation of these fields at a resolution of $\\sim$20kpc, and\ncaptures the statistics of the Ly$\\alpha$ forest with much greater accuracy\nthan existing approximations. Because our model is fully-convolutional, we can\ntrain on smaller simulation boxes and deploy on much larger ones, enabling\nsubstantial computational savings. Furthermore, as our method produces an\napproximation for the hydrodynamic fields instead of Ly$\\alpha$ flux directly,\nit is not limited to a particular choice of ionizing background or mean\ntransmitted flux.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 21:41:47 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Harrington", "Peter", ""], ["Mustafa", "Mustafa", ""], ["Dornfest", "Max", ""], ["Horowitz", "Benjamin", ""], ["Luki\u0107", "Zarija", ""]]}, {"id": "2106.12665", "submitter": "Balaji Ganesan", "authors": "Anjali Singh, Shamanth R Nayak K, Balaji Ganesan", "title": "Reimagining GNN Explanations with ideas from Tabular Data", "comments": "4 pages, 8 figures, XAI Workshop at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainability techniques for Graph Neural Networks still have a long way to\ngo compared to explanations available for both neural and decision decision\ntree-based models trained on tabular data. Using a task that straddles both\ngraphs and tabular data, namely Entity Matching, we comment on key aspects of\nexplainability that are missing in GNN model explanations.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 21:48:35 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Singh", "Anjali", ""], ["K", "Shamanth R Nayak", ""], ["Ganesan", "Balaji", ""]]}, {"id": "2106.12666", "submitter": "Anna Nedorubova", "authors": "Anna Nedorubova, Alena Kadyrova, Aleksey Khlyupin", "title": "Human Activity Recognition using Continuous Wavelet Transform and\n  Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Quite a few people in the world have to stay under permanent surveillance for\nhealth reasons; they include diabetic people or people with some other chronic\nconditions, the elderly and the disabled.These groups may face heightened risk\nof having life-threatening falls or of being struck by a syncope. Due to\nlimited availability of resources a substantial part of people at risk can not\nreceive necessary monitoring and thus are exposed to excessive danger.\nNowadays, this problem is usually solved via applying Human Activity\nRecognition (HAR) methods. HAR is a perspective and fast-paced Data Science\nfield, which has a wide range of application areas such as healthcare, sport,\nsecurity etc. However, the currently techniques of recognition are markedly\nlacking in accuracy, hence, the present paper suggests a highly accurate method\nfor human activity classification. Wepropose a new workflow to address the HAR\nproblem and evaluate it on the UniMiB SHAR dataset, which consists of the\naccelerometer signals. The model we suggest is based on continuous wavelet\ntransform (CWT) and convolutional neural networks (CNNs). Wavelet transform\nlocalizes signal features both in time and frequency domains and after that a\nCNN extracts these features and recognizes activity. It is also worth noting\nthat CWT converts 1D accelerometer signal into 2D images and thus enables to\nobtain better results as 2D networks have a significantly higher predictive\ncapacity. In the course of the work we build a convolutional neural network and\nvary such model parameters as number of spatial axes, number of layers, number\nof neurons in each layer, image size, type of mother wavelet, the order of zero\nmoment of mother wavelet etc. Besides, we also apply models with residual\nblocks which resulted in significantly higher metric values. Finally, we\nsucceed to reach 99.26 % accuracy and it is a worthy performance for this\nproblem.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 21:49:17 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 17:55:52 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Nedorubova", "Anna", ""], ["Kadyrova", "Alena", ""], ["Khlyupin", "Aleksey", ""]]}, {"id": "2106.12672", "submitter": "Yi Tay", "authors": "Yi Tay, Vinh Q. Tran, Sebastian Ruder, Jai Gupta, Hyung Won Chung,\n  Dara Bahri, Zhen Qin, Simon Baumgartner, Cong Yu, Donald Metzler", "title": "Charformer: Fast Character Transformers via Gradient-based Subword\n  Tokenization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art models in natural language processing rely on separate rigid\nsubword tokenization algorithms, which limit their generalization ability and\nadaptation to new settings. In this paper, we propose a new model inductive\nbias that learns a subword tokenization end-to-end as part of the model. To\nthis end, we introduce a soft gradient-based subword tokenization module (GBST)\nthat automatically learns latent subword representations from characters in a\ndata-driven fashion. Concretely, GBST enumerates candidate subword blocks and\nlearns to score them in a position-wise fashion using a block scoring network.\nWe additionally introduce Charformer, a deep Transformer model that integrates\nGBST and operates on the byte level. Via extensive experiments on English GLUE,\nmultilingual, and noisy text datasets, we show that Charformer outperforms a\nseries of competitive byte-level baselines while generally performing on par\nand sometimes outperforming subword-based models. Additionally, Charformer is\nfast, improving the speed of both vanilla byte-level and subword-level\nTransformers by 28%-100% while maintaining competitive quality. We believe this\nwork paves the way for highly performant token-free models that are trained\ncompletely end-to-end.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 22:24:14 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 16:30:28 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Tay", "Yi", ""], ["Tran", "Vinh Q.", ""], ["Ruder", "Sebastian", ""], ["Gupta", "Jai", ""], ["Chung", "Hyung Won", ""], ["Bahri", "Dara", ""], ["Qin", "Zhen", ""], ["Baumgartner", "Simon", ""], ["Yu", "Cong", ""], ["Metzler", "Donald", ""]]}, {"id": "2106.12674", "submitter": "Mengnan Du", "authors": "Mengnan Du, Subhabrata Mukherjee, Guanchu Wang, Ruixiang Tang, Ahmed\n  Hassan Awadallah, Xia Hu", "title": "Fairness via Representation Neutralization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing bias mitigation methods for DNN models primarily work on learning\ndebiased encoders. This process not only requires a lot of instance-level\nannotations for sensitive attributes, it also does not guarantee that all\nfairness sensitive information has been removed from the encoder. To address\nthese limitations, we explore the following research question: Can we reduce\nthe discrimination of DNN models by only debiasing the classification head,\neven with biased representations as inputs? To this end, we propose a new\nmitigation technique, namely, Representation Neutralization for Fairness (RNF)\nthat achieves fairness by debiasing only the task-specific classification head\nof DNN models. To this end, we leverage samples with the same ground-truth\nlabel but different sensitive attributes, and use their neutralized\nrepresentations to train the classification head of the DNN model. The key idea\nof RNF is to discourage the classification head from capturing spurious\ncorrelation between fairness sensitive information in encoder representations\nwith specific class labels. To address low-resource settings with no access to\nsensitive attribute annotations, we leverage a bias-amplified model to generate\nproxy annotations for sensitive attributes. Experimental results over several\nbenchmark datasets demonstrate our RNF framework to effectively reduce\ndiscrimination of DNN models with minimal degradation in task-specific\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 22:26:29 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Du", "Mengnan", ""], ["Mukherjee", "Subhabrata", ""], ["Wang", "Guanchu", ""], ["Tang", "Ruixiang", ""], ["Awadallah", "Ahmed Hassan", ""], ["Hu", "Xia", ""]]}, {"id": "2106.12718", "submitter": "Lucas Liebenwein", "authors": "Lucas Liebenwein, Ramin Hasani, Alexander Amini, Daniela Rus", "title": "Sparse Flows: Pruning Continuous-depth Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Continuous deep learning architectures enable learning of flexible\nprobabilistic models for predictive modeling as neural ordinary differential\nequations (ODEs), and for generative modeling as continuous normalizing flows.\nIn this work, we design a framework to decipher the internal dynamics of these\ncontinuous depth models by pruning their network architectures. Our empirical\nresults suggest that pruning improves generalization for neural ODEs in\ngenerative modeling. Moreover, pruning finds minimal and efficient neural ODE\nrepresentations with up to 98\\% less parameters compared to the original\nnetwork, without loss of accuracy. Finally, we show that by applying pruning we\ncan obtain insightful information about the design of better neural ODEs.We\nhope our results will invigorate further research into the performance-size\ntrade-offs of modern continuous-depth models.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 01:40:17 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Liebenwein", "Lucas", ""], ["Hasani", "Ramin", ""], ["Amini", "Alexander", ""], ["Rus", "Daniela", ""]]}, {"id": "2106.12732", "submitter": "Tianhao Wei", "authors": "Tianhao Wei, Changliu Liu", "title": "Online Verification of Deep Neural Networks under Domain or Weight Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although neural networks are widely used, it remains challenging to formally\nverify the safety and robustness of neural networks in real-world applications.\nExisting methods are designed to verify the network before use, which is\nlimited to relatively simple specifications and fixed networks. These methods\nare not ready to be applied to real-world problems with complex and/or\ndynamically changing specifications and networks. To effectively handle\ndynamically changing specifications and networks, the verification needs to be\nperformed online when these changes take place. However, it is still\nchallenging to run existing verification algorithms online. Our key insight is\nthat we can leverage the temporal dependencies of these changes to accelerate\nthe verification process, e.g., by warm starting new online verification using\nprevious verified results. This paper establishes a novel framework for\nscalable online verification to solve real-world verification problems with\ndynamically changing specifications and/or networks, known as domain shift and\nweight shift respectively. We propose three types of techniques (branch\nmanagement, perturbation tolerance analysis, and incremental computation) to\naccelerate the online verification of deep neural networks. Experiment results\nshow that our online verification algorithm is up to two orders of magnitude\nfaster than existing verification algorithms, and thus can scale to real-world\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 02:38:27 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Wei", "Tianhao", ""], ["Liu", "Changliu", ""]]}, {"id": "2106.12797", "submitter": "Nawshad Farruque", "authors": "Nawshad Farruque, Randy Goebel and Osmar Zaiane", "title": "A comprehensive empirical analysis on cross-domain semantic enrichment\n  for detection of depressive language", "comments": "This is an extension over ECML-PKDD, 2019 paper \"Augmenting Semantic\n  Representation of Depressive Language: from Forums to Microblogs\", with more\n  embedding mapping/augmentation methods and data ablation tests. These\n  experiments were done in the year 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We analyze the process of creating word embedding feature representations\ndesigned for a learning task when annotated data is scarce, for example, in\ndepressive language detection from Tweets. We start with a rich word embedding\npre-trained from a large general dataset, which is then augmented with\nembeddings learned from a much smaller and more specific domain dataset through\na simple non-linear mapping mechanism. We also experimented with several other\nmore sophisticated methods of such mapping including, several auto-encoder\nbased and custom loss-function based methods that learn embedding\nrepresentations through gradually learning to be close to the words of similar\nsemantics and distant to dissimilar semantics. Our strengthened representations\nbetter capture the semantics of the depression domain, as it combines the\nsemantics learned from the specific domain coupled with word coverage from the\ngeneral language. We also present a comparative performance analyses of our\nword embedding representations with a simple bag-of-words model, well known\nsentiment and psycholinguistic lexicons, and a general pre-trained word\nembedding. When used as feature representations for several different machine\nlearning methods, including deep learning models in a depressive Tweets\nidentification task, we show that our augmented word embedding representations\nachieve a significantly better F1 score than the others, specially when applied\nto a high quality dataset. Also, we present several data ablation tests which\nconfirm the efficacy of our augmentation techniques.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 07:15:09 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Farruque", "Nawshad", ""], ["Goebel", "Randy", ""], ["Zaiane", "Osmar", ""]]}, {"id": "2106.12831", "submitter": "Valentina Anita Carriero", "authors": "Luigi Asprino, Valentina Anita Carriero, Valentina Presutti", "title": "Extraction of common conceptual components from multiple ontologies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe a novel method for identifying and extracting conceptual\ncomponents from domain ontologies, which are used to understand and compare\nthem. The method is applied to two corpora of ontologies in the Cultural\nHeritage and Conference domain, respectively. The results, which show good\nquality, are evaluated by manual inspection and by correlation with datasets\nand tool performance from the ontology alignment evaluation initiative.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 08:33:31 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Asprino", "Luigi", ""], ["Carriero", "Valentina Anita", ""], ["Presutti", "Valentina", ""]]}, {"id": "2106.12868", "submitter": "Gaia Belardinelli", "authors": "Gaia Belardinelli and Rasmus K. Rendsvig", "title": "Awareness Logic: Kripke Lattices as a Middle Ground between Syntactic\n  and Semantic Models", "comments": "arXiv admin note: substantial text overlap with arXiv:2012.12982", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.MA econ.TH math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The literature on awareness modeling includes both syntax-free and\nsyntax-based frameworks. Heifetz, Meier \\& Schipper (HMS) propose a lattice\nmodel of awareness that is syntax-free. While their lattice approach is elegant\nand intuitive, it precludes the simple option of relying on formal language to\ninduce lattices, and does not explicitly distinguish uncertainty from\nunawareness. Contra this, the most prominent syntax-based solution, the\nFagin-Halpern (FH) model, accounts for this distinction and offers a simple\nrepresentation of awareness, but lacks the intuitiveness of the lattice\nstructure. Here, we combine these two approaches by providing a lattice of\nKripke models, induced by atom subset inclusion, in which uncertainty and\nunawareness are separate. We show our model equivalent to both HMS and FH\nmodels by defining transformations between them which preserve satisfaction of\nformulas of a language for explicit knowledge, and obtain completeness through\nour and HMS' results. Lastly, we prove that the Kripke lattice model can be\nshown equivalent to the FH model (when awareness is propositionally determined)\nalso with respect to the language of the Logic of General Awareness, for which\nthe FH model where originally proposed.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 10:04:44 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Belardinelli", "Gaia", ""], ["Rendsvig", "Rasmus K.", ""]]}, {"id": "2106.12871", "submitter": "Subhadip Maji", "authors": "Subhadip Maji, Swapna Sourav Rout and Sudeep Choudhary", "title": "DCoM: A Deep Column Mapper for Semantic Data Type Detection", "comments": "9 pages, 2 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Detection of semantic data types is a very crucial task in data science for\nautomated data cleaning, schema matching, data discovery, semantic data type\nnormalization and sensitive data identification. Existing methods include\nregular expression-based or dictionary lookup-based methods that are not robust\nto dirty as well unseen data and are limited to a very less number of semantic\ndata types to predict. Existing Machine Learning methods extract large number\nof engineered features from data and build logistic regression, random forest\nor feedforward neural network for this purpose. In this paper, we introduce\nDCoM, a collection of multi-input NLP-based deep neural networks to detect\nsemantic data types where instead of extracting large number of features from\nthe data, we feed the raw values of columns (or instances) to the model as\ntexts. We train DCoM on 686,765 data columns extracted from VizNet corpus with\n78 different semantic data types. DCoM outperforms other contemporary results\nwith a quite significant margin on the same dataset.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 10:12:35 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Maji", "Subhadip", ""], ["Rout", "Swapna Sourav", ""], ["Choudhary", "Sudeep", ""]]}, {"id": "2106.12887", "submitter": "Ibrahim Alabdulmohsin", "authors": "Ibrahim Alabdulmohsin and Mario Lucic", "title": "A Near-Optimal Algorithm for Debiasing Trained Machine Learning Models", "comments": "21 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a scalable post-processing algorithm for debiasing trained models,\nincluding deep neural networks (DNNs), which we prove to be near-optimal by\nbounding its excess Bayes risk. We empirically validate its advantages on\nstandard benchmark datasets across both classical algorithms as well as modern\nDNN architectures and demonstrate that it outperforms previous post-processing\nmethods while performing on par with in-processing. In addition, we show that\nthe proposed algorithm is particularly effective for models trained at scale\nwhere post-processing is a natural and practical choice.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 09:45:37 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Alabdulmohsin", "Ibrahim", ""], ["Lucic", "Mario", ""]]}, {"id": "2106.12891", "submitter": "Anwesh Bhattacharya", "authors": "Anwesh Bhattacharya, Marios Mattheakis, Pavlos Protopapas", "title": "Encoding Involutory Invariance in Neural Networks", "comments": "19 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In certain situations, Neural Networks (NN) are trained upon data that obey\nunderlying physical symmetries. However, it is not guaranteed that NNs will\nobey the underlying symmetry unless embedded in the network structure. In this\nwork, we explore a special kind of symmetry where functions are invariant with\nrespect to involutory linear/affine transformations up to parity $p=\\pm 1$. We\ndevelop mathematical theorems and propose NN architectures that ensure\ninvariance and universal approximation properties. Numerical experiments\nindicate that the proposed models outperform baseline networks while respecting\nthe imposed symmetry. An adaption of our technique to convolutional NN\nclassification tasks for datasets with inherent horizontal/vertical reflection\nsymmetry has also been proposed.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 16:07:15 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Bhattacharya", "Anwesh", ""], ["Mattheakis", "Marios", ""], ["Protopapas", "Pavlos", ""]]}, {"id": "2106.12894", "submitter": "Nishant Kumar", "authors": "Nishant Kumar, Pia Hanfeld, Michael Hecht, Michael Bussmann, Stefan\n  Gumhold and Nico Hoffmannn", "title": "InFlow: Robust outlier detection utilizing Normalizing Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Normalizing flows are prominent deep generative models that provide tractable\nprobability distributions and efficient density estimation. However, they are\nwell known to fail while detecting Out-of-Distribution (OOD) inputs as they\ndirectly encode the local features of the input representations in their latent\nspace. In this paper, we solve this overconfidence issue of normalizing flows\nby demonstrating that flows, if extended by an attention mechanism, can\nreliably detect outliers including adversarial attacks. Our approach does not\nrequire outlier data for training and we showcase the efficiency of our method\nfor OOD detection by reporting state-of-the-art performance in diverse\nexperimental settings. Code available at\nhttps://github.com/ComputationalRadiationPhysics/InFlow .\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 08:42:50 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Kumar", "Nishant", ""], ["Hanfeld", "Pia", ""], ["Hecht", "Michael", ""], ["Bussmann", "Michael", ""], ["Gumhold", "Stefan", ""], ["Hoffmannn", "Nico", ""]]}, {"id": "2106.12895", "submitter": "Felipe B. Martins", "authors": "Felipe B. Martins, Mateus G. Machado, Hansenclever F. Bassani, Pedro\n  H. M. Braga, Edna S. Barros", "title": "rSoccer: A Framework for Studying Reinforcement Learning in Small and\n  Very Small Size Robot Soccer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Reinforcement learning is an active research area with a vast number of\napplications in robotics, and the RoboCup competition is an interesting\nenvironment for studying and evaluating reinforcement learning methods. A known\ndifficulty in applying reinforcement learning to robotics is the high number of\nexperience samples required, being the use of simulated environments for\ntraining the agents followed by transfer learning to real-world (sim-to-real) a\nviable path. This article introduces an open-source simulator for the IEEE Very\nSmall Size Soccer and the Small Size League optimized for reinforcement\nlearning experiments. We also propose a framework for creating OpenAI Gym\nenvironments with a set of benchmarks tasks for evaluating single-agent and\nmulti-agent robot soccer skills. We then demonstrate the learning capabilities\nof two state-of-the-art reinforcement learning methods as well as their\nlimitations in certain scenarios introduced in this framework. We believe this\nwill make it easier for more teams to compete in these categories using\nend-to-end reinforcement learning approaches and further develop this research\narea.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 01:30:21 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Martins", "Felipe B.", ""], ["Machado", "Mateus G.", ""], ["Bassani", "Hansenclever F.", ""], ["Braga", "Pedro H. M.", ""], ["Barros", "Edna S.", ""]]}, {"id": "2106.12896", "submitter": "Raahil Shah", "authors": "Raahil Shah, Kamil Pokora, Abdelhamid Ezzerg, Viacheslav Klimkov,\n  Goeric Huybrechts, Bartosz Putrycz, Daniel Korzekwa, Thomas Merritt", "title": "Non-Autoregressive TTS with Explicit Duration Modelling for Low-Resource\n  Highly Expressive Speech", "comments": "6 pages, 5 figures. Accepted to Speech Synthesis Workshop (SSW) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whilst recent neural text-to-speech (TTS) approaches produce high-quality\nspeech, they typically require a large amount of recordings from the target\nspeaker. In previous work, a 3-step method was proposed to generate\nhigh-quality TTS while greatly reducing the amount of data required for\ntraining. However, we have observed a ceiling effect in the level of\nnaturalness achievable for highly expressive voices when using this approach.\nIn this paper, we present a method for building highly expressive TTS voices\nwith as little as 15 minutes of speech data from the target speaker. Compared\nto the current state-of-the-art approach, our proposed improvements close the\ngap to recordings by 23.3% for naturalness of speech and by 16.3% for speaker\nsimilarity. Further, we match the naturalness and speaker similarity of a\nTacotron2-based full-data (~10 hours) model using only 15 minutes of target\nspeaker data, whereas with 30 minutes or more, we significantly outperform it.\nThe following improvements are proposed: 1) changing from an autoregressive,\nattention-based TTS model to a non-autoregressive model replacing attention\nwith an external duration model and 2) an additional Conditional Generative\nAdversarial Network (cGAN) based fine-tuning step.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 10:52:10 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 18:25:04 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Shah", "Raahil", ""], ["Pokora", "Kamil", ""], ["Ezzerg", "Abdelhamid", ""], ["Klimkov", "Viacheslav", ""], ["Huybrechts", "Goeric", ""], ["Putrycz", "Bartosz", ""], ["Korzekwa", "Daniel", ""], ["Merritt", "Thomas", ""]]}, {"id": "2106.12915", "submitter": "Bertoin David", "authors": "David Bertoin (ISAE-SUPAERO), J\\'er\\^ome Bolte (TSE), S\\'ebastien\n  Gerchinovitz (IMT), Edouard Pauwels (IRIT-ADRIA)", "title": "Numerical influence of ReLU'(0) on backpropagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In theory, the choice of ReLU'(0) in [0, 1] for a neural network has a\nnegligible influence both on backpropagation and training. Yet, in the real\nworld, 32 bits default precision combined with the size of deep learning\nproblems makes it a hyperparameter of training methods. We investigate the\nimportance of the value of ReLU'(0) for several precision levels (16, 32, 64\nbits), on various networks (fully connected, VGG, ResNet) and datasets (MNIST,\nCIFAR10, SVHN). We observe considerable variations of backpropagation outputs\nwhich occur around half of the time in 32 bits precision. The effect disappears\nwith double precision, while it is systematic at 16 bits. For vanilla SGD\ntraining, the choice ReLU'(0) = 0 seems to be the most efficient. We also\nevidence that reconditioning approaches as batch-norm or ADAM tend to buffer\nthe influence of ReLU'(0)'s value. Overall, the message we want to convey is\nthat algorithmic differentiation of nonsmooth problems potentially hides\nparameters that could be tuned advantageously.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 09:28:17 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 13:27:30 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Bertoin", "David", "", "ISAE-SUPAERO"], ["Bolte", "J\u00e9r\u00f4me", "", "TSE"], ["Gerchinovitz", "S\u00e9bastien", "", "IMT"], ["Pauwels", "Edouard", "", "IRIT-ADRIA"]]}, {"id": "2106.12937", "submitter": "Alexandra Moringen", "authors": "Alexandra Moringen, S\\\"oren R\\\"uttgers, Luisa Zintgraf, Jason\n  Friedman, Helge Ritter", "title": "Optimizing piano practice with a utility-based scaffold", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A typical part of learning to play the piano is the progression through a\nseries of practice units that focus on individual dimensions of the skill, such\nas hand coordination, correct posture, or correct timing. Ideally, a focus on a\nparticular practice method should be made in a way to maximize the learner's\nprogress in learning to play the piano. Because we each learn differently, and\nbecause there are many choices for possible piano practice tasks and methods,\nthe set of practice tasks should be dynamically adapted to the human learner.\nHowever, having a human teacher guide individual practice is not always\nfeasible since it is time consuming, expensive, and not always available.\nInstead, we suggest to optimize in the space of practice methods, the so-called\npractice modes. The proposed optimization process takes into account the skills\nof the individual learner and their history of learning. In this work we\npresent a modeling framework to guide the human learner through the learning\nprocess by choosing practice modes that have the highest expected utility\n(i.e., improvement in piano playing skill). To this end, we propose a human\nlearner utility model based on a Gaussian process, and exemplify the model\ntraining and its application for practice scaffolding on an example of\nsimulated human learners.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 14:05:00 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Moringen", "Alexandra", ""], ["R\u00fcttgers", "S\u00f6ren", ""], ["Zintgraf", "Luisa", ""], ["Friedman", "Jason", ""], ["Ritter", "Helge", ""]]}, {"id": "2106.12940", "submitter": "Guozhi Tang", "authors": "Guozhi Tang, Lele Xie, Lianwen Jin, Jiapeng Wang, Jingdong Chen, Zhen\n  Xu, Qianying Wang, Yaqiang Wu, Hui Li", "title": "MatchVIE: Exploiting Match Relevancy between Entities for Visual\n  Information Extraction", "comments": "accepted by IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Information Extraction (VIE) task aims to extract key information from\nmultifarious document images (e.g., invoices and purchase receipts). Most\nprevious methods treat the VIE task simply as a sequence labeling problem or\nclassification problem, which requires models to carefully identify each kind\nof semantics by introducing multimodal features, such as font, color, layout.\nBut simply introducing multimodal features couldn't work well when faced with\nnumeric semantic categories or some ambiguous texts. To address this issue, in\nthis paper we propose a novel key-value matching model based on a graph neural\nnetwork for VIE (MatchVIE). Through key-value matching based on relevancy\nevaluation, the proposed MatchVIE can bypass the recognitions to various\nsemantics, and simply focuses on the strong relevancy between entities.\nBesides, we introduce a simple but effective operation, Num2Vec, to tackle the\ninstability of encoded values, which helps model converge more smoothly.\nComprehensive experiments demonstrate that the proposed MatchVIE can\nsignificantly outperform previous methods. Notably, to the best of our\nknowledge, MatchVIE may be the first attempt to tackle the VIE task by modeling\nthe relevancy between keys and values and it is a good complement to the\nexisting methods.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 12:06:29 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Tang", "Guozhi", ""], ["Xie", "Lele", ""], ["Jin", "Lianwen", ""], ["Wang", "Jiapeng", ""], ["Chen", "Jingdong", ""], ["Xu", "Zhen", ""], ["Wang", "Qianying", ""], ["Wu", "Yaqiang", ""], ["Li", "Hui", ""]]}, {"id": "2106.12944", "submitter": "Saneem Ahmed Chemmengath", "authors": "Yannis Katsis, Saneem Chemmengath, Vishwajeet Kumar, Samarth\n  Bharadwaj, Mustafa Canim, Michael Glass, Alfio Gliozzo, Feifei Pan, Jaydeep\n  Sen, Karthik Sankaranarayanan, Soumen Chakrabarti", "title": "AIT-QA: Question Answering Dataset over Complex Tables in the Airline\n  Industry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in transformers have enabled Table Question Answering (Table\nQA) systems to achieve high accuracy and SOTA results on open domain datasets\nlike WikiTableQuestions and WikiSQL. Such transformers are frequently\npre-trained on open-domain content such as Wikipedia, where they effectively\nencode questions and corresponding tables from Wikipedia as seen in Table QA\ndataset. However, web tables in Wikipedia are notably flat in their layout,\nwith the first row as the sole column header. The layout lends to a relational\nview of tables where each row is a tuple. Whereas, tables in domain-specific\nbusiness or scientific documents often have a much more complex layout,\nincluding hierarchical row and column headers, in addition to having\nspecialized vocabulary terms from that domain.\n  To address this problem, we introduce the domain-specific Table QA dataset\nAIT-QA (Airline Industry Table QA). The dataset consists of 515 questions\nauthored by human annotators on 116 tables extracted from public U.S. SEC\nfilings (publicly available at: https://www.sec.gov/edgar.shtml) of major\nairline companies for the fiscal years 2017-2019. We also provide annotations\npertaining to the nature of questions, marking those that require hierarchical\nheaders, domain-specific terminology, and paraphrased forms. Our zero-shot\nbaseline evaluation of three transformer-based SOTA Table QA methods - TaPAS\n(end-to-end), TaBERT (semantic parsing-based), and RCI (row-column\nencoding-based) - clearly exposes the limitation of these methods in this\npractical setting, with the best accuracy at just 51.8\\% (RCI). We also present\npragmatic table preprocessing steps used to pivot and project these complex\ntables into a layout suitable for the SOTA Table QA models.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 12:14:18 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Katsis", "Yannis", ""], ["Chemmengath", "Saneem", ""], ["Kumar", "Vishwajeet", ""], ["Bharadwaj", "Samarth", ""], ["Canim", "Mustafa", ""], ["Glass", "Michael", ""], ["Gliozzo", "Alfio", ""], ["Pan", "Feifei", ""], ["Sen", "Jaydeep", ""], ["Sankaranarayanan", "Karthik", ""], ["Chakrabarti", "Soumen", ""]]}, {"id": "2106.12967", "submitter": "Sofia Baroncini", "authors": "S. Baroncini (1), M. Daquino (1), F. Tomasi (1) ((1) Department of\n  Classical Philology and Italian Studies, University of Bologna)", "title": "Modelling Art Interpretation and Meaning. A Data Model for Describing\n  Iconology and Iconography", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Iconology is a branch of art history that investigates the meaning of\nartworks in relation to their social and cultural background. Nowadays, several\ninterdisciplinary research fields leverage theoretical frameworks close to\niconology to pursue quantitative Art History with data science methods and\nSemantic Web technologies. However, while Iconographic studies have been\nrecently addressed in ontologies, a complete description of aspects relevant to\niconological studies is still missing. In this article, we present a\npreliminary study on eleven case studies selected from the literature and we\nenvision new terms for extending existing ontologies. We validate new terms\naccording to a common evaluation method and we discuss our results in the light\nof the opportunities that such an extended ontology would arise in the\ncommunity of Digital Art History.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 14:37:58 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Baroncini", "S.", ""], ["Daquino", "M.", ""], ["Tomasi", "F.", ""]]}, {"id": "2106.12970", "submitter": "Badal Soni", "authors": "Badal Soni, Debangan Thakuria, Nilutpal Nath, Navarun Das and\n  Bhaskarananda Boro", "title": "RikoNet: A Novel Anime Recommendation Engine", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anime is quite well-received today, especially among the younger generations.\nWith many genres of available shows, more and more people are increasingly\ngetting attracted to this niche section of the entertainment industry. As anime\nhas recently garnered mainstream attention, we have insufficient information\nregarding users' penchant and watching habits. Therefore, it is an uphill task\nto build a recommendation engine for this relatively obscure entertainment\nmedium. In this attempt, we have built a novel hybrid recommendation system\nthat could act both as a recommendation system and as a means of exploring new\nanime genres and titles. We have analyzed the general trends in this field and\nthe users' watching habits for coming up with our efficacious solution. Our\nsolution employs deep autoencoders for the tasks of predicting ratings and\ngenerating embeddings. Following this, we formed clusters using the embeddings\nof the anime titles. These clusters form the search space for anime with\nsimilarities and are used to find anime similar to the ones liked and disliked\nby the user. This method, combined with the predicted ratings, forms the novel\nhybrid filter. In this article, we have demonstrated this idea and compared the\nperformance of our implemented model with the existing state-of-the-art\ntechniques.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 12:39:48 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Soni", "Badal", ""], ["Thakuria", "Debangan", ""], ["Nath", "Nilutpal", ""], ["Das", "Navarun", ""], ["Boro", "Bhaskarananda", ""]]}, {"id": "2106.12997", "submitter": "Wesley Maddox", "authors": "Wesley J. Maddox, Maximilian Balandat, Andrew Gordon Wilson, Eytan\n  Bakshy", "title": "Bayesian Optimization with High-Dimensional Outputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bayesian Optimization is a sample-efficient black-box optimization procedure\nthat is typically applied to problems with a small number of independent\nobjectives. However, in practice we often wish to optimize objectives defined\nover many correlated outcomes (or ``tasks\"). For example, scientists may want\nto optimize the coverage of a cell tower network across a dense grid of\nlocations. Similarly, engineers may seek to balance the performance of a robot\nacross dozens of different environments via constrained or robust optimization.\nHowever, the Gaussian Process (GP) models typically used as probabilistic\nsurrogates for multi-task Bayesian Optimization scale poorly with the number of\noutcomes, greatly limiting applicability. We devise an efficient technique for\nexact multi-task GP sampling that combines exploiting Kronecker structure in\nthe covariance matrices with Matheron's identity, allowing us to perform\nBayesian Optimization using exact multi-task GP models with tens of thousands\nof correlated outputs. In doing so, we achieve substantial improvements in\nsample efficiency compared to existing approaches that only model aggregate\nfunctions of the outcomes. We demonstrate how this unlocks a new class of\napplications for Bayesian Optimization across a range of tasks in science and\nengineering, including optimizing interference patterns of an optical\ninterferometer with more than 65,000 outputs.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 13:15:12 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Maddox", "Wesley J.", ""], ["Balandat", "Maximilian", ""], ["Wilson", "Andrew Gordon", ""], ["Bakshy", "Eytan", ""]]}, {"id": "2106.13008", "submitter": "Haixu Wu", "authors": "Haixu Wu, Jiehui Xu, Jianmin Wang, Mingsheng Long", "title": "Autoformer: Decomposition Transformers with Auto-Correlation for\n  Long-Term Series Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Extending the forecasting time is a critical demand for real applications,\nsuch as extreme weather early warning and long-term energy consumption\nplanning. This paper studies the \\textit{long-term forecasting} problem of time\nseries. Prior Transformer-based models adopt various self-attention mechanisms\nto discover the long-range dependencies. However, intricate temporal patterns\nof the long-term future prohibit the model from finding reliable dependencies.\nAlso, Transformers have to adopt the sparse versions of point-wise\nself-attentions for long series efficiency, resulting in the information\nutilization bottleneck. Towards these challenges, we propose Autoformer as a\nnovel decomposition architecture with an Auto-Correlation mechanism. We go\nbeyond the pre-processing convention of series decomposition and renovate it as\na basic inner block of deep models. This design empowers Autoformer with\nprogressive decomposition capacities for complex time series. Further, inspired\nby the stochastic process theory, we design the Auto-Correlation mechanism\nbased on the series periodicity, which conducts the dependencies discovery and\nrepresentation aggregation at the sub-series level. Auto-Correlation\noutperforms self-attention in both efficiency and accuracy. In long-term\nforecasting, Autoformer yields state-of-the-art accuracy, with a 38% relative\nimprovement on six benchmarks, covering five practical applications: energy,\ntraffic, economics, weather and disease.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 13:43:43 GMT"}, {"version": "v2", "created": "Sun, 11 Jul 2021 14:13:26 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wu", "Haixu", ""], ["Xu", "Jiehui", ""], ["Wang", "Jianmin", ""], ["Long", "Mingsheng", ""]]}, {"id": "2106.13024", "submitter": "Hongyu Guo", "authors": "Sun Sun and Hongyu Guo", "title": "Symmetric Wasserstein Autoencoders", "comments": "Accepted by UAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging the framework of Optimal Transport, we introduce a new family of\ngenerative autoencoders with a learnable prior, called Symmetric Wasserstein\nAutoencoders (SWAEs). We propose to symmetrically match the joint distributions\nof the observed data and the latent representation induced by the encoder and\nthe decoder. The resulting algorithm jointly optimizes the modelling losses in\nboth the data and the latent spaces with the loss in the data space leading to\nthe denoising effect. With the symmetric treatment of the data and the latent\nrepresentation, the algorithm implicitly preserves the local structure of the\ndata in the latent space. To further improve the quality of the latent\nrepresentation, we incorporate a reconstruction loss into the objective, which\nsignificantly benefits both the generation and reconstruction. We empirically\nshow the superior performance of SWAEs over the state-of-the-art generative\nautoencoders in terms of classification, reconstruction, and generation.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 13:56:02 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Sun", "Sun", ""], ["Guo", "Hongyu", ""]]}, {"id": "2106.13037", "submitter": "Dom Huh", "authors": "Dom Huh", "title": "Mix and Mask Actor-Critic Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Shared feature spaces for actor-critic methods aims to capture generalized\nlatent representations to be used by the policy and value function with the\nhopes for a more stable and sample-efficient optimization. However, such a\nparadigm present a number of challenges in practice, as parameters generating a\nshared representation must learn off two distinct objectives, resulting in\ncompeting updates and learning perturbations. In this paper, we present a novel\nfeature-sharing framework to address these difficulties by introducing the mix\nand mask mechanisms and the distributional scalarization technique. These\nmechanisms behaves dynamically to couple and decouple connected latent features\nvariably between the policy and value function, while the distributional\nscalarization standardizes the two objectives using a probabilistic standpoint.\nFrom our experimental results, we demonstrate significant performance\nimprovements compared to alternative methods using separate networks and\nnetworks with a shared backbone.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 14:12:45 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Huh", "Dom", ""]]}, {"id": "2106.13052", "submitter": "Lianzhen Wei", "authors": "Lianzhen Wei, Zirui Li, Jianwei Gong, Cheng Gong, Jiachen Li", "title": "Autonomous Driving Strategies at Intersections: Scenarios,\n  State-of-the-Art, and Future Outlooks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the complex and dynamic character of intersection scenarios, the\nautonomous driving strategy at intersections has been a difficult problem and a\nhot point in the research of intelligent transportation systems in recent\nyears. This paper gives a brief summary of state-of-the-art autonomous driving\nstrategies at intersections. Firstly, we enumerate and analyze common types of\nintersection scenarios, corresponding simulation platforms, as well as related\ndatasets. Secondly, by reviewing previous studies, we have summarized\ncharacteristics of existing autonomous driving strategies and classified them\ninto several categories. Finally, we point out problems of the existing\nautonomous driving strategies and put forward several valuable research\noutlooks.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 14:23:00 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 02:15:53 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Wei", "Lianzhen", ""], ["Li", "Zirui", ""], ["Gong", "Jianwei", ""], ["Gong", "Cheng", ""], ["Li", "Jiachen", ""]]}, {"id": "2106.13054", "submitter": "Bruno Escoffier", "authors": "Bruno Escoffier and Olivier Spanjaard and Magdalena Tydrichova", "title": "Kemeny ranking is NP-hard for 2-dimensional Euclidean preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The assumption that voters' preferences share some common structure is a\nstandard way to circumvent NP-hardness results in social choice problems. While\nthe Kemeny ranking problem is NP-hard in the general case, it is known to\nbecome easy if the preferences are 1-dimensional Euclidean. In this note, we\nprove that the Kemeny ranking problem is NP-hard for d-dimensional Euclidean\npreferences with d>=2. We note that this result also holds for the Slater\nranking problem.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 14:25:20 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Escoffier", "Bruno", ""], ["Spanjaard", "Olivier", ""], ["Tydrichova", "Magdalena", ""]]}, {"id": "2106.13061", "submitter": "Jiaqing Xie", "authors": "Jiaqing Xie, Rex Ying", "title": "Fea2Fea: Exploring Structural Feature Correlations via Graph Neural\n  Networks", "comments": "Under review at ECML-PKDD 2021 Graph Embedding and Mining(GEM)\n  workshop; fixed typos in v2; redundant-> non-redundant", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural features are important features in graph datasets. However,\nalthough there are some correlation analysis of features based on covariance,\nthere is no relevant research on exploring structural feature correlation on\ngraphs with graph neural network based models. In this paper, we introduce\ngraph feature to feature (Fea2Fea) prediction pipelines in a low dimensional\nspace to explore some preliminary results on structural feature correlation,\nwhich is based on graph neural network. The results show that there exists high\ncorrelation between some of the structural features. A non-redundant feature\ncombination with initial node features, which is filtered by graph neural\nnetwork has improved its classification accuracy in some graph datasets. We\ncompare the difference between concatenation methods on connecting embeddings\nbetween features and show that the simplest is the best. We generalize on the\nsynthetic geometric graphs and certify the results on prediction difficulty\nbetween two structural features.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 14:36:50 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 01:54:07 GMT"}, {"version": "v3", "created": "Sat, 17 Jul 2021 08:34:13 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Xie", "Jiaqing", ""], ["Ying", "Rex", ""]]}, {"id": "2106.13076", "submitter": "Yuchen Li", "authors": "Yuchen Li, Yifan Bao, Liyao Xiang, Junhan Liu, Cen Chen, Li Wang,\n  Xinbing Wang", "title": "Privacy Threats Analysis to Secure Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning is emerging as a machine learning technique that trains a\nmodel across multiple decentralized parties. It is renowned for preserving\nprivacy as the data never leaves the computational devices, and recent\napproaches further enhance its privacy by hiding messages transferred in\nencryption. However, we found that despite the efforts, federated learning\nremains privacy-threatening, due to its interactive nature across different\nparties. In this paper, we analyze the privacy threats in industrial-level\nfederated learning frameworks with secure computation, and reveal such threats\nwidely exist in typical machine learning models such as linear regression,\nlogistic regression and decision tree. For the linear and logistic regression,\nwe show through theoretical analysis that it is possible for the attacker to\ninvert the entire private input of the victim, given very few information. For\nthe decision tree model, we launch an attack to infer the range of victim's\nprivate inputs. All attacks are evaluated on popular federated learning\nframeworks and real-world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 15:02:54 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Li", "Yuchen", ""], ["Bao", "Yifan", ""], ["Xiang", "Liyao", ""], ["Liu", "Junhan", ""], ["Chen", "Cen", ""], ["Wang", "Li", ""], ["Wang", "Xinbing", ""]]}, {"id": "2106.13083", "submitter": "Stefano Forti", "authors": "Giuseppe Bisicchia, Stefano Forti, Antonio Brogi", "title": "A Declarative Goal-oriented Framework for Smart Environments with LPaaS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart environments powered by the Internet of Things aim at improving our\ndaily lives by automatically tuning ambient parameters (e.g. temperature,\ninterior light) and by achieving energy savings through self-managing\ncyber-physical systems. Commercial solutions, however, only permit setting\nsimple target goals on those parameters and do not consider mediating\nconflicting goals among different users and/or system administrators, and\nfeature limited compatibility across different IoT verticals. In this article,\nwe propose a declarative framework to represent smart environments, user-set\ngoals and customisable mediation policies to reconcile contrasting goals\nencompassing multiple IoT systems. An open-source Prolog prototype of the\nframework is showcased over two lifelike motivating examples.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 14:03:20 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Bisicchia", "Giuseppe", ""], ["Forti", "Stefano", ""], ["Brogi", "Antonio", ""]]}, {"id": "2106.13085", "submitter": "Itai Orr", "authors": "Itai Orr, Moshik Cohen, Harel Damari, Meir Halachmi, Zeev Zalevsky", "title": "Coherent, super resolved radar beamforming using self-supervised\n  learning", "comments": "28 pages 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  High resolution automotive radar sensors are required in order to meet the\nhigh bar of autonomous vehicles needs and regulations. However, current radar\nsystems are limited in their angular resolution causing a technological gap. An\nindustry and academic trend to improve angular resolution by increasing the\nnumber of physical channels, also increases system complexity, requires\nsensitive calibration processes, lowers robustness to hardware malfunctions and\ndrives higher costs. We offer an alternative approach, named Radar signal\nReconstruction using Self Supervision (R2-S2), which significantly improves the\nangular resolution of a given radar array without increasing the number of\nphysical channels. R2-S2 is a family of algorithms which use a Deep Neural\nNetwork (DNN) with complex range-Doppler radar data as input and trained in a\nself-supervised method using a loss function which operates in multiple data\nrepresentation spaces. Improvement of 4x in angular resolution was demonstrated\nusing a real-world dataset collected in urban and highway environments during\nclear and rainy weather conditions.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 16:59:55 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Orr", "Itai", ""], ["Cohen", "Moshik", ""], ["Damari", "Harel", ""], ["Halachmi", "Meir", ""], ["Zalevsky", "Zeev", ""]]}, {"id": "2106.13093", "submitter": "Xianlong Zeng", "authors": "Xianlong Zeng, Fanghao Song, Zhongen Li, Krerkkiat Chusap, Chang Liu", "title": "Human-in-the-loop model explanation via verbatim boundary identification\n  in generated neighborhoods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The black-box nature of machine learning models limits their use in\ncase-critical applications, raising faithful and ethical concerns that lead to\ntrust crises. One possible way to mitigate this issue is to understand how a\n(mispredicted) decision is carved out from the decision boundary. This paper\npresents a human-in-the-loop approach to explain machine learning models using\nverbatim neighborhood manifestation. Contrary to most of the current\neXplainable Artificial Intelligence (XAI) systems, which provide hit-or-miss\napproximate explanations, our approach generates the local decision boundary of\nthe given instance and enables human intelligence to conclude the model\nbehavior. Our method can be divided into three stages: 1) a neighborhood\ngeneration stage, which generates instances based on the given sample; 2) a\nclassification stage, which yields classifications on the generated instances\nto carve out the local decision boundary and delineate the model behavior; and\n3) a human-in-the-loop stage, which involves human to refine and explore the\nneighborhood of interest. In the generation stage, a generative model is used\nto generate the plausible synthetic neighbors around the given instance. After\nthe classification stage, the classified neighbor instances provide a\nmultifaceted understanding of the model behavior. Three intervention points are\nprovided in the human-in-the-loop stage, enabling humans to leverage their own\nintelligence to interpret the model behavior. Several experiments on two\ndatasets are conducted, and the experimental results demonstrate the potential\nof our proposed approach for boosting human understanding of the complex\nmachine learning model.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 15:24:30 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Zeng", "Xianlong", ""], ["Song", "Fanghao", ""], ["Li", "Zhongen", ""], ["Chusap", "Krerkkiat", ""], ["Liu", "Chang", ""]]}, {"id": "2106.13095", "submitter": "Xianlong Zeng", "authors": "Xianlong Zeng, Simon Lin, and Chang Liu", "title": "Pre-training transformer-based framework on large-scale pediatric claims\n  data for downstream population-specific tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The adoption of electronic health records (EHR) has become universal during\nthe past decade, which has afforded in-depth data-based research. By learning\nfrom the large amount of healthcare data, various data-driven models have been\nbuilt to predict future events for different medical tasks, such as auto\ndiagnosis and heart-attack prediction. Although EHR is abundant, the population\nthat satisfies specific criteria for learning population-specific tasks is\nscarce, making it challenging to train data-hungry deep learning models. This\nstudy presents the Claim Pre-Training (Claim-PT) framework, a generic\npre-training model that first trains on the entire pediatric claims dataset,\nfollowed by a discriminative fine-tuning on each population-specific task. The\nsemantic meaning of medical events can be captured in the pre-training stage,\nand the effective knowledge transfer is completed through the task-aware\nfine-tuning stage. The fine-tuning process requires minimal parameter\nmodification without changing the model architecture, which mitigates the data\nscarcity issue and helps train the deep learning model adequately on small\npatient cohorts. We conducted experiments on a real-world claims dataset with\nmore than one million patient records. Experimental results on two downstream\ntasks demonstrated the effectiveness of our method: our general task-agnostic\npre-training framework outperformed tailored task-specific models, achieving\nmore than 10\\% higher in model performance as compared to baselines. In\naddition, our framework showed a great generalizability potential to transfer\nlearned knowledge from one institution to another, paving the way for future\nhealthcare model pre-training across institutions.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 15:25:41 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Zeng", "Xianlong", ""], ["Lin", "Simon", ""], ["Liu", "Chang", ""]]}, {"id": "2106.13105", "submitter": "Andr\\'e Barreto", "authors": "Andr\\'e Barreto, Diana Borsa, Shaobo Hou, Gheorghe Comanici, Eser\n  Ayg\\\"un, Philippe Hamel, Daniel Toyama, Jonathan Hunt, Shibl Mourad, David\n  Silver, Doina Precup", "title": "The Option Keyboard: Combining Skills in Reinforcement Learning", "comments": "Published at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to combine known skills to create new ones may be crucial in the\nsolution of complex reinforcement learning problems that unfold over extended\nperiods. We argue that a robust way of combining skills is to define and\nmanipulate them in the space of pseudo-rewards (or \"cumulants\"). Based on this\npremise, we propose a framework for combining skills using the formalism of\noptions. We show that every deterministic option can be unambiguously\nrepresented as a cumulant defined in an extended domain. Building on this\ninsight and on previous results on transfer learning, we show how to\napproximate options whose cumulants are linear combinations of the cumulants of\nknown options. This means that, once we have learned options associated with a\nset of cumulants, we can instantaneously synthesise options induced by any\nlinear combination of them, without any learning involved. We describe how this\nframework provides a hierarchical interface to the environment whose abstract\nactions correspond to combinations of basic skills. We demonstrate the\npractical benefits of our approach in a resource management problem and a\nnavigation task involving a quadrupedal simulated robot.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 15:40:57 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Barreto", "Andr\u00e9", ""], ["Borsa", "Diana", ""], ["Hou", "Shaobo", ""], ["Comanici", "Gheorghe", ""], ["Ayg\u00fcn", "Eser", ""], ["Hamel", "Philippe", ""], ["Toyama", "Daniel", ""], ["Hunt", "Jonathan", ""], ["Mourad", "Shibl", ""], ["Silver", "David", ""], ["Precup", "Doina", ""]]}, {"id": "2106.13121", "submitter": "Kwan Hui Lim Dr", "authors": "Yasmeen George, Shanika Karunasekera, Aaron Harwood and Kwan Hui Lim", "title": "Real-time Spatio-temporal Event Detection on Geotagged Social Media", "comments": "Accepted to Journal of Big Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A key challenge in mining social media data streams is to identify events\nwhich are actively discussed by a group of people in a specific local or global\narea. Such events are useful for early warning for accident, protest, election\nor breaking news. However, neither the list of events nor the resolution of\nboth event time and space is fixed or known beforehand. In this work, we\npropose an online spatio-temporal event detection system using social media\nthat is able to detect events at different time and space resolutions. First,\nto address the challenge related to the unknown spatial resolution of events, a\nquad-tree method is exploited in order to split the geographical space into\nmultiscale regions based on the density of social media data. Then, a\nstatistical unsupervised approach is performed that involves Poisson\ndistribution and a smoothing method for highlighting regions with unexpected\ndensity of social posts. Further, event duration is precisely estimated by\nmerging events happening in the same region at consecutive time intervals. A\npost processing stage is introduced to filter out events that are spam, fake or\nwrong. Finally, we incorporate simple semantics by using social media entities\nto assess the integrity, and accuracy of detected events. The proposed method\nis evaluated using different social media datasets: Twitter and Flickr for\ndifferent cities: Melbourne, London, Paris and New York. To verify the\neffectiveness of the proposed method, we compare our results with two baseline\nalgorithms based on fixed split of geographical space and clustering method.\nFor performance evaluation, we manually compute recall and precision. We also\npropose a new quality measure named strength index, which automatically\nmeasures how accurate the reported event is.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 07:14:03 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["George", "Yasmeen", ""], ["Karunasekera", "Shanika", ""], ["Harwood", "Aaron", ""], ["Lim", "Kwan Hui", ""]]}, {"id": "2106.13186", "submitter": "Daniel P. Lopresti", "authors": "Nadya Bliss, Mark Briers, Alice Eckstein, James Goulding, Daniel P.\n  Lopresti, Anjali Mazumder, and Gavin Smith", "title": "CCC/Code 8.7: Applying AI in the Fight Against Modern Slavery", "comments": "A Computing Community Consortium (CCC) workshop report, 24 pages", "journal-ref": null, "doi": null, "report-no": "ccc2021report_1", "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  On any given day, tens of millions of people find themselves trapped in\ninstances of modern slavery. The terms \"human trafficking,\" \"trafficking in\npersons,\" and \"modern slavery\" are sometimes used interchangeably to refer to\nboth sex trafficking and forced labor. Human trafficking occurs when a\ntrafficker compels someone to provide labor or services through the use of\nforce, fraud, and/or coercion. The wide range of stakeholders in human\ntrafficking presents major challenges. Direct stakeholders are law enforcement,\nNGOs and INGOs, businesses, local/planning government authorities, and\nsurvivors. Viewed from a very high level, all stakeholders share in a rich\nnetwork of interactions that produce and consume enormous amounts of\ninformation. The problems of making efficient use of such information for the\npurposes of fighting trafficking while at the same time adhering to community\nstandards of privacy and ethics are formidable. At the same time they help us,\ntechnologies that increase surveillance of populations can also undermine basic\nhuman rights.\n  In early March 2020, the Computing Community Consortium (CCC), in\ncollaboration with the Code 8.7 Initiative, brought together over fifty members\nof the computing research community along with anti-slavery practitioners and\nsurvivors to lay out a research roadmap. The primary goal was to explore ways\nin which long-range research in artificial intelligence (AI) could be applied\nto the fight against human trafficking. Building on the kickoff Code 8.7\nconference held at the headquarters of the United Nations in February 2019, the\nfocus for this workshop was to link the ambitious goals outlined in the A\n20-Year Community Roadmap for Artificial Intelligence Research in the US (AI\nRoadmap) to challenges vital in achieving the UN's Sustainable Development Goal\nTarget 8.7, the elimination of modern slavery.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 17:07:56 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Bliss", "Nadya", ""], ["Briers", "Mark", ""], ["Eckstein", "Alice", ""], ["Goulding", "James", ""], ["Lopresti", "Daniel P.", ""], ["Mazumder", "Anjali", ""], ["Smith", "Gavin", ""]]}, {"id": "2106.13213", "submitter": "Paul Pu Liang", "authors": "Paul Pu Liang, Terrance Liu, Anna Cai, Michal Muszynski, Ryo Ishii,\n  Nicholas Allen, Randy Auerbach, David Brent, Ruslan Salakhutdinov,\n  Louis-Philippe Morency", "title": "Learning Language and Multimodal Privacy-Preserving Markers of Mood from\n  Mobile Data", "comments": "ACL 2021. arXiv admin note: substantial text overlap with\n  arXiv:2012.02359", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mental health conditions remain underdiagnosed even in countries with common\naccess to advanced medical care. The ability to accurately and efficiently\npredict mood from easily collectible data has several important implications\nfor the early detection, intervention, and treatment of mental health\ndisorders. One promising data source to help monitor human behavior is daily\nsmartphone usage. However, care must be taken to summarize behaviors without\nidentifying the user through personal (e.g., personally identifiable\ninformation) or protected (e.g., race, gender) attributes. In this paper, we\nstudy behavioral markers of daily mood using a recent dataset of mobile\nbehaviors from adolescent populations at high risk of suicidal behaviors. Using\ncomputational models, we find that language and multimodal representations of\nmobile typed text (spanning typed characters, words, keystroke timings, and app\nusage) are predictive of daily mood. However, we find that models trained to\npredict mood often also capture private user identities in their intermediate\nrepresentations. To tackle this problem, we evaluate approaches that obfuscate\nuser identity while remaining predictive. By combining multimodal\nrepresentations with privacy-preserving learning, we are able to push forward\nthe performance-privacy frontier.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 17:46:03 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Liang", "Paul Pu", ""], ["Liu", "Terrance", ""], ["Cai", "Anna", ""], ["Muszynski", "Michal", ""], ["Ishii", "Ryo", ""], ["Allen", "Nicholas", ""], ["Auerbach", "Randy", ""], ["Brent", "David", ""], ["Salakhutdinov", "Ruslan", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "2106.13219", "submitter": "Paul Pu Liang", "authors": "Paul Pu Liang, Chiyu Wu, Louis-Philippe Morency, Ruslan Salakhutdinov", "title": "Towards Understanding and Mitigating Social Biases in Language Models", "comments": "ICML 2021, code available at https://github.com/pliang279/LM_bias", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning methods are deployed in real-world settings such as\nhealthcare, legal systems, and social science, it is crucial to recognize how\nthey shape social biases and stereotypes in these sensitive decision-making\nprocesses. Among such real-world deployments are large-scale pretrained\nlanguage models (LMs) that can be potentially dangerous in manifesting\nundesirable representational biases - harmful biases resulting from\nstereotyping that propagate negative generalizations involving gender, race,\nreligion, and other social constructs. As a step towards improving the fairness\nof LMs, we carefully define several sources of representational biases before\nproposing new benchmarks and metrics to measure them. With these tools, we\npropose steps towards mitigating social biases during text generation. Our\nempirical results and human evaluation demonstrate effectiveness in mitigating\nbias while retaining crucial contextual information for high-fidelity text\ngeneration, thereby pushing forward the performance-fairness Pareto frontier.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 17:52:43 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Liang", "Paul Pu", ""], ["Wu", "Chiyu", ""], ["Morency", "Louis-Philippe", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "2106.13229", "submitter": "Oleh Rybkin", "authors": "Oleh Rybkin, Chuning Zhu, Anusha Nagabandi, Kostas Daniilidis, Igor\n  Mordatch, Sergey Levine", "title": "Model-Based Reinforcement Learning via Latent-Space Collocation", "comments": "International Conference on Machine Learning (ICML), 2021. Videos and\n  code at https://orybkin.github.io/latco/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to plan into the future while utilizing only raw high-dimensional\nobservations, such as images, can provide autonomous agents with broad\ncapabilities. Visual model-based reinforcement learning (RL) methods that plan\nfuture actions directly have shown impressive results on tasks that require\nonly short-horizon reasoning, however, these methods struggle on temporally\nextended tasks. We argue that it is easier to solve long-horizon tasks by\nplanning sequences of states rather than just actions, as the effects of\nactions greatly compound over time and are harder to optimize. To achieve this,\nwe draw on the idea of collocation, which has shown good results on\nlong-horizon tasks in optimal control literature, and adapt it to the\nimage-based setting by utilizing learned latent state space models. The\nresulting latent collocation method (LatCo) optimizes trajectories of latent\nstates, which improves over previously proposed shooting methods for visual\nmodel-based RL on tasks with sparse rewards and long-term goals. Videos and\ncode at https://orybkin.github.io/latco/.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 17:59:18 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Rybkin", "Oleh", ""], ["Zhu", "Chuning", ""], ["Nagabandi", "Anusha", ""], ["Daniilidis", "Kostas", ""], ["Mordatch", "Igor", ""], ["Levine", "Sergey", ""]]}, {"id": "2106.13230", "submitter": "Yue Cao", "authors": "Ze Liu, Jia Ning, Yue Cao, Yixuan Wei, Zheng Zhang, Stephen Lin, Han\n  Hu", "title": "Video Swin Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The vision community is witnessing a modeling shift from CNNs to\nTransformers, where pure Transformer architectures have attained top accuracy\non the major video recognition benchmarks. These video models are all built on\nTransformer layers that globally connect patches across the spatial and\ntemporal dimensions. In this paper, we instead advocate an inductive bias of\nlocality in video Transformers, which leads to a better speed-accuracy\ntrade-off compared to previous approaches which compute self-attention globally\neven with spatial-temporal factorization. The locality of the proposed video\narchitecture is realized by adapting the Swin Transformer designed for the\nimage domain, while continuing to leverage the power of pre-trained image\nmodels. Our approach achieves state-of-the-art accuracy on a broad range of\nvideo recognition benchmarks, including on action recognition (84.9 top-1\naccuracy on Kinetics-400 and 86.1 top-1 accuracy on Kinetics-600 with ~20x less\npre-training data and ~3x smaller model size) and temporal modeling (69.6 top-1\naccuracy on Something-Something v2). The code and models will be made publicly\navailable at https://github.com/SwinTransformer/Video-Swin-Transformer.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 17:59:46 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Liu", "Ze", ""], ["Ning", "Jia", ""], ["Cao", "Yue", ""], ["Wei", "Yixuan", ""], ["Zhang", "Zheng", ""], ["Lin", "Stephen", ""], ["Hu", "Han", ""]]}, {"id": "2106.13233", "submitter": "Juyang Weng", "authors": "Juyang Weng", "title": "Post Selections Using Test Sets (PSUTS) and How Developmental Networks\n  Avoid Them", "comments": "13 pages, 2 figures. The first part has been accepted as an IJCNN\n  2021 paper and the second has been accepted as an ICDL 2021 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper raises a rarely reported practice in Artificial Intelligence (AI)\ncalled Post Selection Using Test Sets (PSUTS). Consequently, the popular\nerror-backprop methodology in deep learning lacks an acceptable generalization\npower. All AI methods fall into two broad schools, connectionist and symbolic.\nThe PSUTS fall into two kinds, machine PSUTS and human PSUTS. The connectionist\nschool received criticisms for its \"scruffiness\" due to a huge number of\nnetwork parameters and now the worse machine PSUTS; but the seemingly \"clean\"\nsymbolic school seems more brittle because of a weaker generalization power\nusing human PSUTS. This paper formally defines what PSUTS is, analyzes why\nerror-backprop methods with random initial weights suffer from severe local\nminima, why PSUTS violates well-established research ethics, and how every\npaper that used PSUTS should have at least transparently reported PSUTS. For\nimproved transparency in future publications, this paper proposes a new\nstandard for performance evaluation of AI, called developmental errors for all\nnetworks trained, along with Three Learning Conditions: (1) an incremental\nlearning architecture, (2) a training experience and (3) a limited amount of\ncomputational resources. Developmental Networks avoid PSUTS and are not\n\"scruffy\" because they drive Emergent Turing Machines and are optimal in the\nsense of maximum-likelihood across lifetime.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 22:22:04 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Weng", "Juyang", ""]]}, {"id": "2106.13237", "submitter": "Yulun Zhang", "authors": "K.R. Zentner, Ryan Julian, Ujjwal Puri, Yulun Zhang, Gaurav Sukhatme", "title": "Towards Exploiting Geometry and Time for Fast Off-Distribution\n  Adaptation in Multi-Task Robot Learning", "comments": "Accepted to Challenges of Real World Reinforcement Learning, Virtual\n  Workshop at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore possible methods for multi-task transfer learning which seek to\nexploit the shared physical structure of robotics tasks. Specifically, we train\npolicies for a base set of pre-training tasks, then experiment with adapting to\nnew off-distribution tasks, using simple architectural approaches for re-using\nthese policies as black-box priors. These approaches include learning an\nalignment of either the observation space or action space from a base to a\ntarget task to exploit rigid body structure, and methods for learning a\ntime-domain switching policy across base tasks which solves the target task, to\nexploit temporal coherence. We find that combining low-complexity target policy\nclasses, base policies as black-box priors, and simple optimization algorithms\nallows us to acquire new tasks outside the base task distribution, using small\namounts of offline training data.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 02:13:50 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 06:23:14 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Zentner", "K. R.", ""], ["Julian", "Ryan", ""], ["Puri", "Ujjwal", ""], ["Zhang", "Yulun", ""], ["Sukhatme", "Gaurav", ""]]}, {"id": "2106.13239", "submitter": "Huazhu Fu", "authors": "Li Li, Huazhu Fu, Bo Han, Cheng-Zhong Xu, Ling Shao", "title": "Federated Noisy Client Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) collaboratively aggregates a shared global model\ndepending on multiple local clients, while keeping the training data\ndecentralized in order to preserve data privacy. However, standard FL methods\nignore the noisy client issue, which may harm the overall performance of the\naggregated model. In this paper, we first analyze the noisy client statement,\nand then model noisy clients with different noise distributions (e.g.,\nBernoulli and truncated Gaussian distributions). To learn with noisy clients,\nwe propose a simple yet effective FL framework, named Federated Noisy Client\nLearning (Fed-NCL), which is a plug-and-play algorithm and contains two main\ncomponents: a data quality measurement (DQM) to dynamically quantify the data\nquality of each participating client, and a noise robust aggregation (NRA) to\nadaptively aggregate the local models of each client by jointly considering the\namount of local training data and the data quality of each client. Our Fed-NCL\ncan be easily applied in any standard FL workflow to handle the noisy client\nissue. Experimental results on various datasets demonstrate that our algorithm\nboosts the performances of different state-of-the-art systems with noisy\nclients.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 11:09:17 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Li", "Li", ""], ["Fu", "Huazhu", ""], ["Han", "Bo", ""], ["Xu", "Cheng-Zhong", ""], ["Shao", "Ling", ""]]}, {"id": "2106.13241", "submitter": "Fabien Paillusson", "authors": "Matthew Booth and Fabien Paillusson", "title": "A fuzzy take on the logical issues of statistical hypothesis testing", "comments": "15 pages, 3 figures. Preprint version of an amended version of the\n  article published in Philosophies 2021, 6(1), 21", "journal-ref": null, "doi": "10.3390/philosophies6010021", "report-no": null, "categories": "cs.AI physics.hist-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Statistical Hypothesis Testing (SHT) is a class of inference methods whereby\none makes use of empirical data to test a hypothesis and often emit a judgment\nabout whether to reject it or not. In this paper we focus on the logical aspect\nof this strategy, which is largely independent of the adopted school of\nthought, at least within the various frequentist approaches. We identify SHT as\ntaking the form of an unsound argument from Modus Tollens in classical logic,\nand, in order to rescue SHT from this difficulty, we propose that it can\ninstead be grounded in t-norm based fuzzy logics. We reformulate the\nfrequentists' SHT logic by making use of a fuzzy extension of modus Tollens to\ndevelop a model of truth valuation for its premises. Importantly, we show that\nit is possible to preserve the soundness of Modus Tollens by exploring the\nvarious conventions involved with constructing fuzzy negations and fuzzy\nimplications (namely, the S and R conventions). We find that under the S\nconvention, it is possible to conduct the Modus Tollens inference argument\nusing Zadeh's compositional extension and any possible t-norm. Under the R\nconvention we find that this is not necessarily the case, but that by mixing\nR-implication with S-negation we can salvage the product t-norm, for example.\nIn conclusion, we have shown that fuzzy logic is a legitimate framework to\ndiscuss and address the difficulties plaguing frequentist interpretations of\nSHT.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 15:33:43 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Booth", "Matthew", ""], ["Paillusson", "Fabien", ""]]}, {"id": "2106.13249", "submitter": "Tan Zhi-Xuan", "authors": "Arwa Alanqary, Gloria Z. Lin, Joie Le, Tan Zhi-Xuan, Vikash K.\n  Mansinghka, Joshua B. Tenenbaum", "title": "Modeling the Mistakes of Boundedly Rational Agents Within a Bayesian\n  Theory of Mind", "comments": "Accepted to CogSci 2021. 6 pages, 5 figures. (Appendix: 1 page, 1\n  figure)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When inferring the goals that others are trying to achieve, people\nintuitively understand that others might make mistakes along the way. This is\ncrucial for activities such as teaching, offering assistance, and deciding\nbetween blame or forgiveness. However, Bayesian models of theory of mind have\ngenerally not accounted for these mistakes, instead modeling agents as mostly\noptimal in achieving their goals. As a result, they are unable to explain\nphenomena like locking oneself out of one's house, or losing a game of chess.\nHere, we extend the Bayesian Theory of Mind framework to model boundedly\nrational agents who may have mistaken goals, plans, and actions. We formalize\nthis by modeling agents as probabilistic programs, where goals may be confused\nwith semantically similar states, plans may be misguided due to\nresource-bounded planning, and actions may be unintended due to execution\nerrors. We present experiments eliciting human goal inferences in two domains:\n(i) a gridworld puzzle with gems locked behind doors, and (ii) a block-stacking\ndomain. Our model better explains human inferences than alternatives, while\ngeneralizing across domains. These findings indicate the importance of modeling\nothers as bounded agents, in order to account for the full richness of human\nintuitive psychology.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 18:00:03 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Alanqary", "Arwa", ""], ["Lin", "Gloria Z.", ""], ["Le", "Joie", ""], ["Zhi-Xuan", "Tan", ""], ["Mansinghka", "Vikash K.", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "2106.13264", "submitter": "Jianhao Peng", "authors": "Eli Chien, Chao Pan, Jianhao Peng, Olgica Milenkovic", "title": "You are AllSet: A Multiset Function Framework for Hypergraph Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hypergraphs are used to model higher-order interactions amongst agents and\nthere exist many practically relevant instances of hypergraph datasets. To\nenable efficient processing of hypergraph-structured data, several hypergraph\nneural network platforms have been proposed for learning hypergraph properties\nand structure, with a special focus on node classification. However, almost all\nexisting methods use heuristic propagation rules and offer suboptimal\nperformance on many datasets. We propose AllSet, a new hypergraph neural\nnetwork paradigm that represents a highly general framework for (hyper)graph\nneural networks and for the first time implements hypergraph neural network\nlayers as compositions of two multiset functions that can be efficiently\nlearned for each task and each dataset. Furthermore, AllSet draws on new\nconnections between hypergraph neural networks and recent advances in deep\nlearning of multiset functions. In particular, the proposed architecture\nutilizes Deep Sets and Set Transformer architectures that allow for significant\nmodeling flexibility and offer high expressive power. To evaluate the\nperformance of AllSet, we conduct the most extensive experiments to date\ninvolving ten known benchmarking datasets and three newly curated datasets that\nrepresent significant challenges for hypergraph node classification. The\nresults demonstrate that AllSet has the unique ability to consistently either\nmatch or outperform all other hypergraph neural networks across the tested\ndatasets. Our implementation and dataset will be released upon acceptance.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 18:10:08 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Chien", "Eli", ""], ["Pan", "Chao", ""], ["Peng", "Jianhao", ""], ["Milenkovic", "Olgica", ""]]}, {"id": "2106.13280", "submitter": "Katie Kang", "authors": "Katie Kang, Gregory Kahn, Sergey Levine", "title": "Multi-Robot Deep Reinforcement Learning for Mobile Navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning algorithms require large and diverse datasets in\norder to learn successful policies for perception-based mobile navigation.\nHowever, gathering such datasets with a single robot can be prohibitively\nexpensive. Collecting data with multiple different robotic platforms with\npossibly different dynamics is a more scalable approach to large-scale data\ncollection. But how can deep reinforcement learning algorithms leverage such\nheterogeneous datasets? In this work, we propose a deep reinforcement learning\nalgorithm with hierarchically integrated models (HInt). At training time, HInt\nlearns separate perception and dynamics models, and at test time, HInt\nintegrates the two models in a hierarchical manner and plans actions with the\nintegrated model. This method of planning with hierarchically integrated models\nallows the algorithm to train on datasets gathered by a variety of different\nplatforms, while respecting the physical capabilities of the deployment robot\nat test time. Our mobile navigation experiments show that HInt outperforms\nconventional hierarchical policies and single-source approaches.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 19:07:40 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Kang", "Katie", ""], ["Kahn", "Gregory", ""], ["Levine", "Sergey", ""]]}, {"id": "2106.13281", "submitter": "Daniel Freeman", "authors": "C. Daniel Freeman, Erik Frey, Anton Raichuk, Sertan Girgin, Igor\n  Mordatch, Olivier Bachem", "title": "Brax -- A Differentiable Physics Engine for Large Scale Rigid Body\n  Simulation", "comments": "9 pages + 12 pages of appendices and references. In submission at\n  NeurIPS 2021 Datasets and Benchmarks Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present Brax, an open source library for rigid body simulation with a\nfocus on performance and parallelism on accelerators, written in JAX. We\npresent results on a suite of tasks inspired by the existing reinforcement\nlearning literature, but remade in our engine. Additionally, we provide\nreimplementations of PPO, SAC, ES, and direct policy optimization in JAX that\ncompile alongside our environments, allowing the learning algorithm and the\nenvironment processing to occur on the same device, and to scale seamlessly on\naccelerators. Finally, we include notebooks that facilitate training of\nperformant policies on common OpenAI Gym MuJoCo-like tasks in minutes.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 19:09:12 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Freeman", "C. Daniel", ""], ["Frey", "Erik", ""], ["Raichuk", "Anton", ""], ["Girgin", "Sertan", ""], ["Mordatch", "Igor", ""], ["Bachem", "Olivier", ""]]}, {"id": "2106.13314", "submitter": "Justin Clark", "authors": "Anita Mahinpei, Justin Clark, Isaac Lage, Finale Doshi-Velez, Weiwei\n  Pan", "title": "Promises and Pitfalls of Black-Box Concept Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning models that incorporate concept learning as an intermediate\nstep in their decision making process can match the performance of black-box\npredictive models while retaining the ability to explain outcomes in human\nunderstandable terms. However, we demonstrate that the concept representations\nlearned by these models encode information beyond the pre-defined concepts, and\nthat natural mitigation strategies do not fully work, rendering the\ninterpretation of the downstream prediction misleading. We describe the\nmechanism underlying the information leakage and suggest recourse for\nmitigating its effects.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 21:00:28 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Mahinpei", "Anita", ""], ["Clark", "Justin", ""], ["Lage", "Isaac", ""], ["Doshi-Velez", "Finale", ""], ["Pan", "Weiwei", ""]]}, {"id": "2106.13319", "submitter": "Rui Yao", "authors": "Rui Yao, Shlomo Bekhor", "title": "A variational autoencoder approach for choice set generation and\n  implicit perception of alternatives in choice modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG physics.soc-ph stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper derives the generalized extreme value (GEV) model with implicit\navailability/perception (IAP) of alternatives and proposes a variational\nautoencoder (VAE) approach for choice set generation and implicit perception of\nalternatives. Specifically, the cross-nested logit (CNL) model with IAP is\nderived as an example of IAP-GEV models. The VAE approach is adapted to model\nthe choice set generation process, in which the likelihood of perceiving chosen\nalternatives in the choice set is maximized. The VAE approach for route choice\nset generation is exemplified using a real dataset. IAP- CNL model estimated\nhas the best performance in terms of goodness-of-fit and prediction\nperformance, compared to multinomial logit models and conventional choice set\ngeneration methods.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 00:52:49 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Yao", "Rui", ""], ["Bekhor", "Shlomo", ""]]}, {"id": "2106.13320", "submitter": "Irina Basieva Dr", "authors": "Irina Basieva, Vijitashwa Pandey, Polina Khrennikova", "title": "More Causes Less Effect: Destructive Interference in Decision Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new experiment demonstrating destructive interference in\ncustomers' estimates of conditional probabilities of product failure. We take\nthe perspective of a manufacturer of consumer products, and consider two\nsituations of cause and effect. Whereas individually the effect of the causes\nis similar, it is observed that when combined, the two causes produce the\nopposite effect. Such negative interference of two or more reasons may be\nexploited for better modeling the cognitive processes taking place in the\ncustomers' mind. Doing so can enhance the likelihood that a manufacturer will\nbe able to design a better product, or a feature within it. Quantum probability\nhas been used to explain some commonly observed deviations such as question\norder and response replicability effects, as well as in explaining paradoxes\nsuch as violations of the sure-thing principle, and Machina and Ellsberg\nparadoxes. In this work, we present results from a survey conducted regarding\nthe effect of multiple observed symptoms on the drivability of a vehicle. We\ndemonstrate that the set of responses cannot be explained using classical\nprobability, but quantum formulation easily models it, as it allows for both\npositive and negative \"interference\" between events. Since quantum formulism\nalso accounts for classical probability's predictions, it serves as a richer\nparadigm for modeling decision making behavior in engineering design and\nbehavioral economics.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 13:34:19 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Basieva", "Irina", ""], ["Pandey", "Vijitashwa", ""], ["Khrennikova", "Polina", ""]]}, {"id": "2106.13322", "submitter": "Saveli Goldberg", "authors": "Saveli Goldberg (1), Stanislav Belyaev (2), Vladimir Sluchak ((1) MGH\n  Radiation Oncology Department, (2) Eastern New Mexico Medical Center)", "title": "Dr. Watson type Artificial Intellect (AI) Systems", "comments": "24 pages,13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The article proposes a new type of AI system that does not give solutions\ndirectly but rather points toward it, friendly prompting the user with\nquestions and adjusting messages. Models of AI human collaboration can be\ndeduced from the classic literary example of interaction between Mr. Holmes and\nDr. Watson from the stories by Conan Doyle, where the highly qualified expert\nMr. Holmes answers questions posed by Dr. Watson. Here Mr. Holmes, with his\nrule-based calculations, logic, and memory management, apparently plays the\nrole of an AI system, and Dr. Watson is the user. Looking into the same\nHolmes-Watson interaction, we find and promote another model in which the AI\nbehaves like Dr. Watson, who, by asking questions and acting in a particular\nway, helps Holmes (the AI user) make the right decisions. We call the systems\nbased on this principle \"Dr. Watson-type systems.\" The article describes the\nproperties of such systems and introduces two particular: Patient Management\nSystem for intensive care physicians and Data Error Prevention System.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 03:59:39 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Goldberg", "Saveli", ""], ["Belyaev", "Stanislav", ""], ["Sluchak", "Vladimir", ""]]}, {"id": "2106.13346", "submitter": "Jessica Dai", "authors": "Jessica Dai, Sohini Upadhyay, Stephen H. Bach, Himabindu Lakkaraju", "title": "What will it take to generate fairness-preserving explanations?", "comments": "Presented at ICML 2021 Workshop on Theoretic Foundation, Criticism,\n  and Application Trend of Explainable AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In situations where explanations of black-box models may be useful, the\nfairness of the black-box is also often a relevant concern. However, the link\nbetween the fairness of the black-box model and the behavior of explanations\nfor the black-box is unclear. We focus on explanations applied to tabular\ndatasets, suggesting that explanations do not necessarily preserve the fairness\nproperties of the black-box algorithm. In other words, explanation algorithms\ncan ignore or obscure critical relevant properties, creating incorrect or\nmisleading explanations. More broadly, we propose future research directions\nfor evaluating and generating explanations such that they are informative and\nrelevant from a fairness perspective.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 23:03:25 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Dai", "Jessica", ""], ["Upadhyay", "Sohini", ""], ["Bach", "Stephen H.", ""], ["Lakkaraju", "Himabindu", ""]]}, {"id": "2106.13364", "submitter": "Daniel McDuff", "authors": "Daniel McDuff, Yale Song, Jiyoung Lee, Vibhav Vineet, Sai Vemprala,\n  Nicholas Gyde, Hadi Salman, Shuang Ma, Kwanghoon Sohn and Ashish Kapoor", "title": "CausalCity: Complex Simulations with Agency for Causal Discovery and\n  Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to perform causal and counterfactual reasoning are central\nproperties of human intelligence. Decision-making systems that can perform\nthese types of reasoning have the potential to be more generalizable and\ninterpretable. Simulations have helped advance the state-of-the-art in this\ndomain, by providing the ability to systematically vary parameters (e.g.,\nconfounders) and generate examples of the outcomes in the case of\ncounterfactual scenarios. However, simulating complex temporal causal events in\nmulti-agent scenarios, such as those that exist in driving and vehicle\nnavigation, is challenging. To help address this, we present a high-fidelity\nsimulation environment that is designed for developing algorithms for causal\ndiscovery and counterfactual reasoning in the safety-critical context. A core\ncomponent of our work is to introduce \\textit{agency}, such that it is simple\nto define and create complex scenarios using high-level definitions. The\nvehicles then operate with agency to complete these objectives, meaning\nlow-level behaviors need only be controlled if necessary. We perform\nexperiments with three state-of-the-art methods to create baselines and\nhighlight the affordances of this environment. Finally, we highlight challenges\nand opportunities for future work.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 00:21:41 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["McDuff", "Daniel", ""], ["Song", "Yale", ""], ["Lee", "Jiyoung", ""], ["Vineet", "Vibhav", ""], ["Vemprala", "Sai", ""], ["Gyde", "Nicholas", ""], ["Salman", "Hadi", ""], ["Ma", "Shuang", ""], ["Sohn", "Kwanghoon", ""], ["Kapoor", "Ashish", ""]]}, {"id": "2106.13367", "submitter": "Qianru Zhou", "authors": "Qianru Zhou and Alasdair J.G. Gray and Stephen McLaughlin", "title": "SeaNet -- Towards A Knowledge Graph Based Autonomic Management of\n  Software Defined Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Automatic network management driven by Artificial Intelligent technologies\nhas been heatedly discussed over decades. However, current reports mainly focus\non theoretic proposals and architecture designs, works on practical\nimplementations on real-life networks are yet to appear. This paper proposes\nour effort toward the implementation of knowledge graph driven approach for\nautonomic network management in software defined networks (SDNs), termed as\nSeaNet. Driven by the ToCo ontology, SeaNet is reprogrammed based on Mininet (a\nSDN emulator). It consists three core components, a knowledge graph generator,\na SPARQL engine, and a network management API. The knowledge graph generator\nrepresents the knowledge in the telecommunication network management tasks into\nformally represented ontology driven model. Expert experience and network\nmanagement rules can be formalized into knowledge graph and by automatically\ninferenced by SPARQL engine, Network management API is able to packet\ntechnology-specific details and expose technology-independent interfaces to\nusers. The Experiments are carried out to evaluate proposed work by comparing\nwith a commercial SDN controller Ryu implemented by the same language Python.\nThe evaluation results show that SeaNet is considerably faster in most\ncircumstances than Ryu and the SeaNet code is significantly more compact.\nBenefit from RDF reasoning, SeaNet is able to achieve O(1) time complexity on\ndifferent scales of the knowledge graph while the traditional database can\nachieve O(nlogn) at its best. With the developed network management API, SeaNet\nenables researchers to develop semantic-intelligent applications on their own\nSDNs.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 00:33:42 GMT"}, {"version": "v2", "created": "Mon, 5 Jul 2021 07:31:16 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Zhou", "Qianru", ""], ["Gray", "Alasdair J. G.", ""], ["McLaughlin", "Stephen", ""]]}, {"id": "2106.13393", "submitter": "Xiaofeng Liu", "authors": "Wanqing Xie, Lizhong Liang, Yao Lu, Chen Wang, Jihong Shen, Hui Luo,\n  Xiaofeng Liu", "title": "Interpreting Depression From Question-wise Long-term Video Recording of\n  SDS Evaluation", "comments": "Published in IEEE Journal of Biomedical and Health Informatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-Rating Depression Scale (SDS) questionnaire has frequently been used for\nefficient depression preliminary screening. However, the uncontrollable\nself-administered measure can be easily affected by insouciantly or deceptively\nanswering, and producing the different results with the clinician-administered\nHamilton Depression Rating Scale (HDRS) and the final diagnosis. Clinically,\nfacial expression (FE) and actions play a vital role in clinician-administered\nevaluation, while FE and action are underexplored for self-administered\nevaluations. In this work, we collect a novel dataset of 200 subjects to\nevidence the validity of self-rating questionnaires with their corresponding\nquestion-wise video recording. To automatically interpret depression from the\nSDS evaluation and the paired video, we propose an end-to-end hierarchical\nframework for the long-term variable-length video, which is also conditioned on\nthe questionnaire results and the answering time. Specifically, we resort to a\nhierarchical model which utilizes a 3D CNN for local temporal pattern\nexploration and a redundancy-aware self-attention (RAS) scheme for\nquestion-wise global feature aggregation. Targeting for the redundant long-term\nFE video processing, our RAS is able to effectively exploit the correlations of\neach video clip within a question set to emphasize the discriminative\ninformation and eliminate the redundancy based on feature pair-wise affinity.\nThen, the question-wise video feature is concatenated with the questionnaire\nscores for final depression detection. Our thorough evaluations also show the\nvalidity of fusing SDS evaluation and its video recording, and the superiority\nof our framework to the conventional state-of-the-art temporal modeling\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 02:32:13 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Xie", "Wanqing", ""], ["Liang", "Lizhong", ""], ["Lu", "Yao", ""], ["Wang", "Chen", ""], ["Shen", "Jihong", ""], ["Luo", "Hui", ""], ["Liu", "Xiaofeng", ""]]}, {"id": "2106.13401", "submitter": "Nouha Dziri", "authors": "Alessandro Sordoni, Nouha Dziri, Hannes Schulz, Geoff Gordon, Phil\n  Bachman, Remi Tachet", "title": "Decomposed Mutual Information Estimation for Contrastive Representation\n  Learning", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent contrastive representation learning methods rely on estimating mutual\ninformation (MI) between multiple views of an underlying context. E.g., we can\nderive multiple views of a given image by applying data augmentation, or we can\nsplit a sequence into views comprising the past and future of some step in the\nsequence. Contrastive lower bounds on MI are easy to optimize, but have a\nstrong underestimation bias when estimating large amounts of MI. We propose\ndecomposing the full MI estimation problem into a sum of smaller estimation\nproblems by splitting one of the views into progressively more informed\nsubviews and by applying the chain rule on MI between the decomposed views.\nThis expression contains a sum of unconditional and conditional MI terms, each\nmeasuring modest chunks of the total MI, which facilitates approximation via\ncontrastive bounds. To maximize the sum, we formulate a contrastive lower bound\non the conditional MI which can be approximated efficiently. We refer to our\ngeneral approach as Decomposed Estimation of Mutual Information (DEMI). We show\nthat DEMI can capture a larger amount of MI than standard non-decomposed\ncontrastive bounds in a synthetic setting, and learns better representations in\na vision domain and for dialogue generation.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 03:19:25 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Sordoni", "Alessandro", ""], ["Dziri", "Nouha", ""], ["Schulz", "Hannes", ""], ["Gordon", "Geoff", ""], ["Bachman", "Phil", ""], ["Tachet", "Remi", ""]]}, {"id": "2106.13403", "submitter": "Ha Thanh Nguyen", "authors": "Ha-Thanh Nguyen, Vu Tran, Phuong Minh Nguyen, Thi-Hai-Yen Vuong, Quan\n  Minh Bui, Chau Minh Nguyen, Binh Tran Dang, Minh Le Nguyen, Ken Satoh", "title": "ParaLaw Nets -- Cross-lingual Sentence-level Pretraining for Legal Text\n  Processing", "comments": "Also published in COLIEE 2021's Proceeding", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ambiguity is a characteristic of natural language, which makes expression\nideas flexible. However, in a domain that requires accurate statements, it\nbecomes a barrier. Specifically, a single word can have many meanings and\nmultiple words can have the same meaning. When translating a text into a\nforeign language, the translator needs to determine the exact meaning of each\nelement in the original sentence to produce the correct translation sentence.\nFrom that observation, in this paper, we propose ParaLaw Nets, a pretrained\nmodel family using sentence-level cross-lingual information to reduce ambiguity\nand increase the performance in legal text processing. This approach achieved\nthe best result in the Question Answering task of COLIEE-2021.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 03:21:57 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Nguyen", "Ha-Thanh", ""], ["Tran", "Vu", ""], ["Nguyen", "Phuong Minh", ""], ["Vuong", "Thi-Hai-Yen", ""], ["Bui", "Quan Minh", ""], ["Nguyen", "Chau Minh", ""], ["Dang", "Binh Tran", ""], ["Nguyen", "Minh Le", ""], ["Satoh", "Ken", ""]]}, {"id": "2106.13415", "submitter": "Devendra Singh Chaplot", "authors": "Devendra Singh Chaplot", "title": "Building Intelligent Autonomous Navigation Agents", "comments": "CMU Ph.D. Thesis, March 2021. For more details see\n  http://devendrachaplot.github.io/", "journal-ref": null, "doi": null, "report-no": "CMU-ML-21-101", "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Breakthroughs in machine learning in the last decade have led to `digital\nintelligence', i.e. machine learning models capable of learning from vast\namounts of labeled data to perform several digital tasks such as speech\nrecognition, face recognition, machine translation and so on. The goal of this\nthesis is to make progress towards designing algorithms capable of `physical\nintelligence', i.e. building intelligent autonomous navigation agents capable\nof learning to perform complex navigation tasks in the physical world involving\nvisual perception, natural language understanding, reasoning, planning, and\nsequential decision making. Despite several advances in classical navigation\nmethods in the last few decades, current navigation agents struggle at\nlong-term semantic navigation tasks. In the first part of the thesis, we\ndiscuss our work on short-term navigation using end-to-end reinforcement\nlearning to tackle challenges such as obstacle avoidance, semantic perception,\nlanguage grounding, and reasoning. In the second part, we present a new class\nof navigation methods based on modular learning and structured explicit map\nrepresentations, which leverage the strengths of both classical and end-to-end\nlearning methods, to tackle long-term navigation tasks. We show that these\nmethods are able to effectively tackle challenges such as localization,\nmapping, long-term planning, exploration and learning semantic priors. These\nmodular learning methods are capable of long-term spatial and semantic\nunderstanding and achieve state-of-the-art results on various navigation tasks.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 04:10:58 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Chaplot", "Devendra Singh", ""]]}, {"id": "2106.13423", "submitter": "Han Xie", "authors": "Han Xie, Jing Ma, Li Xiong, Carl Yang", "title": "Federated Graph Classification over Non-IID Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning has emerged as an important paradigm for training machine\nlearning models in different domains. For graph-level tasks such as graph\nclassification, graphs can also be regarded as a special type of data samples,\nwhich can be collected and stored in separate local systems. Similar to other\ndomains, multiple local systems, each holding a small set of graphs, may\nbenefit from collaboratively training a powerful graph mining model, such as\nthe popular graph neural networks (GNNs). To provide more motivation towards\nsuch endeavors, we analyze real-world graphs from different domains to confirm\nthat they indeed share certain graph properties that are statistically\nsignificant compared with random graphs. However, we also find that different\nsets of graphs, even from the same domain or same dataset, are non-IID\nregarding both graph structures and node features. To handle this, we propose a\ngraph clustered federated learning (GCFL) framework that dynamically finds\nclusters of local systems based on the gradients of GNNs, and theoretically\njustify that such clusters can reduce the structure and feature heterogeneity\namong graphs owned by the local systems. Moreover, we observe the gradients of\nGNNs to be rather fluctuating in GCFL which impedes high-quality clustering,\nand design a gradient sequence-based clustering mechanism based on dynamic time\nwarping (GCFL+). Extensive experimental results and in-depth analysis\ndemonstrate the effectiveness of our proposed frameworks.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 04:25:29 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 14:04:43 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Xie", "Han", ""], ["Ma", "Jing", ""], ["Xiong", "Li", ""], ["Yang", "Carl", ""]]}, {"id": "2106.13429", "submitter": "Anastasios Zouzias", "authors": "Anastasios Zouzias, Kleovoulos Kalaitzidis and Boris Grot", "title": "Branch Prediction as a Reinforcement Learning Problem: Why, How and Case\n  Studies", "comments": "6 pages, appeared in ML workshop for Computer Architecture and\n  Systems 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent years have seen stagnating improvements to branch predictor (BP)\nefficacy and a dearth of fresh ideas in branch predictor design, calling for\nfresh thinking in this area. This paper argues that looking at BP from the\nviewpoint of Reinforcement Learning (RL) facilitates systematic reasoning\nabout, and exploration of, BP designs. We describe how to apply the RL\nformulation to branch predictors, show that existing predictors can be\nsuccinctly expressed in this formulation, and study two RL-based variants of\nconventional BPs.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 04:52:49 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Zouzias", "Anastasios", ""], ["Kalaitzidis", "Kleovoulos", ""], ["Grot", "Boris", ""]]}, {"id": "2106.13493", "submitter": "Yossi Adi", "authors": "Ori Kabeli, Yossi Adi, Zhenyu Tang, Buye Xu, Anurag Kumar", "title": "Online Self-Attentive Gated RNNs for Real-Time Speaker Separation", "comments": "Appears at the Workshop on Machine Learning in Speech and Language\n  Processing 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have recently shown great success in the task of blind\nsource separation, both under monaural and binaural settings. Although these\nmethods were shown to produce high-quality separations, they were mainly\napplied under offline settings, in which the model has access to the full input\nsignal while separating the signal. In this study, we convert a non-causal\nstate-of-the-art separation model into a causal and real-time model and\nevaluate its performance under both online and offline settings. We compare the\nperformance of the proposed model to several baseline methods under anechoic,\nnoisy, and noisy-reverberant recording conditions while exploring both monaural\nand binaural inputs and outputs. Our findings shed light on the relative\ndifference between causal and non-causal models when performing separation. Our\nstateful implementation for online separation leads to a minor drop in\nperformance compared to the offline model; 0.8dB for monaural inputs and 0.3dB\nfor binaural inputs while reaching a real-time factor of 0.65. Samples can be\nfound under the following link:\nhttps://kwanum.github.io/sagrnnc-stream-results/.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 08:16:02 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 14:07:49 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Kabeli", "Ori", ""], ["Adi", "Yossi", ""], ["Tang", "Zhenyu", ""], ["Xu", "Buye", ""], ["Kumar", "Anurag", ""]]}, {"id": "2106.13516", "submitter": "Rui He", "authors": "Rui He, Shan He, Ke Tang", "title": "Multi-Domain Active Learning: A Comparative Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building classifiers on multiple domains is a practical problem in the real\nlife. Instead of building classifiers one by one, multi-domain learning (MDL)\nsimultaneously builds classifiers on multiple domains. MDL utilizes the\ninformation shared among the domains to improve the performance. As a\nsupervised learning problem, the labeling effort is still high in MDL problems.\nUsually, this high labeling cost issue could be relieved by using active\nlearning. Thus, it is natural to utilize active learning to reduce the labeling\neffort in MDL, and we refer this setting as multi-domain active learning\n(MDAL). However, there are only few works which are built on this setting. And\nwhen the researches have to face this problem, there is no off-the-shelf\nsolutions. Under this circumstance, combining the current multi-domain learning\nmodels and single-domain active learning strategies might be a preliminary\nsolution for MDAL problem. To find out the potential of this preliminary\nsolution, a comparative study over 5 models and 4 selection strategies is made\nin this paper. To the best of our knowledge, this is the first work provides\nthe formal definition of MDAL. Besides, this is the first comparative work for\nMDAL problem. From the results, the Multinomial Adversarial Networks (MAN)\nmodel with a simple best vs second best (BvSB) uncertainty strategy shows its\nsuperiority in most cases. We take this combination as our off-the-shelf\nrecommendation for the MDAL problem.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 09:16:57 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["He", "Rui", ""], ["He", "Shan", ""], ["Tang", "Ke", ""]]}, {"id": "2106.13539", "submitter": "Axel Abels", "authors": "Axel Abels, Tom Lenaerts, Vito Trianni, Ann Now\\'e", "title": "Dealing with Expert Bias in Collective Decision-Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quite some real-world problems can be formulated as decision-making problems\nwherein one must repeatedly make an appropriate choice from a set of\nalternatives. Expert judgements, whether human or artificial, can help in\ntaking correct decisions, especially when exploration of alternative solutions\nis costly. As expert opinions might deviate, the problem of finding the right\nalternative can be approached as a collective decision making problem (CDM).\nCurrent state-of-the-art approaches to solve CDM are limited by the quality of\nthe best expert in the group, and perform poorly if experts are not qualified\nor if they are overly biased, thus potentially derailing the decision-making\nprocess. In this paper, we propose a new algorithmic approach based on\ncontextual multi-armed bandit problems (CMAB) to identify and counteract such\nbiased expertises. We explore homogeneous, heterogeneous and polarised expert\ngroups and show that this approach is able to effectively exploit the\ncollective expertise, irrespective of whether the provided advice is directly\nconducive to good performance, outperforming state-of-the-art methods,\nespecially when the quality of the provided expertise degrades. Our novel\nCMAB-inspired approach achieves a higher final performance and does so while\nconverging more rapidly than previous adaptive algorithms, especially when\nheterogeneous expertise is readily available.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 10:17:37 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Abels", "Axel", ""], ["Lenaerts", "Tom", ""], ["Trianni", "Vito", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "2106.13542", "submitter": "Konstantin Usevich", "authors": "Yassine Zniyed, Konstantin Usevich, Sebastian Miron, David Brie", "title": "Tensor-based framework for training flexible neural networks", "comments": "26 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Activation functions (AFs) are an important part of the design of neural\nnetworks (NNs), and their choice plays a predominant role in the performance of\na NN. In this work, we are particularly interested in the estimation of\nflexible activation functions using tensor-based solutions, where the AFs are\nexpressed as a weighted sum of predefined basis functions. To do so, we propose\na new learning algorithm which solves a constrained coupled matrix-tensor\nfactorization (CMTF) problem. This technique fuses the first and zeroth order\ninformation of the NN, where the first-order information is contained in a\nJacobian tensor, following a constrained canonical polyadic decomposition\n(CPD). The proposed algorithm can handle different decomposition bases. The\ngoal of this method is to compress large pretrained NN models, by replacing\nsubnetworks, {\\em i.e.,} one or multiple layers of the original network, by a\nnew flexible layer. The approach is applied to a pretrained convolutional\nneural network (CNN) used for character classification.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 10:26:48 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Zniyed", "Yassine", ""], ["Usevich", "Konstantin", ""], ["Miron", "Sebastian", ""], ["Brie", "David", ""]]}, {"id": "2106.13552", "submitter": "Chen Xueying", "authors": "Xueying Chen, Rong Zhang, Yibing Zhan", "title": "Graph Pattern Loss based Diversified Attention Network for Cross-Modal\n  Retrieval", "comments": "5 pages, 3 figures", "journal-ref": "[1] Chen X , Zhang R , Zhan Y . Graph Pattern Loss Based\n  Diversified Attention Network For Cross-Modal Retrieval[C]// 2020 IEEE\n  International Conference on Image Processing (ICIP). IEEE, 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cross-modal retrieval aims to enable flexible retrieval experience by\ncombining multimedia data such as image, video, text, and audio. One core of\nunsupervised approaches is to dig the correlations among different object\nrepresentations to complete satisfied retrieval performance without requiring\nexpensive labels. In this paper, we propose a Graph Pattern Loss based\nDiversified Attention Network(GPLDAN) for unsupervised cross-modal retrieval to\ndeeply analyze correlations among representations. First, we propose a\ndiversified attention feature projector by considering the interaction between\ndifferent representations to generate multiple representations of an instance.\nThen, we design a novel graph pattern loss to explore the correlations among\ndifferent representations, in this graph all possible distances between\ndifferent representations are considered. In addition, a modality classifier is\nadded to explicitly declare the corresponding modalities of features before\nfusion and guide the network to enhance discrimination ability. We test GPLDAN\non four public datasets. Compared with the state-of-the-art cross-modal\nretrieval methods, the experimental results demonstrate the performance and\ncompetitiveness of GPLDAN.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 10:53:07 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Chen", "Xueying", ""], ["Zhang", "Rong", ""], ["Zhan", "Yibing", ""]]}, {"id": "2106.13590", "submitter": "Jamal Toutouh", "authors": "Jamal Toutouh and Erik Hemberg and Una-May O'Reilly", "title": "Fostering Diversity in Spatial Evolutionary Generative Adversarial\n  Networks", "comments": "Accepted to be presented during Conference of the Spanish Association\n  of Artificial Intelligence (CAEPIA 2021). arXiv admin note: substantial text\n  overlap with arXiv:1905.12702", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversary networks (GANs) suffer from training pathologies such as\ninstability and mode collapse, which mainly arise from a lack of diversity in\ntheir adversarial interactions. Co-evolutionary GAN (CoE-GAN) training\nalgorithms have shown to be resilient to these pathologies. This article\nintroduces Mustangs, a spatially distributed CoE-GAN, which fosters diversity\nby using different loss functions during the training. Experimental analysis on\nMNIST and CelebA demonstrated that Mustangs trains statistically more accurate\ngenerators.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 12:40:36 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Toutouh", "Jamal", ""], ["Hemberg", "Erik", ""], ["O'Reilly", "Una-May", ""]]}, {"id": "2106.13594", "submitter": "Daniel T Chang", "authors": "Daniel T. Chang", "title": "Bayesian Neural Networks: Essentials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian neural networks utilize probabilistic layers that capture\nuncertainty over weights and activations, and are trained using Bayesian\ninference. Since these probabilistic layers are designed to be drop-in\nreplacement of their deterministic counter parts, Bayesian neural networks\nprovide a direct and natural way to extend conventional deep neural networks to\nsupport probabilistic deep learning. However, it is nontrivial to understand,\ndesign and train Bayesian neural networks due to their complexities. We discuss\nthe essentials of Bayesian neural networks including duality (deep neural\nnetworks, probabilistic models), approximate Bayesian inference, Bayesian\npriors, Bayesian posteriors, and deep variational learning. We use TensorFlow\nProbability APIs and code examples for illustration. The main problem with\nBayesian neural networks is that the architecture of deep neural networks makes\nit quite redundant, and costly, to account for uncertainty for a large number\nof successive layers. Hybrid Bayesian neural networks, which use few\nprobabilistic layers judicially positioned in the networks, provide a practical\nsolution.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 13:54:17 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Chang", "Daniel T.", ""]]}, {"id": "2106.13740", "submitter": "Magy Seif El-Nasr", "authors": "Magy Seif El-Nasr, Casper Harteveld, Paul Fombelle, Truong-Huy Nguyen,\n  Paola Rizzo, Dylan Schouten, Abdelrahman Madkour, Chaima Jemmali, Erica\n  Kleinman, Nithesh Javvaji, Zhaoqing Teng, Extra Ludic Inc", "title": "Advancing Methodology for Social Science Research Using Alternate\n  Reality Games: Proof-of-Concept Through Measuring Individual Differences and\n  Adaptability and their impact on Team Performance", "comments": null, "journal-ref": "DARPA Report, 2018", "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While work in fields of CSCW (Computer Supported Collaborative Work),\nPsychology and Social Sciences have progressed our understanding of team\nprocesses and their effect performance and effectiveness, current methods rely\non observations or self-report, with little work directed towards studying team\nprocesses with quantifiable measures based on behavioral data. In this report\nwe discuss work tackling this open problem with a focus on understanding\nindividual differences and its effect on team adaptation, and further explore\nthe effect of these factors on team performance as both an outcome and a\nprocess. We specifically discuss our contribution in terms of methods that\naugment survey data and behavioral data that allow us to gain more insight on\nteam performance as well as develop a method to evaluate adaptation and\nperformance across and within a group. To make this problem more tractable we\nchose to focus on specific types of environments, Alternate Reality Games\n(ARGs), and for several reasons. First, these types of games involve setups\nthat are similar to a real-world setup, e.g., communication through slack or\nemail. Second, they are more controllable than real environments allowing us to\nembed stimuli if needed. Lastly, they allow us to collect data needed to\nunderstand decisions and communications made through the entire duration of the\nexperience, which makes team processes more transparent than otherwise\npossible. In this report we discuss the work we did so far and demonstrate the\nefficacy of the approach.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 16:22:22 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["El-Nasr", "Magy Seif", ""], ["Harteveld", "Casper", ""], ["Fombelle", "Paul", ""], ["Nguyen", "Truong-Huy", ""], ["Rizzo", "Paola", ""], ["Schouten", "Dylan", ""], ["Madkour", "Abdelrahman", ""], ["Jemmali", "Chaima", ""], ["Kleinman", "Erica", ""], ["Javvaji", "Nithesh", ""], ["Teng", "Zhaoqing", ""], ["Inc", "Extra Ludic", ""]]}, {"id": "2106.13799", "submitter": "Vaishnavh Nagarajan", "authors": "Yiding Jiang, Vaishnavh Nagarajan, Christina Baek, J. Zico Kolter", "title": "Assessing Generalization of SGD via Disagreement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We empirically show that the test error of deep networks can be estimated by\nsimply training the same architecture on the same training set but with a\ndifferent run of Stochastic Gradient Descent (SGD), and measuring the\ndisagreement rate between the two networks on unlabeled test data. This builds\non -- and is a stronger version of -- the observation in Nakkiran & Bansal '20,\nwhich requires the second run to be on an altogether fresh training set. We\nfurther theoretically show that this peculiar phenomenon arises from the\n\\emph{well-calibrated} nature of \\emph{ensembles} of SGD-trained models. This\nfinding not only provides a simple empirical measure to directly predict the\ntest error using unlabeled test data, but also establishes a new conceptual\nconnection between generalization and calibration.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 17:53:09 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Jiang", "Yiding", ""], ["Nagarajan", "Vaishnavh", ""], ["Baek", "Christina", ""], ["Kolter", "J. Zico", ""]]}, {"id": "2106.13804", "submitter": "Boyi Li", "authors": "Boyi Li and Yin Cui and Tsung-Yi Lin and Serge Belongie", "title": "Single Image Texture Translation for Data Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in image synthesis enables one to translate images by\nlearning the mapping between a source domain and a target domain. Existing\nmethods tend to learn the distributions by training a model on a variety of\ndatasets, with results evaluated largely in a subjective manner. Relatively few\nworks in this area, however, study the potential use of semantic image\ntranslation methods for image recognition tasks. In this paper, we explore the\nuse of Single Image Texture Translation (SITT) for data augmentation. We first\npropose a lightweight model for translating texture to images based on a single\ninput of source texture, allowing for fast training and testing. Based on SITT,\nwe then explore the use of augmented data in long-tailed and few-shot image\nclassification tasks. We find the proposed method is capable of translating\ninput data into a target domain, leading to consistent improved image\nrecognition performance. Finally, we examine how SITT and related image\ntranslation methods can provide a basis for a data-efficient, augmentation\nengineering approach to model training.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 17:59:04 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Li", "Boyi", ""], ["Cui", "Yin", ""], ["Lin", "Tsung-Yi", ""], ["Belongie", "Serge", ""]]}, {"id": "2106.13869", "submitter": "Wenjun Kou", "authors": "Wenjun Kou, Dustin A. Carlson, Alexandra J. Baumann, Erica N. Donnan,\n  Jacob M. Schauer, Mozziyar Etemadi, John E. Pandolfino", "title": "A multi-stage machine learning model on diagnosis of esophageal\n  manometry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  High-resolution manometry (HRM) is the primary procedure used to diagnose\nesophageal motility disorders. Its interpretation and classification includes\nan initial evaluation of swallow-level outcomes and then derivation of a\nstudy-level diagnosis based on Chicago Classification (CC), using a tree-like\nalgorithm. This diagnostic approach on motility disordered using HRM was\nmirrored using a multi-stage modeling framework developed using a combination\nof various machine learning approaches. Specifically, the framework includes\ndeep-learning models at the swallow-level stage and feature-based machine\nlearning models at the study-level stage. In the swallow-level stage, three\nmodels based on convolutional neural networks (CNNs) were developed to predict\nswallow type, swallow pressurization, and integrated relaxation pressure (IRP).\nAt the study-level stage, model selection from families of the\nexpert-knowledge-based rule models, xgboost models and artificial neural\nnetwork(ANN) models were conducted, with the latter two model designed and\naugmented with motivation from the export knowledge. A simple model-agnostic\nstrategy of model balancing motivated by Bayesian principles was utilized,\nwhich gave rise to model averaging weighted by precision scores. The averaged\n(blended) models and individual models were compared and evaluated, of which\nthe best performance on test dataset is 0.81 in top-1 prediction, 0.92 in top-2\npredictions. This is the first artificial-intelligence-style model to\nautomatically predict CC diagnosis of HRM study from raw multi-swallow data.\nMoreover, the proposed modeling framework could be easily extended to\nmulti-modal tasks, such as diagnosis of esophageal patients based on clinical\ndata from both HRM and functional luminal imaging probe panometry (FLIP).\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 20:09:23 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Kou", "Wenjun", ""], ["Carlson", "Dustin A.", ""], ["Baumann", "Alexandra J.", ""], ["Donnan", "Erica N.", ""], ["Schauer", "Jacob M.", ""], ["Etemadi", "Mozziyar", ""], ["Pandolfino", "John E.", ""]]}, {"id": "2106.13876", "submitter": "Bodhisattwa Prasad Majumder", "authors": "Bodhisattwa Prasad Majumder, Oana-Maria Camburu, Thomas Lukasiewicz,\n  Julian McAuley", "title": "Rationale-Inspired Natural Language Explanations with Commonsense", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Explainable machine learning models primarily justify predicted labels using\neither extractive rationales (i.e., subsets of input features) or free-text\nnatural language explanations (NLEs) as abstractive justifications. While NLEs\ncan be more comprehensive than extractive rationales, machine-generated NLEs\nhave been shown to sometimes lack commonsense knowledge. Here, we show that\ncommonsense knowledge can act as a bridge between extractive rationales and\nNLEs, rendering both types of explanations better. More precisely, we introduce\na unified framework, called RExC (Rationale-Inspired Explanations with\nCommonsense), that (1) extracts rationales as a set of features responsible for\nmachine predictions, (2) expands the extractive rationales using available\ncommonsense resources, and (3) uses the expanded knowledge to generate natural\nlanguage explanations. Our framework surpasses by a large margin the previous\nstate-of-the-art in generating NLEs across five tasks in both natural language\nprocessing and vision-language understanding, with human annotators\nconsistently rating the explanations generated by RExC to be more\ncomprehensive, grounded in commonsense, and overall preferred compared to\nprevious state-of-the-art models. Moreover, our work shows that\ncommonsense-grounded explanations can enhance both task performance and\nrationales extraction capabilities.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 20:31:33 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Majumder", "Bodhisattwa Prasad", ""], ["Camburu", "Oana-Maria", ""], ["Lukasiewicz", "Thomas", ""], ["McAuley", "Julian", ""]]}, {"id": "2106.13880", "submitter": "Zhao Kang", "authors": "Zhao Kang, Hongfei Liu, Jiangxin Li, Xiaofeng Zhu, and Ling Tian", "title": "Self-paced Principal Component Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal Component Analysis (PCA) has been widely used for dimensionality\nreduction and feature extraction. Robust PCA (RPCA), under different robust\ndistance metrics, such as l1-norm and l2, p-norm, can deal with noise or\noutliers to some extent. However, real-world data may display structures that\ncan not be fully captured by these simple functions. In addition, existing\nmethods treat complex and simple samples equally. By contrast, a learning\npattern typically adopted by human beings is to learn from simple to complex\nand less to more. Based on this principle, we propose a novel method called\nSelf-paced PCA (SPCA) to further reduce the effect of noise and outliers.\nNotably, the complexity of each sample is calculated at the beginning of each\niteration in order to integrate samples from simple to more complex into\ntraining. Based on an alternating optimization, SPCA finds an optimal\nprojection matrix and filters out outliers iteratively. Theoretical analysis is\npresented to show the rationality of SPCA. Extensive experiments on popular\ndata sets demonstrate that the proposed method can improve the state of-the-art\nresults considerably.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 20:50:45 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Kang", "Zhao", ""], ["Liu", "Hongfei", ""], ["Li", "Jiangxin", ""], ["Zhu", "Xiaofeng", ""], ["Tian", "Ling", ""]]}, {"id": "2106.13895", "submitter": "Kaushik Roy", "authors": "Kaushik Roy and Qi Zhang and Manas Gaur and Amit Sheth", "title": "Knowledge Infused Policy Gradients with Upper Confidence Bound for\n  Relational Bandits", "comments": "Accepted for publication in the research track at ECML-PKDD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Contextual Bandits find important use cases in various real-life scenarios\nsuch as online advertising, recommendation systems, healthcare, etc. However,\nmost of the algorithms use flat feature vectors to represent context whereas,\nin the real world, there is a varying number of objects and relations among\nthem to model in the context. For example, in a music recommendation system,\nthe user context contains what music they listen to, which artists create this\nmusic, the artist albums, etc. Adding richer relational context representations\nalso introduces a much larger context space making exploration-exploitation\nharder. To improve the efficiency of exploration-exploitation knowledge about\nthe context can be infused to guide the exploration-exploitation strategy.\nRelational context representations allow a natural way for humans to specify\nknowledge owing to their descriptive nature. We propose an adaptation of\nKnowledge Infused Policy Gradients to the Contextual Bandit setting and a novel\nKnowledge Infused Policy Gradients Upper Confidence Bound algorithm and perform\nan experimental analysis of a simulated music recommendation dataset and\nvarious real-life datasets where expert knowledge can drastically reduce the\ntotal regret and where it cannot.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 21:54:08 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Roy", "Kaushik", ""], ["Zhang", "Qi", ""], ["Gaur", "Manas", ""], ["Sheth", "Amit", ""]]}, {"id": "2106.13898", "submitter": "Ramin Hasani", "authors": "Ramin Hasani, Mathias Lechner, Alexander Amini, Lucas Liebenwein, Max\n  Tschaikowski, Gerald Teschl, Daniela Rus", "title": "Closed-form Continuous-Depth Models", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO math.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Continuous-depth neural models, where the derivative of the model's hidden\nstate is defined by a neural network, have enabled strong sequential data\nprocessing capabilities. However, these models rely on advanced numerical\ndifferential equation (DE) solvers resulting in a significant overhead both in\nterms of computational cost and model complexity. In this paper, we present a\nnew family of models, termed Closed-form Continuous-depth (CfC) networks, that\nare simple to describe and at least one order of magnitude faster while\nexhibiting equally strong modeling abilities compared to their ODE-based\ncounterparts. The models are hereby derived from the analytical closed-form\nsolution of an expressive subset of time-continuous models, thus alleviating\nthe need for complex DE solvers all together. In our experimental evaluations,\nwe demonstrate that CfC networks outperform advanced, recurrent models over a\ndiverse set of time-series prediction tasks, including those with long-term\ndependencies and irregularly sampled data. We believe our findings open new\nopportunities to train and deploy rich, continuous neural models in\nresource-constrained settings, which demand both performance and efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 22:08:51 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Hasani", "Ramin", ""], ["Lechner", "Mathias", ""], ["Amini", "Alexander", ""], ["Liebenwein", "Lucas", ""], ["Tschaikowski", "Max", ""], ["Teschl", "Gerald", ""], ["Rus", "Daniela", ""]]}, {"id": "2106.13899", "submitter": "Joao Monteiro", "authors": "Joao Monteiro, Xavier Gibert, Jianqiao Feng, Vincent Dumoulin,\n  Dar-Shyang Lee", "title": "Domain Conditional Predictors for Domain Adaptation", "comments": "Part of the pre-registration workshop at NeurIPS 2020:\n  https://preregister.science/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning guarantees often rely on assumptions of i.i.d. data, which will\nlikely be violated in practice once predictors are deployed to perform\nreal-world tasks. Domain adaptation approaches thus appeared as a useful\nframework yielding extra flexibility in that distinct train and test data\ndistributions are supported, provided that other assumptions are satisfied such\nas covariate shift, which expects the conditional distributions over labels to\nbe independent of the underlying data distribution. Several approaches were\nintroduced in order to induce generalization across varying train and test data\nsources, and those often rely on the general idea of domain-invariance, in such\na way that the data-generating distributions are to be disregarded by the\nprediction model. In this contribution, we tackle the problem of generalizing\nacross data sources by approaching it from the opposite direction: we consider\na conditional modeling approach in which predictions, in addition to being\ndependent on the input data, use information relative to the underlying\ndata-generating distribution. For instance, the model has an explicit mechanism\nto adapt to changing environments and/or new data sources. We argue that such\nan approach is more generally applicable than current domain adaptation methods\nsince it does not require extra assumptions such as covariate shift and further\nyields simpler training algorithms that avoid a common source of training\ninstabilities caused by minimax formulations, often employed in\ndomain-invariant methods.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 22:15:54 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Monteiro", "Joao", ""], ["Gibert", "Xavier", ""], ["Feng", "Jianqiao", ""], ["Dumoulin", "Vincent", ""], ["Lee", "Dar-Shyang", ""]]}, {"id": "2106.13901", "submitter": "Ramya Srinivasan", "authors": "Ramya Srinivasan and Devi Parikh", "title": "Building Bridges: Generative Artworks to Explore AI Ethics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In recent years, there has been an increased emphasis on understanding and\nmitigating adverse impacts of artificial intelligence (AI) technologies on\nsociety. Across academia, industry, and government bodies, a variety of\nendeavours are being pursued towards enhancing AI ethics. A significant\nchallenge in the design of ethical AI systems is that there are multiple\nstakeholders in the AI pipeline, each with their own set of constraints and\ninterests. These different perspectives are often not understood, due in part\nto communication gaps.For example, AI researchers who design and develop AI\nmodels are not necessarily aware of the instability induced in consumers' lives\nby the compounded effects of AI decisions. Educating different stakeholders\nabout their roles and responsibilities in the broader context becomes\nnecessary. In this position paper, we outline some potential ways in which\ngenerative artworks can play this role by serving as accessible and powerful\neducational tools for surfacing different perspectives. We hope to spark\ninterdisciplinary discussions about computational creativity broadly as a tool\nfor enhancing AI ethics.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 22:31:55 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Srinivasan", "Ramya", ""], ["Parikh", "Devi", ""]]}, {"id": "2106.13906", "submitter": "Kishor Jothimurugan", "authors": "Kishor Jothimurugan, Suguman Bansal, Osbert Bastani and Rajeev Alur", "title": "Compositional Reinforcement Learning from Logical Specifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning control policies for complex tasks given by\nlogical specifications. Recent approaches automatically generate a reward\nfunction from a given specification and use a suitable reinforcement learning\nalgorithm to learn a policy that maximizes the expected reward. These\napproaches, however, scale poorly to complex tasks that require high-level\nplanning. In this work, we develop a compositional learning approach, called\nDiRL, that interleaves high-level planning and reinforcement learning. First,\nDiRL encodes the specification as an abstract graph; intuitively, vertices and\nedges of the graph correspond to regions of the state space and simpler\nsub-tasks, respectively. Our approach then incorporates reinforcement learning\nto learn neural network policies for each edge (sub-task) within a\nDijkstra-style planning algorithm to compute a high-level plan in the graph. An\nevaluation of the proposed approach on a set of challenging control benchmarks\nwith continuous state and action spaces demonstrates that it outperforms\nstate-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 22:54:28 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Jothimurugan", "Kishor", ""], ["Bansal", "Suguman", ""], ["Bastani", "Osbert", ""], ["Alur", "Rajeev", ""]]}, {"id": "2106.13911", "submitter": "Alvaro Ovalle", "authors": "Alvaro Ovalle, Simon M. Lucas", "title": "Predictive Control Using Learned State Space Models via Rolling Horizon\n  Evolution", "comments": "Accepted at the Bridging the Gap Between AI Planning and\n  Reinforcement Learning (PRL) Workshop at ICAPS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A large part of the interest in model-based reinforcement learning derives\nfrom the potential utility to acquire a forward model capable of strategic long\nterm decision making. Assuming that an agent succeeds in learning a useful\npredictive model, it still requires a mechanism to harness it to generate and\nselect among competing simulated plans. In this paper, we explore this theme\ncombining evolutionary algorithmic planning techniques with models learned via\ndeep learning and variational inference. We demonstrate the approach with an\nagent that reliably performs online planning in a set of visual navigation\ntasks.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 23:23:42 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Ovalle", "Alvaro", ""], ["Lucas", "Simon M.", ""]]}, {"id": "2106.13913", "submitter": "Hongyu Guo", "authors": "Hongyu Guo", "title": "Midpoint Regularization: from High Uncertainty Training to Conservative\n  Classification", "comments": "Accepted to ECML-PKDD 2021. arXiv admin note: substantial text\n  overlap with arXiv:2012.01559", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Label Smoothing (LS) improves model generalization through penalizing models\nfrom generating overconfident output distributions. For each training sample\nthe LS strategy smooths the one-hot encoded training signal by distributing its\ndistribution mass over the non-ground truth classes. We extend this technique\nby considering example pairs, coined PLS. PLS first creates midpoint samples by\naveraging random sample pairs and then learns a smoothing distribution during\ntraining for each of these midpoint samples, resulting in midpoints with high\nuncertainty labels for training. We empirically show that PLS significantly\noutperforms LS, achieving up to 30% of relative classification error reduction.\nWe also visualize that PLS produces very low winning softmax scores for both in\nand out of distribution samples.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 00:31:46 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Guo", "Hongyu", ""]]}, {"id": "2106.13917", "submitter": "Furqan Ahmed", "authors": "Furqan Ahmed and Petri M\\\"ah\\\"onen", "title": "Quantum Computing for Artificial Intelligence Based Mobile Network\n  Optimization", "comments": "Accepted in 2021 IEEE 32nd Annual International Symposium on\n  Personal, Indoor and Mobile Radio Communications (PIMRC) - Track 4: Mobile\n  and Wireless Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we discuss how certain radio access network optimization\nproblems can be modelled using the concept of constraint satisfaction problems\nin artificial intelligence, and solved at scale using a quantum computer. As a\ncase study, we discuss root sequence index (RSI) assignment problem - an\nimportant LTE/NR physical random access channel configuration related\nautomation use-case. We formulate RSI assignment as quadratic unconstrained\nbinary optimization (QUBO) problem constructed using data ingested from a\ncommercial mobile network, and solve it using a cloud-based commercially\navailable quantum computing platform. Results show that quantum annealing\nsolver can successfully assign conflict-free RSIs. Comparison with well-known\nheuristics reveals that some classic algorithms are even more effective in\nterms of solution quality and computation time. The non-quantum advantage is\ndue to the fact that current implementation is a semi-quantum proof-of-concept\nalgorithm. Also, the results depend on the type of quantum computer used.\nNevertheless, the proposed framework is highly flexible and holds tremendous\npotential for harnessing the power of quantum computing in mobile network\nautomation.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 01:05:43 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Ahmed", "Furqan", ""], ["M\u00e4h\u00f6nen", "Petri", ""]]}, {"id": "2106.13928", "submitter": "Rui Huang", "authors": "Jingxuan Li, Rui Huang, Wei Li, Kai Yao, Weiguo Tan", "title": "Toward Less Hidden Cost of Code Completion with Acceptance and Ranking\n  Models", "comments": "10 pages, 7 figures, accepted by ICSME 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.PL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Code completion is widely used by software developers to provide coding\nsuggestions given a partially written code snippet. Apart from the traditional\ncode completion methods, which only support single token completion at minimal\npositions, recent studies show the ability to provide longer code completion at\nmore flexible positions. However, such frequently triggered and longer\ncompletion results reduce the overall precision as they generate more invalid\nresults. Moreover, different studies are mostly incompatible with each other.\nThus, it is vital to develop an ensemble framework that can combine results\nfrom multiple models to draw merits and offset defects of each model.\n  This paper conducts a coding simulation to collect data from code context and\ndifferent code completion models and then apply the data in two tasks. First,\nwe introduce an acceptance model which can dynamically control whether to\ndisplay completion results to the developer. It uses simulation features to\npredict whether correct results exist in the output of these models. Our best\nmodel reduces the percentage of false-positive completion from 55.09% to\n17.44%. Second, we design a fusion ranking scheme that can automatically\nidentify the priority of the completion results and reorder the candidates from\nmultiple code completion models. This scheme is flexible in dealing with\nvarious models, regardless of the type or the length of their completion\nresults. We integrate this ranking scheme with two frequency models and a GPT-2\nstyled language model, along with the acceptance model to yield 27.80% and\n37.64% increase in TOP1 and TOP5 accuracy, respectively. In addition, we\npropose a new code completion evaluation metric, Benefit-Cost Ratio(BCR),\ntaking into account the benefit of keystrokes saving and hidden cost of\ncompletion list browsing, which is closer to real coder experience scenario.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 03:02:49 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Li", "Jingxuan", ""], ["Huang", "Rui", ""], ["Li", "Wei", ""], ["Yao", "Kai", ""], ["Tan", "Weiguo", ""]]}, {"id": "2106.13935", "submitter": "Kuan Fang", "authors": "Kuan Fang, Yuke Zhu, Silvio Savarese, Li Fei-Fei", "title": "Discovering Generalizable Skills via Automated Generation of Diverse\n  Tasks", "comments": "RSS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The learning efficiency and generalization ability of an intelligent agent\ncan be greatly improved by utilizing a useful set of skills. However, the\ndesign of robot skills can often be intractable in real-world applications due\nto the prohibitive amount of effort and expertise that it requires. In this\nwork, we introduce Skill Learning In Diversified Environments (SLIDE), a method\nto discover generalizable skills via automated generation of a diverse set of\ntasks. As opposed to prior work on unsupervised discovery of skills which\nincentivizes the skills to produce different outcomes in the same environment,\nour method pairs each skill with a unique task produced by a trainable task\ngenerator. To encourage generalizable skills to emerge, our method trains each\nskill to specialize in the paired task and maximizes the diversity of the\ngenerated tasks. A task discriminator defined on the robot behaviors in the\ngenerated tasks is jointly trained to estimate the evidence lower bound of the\ndiversity objective. The learned skills can then be composed in a hierarchical\nreinforcement learning algorithm to solve unseen target tasks. We demonstrate\nthat the proposed method can effectively learn a variety of robot skills in two\ntabletop manipulation domains. Our results suggest that the learned skills can\neffectively improve the robot's performance in various unseen target tasks\ncompared to existing reinforcement learning and skill learning methods.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 03:41:51 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Fang", "Kuan", ""], ["Zhu", "Yuke", ""], ["Savarese", "Silvio", ""], ["Fei-Fei", "Li", ""]]}, {"id": "2106.13954", "submitter": "Mahardhika Pratama Dr", "authors": "Mao Fubing, Weng Weiwei, Mahardhika Pratama, Edward Yapp Kien Yee", "title": "Continual Learning via Inter-Task Synaptic Mapping", "comments": "This paper has been published in Knowledge-based Systems", "journal-ref": "Knowledge-based Systems, 2021", "doi": "10.1016/j.knosys.2021.106947", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Learning from streaming tasks leads a model to catastrophically erase unique\nexperiences it absorbs from previous episodes. While regularization techniques\nsuch as LWF, SI, EWC have proven themselves as an effective avenue to overcome\nthis issue by constraining important parameters of old tasks from changing when\naccepting new concepts, these approaches do not exploit common information of\neach task which can be shared to existing neurons. As a result, they do not\nscale well to large-scale problems since the parameter importance variables\nquickly explode. An Inter-Task Synaptic Mapping (ISYANA) is proposed here to\nunderpin knowledge retention for continual learning. ISYANA combines\ntask-to-neuron relationship as well as concept-to-concept relationship such\nthat it prevents a neuron to embrace distinct concepts while merely accepting\nrelevant concept. Numerical study in the benchmark continual learning problems\nhas been carried out followed by comparison against prominent continual\nlearning algorithms. ISYANA exhibits competitive performance compared to state\nof the arts. Codes of ISYANA is made available in\n\\url{https://github.com/ContinualAL/ISYANAKBS}.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 06:30:43 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Fubing", "Mao", ""], ["Weiwei", "Weng", ""], ["Pratama", "Mahardhika", ""], ["Yee", "Edward Yapp Kien", ""]]}, {"id": "2106.13955", "submitter": "Mahardhika Pratama Dr", "authors": "Andri Ashfahani, Mahardhika Pratama, Edwin Lughofer, Edward Yapp Kien\n  Yee", "title": "Autonomous Deep Quality Monitoring in Streaming Environments", "comments": "This paper has been accepted for publication in IJCNN, 2021", "journal-ref": "International Joint Conference on Neural Networks, 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The common practice of quality monitoring in industry relies on manual\ninspection well-known to be slow, error-prone and operator-dependent. This\nissue raises strong demand for automated real-time quality monitoring developed\nfrom data-driven approaches thus alleviating from operator dependence and\nadapting to various process uncertainties. Nonetheless, current approaches do\nnot take into account the streaming nature of sensory information while relying\nheavily on hand-crafted features making them application-specific. This paper\nproposes the online quality monitoring methodology developed from recently\ndeveloped deep learning algorithms for data streams, Neural Networks with\nDynamically Evolved Capacity (NADINE), namely NADINE++. It features the\nintegration of 1-D and 2-D convolutional layers to extract natural features of\ntime-series and visual data streams captured from sensors and cameras of the\ninjection molding machines from our own project. Real-time experiments have\nbeen conducted where the online quality monitoring task is simulated on the fly\nunder the prequential test-then-train fashion - the prominent data stream\nevaluation protocol. Comparison with the state-of-the-art techniques clearly\nexhibits the advantage of NADINE++ with 4.68\\% improvement on average for the\nquality monitoring task in streaming environments. To support the reproducible\nresearch initiative, codes, results of NADINE++ along with supplementary\nmaterials and injection molding dataset are made available in\n\\url{https://github.com/ContinualAL/NADINE-IJCNN2021}.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 06:47:41 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Ashfahani", "Andri", ""], ["Pratama", "Mahardhika", ""], ["Lughofer", "Edwin", ""], ["Yee", "Edward Yapp Kien", ""]]}, {"id": "2106.13970", "submitter": "Yue Zhao", "authors": "Yue Zhao, Chenzhuang Du, Hang Zhao, Tiejun Li", "title": "Intrinsically Motivated Self-supervised Learning in Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In vision-based reinforcement learning (RL) tasks, it is prevalent to assign\nthe auxiliary task with a surrogate self-supervised loss so as to obtain more\nsemantic representations and improve sample efficiency. However, abundant\ninformation in self-supervised auxiliary tasks has been disregarded, since the\nrepresentation learning part and the decision-making part are separated. To\nsufficiently utilize information in the auxiliary task, we present a simple yet\neffective idea to employ self-supervised loss as an intrinsic reward, called\nIntrinsically Motivated Self-Supervised learning in Reinforcement learning\n(IM-SSR). We formally show that the self-supervised loss can be decomposed as\nexploration for novel states and robustness improvement from nuisance\nelimination. IM-SSR can be effortlessly plugged into any reinforcement learning\nwith self-supervised auxiliary objectives with nearly no additional cost.\nCombined with IM-SSR, the previous underlying algorithms achieve salient\nimprovements on both sample efficiency and generalization in various\nvision-based robotics tasks from the DeepMind Control Suite, especially when\nthe reward signal is sparse.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 08:43:28 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Zhao", "Yue", ""], ["Du", "Chenzhuang", ""], ["Zhao", "Hang", ""], ["Li", "Tiejun", ""]]}, {"id": "2106.13976", "submitter": "Yiheng Yao", "authors": "Yiheng Yao", "title": "Explanatory Pluralism in Explainable AI", "comments": "To be published in CD-MAKE 2021 conference proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The increasingly widespread application of AI models motivates increased\ndemand for explanations from a variety of stakeholders. However, this demand is\nambiguous because there are many types of 'explanation' with different\nevaluative criteria. In the spirit of pluralism, I chart a taxonomy of types of\nexplanation and the associated XAI methods that can address them. When we look\nto expose the inner mechanisms of AI models, we develop\nDiagnostic-explanations. When we seek to render model output understandable, we\nproduce Explication-explanations. When we wish to form stable generalizations\nof our models, we produce Expectation-explanations. Finally, when we want to\njustify the usage of a model, we produce Role-explanations that situate models\nwithin their social context. The motivation for such a pluralistic view stems\nfrom a consideration of causes as manipulable relationships and the different\ntypes of explanations as identifying the relevant points in AI systems we can\nintervene upon to affect our desired changes. This paper reduces the ambiguity\nin use of the word 'explanation' in the field of XAI, allowing practitioners\nand stakeholders a useful template for avoiding equivocation and evaluating XAI\nmethods and putative explanations.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 09:02:06 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Yao", "Yiheng", ""]]}, {"id": "2106.13984", "submitter": "Shuai Yang", "authors": "Shuai Yang, Kai Qiao", "title": "ShapeEditer: a StyleGAN Encoder for Face Swapping", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel encoder, called ShapeEditor, for\nhigh-resolution, realistic and high-fidelity face exchange. First of all, in\norder to ensure sufficient clarity and authenticity, our key idea is to use an\nadvanced pretrained high-quality random face image generator, i.e. StyleGAN, as\nbackbone. Secondly, we design ShapeEditor, a two-step encoder, to make the\nswapped face integrate the identity and attribute of the input faces. In the\nfirst step, we extract the identity vector of the source image and the\nattribute vector of the target image respectively; in the second step, we map\nthe concatenation of identity vector and attribute vector into the\n$\\mathcal{W+}$ potential space. In addition, for learning to map into the\nlatent space of StyleGAN, we propose a set of self-supervised loss functions\nwith which the training data do not need to be labeled manually. Extensive\nexperiments on the test dataset show that the results of our method not only\nhave a great advantage in clarity and authenticity than other state-of-the-art\nmethods, but also reflect the sufficient integration of identity and attribute.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 09:38:45 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Yang", "Shuai", ""], ["Qiao", "Kai", ""]]}, {"id": "2106.13987", "submitter": "Shaoshan Liu", "authors": "Shaoshan Liu, Jean-Luc Gaudiot", "title": "Rise of the Autonomous Machines", "comments": "to appear in IEEE Computer Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.AR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After decades of uninterrupted progress and growth, information technology\nhas so evolved that it can be said we are entering the age of autonomous\nmachines, but there exist many roadblocks in the way of making this a reality.\nIn this article, we make a preliminary attempt at recognizing and categorizing\nthe technical and non-technical challenges of autonomous machines; for each of\nthe ten areas we have identified, we review current status, roadblocks, and\npotential research directions. It is hoped that this will help the community\ndefine clear, effective, and more formal development goalposts for the future.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 09:46:01 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Liu", "Shaoshan", ""], ["Gaudiot", "Jean-Luc", ""]]}, {"id": "2106.13997", "submitter": "Ivan Y. Tyukin", "authors": "Ivan Y. Tyukin, Desmond J. Higham, Eliyas Woldegeorgis, Alexander N.\n  Gorban", "title": "The Feasibility and Inevitability of Stealth Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We develop and study new adversarial perturbations that enable an attacker to\ngain control over decisions in generic Artificial Intelligence (AI) systems\nincluding deep learning neural networks. In contrast to adversarial data\nmodification, the attack mechanism we consider here involves alterations to the\nAI system itself. Such a stealth attack could be conducted by a mischievous,\ncorrupt or disgruntled member of a software development team. It could also be\nmade by those wishing to exploit a \"democratization of AI\" agenda, where\nnetwork architectures and trained parameter sets are shared publicly. Building\non work by [Tyukin et al., International Joint Conference on Neural Networks,\n2020], we develop a range of new implementable attack strategies with\naccompanying analysis, showing that with high probability a stealth attack can\nbe made transparent, in the sense that system performance is unchanged on a\nfixed validation set which is unknown to the attacker, while evoking any\ndesired output on a trigger input of interest. The attacker only needs to have\nestimates of the size of the validation set and the spread of the AI's relevant\nlatent space. In the case of deep learning neural networks, we show that a one\nneuron attack is possible - a modification to the weights and bias associated\nwith a single neuron - revealing a vulnerability arising from\nover-parameterization. We illustrate these concepts in a realistic setting.\nGuided by the theory and computational results, we also propose strategies to\nguard against stealth attacks.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 10:50:07 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Tyukin", "Ivan Y.", ""], ["Higham", "Desmond J.", ""], ["Woldegeorgis", "Eliyas", ""], ["Gorban", "Alexander N.", ""]]}, {"id": "2106.14043", "submitter": "Mustafa Yal\\c{c}{\\i}ner", "authors": "Ali Vakilian, Mustafa Yal\\c{c}{\\i}ner", "title": "Improved Approximation Algorithms for Individually Fair Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the $k$-clustering problem with $\\ell_p$-norm cost, which\nincludes $k$-median, $k$-means and $k$-center cost functions, under an\nindividual notion of fairness proposed by Jung et al. [2020]: given a set of\npoints $P$ of size $n$, a set of $k$ centers induces a fair clustering if for\nevery point $v\\in P$, $v$ can find a center among its $n/k$ closest neighbors.\nRecently, Mahabadi and Vakilian [2020] showed how to get a\n$(p^{O(p)},7)$-bicriteria approximation for the problem of fair $k$-clustering\nwith $\\ell_p$-norm cost: every point finds a center within distance at most $7$\ntimes its distance to its $(n/k)$-th closest neighbor and the $\\ell_p$-norm\ncost of the solution is at most $p^{O(p)}$ times the cost of an optimal fair\nsolution. In this work, for any $\\varepsilon>0$, we present an improved $(16^p\n+\\varepsilon,3)$-bicriteria approximation for the fair $k$-clustering with\n$\\ell_p$-norm cost. To achieve our guarantees, we extend the framework of\n[Charikar et al., 2002, Swamy, 2016] and devise a $16^p$-approximation\nalgorithm for the facility location with $\\ell_p$-norm cost under matroid\nconstraint which might be of an independent interest. Besides, our approach\nsuggests a reduction from our individually fair clustering to a clustering with\na group fairness requirement proposed by Kleindessner et al. [2019], which is\nessentially the median matroid problem [Krishnaswamy et al., 2011].\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 15:22:52 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Vakilian", "Ali", ""], ["Yal\u00e7\u0131ner", "Mustafa", ""]]}, {"id": "2106.14052", "submitter": "Medina Andresel", "authors": "Medina Andresel, Csaba Domokos, Daria Stepanova, Trung-Kien Tran", "title": "A Neural-symbolic Approach for Ontology-mediated Query Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, low-dimensional vector space representations of knowledge graphs\n(KGs) have been applied to find answers to conjunctive queries (CQs) over\nincomplete KGs. However, the current methods only focus on inductive reasoning,\ni.e. answering CQs by predicting facts based on patterns learned from the data,\nand lack the ability of deductive reasoning by applying external domain\nknowledge. Such (expert or commonsense) domain knowledge is an invaluable\nresource which can be used to advance machine intelligence. To address this\nshortcoming, we introduce a neural-symbolic method for ontology-mediated CQ\nanswering over incomplete KGs that operates in the embedding space. More\nspecifically, we propose various data augmentation strategies to generate\ntraining queries using query-rewriting based methods and then exploit a novel\nloss function for training the model. The experimental results demonstrate the\neffectiveness of our training strategies and the new loss function, i.e., our\nmethod significantly outperforms the baseline in the settings that require both\ninductive and deductive reasoning.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 16:05:44 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Andresel", "Medina", ""], ["Domokos", "Csaba", ""], ["Stepanova", "Daria", ""], ["Tran", "Trung-Kien", ""]]}, {"id": "2106.14070", "submitter": "Bowen Wen", "authors": "Andrew S. Morgan, Bowen Wen, Junchi Liang, Abdeslam Boularias, Aaron\n  M. Dollar, and Kostas Bekris", "title": "Vision-driven Compliant Manipulation for Reliable, High-Precision\n  Assembly Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Highly constrained manipulation tasks continue to be challenging for\nautonomous robots as they require high levels of precision, typically less than\n1mm, which is often incompatible with what can be achieved by traditional\nperception systems. This paper demonstrates that the combination of\nstate-of-the-art object tracking with passively adaptive mechanical hardware\ncan be leveraged to complete precision manipulation tasks with tight,\nindustrially-relevant tolerances (0.25mm). The proposed control method closes\nthe loop through vision by tracking the relative 6D pose of objects in the\nrelevant workspace. It adjusts the control reference of both the compliant\nmanipulator and the hand to complete object insertion tasks via within-hand\nmanipulation. Contrary to previous efforts for insertion, our method does not\nrequire expensive force sensors, precision manipulators, or time-consuming,\nonline learning, which is data hungry. Instead, this effort leverages\nmechanical compliance and utilizes an object agnostic manipulation model of the\nhand learned offline, off-the-shelf motion planning, and an RGBD-based object\ntracker trained solely with synthetic data. These features allow the proposed\nsystem to easily generalize and transfer to new tasks and environments. This\npaper describes in detail the system components and showcases its efficacy with\nextensive experiments involving tight tolerance peg-in-hole insertion tasks of\nvarious geometries as well as open-world constrained placement tasks.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 17:54:16 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Morgan", "Andrew S.", ""], ["Wen", "Bowen", ""], ["Liang", "Junchi", ""], ["Boularias", "Abdeslam", ""], ["Dollar", "Aaron M.", ""], ["Bekris", "Kostas", ""]]}, {"id": "2106.14080", "submitter": "Nirbhay Modhe", "authors": "Nirbhay Modhe, Harish Kamath, Dhruv Batra, Ashwin Kalyan", "title": "Model-Advantage Optimization for Model-Based Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Model-based Reinforcement Learning (MBRL) algorithms have been traditionally\ndesigned with the goal of learning accurate dynamics of the environment. This\nintroduces a mismatch between the objectives of model-learning and the overall\nlearning problem of finding an optimal policy. Value-aware model learning, an\nalternative model-learning paradigm to maximum likelihood, proposes to inform\nmodel-learning through the value function of the learnt policy. While this\nparadigm is theoretically sound, it does not scale beyond toy settings. In this\nwork, we propose a novel value-aware objective that is an upper bound on the\nabsolute performance difference of a policy across two models. Further, we\npropose a general purpose algorithm that modifies the standard MBRL pipeline --\nenabling learning with value aware objectives. Our proposed objective, in\nconjunction with this algorithm, is the first successful instantiation of\nvalue-aware MBRL on challenging continuous control environments, outperforming\nprevious value-aware objectives and with competitive performance w.r.t.\nMLE-based MBRL approaches.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 20:01:28 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Modhe", "Nirbhay", ""], ["Kamath", "Harish", ""], ["Batra", "Dhruv", ""], ["Kalyan", "Ashwin", ""]]}, {"id": "2106.14082", "submitter": "Nihar Shrikant Bendre", "authors": "Nihar Bendre, Kevin Desai and Peyman Najafirad", "title": "Generalized Zero-Shot Learning using Multimodal Variational Auto-Encoder\n  with Semantic Concepts", "comments": "5 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the ever-increasing amount of data, the central challenge in multimodal\nlearning involves limitations of labelled samples. For the task of\nclassification, techniques such as meta-learning, zero-shot learning, and\nfew-shot learning showcase the ability to learn information about novel classes\nbased on prior knowledge. Recent techniques try to learn a cross-modal mapping\nbetween the semantic space and the image space. However, they tend to ignore\nthe local and global semantic knowledge. To overcome this problem, we propose a\nMultimodal Variational Auto-Encoder (M-VAE) which can learn the shared latent\nspace of image features and the semantic space. In our approach we concatenate\nmultimodal data to a single embedding before passing it to the VAE for learning\nthe latent space. We propose the use of a multi-modal loss during the\nreconstruction of the feature embedding through the decoder. Our approach is\ncapable to correlating modalities and exploit the local and global semantic\nknowledge for novel sample predictions. Our experimental results using a MLP\nclassifier on four benchmark datasets show that our proposed model outperforms\nthe current state-of-the-art approaches for generalized zero-shot learning.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 20:08:37 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Bendre", "Nihar", ""], ["Desai", "Kevin", ""], ["Najafirad", "Peyman", ""]]}, {"id": "2106.14101", "submitter": "Youshaa Murhij", "authors": "Youshaa Murhij and Dmitry Yudin", "title": "Real-time 3D Object Detection using Feature Map Flow", "comments": "CVPR 2021 Workshop on autonomous driving (Waymo Real-time 3D\n  Detection)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a real-time 3D detection approach considering\ntime-spatial feature map aggregation from different time steps of deep neural\nmodel inference (named feature map flow, FMF). Proposed approach improves the\nquality of 3D detection center-based baseline and provides real-time\nperformance on the nuScenes and Waymo benchmark. Code is available at\nhttps://github.com/YoushaaMurhij/FMFNet\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 22:20:31 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Murhij", "Youshaa", ""], ["Yudin", "Dmitry", ""]]}, {"id": "2106.14102", "submitter": "Priyank Kalgaonkar", "authors": "Priyank Kalgaonkar, Mohamed El-Sharkawy", "title": "Image Classification with CondenseNeXt for ARM-Based Computing Platforms", "comments": "6 pages, 7 figures, conference, published IEEE Conference paper", "journal-ref": null, "doi": "10.1109/IEMTRONICS52119.2021.9422541", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we demonstrate the implementation of our ultra-efficient deep\nconvolutional neural network architecture: CondenseNeXt on NXP BlueBox, an\nautonomous driving development platform developed for self-driving vehicles. We\nshow that CondenseNeXt is remarkably efficient in terms of FLOPs, designed for\nARM-based embedded computing platforms with limited computational resources and\ncan perform image classification without the need of a CUDA enabled GPU.\nCondenseNeXt utilizes the state-of-the-art depthwise separable convolution and\nmodel compression techniques to achieve a remarkable computational efficiency.\nExtensive analyses are conducted on CIFAR-10, CIFAR-100 and ImageNet datasets\nto verify the performance of CondenseNeXt Convolutional Neural Network (CNN)\narchitecture. It achieves state-of-the-art image classification performance on\nthree benchmark datasets including CIFAR-10 (4.79% top-1 error), CIFAR-100\n(21.98% top-1 error) and ImageNet (7.91% single model, single crop top-5\nerror). CondenseNeXt achieves final trained model size improvement of 2.9+ MB\nand up to 59.98% reduction in forward FLOPs compared to CondenseNet and can\nperform image classification on ARM-Based computing platforms without needing a\nCUDA enabled GPU support, with outstanding efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 22:22:03 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Kalgaonkar", "Priyank", ""], ["El-Sharkawy", "Mohamed", ""]]}, {"id": "2106.14112", "submitter": "Emadeldeen Eldele", "authors": "Emadeldeen Eldele, Mohamed Ragab, Zhenghua Chen, Min Wu, Chee Keong\n  Kwoh, Xiaoli Li and Cuntai Guan", "title": "Time-Series Representation Learning via Temporal and Contextual\n  Contrasting", "comments": "Accepted in IJCAI-21 conference ... please cite the conference\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning decent representations from unlabeled time-series data with temporal\ndynamics is a very challenging task. In this paper, we propose an unsupervised\nTime-Series representation learning framework via Temporal and Contextual\nContrasting (TS-TCC), to learn time-series representation from unlabeled data.\nFirst, the raw time-series data are transformed into two different yet\ncorrelated views by using weak and strong augmentations. Second, we propose a\nnovel temporal contrasting module to learn robust temporal representations by\ndesigning a tough cross-view prediction task. Last, to further learn\ndiscriminative representations, we propose a contextual contrasting module\nbuilt upon the contexts from the temporal contrasting module. It attempts to\nmaximize the similarity among different contexts of the same sample while\nminimizing similarity among contexts of different samples. Experiments have\nbeen carried out on three real-world time-series datasets. The results manifest\nthat training a linear classifier on top of the features learned by our\nproposed TS-TCC performs comparably with the supervised training. Additionally,\nour proposed TS-TCC shows high efficiency in few-labeled data and transfer\nlearning scenarios. The code is publicly available at\nhttps://github.com/emadeldeen24/TS-TCC.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 23:56:31 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Eldele", "Emadeldeen", ""], ["Ragab", "Mohamed", ""], ["Chen", "Zhenghua", ""], ["Wu", "Min", ""], ["Kwoh", "Chee Keong", ""], ["Li", "Xiaoli", ""], ["Guan", "Cuntai", ""]]}, {"id": "2106.14117", "submitter": "Steven Morad", "authors": "Steven D. Morad, Stephan Liwicki, Amanda Prorok", "title": "Graph Convolutional Memory for Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Solving partially-observable Markov decision processes (POMDPs) is critical\nwhen applying deep reinforcement learning (DRL) to real-world robotics\nproblems, where agents have an incomplete view of the world. We present graph\nconvolutional memory (GCM) for solving POMDPs using deep reinforcement\nlearning. Unlike recurrent neural networks (RNNs) or transformers, GCM embeds\ndomain-specific priors into the memory recall process via a knowledge graph. By\nencapsulating priors in the graph, GCM adapts to specific tasks but remains\napplicable to any DRL task. Using graph convolutions, GCM extracts hierarchical\ngraph features, analogous to image features in a convolutional neural network\n(CNN). We show GCM outperforms long short-term memory (LSTM), gated\ntransformers for reinforcement learning (GTrXL), and differentiable neural\ncomputers (DNCs) on control, long-term non-sequential recall, and 3D navigation\ntasks while using significantly fewer parameters.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 00:22:51 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Morad", "Steven D.", ""], ["Liwicki", "Stephan", ""], ["Prorok", "Amanda", ""]]}, {"id": "2106.14127", "submitter": "Songwei Ge", "authors": "Songwei Ge and Devi Parikh", "title": "Visual Conceptual Blending with Large-scale Language and Vision Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We ask the question: to what extent can recent large-scale language and image\ngeneration models blend visual concepts? Given an arbitrary object, we identify\na relevant object and generate a single-sentence description of the blend of\nthe two using a language model. We then generate a visual depiction of the\nblend using a text-based image generation model. Quantitative and qualitative\nevaluations demonstrate the superiority of language models over classical\nmethods for conceptual blending, and of recent large-scale image generation\nmodels over prior models for the visual depiction.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 02:48:39 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Ge", "Songwei", ""], ["Parikh", "Devi", ""]]}, {"id": "2106.14130", "submitter": "Bruno Brandoli", "authors": "Nader Zare and Bruno Brandoli and Mahtab Sarvmaili and Amilcar Soares\n  and Stan Matwin", "title": "Continuous Control with Deep Reinforcement Learning for Autonomous\n  Vessels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Maritime autonomous transportation has played a crucial role in the\nglobalization of the world economy. Deep Reinforcement Learning (DRL) has been\napplied to automatic path planning to simulate vessel collision avoidance\nsituations in open seas. End-to-end approaches that learn complex mappings\ndirectly from the input have poor generalization to reach the targets in\ndifferent environments. In this work, we present a new strategy called\nstate-action rotation to improve agent's performance in unseen situations by\nrotating the obtained experience (state-action-state) and preserving them in\nthe replay buffer. We designed our model based on Deep Deterministic Policy\nGradient, local view maker, and planner. Our agent uses two deep Convolutional\nNeural Networks to estimate the policy and action-value functions. The proposed\nmodel was exhaustively trained and tested in maritime scenarios with real maps\nfrom cities such as Montreal and Halifax. Experimental results show that the\nstate-action rotation on top of the CVN consistently improves the rate of\narrival to a destination (RATD) by up 11.96% with respect to the Vessel\nNavigator with Planner and Local View (VNPLV), as well as it achieves superior\nperformance in unseen mappings by up 30.82%. Our proposed approach exhibits\nadvantages in terms of robustness when tested in a new environment, supporting\nthe idea that generalization can be achieved by using state-action rotation.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 03:12:32 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Zare", "Nader", ""], ["Brandoli", "Bruno", ""], ["Sarvmaili", "Mahtab", ""], ["Soares", "Amilcar", ""], ["Matwin", "Stan", ""]]}, {"id": "2106.14163", "submitter": "Lianbo Ma", "authors": "Lianbo Ma, Huimin Ren, Xiliang Zhang", "title": "Effective Cascade Dual-Decoder Model for Joint Entity and Relation\n  Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting relational triples from texts is a fundamental task in knowledge\ngraph construction. The popular way of existing methods is to jointly extract\nentities and relations using a single model, which often suffers from the\noverlapping triple problem. That is, there are multiple relational triples that\nshare the same entities within one sentence. In this work, we propose an\neffective cascade dual-decoder approach to extract overlapping relational\ntriples, which includes a text-specific relation decoder and a\nrelation-corresponded entity decoder. Our approach is straightforward: the\ntext-specific relation decoder detects relations from a sentence according to\nits text semantics and treats them as extra features to guide the entity\nextraction; for each extracted relation, which is with trainable embedding, the\nrelation-corresponded entity decoder detects the corresponding head and tail\nentities using a span-based tagging scheme. In this way, the overlapping triple\nproblem is tackled naturally. Experiments on two public datasets demonstrate\nthat our proposed approach outperforms state-of-the-art methods and achieves\nbetter F1 scores under the strict evaluation metric. Our implementation is\navailable at https://github.com/prastunlp/DualDec.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 07:42:05 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Ma", "Lianbo", ""], ["Ren", "Huimin", ""], ["Zhang", "Xiliang", ""]]}, {"id": "2106.14167", "submitter": "Romina Etezadi", "authors": "Romina Etezadi, Mehrnoush Shamsfard", "title": "PeCoQ: A Dataset for Persian Complex Question Answering over Knowledge\n  Graph", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": "10.1109/IKT51791.2020.9345610", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Question answering systems may find the answers to users' questions from\neither unstructured texts or structured data such as knowledge graphs.\nAnswering questions using supervised learning approaches including deep\nlearning models need large training datasets. In recent years, some datasets\nhave been presented for the task of Question answering over knowledge graphs,\nwhich is the focus of this paper. Although many datasets in English were\nproposed, there have been a few question-answering datasets in Persian. This\npaper introduces \\textit{PeCoQ}, a dataset for Persian question answering. This\ndataset contains 10,000 complex questions and answers extracted from the\nPersian knowledge graph, FarsBase. For each question, the SPARQL query and two\nparaphrases that were written by linguists are provided as well. There are\ndifferent types of complexities in the dataset, such as multi-relation,\nmulti-entity, ordinal, and temporal constraints. In this paper, we discuss the\ndataset's characteristics and describe our methodology for building it.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 08:21:23 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Etezadi", "Romina", ""], ["Shamsfard", "Mehrnoush", ""]]}, {"id": "2106.14195", "submitter": "Jaroslav Macke", "authors": "J. Macke, J. Sedlar, M. Olsak, J. Urban, J. Sivic", "title": "Learning to solve geometric construction problems from images", "comments": "16 pages, 7 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CG cs.LG cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe a purely image-based method for finding geometric constructions\nwith a ruler and compass in the Euclidea geometric game. The method is based on\nadapting the Mask R-CNN state-of-the-art image processing neural architecture\nand adding a tree-based search procedure to it. In a supervised setting, the\nmethod learns to solve all 68 kinds of geometric construction problems from the\nfirst six level packs of Euclidea with an average 92% accuracy. When evaluated\non new kinds of problems, the method can solve 31 of the 68 kinds of Euclidea\nproblems. We believe that this is the first time that a purely image-based\nlearning has been trained to solve geometric construction problems of this\ndifficulty.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 10:47:41 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Macke", "J.", ""], ["Sedlar", "J.", ""], ["Olsak", "M.", ""], ["Urban", "J.", ""], ["Sivic", "J.", ""]]}, {"id": "2106.14213", "submitter": "Srikanth Chandar", "authors": "Muvazima Mansoor, Srikanth Chandar, Ramamoorthy Srinath", "title": "AI based Presentation Creator With Customized Audio Content Delivery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an architecture to solve a novel problem statement\nthat has stemmed more so in recent times with an increase in demand for virtual\ncontent delivery due to the COVID-19 pandemic. All educational institutions,\nworkplaces, research centers, etc. are trying to bridge the gap of\ncommunication during these socially distanced times with the use of online\ncontent delivery. The trend now is to create presentations, and then\nsubsequently deliver the same using various virtual meeting platforms. The time\nbeing spent in such creation of presentations and delivering is what we try to\nreduce and eliminate through this paper which aims to use Machine Learning (ML)\nalgorithms and Natural Language Processing (NLP) modules to automate the\nprocess of creating a slides-based presentation from a document, and then use\nstate-of-the-art voice cloning models to deliver the content in the desired\nauthor's voice. We consider a structured document such as a research paper to\nbe the content that has to be presented. The research paper is first summarized\nusing BERT summarization techniques and condensed into bullet points that go\ninto the slides. Tacotron inspired architecture with Encoder, Synthesizer, and\na Generative Adversarial Network (GAN) based vocoder, is used to convey the\ncontents of the slides in the author's voice (or any customized voice). Almost\nall learning has now been shifted to online mode, and professionals are now\nworking from the comfort of their homes. Due to the current situation, teachers\nand professionals have shifted to presentations to help them in imparting\ninformation. In this paper, we aim to reduce the considerable amount of time\nthat is taken in creating a presentation by automating this process and\nsubsequently delivering this presentation in a customized voice, using a\ncontent delivery mechanism that can clone any voice using a short audio clip.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 12:17:11 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Mansoor", "Muvazima", ""], ["Chandar", "Srikanth", ""], ["Srinath", "Ramamoorthy", ""]]}, {"id": "2106.14251", "submitter": "Wolfgang Maass", "authors": "Wolfgang Maass, Veda C. Storey", "title": "Pairing Conceptual Modeling with Machine Learning", "comments": null, "journal-ref": "Data & Knowledge Engineering (2021)", "doi": "10.1016/j.datak.2021.101909", "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Both conceptual modeling and machine learning have long been recognized as\nimportant areas of research. With the increasing emphasis on digitizing and\nprocessing large amounts of data for business and other applications, it would\nbe helpful to consider how these areas of research can complement each other.\nTo understand how they can be paired, we provide an overview of machine\nlearning foundations and development cycle. We then examine how conceptual\nmodeling can be applied to machine learning and propose a framework for\nincorporating conceptual modeling into data science projects. The framework is\nillustrated by applying it to a healthcare application. For the inverse\npairing, machine learning can impact conceptual modeling through text and rule\nmining, as well as knowledge graphs. The pairing of conceptual modeling and\nmachine learning in this this way should help lay the foundations for future\nresearch.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 15:06:59 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 16:50:19 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2021 08:36:38 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Maass", "Wolfgang", ""], ["Storey", "Veda C.", ""]]}, {"id": "2106.14300", "submitter": "Ren Wang", "authors": "Ren Wang, Tianqi Chen, Philip Yao, Sijia Liu, Indika Rajapakse, Alfred\n  Hero", "title": "ASK: Adversarial Soft k-Nearest Neighbor Attack and Defense", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  K-Nearest Neighbor (kNN)-based deep learning methods have been applied to\nmany applications due to their simplicity and geometric interpretability.\nHowever, the robustness of kNN-based classification models has not been\nthoroughly explored and kNN attack strategies are underdeveloped. In this\npaper, we propose an Adversarial Soft kNN (ASK) loss to both design more\neffective kNN attack strategies and to develop better defenses against them.\nOur ASK loss approach has two advantages. First, ASK loss can better\napproximate the kNN's probability of classification error than objectives\nproposed in previous works. Second, the ASK loss is interpretable: it preserves\nthe mutual information between the perturbed input and the kNN of the\nunperturbed input. We use the ASK loss to generate a novel attack method called\nthe ASK-Attack (ASK-Atk), which shows superior attack efficiency and accuracy\ndegradation relative to previous kNN attacks. Based on the ASK-Atk, we then\nderive an ASK-Defense (ASK-Def) method that optimizes the worst-case training\nloss induced by ASK-Atk.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 17:58:59 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Wang", "Ren", ""], ["Chen", "Tianqi", ""], ["Yao", "Philip", ""], ["Liu", "Sijia", ""], ["Rajapakse", "Indika", ""], ["Hero", "Alfred", ""]]}, {"id": "2106.14305", "submitter": "Jaekyeom Kim", "authors": "Jaekyeom Kim, Seohong Park, Gunhee Kim", "title": "Unsupervised Skill Discovery with Bottleneck Option Learning", "comments": "Accepted to ICML 2021. Code at https://vision.snu.ac.kr/projects/ibol", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Having the ability to acquire inherent skills from environments without any\nexternal rewards or supervision like humans is an important problem. We propose\na novel unsupervised skill discovery method named Information Bottleneck Option\nLearning (IBOL). On top of the linearization of environments that promotes more\nvarious and distant state transitions, IBOL enables the discovery of diverse\nskills. It provides the abstraction of the skills learned with the information\nbottleneck framework for the options with improved stability and encouraged\ndisentanglement. We empirically demonstrate that IBOL outperforms multiple\nstate-of-the-art unsupervised skill discovery methods on the\ninformation-theoretic evaluations and downstream tasks in MuJoCo environments,\nincluding Ant, HalfCheetah, Hopper and D'Kitty.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 18:29:45 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Kim", "Jaekyeom", ""], ["Park", "Seohong", ""], ["Kim", "Gunhee", ""]]}, {"id": "2106.14361", "submitter": "Shib Sankar Dasgupta", "authors": "Shib Sankar Dasgupta, Michael Boratko, Shriya Atmakuri, Xiang Lorraine\n  Li, Dhruvesh Patel, Andrew McCallum", "title": "Word2Box: Learning Word Representation Using Box Embeddings", "comments": "Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning vector representations for words is one of the most fundamental\ntopics in NLP, capable of capturing syntactic and semantic relationships useful\nin a variety of downstream NLP tasks. Vector representations can be limiting,\nhowever, in that typical scoring such as dot product similarity intertwines\nposition and magnitude of the vector in space. Exciting innovations in the\nspace of representation learning have proposed alternative fundamental\nrepresentations, such as distributions, hyperbolic vectors, or regions. Our\nmodel, Word2Box, takes a region-based approach to the problem of word\nrepresentation, representing words as $n$-dimensional rectangles. These\nrepresentations encode position and breadth independently and provide\nadditional geometric operations such as intersection and containment which\nallow them to model co-occurrence patterns vectors struggle with. We\ndemonstrate improved performance on various word similarity tasks, particularly\non less common words, and perform a qualitative analysis exploring the\nadditional unique expressivity provided by Word2Box.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 01:17:11 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Dasgupta", "Shib Sankar", ""], ["Boratko", "Michael", ""], ["Atmakuri", "Shriya", ""], ["Li", "Xiang Lorraine", ""], ["Patel", "Dhruvesh", ""], ["McCallum", "Andrew", ""]]}, {"id": "2106.14396", "submitter": "Quan Vuong", "authors": "Quan Vuong, Yuzhe Qin, Runlin Guo, Xiaolong Wang, Hao Su, Henrik\n  Christensen", "title": "Single RGB-D Camera Teleoperation for General Robotic Manipulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a teleoperation system that uses a single RGB-D camera as the\nhuman motion capture device. Our system can perform general manipulation tasks\nsuch as cloth folding, hammering and 3mm clearance peg in hole. We propose the\nuse of non-Cartesian oblique coordinate frame, dynamic motion scaling and\nreposition of operator frames to increase the flexibility of our teleoperation\nsystem. We hypothesize that lowering the barrier of entry to teleoperation will\nallow for wider deployment of supervised autonomy system, which will in turn\ngenerates realistic datasets that unlock the potential of machine learning for\nrobotic manipulation.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 05:07:17 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 22:18:50 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Vuong", "Quan", ""], ["Qin", "Yuzhe", ""], ["Guo", "Runlin", ""], ["Wang", "Xiaolong", ""], ["Su", "Hao", ""], ["Christensen", "Henrik", ""]]}, {"id": "2106.14417", "submitter": "Dickson Owuor Dr.", "authors": "Dickson Odhiambo Owuor", "title": "Capturing the temporal constraints of gradual patterns", "comments": "155 pagesm Doctoral thesis, Montpellier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gradual pattern mining allows for extraction of attribute correlations\nthrough gradual rules such as: \"the more X, the more Y\". Such correlations are\nuseful in identifying and isolating relationships among the attributes that may\nnot be obvious through quick scans on a data set. For instance, a researcher\nmay apply gradual pattern mining to determine which attributes of a data set\nexhibit unfamiliar correlations in order to isolate them for deeper exploration\nor analysis. In this work, we propose an ant colony optimization technique\nwhich uses a popular probabilistic approach that mimics the behavior biological\nants as they search for the shortest path to find food in order to solve\ncombinatorial problems. In our second contribution, we extend an existing\ngradual pattern mining technique to allow for extraction of gradual patterns\ntogether with an approximated temporal lag between the affected gradual item\nsets. Such a pattern is referred to as a fuzzy-temporal gradual pattern and it\nmay take the form: \"the more X, the more Y, almost 3 months later\". In our\nthird contribution, we propose a data crossing model that allows for\nintegration of mostly gradual pattern mining algorithm implementations into a\nCloud platform. This contribution is motivated by the proliferation of IoT\napplications in almost every area of our society and this comes with provision\nof large-scale time-series data from different sources.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 06:45:48 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Owuor", "Dickson Odhiambo", ""]]}, {"id": "2106.14431", "submitter": "Steven Schockaert", "authors": "Steven Schockaert", "title": "Modelling Monotonic and Non-Monotonic Attribute Dependencies with\n  Embeddings: A Theoretical Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  During the last decade, entity embeddings have become ubiquitous in\nArtificial Intelligence. Such embeddings essentially serve as compact but\nsemantically meaningful representations of the entities of interest. In most\napproaches, vectors are used for representing the entities themselves, as well\nas for representing their associated attributes. An important advantage of\nusing attribute embeddings is that (some of the) semantic dependencies between\nthe attributes can thus be captured. However, little is known about what kinds\nof semantic dependencies can be modelled in this way. The aim of this paper is\nto shed light on this question, focusing on settings where the embedding of an\nentity is obtained by pooling the embeddings of its known attributes. Our\nparticular focus is on studying the theoretical limitations of different\nembedding strategies, rather than their ability to effectively learn attribute\ndependencies in practice. We first show a number of negative results, revealing\nthat some of the most popular embedding models are not able to capture even\nbasic Horn rules. However, we also find that some embedding strategies are\ncapable, in principle, of modelling both monotonic and non-monotonic attribute\ndependencies.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 07:29:11 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Schockaert", "Steven", ""]]}, {"id": "2106.14447", "submitter": "Zhiyu Cheng", "authors": "Xin Zhou, Le Kang, Zhiyu Cheng, Bo He, Jingyu Xin", "title": "Feature Combination Meets Attention: Baidu Soccer Embeddings and\n  Transformer based Temporal Detection", "comments": "Tech Report. Authors Xin Zhou, Le Kang, and Zhiyu Cheng made equal\n  contributions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With rapidly evolving internet technologies and emerging tools, sports\nrelated videos generated online are increasing at an unprecedentedly fast pace.\nTo automate sports video editing/highlight generation process, a key task is to\nprecisely recognize and locate the events in the long untrimmed videos. In this\ntech report, we present a two-stage paradigm to detect what and when events\nhappen in soccer broadcast videos. Specifically, we fine-tune multiple action\nrecognition models on soccer data to extract high-level semantic features, and\ndesign a transformer based temporal detection module to locate the target\nevents. This approach achieved the state-of-the-art performance in both two\ntasks, i.e., action spotting and replay grounding, in the SoccerNet-v2\nChallenge, under CVPR 2021 ActivityNet workshop. Our soccer embedding features\nare released at https://github.com/baidu-research/vidpress-sports. By sharing\nthese features with the broader community, we hope to accelerate the research\ninto soccer video understanding.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 08:00:21 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Zhou", "Xin", ""], ["Kang", "Le", ""], ["Cheng", "Zhiyu", ""], ["He", "Bo", ""], ["Xin", "Jingyu", ""]]}, {"id": "2106.14463", "submitter": "Saahil Jain", "authors": "Saahil Jain, Ashwin Agrawal, Adriel Saporta, Steven QH Truong, Du\n  Nguyen Duong, Tan Bui, Pierre Chambon, Yuhao Zhang, Matthew P. Lungren,\n  Andrew Y. Ng, Curtis P. Langlotz, Pranav Rajpurkar", "title": "RadGraph: Extracting Clinical Entities and Relations from Radiology\n  Reports", "comments": null, "journal-ref": null, "doi": "10.13026/hm87-5p47", "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting structured clinical information from free-text radiology reports\ncan enable the use of radiology report information for a variety of critical\nhealthcare applications. In our work, we present RadGraph, a dataset of\nentities and relations in full-text chest X-ray radiology reports based on a\nnovel information extraction schema we designed to structure radiology reports.\nWe release a development dataset, which contains board-certified radiologist\nannotations for 500 radiology reports from the MIMIC-CXR dataset (14,579\nentities and 10,889 relations), and a test dataset, which contains two\nindependent sets of board-certified radiologist annotations for 100 radiology\nreports split equally across the MIMIC-CXR and CheXpert datasets. Using these\ndatasets, we train and test a deep learning model, RadGraph Benchmark, that\nachieves a micro F1 of 0.82 and 0.73 on relation extraction on the MIMIC-CXR\nand CheXpert test sets respectively. Additionally, we release an inference\ndataset, which contains annotations automatically generated by RadGraph\nBenchmark across 220,763 MIMIC-CXR reports (around 6 million entities and 4\nmillion relations) and 500 CheXpert reports (13,783 entities and 9,908\nrelations) with mappings to associated chest radiographs. Our freely available\ndataset can facilitate a wide range of research in medical natural language\nprocessing, as well as computer vision and multi-modal learning when linked to\nchest radiographs.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 08:24:23 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Jain", "Saahil", ""], ["Agrawal", "Ashwin", ""], ["Saporta", "Adriel", ""], ["Truong", "Steven QH", ""], ["Duong", "Du Nguyen", ""], ["Bui", "Tan", ""], ["Chambon", "Pierre", ""], ["Zhang", "Yuhao", ""], ["Lungren", "Matthew P.", ""], ["Ng", "Andrew Y.", ""], ["Langlotz", "Curtis P.", ""], ["Rajpurkar", "Pranav", ""]]}, {"id": "2106.14464", "submitter": "Yilin Shen", "authors": "Yilin Shen, Yen-Chang Hsu, Avik Ray, Hongxia Jin", "title": "Enhancing the Generalization for Intent Classification and Out-of-Domain\n  Detection in SLU", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intent classification is a major task in spoken language understanding (SLU).\nSince most models are built with pre-collected in-domain (IND) training\nutterances, their ability to detect unsupported out-of-domain (OOD) utterances\nhas a critical effect in practical use. Recent works have shown that using\nextra data and labels can improve the OOD detection performance, yet it could\nbe costly to collect such data. This paper proposes to train a model with only\nIND data while supporting both IND intent classification and OOD detection. Our\nmethod designs a novel domain-regularized module (DRM) to reduce the\noverconfident phenomenon of a vanilla classifier, achieving a better\ngeneralization in both cases. Besides, DRM can be used as a drop-in replacement\nfor the last layer in any neural network-based intent classifier, providing a\nlow-cost strategy for a significant improvement. The evaluation on four\ndatasets shows that our method built on BERT and RoBERTa models achieves\nstate-of-the-art performance against existing approaches and the strong\nbaselines we created for the comparisons.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 08:27:38 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Shen", "Yilin", ""], ["Hsu", "Yen-Chang", ""], ["Ray", "Avik", ""], ["Jin", "Hongxia", ""]]}, {"id": "2106.14467", "submitter": "Sheng Huang", "authors": "Yi Zhang and Sheng Huang and Xi Peng and Dan Yang", "title": "Dizygotic Conditional Variational AutoEncoder for Multi-Modal and\n  Partial Modality Absent Few-Shot Learning", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Data augmentation is a powerful technique for improving the performance of\nthe few-shot classification task. It generates more samples as supplements, and\nthen this task can be transformed into a common supervised learning issue for\nsolution. However, most mainstream data augmentation based approaches only\nconsider the single modality information, which leads to the low diversity and\nquality of generated features. In this paper, we present a novel multi-modal\ndata augmentation approach named Dizygotic Conditional Variational AutoEncoder\n(DCVAE) for addressing the aforementioned issue. DCVAE conducts feature\nsynthesis via pairing two Conditional Variational AutoEncoders (CVAEs) with the\nsame seed but different modality conditions in a dizygotic symbiosis manner.\nSubsequently, the generated features of two CVAEs are adaptively combined to\nyield the final feature, which can be converted back into its paired conditions\nwhile ensuring these conditions are consistent with the original conditions not\nonly in representation but also in function. DCVAE essentially provides a new\nidea of data augmentation in various multi-modal scenarios by exploiting the\ncomplement of different modality prior information. Extensive experimental\nresults demonstrate our work achieves state-of-the-art performances on\nminiImageNet, CIFAR-FS and CUB datasets, and is able to work well in the\npartial modality absence case.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 08:29:55 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Zhang", "Yi", ""], ["Huang", "Sheng", ""], ["Peng", "Xi", ""], ["Yang", "Dan", ""]]}, {"id": "2106.14483", "submitter": "Azmi Can \\\"Ozgen", "authors": "Azmi Can \\\"Ozgen, Mahiye Uluya\\u{g}mur \\\"Ozt\\\"urk, Umut Bayraktar", "title": "Cheating Detection Pipeline for Online Interviews and Exams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remote examination and job interviews have gained popularity and become\nindispensable because of both pandemics and the advantage of remote working\ncircumstances. Most companies and academic institutions utilize these systems\nfor their recruitment processes and also for online exams. However, one of the\ncritical problems of the remote examination systems is conducting the exams in\na reliable environment. In this work, we present a cheating analysis pipeline\nfor online interviews and exams. The system only requires a video of the\ncandidate, which is recorded during the exam. Then cheating detection pipeline\nis employed to detect another person, electronic device usage, and candidate\nabsence status. The pipeline consists of face detection, face recognition,\nobject detection, and face tracking algorithms. To evaluate the performance of\nthe pipeline we collected a private video dataset. The video dataset includes\nboth cheating activities and clean videos. Ultimately, our pipeline presents an\nefficient and fast guideline to detect and analyze cheating activities in an\nonline interview and exam video.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 08:52:20 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["\u00d6zgen", "Azmi Can", ""], ["\u00d6zt\u00fcrk", "Mahiye Uluya\u011fmur", ""], ["Bayraktar", "Umut", ""]]}, {"id": "2106.14556", "submitter": "Adam White Dr", "authors": "Adam White, Kwun Ho Ngan, James Phelan, Saman Sadeghi Afgeh, Kevin\n  Ryan, Constantino Carlos Reyes-Aldasoro, Artur d'Avila Garcez", "title": "Contrastive Counterfactual Visual Explanations With Overdetermination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A novel explainable AI method called CLEAR Image is introduced in this paper.\nCLEAR Image is based on the view that a satisfactory explanation should be\ncontrastive, counterfactual and measurable. CLEAR Image explains an image's\nclassification probability by contrasting the image with a corresponding image\ngenerated automatically via adversarial learning. This enables both salient\nsegmentation and perturbations that faithfully determine each segment's\nimportance. CLEAR Image was successfully applied to a medical imaging case\nstudy where it outperformed methods such as Grad-CAM and LIME by an average of\n27% using a novel pointing game metric. CLEAR Image excels in identifying cases\nof \"causal overdetermination\" where there are multiple patches in an image, any\none of which is sufficient by itself to cause the classification probability to\nbe close to one.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 10:24:17 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["White", "Adam", ""], ["Ngan", "Kwun Ho", ""], ["Phelan", "James", ""], ["Afgeh", "Saman Sadeghi", ""], ["Ryan", "Kevin", ""], ["Reyes-Aldasoro", "Constantino Carlos", ""], ["Garcez", "Artur d'Avila", ""]]}, {"id": "2106.14563", "submitter": "Mahardhika Pratama Dr", "authors": "Mahardhika Pratama, Andri Ashfahani, Edwin Lughofer", "title": "Unsupervised Continual Learning via Self-Adaptive Deep Clustering\n  Approach", "comments": "currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Unsupervised continual learning remains a relatively uncharted territory in\nthe existing literature because the vast majority of existing works call for\nunlimited access of ground truth incurring expensive labelling cost. Another\nissue lies in the problem of task boundaries and task IDs which must be known\nfor model's updates or model's predictions hindering feasibility for real-time\ndeployment. Knowledge Retention in Self-Adaptive Deep Continual Learner,\n(KIERA), is proposed in this paper. KIERA is developed from the notion of\nflexible deep clustering approach possessing an elastic network structure to\ncope with changing environments in the timely manner. The centroid-based\nexperience replay is put forward to overcome the catastrophic forgetting\nproblem. KIERA does not exploit any labelled samples for model updates while\nfeaturing a task-agnostic merit. The advantage of KIERA has been numerically\nvalidated in popular continual learning problems where it shows highly\ncompetitive performance compared to state-of-the art approaches. Our\nimplementation is available in\n\\textit{\\url{https://github.com/ContinualAL/KIERA}}.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 10:37:14 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Pratama", "Mahardhika", ""], ["Ashfahani", "Andri", ""], ["Lughofer", "Edwin", ""]]}, {"id": "2106.14566", "submitter": "Joaqu\\'in Arias", "authors": "Joaqu\\'in Arias and Manuel Carro and Zhuo Chen and Gopal Gupta", "title": "Modeling and Reasoning in Event Calculus using Goal-Directed Constraint\n  Answer Set Programming", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automated commonsense reasoning is essential for building human-like AI\nsystems featuring, for example, explainable AI. Event Calculus (EC) is a family\nof formalisms that model commonsense reasoning with a sound, logical basis.\nPrevious attempts to mechanize reasoning using EC faced difficulties in the\ntreatment of the continuous change in dense domains (e.g., time and other\nphysical quantities), constraints among variables, default negation, and the\nuniform application of different inference methods, among others. We propose\nthe use of s(CASP), a query-driven, top-down execution model for Predicate\nAnswer Set Programming with Constraints, to model and reason using EC. We show\nhow EC scenarios can be naturally and directly encoded in s(CASP) and how it\nenables deductive and abductive reasoning tasks in domains featuring\nconstraints involving both dense time and dense fluents.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 10:43:25 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Arias", "Joaqu\u00edn", ""], ["Carro", "Manuel", ""], ["Chen", "Zhuo", ""], ["Gupta", "Gopal", ""]]}, {"id": "2106.14587", "submitter": "Jean-Claude Belfiore", "authors": "Jean-Claude Belfiore and Daniel Bennequin", "title": "Topos and Stacks of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every known artificial deep neural network (DNN) corresponds to an object in\na canonical Grothendieck's topos; its learning dynamic corresponds to a flow of\nmorphisms in this topos. Invariance structures in the layers (like CNNs or\nLSTMs) correspond to Giraud's stacks. This invariance is supposed to be\nresponsible of the generalization property, that is extrapolation from learning\ndata under constraints. The fibers represent pre-semantic categories (Culioli,\nThom), over which artificial languages are defined, with internal logics,\nintuitionist, classical or linear (Girard). Semantic functioning of a network\nis its ability to express theories in such a language for answering questions\nin output about input data. Quantities and spaces of semantic information are\ndefined by analogy with the homological interpretation of Shannon's entropy\n(P.Baudot and D.B. 2015). They generalize the measures found by Carnap and\nBar-Hillel (1952). Amazingly, the above semantical structures are classified by\ngeometric fibrant objects in a closed model category of Quillen, then they give\nrise to homotopical invariants of DNNs and of their semantic functioning.\nIntentional type theories (Martin-Loef) organize these objects and fibrations\nbetween them. Information contents and exchanges are analyzed by Grothendieck's\nderivators.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 11:50:06 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 13:45:45 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Belfiore", "Jean-Claude", ""], ["Bennequin", "Daniel", ""]]}, {"id": "2106.14609", "submitter": "Ehab Hamdy", "authors": "Ehab Hamdy", "title": "Neural Models for Offensive Language Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Offensive language detection is an ever-growing natural language processing\n(NLP) application. This growth is mainly because of the widespread usage of\nsocial networks, which becomes a mainstream channel for people to communicate,\nwork, and enjoy entertainment content. Many incidents of sharing aggressive and\noffensive content negatively impacted society to a great extend. We believe\ncontributing to improving and comparing different machine learning models to\nfight such harmful contents is an important and challenging goal for this\nthesis. We targeted the problem of offensive language detection for building\nefficient automated models for offensive language detection. With the recent\nadvancements of NLP models, specifically, the Transformer model, which tackled\nmany shortcomings of the standard seq-to-seq techniques. The BERT model has\nshown state-of-the-art results on many NLP tasks. Although the literature still\nexploring the reasons for the BERT achievements in the NLP field. Other\nefficient variants have been developed to improve upon the standard BERT, such\nas RoBERTa and ALBERT. Moreover, due to the multilingual nature of text on\nsocial media that could affect the model decision on a given tween, it is\nbecoming essential to examine multilingual models such as XLM-RoBERTa trained\non 100 languages and how did it compare to unilingual models. The RoBERTa based\nmodel proved to be the most capable model and achieved the highest F1 score for\nthe tasks. Another critical aspect of a well-rounded offensive language\ndetection system is the speed at which a model can be trained and make\ninferences. In that respect, we have considered the model run-time and\nfine-tuned the very efficient implementation of FastText called BlazingText\nthat achieved good results, which is much faster than BERT-based models.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 13:02:45 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Hamdy", "Ehab", ""]]}, {"id": "2106.14611", "submitter": "Yu Wang", "authors": "Yu Wang, Yilin Shen, Hongxia Jin", "title": "An Adversarial Learning based Multi-Step Spoken Language Understanding\n  System through Human-Computer Interaction", "comments": "5 Pages, original work published at ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the existing spoken language understanding systems can perform only\nsemantic frame parsing based on a single-round user query. They cannot take\nusers' feedback to update/add/remove slot values through multiround\ninteractions with users. In this paper, we introduce a novel multi-step spoken\nlanguage understanding system based on adversarial learning that can leverage\nthe multiround user's feedback to update slot values. We perform two\nexperiments on the benchmark ATIS dataset and demonstrate that the new system\ncan improve parsing performance by at least $2.5\\%$ in terms of F1, with only\none round of feedback. The improvement becomes even larger when the number of\nfeedback rounds increases. Furthermore, we also compare the new system with\nstate-of-the-art dialogue state tracking systems and demonstrate that the new\ninteractive system can perform better on multiround spoken language\nunderstanding tasks in terms of slot- and sentence-level accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 03:46:53 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Wang", "Yu", ""], ["Shen", "Yilin", ""], ["Jin", "Hongxia", ""]]}, {"id": "2106.14613", "submitter": "C. Maria Keet", "authors": "Zola Mahlaza and C. Maria Keet and Jarryd Dunn and Matthew Poulter", "title": "An evaluation of template and ML-based generation of user-readable text\n  from a knowledge graph", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical user-friendly renderings of knowledge graphs are visualisations and\nnatural language text. Within the latter HCI solution approach, data-driven\nnatural language generation systems receive increased attention, but they are\noften outperformed by template-based systems due to suffering from errors such\nas content dropping, hallucination, or repetition. It is unknown which of those\nerrors are associated significantly with low quality judgements by humans who\nthe text is aimed for, which hampers addressing errors based on their impact on\nimproving human evaluations. We assessed their possible association with an\nexperiment availing of expert and crowdsourced evaluations of human authored\ntext, template generated text, and sequence-to-sequence model generated text.\nThe results showed that there was no significant association between human\nauthored texts with errors and the low human judgements of naturalness and\nquality. There was also no significant association between machine learning\ngenerated texts with dropped or hallucinated slots and the low human judgements\nof naturalness and quality. Thus, both approaches appear to be viable options\nfor designing a natural language interface for knowledge graphs.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 14:47:19 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Mahlaza", "Zola", ""], ["Keet", "C. Maria", ""], ["Dunn", "Jarryd", ""], ["Poulter", "Matthew", ""]]}, {"id": "2106.14618", "submitter": "Anastasios Nentidis", "authors": "Anastasios Nentidis, Anastasia Krithara, Konstantinos Bougiatiotis,\n  Martin Krallinger, Carlos Rodriguez-Penagos, Marta Villegas, Georgios\n  Paliouras", "title": "Overview of BioASQ 2020: The eighth BioASQ challenge on Large-Scale\n  Biomedical Semantic Indexing and Question Answering", "comments": "21 pages, 10 tables, 3 figures", "journal-ref": "Arampatzis A. et al. (eds) Experimental IR Meets Multilinguality,\n  Multimodality, and Interaction. CLEF 2020. Lecture Notes in Computer Science,\n  vol 12260. Springer, Cham", "doi": "10.1007/978-3-030-58219-7_16", "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an overview of the eighth edition of the BioASQ\nchallenge, which ran as a lab in the Conference and Labs of the Evaluation\nForum (CLEF) 2020. BioASQ is a series of challenges aiming at the promotion of\nsystems and methodologies for large-scale biomedical semantic indexing and\nquestion answering. To this end, shared tasks are organized yearly since 2012,\nwhere different teams develop systems that compete on the same demanding\nbenchmark datasets that represent the real information needs of experts in the\nbiomedical domain. This year, the challenge has been extended with the\nintroduction of a new task on medical semantic indexing in Spanish. In total,\n34 teams with more than 100 systems participated in the three tasks of the\nchallenge. As in previous years, the results of the evaluation reveal that the\ntop-performing systems managed to outperform the strong baselines, which\nsuggests that state-of-the-art systems keep pushing the frontier of research\nthrough continuous improvements.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 12:24:17 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Nentidis", "Anastasios", ""], ["Krithara", "Anastasia", ""], ["Bougiatiotis", "Konstantinos", ""], ["Krallinger", "Martin", ""], ["Rodriguez-Penagos", "Carlos", ""], ["Villegas", "Marta", ""], ["Paliouras", "Georgios", ""]]}, {"id": "2106.14625", "submitter": "Leo Bouscarrat", "authors": "L\\'eo Bouscarrat (LIS, TALEP, QARMA), Antoine Bonnefoy, C\\'ecile\n  Capponi (LIS, QARMA), Carlos Ramisch (LIS, TALEP)", "title": "AMU-EURANOVA at CASE 2021 Task 1: Assessing the stability of\n  multilingual BERT", "comments": null, "journal-ref": "Proceedings of the 4th Workshop on Challenges and Applications of\n  Automated Extraction of Socio-political Events from Text (CASE 2021), Aug\n  2021, Online, Unknown Region", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explains our participation in task 1 of the CASE 2021 shared task.\nThis task is about multilingual event extraction from news. We focused on\nsub-task 4, event information extraction. This sub-task has a small training\ndataset and we fine-tuned a multilingual BERT to solve this sub-task. We\nstudied the instability problem on the dataset and tried to mitigate it.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 07:54:39 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Bouscarrat", "L\u00e9o", "", "LIS, TALEP, QARMA"], ["Bonnefoy", "Antoine", "", "LIS, QARMA"], ["Capponi", "C\u00e9cile", "", "LIS, QARMA"], ["Ramisch", "Carlos", "", "LIS, TALEP"]]}, {"id": "2106.14642", "submitter": "Li Meng", "authors": "Li Meng, Anis Yazidi, Morten Goodwin, Paal Engelstad", "title": "Expert Q-learning: Deep Q-learning With State Values From Expert\n  Examples", "comments": "fix typos, add discriptions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel algorithm named Expert Q-learning. Expert Q-learning was\ninspired by Dueling Q-learning and aimed at incorporating the ideas from\nsemi-supervised learning into reinforcement learning through splitting Q-values\ninto state values and action advantages. Different from Generative Adversarial\nImitation Learning and Deep Q-Learning from Demonstrations, the offline expert\nwe have used only predicts the value of a state from {-1, 0, 1}, indicating\nwhether this is a bad, neutral or good state. An expert network was designed in\naddition to the Q-network, which updates each time following the regular\noffline minibatch update whenever the expert example buffer is not empty. The\nQ-network plays the role of the advantage function only during the update. Our\nalgorithm also keeps asynchronous copies of the Q-network and expert network,\npredicting the target values using the same manner as of Double Q-learning.\n  We compared on the game of Othello our algorithm with the state-of-the-art\nQ-learning algorithm, which was a combination of Double Q-learning and Dueling\nQ-learning. The results showed that Expert Q-learning was indeed useful and\nmore resistant to the overestimation bias of Q-learning. The baseline\nQ-learning algorithm exhibited unstable and suboptimal behavior, especially\nwhen playing against a stochastic player, whereas Expert Q-learning\ndemonstrated more robust performance with higher scores. Expert Q-learning\nwithout using examples has also gained better results than the baseline\nalgorithm when trained and tested against a fixed player. On the other hand,\nExpert Q-learning without examples cannot win against the baseline Q-learning\nalgorithm in direct game competitions despite the fact that it has also shown\nthe strength of reducing the overestimation bias.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 12:41:45 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 13:37:31 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Meng", "Li", ""], ["Yazidi", "Anis", ""], ["Goodwin", "Morten", ""], ["Engelstad", "Paal", ""]]}, {"id": "2106.14652", "submitter": "Peiyuan Zhu", "authors": "Peiyuan Zhu, Xiaofeng Wang, Zisen Sang, Aiquan Yuan, Guodong Cao", "title": "Context-aware Heterogeneous Graph Attention Network for User Behavior\n  Prediction in Local Consumer Service Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  As a new type of e-commerce platform developed in recent years, local\nconsumer service platform provides users with software to consume service to\nthe nearby store or to the home, such as Groupon and Koubei. Different from\nother common e-commerce platforms, the behavior of users on the local consumer\nservice platform is closely related to their real-time local context\ninformation. Therefore, building a context-aware user behavior prediction\nsystem is able to provide both merchants and users better service in local\nconsumer service platforms. However, most of the previous work just treats the\ncontextual information as an ordinary feature into the prediction model to\nobtain the prediction list under a specific context, which ignores the fact\nthat the interest of a user in different contexts is often significantly\ndifferent. Hence, in this paper, we propose a context-aware heterogeneous graph\nattention network (CHGAT) to dynamically generate the representation of the\nuser and to estimate the probability for future behavior. Specifically, we\nfirst construct the meta-path based heterogeneous graphs with the historical\nbehaviors from multiple sources and comprehend heterogeneous vertices in the\ngraph with a novel unified knowledge representing approach. Next, a multi-level\nattention mechanism is introduced for context-aware aggregation with graph\nvertices, which contains the vertex-level attention network and the path-level\nattention network. Both of them aim to capture the semantic correlation between\ninformation contained in the graph and the outside real-time contextual\ninformation in the search system. Then the model proposed in this paper\naggregates specific graphs with their corresponding context features and\nobtains the representation of user interest under a specific context and input\nit into the prediction network to finally obtain the predicted probability of\nuser behavior.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 03:08:21 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 14:54:50 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Zhu", "Peiyuan", ""], ["Wang", "Xiaofeng", ""], ["Sang", "Zisen", ""], ["Yuan", "Aiquan", ""], ["Cao", "Guodong", ""]]}, {"id": "2106.14662", "submitter": "Chunwei Ma", "authors": "Chunwei Ma, Ziyun Huang, Jiayi Xian, Mingchen Gao, Jinhui Xu", "title": "Improving Uncertainty Calibration of Deep Neural Networks via Truth\n  Discovery and Geometric Optimization", "comments": "37th Conference on Uncertainty in Artificial Intelligence (UAI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deep Neural Networks (DNNs), despite their tremendous success in recent\nyears, could still cast doubts on their predictions due to the intrinsic\nuncertainty associated with their learning process. Ensemble techniques and\npost-hoc calibrations are two types of approaches that have individually shown\npromise in improving the uncertainty calibration of DNNs. However, the\nsynergistic effect of the two types of methods has not been well explored. In\nthis paper, we propose a truth discovery framework to integrate ensemble-based\nand post-hoc calibration methods. Using the geometric variance of the ensemble\ncandidates as a good indicator for sample uncertainty, we design an\naccuracy-preserving truth estimator with provably no accuracy drop.\nFurthermore, we show that post-hoc calibration can also be enhanced by truth\ndiscovery-regularized optimization. On large-scale datasets including CIFAR and\nImageNet, our method shows consistent improvement against state-of-the-art\ncalibration approaches on both histogram-based and kernel density-based\nevaluation metrics. Our codes are available at\nhttps://github.com/horsepurve/truly-uncertain.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 06:44:16 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Ma", "Chunwei", ""], ["Huang", "Ziyun", ""], ["Xian", "Jiayi", ""], ["Gao", "Mingchen", ""], ["Xu", "Jinhui", ""]]}, {"id": "2106.14688", "submitter": "Trevor Bench-Capon", "authors": "Trevor Bench-Capon", "title": "Using Issues to Explain Legal Decisions", "comments": "Presented at the XAILA workshop 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The need to explain the output from Machine Learning systems designed to\npredict the outcomes of legal cases has led to a renewed interest in the\nexplanations offered by traditional AI and Law systems, especially those using\nfactor based reasoning and precedent cases. In this paper we consider what sort\nof explanations we should expect from such systems, with a particular focus on\nthe structure that can be provided by the use of issues in cases.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 15:06:33 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Bench-Capon", "Trevor", ""]]}, {"id": "2106.14693", "submitter": "Adam Polak", "authors": "Jakub Ch{\\l}\\k{e}dowski, Adam Polak, Bartosz Szabucki, Konrad Zolna", "title": "Robust Learning-Augmented Caching: An Experimental Study", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective caching is crucial for the performance of modern-day computing\nsystems. A key optimization problem arising in caching -- which item to evict\nto make room for a new item -- cannot be optimally solved without knowing the\nfuture. There are many classical approximation algorithms for this problem, but\nmore recently researchers started to successfully apply machine learning to\ndecide what to evict by discovering implicit input patterns and predicting the\nfuture. While machine learning typically does not provide any worst-case\nguarantees, the new field of learning-augmented algorithms proposes solutions\nthat leverage classical online caching algorithms to make the machine-learned\npredictors robust. We are the first to comprehensively evaluate these\nlearning-augmented algorithms on real-world caching datasets and\nstate-of-the-art machine-learned predictors. We show that a straightforward\nmethod -- blindly following either a predictor or a classical robust algorithm,\nand switching whenever one becomes worse than the other -- has only a low\noverhead over a well-performing predictor, while competing with classical\nmethods when the coupled predictor fails, thus providing a cheap worst-case\ninsurance.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 13:15:07 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Ch\u0142\u0119dowski", "Jakub", ""], ["Polak", "Adam", ""], ["Szabucki", "Bartosz", ""], ["Zolna", "Konrad", ""]]}, {"id": "2106.14694", "submitter": "Zhiqiang Deng", "authors": "Zhiqiang Deng, Huimin Yu and Yangqi Long", "title": "Fractal Pyramid Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a new network architecture, the Fractal Pyramid Networks (PFNs)\nfor pixel-wise prediction tasks as an alternative to the widely used\nencoder-decoder structure. In the encoder-decoder structure, the input is\nprocessed by an encoding-decoding pipeline that tries to get a semantic\nlarge-channel feature. Different from that, our proposed PFNs hold multiple\ninformation processing pathways and encode the information to multiple separate\nsmall-channel features. On the task of self-supervised monocular depth\nestimation, even without ImageNet pretrained, our models can compete or\noutperform the state-of-the-art methods on the KITTI dataset with much fewer\nparameters. Moreover, the visual quality of the prediction is significantly\nimproved. The experiment of semantic segmentation provides evidence that the\nPFNs can be applied to other pixel-wise prediction tasks, and demonstrates that\nour models can catch more global structure information.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 13:15:30 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Deng", "Zhiqiang", ""], ["Yu", "Huimin", ""], ["Long", "Yangqi", ""]]}, {"id": "2106.14742", "submitter": "Siamak Mehrkanoon", "authors": "Onur Bilgin, Pawe{\\l} M\\k{a}ka, Thomas Vergutz and Siamak Mehrkanoon", "title": "TENT: Tensorized Encoder Transformer for Temperature Forecasting", "comments": "9 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Reliable weather forecasting is of great importance in science, business and\nsociety. The best performing data-driven models for weather prediction tasks\nrely on recurrent or convolutional neural networks, where some of which\nincorporate attention mechanisms. In this work, we introduce a new model based\non the Transformer architecture for weather forecasting. The proposed Tensorial\nEncoder Transformer (TENT) model is equipped with tensorial attention and thus\nit exploits the spatiotemporal structure of weather data by processing it in\nmultidimensional tensorial format. We show that compared to the encoder part of\nthe original transformer and 3D convolutional neural networks, the proposed\nTENT model can better model the underlying complex pattern of weather data for\nthe studied temperature prediction task. Experiments on two real-life weather\ndatasets are performed. The datasets consist of historical measurements from\nUSA, Canada and European cities. The first dataset contains hourly measurements\nof weather attributes for 30 cities in USA and Canada from October 2012 to\nNovember 2017. The second dataset contains daily measurements of weather\nattributes of 18 cities across Europe from May 2005 to April 2020. We use\nattention scores calculated from our attention mechanism to shed light on the\ndecision-making process of our model and have insight knowledge on the most\nimportant cities for the task.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 14:17:22 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Bilgin", "Onur", ""], ["M\u0105ka", "Pawe\u0142", ""], ["Vergutz", "Thomas", ""], ["Mehrkanoon", "Siamak", ""]]}, {"id": "2106.14749", "submitter": "Pan Zhou", "authors": "Pan Zhou, Caiming Xiong, Xiao-Tong Yuan, Steven Hoi", "title": "A Theory-Driven Self-Labeling Refinement Method for Contrastive\n  Representation Learning", "comments": "under review. arXiv admin note: substantial text overlap with\n  arXiv:1903.11680 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG math.OC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  For an image query, unsupervised contrastive learning labels crops of the\nsame image as positives, and other image crops as negatives. Although\nintuitive, such a native label assignment strategy cannot reveal the underlying\nsemantic similarity between a query and its positives and negatives, and\nimpairs performance, since some negatives are semantically similar to the query\nor even share the same semantic class as the query. In this work, we first\nprove that for contrastive learning, inaccurate label assignment heavily\nimpairs its generalization for semantic instance discrimination, while accurate\nlabels benefit its generalization. Inspired by this theory, we propose a novel\nself-labeling refinement approach for contrastive learning. It improves the\nlabel quality via two complementary modules: (i) self-labeling refinery (SLR)\nto generate accurate labels and (ii) momentum mixup (MM) to enhance similarity\nbetween query and its positive. SLR uses a positive of a query to estimate\nsemantic similarity between a query and its positive and negatives, and\ncombines estimated similarity with vanilla label assignment in contrastive\nlearning to iteratively generate more accurate and informative soft labels. We\ntheoretically show that our SLR can exactly recover the true semantic labels of\nlabel-corrupted data, and supervises networks to achieve zero prediction error\non classification tasks. MM randomly combines queries and positives to increase\nsemantic similarity between the generated virtual queries and their positives\nso as to improves label accuracy. Experimental results on CIFAR10, ImageNet,\nVOC and COCO show the effectiveness of our method. PyTorch code and model will\nbe released online.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 14:24:52 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Zhou", "Pan", ""], ["Xiong", "Caiming", ""], ["Yuan", "Xiao-Tong", ""], ["Hoi", "Steven", ""]]}, {"id": "2106.14763", "submitter": "Yin Yang", "authors": "Yin Yang", "title": "Training Massive Deep Neural Networks in a Smart Contract: A New Hope", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deep neural networks (DNNs) could be very useful in blockchain applications\nsuch as DeFi and NFT trading. However, training / running large-scale DNNs as\npart of a smart contract is infeasible on today's blockchain platforms, due to\ntwo fundamental design issues of these platforms. First, blockchains nowadays\ntypically require that each node maintain the complete world state at any time,\nmeaning that the node must execute all transactions in every block. This is\nprohibitively expensive for computationally intensive smart contracts involving\nDNNs. Second, existing blockchain platforms expect smart contract transactions\nto have deterministic, reproducible results and effects. In contrast, DNNs are\nusually trained / run lock-free on massively parallel computing devices such as\nGPUs, TPUs and / or computing clusters, which often do not yield deterministic\nresults.\n  This paper proposes novel platform designs, collectively called A New Hope\n(ANH), that address the above issues. The main ideas are (i)\ncomputing-intensive smart contract transactions are only executed by nodes who\nneed their results, or by specialized serviced providers, and (ii) a\nnon-deterministic smart contract transaction leads to uncertain results, which\ncan still be validated, though at a relatively high cost; specifically for\nDNNs, the validation cost can often be reduced by verifying properties of the\nresults instead of their exact values. In addition, we discuss various\nimplications of ANH, including its effects on token fungibility, sharding,\nprivate transactions, and the fundamental meaning of a smart contract.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 14:38:44 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Yang", "Yin", ""]]}, {"id": "2106.14801", "submitter": "Loris Bozzato", "authors": "Loris Bozzato, Thomas Eiter, Luciano Serafini", "title": "Reasoning on $\\textit{DL-Lite}_{\\cal R}$ with Defeasibility in ASP", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP). This paper is an extended and revised version of a conference paper\n  appearing in the proceedings of the 3rd International Joint Conference on\n  Rules and Reasoning (RuleML+RR 2019). (v2 updates: added discussion on\n  equivalence in Appendix, typos corrected). arXiv admin note: text overlap\n  with arXiv:1905.09221", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning on defeasible knowledge is a topic of interest in the area of\ndescription logics, as it is related to the need of representing exceptional\ninstances in knowledge bases. In this direction, in our previous works we\npresented a framework for representing (contextualized) OWL RL knowledge bases\nwith a notion of justified exceptions on defeasible axioms: reasoning in such\nframework is realized by a translation into ASP programs. The resulting\nreasoning process for OWL RL, however, introduces a complex encoding in order\nto capture reasoning on the negative information needed for reasoning on\nexceptions. In this paper, we apply the justified exception approach to\nknowledge bases in $\\textit{DL-Lite}_{\\cal R}$, i.e., the language underlying\nOWL QL. We provide a definition for $\\textit{DL-Lite}_{\\cal R}$ knowledge bases\nwith defeasible axioms and study their semantic and computational properties.\nIn particular, we study the effects of exceptions over unnamed individuals. The\nlimited form of $\\textit{DL-Lite}_{\\cal R}$ axioms allows us to formulate a\nsimpler ASP encoding, where reasoning on negative information is managed by\ndirect rules. The resulting materialization method gives rise to a complete\nreasoning procedure for instance checking in $\\textit{DL-Lite}_{\\cal R}$ with\ndefeasible axioms. Under consideration in Theory and Practice of Logic\nProgramming (TPLP).\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 15:23:11 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 13:51:29 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Bozzato", "Loris", ""], ["Eiter", "Thomas", ""], ["Serafini", "Luciano", ""]]}, {"id": "2106.14804", "submitter": "Yunsong Zhao", "authors": "Yunsong Zhao, Yin Li, Zhihan Chen, Tianchong Qiu and Guojin Liu", "title": "Hyperspectral Remote Sensing Image Classification Based on Multi-scale\n  Cross Graphic Convolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The mining and utilization of features directly affect the classification\nperformance of models used in the classification and recognition of\nhyperspectral remote sensing images. Traditional models usually conduct feature\nmining from a single perspective, with the features mined being limited and the\ninternal relationships between them being ignored. Consequently, useful\nfeatures are lost and classification results are unsatisfactory. To fully mine\nand utilize image features, a new multi-scale feature-mining learning algorithm\n(MGRNet) is proposed. The model uses principal component analysis to reduce the\ndimensionality of the original hyperspectral image (HSI) to retain 99.99% of\nits semantic information and extract dimensionality reduction features. Using a\nmulti-scale convolution algorithm, the input dimensionality reduction features\nwere mined to obtain shallow features, which then served as inputs into a\nmulti-scale graph convolution algorithm to construct the internal relationships\nbetween eigenvalues at different scales. We then carried out cross fusion of\nmulti-scale information obtained by graph convolution, before inputting the new\ninformation obtained into the residual network algorithm for deep feature\nmining. Finally, a flexible maximum transfer function classifier was used to\npredict the final features and complete the classification. Experiments on\nthree common hyperspectral datasets showed the MGRNet algorithm proposed in\nthis paper to be superior to traditional methods in recognition accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 15:28:09 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Zhao", "Yunsong", ""], ["Li", "Yin", ""], ["Chen", "Zhihan", ""], ["Qiu", "Tianchong", ""], ["Liu", "Guojin", ""]]}, {"id": "2106.14815", "submitter": "Gilad Gressel", "authors": "Gilad Gressel, Niranjan Hegde, Archana Sreekumar, and Michael Darling", "title": "Feature Importance Guided Attack: A Model Agnostic Adversarial Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning models are susceptible to adversarial attacks which\ndramatically reduce their performance. Reliable defenses to these attacks are\nan unsolved challenge. In this work, we present a novel evasion attack: the\n'Feature Importance Guided Attack' (FIGA) which generates adversarial evasion\nsamples. FIGA is model agnostic, it assumes no prior knowledge of the defending\nmodel's learning algorithm, but does assume knowledge of the feature\nrepresentation. FIGA leverages feature importance rankings; it perturbs the\nmost important features of the input in the direction of the target class we\nwish to mimic. We demonstrate FIGA against eight phishing detection models. We\nkeep the attack realistic by perturbing phishing website features that an\nadversary would have control over. Using FIGA we are able to cause a reduction\nin the F1-score of a phishing detection model from 0.96 to 0.41 on average.\nFinally, we implement adversarial training as a defense against FIGA and show\nthat while it is sometimes effective, it can be evaded by changing the\nparameters of FIGA.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 15:46:22 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Gressel", "Gilad", ""], ["Hegde", "Niranjan", ""], ["Sreekumar", "Archana", ""], ["Darling", "Michael", ""]]}, {"id": "2106.14835", "submitter": "Anna Xambo", "authors": "Anna Xamb\\'o", "title": "Virtual Agents in Live Coding: A Short Review", "comments": "Preprint version submitted to eContact! (https://econtact.ca) for the\n  special issue 21.1 - Take Back the Stage: Live coding, live audiovisual,\n  laptop orchestra", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  AI and live coding has been little explored. This article contributes with a\nshort review of different perspectives of using virtual agents in the practice\nof live coding looking at past and present as well as pointing to future\ndirections.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 16:23:38 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Xamb\u00f3", "Anna", ""]]}, {"id": "2106.14838", "submitter": "Matthew Barren", "authors": "Matthew Barren, Milos Hauskrecht", "title": "Improving Prediction of Low-Prior Clinical Events with Simultaneous\n  General Patient-State Representation Learning", "comments": "Accepted at 19th International Conference on Artificial Intelligence\n  in Medicine (AIME 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-prior targets are common among many important clinical events, which\nintroduces the challenge of having enough data to support learning of their\npredictive models. Many prior works have addressed this problem by first\nbuilding a general patient-state representation model, and then adapting it to\na new low-prior prediction target. In this schema, there is potential for the\npredictive performance to be hindered by the misalignment between the general\npatient-state model and the target task. To overcome this challenge, we propose\na new method that simultaneously optimizes a shared model through multi-task\nlearning of both the low-prior supervised target and general purpose\npatient-state representation (GPSR). More specifically, our method improves\nprediction performance of a low-prior task by jointly optimizing a shared model\nthat combines the loss of the target event and a broad range of generic\nclinical events. We study the approach in the context of Recurrent Neural\nNetworks (RNNs). Through extensive experiments on multiple clinical event\ntargets using MIMIC-III data, we show that the inclusion of general\npatient-state representation tasks during model training improves the\nprediction of individual low-prior targets.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 16:32:12 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Barren", "Matthew", ""], ["Hauskrecht", "Milos", ""]]}, {"id": "2106.14855", "submitter": "Wenwei Zhang", "authors": "Wenwei Zhang, Jiangmiao Pang, Kai Chen, Chen Change Loy", "title": "K-Net: Towards Unified Image Segmentation", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Semantic, instance, and panoptic segmentations have been addressed using\ndifferent and specialized frameworks despite their underlying connections. This\npaper presents a unified, simple, and effective framework for these essentially\nsimilar tasks. The framework, named K-Net, segments both instances and semantic\ncategories consistently by a group of learnable kernels, where each kernel is\nresponsible for generating a mask for either a potential instance or a stuff\nclass. To remedy the difficulties of distinguishing various instances, we\npropose a kernel update strategy that enables each kernel dynamic and\nconditional on its meaningful group in the input image. K-Net can be trained in\nan end-to-end manner with bipartite matching, and its training and inference\nare naturally NMS-free and box-free. Without bells and whistles, K-Net\nsurpasses all previous state-of-the-art single-model results of panoptic\nsegmentation on MS COCO and semantic segmentation on ADE20K with 52.1% PQ and\n54.3% mIoU, respectively. Its instance segmentation performance is also on par\nwith Cascade Mask R-CNNon MS COCO with 60%-90% faster inference speeds. Code\nand models will be released at https://github.com/open-mmlab/mmdetection.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 17:18:21 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Zhang", "Wenwei", ""], ["Pang", "Jiangmiao", ""], ["Chen", "Kai", ""], ["Loy", "Chen Change", ""]]}, {"id": "2106.14861", "submitter": "Zainul Abi Din", "authors": "Zainul Abi Din (1), Hari Venugopalan (1), Henry Lin (2), Adam\n  Wushensky (2), Steven Liu (2), Samuel T. King (1 and 2) ((1) University of\n  California, Davis, (2) Bouncer Technologies)", "title": "Doing good by fighting fraud: Ethical anti-fraud systems for mobile\n  payments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  App builders commonly use security challenges, a form of step-up\nauthentication, to add security to their apps. However, the ethical\nimplications of this type of architecture has not been studied previously. In\nthis paper, we present a large-scale measurement study of running an existing\nanti-fraud security challenge, Boxer, in real apps running on mobile devices.\nWe find that although Boxer does work well overall, it is unable to scan\neffectively on devices that run its machine learning models at less than one\nframe per second (FPS), blocking users who use inexpensive devices. With the\ninsights from our study, we design Daredevil, anew anti-fraud system for\nscanning payment cards that work swell across the broad range of performance\ncharacteristics and hardware configurations found on modern mobile devices.\nDaredevil reduces the number of devices that run at less than one FPS by an\norder of magnitude compared to Boxer, providing a more equitable system for\nfighting fraud. In total, we collect data from 5,085,444 real devices spread\nacross 496 real apps running production software and interacting with real\nusers.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 17:28:28 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 01:46:13 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Din", "Zainul Abi", "", "1 and 2"], ["Venugopalan", "Hari", "", "1 and 2"], ["Lin", "Henry", "", "1 and 2"], ["Wushensky", "Adam", "", "1 and 2"], ["Liu", "Steven", "", "1 and 2"], ["King", "Samuel T.", "", "1 and 2"]]}, {"id": "2106.14866", "submitter": "Wenshuo Guo", "authors": "Wenshuo Guo, Kumar Krishna Agrawal, Aditya Grover, Vidya Muthukumar,\n  Ashwin Pananjady", "title": "Learning from an Exploring Demonstrator: Optimal Reward Estimation for\n  Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IT cs.LG cs.RO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the \"inverse bandit\" problem of estimating the rewards of a\nmulti-armed bandit instance from observing the learning process of a low-regret\ndemonstrator. Existing approaches to the related problem of inverse\nreinforcement learning assume the execution of an optimal policy, and thereby\nsuffer from an identifiability issue. In contrast, our paradigm leverages the\ndemonstrator's behavior en route to optimality, and in particular, the\nexploration phase, to obtain consistent reward estimates. We develop simple and\nefficient reward estimation procedures for demonstrations within a class of\nupper-confidence-based algorithms, showing that reward estimation gets\nprogressively easier as the regret of the algorithm increases. We match these\nupper bounds with information-theoretic lower bounds that apply to any\ndemonstrator algorithm, thereby characterizing the optimal tradeoff between\nexploration and reward estimation. Extensive empirical evaluations on both\nsynthetic data and simulated experimental design data from the natural sciences\ncorroborate our theoretical results.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 17:37:49 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Guo", "Wenshuo", ""], ["Agrawal", "Kumar Krishna", ""], ["Grover", "Aditya", ""], ["Muthukumar", "Vidya", ""], ["Pananjady", "Ashwin", ""]]}, {"id": "2106.14885", "submitter": "Anastasios Nentidis", "authors": "Anastasios Nentidis, Georgios Katsimpras, Eirini Vandorou, Anastasia\n  Krithara, Luis Gasco, Martin Krallinger, Georgios Paliouras", "title": "Overview of BioASQ 2021: The ninth BioASQ challenge on Large-Scale\n  Biomedical Semantic Indexing and Question Answering", "comments": "25 pages, 15 tables, 3 figures. arXiv admin note: text overlap with\n  arXiv:2106.14618", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advancing the state-of-the-art in large-scale biomedical semantic indexing\nand question answering is the main focus of the BioASQ challenge. BioASQ\norganizes respective tasks where different teams develop systems that are\nevaluated on the same benchmark datasets that represent the real information\nneeds of experts in the biomedical domain. This paper presents an overview of\nthe ninth edition of the BioASQ challenge in the context of the Conference and\nLabs of the Evaluation Forum (CLEF) 2021. In this year, a new question\nanswering task, named Synergy, is introduced to support researchers studying\nthe COVID-19 disease and measure the ability of the participating teams to\ndiscern information while the problem is still developing. In total, 42 teams\nwith more than 170 systems were registered to participate in the four tasks of\nthe challenge. The evaluation results, similarly to previous years, show a\nperformance gain against the baselines which indicates the continuous\nimprovement of the state-of-the-art in this field.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 10:03:11 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Nentidis", "Anastasios", ""], ["Katsimpras", "Georgios", ""], ["Vandorou", "Eirini", ""], ["Krithara", "Anastasia", ""], ["Gasco", "Luis", ""], ["Krallinger", "Martin", ""], ["Paliouras", "Georgios", ""]]}, {"id": "2106.14943", "submitter": "Pu Zhao", "authors": "Pu Zhao, Wei Niu, Geng Yuan, Yuxuan Cai, Bin Ren, Yanzhi Wang, Xue Lin", "title": "Achieving Real-Time Object Detection on MobileDevices with Neural\n  Pruning Search", "comments": "Presented on the HiPEAC 2021 workshop (cogarch 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Object detection plays an important role in self-driving cars for security\ndevelopment. However, mobile systems on self-driving cars with limited\ncomputation resources lead to difficulties for object detection. To facilitate\nthis, we propose a compiler-aware neural pruning search framework to achieve\nhigh-speed inference on autonomous vehicles for 2D and 3D object detection. The\nframework automatically searches the pruning scheme and rate for each layer to\nfind a best-suited pruning for optimizing detection accuracy and speed\nperformance under compiler optimization. Our experiments demonstrate that for\nthe first time, the proposed method achieves (close-to) real-time, 55ms and\n99ms inference times for YOLOv4 based 2D object detection and PointPillars\nbased 3D detection, respectively, on an off-the-shelf mobile phone with minor\n(or no) accuracy loss.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 18:59:20 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Zhao", "Pu", ""], ["Niu", "Wei", ""], ["Yuan", "Geng", ""], ["Cai", "Yuxuan", ""], ["Ren", "Bin", ""], ["Wang", "Yanzhi", ""], ["Lin", "Xue", ""]]}, {"id": "2106.14977", "submitter": "Sharada Mohanty", "authors": "Sharada Prasanna Mohanty, Gaurav Singhal, Eric Antoine Scuccimarra,\n  Djilani Kebaili, Harris H\\'eritier, Victor Boulanger, Marcel Salath\\'e", "title": "The Food Recognition Benchmark: Using DeepLearning to Recognize Food on\n  Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The automatic recognition of food on images has numerous interesting\napplications, including nutritional tracking in medical cohorts. The problem\nhas received significant research attention, but an ongoing public benchmark to\ndevelop open and reproducible algorithms has been missing. Here, we report on\nthe setup of such a benchmark using publicly available food images sourced\nthrough the mobile MyFoodRepo app. Through four rounds, the benchmark released\nthe MyFoodRepo-273 dataset constituting 24,119 images and a total of 39,325\nsegmented polygons categorized in 273 different classes. Models were evaluated\non private tests sets from the same platform with 5,000 images and 7,865\nannotations in the final round. Top-performing models on the 273 food\ncategories reached a mean average precision of 0.568 (round 4) and a mean\naverage recall of 0.885 (round 3). We present experimental validation of round\n4 results, and discuss implications of the benchmark setup designed to increase\nthe size and diversity of the dataset for future rounds.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 20:51:26 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 10:05:21 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Mohanty", "Sharada Prasanna", ""], ["Singhal", "Gaurav", ""], ["Scuccimarra", "Eric Antoine", ""], ["Kebaili", "Djilani", ""], ["H\u00e9ritier", "Harris", ""], ["Boulanger", "Victor", ""], ["Salath\u00e9", "Marcel", ""]]}, {"id": "2106.14993", "submitter": "Michael Chang", "authors": "Michael Chang, Sidhant Kaushik, Sergey Levine, Thomas L. Griffiths", "title": "Modularity in Reinforcement Learning via Algorithmic Independence in\n  Credit Assignment", "comments": "Long Presentation at the Thirty-eighth International Conference on\n  Machine Learning (ICML) 2021. 21 pages, 11 figures. v2: updated\n  acknowledgments. v3: clarified that the internal function nodes of the credit\n  assignment mechanism are not considered O(1)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT cs.NE math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many transfer problems require re-using previously optimal decisions for\nsolving new tasks, which suggests the need for learning algorithms that can\nmodify the mechanisms for choosing certain actions independently of those for\nchoosing others. However, there is currently no formalism nor theory for how to\nachieve this kind of modular credit assignment. To answer this question, we\ndefine modular credit assignment as a constraint on minimizing the algorithmic\nmutual information among feedback signals for different decisions. We introduce\nwhat we call the modularity criterion for testing whether a learning algorithm\nsatisfies this constraint by performing causal analysis on the algorithm\nitself. We generalize the recently proposed societal decision-making framework\nas a more granular formalism than the Markov decision process to prove that for\ndecision sequences that do not contain cycles, certain single-step temporal\ndifference action-value methods meet this criterion while all policy-gradient\nmethods do not. Empirical evidence suggests that such action-value methods are\nmore sample efficient than policy-gradient methods on transfer problems that\nrequire only sparse changes to a sequence of previously optimal decisions.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 21:29:13 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2021 21:42:55 GMT"}, {"version": "v3", "created": "Wed, 21 Jul 2021 17:07:10 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Chang", "Michael", ""], ["Kaushik", "Sidhant", ""], ["Levine", "Sergey", ""], ["Griffiths", "Thomas L.", ""]]}, {"id": "2106.15011", "submitter": "Houssem Eddine Boulahbal", "authors": "Houssem-eddine Boulahbal, Adrian Voicila, Andrew Comport", "title": "Are conditional GANs explicitly conditional?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper proposes two important contributions for conditional Generative\nAdversarial Networks (cGANs) to improve the wide variety of applications that\nexploit this architecture. The first main contribution is an analysis of cGANs\nto show that they are not explicitly conditional. In particular, it will be\nshown that the discriminator and subsequently the cGAN does not automatically\nlearn the conditionality between inputs. The second contribution is a new\nmethod, called acontrario, that explicitly models conditionality for both parts\nof the adversarial architecture via a novel acontrario loss that involves\ntraining the discriminator to learn unconditional (adverse) examples. This\nleads to a novel type of data augmentation approach for GANs (acontrario\nlearning) which allows to restrict the search space of the generator to\nconditional outputs using adverse examples. Extensive experimentation is\ncarried out to evaluate the conditionality of the discriminator by proposing a\nprobability distribution analysis. Comparisons with the cGAN architecture for\ndifferent applications show significant improvements in performance on well\nknown datasets including, semantic image synthesis, image segmentation and\nmonocular depth prediction using different metrics including Fr\\'echet\nInception Distance(FID), mean Intersection over Union (mIoU), Root Mean Square\nError log (RMSE log) and Number of statistically-Different Bins (NDB)\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 22:49:27 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Boulahbal", "Houssem-eddine", ""], ["Voicila", "Adrian", ""], ["Comport", "Andrew", ""]]}, {"id": "2106.15045", "submitter": "Nitin J. Sanket", "authors": "Nitin J. Sanket, Chahat Deep Singh, Chethan M. Parameshwara, Cornelia\n  Ferm\\\"uller, Guido C.H.E. de Croon, Yiannis Aloimonos", "title": "EVPropNet: Detecting Drones By Finding Propellers For Mid-Air Landing\n  And Following", "comments": "11 pages, 10 figures, 6 tables. Accepted in Robotics: Science and\n  Systems (RSS) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The rapid rise of accessibility of unmanned aerial vehicles or drones pose a\nthreat to general security and confidentiality. Most of the commercially\navailable or custom-built drones are multi-rotors and are comprised of multiple\npropellers. Since these propellers rotate at a high-speed, they are generally\nthe fastest moving parts of an image and cannot be directly \"seen\" by a\nclassical camera without severe motion blur. We utilize a class of sensors that\nare particularly suitable for such scenarios called event cameras, which have a\nhigh temporal resolution, low-latency, and high dynamic range.\n  In this paper, we model the geometry of a propeller and use it to generate\nsimulated events which are used to train a deep neural network called EVPropNet\nto detect propellers from the data of an event camera. EVPropNet directly\ntransfers to the real world without any fine-tuning or retraining. We present\ntwo applications of our network: (a) tracking and following an unmarked drone\nand (b) landing on a near-hover drone. We successfully evaluate and demonstrate\nthe proposed approach in many real-world experiments with different propeller\nshapes and sizes. Our network can detect propellers at a rate of 85.1% even\nwhen 60% of the propeller is occluded and can run at upto 35Hz on a 2W power\nbudget. To our knowledge, this is the first deep learning-based solution for\ndetecting propellers (to detect drones). Finally, our applications also show an\nimpressive success rate of 92% and 90% for the tracking and landing tasks\nrespectively.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 01:16:01 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Sanket", "Nitin J.", ""], ["Singh", "Chahat Deep", ""], ["Parameshwara", "Chethan M.", ""], ["Ferm\u00fcller", "Cornelia", ""], ["de Croon", "Guido C. H. E.", ""], ["Aloimonos", "Yiannis", ""]]}, {"id": "2106.15047", "submitter": "Yuxia Geng", "authors": "Yuxia Geng, Jiaoyan Chen, Zhuo Chen, Jeff Z. Pan, Zonggang Yuan,\n  Huajun Chen", "title": "K-ZSL: Resources for Knowledge-driven Zero-shot Learning", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  External knowledge (a.k.a side information) plays a critical role in\nzero-shot learning (ZSL) which aims to predict with unseen classes that have\nnever appeared in training data. Several kinds of external knowledge such as\ntext and attribute have been widely investigated, but they alone are limited\nwith incomplete semantics. Therefore, some very recent studies propose to use\nKnowledge Graph (KG) due to its high expressivity and compatibility for\nrepresenting kinds of knowledge. However, the ZSL community is still short of\nstandard benchmarks for studying and comparing different KG-based ZSL methods.\nIn this paper, we proposed 5 resources for KG-based research in zero-shot image\nclassification (ZS-IMGC) and zero-shot KG completion (ZS-KGC). For each\nresource, we contributed a benchmark and its KG with semantics ranging from\ntext to attributes, from relational knowledge to logical expressions. We have\nclearly presented how the resources are constructed, their statistics and\nformats, and how they can be utilized with cases in evaluating ZSL methods'\nperformance and explanations. Our resources are available at\nhttps://github.com/China-UK-ZSL/Resources_for_KZSL.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 01:22:49 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Geng", "Yuxia", ""], ["Chen", "Jiaoyan", ""], ["Chen", "Zhuo", ""], ["Pan", "Jeff Z.", ""], ["Yuan", "Zonggang", ""], ["Chen", "Huajun", ""]]}, {"id": "2106.15078", "submitter": "Guangyi Liu", "authors": "Guangyi Liu, Zichao Yang, Tianhua Tao, Xiaodan Liang, Zhen Li, Bowen\n  Zhou, Shuguang Cui, Zhiting Hu", "title": "Don't Take It Literally: An Edit-Invariant Sequence Loss for Text\n  Generation", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural text generation models are typically trained by maximizing\nlog-likelihood with the sequence cross entropy loss, which encourages an exact\ntoken-by-token match between a target sequence with a generated sequence. Such\ntraining objective is sub-optimal when the target sequence not perfect, e.g.,\nwhen the target sequence is corrupted with noises, or when only weak sequence\nsupervision is available. To address this challenge, we propose a novel\nEdit-Invariant Sequence Loss (EISL), which computes the matching loss of a\ntarget n-gram with all n-grams in the generated sequence. EISL draws\ninspirations from convolutional networks (ConvNets) which are shift-invariant\nto images, hence is robust to the shift of n-grams to tolerate edits in the\ntarget sequences. Moreover, the computation of EISL is essentially a\nconvolution operation with target n-grams as kernels, which is easy to\nimplement with existing libraries. To demonstrate the effectiveness of EISL, we\nconduct experiments on three tasks: machine translation with noisy target\nsequences, unsupervised text style transfer, and non-autoregressive machine\ntranslation. Experimental results show our method significantly outperforms\ncross entropy loss on these three tasks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 03:59:21 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 02:34:03 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Liu", "Guangyi", ""], ["Yang", "Zichao", ""], ["Tao", "Tianhua", ""], ["Liang", "Xiaodan", ""], ["Li", "Zhen", ""], ["Zhou", "Bowen", ""], ["Cui", "Shuguang", ""], ["Hu", "Zhiting", ""]]}, {"id": "2106.15113", "submitter": "Ziquan Wei", "authors": "Ziquan Wei, Shenghua Cheng, Xiuli Liu, Shaoqun Zeng", "title": "An Efficient Cervical Whole Slide Image Analysis Framework Based on\n  Multi-scale Semantic and Spatial Deep Features", "comments": "16 pages, 8 figures, already submitted to Medical Image Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital gigapixel whole slide image (WSI) is widely used in clinical\ndiagnosis, and automated WSI analysis is key for computer-aided diagnosis.\nCurrently, analyzing the integrated descriptor of probabilities or feature maps\nfrom massive local patches encoded by ResNet classifier is the main manner for\nWSI-level prediction. Feature representations of the sparse and tiny lesion\ncells in cervical slides, however, are still challengeable for the\nunder-promoted upstream encoders, while the unused spatial representations of\ncervical cells are the available features to supply the semantics analysis. As\nwell as patches sampling with overlap and repetitive processing incur the\ninefficiency and the unpredictable side effect. This study designs a novel\ninline connection network (InCNet) by enriching the multi-scale connectivity to\nbuild the lightweight model named You Only Look Cytopathology Once (YOLCO) with\nthe additional supervision of spatial information. The proposed model allows\nthe input size enlarged to megapixel that can stitch the WSI without any\noverlap by the average repeats decreased from $10^3\\sim10^4$ to $10^1\\sim10^2$\nfor collecting features and predictions at two scales. Based on Transformer for\nclassifying the integrated multi-scale multi-task features, the experimental\nresults appear $0.872$ AUC score better and $2.51\\times$ faster than the best\nconventional method in WSI classification on multicohort datasets of 2,019\nslides from four scanning devices.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 06:24:55 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2021 02:48:15 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Wei", "Ziquan", ""], ["Cheng", "Shenghua", ""], ["Liu", "Xiuli", ""], ["Zeng", "Shaoqun", ""]]}, {"id": "2106.15115", "submitter": "Rishemjit Kaur", "authors": "Surangika Ranathunga, En-Shiun Annie Lee, Marjana Prifti Skenduli,\n  Ravi Shekhar, Mehreen Alam and Rishemjit Kaur", "title": "Neural Machine Translation for Low-Resource Languages: A Survey", "comments": "35 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) has seen a tremendous spurt of growth in\nless than ten years, and has already entered a mature phase. While considered\nas the most widely used solution for Machine Translation, its performance on\nlow-resource language pairs still remains sub-optimal compared to the\nhigh-resource counterparts, due to the unavailability of large parallel\ncorpora. Therefore, the implementation of NMT techniques for low-resource\nlanguage pairs has been receiving the spotlight in the recent NMT research\narena, thus leading to a substantial amount of research reported on this topic.\nThis paper presents a detailed survey of research advancements in low-resource\nlanguage NMT (LRL-NMT), along with a quantitative analysis aimed at identifying\nthe most popular solutions. Based on our findings from reviewing previous work,\nthis survey paper provides a set of guidelines to select the possible NMT\ntechnique for a given LRL data setting. It also presents a holistic view of the\nLRL-NMT research landscape and provides a list of recommendations to further\nenhance the research efforts on LRL-NMT.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 06:31:58 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Ranathunga", "Surangika", ""], ["Lee", "En-Shiun Annie", ""], ["Skenduli", "Marjana Prifti", ""], ["Shekhar", "Ravi", ""], ["Alam", "Mehreen", ""], ["Kaur", "Rishemjit", ""]]}, {"id": "2106.15128", "submitter": "Yichi Zhou", "authors": "Yichi Zhou, Shihong Song, Huishuai Zhang, Jun Zhu, Wei Chen, Tie-Yan\n  Liu", "title": "Regularized OFU: an Efficient UCB Estimator forNon-linear Contextual\n  Bandit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Balancing exploration and exploitation (EE) is a fundamental problem in\ncontex-tual bandit. One powerful principle for EE trade-off isOptimism in Face\nof Uncer-tainty(OFU), in which the agent takes the action according to an upper\nconfidencebound (UCB) of reward. OFU has achieved (near-)optimal regret bound\nfor lin-ear/kernel contextual bandits. However, it is in general unknown how to\nderiveefficient and effective EE trade-off methods for non-linearcomplex tasks,\nsuchas contextual bandit with deep neural network as the reward function. In\nthispaper, we propose a novel OFU algorithm namedregularized OFU(ROFU). InROFU,\nwe measure the uncertainty of the reward by a differentiable function\nandcompute the upper confidence bound by solving a regularized optimization\nprob-lem. We prove that, for multi-armed bandit, kernel contextual bandit and\nneuraltangent kernel bandit, ROFU achieves (near-)optimal regret bounds with\ncertainuncertainty measure, which theoretically justifies its effectiveness on\nEE trade-off.Importantly, ROFU admits a very efficient implementation with\ngradient-basedoptimizer, which easily extends to general deep neural network\nmodels beyondneural tangent kernel, in sharp contrast with previous OFU\nmethods. The em-pirical evaluation demonstrates that ROFU works extremelywell\nfor contextualbandits under various settings.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 07:28:15 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Zhou", "Yichi", ""], ["Song", "Shihong", ""], ["Zhang", "Huishuai", ""], ["Zhu", "Jun", ""], ["Chen", "Wei", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2106.15130", "submitter": "Ehsan Nowroozi", "authors": "Mauro Conti, Simone Milani, Ehsan Nowroozi, Gabriele Orazi", "title": "Do Not Deceive Your Employer with a Virtual Background: A Video\n  Conferencing Manipulation-Detection System", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The last-generation video conferencing software allows users to utilize a\nvirtual background to conceal their personal environment due to privacy\nconcerns, especially in official meetings with other employers. On the other\nhand, users maybe want to fool people in the meeting by considering the virtual\nbackground to conceal where they are. In this case, developing tools to\nunderstand the virtual background utilize for fooling people in meeting plays\nan important role. Besides, such detectors must prove robust against different\nkinds of attacks since a malicious user can fool the detector by applying a set\nof adversarial editing steps on the video to conceal any revealing footprint.\nIn this paper, we study the feasibility of an efficient tool to detect whether\na videoconferencing user background is real. In particular, we provide the\nfirst tool which computes pixel co-occurrences matrices and uses them to search\nfor inconsistencies among spectral and spatial bands. Our experiments confirm\nthat cross co-occurrences matrices improve the robustness of the detector\nagainst different kinds of attacks. This work's performance is especially\nnoteworthy with regard to color SPAM features. Moreover, the performance\nespecially is significant with regard to robustness versus post-processing,\nlike geometric transformations, filtering, contrast enhancement, and JPEG\ncompression with different quality factors.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 07:31:21 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Conti", "Mauro", ""], ["Milani", "Simone", ""], ["Nowroozi", "Ehsan", ""], ["Orazi", "Gabriele", ""]]}, {"id": "2106.15133", "submitter": "Tomoharu Iwata", "authors": "Tomoharu Iwata", "title": "Meta-learning for Matrix Factorization without Shared Rows or Columns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method that meta-learns a knowledge on matrix factorization from\nvarious matrices, and uses the knowledge for factorizing unseen matrices. The\nproposed method uses a neural network that takes a matrix as input, and\ngenerates prior distributions of factorized matrices of the given matrix. The\nneural network is meta-learned such that the expected imputation error is\nminimized when the factorized matrices are adapted to each matrix by a maximum\na posteriori (MAP) estimation. We use a gradient descent method for the MAP\nestimation, which enables us to backpropagate the expected imputation error\nthrough the gradient descent steps for updating neural network parameters since\neach gradient descent step is written in a closed form and is differentiable.\nThe proposed method can meta-learn from matrices even when their rows and\ncolumns are not shared, and their sizes are different from each other. In our\nexperiments with three user-item rating datasets, we demonstrate that our\nproposed method can impute the missing values from a limited number of\nobservations in unseen matrices after being trained with different matrices.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 07:40:20 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Iwata", "Tomoharu", ""]]}, {"id": "2106.15147", "submitter": "Dara Bahri", "authors": "Dara Bahri, Heinrich Jiang, Yi Tay, Donald Metzler", "title": "SCARF: Self-Supervised Contrastive Learning using Random Feature\n  Corruption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-supervised contrastive representation learning has proved incredibly\nsuccessful in the vision and natural language domains, enabling\nstate-of-the-art performance with orders of magnitude less labeled data.\nHowever, such methods are domain-specific and little has been done to leverage\nthis technique on real-world tabular datasets. We propose SCARF, a simple,\nwidely-applicable technique for contrastive learning, where views are formed by\ncorrupting a random subset of features. When applied to pre-train deep neural\nnetworks on the 69 real-world, tabular classification datasets from the\nOpenML-CC18 benchmark, SCARF not only improves classification accuracy in the\nfully-supervised setting but does so also in the presence of label noise and in\nthe semi-supervised setting where only a fraction of the available training\ndata is labeled. We show that SCARF complements existing strategies and\noutperforms alternatives like autoencoders. We conduct comprehensive ablations,\ndetailing the importance of a range of factors.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 08:08:33 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Bahri", "Dara", ""], ["Jiang", "Heinrich", ""], ["Tay", "Yi", ""], ["Metzler", "Donald", ""]]}, {"id": "2106.15150", "submitter": "Bartosz Bednarczyk", "authors": "Bartosz Bednarczyk and Sebastian Rudolph", "title": "The Price of Selfishness: Conjunctive Query Entailment for ALCSelf is\n  2ExpTime-hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In logic-based knowledge representation, query answering has essentially\nreplaced mere satisfiability checking as the inferencing problem of primary\ninterest. For knowledge bases in the basic description logic ALC, the\ncomputational complexity of conjunctive query (CQ) answering is well known to\nbe ExpTime-complete and hence not harder than satisfiability. This does not\nchange when the logic is extended by certain features (such as counting or role\nhierarchies), whereas adding others (inverses, nominals or transitivity\ntogether with role-hierarchies) turns CQ answering exponentially harder. We\ncontribute to this line of results by showing the surprising fact that even\nextending ALC by just the Self operator - which proved innocuous in many other\ncontexts - increases the complexity of CQ entailment to 2ExpTime. As common for\nthis type of problem, our proof establishes a reduction from alternating Turing\nmachines running in exponential space, but several novel ideas and encoding\ntricks are required to make the approach work in that specific, restricted\nsetting.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 08:12:03 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Bednarczyk", "Bartosz", ""], ["Rudolph", "Sebastian", ""]]}, {"id": "2106.15182", "submitter": "Pietro Liguori", "authors": "Domenico Cotroneo, Luigi De Simone, Pietro Liguori, Roberto Natella", "title": "Enhancing the Analysis of Software Failures in Cloud Computing Systems\n  with Deep Learning", "comments": "Paper accepted to the Journal of Systems and Software on June 28th,\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Identifying the failure modes of cloud computing systems is a difficult and\ntime-consuming task, due to the growing complexity of such systems, and the\nlarge volume and noisiness of failure data. This paper presents a novel\napproach for analyzing failure data from cloud systems, in order to relieve\nhuman analysts from manually fine-tuning the data for feature engineering. The\napproach leverages Deep Embedded Clustering (DEC), a family of unsupervised\nclustering algorithms based on deep learning, which uses an autoencoder to\noptimize data dimensionality and inter-cluster variance. We applied the\napproach in the context of the OpenStack cloud computing platform, both on the\nraw failure data and in combination with an anomaly detection pre-processing\nalgorithm. The results show that the performance of the proposed approach, in\nterms of purity of clusters, is comparable to, or in some cases even better\nthan manually fine-tuned clustering, thus avoiding the need for deep domain\nknowledge and reducing the effort to perform the analysis. In all cases, the\nproposed approach provides better performance than unsupervised clustering when\nno feature engineering is applied to the data. Moreover, the distribution of\nfailure modes from the proposed approach is closer to the actual frequency of\nthe failure modes.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 09:00:41 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Cotroneo", "Domenico", ""], ["De Simone", "Luigi", ""], ["Liguori", "Pietro", ""], ["Natella", "Roberto", ""]]}, {"id": "2106.15190", "submitter": "Karn Watcharasupat", "authors": "Thi Ngoc Tho Nguyen and Karn Watcharasupat and Ngoc Khanh Nguyen and\n  Douglas L. Jones and Woon Seng Gan", "title": "DCASE 2021 Task 3: Spectrotemporally-aligned Features for Polyphonic\n  Sound Event Localization and Detection", "comments": "5 pages, Technical Report for DCASE 2021 Challenge Task 3", "journal-ref": null, "doi": "10.5281/zenodo.5031836", "report-no": null, "categories": "eess.AS cs.AI cs.LG cs.SD eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sound event localization and detection consists of two subtasks which are\nsound event detection and direction-of-arrival estimation. While sound event\ndetection mainly relies on time-frequency patterns to distinguish different\nsound classes, direction-of-arrival estimation uses magnitude or phase\ndifferences between microphones to estimate source directions. Therefore, it is\noften difficult to jointly train these two subtasks simultaneously. We propose\na novel feature called spatial cue-augmented log-spectrogram (SALSA) with exact\ntime-frequency mapping between the signal power and the source\ndirection-of-arrival. The feature includes multichannel log-spectrograms\nstacked along with the estimated direct-to-reverberant ratio and a normalized\nversion of the principal eigenvector of the spatial covariance matrix at each\ntime-frequency bin on the spectrograms. Experimental results on the DCASE 2021\ndataset for sound event localization and detection with directional\ninterference showed that the deep learning-based models trained on this new\nfeature outperformed the DCASE challenge baseline by a large margin. We\ncombined several models with slightly different architectures that were trained\non the new feature to further improve the system performances for the DCASE\nsound event localization and detection challenge.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 09:18:30 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Nguyen", "Thi Ngoc Tho", ""], ["Watcharasupat", "Karn", ""], ["Nguyen", "Ngoc Khanh", ""], ["Jones", "Douglas L.", ""], ["Gan", "Woon Seng", ""]]}, {"id": "2106.15200", "submitter": "Bo Zhou", "authors": "Bo Zhou, Hongsheng Zeng, Yuecheng Liu, Kejiao Li, Fan Wang, Hao Tian", "title": "Action Set Based Policy Optimization for Safe Power Grid Management", "comments": "accepted by ECML PKDD 2021; 1st place in NeurIPS2020 RL challenge:\n  power grid management", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Maintaining the stability of the modern power grid is becoming increasingly\ndifficult due to fluctuating power consumption, unstable power supply coming\nfrom renewable energies, and unpredictable accidents such as man-made and\nnatural disasters. As the operation on the power grid must consider its impact\non future stability, reinforcement learning (RL) has been employed to provide\nsequential decision-making in power grid management. However, existing methods\nhave not considered the environmental constraints. As a result, the learned\npolicy has risk of selecting actions that violate the constraints in\nemergencies, which will escalate the issue of overloaded power lines and lead\nto large-scale blackouts. In this work, we propose a novel method for this\nproblem, which builds on top of the search-based planning algorithm. At the\nplanning stage, the search space is limited to the action set produced by the\npolicy. The selected action strictly follows the constraints by testing its\noutcome with the simulation function provided by the system. At the learning\nstage, to address the problem that gradients cannot be propagated to the\npolicy, we introduce Evolutionary Strategies (ES) with black-box policy\noptimization to improve the policy directly, maximizing the returns of the long\nrun. In NeurIPS 2020 Learning to Run Power Network (L2RPN) competition, our\nsolution safely managed the power grid and ranked first in both tracks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 09:36:36 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Zhou", "Bo", ""], ["Zeng", "Hongsheng", ""], ["Liu", "Yuecheng", ""], ["Li", "Kejiao", ""], ["Wang", "Fan", ""], ["Tian", "Hao", ""]]}, {"id": "2106.15202", "submitter": "Tao Bai", "authors": "Tao Bai, Jinqi Luo, Jun Zhao", "title": "Inconspicuous Adversarial Patches for Fooling Image Recognition Systems\n  on Mobile Devices", "comments": "arXiv admin note: substantial text overlap with arXiv:2009.09774", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning based image recognition systems have been widely deployed on\nmobile devices in today's world. In recent studies, however, deep learning\nmodels are shown vulnerable to adversarial examples. One variant of adversarial\nexamples, called adversarial patch, draws researchers' attention due to its\nstrong attack abilities. Though adversarial patches achieve high attack success\nrates, they are easily being detected because of the visual inconsistency\nbetween the patches and the original images. Besides, it usually requires a\nlarge amount of data for adversarial patch generation in the literature, which\nis computationally expensive and time-consuming. To tackle these challenges, we\npropose an approach to generate inconspicuous adversarial patches with one\nsingle image. In our approach, we first decide the patch locations basing on\nthe perceptual sensitivity of victim models, then produce adversarial patches\nin a coarse-to-fine way by utilizing multiple-scale generators and\ndiscriminators. The patches are encouraged to be consistent with the background\nimages with adversarial training while preserving strong attack abilities. Our\napproach shows the strong attack abilities in white-box settings and the\nexcellent transferability in black-box settings through extensive experiments\non various models with different architectures and training methods. Compared\nto other adversarial patches, our adversarial patches hold the most negligible\nrisks to be detected and can evade human observations, which is supported by\nthe illustrations of saliency maps and results of user evaluations. Lastly, we\nshow that our adversarial patches can be applied in the physical world.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 09:39:34 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Bai", "Tao", ""], ["Luo", "Jinqi", ""], ["Zhao", "Jun", ""]]}, {"id": "2106.15212", "submitter": "Thomas Spooner", "authors": "Thomas Spooner, Danial Dervovic, Jason Long, Jon Shepard, Jiahao Chen,\n  Daniele Magazzeni", "title": "Counterfactual Explanations for Arbitrary Regression Models", "comments": "20 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for counterfactual explanations (CFEs) based on\nBayesian optimisation that applies to both classification and regression\nmodels. Our method is a globally convergent search algorithm with support for\narbitrary regression models and constraints like feature sparsity and\nactionable recourse, and furthermore can answer multiple counterfactual\nquestions in parallel while learning from previous queries. We formulate CFE\nsearch for regression models in a rigorous mathematical framework using\ndifferentiable potentials, which resolves robustness issues in threshold-based\nobjectives. We prove that in this framework, (a) verifying the existence of\ncounterfactuals is NP-complete; and (b) that finding instances using such\npotentials is CLS-complete. We describe a unified algorithm for CFEs using a\nspecialised acquisition function that composes both expected improvement and an\nexponential-polynomial (EP) family with desirable properties. Our evaluation on\nreal-world benchmark domains demonstrate high sample-efficiency and precision.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 09:53:53 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Spooner", "Thomas", ""], ["Dervovic", "Danial", ""], ["Long", "Jason", ""], ["Shepard", "Jon", ""], ["Chen", "Jiahao", ""], ["Magazzeni", "Daniele", ""]]}, {"id": "2106.15217", "submitter": "Jianhao Yan", "authors": "Jianhao Yan, Chenming Wu, Fandong Meng, Jie Zhou", "title": "Rethinking the Evaluation of Neural Machine Translation", "comments": "Submitted to NeurIPS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The evaluation of neural machine translation systems is usually built upon\ngenerated translation of a certain decoding method (e.g., beam search) with\nevaluation metrics over the generated translation (e.g., BLEU). However, this\nevaluation framework suffers from high search errors brought by heuristic\nsearch algorithms and is limited by its nature of evaluation over one best\ncandidate. In this paper, we propose a novel evaluation protocol, which not\nonly avoids the effect of search errors but provides a system-level evaluation\nin the perspective of model ranking. In particular, our method is based on our\nnewly proposed exact top-$k$ decoding instead of beam search. Our approach\nevaluates model errors by the distance between the candidate spaces scored by\nthe references and the model respectively. Extensive experiments on WMT'14\nEnglish-German demonstrate that bad ranking ability is connected to the\nwell-known beam search curse, and state-of-the-art Transformer models are\nfacing serious ranking errors. By evaluating various model architectures and\ntechniques, we provide several interesting findings. Finally, to effectively\napproximate the exact search algorithm with same time cost as original beam\nsearch, we present a minimum heap augmented beam search algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 09:59:50 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Yan", "Jianhao", ""], ["Wu", "Chenming", ""], ["Meng", "Fandong", ""], ["Zhou", "Jie", ""]]}, {"id": "2106.15221", "submitter": "Linyi Yang", "authors": "Linyi Yang, Tin Lok James Ng, Barry Smyth, Ruihai Dong", "title": "Fact Check: Analyzing Financial Events from Multilingual News Sources", "comments": "Demo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The explosion in the sheer magnitude and complexity of financial news data in\nrecent years makes it increasingly challenging for investment analysts to\nextract valuable insights and perform analysis. We propose FactCheck in\nfinance, a web-based news aggregator with deep learning models, to provide\nanalysts with a holistic view of important financial events from multilingual\nnews sources and extract events using an unsupervised clustering method. A web\ninterface is provided to examine the credibility of news articles using a\ntransformer-based fact-checker. The performance of the fact checker is\nevaluated using a dataset related to merger and acquisition (M\\&A) events and\nis shown to outperform several strong baselines.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 10:05:47 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 05:00:20 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Yang", "Linyi", ""], ["Ng", "Tin Lok James", ""], ["Smyth", "Barry", ""], ["Dong", "Ruihai", ""]]}, {"id": "2106.15223", "submitter": "Wessel Radstok", "authors": "Wessel Radstok and Mel Chekol", "title": "Leveraging Static Models for Link Prediction in Temporal Knowledge\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The inclusion of temporal scopes of facts in knowledge graph embedding (KGE)\npresents significant opportunities for improving the resulting embeddings, and\nconsequently for increased performance in downstream applications. Yet, little\nresearch effort has focussed on this area and much of the carried out research\nreports only marginally improved results compared to models trained without\ntemporal scopes (static models). Furthermore, rather than leveraging existing\nwork on static models, they introduce new models specific to temporal knowledge\ngraphs. We propose a novel perspective that takes advantage of the power of\nexisting static embedding models by focussing effort on manipulating the data\ninstead. Our method, SpliMe, draws inspiration from the field of signal\nprocessing and early work in graph embedding. We show that SpliMe competes with\nor outperforms the current state of the art in temporal KGE. Additionally, we\nuncover issues with the procedure currently used to assess the performance of\nstatic models on temporal graphs and introduce two ways to counteract them.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 10:15:17 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Radstok", "Wessel", ""], ["Chekol", "Mel", ""]]}, {"id": "2106.15231", "submitter": "Linyi Yang", "authors": "Linyi Yang, Jiazheng Li, P\\'adraig Cunningham, Yue Zhang, Barry Smyth,\n  Ruihai Dong", "title": "Exploring the Efficacy of Automatically Generated Counterfactuals for\n  Sentiment Analysis", "comments": "ACL-21, Main Conference, Long Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  While state-of-the-art NLP models have been achieving the excellent\nperformance of a wide range of tasks in recent years, important questions are\nbeing raised about their robustness and their underlying sensitivity to\nsystematic biases that may exist in their training and test data. Such issues\ncome to be manifest in performance problems when faced with out-of-distribution\ndata in the field. One recent solution has been to use counterfactually\naugmented datasets in order to reduce any reliance on spurious patterns that\nmay exist in the original data. Producing high-quality augmented data can be\ncostly and time-consuming as it usually needs to involve human feedback and\ncrowdsourcing efforts. In this work, we propose an alternative by describing\nand evaluating an approach to automatically generating counterfactual data for\ndata augmentation and explanation. A comprehensive evaluation on several\ndifferent datasets and using a variety of state-of-the-art benchmarks\ndemonstrate how our approach can achieve significant improvements in model\nperformance when compared to models training on the original data and even when\ncompared to models trained with the benefit of human-generated augmented data.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 10:27:01 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 04:56:27 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Yang", "Linyi", ""], ["Li", "Jiazheng", ""], ["Cunningham", "P\u00e1draig", ""], ["Zhang", "Yue", ""], ["Smyth", "Barry", ""], ["Dong", "Ruihai", ""]]}, {"id": "2106.15247", "submitter": "Peter Ochieng", "authors": "Peter Ochieng and Dennis Mugambi", "title": "Unsupervised Technique To Conversational Machine Reading", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Conversational machine reading (CMR) tools have seen a rapid progress in the\nrecent past. The current existing tools rely on the supervised learning\ntechnique which require labeled dataset for their training. The supervised\ntechnique necessitates that for every new rule text, a manually labeled dataset\nmust be created. This is tedious and error prone. This paper introduces and\ndemonstrates how unsupervised learning technique can be applied in the\ndevelopment of CMR. Specifically, we demonstrate how unsupervised learning can\nbe used in rule extraction and entailment modules of CMR. Compared to the\ncurrent best CMR tool, our developed framework reports 3.3% improvement in\nmicro averaged accuracy and 1.4 % improvement in macro averaged accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 10:59:03 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Ochieng", "Peter", ""], ["Mugambi", "Dennis", ""]]}, {"id": "2106.15273", "submitter": "Utkarsh Mishra", "authors": "Utkarsh A. Mishra", "title": "Learning Control Policies for Imitating Human Gaits", "comments": "47 pages, 17 figures, Bachelor of Technology Final Year Project\n  Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The work presented in this report introduces a framework aimed towards\nlearning to imitate human gaits. Humans exhibit movements like walking,\nrunning, and jumping in the most efficient manner, which served as the source\nof motivation for this project. Skeletal and Musculoskeletal human models were\nconsidered for motions in the sagittal plane, and results from both were\ncompared exhaustively. While skeletal models are driven with motor actuation,\nmusculoskeletal models perform through muscle-tendon actuation. Model-free\nreinforcement learning algorithms were used to optimize inverse dynamics\ncontrol actions to satisfy the objective of imitating a reference motion along\nwith secondary objectives of minimizing effort in terms of power spent by\nmotors and metabolic energy consumed by the muscles. On the one hand, the\ncontrol actions for the motor actuated model is the target joint angles\nconverted into joint torques through a Proportional-Differential controller.\nWhile on the other hand, the control actions for the muscle-tendon actuated\nmodel is the muscle excitations converted implicitly to muscle activations and\nthen to muscle forces which apply moments on joints. Muscle-tendon actuated\nmodels were found to have superiority over motor actuation as they are\ninherently smooth due to muscle activation dynamics and don't need any external\nregularizers. Finally, a strategy that was used to obtain an optimal\nconfiguration of the significant decision variables in the framework was\ndiscussed. All the results and analysis are presented in an illustrative,\nqualitative, and quantitative manner. Supporting video links are provided in\nthe Appendix.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 16:33:24 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Mishra", "Utkarsh A.", ""]]}, {"id": "2106.15278", "submitter": "Geeho Kim", "authors": "Geeho Kim and Bohyung Han", "title": "Open-Set Representation Learning through Combinatorial Embedding", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual recognition tasks are often limited to dealing with a small subset of\nclasses simply because the labels for the remaining classes are unavailable. We\nare interested in identifying novel concepts in a dataset through\nrepresentation learning based on the examples in both labeled and unlabeled\nclasses, and extending the horizon of recognition to both known and novel\nclasses. To address this challenging task, we propose a combinatorial learning\napproach, which naturally clusters the examples in unseen classes using the\ncompositional knowledge given by multiple supervised meta-classifiers on\nheterogeneous label spaces. We also introduce a metric learning strategy to\nestimate pairwise pseudo-labels for improving representations of unlabeled\nexamples, which preserves semantic relations across known and novel classes\neffectively. The proposed algorithm discovers novel concepts via a joint\noptimization of enhancing the discrimitiveness of unseen classes as well as\nlearning the representations of known classes generalizable to novel ones. Our\nextensive experiments demonstrate remarkable performance gains by the proposed\napproach in multiple image retrieval and novel class discovery benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 11:51:57 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Kim", "Geeho", ""], ["Han", "Bohyung", ""]]}, {"id": "2106.15282", "submitter": "Jonathan Ho", "authors": "Jonathan Ho, Chitwan Saharia, William Chan, David J. Fleet, Mohammad\n  Norouzi, Tim Salimans", "title": "Cascaded Diffusion Models for High Fidelity Image Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that cascaded diffusion models are capable of generating high\nfidelity images on the class-conditional ImageNet generation challenge, without\nany assistance from auxiliary image classifiers to boost sample quality. A\ncascaded diffusion model comprises a pipeline of multiple diffusion models that\ngenerate images of increasing resolution, beginning with a standard diffusion\nmodel at the lowest resolution, followed by one or more super-resolution\ndiffusion models that successively upsample the image and add higher resolution\ndetails. We find that the sample quality of a cascading pipeline relies\ncrucially on conditioning augmentation, our proposed method of data\naugmentation of the lower resolution conditioning inputs to the\nsuper-resolution models. Our experiments show that conditioning augmentation\nprevents compounding error during sampling in a cascaded model, helping us to\ntrain cascading pipelines achieving FID scores of 1.48 at 64x64, 3.52 at\n128x128 and 4.88 at 256x256 resolutions, outperforming BigGAN-deep, and\nclassification accuracy scores of 63.02% (top-1) and 84.06% (top-5) at 256x256,\noutperforming VQ-VAE-2.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 17:14:52 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 19:43:38 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Ho", "Jonathan", ""], ["Saharia", "Chitwan", ""], ["Chan", "William", ""], ["Fleet", "David J.", ""], ["Norouzi", "Mohammad", ""], ["Salimans", "Tim", ""]]}, {"id": "2106.15292", "submitter": "Deep Patel", "authors": "Deep Patel and P.S. Sastry", "title": "Adaptive Sample Selection for Robust Learning under Label Noise", "comments": "19 pages, 7 figures, and 16 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have been shown to be susceptible to memorization\nor overfitting in the presence of noisily labelled data. For the problem of\nrobust learning under such noisy data, several algorithms have been proposed. A\nprominent class of algorithms rely on sample selection strategies, motivated by\ncurriculum learning. For example, many algorithms use the `small loss trick'\nwherein a fraction of samples with loss values below a certain threshold are\nselected for training. These algorithms are sensitive to such thresholds, and\nit is difficult to fix or learn these thresholds. Often, these algorithms also\nrequire information such as label noise rates which are typically unavailable\nin practice. In this paper, we propose a data-dependent, adaptive sample\nselection strategy that relies only on batch statistics of a given mini-batch\nto provide robustness against label noise. The algorithm does not have any\nadditional hyperparameters for sample selection, does not need any information\non noise rates, and does not need access to separate data with clean labels. We\nempirically demonstrate the effectiveness of our algorithm on benchmark\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 12:10:58 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 08:47:05 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Patel", "Deep", ""], ["Sastry", "P. S.", ""]]}, {"id": "2106.15307", "submitter": "Martin Bauw", "authors": "Martin Bauw, Santiago Velasco-Forero, Jesus Angulo, Claude Adnet,\n  Olivier Airiau", "title": "Deep Random Projection Outlyingness for Unsupervised Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random projection is a common technique for designing algorithms in a variety\nof areas, including information retrieval, compressive sensing and measuring of\noutlyingness. In this work, the original random projection outlyingness measure\nis modified and associated with a neural network to obtain an unsupervised\nanomaly detection method able to handle multimodal normality. Theoretical and\nexperimental arguments are presented to justify the choices of the anomaly\nscore estimator, the dimensions of the random projections, and the number of\nsuch projections. The contribution of adapted dropouts is investigated, along\nwith the affine stability of the proposed method. The performance of the\nproposed neural network approach is comparable to a state-of-the-art anomaly\ndetection method. Experiments conducted on the MNIST, Fashion-MNIST and\nCIFAR-10 datasets show the relevance of the proposed approach, and suggest a\npossible extension to a semi-supervised setup.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 14:13:43 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Bauw", "Martin", ""], ["Velasco-Forero", "Santiago", ""], ["Angulo", "Jesus", ""], ["Adnet", "Claude", ""], ["Airiau", "Olivier", ""]]}, {"id": "2106.15322", "submitter": "Abdelrahman Abdallah", "authors": "Abdelrahman Abdallah, Alexander Berendeyev, Islam Nuradin, Daniyar\n  Nurseitov", "title": "TNCR: Table Net Detection and Classification Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present TNCR, a new table dataset with varying image quality collected\nfrom free websites. The TNCR dataset can be used for table detection in scanned\ndocument images and their classification into 5 different classes. TNCR\ncontains 9428 high-quality labeled images. In this paper, we have implemented\nstate-of-the-art deep learning-based methods for table detection to create\nseveral strong baselines. Cascade Mask R-CNN with ResNeXt-101-64x4d Backbone\nNetwork achieves the highest performance compared to other methods with a\nprecision of 79.7%, recall of 89.8%, and f1 score of 84.4% on the TNCR dataset.\nWe have made TNCR open source in the hope of encouraging more deep learning\napproaches to table detection, classification, and structure recognition. The\ndataset and trained model checkpoints are available at\nhttps://github.com/abdoelsayed2016/TNCR_Dataset.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 10:48:58 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Abdallah", "Abdelrahman", ""], ["Berendeyev", "Alexander", ""], ["Nuradin", "Islam", ""], ["Nurseitov", "Daniyar", ""]]}, {"id": "2106.15324", "submitter": "Nathan Beck", "authors": "Nathan Beck, Durga Sivasubramanian, Apurva Dani, Ganesh Ramakrishnan,\n  Rishabh Iyer", "title": "Effective Evaluation of Deep Active Learning on Image Classification\n  Tasks", "comments": "9 pages in main paper, 6 figures in main paper, 3 tables in main\n  paper. 23 pages in total, 15 figures in total, 14 tables in total", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the goal of making deep learning more label-efficient, a growing number\nof papers have been studying active learning (AL) for deep models. However,\nthere are a number of issues in the prevalent experimental settings, mainly\nstemming from a lack of unified implementation and benchmarking. Issues in the\ncurrent literature include sometimes contradictory observations on the\nperformance of different AL algorithms, unintended exclusion of important\ngeneralization approaches such as data augmentation and SGD for optimization, a\nlack of study of evaluation facets like the labeling efficiency of AL, and\nlittle or no clarity on the scenarios in which AL outperforms random sampling\n(RS). In this work, we present a unified re-implementation of state-of-the-art\nAL algorithms in the context of image classification, and we carefully study\nthese issues as facets of effective evaluation. On the positive side, we show\nthat AL techniques are 2x to 4x more label-efficient compared to RS with the\nuse of data augmentation. Surprisingly, when data augmentation is included,\nthere is no longer a consistent gain in using BADGE, a state-of-the-art\napproach, over simple uncertainty sampling. We then do a careful analysis of\nhow existing approaches perform with varying amounts of redundancy and number\nof examples per class. Finally, we provide several insights for AL\npractitioners to consider in future work, such as the effect of the AL batch\nsize, the effect of initialization, the importance of retraining a new model at\nevery round, and other insights.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 23:29:39 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 04:49:40 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Beck", "Nathan", ""], ["Sivasubramanian", "Durga", ""], ["Dani", "Apurva", ""], ["Ramakrishnan", "Ganesh", ""], ["Iyer", "Rishabh", ""]]}, {"id": "2106.15325", "submitter": "Abdul Mueed Hafiz Dr.", "authors": "Abdul Mueed Hafiz, Rouf Ul Alam Bhat, Shabir Ahmad Parah, M.\n  Hassaballah", "title": "SE-MD: A Single-encoder multiple-decoder deep network for point cloud\n  generation from 2D images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D model generation from single 2D RGB images is a challenging and actively\nresearched computer vision task. Various techniques using conventional network\narchitectures have been proposed for the same. However, the body of research\nwork is limited and there are various issues like using inefficient 3D\nrepresentation formats, weak 3D model generation backbones, inability to\ngenerate dense point clouds, dependence of post-processing for generation of\ndense point clouds, and dependence on silhouettes in RGB images. In this paper,\na novel 2D RGB image to point cloud conversion technique is proposed, which\nimproves the state of art in the field due to its efficient, robust and simple\nmodel by using the concept of parallelization in network architecture. It not\nonly uses the efficient and rich 3D representation of point clouds, but also\nuses a novel and robust point cloud generation backbone in order to address the\nprevalent issues. This involves using a single-encoder multiple-decoder deep\nnetwork architecture wherein each decoder generates certain fixed viewpoints.\nThis is followed by fusing all the viewpoints to generate a dense point cloud.\nVarious experiments are conducted on the technique and its performance is\ncompared with those of other state of the art techniques and impressive gains\nin performance are demonstrated. Code is available at\nhttps://github.com/mueedhafiz1982/\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 10:48:46 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Hafiz", "Abdul Mueed", ""], ["Bhat", "Rouf Ul Alam", ""], ["Parah", "Shabir Ahmad", ""], ["Hassaballah", "M.", ""]]}, {"id": "2106.15338", "submitter": "Prasad Gabbur", "authors": "Prasad Gabbur and Manjot Bilkhu and Javier Movellan", "title": "Probabilistic Attention for Interactive Segmentation", "comments": "Updated with link to GitHub, 17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We provide a probabilistic interpretation of attention and show that the\nstandard dot-product attention in transformers is a special case of Maximum A\nPosteriori (MAP) inference. The proposed approach suggests the use of\nExpectation Maximization algorithms for online adaptation of key and value\nmodel parameters. This approach is useful for cases in which external agents,\ne.g., annotators, provide inference-time information about the correct values\nof some tokens, e.g, the semantic category of some pixels, and we need for this\nnew information to propagate to other tokens in a principled manner. We\nillustrate the approach on an interactive semantic segmentation task in which\nannotators and models collaborate online to improve annotation efficiency.\nUsing standard benchmarks, we observe that key adaptation boosts model\nperformance ($\\sim10\\%$ mIoU) in the low feedback regime and value propagation\nimproves model responsiveness in the high feedback regime. A PyTorch layer\nimplementation of our probabilistic attention model will be made publicly\navailable here: https://github.com/apple/ml-probabilistic-attention.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 00:19:43 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 20:42:33 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Gabbur", "Prasad", ""], ["Bilkhu", "Manjot", ""], ["Movellan", "Javier", ""]]}, {"id": "2106.15349", "submitter": "Manjesh Kumar Hanawal", "authors": "Sayan Chatterjee and Manjesh K. Hanawal", "title": "Federated Learning for Intrusion Detection in IoT Security: A Hybrid\n  Ensemble Approach", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Critical role of Internet of Things (IoT) in various domains like smart city,\nhealthcare, supply chain and transportation has made them the target of\nmalicious attacks. Past works in this area focused on centralized Intrusion\nDetection System (IDS), assuming the existence of a central entity to perform\ndata analysis and identify threats. However, such IDS may not always be\nfeasible, mainly due to spread of data across multiple sources and gathering at\ncentral node can be costly. Also, the earlier works primarily focused on\nimproving True Positive Rate (TPR) and ignored the False Positive Rate (FPR),\nwhich is also essential to avoid unnecessary downtime of the systems. In this\npaper, we first present an architecture for IDS based on hybrid ensemble model,\nnamed PHEC, which gives improved performance compared to state-of-the-art\narchitectures. We then adapt this model to a federated learning framework that\nperforms local training and aggregates only the model parameters. Next, we\npropose Noise-Tolerant PHEC in centralized and federated settings to address\nthe label-noise problem. The proposed idea uses classifiers using weighted\nconvex surrogate loss functions. Natural robustness of KNN classifier towards\nnoisy data is also used in the proposed architecture. Experimental results on\nfour benchmark datasets drawn from various security attacks show that our model\nachieves high TPR while keeping FPR low on noisy and clean data. Further, they\nalso demonstrate that the hybrid ensemble models achieve performance in\nfederated settings close to that of the centralized settings.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 06:33:35 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Chatterjee", "Sayan", ""], ["Hanawal", "Manjesh K.", ""]]}, {"id": "2106.15367", "submitter": "Chia Hsiang Kao", "authors": "Chia-Hsiang Kao, Wei-Chen Chiu and Pin-Yu Chen", "title": "MAML is a Noisy Contrastive Learner", "comments": "15 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Model-agnostic meta-learning (MAML) is one of the most popular and\nwidely-adopted meta-learning algorithms nowadays, which achieves remarkable\nsuccess in various learning problems. Yet, with the unique design of nested\ninner-loop and outer-loop updates which respectively govern the task-specific\nand meta-model-centric learning, the underlying learning objective of MAML\nstill remains implicit and thus impedes a more straightforward understanding of\nit. In this paper, we provide a new perspective to the working mechanism of\nMAML and discover that: MAML is analogous to a meta-learner using a supervised\ncontrastive objective function, where the query features are pulled towards the\nsupport features of the same class and against those of different classes, in\nwhich such contrastiveness is experimentally verified via an analysis based on\nthe cosine similarity. Moreover, our analysis reveals that the vanilla MAML\nalgorithm has an undesirable interference term originating from the random\ninitialization and the cross-task interaction. We therefore propose a simple\nbut effective technique, zeroing trick, to alleviate such interference, where\nthe extensive experiments are then conducted on both miniImagenet and Omniglot\ndatasets to demonstrate the consistent improvement brought by our proposed\ntechnique thus well validating its effectiveness.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 12:52:26 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Kao", "Chia-Hsiang", ""], ["Chiu", "Wei-Chen", ""], ["Chen", "Pin-Yu", ""]]}, {"id": "2106.15373", "submitter": "Caglar Demir", "authors": "Caglar Demir and Axel-Cyrille Ngonga Ngomo", "title": "DRILL-- Deep Reinforcement Learning for Refinement Operators in\n  $\\mathcal{ALC}$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Approaches based on refinement operators have been successfully applied to\nclass expression learning on RDF knowledge graphs. These approaches often need\nto explore a large number of concepts to find adequate hypotheses. This need\narguably stems from current approaches relying on myopic heuristic functions to\nguide their search through an infinite concept space. In turn, deep\nreinforcement learning provides effective means to address myopia by estimating\nhow much discounted cumulated future reward states promise. In this work, we\nleverage deep reinforcement learning to accelerate the learning of concepts in\n$\\mathcal{ALC}$ by proposing DRILL -- a novel class expression learning\napproach that uses a convolutional deep Q-learning model to steer its search.\nBy virtue of its architecture, DRILL is able to compute the expected discounted\ncumulated future reward of more than $10^3$ class expressions in a second on\nstandard hardware. We evaluate DRILL on four benchmark datasets against\nstate-of-the-art approaches. Our results suggest that DRILL converges to goal\nstates at least 2.7$\\times$ faster than state-of-the-art models on all\nbenchmark datasets. We provide an open-source implementation of our approach,\nincluding training and evaluation scripts as well as pre-trained models.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 12:57:45 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Demir", "Caglar", ""], ["Ngomo", "Axel-Cyrille Ngonga", ""]]}, {"id": "2106.15380", "submitter": "Guillermo Infante", "authors": "Guillermo Infante, Anders Jonsso, Vicen\\c{c} G\\'omez", "title": "Globally Optimal Hierarchical Reinforcement Learning for\n  Linearly-Solvable Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this work we present a novel approach to hierarchical reinforcement\nlearning for linearly-solvable Markov decision processes. Our approach assumes\nthat the state space is partitioned, and the subtasks consist in moving between\nthe partitions. We represent value functions on several levels of abstraction,\nand use the compositionality of subtasks to estimate the optimal values of the\nstates in each partition. The policy is implicitly defined on these optimal\nvalue estimates, rather than being decomposed among the subtasks. As a\nconsequence, our approach can learn the globally optimal policy, and does not\nsuffer from the non-stationarity of high-level decisions. If several partitions\nhave equivalent dynamics, the subtasks of those partitions can be shared. If\nthe set of boundary states is smaller than the entire state space, our approach\ncan have significantly smaller sample complexity than that of a flat learner,\nand we validate this empirically in several experiments.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 13:10:08 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Infante", "Guillermo", ""], ["Jonsso", "Anders", ""], ["G\u00f3mez", "Vicen\u00e7", ""]]}, {"id": "2106.15398", "submitter": "Anna Kalenkova", "authors": "Anna Kalenkova, Josep Carmona, Artem Polyvyanyy, Marcello La Rosa", "title": "Automated Repair of Process Models with Non-Local Constraints Using\n  State-Based Region Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art process discovery methods construct free-choice process\nmodels from event logs. Consequently, the constructed models do not take into\naccount indirect dependencies between events. Whenever the input behaviour is\nnot free-choice, these methods fail to provide a precise model. In this paper,\nwe propose a novel approach for enhancing free-choice process models by adding\nnon-free-choice constructs discovered a-posteriori via region-based techniques.\nThis allows us to benefit from the performance of existing process discovery\nmethods and the accuracy of the employed fundamental synthesis techniques. We\nprove that the proposed approach preserves fitness with respect to the event\nlog while improving the precision when indirect dependencies exist. The\napproach has been implemented and tested on both synthetic and real-life\ndatasets. The results show its effectiveness in repairing models discovered\nfrom event logs.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 21:14:04 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Kalenkova", "Anna", ""], ["Carmona", "Josep", ""], ["Polyvyanyy", "Artem", ""], ["La Rosa", "Marcello", ""]]}, {"id": "2106.15411", "submitter": "Jasmin Bogatinovski", "authors": "Jasmin Bogatinovski, Ljup\\v{c}o Todorovski, Sa\\v{s}o D\\v{z}eroski,\n  Dragi Kocev", "title": "Explaining the Performance of Multi-label Classification Methods with\n  Data Set Properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Meta learning generalizes the empirical experience with different learning\ntasks and holds promise for providing important empirical insight into the\nbehaviour of machine learning algorithms. In this paper, we present a\ncomprehensive meta-learning study of data sets and methods for multi-label\nclassification (MLC). MLC is a practically relevant machine learning task where\neach example is labelled with multiple labels simultaneously. Here, we analyze\n40 MLC data sets by using 50 meta features describing different properties of\nthe data. The main findings of this study are as follows. First, the most\nprominent meta features that describe the space of MLC data sets are the ones\nassessing different aspects of the label space. Second, the meta models show\nthat the most important meta features describe the label space, and, the meta\nfeatures describing the relationships among the labels tend to occur a bit more\noften than the meta features describing the distributions between and within\nthe individual labels. Third, the optimization of the hyperparameters can\nimprove the predictive performance, however, quite often the extent of the\nimprovements does not always justify the resource utilization.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 11:00:05 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Bogatinovski", "Jasmin", ""], ["Todorovski", "Ljup\u010do", ""], ["D\u017eeroski", "Sa\u0161o", ""], ["Kocev", "Dragi", ""]]}, {"id": "2106.15416", "submitter": "Alexander Gorban", "authors": "Alexander N. Gorban, Bogdan Grechuk, Evgeny M. Mirkes, Sergey V.\n  Stasenko, Ivan Y. Tyukin", "title": "High-dimensional separability for one- and few-shot learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work is driven by a practical question, corrections of Artificial\nIntelligence (AI) errors. Systematic re-training of a large AI system is hardly\npossible. To solve this problem, special external devices, correctors, are\ndeveloped. They should provide quick and non-iterative system fix without\nmodification of a legacy AI system. A common universal part of the AI corrector\nis a classifier that should separate undesired and erroneous behavior from\nnormal operation. Training of such classifiers is a grand challenge at the\nheart of the one- and few-shot learning methods. Effectiveness of one- and\nfew-short methods is based on either significant dimensionality reductions or\nthe blessing of dimensionality effects. Stochastic separability is a blessing\nof dimensionality phenomenon that allows one-and few-shot error correction: in\nhigh-dimensional datasets under broad assumptions each point can be separated\nfrom the rest of the set by simple and robust linear discriminant. The\nhierarchical structure of data universe is introduced where each data cluster\nhas a granular internal structure, etc. New stochastic separation theorems for\nthe data distributions with fine-grained structure are formulated and proved.\nSeparation theorems in infinite-dimensional limits are proven under assumptions\nof compact embedding of patterns into data space. New multi-correctors of AI\nsystems are presented and illustrated with examples of predicting errors and\nlearning new classes of objects by a deep convolutional neural network.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 14:58:14 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Gorban", "Alexander N.", ""], ["Grechuk", "Bogdan", ""], ["Mirkes", "Evgeny M.", ""], ["Stasenko", "Sergey V.", ""], ["Tyukin", "Ivan Y.", ""]]}, {"id": "2106.15419", "submitter": "Zhikang Wang Mr.", "authors": "Zhikang T. Wang, Masahito Ueda", "title": "A Convergent and Efficient Deep Q Network Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the empirical success of the deep Q network (DQN) reinforcement\nlearning algorithm and its variants, DQN is still not well understood and it\ndoes not guarantee convergence. In this work, we show that DQN can diverge and\ncease to operate in realistic settings. Although there exist gradient-based\nconvergent methods, we show that they actually have inherent problems in\nlearning behaviour and elucidate why they often fail in practice. To overcome\nthese problems, we propose a convergent DQN algorithm (C-DQN) by carefully\nmodifying DQN, and we show that the algorithm is convergent and can work with\nlarge discount factors (0.9998). It learns robustly in difficult settings and\ncan learn several difficult games in the Atari 2600 benchmark where DQN fail,\nwithin a moderate computational budget. Our codes have been publicly released\nand can be used to reproduce our results.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 13:38:59 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Wang", "Zhikang T.", ""], ["Ueda", "Masahito", ""]]}, {"id": "2106.15433", "submitter": "Bla\\v{z} \\v{S}krlj", "authors": "Timen Stepi\\v{s}nik Perdih, Nada Lavra\\v{c}, Bla\\v{z} \\v{S}krlj", "title": "Semantic Reasoning from Model-Agnostic Explanations", "comments": null, "journal-ref": null, "doi": "10.1109/SAMI50585.2021.9378668", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  With the wide adoption of black-box models, instance-based \\emph{post hoc}\nexplanation tools, such as LIME and SHAP became increasingly popular. These\ntools produce explanations, pinpointing contributions of key features\nassociated with a given prediction. However, the obtained explanations remain\nat the raw feature level and are not necessarily understandable by a human\nexpert without extensive domain knowledge. We propose ReEx (Reasoning with\nExplanations), a method applicable to explanations generated by arbitrary\ninstance-level explainers, such as SHAP. By using background knowledge in the\nform of ontologies, ReEx generalizes instance explanations in a least general\ngeneralization-like manner. The resulting symbolic descriptions are specific\nfor individual classes and offer generalizations based on the explainer's\noutput. The derived semantic explanations are potentially more informative, as\nthey describe the key attributes in the context of more general background\nknowledge, e.g., at the biological process level. We showcase ReEx's\nperformance on nine biological data sets, showing that compact, semantic\nexplanations can be obtained and are more informative than generic ontology\nmappings that link terms directly to feature names. ReEx is offered as a\nsimple-to-use Python library and is compatible with tools such as SHAP and\nsimilar. To our knowledge, this is one of the first methods that directly\ncouples semantic reasoning with contemporary model explanation methods. This\npaper is a preprint. Full version's doi is: 10.1109/SAMI50585.2021.9378668\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 14:03:47 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Perdih", "Timen Stepi\u0161nik", ""], ["Lavra\u010d", "Nada", ""], ["\u0160krlj", "Bla\u017e", ""]]}, {"id": "2106.15444", "submitter": "Paolo Cintia", "authors": "Paolo Cintia, Luca Pappalardo", "title": "Coach2vec: autoencoding the playing style of soccer coaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Capturing the playing style of professional soccer coaches is a complex, and\nyet barely explored, task in sports analytics. Nowadays, the availability of\ndigital data describing every relevant spatio-temporal aspect of soccer\nmatches, allows for capturing and analyzing the playing style of players,\nteams, and coaches in an automatic way. In this paper, we present coach2vec, a\nworkflow to capture the playing style of professional coaches using match event\nstreams and artificial intelligence. Coach2vec extracts ball possessions from\neach match, clusters them based on their similarity, and reconstructs the\ntypical ball possessions of coaches. Then, it uses an autoencoder, a type of\nartificial neural network, to obtain a concise representation (encoding) of the\nplaying style of each coach. Our experiments, conducted on soccer-logs\ndescribing the last four seasons of the Italian first division, reveal\ninteresting similarities between prominent coaches, paving the road to the\nsimulation of playing styles and the quantitative comparison of professional\ncoaches.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 14:32:38 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Cintia", "Paolo", ""], ["Pappalardo", "Luca", ""]]}, {"id": "2106.15453", "submitter": "Varsha Suresh", "authors": "Yan San Kong, Varsha Suresh, Jonathan Soh, Desmond C. Ong", "title": "A Systematic Evaluation of Domain Adaptation in Facial Expression\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Facial Expression Recognition is a commercially important application, but\none common limitation is that applications often require making predictions on\nout-of-sample distributions, where target images may have very different\nproperties from the images that the model was trained on. How well, or badly,\ndo these models do on unseen target domains? In this paper, we provide a\nsystematic evaluation of domain adaptation in facial expression recognition.\nUsing state-of-the-art transfer learning techniques and six commonly-used\nfacial expression datasets (three collected in the lab and three\n\"in-the-wild\"), we conduct extensive round-robin experiments to examine the\nclassification accuracies for a state-of-the-art CNN model. We also perform\nmulti-source experiments where we examine a model's ability to transfer from\nmultiple source datasets, including (i) within-setting (e.g., lab to lab), (ii)\ncross-setting (e.g., in-the-wild to lab), (iii) mixed-setting (e.g., lab and\nwild to lab) transfer learning experiments. We find sobering results that the\naccuracy of transfer learning is not high, and varies idiosyncratically with\nthe target dataset, and to a lesser extent the source dataset. Generally, the\nbest settings for transfer include fine-tuning the weights of a pre-trained\nmodel, and we find that training with more datasets, regardless of setting,\nimproves transfer performance. We end with a discussion of the need for more --\nand regular -- systematic investigations into the generalizability of FER\nmodels, especially for deployed applications.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 14:41:19 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Kong", "Yan San", ""], ["Suresh", "Varsha", ""], ["Soh", "Jonathan", ""], ["Ong", "Desmond C.", ""]]}, {"id": "2106.15456", "submitter": "Saachi Jain", "authors": "Saachi Jain, Adityanarayanan Radhakrishnan, Caroline Uhler", "title": "A Mechanism for Producing Aligned Latent Spaces with Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aligned latent spaces, where meaningful semantic shifts in the input space\ncorrespond to a translation in the embedding space, play an important role in\nthe success of downstream tasks such as unsupervised clustering and data\nimputation. In this work, we prove that linear and nonlinear autoencoders\nproduce aligned latent spaces by stretching along the left singular vectors of\nthe data. We fully characterize the amount of stretching in linear autoencoders\nand provide an initialization scheme to arbitrarily stretch along the top\ndirections using these networks. We also quantify the amount of stretching in\nnonlinear autoencoders in a simplified setting. We use our theoretical results\nto align drug signatures across cell types in gene expression space and\nsemantic shifts in word embedding spaces.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 14:43:06 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Jain", "Saachi", ""], ["Radhakrishnan", "Adityanarayanan", ""], ["Uhler", "Caroline", ""]]}, {"id": "2106.15467", "submitter": "Shanshan Wang", "authors": "Shanshan Wang, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Huasheng Liang,\n  Qiang Yan, Evangelos Kanoulas, Maarten de Rijke", "title": "Few-Shot Electronic Health Record Coding through Graph Contrastive\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Electronic health record (EHR) coding is the task of assigning ICD codes to\neach EHR. Most previous studies either only focus on the frequent ICD codes or\ntreat rare and frequent ICD codes in the same way. These methods perform well\non frequent ICD codes but due to the extremely unbalanced distribution of ICD\ncodes, the performance on rare ones is far from satisfactory. We seek to\nimprove the performance for both frequent and rare ICD codes by using a\ncontrastive graph-based EHR coding framework, CoGraph, which re-casts EHR\ncoding as a few-shot learning task. First, we construct a heterogeneous EHR\nword-entity (HEWE) graph for each EHR, where the words and entities extracted\nfrom an EHR serve as nodes and the relations between them serve as edges. Then,\nCoGraph learns similarities and dissimilarities between HEWE graphs from\ndifferent ICD codes so that information can be transferred among them. In a\nfew-shot learning scenario, the model only has access to frequent ICD codes\nduring training, which might force it to encode features that are useful for\nfrequent ICD codes only. To mitigate this risk, CoGraph devises two graph\ncontrastive learning schemes, GSCL and GECL, that exploit the HEWE graph\nstructures so as to encode transferable features. GSCL utilizes the\nintra-correlation of different sub-graphs sampled from HEWE graphs while GECL\nexploits the inter-correlation among HEWE graphs at different clinical stages.\nExperiments on the MIMIC-III benchmark dataset show that CoGraph significantly\noutperforms state-of-the-art methods on EHR coding, not only on frequent ICD\ncodes, but also on rare codes, in terms of several evaluation indicators. On\nfrequent ICD codes, GSCL and GECL improve the classification accuracy and F1 by\n1.31% and 0.61%, respectively, and on rare ICD codes CoGraph has more obvious\nimprovements by 2.12% and 2.95%.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 14:53:17 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Wang", "Shanshan", ""], ["Ren", "Pengjie", ""], ["Chen", "Zhumin", ""], ["Ren", "Zhaochun", ""], ["Liang", "Huasheng", ""], ["Yan", "Qiang", ""], ["Kanoulas", "Evangelos", ""], ["de Rijke", "Maarten", ""]]}, {"id": "2106.15499", "submitter": "Sangmin Bae", "authors": "Sangmin Bae, Sungnyun Kim, Jongwoo Ko, Gihun Lee, Seungjong Noh,\n  Se-Young Yun", "title": "Self-Contrastive Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a novel contrastive learning framework, coined as\nSelf-Contrastive (SelfCon) Learning, that self-contrasts within multiple\noutputs from the different levels of a network. We confirmed that SelfCon loss\nguarantees the lower bound of mutual information (MI) between the intermediate\nand last representations. Besides, we empirically showed, via various MI\nestimators, that SelfCon loss highly correlates to the increase of MI and\nbetter classification performance. In our experiments, SelfCon surpasses\nsupervised contrastive (SupCon) learning without the need for a multi-viewed\nbatch and with the cheaper computational cost. Especially on ResNet-18, we\nachieved top-1 classification accuracy of 76.45% for the CIFAR-100 dataset,\nwhich is 2.87% and 4.36% higher than SupCon and cross-entropy loss,\nrespectively. We found that mitigating both vanishing gradient and overfitting\nissue makes our method outperform the counterparts.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 15:26:00 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 12:00:42 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Bae", "Sangmin", ""], ["Kim", "Sungnyun", ""], ["Ko", "Jongwoo", ""], ["Lee", "Gihun", ""], ["Noh", "Seungjong", ""], ["Yun", "Se-Young", ""]]}, {"id": "2106.15502", "submitter": "Ankush Chakrabarty", "authors": "Ankush Chakrabarty, Gordon Wichern, Christopher Laughman", "title": "Attentive Neural Processes and Batch Bayesian Optimization for Scalable\n  Calibration of Physics-Informed Digital Twins", "comments": "12 pages, accepted to ICML 2021 Workshop on Tackling Climate Change\n  with Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physics-informed dynamical system models form critical components of digital\ntwins of the built environment. These digital twins enable the design of\nenergy-efficient infrastructure, but must be properly calibrated to accurately\nreflect system behavior for downstream prediction and analysis. Dynamical\nsystem models of modern buildings are typically described by a large number of\nparameters and incur significant computational expenditure during simulations.\nTo handle large-scale calibration of digital twins without exorbitant\nsimulations, we propose ANP-BBO: a scalable and parallelizable batch-wise\nBayesian optimization (BBO) methodology that leverages attentive neural\nprocesses (ANPs).\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 15:30:55 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Chakrabarty", "Ankush", ""], ["Wichern", "Gordon", ""], ["Laughman", "Christopher", ""]]}, {"id": "2106.15503", "submitter": "Maurizio Parton", "authors": "Marco Miani, Maurizio Parton, Marco Romito", "title": "Curious Explorer: a provable exploration strategy in Policy Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Having access to an exploring restart distribution (the so-called wide\ncoverage assumption) is critical with policy gradient methods. This is due to\nthe fact that, while the objective function is insensitive to updates in\nunlikely states, the agent may still need improvements in those states in order\nto reach a nearly optimal payoff. For this reason, wide coverage is used in\nsome form when analyzing theoretical properties of practical policy gradient\nmethods. However, this assumption can be unfeasible in certain environments,\nfor instance when learning is online, or when restarts are possible only from a\nfixed initial state. In these cases, classical policy gradient algorithms can\nhave very poor convergence properties and sample efficiency. In this paper, we\ndevelop Curious Explorer, a novel and simple iterative state space exploration\nstrategy that can be used with any starting distribution $\\rho$. Curious\nExplorer starts from $\\rho$, then using intrinsic rewards assigned to the set\nof poorly visited states produces a sequence of policies, each one more\nexploratory than the previous one in an informed way, and finally outputs a\nrestart model $\\mu$ based on the state visitation distribution of the\nexploratory policies. Curious Explorer is provable, in the sense that we\nprovide theoretical upper bounds on how often an optimal policy visits poorly\nvisited states. These bounds can be used to prove PAC convergence and sample\nefficiency results when a PAC optimizer is plugged in Curious Explorer. This\nallows to achieve global convergence and sample efficiency results without any\ncoverage assumption for REINFORCE, and potentially for any other policy\ngradient method ensuring PAC convergence with wide coverage. Finally, we plug\n(the output of) Curious Explorer into REINFORCE and TRPO, and show empirically\nthat it can improve performance in MDPs with challenging exploration.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 15:31:51 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Miani", "Marco", ""], ["Parton", "Maurizio", ""], ["Romito", "Marco", ""]]}, {"id": "2106.15504", "submitter": "Siddharth Bhatia", "authors": "Siddharth Bhatia, Yiwei Wang, Bryan Hooi, Tanmoy Chakraborty", "title": "GraphAnoGAN: Detecting Anomalous Snapshots from Attributed Graphs", "comments": "Accepted at ECML-PKDD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Finding anomalous snapshots from a graph has garnered huge attention\nrecently. Existing studies address the problem using shallow learning\nmechanisms such as subspace selection, ego-network, or community analysis.\nThese models do not take into account the multifaceted interactions between the\nstructure and attributes in the network. In this paper, we propose GraphAnoGAN,\nan anomalous snapshot ranking framework, which consists of two core components\n-- generative and discriminative models. Specifically, the generative model\nlearns to approximate the distribution of anomalous samples from the candidate\nset of graph snapshots, and the discriminative model detects whether the\nsampled snapshot is from the ground-truth or not. Experiments on 4 real-world\nnetworks show that GraphAnoGAN outperforms 6 baselines with a significant\nmargin (28.29% and 22.01% higher precision and recall, respectively compared to\nthe best baseline, averaged across all datasets).\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 15:35:37 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Bhatia", "Siddharth", ""], ["Wang", "Yiwei", ""], ["Hooi", "Bryan", ""], ["Chakraborty", "Tanmoy", ""]]}, {"id": "2106.15515", "submitter": "Andrea Roli", "authors": "Stuart A. Kauffman and Andrea Roli", "title": "What Is Consciousness? Artificial Intelligence, Real Intelligence,\n  Quantum Mind, And Qualia", "comments": "Minor changes (typos corrected, references added)", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.AI physics.bio-ph physics.hist-ph", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We approach the question \"What is Consciousness?\" in a new way, not as\nDescartes' \"systematic doubt\", but as how organisms find their way in their\nworld. Finding one's way involves finding possible uses of features of the\nworld that might be beneficial or avoiding those that might be harmful.\n\"Possible uses of X to accomplish Y\" are \"Affordances\". The number of uses of X\nis indefinite (or unknown), the different uses are unordered and are not\ndeducible from one another. All biological adaptations are either affordances\nseized by heritable variation and selection or, far faster, by the organism\nacting in its world finding uses of X to accomplish Y. Based on this, we reach\nrather astonishing conclusions: (1) Artificial General Intelligence based on\nUniversal Turing Machines (UTMs) is not possible, since UTMs cannot \"find\"\nnovel affordances. (2) Brain-mind is not purely classical physics for no\nclassical physics system can be an analogue computer whose dynamical behavior\ncan be isomorphic to \"possible uses\". (3) Brain mind must be partly quantum -\nsupported by increasing evidence at 6.0 sigma to 7.3 Sigma. (4) Based on\nHeisenberg's interpretation of the quantum state as \"Potentia\" converted to\n\"Actuals\" by Measurement, a natural hypothesis is that mind actualizes\nPotentia. This is supported at 5.2 Sigma. Then Mind's actualizations of\nentangled brain-mind-world states are experienced as qualia and allow \"seeing\"\nor \"perceiving\" of uses of X to accomplish Y. We can and do jury-rig. Computers\ncannot. (5) Beyond familiar quantum computers, we discuss the potentialities of\nTrans-Turing-Systems.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 11:20:21 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 18:19:13 GMT"}, {"version": "v3", "created": "Sat, 24 Jul 2021 07:55:55 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Kauffman", "Stuart A.", ""], ["Roli", "Andrea", ""]]}, {"id": "2106.15535", "submitter": "Jiaqi Ma", "authors": "Jiaqi Ma, Junwei Deng, Qiaozhu Mei", "title": "Subgroup Generalization and Fairness of Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite enormous successful applications of graph neural networks (GNNs)\nrecently, theoretical understandings of their generalization ability,\nespecially for node-level tasks where data are not independent and\nidentically-distributed (IID), have been sparse. The theoretical investigation\nof the generalization performance is beneficial for understanding fundamental\nissues (such as fairness) of GNN models and designing better learning methods.\nIn this paper, we present a novel PAC-Bayesian analysis for GNNs under a\nnon-IID semi-supervised learning setup. Moreover, we analyze the generalization\nperformances on different subgroups of unlabeled nodes, which allows us to\nfurther study an accuracy-(dis)parity-style (un)fairness of GNNs from a\ntheoretical perspective. Under reasonable assumptions, we demonstrate that the\ndistance between a test subgroup and the training set can be a key factor\naffecting the GNN performance on that subgroup, which calls special attention\nto the training node selection for fair learning. Experiments across multiple\nGNN models and datasets support our theoretical results.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 16:13:41 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Ma", "Jiaqi", ""], ["Deng", "Junwei", ""], ["Mei", "Qiaozhu", ""]]}, {"id": "2106.15563", "submitter": "Bohdan Kivva", "authors": "Bohdan Kivva, Goutham Rajendran, Pradeep Ravikumar and Bryon Aragam", "title": "Learning latent causal graphs via mixture oracles", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of reconstructing a causal graphical model from data in\nthe presence of latent variables. The main problem of interest is recovering\nthe causal structure over the latent variables while allowing for general,\npotentially nonlinear dependence between the variables. In many practical\nproblems, the dependence between raw observations (e.g. pixels in an image) is\nmuch less relevant than the dependence between certain high-level, latent\nfeatures (e.g. concepts or objects), and this is the setting of interest. We\nprovide conditions under which both the latent representations and the\nunderlying latent causal model are identifiable by a reduction to a mixture\noracle. The proof is constructive, and leads to several algorithms for\nexplicitly reconstructing the full graphical model. We discuss efficient\nalgorithms and provide experiments illustrating the algorithms in practice.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 16:53:34 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Kivva", "Bohdan", ""], ["Rajendran", "Goutham", ""], ["Ravikumar", "Pradeep", ""], ["Aragam", "Bryon", ""]]}, {"id": "2106.15577", "submitter": "Fiorella Wever", "authors": "Fiorella Wever, T. Anderson Keller, Victor Garcia, Laura Symul", "title": "As easy as APC: Leveraging self-supervised learning in the context of\n  time series classification with varying levels of sparsity and severe class\n  imbalance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High levels of sparsity and strong class imbalance are ubiquitous challenges\nthat are often presented simultaneously in real-world time series data. While\nmost methods tackle each problem separately, our proposed approach handles both\nin conjunction, while imposing fewer assumptions on the data. In this work, we\npropose leveraging a self-supervised learning method, specifically\nAutoregressive Predictive Coding (APC), to learn relevant hidden\nrepresentations of time series data in the context of both missing data and\nclass imbalance. We apply APC using either a GRU or GRU-D encoder on two\nreal-world datasets, and show that applying one-step-ahead prediction with APC\nimproves the classification results in all settings. In fact, by applying GRU-D\n- APC, we achieve state-of-the-art AUPRC results on the Physionet benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 17:11:36 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Wever", "Fiorella", ""], ["Keller", "T. Anderson", ""], ["Garcia", "Victor", ""], ["Symul", "Laura", ""]]}, {"id": "2106.15590", "submitter": "William Agnew", "authors": "Abeba Birhane, Pratyusha Kalluri, Dallas Card, William Agnew, Ravit\n  Dotan, Michelle Bao", "title": "The Values Encoded in Machine Learning Research", "comments": "Data and code available at\n  https://github.com/wagnew3/The-Values-Encoded-in-Machine-Learning-Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine learning (ML) currently exerts an outsized influence on the world,\nincreasingly affecting communities and institutional practices. It is therefore\ncritical that we question vague conceptions of the field as value-neutral or\nuniversally beneficial, and investigate what specific values the field is\nadvancing. In this paper, we present a rigorous examination of the values of\nthe field by quantitatively and qualitatively analyzing 100 highly cited ML\npapers published at premier ML conferences, ICML and NeurIPS. We annotate key\nfeatures of papers which reveal their values: how they justify their choice of\nproject, which aspects they uplift, their consideration of potential negative\nconsequences, and their institutional affiliations and funding sources. We find\nthat societal needs are typically very loosely connected to the choice of\nproject, if mentioned at all, and that consideration of negative consequences\nis extremely rare. We identify 67 values that are uplifted in machine learning\nresearch, and, of these, we find that papers most frequently justify and assess\nthemselves based on performance, generalization, efficiency, researcher\nunderstanding, novelty, and building on previous work. We present extensive\ntextual evidence and analysis of how these values are operationalized. Notably,\nwe find that each of these top values is currently being defined and applied\nwith assumptions and implications generally supporting the centralization of\npower. Finally, we find increasingly close ties between these highly cited\npapers and tech companies and elite universities.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 17:24:14 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Birhane", "Abeba", ""], ["Kalluri", "Pratyusha", ""], ["Card", "Dallas", ""], ["Agnew", "William", ""], ["Dotan", "Ravit", ""], ["Bao", "Michelle", ""]]}, {"id": "2106.15599", "submitter": "Nirmalya Thakur", "authors": "Nirmalya Thakur and Chia Y. Han", "title": "Framework for an Intelligent Affect Aware Smart Home Environment for\n  Elderly People", "comments": null, "journal-ref": "International Journal of Recent Trends in Human Computer\n  Interaction (IJHCI), Volume - 9, Issue 1, 2019, pp. 23-43", "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CV cs.ET cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The population of elderly people has been increasing at a rapid rate over the\nlast few decades and their population is expected to further increase in the\nupcoming future. Their increasing population is associated with their\nincreasing needs due to problems like physical disabilities, cognitive issues,\nweakened memory and disorganized behavior, that elderly people face with\nincreasing age. To reduce their financial burden on the world economy and to\nenhance their quality of life, it is essential to develop technology-based\nsolutions that are adaptive, assistive and intelligent in nature. Intelligent\nAffect Aware Systems that can not only analyze but also predict the behavior of\nelderly people in the context of their day to day interactions with technology\nin an IoT-based environment, holds immense potential for serving as a long-term\nsolution for improving the user experience of elderly in smart homes. This work\ntherefore proposes the framework for an Intelligent Affect Aware environment\nfor elderly people that can not only analyze the affective components of their\ninteractions but also predict their likely user experience even before they\nstart engaging in any activity in the given smart home environment. This\nforecasting of user experience would provide scope for enhancing the same,\nthereby increasing the assistive and adaptive nature of such intelligent\nsystems. To uphold the efficacy of this proposed framework for improving the\nquality of life of elderly people in smart homes, it has been tested on three\ndatasets and the results are presented and discussed.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 17:34:16 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Thakur", "Nirmalya", ""], ["Han", "Chia Y.", ""]]}, {"id": "2106.15612", "submitter": "Xiang Fu", "authors": "Xiang Fu, Ge Yang, Pulkit Agrawal, Tommi Jaakkola", "title": "Learning Task Informed Abstractions", "comments": "8 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current model-based reinforcement learning methods struggle when operating\nfrom complex visual scenes due to their inability to prioritize task-relevant\nfeatures. To mitigate this problem, we propose learning Task Informed\nAbstractions (TIA) that explicitly separates reward-correlated visual features\nfrom distractors. For learning TIA, we introduce the formalism of Task Informed\nMDP (TiMDP) that is realized by training two models that learn visual features\nvia cooperative reconstruction, but one model is adversarially dissociated from\nthe reward signal. Empirical evaluation shows that TIA leads to significant\nperformance gains over state-of-the-art methods on many visual control tasks\nwhere natural and unconstrained visual distractions pose a formidable\nchallenge.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 17:56:11 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 01:45:03 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Fu", "Xiang", ""], ["Yang", "Ge", ""], ["Agrawal", "Pulkit", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "2106.15615", "submitter": "Nikunj Saunshi", "authors": "Nikunj Saunshi, Arushi Gupta, Wei Hu", "title": "A Representation Learning Perspective on the Importance of\n  Train-Validation Splitting in Meta-Learning", "comments": "In proceedings of ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An effective approach in meta-learning is to utilize multiple \"train tasks\"\nto learn a good initialization for model parameters that can help solve unseen\n\"test tasks\" with very few samples by fine-tuning from this initialization.\nAlthough successful in practice, theoretical understanding of such methods is\nlimited. This work studies an important aspect of these methods: splitting the\ndata from each task into train (support) and validation (query) sets during\nmeta-training. Inspired by recent work (Raghu et al., 2020), we view such\nmeta-learning methods through the lens of representation learning and argue\nthat the train-validation split encourages the learned representation to be\nlow-rank without compromising on expressivity, as opposed to the non-splitting\nvariant that encourages high-rank representations. Since sample efficiency\nbenefits from low-rankness, the splitting strategy will require very few\nsamples to solve unseen test tasks. We present theoretical results that\nformalize this idea for linear representation learning on a subspace\nmeta-learning instance, and experimentally verify this practical benefit of\nsplitting in simulations and on standard meta-learning benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 17:59:33 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Saunshi", "Nikunj", ""], ["Gupta", "Arushi", ""], ["Hu", "Wei", ""]]}, {"id": "2106.15674", "submitter": "Seyyed Ehsan Mahmoudi", "authors": "Seyyed Ehsan Mahmoudi and Mehrnoush Shamsfard", "title": "SAT Based Analogy Evaluation Framework for Persian Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years there has been a special interest in word embeddings as a new\napproach to convert words to vectors. It has been a focal point to understand\nhow much of the semantics of the the words has been transferred into embedding\nvectors. This is important as the embedding is going to be used as the basis\nfor downstream NLP applications and it will be costly to evaluate the\napplication end-to-end in order to identify quality of the used embedding\nmodel. Generally the word embeddings are evaluated through a number of tests,\nincluding analogy test. In this paper we propose a test framework for Persian\nembedding models. Persian is a low resource language and there is no rich\nsemantic benchmark to evaluate word embedding models for this language. In this\npaper we introduce an evaluation framework including a hand crafted Persian SAT\nbased analogy dataset, a colliquial test set (specific to Persian) and a\nbenchmark to study the impact of various parameters on the semantic evaluation\ntask.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 18:43:06 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Mahmoudi", "Seyyed Ehsan", ""], ["Shamsfard", "Mehrnoush", ""]]}, {"id": "2106.15691", "submitter": "Annie Wong", "authors": "Annie Wong, Thomas B\\\"ack, Anna V. Kononova, Aske Plaat", "title": "Multiagent Deep Reinforcement Learning: Challenges and Directions\n  Towards Human-Like Approaches", "comments": "37 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper surveys the field of multiagent deep reinforcement learning. The\ncombination of deep neural networks with reinforcement learning has gained\nincreased traction in recent years and is slowly shifting the focus from\nsingle-agent to multiagent environments. Dealing with multiple agents is\ninherently more complex as (a) the future rewards depend on the joint actions\nof multiple players and (b) the computational complexity of functions\nincreases. We present the most common multiagent problem representations and\ntheir main challenges, and identify five research areas that address one or\nmore of these challenges: centralised training and decentralised execution,\nopponent modelling, communication, efficient coordination, and reward shaping.\nWe find that many computational studies rely on unrealistic assumptions or are\nnot generalisable to other settings; they struggle to overcome the curse of\ndimensionality or nonstationarity. Approaches from psychology and sociology\ncapture promising relevant behaviours such as communication and coordination.\nWe suggest that, for multiagent reinforcement learning to be successful, future\nresearch addresses these challenges with an interdisciplinary approach to open\nup new possibilities for more human-oriented solutions in multiagent\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 19:53:15 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Wong", "Annie", ""], ["B\u00e4ck", "Thomas", ""], ["Kononova", "Anna V.", ""], ["Plaat", "Aske", ""]]}, {"id": "2106.15755", "submitter": "Yuhong Guo", "authors": "Abdullah Alchihabi, Yuhong Guo", "title": "Dual GNNs: Graph Neural Network Learning with Limited Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) require a relatively large number of labeled\nnodes and a reliable/uncorrupted graph connectivity structure in order to\nobtain good performance on the semi-supervised node classification task. The\nperformance of GNNs can degrade significantly as the number of labeled nodes\ndecreases or the graph connectivity structure is corrupted by adversarial\nattacks or due to noises in data measurement /collection. Therefore, it is\nimportant to develop GNN models that are able to achieve good performance when\nthere is limited supervision knowledge -- a few labeled nodes and noisy graph\nstructures. In this paper, we propose a novel Dual GNN learning framework to\naddress this challenge task. The proposed framework has two GNN based node\nprediction modules. The primary module uses the input graph structure to induce\nregular node embeddings and predictions with a regular GNN baseline, while the\nauxiliary module constructs a new graph structure through fine-grained spectral\nclusterings and learns new node embeddings and predictions. By integrating the\ntwo modules in a dual GNN learning framework, we perform joint learning in an\nend-to-end fashion. This general framework can be applied on many GNN baseline\nmodels. The experimental results validate that the proposed dual GNN framework\ncan greatly outperform the GNN baseline methods when the labeled nodes are\nscarce and the graph connectivity structure is noisy.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 23:52:25 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Alchihabi", "Abdullah", ""], ["Guo", "Yuhong", ""]]}, {"id": "2106.15760", "submitter": "Tung Nguyen Thanh", "authors": "Thanh-Tung Nguyen, Xuan-Phi Nguyen, Shafiq Joty, Xiaoli Li", "title": "A Conditional Splitting Framework for Efficient Constituency Parsing", "comments": "Accepted to ACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a generic seq2seq parsing framework that casts constituency\nparsing problems (syntactic and discourse parsing) into a series of conditional\nsplitting decisions. Our parsing model estimates the conditional probability\ndistribution of possible splitting points in a given text span and supports\nefficient top-down decoding, which is linear in number of nodes. The\nconditional splitting formulation together with efficient beam search inference\nfacilitate structural consistency without relying on expensive structured\ninference. Crucially, for discourse analysis we show that in our formulation,\ndiscourse segmentation can be framed as a special case of parsing which allows\nus to perform discourse parsing without requiring segmentation as a\npre-requisite. Experiments show that our model achieves good results on the\nstandard syntactic parsing tasks under settings with/without pre-trained\nrepresentations and rivals state-of-the-art (SoTA) methods that are more\ncomputationally expensive than ours. In discourse parsing, our method\noutperforms SoTA by a good margin.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 00:36:34 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Nguyen", "Thanh-Tung", ""], ["Nguyen", "Xuan-Phi", ""], ["Joty", "Shafiq", ""], ["Li", "Xiaoli", ""]]}, {"id": "2106.15762", "submitter": "Haifeng Li", "authors": "Haifeng Li, Jun Cao, Jiawei Zhu, Yu Liu, Qing Zhu, Guohua Wu", "title": "Curvature Graph Neural Network", "comments": "16 Pages, 9 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Graph neural networks (GNNs) have achieved great success in many graph-based\ntasks. Much work is dedicated to empowering GNNs with the adaptive locality\nability, which enables measuring the importance of neighboring nodes to the\ntarget node by a node-specific mechanism. However, the current node-specific\nmechanisms are deficient in distinguishing the importance of nodes in the\ntopology structure. We believe that the structural importance of neighboring\nnodes is closely related to their importance in aggregation. In this paper, we\nintroduce discrete graph curvature (the Ricci curvature) to quantify the\nstrength of structural connection of pairwise nodes. And we propose Curvature\nGraph Neural Network (CGNN), which effectively improves the adaptive locality\nability of GNNs by leveraging the structural property of graph curvature. To\nimprove the adaptability of curvature to various datasets, we explicitly\ntransform curvature into the weights of neighboring nodes by the necessary\nNegative Curvature Processing Module and Curvature Normalization Module. Then,\nwe conduct numerous experiments on various synthetic datasets and real-world\ndatasets. The experimental results on synthetic datasets show that CGNN\neffectively exploits the topology structure information, and the performance is\nimproved significantly. CGNN outperforms the baselines on 5 dense node\nclassification benchmark datasets. This study deepens the understanding of how\nto utilize advanced topology information and assign the importance of\nneighboring nodes from the perspective of graph curvature and encourages us to\nbridge the gap between graph theory and neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 00:56:03 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Li", "Haifeng", ""], ["Cao", "Jun", ""], ["Zhu", "Jiawei", ""], ["Liu", "Yu", ""], ["Zhu", "Qing", ""], ["Wu", "Guohua", ""]]}, {"id": "2106.15764", "submitter": "Yisroel Mirsky Dr.", "authors": "Yisroel Mirsky, Ambra Demontis, Jaidip Kotak, Ram Shankar, Deng Gelei,\n  Liu Yang, Xiangyu Zhang, Wenke Lee, Yuval Elovici, Battista Biggio", "title": "The Threat of Offensive AI to Organizations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  AI has provided us with the ability to automate tasks, extract information\nfrom vast amounts of data, and synthesize media that is nearly\nindistinguishable from the real thing. However, positive tools can also be used\nfor negative purposes. In particular, cyber adversaries can use AI (such as\nmachine learning) to enhance their attacks and expand their campaigns.\n  Although offensive AI has been discussed in the past, there is a need to\nanalyze and understand the threat in the context of organizations. For example,\nhow does an AI-capable adversary impact the cyber kill chain? Does AI benefit\nthe attacker more than the defender? What are the most significant AI threats\nfacing organizations today and what will be their impact on the future?\n  In this survey, we explore the threat of offensive AI on organizations.\nFirst, we present the background and discuss how AI changes the adversary's\nmethods, strategies, goals, and overall attack model. Then, through a\nliterature review, we identify 33 offensive AI capabilities which adversaries\ncan use to enhance their attacks. Finally, through a user study spanning\nindustry and academia, we rank the AI threats and provide insights on the\nadversaries.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 01:03:28 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Mirsky", "Yisroel", ""], ["Demontis", "Ambra", ""], ["Kotak", "Jaidip", ""], ["Shankar", "Ram", ""], ["Gelei", "Deng", ""], ["Yang", "Liu", ""], ["Zhang", "Xiangyu", ""], ["Lee", "Wenke", ""], ["Elovici", "Yuval", ""], ["Biggio", "Battista", ""]]}, {"id": "2106.15772", "submitter": "Chao-Chun Liang", "authors": "Shen-Yun Miao, Chao-Chun Liang, Keh-Yih Su", "title": "A Diverse Corpus for Evaluating and Developing English Math Word Problem\n  Solvers", "comments": "ACL-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present ASDiv (Academia Sinica Diverse MWP Dataset), a diverse (in terms\nof both language patterns and problem types) English math word problem (MWP)\ncorpus for evaluating the capability of various MWP solvers. Existing MWP\ncorpora for studying AI progress remain limited either in language usage\npatterns or in problem types. We thus present a new English MWP corpus with\n2,305 MWPs that cover more text patterns and most problem types taught in\nelementary school. Each MWP is annotated with its problem type and grade level\n(for indicating the level of difficulty). Furthermore, we propose a metric to\nmeasure the lexicon usage diversity of a given MWP corpus, and demonstrate that\nASDiv is more diverse than existing corpora. Experiments show that our proposed\ncorpus reflects the true capability of MWP solvers more faithfully.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 01:54:11 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Miao", "Shen-Yun", ""], ["Liang", "Chao-Chun", ""], ["Su", "Keh-Yih", ""]]}, {"id": "2106.15792", "submitter": "Zhen Fang", "authors": "Zhen Fang, Jie Lu, Anjin Liu, Feng Liu, Guangquan Zhang", "title": "Learning Bounds for Open-Set Learning", "comments": "Open-set Learning, Open-set Recognition, Machine Learning Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional supervised learning aims to train a classifier in the closed-set\nworld, where training and test samples share the same label space. In this\npaper, we target a more challenging and realistic setting: open-set learning\n(OSL), where there exist test samples from the classes that are unseen during\ntraining. Although researchers have designed many methods from the algorithmic\nperspectives, there are few methods that provide generalization guarantees on\ntheir ability to achieve consistent performance on different training samples\ndrawn from the same distribution. Motivated by the transfer learning and\nprobably approximate correct (PAC) theory, we make a bold attempt to study OSL\nby proving its generalization error-given training samples with size n, the\nestimation error will get close to order O_p(1/\\sqrt{n}). This is the first\nstudy to provide a generalization bound for OSL, which we do by theoretically\ninvestigating the risk of the target classifier on unknown classes. According\nto our theory, a novel algorithm, called auxiliary open-set risk (AOSR) is\nproposed to address the OSL problem. Experiments verify the efficacy of AOSR.\nThe code is available at github.com/Anjin-Liu/Openset_Learning_AOSR.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 03:10:06 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Fang", "Zhen", ""], ["Lu", "Jie", ""], ["Liu", "Anjin", ""], ["Liu", "Feng", ""], ["Zhang", "Guangquan", ""]]}, {"id": "2106.15793", "submitter": "Sicheng Zhao", "authors": "Xingxu Yao, Sicheng Zhao, Pengfei Xu, Jufeng Yang", "title": "Multi-Source Domain Adaptation for Object Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To reduce annotation labor associated with object detection, an increasing\nnumber of studies focus on transferring the learned knowledge from a labeled\nsource domain to another unlabeled target domain. However, existing methods\nassume that the labeled data are sampled from a single source domain, which\nignores a more generalized scenario, where labeled data are from multiple\nsource domains. For the more challenging task, we propose a unified Faster\nR-CNN based framework, termed Divide-and-Merge Spindle Network (DMSN), which\ncan simultaneously enhance domain invariance and preserve discriminative power.\nSpecifically, the framework contains multiple source subnets and a pseudo\ntarget subnet. First, we propose a hierarchical feature alignment strategy to\nconduct strong and weak alignments for low- and high-level features,\nrespectively, considering their different effects for object detection. Second,\nwe develop a novel pseudo subnet learning algorithm to approximate optimal\nparameters of pseudo target subset by weighted combination of parameters in\ndifferent source subnets. Finally, a consistency regularization for region\nproposal network is proposed to facilitate each subnet to learn more abstract\ninvariances. Extensive experiments on different adaptation scenarios\ndemonstrate the effectiveness of the proposed model.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 03:17:20 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Yao", "Xingxu", ""], ["Zhao", "Sicheng", ""], ["Xu", "Pengfei", ""], ["Yang", "Jufeng", ""]]}, {"id": "2106.15802", "submitter": "Xu Geng", "authors": "Xu Geng, Yilun Jin, Zhengfei Zheng, Yu Yang, Yexin Li, Han Tian, Peibo\n  Duan, Leye Wang, Jiannong Cao, Hai Yang, Qiang Yang, Kai Chen", "title": "CityNet: A Multi-city Multi-modal Dataset for Smart City Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data-driven approaches have been applied to many problems in urban computing.\nHowever, in the research community, such approaches are commonly studied under\ndata from limited sources, and are thus unable to characterize the complexity\nof urban data coming from multiple entities and the correlations among them.\nConsequently, an inclusive and multifaceted dataset is necessary to facilitate\nmore extensive studies on urban computing. In this paper, we present CityNet, a\nmulti-modal urban dataset containing data from 7 cities, each of which coming\nfrom 3 data sources. We first present the generation process of CityNet as well\nas its basic properties. In addition, to facilitate the use of CityNet, we\ncarry out extensive machine learning experiments, including spatio-temporal\npredictions, transfer learning, and reinforcement learning. The experimental\nresults not only provide benchmarks for a wide range of tasks and methods, but\nalso uncover internal correlations among cities and tasks within CityNet that,\nwith adequate leverage, can improve performances on various tasks. With the\nbenchmarking results and the correlations uncovered, we believe that CityNet\ncan contribute to the field of urban computing by supporting research on many\nadvanced topics.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 04:05:51 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Geng", "Xu", ""], ["Jin", "Yilun", ""], ["Zheng", "Zhengfei", ""], ["Yang", "Yu", ""], ["Li", "Yexin", ""], ["Tian", "Han", ""], ["Duan", "Peibo", ""], ["Wang", "Leye", ""], ["Cao", "Jiannong", ""], ["Yang", "Hai", ""], ["Yang", "Qiang", ""], ["Chen", "Kai", ""]]}, {"id": "2106.15808", "submitter": "Baihan Lin", "authors": "Baihan Lin, Djallel Bouneffouf", "title": "Optimal Epidemic Control as a Contextual Combinatorial Bandit with\n  Budget", "comments": "arXiv admin note: text overlap with arXiv:1906.09384 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In light of the COVID-19 pandemic, it is an open challenge and critical\npractical problem to find a optimal way to dynamically prescribe the best\npolicies that balance both the governmental resources and epidemic control in\ndifferent countries and regions. To solve this multi-dimensional tradeoff of\nexploitation and exploration, we formulate this technical challenge as a\ncontextual combinatorial bandit problem that jointly optimizes a multi-criteria\nreward function. Given the historical daily cases in a region and the past\nintervention plans in place, the agent should generate useful intervention\nplans that policy makers can implement in real time to minimizing both the\nnumber of daily COVID-19 cases and the stringency of the recommended\ninterventions. We prove this concept with simulations of multiple realistic\npolicy making scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 04:46:31 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Lin", "Baihan", ""], ["Bouneffouf", "Djallel", ""]]}, {"id": "2106.15831", "submitter": "Anders Johan Andreassen", "authors": "Anders Andreassen, Yasaman Bahri, Behnam Neyshabur, Rebecca Roelofs", "title": "The Evolution of Out-of-Distribution Robustness Throughout Fine-Tuning", "comments": "27 pages, 25 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although machine learning models typically experience a drop in performance\non out-of-distribution data, accuracies on in- versus out-of-distribution data\nare widely observed to follow a single linear trend when evaluated across a\ntestbed of models. Models that are more accurate on the out-of-distribution\ndata relative to this baseline exhibit \"effective robustness\" and are\nexceedingly rare. Identifying such models, and understanding their properties,\nis key to improving out-of-distribution performance. We conduct a thorough\nempirical investigation of effective robustness during fine-tuning and\nsurprisingly find that models pre-trained on larger datasets exhibit effective\nrobustness during training that vanishes at convergence. We study how\nproperties of the data influence effective robustness, and we show that it\nincreases with the larger size, more diversity, and higher example difficulty\nof the dataset. We also find that models that display effective robustness are\nable to correctly classify 10% of the examples that no other current testbed\nmodel gets correct. Finally, we discuss several strategies for scaling\neffective robustness to the high-accuracy regime to improve the\nout-of-distribution accuracy of state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 06:21:42 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Andreassen", "Anders", ""], ["Bahri", "Yasaman", ""], ["Neyshabur", "Behnam", ""], ["Roelofs", "Rebecca", ""]]}, {"id": "2106.15842", "submitter": "Wen Song", "authors": "Zhizheng Zhang, Wen Song, Qiqiang Li", "title": "Dual Aspect Self-Attention based on Transformer for Remaining Useful\n  Life Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remaining useful life prediction (RUL) is one of the key technologies of\ncondition-based maintenance, which is important to maintain the reliability and\nsafety of industrial equipments. While deep learning has achieved great success\nin RUL prediction, existing methods have difficulties in processing long\nsequences and extracting information from the sensor and time step aspects. In\nthis paper, we propose Dual Aspect Self-attention based on Transformer (DAST),\na novel deep RUL prediction method. DAST consists of two encoders, which work\nin parallel to simultaneously extract features of different sensors and time\nsteps. Solely based on self-attention, the DAST encoders are more effective in\nprocessing long data sequences, and are capable of adaptively learning to focus\non more important parts of input. Moreover, the parallel feature extraction\ndesign avoids mutual influence of information from two aspects. Experimental\nresults on two real turbofan engine datasets show that our method significantly\noutperforms state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 06:54:59 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Zhang", "Zhizheng", ""], ["Song", "Wen", ""], ["Li", "Qiqiang", ""]]}, {"id": "2106.15844", "submitter": "Benjamin Patrick Evans", "authors": "Benjamin Patrick Evans, Mikhail Prokopenko", "title": "Bounded rationality for relaxing best response and mutual consistency:\n  An information-theoretic model of partial self-reference", "comments": "35 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.IT econ.GN math.IT q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While game theory has been transformative for decision-making, the\nassumptions made can be overly restrictive in certain instances. In this work,\nwe focus on some of the assumptions underlying rationality such as mutual\nconsistency and best-response, and consider ways to relax these assumptions\nusing concepts from level-$k$ reasoning and quantal response equilibrium (QRE)\nrespectively. Specifically, we provide an information-theoretic two-parameter\nmodel that can relax both mutual consistency and best-response, but can recover\napproximations of level-$k$, QRE, or typical Nash equilibrium behaviour in the\nlimiting cases. The proposed approach is based on a recursive form of the\nvariational free energy principle, representing self-referential games as\n(pseudo) sequential decisions. Bounds in player processing abilities are\ncaptured as information costs, where future chains of reasoning are discounted,\nimplying a hierarchy of players where lower-level players have fewer processing\nresources.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 06:56:56 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Evans", "Benjamin Patrick", ""], ["Prokopenko", "Mikhail", ""]]}, {"id": "2106.15846", "submitter": "Zhiyuan Wen", "authors": "Wen Zhiyuan, Cao Jiannong, Yang Ruosong, Liu Shuaiqi, Shen Jiaxing", "title": "Automatically Select Emotion for Response via Personality-affected\n  Emotion Transition", "comments": "Accepted by Findings of ACL-IJCNLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To provide consistent emotional interaction with users, dialog systems should\nbe capable to automatically select appropriate emotions for responses like\nhumans. However, most existing works focus on rendering specified emotions in\nresponses or empathetically respond to the emotion of users, yet the individual\ndifference in emotion expression is overlooked. This may lead to inconsistent\nemotional expressions and disinterest users. To tackle this issue, we propose\nto equip the dialog system with personality and enable it to automatically\nselect emotions in responses by simulating the emotion transition of humans in\nconversation. In detail, the emotion of the dialog system is transitioned from\nits preceding emotion in context. The transition is triggered by the preceding\ndialog context and affected by the specified personality trait. To achieve\nthis, we first model the emotion transition in the dialog system as the\nvariation between the preceding emotion and the response emotion in the\nValence-Arousal-Dominance (VAD) emotion space. Then, we design neural networks\nto encode the preceding dialog context and the specified personality traits to\ncompose the variation. Finally, the emotion for response is selected from the\nsum of the preceding emotion and the variation. We construct a dialog dataset\nwith emotion and personality labels and conduct emotion prediction tasks for\nevaluation. Experimental results validate the effectiveness of the\npersonality-affected emotion transition.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 07:00:42 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Zhiyuan", "Wen", ""], ["Jiannong", "Cao", ""], ["Ruosong", "Yang", ""], ["Shuaiqi", "Liu", ""], ["Jiaxing", "Shen", ""]]}, {"id": "2106.15850", "submitter": "Asim Waqas", "authors": "Asim Waqas (1), Ghulam Rasool (1), Hamza Farooq (2), and Nidhal C.\n  Bouaynaya (1), ((1) Rowan University, (2) University of Minnesota)", "title": "Exploring Robustness of Neural Networks through Graph Measures", "comments": "18 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Motivated by graph theory, artificial neural networks (ANNs) are\ntraditionally structured as layers of neurons (nodes), which learn useful\ninformation by the passage of data through interconnections (edges). In the\nmachine learning realm, graph structures (i.e., neurons and connections) of\nANNs have recently been explored using various graph-theoretic measures linked\nto their predictive performance. On the other hand, in network science\n(NetSci), certain graph measures including entropy and curvature are known to\nprovide insight into the robustness and fragility of real-world networks. In\nthis work, we use these graph measures to explore the robustness of various\nANNs to adversarial attacks. To this end, we (1) explore the design space of\ninter-layer and intra-layers connectivity regimes of ANNs in the graph domain\nand record their predictive performance after training under different types of\nadversarial attacks, (2) use graph representations for both inter-layer and\nintra-layers connectivity regimes to calculate various graph-theoretic\nmeasures, including curvature and entropy, and (3) analyze the relationship\nbetween these graph measures and the adversarial performance of ANNs. We show\nthat curvature and entropy, while operating in the graph domain, can quantify\nthe robustness of ANNs without having to train these ANNs. Our results suggest\nthat the real-world networks, including brain networks, financial networks, and\nsocial networks may provide important clues to the neural architecture search\nfor robust ANNs. We propose a search strategy that efficiently finds robust\nANNs amongst a set of well-performing ANNs without having a need to train all\nof these ANNs.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 07:12:19 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Waqas", "Asim", "", "Rowan University"], ["Rasool", "Ghulam", "", "Rowan University"], ["Farooq", "Hamza", "", "University of Minnesota"], ["Bouaynaya", "Nidhal C.", "", "Rowan University"]]}, {"id": "2106.15868", "submitter": "Per R. Leikanger", "authors": "Per R. Leikanger", "title": "Decomposing the Prediction Problem; Autonomous Navigation by neoRL\n  Agents", "comments": "Accepted at A-life 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Navigating the world is a fundamental ability for any living entity.\nAccomplishing the same degree of freedom in technology has proven to be\ndifficult. The brain is the only known mechanism capable of voluntary\nnavigation, making neuroscience our best source of inspiration toward autonomy.\nAssuming that state representation is key, we explore the difference in how the\nbrain and the machine represent the navigational state. Where Reinforcement\nLearning (RL) requires a monolithic state representation in accordance with the\nMarkov property, Neural Representation of Euclidean Space (NRES) reflects\nnavigational state via distributed activation patterns. We show how\nNRES-Oriented RL (neoRL) agents are possible before verifying our theoretical\nfindings by experiments. Ultimately, neoRL agents are capable of behavior\nsynthesis across state spaces -- allowing for decomposition of the problem into\nsmaller spaces, alleviating the curse of dimensionality.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 07:57:36 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Leikanger", "Per R.", ""]]}, {"id": "2106.15877", "submitter": "Jialin Liu Ph.D", "authors": "Tianye Shu, Jialin Liu, Georgios N. Yannakakis", "title": "Experience-Driven PCG via Reinforcement Learning: A Super Mario Bros\n  Study", "comments": "This paper is accepted by the 2021 IEEE Conference on Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a procedural content generation (PCG) framework at the\nintersections of experience-driven PCG and PCG via reinforcement learning,\nnamed ED(PCG)RL, EDRL in short. EDRL is able to teach RL designers to generate\nendless playable levels in an online manner while respecting particular\nexperiences for the player as designed in the form of reward functions. The\nframework is tested initially in the Super Mario Bros game. In particular, the\nRL designers of Super Mario Bros generate and concatenate level segments while\nconsidering the diversity among the segments. The correctness of the generation\nis ensured by a neural net-assisted evolutionary level repairer and the\nplayability of the whole level is determined through AI-based testing. Our\nagents in this EDRL implementation learn to maximise a quantification of\nKoster's principle of fun by moderating the degree of diversity across level\nsegments. Moreover, we test their ability to design fun levels that are diverse\nover time and playable. Our proposed framework is capable of generating\nendless, playable Super Mario Bros levels with varying degrees of fun,\ndeviation from earlier segments, and playability. EDRL can be generalised to\nany game that is built as a segment-based sequential process and features a\nbuilt-in compressed representation of its game content.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 08:10:45 GMT"}, {"version": "v2", "created": "Mon, 5 Jul 2021 01:30:15 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Shu", "Tianye", ""], ["Liu", "Jialin", ""], ["Yannakakis", "Georgios N.", ""]]}, {"id": "2106.15896", "submitter": "Valerio Basile", "authors": "Sohail Akhtar, Valerio Basile, Viviana Patti", "title": "Whose Opinions Matter? Perspective-aware Models to Identify Opinions of\n  Hate Speech Victims in Abusive Language Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Social media platforms provide users the freedom of expression and a medium\nto exchange information and express diverse opinions. Unfortunately, this has\nalso resulted in the growth of abusive content with the purpose of\ndiscriminating people and targeting the most vulnerable communities such as\nimmigrants, LGBT, Muslims, Jews and women. Because abusive language is\nsubjective in nature, there might be highly polarizing topics or events\ninvolved in the annotation of abusive contents such as hate speech (HS).\nTherefore, we need novel approaches to model conflicting perspectives and\nopinions coming from people with different personal and demographic\nbackgrounds. In this paper, we present an in-depth study to model polarized\nopinions coming from different communities under the hypothesis that similar\ncharacteristics (ethnicity, social background, culture etc.) can influence the\nperspectives of annotators on a certain phenomenon. We believe that by relying\non this information, we can divide the annotators into groups sharing similar\nperspectives. We can create separate gold standards, one for each group, to\ntrain state-of-the-art deep learning models. We can employ an ensemble approach\nto combine the perspective-aware classifiers from different groups to an\ninclusive model. We also propose a novel resource, a multi-perspective English\nlanguage dataset annotated according to different sub-categories relevant for\ncharacterising online abuse: hate speech, aggressiveness, offensiveness and\nstereotype. By training state-of-the-art deep learning models on this novel\nresource, we show how our approach improves the prediction performance of a\nstate-of-the-art supervised classifier.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 08:35:49 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Akhtar", "Sohail", ""], ["Basile", "Valerio", ""], ["Patti", "Viviana", ""]]}, {"id": "2106.15905", "submitter": "Meng Zhang", "authors": "Meng Zhang, Ermin Wei, and Randall Berry", "title": "Faithful Edge Federated Learning: Scalability and Privacy", "comments": "Under review by JSAC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning enables machine learning algorithms to be trained over a\nnetwork of multiple decentralized edge devices without requiring the exchange\nof local datasets. Successfully deploying federated learning requires ensuring\nthat agents (e.g., mobile devices) faithfully execute the intended algorithm,\nwhich has been largely overlooked in the literature. In this study, we first\nuse risk bounds to analyze how the key feature of federated learning,\nunbalanced and non-i.i.d. data, affects agents' incentives to voluntarily\nparticipate and obediently follow traditional federated learning algorithms.\n  To be more specific, our analysis reveals that agents with less typical data\ndistributions and relatively more samples are more likely to opt out of or\ntamper with federated learning algorithms. To this end, we formulate the first\nfaithful implementation problem of federated learning and design two faithful\nfederated learning mechanisms which satisfy economic properties, scalability,\nand privacy. Further, the time complexity of computing all agents' payments in\nthe number of agents is $\\mathcal{O}(1)$. First, we design a Faithful Federated\nLearning (FFL) mechanism which approximates the Vickrey-Clarke-Groves (VCG)\npayments via an incremental computation. We show that it achieves (probably\napproximate) optimality, faithful implementation, voluntary participation, and\nsome other economic properties (such as budget balance). Second, by\npartitioning agents into several subsets, we present a scalable VCG mechanism\napproximation. We further design a scalable and Differentially Private FFL\n(DP-FFL) mechanism, the first differentially private faithful mechanism, that\nmaintains the economic properties. Our mechanism enables one to make three-way\nperformance tradeoffs among privacy, the iterations needed, and payment\naccuracy loss.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 08:46:40 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Zhang", "Meng", ""], ["Wei", "Ermin", ""], ["Berry", "Randall", ""]]}, {"id": "2106.15931", "submitter": "Maximilian Hoffmann", "authors": "Maximilian Hoffmann, Ralph Bergmann", "title": "Informed Machine Learning for Improved Similarity Assessment in\n  Process-Oriented Case-Based Reasoning", "comments": "Accepted at the IJCAI-21 workshop on Deep Learning, Case-Based\n  Reasoning, and AutoML: Present and Future Synergies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Currently, Deep Learning (DL) components within a Case-Based Reasoning (CBR)\napplication often lack the comprehensive integration of available domain\nknowledge. The trend within machine learning towards so-called Informed machine\nlearning can help to overcome this limitation. In this paper, we therefore\ninvestigate the potential of integrating domain knowledge into Graph Neural\nNetworks (GNNs) that are used for similarity assessment between semantic graphs\nwithin process-oriented CBR applications. We integrate knowledge in two ways:\nFirst, a special data representation and processing method is used that encodes\nstructural knowledge about the semantic annotations of each graph node and\nedge. Second, the message-passing component of the GNNs is constrained by\nknowledge on legal node mappings. The evaluation examines the quality and\ntraining time of the extended GNNs, compared to the stock models. The results\nshow that both extensions are capable of providing better quality, shorter\ntraining times, or in some configurations both advantages at once.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 09:31:58 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Hoffmann", "Maximilian", ""], ["Bergmann", "Ralph", ""]]}, {"id": "2106.15962", "submitter": "Chang Liu", "authors": "Chang Liu, Haoyue Tang, Tao Qin, Jintao Wang, Tie-Yan Liu", "title": "On the Generative Utility of Cyclic Conditionals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study whether and how can we model a joint distribution $p(x,z)$ using two\nconditional models $p(x|z)$ and $q(z|x)$ that form a cycle. This is motivated\nby the observation that deep generative models, in addition to a likelihood\nmodel $p(x|z)$, often also use an inference model $q(z|x)$ for data\nrepresentation, but they rely on a usually uninformative prior distribution\n$p(z)$ to define a joint distribution, which may render problems like posterior\ncollapse and manifold mismatch. To explore the possibility to model a joint\ndistribution using only $p(x|z)$ and $q(z|x)$, we study their compatibility and\ndeterminacy, corresponding to the existence and uniqueness of a joint\ndistribution whose conditional distributions coincide with them. We develop a\ngeneral theory for novel and operable equivalence criteria for compatibility,\nand sufficient conditions for determinacy. Based on the theory, we propose the\nCyGen framework for cyclic-conditional generative modeling, including methods\nto enforce compatibility and use the determined distribution to fit and\ngenerate data. With the prior constraint removed, CyGen better fits data and\ncaptures more representative features, supported by experiments showing better\ngeneration and downstream classification performance.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 10:23:45 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Liu", "Chang", ""], ["Tang", "Haoyue", ""], ["Qin", "Tao", ""], ["Wang", "Jintao", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2106.15979", "submitter": "Evan Piermont", "authors": "Evan Piermont", "title": "Hypothetical Expected Utility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.TH cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a model to analyze and identify a decision maker's (DM's)\nhypothetical reasoning. Using this model, I show that a DM's propensity to\nengage in hypothetical thinking is captured exactly by her ability to recognize\nimplications (i.e., to identify that one hypothesis implies another) and that\nthis later relation is encoded by a DM's observable behavior. Thus, this\ncharacterization both provides a concrete definition of (flawed) hypothetical\nreasoning and, importantly, yields a methodology to identify these judgments\nfrom standard economic data.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 10:56:24 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 18:30:16 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Piermont", "Evan", ""]]}, {"id": "2106.16000", "submitter": "Yuexiang Li", "authors": "Jiawei Chen and Yuexiang Li and Kai Ma and Yefeng Zheng", "title": "Mutual-GAN: Towards Unsupervised Cross-Weather Adaptation with Mutual\n  Information Constraint", "comments": "An extension of our MICCAI paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Convolutional neural network (CNN) have proven its success for semantic\nsegmentation, which is a core task of emerging industrial applications such as\nautonomous driving. However, most progress in semantic segmentation of urban\nscenes is reported on standard scenarios, i.e., daytime scenes with favorable\nillumination conditions. In practical applications, the outdoor weather and\nillumination are changeable, e.g., cloudy and nighttime, which results in a\nsignificant drop of semantic segmentation accuracy of CNN only trained with\ndaytime data. In this paper, we propose a novel generative adversarial network\n(namely Mutual-GAN) to alleviate the accuracy decline when daytime-trained\nneural network is applied to videos captured under adverse weather conditions.\nThe proposed Mutual-GAN adopts mutual information constraint to preserve\nimage-objects during cross-weather adaptation, which is an unsolved problem for\nmost unsupervised image-to-image translation approaches (e.g., CycleGAN). The\nproposed Mutual-GAN is evaluated on two publicly available driving video\ndatasets (i.e., CamVid and SYNTHIA). The experimental results demonstrate that\nour Mutual-GAN can yield visually plausible translated images and significantly\nimprove the semantic segmentation accuracy of daytime-trained deep learning\nnetwork while processing videos under challenging weathers.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 11:44:22 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Chen", "Jiawei", ""], ["Li", "Yuexiang", ""], ["Ma", "Kai", ""], ["Zheng", "Yefeng", ""]]}, {"id": "2106.16004", "submitter": "Tiffany Vlaar", "authors": "Tiffany Vlaar and Jonathan Frankle", "title": "What can linear interpolation of neural network loss landscapes tell us?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studying neural network loss landscapes provides insights into the nature of\nthe underlying optimization problems. Unfortunately, loss landscapes are\nnotoriously difficult to visualize in a human-comprehensible fashion. One\ncommon way to address this problem is to plot linear slices of the landscape,\nfor example from the initial state of the network to the final state after\noptimization. On the basis of this analysis, prior work has drawn broader\nconclusions about the difficulty of the optimization problem. In this paper, we\nput inferences of this kind to the test, systematically evaluating how linear\ninterpolation and final performance vary when altering the data, choice of\ninitialization, and other optimizer and architecture design choices. Further,\nwe use linear interpolation to study the role played by individual layers and\nsubstructures of the network. We find that certain layers are more sensitive to\nthe choice of initialization and optimizer hyperparameter settings, and we\nexploit these observations to design custom optimization schemes. However, our\nresults cast doubt on the broader intuition that the presence or absence of\nbarriers when interpolating necessarily relates to the success of optimization.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 11:54:04 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Vlaar", "Tiffany", ""], ["Frankle", "Jonathan", ""]]}, {"id": "2106.16036", "submitter": "Prateek Verma", "authors": "Prateek Verma, Chris Chafe", "title": "A Generative Model for Raw Audio Using Transformer Architectures", "comments": "DAFX 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG cs.MM eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel way of doing audio synthesis at the waveform\nlevel using Transformer architectures. We propose a deep neural network for\ngenerating waveforms, similar to wavenet. This is fully probabilistic,\nauto-regressive, and causal, i.e. each sample generated depends only on the\npreviously observed samples. Our approach outperforms a widely used wavenet\narchitecture by up to 9% on a similar dataset for predicting the next step.\nUsing the attention mechanism, we enable the architecture to learn which audio\nsamples are important for the prediction of the future sample. We show how\ncausal transformer generative models can be used for raw waveform synthesis. We\nalso show that this performance can be improved by another 2% by conditioning\nsamples over a wider context. The flexibility of the current model to\nsynthesize audio from latent representations suggests a large number of\npotential applications. The novel approach of using generative transformer\narchitectures for raw audio synthesis is, however, still far away from\ngenerating any meaningful music, without using latent codes/meta-data to aid\nthe generation process.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 13:05:31 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2021 12:41:18 GMT"}, {"version": "v3", "created": "Thu, 8 Jul 2021 15:28:02 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Verma", "Prateek", ""], ["Chafe", "Chris", ""]]}, {"id": "2106.16046", "submitter": "Liyue Chen", "authors": "Liyue Chen, Leye Wang", "title": "Exploring Context Modeling Techniques on the Spatiotemporal Crowd Flow\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the big data and AI era, context is widely exploited as extra information\nwhich makes it easier to learn a more complex pattern in machine learning\nsystems. However, most of the existing related studies seldom take context into\naccount. The difficulty lies in the unknown generalization ability of both\ncontext and its modeling techniques across different scenarios. To fill the\nabove gaps, we conduct a large-scale analytical and empirical study on the\nspatiotemporal crowd prediction (STCFP) problem that is a widely-studied and\nhot research topic. We mainly make three efforts:(i) we develop new taxonomy\nabout both context features and context modeling techniques based on extensive\ninvestigations in prevailing STCFP research; (ii) we conduct extensive\nexperiments on seven datasets with hundreds of millions of records to\nquantitatively evaluate the generalization ability of both distinct context\nfeatures and context modeling techniques; (iii) we summarize some guidelines\nfor researchers to conveniently utilize context in diverse applications.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 13:19:41 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Chen", "Liyue", ""], ["Wang", "Leye", ""]]}, {"id": "2106.16050", "submitter": "Per Erik Strandberg", "authors": "Per Erik Strandberg, Mirgita Frasheri, Eduard Paul Enoiu", "title": "Ethical AI-Powered Regression Test Selection", "comments": "2 pages, 1 figure, accepted to AITest'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Test automation is common in software development; often one tests repeatedly\nto identify regressions. If the amount of test cases is large, one may select a\nsubset and only use the most important test cases. The regression test\nselection (RTS) could be automated and enhanced with Artificial Intelligence\n(AI-RTS). This however could introduce ethical challenges. While such\nchallenges in AI are in general well studied, there is a gap with respect to\nethical AI-RTS. By exploring the literature and learning from our experiences\nof developing an industry AI-RTS tool, we contribute to the literature by\nidentifying three challenges (assigning responsibility, bias in decision-making\nand lack of participation) and three approaches (explicability, supervision and\ndiversity). Additionally, we provide a checklist for ethical AI-RTS to help\nguide the decision-making of the stakeholders involved in the process.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 13:24:51 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Strandberg", "Per Erik", ""], ["Frasheri", "Mirgita", ""], ["Enoiu", "Eduard Paul", ""]]}, {"id": "2106.16061", "submitter": "Quanlong Wang", "authors": "Camilo Miguel Signorelli, Quanlong Wang, Bob Coecke", "title": "Reasoning about conscious experience with axiomatic and graphical\n  mathematics", "comments": "20 pages, accepted to Consciousness and Cognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We cast aspects of consciousness in axiomatic mathematical terms, using the\ngraphical calculus of general process theories (a.k.a symmetric monoidal\ncategories and Frobenius algebras therein). This calculus exploits the\nontological neutrality of process theories. A toy example using the axiomatic\ncalculus is given to show the power of this approach, recovering other aspects\nof conscious experience, such as external and internal subjective distinction,\nprivacy or unreadability of personal subjective experience, and phenomenal\nunity, one of the main issues for scientific studies of consciousness. In fact,\nthese features naturally arise from the compositional nature of axiomatic\ncalculus.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 13:39:02 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Signorelli", "Camilo Miguel", ""], ["Wang", "Quanlong", ""], ["Coecke", "Bob", ""]]}, {"id": "2106.16125", "submitter": "Sicheng Zhao", "authors": "Sicheng Zhao, Xingxu Yao, Jufeng Yang, Guoli Jia, Guiguang Ding,\n  Tat-Seng Chua, Bj\\\"orn W. Schuller, Kurt Keutzer", "title": "Affective Image Content Analysis: Two Decades Review and New\n  Perspectives", "comments": "Accepted by IEEE TPAMI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Images can convey rich semantics and induce various emotions in viewers.\nRecently, with the rapid advancement of emotional intelligence and the\nexplosive growth of visual data, extensive research efforts have been dedicated\nto affective image content analysis (AICA). In this survey, we will\ncomprehensively review the development of AICA in the recent two decades,\nespecially focusing on the state-of-the-art methods with respect to three main\nchallenges -- the affective gap, perception subjectivity, and label noise and\nabsence. We begin with an introduction to the key emotion representation models\nthat have been widely employed in AICA and description of available datasets\nfor performing evaluation with quantitative comparison of label noise and\ndataset bias. We then summarize and compare the representative approaches on\n(1) emotion feature extraction, including both handcrafted and deep features,\n(2) learning methods on dominant emotion recognition, personalized emotion\nprediction, emotion distribution learning, and learning from noisy data or few\nlabels, and (3) AICA based applications. Finally, we discuss some challenges\nand promising research directions in the future, such as image content and\ncontext understanding, group emotion clustering, and viewer-image interaction.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 15:20:56 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Zhao", "Sicheng", ""], ["Yao", "Xingxu", ""], ["Yang", "Jufeng", ""], ["Jia", "Guoli", ""], ["Ding", "Guiguang", ""], ["Chua", "Tat-Seng", ""], ["Schuller", "Bj\u00f6rn W.", ""], ["Keutzer", "Kurt", ""]]}, {"id": "2106.16176", "submitter": "Shamay Samuel", "authors": "Shamay G. Samuel, Enrique Areyan Viqueira, Serdar Kadioglu", "title": "Integrated Vehicle Routing and Monte Carlo Scheduling Approach for the\n  Home Service Assignment, Routing, and Scheduling Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We formulate and solve the H-SARA Problem, a Vehicle Routing and Appointment\nScheduling Problem motivated by home services management. We assume that travel\ntimes, service durations, and customer cancellations are stochastic. We use a\ntwo-stage process that first generates teams and routes using a VRP Solver with\noptional extensions and then uses an MC Scheduler that determines expected\narrival times by teams at customers. We further introduce two different models\nof cancellation and their associated impacts on routing and scheduling.\nFinally, we introduce the Route Fracture Metaheuristic that iteratively\nimproves an H-SARA solution by replacing the worst-performing teams. We present\ninsights into the problem and a series of numerical experiments that illustrate\nproperties of the optimal routing, scheduling, and the impact of the Route\nFracture Metaheuristic for both models of cancellation.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 16:12:14 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Samuel", "Shamay G.", ""], ["Viqueira", "Enrique Areyan", ""], ["Kadioglu", "Serdar", ""]]}, {"id": "2106.16233", "submitter": "Isel Grau", "authors": "Gonzalo N\\'apoles, Isel Grau, Agnieszka Jastrzebska, Yamisleydi\n  Salgueiro", "title": "Long Short-term Cognitive Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we present a recurrent neural system named Long Short-term\nCognitive Networks (LSTCNs) as a generalisation of the Short-term Cognitive\nNetwork (STCN) model. Such a generalisation is motivated by the difficulty of\nforecasting very long time series in an efficient, greener fashion. The LSTCN\nmodel can be defined as a collection of STCN blocks, each processing a specific\ntime patch of the (multivariate) time series being modelled. In this neural\nensemble, each block passes information to the subsequent one in the form of a\nweight matrix referred to as the prior knowledge matrix. As a second\ncontribution, we propose a deterministic learning algorithm to compute the\nlearnable weights while preserving the prior knowledge resulting from previous\nlearning processes. As a third contribution, we introduce a feature influence\nscore as a proxy to explain the forecasting process in multivariate time\nseries. The simulations using three case studies show that our neural system\nreports small forecasting errors while being up to thousands of times faster\nthan state-of-the-art recurrent models.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 17:42:09 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["N\u00e1poles", "Gonzalo", ""], ["Grau", "Isel", ""], ["Jastrzebska", "Agnieszka", ""], ["Salgueiro", "Yamisleydi", ""]]}, {"id": "2106.16245", "submitter": "Wei-Lun Chao", "authors": "Han-Jia Ye, Wei-Lun Chao", "title": "How to Train Your MAML to Excel in Few-Shot Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Model-agnostic meta-learning (MAML) is arguably the most popular\nmeta-learning algorithm nowadays, given its flexibility to incorporate various\nmodel architectures and to be applied to different problems. Nevertheless, its\nperformance on few-shot classification is far behind many recent algorithms\ndedicated to the problem. In this paper, we point out several key facets of how\nto train MAML to excel in few-shot classification. First, we find that a large\nnumber of gradient steps are needed for the inner loop update, which\ncontradicts the common usage of MAML for few-shot classification. Second, we\nfind that MAML is sensitive to the permutation of class assignments in\nmeta-testing: for a few-shot task of $N$ classes, there are exponentially many\nways to assign the learned initialization of the $N$-way classifier to the $N$\nclasses, leading to an unavoidably huge variance. Third, we investigate several\nways for permutation invariance and find that learning a shared classifier\ninitialization for all the classes performs the best. On benchmark datasets\nsuch as MiniImageNet and TieredImageNet, our approach, which we name\nUNICORN-MAML, performs on a par with or even outperforms state-of-the-art\nalgorithms, while keeping the simplicity of MAML without adding any extra\nsub-networks.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 17:56:15 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Ye", "Han-Jia", ""], ["Chao", "Wei-Lun", ""]]}]