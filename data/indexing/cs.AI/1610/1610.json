[{"id": "1610.00001", "submitter": "Harishchandra Dubey", "authors": "Shiba R. Paital, Prakash K. Ray, Asit Mohanty, Sandipan Patra,\n  Harishchandra Dubey", "title": "Bacterial Foraging Optimized STATCOM for Stability Assessment in Power\n  System", "comments": "5 pages, 7 figures, 2016 IEEE Students' Technology Symposium (TechSym\n  2016), At IIT Kharagpur, India", "journal-ref": null, "doi": "10.13140/RG.2.2.16849.33129", "report-no": null, "categories": "cs.SY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a study of improvement in stability in a single machine\nconnected to infinite bus (SMIB) power system by using static compensator\n(STATCOM). The gains of Proportional-Integral-Derivative (PID) controller in\nSTATCOM are being optimized by heuristic technique based on Particle swarm\noptimization (PSO). Further, Bacterial Foraging Optimization (BFO) as an\nalternative heuristic method is also applied to select optimal gains of PID\ncontroller. The performance of STATCOM with the above soft-computing techniques\nare studied and compared with the conventional PID controller under various\nscenarios. The simulation results are accompanied with performance indices\nbased quantitative analysis. The analysis clearly signifies the robustness of\nthe new scheme in terms of stability and voltage regulation when compared with\nconventional PID.\n", "versions": [{"version": "v1", "created": "Sat, 1 Oct 2016 22:55:32 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Paital", "Shiba R.", ""], ["Ray", "Prakash K.", ""], ["Mohanty", "Asit", ""], ["Patra", "Sandipan", ""], ["Dubey", "Harishchandra", ""]]}, {"id": "1610.00054", "submitter": "Xuan Hong Dang", "authors": "Xuan-Hong Dang, Arlei Silva, Ambuj Singh, Ananthram Swami, Prithwish\n  Basu", "title": "Outlier Detection from Network Data with Subnetwork Interpretation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting a small number of outliers from a set of data observations is\nalways challenging. This problem is more difficult in the setting of multiple\nnetwork samples, where computing the anomalous degree of a network sample is\ngenerally not sufficient. In fact, explaining why the network is exceptional,\nexpressed in the form of subnetwork, is also equally important. In this paper,\nwe develop a novel algorithm to address these two key problems. We treat each\nnetwork sample as a potential outlier and identify subnetworks that mostly\ndiscriminate it from nearby regular samples. The algorithm is developed in the\nframework of network regression combined with the constraints on both network\ntopology and L1-norm shrinkage to perform subnetwork discovery. Our method thus\ngoes beyond subspace/subgraph discovery and we show that it converges to a\nglobal optimum. Evaluation on various real-world network datasets demonstrates\nthat our algorithm not only outperforms baselines in both network and high\ndimensional setting, but also discovers highly relevant and interpretable local\nsubnetworks, further enhancing our understanding of anomalous networks.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 23:13:28 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Dang", "Xuan-Hong", ""], ["Silva", "Arlei", ""], ["Singh", "Ambuj", ""], ["Swami", "Ananthram", ""], ["Basu", "Prithwish", ""]]}, {"id": "1610.00081", "submitter": "Junbo Zhang", "authors": "Junbo Zhang, Yu Zheng, Dekang Qi", "title": "Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows\n  Prediction", "comments": "AAAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting the flow of crowds is of great importance to traffic management\nand public safety, yet a very challenging task affected by many complex\nfactors, such as inter-region traffic, events and weather. In this paper, we\npropose a deep-learning-based approach, called ST-ResNet, to collectively\nforecast the in-flow and out-flow of crowds in each and every region through a\ncity. We design an end-to-end structure of ST-ResNet based on unique properties\nof spatio-temporal data. More specifically, we employ the framework of the\nresidual neural networks to model the temporal closeness, period, and trend\nproperties of the crowd traffic, respectively. For each property, we design a\nbranch of residual convolutional units, each of which models the spatial\nproperties of the crowd traffic. ST-ResNet learns to dynamically aggregate the\noutput of the three residual neural networks based on data, assigning different\nweights to different branches and regions. The aggregation is further combined\nwith external factors, such as weather and day of the week, to predict the\nfinal traffic of crowds in each and every region. We evaluate ST-ResNet based\non two types of crowd flows in Beijing and NYC, finding that its performance\nexceeds six well-know methods.\n", "versions": [{"version": "v1", "created": "Sat, 1 Oct 2016 03:56:13 GMT"}, {"version": "v2", "created": "Tue, 10 Jan 2017 09:53:16 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Zhang", "Junbo", ""], ["Zheng", "Yu", ""], ["Qi", "Dekang", ""]]}, {"id": "1610.00086", "submitter": "Marzieh Adelnia", "authors": "Marzieh Adelnia and Mohammad Reza Khayyambashi", "title": "Consistency Ensuring in Social Web Services Based on Commitments\n  Structure", "comments": "International Journal of Computer Science and Information Security\n  (IJCSIS), Vol. 14, No. 8, August 2016. arXiv admin note: text overlap with\n  arXiv:1412.0152", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web Service is one of the most significant current discussions in information\nsharing technologies and one of the examples of service oriented processing. To\nensure accurate execution of web services operations, it must be adaptable with\npolicies of the social networks in which it signs up. This adaptation\nimplements using controls called 'Commitment'. This paper describes commitments\nstructure and existing research about commitments and social web services, then\nsuggests an algorithm for consistency of commitments in social web services. As\nregards the commitments may be executed concurrently, a key challenge in web\nservices execution based on commitment structure is consistency ensuring in\nexecution time. The purpose of this research is providing an algorithm for\nconsistency ensuring between web services operations based on commitments\nstructure.\n", "versions": [{"version": "v1", "created": "Sat, 1 Oct 2016 04:59:05 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Adelnia", "Marzieh", ""], ["Khayyambashi", "Mohammad Reza", ""]]}, {"id": "1610.00163", "submitter": "Petar Veli\\v{c}kovi\\'c", "authors": "Petar Veli\\v{c}kovi\\'c, Duo Wang, Nicholas D. Lane and Pietro Li\\`o", "title": "X-CNN: Cross-modal Convolutional Neural Networks for Sparse Datasets", "comments": "To appear in the 7th IEEE Symposium Series on Computational\n  Intelligence (IEEE SSCI 2016), 8 pages, 6 figures. Minor revisions, in\n  response to reviewers' comments", "journal-ref": null, "doi": "10.1109/SSCI.2016.7849978", "report-no": null, "categories": "stat.ML cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose cross-modal convolutional neural networks (X-CNNs),\na novel biologically inspired type of CNN architectures, treating gradient\ndescent-specialised CNNs as individual units of processing in a larger-scale\nnetwork topology, while allowing for unconstrained information flow and/or\nweight sharing between analogous hidden layers of the network---thus\ngeneralising the already well-established concept of neural network ensembles\n(where information typically may flow only between the output layers of the\nindividual networks). The constituent networks are individually designed to\nlearn the output function on their own subset of the input data, after which\ncross-connections between them are introduced after each pooling operation to\nperiodically allow for information exchange between them. This injection of\nknowledge into a model (by prior partition of the input data through domain\nknowledge or unsupervised methods) is expected to yield greatest returns in\nsparse data environments, which are typically less suitable for training CNNs.\nFor evaluation purposes, we have compared a standard four-layer CNN as well as\na sophisticated FitNet4 architecture against their cross-modal variants on the\nCIFAR-10 and CIFAR-100 datasets with differing percentages of the training data\nbeing removed, and find that at lower levels of data availability, the X-CNNs\nsignificantly outperform their baselines (typically providing a 2--6% benefit,\ndepending on the dataset size and whether data augmentation is used), while\nstill maintaining an edge on all of the full dataset tests.\n", "versions": [{"version": "v1", "created": "Sat, 1 Oct 2016 18:01:35 GMT"}, {"version": "v2", "created": "Mon, 17 Oct 2016 14:51:36 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Veli\u010dkovi\u0107", "Petar", ""], ["Wang", "Duo", ""], ["Lane", "Nicholas D.", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "1610.00243", "submitter": "Elad Hoffer", "authors": "Elad Hoffer, Itay Hubara, Nir Ailon", "title": "Deep unsupervised learning through spatial contrasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional networks have marked their place over the last few years as the\nbest performing model for various visual tasks. They are, however, most suited\nfor supervised learning from large amounts of labeled data. Previous attempts\nhave been made to use unlabeled data to improve model performance by applying\nunsupervised techniques. These attempts require different architectures and\ntraining methods. In this work we present a novel approach for unsupervised\ntraining of Convolutional networks that is based on contrasting between spatial\nregions within images. This criterion can be employed within conventional\nneural networks and trained using standard techniques such as SGD and\nback-propagation, thus complementing supervised methods.\n", "versions": [{"version": "v1", "created": "Sun, 2 Oct 2016 08:42:59 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 15:38:31 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Hoffer", "Elad", ""], ["Hubara", "Itay", ""], ["Ailon", "Nir", ""]]}, {"id": "1610.00366", "submitter": "Ruben Martinez-Cantin", "authors": "Ruben Martinez-Cantin", "title": "Funneled Bayesian Optimization for Design, Tuning and Control of\n  Autonomous Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization has become a fundamental global optimization algorithm\nin many problems where sample efficiency is of paramount importance. Recently,\nthere has been proposed a large number of new applications in fields such as\nrobotics, machine learning, experimental design, simulation, etc. In this\npaper, we focus on several problems that appear in robotics and autonomous\nsystems: algorithm tuning, automatic control and intelligent design. All those\nproblems can be mapped to global optimization problems. However, they become\nhard optimization problems. Bayesian optimization internally uses a\nprobabilistic surrogate model (e.g.: Gaussian process) to learn from the\nprocess and reduce the number of samples required. In order to generalize to\nunknown functions in a black-box fashion, the common assumption is that the\nunderlying function can be modeled with a stationary process. Nonstationary\nGaussian process regression cannot generalize easily and it typically requires\nprior knowledge of the function. Some works have designed techniques to\ngeneralize Bayesian optimization to nonstationary functions in an indirect way,\nbut using techniques originally designed for regression, where the objective is\nto improve the quality of the surrogate model everywhere. Instead optimization\nshould focus on improving the surrogate model near the optimum. In this paper,\nwe present a novel kernel function specially designed for Bayesian\noptimization, that allows nonstationary behavior of the surrogate model in an\nadaptive local region. In our experiments, we found that this new kernel\nresults in an improved local search (exploitation), without penalizing the\nglobal search (exploration). We provide results in well-known benchmarks and\nreal applications. The new method outperforms the state of the art in Bayesian\noptimization both in stationary and nonstationary problems.\n", "versions": [{"version": "v1", "created": "Sun, 2 Oct 2016 23:13:45 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 15:48:07 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Martinez-Cantin", "Ruben", ""]]}, {"id": "1610.00378", "submitter": "Joseph Ramsey", "authors": "Joseph Ramsey", "title": "Improving Accuracy and Scalability of the PC Algorithm by Maximizing\n  P-value", "comments": "11 pages, 4 figures, 2 tables, technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of attempts have been made to improve accuracy and/or scalability of\nthe PC (Peter and Clark) algorithm, some well known (Buhlmann, et al., 2010;\nKalisch and Buhlmann, 2007; 2008; Zhang, 2012, to give some examples). We add\nhere one more tool to the toolbox: the simple observation that if one is forced\nto choose between a variety of possible conditioning sets for a pair of\nvariables, one should choose the one with the highest p-value. One can use the\nCPC (Conservative PC, Ramsey et al., 2012) algorithm as a guide to possible\nsepsets for a pair of variables. However, whereas CPC uses a voting rule to\nclassify colliders versus noncolliders, our proposed algorithm, PC-Max, picks\nthe conditioning set with the highest p-value, so that there are no\nambiguities. We combine this with two other optimizations: (a) avoiding\nbidirected edges in the orientation of colliders, and (b) parallelization. For\n(b) we borrow ideas from the PC-Stable algorithm (Colombo and Maathuis, 2014).\nThe result is an algorithm that scales quite well both in terms of accuracy and\ntime, with no risk of bidirected edges.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2016 00:47:51 GMT"}, {"version": "v2", "created": "Wed, 5 Oct 2016 17:24:45 GMT"}], "update_date": "2016-10-06", "authors_parsed": [["Ramsey", "Joseph", ""]]}, {"id": "1610.00442", "submitter": "Sixue Liu", "authors": "Sixue Liu and Gerard de Melo", "title": "Should Algorithms for Random SAT and Max-SAT be Different?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze to what extent the random SAT and Max-SAT problems differ in their\nproperties. Our findings suggest that for random $k$-CNF with ratio in a\ncertain range, Max-SAT can be solved by any SAT algorithm with subexponential\nslowdown, while for formulae with ratios greater than some constant, algorithms\nunder the random walk framework require substantially different heuristics. In\nlight of these results, we propose a novel probabilistic approach for random\nMax-SAT called ProMS. Experimental results illustrate that ProMS outperforms\nmany state-of-the-art local search solvers on random Max-SAT benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2016 08:30:47 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 07:27:51 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Liu", "Sixue", ""], ["de Melo", "Gerard", ""]]}, {"id": "1610.00465", "submitter": "Bhanu Pratap Singh Rawat", "authors": "Harsh Nisar, Bhanu Pratap Singh Rawat", "title": "Can Evolutionary Sampling Improve Bagged Ensembles?", "comments": "3 pages, 1 table, Data Efficient Machine Learning Workshop (DEML'16),\n  ICML", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perturb and Combine (P&C) group of methods generate multiple versions of the\npredictor by perturbing the training set or construction and then combining\nthem into a single predictor (Breiman, 1996b). The motive is to improve the\naccuracy in unstable classification and regression methods. One of the most\nwell known method in this group is Bagging. Arcing or Adaptive Resampling and\nCombining methods like AdaBoost are smarter variants of P&C methods. In this\nextended abstract, we lay the groundwork for a new family of methods under the\nP&C umbrella, known as Evolutionary Sampling (ES). We employ Evolutionary\nalgorithms to suggest smarter sampling in both the feature space (sub-spaces)\nas well as training samples. We discuss multiple fitness functions to assess\nensembles and empirically compare our performance against randomized sampling\nof training data and feature sub-spaces.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2016 09:53:06 GMT"}], "update_date": "2016-10-05", "authors_parsed": [["Nisar", "Harsh", ""], ["Rawat", "Bhanu Pratap Singh", ""]]}, {"id": "1610.00633", "submitter": "Shixiang Gu", "authors": "Shixiang Gu and Ethan Holly and Timothy Lillicrap and Sergey Levine", "title": "Deep Reinforcement Learning for Robotic Manipulation with Asynchronous\n  Off-Policy Updates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning holds the promise of enabling autonomous robots to\nlearn large repertoires of behavioral skills with minimal human intervention.\nHowever, robotic applications of reinforcement learning often compromise the\nautonomy of the learning process in favor of achieving training times that are\npractical for real physical systems. This typically involves introducing\nhand-engineered policy representations and human-supplied demonstrations. Deep\nreinforcement learning alleviates this limitation by training general-purpose\nneural network policies, but applications of direct deep reinforcement learning\nalgorithms have so far been restricted to simulated settings and relatively\nsimple tasks, due to their apparent high sample complexity. In this paper, we\ndemonstrate that a recent deep reinforcement learning algorithm based on\noff-policy training of deep Q-functions can scale to complex 3D manipulation\ntasks and can learn deep neural network policies efficiently enough to train on\nreal physical robots. We demonstrate that the training times can be further\nreduced by parallelizing the algorithm across multiple robots which pool their\npolicy updates asynchronously. Our experimental evaluation shows that our\nmethod can learn a variety of 3D manipulation skills in simulation and a\ncomplex door opening skill on real robots without any prior demonstrations or\nmanually designed representations.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2016 16:52:10 GMT"}, {"version": "v2", "created": "Wed, 23 Nov 2016 10:23:25 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Gu", "Shixiang", ""], ["Holly", "Ethan", ""], ["Lillicrap", "Timothy", ""], ["Levine", "Sergey", ""]]}, {"id": "1610.00673", "submitter": "Ali Yahya", "authors": "Ali Yahya, Adrian Li, Mrinal Kalakrishnan, Yevgen Chebotar, Sergey\n  Levine", "title": "Collective Robot Reinforcement Learning with Distributed Asynchronous\n  Guided Policy Search", "comments": "Submitted to the IEEE International Conference on Robotics and\n  Automation 2017", "journal-ref": null, "doi": "10.1109/IROS.2017.8202141", "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In principle, reinforcement learning and policy search methods can enable\nrobots to learn highly complex and general skills that may allow them to\nfunction amid the complexity and diversity of the real world. However, training\na policy that generalizes well across a wide range of real-world conditions\nrequires far greater quantity and diversity of experience than is practical to\ncollect with a single robot. Fortunately, it is possible for multiple robots to\nshare their experience with one another, and thereby, learn a policy\ncollectively. In this work, we explore distributed and asynchronous policy\nlearning as a means to achieve generalization and improved training times on\nchallenging, real-world manipulation tasks. We propose a distributed and\nasynchronous version of Guided Policy Search and use it to demonstrate\ncollective policy learning on a vision-based door opening task using four\nrobots. We show that it achieves better generalization, utilization, and\ntraining times than the single robot alternative.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2016 18:54:00 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Yahya", "Ali", ""], ["Li", "Adrian", ""], ["Kalakrishnan", "Mrinal", ""], ["Chebotar", "Yevgen", ""], ["Levine", "Sergey", ""]]}, {"id": "1610.00689", "submitter": "Yexiang Xue", "authors": "Yexiang Xue, Junwen Bai, Ronan Le Bras, Brendan Rappazzo, Richard\n  Bernstein, Johan Bjorck, Liane Longpre, Santosh K. Suram, Robert B. van\n  Dover, John Gregoire, Carla P. Gomes", "title": "Phase-Mapper: An AI Platform to Accelerate High Throughput Materials\n  Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-Throughput materials discovery involves the rapid synthesis,\nmeasurement, and characterization of many different but structurally-related\nmaterials. A key problem in materials discovery, the phase map identification\nproblem, involves the determination of the crystal phase diagram from the\nmaterials' composition and structural characterization data. We present\nPhase-Mapper, a novel AI platform to solve the phase map identification problem\nthat allows humans to interact with both the data and products of AI\nalgorithms, including the incorporation of human feedback to constrain or\ninitialize solutions. Phase-Mapper affords incorporation of any spectral\ndemixing algorithm, including our novel solver, AgileFD, which is based on a\nconvolutive non-negative matrix factorization algorithm. AgileFD can\nincorporate constraints to capture the physics of the materials as well as\nhuman feedback. We compare three solver variants with previously proposed\nmethods in a large-scale experiment involving 20 synthetic systems,\ndemonstrating the efficacy of imposing physical constrains using AgileFD.\nPhase-Mapper has also been used by materials scientists to solve a wide variety\nof phase diagrams, including the previously unsolved Nb-Mn-V oxide system,\nwhich is provided here as an illustrative example.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2016 19:35:30 GMT"}, {"version": "v2", "created": "Fri, 7 Oct 2016 17:16:13 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Xue", "Yexiang", ""], ["Bai", "Junwen", ""], ["Bras", "Ronan Le", ""], ["Rappazzo", "Brendan", ""], ["Bernstein", "Richard", ""], ["Bjorck", "Johan", ""], ["Longpre", "Liane", ""], ["Suram", "Santosh K.", ""], ["van Dover", "Robert B.", ""], ["Gregoire", "John", ""], ["Gomes", "Carla P.", ""]]}, {"id": "1610.00696", "submitter": "Chelsea Finn", "authors": "Chelsea Finn and Sergey Levine", "title": "Deep Visual Foresight for Planning Robot Motion", "comments": "ICRA 2017. Supplementary video:\n  https://sites.google.com/site/robotforesight/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge in scaling up robot learning to many skills and environments\nis removing the need for human supervision, so that robots can collect their\nown data and improve their own performance without being limited by the cost of\nrequesting human feedback. Model-based reinforcement learning holds the promise\nof enabling an agent to learn to predict the effects of its actions, which\ncould provide flexible predictive models for a wide range of tasks and\nenvironments, without detailed human supervision. We develop a method for\ncombining deep action-conditioned video prediction models with model-predictive\ncontrol that uses entirely unlabeled training data. Our approach does not\nrequire a calibrated camera, an instrumented training set-up, nor precise\nsensing and actuation. Our results show that our method enables a real robot to\nperform nonprehensile manipulation -- pushing objects -- and can handle novel\nobjects not seen during training.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2016 19:54:17 GMT"}, {"version": "v2", "created": "Mon, 13 Mar 2017 00:18:49 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Finn", "Chelsea", ""], ["Levine", "Sergey", ""]]}, {"id": "1610.00782", "submitter": "Ivan Brugere", "authors": "Ivan Brugere and Brian Gallagher and Tanya Y. Berger-Wolf", "title": "Network Structure Inference, A Survey: Motivations, Methods, and\n  Applications", "comments": "37 pages, ACM Computing Surveys (in press)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks represent relationships between entities in many complex systems,\nspanning from online social interactions to biological cell development and\nbrain connectivity. In many cases, relationships between entities are\nunambiguously known: are two users 'friends' in a social network? Do two\nresearchers collaborate on a published paper? Do two road segments in a\ntransportation system intersect? These are directly observable in the system in\nquestion. In most cases, relationship between nodes are not directly observable\nand must be inferred: does one gene regulate the expression of another? Do two\nanimals who physically co-locate have a social bond? Who infected whom in a\ndisease outbreak in a population?\n  Existing approaches for inferring networks from data are found across many\napplication domains and use specialized knowledge to infer and measure the\nquality of inferred network for a specific task or hypothesis. However, current\nresearch lacks a rigorous methodology which employs standard statistical\nvalidation on inferred models. In this survey, we examine (1) how network\nrepresentations are constructed from underlying data, (2) the variety of\nquestions and tasks on these representations over several domains, and (3)\nvalidation strategies for measuring the inferred network's capability of\nanswering questions on the system of interest.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2016 23:00:59 GMT"}, {"version": "v2", "created": "Tue, 22 Aug 2017 16:25:50 GMT"}, {"version": "v3", "created": "Mon, 4 Dec 2017 22:30:55 GMT"}, {"version": "v4", "created": "Fri, 19 Jan 2018 21:55:34 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Brugere", "Ivan", ""], ["Gallagher", "Brian", ""], ["Berger-Wolf", "Tanya Y.", ""]]}, {"id": "1610.00946", "submitter": "Jean-Baptiste Mouret", "authors": "Jean-Baptiste Mouret (LORIA, LARSEN)", "title": "Micro-Data Learning: The Other End of the Spectrum", "comments": null, "journal-ref": "ERCIM News, ERCIM, 2016, pp.2", "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many fields are now snowed under with an avalanche of data, which raises\nconsiderable challenges for computer scientists. Meanwhile, robotics (among\nother fields) can often only use a few dozen data points because acquiring them\ninvolves a process that is expensive or time-consuming. How can an algorithm\nlearn with only a few data points?\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2016 12:29:05 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Mouret", "Jean-Baptiste", "", "LORIA, LARSEN"]]}, {"id": "1610.00956", "submitter": "Ondrej Bajgar", "authors": "Ondrej Bajgar, Rudolf Kadlec and Jan Kleindienst", "title": "Embracing data abundance: BookTest Dataset for Reading Comprehension", "comments": "The first two authors contributed equally to this work. Submitted to\n  EACL 2017. Code and dataset are publicly available", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a practically unlimited amount of natural language data available.\nStill, recent work in text comprehension has focused on datasets which are\nsmall relative to current computing possibilities. This article is making a\ncase for the community to move to larger data and as a step in that direction\nit is proposing the BookTest, a new dataset similar to the popular Children's\nBook Test (CBT), however more than 60 times larger. We show that training on\nthe new data improves the accuracy of our Attention-Sum Reader model on the\noriginal CBT test data by a much larger margin than many recent attempts to\nimprove the model architecture. On one version of the dataset our ensemble even\nexceeds the human baseline provided by Facebook. We then show in our own human\nstudy that there is still space for further improvement.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2016 12:48:51 GMT"}], "update_date": "2016-10-05", "authors_parsed": [["Bajgar", "Ondrej", ""], ["Kadlec", "Rudolf", ""], ["Kleindienst", "Jan", ""]]}, {"id": "1610.00976", "submitter": "Adam Chehouri", "authors": "Adam Chehouri, Rafic Younes, Jean Perron, Adrian Ilinca (UQAR)", "title": "A Constraint-Handling Technique for Genetic Algorithms using a Violation\n  Factor", "comments": null, "journal-ref": "Journal of Computer Science, Science Publications, 2016, 12 (7),\n  pp.350-362", "doi": "10.3844/jcssp.2016.350.362", "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the years, several meta-heuristic algorithms were proposed and are now\nemerging as common methods for constrained optimization problems. Among them,\ngenetic algorithms (GA's) shine as popular evolutionary algorithms (EA's) in\nengineering optimization. Most engineering design problems are difficult to\nresolve with conventional optimization algorithms because they are highly\nnonlinear and contain constraints. In order to handle these constraints, the\nmost common technique is to apply penalty functions. The major drawback is that\nthey require tuning of parameters, which can be very challenging. In this\npaper, we present a constraint-handling technique for GA's solely using the\nviolation factor, called VCH (Violation Constraint-Handling) method. Several\nbenchmark problems from the literature are examined. The VCH technique was able\nto provide a consistent performance and match results from other GA-based\ntechniques.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2016 13:21:21 GMT"}], "update_date": "2016-10-05", "authors_parsed": [["Chehouri", "Adam", "", "UQAR"], ["Younes", "Rafic", "", "UQAR"], ["Perron", "Jean", "", "UQAR"], ["Ilinca", "Adrian", "", "UQAR"]]}, {"id": "1610.01044", "submitter": "Przemyslaw Chojecki", "authors": "Przemyslaw Chojecki", "title": "DeepAlgebra - an outline of a program", "comments": "6 pages, https://przchojecki.github.io/deepalgebra/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We outline a program in the area of formalization of mathematics to automate\ntheorem proving in algebra and algebraic geometry. We propose a construction of\na dictionary between automated theorem provers and (La)TeX exploiting syntactic\nparsers. We describe its application to a repository of human-written facts and\ndefinitions in algebraic geometry (The Stacks Project). We use deep learning\ntechniques.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2016 15:22:33 GMT"}], "update_date": "2016-10-05", "authors_parsed": [["Chojecki", "Przemyslaw", ""]]}, {"id": "1610.01076", "submitter": "Mateusz Malinowski", "authors": "Mateusz Malinowski and Mario Fritz", "title": "Tutorial on Answering Questions about Images with Deep Learning", "comments": "The tutorial was presented at '2nd Summer School on Integrating\n  Vision and Language: Deep Learning' in Malta, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Together with the development of more accurate methods in Computer Vision and\nNatural Language Understanding, holistic architectures that answer on questions\nabout the content of real-world images have emerged. In this tutorial, we build\na neural-based approach to answer questions about images. We base our tutorial\non two datasets: (mostly on) DAQUAR, and (a bit on) VQA. With small tweaks the\nmodels that we present here can achieve a competitive performance on both\ndatasets, in fact, they are among the best methods that use a combination of\nLSTM with a global, full frame CNN representation of an image. We hope that\nafter reading this tutorial, the reader will be able to use Deep Learning\nframeworks, such as Keras and introduced Kraino, to build various architectures\nthat will lead to a further performance improvement on this challenging task.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2016 16:29:28 GMT"}], "update_date": "2016-10-05", "authors_parsed": [["Malinowski", "Mateusz", ""], ["Fritz", "Mario", ""]]}, {"id": "1610.01085", "submitter": "Venkata Sriram Siddhardh (Sid) Nadendla", "authors": "V. Sriram Siddhardh Nadendla, Swastik Brahma, Pramod K. Varshney", "title": "Towards the Design of Prospect-Theory based Human Decision Rules for\n  Hypothesis Testing", "comments": "8 pages, 5 figures, Presented at the 54th Annual Allerton Conference\n  on Communication, Control, and Computing, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detection rules have traditionally been designed for rational agents that\nminimize the Bayes risk (average decision cost). With the advent of\ncrowd-sensing systems, there is a need to redesign binary hypothesis testing\nrules for behavioral agents, whose cognitive behavior is not captured by\ntraditional utility functions such as Bayes risk. In this paper, we adopt\nprospect theory based models for decision makers. We consider special agent\nmodels namely optimists and pessimists in this paper, and derive optimal\ndetection rules under different scenarios. Using an illustrative example, we\nalso show how the decision rule of a human agent deviates from the Bayesian\ndecision rule under various behavioral models, considered in this paper.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2016 16:52:03 GMT"}], "update_date": "2016-10-07", "authors_parsed": [["Nadendla", "V. Sriram Siddhardh", ""], ["Brahma", "Swastik", ""], ["Varshney", "Pramod K.", ""]]}, {"id": "1610.01221", "submitter": "Kyriakos Sideris", "authors": "Kyriakos Sideris, Reza Nejabati, Dimitra Simeonidou", "title": "Seer: Empowering Software Defined Networking with Data Analytics", "comments": "8 pages, 6 figures, Big data, data analytics, data mining, knowledge\n  centric networking (KCN), software defined networking (SDN), Seer, 2016 15th\n  International Conference on Ubiquitous Computing and Communications and 2016\n  International Symposium on Cyberspace and Security (IUCC-CSS 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network complexity is increasing, making network control and orchestration a\nchallenging task. The proliferation of network information and tools for data\nanalytics can provide an important insight into resource provisioning and\noptimisation. The network knowledge incorporated in software defined networking\ncan facilitate the knowledge driven control, leveraging the network\nprogrammability. We present Seer: a flexible, highly configurable data\nanalytics platform for network intelligence based on software defined\nnetworking and big data principles. Seer combines a computational engine with a\ndistributed messaging system to provide a scalable, fault tolerant and\nreal-time platform for knowledge extraction. Our first prototype uses Apache\nSpark for streaming analytics and open network operating system (ONOS)\ncontroller to program a network in real-time. The first application we\ndeveloped aims to predict the mobility pattern of mobile devices inside a smart\ncity environment.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2016 22:22:53 GMT"}], "update_date": "2016-10-06", "authors_parsed": [["Sideris", "Kyriakos", ""], ["Nejabati", "Reza", ""], ["Simeonidou", "Dimitra", ""]]}, {"id": "1610.01238", "submitter": "Dan Barnes", "authors": "Dan Barnes, Will Maddern and Ingmar Posner", "title": "Find Your Own Way: Weakly-Supervised Segmentation of Path Proposals for\n  Urban Autonomy", "comments": "International Conference on Robotics and Automation (ICRA), 2017.\n  Video summary: http://youtu.be/rbZ8ck_1nZk", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a weakly-supervised approach to segmenting proposed drivable paths\nin images with the goal of autonomous driving in complex urban environments.\nUsing recorded routes from a data collection vehicle, our proposed method\ngenerates vast quantities of labelled images containing proposed paths and\nobstacles without requiring manual annotation, which we then use to train a\ndeep semantic segmentation network. With the trained network we can segment\nproposed paths and obstacles at run-time using a vehicle equipped with only a\nmonocular camera without relying on explicit modelling of road or lane\nmarkings. We evaluate our method on the large-scale KITTI and Oxford RobotCar\ndatasets and demonstrate reliable path proposal and obstacle segmentation in a\nwide variety of environments under a range of lighting, weather and traffic\nconditions. We illustrate how the method can generalise to multiple path\nproposals at intersections and outline plans to incorporate the system into a\nframework for autonomous urban driving.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2016 00:44:49 GMT"}, {"version": "v2", "created": "Tue, 14 Mar 2017 22:05:10 GMT"}, {"version": "v3", "created": "Fri, 17 Nov 2017 16:54:44 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Barnes", "Dan", ""], ["Maddern", "Will", ""], ["Posner", "Ingmar", ""]]}, {"id": "1610.01283", "submitter": "Aravind Rajeswaran", "authors": "Aravind Rajeswaran, Sarvjeet Ghotra, Balaraman Ravindran, Sergey\n  Levine", "title": "EPOpt: Learning Robust Neural Network Policies Using Model Ensembles", "comments": "Accepted for publication at the International Conference on Learning\n  Representations (ICLR) 2017. Supplementary video:\n  https://youtu.be/w1YJ9vwaoto", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sample complexity and safety are major challenges when learning policies with\nreinforcement learning for real-world tasks, especially when the policies are\nrepresented using rich function approximators like deep neural networks.\nModel-based methods where the real-world target domain is approximated using a\nsimulated source domain provide an avenue to tackle the above challenges by\naugmenting real data with simulated data. However, discrepancies between the\nsimulated source domain and the target domain pose a challenge for simulated\ntraining. We introduce the EPOpt algorithm, which uses an ensemble of simulated\nsource domains and a form of adversarial training to learn policies that are\nrobust and generalize to a broad range of possible target domains, including\nunmodeled effects. Further, the probability distribution over source domains in\nthe ensemble can be adapted using data from target domain and approximate\nBayesian methods, to progressively make it a better approximation. Thus,\nlearning on a model ensemble, along with source domain adaptation, provides the\nbenefit of both robustness and learning/adaptation.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2016 06:51:58 GMT"}, {"version": "v2", "created": "Mon, 10 Oct 2016 07:18:36 GMT"}, {"version": "v3", "created": "Fri, 16 Dec 2016 16:48:17 GMT"}, {"version": "v4", "created": "Fri, 3 Mar 2017 19:58:56 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Rajeswaran", "Aravind", ""], ["Ghotra", "Sarvjeet", ""], ["Ravindran", "Balaraman", ""], ["Levine", "Sergey", ""]]}, {"id": "1610.01374", "submitter": "Samik Banerjee", "authors": "Samik Banerjee, Sukhendu Das", "title": "Domain Adaptation with Soft-margin multiple feature-kernel learning\n  beats Deep Learning for surveillance face recognition", "comments": "This is an extended version of the paper accepted in CVPR Biometric\n  Workshop, 2016. arXiv admin note: text overlap with arXiv:1610.00660", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face recognition (FR) is the most preferred mode for biometric-based\nsurveillance, due to its passive nature of detecting subjects, amongst all\ndifferent types of biometric traits. FR under surveillance scenario does not\ngive satisfactory performance due to low contrast, noise and poor illumination\nconditions on probes, as compared to the training samples. A state-of-the-art\ntechnology, Deep Learning, even fails to perform well in these scenarios. We\npropose a novel soft-margin based learning method for multiple feature-kernel\ncombinations, followed by feature transformed using Domain Adaptation, which\noutperforms many recent state-of-the-art techniques, when tested using three\nreal-world surveillance face datasets.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2016 11:48:56 GMT"}, {"version": "v2", "created": "Thu, 27 Oct 2016 13:14:49 GMT"}], "update_date": "2016-10-28", "authors_parsed": [["Banerjee", "Samik", ""], ["Das", "Sukhendu", ""]]}, {"id": "1610.01381", "submitter": "Alasdair Thomason", "authors": "Alasdair Thomason, Nathan Griffiths, Victor Sanchez", "title": "The Predictive Context Tree: Predicting Contexts and Interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With a large proportion of people carrying location-aware smartphones, we\nhave an unprecedented platform from which to understand individuals and predict\ntheir future actions. This work builds upon the Context Tree data structure\nthat summarises the historical contexts of individuals from augmented\ngeospatial trajectories, and constructs a predictive model for their likely\nfuture contexts. The Predictive Context Tree (PCT) is constructed as a\nhierarchical classifier, capable of predicting both the future locations that a\nuser will visit and the contexts that a user will be immersed within. The PCT\nis evaluated over real-world geospatial trajectories, and compared against\nexisting location extraction and prediction techniques, as well as a proposed\nhybrid approach that uses identified land usage elements in combination with\nmachine learning to predict future interactions. Our results demonstrate that\nhigher predictive accuracies can be achieved using this hybrid approach over\ntraditional extracted location datasets, and the PCT itself matches the\nperformance of the hybrid approach at predicting future interactions, while\nadding utility in the form of context predictions. Such a prediction system is\ncapable of understanding not only where a user will visit, but also their\ncontext, in terms of what they are likely to be doing.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2016 12:14:57 GMT"}], "update_date": "2016-10-06", "authors_parsed": [["Thomason", "Alasdair", ""], ["Griffiths", "Nathan", ""], ["Sanchez", "Victor", ""]]}, {"id": "1610.01407", "submitter": "Konstantinos Chatzilygeroudis", "authors": "Konstantinos Chatzilygeroudis (LORIA, LARSEN), Antoine Cully,\n  Jean-Baptiste Mouret (LORIA, LARSEN)", "title": "Towards semi-episodic learning for robot damage recovery", "comments": "Workshop on AI for Long-Term Autonomy at the IEEE International\n  Conference on Robotics and Automation (ICRA), May 2016, Stockholm, Sweden.\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently introduced Intelligent Trial and Error algorithm (IT\\&E) enables\nrobots to creatively adapt to damage in a matter of minutes by combining an\noff-line evolutionary algorithm and an on-line learning algorithm based on\nBayesian Optimization. We extend the IT\\&E algorithm to allow for robots to\nlearn to compensate for damages while executing their task(s). This leads to a\nsemi-episodic learning scheme that increases the robot's lifetime autonomy and\nadaptivity. Preliminary experiments on a toy simulation and a 6-legged robot\nlocomotion task show promising results.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2016 13:21:43 GMT"}], "update_date": "2016-10-06", "authors_parsed": [["Chatzilygeroudis", "Konstantinos", "", "LORIA, LARSEN"], ["Cully", "Antoine", "", "LORIA, LARSEN"], ["Mouret", "Jean-Baptiste", "", "LORIA, LARSEN"]]}, {"id": "1610.01465", "submitter": "Kushal Kafle", "authors": "Kushal Kafle, Christopher Kanan", "title": "Visual Question Answering: Datasets, Algorithms, and Future Challenges", "comments": null, "journal-ref": null, "doi": "10.1016/j.cviu.2017.06.005", "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Question Answering (VQA) is a recent problem in computer vision and\nnatural language processing that has garnered a large amount of interest from\nthe deep learning, computer vision, and natural language processing\ncommunities. In VQA, an algorithm needs to answer text-based questions about\nimages. Since the release of the first VQA dataset in 2014, additional datasets\nhave been released and many algorithms have been proposed. In this review, we\ncritically examine the current state of VQA in terms of problem formulation,\nexisting datasets, evaluation metrics, and algorithms. In particular, we\ndiscuss the limitations of current datasets with regard to their ability to\nproperly train and assess VQA algorithms. We then exhaustively review existing\nalgorithms for VQA. Finally, we discuss possible future directions for VQA and\nimage understanding research.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2016 14:58:36 GMT"}, {"version": "v2", "created": "Wed, 26 Oct 2016 01:39:40 GMT"}, {"version": "v3", "created": "Wed, 1 Mar 2017 05:39:21 GMT"}, {"version": "v4", "created": "Thu, 15 Jun 2017 01:52:59 GMT"}], "update_date": "2017-06-16", "authors_parsed": [["Kafle", "Kushal", ""], ["Kanan", "Christopher", ""]]}, {"id": "1610.01476", "submitter": "Dominik Meyer", "authors": "Dominik Meyer, Hao Shen, Klaus Diepold", "title": "$\\ell_1$ Regularized Gradient Temporal-Difference Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the Temporal Difference (TD) learning with linear\nvalue function approximation. It is well known that most TD learning algorithms\nare unstable with linear function approximation and off-policy learning. Recent\ndevelopment of Gradient TD (GTD) algorithms has addressed this problem\nsuccessfully. However, the success of GTD algorithms requires a set of well\nchosen features, which are not always available. When the number of features is\nhuge, the GTD algorithms might face the problem of overfitting and being\ncomputationally expensive. To cope with this difficulty, regularization\ntechniques, in particular $\\ell_1$ regularization, have attracted significant\nattentions in developing TD learning algorithms. The present work combines the\nGTD algorithms with $\\ell_1$ regularization. We propose a family of $\\ell_1$\nregularized GTD algorithms, which employ the well known soft thresholding\noperator. We investigate convergence properties of the proposed algorithms, and\ndepict their performance with several numerical experiments.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2016 15:15:27 GMT"}], "update_date": "2016-10-06", "authors_parsed": [["Meyer", "Dominik", ""], ["Shen", "Hao", ""], ["Diepold", "Klaus", ""]]}, {"id": "1610.01525", "submitter": "Udi Apsel", "authors": "Udi Apsel", "title": "Lifted Message Passing for the Generalized Belief Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the lifted Generalized Belief Propagation (GBP) message passing\nalgorithm, for the computation of sum-product queries in Probabilistic\nRelational Models (e.g. Markov logic network). The algorithm forms a compact\nregion graph and establishes a modified version of message passing, which\nmimics the GBP behavior in a corresponding ground model. The compact graph is\nobtained by exploiting a graphical representation of clusters, which reduces\ncluster symmetry detection to isomorphism tests on small local graphs. The\nframework is thus capable of handling complex models, while remaining\ndomain-size independent.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2016 16:56:02 GMT"}], "update_date": "2016-10-06", "authors_parsed": [["Apsel", "Udi", ""]]}, {"id": "1610.01549", "submitter": "Anthony Caterini", "authors": "Anthony Caterini and Dong Eui Chang", "title": "A Novel Representation of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have become very popular for prediction in many\nareas. Their strength is in representation with a high number of parameters\nthat are commonly learned via gradient descent or similar optimization methods.\nHowever, the representation is non-standardized, and the gradient calculation\nmethods are often performed using component-based approaches that break\nparameters down into scalar units, instead of considering the parameters as\nwhole entities. In this work, these problems are addressed. Standard notation\nis used to represent DNNs in a compact framework. Gradients of DNN loss\nfunctions are calculated directly over the inner product space on which the\nparameters are defined. This framework is general and is applied to two common\nnetwork types: the Multilayer Perceptron and the Deep Autoencoder.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2016 18:06:44 GMT"}, {"version": "v2", "created": "Fri, 7 Oct 2016 21:31:13 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Caterini", "Anthony", ""], ["Chang", "Dong Eui", ""]]}, {"id": "1610.01578", "submitter": "Krzysztof Cpa{\\l}ka", "authors": "Krzysztof Cpalka, Marcin Zalasinski, Leszek Rutkowski", "title": "A new algorithm for identity verification based on the analysis of a\n  handwritten dynamic signature", "comments": "34 pages, 7 figures", "journal-ref": "Applied Soft Computing, vol. 43, pp. 47-56, 2016", "doi": "10.1016/j.asoc.2016.02.017", "report-no": null, "categories": "cs.CV cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identity verification based on authenticity assessment of a handwritten\nsignature is an important issue in biometrics. There are many effective methods\nfor signature verification taking into account dynamics of a signing process.\nMethods based on partitioning take a very important place among them. In this\npaper we propose a new approach to signature partitioning. Its most important\nfeature is the possibility of selecting and processing of hybrid partitions in\norder to increase a precision of the test signature analysis. Partitions are\nformed by a combination of vertical and horizontal sections of the signature.\nVertical sections correspond to the initial, middle, and final time moments of\nthe signing process. In turn, horizontal sections correspond to the signature\nareas associated with high and low pen velocity and high and low pen pressure\non the surface of a graphics tablet. Our previous research on vertical and\nhorizontal sections of the dynamic signature (created independently) led us to\ndevelop the algorithm presented in this paper. Selection of sections, among\nothers, allows us to define the stability of the signing process in the\npartitions, promoting signature areas of greater stability (and vice versa). In\nthe test of the proposed method two databases were used: public MCYT-100 and\npaid BioSecure.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2016 19:32:55 GMT"}], "update_date": "2016-10-06", "authors_parsed": [["Cpalka", "Krzysztof", ""], ["Zalasinski", "Marcin", ""], ["Rutkowski", "Leszek", ""]]}, {"id": "1610.01698", "submitter": "Pedro Alejandro Ortega", "authors": "Pedro A. Ortega and Alan A. Stocker", "title": "Human Decision-Making under Limited Time", "comments": "9 pages, 4 figures, NIPS Advances in Neural Information Processing\n  Systems 29, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subjective expected utility theory assumes that decision-makers possess\nunlimited computational resources to reason about their choices; however,\nvirtually all decisions in everyday life are made under resource constraints -\ni.e. decision-makers are bounded in their rationality. Here we experimentally\ntested the predictions made by a formalization of bounded rationality based on\nideas from statistical mechanics and information-theory. We systematically\ntested human subjects in their ability to solve combinatorial puzzles under\ndifferent time limitations. We found that our bounded-rational model accounts\nwell for the data. The decomposition of the fitted model parameter into the\nsubjects' expected utility function and resource parameter provide interesting\ninsight into the subjects' information capacity limits. Our results confirm\nthat humans gradually fall back on their learned prior choice patterns when\nconfronted with increasing resource limitations.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 00:40:14 GMT"}], "update_date": "2016-10-07", "authors_parsed": [["Ortega", "Pedro A.", ""], ["Stocker", "Alan A.", ""]]}, {"id": "1610.01733", "submitter": "Lei Tai Mr", "authors": "Lei Tai and Ming Liu", "title": "Towards Cognitive Exploration through Deep Reinforcement Learning for\n  Mobile Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration in an unknown environment is the core functionality for mobile\nrobots. Learning-based exploration methods, including convolutional neural\nnetworks, provide excellent strategies without human-designed logic for the\nfeature extraction. But the conventional supervised learning algorithms cost\nlots of efforts on the labeling work of datasets inevitably. Scenes not\nincluded in the training set are mostly unrecognized either. We propose a deep\nreinforcement learning method for the exploration of mobile robots in an indoor\nenvironment with the depth information from an RGB-D sensor only. Based on the\nDeep Q-Network framework, the raw depth image is taken as the only input to\nestimate the Q values corresponding to all moving commands. The training of the\nnetwork weights is end-to-end. In arbitrarily constructed simulation\nenvironments, we show that the robot can be quickly adapted to unfamiliar\nscenes without any man-made labeling. Besides, through analysis of receptive\nfields of feature representations, deep reinforcement learning motivates the\nconvolutional networks to estimate the traversability of the scenes. The test\nresults are compared with the exploration strategies separately based on deep\nlearning or reinforcement learning. Even trained only in the simulated\nenvironment, experimental results in real-world environment demonstrate that\nthe cognitive ability of robot controller is dramatically improved compared\nwith the supervised method. We believe it is the first time that raw sensor\ninformation is used to build cognitive exploration strategy for mobile robots\nthrough end-to-end deep reinforcement learning.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 05:08:21 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Tai", "Lei", ""], ["Liu", "Ming", ""]]}, {"id": "1610.01807", "submitter": "Junbo Zhang", "authors": "Junbo Zhang, Tianrui Li, Yi Pan", "title": "Parallel Large-Scale Attribute Reduction on Cloud Systems", "comments": "14 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth of emerging information technologies and application\npatterns in modern society, e.g., Internet, Internet of Things, Cloud Computing\nand Tri-network Convergence, has caused the advent of the era of big data. Big\ndata contains huge values, however, mining knowledge from big data is a\ntremendously challenging task because of data uncertainty and inconsistency.\nAttribute reduction (also known as feature selection) can not only be used as\nan effective preprocessing step, but also exploits the data redundancy to\nreduce the uncertainty. However, existing solutions are designed 1) either for\na single machine that means the entire data must fit in the main memory and the\nparallelism is limited; 2) or for the Hadoop platform which means that the data\nhave to be loaded into the distributed memory frequently and therefore become\ninefficient. In this paper, we overcome these shortcomings for maximum\nefficiency possible, and propose a unified framework for Parallel Large-scale\nAttribute Reduction, termed PLAR, for big data analysis. PLAR consists of three\ncomponents: 1) Granular Computing (GrC)-based initialization: it converts a\ndecision table (i.e., original data representation) into a granularity\nrepresentation which reduces the amount of space and hence can be easily cached\nin the distributed memory: 2) model-parallelism: it simultaneously evaluates\nall feature candidates and makes attribute reduction highly parallelizable; 3)\ndata-parallelism: it computes the significance of an attribute in parallel\nusing a MapReduce-style manner. We implement PLAR with four representative\nheuristic feature selection algorithms on Spark, and evaluate them on various\nhuge datasets, including UCI and astronomical datasets, finding our method's\nadvantages beyond existing solutions.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 10:36:48 GMT"}], "update_date": "2016-10-07", "authors_parsed": [["Zhang", "Junbo", ""], ["Li", "Tianrui", ""], ["Pan", "Yi", ""]]}, {"id": "1610.01891", "submitter": "Mohamad Ivan Fanany", "authors": "Sadikin Mujiono, Mohamad Ivan Fanany, Chan Basaruddin", "title": "A New Data Representation Based on Training Data Characteristics to\n  Extract Drug Named-Entity in Medical Text", "comments": "Hindawi Publishing. Computational Intelligence and Neuroscience\n  Volume 2016 (2016), Article ID 3483528, 24 pages Received 27 May 2016;\n  Revised 8 August 2016; Accepted 18 September 2016. Special Issue on \"Smart\n  Data: Where the Big Data Meets the Semantics\". Academic Editor: Trong H.\n  Duong", "journal-ref": "Computational Intelligence and Neuroscience Volume 2016 (2016),\n  Article ID 3483528, 24 pages", "doi": null, "report-no": "3483528", "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One essential task in information extraction from the medical corpus is drug\nname recognition. Compared with text sources come from other domains, the\nmedical text is special and has unique characteristics. In addition, the\nmedical text mining poses more challenges, e.g., more unstructured text, the\nfast growing of new terms addition, a wide range of name variation for the same\ndrug. The mining is even more challenging due to the lack of labeled dataset\nsources and external knowledge, as well as multiple token representations for a\nsingle drug name that is more common in the real application setting. Although\nmany approaches have been proposed to overwhelm the task, some problems\nremained with poor F-score performance (less than 0.75). This paper presents a\nnew treatment in data representation techniques to overcome some of those\nchallenges. We propose three data representation techniques based on the\ncharacteristics of word distribution and word similarities as a result of word\nembedding training. The first technique is evaluated with the standard NN\nmodel, i.e., MLP (Multi-Layer Perceptrons). The second technique involves two\ndeep network classifiers, i.e., DBN (Deep Belief Networks), and SAE (Stacked\nDenoising Encoders). The third technique represents the sentence as a sequence\nthat is evaluated with a recurrent NN model, i.e., LSTM (Long Short Term\nMemory). In extracting the drug name entities, the third technique gives the\nbest F-score performance compared to the state of the art, with its average\nF-score being 0.8645.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 14:38:09 GMT"}], "update_date": "2016-10-07", "authors_parsed": [["Mujiono", "Sadikin", ""], ["Fanany", "Mohamad Ivan", ""], ["Basaruddin", "Chan", ""]]}, {"id": "1610.01922", "submitter": "Mohamad Ivan Fanany", "authors": "Arif Budiman, Mohamad Ivan Fanany, Chan Basaruddin", "title": "Adaptive Online Sequential ELM for Concept Drift Tackling", "comments": "Hindawi Publishing. Computational Intelligence and Neuroscience\n  Volume 2016 (2016), Article ID 8091267, 17 pages Received 29 January 2016,\n  Accepted 17 May 2016. Special Issue on \"Advances in Neural Networks and\n  Hybrid-Metaheuristics: Theory, Algorithms, and Novel Engineering\n  Applications\". Academic Editor: Stefan Haufe", "journal-ref": "Computational Intelligence and Neuroscience Volume 2016 (2016),\n  Article ID 8091267, 17 pages", "doi": "10.1155/2016/8091267", "report-no": "8091267", "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A machine learning method needs to adapt to over time changes in the\nenvironment. Such changes are known as concept drift. In this paper, we propose\nconcept drift tackling method as an enhancement of Online Sequential Extreme\nLearning Machine (OS-ELM) and Constructive Enhancement OS-ELM (CEOS-ELM) by\nadding adaptive capability for classification and regression problem. The\nscheme is named as adaptive OS-ELM (AOS-ELM). It is a single classifier scheme\nthat works well to handle real drift, virtual drift, and hybrid drift. The\nAOS-ELM also works well for sudden drift and recurrent context change type. The\nscheme is a simple unified method implemented in simple lines of code. We\nevaluated AOS-ELM on regression and classification problem by using concept\ndrift public data set (SEA and STAGGER) and other public data sets such as\nMNIST, USPS, and IDS. Experiments show that our method gives higher kappa value\ncompared to the multiclassifier ELM ensemble. Even though AOS-ELM in practice\ndoes not need hidden nodes increase, we address some issues related to the\nincreasing of the hidden nodes such as error condition and rank values. We\npropose taking the rank of the pseudoinverse matrix as an indicator parameter\nto detect underfitting condition.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 16:08:52 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Budiman", "Arif", ""], ["Fanany", "Mohamad Ivan", ""], ["Basaruddin", "Chan", ""]]}, {"id": "1610.01925", "submitter": "Mohamad Ivan Fanany", "authors": "L. M. Rasdi Rere, Mohamad Ivan Fanany, and Aniati Murni Arymurthy", "title": "Metaheuristic Algorithms for Convolution Neural Network", "comments": "Article ID 1537325, 13 pages. Received 29 January 2016; Revised 15\n  April 2016; Accepted 10 May 2016. Academic Editor: Martin Hagan. in Hindawi\n  Publishing. Computational Intelligence and Neuroscience Volume 2016 (2016)", "journal-ref": "Computational Intelligence and Neuroscience Volume 2016 (2016),\n  Article ID 1537325, 13 pages", "doi": "10.1155/2016/1537325", "report-no": "1537325", "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A typical modern optimization technique is usually either heuristic or\nmetaheuristic. This technique has managed to solve some optimization problems\nin the research area of science, engineering, and industry. However,\nimplementation strategy of metaheuristic for accuracy improvement on\nconvolution neural networks (CNN), a famous deep learning method, is still\nrarely investigated. Deep learning relates to a type of machine learning\ntechnique, where its aim is to move closer to the goal of artificial\nintelligence of creating a machine that could successfully perform any\nintellectual tasks that can be carried out by a human. In this paper, we\npropose the implementation strategy of three popular metaheuristic approaches,\nthat is, simulated annealing, differential evolution, and harmony search, to\noptimize CNN. The performances of these metaheuristic methods in optimizing CNN\non classifying MNIST and CIFAR dataset were evaluated and compared.\nFurthermore, the proposed methods are also compared with the original CNN.\nAlthough the proposed methods show an increase in the computation time, their\naccuracy has also been improved (up to 7.14 percent).\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 16:11:06 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Rere", "L. M. Rasdi", ""], ["Fanany", "Mohamad Ivan", ""], ["Arymurthy", "Aniati Murni", ""]]}, {"id": "1610.01969", "submitter": "Hyrum Anderson", "authors": "Hyrum S. Anderson, Jonathan Woodbridge and Bobby Filar", "title": "DeepDGA: Adversarially-Tuned Domain Generation and Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many malware families utilize domain generation algorithms (DGAs) to\nestablish command and control (C&C) connections. While there are many methods\nto pseudorandomly generate domains, we focus in this paper on detecting (and\ngenerating) domains on a per-domain basis which provides a simple and flexible\nmeans to detect known DGA families. Recent machine learning approaches to DGA\ndetection have been successful on fairly simplistic DGAs, many of which produce\nnames of fixed length. However, models trained on limited datasets are somewhat\nblind to new DGA variants.\n  In this paper, we leverage the concept of generative adversarial networks to\nconstruct a deep learning based DGA that is designed to intentionally bypass a\ndeep learning based detector. In a series of adversarial rounds, the generator\nlearns to generate domain names that are increasingly more difficult to detect.\nIn turn, a detector model updates its parameters to compensate for the\nadversarially generated domains. We test the hypothesis of whether\nadversarially generated domains may be used to augment training sets in order\nto harden other machine learning models against yet-to-be-observed DGAs. We\ndetail solutions to several challenges in training this character-based\ngenerative adversarial network (GAN). In particular, our deep learning\narchitecture begins as a domain name auto-encoder (encoder + decoder) trained\non domains in the Alexa one million. Then the encoder and decoder are\nreassembled competitively in a generative adversarial network (detector +\ngenerator), with novel neural architectures and training strategies to improve\nconvergence.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 17:50:27 GMT"}], "update_date": "2016-11-04", "authors_parsed": [["Anderson", "Hyrum S.", ""], ["Woodbridge", "Jonathan", ""], ["Filar", "Bobby", ""]]}, {"id": "1610.02055", "submitter": "Bolei Zhou", "authors": "Bolei Zhou, Aditya Khosla, Agata Lapedriza, Antonio Torralba, Aude\n  Oliva", "title": "Places: An Image Database for Deep Scene Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The rise of multi-million-item dataset initiatives has enabled data-hungry\nmachine learning algorithms to reach near-human semantic classification at\ntasks such as object and scene recognition. Here we describe the Places\nDatabase, a repository of 10 million scene photographs, labeled with scene\nsemantic categories and attributes, comprising a quasi-exhaustive list of the\ntypes of environments encountered in the world. Using state of the art\nConvolutional Neural Networks, we provide impressive baseline performances at\nscene classification. With its high-coverage and high-diversity of exemplars,\nthe Places Database offers an ecosystem to guide future progress on currently\nintractable visual recognition problems.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 20:14:13 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Zhou", "Bolei", ""], ["Khosla", "Aditya", ""], ["Lapedriza", "Agata", ""], ["Torralba", "Antonio", ""], ["Oliva", "Aude", ""]]}, {"id": "1610.02164", "submitter": "Danijar Hafner", "authors": "Danijar Hafner", "title": "Deep Reinforcement Learning From Raw Pixels in Doom", "comments": "Bachelor's thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using current reinforcement learning methods, it has recently become possible\nto learn to play unknown 3D games from raw pixels. In this work, we study the\nchallenges that arise in such complex environments, and summarize current\nmethods to approach these. We choose a task within the Doom game, that has not\nbeen approached yet. The goal for the agent is to fight enemies in a 3D world\nconsisting of five rooms. We train the DQN and LSTM-A3C algorithms on this\ntask. Results show that both algorithms learn sensible policies, but fail to\nachieve high scores given the amount of training. We provide insights into the\nlearned behavior, which can serve as a valuable starting point for further\nresearch in the Doom domain.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2016 07:07:47 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Hafner", "Danijar", ""]]}, {"id": "1610.02293", "submitter": "Sandra Castellanos-Paez", "authors": "Sandra Castellanos-Paez (LIG Laboratoire d'Informatique de Grenoble),\n  Damien Pellier (LIG Laboratoire d'Informatique de Grenoble), Humbert Fiorino\n  (LIG Laboratoire d'Informatique de Grenoble), Sylvie Pesty (LIG Laboratoire\n  d'Informatique de Grenoble)", "title": "Learning Macro-actions for State-Space Planning", "comments": "Journ{\\'e}es Francophones sur la Planification, la D{\\'e}cision et\n  l'Apprentissage pour la conduite de syst{\\`e}mes (JFPDA 2016) , Jul 2016,\n  Grenoble, France. 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning has achieved significant progress in recent years. Among the various\napproaches to scale up plan synthesis, the use of macro-actions has been widely\nexplored. As a first stage towards the development of a solution to learn\non-line macro-actions, we propose an algorithm to identify useful macro-actions\nbased on data mining techniques. The integration in the planning search of\nthese learned macro-actions shows significant improvements over four classical\nplanning benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2016 14:06:40 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Castellanos-Paez", "Sandra", "", "LIG Laboratoire d'Informatique de Grenoble"], ["Pellier", "Damien", "", "LIG Laboratoire d'Informatique de Grenoble"], ["Fiorino", "Humbert", "", "LIG Laboratoire d'Informatique de Grenoble"], ["Pesty", "Sylvie", "", "LIG Laboratoire\n  d'Informatique de Grenoble"]]}, {"id": "1610.02333", "submitter": "Fahim Imam", "authors": "Fahim T. Imam", "title": "Application of Ontologies in Cloud Computing: The State-Of-The-Art", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a systematic survey on existing literature and seminal\nworks relevant to the application of ontologies in different aspects of Cloud\ncomputing. Our hypothesis is that ontologies along with their reasoning\ncapabilities can have significant impact on improving various aspects of the\nCloud computing phenomena. Ontologies can promote intelligent decision support\nmechanisms for various Cloud based services. They can also provide effective\ninteroperability among the Cloud based systems and resources. This survey can\npromote a comprehensive understanding on the roles and significance of\nontologies within the overall domain of Cloud Computing. Also, this project can\npotentially form the basis of new research area and possibilities for both\nontology and Cloud computing communities.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 05:39:37 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Imam", "Fahim T.", ""]]}, {"id": "1610.02348", "submitter": "Mohamad Ivan Fanany", "authors": "Arif Budiman, Mohamad Ivan Fanany, Chan Basaruddin", "title": "Adaptive Convolutional ELM For Concept Drift Handling in Online Stream\n  Data", "comments": "Submitted to IEEE Transactions on Systems, Man and Cybernetics:\n  Systems. Special Issue on Efficient and Rapid Machine Learning Algorithms for\n  Big Data and Dynamic Varying Systems", "journal-ref": null, "doi": null, "report-no": "SMCA-16-09-1038", "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In big data era, the data continuously generated and its distribution may\nkeep changes overtime. These challenges in online stream of data are known as\nconcept drift. In this paper, we proposed the Adaptive Convolutional ELM method\n(ACNNELM) as enhancement of Convolutional Neural Network (CNN) with a hybrid\nExtreme Learning Machine (ELM) model plus adaptive capability. This method is\naimed for concept drift handling. We enhanced the CNN as convolutional\nhiererchical features representation learner combined with Elastic ELM\n(E$^2$LM) as a parallel supervised classifier. We propose an Adaptive OS-ELM\n(AOS-ELM) for concept drift adaptability in classifier level (named ACNNELM-1)\nand matrices concatenation ensembles for concept drift adaptability in ensemble\nlevel (named ACNNELM-2). Our proposed Adaptive CNNELM is flexible that works\nwell in classifier level and ensemble level while most current methods only\nproposed to work on either one of the levels.\n  We verified our method in extended MNIST data set and not MNIST data set. We\nset the experiment to simulate virtual drift, real drift, and hybrid drift\nevent and we demonstrated how our CNNELM adaptability works. Our proposed\nmethod works well and gives better accuracy, computation scalability, and\nconcept drifts adaptability compared to the regular ELM and CNN. Further\nresearches are still required to study the optimum parameters and to use more\nvaried image data set.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2016 16:53:09 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Budiman", "Arif", ""], ["Fanany", "Mohamad Ivan", ""], ["Basaruddin", "Chan", ""]]}, {"id": "1610.02391", "submitter": "Ramprasaath R. Selvaraju", "authors": "Ramprasaath R. Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna\n  Vedantam, Devi Parikh, Dhruv Batra", "title": "Grad-CAM: Visual Explanations from Deep Networks via Gradient-based\n  Localization", "comments": "This version was published in International Journal of Computer\n  Vision (IJCV) in 2019; A previous version of the paper was published at\n  International Conference on Computer Vision (ICCV'17)", "journal-ref": null, "doi": "10.1007/s11263-019-01228-7", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a technique for producing \"visual explanations\" for decisions from\na large class of CNN-based models, making them more transparent. Our approach -\nGradient-weighted Class Activation Mapping (Grad-CAM), uses the gradients of\nany target concept, flowing into the final convolutional layer to produce a\ncoarse localization map highlighting important regions in the image for\npredicting the concept. Grad-CAM is applicable to a wide variety of CNN\nmodel-families: (1) CNNs with fully-connected layers, (2) CNNs used for\nstructured outputs, (3) CNNs used in tasks with multimodal inputs or\nreinforcement learning, without any architectural changes or re-training. We\ncombine Grad-CAM with fine-grained visualizations to create a high-resolution\nclass-discriminative visualization and apply it to off-the-shelf image\nclassification, captioning, and visual question answering (VQA) models,\nincluding ResNet-based architectures. In the context of image classification\nmodels, our visualizations (a) lend insights into their failure modes, (b) are\nrobust to adversarial images, (c) outperform previous methods on localization,\n(d) are more faithful to the underlying model and (e) help achieve\ngeneralization by identifying dataset bias. For captioning and VQA, we show\nthat even non-attention based models can localize inputs. We devise a way to\nidentify important neurons through Grad-CAM and combine it with neuron names to\nprovide textual explanations for model decisions. Finally, we design and\nconduct human studies to measure if Grad-CAM helps users establish appropriate\ntrust in predictions from models and show that Grad-CAM helps untrained users\nsuccessfully discern a 'stronger' nodel from a 'weaker' one even when both make\nidentical predictions. Our code is available at\nhttps://github.com/ramprs/grad-cam/, along with a demo at\nhttp://gradcam.cloudcv.org, and a video at youtu.be/COjUB9Izk6E.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2016 19:54:24 GMT"}, {"version": "v2", "created": "Fri, 30 Dec 2016 07:19:35 GMT"}, {"version": "v3", "created": "Tue, 21 Mar 2017 23:48:00 GMT"}, {"version": "v4", "created": "Tue, 3 Dec 2019 02:13:03 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Selvaraju", "Ramprasaath R.", ""], ["Cogswell", "Michael", ""], ["Das", "Abhishek", ""], ["Vedantam", "Ramakrishna", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""]]}, {"id": "1610.02424", "submitter": "Ashwin Kalyan", "authors": "Ashwin K Vijayakumar, Michael Cogswell, Ramprasath R. Selvaraju, Qing\n  Sun, Stefan Lee, David Crandall, Dhruv Batra", "title": "Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence\n  Models", "comments": "16 pages; accepted at AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural sequence models are widely used to model time-series data. Equally\nubiquitous is the usage of beam search (BS) as an approximate inference\nalgorithm to decode output sequences from these models. BS explores the search\nspace in a greedy left-right fashion retaining only the top-B candidates -\nresulting in sequences that differ only slightly from each other. Producing\nlists of nearly identical sequences is not only computationally wasteful but\nalso typically fails to capture the inherent ambiguity of complex AI tasks. To\novercome this problem, we propose Diverse Beam Search (DBS), an alternative to\nBS that decodes a list of diverse outputs by optimizing for a\ndiversity-augmented objective. We observe that our method finds better top-1\nsolutions by controlling for the exploration and exploitation of the search\nspace - implying that DBS is a better search algorithm. Moreover, these gains\nare achieved with minimal computational or memory over- head as compared to\nbeam search. To demonstrate the broad applicability of our method, we present\nresults on image captioning, machine translation and visual question generation\nusing both standard quantitative metrics and qualitative human studies.\nFurther, we study the role of diversity for image-grounded language generation\ntasks as the complexity of the image changes. We observe that our method\nconsistently outperforms BS and previously proposed techniques for diverse\ndecoding from neural sequence models.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2016 20:56:47 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 13:48:32 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Vijayakumar", "Ashwin K", ""], ["Cogswell", "Michael", ""], ["Selvaraju", "Ramprasath R.", ""], ["Sun", "Qing", ""], ["Lee", "Stefan", ""], ["Crandall", "David", ""], ["Batra", "Dhruv", ""]]}, {"id": "1610.02591", "submitter": "Yexiang Xue", "authors": "Yexiang Xue, Zhiyuan Li, Stefano Ermon, Carla P. Gomes, Bart Selman", "title": "Solving Marginal MAP Problems with NP Oracles and Parity Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arising from many applications at the intersection of decision making and\nmachine learning, Marginal Maximum A Posteriori (Marginal MAP) Problems unify\nthe two main classes of inference, namely maximization (optimization) and\nmarginal inference (counting), and are believed to have higher complexity than\nboth of them. We propose XOR_MMAP, a novel approach to solve the Marginal MAP\nProblem, which represents the intractable counting subproblem with queries to\nNP oracles, subject to additional parity constraints. XOR_MMAP provides a\nconstant factor approximation to the Marginal MAP Problem, by encoding it as a\nsingle optimization in polynomial size of the original problem. We evaluate our\napproach in several machine learning and decision making applications, and show\nthat our approach outperforms several state-of-the-art Marginal MAP solvers.\n", "versions": [{"version": "v1", "created": "Sat, 8 Oct 2016 22:32:35 GMT"}, {"version": "v2", "created": "Tue, 29 Nov 2016 21:22:06 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Xue", "Yexiang", ""], ["Li", "Zhiyuan", ""], ["Ermon", "Stefano", ""], ["Gomes", "Carla P.", ""], ["Selman", "Bart", ""]]}, {"id": "1610.02634", "submitter": "Mani A", "authors": "A. Mani", "title": "On Deductive Systems of AC Semantics for Rough Sets", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Antichain based semantics for general rough sets were introduced recently by\nthe present author. In her paper two different semantics, one for general rough\nsets and another for general approximation spaces over quasi-equivalence\nrelations, were developed. These semantics are improved and studied further\nfrom a lateral algebraic logic perspective in this research. The main results\nconcern the structure of the algebras and deductive systems in the context.\n", "versions": [{"version": "v1", "created": "Sun, 9 Oct 2016 06:42:20 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Mani", "A.", ""]]}, {"id": "1610.02649", "submitter": "Muhammad Yousefnezhad", "authors": "Muhammad Yousefnezhad, Ali Reihanian, Daoqiang Zhang, Behrouz\n  Minaei-Bidgoli", "title": "A new selection strategy for selective cluster ensemble based on\n  Diversity and Independency", "comments": "Accepted in Engineering Applications of Artificial Intelligence\n  (EAAI) Journal", "journal-ref": null, "doi": "10.1016/j.engappai.2016.10.005", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research introduces a new strategy in cluster ensemble selection by\nusing Independency and Diversity metrics. In recent years, Diversity and\nQuality, which are two metrics in evaluation procedure, have been used for\nselecting basic clustering results in the cluster ensemble selection. Although\nquality can improve the final results in cluster ensemble, it cannot control\nthe procedures of generating basic results, which causes a gap in prediction of\nthe generated basic results' accuracy. Instead of quality, this paper\nintroduces Independency as a supplementary method to be used in conjunction\nwith Diversity. Therefore, this paper uses a heuristic metric, which is based\non the procedure of converting code to graph in Software Testing, in order to\ncalculate the Independency of two basic clustering algorithms. Moreover, a new\nmodeling language, which we called as \"Clustering Algorithms Independency\nLanguage\" (CAIL), is introduced in order to generate graphs which depict\nIndependency of algorithms. Also, Uniformity, which is a new similarity metric,\nhas been introduced for evaluating the diversity of basic results. As a\ncredential, our experimental results on varied different standard data sets\nshow that the proposed framework improves the accuracy of final results\ndramatically in comparison with other cluster ensemble methods.\n", "versions": [{"version": "v1", "created": "Sun, 9 Oct 2016 09:28:01 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Yousefnezhad", "Muhammad", ""], ["Reihanian", "Ali", ""], ["Zhang", "Daoqiang", ""], ["Minaei-Bidgoli", "Behrouz", ""]]}, {"id": "1610.02683", "submitter": "Malika Aubakirova", "authors": "Malika Aubakirova, Mohit Bansal", "title": "Interpreting Neural Networks to Improve Politeness Comprehension", "comments": "To appear at EMNLP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an interpretable neural network approach to predicting and\nunderstanding politeness in natural language requests. Our models are based on\nsimple convolutional neural networks directly on raw text, avoiding any manual\nidentification of complex sentiment or syntactic features, while performing\nbetter than such feature-based models from previous work. More importantly, we\nuse the challenging task of politeness prediction as a testbed to next present\na much-needed understanding of what these successful networks are actually\nlearning. For this, we present several network visualizations based on\nactivation clusters, first derivative saliency, and embedding space\ntransformations, helping us automatically identify several subtle linguistics\nmarkers of politeness theories. Further, this analysis reveals multiple novel,\nhigh-scoring politeness strategies which, when added back as new features,\nreduce the accuracy gap between the original featurized system and the neural\nmodel, thus providing a clear quantitative interpretation of the success of\nthese neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 9 Oct 2016 14:42:58 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Aubakirova", "Malika", ""], ["Bansal", "Mohit", ""]]}, {"id": "1610.02707", "submitter": "Yannis Assael", "authors": "Hossam Mossalam, Yannis M. Assael, Diederik M. Roijers, Shimon\n  Whiteson", "title": "Multi-Objective Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Deep Optimistic Linear Support Learning (DOL) to solve\nhigh-dimensional multi-objective decision problems where the relative\nimportances of the objectives are not known a priori. Using features from the\nhigh-dimensional inputs, DOL computes the convex coverage set containing all\npotential optimal solutions of the convex combinations of the objectives. To\nour knowledge, this is the first time that deep reinforcement learning has\nsucceeded in learning multi-objective policies. In addition, we provide a\ntestbed with two experiments to be used as a benchmark for deep multi-objective\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Sun, 9 Oct 2016 19:08:36 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Mossalam", "Hossam", ""], ["Assael", "Yannis M.", ""], ["Roijers", "Diederik M.", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1610.02751", "submitter": "Shiyou Lian", "authors": "Shiyou Lian", "title": "A New Theoretical and Technological System of Imprecise-Information\n  Processing", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imprecise-information processing will play an indispensable role in\nintelligent systems, especially in the anthropomorphic intelligent systems (as\nintelligent robots). A new theoretical and technological system of\nimprecise-information processing has been founded in Principles of\nImprecise-Information Processing: A New Theoretical and Technological System[1]\nwhich is different from fuzzy technology. The system has clear hierarchy and\nrigorous structure, which results from the formation principle of imprecise\ninformation and has solid mathematical and logical bases, and which has many\nadvantages beyond fuzzy technology. The system provides a technological\nplatform for relevant applications and lays a theoretical foundation for\nfurther research.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2016 02:14:16 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Lian", "Shiyou", ""]]}, {"id": "1610.02828", "submitter": "Jobin Wilson", "authors": "Jobin Wilson, Ram Mohan, Muhammad Arif, Santanu Chaudhury, Brejesh\n  Lall", "title": "Ranking academic institutions on potential paper acceptance in upcoming\n  conferences", "comments": "KDD 2016, KDD Cup 2016, Appeared in the KDD Cup Workshop\n  2016,https://kddcup2016.azurewebsites.net/Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The crux of the problem in KDD Cup 2016 involves developing data mining\ntechniques to rank research institutions based on publications. Rank importance\nof research institutions are derived from predictions on the number of full\nresearch papers that would potentially get accepted in upcoming top-tier\nconferences, utilizing public information on the web. This paper describes our\nsolution to KDD Cup 2016. We used a two step approach in which we first\nidentify full research papers corresponding to each conference of interest and\nthen train two variants of exponential smoothing models to make predictions.\nOur solution achieves an overall score of 0.7508, while the winning submission\nscored 0.7656 in the overall results.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2016 09:55:14 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Wilson", "Jobin", ""], ["Mohan", "Ram", ""], ["Arif", "Muhammad", ""], ["Chaudhury", "Santanu", ""], ["Lall", "Brejesh", ""]]}, {"id": "1610.02847", "submitter": "Daniel J Mankowitz", "authors": "Daniel J. Mankowitz, Aviv Tamar and Shie Mannor", "title": "Situational Awareness by Risk-Conscious Skills", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical Reinforcement Learning has been previously shown to speed up the\nconvergence rate of RL planning algorithms as well as mitigate feature-based\nmodel misspecification (Mankowitz et. al. 2016a,b, Bacon 2015). To do so, it\nutilizes hierarchical abstractions, also known as skills -- a type of\ntemporally extended action (Sutton et. al. 1999) to plan at a higher level,\nabstracting away from the lower-level details. We incorporate risk sensitivity,\nalso referred to as Situational Awareness (SA), into hierarchical RL for the\nfirst time by defining and learning risk aware skills in a Probabilistic Goal\nSemi-Markov Decision Process (PG-SMDP). This is achieved using our novel\nSituational Awareness by Risk-Conscious Skills (SARiCoS) algorithm which comes\nwith a theoretical convergence guarantee. We show in a RoboCup soccer domain\nthat the learned risk aware skills exhibit complex human behaviors such as\n`time-wasting' in a soccer game. In addition, the learned risk aware skills are\nable to mitigate reward-based model misspecification.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2016 11:01:32 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Mankowitz", "Daniel J.", ""], ["Tamar", "Aviv", ""], ["Mannor", "Shie", ""]]}, {"id": "1610.02876", "submitter": "Niek Tax", "authors": "Niek Tax, Natalia Sidorova, Wil M. P. van der Aalst, Reinder Haakma", "title": "Heuristic Approaches for Generating Local Process Models through Log\n  Projections", "comments": "paper accepted and to appear in the proceedings of the IEEE Symposium\n  on Computational Intelligence and Data Mining (CIDM), special session on\n  Process Mining, part of the Symposium Series on Computational Intelligence\n  (SSCI)", "journal-ref": "Proceedings of the IEEE Symposium Series on Computational\n  Intelligence (SSCI), (2016) 1-8", "doi": "10.1109/SSCI.2016.7849948", "report-no": null, "categories": "cs.LG cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local Process Model (LPM) discovery is focused on the mining of a set of\nprocess models where each model describes the behavior represented in the event\nlog only partially, i.e. subsets of possible events are taken into account to\ncreate so-called local process models. Often such smaller models provide\nvaluable insights into the behavior of the process, especially when no adequate\nand comprehensible single overall process model exists that is able to describe\nthe traces of the process from start to end. The practical application of LPM\ndiscovery is however hindered by computational issues in the case of logs with\nmany activities (problems may already occur when there are more than 17 unique\nactivities). In this paper, we explore three heuristics to discover subsets of\nactivities that lead to useful log projections with the goal of speeding up LPM\ndiscovery considerably while still finding high-quality LPMs. We found that a\nMarkov clustering approach to create projection sets results in the largest\nimprovement of execution time, with discovered LPMs still being better than\nwith the use of randomly generated activity sets of the same size. Another\nheuristic, based on log entropy, yields a more moderate speedup, but enables\nthe discovery of higher quality LPMs. The third heuristic, based on the\nrelative information gain, shows unstable performance: for some data sets the\nspeedup and LPM quality are higher than with the log entropy based method,\nwhile for other data sets there is no speedup at all.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2016 12:12:46 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Tax", "Niek", ""], ["Sidorova", "Natalia", ""], ["van der Aalst", "Wil M. P.", ""], ["Haakma", "Reinder", ""]]}, {"id": "1610.02891", "submitter": "Kaixiang Mo", "authors": "Kaixiang Mo, Shuangyin Li, Yu Zhang, Jiajun Li, Qiang Yang", "title": "Personalizing a Dialogue System with Transfer Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is difficult to train a personalized task-oriented dialogue system because\nthe data collected from each individual is often insufficient. Personalized\ndialogue systems trained on a small dataset can overfit and make it difficult\nto adapt to different user needs. One way to solve this problem is to consider\na collection of multiple users' data as a source domain and an individual\nuser's data as a target domain, and to perform a transfer learning from the\nsource to the target domain. By following this idea, we propose\n\"PETAL\"(PErsonalized Task-oriented diALogue), a transfer-learning framework\nbased on POMDP to learn a personalized dialogue system. The system first learns\ncommon dialogue knowledge from the source domain and then adapts this knowledge\nto the target user. This framework can avoid the negative transfer problem by\nconsidering differences between source and target users. The policy in the\npersonalized POMDP can learn to choose different actions appropriately for\ndifferent users. Experimental results on a real-world coffee-shopping data and\nsimulation data show that our personalized dialogue system can choose different\noptimal actions for different users, and thus effectively improve the dialogue\nquality under the personalized setting.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2016 12:51:05 GMT"}, {"version": "v2", "created": "Mon, 17 Oct 2016 14:08:42 GMT"}, {"version": "v3", "created": "Fri, 26 May 2017 14:05:07 GMT"}], "update_date": "2017-05-29", "authors_parsed": [["Mo", "Kaixiang", ""], ["Li", "Shuangyin", ""], ["Zhang", "Yu", ""], ["Li", "Jiajun", ""], ["Yang", "Qiang", ""]]}, {"id": "1610.02922", "submitter": "Henry Kim", "authors": "Henry M. Kim, Marek Laskowski", "title": "Towards an Ontology-Driven Blockchain Design for Supply Chain Provenance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An interesting research problem in our age of Big Data is that of determining\nprovenance. Granular evaluation of provenance of physical goods--e.g. tracking\ningredients of a pharmaceutical or demonstrating authenticity of luxury\ngoods--has often not been possible with today's items that are produced and\ntransported in complex, inter-organizational, often internationally-spanning\nsupply chains. Recent adoption of Internet of Things and Blockchain\ntechnologies give promise at better supply chain provenance. We are\nparticularly interested in the blockchain as many favoured use cases of\nblockchain are for provenance tracking. We are also interested in applying\nontologies as there has been some work done on knowledge provenance,\ntraceability, and food provenance using ontologies. In this paper, we make a\ncase for why ontologies can contribute to blockchain design. To support this\ncase, we analyze a traceability ontology and translate some of its\nrepresentations to smart contracts that execute a provenance trace and enforce\ntraceability constraints on the Ethereum blockchain platform.\n", "versions": [{"version": "v1", "created": "Sun, 28 Aug 2016 19:37:00 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Kim", "Henry M.", ""], ["Laskowski", "Marek", ""]]}, {"id": "1610.02995", "submitter": "Georg Martius", "authors": "Georg Martius and Christoph H. Lampert", "title": "Extrapolation and learning equations", "comments": "13 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In classical machine learning, regression is treated as a black box process\nof identifying a suitable function from a hypothesis set without attempting to\ngain insight into the mechanism connecting inputs and outputs. In the natural\nsciences, however, finding an interpretable function for a phenomenon is the\nprime goal as it allows to understand and generalize results. This paper\nproposes a novel type of function learning network, called equation learner\n(EQL), that can learn analytical expressions and is able to extrapolate to\nunseen domains. It is implemented as an end-to-end differentiable feed-forward\nnetwork and allows for efficient gradient based training. Due to sparsity\nregularization concise interpretable expressions can be obtained. Often the\ntrue underlying source expression is identified.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2016 16:47:36 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Martius", "Georg", ""], ["Lampert", "Christoph H.", ""]]}, {"id": "1610.03024", "submitter": "Kristijonas Cyras", "authors": "Kristijonas \\v{C}yras and Francesca Toni", "title": "ABA+: Assumption-Based Argumentation with Preferences", "comments": "This is a preprint of a manuscript under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ABA+, a new approach to handling preferences in a well known\nstructured argumentation formalism, Assumption-Based Argumentation (ABA). In\nABA+, preference information given over assumptions is incorporated directly\ninto the attack relation, thus resulting in attack reversal. ABA+\nconservatively extends ABA and exhibits various desirable features regarding\nrelationship among argumentation semantics as well as preference handling. We\nalso introduce Weak Contraposition, a principle concerning reasoning with rules\nand preferences that relaxes the standard principle of contraposition, while\nguaranteeing additional desirable features for ABA+.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2016 18:45:41 GMT"}, {"version": "v2", "created": "Wed, 12 Oct 2016 17:40:10 GMT"}], "update_date": "2016-10-13", "authors_parsed": [["\u010cyras", "Kristijonas", ""], ["Toni", "Francesca", ""]]}, {"id": "1610.03138", "submitter": "Michael Cook", "authors": "Michael Cook, Mirjam Eladhari, Andy Nealen, Mike Treanor, Eddy\n  Boxerman, Alex Jaffe, Paul Sottosanti, Steve Swink", "title": "PCG-Based Game Design Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People enjoy encounters with generative software, but rarely are they\nencouraged to interact with, understand or engage with it. In this paper we\ndefine the term 'PCG-based game', and explain how this concept follows on from\nthe idea of an AI-based game. We look at existing examples of games which\nforeground their AI, put forward a methodology for designing PCG-based games,\ndescribe some example case study designs for PCG-based games, and describe\nlessons learned during this process of sketching and developing ideas.\n", "versions": [{"version": "v1", "created": "Tue, 11 Oct 2016 00:23:09 GMT"}], "update_date": "2016-10-12", "authors_parsed": [["Cook", "Michael", ""], ["Eladhari", "Mirjam", ""], ["Nealen", "Andy", ""], ["Treanor", "Mike", ""], ["Boxerman", "Eddy", ""], ["Jaffe", "Alex", ""], ["Sottosanti", "Paul", ""], ["Swink", "Steve", ""]]}, {"id": "1610.03164", "submitter": "Andrea Daniele", "authors": "Andrea F. Daniele and Mohit Bansal and Matthew R. Walter", "title": "Navigational Instruction Generation as Inverse Reinforcement Learning\n  with Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern robotics applications that involve human-robot interaction require\nrobots to be able to communicate with humans seamlessly and effectively.\nNatural language provides a flexible and efficient medium through which robots\ncan exchange information with their human partners. Significant advancements\nhave been made in developing robots capable of interpreting free-form\ninstructions, but less attention has been devoted to endowing robots with the\nability to generate natural language. We propose a navigational guide model\nthat enables robots to generate natural language instructions that allow humans\nto navigate a priori unknown environments. We first decide which information to\nshare with the user according to their preferences, using a policy trained from\nhuman demonstrations via inverse reinforcement learning. We then \"translate\"\nthis information into a natural language instruction using a neural\nsequence-to-sequence model that learns to generate free-form instructions from\nnatural language corpora. We evaluate our method on a benchmark route\ninstruction dataset and achieve a BLEU score of 72.18% when compared to\nhuman-generated reference instructions. We additionally conduct navigation\nexperiments with human participants that demonstrate that our method generates\ninstructions that people follow as accurately and easily as those produced by\nhumans.\n", "versions": [{"version": "v1", "created": "Tue, 11 Oct 2016 02:47:09 GMT"}], "update_date": "2016-10-12", "authors_parsed": [["Daniele", "Andrea F.", ""], ["Bansal", "Mohit", ""], ["Walter", "Matthew R.", ""]]}, {"id": "1610.03263", "submitter": "Patrick Bl\\\"obaum", "authors": "Patrick Bl\\\"obaum, Takashi Washio, Shohei Shimizu", "title": "Error Asymmetry in Causal and Anticausal Regression", "comments": null, "journal-ref": "Behaviormetrika, 2017, 10.1007/s41237-017-0022-z", "doi": "10.1007/s41237-017-0022-z", "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is generally difficult to make any statements about the expected\nprediction error in an univariate setting without further knowledge about how\nthe data were generated. Recent work showed that knowledge about the real\nunderlying causal structure of a data generation process has implications for\nvarious machine learning settings. Assuming an additive noise and an\nindependence between data generating mechanism and its input, we draw a novel\nconnection between the intrinsic causal relationship of two variables and the\nexpected prediction error. We formulate the theorem that the expected error of\nthe true data generating function as prediction model is generally smaller when\nthe effect is predicted from its cause and, on the contrary, greater when the\ncause is predicted from its effect. The theorem implies an asymmetry in the\nerror depending on the prediction direction. This is further corroborated with\nempirical evaluations in artificial and real-world data sets.\n", "versions": [{"version": "v1", "created": "Tue, 11 Oct 2016 10:15:15 GMT"}, {"version": "v2", "created": "Mon, 17 Apr 2017 12:25:44 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Bl\u00f6baum", "Patrick", ""], ["Washio", "Takashi", ""], ["Shimizu", "Shohei", ""]]}, {"id": "1610.03295", "submitter": "Shai Shalev-Shwartz", "authors": "Shai Shalev-Shwartz and Shaked Shammah and Amnon Shashua", "title": "Safe, Multi-Agent, Reinforcement Learning for Autonomous Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous driving is a multi-agent setting where the host vehicle must apply\nsophisticated negotiation skills with other road users when overtaking, giving\nway, merging, taking left and right turns and while pushing ahead in\nunstructured urban roadways. Since there are many possible scenarios, manually\ntackling all possible cases will likely yield a too simplistic policy.\nMoreover, one must balance between unexpected behavior of other\ndrivers/pedestrians and at the same time not to be too defensive so that normal\ntraffic flow is maintained.\n  In this paper we apply deep reinforcement learning to the problem of forming\nlong term driving strategies. We note that there are two major challenges that\nmake autonomous driving different from other robotic tasks. First, is the\nnecessity for ensuring functional safety - something that machine learning has\ndifficulty with given that performance is optimized at the level of an\nexpectation over many instances. Second, the Markov Decision Process model\noften used in robotics is problematic in our case because of unpredictable\nbehavior of other agents in this multi-agent scenario. We make three\ncontributions in our work. First, we show how policy gradient iterations can be\nused without Markovian assumptions. Second, we decompose the problem into a\ncomposition of a Policy for Desires (which is to be learned) and trajectory\nplanning with hard constraints (which is not learned). The goal of Desires is\nto enable comfort of driving, while hard constraints guarantees the safety of\ndriving. Third, we introduce a hierarchical temporal abstraction we call an\n\"Option Graph\" with a gating mechanism that significantly reduces the effective\nhorizon and thereby reducing the variance of the gradient estimation even\nfurther.\n", "versions": [{"version": "v1", "created": "Tue, 11 Oct 2016 12:09:03 GMT"}], "update_date": "2016-10-12", "authors_parsed": [["Shalev-Shwartz", "Shai", ""], ["Shammah", "Shaked", ""], ["Shashua", "Amnon", ""]]}, {"id": "1610.03518", "submitter": "Wojciech Zaremba", "authors": "Paul Christiano, Zain Shah, Igor Mordatch, Jonas Schneider, Trevor\n  Blackwell, Joshua Tobin, Pieter Abbeel, and Wojciech Zaremba", "title": "Transfer from Simulation to Real World through Learning Deep Inverse\n  Dynamics Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing control policies in simulation is often more practical and safer\nthan directly running experiments in the real world. This applies to policies\nobtained from planning and optimization, and even more so to policies obtained\nfrom reinforcement learning, which is often very data demanding. However, a\npolicy that succeeds in simulation often doesn't work when deployed on a real\nrobot. Nevertheless, often the overall gist of what the policy does in\nsimulation remains valid in the real world. In this paper we investigate such\nsettings, where the sequence of states traversed in simulation remains\nreasonable for the real world, even if the details of the controls are not, as\ncould be the case when the key differences lie in detailed friction, contact,\nmass and geometry properties. During execution, at each time step our approach\ncomputes what the simulation-based control policy would do, but then, rather\nthan executing these controls on the real robot, our approach computes what the\nsimulation expects the resulting next state(s) will be, and then relies on a\nlearned deep inverse dynamics model to decide which real-world action is most\nsuitable to achieve those next states. Deep models are only as good as their\ntraining data, and we also propose an approach for data collection to\n(incrementally) learn the deep inverse dynamics model. Our experiments shows\nour approach compares favorably with various baselines that have been developed\nfor dealing with simulation to real world model discrepancy, including output\nerror control and Gaussian dynamics adaptation.\n", "versions": [{"version": "v1", "created": "Tue, 11 Oct 2016 20:24:31 GMT"}], "update_date": "2016-10-13", "authors_parsed": [["Christiano", "Paul", ""], ["Shah", "Zain", ""], ["Mordatch", "Igor", ""], ["Schneider", "Jonas", ""], ["Blackwell", "Trevor", ""], ["Tobin", "Joshua", ""], ["Abbeel", "Pieter", ""], ["Zaremba", "Wojciech", ""]]}, {"id": "1610.03573", "submitter": "Azlan Iqbal", "authors": "Paul Bonham and Azlan Iqbal", "title": "A Chain-Detection Algorithm for Two-Dimensional Grids", "comments": "28 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a general method of detecting valid chains or links of pieces on\na two-dimensional grid. Specifically, using the example of the chess variant\nknown as Switch-Side Chain-Chess (SSCC). Presently, no foolproof method of\ndetecting such chains in any given chess position is known and existing graph\ntheory, to our knowledge, is unable to fully address this problem either. We\ntherefore propose a solution implemented and tested using the C++ programming\nlanguage. We have been unable to find an incorrect result and therefore offer\nit as the most viable solution thus far to the chain-detection problem in this\nchess variant. The algorithm is also scalable, in principle, to areas beyond\ntwo-dimensional grids such as 3D analysis and molecular chemistry.\n", "versions": [{"version": "v1", "created": "Wed, 12 Oct 2016 01:34:34 GMT"}], "update_date": "2016-10-13", "authors_parsed": [["Bonham", "Paul", ""], ["Iqbal", "Azlan", ""]]}, {"id": "1610.03606", "submitter": "Simon Moulieras", "authors": "Simon Moulieras, Fran\\c{c}ois Pachet", "title": "Maximum entropy models for generation of expressive music", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of contemporary monophonic music, expression can be seen as\nthe difference between a musical performance and its symbolic representation,\ni.e. a musical score. In this paper, we show how Maximum Entropy (MaxEnt)\nmodels can be used to generate musical expression in order to mimic a human\nperformance. As a training corpus, we had a professional pianist play about 150\nmelodies of jazz, pop, and latin jazz. The results show a good predictive\npower, validating the choice of our model. Additionally, we set up a listening\ntest whose results reveal that on average, people significantly prefer the\nmelodies generated by the MaxEnt model than the ones without any expression, or\nwith fully random expression. Furthermore, in some cases, MaxEnt melodies are\nalmost as popular as the human performed ones.\n", "versions": [{"version": "v1", "created": "Wed, 12 Oct 2016 06:20:22 GMT"}], "update_date": "2016-10-13", "authors_parsed": [["Moulieras", "Simon", ""], ["Pachet", "Fran\u00e7ois", ""]]}, {"id": "1610.03677", "submitter": "Suchet Bargoti", "authors": "Suchet Bargoti and James Underwood", "title": "Deep Fruit Detection in Orchards", "comments": "Submitted to the IEEE International Conference on Robotics and\n  Automation 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An accurate and reliable image based fruit detection system is critical for\nsupporting higher level agriculture tasks such as yield mapping and robotic\nharvesting. This paper presents the use of a state-of-the-art object detection\nframework, Faster R-CNN, in the context of fruit detection in orchards,\nincluding mangoes, almonds and apples. Ablation studies are presented to better\nunderstand the practical deployment of the detection network, including how\nmuch training data is required to capture variability in the dataset. Data\naugmentation techniques are shown to yield significant performance gains,\nresulting in a greater than two-fold reduction in the number of training images\nrequired. In contrast, transferring knowledge between orchards contributed to\nnegligible performance gain over initialising the Deep Convolutional Neural\nNetwork directly from ImageNet features. Finally, to operate over orchard data\ncontaining between 100-1000 fruit per image, a tiling approach is introduced\nfor the Faster R-CNN framework. The study has resulted in the best yet\ndetection performance for these orchards relative to previous works, with an\nF1-score of >0.9 achieved for apples and mangoes.\n", "versions": [{"version": "v1", "created": "Wed, 12 Oct 2016 11:40:24 GMT"}, {"version": "v2", "created": "Mon, 18 Sep 2017 01:03:55 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Bargoti", "Suchet", ""], ["Underwood", "James", ""]]}, {"id": "1610.03761", "submitter": "Shehroz Khan", "authors": "Shehroz S. Khan, Babak Taati", "title": "Detecting Unseen Falls from Wearable Devices using Channel-wise Ensemble\n  of Autoencoders", "comments": "25 pages, 6 figures, 4 Tables", "journal-ref": "Expert Systems with Applications, Volume 87, 30 November 2017,\n  Pages 280-290", "doi": "10.1016/j.eswa.2017.06.011", "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fall is an abnormal activity that occurs rarely, so it is hard to collect\nreal data for falls. It is, therefore, difficult to use supervised learning\nmethods to automatically detect falls. Another challenge in using machine\nlearning methods to automatically detect falls is the choice of engineered\nfeatures. In this paper, we propose to use an ensemble of autoencoders to\nextract features from different channels of wearable sensor data trained only\non normal activities. We show that the traditional approach of choosing a\nthreshold as the maximum of the reconstruction error on the training normal\ndata is not the right way to identify unseen falls. We propose two methods for\nautomatic tightening of reconstruction error from only the normal activities\nfor better identification of unseen falls. We present our results on two\nactivity recognition datasets and show the efficacy of our proposed method\nagainst traditional autoencoder models and two standard one-class\nclassification methods.\n", "versions": [{"version": "v1", "created": "Wed, 12 Oct 2016 15:55:06 GMT"}, {"version": "v2", "created": "Mon, 17 Oct 2016 18:00:04 GMT"}, {"version": "v3", "created": "Wed, 22 Mar 2017 20:51:59 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Khan", "Shehroz S.", ""], ["Taati", "Babak", ""]]}, {"id": "1610.03957", "submitter": "Sourish Ghosh", "authors": "Sourish Ghosh, Aaditya Sanjay Boob, Nishant Nikhil, Nayan Raju\n  Vysyaraju, Ankit Kumar", "title": "A Fuzzy Logic System to Analyze a Student's Lifestyle", "comments": "To appear at ICACI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A college student's life can be primarily categorized into domains such as\neducation, health, social and other activities which may include daily chores\nand travelling time. Time management is crucial for every student. A self\nrealisation of one's daily time expenditure in various domains is therefore\nessential to maximize one's effective output. This paper presents how a mobile\napplication using Fuzzy Logic and Global Positioning System (GPS) analyzes a\nstudent's lifestyle and provides recommendations and suggestions based on the\nresults.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 07:14:34 GMT"}, {"version": "v2", "created": "Tue, 8 Nov 2016 17:06:34 GMT"}], "update_date": "2016-11-09", "authors_parsed": [["Ghosh", "Sourish", ""], ["Boob", "Aaditya Sanjay", ""], ["Nikhil", "Nishant", ""], ["Vysyaraju", "Nayan Raju", ""], ["Kumar", "Ankit", ""]]}, {"id": "1610.03996", "submitter": "Martin Wistuba", "authors": "Martin Wistuba, Nghia Duong-Trung, Nicolas Schilling, Lars\n  Schmidt-Thieme", "title": "Bank Card Usage Prediction Exploiting Geolocation Information", "comments": "Describes the winning solution for the ECML-PKDD 2016 Discovery\n  Challenge on Bank Card Usage Analysis. Final results on the private\n  leaderboard are available here:\n  https://dms.sztaki.hu/ecml-pkkd-2016/#/app/privateleaderboard", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the solution of team ISMLL for the ECML-PKDD 2016 Discovery\nChallenge on Bank Card Usage for both tasks. Our solution is based on three\npillars. Gradient boosted decision trees as a strong regression and\nclassification model, an intensive search for good hyperparameter\nconfigurations and strong features that exploit geolocation information. This\napproach achieved the best performance on the public leaderboard for the first\ntask and a decent fourth position for the second task.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 09:44:03 GMT"}], "update_date": "2016-10-14", "authors_parsed": [["Wistuba", "Martin", ""], ["Duong-Trung", "Nghia", ""], ["Schilling", "Nicolas", ""], ["Schmidt-Thieme", "Lars", ""]]}, {"id": "1610.04005", "submitter": "Konstantin Schekotihin", "authors": "Harald Beck and Bruno Bierbaumer and Minh Dao-Tran and Thomas Eiter\n  and Hermann Hellwagner and Konstantin Schekotihin", "title": "Stream Reasoning-Based Control of Caching Strategies in CCN Routers", "comments": "21 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Content-Centric Networking (CCN) research addresses the mismatch between the\nmodern usage of the Internet and its outdated architecture. Importantly, CCN\nrouters may locally cache frequently requested content in order to speed up\ndelivery to end users. Thus, the issue of caching strategies arises, i.e.,\nwhich content shall be stored and when it should be replaced. In this work, we\nemploy novel techniques towards intelligent administration of CCN routers that\nautonomously switch between existing strategies in response to changing content\nrequest patterns. In particular, we present a router architecture for CCN\nnetworks that is controlled by rule-based stream reasoning, following the\nrecent formal framework LARS which extends Answer Set Programming for streams.\nThe obtained possibility for flexible router configuration at runtime allows\nfor faster experimentation and may thus help to advance the further development\nof CCN. Moreover, the empirical evaluation of our feasibility study shows that\nthe resulting caching agent may give significant performance gains.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 10:08:37 GMT"}], "update_date": "2016-10-14", "authors_parsed": [["Beck", "Harald", ""], ["Bierbaumer", "Bruno", ""], ["Dao-Tran", "Minh", ""], ["Eiter", "Thomas", ""], ["Hellwagner", "Hermann", ""], ["Schekotihin", "Konstantin", ""]]}, {"id": "1610.04028", "submitter": "Arash Andalib", "authors": "Arash Andalib, Mehdi Zare, Farid Atry", "title": "A fuzzy expert system for earthquake prediction, case study: the Zagros\n  range", "comments": "4 pages, 4 figures in proceedings of the third International\n  Conference on Modeling, Simulation and Applied Optimization, 2009 Corrected\n  typos, added publication information, Corrected typo, Added publication\n  information", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A methodology for the development of a fuzzy expert system (FES) with\napplication to earthquake prediction is presented. The idea is to reproduce the\nperformance of a human expert in earthquake prediction. To do this, at the\nfirst step, rules provided by the human expert are used to generate a fuzzy\nrule base. These rules are then fed into an inference engine to produce a fuzzy\ninference system (FIS) and to infer the results. In this paper, we have used a\nSugeno type fuzzy inference system to build the FES. At the next step, the\nadaptive network-based fuzzy inference system (ANFIS) is used to refine the FES\nparameters and improve its performance. The proposed framework is then employed\nto attain the performance of a human expert used to predict earthquakes in the\nZagros area based on the idea of coupled earthquakes. While the prediction\nresults are promising in parts of the testing set, the general performance\nindicates that prediction methodology based on coupled earthquakes needs more\ninvestigation and more complicated reasoning procedure to yield satisfactory\npredictions.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 11:18:02 GMT"}, {"version": "v2", "created": "Wed, 17 May 2017 21:23:01 GMT"}], "update_date": "2017-05-19", "authors_parsed": [["Andalib", "Arash", ""], ["Zare", "Mehdi", ""], ["Atry", "Farid", ""]]}, {"id": "1610.04069", "submitter": "Shreyas Sekar", "authors": "Elliot Anshelevich and Shreyas Sekar", "title": "Truthful Mechanisms for Matching and Clustering in an Ordinal World", "comments": "To appear in the Proceedings of WINE 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study truthful mechanisms for matching and related problems in a partial\ninformation setting, where the agents' true utilities are hidden, and the\nalgorithm only has access to ordinal preference information. Our model is\nmotivated by the fact that in many settings, agents cannot express the\nnumerical values of their utility for different outcomes, but are still able to\nrank the outcomes in their order of preference. Specifically, we study problems\nwhere the ground truth exists in the form of a weighted graph of agent\nutilities, but the algorithm can only elicit the agents' private information in\nthe form of a preference ordering for each agent induced by the underlying\nweights. Against this backdrop, we design truthful algorithms to approximate\nthe true optimum solution with respect to the hidden weights. Our techniques\nyield universally truthful algorithms for a number of graph problems: a\n1.76-approximation algorithm for Max-Weight Matching, 2-approximation algorithm\nfor Max k-matching, a 6-approximation algorithm for Densest k-subgraph, and a\n2-approximation algorithm for Max Traveling Salesman as long as the hidden\nweights constitute a metric. We also provide improved approximation algorithms\nfor such problems when the agents are not able to lie about their preferences.\nOur results are the first non-trivial truthful approximation algorithms for\nthese problems, and indicate that in many situations, we can design robust\nalgorithms even when the agents may lie and only provide ordinal information\ninstead of precise utilities.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 13:26:35 GMT"}, {"version": "v2", "created": "Tue, 18 Oct 2016 22:56:45 GMT"}], "update_date": "2016-10-20", "authors_parsed": [["Anshelevich", "Elliot", ""], ["Sekar", "Shreyas", ""]]}, {"id": "1610.04073", "submitter": "Wenhao Huang", "authors": "Wenhao Huang, Ge Li, Zhi Jin", "title": "Improved Knowledge Base Completion by Path-Augmented TransR Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge base completion aims to infer new relations from existing\ninformation. In this paper, we propose path-augmented TransR (PTransR) model to\nimprove the accuracy of link prediction. In our approach, we base PTransR model\non TransR, which is the best one-hop model at present. Then we regularize\nTransR with information of relation paths. In our experiment, we evaluate\nPTransR on the task of entity prediction. Experimental results show that\nPTransR outperforms previous models.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 08:34:15 GMT"}], "update_date": "2016-10-14", "authors_parsed": [["Huang", "Wenhao", ""], ["Li", "Ge", ""], ["Jin", "Zhi", ""]]}, {"id": "1610.04120", "submitter": "Lina Rojas-Barahona", "authors": "Lina M. Rojas Barahona, Milica Gasic, Nikola Mrk\\v{s}i\\'c, Pei-Hao Su,\n  Stefan Ultes, Tsung-Hsien Wen and Steve Young", "title": "Exploiting Sentence and Context Representations in Deep Neural Models\n  for Spoken Language Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a deep learning architecture for the semantic decoder\ncomponent of a Statistical Spoken Dialogue System. In a slot-filling dialogue,\nthe semantic decoder predicts the dialogue act and a set of slot-value pairs\nfrom a set of n-best hypotheses returned by the Automatic Speech Recognition.\nMost current models for spoken language understanding assume (i) word-aligned\nsemantic annotations as in sequence taggers and (ii) delexicalisation, or a\nmapping of input words to domain-specific concepts using heuristics that try to\ncapture morphological variation but that do not scale to other domains nor to\nlanguage variation (e.g., morphology, synonyms, paraphrasing ). In this work\nthe semantic decoder is trained using unaligned semantic annotations and it\nuses distributed semantic representation learning to overcome the limitations\nof explicit delexicalisation. The proposed architecture uses a convolutional\nneural network for the sentence representation and a long-short term memory\nnetwork for the context representation. Results are presented for the publicly\navailable DSTC2 corpus and an In-car corpus which is similar to DSTC2 but has a\nsignificantly higher word error rate (WER).\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 15:11:40 GMT"}], "update_date": "2016-10-14", "authors_parsed": [["Barahona", "Lina M. Rojas", ""], ["Gasic", "Milica", ""], ["Mrk\u0161i\u0107", "Nikola", ""], ["Su", "Pei-Hao", ""], ["Ultes", "Stefan", ""], ["Wen", "Tsung-Hsien", ""], ["Young", "Steve", ""]]}, {"id": "1610.04154", "submitter": "Sergio Ram\\'irez-Gallego", "authors": "Sergio Ram\\'irez-Gallego, H\\'ector Mouri\\~no-Tal\\'in, David\n  Mart\\'inez-Rego, Ver\\'onica Bol\\'on-Canedo, Jos\\'e Manuel Ben\\'itez, Amparo\n  Alonso-Betanzos, Francisco Herrera", "title": "An Information Theoretic Feature Selection Framework for Big Data under\n  Apache Spark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of extremely high dimensional datasets, dimensionality\nreduction techniques are becoming mandatory. Among many techniques, feature\nselection has been growing in interest as an important tool to identify\nrelevant features on huge datasets --both in number of instances and\nfeatures--. The purpose of this work is to demonstrate that standard feature\nselection methods can be parallelized in Big Data platforms like Apache Spark,\nboosting both performance and accuracy. We thus propose a distributed\nimplementation of a generic feature selection framework which includes a wide\ngroup of well-known Information Theoretic methods. Experimental results on a\nwide set of real-world datasets show that our distributed framework is capable\nof dealing with ultra-high dimensional datasets as well as those with a huge\nnumber of samples in a short period of time, outperforming the sequential\nversion in all the cases studied.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 16:17:07 GMT"}, {"version": "v2", "created": "Wed, 19 Oct 2016 16:46:28 GMT"}], "update_date": "2016-10-20", "authors_parsed": [["Ram\u00edrez-Gallego", "Sergio", ""], ["Mouri\u00f1o-Tal\u00edn", "H\u00e9ctor", ""], ["Mart\u00ednez-Rego", "David", ""], ["Bol\u00f3n-Canedo", "Ver\u00f3nica", ""], ["Ben\u00edtez", "Jos\u00e9 Manuel", ""], ["Alonso-Betanzos", "Amparo", ""], ["Herrera", "Francisco", ""]]}, {"id": "1610.04213", "submitter": "Konstantinos Chatzilygeroudis", "authors": "Konstantinos Chatzilygeroudis, Vassilis Vassiliades, Jean-Baptiste\n  Mouret", "title": "Reset-free Trial-and-Error Learning for Robot Damage Recovery", "comments": "18 pages, 16 figures, 3 tables, 6 pseudocodes/algorithms, video at\n  https://youtu.be/IqtyHFrb3BU, code at\n  https://github.com/resibots/chatzilygeroudis_2018_rte", "journal-ref": null, "doi": "10.1016/j.robot.2017.11.010", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The high probability of hardware failures prevents many advanced robots\n(e.g., legged robots) from being confidently deployed in real-world situations\n(e.g., post-disaster rescue). Instead of attempting to diagnose the failures,\nrobots could adapt by trial-and-error in order to be able to complete their\ntasks. In this situation, damage recovery can be seen as a Reinforcement\nLearning (RL) problem. However, the best RL algorithms for robotics require the\nrobot and the environment to be reset to an initial state after each episode,\nthat is, the robot is not learning autonomously. In addition, most of the RL\nmethods for robotics do not scale well with complex robots (e.g., walking\nrobots) and either cannot be used at all or take too long to converge to a\nsolution (e.g., hours of learning). In this paper, we introduce a novel\nlearning algorithm called \"Reset-free Trial-and-Error\" (RTE) that (1) breaks\nthe complexity by pre-generating hundreds of possible behaviors with a dynamics\nsimulator of the intact robot, and (2) allows complex robots to quickly recover\nfrom damage while completing their tasks and taking the environment into\naccount. We evaluate our algorithm on a simulated wheeled robot, a simulated\nsix-legged robot, and a real six-legged walking robot that are damaged in\nseveral ways (e.g., a missing leg, a shortened leg, faulty motor, etc.) and\nwhose objective is to reach a sequence of targets in an arena. Our experiments\nshow that the robots can recover most of their locomotion abilities in an\nenvironment with obstacles, and without any human intervention.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 19:39:58 GMT"}, {"version": "v2", "created": "Wed, 12 Apr 2017 23:08:17 GMT"}, {"version": "v3", "created": "Thu, 23 Nov 2017 10:55:03 GMT"}, {"version": "v4", "created": "Tue, 12 Dec 2017 08:02:31 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Chatzilygeroudis", "Konstantinos", ""], ["Vassiliades", "Vassilis", ""], ["Mouret", "Jean-Baptiste", ""]]}, {"id": "1610.04325", "submitter": "Jin-Hwa Kim", "authors": "Jin-Hwa Kim, Kyoung-Woon On, Woosang Lim, Jeonghee Kim, Jung-Woo Ha,\n  Byoung-Tak Zhang", "title": "Hadamard Product for Low-rank Bilinear Pooling", "comments": "13 pages, 1 figure, & appendix. ICLR 2017 accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bilinear models provide rich representations compared with linear models.\nThey have been applied in various visual tasks, such as object recognition,\nsegmentation, and visual question-answering, to get state-of-the-art\nperformances taking advantage of the expanded representations. However,\nbilinear representations tend to be high-dimensional, limiting the\napplicability to computationally complex tasks. We propose low-rank bilinear\npooling using Hadamard product for an efficient attention mechanism of\nmultimodal learning. We show that our model outperforms compact bilinear\npooling in visual question-answering tasks with the state-of-the-art results on\nthe VQA dataset, having a better parsimonious property.\n", "versions": [{"version": "v1", "created": "Fri, 14 Oct 2016 04:29:52 GMT"}, {"version": "v2", "created": "Tue, 1 Nov 2016 05:31:27 GMT"}, {"version": "v3", "created": "Tue, 14 Feb 2017 05:22:01 GMT"}, {"version": "v4", "created": "Sun, 26 Mar 2017 16:22:47 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Kim", "Jin-Hwa", ""], ["On", "Kyoung-Woon", ""], ["Lim", "Woosang", ""], ["Kim", "Jeonghee", ""], ["Ha", "Jung-Woo", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1610.04416", "submitter": "Dimitri Kartsaklis", "authors": "Dimitri Kartsaklis, Mehrnoosh Sadrzadeh", "title": "Distributional Inclusion Hypothesis for Tensor-based Composition", "comments": "To appear in COLING 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  According to the distributional inclusion hypothesis, entailment between\nwords can be measured via the feature inclusions of their distributional\nvectors. In recent work, we showed how this hypothesis can be extended from\nwords to phrases and sentences in the setting of compositional distributional\nsemantics. This paper focuses on inclusion properties of tensors; its main\ncontribution is a theoretical and experimental analysis of how feature\ninclusion works in different concrete models of verb tensors. We present\nresults for relational, Frobenius, projective, and holistic methods and compare\nthem to the simple vector addition, multiplication, min, and max models. The\ndegrees of entailment thus obtained are evaluated via a variety of existing\nword-based measures, such as Weed's and Clarke's, KL-divergence, APinc,\nbalAPinc, and two of our previously proposed metrics at the phrase/sentence\nlevel. We perform experiments on three entailment datasets, investigating which\nversion of tensor-based composition achieves the highest performance when\ncombined with the sentence-level measures.\n", "versions": [{"version": "v1", "created": "Fri, 14 Oct 2016 11:52:19 GMT"}], "update_date": "2016-10-17", "authors_parsed": [["Kartsaklis", "Dimitri", ""], ["Sadrzadeh", "Mehrnoosh", ""]]}, {"id": "1610.04494", "submitter": "Shiu Kumar", "authors": "Shiu Kumar, Ronesh Sharma, Edwin Vans", "title": "Localization for Wireless Sensor Networks: A Neural Network Approach", "comments": "11 pages, 7 figures, 1 table, IJCNC", "journal-ref": "International Journal of Computer Networks & Communications\n  (IJCNC), vol. 8, pp. 61-71, January 2016", "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Wireless Sensor Networks are penetrating into the industrial domain, many\nresearch opportunities are emerging. One such essential and challenging\napplication is that of node localization. A feed-forward neural network based\nmethodology is adopted in this paper. The Received Signal Strength Indicator\n(RSSI) values of the anchor node beacons are used. The number of anchor nodes\nand their configurations has an impact on the accuracy of the localization\nsystem, which is also addressed in this paper. Five different training\nalgorithms are evaluated to find the training algorithm that gives the best\nresult. The multi-layer Perceptron (MLP) neural network model was trained using\nMatlab. In order to evaluate the performance of the proposed method in real\ntime, the model obtained was then implemented on the Arduino microcontroller.\nWith four anchor nodes, an average 2D localization error of 0.2953 m has been\nachieved with a 12-12-2 neural network structure. The proposed method can also\nbe implemented on any other embedded microcontroller system.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2016 19:28:08 GMT"}], "update_date": "2016-10-17", "authors_parsed": [["Kumar", "Shiu", ""], ["Sharma", "Ronesh", ""], ["Vans", "Edwin", ""]]}, {"id": "1610.04574", "submitter": "Jure Sokolic", "authors": "Jure Sokolic, Raja Giryes, Guillermo Sapiro, Miguel R. D. Rodrigues", "title": "Generalization Error of Invariant Classifiers", "comments": "Accepted to AISTATS. This version has updated references", "journal-ref": "Conference on Artificial Intelligence and Statistics (AISTATS),\n  2017, pp. 1094-1103", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the generalization error of invariant classifiers. In\nparticular, we consider the common scenario where the classification task is\ninvariant to certain transformations of the input, and that the classifier is\nconstructed (or learned) to be invariant to these transformations. Our approach\nrelies on factoring the input space into a product of a base space and a set of\ntransformations. We show that whereas the generalization error of a\nnon-invariant classifier is proportional to the complexity of the input space,\nthe generalization error of an invariant classifier is proportional to the\ncomplexity of the base space. We also derive a set of sufficient conditions on\nthe geometry of the base space and the set of transformations that ensure that\nthe complexity of the base space is much smaller than the complexity of the\ninput space. Our analysis applies to general classifiers such as convolutional\nneural networks. We demonstrate the implications of the developed theory for\nsuch classifiers with experiments on the MNIST and CIFAR-10 datasets.\n", "versions": [{"version": "v1", "created": "Fri, 14 Oct 2016 18:40:52 GMT"}, {"version": "v2", "created": "Tue, 23 May 2017 11:32:03 GMT"}, {"version": "v3", "created": "Sun, 2 Jul 2017 18:58:21 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Sokolic", "Jure", ""], ["Giryes", "Raja", ""], ["Sapiro", "Guillermo", ""], ["Rodrigues", "Miguel R. D.", ""]]}, {"id": "1610.04631", "submitter": "Shuai Zheng", "authors": "Shuai Zheng, Feiping Nie, Chris Ding, Heng Huang", "title": "A Harmonic Mean Linear Discriminant Analysis for Robust Image\n  Classification", "comments": "IEEE 28th International Conference on Tools with Artificial\n  Intelligence, ICTAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear Discriminant Analysis (LDA) is a widely-used supervised dimensionality\nreduction method in computer vision and pattern recognition. In null space\nbased LDA (NLDA), a well-known LDA extension, between-class distance is\nmaximized in the null space of the within-class scatter matrix. However, there\nare some limitations in NLDA. Firstly, for many data sets, null space of\nwithin-class scatter matrix does not exist, thus NLDA is not applicable to\nthose datasets. Secondly, NLDA uses arithmetic mean of between-class distances\nand gives equal consideration to all between-class distances, which makes\nlarger between-class distances can dominate the result and thus limits the\nperformance of NLDA. In this paper, we propose a harmonic mean based Linear\nDiscriminant Analysis, Multi-Class Discriminant Analysis (MCDA), for image\nclassification, which minimizes the reciprocal of weighted harmonic mean of\npairwise between-class distance. More importantly, MCDA gives higher priority\nto maximize small between-class distances. MCDA can be extended to multi-label\ndimension reduction. Results on 7 single-label data sets and 4 multi-label data\nsets show that MCDA has consistently better performance than 10 other\nsingle-label approaches and 4 other multi-label approaches in terms of\nclassification accuracy, macro and micro average F1 score.\n", "versions": [{"version": "v1", "created": "Fri, 14 Oct 2016 20:36:57 GMT"}, {"version": "v2", "created": "Mon, 24 Oct 2016 16:38:29 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Zheng", "Shuai", ""], ["Nie", "Feiping", ""], ["Ding", "Chris", ""], ["Huang", "Heng", ""]]}, {"id": "1610.04850", "submitter": "Alexander Fonarev", "authors": "Alexander Fonarev, Alexander Mikhalev, Pavel Serdyukov, Gleb Gusev,\n  Ivan Oseledets", "title": "Efficient Rectangular Maximal-Volume Algorithm for Rating Elicitation in\n  Collaborative Filtering", "comments": "IEEE International Conference on Data Mining (ICDM) 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cold start problem in Collaborative Filtering can be solved by asking new\nusers to rate a small seed set of representative items or by asking\nrepresentative users to rate a new item. The question is how to build a seed\nset that can give enough preference information for making good\nrecommendations. One of the most successful approaches, called Representative\nBased Matrix Factorization, is based on Maxvol algorithm. Unfortunately, this\napproach has one important limitation --- a seed set of a particular size\nrequires a rating matrix factorization of fixed rank that should coincide with\nthat size. This is not necessarily optimal in the general case. In the current\npaper, we introduce a fast algorithm for an analytical generalization of this\napproach that we call Rectangular Maxvol. It allows the rank of factorization\nto be lower than the required size of the seed set. Moreover, the paper\nincludes the theoretical analysis of the method's error, the complexity\nanalysis of the existing methods and the comparison to the state-of-the-art\napproaches.\n", "versions": [{"version": "v1", "created": "Sun, 16 Oct 2016 12:50:37 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Fonarev", "Alexander", ""], ["Mikhalev", "Alexander", ""], ["Serdyukov", "Pavel", ""], ["Gusev", "Gleb", ""], ["Oseledets", "Ivan", ""]]}, {"id": "1610.04872", "submitter": "Bodhisattwa Majumder", "authors": "Bodhisattwa Prasad Majumder, Ayan Sengupta, Sajal jain, Parikshit\n  Bhaduri", "title": "Fault Detection Engine in Intelligent Predictive Analytics Platform for\n  DCIM", "comments": "Accepted in 4th International Conference on Business Analytics and\n  Intelligence (ICBAI 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advancement of huge data generation and data handling capability,\nMachine Learning and Probabilistic modelling enables an immense opportunity to\nemploy predictive analytics platform in high security critical industries\nnamely data centers, electricity grids, utilities, airport etc. where downtime\nminimization is one of the primary objectives. This paper proposes a novel,\ncomplete architecture of an intelligent predictive analytics platform, Fault\nEngine, for huge device network connected with electrical/information flow.\nThree unique modules, here proposed, seamlessly integrate with available\ntechnology stack of data handling and connect with middleware to produce online\nintelligent prediction in critical failure scenarios. The Markov Failure module\npredicts the severity of a failure along with survival probability of a device\nat any given instances. The Root Cause Analysis model indicates probable\ndevices as potential root cause employing Bayesian probability assignment and\ntopological sort. Finally, a community detection algorithm produces correlated\nclusters of device in terms of failure probability which will further narrow\ndown the search space of finding route cause. The whole Engine has been tested\nwith different size of network with simulated failure environments and shows\nits potential to be scalable in real-time implementation.\n", "versions": [{"version": "v1", "created": "Sun, 16 Oct 2016 15:14:36 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Majumder", "Bodhisattwa Prasad", ""], ["Sengupta", "Ayan", ""], ["jain", "Sajal", ""], ["Bhaduri", "Parikshit", ""]]}, {"id": "1610.04964", "submitter": "Pavel Surynek", "authors": "Pavel Surynek, Petr Michal\\'ik", "title": "Improvements in Sub-optimal Solving of the $(N^2-1)$-Puzzle via Joint\n  Relocation of Pebbles and its Applications to Rule-based Cooperative\n  Path-Finding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of solving $(n^2-1)$-puzzle and cooperative path-finding (CPF)\nsub-optimally by rule based algorithms is addressed in this manuscript. The\ntask in the puzzle is to rearrange $n^2-1$ pebbles on the square grid of the\nsize of n x n using one vacant position to a desired goal configuration. An\nimprovement to the existent polynomial-time algorithm is proposed and\nexperimentally analyzed. The improved algorithm is trying to move pebbles in a\nmore efficient way than the original algorithm by grouping them into so-called\nsnakes and moving them jointly within the snake. An experimental evaluation\nshowed that the algorithm using snakes produces solutions that are 8% to 9%\nshorter than solutions generated by the original algorithm.\n  The snake-based relocation has been also integrated into rule-based\nalgorithms for solving the CPF problem sub-optimally, which is a closely\nrelated task. The task in CPF is to relocate a group of abstract robots that\nmove over an undirected graph to given goal vertices. Robots can move to\nunoccupied neighboring vertices and at most one robot can be placed in each\nvertex. The $(n^2-1)$-puzzle is a special case of CPF where the underlying\ngraph is represented by a 4-connected grid and there is only one vacant vertex.\nTwo major rule-based algorithms for CPF were included in our study - BIBOX and\nPUSH-and-SWAP (PUSH-and-ROTATE). Improvements gained by using snakes in the\nBIBOX algorithm were stable around 30% in $(n^2-1)$-puzzle solving and up to\n50% in CPFs over bi-connected graphs with various ear decompositions and\nmultiple vacant vertices. In the case of the PUSH-and-SWAP algorithm the\nimprovement achieved by snakes was around 5% to 8%. However, the improvement\nwas unstable and hardly predictable in the case of PUSH-and-SWAP.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 03:29:42 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Surynek", "Pavel", ""], ["Michal\u00edk", "Petr", ""]]}, {"id": "1610.05009", "submitter": "Saurav Gupta", "authors": "Saurav Gupta, Nitin Anand Shrivastava, Abbas Khosravi, Bijaya Ketan\n  Panigrahi", "title": "Wind ramp event prediction with parallelized Gradient Boosted Regression\n  Trees", "comments": "IJCNN 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Accurate prediction of wind ramp events is critical for ensuring the\nreliability and stability of the power systems with high penetration of wind\nenergy. This paper proposes a classification based approach for estimating the\nfuture class of wind ramp event based on certain thresholds. A parallelized\ngradient boosted regression tree based technique has been proposed to\naccurately classify the normal as well as rare extreme wind power ramp events.\nThe model has been validated using wind power data obtained from the National\nRenewable Energy Laboratory database. Performance comparison with several\nbenchmark techniques indicates the superiority of the proposed technique in\nterms of superior classification accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 08:29:57 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Gupta", "Saurav", ""], ["Shrivastava", "Nitin Anand", ""], ["Khosravi", "Abbas", ""], ["Panigrahi", "Bijaya Ketan", ""]]}, {"id": "1610.05016", "submitter": "Andrew Palmer", "authors": "Andrew W. Palmer, Robin Vujanic, Andrew J. Hill, Steven J. Scheding", "title": "Weekly maintenance scheduling using exact and genetic methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The weekly maintenance schedule specifies when maintenance activities should\nbe performed on the equipment, taking into account the availability of workers\nand maintenance bays, and other operational constraints. The current approach\nto generating this schedule is labour intensive and requires coordination\nbetween the maintenance schedulers and operations staff to minimise its impact\non the operation of the mine. This paper presents methods for automatically\ngenerating this schedule from the list of maintenance tasks to be performed,\nthe availability roster of the maintenance staff, and time windows in which\neach piece of equipment is available for maintenance. Both Mixed-Integer Linear\nProgramming (MILP) and genetic algorithms are evaluated, with the genetic\nalgorithm shown to significantly outperform the MILP. Two fitness functions for\nthe genetic algorithm are also examined, with a linear fitness function\noutperforming an inverse fitness function by up to 5% for the same calculation\ntime. The genetic algorithm approach is computationally fast, allowing the\nschedule to be rapidly recalculated in response to unexpected delays and\nbreakdowns.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 08:54:47 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Palmer", "Andrew W.", ""], ["Vujanic", "Robin", ""], ["Hill", "Andrew J.", ""], ["Scheding", "Steven J.", ""]]}, {"id": "1610.05182", "submitter": "Nicolas Heess", "authors": "Nicolas Heess, Greg Wayne, Yuval Tassa, Timothy Lillicrap, Martin\n  Riedmiller, David Silver", "title": "Learning and Transfer of Modulated Locomotor Controllers", "comments": "Supplemental video available at https://youtu.be/sboPYvhpraQ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a novel architecture and training procedure for locomotion tasks. A\nhigh-frequency, low-level \"spinal\" network with access to proprioceptive\nsensors learns sensorimotor primitives by training on simple tasks. This\npre-trained module is fixed and connected to a low-frequency, high-level\n\"cortical\" network, with access to all sensors, which drives behavior by\nmodulating the inputs to the spinal network. Where a monolithic end-to-end\narchitecture fails completely, learning with a pre-trained spinal module\nsucceeds at multiple high-level tasks, and enables the effective exploration\nrequired to learn from sparse rewards. We test our proposed architecture on\nthree simulated bodies: a 16-dimensional swimming snake, a 20-dimensional\nquadruped, and a 54-dimensional humanoid. Our results are illustrated in the\naccompanying video at https://youtu.be/sboPYvhpraQ\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 16:03:42 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Heess", "Nicolas", ""], ["Wayne", "Greg", ""], ["Tassa", "Yuval", ""], ["Lillicrap", "Timothy", ""], ["Riedmiller", "Martin", ""], ["Silver", "David", ""]]}, {"id": "1610.05202", "submitter": "Aur\\'elien Bellet", "authors": "Paul Vanhaesebrouck, Aur\\'elien Bellet, Marc Tommasi", "title": "Decentralized Collaborative Learning of Personalized Models over\n  Networks", "comments": "To appear in the Proceedings of the 20th International Conference on\n  Artificial Intelligence and Statistics (AISTATS 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a set of learning agents in a collaborative peer-to-peer network,\nwhere each agent learns a personalized model according to its own learning\nobjective. The question addressed in this paper is: how can agents improve upon\ntheir locally trained model by communicating with other agents that have\nsimilar objectives? We introduce and analyze two asynchronous gossip algorithms\nrunning in a fully decentralized manner. Our first approach, inspired from\nlabel propagation, aims to smooth pre-trained local models over the network\nwhile accounting for the confidence that each agent has in its initial model.\nIn our second approach, agents jointly learn and propagate their model by\nmaking iterative updates based on both their local dataset and the behavior of\ntheir neighbors. To optimize this challenging objective, our decentralized\nalgorithm is based on ADMM.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 16:51:49 GMT"}, {"version": "v2", "created": "Wed, 15 Feb 2017 18:32:17 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Vanhaesebrouck", "Paul", ""], ["Bellet", "Aur\u00e9lien", ""], ["Tommasi", "Marc", ""]]}, {"id": "1610.05287", "submitter": "Jun Xu", "authors": "Jun Xu, Gurkan Solmaz, Rouhollah Rahmatizadeh, Damla Turgut, and\n  Ladislau Boloni", "title": "Internet of Things Applications: Animal Monitoring with Unmanned Aerial\n  Vehicle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In animal monitoring applications, both animal detection and their movement\nprediction are major tasks. While a variety of animal monitoring strategies\nexist, most of them rely on mounting devices. However, in real world, it is\ndifficult to find these animals and install mounting devices. In this paper, we\npropose an animal monitoring application by utilizing wireless sensor networks\n(WSNs) and unmanned aerial vehicle (UAV). The objective of the application is\nto detect locations of endangered species in large-scale wildlife areas and\nmonitor movement of animals without any attached devices. In this application,\nsensors deployed throughout the observation area are responsible for gathering\nanimal information. The UAV flies above the observation area and collects the\ninformation from sensors. To achieve the information efficiently, we propose a\npath planning approach for the UAV based on a Markov decision process (MDP)\nmodel. The UAV receives a certain amount of reward from an area if some animals\nare detected at that location. We solve the MDP using Q-learning such that the\nUAV prefers going to those areas that animals are detected before. Meanwhile,\nthe UAV explores other areas as well to cover the entire network and detects\nchanges in the animal positions. We first define the mathematical model\nunderlying the animal monitoring problem in terms of the value of information\n(VoI) and rewards. We propose a network model including clusters of sensor\nnodes and a single UAV that acts as a mobile sink and visits the clusters.\nThen, one MDP-based path planning approach is designed to maximize the VoI\nwhile reducing message delays. The effectiveness of the proposed approach is\nevaluated using two real-world movement datasets of zebras and leopard.\nSimulation results show that our approach outperforms greedy, random heuristics\nand the path planning based on the traveling salesman problem.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 19:39:23 GMT"}, {"version": "v2", "created": "Thu, 20 Oct 2016 20:24:58 GMT"}], "update_date": "2016-10-24", "authors_parsed": [["Xu", "Jun", ""], ["Solmaz", "Gurkan", ""], ["Rahmatizadeh", "Rouhollah", ""], ["Turgut", "Damla", ""], ["Boloni", "Ladislau", ""]]}, {"id": "1610.05402", "submitter": "Luis Meira", "authors": "Guilherme A. Zeni, Mauro Menzori, P. S. Martins, Luis A. A. Meira", "title": "VRPBench: A Vehicle Routing Benchmark Tool", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of optimization techniques in the combinatorial domain is large\nand diversified. Nevertheless, there is still a lack of real benchmarks to\nvalidate optimization algorithms. In this work we introduce VRPBench, a tool to\ncreate instances and visualize solutions to the Vehicle Routing Problem (VRP)\nin a planar graph embedded in the Euclidean 2D space. We use VRPBench to model\na real-world mail delivery case of the city of Artur Nogueira. Such scenarios\nwere characterized as a multi-objective optimization of the VRP. We extracted a\nweighted graph from a digital map of the city to create a challenging benchmark\nfor the VRP. Each instance models one generic day of mail delivery with\nhundreds to thousands of delivery points, thus allowing both the comparison and\nvalidation of optimization algorithms for routing problems.\n", "versions": [{"version": "v1", "created": "Tue, 18 Oct 2016 02:01:16 GMT"}], "update_date": "2016-10-19", "authors_parsed": [["Zeni", "Guilherme A.", ""], ["Menzori", "Mauro", ""], ["Martins", "P. S.", ""], ["Meira", "Luis A. A.", ""]]}, {"id": "1610.05452", "submitter": "Pavel Surynek", "authors": "Pavel Surynek", "title": "Makespan Optimal Solving of Cooperative Path-Finding via Reductions to\n  Propositional Satisfiability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of makespan optimal solving of cooperative path finding (CPF) is\naddressed in this paper. The task in CPF is to relocate a group of agents in a\nnon-colliding way so that each agent eventually reaches its goal location from\nthe given initial location. The abstraction adopted in this work assumes that\nagents are discrete items moving in an undirected graph by traversing edges.\nMakespan optimal solving of CPF means to generate solutions that are as short\nas possi-ble in terms of the total number of time steps required for the\nexecution of the solution.\n  We show that reducing CPF to propositional satisfiability (SAT) represents a\nviable option for obtaining makespan optimal solutions. Several encodings of\nCPF into propositional formulae are suggested and experimentally evaluated. The\nevaluation indicates that SAT based CPF solving outperforms other makespan\noptimal methods significantly in highly constrained situations (environments\nthat are densely occupied by agents).\n", "versions": [{"version": "v1", "created": "Tue, 18 Oct 2016 06:42:45 GMT"}], "update_date": "2016-10-19", "authors_parsed": [["Surynek", "Pavel", ""]]}, {"id": "1610.05521", "submitter": "Gianni D'Angelo", "authors": "Gianni D'Angelo, Salvatore Rampone", "title": "Diagnosis of aerospace structure defects by a HPC implemented soft\n  computing algorithm", "comments": "5 pages, IEEE International Workshop on Metrology for Aerospace", "journal-ref": "IEEE International Workshop on Metrology for Aerospace, Benevento,\n  Italy, May 29-30, 2014", "doi": "10.1109/MetroAeroSpace.2014.6865959", "report-no": null, "categories": "cs.AI physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study concerns with the diagnosis of aerospace structure defects by\napplying a HPC parallel implementation of a novel learning algorithm, named\nU-BRAIN. The Soft Computing approach allows advanced multi-parameter data\nprocessing in composite materials testing. The HPC parallel implementation\novercomes the limits due to the great amount of data and the complexity of data\nprocessing. Our experimental results illustrate the effectiveness of the\nU-BRAIN parallel implementation as defect classifier in aerospace structures.\nThe resulting system is implemented on a Linux-based cluster with multi-core\narchitecture.\n", "versions": [{"version": "v1", "created": "Tue, 18 Oct 2016 10:12:29 GMT"}], "update_date": "2016-10-19", "authors_parsed": [["D'Angelo", "Gianni", ""], ["Rampone", "Salvatore", ""]]}, {"id": "1610.05551", "submitter": "Giso Dal", "authors": "Giso H. Dal and Peter J.F. Lucas", "title": "Weighted Positive Binary Decision Diagrams for Exact Probabilistic\n  Inference", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on weighted model counting has been very successfully applied to\nthe problem of probabilistic inference in Bayesian networks. The probability\ndistribution is encoded into a Boolean normal form and compiled to a target\nlanguage, in order to represent local structure expressed among conditional\nprobabilities more efficiently. We show that further improvements are possible,\nby exploiting the knowledge that is lost during the encoding phase and\nincorporating it into a compiler inspired by Satisfiability Modulo Theories.\nConstraints among variables are used as a background theory, which allows us to\noptimize the Shannon decomposition. We propose a new language, called Weighted\nPositive Binary Decision Diagrams, that reduces the cost of probabilistic\ninference by using this decomposition variant to induce an arithmetic circuit\nof reduced size.\n", "versions": [{"version": "v1", "created": "Tue, 18 Oct 2016 11:58:28 GMT"}], "update_date": "2016-10-19", "authors_parsed": [["Dal", "Giso H.", ""], ["Lucas", "Peter J. F.", ""]]}, {"id": "1610.05556", "submitter": "Marta Arias", "authors": "Gilles Blondel and Marta Arias and Ricard Gavald\\`a", "title": "Identifiability and Transportability in Dynamic Causal Networks", "comments": "Presented at the 2016 ACM SIGKDD Workshop on Causal Discovery", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a causal analog to the purely observational Dynamic\nBayesian Networks, which we call Dynamic Causal Networks. We provide a sound\nand complete algorithm for identification of Dynamic Causal Net- works, namely,\nfor computing the effect of an intervention or experiment, based on passive\nobservations only, whenever possible. We note the existence of two types of\nconfounder variables that affect in substantially different ways the iden-\ntification procedures, a distinction with no analog in either Dynamic Bayesian\nNetworks or standard causal graphs. We further propose a procedure for the\ntransportability of causal effects in Dynamic Causal Network settings, where\nthe re- sult of causal experiments in a source domain may be used for the\nidentification of causal effects in a target domain.\n", "versions": [{"version": "v1", "created": "Tue, 18 Oct 2016 12:07:03 GMT"}], "update_date": "2016-10-19", "authors_parsed": [["Blondel", "Gilles", ""], ["Arias", "Marta", ""], ["Gavald\u00e0", "Ricard", ""]]}, {"id": "1610.05612", "submitter": "Zhe Xu", "authors": "Zhe Xu and Agung Julius", "title": "Census Signal Temporal Logic Inference for Multi-Agent Group Behavior\n  Analysis", "comments": "26 pages, 5 figures", "journal-ref": null, "doi": "10.1109/TASE.2016.2611536", "report-no": null, "categories": "cs.AI cs.MA math.LO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we define a novel census signal temporal logic (CensusSTL)\nthat focuses on the number of agents in different subsets of a group that\ncomplete a certain task specified by the signal temporal logic (STL). CensusSTL\nconsists of an \"inner logic\" STL formula and an \"outer logic\" STL formula. We\npresent a new inference algorithm to infer CensusSTL formulae from the\ntrajectory data of a group of agents. We first identify the \"inner logic\" STL\nformula and then infer the subgroups based on whether the agents' behaviors\nsatisfy the \"inner logic\" formula at each time point. We use two different\napproaches to infer the subgroups based on similarity and complementarity,\nrespectively. The \"outer logic\" CensusSTL formula is inferred from the census\ntrajectories of different subgroups. We apply the algorithm in analyzing data\nfrom a soccer match by inferring the CensusSTL formula for different subgroups\nof a soccer team.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2016 14:27:20 GMT"}], "update_date": "2016-10-19", "authors_parsed": [["Xu", "Zhe", ""], ["Julius", "Agung", ""]]}, {"id": "1610.05688", "submitter": "Pranay Dighe", "authors": "Pranay Dighe, Afsaneh Asaei and Herve Bourlard", "title": "Low-rank and Sparse Soft Targets to Learn Better DNN Acoustic Models", "comments": null, "journal-ref": null, "doi": "10.1109/ICASSP.2017.7953161", "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional deep neural networks (DNN) for speech acoustic modeling rely on\nGaussian mixture models (GMM) and hidden Markov model (HMM) to obtain binary\nclass labels as the targets for DNN training. Subword classes in speech\nrecognition systems correspond to context-dependent tied states or senones. The\npresent work addresses some limitations of GMM-HMM senone alignments for DNN\ntraining. We hypothesize that the senone probabilities obtained from a DNN\ntrained with binary labels can provide more accurate targets to learn better\nacoustic models. However, DNN outputs bear inaccuracies which are exhibited as\nhigh dimensional unstructured noise, whereas the informative components are\nstructured and low-dimensional. We exploit principle component analysis (PCA)\nand sparse coding to characterize the senone subspaces. Enhanced probabilities\nobtained from low-rank and sparse reconstructions are used as soft-targets for\nDNN acoustic modeling, that also enables training with untranscribed data.\nExperiments conducted on AMI corpus shows 4.6% relative reduction in word error\nrate.\n", "versions": [{"version": "v1", "created": "Tue, 18 Oct 2016 16:02:10 GMT"}], "update_date": "2017-09-07", "authors_parsed": [["Dighe", "Pranay", ""], ["Asaei", "Afsaneh", ""], ["Bourlard", "Herve", ""]]}, {"id": "1610.05716", "submitter": "Richard Preen", "authors": "Richard J. Preen, Jiseon You, Larry Bull, and Ioannis A. Ieropoulos", "title": "Design Mining Microbial Fuel Cell Cascades", "comments": null, "journal-ref": "Soft Computing (2019), 23(13):4673-4683", "doi": "10.1007/s00500-018-3117-x", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microbial fuel cells (MFCs) perform wastewater treatment and electricity\nproduction through the conversion of organic matter using microorganisms. For\npractical applications, it has been suggested that greater efficiency can be\nachieved by arranging multiple MFC units into physical stacks in a cascade with\nfeedstock flowing sequentially between units. In this paper, we investigate the\nuse of computational intelligence to physically explore and optimise\n(potentially) heterogeneous MFC designs in a cascade, i.e. without simulation.\nConductive structures are 3-D printed and inserted into the anodic chamber of\neach MFC unit, augmenting a carbon fibre veil anode and affecting the\nhydrodynamics, including the feedstock volume and hydraulic retention time, as\nwell as providing unique habitats for microbial colonisation. We show that it\nis possible to use design mining to identify new conductive inserts that\nincrease both the cascade power output and power density.\n", "versions": [{"version": "v1", "created": "Tue, 18 Oct 2016 17:36:26 GMT"}, {"version": "v2", "created": "Tue, 31 Jan 2017 17:10:00 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Preen", "Richard J.", ""], ["You", "Jiseon", ""], ["Bull", "Larry", ""], ["Ieropoulos", "Ioannis A.", ""]]}, {"id": "1610.05735", "submitter": "Daniel Ritchie", "authors": "Daniel Ritchie, Paul Horsfall, Noah D. Goodman", "title": "Deep Amortized Inference for Probabilistic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic programming languages (PPLs) are a powerful modeling tool, able\nto represent any computable probability distribution. Unfortunately,\nprobabilistic program inference is often intractable, and existing PPLs mostly\nrely on expensive, approximate sampling-based methods. To alleviate this\nproblem, one could try to learn from past inferences, so that future inferences\nrun faster. This strategy is known as amortized inference; it has recently been\napplied to Bayesian networks and deep generative models. This paper proposes a\nsystem for amortized inference in PPLs. In our system, amortization comes in\nthe form of a parameterized guide program. Guide programs have similar\nstructure to the original program, but can have richer data flow, including\nneural network components. These networks can be optimized so that the guide\napproximately samples from the posterior distribution defined by the original\nprogram. We present a flexible interface for defining guide programs and a\nstochastic gradient-based scheme for optimizing guide parameters, as well as\nsome preliminary results on automatically deriving guide programs. We explore\nin detail the common machine learning pattern in which a 'local' model is\nspecified by 'global' random values and used to generate independent observed\ndata points; this gives rise to amortized local inference supporting global\nmodel learning.\n", "versions": [{"version": "v1", "created": "Tue, 18 Oct 2016 18:35:09 GMT"}], "update_date": "2016-10-19", "authors_parsed": [["Ritchie", "Daniel", ""], ["Horsfall", "Paul", ""], ["Goodman", "Noah D.", ""]]}, {"id": "1610.05984", "submitter": "Daniel Hein", "authors": "Daniel Hein, Alexander Hentschel, Thomas Runkler, Steffen Udluft", "title": "Particle Swarm Optimization for Generating Interpretable Fuzzy\n  Reinforcement Learning Policies", "comments": null, "journal-ref": "Engineering Applications of Artificial Intelligence, Volume 65C,\n  October 2017, Pages 87-98", "doi": "10.1016/j.engappai.2017.07.005", "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzy controllers are efficient and interpretable system controllers for\ncontinuous state and action spaces. To date, such controllers have been\nconstructed manually or trained automatically either using expert-generated\nproblem-specific cost functions or incorporating detailed knowledge about the\noptimal control strategy. Both requirements for automatic training processes\nare not found in most real-world reinforcement learning (RL) problems. In such\napplications, online learning is often prohibited for safety reasons because\nonline learning requires exploration of the problem's dynamics during policy\ntraining. We introduce a fuzzy particle swarm reinforcement learning (FPSRL)\napproach that can construct fuzzy RL policies solely by training parameters on\nworld models that simulate real system dynamics. These world models are created\nby employing an autonomous machine learning technique that uses previously\ngenerated transition samples of a real system. To the best of our knowledge,\nthis approach is the first to relate self-organizing fuzzy controllers to\nmodel-based batch RL. Therefore, FPSRL is intended to solve problems in domains\nwhere online learning is prohibited, system dynamics are relatively easy to\nmodel from previously generated default policy transition samples, and it is\nexpected that a relatively easily interpretable control policy exists. The\nefficiency of the proposed approach with problems from such domains is\ndemonstrated using three standard RL benchmarks, i.e., mountain car, cart-pole\nbalancing, and cart-pole swing-up. Our experimental results demonstrate\nhigh-performing, interpretable fuzzy policies.\n", "versions": [{"version": "v1", "created": "Wed, 19 Oct 2016 12:41:52 GMT"}, {"version": "v2", "created": "Fri, 7 Apr 2017 07:22:21 GMT"}, {"version": "v3", "created": "Fri, 5 May 2017 09:01:41 GMT"}, {"version": "v4", "created": "Thu, 29 Jun 2017 07:13:09 GMT"}, {"version": "v5", "created": "Tue, 15 Aug 2017 21:41:03 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["Hein", "Daniel", ""], ["Hentschel", "Alexander", ""], ["Runkler", "Thomas", ""], ["Udluft", "Steffen", ""]]}, {"id": "1610.06009", "submitter": "Anand Kulkarni Dr", "authors": "Omkar Kulkarni, Ninad Kulkarni, Anand J Kulkarni, Ganesh Kakandikar", "title": "Constrained Cohort Intelligence using Static and Dynamic Penalty\n  Function Approach for Mechanical Components Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the metaheuristics can efficiently solve unconstrained problems;\nhowever, their performance may degenerate if the constraints are involved. This\npaper proposes two constraint handling approaches for an emerging metaheuristic\nof Cohort Intelligence (CI). More specifically CI with static penalty function\napproach (SCI) and CI with dynamic penalty function approach (DCI) are\nproposed. The approaches have been tested by solving several constrained test\nproblems. The performance of the SCI and DCI have been compared with algorithms\nlike GA, PSO, ABC, d-Ds. In addition, as well as three real world problems from\nmechanical engineering domain with improved solutions. The results were\nsatisfactory and validated the applicability of CI methodology for solving real\nworld problems.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 16:36:39 GMT"}], "update_date": "2016-10-20", "authors_parsed": [["Kulkarni", "Omkar", ""], ["Kulkarni", "Ninad", ""], ["Kulkarni", "Anand J", ""], ["Kakandikar", "Ganesh", ""]]}, {"id": "1610.06067", "submitter": "Aws Albarghouthi", "authors": "Aws Albarghouthi and Loris D'Antoni and Samuel Drews and Aditya Nori", "title": "Fairness as a Program Property", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the following question: Is a decision-making program fair, for\nsome useful definition of fairness? First, we describe how several algorithmic\nfairness questions can be phrased as program verification problems. Second, we\ndiscuss an automated verification technique for proving or disproving fairness\nof decision-making programs with respect to a probabilistic model of the\npopulation.\n", "versions": [{"version": "v1", "created": "Wed, 19 Oct 2016 15:31:34 GMT"}], "update_date": "2016-10-20", "authors_parsed": [["Albarghouthi", "Aws", ""], ["D'Antoni", "Loris", ""], ["Drews", "Samuel", ""], ["Nori", "Aditya", ""]]}, {"id": "1610.06340", "submitter": "Arnaud Martin", "authors": "Siwar Jendoubi (CERT, DRUID, LARODEC), Arnaud Martin (DRUID), Ludovic\n  Li\\'etard (IRISA), Hend Hadji (CERT), Boutheina Yaghlane (LARODEC)", "title": "Maximizing positive opinion influence using an evidential approach", "comments": null, "journal-ref": "FLINS, Aug 2016, Roubaix, France. pp.168 - 174, 2016", "doi": "10.1142/9789813146976_0029", "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new data based model for influence maximization\nin online social networks. We use the theory of belief functions to overcome\nthe data imperfection problem. Besides, the proposed model searches to detect\ninfluencer users that adopt a positive opinion about the product, the idea,\netc, to be propagated. Moreover, we present some experiments to show the\nperformance of our model.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 09:39:15 GMT"}], "update_date": "2016-10-21", "authors_parsed": [["Jendoubi", "Siwar", "", "CERT, DRUID, LARODEC"], ["Martin", "Arnaud", "", "DRUID"], ["Li\u00e9tard", "Ludovic", "", "IRISA"], ["Hadji", "Hend", "", "CERT"], ["Yaghlane", "Boutheina", "", "LARODEC"]]}, {"id": "1610.06347", "submitter": "Oliver Giudice", "authors": "Oliver Giudice, Antonino Paratore, Marco Moltisanti, Sebastiano\n  Battiato", "title": "A Classification Engine for Image Ballistics of Social Data", "comments": "6 pages, 1 figure", "journal-ref": "Image Analysis and Processing - ICIAP 2017: 19th International\n  Conference, Catania, Italy, September 11-15, 2017, Proceedings, Part II,\n  Springer International Publishing", "doi": "10.1007/978-3-319-68548-9_57", "report-no": null, "categories": "cs.MM cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image Forensics has already achieved great results for the source camera\nidentification task on images. Standard approaches for data coming from Social\nNetwork Platforms cannot be applied due to different processes involved (e.g.,\nscaling, compression, etc.). Over 1 billion images are shared each day on the\nInternet and obtaining information about their history from the moment they\nwere acquired could be exploited for investigation purposes. In this paper, a\nclassification engine for the reconstruction of the history of an image, is\npresented. Specifically, exploiting K-NN and decision trees classifiers and\na-priori knowledge acquired through image analysis, we propose an automatic\napproach that can understand which Social Network Platform has processed an\nimage and the software application used to perform the image upload. The engine\nmakes use of proper alterations introduced by each platform as features.\nResults, in terms of global accuracy on a dataset of 2720 images, confirm the\neffectiveness of the proposed strategy.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 10:27:10 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Giudice", "Oliver", ""], ["Paratore", "Antonino", ""], ["Moltisanti", "Marco", ""], ["Battiato", "Sebastiano", ""]]}, {"id": "1610.06395", "submitter": "Sumalini Vartak", "authors": "Anne Veenendaal, Eddie Jones, Zhao Gang, Elliot Daly, Sumalini Vartak,\n  Rahul Patwardhan", "title": "Dynamic Probabilistic Network Based Human Action Recognition", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines use of dynamic probabilistic networks (DPN) for human\naction recognition. The actions of lifting objects and walking in the room,\nsitting in the room and neutral standing pose were used for testing the\nclassification. The research used the dynamic interrelation between various\ndifferent regions of interest (ROI) on the human body (face, body, arms, legs)\nand the time series based events related to the these ROIs. This dynamic links\nare then used to recognize the human behavioral aspects in the scene. First a\nmodel is developed to identify the human activities in an indoor scene and this\nmodel is dependent on the key features and interlinks between the various\ndynamic events using DPNs. The sub ROI are classified with DPN to associate the\ncombined interlink with a specific human activity. The recognition accuracy\nperformance between indoor (controlled lighting conditions) is compared with\nthe outdoor lighting conditions. The accuracy in outdoor scenes was lower than\nthe controlled environment.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jul 2016 03:19:58 GMT"}], "update_date": "2016-10-21", "authors_parsed": [["Veenendaal", "Anne", ""], ["Jones", "Eddie", ""], ["Gang", "Zhao", ""], ["Daly", "Elliot", ""], ["Vartak", "Sumalini", ""], ["Patwardhan", "Rahul", ""]]}, {"id": "1610.06402", "submitter": "Marc Pickett", "authors": "Marc Pickett and Rami Al-Rfou and Louis Shao and Chris Tar", "title": "A Growing Long-term Episodic & Semantic Memory", "comments": "Submission to NIPS workshop on Continual Learning. 4 page extended\n  abstract plus 5 more pages of references, figures, and supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The long-term memory of most connectionist systems lies entirely in the\nweights of the system. Since the number of weights is typically fixed, this\nbounds the total amount of knowledge that can be learned and stored. Though\nthis is not normally a problem for a neural network designed for a specific\ntask, such a bound is undesirable for a system that continually learns over an\nopen range of domains. To address this, we describe a lifelong learning system\nthat leverages a fast, though non-differentiable, content-addressable memory\nwhich can be exploited to encode both a long history of sequential episodic\nknowledge and semantic knowledge over many episodes for an unbounded number of\ndomains. This opens the door for investigation into transfer learning, and\nleveraging prior knowledge that has been learned over a lifetime of experiences\nto new domains.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 13:29:56 GMT"}], "update_date": "2016-10-21", "authors_parsed": [["Pickett", "Marc", ""], ["Al-Rfou", "Rami", ""], ["Shao", "Louis", ""], ["Tar", "Chris", ""]]}, {"id": "1610.06449", "submitter": "Hamed R.-Tavakoli", "authors": "Hamed R.-Tavakoli, Ali Borji, Jorma Laaksonen, Esa Rahtu", "title": "Exploiting inter-image similarity and ensemble of extreme learners for\n  fixation prediction using deep features", "comments": null, "journal-ref": "Neurocomputing 244 (2017) 10-18", "doi": "10.1016/j.neucom.2017.03.018", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel fixation prediction and saliency modeling\nframework based on inter-image similarities and ensemble of Extreme Learning\nMachines (ELM). The proposed framework is inspired by two observations, 1) the\ncontextual information of a scene along with low-level visual cues modulates\nattention, 2) the influence of scene memorability on eye movement patterns\ncaused by the resemblance of a scene to a former visual experience. Motivated\nby such observations, we develop a framework that estimates the saliency of a\ngiven image using an ensemble of extreme learners, each trained on an image\nsimilar to the input image. That is, after retrieving a set of similar images\nfor a given image, a saliency predictor is learnt from each of the images in\nthe retrieved image set using an ELM, resulting in an ensemble. The saliency of\nthe given image is then measured in terms of the mean of predicted saliency\nvalue by the ensemble's members.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 14:55:29 GMT"}], "update_date": "2017-05-31", "authors_parsed": [["-Tavakoli", "Hamed R.", ""], ["Borji", "Ali", ""], ["Laaksonen", "Jorma", ""], ["Rahtu", "Esa", ""]]}, {"id": "1610.06454", "submitter": "Tsendsuren Munkhdalai", "authors": "Tsendsuren Munkhdalai and Hong Yu", "title": "Reasoning with Memory Augmented Neural Networks for Language\n  Comprehension", "comments": "Accepted at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypothesis testing is an important cognitive process that supports human\nreasoning. In this paper, we introduce a computational hypothesis testing\napproach based on memory augmented neural networks. Our approach involves a\nhypothesis testing loop that reconsiders and progressively refines a previously\nformed hypothesis in order to generate new hypotheses to test. We apply the\nproposed approach to language comprehension task by using Neural Semantic\nEncoders (NSE). Our NSE models achieve the state-of-the-art results showing an\nabsolute improvement of 1.2% to 2.6% accuracy over previous results obtained by\nsingle and ensemble systems on standard machine comprehension benchmarks such\nas the Children's Book Test (CBT) and Who-Did-What (WDW) news article datasets.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 15:17:04 GMT"}, {"version": "v2", "created": "Tue, 28 Feb 2017 17:06:17 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Munkhdalai", "Tsendsuren", ""], ["Yu", "Hong", ""]]}, {"id": "1610.06473", "submitter": "Benjam\\'in Bedregal Prof.", "authors": "Benjamin Bedregal, Humberto Bustince, Eduardo Palmeira, Gra\\c{c}aliz\n  Pereira Dimuro and Javier Fernandez", "title": "Generalized Interval-valued OWA Operators with Interval Weights Derived\n  from Interval-valued Overlap Functions", "comments": null, "journal-ref": null, "doi": "10.1016/j.ijar.2017.07.001", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we extend to the interval-valued setting the notion of an\noverlap functions and we discuss a method which makes use of interval-valued\noverlap functions for constructing OWA operators with interval-valued weights.\n. Some properties of interval-valued overlap functions and the derived\ninterval-valued OWA operators are analysed. We specially focus on the\nhomogeneity and migrativity properties.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 16:02:59 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Bedregal", "Benjamin", ""], ["Bustince", "Humberto", ""], ["Palmeira", "Eduardo", ""], ["Dimuro", "Gra\u00e7aliz Pereira", ""], ["Fernandez", "Javier", ""]]}, {"id": "1610.06483", "submitter": "Oleksii Tyshchenko Dr", "authors": "Yevgeniy V. Bodyanskiy, Oleksii K. Tyshchenko, Daria S. Kopaliani", "title": "An Extended Neo-Fuzzy Neuron and its Adaptive Learning Algorithm", "comments": null, "journal-ref": "I.J. Intelligent Systems and Applications, 2015, 02, 21-26", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A modification of the neo-fuzzy neuron is proposed (an extended neo-fuzzy\nneuron (ENFN)) that is characterized by improved approximating properties. An\nadaptive learning algorithm is proposed that has both tracking and smoothing\nproperties. An ENFN distinctive feature is its computational simplicity\ncompared to other artificial neural networks and neuro-fuzzy systems.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 16:25:38 GMT"}], "update_date": "2016-10-21", "authors_parsed": [["Bodyanskiy", "Yevgeniy V.", ""], ["Tyshchenko", "Oleksii K.", ""], ["Kopaliani", "Daria S.", ""]]}, {"id": "1610.06484", "submitter": "Oleksii Tyshchenko Dr", "authors": "Zhengbing Hu, Yevgeniy V. Bodyanskiy, Oleksii K. Tyshchenko and Olena\n  O. Boiko", "title": "An Evolving Cascade System Based on A Set Of Neo Fuzzy Nodes", "comments": null, "journal-ref": "I.J. Intelligent Systems and Applications, 2016, 9, 1-7", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neo-fuzzy elements are used as nodes for an evolving cascade system. The\nproposed system can tune both its parameters and architecture in an online\nmode. It can be used for solving a wide range of Data Mining tasks (namely time\nseries forecasting). The evolving cascade system with neo-fuzzy nodes can\nprocess rather large data sets with high speed and effectiveness.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 16:27:11 GMT"}], "update_date": "2016-10-21", "authors_parsed": [["Hu", "Zhengbing", ""], ["Bodyanskiy", "Yevgeniy V.", ""], ["Tyshchenko", "Oleksii K.", ""], ["Boiko", "Olena O.", ""]]}, {"id": "1610.06485", "submitter": "Oleksii Tyshchenko Dr", "authors": "Yevgeniy V. Bodyanskiy, Oleksii K. Tyshchenko and Daria S. Kopaliani", "title": "A Multidimensional Cascade Neuro-Fuzzy System with Neuron Pool\n  Optimization in Each Cascade", "comments": null, "journal-ref": "I.J. Information Technology and Computer Science, 2014, 08, 11-17", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new architecture and learning algorithms for the multidimensional hybrid\ncascade neural network with neuron pool optimization in each cascade are\nproposed in this paper. The proposed system differs from the well-known cascade\nsystems in its capability to process multidimensional time series in an online\nmode, which makes it possible to process non-stationary stochastic and chaotic\nsignals with the required accuracy. Compared to conventional analogs, the\nproposed system provides computational simplicity and possesses both tracking\nand filtering capabilities.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 16:27:51 GMT"}], "update_date": "2016-10-21", "authors_parsed": [["Bodyanskiy", "Yevgeniy V.", ""], ["Tyshchenko", "Oleksii K.", ""], ["Kopaliani", "Daria S.", ""]]}, {"id": "1610.06486", "submitter": "Oleksii Tyshchenko Dr", "authors": "Zhengbing Hu, Yevgeniy V. Bodyanskiy, Oleksii K. Tyshchenko and Olena\n  O. Boiko", "title": "Adaptive Forecasting of Non-Stationary Nonlinear Time Series Based on\n  the Evolving Weighted Neuro-Neo-Fuzzy-ANARX-Model", "comments": null, "journal-ref": "I.J. Information Technology and Computer Science, 2016, 10, 1-10", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An evolving weighted neuro-neo-fuzzy-ANARX model and its learning procedures\nare introduced in the article. This system is basically used for time series\nforecasting. This system may be considered as a pool of elements that process\ndata in a parallel manner. The proposed evolving system may provide online\nprocessing data streams.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 16:28:43 GMT"}], "update_date": "2016-10-21", "authors_parsed": [["Hu", "Zhengbing", ""], ["Bodyanskiy", "Yevgeniy V.", ""], ["Tyshchenko", "Oleksii K.", ""], ["Boiko", "Olena O.", ""]]}, {"id": "1610.06488", "submitter": "Oleksii Tyshchenko Dr", "authors": "Yevgeniy V. Bodyanskiy, Oleksii K. Tyshchenko and Anastasiia O.\n  Deineko", "title": "An Evolving Neuro-Fuzzy System with Online Learning/Self-learning", "comments": null, "journal-ref": "I.J. Modern Education and Computer Science, 2015, 2, 1-7", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An architecture of a new neuro-fuzzy system is proposed. The basic idea of\nthis approach is to tune both synaptic weights and membership functions with\nthe help of the supervised learning and self-learning paradigms. The approach\nto solving the problem has to do with evolving online neuro-fuzzy systems that\ncan process data under uncertainty conditions. The results prove the\neffectiveness of the developed architecture and the learning procedure.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 16:29:40 GMT"}], "update_date": "2016-10-21", "authors_parsed": [["Bodyanskiy", "Yevgeniy V.", ""], ["Tyshchenko", "Oleksii K.", ""], ["Deineko", "Anastasiia O.", ""]]}, {"id": "1610.06490", "submitter": "Oleksii Tyshchenko Dr", "authors": "Zhengbing Hu, Yevgeniy V. Bodyanskiy, Oleksii K. Tyshchenko and Olena\n  O. Boiko", "title": "An Ensemble of Adaptive Neuro-Fuzzy Kohonen Networks for Online Data\n  Stream Fuzzy Clustering", "comments": null, "journal-ref": "I.J. Modern Education and Computer Science, 2016, 5, 12-18", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new approach to data stream clustering with the help of an ensemble of\nadaptive neuro-fuzzy systems is proposed. The proposed ensemble is formed with\nadaptive neuro-fuzzy self-organizing Kohonen maps in a parallel processing\nmode. A final result is chosen by the best neuro-fuzzy self-organizing Kohonen\nmap.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 16:30:25 GMT"}], "update_date": "2016-10-21", "authors_parsed": [["Hu", "Zhengbing", ""], ["Bodyanskiy", "Yevgeniy V.", ""], ["Tyshchenko", "Oleksii K.", ""], ["Boiko", "Olena O.", ""]]}, {"id": "1610.06540", "submitter": "Shubham Toshniwal", "authors": "Shubham Toshniwal, Karen Livescu", "title": "Jointly Learning to Align and Convert Graphemes to Phonemes with Neural\n  Attention Models", "comments": "Accepted in SLT 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an attention-enabled encoder-decoder model for the problem of\ngrapheme-to-phoneme conversion. Most previous work has tackled the problem via\njoint sequence models that require explicit alignments for training. In\ncontrast, the attention-enabled encoder-decoder model allows for jointly\nlearning to align and convert characters to phonemes. We explore different\ntypes of attention models, including global and local attention, and our best\nmodels achieve state-of-the-art results on three standard data sets (CMUDict,\nPronlex, and NetTalk).\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 19:00:48 GMT"}], "update_date": "2016-10-21", "authors_parsed": [["Toshniwal", "Shubham", ""], ["Livescu", "Karen", ""]]}, {"id": "1610.06620", "submitter": "Omid Bakhshandeh", "authors": "Omid Bakhshandeh, Trung Bui, Zhe Lin, Walter Chang", "title": "Proposing Plausible Answers for Open-ended Visual Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering open-ended questions is an essential capability for any intelligent\nagent. One of the most interesting recent open-ended question answering\nchallenges is Visual Question Answering (VQA) which attempts to evaluate a\nsystem's visual understanding through its answers to natural language questions\nabout images. There exist many approaches to VQA, the majority of which do not\nexhibit deeper semantic understanding of the candidate answers they produce. We\nstudy the importance of generating plausible answers to a given question by\nintroducing the novel task of `Answer Proposal': for a given open-ended\nquestion, a system should generate a ranked list of candidate answers informed\nby the semantics of the question. We experiment with various models including a\nneural generative model as well as a semantic graph matching one. We provide\nboth intrinsic and extrinsic evaluations for the task of Answer Proposal,\nshowing that our best model learns to propose plausible answers with a high\nrecall and performs competitively with some other solutions to VQA.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 22:01:36 GMT"}, {"version": "v2", "created": "Mon, 24 Oct 2016 00:12:29 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Bakhshandeh", "Omid", ""], ["Bui", "Trung", ""], ["Lin", "Zhe", ""], ["Chang", "Walter", ""]]}, {"id": "1610.06781", "submitter": "Fangyi Zhang", "authors": "Fangyi Zhang, J\\\"urgen Leitner, Michael Milford, Peter Corke", "title": "Modular Deep Q Networks for Sim-to-real Transfer of Visuo-motor Policies", "comments": "Australasian Conference on Robotics and Automation (ACRA) 2017,\n  Student Paper Award Finalist", "journal-ref": "The proceedings of the Australasian Conference on Robotics and\n  Automation (ACRA) 2017", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning has had significant successes in computer vision thanks\nto the abundance of visual data, collecting sufficiently large real-world\ndatasets for robot learning can be costly. To increase the practicality of\nthese techniques on real robots, we propose a modular deep reinforcement\nlearning method capable of transferring models trained in simulation to a\nreal-world robotic task. We introduce a bottleneck between perception and\ncontrol, enabling the networks to be trained independently, but then merged and\nfine-tuned in an end-to-end manner to further improve hand-eye coordination. On\na canonical, planar visually-guided robot reaching task a fine-tuned accuracy\nof 1.6 pixels is achieved, a significant improvement over naive transfer (17.5\npixels), showing the potential for more complicated and broader applications.\nOur method provides a technique for more efficient learning and transfer of\nvisuo-motor policies for real robotic systems without relying entirely on large\nreal-world robot datasets.\n", "versions": [{"version": "v1", "created": "Fri, 21 Oct 2016 13:36:25 GMT"}, {"version": "v2", "created": "Wed, 1 Mar 2017 09:59:51 GMT"}, {"version": "v3", "created": "Mon, 17 Jul 2017 09:59:35 GMT"}, {"version": "v4", "created": "Tue, 19 Dec 2017 04:59:03 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Zhang", "Fangyi", ""], ["Leitner", "J\u00fcrgen", ""], ["Milford", "Michael", ""], ["Corke", "Peter", ""]]}, {"id": "1610.06856", "submitter": "Ethan Rudd", "authors": "Khudran Alzhrani, Ethan M. Rudd, Terrance E. Boult, and C. Edward Chow", "title": "Automated Big Text Security Classification", "comments": "Pre-print of Best Paper Award IEEE Intelligence and Security\n  Informatics (ISI) 2016 Manuscript", "journal-ref": "2016 IEEE International Conference on Intelligence and Security\n  Informatics (ISI)", "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, traditional cybersecurity safeguards have proven ineffective\nagainst insider threats. Famous cases of sensitive information leaks caused by\ninsiders, including the WikiLeaks release of diplomatic cables and the Edward\nSnowden incident, have greatly harmed the U.S. government's relationship with\nother governments and with its own citizens. Data Leak Prevention (DLP) is a\nsolution for detecting and preventing information leaks from within an\norganization's network. However, state-of-art DLP detection models are only\nable to detect very limited types of sensitive information, and research in the\nfield has been hindered due to the lack of available sensitive texts. Many\nresearchers have focused on document-based detection with artificially labeled\n\"confidential documents\" for which security labels are assigned to the entire\ndocument, when in reality only a portion of the document is sensitive. This\ntype of whole-document based security labeling increases the chances of\npreventing authorized users from accessing non-sensitive information within\nsensitive documents. In this paper, we introduce Automated Classification\nEnabled by Security Similarity (ACESS), a new and innovative detection model\nthat penetrates the complexity of big text security classification/detection.\nTo analyze the ACESS system, we constructed a novel dataset, containing\nformerly classified paragraphs from diplomatic cables made public by the\nWikiLeaks organization. To our knowledge this paper is the first to analyze a\ndataset that contains actual formerly sensitive information annotated at\nparagraph granularity.\n", "versions": [{"version": "v1", "created": "Fri, 21 Oct 2016 16:53:09 GMT"}], "update_date": "2016-10-24", "authors_parsed": [["Alzhrani", "Khudran", ""], ["Rudd", "Ethan M.", ""], ["Boult", "Terrance E.", ""], ["Chow", "C. Edward", ""]]}, {"id": "1610.06912", "submitter": "Prakhar Ojha", "authors": "Prakhar Ojha, Partha Talukdar", "title": "KGEval: Estimating Accuracy of Automatically Constructed Knowledge\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic construction of large knowledge graphs (KG) by mining web-scale\ntext datasets has received considerable attention recently. Estimating accuracy\nof such automatically constructed KGs is a challenging problem due to their\nsize and diversity. This important problem has largely been ignored in prior\nresearch we fill this gap and propose KGEval. KGEval binds facts of a KG using\ncoupling constraints and crowdsources the facts that infer correctness of large\nparts of the KG. We demonstrate that the objective optimized by KGEval is\nsubmodular and NP-hard, allowing guarantees for our approximation algorithm.\nThrough extensive experiments on real-world datasets, we demonstrate that\nKGEval is able to estimate KG accuracy more accurately compared to other\ncompetitive baselines, while requiring significantly lesser number of human\nevaluations.\n", "versions": [{"version": "v1", "created": "Fri, 21 Oct 2016 19:49:19 GMT"}, {"version": "v2", "created": "Thu, 1 Dec 2016 06:45:34 GMT"}], "update_date": "2016-12-02", "authors_parsed": [["Ojha", "Prakhar", ""], ["Talukdar", "Partha", ""]]}, {"id": "1610.06920", "submitter": "Jorge Albericio", "authors": "J. Albericio, P. Judd, A. Delm\\'as, S. Sharify, A. Moshovos", "title": "Bit-pragmatic Deep Neural Network Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.AR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We quantify a source of ineffectual computations when processing the\nmultiplications of the convolutional layers in Deep Neural Networks (DNNs) and\npropose Pragmatic (PRA), an architecture that exploits it improving performance\nand energy efficiency. The source of these ineffectual computations is best\nunderstood in the context of conventional multipliers which generate internally\nmultiple terms, that is, products of the multiplicand and powers of two, which\nadded together produce the final product [1]. At runtime, many of these terms\nare zero as they are generated when the multiplicand is combined with the\nzero-bits of the multiplicator. While conventional bit-parallel multipliers\ncalculate all terms in parallel to reduce individual product latency, PRA\ncalculates only the non-zero terms using a) on-the-fly conversion of the\nmultiplicator representation into an explicit list of powers of two, and b)\nhybrid bit-parallel multplicand/bit-serial multiplicator processing units. PRA\nexploits two sources of ineffectual computations: 1) the aforementioned zero\nproduct terms which are the result of the lack of explicitness in the\nmultiplicator representation, and 2) the excess in the representation precision\nused for both multiplicants and multiplicators, e.g., [2]. Measurements\ndemonstrate that for the convolutional layers, a straightforward variant of PRA\nimproves performance by 2.6x over the DaDiaNao (DaDN) accelerator [3] and by\n1.4x over STR [4]. Similarly, PRA improves energy efficiency by 28% and 10% on\naverage compared to DaDN and STR. An improved cross lane synchronication scheme\nboosts performance improvements to 3.1x over DaDN. Finally, Pragmatic benefits\npersist even with an 8-bit quantized representation [5].\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 22:16:05 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Albericio", "J.", ""], ["Judd", "P.", ""], ["Delm\u00e1s", "A.", ""], ["Sharify", "S.", ""], ["Moshovos", "A.", ""]]}, {"id": "1610.06940", "submitter": "Xiaowei Huang", "authors": "Xiaowei Huang and Marta Kwiatkowska and Sen Wang and Min Wu", "title": "Safety Verification of Deep Neural Networks", "comments": "To appear as invited paper at CAV 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have achieved impressive experimental results in image\nclassification, but can surprisingly be unstable with respect to adversarial\nperturbations, that is, minimal changes to the input image that cause the\nnetwork to misclassify it. With potential applications including perception\nmodules and end-to-end controllers for self-driving cars, this raises concerns\nabout their safety. We develop a novel automated verification framework for\nfeed-forward multi-layer neural networks based on Satisfiability Modulo Theory\n(SMT). We focus on safety of image classification decisions with respect to\nimage manipulations, such as scratches or changes to camera angle or lighting\nconditions that would result in the same class being assigned by a human, and\ndefine safety for an individual decision in terms of invariance of the\nclassification within a small neighbourhood of the original image. We enable\nexhaustive search of the region by employing discretisation, and propagate the\nanalysis layer by layer. Our method works directly with the network code and,\nin contrast to existing methods, can guarantee that adversarial examples, if\nthey exist, are found for the given region and family of manipulations. If\nfound, adversarial examples can be shown to human testers and/or used to\nfine-tune the network. We implement the techniques using Z3 and evaluate them\non state-of-the-art networks, including regularised and deep learning networks.\nWe also compare against existing techniques to search for adversarial examples\nand estimate network robustness.\n", "versions": [{"version": "v1", "created": "Fri, 21 Oct 2016 20:16:16 GMT"}, {"version": "v2", "created": "Sat, 5 Nov 2016 16:05:08 GMT"}, {"version": "v3", "created": "Fri, 5 May 2017 10:16:50 GMT"}], "update_date": "2017-05-08", "authors_parsed": [["Huang", "Xiaowei", ""], ["Kwiatkowska", "Marta", ""], ["Wang", "Sen", ""], ["Wu", "Min", ""]]}, {"id": "1610.06972", "submitter": "Himabindu Lakkaraju", "authors": "Himabindu Lakkaraju, Cynthia Rudin", "title": "Learning Cost-Effective Treatment Regimes using Markov Decision\n  Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision makers, such as doctors and judges, make crucial decisions such as\nrecommending treatments to patients, and granting bails to defendants on a\ndaily basis. Such decisions typically involve weighting the potential benefits\nof taking an action against the costs involved. In this work, we aim to\nautomate this task of learning \\emph{cost-effective, interpretable and\nactionable treatment regimes}. We formulate this as a problem of learning a\ndecision list -- a sequence of if-then-else rules -- which maps characteristics\nof subjects (eg., diagnostic test results of patients) to treatments. We\npropose a novel objective to construct a decision list which maximizes outcomes\nfor the population, and minimizes overall costs. We model the problem of\nlearning such a list as a Markov Decision Process (MDP) and employ a variant of\nthe Upper Confidence Bound for Trees (UCT) strategy which leverages customized\nchecks for pruning the search space effectively. Experimental results on real\nworld observational data capturing judicial bail decisions and treatment\nrecommendations for asthma patients demonstrate the effectiveness of our\napproach.\n", "versions": [{"version": "v1", "created": "Fri, 21 Oct 2016 23:17:03 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Lakkaraju", "Himabindu", ""], ["Rudin", "Cynthia", ""]]}, {"id": "1610.07045", "submitter": "Yixuan (Julie) Zhu", "authors": "Julie Yixuan Zhu, Chao Zhang, Huichu Zhang, Shi Zhi, Victor O.K. Li,\n  Jiawei Han, Yu Zheng", "title": "pg-Causality: Identifying Spatiotemporal Causal Pathways for Air\n  Pollutants with Urban Big Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many countries are suffering from severe air pollution. Understanding how\ndifferent air pollutants accumulate and propagate is critical to making\nrelevant public policies. In this paper, we use urban big data (air quality\ndata and meteorological data) to identify the \\emph{spatiotemporal (ST) causal\npathways} for air pollutants. This problem is challenging because: (1) there\nare numerous noisy and low-pollution periods in the raw air quality data, which\nmay lead to unreliable causality analysis, (2) for large-scale data in the ST\nspace, the computational complexity of constructing a causal structure is very\nhigh, and (3) the \\emph{ST causal pathways} are complex due to the interactions\nof multiple pollutants and the influence of environmental factors. Therefore,\nwe present \\emph{p-Causality}, a novel pattern-aided causality analysis\napproach that combines the strengths of \\emph{pattern mining} and\n\\emph{Bayesian learning} to efficiently and faithfully identify the \\emph{ST\ncausal pathways}. First, \\emph{Pattern mining} helps suppress the noise by\ncapturing frequent evolving patterns (FEPs) of each monitoring sensor, and\ngreatly reduce the complexity by selecting the pattern-matched sensors as\n\"causers\". Then, \\emph{Bayesian learning} carefully encodes the local and ST\ncausal relations with a Gaussian Bayesian network (GBN)-based graphical model,\nwhich also integrates environmental influences to minimize biases in the final\nresults. We evaluate our approach with three real-world data sets containing\n982 air quality sensors, in three regions of China from 01-Jun-2013 to\n19-Dec-2015. Results show that our approach outperforms the traditional causal\nstructure learning methods in time efficiency, inference accuracy and\ninterpretability.\n", "versions": [{"version": "v1", "created": "Sat, 22 Oct 2016 13:17:28 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2017 08:30:29 GMT"}, {"version": "v3", "created": "Wed, 18 Apr 2018 07:39:53 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Zhu", "Julie Yixuan", ""], ["Zhang", "Chao", ""], ["Zhang", "Huichu", ""], ["Zhi", "Shi", ""], ["Li", "Victor O. K.", ""], ["Han", "Jiawei", ""], ["Zheng", "Yu", ""]]}, {"id": "1610.07089", "submitter": "Dominik Meyer", "authors": "Dominik Meyer, Johannes Feldmaier, Hao Shen", "title": "Reinforcement Learning in Conflicting Environments for Autonomous\n  Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate the application of Reinforcement Learning to two\nwell known decision dilemmas, namely Newcomb's Problem and Prisoner's Dilemma.\nThese problems are exemplary for dilemmas that autonomous agents are faced with\nwhen interacting with humans. Furthermore, we argue that a Newcomb-like\nformulation is more adequate in the human-machine interaction case and\ndemonstrate empirically that the unmodified Reinforcement Learning algorithms\nend up with the well known maximum expected utility solution.\n", "versions": [{"version": "v1", "created": "Sat, 22 Oct 2016 19:27:20 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Meyer", "Dominik", ""], ["Feldmaier", "Johannes", ""], ["Shen", "Hao", ""]]}, {"id": "1610.07231", "submitter": "Nazanin Hashemi", "authors": "Nazanin Sadat Hashemi, Roya Babaie Aghdam, Atieh Sadat Bayat Ghiasi\n  and Parastoo Fatemi", "title": "Template Matching Advances and Applications in Image Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In most computer vision and image analysis problems, it is necessary to\ndefine a similarity measure between two or more different objects or images.\nTemplate matching is a classic and fundamental method used to score\nsimilarities between objects using certain mathematical algorithms. In this\npaper, we reviewed the basic concept of matching, as well as advances in\ntemplate matching and applications such as invariant features or novel\napplications in medical image analysis. Additionally, deformable models and\ntemplates originating from classic template matching were discussed. These\nmodels have broad applications in image registration, and they are a\nfundamental aspect of novel machine vision or deep learning algorithms, such as\nconvolutional neural networks (CNN), which perform shift and scale invariant\nfunctions followed by classification. In general, although template matching\nmethods have restrictions which limit their application, they are recommended\nfor use with other object recognition methods as pre- or post-processing steps.\nCombining a template matching technique such as normalized cross-correlation or\ndice coefficient with a robust decision-making algorithm yields a significant\nimprovement in the accuracy rate for object detection and recognition.\n", "versions": [{"version": "v1", "created": "Sun, 23 Oct 2016 20:48:17 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Hashemi", "Nazanin Sadat", ""], ["Aghdam", "Roya Babaie", ""], ["Ghiasi", "Atieh Sadat Bayat", ""], ["Fatemi", "Parastoo", ""]]}, {"id": "1610.07365", "submitter": "Thierry Poibeau", "authors": "Thierry Poibeau (LaTTICe), Shravan Vasishth", "title": "Introduction: Cognitive Issues in Natural Language Processing", "comments": null, "journal-ref": "Traitement Automatique des Langues, ATALA, 2014, Traitement\n  Automatique des Langues et Sciences Cognitives, 55 (3), pp.7-19", "doi": "10.1201/b21583-2", "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This special issue is dedicated to get a better picture of the relationships\nbetween computational linguistics and cognitive science. It specifically raises\ntwo questions: \"what is the potential contribution of computational language\nmodeling to cognitive science?\" and conversely: \"what is the influence of\ncognitive science in contemporary computational linguistics?\"\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2016 11:30:22 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Poibeau", "Thierry", "", "LaTTICe"], ["Vasishth", "Shravan", ""]]}, {"id": "1610.07388", "submitter": "L\\'aszl\\'o Csat\\'o", "authors": "L\\'aszl\\'o Csat\\'o", "title": "Characterization of an inconsistency ranking for pairwise comparison\n  matrices", "comments": "13 pages", "journal-ref": "Annals of Operations Research, 261(1-2): 155-165, 2018", "doi": "10.1007/s10479-017-2627-8", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pairwise comparisons between alternatives are a well-known method for\nmeasuring preferences of a decision-maker. Since these often do not exhibit\nconsistency, a number of inconsistency indices has been introduced in order to\nmeasure the deviation from this ideal case. We axiomatically characterize the\ninconsistency ranking induced by the Koczkodaj inconsistency index: six\nindependent properties are presented such that they determine a unique linear\norder on the set of all pairwise comparison matrices.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2016 12:37:36 GMT"}, {"version": "v2", "created": "Mon, 23 Jan 2017 12:48:49 GMT"}, {"version": "v3", "created": "Mon, 12 Jun 2017 13:23:02 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Csat\u00f3", "L\u00e1szl\u00f3", ""]]}, {"id": "1610.07432", "submitter": "Douwe Kiela", "authors": "Douwe Kiela and Luana Bulat and Anita L. Vero and Stephen Clark", "title": "Virtual Embodiment: A Scalable Long-Term Strategy for Artificial\n  Intelligence Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Meaning has been called the \"holy grail\" of a variety of scientific\ndisciplines, ranging from linguistics to philosophy, psychology and the\nneurosciences. The field of Artifical Intelligence (AI) is very much a part of\nthat list: the development of sophisticated natural language semantics is a\nsine qua non for achieving a level of intelligence comparable to humans.\nEmbodiment theories in cognitive science hold that human semantic\nrepresentation depends on sensori-motor experience; the abundant evidence that\nhuman meaning representation is grounded in the perception of physical reality\nleads to the conclusion that meaning must depend on a fusion of multiple\n(perceptual) modalities. Despite this, AI research in general, and its\nsubdisciplines such as computational linguistics and computer vision in\nparticular, have focused primarily on tasks that involve a single modality.\nHere, we propose virtual embodiment as an alternative, long-term strategy for\nAI research that is multi-modal in nature and that allows for the kind of\nscalability required to develop the field coherently and incrementally, in an\nethically responsible fashion.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2016 14:37:27 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Kiela", "Douwe", ""], ["Bulat", "Luana", ""], ["Vero", "Anita L.", ""], ["Clark", "Stephen", ""]]}, {"id": "1610.07505", "submitter": "Ahmed Alaa", "authors": "Ahmed M. Alaa and Mihaela van der Schaar", "title": "Balancing Suspense and Surprise: Timely Decision Making with Endogenous\n  Information Acquisition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a Bayesian model for decision-making under time pressure with\nendogenous information acquisition. In our model, the decision maker decides\nwhen to observe (costly) information by sampling an underlying continuous-time\nstochastic process (time series) that conveys information about the potential\noccurrence or non-occurrence of an adverse event which will terminate the\ndecision-making process. In her attempt to predict the occurrence of the\nadverse event, the decision-maker follows a policy that determines when to\nacquire information from the time series (continuation), and when to stop\nacquiring information and make a final prediction (stopping). We show that the\noptimal policy has a rendezvous structure, i.e. a structure in which whenever a\nnew information sample is gathered from the time series, the optimal \"date\" for\nacquiring the next sample becomes computable. The optimal interval between two\ninformation samples balances a trade-off between the decision maker's surprise,\ni.e. the drift in her posterior belief after observing new information, and\nsuspense, i.e. the probability that the adverse event occurs in the time\ninterval between two information samples. Moreover, we characterize the\ncontinuation and stopping regions in the decision-maker's state-space, and show\nthat they depend not only on the decision-maker's beliefs, but also on the\ncontext, i.e. the current realization of the time series.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2016 17:43:34 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Alaa", "Ahmed M.", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1610.07675", "submitter": "Kamil Rocki", "authors": "Kamil Rocki, Tomasz Kornuta, Tegan Maharaj", "title": "Surprisal-Driven Zoneout", "comments": "Published at the Continual Learning and Deep Networks Workshop; NIPS\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method of regularization for recurrent neural networks\ncalled suprisal-driven zoneout. In this method, states zoneout (maintain their\nprevious value rather than updating), when the suprisal (discrepancy between\nthe last state's prediction and target) is small. Thus regularization is\nadaptive and input-driven on a per-neuron basis. We demonstrate the\neffectiveness of this idea by achieving state-of-the-art bits per character of\n1.31 on the Hutter Prize Wikipedia dataset, significantly reducing the gap to\nthe best known highly-engineered compression methods.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2016 22:38:52 GMT"}, {"version": "v2", "created": "Fri, 28 Oct 2016 19:55:16 GMT"}, {"version": "v3", "created": "Mon, 31 Oct 2016 15:18:11 GMT"}, {"version": "v4", "created": "Thu, 3 Nov 2016 17:09:23 GMT"}, {"version": "v5", "created": "Thu, 24 Nov 2016 06:40:26 GMT"}, {"version": "v6", "created": "Tue, 13 Dec 2016 23:32:24 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Rocki", "Kamil", ""], ["Kornuta", "Tomasz", ""], ["Maharaj", "Tegan", ""]]}, {"id": "1610.07708", "submitter": "Amit Sheth", "authors": "Amit Sheth, Sujan Perera, Sanjaya Wijeratne", "title": "Knowledge will Propel Machine Understanding of Content: Extrapolating\n  from Current Examples", "comments": "There is a new version of this paper with new authors uploaded as\n  arXiv:1707.05308, so this is an invalid entry", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning has been a big success story during the AI resurgence. One\nparticular stand out success relates to unsupervised learning from a massive\namount of data, albeit much of it relates to one modality/type of data at a\ntime. In spite of early assertions of the unreasonable effectiveness of data,\nthere is increasing recognition of utilizing knowledge whenever it is available\nor can be created purposefully. In this paper, we focus on discussing the\nindispensable role of knowledge for deeper understanding of complex text and\nmultimodal data in situations where (i) large amounts of training data\n(labeled/unlabeled) are not available or labor intensive to create, (ii) the\nobjects (particularly text) to be recognized are complex (i.e., beyond simple\nentity-person/location/organization names), such as implicit entities and\nhighly subjective content, and (iii) applications need to use complementary or\nrelated data in multiple modalities/media. What brings us to the cusp of rapid\nprogress is our ability to (a) create knowledge, varying from comprehensive or\ncross domain to domain or application specific, and (b) carefully exploit the\nknowledge to further empower or extend the applications of ML/NLP techniques.\nUsing the early results in several diverse situations - both in data types and\napplications - we seek to foretell unprecedented progress in our ability for\ndeeper understanding and exploitation of multimodal data.\n", "versions": [{"version": "v1", "created": "Tue, 25 Oct 2016 02:13:53 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2019 18:37:27 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Sheth", "Amit", ""], ["Perera", "Sujan", ""], ["Wijeratne", "Sanjaya", ""]]}, {"id": "1610.07862", "submitter": "Shoumen Datta", "authors": "Shoumen Palit Austin Datta", "title": "Intelligence in Artificial Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The elusive quest for intelligence in artificial intelligence prompts us to\nconsider that instituting human-level intelligence in systems may be (still) in\nthe realm of utopia. In about a quarter century, we have witnessed the winter\nof AI (1990) being transformed and transported to the zenith of tabloid fodder\nabout AI (2015). The discussion at hand is about the elements that constitute\nthe canonical idea of intelligence. The delivery of intelligence as a\npay-per-use-service, popping out of an app or from a shrink-wrapped software\ndefined point solution, is in contrast to the bio-inspired view of intelligence\nas an outcome, perhaps formed from a tapestry of events, cross-pollinated by\ninstances, each with its own microcosm of experiences and learning, which may\nnot be discrete all-or-none functions but continuous, over space and time. The\nenterprise world may not require, aspire or desire such an engaged solution to\nimprove its services for enabling digital transformation through the deployment\nof digital twins, for example. One might ask whether the \"work-flow on\nsteroids\" version of decision support may suffice for intelligence? Are we\nharking back to the era of rule based expert systems? The image conjured by the\npublicity machines offers deep solutions with human-level AI and preposterous\nclaims about capturing the \"brain in a box\" by 2020. Even emulating insects may\nbe difficult in terms of real progress. Perhaps we can try to focus on worms\n(Caenorhabditis elegans) which may be better suited for what business needs to\nquench its thirst for so-called intelligence in AI.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2016 02:15:46 GMT"}, {"version": "v2", "created": "Wed, 26 Oct 2016 02:32:30 GMT"}], "update_date": "2016-10-27", "authors_parsed": [["Datta", "Shoumen Palit Austin", ""]]}, {"id": "1610.07989", "submitter": "Raji Ghawi", "authors": "Raji Ghawi", "title": "Process Discovery using Inductive Miner and Decomposition", "comments": "A Submission to the Process Discovery Contest @ BPM2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report presents a submission to the Process Discovery Contest. The\ncontest is dedicated to the assessment of tools and techniques that discover\nbusiness process models from event logs. The objective is to compare the\nefficiency of techniques to discover process models that provide a proper\nbalance between \"overfitting\" and \"underfitting\". In the context of the Process\nDiscovery Contest, process discovery is turned into a classification task with\na training set and a test set; where a process model needs to decide whether\ntraces are fitting or not. In this report, we first show how we use two\ndiscovery techniques, namely: Inductive Miner and Decomposition, to discover\nprocess models from the training set using ProM tool. Second, we show how we\nuse replay results to 1) check the rediscoverability of models, and to 2)\nclassify unseen traces (in test logs) as fitting or not. Then, we discuss the\nclassification results of validation logs, the complexity of discovered models,\nand their impact on the selection of models for submission. The report ends\nwith the pictures of the submitted process models.\n", "versions": [{"version": "v1", "created": "Tue, 25 Oct 2016 17:58:54 GMT"}], "update_date": "2016-10-27", "authors_parsed": [["Ghawi", "Raji", ""]]}, {"id": "1610.07997", "submitter": "Roman Yampolskiy", "authors": "Roman V. Yampolskiy, M. S. Spellchecker", "title": "Artificial Intelligence Safety and Cybersecurity: a Timeline of AI\n  Failures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present and analyze reported failures of artificially\nintelligent systems and extrapolate our analysis to future AIs. We suggest that\nboth the frequency and the seriousness of future AI failures will steadily\nincrease. AI Safety can be improved based on ideas developed by cybersecurity\nexperts. For narrow AIs safety failures are at the same, moderate, level of\ncriticality as in cybersecurity, however for general AI, failures have a\nfundamentally different impact. A single failure of a superintelligent system\nmay cause a catastrophic event without a chance for recovery. The goal of\ncybersecurity is to reduce the number of successful attacks on the system; the\ngoal of AI Safety is to make sure zero attacks succeed in bypassing the safety\nmechanisms. Unfortunately, such a level of performance is unachievable. Every\nsecurity system will eventually fail; there is no such thing as a 100% secure\nsystem.\n", "versions": [{"version": "v1", "created": "Tue, 25 Oct 2016 18:14:24 GMT"}], "update_date": "2016-10-26", "authors_parsed": [["Yampolskiy", "Roman V.", ""], ["Spellchecker", "M. S.", ""]]}, {"id": "1610.08087", "submitter": "Minh Ha Quang", "authors": "Minh Ha Quang", "title": "Infinite-dimensional Log-Determinant divergences II: Alpha-Beta\n  divergences", "comments": "71 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a parametrized family of divergences, namely Alpha-Beta\nLog- Determinant (Log-Det) divergences, between positive definite unitized\ntrace class operators on a Hilbert space. This is a generalization of the\nAlpha-Beta Log-Determinant divergences between symmetric, positive definite\nmatrices to the infinite-dimensional setting. The family of Alpha-Beta Log-Det\ndivergences is highly general and contains many divergences as special cases,\nincluding the recently formulated infinite dimensional affine-invariant\nRiemannian distance and the infinite-dimensional Alpha Log-Det divergences\nbetween positive definite unitized trace class operators. In particular, it\nincludes a parametrized family of metrics between positive definite trace class\noperators, with the affine-invariant Riemannian distance and the square root of\nthe symmetric Stein divergence being special cases. For the Alpha-Beta Log-Det\ndivergences between covariance operators on a Reproducing Kernel Hilbert Space\n(RKHS), we obtain closed form formulas via the corresponding Gram matrices.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 17:58:58 GMT"}, {"version": "v2", "created": "Sat, 14 Jan 2017 18:36:16 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Quang", "Minh Ha", ""]]}, {"id": "1610.08115", "submitter": "Zhuo Chen", "authors": "Zhuo Chen, Kyle Marple, Elmer Salazar, Gopal Gupta, Lakshman Tamil", "title": "A Physician Advisory System for Chronic Heart Failure Management Based\n  on Knowledge Patterns", "comments": "Paper presented at the 32nd International Conference on Logic\n  Programming (ICLP 2016), New York City, USA, 16-21 October 2016, 14 pages,\n  LaTeX", "journal-ref": null, "doi": "10.1017/S1471068416000429", "report-no": null, "categories": "cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Management of chronic diseases such as heart failure, diabetes, and chronic\nobstructive pulmonary disease (COPD) is a major problem in health care. A\nstandard approach that the medical community has devised to manage widely\nprevalent chronic diseases such as chronic heart failure (CHF) is to have a\ncommittee of experts develop guidelines that all physicians should follow.\nThese guidelines typically consist of a series of complex rules that make\nrecommendations based on a patient's information. Due to their complexity,\noften the guidelines are either ignored or not complied with at all, which can\nresult in poor medical practices. It is not even clear whether it is humanly\npossible to follow these guidelines due to their length and complexity. In the\ncase of CHF management, the guidelines run nearly 80 pages. In this paper we\ndescribe a physician-advisory system for CHF management that codes the entire\nset of clinical practice guidelines for CHF using answer set programming. Our\napproach is based on developing reasoning templates (that we call knowledge\npatterns) and using these patterns to systemically code the clinical guidelines\nfor CHF as ASP rules. Use of the knowledge patterns greatly facilitates the\ndevelopment of our system. Given a patient's medical information, our system\ngenerates a recommendation for treatment just as a human physician would, using\nthe guidelines. Our system will work even in the presence of incomplete\ninformation. Our work makes two contributions: (i) it shows that highly complex\nguidelines can be successfully coded as ASP rules, and (ii) it develops a\nseries of knowledge patterns that facilitate the coding of knowledge expressed\nin a natural language and that can be used for other application domains. This\npaper is under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Tue, 25 Oct 2016 23:05:03 GMT"}], "update_date": "2016-10-28", "authors_parsed": [["Chen", "Zhuo", ""], ["Marple", "Kyle", ""], ["Salazar", "Elmer", ""], ["Gupta", "Gopal", ""], ["Tamil", "Lakshman", ""]]}, {"id": "1610.08127", "submitter": "Thomas Brouwer", "authors": "Thomas Brouwer, Jes Frellsen, Pietro Lio'", "title": "Fast Bayesian Non-Negative Matrix Factorisation and Tri-Factorisation", "comments": "NIPS 2016 Workshop on Advances in Approximate Bayesian Inference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a fast variational Bayesian algorithm for performing non-negative\nmatrix factorisation and tri-factorisation. We show that our approach achieves\nfaster convergence per iteration and timestep (wall-clock) than Gibbs sampling\nand non-probabilistic approaches, and do not require additional samples to\nestimate the posterior. We show that in particular for matrix tri-factorisation\nconvergence is difficult, but our variational Bayesian approach offers a fast\nsolution, allowing the tri-factorisation approach to be used more effectively.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 00:10:44 GMT"}], "update_date": "2016-10-28", "authors_parsed": [["Brouwer", "Thomas", ""], ["Frellsen", "Jes", ""], ["Lio'", "Pietro", ""]]}, {"id": "1610.08222", "submitter": "Anuradha Ariyaratne", "authors": "M. K. A. Ariyaratne, T. G. I. Fernando and S. Weerakoon", "title": "A self-tuning Firefly algorithm to tune the parameters of Ant Colony\n  System (ACSFA)", "comments": "18 pages, 21 references, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ant colony system (ACS) is a promising approach which has been widely used in\nproblems such as Travelling Salesman Problems (TSP), Job shop scheduling\nproblems (JSP) and Quadratic Assignment problems (QAP). In its original\nimplementation, parameters of the algorithm were selected by trial and error\napproach. Over the last few years, novel approaches have been proposed on\nadapting the parameters of ACS in improving its performance. The aim of this\npaper is to use a framework introduced for self-tuning optimization algorithms\ncombined with the firefly algorithm (FA) to tune the parameters of the ACS\nsolving symmetric TSP problems. The FA optimizes the problem specific\nparameters of ACS while the parameters of the FA are tuned by the selected\nframework itself. With this approach, the user neither has to work with the\nparameters of ACS nor the parameters of FA. Using common symmetric TSP problems\nwe demonstrate that the framework fits well for the ACS. A detailed statistical\nanalysis further verifies the goodness of the new ACS over the existing ACS and\nalso of the other techniques used to tune the parameters of ACS.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 08:01:27 GMT"}], "update_date": "2016-10-27", "authors_parsed": [["Ariyaratne", "M. K. A.", ""], ["Fernando", "T. G. I.", ""], ["Weerakoon", "S.", ""]]}, {"id": "1610.08251", "submitter": "Vedran Dunjko", "authors": "Vedran Dunjko, Jacob M. Taylor, Hans J. Briegel", "title": "Quantum-enhanced machine learning", "comments": "5+15 pages. This paper builds upon and mostly supersedes\n  arXiv:1507.08482. In addition to results provided in this previous work, here\n  we achieve learning improvements in more general environments, and provide\n  connections to other work in quantum machine learning. Explicit constructions\n  of oracularized environments given in arXiv:1507.08482 are omitted in this\n  version", "journal-ref": "Phys. Rev. Lett. 117, 130501 (2016)", "doi": "10.1103/PhysRevLett.117.130501", "report-no": null, "categories": "quant-ph cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emerging field of quantum machine learning has the potential to\nsubstantially aid in the problems and scope of artificial intelligence. This is\nonly enhanced by recent successes in the field of classical machine learning.\nIn this work we propose an approach for the systematic treatment of machine\nlearning, from the perspective of quantum information. Our approach is general\nand covers all three main branches of machine learning: supervised,\nunsupervised and reinforcement learning. While quantum improvements in\nsupervised and unsupervised learning have been reported, reinforcement learning\nhas received much less attention. Within our approach, we tackle the problem of\nquantum enhancements in reinforcement learning as well, and propose a\nsystematic scheme for providing improvements. As an example, we show that\nquadratic improvements in learning efficiency, and exponential improvements in\nperformance over limited time periods, can be obtained for a broad class of\nlearning problems.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 09:35:11 GMT"}], "update_date": "2016-10-27", "authors_parsed": [["Dunjko", "Vedran", ""], ["Taylor", "Jacob M.", ""], ["Briegel", "Hans J.", ""]]}, {"id": "1610.08401", "submitter": "Seyed-Mohsen Moosavi-Dezfooli", "authors": "Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Omar Fawzi, Pascal\n  Frossard", "title": "Universal adversarial perturbations", "comments": "Accepted at IEEE Conference on Computer Vision and Pattern\n  Recognition (CVPR), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a state-of-the-art deep neural network classifier, we show the\nexistence of a universal (image-agnostic) and very small perturbation vector\nthat causes natural images to be misclassified with high probability. We\npropose a systematic algorithm for computing universal perturbations, and show\nthat state-of-the-art deep neural networks are highly vulnerable to such\nperturbations, albeit being quasi-imperceptible to the human eye. We further\nempirically analyze these universal perturbations and show, in particular, that\nthey generalize very well across neural networks. The surprising existence of\nuniversal perturbations reveals important geometric correlations among the\nhigh-dimensional decision boundary of classifiers. It further outlines\npotential security breaches with the existence of single directions in the\ninput space that adversaries can possibly exploit to break a classifier on most\nnatural images.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 16:30:45 GMT"}, {"version": "v2", "created": "Thu, 17 Nov 2016 07:15:00 GMT"}, {"version": "v3", "created": "Thu, 9 Mar 2017 17:01:25 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Moosavi-Dezfooli", "Seyed-Mohsen", ""], ["Fawzi", "Alhussein", ""], ["Fawzi", "Omar", ""], ["Frossard", "Pascal", ""]]}, {"id": "1610.08445", "submitter": "Seyed Mehran Kazemi", "authors": "Seyed Mehran Kazemi, Angelika Kimmig, Guy Van den Broeck, David Poole", "title": "New Liftable Classes for First-Order Probabilistic Inference", "comments": "Accepted at NIPS-2016. 22 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Statistical relational models provide compact encodings of probabilistic\ndependencies in relational domains, but result in highly intractable graphical\nmodels. The goal of lifted inference is to carry out probabilistic inference\nwithout needing to reason about each individual separately, by instead treating\nexchangeable, undistinguished objects as a whole. In this paper, we study the\ndomain recursion inference rule, which, despite its central role in early\ntheoretical results on domain-lifted inference, has later been believed\nredundant. We show that this rule is more powerful than expected, and in fact\nsignificantly extends the range of models for which lifted inference runs in\ntime polynomial in the number of individuals in the domain. This includes an\nopen problem called S4, the symmetric transitivity model, and a first-order\nlogic encoding of the birthday paradox. We further identify new classes S2FO2\nand S2RU of domain-liftable theories, which respectively subsume FO2 and\nrecursively unary theories, the largest classes of domain-liftable theories\nknown so far, and show that using domain recursion can achieve exponential\nspeedup even in theories that cannot fully be lifted with the existing set of\ninference rules.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 18:13:42 GMT"}], "update_date": "2016-10-27", "authors_parsed": [["Kazemi", "Seyed Mehran", ""], ["Kimmig", "Angelika", ""], ["Broeck", "Guy Van den", ""], ["Poole", "David", ""]]}, {"id": "1610.08469", "submitter": "Emiliano De Cristofaro", "authors": "Sina Sajadmanesh and Sina Jafarzadeh and Seyed Ali Osia and Hamid R.\n  Rabiee and Hamed Haddadi and Yelena Mejova and Mirco Musolesi and Emiliano De\n  Cristofaro and Gianluca Stringhini", "title": "Kissing Cuisines: Exploring Worldwide Culinary Habits on the Web", "comments": "In the Web Science Track of 26th International World Wide Web\n  Conference (WWW 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Food and nutrition occupy an increasingly prevalent space on the web, and\ndishes and recipes shared online provide an invaluable mirror into culinary\ncultures and attitudes around the world. More specifically, ingredients,\nflavors, and nutrition information become strong signals of the taste\npreferences of individuals and civilizations. However, there is little\nunderstanding of these palate varieties. In this paper, we present a\nlarge-scale study of recipes published on the web and their content, aiming to\nunderstand cuisines and culinary habits around the world. Using a database of\nmore than 157K recipes from over 200 different cuisines, we analyze\ningredients, flavors, and nutritional values which distinguish dishes from\ndifferent regions, and use this knowledge to assess the predictability of\nrecipes from different cuisines. We then use country health statistics to\nunderstand the relation between these factors and health indicators of\ndifferent nations, such as obesity, diabetes, migration, and health\nexpenditure. Our results confirm the strong effects of geographical and\ncultural similarities on recipes, health indicators, and culinary preferences\nacross the globe.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 19:12:05 GMT"}, {"version": "v2", "created": "Thu, 23 Feb 2017 20:41:45 GMT"}, {"version": "v3", "created": "Wed, 5 Apr 2017 00:26:32 GMT"}, {"version": "v4", "created": "Tue, 25 Apr 2017 11:57:25 GMT"}], "update_date": "2017-04-26", "authors_parsed": [["Sajadmanesh", "Sina", ""], ["Jafarzadeh", "Sina", ""], ["Osia", "Seyed Ali", ""], ["Rabiee", "Hamid R.", ""], ["Haddadi", "Hamed", ""], ["Mejova", "Yelena", ""], ["Musolesi", "Mirco", ""], ["De Cristofaro", "Emiliano", ""], ["Stringhini", "Gianluca", ""]]}, {"id": "1610.08500", "submitter": "Nils Jansen", "authors": "Nils Jansen and Murat Cubuktepe and Ufuk Topcu", "title": "Synthesis of Shared Control Protocols with Provable Safety and\n  Performance Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalize synthesis of shared control protocols with correctness\nguarantees for temporal logic specifications. More specifically, we introduce a\nmodeling formalism in which both a human and an autonomy protocol can issue\ncommands to a robot towards performing a certain task. These commands are\nblended into a joint input to the robot. The autonomy protocol is synthesized\nusing an abstraction of possible human commands accounting for randomness in\ndecisions caused by factors such as fatigue or incomprehensibility of the\nproblem at hand. The synthesis is designed to ensure that the resulting robot\nbehavior satisfies given safety and performance specifications, e.g., in\ntemporal logic. Our solution is based on nonlinear programming and we address\nthe inherent scalability issue by presenting alternative methods. We assess the\nfeasibility and the scalability of the approach by an experimental evaluation.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 19:49:09 GMT"}], "update_date": "2016-10-28", "authors_parsed": [["Jansen", "Nils", ""], ["Cubuktepe", "Murat", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1610.08602", "submitter": "Iuliia Kotseruba", "authors": "Iuliia Kotseruba, John K. Tsotsos", "title": "A Review of 40 Years of Cognitive Architecture Research: Core Cognitive\n  Abilities and Practical Applications", "comments": "74 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a broad overview of the last 40 years of research on\ncognitive architectures. Although the number of existing architectures is\nnearing several hundred, most of the existing surveys do not reflect this\ngrowth and focus on a handful of well-established architectures. Thus, in this\nsurvey we wanted to shift the focus towards a more inclusive and high-level\noverview of the research on cognitive architectures. Our final set of 84\narchitectures includes 49 that are still actively developed, and borrow from a\ndiverse set of disciplines, spanning areas from psychoanalysis to neuroscience.\nTo keep the length of this paper within reasonable limits we discuss only the\ncore cognitive abilities, such as perception, attention mechanisms, action\nselection, memory, learning and reasoning. In order to assess the breadth of\npractical applications of cognitive architectures we gathered information on\nover 900 practical projects implemented using the cognitive architectures in\nour list. We use various visualization techniques to highlight overall trends\nin the development of the field. In addition to summarizing the current\nstate-of-the-art in the cognitive architecture research, this survey describes\na variety of methods and ideas that have been tried and their relative success\nin modeling human cognitive abilities, as well as which aspects of cognitive\nbehavior need more research with respect to their mechanistic counterparts and\nthus can further inform how cognitive science might progress.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2016 03:48:33 GMT"}, {"version": "v2", "created": "Fri, 8 Sep 2017 02:58:54 GMT"}, {"version": "v3", "created": "Sat, 13 Jan 2018 21:00:14 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Kotseruba", "Iuliia", ""], ["Tsotsos", "John K.", ""]]}, {"id": "1610.08606", "submitter": "Tiep H. Vu", "authors": "Tiep Vu and Vishal Monga", "title": "Fast Low-rank Shared Dictionary Learning for Image Classification", "comments": "Accepted version", "journal-ref": null, "doi": "10.1109/TIP.2017.2729885", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the fact that different objects possess distinct class-specific\nfeatures, they also usually share common patterns. This observation has been\nexploited partially in a recently proposed dictionary learning framework by\nseparating the particularity and the commonality (COPAR). Inspired by this, we\npropose a novel method to explicitly and simultaneously learn a set of common\npatterns as well as class-specific features for classification with more\nintuitive constraints. Our dictionary learning framework is hence characterized\nby both a shared dictionary and particular (class-specific) dictionaries. For\nthe shared dictionary, we enforce a low-rank constraint, i.e. claim that its\nspanning subspace should have low dimension and the coefficients corresponding\nto this dictionary should be similar. For the particular dictionaries, we\nimpose on them the well-known constraints stated in the Fisher discrimination\ndictionary learning (FDDL). Further, we develop new fast and accurate\nalgorithms to solve the subproblems in the learning step, accelerating its\nconvergence. The said algorithms could also be applied to FDDL and its\nextensions. The efficiencies of these algorithms are theoretically and\nexperimentally verified by comparing their complexities and running time with\nthose of other well-known dictionary learning methods. Experimental results on\nwidely used image datasets establish the advantages of our method over\nstate-of-the-art dictionary learning methods.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2016 03:58:17 GMT"}, {"version": "v2", "created": "Thu, 6 Jul 2017 15:57:15 GMT"}, {"version": "v3", "created": "Sun, 16 Jul 2017 02:39:50 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Vu", "Tiep", ""], ["Monga", "Vishal", ""]]}, {"id": "1610.08640", "submitter": "Marc Schoenauer", "authors": "Marti Luis (TAO, LRI), Fansi-Tchango Arsene (TRT), Navarro Laurent\n  (TRT), Marc Schoenauer (TAO, LRI)", "title": "Anomaly Detection with the Voronoi Diagram Evolutionary Algorithm", "comments": null, "journal-ref": "Parallel Problem Solving from Nature -- PPSN XIV, Sep 2016,\n  Edinburgh, France. Springer Verlag, 9921, pp.697-706, 2016, LNCS", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the Voronoi diagram-based evolutionary algorithm\n(VorEAl). VorEAl partitions input space in abnormal/normal subsets using\nVoronoi diagrams. Diagrams are evolved using a multi-objective bio-inspired\napproach in order to conjointly optimize classification metrics while also\nbeing able to represent areas of the data space that are not present in the\ntraining dataset. As part of the paper VorEAl is experimentally validated and\ncontrasted with similar approaches.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2016 07:05:54 GMT"}], "update_date": "2016-10-28", "authors_parsed": [["Luis", "Marti", "", "TAO, LRI"], ["Arsene", "Fansi-Tchango", "", "TRT"], ["Laurent", "Navarro", "", "TRT"], ["Schoenauer", "Marc", "", "TAO, LRI"]]}, {"id": "1610.08853", "submitter": "Ahmed Alaa", "authors": "Ahmed M. Alaa, Jinsung Yoon, Scott Hu, and Mihaela van der Schaar", "title": "Personalized Risk Scoring for Critical Care Prognosis using Mixtures of\n  Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: In this paper, we develop a personalized real-time risk scoring\nalgorithm that provides timely and granular assessments for the clinical acuity\nof ward patients based on their (temporal) lab tests and vital signs; the\nproposed risk scoring system ensures timely intensive care unit (ICU)\nadmissions for clinically deteriorating patients. Methods: The risk scoring\nsystem learns a set of latent patient subtypes from the offline electronic\nhealth record data, and trains a mixture of Gaussian Process (GP) experts,\nwhere each expert models the physiological data streams associated with a\nspecific patient subtype. Transfer learning techniques are used to learn the\nrelationship between a patient's latent subtype and her static admission\ninformation (e.g. age, gender, transfer status, ICD-9 codes, etc). Results:\nExperiments conducted on data from a heterogeneous cohort of 6,321 patients\nadmitted to Ronald Reagan UCLA medical center show that our risk score\nsignificantly and consistently outperforms the currently deployed risk scores,\nsuch as the Rothman index, MEWS, APACHE and SOFA scores, in terms of\ntimeliness, true positive rate (TPR), and positive predictive value (PPV).\nConclusion: Our results reflect the importance of adopting the concepts of\npersonalized medicine in critical care settings; significant accuracy and\ntimeliness gains can be achieved by accounting for the patients' heterogeneity.\nSignificance: The proposed risk scoring methodology can confer huge clinical\nand social benefits on more than 200,000 critically ill inpatient who exhibit\ncardiac arrests in the US every year.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2016 15:54:04 GMT"}], "update_date": "2016-10-28", "authors_parsed": [["Alaa", "Ahmed M.", ""], ["Yoon", "Jinsung", ""], ["Hu", "Scott", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1610.08865", "submitter": "Yasin Abbasi-Yadkori", "authors": "Yasin Abbasi-Yadkori and Peter L. Bartlett and Victor Gabillon and\n  Alan Malek", "title": "Hit-and-Run for Sampling and Planning in Non-Convex Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.AI math.CO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Hit-and-Run algorithm for planning and sampling problems in\nnon-convex spaces. For sampling, we show the first analysis of the Hit-and-Run\nalgorithm in non-convex spaces and show that it mixes fast as long as certain\nsmoothness conditions are satisfied. In particular, our analysis reveals an\nintriguing connection between fast mixing and the existence of smooth\nmeasure-preserving mappings from a convex space to the non-convex space. For\nplanning, we show advantages of Hit-and-Run compared to state-of-the-art\nplanning methods such as Rapidly-Exploring Random Trees.\n", "versions": [{"version": "v1", "created": "Wed, 19 Oct 2016 04:39:53 GMT"}], "update_date": "2016-10-28", "authors_parsed": [["Abbasi-Yadkori", "Yasin", ""], ["Bartlett", "Peter L.", ""], ["Gabillon", "Victor", ""], ["Malek", "Alan", ""]]}, {"id": "1610.08936", "submitter": "Maruan Al-Shedivat", "authors": "Maruan Al-Shedivat, Andrew Gordon Wilson, Yunus Saatchi, Zhiting Hu,\n  Eric P. Xing", "title": "Learning Scalable Deep Kernels with Recurrent Structure", "comments": "37 pages, 7 figures, 5 tables. Updated to the final version that\n  appears in JMLR, 18(82):1-37, 2017", "journal-ref": "Journal of Machine Learning Research (JMLR), JMLR 18(82):1-37,\n  2017", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications in speech, robotics, finance, and biology deal with\nsequential data, where ordering matters and recurrent structures are common.\nHowever, this structure cannot be easily captured by standard kernel functions.\nTo model such structure, we propose expressive closed-form kernel functions for\nGaussian processes. The resulting model, GP-LSTM, fully encapsulates the\ninductive biases of long short-term memory (LSTM) recurrent networks, while\nretaining the non-parametric probabilistic advantages of Gaussian processes. We\nlearn the properties of the proposed kernels by optimizing the Gaussian process\nmarginal likelihood using a new provably convergent semi-stochastic gradient\nprocedure and exploit the structure of these kernels for scalable training and\nprediction. This approach provides a practical representation for Bayesian\nLSTMs. We demonstrate state-of-the-art performance on several benchmarks, and\nthoroughly investigate a consequential autonomous driving application, where\nthe predictive uncertainties provided by GP-LSTM are uniquely valuable.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2016 19:08:57 GMT"}, {"version": "v2", "created": "Mon, 26 Jun 2017 06:49:55 GMT"}, {"version": "v3", "created": "Thu, 5 Oct 2017 01:14:56 GMT"}], "update_date": "2017-10-06", "authors_parsed": [["Al-Shedivat", "Maruan", ""], ["Wilson", "Andrew Gordon", ""], ["Saatchi", "Yunus", ""], ["Hu", "Zhiting", ""], ["Xing", "Eric P.", ""]]}, {"id": "1610.09018", "submitter": "Reimar Heinrich Leike", "authors": "Reimar H. Leike, Torsten A. En{\\ss}lin", "title": "Optimal Belief Approximation", "comments": "made improvements on the proof and the language", "journal-ref": null, "doi": "10.3390/e19080402", "report-no": null, "categories": "math.ST cs.AI physics.data-an stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Bayesian statistics probability distributions express beliefs. However,\nfor many problems the beliefs cannot be computed analytically and\napproximations of beliefs are needed. We seek a loss function that quantifies\nhow \"embarrassing\" it is to communicate a given approximation. We reproduce and\ndiscuss an old proof showing that there is only one ranking under the\nrequirements that (1) the best ranked approximation is the non-approximated\nbelief and (2) that the ranking judges approximations only by their predictions\nfor actual outcomes. The loss function that is obtained in the derivation is\nequal to the Kullback-Leibler divergence when normalized. This loss function is\nfrequently used in the literature. However, there seems to be confusion about\nthe correct order in which its functional arguments, the approximated and\nnon-approximated beliefs, should be used. The correct order ensures that the\nrecipient of a communication is only deprived of the minimal amount of\ninformation. We hope that the elementary derivation settles the apparent\nconfusion. For example when approximating beliefs with Gaussian distributions\nthe optimal approximation is given by moment matching. This is in contrast to\nmany suggested computational schemes.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2016 21:38:08 GMT"}, {"version": "v2", "created": "Tue, 29 Nov 2016 13:18:57 GMT"}, {"version": "v3", "created": "Tue, 18 Apr 2017 15:05:30 GMT"}, {"version": "v4", "created": "Mon, 12 Jun 2017 13:59:29 GMT"}, {"version": "v5", "created": "Tue, 4 Jul 2017 11:38:44 GMT"}, {"version": "v6", "created": "Thu, 3 Aug 2017 12:15:13 GMT"}], "update_date": "2017-08-07", "authors_parsed": [["Leike", "Reimar H.", ""], ["En\u00dflin", "Torsten A.", ""]]}, {"id": "1610.09064", "submitter": "Himabindu Lakkaraju", "authors": "Himabindu Lakkaraju, Ece Kamar, Rich Caruana, Eric Horvitz", "title": "Identifying Unknown Unknowns in the Open World: Representations and\n  Policies for Guided Exploration", "comments": "To appear in AAAI 2017; Presented at NIPS Workshop on Reliability in\n  ML, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive models deployed in the real world may assign incorrect labels to\ninstances with high confidence. Such errors or unknown unknowns are rooted in\nmodel incompleteness, and typically arise because of the mismatch between\ntraining data and the cases encountered at test time. As the models are blind\nto such errors, input from an oracle is needed to identify these failures. In\nthis paper, we formulate and address the problem of informed discovery of\nunknown unknowns of any given predictive model where unknown unknowns occur due\nto systematic biases in the training data. We propose a model-agnostic\nmethodology which uses feedback from an oracle to both identify unknown\nunknowns and to intelligently guide the discovery. We employ a two-phase\napproach which first organizes the data into multiple partitions based on the\nfeature similarity of instances and the confidence scores assigned by the\npredictive model, and then utilizes an explore-exploit strategy for discovering\nunknown unknowns across these partitions. We demonstrate the efficacy of our\nframework by varying the underlying causes of unknown unknowns across various\napplications. To the best of our knowledge, this paper presents the first\nalgorithmic approach to the problem of discovering unknown unknowns of\npredictive models.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2016 02:55:14 GMT"}, {"version": "v2", "created": "Tue, 6 Dec 2016 03:01:21 GMT"}, {"version": "v3", "created": "Sat, 10 Dec 2016 06:02:38 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Lakkaraju", "Himabindu", ""], ["Kamar", "Ece", ""], ["Caruana", "Rich", ""], ["Horvitz", "Eric", ""]]}, {"id": "1610.09077", "submitter": "Danis Wilson", "authors": "Danis J. Wilson and Wei Zhang", "title": "Integrating Topic Models and Latent Factors for Recommendation", "comments": "11 pages, 3 figures, version 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research of personalized recommendation techniques today has mostly\nparted into two mainstream directions, i.e., the factorization-based approaches\nand topic models. Practically, they aim to benefit from the numerical ratings\nand textual reviews, correspondingly, which compose two major information\nsources in various real-world systems. However, although the two approaches are\nsupposed to be correlated for their same goal of accurate recommendation, there\nstill lacks a clear theoretical understanding of how their objective functions\ncan be mathematically bridged to leverage the numerical ratings and textual\nreviews collectively, and why such a bridge is intuitively reasonable to match\nup their learning procedures for the rating prediction and top-N recommendation\ntasks, respectively.\n  In this work, we exposit with mathematical analysis that, the vector-level\nrandomization functions to coordinate the optimization objectives of\nfactorizational and topic models unfortunately do not exist at all, although\nthey are usually pre-assumed and intuitively designed in the literature.\nFortunately, we also point out that one can avoid the seeking of such a\nrandomization function by optimizing a Joint Factorizational Topic (JFT) model\ndirectly. We apply our JFT model to restaurant recommendation, and study its\nperformance in both normal and cross-city recommendation scenarios, where the\nlatter is an extremely difficult task for its inherent cold-start nature.\nExperimental results on real-world datasets verified the appealing performance\nof our approach against previous methods, on both rating prediction and top-N\nrecommendation tasks.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2016 04:20:54 GMT"}, {"version": "v2", "created": "Sat, 5 Nov 2016 20:36:43 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Wilson", "Danis J.", ""], ["Zhang", "Wei", ""]]}, {"id": "1610.09156", "submitter": "Indranil Pan", "authors": "Indranil Pan and Dirk Bester", "title": "Fuzzy Bayesian Learning", "comments": "16 pages, 12 figures, submitted", "journal-ref": "IEEE Transactions on Fuzzy Systems, Vol. 26, Issue 3, June 2018,\n  pp. 1719-1731", "doi": null, "report-no": null, "categories": "stat.ML cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel approach for learning from data using rule\nbased fuzzy inference systems where the model parameters are estimated using\nBayesian inference and Markov Chain Monte Carlo (MCMC) techniques. We show the\napplicability of the method for regression and classification tasks using\nsynthetic data-sets and also a real world example in the financial services\nindustry. Then we demonstrate how the method can be extended for knowledge\nextraction to select the individual rules in a Bayesian way which best explains\nthe given data. Finally we discuss the advantages and pitfalls of using this\nmethod over state-of-the-art techniques and highlight the specific class of\nproblems where this would be useful.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2016 10:23:42 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2018 10:28:07 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Pan", "Indranil", ""], ["Bester", "Dirk", ""]]}, {"id": "1610.09160", "submitter": "Simon Walk", "authors": "Simon Walk, Lisette Esp\\'in-Noboa, Denis Helic, Markus Strohmaier,\n  Mark Musen", "title": "How Users Explore Ontologies on the Web: A Study of NCBO's BioPortal\n  Usage Logs", "comments": "Under review for WWW'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.DL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontologies in the biomedical domain are numerous, highly specialized and very\nexpensive to develop. Thus, a crucial prerequisite for ontology adoption and\nreuse is effective support for exploring and finding existing ontologies.\nTowards that goal, the National Center for Biomedical Ontology (NCBO) has\ndeveloped BioPortal---an online repository designed to support users in\nexploring and finding more than 500 existing biomedical ontologies. In 2016,\nBioPortal represents one of the largest portals for exploration of semantic\nbiomedical vocabularies and terminologies, which is used by many researchers\nand practitioners. While usage of this portal is high, we know very little\nabout how exactly users search and explore ontologies and what kind of usage\npatterns or user groups exist in the first place. Deeper insights into user\nbehavior on such portals can provide valuable information to devise strategies\nfor a better support of users in exploring and finding existing ontologies, and\nthereby enable better ontology reuse. To that end, we study and group users\naccording to their browsing behavior on BioPortal using data mining techniques.\nAdditionally, we use the obtained groups to characterize and compare\nexploration strategies across ontologies. In particular, we were able to\nidentify seven distinct browsing-behavior types, which all make use of\ndifferent functionality provided by BioPortal. For example, Search Explorers\nmake extensive use of the search functionality while Ontology Tree Explorers\nmainly rely on the class hierarchy to explore ontologies. Further, we show that\nspecific characteristics of ontologies influence the way users explore and\ninteract with the website. Our results may guide the development of more\nuser-oriented systems for ontology exploration on the Web.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2016 10:33:26 GMT"}, {"version": "v2", "created": "Mon, 31 Oct 2016 20:44:33 GMT"}], "update_date": "2016-11-02", "authors_parsed": [["Walk", "Simon", ""], ["Esp\u00edn-Noboa", "Lisette", ""], ["Helic", "Denis", ""], ["Strohmaier", "Markus", ""], ["Musen", "Mark", ""]]}, {"id": "1610.09263", "submitter": "Vladimir Dzyuba", "authors": "Vladimir Dzyuba, Matthijs van Leeuwen, Luc De Raedt", "title": "Flexible constrained sampling with guarantees for pattern mining", "comments": "Accepted for publication in Data Mining & Knowledge Discovery journal\n  (ECML/PKDD 2017 journal track)", "journal-ref": null, "doi": "10.1007/s10618-017-0501-6", "report-no": null, "categories": "cs.AI cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pattern sampling has been proposed as a potential solution to the infamous\npattern explosion. Instead of enumerating all patterns that satisfy the\nconstraints, individual patterns are sampled proportional to a given quality\nmeasure. Several sampling algorithms have been proposed, but each of them has\nits limitations when it comes to 1) flexibility in terms of quality measures\nand constraints that can be used, and/or 2) guarantees with respect to sampling\naccuracy. We therefore present Flexics, the first flexible pattern sampler that\nsupports a broad class of quality measures and constraints, while providing\nstrong guarantees regarding sampling accuracy. To achieve this, we leverage the\nperspective on pattern mining as a constraint satisfaction problem and build\nupon the latest advances in sampling solutions in SAT as well as existing\npattern mining algorithms. Furthermore, the proposed algorithm is applicable to\na variety of pattern languages, which allows us to introduce and tackle the\nnovel task of sampling sets of patterns. We introduce and empirically evaluate\ntwo variants of Flexics: 1) a generic variant that addresses the well-known\nitemset sampling task and the novel pattern set sampling task as well as a wide\nrange of expressive constraints within these tasks, and 2) a specialized\nvariant that exploits existing frequent itemset techniques to achieve\nsubstantial speed-ups. Experiments show that Flexics is both accurate and\nefficient, making it a useful tool for pattern-based data exploration.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2016 15:21:53 GMT"}, {"version": "v2", "created": "Wed, 1 Mar 2017 16:18:39 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Dzyuba", "Vladimir", ""], ["van Leeuwen", "Matthijs", ""], ["De Raedt", "Luc", ""]]}, {"id": "1610.09296", "submitter": "Antonia Creswell", "authors": "Antonia Creswell, Kai Arulkumaran, Anil Anthony Bharath", "title": "Improving Sampling from Generative Autoencoders with Markov Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on generative autoencoders, such as variational or adversarial\nautoencoders, which jointly learn a generative model alongside an inference\nmodel. Generative autoencoders are those which are trained to softly enforce a\nprior on the latent distribution learned by the inference model. We call the\ndistribution to which the inference model maps observed samples, the learned\nlatent distribution, which may not be consistent with the prior. We formulate a\nMarkov chain Monte Carlo (MCMC) sampling process, equivalent to iteratively\ndecoding and encoding, which allows us to sample from the learned latent\ndistribution. Since, the generative model learns to map from the learned latent\ndistribution, rather than the prior, we may use MCMC to improve the quality of\nsamples drawn from the generative model, especially when the learned latent\ndistribution is far from the prior. Using MCMC sampling, we are able to reveal\npreviously unseen differences between generative autoencoders trained either\nwith or without a denoising criterion.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2016 16:17:03 GMT"}, {"version": "v2", "created": "Mon, 7 Nov 2016 15:17:32 GMT"}, {"version": "v3", "created": "Thu, 12 Jan 2017 16:13:14 GMT"}], "update_date": "2017-01-13", "authors_parsed": [["Creswell", "Antonia", ""], ["Arulkumaran", "Kai", ""], ["Bharath", "Anil Anthony", ""]]}, {"id": "1610.09372", "submitter": "Rasoul Kheiri", "authors": "Rasoul Kheiri", "title": "A Projective Simulation Scheme for Partially-Observable Multi-Agent\n  Systems", "comments": "28 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a kind of partial observability to the projective simulation\n(PS) learning method. It is done by adding a belief projection operator and an\nobservability parameter to the original framework of the efficiency of the PS\nmodel. I provide theoretical formulations, network representations, and\nsituated scenarios derived from the invasion toy problem as a starting point\nfor some multi-agent PS models.\n", "versions": [{"version": "v1", "created": "Sat, 29 Oct 2016 10:35:53 GMT"}, {"version": "v2", "created": "Sun, 4 Jun 2017 16:28:34 GMT"}, {"version": "v3", "created": "Wed, 4 Apr 2018 11:53:43 GMT"}, {"version": "v4", "created": "Wed, 22 May 2019 05:35:32 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Kheiri", "Rasoul", ""]]}, {"id": "1610.09409", "submitter": "Nils Jansen", "authors": "Sebastian Junges and Nils Jansen and Joost-Pieter Katoen and Ufuk\n  Topcu", "title": "Probabilistic Model Checking for Complex Cognitive Tasks -- A case study\n  in human-robot interaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes to use probabilistic model checking to synthesize optimal\nrobot policies in multi-tasking autonomous systems that are subject to\nhuman-robot interaction. Given the convincing empirical evidence that human\nbehavior can be related to reinforcement models, we take as input a\nwell-studied Q-table model of the human behavior for flexible scenarios. We\nfirst describe an automated procedure to distill a Markov decision process\n(MDP) for the human in an arbitrary but fixed scenario. The distinctive issue\nis that -- in contrast to existing models -- under-specification of the human\nbehavior is included. Probabilistic model checking is used to predict the\nhuman's behavior. Finally, the MDP model is extended with a robot model.\nOptimal robot policies are synthesized by analyzing the resulting two-player\nstochastic game. Experimental results with a prototypical implementation using\nPRISM show promising results.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2016 21:37:14 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Junges", "Sebastian", ""], ["Jansen", "Nils", ""], ["Katoen", "Joost-Pieter", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1610.09609", "submitter": "Keyu Lu", "authors": "Keyu Lu and Jian Li and Xiangjing An and Hangen He", "title": "Generalized Haar Filter based Deep Networks for Real-Time Object\n  Detection in Traffic Scene", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision-based object detection is one of the fundamental functions in numerous\ntraffic scene applications such as self-driving vehicle systems and advance\ndriver assistance systems (ADAS). However, it is also a challenging task due to\nthe diversity of traffic scene and the storage, power and computing source\nlimitations of the platforms for traffic scene applications. This paper\npresents a generalized Haar filter based deep network which is suitable for the\nobject detection tasks in traffic scene. In this approach, we first decompose a\nobject detection task into several easier local regression tasks. Then, we\nhandle the local regression tasks by using several tiny deep networks which\nsimultaneously output the bounding boxes, categories and confidence scores of\ndetected objects. To reduce the consumption of storage and computing resources,\nthe weights of the deep networks are constrained to the form of generalized\nHaar filter in training phase. Additionally, we introduce the strategy of\nsparse windows generation to improve the efficiency of the algorithm. Finally,\nwe perform several experiments to validate the performance of our proposed\napproach. Experimental results demonstrate that the proposed approach is both\nefficient and effective in traffic scene compared with the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 30 Oct 2016 07:02:57 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Lu", "Keyu", ""], ["Li", "Jian", ""], ["An", "Xiangjing", ""], ["He", "Hangen", ""]]}, {"id": "1610.09778", "submitter": "Jingbo Shang", "authors": "Jingbo Shang, Meng Jiang, Wenzhu Tong, Jinfeng Xiao, Jian Peng, Jiawei\n  Han", "title": "DPPred: An Effective Prediction Framework with Concise Discriminative\n  Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the literature, two series of models have been proposed to address\nprediction problems including classification and regression. Simple models,\nsuch as generalized linear models, have ordinary performance but strong\ninterpretability on a set of simple features. The other series, including\ntree-based models, organize numerical, categorical and high dimensional\nfeatures into a comprehensive structure with rich interpretable information in\nthe data.\n  In this paper, we propose a novel Discriminative Pattern-based Prediction\nframework (DPPred) to accomplish the prediction tasks by taking their\nadvantages of both effectiveness and interpretability. Specifically, DPPred\nadopts the concise discriminative patterns that are on the prefix paths from\nthe root to leaf nodes in the tree-based models. DPPred selects a limited\nnumber of the useful discriminative patterns by searching for the most\neffective pattern combination to fit generalized linear models. Extensive\nexperiments show that in many scenarios, DPPred provides competitive accuracy\nwith the state-of-the-art as well as the valuable interpretability for\ndevelopers and experts. In particular, taking a clinical application dataset as\na case study, our DPPred outperforms the baselines by using only 40 concise\ndiscriminative patterns out of a potentially exponentially large set of\npatterns.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 03:43:04 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Shang", "Jingbo", ""], ["Jiang", "Meng", ""], ["Tong", "Wenzhu", ""], ["Xiao", "Jinfeng", ""], ["Peng", "Jian", ""], ["Han", "Jiawei", ""]]}, {"id": "1610.09787", "submitter": "Dustin Tran", "authors": "Dustin Tran, Alp Kucukelbir, Adji B. Dieng, Maja Rudolph, Dawen Liang,\n  David M. Blei", "title": "Edward: A library for probabilistic modeling, inference, and criticism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.AI cs.PL stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic modeling is a powerful approach for analyzing empirical\ninformation. We describe Edward, a library for probabilistic modeling. Edward's\ndesign reflects an iterative process pioneered by George Box: build a model of\na phenomenon, make inferences about the model given data, and criticize the\nmodel's fit to the data. Edward supports a broad class of probabilistic models,\nefficient algorithms for inference, and many techniques for model criticism.\nThe library builds on top of TensorFlow to support distributed training and\nhardware such as GPUs. Edward enables the development of complex probabilistic\nmodels and their algorithms at a massive scale.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 04:56:13 GMT"}, {"version": "v2", "created": "Thu, 17 Nov 2016 06:47:13 GMT"}, {"version": "v3", "created": "Wed, 1 Feb 2017 01:37:04 GMT"}], "update_date": "2017-02-02", "authors_parsed": [["Tran", "Dustin", ""], ["Kucukelbir", "Alp", ""], ["Dieng", "Adji B.", ""], ["Rudolph", "Maja", ""], ["Liang", "Dawen", ""], ["Blei", "David M.", ""]]}, {"id": "1610.09882", "submitter": "Amit Mishra", "authors": "Jarryd Son and Amit Kumar Mishra", "title": "A Survey of Brain Inspired Technologies for Engineering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive engineering is a multi-disciplinary field and hence it is difficult\nto find a review article consolidating the leading developments in the field.\nThe in-credible pace at which technology is advancing pushes the boundaries of\nwhat is achievable in cognitive engineering. There are also differing\napproaches to cognitive engineering brought about from the multi-disciplinary\nnature of the field and the vastness of possible applications. Thus research\ncommunities require more frequent reviews to keep up to date with the latest\ntrends. In this paper we shall dis-cuss some of the approaches to cognitive\nengineering holistically to clarify the reasoning behind the different\napproaches and to highlight their strengths and weaknesses. We shall then show\nhow developments from seemingly disjointed views could be integrated to achieve\nthe same goal of creating cognitive machines. By reviewing the major\ncontributions in the different fields and showing the potential for a combined\napproach, this work intends to assist the research community in devising more\nunified methods and techniques for developing cognitive machines.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 11:58:29 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Son", "Jarryd", ""], ["Mishra", "Amit Kumar", ""]]}, {"id": "1610.09889", "submitter": "Zhe Wang", "authors": "Zhe Wang, Wei He, Hua Wu, Haiyang Wu, Wei Li, Haifeng Wang, Enhong\n  Chen", "title": "Chinese Poetry Generation with Planning based Neural Network", "comments": "Accepted paper at COLING 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chinese poetry generation is a very challenging task in natural language\nprocessing. In this paper, we propose a novel two-stage poetry generating\nmethod which first plans the sub-topics of the poem according to the user's\nwriting intent, and then generates each line of the poem sequentially, using a\nmodified recurrent neural network encoder-decoder framework. The proposed\nplanning-based method can ensure that the generated poem is coherent and\nsemantically consistent with the user's intent. A comprehensive evaluation with\nhuman judgments demonstrates that our proposed approach outperforms the\nstate-of-the-art poetry generating methods and the poem quality is somehow\ncomparable to human poets.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 12:16:39 GMT"}, {"version": "v2", "created": "Wed, 7 Dec 2016 03:56:19 GMT"}], "update_date": "2016-12-08", "authors_parsed": [["Wang", "Zhe", ""], ["He", "Wei", ""], ["Wu", "Hua", ""], ["Wu", "Haiyang", ""], ["Li", "Wei", ""], ["Wang", "Haifeng", ""], ["Chen", "Enhong", ""]]}, {"id": "1610.09894", "submitter": "Pedro Saleiro", "authors": "Daniela Ulloa, Pedro Saleiro, Rosaldo J. F. Rossetti, Elis Regina\n  Silva", "title": "Mining Social Media for Open Innovation in Transportation Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a novel framework for the development of new products and\nservices in transportation through an open innovation approach based on\nautomatic content analysis of social media data. The framework is able to\nextract users comments from Online Social Networks (OSN), to process and\nanalyze text through information extraction and sentiment analysis techniques\nto obtain relevant information about product reception on the market. A use\ncase was developed using the mobile application Uber, which is today one of the\nfastest growing technology companies in the world. We measured how a\ncontroversial, highly diffused event influences the volume of tweets about Uber\nand the perception of its users. While there is no change in the image of Uber,\na large increase in the number of tweets mentioning the company is observed,\nwhich meant a free and important diffusion of its product.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 12:25:57 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Ulloa", "Daniela", ""], ["Saleiro", "Pedro", ""], ["Rossetti", "Rosaldo J. F.", ""], ["Silva", "Elis Regina", ""]]}, {"id": "1610.09900", "submitter": "Atilim Gunes Baydin", "authors": "Tuan Anh Le, Atilim Gunes Baydin, Frank Wood", "title": "Inference Compilation and Universal Probabilistic Programming", "comments": "11 pages, 6 figures", "journal-ref": "In Proceedings of the 20th International Conference on Artificial\n  Intelligence and Statistics (AISTATS 2017), 54:1338--1348. Proceedings of\n  Machine Learning Research. Fort Lauderdale, FL, USA: PMLR", "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a method for using deep neural networks to amortize the cost of\ninference in models from the family induced by universal probabilistic\nprogramming languages, establishing a framework that combines the strengths of\nprobabilistic programming and deep learning methods. We call what we do\n\"compilation of inference\" because our method transforms a denotational\nspecification of an inference problem in the form of a probabilistic program\nwritten in a universal programming language into a trained neural network\ndenoted in a neural network specification language. When at test time this\nneural network is fed observational data and executed, it performs approximate\ninference in the original model specified by the probabilistic program. Our\ntraining objective and learning procedure are designed to allow the trained\nneural network to be used as a proposal distribution in a sequential importance\nsampling inference engine. We illustrate our method on mixture models and\nCaptcha solving and show significant speedups in the efficiency of inference.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 12:53:20 GMT"}, {"version": "v2", "created": "Thu, 2 Mar 2017 17:11:01 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Le", "Tuan Anh", ""], ["Baydin", "Atilim Gunes", ""], ["Wood", "Frank", ""]]}, {"id": "1610.09950", "submitter": "Vincent Zheng", "authors": "Vincent W. Zheng, Sandro Cavallari, Hongyun Cai, Kevin Chen-Chuan\n  Chang, Erik Cambria", "title": "From Node Embedding To Community Embedding", "comments": "Code available at\n  https://github.com/andompesta/nodeembedding-to-communityembedding", "journal-ref": "KDD WISDOM 2016", "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the existing graph embedding methods focus on nodes, which aim to\noutput a vector representation for each node in the graph such that two nodes\nbeing \"close\" on the graph are close too in the low-dimensional space. Despite\nthe success of embedding individual nodes for graph analytics, we notice that\nan important concept of embedding communities (i.e., groups of nodes) is\nmissing. Embedding communities is useful, not only for supporting various\ncommunity-level applications, but also to help preserve community structure in\ngraph embedding. In fact, we see community embedding as providing a\nhigher-order proximity to define the node closeness, whereas most of the\npopular graph embedding methods focus on first-order and/or second-order\nproximities. To learn the community embedding, we hinge upon the insight that\ncommunity embedding and node embedding reinforce with each other. As a result,\nwe propose ComEmbed, the first community embedding method, which jointly\noptimizes the community embedding and node embedding together. We evaluate\nComEmbed on real-world data sets. We show it outperforms the state-of-the-art\nbaselines in both tasks of node classification and community prediction.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 14:50:41 GMT"}, {"version": "v2", "created": "Thu, 14 Sep 2017 06:35:39 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Zheng", "Vincent W.", ""], ["Cavallari", "Sandro", ""], ["Cai", "Hongyun", ""], ["Chang", "Kevin Chen-Chuan", ""], ["Cambria", "Erik", ""]]}, {"id": "1610.09964", "submitter": "Vinu E V", "authors": "Vinu E.V and P Sreenivasa Kumar", "title": "Ontology Verbalization using Semantic-Refinement", "comments": "Currently this paper is under review in the Semantic Web Journal.\n  arXiv admin note: text overlap with arXiv:1607.07027", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We propose a rule-based technique to generate redundancy-free NL descriptions\nof OWL entities.The existing approaches which address the problem of\nverbalizing OWL ontologies generate NL text segments which are close to their\ncounterpart OWL statements.Some of these approaches also perform grouping and\naggregating of these NL text segments to generate a more fluent and\ncomprehensive form of the content.Restricting our attention to description of\nindividuals and concepts, we find that the approach currently followed in the\navailable tools is that of determining the set of all logical conditions that\nare satisfied by the given individual/concept name and translate these\nconditions verbatim into corresponding NL descriptions.Human-understandability\nof such descriptions is affected by the presence of repetitions and\nredundancies, as they have high fidelity to their OWL representation.In the\nliterature, no efforts had been taken to remove redundancies and repetitions at\nthe logical-level before generating the NL descriptions of entities and we find\nthis to be the main reason for lack of readability of the generated\ntext.Herein, we propose a technique called semantic-refinement(SR) to generate\nmeaningful and easily-understandable descriptions of individuals and concepts\nof a given OWLontology.We identify the combinations of OWL/DL constructs that\nlead to repetitive/redundant descriptions and propose a series of refinement\nrules to rewrite the conditions that are satisfied by an individual/concept in\na meaning-preserving manner.The reduced set of conditions are then employed for\ngenerating NL descriptions.Our experiments show that, SR leads to significantly\nimproved descriptions of ontology entities.We also test the effectiveness and\nusefulness of the the generated descriptions for the purpose of validating the\nontologies and find that the proposed technique is indeed helpful in the\ncontext.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 15:20:14 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["E.", "Vinu", "V"], ["Kumar", "P Sreenivasa", ""]]}]