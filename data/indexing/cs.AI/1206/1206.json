[{"id": "1206.0111", "submitter": "Bjoern Andres", "authors": "Bjoern Andres, Thorsten Beier, Joerg H. Kappes", "title": "OpenGM: A C++ Library for Discrete Graphical Models", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OpenGM is a C++ template library for defining discrete graphical models and\nperforming inference on these models, using a wide range of state-of-the-art\nalgorithms. No restrictions are imposed on the factor graph to allow for\nhigher-order factors and arbitrary neighborhood structures. Large models with\nrepetitive structure are handled efficiently because (i) functions that occur\nrepeatedly need to be stored only once, and (ii) distinct functions can be\nimplemented differently, using different encodings alongside each other in the\nsame model. Several parametric functions (e.g. metrics), sparse and dense value\ntables are provided and so is an interface for custom C++ code. Algorithms are\nseparated by design from the representation of graphical models and are easily\nexchangeable. OpenGM, its algorithms, HDF5 file format and command line tools\nare modular and extendible.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2012 07:36:54 GMT"}], "update_date": "2012-06-04", "authors_parsed": [["Andres", "Bjoern", ""], ["Beier", "Thorsten", ""], ["Kappes", "Joerg H.", ""]]}, {"id": "1206.0259", "submitter": "Stevan Harnad", "authors": "Stevan Harnad", "title": "The Causal Topography of Cognition", "comments": "11 pages, 0 figures, 10 references, Journal of Cognitive Science 13\n  2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The causal structure of cognition can be simulated but not implemented\ncomputationally, just as the causal structure of a comet can be simulated but\nnot implemented computationally. The only thing that allows us even to imagine\notherwise is that cognition, unlike a comet, is invisible (to all but the\ncognizer).\n", "versions": [{"version": "v1", "created": "Sat, 25 Feb 2012 14:59:49 GMT"}, {"version": "v2", "created": "Mon, 4 Jun 2012 00:45:35 GMT"}], "update_date": "2012-06-05", "authors_parsed": [["Harnad", "Stevan", ""]]}, {"id": "1206.0855", "submitter": "Pouyan  Rafiei Fard", "authors": "Pouyan Rafiei Fard, Keyvan Yahya", "title": "A Mixed Observability Markov Decision Process Model for Musical Pitch", "comments": "In 5th International Workshop on Machine Learning and Music,\n  Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partially observable Markov decision processes have been widely used to\nprovide models for real-world decision making problems. In this paper, we will\nprovide a method in which a slightly different version of them called Mixed\nobservability Markov decision process, MOMDP, is going to join with our\nproblem. Basically, we aim at offering a behavioural model for interaction of\nintelligent agents with musical pitch environment and we will show that how\nMOMDP can shed some light on building up a decision making model for musical\npitch conveniently.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2012 09:35:44 GMT"}], "update_date": "2012-06-06", "authors_parsed": [["Fard", "Pouyan Rafiei", ""], ["Yahya", "Keyvan", ""]]}, {"id": "1206.0918", "submitter": "Omri Mohamed Nazih", "authors": "Abdelkader Heni, Mohamed Nazih Omri and Adel Alimi", "title": "Fuzzy Knowledge Representation Based on Possibilistic and Necessary\n  Bayesian Networks", "comments": "ISSN: 1790-0832", "journal-ref": "WSEAS Transactions on Information Science & Applications Issue 2,\n  Volume 3, February 2006, 224-231", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the framework proposed in this paper, we address the issue of\nextending the certain networks to a fuzzy certain networks in order to cope\nwith a vagueness and limitations of existing models for decision under\nimprecise and uncertain knowledge. This paper proposes a framework that\ncombines two disciplines to exploit their own advantages in uncertain and\nimprecise knowledge representation problems. The framework proposed is a\npossibilistic logic based one in which Bayesian nodes and their properties are\nrepresented by local necessity-valued knowledge base. Data in properties are\ninterpreted as set of valuated formulas. In our contribution possibilistic\nBayesian networks have a qualitative part and a quantitative part, represented\nby local knowledge bases. The general idea is to study how a fusion of these\ntwo formalisms would permit representing compact way to solve efficiently\nproblems for knowledge representation. We show how to apply possibility and\nnecessity measures to the problem of knowledge representation with large scale\ndata. On the other hand fuzzification of crisp certainty degrees to fuzzy\nvariables improves the quality of the network and tends to bring smoothness and\nrobustness in the network performance. The general aim is to provide a new\napproach for decision under uncertainty that combines three methodologies:\nBayesian networks certainty distribution and fuzzy logic.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2012 13:13:21 GMT"}], "update_date": "2012-06-06", "authors_parsed": [["Heni", "Abdelkader", ""], ["Omri", "Mohamed Nazih", ""], ["Alimi", "Adel", ""]]}, {"id": "1206.0925", "submitter": "Omri Mohamed Nazih", "authors": "Mohamed Nazih Omri", "title": "Possibilistic Pertinence Feedback and Semantic Networks for Goal's\n  Extraction", "comments": null, "journal-ref": "Asian Journal of Information Technology (4):258-265 - 2004", "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pertinence Feedback is a technique that enables a user to interactively\nexpress his information requirement by modifying his original query formulation\nwith further information. This information is provided by explicitly confirming\nthe pertinent of some indicating objects and/or goals extracted by the system.\nObviously the user cannot mark objects and/or goals as pertinent until some are\nextracted, so the first search has to be initiated by a query and the initial\nquery specification has to be good enough to pick out some pertinent objects\nand/or goals from the Semantic Network. In this paper we present a short survey\nof fuzzy and Semantic approaches to Knowledge Extraction. The goal of such\napproaches is to define flexible Knowledge Extraction Systems able to deal with\nthe inherent vagueness and uncertainty of the Extraction process. It has long\nbeen recognised that interactivity improves the effectiveness of Knowledge\nExtraction systems. Novice user's queries are the most natural and interactive\nmedium of communication and recent progress in recognition is making it\npossible to build systems that interact with the user. However, given the\ntypical novice user's queries submitted to Knowledge Extraction Systems, it is\neasy to imagine that the effects of goal recognition errors in novice user's\nqueries must be severely destructive on the system's effectiveness. The\nexperimental work reported in this paper shows that the use of possibility\ntheory in classical Knowledge Extraction techniques for novice user's query\nprocessing is more robust than the use of the probability theory. Moreover,\nboth possibilistic and probabilistic pertinence feedback can be effectively\nemployed to improve the effectiveness of novice user's query processing.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2012 13:30:37 GMT"}], "update_date": "2012-06-06", "authors_parsed": [["Omri", "Mohamed Nazih", ""]]}, {"id": "1206.0976", "submitter": "Omri Mohamed Nazih", "authors": "Amen Ajroud, Mohamed Nazih Omri, Habib Youssef and Salem Benferhat", "title": "Loopy Belief Propagation in Bayesian Networks : origin and possibilistic\n  perspectives", "comments": "The International Conference on Computing & e-Systems - 2007", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a synthesis of the work performed on two inference\nalgorithms: the Pearl's belief propagation (BP) algorithm applied to Bayesian\nnetworks without loops (i.e. polytree) and the Loopy belief propagation (LBP)\nalgorithm (inspired from the BP) which is applied to networks containing\nundirected cycles. It is known that the BP algorithm, applied to Bayesian\nnetworks with loops, gives incorrect numerical results i.e. incorrect posterior\nprobabilities. Murphy and al. [7] find that the LBP algorithm converges on\nseveral networks and when this occurs, LBP gives a good approximation of the\nexact posterior probabilities. However this algorithm presents an oscillatory\nbehaviour when it is applied to QMR (Quick Medical Reference) network [15].\nThis phenomenon prevents the LBP algorithm from converging towards a good\napproximation of posterior probabilities. We believe that the translation of\nthe inference computation problem from the probabilistic framework to the\npossibilistic framework will allow performance improvement of LBP algorithm. We\nhope that an adaptation of this algorithm to a possibilistic causal network\nwill show an improvement of the convergence of LBP.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2012 16:14:16 GMT"}], "update_date": "2012-06-06", "authors_parsed": [["Ajroud", "Amen", ""], ["Omri", "Mohamed Nazih", ""], ["Youssef", "Habib", ""], ["Benferhat", "Salem", ""]]}, {"id": "1206.1061", "submitter": "Omri Mohamed Nazih", "authors": "Mohamed Nazih Omri and Mohamed Ali Mahjoub", "title": "Use of Fuzzy Sets in Semantic Nets for Providing On-Line Assistance to\n  User of Technological Systems", "comments": null, "journal-ref": "International Workshop on Intelligent Knowledge Management\n  Techniques I-KOMAT'2002-KES'2002. p. 1444-1449. Podere d'Ombriano, Crema,\n  Italy, (2002)", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main objective of this paper is to develop a new semantic Network\nstructure, based on the fuzzy sets theory, used in Artificial Intelligent\nsystem in order to provide effective on-line assistance to users of new\ntechnological systems. This Semantic Networks is used to describe the knowledge\nof an \"ideal\" expert while fuzzy sets are used both to describe the approximate\nand uncertain knowledge of novice users who intervene to match fuzzy labels of\na query with categories from an \"ideal\" expert. The technical system we\nconsider is a word processor software, with Objects such as \"Word\" and Goals\nsuch as \"Cut\" or \"Copy\". We suggest to consider the set of the system's Goals\nas a set of linguistic variables to which corresponds a set of possible\nlinguistic values based on the fuzzy set. We consider, therefore, a set of\ninterpretation's levels for these possible values to which corresponds a set of\nmembership functions. We also propose a method to measure the similarity degree\nbetween different fuzzy linguistic variables for the partition of the semantic\nnetwork in class of similar objects to make easy the diagnosis of the user's\nfuzzy queries.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2012 20:05:48 GMT"}], "update_date": "2012-06-07", "authors_parsed": [["Omri", "Mohamed Nazih", ""], ["Mahjoub", "Mohamed Ali", ""]]}, {"id": "1206.1069", "submitter": "Diederik Aerts", "authors": "Diederik Aerts, Liane Gabora and Sandro Sozzo", "title": "Concepts and Their Dynamics: A Quantum-Theoretic Modeling of Human\n  Thought", "comments": "31 pages, 5 figures", "journal-ref": "Topics in Cognitive Science, 5, pp. 737-772, 2013", "doi": "10.1111/tops.12042", "report-no": null, "categories": "cs.AI cs.CL quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze different aspects of our quantum modeling approach of human\nconcepts, and more specifically focus on the quantum effects of contextuality,\ninterference, entanglement and emergence, illustrating how each of them makes\nits appearance in specific situations of the dynamics of human concepts and\ntheir combinations. We point out the relation of our approach, which is based\non an ontology of a concept as an entity in a state changing under influence of\na context, with the main traditional concept theories, i.e. prototype theory,\nexemplar theory and theory theory. We ponder about the question why quantum\ntheory performs so well in its modeling of human concepts, and shed light on\nthis question by analyzing the role of complex amplitudes, showing how they\nallow to describe interference in the statistics of measurement outcomes, while\nin the traditional theories statistics of outcomes originates in classical\nprobability weights, without the possibility of interference. The relevance of\ncomplex numbers, the appearance of entanglement, and the role of Fock space in\nexplaining contextual emergence, all as unique features of the quantum\nmodeling, are explicitly revealed in this paper by analyzing human concepts and\ntheir dynamics.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2012 20:24:34 GMT"}, {"version": "v2", "created": "Sat, 5 Jan 2013 02:33:27 GMT"}], "update_date": "2014-03-18", "authors_parsed": [["Aerts", "Diederik", ""], ["Gabora", "Liane", ""], ["Sozzo", "Sandro", ""]]}, {"id": "1206.1074", "submitter": "Iztok Fister", "authors": "Iztok Fister, Iztok Fister Jr., Janez Brest, Viljem \\v{Z}umer", "title": "Memetic Artificial Bee Colony Algorithm for Large-Scale Global\n  Optimization", "comments": "CONFERENCE: IEEE Congress on Evolutionary Computation, Brisbane,\n  Australia, 2012", "journal-ref": null, "doi": "10.1109/CEC.2012.6252938", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memetic computation (MC) has emerged recently as a new paradigm of efficient\nalgorithms for solving the hardest optimization problems. On the other hand,\nartificial bees colony (ABC) algorithms demonstrate good performances when\nsolving continuous and combinatorial optimization problems. This study tries to\nuse these technologies under the same roof. As a result, a memetic ABC (MABC)\nalgorithm has been developed that is hybridized with two local search\nheuristics: the Nelder-Mead algorithm (NMA) and the random walk with direction\nexploitation (RWDE). The former is attended more towards exploration, while the\nlatter more towards exploitation of the search space. The stochastic adaptation\nrule was employed in order to control the balancing between exploration and\nexploitation. This MABC algorithm was applied to a Special suite on Large Scale\nContinuous Global Optimization at the 2012 IEEE Congress on Evolutionary\nComputation. The obtained results the MABC are comparable with the results of\nDECC-G, DECC-G*, and MLCC.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2012 21:04:10 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Fister", "Iztok", ""], ["Fister", "Iztok", "Jr."], ["Brest", "Janez", ""], ["\u017dumer", "Viljem", ""]]}, {"id": "1206.1291", "submitter": "Reza Tavoli", "authors": "Mohammadreza Keyvanpour, Reza Tavoli", "title": "Feature Weighting for Improving Document Image Retrieval System\n  Performance", "comments": null, "journal-ref": "International Journal of Computer Science Issues, Vol 9, Issue 3,\n  No 3 (2012) 125-130", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature weighting is a technique used to approximate the optimal degree of\ninfluence of individual features. This paper presents a feature weighting\nmethod for Document Image Retrieval System (DIRS) based on keyword spotting. In\nthis method, we weight the feature using coefficient of multiple correlations.\nCoefficient of multiple correlations can be used to describe the synthesized\neffects and correlation of each feature. The aim of this paper is to show that\nfeature weighting increases the performance of DIRS. After applying the feature\nweighting method to DIRS the average precision is 93.23% and average recall\nbecome 98.66% respectively\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2012 18:20:27 GMT"}], "update_date": "2012-06-11", "authors_parsed": [["Keyvanpour", "Mohammadreza", ""], ["Tavoli", "Reza", ""]]}, {"id": "1206.1319", "submitter": "Omri Mohamed Nazih", "authors": "Abdelkader Heni, Mohamed Nazih Omri and Adel Alimi", "title": "Certain Bayesian Network based on Fuzzy knowledge Bases", "comments": "arXiv admin note: substantial text overlap with 1206.0918", "journal-ref": "International Conference on Internet &, Information Technology in\n  Modern Organizations (5th IBIMA), p. 826-832, Cairo, Egypt, December, 13-15\n  (2005)", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we are trying to examine trade offs between fuzzy logic and\ncertain Bayesian networks and we propose to combine their respective advantages\ninto fuzzy certain Bayesian networks (FCBN), a certain Bayesian networks of\nfuzzy random variables. This paper deals with different definitions and\nclassifications of uncertainty, sources of uncertainty, and theories and\nmethodologies presented to deal with uncertainty. Fuzzification of crisp\ncertainty degrees to fuzzy variables improves the quality of the network and\ntends to bring smoothness and robustness in the network performance. The aim is\nto provide a new approach for decision under uncertainty that combines three\nmethodologies: Bayesian networks certainty distribution and fuzzy logic. Within\nthe framework proposed in this paper, we address the issue of extending the\ncertain networks to a fuzzy certain networks in order to cope with a vagueness\nand limitations of existing models for decision under imprecise and uncertain\nknowledge.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2012 19:53:43 GMT"}], "update_date": "2012-06-07", "authors_parsed": [["Heni", "Abdelkader", ""], ["Omri", "Mohamed Nazih", ""], ["Alimi", "Adel", ""]]}, {"id": "1206.1414", "submitter": "Amin Nezarat", "authors": "Shahab Firouzi (Department of Computer engineering, Yazd Branch,\n  Islamic Azad University, Yazd, Iran), Amin Nezarat (Department of Computer\n  engineering, Yazd Branch, Islamic Azad University, Yazd, Iran)", "title": "An Intelligent Approach for Negotiating between chains in Supply Chain\n  Management Systems", "comments": "10", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Holding commercial negotiations and selecting the best supplier in supply\nchain management systems are among weaknesses of producers in production\nprocess. Therefore, applying intelligent systems may have an effective role in\nincreased speed and improved quality in the selections .This paper introduces a\nsystem which tries to trade using multi-agents systems and holding negotiations\nbetween any agents. In this system, an intelligent agent is considered for each\nsegment of chains which it tries to send order and receive the response with\nattendance in negotiation medium and communication with other agents .This\npaper introduces how to communicate between agents, characteristics of\nmulti-agent and standard registration medium of each agent in the environment.\nJADE (Java Application Development Environment) was used for implementation and\nsimulation of agents cooperation.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2012 07:50:43 GMT"}], "update_date": "2012-06-08", "authors_parsed": [["Firouzi", "Shahab", "", "Department of Computer engineering, Yazd Branch,\n  Islamic Azad University, Yazd, Iran"], ["Nezarat", "Amin", "", "Department of Computer\n  engineering, Yazd Branch, Islamic Azad University, Yazd, Iran"]]}, {"id": "1206.1418", "submitter": "Dinh Que Tran", "authors": "Thuy Van T. Duong, Dinh Que Tran and Cong Hung Tran", "title": "A weighted combination similarity measure for mobility patterns in\n  wireless networks", "comments": "15 pages, 2 figures; International Journal of Computer Networks &\n  Communications (IJCNC) http://airccse.org/journal/ijc2012.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The similarity between trajectory patterns in clustering has played an\nimportant role in discovering movement behaviour of different groups of mobile\nobjects. Several approaches have been proposed to measure the similarity\nbetween sequences in trajectory data. Most of these measures are based on\nEuclidean space or on spatial network and some of them have been concerned with\ntemporal aspect or ordering types. However, they are not appropriate to\ncharacteristics of spatiotemporal mobility patterns in wireless networks. In\nthis paper, we propose a new similarity measure for mobility patterns in\ncellular space of wireless network. The framework for constructing our measure\nis composed of two phases as follows. First, we present formal definitions to\ncapture mathematically two spatial and temporal similarity measures for\nmobility patterns. And then, we define the total similarity measure by means of\na weighted combination of these similarities. The truth of the partial and\ntotal similarity measures are proved in mathematics. Furthermore, instead of\nthe time interval or ordering, our work makes use of the timestamp at which two\nmobility patterns share the same cell. A case study is also described to give a\ncomparison of the combination measure with other ones.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2012 07:58:18 GMT"}], "update_date": "2012-06-08", "authors_parsed": [["Duong", "Thuy Van T.", ""], ["Tran", "Dinh Que", ""], ["Tran", "Cong Hung", ""]]}, {"id": "1206.1458", "submitter": "Shervan Fekri ershad", "authors": "Shervan Fekri Ershad and Sattar Hashemi", "title": "Dispelling Classes Gradually to Improve Quality of Feature Reduction\n  Approaches", "comments": "11 Pages, 5 Figure, 7 Tables; Advanced Computing: An International\n  Journal (ACIJ), Vol.3, No.3, May 2012", "journal-ref": null, "doi": "10.5121/acij.2012.3310", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature reduction is an important concept which is used for reducing\ndimensions to decrease the computation complexity and time of classification.\nSince now many approaches have been proposed for solving this problem, but\nalmost all of them just presented a fix output for each input dataset that some\nof them aren't satisfied cases for classification. In this we proposed an\napproach as processing input dataset to increase accuracy rate of each feature\nextraction methods. First of all, a new concept called dispelling classes\ngradually (DCG) is proposed to increase separability of classes based on their\nlabels. Next, this method is used to process input dataset of the feature\nreduction approaches to decrease the misclassification error rate of their\noutputs more than when output is achieved without any processing. In addition\nour method has a good quality to collate with noise based on adapting dataset\nwith feature reduction approaches. In the result part, two conditions (With\nprocess and without that) are compared to support our idea by using some of UCI\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2012 11:52:21 GMT"}], "update_date": "2012-06-08", "authors_parsed": [["Ershad", "Shervan Fekri", ""], ["Hashemi", "Sattar", ""]]}, {"id": "1206.1534", "submitter": "Sumathi Gnanasekaran", "authors": "G. Sumathi and R. Raju", "title": "Software Aging Analysis of Web Server Using Neural Networks", "comments": "11 pages, 8 figures, 1 table; International Journal of Artificial\n  Intelligence & Applications (IJAIA), Vol.3, No.3, May 2012", "journal-ref": null, "doi": "10.5121/ijaia.2012.3302", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software aging is a phenomenon that refers to progressive performance\ndegradation or transient failures or even crashes in long running software\nsystems such as web servers. It mainly occurs due to the deterioration of\noperating system resource, fragmentation and numerical error accumulation. A\nprimitive method to fight against software aging is software rejuvenation.\nSoftware rejuvenation is a proactive fault management technique aimed at\ncleaning up the system internal state to prevent the occurrence of more severe\ncrash failures in the future. It involves occasionally stopping the running\nsoftware, cleaning its internal state and restarting it. An optimized schedule\nfor performing the software rejuvenation has to be derived in advance because a\nlong running application could not be put down now and then as it may lead to\nwaste of cost. This paper proposes a method to derive an accurate and optimized\nschedule for rejuvenation of a web server (Apache) by using Radial Basis\nFunction (RBF) based Feed Forward Neural Network, a variant of Artificial\nNeural Networks (ANN). Aging indicators are obtained through experimental setup\ninvolving Apache web server and clients, which acts as input to the neural\nnetwork model. This method is better than existing ones because usage of RBF\nleads to better accuracy and speed in convergence.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2012 15:52:46 GMT"}], "update_date": "2012-06-08", "authors_parsed": [["Sumathi", "G.", ""], ["Raju", "R.", ""]]}, {"id": "1206.1557", "submitter": "Jay Gholap", "authors": "Jay Gholap, Anurag Ingole, Jayesh Gohil, Shailesh Gargade and Vahida\n  Attar", "title": "Soil Data Analysis Using Classification Techniques and Soil Attribute\n  Prediction", "comments": "4 pages, published in International Journal of Computer Science\n  Issues, Volume 9, Issue 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agricultural research has been profited by technical advances such as\nautomation, data mining. Today, data mining is used in a vast areas and many\noff-the-shelf data mining system products and domain specific data mining\napplication soft wares are available, but data mining in agricultural soil\ndatasets is a relatively a young research field. The large amounts of data that\nare nowadays virtually harvested along with the crops have to be analyzed and\nshould be used to their full extent. This research aims at analysis of soil\ndataset using data mining techniques. It focuses on classification of soil\nusing various algorithms available. Another important purpose is to predict\nuntested attributes using regression technique, and implementation of automated\nsoil sample classification.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2012 17:28:20 GMT"}], "update_date": "2012-06-08", "authors_parsed": [["Gholap", "Jay", ""], ["Ingole", "Anurag", ""], ["Gohil", "Jayesh", ""], ["Gargade", "Shailesh", ""], ["Attar", "Vahida", ""]]}, {"id": "1206.1579", "submitter": "Daniel Karapetyan Dr", "authors": "Mohammad Reihaneh and Daniel Karapetyan", "title": "An Efficient Hybrid Ant Colony System for the Generalized Traveling\n  Salesman Problem", "comments": "7 pages", "journal-ref": "Algorithmic Operations Research Vol. 7 (2012) 21-28", "doi": null, "report-no": null, "categories": "cs.AI math.CO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Generalized Traveling Salesman Problem (GTSP) is an extension of the\nwell-known Traveling Salesman Problem (TSP), where the node set is partitioned\ninto clusters, and the objective is to find the shortest cycle visiting each\ncluster exactly once. In this paper, we present a new hybrid Ant Colony System\n(ACS) algorithm for the symmetric GTSP. The proposed algorithm is a\nmodification of a simple ACS for the TSP improved by an efficient GTSP-specific\nlocal search procedure. Our extensive computational experiments show that the\nuse of the local search procedure dramatically improves the performance of the\nACS algorithm, making it one of the most successful GTSP metaheuristics to\ndate.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2012 19:01:11 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2012 05:53:19 GMT"}], "update_date": "2012-07-06", "authors_parsed": [["Reihaneh", "Mohammad", ""], ["Karapetyan", "Daniel", ""]]}, {"id": "1206.1678", "submitter": "Magesh George", "authors": "G. Mageshwari and E. Grace Mary Kanaga", "title": "A Distributed Optimized Patient Scheduling using Partial Information", "comments": "11 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A software agent may be a member of a Multi-Agent System (MAS) which is\ncollectively performing a range of complex and intelligent tasks. In the\nhospital, scheduling decisions are finding difficult to schedule because of the\ndynamic changes and distribution. In order to face this problem with dynamic\nchanges in the hospital, a new method, Distributed Optimized Patient Scheduling\nwith Grouping (DOPSG) has been proposed. The goal of this method is that there\nis no necessity for knowing patient agents information globally. With minimal\ninformation this method works effectively. Scheduling problem can be solved for\nmultiple departments in the hospital. Patient agents have been scheduled to the\nresource agent based on the patient priority to reduce the waiting time of\npatient agent and to reduce idle time of resources.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2012 07:02:06 GMT"}], "update_date": "2012-06-11", "authors_parsed": [["Mageshwari", "G.", ""], ["Kanaga", "E. Grace Mary", ""]]}, {"id": "1206.1724", "submitter": "Omri Mohamed Nazih", "authors": "Mohamed Nazih Omri", "title": "Softening Fuzzy Knowledge Representation Tool with the Learning of New\n  Words in Natural Language", "comments": null, "journal-ref": "International Conference on Artificial and Computational\n  Intelligence for Decision, Control and Automation in Engineering and\n  Industrial Applications,(ACIDCA'2000). p. 190-194. Monastir, Tunisia,2000", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The approach described here allows using membership function to represent\nimprecise and uncertain knowledge by learning in Fuzzy Semantic Networks. This\nrepresentation has a great practical interest due to the possibility to realize\non the one hand, the construction of this membership function from a simple\nvalue expressing the degree of interpretation of an Object or a Goal as\ncompared to an other and on the other hand, the adjustment of the membership\nfunction during the apprenticeship. We show, how to use these membership\nfunctions to represent the interpretation of an Object (respectively of a Goal)\nuser as compared to an system Object (respectively to a Goal). We also show the\npossibility to make decision for each representation of an user Object compared\nto a system Object. This decision is taken by determining decision coefficient\ncalculates according to the nucleus of the membership function of the user\nObject.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2012 10:51:51 GMT"}], "update_date": "2012-06-11", "authors_parsed": [["Omri", "Mohamed Nazih", ""]]}, {"id": "1206.1728", "submitter": "Derek Greene", "authors": "Derek Greene, Gavin Sheridan, Barry Smyth, P\\'adraig Cunningham", "title": "Aggregating Content and Network Information to Curate Twitter User Lists", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twitter introduced user lists in late 2009, allowing users to be grouped\naccording to meaningful topics or themes. Lists have since been adopted by\nmedia outlets as a means of organising content around news stories. Thus the\ncuration of these lists is important - they should contain the key information\ngatekeepers and present a balanced perspective on a story. Here we address this\nlist curation process from a recommender systems perspective. We propose a\nvariety of criteria for generating user list recommendations, based on content\nanalysis, network analysis, and the \"crowdsourcing\" of existing user lists. We\ndemonstrate that these types of criteria are often only successful for datasets\nwith certain characteristics. To resolve this issue, we propose the aggregation\nof these different \"views\" of a news story on Twitter to produce more accurate\nuser recommendations to support the curation process.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2012 11:12:53 GMT"}, {"version": "v2", "created": "Mon, 2 Jul 2012 12:20:38 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Greene", "Derek", ""], ["Sheridan", "Gavin", ""], ["Smyth", "Barry", ""], ["Cunningham", "P\u00e1draig", ""]]}, {"id": "1206.1794", "submitter": "Omri Mohamed Nazih", "authors": "Mohamed Nazih Omri", "title": "Fuzzy Knowledge Representation, Learning and Optimization with Bayesian\n  Analysis in Fuzzy Semantic Networks", "comments": null, "journal-ref": "The 6th International Conference of Neural Information Processing.\n  ICONIP'99. p. 345-351. Perth. Austria, 1999", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a method of optimization, based on both Bayesian Analysis\ntechnical and Gallois Lattice, of a Fuzzy Semantic Networks. The technical\nSystem we use learn by interpreting an unknown word using the links created\nbetween this new word and known words. The main link is provided by the context\nof the query. When novice's query is confused with an unknown verb (goal)\napplied to a known noun denoting either an object in the ideal user's Network\nor an object in the user's Network, the system infer that this new verb\ncorresponds to one of the known goal. With the learning of new words in natural\nlanguage as the interpretation, which was produced in agreement with the user,\nthe system improves its representation scheme at each experiment with a new\nuser and, in addition, takes advantage of previous discussions with users. The\nsemantic Net of user objects thus obtained by these kinds of learning is not\nalways optimal because some relationships between couple of user objects can be\ngeneralized and others suppressed according to values of forces that\ncharacterize them. Indeed, to simplify the obtained Net, we propose to proceed\nto an inductive Bayesian analysis, on the Net obtained from Gallois lattice.\nThe objective of this analysis can be seen as an operation of filtering of the\nobtained descriptive graph.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2012 15:41:03 GMT"}], "update_date": "2012-06-11", "authors_parsed": [["Omri", "Mohamed Nazih", ""]]}, {"id": "1206.1898", "submitter": "Pedro Alejandro Ortega", "authors": "Pedro A. Ortega, Jordi Grau-Moya, Tim Genewein, David Balduzzi, Daniel\n  A. Braun", "title": "A Nonparametric Conjugate Prior Distribution for the Maximizing Argument\n  of a Noisy Function", "comments": "9 pages, 5 figures", "journal-ref": "Neural Information Processing Systems (NIPS) 2012", "doi": null, "report-no": null, "categories": "stat.ML cs.AI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel Bayesian approach to solve stochastic optimization\nproblems that involve finding extrema of noisy, nonlinear functions. Previous\nwork has focused on representing possible functions explicitly, which leads to\na two-step procedure of first, doing inference over the function space and\nsecond, finding the extrema of these functions. Here we skip the representation\nstep and directly model the distribution over extrema. To this end, we devise a\nnon-parametric conjugate prior based on a kernel regressor. The resulting\nposterior distribution directly captures the uncertainty over the maximum of\nthe unknown function. We illustrate the effectiveness of our model by\noptimizing a noisy, high-dimensional, non-convex objective function.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jun 2012 01:57:02 GMT"}, {"version": "v2", "created": "Sat, 10 Nov 2012 18:09:17 GMT"}], "update_date": "2012-11-13", "authors_parsed": [["Ortega", "Pedro A.", ""], ["Grau-Moya", "Jordi", ""], ["Genewein", "Tim", ""], ["Balduzzi", "David", ""], ["Braun", "Daniel A.", ""]]}, {"id": "1206.1926", "submitter": "Nikolay Novozhilov", "authors": "Nikolay Novozhilov", "title": "The hardest logic puzzle ever becomes even tougher", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"The hardest logic puzzle ever\" presented by George Boolos became a target\nfor philosophers and logicians who tried to modify it and make it even tougher.\nI propose further modification of the original puzzle where part of the\navailable information is eliminated but the solution is still possible. The\nsolution also gives interesting ideas on logic behind discovery of unknown\nlanguage.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jun 2012 10:22:48 GMT"}], "update_date": "2012-06-12", "authors_parsed": [["Novozhilov", "Nikolay", ""]]}, {"id": "1206.2082", "submitter": "Reza Bosagh Zadeh", "authors": "Reza Bosagh Zadeh, Ashish Goel", "title": "Dimension Independent Similarity Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a suite of algorithms for Dimension Independent Similarity\nComputation (DISCO) to compute all pairwise similarities between very high\ndimensional sparse vectors. All of our results are provably independent of\ndimension, meaning apart from the initial cost of trivially reading in the\ndata, all subsequent operations are independent of the dimension, thus the\ndimension can be very large. We study Cosine, Dice, Overlap, and the Jaccard\nsimilarity measures. For Jaccard similiarity we include an improved version of\nMinHash. Our results are geared toward the MapReduce framework. We empirically\nvalidate our theorems at large scale using data from the social networking site\nTwitter. At time of writing, our algorithms are live in production at\ntwitter.com.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2012 02:19:27 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2012 04:40:52 GMT"}, {"version": "v3", "created": "Tue, 2 Apr 2013 03:54:28 GMT"}, {"version": "v4", "created": "Thu, 23 May 2013 07:56:18 GMT"}], "update_date": "2013-05-24", "authors_parsed": [["Zadeh", "Reza Bosagh", ""], ["Goel", "Ashish", ""]]}, {"id": "1206.2347", "submitter": "Omri Mohamed Nazih", "authors": "Mohamed Nazih Omri", "title": "Uncertain and Approximative Knowledge Representation to Reasoning on\n  Classification with a Fuzzy Networks Based System", "comments": "arXiv admin note: text overlap with arXiv:1206.1794", "journal-ref": "The 8th IEEE International Conference on Fuzzy Systems,\n  FUZZ-IEEE'99. p. 1632-1637. Seoul. Korea,1999", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The approach described here allows to use the fuzzy Object Based\nRepresentation of imprecise and uncertain knowledge. This representation has a\ngreat practical interest due to the possibility to realize reasoning on\nclassification with a fuzzy semantic network based system. For instance, the\ndistinction between necessary, possible and user classes allows to take into\naccount exceptions that may appear on fuzzy knowledge-base and facilitates\nintegration of user's Objects in the base. This approach describes the\ntheoretical aspects of the architecture of the whole experimental A.I. system\nwe built in order to provide effective on-line assistance to users of new\ntechnological systems: the understanding of \"how it works\" and \"how to complete\ntasks\" from queries in quite natural languages. In our model, procedural\nsemantic networks are used to describe the knowledge of an \"ideal\" expert while\nfuzzy sets are used both to describe the approximative and uncertain knowledge\nof novice users in fuzzy semantic networks which intervene to match fuzzy\nlabels of a query with categories from our \"ideal\" expert.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2012 20:51:51 GMT"}], "update_date": "2012-06-13", "authors_parsed": [["Omri", "Mohamed Nazih", ""]]}, {"id": "1206.2742", "submitter": "Finn {\\AA}rup Nielsen", "authors": "Finn {\\AA}rup Nielsen, Matthew J. Kempton, Steven C. R. Williams", "title": "Online open neuroimaging mass meta-analysis", "comments": "5 pages, 4 figures SePublica 2012, ESWC 2012 Workshop, 28 May 2012,\n  Heraklion, Greece", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a system for meta-analysis where a wiki stores numerical data in\na simple format and a web service performs the numerical computation.\n  We initially apply the system on multiple meta-analyses of structural\nneuroimaging data results. The described system allows for mass meta-analysis,\ne.g., meta-analysis across multiple brain regions and multiple mental\ndisorders.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 08:23:42 GMT"}], "update_date": "2012-06-14", "authors_parsed": [["Nielsen", "Finn \u00c5rup", ""], ["Kempton", "Matthew J.", ""], ["Williams", "Steven C. R.", ""]]}, {"id": "1206.2802", "submitter": "Jose Fontanari", "authors": "P. F. C. Tilles and J. F. Fontanari", "title": "Critical behavior in a cross-situational lexicon learning scenario", "comments": null, "journal-ref": "EPL, 99 (2012) 60001", "doi": "10.1209/0295-5075/99/60001", "report-no": null, "categories": "physics.soc-ph cond-mat.stat-mech cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The associationist account for early word-learning is based on the\nco-occurrence between objects and words. Here we examine the performance of a\nsimple associative learning algorithm for acquiring the referents of words in a\ncross-situational scenario affected by noise produced by out-of-context words.\nWe find a critical value of the noise parameter $\\gamma_c$ above which learning\nis impossible. We use finite-size scaling to show that the sharpness of the\ntransition persists across a region of order $\\tau^{-1/2}$ about $\\gamma_c$,\nwhere $\\tau$ is the number of learning trials, as well as to obtain the\nlearning error (scaling function) in the critical region. In addition, we show\nthat the distribution of durations of periods when the learning error is zero\nis a power law with exponent -3/2 at the critical point.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 13:36:52 GMT"}], "update_date": "2012-10-16", "authors_parsed": [["Tilles", "P. F. C.", ""], ["Fontanari", "J. F.", ""]]}, {"id": "1206.3111", "submitter": "Francesco Calimeri", "authors": "Francesco Calimeri, Giovambattista Ianni, Francesco Ricca", "title": "The third open Answer Set Programming competition", "comments": "37 pages, 12 figures, 1 table - To appear in Theory and Practice of\n  Logic Programming (TPLP)", "journal-ref": "Theory and Practice of Logic Programming 14 (2014) 117-135", "doi": "10.1017/S1471068412000105", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer Set Programming (ASP) is a well-established paradigm of declarative\nprogramming in close relationship with other declarative formalisms such as SAT\nModulo Theories, Constraint Handling Rules, FO(.), PDDL and many others. Since\nits first informal editions, ASP systems have been compared in the now\nwell-established ASP Competition. The Third (Open) ASP Competition, as the\nsequel to the ASP Competitions Series held at the University of Potsdam in\nGermany (2006-2007) and at the University of Leuven in Belgium in 2009, took\nplace at the University of Calabria (Italy) in the first half of 2011.\nParticipants competed on a pre-selected collection of benchmark problems, taken\nfrom a variety of domains as well as real world applications. The Competition\nran on two tracks: the Model and Solve (M&S) Track, based on an open problem\nencoding, and open language, and open to any kind of system based on a\ndeclarative specification paradigm; and the System Track, run on the basis of\nfixed, public problem encodings, written in a standard ASP language. This paper\ndiscusses the format of the Competition and the rationale behind it, then\nreports the results for both tracks. Comparison with the second ASP competition\nand state-of-the-art solutions for some of the benchmark domains is eventually\ndiscussed.\n  To appear in Theory and Practice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2012 14:03:28 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Calimeri", "Francesco", ""], ["Ianni", "Giovambattista", ""], ["Ricca", "Francesco", ""]]}, {"id": "1206.3232", "submitter": "Vibhav Gogate", "authors": "Vibhav Gogate, Rina Dechter", "title": "AND/OR Importance Sampling", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-212-219", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper introduces AND/OR importance sampling for probabilistic graphical\nmodels. In contrast to importance sampling, AND/OR importance sampling caches\nsamples in the AND/OR space and then extracts a new sample mean from the stored\nsamples. We prove that AND/OR importance sampling may have lower variance than\nimportance sampling; thereby providing a theoretical justification for\npreferring it over importance sampling. Our empirical evaluation demonstrates\nthat AND/OR importance sampling is far more accurate than importance sampling\nin many cases.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 12:33:40 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Gogate", "Vibhav", ""], ["Dechter", "Rina", ""]]}, {"id": "1206.3233", "submitter": "Alejandro Isaza", "authors": "Alejandro Isaza, Csaba Szepesvari, Vadim Bulitko, Russell Greiner", "title": "Speeding Up Planning in Markov Decision Processes via Automatically\n  Constructed Abstractions", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-306-314", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider planning in stochastic shortest path (SSP)\nproblems, a subclass of Markov Decision Problems (MDP). We focus on medium-size\nproblems whose state space can be fully enumerated. This problem has numerous\nimportant applications, such as navigation and planning under uncertainty. We\npropose a new approach for constructing a multi-level hierarchy of\nprogressively simpler abstractions of the original problem. Once computed, the\nhierarchy can be used to speed up planning by first finding a policy for the\nmost abstract level and then recursively refining it into a solution to the\noriginal problem. This approach is fully automated and delivers a speed-up of\ntwo orders of magnitude over a state-of-the-art MDP solver on sample problems\nwhile returning near-optimal solutions. We also prove theoretical bounds on the\nloss of solution optimality resulting from the use of abstractions.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 12:34:35 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Isaza", "Alejandro", ""], ["Szepesvari", "Csaba", ""], ["Bulitko", "Vadim", ""], ["Greiner", "Russell", ""]]}, {"id": "1206.3234", "submitter": "Umut A. Acar", "authors": "Umut A. Acar, Alexander T. Ihler, Ramgopal Mettu, Ozgur Sumer", "title": "Adaptive Inference on General Graphical Models", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-1-8", "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many algorithms and applications involve repeatedly solving variations of the\nsame inference problem; for example we may want to introduce new evidence to\nthe model or perform updates to conditional dependencies. The goal of adaptive\ninference is to take advantage of what is preserved in the model and perform\ninference more rapidly than from scratch. In this paper, we describe techniques\nfor adaptive inference on general graphs that support marginal computation and\nupdates to the conditional probabilities and dependencies in logarithmic time.\nWe give experimental results for an implementation of our algorithm, and\ndemonstrate its potential performance benefit in the study of protein\nstructure.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 14:16:36 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Acar", "Umut A.", ""], ["Ihler", "Alexander T.", ""], ["Mettu", "Ramgopal", ""], ["Sumer", "Ozgur", ""]]}, {"id": "1206.3235", "submitter": "Dimitrios Antos", "authors": "Dimitrios Antos, Avi Pfeffer", "title": "Identifying reasoning patterns in games", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-9-17", "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm that identifies the reasoning patterns of agents in a\ngame, by iteratively examining the graph structure of its Multi-Agent Influence\nDiagram (MAID) representation. If the decision of an agent participates in no\nreasoning patterns, then we can effectively ignore that decision for the\npurpose of calculating a Nash equilibrium for the game. In some cases, this can\nlead to exponential time savings in the process of equilibrium calculation.\nMoreover, our algorithm can be used to enumerate the reasoning patterns in a\ngame, which can be useful for constructing more effective computerized agents\ninteracting with humans.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 14:17:02 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Antos", "Dimitrios", ""], ["Pfeffer", "Avi", ""]]}, {"id": "1206.3239", "submitter": "Zhihong Cai", "authors": "Zhihong Cai, Manabu Kuroki", "title": "On Identifying Total Effects in the Presence of Latent Variables and\n  Selection bias", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-62-69", "categories": "stat.ME cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assume that cause-effect relationships between variables can be described as\na directed acyclic graph and the corresponding linear structural equation\nmodel.We consider the identification problem of total effects in the presence\nof latent variables and selection bias between a treatment variable and a\nresponse variable. Pearl and his colleagues provided the back door criterion,\nthe front door criterion (Pearl, 2000) and the conditional instrumental\nvariable method (Brito and Pearl, 2002) as identifiability criteria for total\neffects in the presence of latent variables, but not in the presence of\nselection bias. In order to solve this problem, we propose new graphical\nidentifiability criteria for total effects based on the identifiable factor\nmodels. The results of this paper are useful to identify total effects in\nobservational studies and provide a new viewpoint to the identification\nconditions of factor models.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 14:59:34 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Cai", "Zhihong", ""], ["Kuroki", "Manabu", ""]]}, {"id": "1206.3240", "submitter": "Venkat Chandrasekaran", "authors": "Venkat Chandrasekaran, Nathan Srebro, Prahladh Harsha", "title": "Complexity of Inference in Graphical Models", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-70-78", "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that inference in graphical models is hard in the worst\ncase, but tractable for models with bounded treewidth. We ask whether treewidth\nis the only structural criterion of the underlying graph that enables tractable\ninference. In other words, is there some class of structures with unbounded\ntreewidth in which inference is tractable? Subject to a combinatorial\nhypothesis due to Robertson et al. (1994), we show that low treewidth is indeed\nthe only structural restriction that can ensure tractability. Thus, even for\nthe \"best case\" graph structure, there is no inference algorithm with\ncomplexity polynomial in the treewidth.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:01:35 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Chandrasekaran", "Venkat", ""], ["Srebro", "Nathan", ""], ["Harsha", "Prahladh", ""]]}, {"id": "1206.3244", "submitter": "James Cussens", "authors": "James Cussens", "title": "Bayesian network learning by compiling to weighted MAX-SAT", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-105-112", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of learning discrete Bayesian networks from data is encoded as a\nweighted MAX-SAT problem and the MaxWalkSat local search algorithm is used to\naddress it. For each dataset, the per-variable summands of the (BDeu) marginal\nlikelihood for different choices of parents ('family scores') are computed\nprior to applying MaxWalkSat. Each permissible choice of parents for each\nvariable is encoded as a distinct propositional atom and the associated family\nscore encoded as a 'soft' weighted single-literal clause. Two approaches to\nenforcing acyclicity are considered: either by encoding the ancestor relation\nor by attaching a total order to each graph and encoding that. The latter\napproach gives better results. Learning experiments have been conducted on 21\nsynthetic datasets sampled from 7 BNs. The largest dataset has 10,000\ndatapoints and 60 variables producing (for the 'ancestor' encoding) a weighted\nCNF input file with 19,932 atoms and 269,367 clauses. For most datasets,\nMaxWalkSat quickly finds BNs with higher BDeu score than the 'true' BN. The\neffect of adding prior information is assessed. It is further shown that\nBayesian model averaging can be effected by collecting BNs generated during the\nsearch.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:06:22 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Cussens", "James", ""]]}, {"id": "1206.3245", "submitter": "Philip Dawid", "authors": "Philip Dawid, Vanessa Didelez", "title": "Identifying Optimal Sequential Decisions", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": "In Proc. 24th Annual Conference on Uncertainty in Artificial\n  Intelligence (2008), edited by D. McAllester and P. Myllymaki. AUAI Press,\n  113-120", "doi": null, "report-no": "UAI-P-2008-PG-113-120", "categories": "cs.AI math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider conditions that allow us to find an optimal strategy for\nsequential decisions from a given data situation. For the case where all\ninterventions are unconditional (atomic), identifiability has been discussed by\nPearl & Robins (1995). We argue here that an optimal strategy must be\nconditional, i.e. take the information available at each decision point into\naccount. We show that the identification of an optimal sequential decision\nstrategy is more restrictive, in the sense that conditional interventions might\nnot always be identified when atomic interventions are. We further demonstrate\nthat a simple graphical criterion for the identifiability of an optimal\nstrategy can be given.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:06:54 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Dawid", "Philip", ""], ["Didelez", "Vanessa", ""]]}, {"id": "1206.3246", "submitter": "Cassio Polpo de Campos", "authors": "Cassio Polpo de Campos, Qiang Ji", "title": "Strategy Selection in Influence Diagrams using Imprecise Probabilities", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-121-128", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new algorithm to solve the decision making problem in\nInfluence Diagrams based on algorithms for credal networks. Decision nodes are\nassociated to imprecise probability distributions and a reformulation is\nintroduced that finds the global maximum strategy with respect to the expected\nutility. We work with Limited Memory Influence Diagrams, which generalize most\nInfluence Diagram proposals and handle simultaneous decisions. Besides the\nglobal optimum method, we explore an anytime approximate solution with a\nguaranteed maximum error and show that imprecise probabilities are handled in a\nstraightforward way. Complexity issues and experiments with random diagrams and\nan effects-based military planning problem are discussed.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:08:24 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["de Campos", "Cassio Polpo", ""], ["Ji", "Qiang", ""]]}, {"id": "1206.3248", "submitter": "Quang Duong", "authors": "Quang Duong, Michael P. Wellman, Satinder Singh", "title": "Knowledge Combination in Graphical Multiagent Model", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-145-152", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graphical multiagent model (GMM) represents a joint distribution over the\nbehavior of a set of agents. One source of knowledge about agents' behavior may\ncome from gametheoretic analysis, as captured by several graphical game\nrepresentations developed in recent years. GMMs generalize this approach to\nexpress arbitrary distributions, based on game descriptions or other sources of\nknowledge bearing on beliefs about agent behavior. To illustrate the\nflexibility of GMMs, we exhibit game-derived models that allow probabilistic\ndeviation from equilibrium, as well as models based on heuristic action choice.\nWe investigate three different methods of integrating these models into a\nsingle model representing the combined knowledge sources. To evaluate the\npredictive performance of the combined model, we treat as actual outcome the\nbehavior produced by a reinforcement learning process. We find that combining\nthe two knowledge sources, using any of the methods, provides better\npredictions than either source alone. Among the combination methods, mixing\ndata outperforms the opinion pool and direct update methods investigated in\nthis empirical trial.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:09:25 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Duong", "Quang", ""], ["Wellman", "Michael P.", ""], ["Singh", "Satinder", ""]]}, {"id": "1206.3250", "submitter": "Frederick Eberhardt", "authors": "Frederick Eberhardt", "title": "Almost Optimal Intervention Sets for Causal Discovery", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-161-168", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conjecture that the worst case number of experiments necessary and\nsufficient to discover a causal graph uniquely given its observational Markov\nequivalence class can be specified as a function of the largest clique in the\nMarkov equivalence class. We provide an algorithm that computes intervention\nsets that we believe are optimal for the above task. The algorithm builds on\ninsights gained from the worst case analysis in Eberhardt et al. (2005) for\nsequences of experiments when all possible directed acyclic graphs over N\nvariables are considered. A simulation suggests that our conjecture is correct.\nWe also show that a generalization of our conjecture to other classes of\npossible graph hypotheses cannot be given easily, and in what sense the\nalgorithm is then no longer optimal.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:10:21 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Eberhardt", "Frederick", ""]]}, {"id": "1206.3251", "submitter": "Tal El-Hay", "authors": "Tal El-Hay, Nir Friedman, Raz Kupferman", "title": "Gibbs Sampling in Factorized Continuous-Time Markov Processes", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-169-178", "categories": "cs.AI stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central task in many applications is reasoning about processes that change\nover continuous time. Continuous-Time Bayesian Networks is a general compact\nrepresentation language for multi-component continuous-time processes. However,\nexact inference in such processes is exponential in the number of components,\nand thus infeasible for most models of interest. Here we develop a novel Gibbs\nsampling procedure for multi-component processes. This procedure iteratively\nsamples a trajectory for one of the components given the remaining ones. We\nshow how to perform exact sampling that adapts to the natural time scale of the\nsampled process. Moreover, we show that this sampling procedure naturally\nexploits the structure of the network to reduce the computational cost of each\nstep. This procedure is the first that can provide asymptotically unbiased\napproximation in such processes.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:11:00 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["El-Hay", "Tal", ""], ["Friedman", "Nir", ""], ["Kupferman", "Raz", ""]]}, {"id": "1206.3253", "submitter": "Sevan G. Ficici", "authors": "Sevan G. Ficici, David C. Parkes, Avi Pfeffer", "title": "Learning and Solving Many-Player Games through a Cluster-Based\n  Representation", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-188-195", "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In addressing the challenge of exponential scaling with the number of agents\nwe adopt a cluster-based representation to approximately solve asymmetric games\nof very many players. A cluster groups together agents with a similar\n\"strategic view\" of the game. We learn the clustered approximation from data\nconsisting of strategy profiles and payoffs, which may be obtained from\nobservations of play or access to a simulator. Using our clustering we\nconstruct a reduced \"twins\" game in which each cluster is associated with two\nplayers of the reduced game. This allows our representation to be individually-\nresponsive because we align the interests of every individual agent with the\nstrategy of its cluster. Our approach provides agents with higher payoffs and\nlower regret on average than model-free methods as well as previous\ncluster-based methods, and requires only few observations for learning to be\nsuccessful. The \"twins\" approach is shown to be an important component of\nproviding these low regret approximations.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:12:21 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Ficici", "Sevan G.", ""], ["Parkes", "David C.", ""], ["Pfeffer", "Avi", ""]]}, {"id": "1206.3255", "submitter": "Daniel Roy", "authors": "Noah Goodman, Vikash Mansinghka, Daniel M. Roy, Keith Bonawitz, Joshua\n  B. Tenenbaum", "title": "Church: a language for generative models", "comments": "Minor revisions. Fixed errors in author list", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-220-229", "categories": "cs.PL cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Church, a universal language for describing stochastic\ngenerative processes. Church is based on the Lisp model of lambda calculus,\ncontaining a pure Lisp as its deterministic subset. The semantics of Church is\ndefined in terms of evaluation histories and conditional distributions on such\nhistories. Church also includes a novel language construct, the stochastic\nmemoizer, which enables simple description of many complex non-parametric\nmodels. We illustrate language features through several examples, including: a\ngeneralized Bayes net in which parameters cluster over trials, infinite PCFGs,\nplanning by inference, and various non-parametric clustering models. Finally,\nwe show how to implement query on any Church program, exactly and\napproximately, using Monte Carlo techniques.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:30:30 GMT"}, {"version": "v2", "created": "Tue, 15 Jul 2014 08:32:38 GMT"}], "update_date": "2014-07-16", "authors_parsed": [["Goodman", "Noah", ""], ["Mansinghka", "Vikash", ""], ["Roy", "Daniel M.", ""], ["Bonawitz", "Keith", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1206.3258", "submitter": "Bowen Hui", "authors": "Bowen Hui, Craig Boutilier", "title": "Toward Experiential Utility Elicitation for Interface Customization", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-298-305", "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User preferences for automated assistance often vary widely, depending on the\nsituation, and quality or presentation of help. Developing effectivemodels to\nlearn individual preferences online requires domain models that associate\nobservations of user behavior with their utility functions, which in turn can\nbe constructed using utility elicitation techniques. However, most elicitation\nmethods ask for users' predicted utilities based on hypothetical scenarios\nrather than more realistic experienced utilities. This is especially true in\ninterface customization, where users are asked to assess novel interface\ndesigns. We propose experiential utility elicitation methods for customization\nand compare these to predictivemethods. As experienced utilities have been\nargued to better reflect true preferences in behavioral decision making, the\npurpose here is to investigate accurate and efficient procedures that are\nsuitable for software domains. Unlike conventional elicitation, our results\nindicate that an experiential approach helps people understand stochastic\noutcomes, as well as better appreciate the sequential utility of intelligent\nassistance.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:32:43 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Hui", "Bowen", ""], ["Boutilier", "Craig", ""]]}, {"id": "1206.3260", "submitter": "Patrik O. Hoyer", "authors": "Patrik O. Hoyer, Aapo Hyvarinen, Richard Scheines, Peter L. Spirtes,\n  Joseph Ramsey, Gustavo Lacerda, Shohei Shimizu", "title": "Causal discovery of linear acyclic models with arbitrary distributions", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-282-289", "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important task in data analysis is the discovery of causal relationships\nbetween observed variables. For continuous-valued data, linear acyclic causal\nmodels are commonly used to model the data-generating process, and the\ninference of such models is a well-studied problem. However, existing methods\nhave significant limitations. Methods based on conditional independencies\n(Spirtes et al. 1993; Pearl 2000) cannot distinguish between\nindependence-equivalent models, whereas approaches purely based on Independent\nComponent Analysis (Shimizu et al. 2006) are inapplicable to data which is\npartially Gaussian. In this paper, we generalize and combine the two\napproaches, to yield a method able to learn the model structure in many cases\nfor which the previous methods provide answers that are either incorrect or are\nnot as informative as possible. We give exact graphical conditions for when two\ndistinct models represent the same family of distributions, and empirically\ndemonstrate the power of our method through thorough simulations.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:33:32 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Hoyer", "Patrik O.", ""], ["Hyvarinen", "Aapo", ""], ["Scheines", "Richard", ""], ["Spirtes", "Peter L.", ""], ["Ramsey", "Joseph", ""], ["Lacerda", "Gustavo", ""], ["Shimizu", "Shohei", ""]]}, {"id": "1206.3261", "submitter": "Greg Hines", "authors": "Greg Hines, Kate Larson", "title": "Learning When to Take Advice: A Statistical Test for Achieving A\n  Correlated Equilibrium", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-274-281", "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a multiagent learning problem where agents can either learn via\nrepeated interactions, or can follow the advice of a mediator who suggests\npossible actions to take. We present an algorithmthat each agent can use so\nthat, with high probability, they can verify whether or not the mediator's\nadvice is useful. In particular, if the mediator's advice is useful then agents\nwill reach a correlated equilibrium, but if the mediator's advice is not\nuseful, then agents are not harmed by using our test, and can fall back to\ntheir original learning algorithm. We then generalize our algorithm and show\nthat in the limit it always correctly verifies the mediator's advice.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:33:53 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Hines", "Greg", ""], ["Larson", "Kate", ""]]}, {"id": "1206.3263", "submitter": "Eric A. Hansen", "authors": "Eric A. Hansen", "title": "Sparse Stochastic Finite-State Controllers for POMDPs", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-256-263", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bounded policy iteration is an approach to solving infinite-horizon POMDPs\nthat represents policies as stochastic finite-state controllers and iteratively\nimproves a controller by adjusting the parameters of each node using linear\nprogramming. In the original algorithm, the size of the linear programs, and\nthus the complexity of policy improvement, depends on the number of parameters\nof each node, which grows with the size of the controller. But in practice, the\nnumber of parameters of a node with non-zero values is often very small, and\ndoes not grow with the size of the controller. Based on this observation, we\ndevelop a version of bounded policy iteration that leverages the sparse\nstructure of a stochastic finite-state controller. In each iteration, it\nimproves a policy by the same amount as the original algorithm, but with much\nbetter scalability.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:34:42 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Hansen", "Eric A.", ""]]}, {"id": "1206.3264", "submitter": "Hannaneh Hajishirzi", "authors": "Hannaneh Hajishirzi, Eyal Amir", "title": "Sampling First Order Logical Particles", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-248-255", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate inference in dynamic systems is the problem of estimating the\nstate of the system given a sequence of actions and partial observations. High\nprecision estimation is fundamental in many applications like diagnosis,\nnatural language processing, tracking, planning, and robotics. In this paper we\npresent an algorithm that samples possible deterministic executions of a\nprobabilistic sequence. The algorithm takes advantage of a compact\nrepresentation (using first order logic) for actions and world states to\nimprove the precision of its estimation. Theoretical and empirical results show\nthat the algorithm's expected error is smaller than propositional sampling and\nSequential Monte Carlo (SMC) sampling techniques.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:35:12 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Hajishirzi", "Hannaneh", ""], ["Amir", "Eyal", ""]]}, {"id": "1206.3265", "submitter": "Johan Kwisthout", "authors": "Johan Kwisthout, Linda C. van der Gaag", "title": "The Computational Complexity of Sensitivity Analysis and Parameter\n  Tuning", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-349-356", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While known algorithms for sensitivity analysis and parameter tuning in\nprobabilistic networks have a running time that is exponential in the size of\nthe network, the exact computational complexity of these problems has not been\nestablished as yet. In this paper we study several variants of the tuning\nproblem and show that these problems are NPPP-complete in general. We further\nshow that the problems remain NP-complete or PP-complete, for a number of\nrestricted variants. These complexity results provide insight in whether or not\nrecent achievements in sensitivity analysis and tuning can be extended to more\ngeneral, practicable methods.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:35:54 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Kwisthout", "Johan", ""], ["van der Gaag", "Linda C.", ""]]}, {"id": "1206.3266", "submitter": "Branislav Kveton", "authors": "Branislav Kveton, Milos Hauskrecht", "title": "Partitioned Linear Programming Approximations for MDPs", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-341-348", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate linear programming (ALP) is an efficient approach to solving\nlarge factored Markov decision processes (MDPs). The main idea of the method is\nto approximate the optimal value function by a set of basis functions and\noptimize their weights by linear programming (LP). This paper proposes a new\nALP approximation. Comparing to the standard ALP formulation, we decompose the\nconstraint space into a set of low-dimensional spaces. This structure allows\nfor solving the new LP efficiently. In particular, the constraints of the LP\ncan be satisfied in a compact form without an exponential dependence on the\ntreewidth of ALP constraints. We study both practical and theoretical aspects\nof the proposed approach. Moreover, we demonstrate its scale-up potential on an\nMDP with more than 2^100 states.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:36:14 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Kveton", "Branislav", ""], ["Hauskrecht", "Milos", ""]]}, {"id": "1206.3267", "submitter": "Manabu Kuroki", "authors": "Manabu Kuroki, Zhihong Cai", "title": "The Evaluation of Causal Effects in Studies with an Unobserved\n  Exposure/Outcome Variable: Bounds and Identification", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-333-340", "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the problem of evaluating the causal effect using\nobservational data in the presence of an unobserved exposure/ outcome variable,\nwhen cause-effect relationships between variables can be described as a\ndirected acyclic graph and the corresponding recursive factorization of a joint\ndistribution. First, we propose identifiability criteria for causal effects\nwhen an unobserved exposure/outcome variable is considered to contain more than\ntwo categories. Next, when unmeasured variables exist between an unobserved\noutcome variable and its proxy variables, we provide the tightest bounds based\non the potential outcome approach. The results of this paper are helpful to\nevaluate causal effects in the case where it is difficult or expensive to\nobserve an exposure/ outcome variable in many practical fields.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:36:40 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Kuroki", "Manabu", ""], ["Cai", "Zhihong", ""]]}, {"id": "1206.3271", "submitter": "Daniel Lowd", "authors": "Daniel Lowd, Pedro Domingos", "title": "Learning Arithmetic Circuits", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-383-392", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphical models are usually learned without regard to the cost of doing\ninference with them. As a result, even if a good model is learned, it may\nperform poorly at prediction, because it requires approximate inference. We\npropose an alternative: learning models with a score function that directly\npenalizes the cost of inference. Specifically, we learn arithmetic circuits\nwith a penalty on the number of edges in the circuit (in which the cost of\ninference is linear). Our algorithm is equivalent to learning a Bayesian\nnetwork with context-specific independence by greedily splitting conditional\ndistributions, at each step scoring the candidates by compiling the resulting\nnetwork into an arithmetic circuit, and using its size as the penalty. We show\nhow this can be done efficiently, without compiling a circuit from scratch for\neach candidate. Experiments on several real-world domains show that our\nalgorithm is able to learn tractable models with very large treewidth, and\nyields more accurate predictions than a standard context-specific Bayesian\nnetwork learner, in far less time.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:38:26 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Lowd", "Daniel", ""], ["Domingos", "Pedro", ""]]}, {"id": "1206.3272", "submitter": "Gregory Lawrence", "authors": "Gregory Lawrence, Stuart Russell", "title": "Improving Gradient Estimation by Incorporating Sensor Data", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-375-382", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An efficient policy search algorithm should estimate the local gradient of\nthe objective function, with respect to the policy parameters, from as few\ntrials as possible. Whereas most policy search methods estimate this gradient\nby observing the rewards obtained during policy trials, we show, both\ntheoretically and empirically, that taking into account the sensor data as well\ngives better gradient estimates and hence faster learning. The reason is that\nrewards obtained during policy execution vary from trial to trial due to noise\nin the environment; sensor data, which correlates with the noise, can be used\nto partially correct for this variation, resulting in an estimatorwith lower\nvariance.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:38:50 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Lawrence", "Gregory", ""], ["Russell", "Stuart", ""]]}, {"id": "1206.3273", "submitter": "Gustavo Lacerda", "authors": "Gustavo Lacerda, Peter L. Spirtes, Joseph Ramsey, Patrik O. Hoyer", "title": "Discovering Cyclic Causal Models by Independent Components Analysis", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-366-374", "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize Shimizu et al's (2006) ICA-based approach for discovering\nlinear non-Gaussian acyclic (LiNGAM) Structural Equation Models (SEMs) from\ncausally sufficient, continuous-valued observational data. By relaxing the\nassumption that the generating SEM's graph is acyclic, we solve the more\ngeneral problem of linear non-Gaussian (LiNG) SEM discovery. LiNG discovery\nalgorithms output the distribution equivalence class of SEMs which, in the\nlarge sample limit, represents the population distribution. We apply a LiNG\ndiscovery algorithm to simulated data. Finally, we give sufficient conditions\nunder which only one of the SEMs in the output class is 'stable'.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:39:27 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Lacerda", "Gustavo", ""], ["Spirtes", "Peter L.", ""], ["Ramsey", "Joseph", ""], ["Hoyer", "Patrik O.", ""]]}, {"id": "1206.3276", "submitter": "Ulf Nielsen", "authors": "Ulf Nielsen, Jean-Philippe Pellet, Andr\\'e Elisseeff", "title": "Explanation Trees for Causal Bayesian Networks", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-427-434", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian networks can be used to extract explanations about the observed\nstate of a subset of variables. In this paper, we explicate the desiderata of\nan explanation and confront them with the concept of explanation proposed by\nexisting methods. The necessity of taking into account causal approaches when a\ncausal graph is available is discussed. We then introduce causal explanation\ntrees, based on the construction of explanation trees using the measure of\ncausal information ow (Ay and Polani, 2006). This approach is compared to\nseveral other methods on known networks.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:41:30 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Nielsen", "Ulf", ""], ["Pellet", "Jean-Philippe", ""], ["Elisseeff", "Andr\u00e9", ""]]}, {"id": "1206.3280", "submitter": "Aleksandr Simma", "authors": "Aleksandr Simma, Moises Goldszmidt, John MacCormick, Paul Barham,\n  Richard Black, Rebecca Isaacs, Richard Mortier", "title": "CT-NOR: Representing and Reasoning About Events in Continuous Time", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-484-493", "categories": "cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a generative model for representing and reasoning about the\nrelationships among events in continuous time. We apply the model to the domain\nof networked and distributed computing environments where we fit the parameters\nof the model from timestamp observations, and then use hypothesis testing to\ndiscover dependencies between the events and changes in behavior for monitoring\nand diagnosis. After introducing the model, we present an EM algorithm for\nfitting the parameters and then present the hypothesis testing approach for\nboth dependence discovery and change-point detection. We validate the approach\nfor both tasks using real data from a trace of network events at Microsoft\nResearch Cambridge. Finally, we formalize the relationship between the proposed\nmodel and the noisy-or gate for cases when time can be discretized.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:43:08 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Simma", "Aleksandr", ""], ["Goldszmidt", "Moises", ""], ["MacCormick", "John", ""], ["Barham", "Paul", ""], ["Black", "Richard", ""], ["Isaacs", "Rebecca", ""], ["Mortier", "Richard", ""]]}, {"id": "1206.3281", "submitter": "Stephane Ross", "authors": "Stephane Ross, Joelle Pineau", "title": "Model-Based Bayesian Reinforcement Learning in Large Structured Domains", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-476-483", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based Bayesian reinforcement learning has generated significant\ninterest in the AI community as it provides an elegant solution to the optimal\nexploration-exploitation tradeoff in classical reinforcement learning.\nUnfortunately, the applicability of this type of approach has been limited to\nsmall domains due to the high complexity of reasoning about the joint posterior\nover model parameters. In this paper, we consider the use of factored\nrepresentations combined with online planning techniques, to improve\nscalability of these methods. The main contribution of this paper is a Bayesian\nframework for learning the structure and parameters of a dynamical system,\nwhile also simultaneously planning a (near-)optimal sequence of actions.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:43:32 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Ross", "Stephane", ""], ["Pineau", "Joelle", ""]]}, {"id": "1206.3282", "submitter": "Sebastian Riedel", "authors": "Sebastian Riedel", "title": "Improving the Accuracy and Efficiency of MAP Inference for Markov Logic", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-468-475", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present Cutting Plane Inference (CPI), a Maximum A Posteriori\n(MAP) inference method for Statistical Relational Learning. Framed in terms of\nMarkov Logic and inspired by the Cutting Plane Method, it can be seen as a meta\nalgorithm that instantiates small parts of a large and complex Markov Network\nand then solves these using a conventional MAP method. We evaluate CPI on two\ntasks, Semantic Role Labelling and Joint Entity Resolution, while plugging in\ntwo different MAP inference methods: the current method of choice for MAP\ninference in Markov Logic, MaxWalkSAT, and Integer Linear Programming. We\nobserve that when used with CPI both methods are significantly faster than when\nused alone. In addition, CPI improves the accuracy of MaxWalkSAT and maintains\nthe exactness of Integer Linear Programming.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:43:49 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Riedel", "Sebastian", ""]]}, {"id": "1206.3283", "submitter": "Yan Radovilsky", "authors": "Yan Radovilsky, Solomon Eyal Shimony", "title": "Observation Subset Selection as Local Compilation of Performance\n  Profiles", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-460-467", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deciding what to sense is a crucial task, made harder by dependencies and by\na nonadditive utility function. We develop approximation algorithms for\nselecting an optimal set of measurements, under a dependency structure modeled\nby a tree-shaped Bayesian network (BN). Our approach is a generalization of\ncomposing anytime algorithm represented by conditional performance profiles.\nThis is done by relaxing the input monotonicity assumption, and extending the\nlocal compilation technique to more general classes of performance profiles\n(PPs). We apply the extended scheme to selecting a subset of measurements for\nchoosing a maximum expectation variable in a binary valued BN, and for\nminimizing the worst variance in a Gaussian BN.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:44:14 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Radovilsky", "Yan", ""], ["Shimony", "Solomon Eyal", ""]]}, {"id": "1206.3284", "submitter": "Lars Otten", "authors": "Lars Otten, Rina Dechter", "title": "Bounding Search Space Size via (Hyper)tree Decompositions", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-452-459", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a measure for bounding the performance of AND/OR search\nalgorithms for solving a variety of queries over graphical models. We show how\ndrawing a connection to the recent notion of hypertree decompositions allows to\nexploit determinism in the problem specification and produce tighter bounds. We\ndemonstrate on a variety of practical problem instances that we are often able\nto improve upon existing bounds by several orders of magnitude.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:44:34 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Otten", "Lars", ""], ["Dechter", "Rina", ""]]}, {"id": "1206.3285", "submitter": "Richard S. Sutton", "authors": "Richard S. Sutton, Csaba Szepesvari, Alborz Geramifard, Michael P.\n  Bowling", "title": "Dyna-Style Planning with Linear Function Approximation and Prioritized\n  Sweeping", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-528-536", "categories": "cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of efficiently learning optimal control policies and\nvalue functions over large state spaces in an online setting in which estimates\nmust be available after each interaction with the world. This paper develops an\nexplicitly model-based approach extending the Dyna architecture to linear\nfunction approximation. Dynastyle planning proceeds by generating imaginary\nexperience from the world model and then applying model-free reinforcement\nlearning algorithms to the imagined state transitions. Our main results are to\nprove that linear Dyna-style planning converges to a unique solution\nindependent of the generating distribution, under natural conditions. In the\npolicy evaluation setting, we prove that the limit point is the least-squares\n(LSTD) solution. An implication of our results is that prioritized-sweeping can\nbe soundly extended to the linear approximation case, backing up to preceding\nfeatures rather than to preceding states. We introduce two versions of\nprioritized sweeping with linear Dyna and briefly illustrate their performance\nempirically on the Mountain Car and Boyan Chain problems.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:45:04 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Sutton", "Richard S.", ""], ["Szepesvari", "Csaba", ""], ["Geramifard", "Alborz", ""], ["Bowling", "Michael P.", ""]]}, {"id": "1206.3286", "submitter": "Matthew Streeter", "authors": "Matthew Streeter, Stephen F. Smith", "title": "New Techniques for Algorithm Portfolio Design", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-519-527", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present and evaluate new techniques for designing algorithm portfolios. In\nour view, the problem has both a scheduling aspect and a machine learning\naspect. Prior work has largely addressed one of the two aspects in isolation.\nBuilding on recent work on the scheduling aspect of the problem, we present a\ntechnique that addresses both aspects simultaneously and has attractive\ntheoretical guarantees. Experimentally, we show that this technique can be used\nto improve the performance of state-of-the-art algorithms for Boolean\nsatisfiability, zero-one integer programming, and A.I. planning.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:45:20 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Streeter", "Matthew", ""], ["Smith", "Stephen F.", ""]]}, {"id": "1206.3288", "submitter": "David Sontag", "authors": "David Sontag, Talya Meltzer, Amir Globerson, Tommi S. Jaakkola, Yair\n  Weiss", "title": "Tightening LP Relaxations for MAP using Message Passing", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-503-510", "categories": "cs.DS cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear Programming (LP) relaxations have become powerful tools for finding\nthe most probable (MAP) configuration in graphical models. These relaxations\ncan be solved efficiently using message-passing algorithms such as belief\npropagation and, when the relaxation is tight, provably find the MAP\nconfiguration. The standard LP relaxation is not tight enough in many\nreal-world problems, however, and this has lead to the use of higher order\ncluster-based LP relaxations. The computational cost increases exponentially\nwith the size of the clusters and limits the number and type of clusters we can\nuse. We propose to solve the cluster selection problem monotonically in the\ndual LP, iteratively selecting clusters with guaranteed improvement, and\nquickly re-solving with the added clusters by reusing the existing solution.\nOur dual message-passing algorithm finds the MAP configuration in protein\nsidechain placement, protein design, and stereo problems, in cases where the\nstandard LP relaxation fails.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:46:00 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Sontag", "David", ""], ["Meltzer", "Talya", ""], ["Globerson", "Amir", ""], ["Jaakkola", "Tommi S.", ""], ["Weiss", "Yair", ""]]}, {"id": "1206.3289", "submitter": "Tomas Singliar", "authors": "Tomas Singliar, Denver Dash", "title": "Efficient inference in persistent Dynamic Bayesian Networks", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-494-502", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous temporal inference tasks such as fault monitoring and anomaly\ndetection exhibit a persistence property: for example, if something breaks, it\nstays broken until an intervention. When modeled as a Dynamic Bayesian Network,\npersistence adds dependencies between adjacent time slices, often making exact\ninference over time intractable using standard inference algorithms. However,\nwe show that persistence implies a regular structure that can be exploited for\nefficient inference. We present three successively more general classes of\nmodels: persistent causal chains (PCCs), persistent causal trees (PCTs) and\npersistent polytrees (PPTs), and the corresponding exact inference algorithms\nthat exploit persistence. We show that analytic asymptotic bounds for our\nalgorithms compare favorably to junction tree inference; and we demonstrate\nempirically that we can perform exact smoothing on the order of 100 times\nfaster than the approximate Boyen-Koller method on randomly generated instances\nof persistent tree models. We also show how to handle non-persistent variables\nand how persistence can be exploited effectively for approximate filtering.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:46:24 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Singliar", "Tomas", ""], ["Dash", "Denver", ""]]}, {"id": "1206.3291", "submitter": "Marc Toussaint", "authors": "Marc Toussaint, Laurent Charlin, Pascal Poupart", "title": "Hierarchical POMDP Controller Optimization by Likelihood Maximization", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-562-570", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning can often be simpli ed by decomposing the task into smaller tasks\narranged hierarchically. Charlin et al. [4] recently showed that the hierarchy\ndiscovery problem can be framed as a non-convex optimization problem. However,\nthe inherent computational di culty of solving such an optimization problem\nmakes it hard to scale to realworld problems. In another line of research,\nToussaint et al. [18] developed a method to solve planning problems by\nmaximumlikelihood estimation. In this paper, we show how the hierarchy\ndiscovery problem in partially observable domains can be tackled using a\nsimilar maximum likelihood approach. Our technique rst transforms the problem\ninto a dynamic Bayesian network through which a hierarchical structure can\nnaturally be discovered while optimizing the policy. Experimental results\ndemonstrate that this approach scales better than previous techniques based on\nnon-convex optimization.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:51:21 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Toussaint", "Marc", ""], ["Charlin", "Laurent", ""], ["Poupart", "Pascal", ""]]}, {"id": "1206.3292", "submitter": "Jin Tian", "authors": "Jin Tian", "title": "Identifying Dynamic Sequential Plans", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-554-561", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of identifying dynamic sequential plans in the\nframework of causal Bayesian networks, and show that the problem is reduced to\nidentifying causal effects, for which there are complete identi cation\nalgorithms available in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:51:48 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Tian", "Jin", ""]]}, {"id": "1206.3293", "submitter": "Peter  Thwaites", "authors": "Peter Thwaites, Jim Q. Smith, Robert G. Cowell", "title": "Propagation using Chain Event Graphs", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-546-553", "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Chain Event Graph (CEG) is a graphial model which designed to embody\nconditional independencies in problems whose state spaces are highly asymmetric\nand do not admit a natural product structure. In this paer we present a\nprobability propagation algorithm which uses the topology of the CEG to build a\ntransporter CEG. Intriungly,the transporter CEG is directly analogous to the\ntriangulated Bayesian Network (BN) in the more conventional junction tree\npropagation algorithms used with BNs. The propagation method uses factorization\nformulae also analogous to (but different from) the ones using potentials on\ncliques and separators of the BN. It appears that the methods will be typically\nmore efficient than the BN algorithms when applied to contexts where there is\nsignificant asymmetry present.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:52:10 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Thwaites", "Peter", ""], ["Smith", "Jim Q.", ""], ["Cowell", "Robert G.", ""]]}, {"id": "1206.3295", "submitter": "Haohai Yu", "authors": "Haohai Yu, Robert A. van Engelen", "title": "Refractor Importance Sampling", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-603-609", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce Refractor Importance Sampling (RIS), an\nimprovement to reduce error variance in Bayesian network importance sampling\npropagation under evidential reasoning. We prove the existence of a collection\nof importance functions that are close to the optimal importance function under\nevidential reasoning. Based on this theoretic result we derive the RIS\nalgorithm. RIS approaches the optimal importance function by applying localized\narc changes to minimize the divergence between the evidence-adjusted importance\nfunction and the optimal importance function. The validity and performance of\nRIS is empirically tested with a large setof synthetic Bayesian networks and\ntwo real-world networks.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:53:49 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Yu", "Haohai", ""], ["van Engelen", "Robert A.", ""]]}, {"id": "1206.3296", "submitter": "Ydo Wexler", "authors": "Ydo Wexler, Christopher Meek", "title": "Inference for Multiplicative Models", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-595-602", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper introduces a generalization for known probabilistic models such as\nlog-linear and graphical models, called here multiplicative models. These\nmodels, that express probabilities via product of parameters are shown to\ncapture multiple forms of contextual independence between variables, including\ndecision graphs and noisy-OR functions. An inference algorithm for\nmultiplicative models is provided and its correctness is proved. The complexity\nanalysis of the inference algorithm uses a more refined parameter than the\ntree-width of the underlying graph, and shows the computational cost does not\nexceed that of the variable elimination algorithm in graphical models. The\npaper ends with examples where using the new models and algorithm is\ncomputationally beneficial.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:55:04 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Wexler", "Ydo", ""], ["Meek", "Christopher", ""]]}, {"id": "1206.3318", "submitter": "Vanessa Burke", "authors": "Michael Bowling, Martin Zinkevich", "title": "On Local Regret", "comments": "This is the longer version of the same-titled paper appearing in the\n  Proceedings of the Twenty-Ninth International Conference on Machine Learning\n  (ICML), 2012", "journal-ref": null, "doi": null, "report-no": "TR12-04", "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Online learning aims to perform nearly as well as the best hypothesis in\nhindsight. For some hypothesis classes, though, even finding the best\nhypothesis offline is challenging. In such offline cases, local search\ntechniques are often employed and only local optimality guaranteed. For online\ndecision-making with such hypothesis classes, we introduce local regret, a\ngeneralization of regret that aims to perform nearly as well as only nearby\nhypotheses. We then present a general algorithm to minimize local regret with\narbitrary locality graphs. We also show how the graph structure can be\nexploited to drastically speed learning. These algorithms are then demonstrated\non a diverse set of online problems: online disjunct learning, online Max-SAT,\nand online decision tree learning.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2012 20:07:30 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Bowling", "Michael", ""], ["Zinkevich", "Martin", ""]]}, {"id": "1206.3382", "submitter": "Carmel Domshlak", "authors": "Zohar Feldman, Carmel Domshlak", "title": "Simple Regret Optimization in Online Planning for Markov Decision\n  Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider online planning in Markov decision processes (MDPs). In online\nplanning, the agent focuses on its current state only, deliberates about the\nset of possible policies from that state onwards and, when interrupted, uses\nthe outcome of that exploratory deliberation to choose what action to perform\nnext. The performance of algorithms for online planning is assessed in terms of\nsimple regret, which is the agent's expected performance loss when the chosen\naction, rather than an optimal one, is followed.\n  To date, state-of-the-art algorithms for online planning in general MDPs are\neither best effort, or guarantee only polynomial-rate reduction of simple\nregret over time. Here we introduce a new Monte-Carlo tree search algorithm,\nBRUE, that guarantees exponential-rate reduction of simple regret and error\nprobability. This algorithm is based on a simple yet non-standard state-space\nsampling scheme, MCTS2e, in which different parts of each sample are dedicated\nto different exploratory objectives. Our empirical evaluation shows that BRUE\nnot only provides superior performance guarantees, but is also very effective\nin practice and favorably compares to state-of-the-art. We then extend BRUE\nwith a variant of \"learning by forgetting.\" The resulting set of algorithms,\nBRUE(alpha), generalizes BRUE, improves the exponential factor in the upper\nbound on its reduction rate, and exhibits even more attractive empirical\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2012 07:23:28 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2012 08:48:44 GMT"}], "update_date": "2012-12-20", "authors_parsed": [["Feldman", "Zohar", ""], ["Domshlak", "Carmel", ""]]}, {"id": "1206.3437", "submitter": "Jean-Guillaume Fages", "authors": "Jean-Guillaume Fages and Xavier Lorca", "title": "Improving the Asymmetric TSP by Considering Graph Structure", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": "12/4/INFO", "categories": "cs.DM cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works on cost based relaxations have improved Constraint Programming\n(CP) models for the Traveling Salesman Problem (TSP). We provide a short survey\nover solving asymmetric TSP with CP. Then, we suggest new implied propagators\nbased on general graph properties. We experimentally show that such implied\npropagators bring robustness to pathological instances and highlight the fact\nthat graph structure can significantly improve search heuristics behavior.\nFinally, we show that our approach outperforms current state of the art\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2012 12:15:31 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Fages", "Jean-Guillaume", ""], ["Lorca", "Xavier", ""]]}, {"id": "1206.3536", "submitter": "Marc Maier", "authors": "Marc Maier, David Jensen", "title": "Identifying Independence in Relational Models", "comments": "This paper has been revised and expanded. See \"Reasoning about\n  Independence in Probabilistic Models of Relational Data\"\n  http://arxiv.org/abs/1302.4381", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rules of d-separation provide a framework for deriving conditional\nindependence facts from model structure. However, this theory only applies to\nsimple directed graphical models. We introduce relational d-separation, a\ntheory for deriving conditional independence in relational models. We provide a\nsound, complete, and computationally efficient method for relational\nd-separation, and we present empirical results that demonstrate effectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2012 18:23:56 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2012 18:21:10 GMT"}, {"version": "v3", "created": "Mon, 15 Apr 2013 13:42:19 GMT"}], "update_date": "2013-04-16", "authors_parsed": [["Maier", "Marc", ""], ["Jensen", "David", ""]]}, {"id": "1206.3551", "submitter": "Debarun Bhattacharjya", "authors": "Debarun Bhattacharjya, Ross D. Shachter", "title": "Sensitivity analysis in decision circuits", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-34-42", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision circuits have been developed to perform efficient evaluation of\ninfluence diagrams [Bhattacharjya and Shachter, 2007], building on the advances\nin arithmetic circuits for belief network inference [Darwiche,2003]. In the\nprocess of model building and analysis, we perform sensitivity analysis to\nunderstand how the optimal solution changes in response to changes in the\nmodel. When sequential decision problems under uncertainty are represented as\ndecision circuits, we can exploit the efficient solution process embodied in\nthe decision circuit and the wealth of derivative information available to\ncompute the value of information for the uncertainties in the problem and the\neffects of changes to model parameters on the value and the optimal strategy.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 14:18:02 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Bhattacharjya", "Debarun", ""], ["Shachter", "Ross D.", ""]]}, {"id": "1206.3555", "submitter": "Andreas Stuhlm\\\"uller", "authors": "Andreas Stuhlm\\\"uller, Noah D. Goodman", "title": "A Dynamic Programming Algorithm for Inference in Recursive Probabilistic\n  Programs", "comments": "Second Statistical Relational AI workshop at UAI 2012 (StaRAI-12)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a dynamic programming algorithm for computing the marginal\ndistribution of discrete probabilistic programs. This algorithm takes a\nfunctional interpreter for an arbitrary probabilistic programming language and\nturns it into an efficient marginalizer. Because direct caching of\nsub-distributions is impossible in the presence of recursion, we build a graph\nof dependencies between sub-distributions. This factored sum-product network\nmakes (potentially cyclic) dependencies between subproblems explicit, and\ncorresponds to a system of equations for the marginal distribution. We solve\nthese equations by fixed-point iteration in topological order. We illustrate\nthis algorithm on examples used in teaching probabilistic models, computational\ncognitive science research, and game theory.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2012 19:44:02 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2012 22:00:30 GMT"}], "update_date": "2012-09-12", "authors_parsed": [["Stuhlm\u00fcller", "Andreas", ""], ["Goodman", "Noah D.", ""]]}, {"id": "1206.3614", "submitter": "Carleton Coffrin", "authors": "Carleton Coffrin, Pascal Van Hentenryck", "title": "A Linear-Programming Approximation of AC Power Flows", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear active-power-only DC power flow approximations are pervasive in the\nplanning and control of power systems. However, these approximations fail to\ncapture reactive power and voltage magnitudes, both of which are necessary in\nmany applications to ensure voltage stability and AC power flow feasibility.\nThis paper proposes linear-programming models (the LPAC models) that\nincorporate reactive power and voltage magnitudes in a linear power flow\napproximation. The LPAC models are built on a convex approximation of the\ncosine terms in the AC equations, as well as Taylor approximations of the\nremaining nonlinear terms. Experimental comparisons with AC solutions on a\nvariety of standard IEEE and MatPower benchmarks show that the LPAC models\nproduce accurate values for active and reactive power, phase angles, and\nvoltage magnitudes. The potential benefits of the LPAC models are illustrated\non two \"proof-of-concept\" studies in power restoration and capacitor placement.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jun 2012 00:10:07 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2012 06:00:22 GMT"}, {"version": "v3", "created": "Tue, 6 Aug 2013 04:29:35 GMT"}], "update_date": "2013-08-07", "authors_parsed": [["Coffrin", "Carleton", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "1206.3633", "submitter": "Koushik Mondal", "authors": "Koushik Mondal, Paramartha Dutta, Siddhartha Bhattacharyya", "title": "Feature Based Fuzzy Rule Base Design for Image Extraction", "comments": "6 pages, 5 figures, Fuzzy Rule Base; Image Extraction; Fuzzy\n  Inference System (FIS); Membership Functions; Region of Interests; Feature\n  Selection", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent advancement of multimedia technologies, it becomes a major\nconcern of detecting visual attention regions in the field of image processing.\nThe popularity of the terminal devices in a heterogeneous environment of the\nmultimedia technology gives us enough scope for the betterment of image\nvisualization. Although there exist numerous methods, feature based image\nextraction becomes a popular one in the field of image processing. The\nobjective of image segmentation is the domain-independent partition of the\nimage into a set of regions, which are visually distinct and uniform with\nrespect to some property, such as grey level, texture or colour. Segmentation\nand subsequent extraction can be considered the first step and key issue in\nobject recognition, scene understanding and image analysis. Its application\narea encompasses mobile devices, industrial quality control, medical\nappliances, robot navigation, geophysical exploration, military applications,\netc. In all these areas, the quality of the final results depends largely on\nthe quality of the preprocessing work. Most of the times, acquiring\nspurious-free preprocessing data requires a lot of application cum mathematical\nintensive background works. We propose a feature based fuzzy rule guided novel\ntechnique that is functionally devoid of any external intervention during\nexecution. Experimental results suggest that this approach is an efficient one\nin comparison to different other techniques extensively addressed in\nliterature. In order to justify the supremacy of performance of our proposed\ntechnique in respect of its competitors, we take recourse to effective metrics\nlike Mean Squared Error (MSE), Mean Absolute Error (MAE) and Peak Signal to\nNoise Ratio (PSNR).\n", "versions": [{"version": "v1", "created": "Sat, 16 Jun 2012 07:11:02 GMT"}], "update_date": "2012-06-19", "authors_parsed": [["Mondal", "Koushik", ""], ["Dutta", "Paramartha", ""], ["Bhattacharyya", "Siddhartha", ""]]}, {"id": "1206.3658", "submitter": "Stevan Harnad", "authors": "Stevan Harnad", "title": "Alan Turing and the \"Hard\" and \"Easy\" Problem of Cognition: Doing and\n  Feeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The \"easy\" problem of cognitive science is explaining how and why we can do\nwhat we can do. The \"hard\" problem is explaining how and why we feel. Turing's\nmethodology for cognitive science (the Turing Test) is based on doing: Design a\nmodel that can do anything a human can do, indistinguishably from a human, to a\nhuman, and you have explained cognition. Searle has shown that the successful\nmodel cannot be solely computational. Sensory-motor robotic capacities are\nnecessary to ground some, at least, of the model's words, in what the robot can\ndo with the things in the world that the words are about. But even grounding is\nnot enough to guarantee that -- nor to explain how and why -- the model feels\n(if it does). That problem is much harder to solve (and perhaps insoluble).\n", "versions": [{"version": "v1", "created": "Sat, 16 Jun 2012 11:42:40 GMT"}], "update_date": "2012-06-19", "authors_parsed": [["Harnad", "Stevan", ""]]}, {"id": "1206.3667", "submitter": "Sudhir Ahuja", "authors": "Sudhir Ahuja, Mr. Rinkaj Goyal", "title": "Information Retrieval in Intelligent Systems: Current Scenario & Issues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web space is the huge repository of data. Everyday lots of new information\nget added to this web space. The more the information, more is demand for tools\nto access that information. Answering users' queries about the online\ninformation intelligently is one of the great challenges in information\nretrieval in intelligent systems. In this paper, we will start with the brief\nintroduction on information retrieval and intelligent systems and explain how\nswoogle, the semantic search engine, uses its algorithms and techniques to\nsearch for the desired contents in the web. We then continue with the\nclustering technique that is used to group the similar things together and\ndiscuss the machine learning technique called Self-organizing maps [6] or SOM,\nwhich is a data visualization technique that reduces the dimensions of data\nthrough the use of self-organizing neural networks. We then discuss how SOM is\nused to visualize the contents of the data, by following some lines of\nalgorithm, in the form of maps. So, we could say that websites or machines can\nbe used to retrieve the information that what exactly users want from them.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jun 2012 13:46:33 GMT"}], "update_date": "2012-06-19", "authors_parsed": [["Ahuja", "Sudhir", ""], ["Goyal", "Mr. Rinkaj", ""]]}, {"id": "1206.3714", "submitter": "Santosh Kumar Divvala", "authors": "Santosh K. Divvala and Alexei A. Efros and Martial Hebert", "title": "How important are Deformable Parts in the Deformable Parts Model?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main stated contribution of the Deformable Parts Model (DPM) detector of\nFelzenszwalb et al. (over the Histogram-of-Oriented-Gradients approach of Dalal\nand Triggs) is the use of deformable parts. A secondary contribution is the\nlatent discriminative learning. Tertiary is the use of multiple components. A\ncommon belief in the vision community (including ours, before this study) is\nthat their ordering of contributions reflects the performance of detector in\npractice. However, what we have experimentally found is that the ordering of\nimportance might actually be the reverse. First, we show that by increasing the\nnumber of components, and switching the initialization step from their\naspect-ratio, left-right flipping heuristics to appearance-based clustering,\nconsiderable improvement in performance is obtained. But more intriguingly, we\nshow that with these new components, the part deformations can now be\ncompletely switched off, yet obtaining results that are almost on par with the\noriginal DPM detector. Finally, we also show initial results for using multiple\ncomponents on a different problem -- scene classification, suggesting that this\nidea might have wider applications in addition to object detection.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jun 2012 23:26:38 GMT"}], "update_date": "2012-06-19", "authors_parsed": [["Divvala", "Santosh K.", ""], ["Efros", "Alexei A.", ""], ["Hebert", "Martial", ""]]}, {"id": "1206.3902", "submitter": "Hubie Chen", "authors": "Hubie Chen", "title": "On the Complexity of Existential Positive Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We systematically investigate the complexity of model checking the\nexistential positive fragment of first-order logic. In particular, for a set of\nexistential positive sentences, we consider model checking where the sentence\nis restricted to fall into the set; a natural question is then to classify\nwhich sentence sets are tractable and which are intractable. With respect to\nfixed-parameter tractability, we give a general theorem that reduces this\nclassification question to the corresponding question for primitive positive\nlogic, for a variety of representations of structures. This general theorem\nallows us to deduce that an existential positive sentence set having bounded\narity is fixed-parameter tractable if and only if each sentence is equivalent\nto one in bounded-variable logic. We then use the lens of classical complexity\nto study these fixed-parameter tractable sentence sets. We show that such a set\ncan be NP-complete, and consider the length needed by a translation from\nsentences in such a set to bounded-variable logic; we prove superpolynomial\nlower bounds on this length using the theory of compilability, obtaining an\ninteresting type of formula size lower bound. Overall, the tools, concepts, and\nresults of this article set the stage for the future consideration of the\ncomplexity of model checking on more expressive logics.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 12:19:32 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2012 14:51:45 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Chen", "Hubie", ""]]}, {"id": "1206.3959", "submitter": "Jeff Bilmes", "authors": "Jeff Bilmes, Andrew Ng", "title": "Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial\n  Intelligence (2009)", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI2009", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the Twenty-Fifth Conference on Uncertainty in\nArtificial Intelligence, which was held in Montreal, QC, Canada, June 18 - 21\n2009.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 16:43:44 GMT"}, {"version": "v2", "created": "Thu, 28 Aug 2014 04:27:28 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["Bilmes", "Jeff", ""], ["Ng", "Andrew", ""]]}, {"id": "1206.4116", "submitter": "Makoto Yamada", "authors": "Makoto Yamada, Leonid Sigal, Michalis Raptis, Masashi Sugiyama", "title": "Dependence Maximizing Temporal Alignment via Squared-Loss Mutual\n  Information", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of temporal alignment is to establish time correspondence between\ntwo sequences, which has many applications in a variety of areas such as speech\nprocessing, bioinformatics, computer vision, and computer graphics. In this\npaper, we propose a novel temporal alignment method called least-squares\ndynamic time warping (LSDTW). LSDTW finds an alignment that maximizes\nstatistical dependency between sequences, measured by a squared-loss variant of\nmutual information. The benefit of this novel information-theoretic formulation\nis that LSDTW can align sequences with different lengths, different\ndimensionality, high non-linearity, and non-Gaussianity in a computationally\nefficient manner. In addition, model parameters such as an initial alignment\nmatrix can be systematically optimized by cross-validation. We demonstrate the\nusefulness of LSDTW through experiments on synthetic and real-world Kinect\naction recognition datasets.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2012 03:35:52 GMT"}], "update_date": "2012-06-20", "authors_parsed": [["Yamada", "Makoto", ""], ["Sigal", "Leonid", ""], ["Raptis", "Michalis", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1206.4185", "submitter": "Eliyahu Osherovich", "authors": "Eliyahu Osherovich", "title": "Ant Robotics: Covering Continuous Domains by Multi-A(ge)nt Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": "MSC-2007-18", "categories": "cs.RO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present an algorithm for covering continuous connected\ndomains by ant-like robots with very limited capabilities. The robots can mark\nvisited places with pheromone marks and sense the level of the pheromone in\ntheir local neighborhood. In case of multiple robots these pheromone marks can\nbe sensed by all robots and provide the only way of (indirect) communication\nbetween the robots. The robots are assumed to be memoryless, and to have no\nglobal information such as the domain map, their own position (either absolute\nor relative), total marked area percentage, maximal pheromone level, etc..\nDespite the robots' simplicity, we show that they are able, by running a very\nsimple rule of behavior, to ensure efficient covering of arbitrary connected\ndomains, including non-planar and multidimensional ones. The novelty of our\nalgorithm lies in the fact that, unlike previously proposed methods, our\nalgorithm works on continuous domains without relying on some \"induced\"\nunderlying graph, that effectively reduces the problem to a discrete case of\ngraph covering. The algorithm guarantees complete coverage of any connected\ndomain. We also prove that the algorithm is noise immune, i.e., it is able to\ncope with any initial pheromone profile (noise). In addition the algorithm\nprovides a bounded constant time between two successive visits of the robot,\nand thus, is suitable for patrolling or surveillance applications.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2012 12:00:47 GMT"}], "update_date": "2012-06-20", "authors_parsed": [["Osherovich", "Eliyahu", ""]]}, {"id": "1206.4329", "submitter": "Sudarshan Nandy", "authors": "Sudarshan Nandy, Partha Pratim Sarkar and Achintya Das", "title": "An Improved Gauss-Newtons Method based Back-propagation Algorithm for\n  Fast Convergence", "comments": "7 pages, 6 figures,2 tables, Published with International Journal of\n  Computer Applications (IJCA)", "journal-ref": "International Journal of Computer Applications 39(8):1-7, February\n  2012. Published by Foundation of Computer Science, New York, USA", "doi": "10.5120/4837-7097", "report-no": null, "categories": "cs.AI cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present work deals with an improved back-propagation algorithm based on\nGauss-Newton numerical optimization method for fast convergence. The steepest\ndescent method is used for the back-propagation. The algorithm is tested using\nvarious datasets and compared with the steepest descent back-propagation\nalgorithm. In the system, optimization is carried out using multilayer neural\nnetwork. The efficacy of the proposed method is observed during the training\nperiod as it converges quickly for the dataset used in test. The requirement of\nmemory for computing the steps of algorithm is also analyzed.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2012 20:20:56 GMT"}], "update_date": "2012-06-21", "authors_parsed": [["Nandy", "Sudarshan", ""], ["Sarkar", "Partha Pratim", ""], ["Das", "Achintya", ""]]}, {"id": "1206.4391", "submitter": "Koushik Mondal", "authors": "Koushik Mondal, Paramartha Dutta, Siddhartha Bhattacharyya", "title": "Gray Image extraction using Fuzzy Logic", "comments": "8 pages, 5 figures, Fuzzy Rule Base, Image Extraction, Fuzzy\n  Inference System (FIS), Membership Functions, Membership values,Image coding\n  and Processing, Soft Computing, Computer Vision Accepted and published in\n  IEEE. arXiv admin note: text overlap with arXiv:1206.3633", "journal-ref": null, "doi": "10.1109/ACCT.2012.60", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzy systems concern fundamental methodology to represent and process\nuncertainty and imprecision in the linguistic information. The fuzzy systems\nthat use fuzzy rules to represent the domain knowledge of the problem are known\nas Fuzzy Rule Base Systems (FRBS). On the other hand image segmentation and\nsubsequent extraction from a noise-affected background, with the help of\nvarious soft computing methods, are relatively new and quite popular due to\nvarious reasons. These methods include various Artificial Neural Network (ANN)\nmodels (primarily supervised in nature), Genetic Algorithm (GA) based\ntechniques, intensity histogram based methods etc. providing an extraction\nsolution working in unsupervised mode happens to be even more interesting\nproblem. Literature suggests that effort in this respect appears to be quite\nrudimentary. In the present article, we propose a fuzzy rule guided novel\ntechnique that is functional devoid of any external intervention during\nexecution. Experimental results suggest that this approach is an efficient one\nin comparison to different other techniques extensively addressed in\nliterature. In order to justify the supremacy of performance of our proposed\ntechnique in respect of its competitors, we take recourse to effective metrics\nlike Mean Squared Error (MSE), Mean Absolute Error (MAE), Peak Signal to Noise\nRatio (PSNR).\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 06:16:18 GMT"}], "update_date": "2012-06-21", "authors_parsed": [["Mondal", "Koushik", ""], ["Dutta", "Paramartha", ""], ["Bhattacharyya", "Siddhartha", ""]]}, {"id": "1206.4603", "submitter": "Jason Weston", "authors": "Jason Weston (Google), Chong Wang (Princeton University), Ron Weiss\n  (Google), Adam Berenzweig (Google)", "title": "Latent Collaborative Retrieval", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retrieval tasks typically require a ranking of items given a query.\nCollaborative filtering tasks, on the other hand, learn to model user's\npreferences over items. In this paper we study the joint problem of\nrecommending items to a user with respect to a given query, which is a\nsurprisingly common task. This setup differs from the standard collaborative\nfiltering one in that we are given a query x user x item tensor for training\ninstead of the more traditional user x item matrix. Compared to document\nretrieval we do have a query, but we may or may not have content features (we\nwill consider both cases) and we can also take account of the user's profile.\nWe introduce a factorized model for this new task that optimizes the top-ranked\nitems returned for the given query and user. We report empirical results where\nit outperforms several baselines.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 14:41:20 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Weston", "Jason", "", "Google"], ["Wang", "Chong", "", "Princeton University"], ["Weiss", "Ron", "", "Google"], ["Berenzweig", "Adam", "", "Google"]]}, {"id": "1206.4604", "submitter": "Elad Eban", "authors": "Elad Eban (Hebrew University), Aharon Birnbaum (Hebrew University),\n  Shai Shalev-Shwartz (Hebrew University), Amir Globerson (Hebrew University)", "title": "Learning the Experts for Online Sequence Prediction", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online sequence prediction is the problem of predicting the next element of a\nsequence given previous elements. This problem has been extensively studied in\nthe context of individual sequence prediction, where no prior assumptions are\nmade on the origin of the sequence. Individual sequence prediction algorithms\nwork quite well for long sequences, where the algorithm has enough time to\nlearn the temporal structure of the sequence. However, they might give poor\npredictions for short sequences. A possible remedy is to rely on the general\nmodel of prediction with expert advice, where the learner has access to a set\nof $r$ experts, each of which makes its own predictions on the sequence. It is\nwell known that it is possible to predict almost as well as the best expert if\nthe sequence length is order of $\\log(r)$. But, without firm prior knowledge on\nthe problem, it is not clear how to choose a small set of {\\em good} experts.\nIn this paper we describe and analyze a new algorithm that learns a good set of\nexperts using a training set of previously observed sequences. We demonstrate\nthe merits of our approach by applying it on the task of click prediction on\nthe web.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 14:42:16 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Eban", "Elad", "", "Hebrew University"], ["Birnbaum", "Aharon", "", "Hebrew University"], ["Shalev-Shwartz", "Shai", "", "Hebrew University"], ["Globerson", "Amir", "", "Hebrew University"]]}, {"id": "1206.4606", "submitter": "Chao Liu", "authors": "Chao Liu (Tencent Inc.), Yi-Min Wang (Microsoft Research)", "title": "TrueLabel + Confusions: A Spectrum of Probabilistic Models in Analyzing\n  Multiple Ratings", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper revisits the problem of analyzing multiple ratings given by\ndifferent judges. Different from previous work that focuses on distilling the\ntrue labels from noisy crowdsourcing ratings, we emphasize gaining diagnostic\ninsights into our in-house well-trained judges. We generalize the well-known\nDawidSkene model (Dawid & Skene, 1979) to a spectrum of probabilistic models\nunder the same \"TrueLabel + Confusion\" paradigm, and show that our proposed\nhierarchical Bayesian model, called HybridConfusion, consistently outperforms\nDawidSkene on both synthetic and real-world data sets.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 14:43:42 GMT"}], "update_date": "2012-06-25", "authors_parsed": [["Liu", "Chao", "", "Tencent Inc."], ["Wang", "Yi-Min", "", "Microsoft Research"]]}, {"id": "1206.4613", "submitter": "Mauricio Araya", "authors": "Mauricio Araya (LORIA/INRIA), Olivier Buffet (LORIA/INRIA), Vincent\n  Thomas (LORIA/INRIA)", "title": "Near-Optimal BRL using Optimistic Local Transitions", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based Bayesian Reinforcement Learning (BRL) allows a found\nformalization of the problem of acting optimally while facing an unknown\nenvironment, i.e., avoiding the exploration-exploitation dilemma. However,\nalgorithms explicitly addressing BRL suffer from such a combinatorial explosion\nthat a large body of work relies on heuristic algorithms. This paper introduces\nBOLT, a simple and (almost) deterministic heuristic algorithm for BRL which is\noptimistic about the transition function. We analyze BOLT's sample complexity,\nand show that under certain parameters, the algorithm is near-optimal in the\nBayesian sense with high probability. Then, experimental results highlight the\nkey differences of this method compared to previous work.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:00:40 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Araya", "Mauricio", "", "LORIA/INRIA"], ["Buffet", "Olivier", "", "LORIA/INRIA"], ["Thomas", "Vincent", "", "LORIA/INRIA"]]}, {"id": "1206.4617", "submitter": "Sergey Levine", "authors": "Sergey Levine (Stanford University), Vladlen Koltun (Stanford\n  University)", "title": "Continuous Inverse Optimal Control with Locally Optimal Examples", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse optimal control, also known as inverse reinforcement learning, is the\nproblem of recovering an unknown reward function in a Markov decision process\nfrom expert demonstrations of the optimal policy. We introduce a probabilistic\ninverse optimal control algorithm that scales gracefully with task\ndimensionality, and is suitable for large, continuous domains where even\ncomputing a full policy is impractical. By using a local approximation of the\nreward function, our method can also drop the assumption that the\ndemonstrations are globally optimal, requiring only local optimality. This\nallows it to learn from examples that are unsuitable for prior methods.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:02:28 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Levine", "Sergey", "", "Stanford University"], ["Koltun", "Vladlen", "", "Stanford\n  University"]]}, {"id": "1206.4636", "submitter": "M. Pawan Kumar", "authors": "M. Pawan Kumar (Ecole Centrale Paris), Ben Packer (Stanford\n  University), Daphne Koller (Stanford University)", "title": "Modeling Latent Variable Uncertainty for Loss-based Learning", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of parameter estimation using weakly supervised\ndatasets, where a training sample consists of the input and a partially\nspecified annotation, which we refer to as the output. The missing information\nin the annotation is modeled using latent variables. Previous methods\noverburden a single distribution with two separate tasks: (i) modeling the\nuncertainty in the latent variables during training; and (ii) making accurate\npredictions for the output and the latent variables during testing. We propose\na novel framework that separates the demands of the two tasks using two\ndistributions: (i) a conditional distribution to model the uncertainty of the\nlatent variables for a given input-output pair; and (ii) a delta distribution\nto predict the output and the latent variables for a given input. During\nlearning, we encourage agreement between the two distributions by minimizing a\nloss-based dissimilarity coefficient. Our approach generalizes latent SVM in\ntwo important ways: (i) it models the uncertainty over latent variables instead\nof relying on a pointwise estimate; and (ii) it allows the use of loss\nfunctions that depend on latent variables, which greatly increases its\napplicability. We demonstrate the efficacy of our approach on two challenging\nproblems---object detection and action detection---using publicly available\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:15:13 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Kumar", "M. Pawan", "", "Ecole Centrale Paris"], ["Packer", "Ben", "", "Stanford\n  University"], ["Koller", "Daphne", "", "Stanford University"]]}, {"id": "1206.4639", "submitter": "Koby Crammer", "authors": "Koby Crammer (The Technion), Gal Chechik (Bar Ilan University and\n  Google research)", "title": "Adaptive Regularization for Weight Matrices", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms for learning distributions over weight-vectors, such as AROW were\nrecently shown empirically to achieve state-of-the-art performance at various\nproblems, with strong theoretical guaranties. Extending these algorithms to\nmatrix models pose challenges since the number of free parameters in the\ncovariance of the distribution scales as $n^4$ with the dimension $n$ of the\nmatrix, and $n$ tends to be large in real applications. We describe, analyze\nand experiment with two new algorithms for learning distribution of matrix\nmodels. Our first algorithm maintains a diagonal covariance over the parameters\nand can handle large covariance matrices. The second algorithm factors the\ncovariance to capture inter-features correlation while keeping the number of\nparameters linear in the size of the original matrix. We analyze both\nalgorithms in the mistake bound model and show a superior precision performance\nof our approach over other algorithms in two tasks: retrieving similar images,\nand ranking similar documents. The factored algorithm is shown to attain faster\nconvergence rate.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:17:49 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Crammer", "Koby", "", "The Technion"], ["Chechik", "Gal", "", "Bar Ilan University and\n  Google research"]]}, {"id": "1206.4647", "submitter": "Laurent Charlin", "authors": "Laurent Charlin (University of Toronto), Rich Zemel (University of\n  Toronto), Craig Boutilier (University of Toronto)", "title": "Active Learning for Matching Problems", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective learning of user preferences is critical to easing user burden in\nvarious types of matching problems. Equally important is active query selection\nto further reduce the amount of preference information users must provide. We\naddress the problem of active learning of user preferences for matching\nproblems, introducing a novel method for determining probabilistic matchings,\nand developing several new active learning strategies that are sensitive to the\nspecific matching objective. Experiments with real-world data sets spanning\ndiverse domains demonstrate that matching-sensitive active learning\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:22:24 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Charlin", "Laurent", "", "University of Toronto"], ["Zemel", "Rich", "", "University of\n  Toronto"], ["Boutilier", "Craig", "", "University of Toronto"]]}, {"id": "1206.4652", "submitter": "Novi Quadrianto", "authors": "Novi Quadrianto (University of Cambridge), Chao Chen (IST Austria),\n  Christoph Lampert (IST Austria)", "title": "The Most Persistent Soft-Clique in a Set of Sampled Graphs", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When searching for characteristic subpatterns in potentially noisy graph\ndata, it appears self-evident that having multiple observations would be better\nthan having just one. However, it turns out that the inconsistencies introduced\nwhen different graph instances have different edge sets pose a serious\nchallenge. In this work we address this challenge for the problem of finding\nmaximum weighted cliques.\n  We introduce the concept of most persistent soft-clique. This is subset of\nvertices, that 1) is almost fully or at least densely connected, 2) occurs in\nall or almost all graph instances, and 3) has the maximum weight. We present a\nmeasure of clique-ness, that essentially counts the number of edge missing to\nmake a subset of vertices into a clique. With this measure, we show that the\nproblem of finding the most persistent soft-clique problem can be cast either\nas: a) a max-min two person game optimization problem, or b) a min-min soft\nmargin optimization problem. Both formulations lead to the same solution when\nusing a partial Lagrangian method to solve the optimization problems. By\nexperiments on synthetic data and on real social network data, we show that the\nproposed method is able to reliably find soft cliques in graph data, even if\nthat is distorted by random noise or unreliable observations.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:24:31 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Quadrianto", "Novi", "", "University of Cambridge"], ["Chen", "Chao", "", "IST Austria"], ["Lampert", "Christoph", "", "IST Austria"]]}, {"id": "1206.4654", "submitter": "Russell Greiner", "authors": "Siamak Ravanbakhsh (University of Alberta), Chun-Nam Yu (University of\n  Alberta), Russell Greiner (University of Alberta)", "title": "A Generalized Loop Correction Method for Approximate Inference in\n  Graphical Models", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Belief Propagation (BP) is one of the most popular methods for inference in\nprobabilistic graphical models. BP is guaranteed to return the correct answer\nfor tree structures, but can be incorrect or non-convergent for loopy graphical\nmodels. Recently, several new approximate inference algorithms based on cavity\ndistribution have been proposed. These methods can account for the effect of\nloops by incorporating the dependency between BP messages. Alternatively,\nregion-based approximations (that lead to methods such as Generalized Belief\nPropagation) improve upon BP by considering interactions within small clusters\nof variables, thus taking small loops within these clusters into account. This\npaper introduces an approach, Generalized Loop Correction (GLC), that benefits\nfrom both of these types of loop correction. We show how GLC relates to these\ntwo families of inference methods, then provide empirical evidence that GLC\nworks effectively in general, and can be significantly more accurate than both\ncorrection schemes.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:25:04 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Ravanbakhsh", "Siamak", "", "University of Alberta"], ["Yu", "Chun-Nam", "", "University of\n  Alberta"], ["Greiner", "Russell", "", "University of Alberta"]]}, {"id": "1206.4656", "submitter": "Kiri Wagstaff", "authors": "Kiri Wagstaff (Jet Propulsion Laboratory)", "title": "Machine Learning that Matters", "comments": "ICML2012", "journal-ref": "Proceedings of the Twenty-Ninth International Conference on\n  Machine Learning (ICML), p. 529-536", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of current machine learning (ML) research has lost its connection to\nproblems of import to the larger world of science and society. From this\nperspective, there exist glaring limitations in the data sets we investigate,\nthe metrics we employ for evaluation, and the degree to which results are\ncommunicated back to their originating domains. What changes are needed to how\nwe conduct research to increase the impact that ML has? We present six Impact\nChallenges to explicitly focus the field?s energy and attention, and we discuss\nexisting obstacles that must be addressed. We aim to inspire ongoing discussion\nand focus on ML that matters.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:26:13 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Wagstaff", "Kiri", "", "Jet Propulsion Laboratory"]]}, {"id": "1206.4667", "submitter": "Kendrick Boyd", "authors": "Kendrick Boyd (University of Wisconsin Madison), Vitor Santos Costa\n  (University of Porto), Jesse Davis (KU Leuven), David Page (University of\n  Wisconsin Madison)", "title": "Unachievable Region in Precision-Recall Space and Its Effect on\n  Empirical Evaluation", "comments": "ICML2012, fixed citations to use correct tech report number", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precision-recall (PR) curves and the areas under them are widely used to\nsummarize machine learning results, especially for data sets exhibiting class\nskew. They are often used analogously to ROC curves and the area under ROC\ncurves. It is known that PR curves vary as class skew changes. What was not\nrecognized before this paper is that there is a region of PR space that is\ncompletely unachievable, and the size of this region depends only on the skew.\nThis paper precisely characterizes the size of that region and discusses its\nimplications for empirical evaluation methodology in machine learning.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:33:05 GMT"}, {"version": "v2", "created": "Wed, 18 Jul 2012 18:54:06 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Boyd", "Kendrick", "", "University of Wisconsin Madison"], ["Costa", "Vitor Santos", "", "University of Porto"], ["Davis", "Jesse", "", "KU Leuven"], ["Page", "David", "", "University of\n  Wisconsin Madison"]]}, {"id": "1206.5157", "submitter": "Vini Katyal", "authors": "Vini Katyal, Aviral", "title": "Leaf vein segmentation using Odd Gabor filters and morphological\n  operations", "comments": "International Journal of Advanced Research in Computer Science Volume\n  3, No. 3, May-June 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leaf vein forms the basis of leaf characterization and classification.\nDifferent species have different leaf vein patterns. It is seen that leaf vein\nsegmentation will help in maintaining a record of all the leaves according to\ntheir specific pattern of veins thus provide an effective way to retrieve and\nstore information regarding various plant species in database as well as\nprovide an effective means to characterize plants on the basis of leaf vein\nstructure which is unique for every species. The algorithm proposes a new way\nof segmentation of leaf veins with the use of Odd Gabor filters and the use of\nmorphological operations for producing a better output. The Odd Gabor filter\ngives an efficient output and is robust and scalable as compared with the\nexisting techniques as it detects the fine fiber like veins present in leaves\nmuch more efficiently.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2012 14:22:16 GMT"}], "update_date": "2012-06-25", "authors_parsed": [["Katyal", "Vini", ""], ["Aviral", "", ""]]}, {"id": "1206.5239", "submitter": "Firas Hamze", "authors": "Firas Hamze, Nando de Freitas", "title": "Large-Flip Importance Sampling", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-167-174", "categories": "stat.CO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new Monte Carlo algorithm for complex discrete distributions.\nThe algorithm is motivated by the N-Fold Way, which is an ingenious\nevent-driven MCMC sampler that avoids rejection moves at any specific state.\nThe N-Fold Way can however get \"trapped\" in cycles. We surmount this problem by\nmodifying the sampling process. This correction does introduce bias, but the\nbias is subsequently corrected with a carefully engineered importance sampler.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 14:51:32 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Hamze", "Firas", ""], ["de Freitas", "Nando", ""]]}, {"id": "1206.5242", "submitter": "Vibhav Gogate", "authors": "Vibhav Gogate, Bozhena Bidyuk, Rina Dechter", "title": "Studies in Lower Bounding Probabilities of Evidence using the Markov\n  Inequality", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-141-148", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing the probability of evidence even with known error bounds is\nNP-hard. In this paper we address this hard problem by settling on an easier\nproblem. We propose an approximation which provides high confidence lower\nbounds on probability of evidence but does not have any guarantees in terms of\nrelative or absolute error. Our proposed approximation is a randomized\nimportance sampling scheme that uses the Markov inequality. However, a\nstraight-forward application of the Markov inequality may lead to poor lower\nbounds. We therefore propose several heuristic measures to improve its\nperformance in practice. Empirical evaluation of our scheme with state-of-\nthe-art lower bounding schemes reveals the promise of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 14:53:07 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Gogate", "Vibhav", ""], ["Bidyuk", "Bozhena", ""], ["Dechter", "Rina", ""]]}, {"id": "1206.5244", "submitter": "Lucie Galand", "authors": "Lucie Galand, Patrice Perny", "title": "Search for Choquet-optimal paths under uncertainty", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-125-132", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Choquet expected utility (CEU) is one of the most sophisticated decision\ncriteria used in decision theory under uncertainty. It provides a\ngeneralisation of expected utility enhancing both descriptive and prescriptive\npossibilities. In this paper, we investigate the use of CEU for path-planning\nunder uncertainty with a special focus on robust solutions. We first recall the\nmain features of the CEU model and introduce some examples showing its\ndescriptive potential. Then we focus on the search for Choquet-optimal paths in\nmultivalued implicit graphs where costs depend on different scenarios. After\ndiscussing complexity issues, we propose two different heuristic search\nalgorithms to solve the problem. Finally, numerical experiments are reported,\nshowing the practical efficiency of the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 14:53:49 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Galand", "Lucie", ""], ["Perny", "Patrice", ""]]}, {"id": "1206.5245", "submitter": "Ad Feelders", "authors": "Ad Feelders", "title": "A new parameter Learning Method for Bayesian Networks with Qualitative\n  Influences", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-117-124", "categories": "cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for parameter learning in Bayesian networks with\nqualitative influences. This method extends our previous work from networks of\nbinary variables to networks of discrete variables with ordered values. The\nspecified qualitative influences correspond to certain order restrictions on\nthe parameters in the network. These parameters may therefore be estimated\nusing constrained maximum likelihood estimation. We propose an alternative\nmethod, based on the isotonic regression. The constrained maximum likelihood\nestimates are fairly complicated to compute, whereas computation of the\nisotonic regression estimates only requires the repeated application of the\nPool Adjacent Violators algorithm for linear orders. Therefore, the isotonic\nregression estimator is to be preferred from the viewpoint of computational\ncomplexity. Through experiments on simulated and real data, we show that the\nnew learning method is competitive in performance to the constrained maximum\nlikelihood estimator, and that both estimators improve on the standard\nestimator.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 14:54:06 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Feelders", "Ad", ""]]}, {"id": "1206.5246", "submitter": "Michael Eichler", "authors": "Michael Eichler, Vanessa Didelez", "title": "Causal Reasoning in Graphical Time Series Models", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-109-116", "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a definition of causality for time series in terms of the effect\nof an intervention in one component of a multivariate time series on another\ncomponent at some later point in time. Conditions for identifiability,\ncomparable to the back-door and front-door criteria, are presented and can also\nbe verified graphically. Computation of the causal effect is derived and\nillustrated for the linear case.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 14:54:25 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Eichler", "Michael", ""], ["Didelez", "Vanessa", ""]]}, {"id": "1206.5249", "submitter": "Ashwin Deshpande", "authors": "Ashwin Deshpande, Brian Milch, Luke S. Zettlemoyer, Leslie Pack\n  Kaelbling", "title": "Learning Probabilistic Relational Dynamics for Multiple Tasks", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-83-92", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ways in which an agent's actions affect the world can often be modeled\ncompactly using a set of relational probabilistic planning rules. This paper\naddresses the problem of learning such rule sets for multiple related tasks. We\ntake a hierarchical Bayesian approach, in which the system learns a prior\ndistribution over rule sets. We present a class of prior distributions\nparameterized by a rule set prototype that is stochastically modified to\nproduce a task-specific rule set. We also describe a coordinate ascent\nalgorithm that iteratively optimizes the task-specific rule sets and the prior\ndistribution. Experiments using this algorithm show that transferring\ninformation from related tasks significantly reduces the amount of training\ndata required to predict action effects in blocks-world domains.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 14:55:37 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Deshpande", "Ashwin", ""], ["Milch", "Brian", ""], ["Zettlemoyer", "Luke S.", ""], ["Kaelbling", "Leslie Pack", ""]]}, {"id": "1206.5250", "submitter": "Ethan W. Dereszynski", "authors": "Ethan W. Dereszynski, Thomas G. Dietterich", "title": "Probabilistic Models for Anomaly Detection in Remote Sensor Data Streams", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-75-82", "categories": "cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remote sensors are becoming the standard for observing and recording\necological data in the field. Such sensors can record data at fine temporal\nresolutions, and they can operate under extreme conditions prohibitive to human\naccess. Unfortunately, sensor data streams exhibit many kinds of errors ranging\nfrom corrupt communications to partial or total sensor failures. This means\nthat the raw data stream must be cleaned before it can be used by domain\nscientists. In our application environment|the H.J. Andrews Experimental\nForest|this data cleaning is performed manually. This paper introduces a\nDynamic Bayesian Network model for analyzing sensor observations and\ndistinguishing sensor failures from valid data for the case of air temperature\nmeasured at 15 minute time resolution. The model combines an accurate\ndistribution of long-term and short-term temperature variations with a single\ngeneralized fault model. Experiments with historical data show that the\nprecision and recall of the method is comparable to that of the domain expert.\nThe system is currently being deployed to perform real-time automated data\ncleaning.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 14:56:02 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Dereszynski", "Ethan W.", ""], ["Dietterich", "Thomas G.", ""]]}, {"id": "1206.5251", "submitter": "Arthur Choi", "authors": "Arthur Choi, Mark Chavira, Adnan Darwiche", "title": "Node Splitting: A Scheme for Generating Upper Bounds in Bayesian\n  Networks", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-57-66", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate in this paper the mini-bucket algorithm for approximate\ninference in terms of exact inference on an approximate model produced by\nsplitting nodes in a Bayesian network. The new formulation leads to a number of\ntheoretical and practical implications. First, we show that branchand- bound\nsearch algorithms that use minibucket bounds may operate in a drastically\nreduced search space. Second, we show that the proposed formulation inspires\nnew minibucket heuristics and allows us to analyze existing heuristics from a\nnew perspective. Finally, we show that this new formulation allows mini-bucket\napproximations to benefit from recent advances in exact inference, allowing one\nto significantly increase the reach of these approximations.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 14:56:19 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Choi", "Arthur", ""], ["Chavira", "Mark", ""], ["Darwiche", "Adnan", ""]]}, {"id": "1206.5253", "submitter": "Allen Chang", "authors": "Allen Chang, Eyal Amir", "title": "Reachability Under Uncertainty", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-41-48", "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a new network reachability problem where the goal\nis to find the most reliable path between two nodes in a network, represented\nas a directed acyclic graph. Individual edges within this network may fail\naccording to certain probabilities, and these failure probabilities may depend\non the values of one or more hidden variables. This problem may be viewed as a\ngeneralization of shortest-path problems for finding minimum cost paths or\nViterbi-type problems for finding highest-probability sequences of states,\nwhere the addition of the hidden variables introduces correlations that are not\nhandled by previous algorithms. We give theoretical results characterizing this\nproblem including an NP-hardness proof. We also give an exact algorithm and a\nmore efficient approximation algorithm for this problem.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 14:57:25 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Chang", "Allen", ""], ["Amir", "Eyal", ""]]}, {"id": "1206.5255", "submitter": "Darius Braziunas", "authors": "Darius Braziunas, Craig Boutilier", "title": "Minimax regret based elicitation of generalized additive utilities", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-25-32", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the semantic foundations for elicitation of generalized\nadditively independent (GAI) utilities using the minimax regret criterion, and\npropose several new query types and strategies for this purpose. Computational\nfeasibility is obtained by exploiting the local GAI structure in the model. Our\nresults provide a practical approach for implementing preference-based\nconstrained configuration optimization as well as effective search in\nmultiattribute product databases.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 14:57:59 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Braziunas", "Darius", ""], ["Boutilier", "Craig", ""]]}, {"id": "1206.5257", "submitter": "Debarun Bhattacharjya", "authors": "Debarun Bhattacharjya, Ross D. Shachter", "title": "Evaluating influence diagrams with decision circuits", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-9-16", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although a number of related algorithms have been developed to evaluate\ninfluence diagrams, exploiting the conditional independence in the diagram, the\nexact solution has remained intractable for many important problems. In this\npaper we introduce decision circuits as a means to exploit the local structure\nusually found in decision problems and to improve the performance of influence\ndiagram analysis. This work builds on the probabilistic inference algorithms\nusing arithmetic circuits to represent Bayesian belief networks [Darwiche,\n2003]. Once compiled, these arithmetic circuits efficiently evaluate\nprobabilistic queries on the belief network, and methods have been developed to\nexploit both the global and local structure of the network. We show that\ndecision circuits can be constructed in a similar fashion and promise similar\nbenefits.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 14:59:08 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Bhattacharjya", "Debarun", ""], ["Shachter", "Ross D.", ""]]}, {"id": "1206.5258", "submitter": "Christopher Amato", "authors": "Christopher Amato, Daniel S Bernstein, Shlomo Zilberstein", "title": "Optimizing Memory-Bounded Controllers for Decentralized POMDPs", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-1-8", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a memory-bounded optimization approach for solving\ninfinite-horizon decentralized POMDPs. Policies for each agent are represented\nby stochastic finite state controllers. We formulate the problem of optimizing\nthese policies as a nonlinear program, leveraging powerful existing nonlinear\noptimization techniques for solving the problem. While existing solvers only\nguarantee locally optimal solutions, we show that our formulation produces\nhigher quality controllers than the state-of-the-art approach. We also\nincorporate a shared source of randomness in the form of a correlation device\nto further increase solution quality with only a limited increase in space and\ntime. Our experimental results show that nonlinear optimization can be used to\nprovide high quality, concise solutions to decentralized decision problems\nunder uncertainty.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 14:59:30 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Amato", "Christopher", ""], ["Bernstein", "Daniel S", ""], ["Zilberstein", "Shlomo", ""]]}, {"id": "1206.5260", "submitter": "Suchi Saria", "authors": "Suchi Saria, Uri Nodelman, Daphne Koller", "title": "Reasoning at the Right Time Granularity", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-326-334", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most real-world dynamic systems are composed of different components that\noften evolve at very different rates. In traditional temporal graphical models,\nsuch as dynamic Bayesian networks, time is modeled at a fixed granularity,\ngenerally selected based on the rate at which the fastest component evolves.\nInference must then be performed at this fastest granularity, potentially at\nsignificant computational cost. Continuous Time Bayesian Networks (CTBNs) avoid\ntime-slicing in the representation by modeling the system as evolving\ncontinuously over time. The expectation-propagation (EP) inference algorithm of\nNodelman et al. (2005) can then vary the inference granularity over time, but\nthe granularity is uniform across all parts of the system, and must be selected\nin advance. In this paper, we provide a new EP algorithm that utilizes a\ngeneral cluster graph architecture where clusters contain distributions that\ncan overlap in both space (set of variables) and time. This architecture allows\ndifferent parts of the system to be modeled at very different time\ngranularities, according to their current rate of evolution. We also provide an\ninformation-theoretic criterion for dynamically re-partitioning the clusters\nduring inference to tune the level of approximation to the current rate of\nevolution. This avoids the need to hand-select the appropriate granularity, and\nallows the granularity to adapt as information is transmitted across the\nnetwork. We present experiments demonstrating that this approach can result in\nsignificant computational savings.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:00:31 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Saria", "Suchi", ""], ["Nodelman", "Uri", ""], ["Koller", "Daphne", ""]]}, {"id": "1206.5261", "submitter": "David S. Rosenberg", "authors": "David S. Rosenberg, Dan Klein, Ben Taskar", "title": "Mixture-of-Parents Maximum Entropy Markov Models", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-318-325", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the mixture-of-parents maximum entropy Markov model (MoP-MEMM), a\nclass of directed graphical models extending MEMMs. The MoP-MEMM allows\ntractable incorporation of long-range dependencies between nodes by restricting\nthe conditional distribution of each node to be a mixture of distributions\ngiven the parents. We show how to efficiently compute the exact marginal\nposterior node distributions, regardless of the range of the dependencies. This\nenables us to model non-sequential correlations present within text documents,\nas well as between interconnected documents, such as hyperlinked web pages. We\napply the MoP-MEMM to a named entity recognition task and a web page\nclassification task. In each, our model shows significant improvement over the\nbasic MEMM, and is competitive with other long-range sequence models that use\napproximate inference.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:00:46 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Rosenberg", "David S.", ""], ["Klein", "Dan", ""], ["Taskar", "Ben", ""]]}, {"id": "1206.5263", "submitter": "Jose M. Pena", "authors": "Jose M. Pena", "title": "Reading Dependencies from Polytree-Like Bayesian Networks", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-303-309", "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a graphical criterion for reading dependencies from the minimal\ndirected independence map G of a graphoid p when G is a polytree and p\nsatisfies composition and weak transitivity. We prove that the criterion is\nsound and complete. We argue that assuming composition and weak transitivity is\nnot too restrictive.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:01:43 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Pena", "Jose M.", ""]]}, {"id": "1206.5265", "submitter": "Marina Meila", "authors": "Marina Meila, Kapil Phadnis, Arthur Patterson, Jeff A. Bilmes", "title": "Consensus ranking under the exponential model", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-285-294", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the generalized Mallows model, a popular exponential model over\nrankings. Estimating the central (or consensus) ranking from data is NP-hard.\nWe obtain the following new results: (1) We show that search methods can\nestimate both the central ranking pi0 and the model parameters theta exactly.\nThe search is n! in the worst case, but is tractable when the true distribution\nis concentrated around its mode; (2) We show that the generalized Mallows model\nis jointly exponential in (pi0; theta), and introduce the conjugate prior for\nthis model class; (3) The sufficient statistics are the pairwise marginal\nprobabilities that item i is preferred to item j. Preliminary experiments\nconfirm the theoretical predictions and compare the new algorithm and existing\nheuristics.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:02:29 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Meila", "Marina", ""], ["Phadnis", "Kapil", ""], ["Patterson", "Arthur", ""], ["Bilmes", "Jeff A.", ""]]}, {"id": "1206.5266", "submitter": "Robert Mateescu", "authors": "Robert Mateescu, Rina Dechter", "title": "AND/OR Multi-Valued Decision Diagrams (AOMDDs) for Weighted Graphical\n  Models", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-276-284", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compiling graphical models has recently been under intense investigation,\nespecially for probabilistic modeling and processing. We present here a novel\ndata structure for compiling weighted graphical models (in particular,\nprobabilistic models), called AND/OR Multi-Valued Decision Diagram (AOMDD).\nThis is a generalization of our previous work on constraint networks, to\nweighted models. The AOMDD is based on the frameworks of AND/OR search spaces\nfor graphical models, and Ordered Binary Decision Diagrams (OBDD). The AOMDD is\na canonical representation of a graphical model, and its size and compilation\ntime are bounded exponentially by the treewidth of the graph, rather than\npathwidth as is known for OBDDs. We discuss a Variable Elimination schedule for\ncompilation, and present the general APPLY algorithm that combines two weighted\nAOMDDs, and also present a search based method for compilation method. The\npreliminary experimental evaluation is quite encouraging, showing the potential\nof the AOMDD data structure.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:02:53 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Mateescu", "Robert", ""], ["Dechter", "Rina", ""]]}, {"id": "1206.5268", "submitter": "Radu Marinescu", "authors": "Radu Marinescu, Rina Dechter", "title": "Best-First AND/OR Search for Most Probable Explanations", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-259-266", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper evaluates the power of best-first search over AND/OR search spaces\nfor solving the Most Probable Explanation (MPE) task in Bayesian networks. The\nmain virtue of the AND/OR representation of the search space is its sensitivity\nto the structure of the problem, which can translate into significant time\nsavings. In recent years depth-first AND/OR Branch-and- Bound algorithms were\nshown to be very effective when exploring such search spaces, especially when\nusing caching. Since best-first strategies are known to be superior to\ndepth-first when memory is utilized, exploring the best-first control strategy\nis called for. The main contribution of this paper is in showing that a recent\nextension of AND/OR search algorithms from depth-first Branch-and-Bound to\nbest-first is indeed very effective for computing the MPE in Bayesian networks.\nWe demonstrate empirically the superiority of the best-first search approach on\nvarious probabilistic networks.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:04:10 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Marinescu", "Radu", ""], ["Dechter", "Rina", ""]]}, {"id": "1206.5271", "submitter": "Eric Lantz", "authors": "Eric Lantz, Soumya Ray, David Page", "title": "Learning Bayesian Network Structure from Correlation-Immune Data", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-235-242", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Searching the complete space of possible Bayesian networks is intractable for\nproblems of interesting size, so Bayesian network structure learning\nalgorithms, such as the commonly used Sparse Candidate algorithm, employ\nheuristics. However, these heuristics also restrict the types of relationships\nthat can be learned exclusively from data. They are unable to learn\nrelationships that exhibit \"correlation-immunity\", such as parity. To learn\nBayesian networks in the presence of correlation-immune relationships, we\nextend the Sparse Candidate algorithm with a technique called \"skewing\". This\ntechnique uses the observation that relationships that are correlation-immune\nunder a specific input distribution may not be correlation-immune under\nanother, sufficiently different distribution. We show that by extending Sparse\nCandidate with this technique we are able to discover relationships between\nrandom variables that are approximately correlation-immune, with a\nsignificantly lower computational cost than the alternative of considering\nmultiple parents of a node at a time.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:05:10 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Lantz", "Eric", ""], ["Ray", "Soumya", ""], ["Page", "David", ""]]}, {"id": "1206.5272", "submitter": "Manabu Kuroki", "authors": "Manabu Kuroki, Zhihong Cai", "title": "Evaluation of the Causal Effect of Control Plans in Nonrecursive\n  Structural Equation Models", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-227-234", "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When observational data is available from practical studies and a directed\ncyclic graph for how various variables affect each other is known based on\nsubstantive understanding of the process, we consider a problem in which a\ncontrol plan of a treatment variable is conducted in order to bring a response\nvariable close to a target value with variation reduction. We formulate an\noptimal control plan concerning a certain treatment variable through path\ncoefficients in the framework of linear nonrecursive structural equation\nmodels. Based on the formulation, we clarify the properties of causal effects\nwhen conducting a control plan. The results enable us to evaluate the effect of\na control plan on the variance from observational data.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:05:31 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Kuroki", "Manabu", ""], ["Cai", "Zhihong", ""]]}, {"id": "1206.5273", "submitter": "Lukas Kroc", "authors": "Lukas Kroc, Ashish Sabharwal, Bart Selman", "title": "Survey Propagation Revisited", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-217-226", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Survey propagation (SP) is an exciting new technique that has been remarkably\nsuccessful at solving very large hard combinatorial problems, such as\ndetermining the satisfiability of Boolean formulas. In a promising attempt at\nunderstanding the success of SP, it was recently shown that SP can be viewed as\na form of belief propagation, computing marginal probabilities over certain\nobjects called covers of a formula. This explanation was, however, shortly\ndismissed by experiments suggesting that non-trivial covers simply do not exist\nfor large formulas. In this paper, we show that these experiments were\nmisleading: not only do covers exist for large hard random formulas, SP is\nsurprisingly accurate at computing marginals over these covers despite the\nexistence of many cycles in the formulas. This re-opens a potentially simpler\nline of reasoning for understanding SP, in contrast to some alternative lines\nof explanation that have been proposed assuming covers do not exist.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:05:48 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Kroc", "Lukas", ""], ["Sabharwal", "Ashish", ""], ["Selman", "Bart", ""]]}, {"id": "1206.5275", "submitter": "Changsung Kang", "authors": "Changsung Kang, Jin Tian", "title": "Polynomial Constraints in Causal Bayesian Networks", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-200-208", "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use the implicitization procedure to generate polynomial equality\nconstraints on the set of distributions induced by local interventions on\nvariables governed by a causal Bayesian network with hidden variables. We show\nhow we may reduce the complexity of the implicitization problem and make the\nproblem tractable in certain causal Bayesian networks. We also show some\npreliminary results on the algebraic structure of polynomial constraints. The\nresults have applications in distinguishing between causal models and in\ntesting causal models with combined observational and experimental data.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:06:26 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Kang", "Changsung", ""], ["Tian", "Jin", ""]]}, {"id": "1206.5276", "submitter": "Ariel Jaimovich", "authors": "Ariel Jaimovich, Ofer Meshi, Nir Friedman", "title": "Template Based Inference in Symmetric Relational Markov Random Fields", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-191-199", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational Markov Random Fields are a general and flexible framework for\nreasoning about the joint distribution over attributes of a large number of\ninteracting entities. The main computational difficulty in learning such models\nis inference. Even when dealing with complete data, where one can summarize a\nlarge domain by sufficient statistics, learning requires one to compute the\nexpectation of the sufficient statistics given different parameter choices. The\ntypical solution to this problem is to resort to approximate inference\nprocedures, such as loopy belief propagation. Although these procedures are\nquite efficient, they still require computation that is on the order of the\nnumber of interactions (or features) in the model. When learning a large\nrelational model over a complex domain, even such approximations require\nunrealistic running time. In this paper we show that for a particular class of\nrelational MRFs, which have inherent symmetry, we can perform the inference\nneeded for learning procedures using a template-level belief propagation. This\nprocedure's running time is proportional to the size of the relational model\nrather than the size of the domain. Moreover, we show that this computational\nprocedure is equivalent to sychronous loopy belief propagation. This enables a\ndramatic speedup in inference and learning time. We use this procedure to learn\nrelational MRFs for capturing the joint distribution of large protein-protein\ninteraction networks.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:06:55 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Jaimovich", "Ariel", ""], ["Meshi", "Ofer", ""], ["Friedman", "Nir", ""]]}, {"id": "1206.5277", "submitter": "Alexander T. Ihler", "authors": "Alexander T. Ihler", "title": "Accuracy Bounds for Belief Propagation", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-183-190", "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The belief propagation (BP) algorithm is widely applied to perform\napproximate inference on arbitrary graphical models, in part due to its\nexcellent empirical properties and performance. However, little is known\ntheoretically about when this algorithm will perform well. Using recent\nanalysis of convergence and stability properties in BP and new results on\napproximations in binary systems, we derive a bound on the error in BP's\nestimates for pairwise Markov random fields over discrete valued random\nvariables. Our bound is relatively simple to compute, and compares favorably\nwith a previous method of bounding the accuracy of BP.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:07:42 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Ihler", "Alexander T.", ""]]}, {"id": "1206.5279", "submitter": "Moises Goldszmidt", "authors": "Moises Goldszmidt", "title": "Making life better one large system at a time: Challenges for UAI\n  research", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-475-481", "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth and diversity in service offerings and the ensuing\ncomplexity of information technology ecosystems present numerous management\nchallenges (both operational and strategic). Instrumentation and measurement\ntechnology is, by and large, keeping pace with this development and growth.\nHowever, the algorithms, tools, and technology required to transform the data\ninto relevant information for decision making are not. The claim in this paper\n(and the invited talk) is that the line of research conducted in Uncertainty in\nArtificial Intelligence is very well suited to address the challenges and close\nthis gap. I will support this claim and discuss open problems using recent\nexamples in diagnosis, model discovery, and policy optimization on three real\nlife distributed systems.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:09:50 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Goldszmidt", "Moises", ""]]}, {"id": "1206.5280", "submitter": "Or Zuk", "authors": "Or Zuk, Liat Ein-Dor, Eytan Domany", "title": "Ranking Under Uncertainty", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-466-473", "categories": "cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ranking objects is a simple and natural procedure for organizing data. It is\noften performed by assigning a quality score to each object according to its\nrelevance to the problem at hand. Ranking is widely used for object selection,\nwhen resources are limited and it is necessary to select a subset of most\nrelevant objects for further processing. In real world situations, the object's\nscores are often calculated from noisy measurements, casting doubt on the\nranking reliability. We introduce an analytical method for assessing the\ninfluence of noise levels on the ranking reliability. We use two similarity\nmeasures for reliability evaluation, Top-K-List overlap and Kendall's tau\nmeasure, and show that the former is much more sensitive to noise than the\nlatter. We apply our method to gene selection in a series of microarray\nexperiments of several cancer types. The results indicate that the reliability\nof the lists obtained from these experiments is very poor, and that experiment\nsizes which are necessary for attaining reasonably stable Top-K-Lists are much\nlarger than those currently available. Simulations support our analytical\nresults.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:10:59 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Zuk", "Or", ""], ["Ein-Dor", "Liat", ""], ["Domany", "Eytan", ""]]}, {"id": "1206.5284", "submitter": "Fusun Yaman", "authors": "Fusun Yaman, Marie desJardins", "title": "More-or-Less CP-Networks", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-434-441", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preferences play an important role in our everyday lives. CP-networks, or\nCP-nets in short, are graphical models for representing conditional qualitative\npreferences under ceteris paribus (\"all else being equal\") assumptions. Despite\ntheir intuitive nature and rich representation, dominance testing with CP-nets\nis computationally complex, even when the CP-nets are restricted to\nbinary-valued preferences. Tractable algorithms exist for binary CP-nets, but\nthese algorithms are incomplete for multi-valued CPnets. In this paper, we\nidentify a class of multivalued CP-nets, which we call more-or-less CPnets,\nthat have the same computational complexity as binary CP-nets. More-or-less\nCP-nets exploit the monotonicity of the attribute values and use intervals to\naggregate values that induce similar preferences. We then present a search\ncontrol rule for dominance testing that effectively prunes the search space\nwhile preserving completeness.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:15:21 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Yaman", "Fusun", ""], ["desJardins", "Marie", ""]]}, {"id": "1206.5285", "submitter": "Ydo Wexler", "authors": "Ydo Wexler, Dan Geiger", "title": "Importance Sampling via Variational Optimization", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-426-433", "categories": "stat.CO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing the exact likelihood of data in large Bayesian networks consisting\nof thousands of vertices is often a difficult task. When these models contain\nmany deterministic conditional probability tables and when the observed values\nare extremely unlikely even alternative algorithms such as variational methods\nand stochastic sampling often perform poorly. We present a new importance\nsampling algorithm for Bayesian networks which is based on variational\ntechniques. We use the updates of the importance function to predict whether\nthe stochastic sampling converged above or below the true likelihood, and\nchange the proposal distribution accordingly. The validity of the method and\nits contribution to convergence is demonstrated on hard networks of large\ngenetic linkage analysis tasks.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:15:41 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Wexler", "Ydo", ""], ["Geiger", "Dan", ""]]}, {"id": "1206.5286", "submitter": "Yair Weiss", "authors": "Yair Weiss, Chen Yanover, Talya Meltzer", "title": "MAP Estimation, Linear Programming and Belief Propagation with Convex\n  Free Energies", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-416-425", "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the most probable assignment (MAP) in a general graphical model is\nknown to be NP hard but good approximations have been attained with max-product\nbelief propagation (BP) and its variants. In particular, it is known that using\nBP on a single-cycle graph or tree reweighted BP on an arbitrary graph will\ngive the MAP solution if the beliefs have no ties. In this paper we extend the\nsetting under which BP can be used to provably extract the MAP. We define\nConvex BP as BP algorithms based on a convex free energy approximation and show\nthat this class includes ordinary BP with single-cycle, tree reweighted BP and\nmany other BP variants. We show that when there are no ties, fixed-points of\nconvex max-product BP will provably give the MAP solution. We also show that\nconvex sum-product BP at sufficiently small temperatures can be used to solve\nlinear programs that arise from relaxing the MAP problem. Finally, we derive a\nnovel condition that allows us to derive the MAP solution even if some of the\nconvex BP beliefs have ties. In experiments, we show that our theorems allow us\nto find the MAP in many real-world instances of graphical models where exact\ninference using junction-tree is impossible.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:16:08 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Weiss", "Yair", ""], ["Yanover", "Chen", ""], ["Meltzer", "Talya", ""]]}, {"id": "1206.5287", "submitter": "Chenggang Wang", "authors": "Chenggang Wang, Roni Khardon", "title": "Policy Iteration for Relational MDPs", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-408-415", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational Markov Decision Processes are a useful abstraction for complex\nreinforcement learning problems and stochastic planning problems. Recent work\ndeveloped representation schemes and algorithms for planning in such problems\nusing the value iteration algorithm. However, exact versions of more complex\nalgorithms, including policy iteration, have not been developed or analyzed.\nThe paper investigates this potential and makes several contributions. First we\nobserve two anomalies for relational representations showing that the value of\nsome policies is not well defined or cannot be calculated for restricted\nrepresentation schemes used in the literature. On the other hand, we develop a\nvariant of policy iteration that can get around these anomalies. The algorithm\nincludes an aspect of policy improvement in the process of policy evaluation\nand thus differs from the original algorithm. We show that despite this\ndifference the algorithm converges to the optimal policy.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:16:29 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Wang", "Chenggang", ""], ["Khardon", "Roni", ""]]}, {"id": "1206.5288", "submitter": "Yevgeniy Vorobeychik", "authors": "Yevgeniy Vorobeychik, Daniel Reeves, Michael P. Wellman", "title": "Constrained Automated Mechanism Design for Infinite Games of Incomplete\n  Information", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-400-407", "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a functional framework for automated mechanism design based on a\ntwo-stage game model of strategic interaction between the designer and the\nmechanism participants, and apply it to several classes of two-player infinite\ngames of incomplete information. At the core of our framework is a black-box\noptimization algorithm which guides the selection process of candidate\nmechanisms. Our approach yields optimal or nearly optimal mechanisms in several\napplication domains using various objective functions. By comparing our results\nwith known optimal mechanisms, and in some cases improving on the best known\nmechanisms, we provide evidence that ours is a promising approach to parametric\ndesign of indirect mechanisms.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:16:48 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Vorobeychik", "Yevgeniy", ""], ["Reeves", "Daniel", ""], ["Wellman", "Michael P.", ""]]}, {"id": "1206.5289", "submitter": "Jin Tian", "authors": "Jin Tian", "title": "A Criterion for Parameter Identification in Structural Equation Models", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-392-399", "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the problem of identifying direct causal effects in\nrecursive linear structural equation models. The paper establishes a sufficient\ncriterion for identifying individual causal effects and provides a procedure\ncomputing identified causal effects in terms of observed covariance matrix.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:17:07 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Tian", "Jin", ""]]}, {"id": "1206.5290", "submitter": "Umar Syed", "authors": "Umar Syed, Robert E. Schapire", "title": "Imitation Learning with a Value-Based Prior", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-384-391", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of imitation learning is for an apprentice to learn how to behave in\na stochastic environment by observing a mentor demonstrating the correct\nbehavior. Accurate prior knowledge about the correct behavior can reduce the\nneed for demonstrations from the mentor. We present a novel approach to\nencoding prior knowledge about the correct behavior, where we assume that this\nprior knowledge takes the form of a Markov Decision Process (MDP) that is used\nby the apprentice as a rough and imperfect model of the mentor's behavior.\nSpecifically, taking a Bayesian approach, we treat the value of a policy in\nthis modeling MDP as the log prior probability of the policy. In other words,\nwe assume a priori that the mentor's behavior is likely to be a high value\npolicy in the modeling MDP, though quite possibly different from the optimal\npolicy. We describe an efficient algorithm that, given a modeling MDP and a set\nof demonstrations by a mentor, provably converges to a stationary point of the\nlog posterior of the mentor's policy, where the posterior is computed with\nrespect to the \"value based\" prior. We also present empirical evidence that\nthis prior does in fact speed learning of the mentor's policy, and is an\nimprovement in our experiments over similar previous methods.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:18:02 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Syed", "Umar", ""], ["Schapire", "Robert E.", ""]]}, {"id": "1206.5291", "submitter": "Charles Sutton", "authors": "Charles Sutton, Andrew McCallum", "title": "Improved Dynamic Schedules for Belief Propagation", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-376-383", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Belief propagation and its variants are popular methods for approximate\ninference, but their running time and even their convergence depend greatly on\nthe schedule used to send the messages. Recently, dynamic update schedules have\nbeen shown to converge much faster on hard networks than static schedules,\nnamely the residual BP schedule of Elidan et al. [2006]. But that RBP algorithm\nwastes message updates: many messages are computed solely to determine their\npriority, and are never actually performed. In this paper, we show that\nestimating the residual, rather than calculating it directly, leads to\nsignificant decreases in the number of messages required for convergence, and\nin the total running time. The residual is estimated using an upper bound based\non recent work on message errors in BP. On both synthetic and real-world\nnetworks, this dramatically decreases the running time of BP, in some cases by\na factor of five, without affecting the quality of the solution.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:18:24 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Sutton", "Charles", ""], ["McCallum", "Andrew", ""]]}, {"id": "1206.5292", "submitter": "Parag Singla", "authors": "Parag Singla, Pedro Domingos", "title": "Markov Logic in Infinite Domains", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-368-375", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining first-order logic and probability has long been a goal of AI.\nMarkov logic (Richardson & Domingos, 2006) accomplishes this by attaching\nweights to first-order formulas and viewing them as templates for features of\nMarkov networks. Unfortunately, it does not have the full power of first-order\nlogic, because it is only defined for finite domains. This paper extends Markov\nlogic to infinite domains, by casting it in the framework of Gibbs measures\n(Georgii, 1988). We show that a Markov logic network (MLN) admits a Gibbs\nmeasure as long as each ground atom has a finite number of neighbors. Many\ninteresting cases fall in this category. We also show that an MLN admits a\nunique measure if the weights of its non-unit clauses are small enough. We then\nexamine the structure of the set of consistent measures in the non-unique case.\nMany important phenomena, including systems with phase transitions, are\nrepresented by MLNs with non-unique measures. We relate the problem of\nsatisfiability in first-order logic to the properties of MLN measures, and\ndiscuss how Markov logic relates to previous infinite models.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:18:47 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Singla", "Parag", ""], ["Domingos", "Pedro", ""]]}, {"id": "1206.5294", "submitter": "Ilya Shpitser", "authors": "Ilya Shpitser, Judea Pearl", "title": "What Counterfactuals Can Be Tested", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-352-359", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual statements, e.g., \"my headache would be gone had I taken an\naspirin\" are central to scientific discourse, and are formally interpreted as\nstatements derived from \"alternative worlds\". However, since they invoke\nhypothetical states of affairs, often incompatible with what is actually known\nor observed, testing counterfactuals is fraught with conceptual and practical\ndifficulties. In this paper, we provide a complete characterization of\n\"testable counterfactuals,\" namely, counterfactual statements whose\nprobabilities can be inferred from physical experiments. We provide complete\nprocedures for discerning whether a given counterfactual is testable and, if\nso, expressing its probability in terms of experimental data.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:19:30 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Shpitser", "Ilya", ""], ["Pearl", "Judea", ""]]}, {"id": "1206.5295", "submitter": "Sven Seuken", "authors": "Sven Seuken, Shlomo Zilberstein", "title": "Improved Memory-Bounded Dynamic Programming for Decentralized POMDPs", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-344-351", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory-Bounded Dynamic Programming (MBDP) has proved extremely effective in\nsolving decentralized POMDPs with large horizons. We generalize the algorithm\nand improve its scalability by reducing the complexity with respect to the\nnumber of observations from exponential to polynomial. We derive error bounds\non solution quality with respect to this new approximation and analyze the\nconvergence behavior. To evaluate the effectiveness of the improvements, we\nintroduce a new, larger benchmark problem. Experimental results show that\ndespite the high complexity of decentralized POMDPs, scalable solution\ntechniques such as MBDP perform surprisingly well.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:19:47 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Seuken", "Sven", ""], ["Zilberstein", "Shlomo", ""]]}, {"id": "1206.5360", "submitter": "Sudarshan Nandy", "authors": "Sudarshan Nandy, Partha Pratim Sarkar and Achintya Das", "title": "Analysis of a Nature Inspired Firefly Algorithm based Back-propagation\n  Neural Network Training", "comments": "9 pages, 10 figures, Published with International Journal of Computer\n  Applications (IJCA)", "journal-ref": "International Journal of Computer Applications 43(22):8-16, April\n  2012. Published by Foundation of Computer Science, New York, USA", "doi": "10.5120/6401-8339", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization algorithms are normally influenced by meta-heuristic approach.\nIn recent years several hybrid methods for optimization are developed to find\nout a better solution. The proposed work using meta-heuristic Nature Inspired\nalgorithm is applied with back-propagation method to train a feed-forward\nneural network. Firefly algorithm is a nature inspired meta-heuristic\nalgorithm, and it is incorporated into back-propagation algorithm to achieve\nfast and improved convergence rate in training feed-forward neural network. The\nproposed technique is tested over some standard data set. It is found that\nproposed method produces an improved convergence within very few iteration.\nThis performance is also analyzed and compared to genetic algorithm based\nback-propagation. It is observed that proposed method consumes less time to\nconverge and providing improved convergence rate with minimum feed-forward\nneural network design.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jun 2012 05:37:37 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Nandy", "Sudarshan", ""], ["Sarkar", "Partha Pratim", ""], ["Das", "Achintya", ""]]}, {"id": "1206.5384", "submitter": "Tarek El-Shishtawy Ahmed", "authors": "Tarek El-Shishtawy and Fatma El-Ghannam", "title": "Keyphrase Based Arabic Summarizer (KPAS)", "comments": "INFOS 2012, The 8th INFOS2012 International Conference on Informatics\n  and Systems, 14-16 May, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a computationally inexpensive and efficient generic\nsummarization algorithm for Arabic texts. The algorithm belongs to extractive\nsummarization family, which reduces the problem into representative sentences\nidentification and extraction sub-problems. Important keyphrases of the\ndocument to be summarized are identified employing combinations of statistical\nand linguistic features. The sentence extraction algorithm exploits keyphrases\nas the primary attributes to rank a sentence. The present experimental work,\ndemonstrates different techniques for achieving various summarization goals\nincluding: informative richness, coverage of both main and auxiliary topics,\nand keeping redundancy to a minimum. A scoring scheme is then adopted that\nbalances between these summarization goals. To evaluate the resulted Arabic\nsummaries with well-established systems, aligned English/Arabic texts are used\nthrough the experiments.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jun 2012 12:19:38 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["El-Shishtawy", "Tarek", ""], ["El-Ghannam", "Fatma", ""]]}, {"id": "1206.5396", "submitter": "Mathias Niepert", "authors": "Mathias Niepert", "title": "Markov Chains on Orbits of Permutation Groups", "comments": "To appear in Proceedings of UAI2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.CO stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach to detecting and utilizing symmetries in\nprobabilistic graphical models with two main contributions. First, we present a\nscalable approach to computing generating sets of permutation groups\nrepresenting the symmetries of graphical models. Second, we introduce orbital\nMarkov chains, a novel family of Markov chains leveraging model symmetries to\nreduce mixing times. We establish an insightful connection between model\nsymmetries and rapid mixing of orbital Markov chains. Thus, we present the\nfirst lifted MCMC algorithm for probabilistic graphical models. Both analytical\nand empirical results demonstrate the effectiveness and efficiency of the\napproach.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jun 2012 14:27:39 GMT"}, {"version": "v2", "created": "Thu, 28 Jun 2012 14:54:39 GMT"}], "update_date": "2012-06-29", "authors_parsed": [["Niepert", "Mathias", ""]]}, {"id": "1206.5698", "submitter": "Jesse Hoey", "authors": "Marek Grzes and Jesse Hoey and Shehroz Khan and Alex Mihailidis and\n  Stephen Czarnuch and Dan Jackson and Andrew Monk", "title": "Relational Approach to Knowledge Engineering for POMDP-based Assistance\n  Systems as a Translation of a Psychological Model", "comments": null, "journal-ref": null, "doi": "10.1016/j.ijar.2013.03.006", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assistive systems for persons with cognitive disabilities (e.g. dementia) are\ndifficult to build due to the wide range of different approaches people can\ntake to accomplishing the same task, and the significant uncertainties that\narise from both the unpredictability of client's behaviours and from noise in\nsensor readings. Partially observable Markov decision process (POMDP) models\nhave been used successfully as the reasoning engine behind such assistive\nsystems for small multi-step tasks such as hand washing. POMDP models are a\npowerful, yet flexible framework for modelling assistance that can deal with\nuncertainty and utility. Unfortunately, POMDPs usually require a very labour\nintensive, manual procedure for their definition and construction. Our previous\nwork has described a knowledge driven method for automatically generating POMDP\nactivity recognition and context sensitive prompting systems for complex tasks.\nWe call the resulting POMDP a SNAP (SyNdetic Assistance Process). The\nspreadsheet-like result of the analysis does not correspond to the POMDP model\ndirectly and the translation to a formal POMDP representation is required. To\ndate, this translation had to be performed manually by a trained POMDP expert.\nIn this paper, we formalise and automate this translation process using a\nprobabilistic relational model (PRM) encoded in a relational database. We\ndemonstrate the method by eliciting three assistance tasks from non-experts. We\nvalidate the resulting POMDP models using case-based simulations to show that\nthey are reasonable for the domains. We also show a complete case study of a\ndesigner specifying one database, including an evaluation in a real-life\nexperiment with a human actor.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2012 14:46:15 GMT"}], "update_date": "2013-06-21", "authors_parsed": [["Grzes", "Marek", ""], ["Hoey", "Jesse", ""], ["Khan", "Shehroz", ""], ["Mihailidis", "Alex", ""], ["Czarnuch", "Stephen", ""], ["Jackson", "Dan", ""], ["Monk", "Andrew", ""]]}, {"id": "1206.5754", "submitter": "Aki Vehtari", "authors": "Jarno Vanhatalo, Jaakko Riihim\\\"aki, Jouni Hartikainen, Pasi\n  Jyl\\\"anki, Ville Tolvanen and Aki Vehtari", "title": "Bayesian Modeling with Gaussian Processes using the GPstuff Toolbox", "comments": "- Updated according to GPstuff 4.6. Added, e.g., Pareto smoothed\n  importance sampling", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GP) are powerful tools for probabilistic modeling\npurposes. They can be used to define prior distributions over latent functions\nin hierarchical Bayesian models. The prior over functions is defined implicitly\nby the mean and covariance function, which determine the smoothness and\nvariability of the function. The inference can then be conducted directly in\nthe function space by evaluating or approximating the posterior process.\nDespite their attractive theoretical properties GPs provide practical\nchallenges in their implementation. GPstuff is a versatile collection of\ncomputational tools for GP models compatible with Linux and Windows MATLAB and\nOctave. It includes, among others, various inference methods, sparse\napproximations and tools for model assessment. In this work, we review these\ntools and demonstrate the use of GPstuff in several models.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2012 18:19:45 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2012 12:44:54 GMT"}, {"version": "v3", "created": "Fri, 22 Mar 2013 08:01:15 GMT"}, {"version": "v4", "created": "Fri, 26 Apr 2013 06:39:27 GMT"}, {"version": "v5", "created": "Tue, 15 Apr 2014 08:53:01 GMT"}, {"version": "v6", "created": "Wed, 15 Jul 2015 13:04:29 GMT"}], "update_date": "2015-07-16", "authors_parsed": [["Vanhatalo", "Jarno", ""], ["Riihim\u00e4ki", "Jaakko", ""], ["Hartikainen", "Jouni", ""], ["Jyl\u00e4nki", "Pasi", ""], ["Tolvanen", "Ville", ""], ["Vehtari", "Aki", ""]]}, {"id": "1206.5833", "submitter": "Guido Governatori", "authors": "Guido Governatori, Francesco Olivieri, Simone Scannapieco and Matteo\n  Cristani", "title": "Revision of Defeasible Logic Preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are several contexts of non-monotonic reasoning where a priority\nbetween rules is established whose purpose is preventing conflicts.\n  One formalism that has been widely employed for non-monotonic reasoning is\nthe sceptical one known as Defeasible Logic. In Defeasible Logic the tool used\nfor conflict resolution is a preference relation between rules, that\nestablishes the priority among them.\n  In this paper we investigate how to modify such a preference relation in a\ndefeasible logic theory in order to change the conclusions of the theory\nitself. We argue that the approach we adopt is applicable to legal reasoning\nwhere users, in general, cannot change facts or rules, but can propose their\npreferences about the relative strength of the rules.\n  We provide a comprehensive study of the possible combinatorial cases and we\nidentify and analyse the cases where the revision process is successful.\n  After this analysis, we identify three revision/update operators and study\nthem against the AGM postulates for belief revision operators, to discover that\nonly a part of these postulates are satisfied by the three operators.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2012 20:46:46 GMT"}, {"version": "v2", "created": "Fri, 23 Nov 2012 11:35:20 GMT"}], "update_date": "2012-11-26", "authors_parsed": [["Governatori", "Guido", ""], ["Olivieri", "Francesco", ""], ["Scannapieco", "Simone", ""], ["Cristani", "Matteo", ""]]}, {"id": "1206.5928", "submitter": "Truong-Huy Nguyen", "authors": "Truong-Huy Dinh Nguyen, David Hsu, Wee-Sun Lee, Tze-Yun Leong, Leslie\n  Pack Kaelbling, Tomas Lozano-Perez, Andrew Haydn Grant", "title": "CAPIR: Collaborative Action Planning with Intention Recognition", "comments": "6 pages, accepted for presentation at AIIDE'11", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply decision theoretic techniques to construct non-player characters\nthat are able to assist a human player in collaborative games. The method is\nbased on solving Markov decision processes, which can be difficult when the\ngame state is described by many variables. To scale to more complex games, the\nmethod allows decomposition of a game task into subtasks, each of which can be\nmodelled by a Markov decision process. Intention recognition is used to infer\nthe subtask that the human is currently performing, allowing the helper to\nassist the human in performing the correct task. Experiments show that the\nmethod can be effective, giving near-human level performance in helping a human\nin a collaborative game.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2012 09:13:53 GMT"}], "update_date": "2012-06-27", "authors_parsed": [["Nguyen", "Truong-Huy Dinh", ""], ["Hsu", "David", ""], ["Lee", "Wee-Sun", ""], ["Leong", "Tze-Yun", ""], ["Kaelbling", "Leslie Pack", ""], ["Lozano-Perez", "Tomas", ""], ["Grant", "Andrew Haydn", ""]]}, {"id": "1206.5940", "submitter": "Truong-Huy Nguyen", "authors": "Truong-Huy Dinh Nguyen, Wee-Sun Lee, and Tze-Yun Leong", "title": "Bootstrapping Monte Carlo Tree Search with an Imperfect Heuristic", "comments": "16 pages, accepted for presentation at ECML'12", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of using a heuristic policy to improve the value\napproximation by the Upper Confidence Bound applied in Trees (UCT) algorithm in\nnon-adversarial settings such as planning with large-state space Markov\nDecision Processes. Current improvements to UCT focus on either changing the\naction selection formula at the internal nodes or the rollout policy at the\nleaf nodes of the search tree. In this work, we propose to add an auxiliary arm\nto each of the internal nodes, and always use the heuristic policy to roll out\nsimulations at the auxiliary arms. The method aims to get fast convergence to\noptimal values at states where the heuristic policy is optimal, while retaining\nsimilar approximation as the original UCT in other states. We show that\nbootstrapping with the proposed method in the new algorithm, UCT-Aux, performs\nbetter compared to the original UCT algorithm and its variants in two benchmark\nexperiment settings. We also examine conditions under which UCT-Aux works well.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2012 09:53:59 GMT"}], "update_date": "2012-06-27", "authors_parsed": [["Nguyen", "Truong-Huy Dinh", ""], ["Lee", "Wee-Sun", ""], ["Leong", "Tze-Yun", ""]]}, {"id": "1206.6080", "submitter": "Erik Schlicht", "authors": "Erik J. Schlicht, Ritchie Lee, David H. Wolpert, Mykel J.\n  Kochenderfer, and Brendan Tracey", "title": "Predicting the behavior of interacting humans by fusing data from\n  multiple sources", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-fidelity methods combine inexpensive low-fidelity simulations with\ncostly but high-fidelity simulations to produce an accurate model of a system\nof interest at minimal cost. They have proven useful in modeling physical\nsystems and have been applied to engineering problems such as wing-design\noptimization. During human-in-the-loop experimentation, it has become\nincreasingly common to use online platforms, like Mechanical Turk, to run\nlow-fidelity experiments to gather human performance data in an efficient\nmanner. One concern with these experiments is that the results obtained from\nthe online environment generalize poorly to the actual domain of interest. To\naddress this limitation, we extend traditional multi-fidelity approaches to\nallow us to combine fewer data points from high-fidelity human-in-the-loop\nexperiments with plentiful but less accurate data from low-fidelity experiments\nto produce accurate models of how humans interact. We present both model-based\nand model-free methods, and summarize the predictive performance of each method\nunder different conditions.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2012 18:44:47 GMT"}], "update_date": "2012-06-27", "authors_parsed": [["Schlicht", "Erik J.", ""], ["Lee", "Ritchie", ""], ["Wolpert", "David H.", ""], ["Kochenderfer", "Mykel J.", ""], ["Tracey", "Brendan", ""]]}, {"id": "1206.6230", "submitter": "Kian Hsiang Low", "authors": "Jie Chen, Kian Hsiang Low, Colin Keng-Yan Tan, Ali Oran, Patrick\n  Jaillet, John M. Dolan and Gaurav S. Sukhatme", "title": "Decentralized Data Fusion and Active Sensing with Mobile Sensors for\n  Modeling and Predicting Spatiotemporal Traffic Phenomena", "comments": "28th Conference on Uncertainty in Artificial Intelligence (UAI 2012),\n  Extended version with proofs, 13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of modeling and predicting spatiotemporal traffic phenomena over\nan urban road network is important to many traffic applications such as\ndetecting and forecasting congestion hotspots. This paper presents a\ndecentralized data fusion and active sensing (D2FAS) algorithm for mobile\nsensors to actively explore the road network to gather and assimilate the most\ninformative data for predicting the traffic phenomenon. We analyze the time and\ncommunication complexity of D2FAS and demonstrate that it can scale well with a\nlarge number of observations and sensors. We provide a theoretical guarantee on\nits predictive performance to be equivalent to that of a sophisticated\ncentralized sparse approximation for the Gaussian process (GP) model: The\ncomputation of such a sparse approximate GP model can thus be parallelized and\ndistributed among the mobile sensors (in a Google-like MapReduce paradigm),\nthereby achieving efficient and scalable prediction. We also theoretically\nguarantee its active sensing performance that improves under various practical\nenvironmental conditions. Empirical evaluation on real-world urban road network\ndata shows that our D2FAS algorithm is significantly more time-efficient and\nscalable than state-of-the-art centralized algorithms while achieving\ncomparable predictive performance.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 11:11:55 GMT"}, {"version": "v2", "created": "Thu, 28 Jun 2012 04:21:18 GMT"}], "update_date": "2012-06-29", "authors_parsed": [["Chen", "Jie", ""], ["Low", "Kian Hsiang", ""], ["Tan", "Colin Keng-Yan", ""], ["Oran", "Ali", ""], ["Jaillet", "Patrick", ""], ["Dolan", "John M.", ""], ["Sukhatme", "Gaurav S.", ""]]}, {"id": "1206.6262", "submitter": "Adam White", "authors": "Adam White, Joseph Modayil, and Richard S. Sutton", "title": "Scaling Life-long Off-policy Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We pursue a life-long learning approach to artificial intelligence that makes\nextensive use of reinforcement learning algorithms. We build on our prior work\nwith general value functions (GVFs) and the Horde architecture. GVFs have been\nshown able to represent a wide variety of facts about the world's dynamics that\nmay be useful to a long-lived agent (Sutton et al. 2011). We have also\npreviously shown scaling - that thousands of on-policy GVFs can be learned\naccurately in real-time on a mobile robot (Modayil, White & Sutton 2011). That\nwork was limited in that it learned about only one policy at a time, whereas\nthe greatest potential benefits of life-long learning come from learning about\nmany policies in parallel, as we explore in this paper. Many new challenges\narise in this off-policy learning setting. To deal with convergence and\nefficiency challenges, we utilize the recently introduced GTD({\\lambda})\nalgorithm. We show that GTD({\\lambda}) with tile coding can simultaneously\nlearn hundreds of predictions for five simple target policies while following a\nsingle random behavior policy, assessing accuracy with interspersed on-policy\ntests. To escape the need for the tests, which preclude further scaling, we\nintroduce and empirically vali- date two online estimators of the off-policy\nobjective (MSPBE). Finally, we use the more efficient of the two estimators to\ndemonstrate off-policy learning at scale - the learning of value functions for\none thousand policies in real time on a physical robot. This ability\nconstitutes a significant step towards scaling life-long off-policy learning.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 13:27:56 GMT"}], "update_date": "2012-06-28", "authors_parsed": [["White", "Adam", ""], ["Modayil", "Joseph", ""], ["Sutton", "Richard S.", ""]]}, {"id": "1206.6347", "submitter": "Simon Scheider", "authors": "Simon Scheider, Krzysztof Janowicz, Benjamin Adams", "title": "The observational roots of reference of the semantic web", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": "DPA-12221", "categories": "cs.AI cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shared reference is an essential aspect of meaning. It is also indispensable\nfor the semantic web, since it enables to weave the global graph, i.e., it\nallows different users to contribute to an identical referent. For example, an\nessential kind of referent is a geographic place, to which users may contribute\nobservations. We argue for a human-centric, operational approach towards\nreference, based on respective human competences. These competences encompass\nperceptual, cognitive as well as technical ones, and together they allow humans\nto inter-subjectively refer to a phenomenon in their environment. The\ntechnology stack of the semantic web should be extended by such operations.\nThis would allow establishing new kinds of observation-based reference systems\nthat help constrain and integrate the semantic web bottom-up.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 17:44:26 GMT"}], "update_date": "2012-06-28", "authors_parsed": [["Scheider", "Simon", ""], ["Janowicz", "Krzysztof", ""], ["Adams", "Benjamin", ""]]}, {"id": "1206.6386", "submitter": "Yoram Bachrach", "authors": "Yoram Bachrach (Microsoft Research), Thore Graepel (Microsoft\n  Research), Tom Minka (Microsoft Research), John Guiver (Microsoft Research)", "title": "How To Grade a Test Without Knowing the Answers --- A Bayesian Graphical\n  Model for Adaptive Crowdsourcing and Aptitude Testing", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new probabilistic graphical model that jointly models the\ndifficulties of questions, the abilities of participants and the correct\nanswers to questions in aptitude testing and crowdsourcing settings. We devise\nan active learning/adaptive testing scheme based on a greedy minimization of\nexpected model entropy, which allows a more efficient resource allocation by\ndynamically choosing the next question to be asked based on the previous\nresponses. We present experimental results that confirm the ability of our\nmodel to infer the required parameters and demonstrate that the adaptive\ntesting scheme requires fewer questions to obtain the same accuracy as a static\ntest scenario.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Bachrach", "Yoram", "", "Microsoft Research"], ["Graepel", "Thore", "", "Microsoft\n  Research"], ["Minka", "Tom", "", "Microsoft Research"], ["Guiver", "John", "", "Microsoft Research"]]}, {"id": "1206.6390", "submitter": "Giorgos Borboudakis", "authors": "Giorgos Borboudakis (ICS FORTH), Ioannis Tsamardinos (University of\n  Crete)", "title": "Incorporating Causal Prior Knowledge as Path-Constraints in Bayesian\n  Networks and Maximal Ancestral Graphs", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the incorporation of causal knowledge about the presence or\nabsence of (possibly indirect) causal relations into a causal model. Such\ncausal relations correspond to directed paths in a causal model. This type of\nknowledge naturally arises from experimental data, among others. Specifically,\nwe consider the formalisms of Causal Bayesian Networks and Maximal Ancestral\nGraphs and their Markov equivalence classes: Partially Directed Acyclic Graphs\nand Partially Oriented Ancestral Graphs. We introduce sound and complete\nprocedures which are able to incorporate causal prior knowledge in such models.\nIn simulated experiments, we show that often considering even a few causal\nfacts leads to a significant number of new inferences. In a case study, we also\nshow how to use real experimental data to infer causal knowledge and\nincorporate it into a real biological causal network. The code is available at\nmensxmachina.org.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Borboudakis", "Giorgos", "", "ICS FORTH"], ["Tsamardinos", "Ioannis", "", "University of\n  Crete"]]}, {"id": "1206.6399", "submitter": "Jesse Davis", "authors": "Jesse Davis (KU Leuven), Vitor Santos Costa (University of Porto),\n  Peggy Peissig (Marshfield Clinic), Michael Caldwell (Marshfield Clinic),\n  Elizabeth Berg (University of Wisconsin - Madison), David Page (University of\n  Wisconsin - Madison)", "title": "Demand-Driven Clustering in Relational Domains for Predicting Adverse\n  Drug Events", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from electronic medical records (EMR) is challenging due to their\nrelational nature and the uncertain dependence between a patient's past and\nfuture health status. Statistical relational learning is a natural fit for\nanalyzing EMRs but is less adept at handling their inherent latent structure,\nsuch as connections between related medications or diseases. One way to capture\nthe latent structure is via a relational clustering of objects. We propose a\nnovel approach that, instead of pre-clustering the objects, performs a\ndemand-driven clustering during learning. We evaluate our algorithm on three\nreal-world tasks where the goal is to use EMRs to predict whether a patient\nwill have an adverse reaction to a medication. We find that our approach is\nmore accurate than performing no clustering, pre-clustering, and using\nexpert-constructed medical heterarchies.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Davis", "Jesse", "", "KU Leuven"], ["Costa", "Vitor Santos", "", "University of Porto"], ["Peissig", "Peggy", "", "Marshfield Clinic"], ["Caldwell", "Michael", "", "Marshfield Clinic"], ["Berg", "Elizabeth", "", "University of Wisconsin - Madison"], ["Page", "David", "", "University of\n  Wisconsin - Madison"]]}, {"id": "1206.6405", "submitter": "Roy Fox", "authors": "Roy Fox (Hebrew University), Naftali Tishby (Hebrew University)", "title": "Bounded Planning in Passive POMDPs", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Passive POMDPs actions do not affect the world state, but still incur\ncosts. When the agent is bounded by information-processing constraints, it can\nonly keep an approximation of the belief. We present a variational principle\nfor the problem of maintaining the information which is most useful for\nminimizing the cost, and introduce an efficient and simple algorithm for\nfinding an optimum.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Fox", "Roy", "", "Hebrew University"], ["Tishby", "Naftali", "", "Hebrew University"]]}, {"id": "1206.6424", "submitter": "Denis Maua", "authors": "Denis Maua (IDSIA), Cassio De Campos (IDSIA)", "title": "Anytime Marginal MAP Inference", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new anytime algorithm for the marginal MAP problem in\ngraphical models. The algorithm is described in detail, its complexity and\nconvergence rate are studied, and relations to previous theoretical results for\nthe problem are discussed. It is shown that the algorithm runs in\npolynomial-time if the underlying graph of the model has bounded tree-width,\nand that it provides guarantees to the lower and upper bounds obtained within a\nfixed amount of computational resources. Experiments with both real and\nsynthetic generated models highlight its main characteristics and show that it\ncompares favorably against Park and Darwiche's systematic search, particularly\nin the case of problems with many MAP variables and moderate tree-width.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-12-21", "authors_parsed": [["Maua", "Denis", "", "IDSIA"], ["De Campos", "Cassio", "", "IDSIA"]]}, {"id": "1206.6460", "submitter": "Janardhan Rao Doppa", "authors": "Janardhan Rao Doppa (Oregon State University), Alan Fern (Oregon State\n  University), Prasad Tadepalli (Oregon State University)", "title": "Output Space Search for Structured Prediction", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a framework for structured prediction based on search in the\nspace of complete structured outputs. Given a structured input, an output is\nproduced by running a time-bounded search procedure guided by a learned cost\nfunction, and then returning the least cost output uncovered during the search.\nThis framework can be instantiated for a wide range of search spaces and search\nprocedures, and easily incorporates arbitrary structured-prediction loss\nfunctions. In this paper, we make two main technical contributions. First, we\ndefine the limited-discrepancy search space over structured outputs, which is\nable to leverage powerful classification learning algorithms to improve the\nsearch space quality. Second, we give a generic cost function learning\napproach, where the key idea is to learn a cost function that attempts to mimic\nthe behavior of conducting searches guided by the true loss function. Our\nexperiments on six benchmark domains demonstrate that using our framework with\nonly a small amount of search is sufficient for significantly improving on\nstate-of-the-art structured-prediction performance.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Doppa", "Janardhan Rao", "", "Oregon State University"], ["Fern", "Alan", "", "Oregon State\n  University"], ["Tadepalli", "Prasad", "", "Oregon State University"]]}, {"id": "1206.6473", "submitter": "David Silver", "authors": "David Silver (University College London), Kamil Ciosek (University\n  College London)", "title": "Compositional Planning Using Optimal Option Models", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a framework for option model composition. Option\nmodels are temporal abstractions that, like macro-operators in classical\nplanning, jump directly from a start state to an end state. Prior work has\nfocused on constructing option models from primitive actions, by intra-option\nmodel learning; or on using option models to construct a value function, by\ninter-option planning. We present a unified view of intra- and inter-option\nmodel learning, based on a major generalisation of the Bellman equation. Our\nfundamental operation is the recursive composition of option models into other\noption models. This key idea enables compositional planning over many levels of\nabstraction. We illustrate our framework using a dynamic programming algorithm\nthat simultaneously constructs optimal option models for multiple subgoals, and\nalso searches over those option models to provide rapid progress towards other\nsubgoals.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Silver", "David", "", "University College London"], ["Ciosek", "Kamil", "", "University\n  College London"]]}, {"id": "1206.6476", "submitter": "Aurelien Bellet", "authors": "Aurelien Bellet (University of Saint-Etienne), Amaury Habrard\n  (University of Saint-Etienne), Marc Sebban (University of Saint-Etienne)", "title": "Similarity Learning for Provably Accurate Sparse Linear Classification", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the crucial importance of metrics in machine learning\nalgorithms has led to an increasing interest for optimizing distance and\nsimilarity functions. Most of the state of the art focus on learning\nMahalanobis distances (requiring to fulfill a constraint of positive\nsemi-definiteness) for use in a local k-NN algorithm. However, no theoretical\nlink is established between the learned metrics and their performance in\nclassification. In this paper, we make use of the formal framework of good\nsimilarities introduced by Balcan et al. to design an algorithm for learning a\nnon PSD linear similarity optimized in a nonlinear feature space, which is then\nused to build a global linear classifier. We show that our approach has uniform\nstability and derive a generalization bound on the classification error.\nExperiments performed on various datasets confirm the effectiveness of our\napproach compared to state-of-the-art methods and provide evidence that (i) it\nis fast, (ii) robust to overfitting and (iii) produces very sparse classifiers.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Bellet", "Aurelien", "", "University of Saint-Etienne"], ["Habrard", "Amaury", "", "University of Saint-Etienne"], ["Sebban", "Marc", "", "University of Saint-Etienne"]]}, {"id": "1206.6484", "submitter": "Takaki Makino", "authors": "Takaki Makino (University of Tokyo), Johane Takeuchi (Honda Research\n  Institute Japan)", "title": "Apprenticeship Learning for Model Parameters of Partially Observable\n  Environments", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider apprenticeship learning, i.e., having an agent learn a task by\nobserving an expert demonstrating the task in a partially observable\nenvironment when the model of the environment is uncertain. This setting is\nuseful in applications where the explicit modeling of the environment is\ndifficult, such as a dialogue system. We show that we can extract information\nabout the environment model by inferring action selection process behind the\ndemonstration, under the assumption that the expert is choosing optimal actions\nbased on knowledge of the true model of the target environment. Proposed\nalgorithms can achieve more accurate estimates of POMDP parameters and better\npolicies from a short demonstration, compared to methods that learns only from\nthe reaction from the environment.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Makino", "Takaki", "", "University of Tokyo"], ["Takeuchi", "Johane", "", "Honda Research\n  Institute Japan"]]}, {"id": "1206.6570", "submitter": "Jingwei  Liu", "authors": "Jingwei Liu", "title": "Extension of Three-Variable Counterfactual Casual Graphic Model: from\n  Two-Value to Three-Value Random Variable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extension of counterfactual causal graphic model with three variables of\nvertex set in directed acyclic graph (DAG) is discussed in this paper by\nextending two- value distribution to three-value distribution of the variables\ninvolved in DAG. Using the conditional independence as ancillary information, 6\nkinds of extension counterfactual causal graphic models with some variables are\nextended from two-value distribution to three-value distribution and the\nsufficient conditions of identifiability are derived.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 06:14:12 GMT"}, {"version": "v2", "created": "Fri, 29 Jun 2012 10:54:26 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Liu", "Jingwei", ""]]}, {"id": "1206.6735", "submitter": "Shay Cohen", "authors": "Shay B. Cohen, Carlos G\\'omez-Rodr\\'iguez, Giorgio Satta", "title": "Elimination of Spurious Ambiguity in Transition-Based Dependency Parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel technique to remove spurious ambiguity from transition\nsystems for dependency parsing. Our technique chooses a canonical sequence of\ntransition operations (computation) for a given dependency tree. Our technique\ncan be applied to a large class of bottom-up transition systems, including for\ninstance Nivre (2004) and Attardi (2006).\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 15:43:57 GMT"}], "update_date": "2012-06-29", "authors_parsed": [["Cohen", "Shay B.", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""], ["Satta", "Giorgio", ""]]}, {"id": "1206.6814", "submitter": "Varsha Dani", "authors": "Varsha Dani, Omid Madani, David M Pennock, Sumit Sanghai, Brian\n  Galebach", "title": "An Empirical Comparison of Algorithms for Aggregating Expert Predictions", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-106-113", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the outcomes of future events is a challenging problem for which a\nvariety of solution methods have been explored and attempted. We present an\nempirical comparison of a variety of online and offline adaptive algorithms for\naggregating experts' predictions of the outcomes of five years of US National\nFootball League games (1319 games) using expert probability elicitations\nobtained from an Internet contest called ProbabilitySports. We find that it is\ndifficult to improve over simple averaging of the predictions in terms of\nprediction accuracy, but that there is room for improvement in quadratic loss.\nSomewhat surprisingly, a Bayesian estimation algorithm which estimates the\nvariance of each expert's prediction exhibits the most consistent superior\nperformance over simple averaging among our collection of algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 15:37:14 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Dani", "Varsha", ""], ["Madani", "Omid", ""], ["Pennock", "David M", ""], ["Sanghai", "Sumit", ""], ["Galebach", "Brian", ""]]}, {"id": "1206.6816", "submitter": "Robert G. Cowell", "authors": "Robert G. Cowell, Steffen L. Lauritzen, Julia Mortera", "title": "MAIES: A Tool for DNA Mixture Analysis", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-90-97", "categories": "cs.AI cs.CE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an expert system, MAIES, developed for analysing forensic\nidentification problems involving DNA mixture traces using quantitative peak\narea information. Peak area information is represented by conditional Gaussian\ndistributions, and inference based on exact junction tree propagation\nascertains whether individuals, whose profiles have been measured, have\ncontributed to the mixture. The system can also be used to predict DNA profiles\nof unknown contributors by separating the mixture into its individual\ncomponents. The use of the system is illustrated with an application to a real\nworld example. The system implements a novel MAP (maximum a posteriori) search\nalgorithm that is described in an appendix.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 15:38:31 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Cowell", "Robert G.", ""], ["Lauritzen", "Steffen L.", ""], ["Mortera", "Julia", ""]]}, {"id": "1206.6817", "submitter": "Arthur Choi", "authors": "Arthur Choi, Adnan Darwiche", "title": "A Variational Approach for Approximating Bayesian Networks by Edge\n  Deletion", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-80-89", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider in this paper the formulation of approximate inference in\nBayesian networks as a problem of exact inference on an approximate network\nthat results from deleting edges (to reduce treewidth). We have shown in\nearlier work that deleting edges calls for introducing auxiliary network\nparameters to compensate for lost dependencies, and proposed intuitive\nconditions for determining these parameters. We have also shown that our method\ncorresponds to IBP when enough edges are deleted to yield a polytree, and\ncorresponds to some generalizations of IBP when fewer edges are deleted. In\nthis paper, we propose a different criteria for determining auxiliary\nparameters based on optimizing the KL-divergence between the original and\napproximate networks. We discuss the relationship between the two methods for\nselecting parameters, shedding new light on IBP and its generalizations. We\nalso discuss the application of our new method to approximating inference\nproblems which are exponential in constrained treewidth, including MAP and\nnonmyopic value of information.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 15:38:46 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Choi", "Arthur", ""], ["Darwiche", "Adnan", ""]]}, {"id": "1206.6818", "submitter": "Theodore Charitos", "authors": "Theodore Charitos, Linda C. van der Gaag", "title": "Sensitivity Analysis for Threshold Decision Making with Dynamic Networks", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-72-79", "categories": "cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effect of inaccuracies in the parameters of a dynamic Bayesian network\ncan be investigated by subjecting the network to a sensitivity analysis. Having\ndetailed the resulting sensitivity functions in our previous work, we now study\nthe effect of parameter inaccuracies on a recommended decision in view of a\nthreshold decision-making model. We detail the effect of varying a single and\nmultiple parameters from a conditional probability table and present a\ncomputational procedure for establishing bounds between which assessments for\nthese parameters can be varied without inducing a change in the recommended\ndecision. We illustrate the various concepts involved by means of a real-life\ndynamic network in the field of infectious disease.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 15:39:01 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Charitos", "Theodore", ""], ["van der Gaag", "Linda C.", ""]]}, {"id": "1206.6819", "submitter": "Hei Chan", "authors": "Hei Chan, Adnan Darwiche", "title": "On the Robustness of Most Probable Explanations", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-63-71", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Bayesian networks, a Most Probable Explanation (MPE) is a complete\nvariable instantiation with a highest probability given the current evidence.\nIn this paper, we discuss the problem of finding robustness conditions of the\nMPE under single parameter changes. Specifically, we ask the question: How much\nchange in a single network parameter can we afford to apply while keeping the\nMPE unchanged? We will describe a procedure, which is the first of its kind,\nthat computes this answer for each parameter in the Bayesian network variable\nin time O(n exp(w)), where n is the number of network variables and w is its\ntreewidth.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 15:39:15 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Chan", "Hei", ""], ["Darwiche", "Adnan", ""]]}, {"id": "1206.6820", "submitter": "Ruggiero Cavallo", "authors": "Ruggiero Cavallo, David C. Parkes, Satinder Singh", "title": "Optimal Coordinated Planning Amongst Self-Interested Agents with Private\n  State", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-55-62", "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a multi-agent system in a dynamic and uncertain environment. Each\nagent's local decision problem is modeled as a Markov decision process (MDP)\nand agents must coordinate on a joint action in each period, which provides a\nreward to each agent and causes local state transitions. A social planner knows\nthe model of every agent's MDP and wants to implement the optimal joint policy,\nbut agents are self-interested and have private local state. We provide an\nincentive-compatible mechanism for eliciting state information that achieves\nthe optimal joint plan in a Markov perfect equilibrium of the induced\nstochastic game. In the special case in which local problems are Markov chains\nand agents compete to take a single action in each period, we leverage Gittins\nallocation indices to provide an efficient factored algorithm and distribute\ncomputation of the optimal policy among the agents. Distributed, optimal\ncoordinated learning in a multi-agent variant of the multi-armed bandit problem\nis obtained as a special case.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 15:39:28 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Cavallo", "Ruggiero", ""], ["Parkes", "David C.", ""], ["Singh", "Satinder", ""]]}, {"id": "1206.6821", "submitter": "Carlos Brito", "authors": "Carlos Brito, Judea Pearl", "title": "Graphical Condition for Identification in recursive SEM", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-47-54", "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper concerns the problem of predicting the effect of actions or\ninterventions on a system from a combination of (i) statistical data on a set\nof observed variables, and (ii) qualitative causal knowledge encoded in the\nform of a directed acyclic graph (DAG). The DAG represents a set of linear\nequations called Structural Equations Model (SEM), whose coefficients are\nparameters representing direct causal effects. Reliable quantitative\nconclusions can only be obtained from the model if the causal effects are\nuniquely determined by the data. That is, if there exists a unique\nparametrization for the model that makes it compatible with the data. If this\nis the case, the model is called identified. The main result of the paper is a\ngeneral sufficient condition for identification of recursive SEM models.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 15:39:51 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Brito", "Carlos", ""], ["Pearl", "Judea", ""]]}, {"id": "1206.6822", "submitter": "Bozhena Bidyuk", "authors": "Bozhena Bidyuk, Rina Dechter", "title": "Cutset Sampling with Likelihood Weighting", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-39-46", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper analyzes theoretically and empirically the performance of\nlikelihood weighting (LW) on a subset of nodes in Bayesian networks. The\nproposed scheme requires fewer samples to converge due to reduction in sampling\nvariance. The method exploits the structure of the network to bound the\ncomplexity of exact inference used to compute sampling distributions, similar\nto Gibbs cutset sampling. Yet, the extension of the previosly proposed cutset\nsampling principles to likelihood weighting is non-trivial due to differences\nin the sampling processes of Gibbs sampler and LW. We demonstrate empirically\nthat likelihood weighting on a cutset (LWLC) is effective time-wise and has a\nlower rejection rate than LW when applied to networks with many deterministic\nprobabilities. Finally, we show that the performance of likelihood weighting on\na cutset can be improved further by caching computed sampling distributions\nand, consequently, learning 'zeros' of the target distribution.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 15:40:35 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Bidyuk", "Bozhena", ""], ["Dechter", "Rina", ""]]}, {"id": "1206.6823", "submitter": "Yaxin Bi", "authors": "Yaxin Bi, Jiwen W. Guan", "title": "An Efficient Triplet-based Algorithm for Evidential Reasoning", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-31-38", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear-time computational techniques have been developed for combining\nevidence which is available on a number of contending hypotheses. They offer a\nmeans of making the computation-intensive calculations involved more efficient\nin certain circumstances. Unfortunately, they restrict the orthogonal sum of\nevidential functions to the dichotomous structure applies only to elements and\ntheir complements. In this paper, we present a novel evidence structure in\nterms of a triplet and a set of algorithms for evidential reasoning. The merit\nof this structure is that it divides a set of evidence into three subsets,\ndistinguishing trivial evidential elements from important ones focusing some\nparticular elements. It avoids the deficits of the dichotomous structure in\nrepresenting the preference of evidence and estimating the basic probability\nassignment of evidence. We have established a formalism for this structure and\nthe general formulae for combining pieces of evidence in the form of the\ntriplet, which have been theoretically justified.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 15:40:48 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Bi", "Yaxin", ""], ["Guan", "Jiwen W.", ""]]}, {"id": "1206.6825", "submitter": "Chris Bartels", "authors": "Chris Bartels, Jeff A. Bilmes", "title": "Non-Minimal Triangulations for Mixed Stochastic/Deterministic Graphical\n  Models", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-15-22", "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We observe that certain large-clique graph triangulations can be useful to\nreduce both computational and space requirements when making queries on mixed\nstochastic/deterministic graphical models. We demonstrate that many of these\nlarge-clique triangulations are non-minimal and are thus unattainable via the\nvariable elimination algorithm. We introduce ancestral pairs as the basis for\nnovel triangulation heuristics and prove that no more than the addition of\nedges between ancestral pairs need be considered when searching for state space\noptimal triangulations in such graphs. Empirical results on random and real\nworld graphs show that the resulting triangulations that yield significant\nspeedups are almost always non-minimal. We also give an algorithm and\ncorrectness proof for determining if a triangulation can be obtained via\nelimination, and we show that the decision problem associated with finding\noptimal state space triangulations in this mixed stochastic/deterministic\nsetting is NP-complete.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 15:41:21 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Bartels", "Chris", ""], ["Bilmes", "Jeff A.", ""]]}, {"id": "1206.6827", "submitter": "Chalee Asavathiratham", "authors": "Chalee Asavathiratham", "title": "Linear Algebra Approach to Separable Bayesian Networks", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-1-6", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Separable Bayesian Networks, or the Influence Model, are dynamic Bayesian\nNetworks in which the conditional probability distribution can be separated\ninto a function of only the marginal distribution of a node's neighbors,\ninstead of the joint distributions. In terms of modeling, separable networks\nhas rendered possible siginificant reduction in complexity, as the state space\nis only linear in the number of variables on the network, in contrast to a\ntypical state space which is exponential. In this work, We describe the\nconnection between an arbitrary Conditional Probability Table (CPT) and\nseparable systems using linear algebra. We give an alternate proof on the\nequivalence of sufficiency and separability. We present a computational method\nfor testing whether a given CPT is separable.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 15:41:47 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Asavathiratham", "Chalee", ""]]}, {"id": "1206.6828", "submitter": "Mikko Koivisto", "authors": "Mikko Koivisto", "title": "Advances in exact Bayesian structure discovery in Bayesian networks", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-241-248", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a Bayesian method for learning the Bayesian network structure\nfrom complete data. Recently, Koivisto and Sood (2004) presented an algorithm\nthat for any single edge computes its marginal posterior probability in O(n\n2^n) time, where n is the number of attributes; the number of parents per\nattribute is bounded by a constant. In this paper we show that the posterior\nprobabilities for all the n (n - 1) potential edges can be computed in O(n 2^n)\ntotal time. This result is achieved by a forward-backward technique and fast\nMoebius transform algorithms, which are of independent interest. The resulting\nspeedup by a factor of about n^2 allows us to experimentally study the\nstatistical power of learning moderate-size networks. We report results from a\nsimulation study that covers data sets with 20 to 10,000 records over 5 to 25\ndiscrete attributes\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:15:14 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Koivisto", "Mikko", ""]]}, {"id": "1206.6829", "submitter": "Changsung Kang", "authors": "Changsung Kang, Jin Tian", "title": "Inequality Constraints in Causal Models with Hidden Variables", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-233-240", "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a class of inequality constraints on the set of distributions\ninduced by local interventions on variables governed by a causal Bayesian\nnetwork, in which some of the variables remain unmeasured. We derive bounds on\ncausal effects that are not directly measured in randomized experiments. We\nderive instrumental inequality type of constraints on nonexperimental\ndistributions. The results have applications in testing causal models with\nobservational or experimental data.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:15:29 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Kang", "Changsung", ""], ["Tian", "Jin", ""]]}, {"id": "1206.6830", "submitter": "Manfred Jaeger", "authors": "Manfred Jaeger", "title": "The AI&M Procedure for Learning from Incomplete Data", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-225-232", "categories": "stat.ME cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate methods for parameter learning from incomplete data that is\nnot missing at random. Likelihood-based methods then require the optimization\nof a profile likelihood that takes all possible missingness mechanisms into\naccount. Optimzing this profile likelihood poses two main difficulties:\nmultiple (local) maxima, and its very high-dimensional parameter space. In this\npaper a new method is presented for optimizing the profile likelihood that\naddresses the second difficulty: in the proposed AI&M (adjusting imputation and\nmazimization) procedure the optimization is performed by operations in the\nspace of data completions, rather than directly in the parameter space of the\nprofile likelihood. We apply the AI&M method to learning parameters for\nBayesian networks. The method is compared against conservative inference, which\ntakes into account each possible data completion, and against EM. The results\nindicate that likelihood-based inference is still feasible in the case of\nunknown missingness mechanisms, and that conservative inference is\nunnecessarily weak. On the other hand, our results also provide evidence that\nthe EM algorithm is still quite effective when the data is not missing at\nrandom.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:15:42 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Jaeger", "Manfred", ""]]}, {"id": "1206.6831", "submitter": "Yimin Huang", "authors": "Yimin Huang, Marco Valtorta", "title": "Pearl's Calculus of Intervention Is Complete", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-217-224", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with graphical criteria that can be used to solve the\nproblem of identifying casual effects from nonexperimental data in a causal\nBayesian network structure, i.e., a directed acyclic graph that represents\ncausal relationships. We first review Pearl's work on this topic [Pearl, 1995],\nin which several useful graphical criteria are presented. Then we present a\ncomplete algorithm [Huang and Valtorta, 2006b] for the identifiability problem.\nBy exploiting the completeness of this algorithm, we prove that the three basic\ndo-calculus rules that Pearl presents are complete, in the sense that, if a\ncausal effect is identifiable, there exists a sequence of applications of the\nrules of the do-calculus that transforms the causal effect formula into a\nformula that only includes observational quantities.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:17:19 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Huang", "Yimin", ""], ["Valtorta", "Marco", ""]]}, {"id": "1206.6834", "submitter": "Phan H. Giang", "authors": "Phan H. Giang", "title": "A new axiomatization for likelihood gambles", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-192-199", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a new and more general axiomatization than one presented\npreviously for preference on likelihood gambles. Likelihood gambles describe\nactions in a situation where a decision maker knows multiple probabilistic\nmodels and a random sample generated from one of those models but does not know\nprior probability of models. This new axiom system is inspired by Jensen's\naxiomatization of probabilistic gambles. Our approach provides a new\nperspective to the role of data in decision making under ambiguity. It avoids\none of the most controversial issue of Bayesian methodology namely the\nassumption of prior probability.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:18:21 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Giang", "Phan H.", ""]]}, {"id": "1206.6835", "submitter": "Nir Friedman", "authors": "Nir Friedman, Raz Kupferman", "title": "Dimension Reduction in Singularly Perturbed Continuous-Time Bayesian\n  Networks", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-182-191", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous-time Bayesian networks (CTBNs) are graphical representations of\nmulti-component continuous-time Markov processes as directed graphs. The edges\nin the network represent direct influences among components. The joint rate\nmatrix of the multi-component process is specified by means of conditional rate\nmatrices for each component separately. This paper addresses the situation\nwhere some of the components evolve on a time scale that is much shorter\ncompared to the time scale of the other components. In this paper, we prove\nthat in the limit where the separation of scales is infinite, the Markov\nprocess converges (in distribution, or weakly) to a reduced, or effective\nMarkov process that only involves the slow components. We also demonstrate that\nfor reasonable separation of scale (an order of magnitude) the reduced process\nis a good approximation of the marginal process over the slow components. We\nprovide a simple procedure for building a reduced CTBN for this effective\nprocess, with conditional rate matrices that can be directly calculated from\nthe original CTBN, and discuss the implications for approximate reasoning in\nlarge systems.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:18:35 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Friedman", "Nir", ""], ["Kupferman", "Raz", ""]]}, {"id": "1206.6836", "submitter": "Norman Ferns", "authors": "Norman Ferns, Pablo Samuel Castro, Doina Precup, Prakash Panangaden", "title": "Methods for computing state similarity in Markov Decision Processes", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-174-181", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular approach to solving large probabilistic systems relies on\naggregating states based on a measure of similarity. Many approaches in the\nliterature are heuristic. A number of recent methods rely instead on metrics\nbased on the notion of bisimulation, or behavioral equivalence between states\n(Givan et al, 2001, 2003; Ferns et al, 2004). An integral component of such\nmetrics is the Kantorovich metric between probability distributions. However,\nwhile this metric enables many satisfying theoretical properties, it is costly\nto compute in practice. In this paper, we use techniques from network\noptimization and statistical sampling to overcome this problem. We obtain in\nthis manner a variety of distance functions for MDP state aggregation, which\ndiffer in the tradeoff between time and space complexity, as well as the\nquality of the aggregation. We provide an empirical evaluation of these\ntrade-offs.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:18:48 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Ferns", "Norman", ""], ["Castro", "Pablo Samuel", ""], ["Precup", "Doina", ""], ["Panangaden", "Prakash", ""]]}, {"id": "1206.6837", "submitter": "Gal Elidan", "authors": "Gal Elidan, Ian McGraw, Daphne Koller", "title": "Residual Belief Propagation: Informed Scheduling for Asynchronous\n  Message Passing", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-165-173", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference for probabilistic graphical models is still very much a practical\nchallenge in large domains. The commonly used and effective belief propagation\n(BP) algorithm and its generalizations often do not converge when applied to\nhard, real-life inference tasks. While it is widely recognized that the\nscheduling of messages in these algorithms may have significant consequences,\nthis issue remains largely unexplored. In this work, we address the question of\nhow to schedule messages for asynchronous propagation so that a fixed point is\nreached faster and more often. We first show that any reasonable asynchronous\nBP converges to a unique fixed point under conditions similar to those that\nguarantee convergence of synchronous BP. In addition, we show that the\nconvergence rate of a simple round-robin schedule is at least as good as that\nof synchronous propagation. We then propose residual belief propagation (RBP),\na novel, easy-to-implement, asynchronous propagation algorithm that schedules\nmessages in an informed way, that pushes down a bound on the distance from the\nfixed point. Finally, we demonstrate the superiority of RBP over\nstate-of-the-art methods for a variety of challenging synthetic and real-life\nproblems: RBP converges significantly more often than other methods; and it\nsignificantly reduces running time until convergence, even when other methods\nconverge.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:19:01 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Elidan", "Gal", ""], ["McGraw", "Ian", ""], ["Koller", "Daphne", ""]]}, {"id": "1206.6838", "submitter": "Tal El-Hay", "authors": "Tal El-Hay, Nir Friedman, Daphne Koller, Raz Kupferman", "title": "Continuous Time Markov Networks", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-155-164", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central task in many applications is reasoning about processes that change\nin a continuous time. The mathematical framework of Continuous Time Markov\nProcesses provides the basic foundations for modeling such systems. Recently,\nNodelman et al introduced continuous time Bayesian networks (CTBNs), which\nallow a compact representation of continuous-time processes over a factored\nstate space. In this paper, we introduce continuous time Markov networks\n(CTMNs), an alternative representation language that represents a different\ntype of continuous-time dynamics. In many real life processes, such as\nbiological and chemical systems, the dynamics of the process can be naturally\ndescribed as an interplay between two forces - the tendency of each entity to\nchange its state, and the overall fitness or energy function of the entire\nsystem. In our model, the first force is described by a continuous-time\nproposal process that suggests possible local changes to the state of the\nsystem at different rates. The second force is represented by a Markov network\nthat encodes the fitness, or desirability, of different states; a proposed\nlocal change is then accepted with a probability that is a function of the\nchange in the fitness distribution. We show that the fitness distribution is\nalso the stationary distribution of the Markov process, so that this\nrepresentation provides a characterization of a temporal process whose\nstationary distribution has a compact graphical representation. This allows us\nto naturally capture a different type of structure in complex dynamical\nprocesses, such as evolving biological sequences. We describe the semantics of\nthe representation, its basic properties, and how it compares to CTBNs. We also\nprovide algorithms for learning such models from data, and discuss its\napplicability to biological sequence evolution.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:19:16 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["El-Hay", "Tal", ""], ["Friedman", "Nir", ""], ["Koller", "Daphne", ""], ["Kupferman", "Raz", ""]]}, {"id": "1206.6841", "submitter": "Vanessa Didelez", "authors": "Vanessa Didelez", "title": "Asymmetric separation for local independence graphs", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-130-137", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directed possibly cyclic graphs have been proposed by Didelez (2000) and\nNodelmann et al. (2002) in order to represent the dynamic dependencies among\nstochastic processes. These dependencies are based on a generalization of\nGranger-causality to continuous time, first developed by Schweder (1970) for\nMarkov processes, who called them local dependencies. They deserve special\nattention as they are asymmetric unlike stochastic (in)dependence. In this\npaper we focus on their graphical representation and develop a suitable, i.e.\nasymmetric notion of separation, called delta-separation. The properties of\nthis graph separation as well as of local independence are investigated in\ndetail within a framework of asymmetric (semi)graphoids allowing a deeper\ninsight into what information can be read off these graphs.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:20:13 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Didelez", "Vanessa", ""]]}, {"id": "1206.6842", "submitter": "Thomas Degris", "authors": "Thomas Degris, Olivier Sigaud, Pierre-Henri Wuillemin", "title": "Chi-square Tests Driven Method for Learning the Structure of Factored\n  MDPs", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-122-129", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SDYNA is a general framework designed to address large stochastic\nreinforcement learning problems. Unlike previous model based methods in FMDPs,\nit incrementally learns the structure and the parameters of a RL problem using\nsupervised learning techniques. Then, it integrates decision-theoric planning\nalgorithms based on FMDPs to compute its policy. SPITI is an instanciation of\nSDYNA that exploits ITI, an incremental decision tree algorithm, to learn the\nreward function and the Dynamic Bayesian Networks with local structures\nrepresenting the transition function of the problem. These representations are\nused by an incremental version of the Structured Value Iteration algorithm. In\norder to learn the structure, SPITI uses Chi-Square tests to detect the\nindependence between two probability distributions. Thus, we study the relation\nbetween the threshold used in the Chi-Square test, the size of the model built\nand the relative error of the value function of the induced policy with respect\nto the optimal value. We show that, on stochastic problems, one can tune the\nthreshold so as to generate both a compact model and an efficient policy. Then,\nwe show that SPITI, while keeping its model compact, uses the generalization\nproperty of its learning method to perform better than a stochastic classical\ntabular algorithm in large RL problem with an unknown structure. We also\nintroduce a new measure based on Chi-Square to qualify the accuracy of the\nmodel learned by SPITI. We qualitatively show that the generalization property\nin SPITI within the FMDP framework may prevent an exponential growth of the\ntime required to learn the structure of large stochastic RL problems.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:20:30 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Degris", "Thomas", ""], ["Sigaud", "Olivier", ""], ["Wuillemin", "Pierre-Henri", ""]]}, {"id": "1206.6843", "submitter": "Joseph Ramsey", "authors": "Joseph Ramsey, Jiji Zhang, Peter L. Spirtes", "title": "Adjacency-Faithfulness and Conservative Causal Inference", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-401-408", "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most causal inference algorithms in the literature (e.g., Pearl (2000),\nSpirtes et al. (2000), Heckerman et al. (1999)) exploit an assumption usually\nreferred to as the causal Faithfulness or Stability condition. In this paper,\nwe highlight two components of the condition used in constraint-based\nalgorithms, which we call \"Adjacency-Faithfulness\" and\n\"Orientation-Faithfulness\". We point out that assuming Adjacency-Faithfulness\nis true, it is in principle possible to test the validity of\nOrientation-Faithfulness. Based on this observation, we explore the consequence\nof making only the Adjacency-Faithfulness assumption. We show that the familiar\nPC algorithm has to be modified to be (asymptotically) correct under the\nweaker, Adjacency-Faithfulness assumption. Roughly the modified algorithm,\ncalled Conservative PC (CPC), checks whether Orientation-Faithfulness holds in\nthe orientation phase, and if not, avoids drawing certain causal conclusions\nthe PC algorithm would draw. However, if the stronger, standard causal\nFaithfulness condition actually obtains, the CPC algorithm is shown to output\nthe same pattern as the PC algorithm does in the large sample limit. We also\npresent a simulation study showing that the CPC algorithm runs almost as fast\nas the PC algorithm, and outputs significantly fewer false causal arrowheads\nthan the PC algorithm does on realistic sample sizes. We end our paper by\ndiscussing how score-based algorithms such as GES perform when the\nAdjacency-Faithfulness but not the standard causal Faithfulness condition\nholds, and how to extend our work to the FCI algorithm, which allows for the\npossibility of latent variables.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:21:05 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Ramsey", "Joseph", ""], ["Zhang", "Jiji", ""], ["Spirtes", "Peter L.", ""]]}, {"id": "1206.6844", "submitter": "Cedric Pralet", "authors": "Cedric Pralet, Thomas Schiex, Gerard Verfaillie", "title": "From influence diagrams to multi-operator cluster DAGs", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-393-400", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There exist several architectures to solve influence diagrams using local\ncomputations, such as the Shenoy-Shafer, the HUGIN, or the Lazy Propagation\narchitectures. They all extend usual variable elimination algorithms thanks to\nthe use of so-called 'potentials'. In this paper, we introduce a new\narchitecture, called the Multi-operator Cluster DAG architecture, which can\nproduce decompositions with an improved constrained induced-width, and\ntherefore induce potentially exponential gains. Its principle is to benefit\nfrom the composite nature of influence diagrams, instead of using uniform\npotentials, in order to better analyze the problem structure.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:21:20 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Pralet", "Cedric", ""], ["Schiex", "Thomas", ""], ["Verfaillie", "Gerard", ""]]}, {"id": "1206.6846", "submitter": "Avi Pfeffer", "authors": "Avi Pfeffer", "title": "Approximate Separability for Weak Interaction in Dynamic Systems", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-375-384", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One approach to monitoring a dynamic system relies on decomposition of the\nsystem into weakly interacting subsystems. An earlier paper introduced a notion\nof weak interaction called separability, and showed that it leads to exact\npropagation of marginals for prediction. This paper addresses two questions\nleft open by the earlier paper: can we define a notion of approximate\nseparability that occurs naturally in practice, and do separability and\napproximate separability lead to accurate monitoring? The answer to both\nquestions is afirmative. The paper also analyzes the structure of approximately\nseparable decompositions, and provides some explanation as to why these models\nperform well.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:23:17 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Pfeffer", "Avi", ""]]}, {"id": "1206.6847", "submitter": "Jose M. Pena", "authors": "Jose M. Pena, Roland Nilsson, Johan Bj\\\"orkegren, Jesper Tegn\\'er", "title": "Identifying the Relevant Nodes Without Learning the Model", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-367-374", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to identify all the nodes that are relevant to compute\nall the conditional probability distributions for a given set of nodes. Our\nmethod is simple, effcient, consistent, and does not require learning a\nBayesian network first. Therefore, our method can be applied to\nhigh-dimensional databases, e.g. gene expression databases.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:23:41 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Pena", "Jose M.", ""], ["Nilsson", "Roland", ""], ["Bj\u00f6rkegren", "Johan", ""], ["Tegn\u00e9r", "Jesper", ""]]}, {"id": "1206.6849", "submitter": "Brian Milch", "authors": "Brian Milch, Stuart Russell", "title": "General-Purpose MCMC Inference over Relational Structures", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-349-358", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tasks such as record linkage and multi-target tracking, which involve\nreconstructing the set of objects that underlie some observed data, are\nparticularly challenging for probabilistic inference. Recent work has achieved\nefficient and accurate inference on such problems using Markov chain Monte\nCarlo (MCMC) techniques with customized proposal distributions. Currently,\nimplementing such a system requires coding MCMC state representations and\nacceptance probability calculations that are specific to a particular\napplication. An alternative approach, which we pursue in this paper, is to use\na general-purpose probabilistic modeling language (such as BLOG) and a generic\nMetropolis-Hastings MCMC algorithm that supports user-supplied proposal\ndistributions. Our algorithm gains flexibility by using MCMC states that are\nonly partial descriptions of possible worlds; we provide conditions under which\nMCMC over partial worlds yields correct answers to queries. We also show how to\nuse a context-specific Bayes net to identify the factors in the acceptance\nprobability that need to be computed for a given proposed move. Experimental\nresults on a citation matching task show that our general-purpose MCMC engine\ncompares favorably with an application-specific system.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:24:15 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Milch", "Brian", ""], ["Russell", "Stuart", ""]]}, {"id": "1206.6850", "submitter": "Guobiao Mei", "authors": "Guobiao Mei, Christian R. Shelton", "title": "Visualization of Collaborative Data", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-341-348", "categories": "cs.GR cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative data consist of ratings relating two distinct sets of objects:\nusers and items. Much of the work with such data focuses on filtering:\npredicting unknown ratings for pairs of users and items. In this paper we focus\non the problem of visualizing the information. Given all of the ratings, our\ntask is to embed all of the users and items as points in the same Euclidean\nspace. We would like to place users near items that they have rated (or would\nrate) high, and far away from those they would give a low rating. We pose this\nproblem as a real-valued non-linear Bayesian network and employ Markov chain\nMonte Carlo and expectation maximization to find an embedding. We present a\nmetric by which to judge the quality of a visualization and compare our results\nto local linear embedding and Eigentaste on three real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:24:29 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Mei", "Guobiao", ""], ["Shelton", "Christian R.", ""]]}, {"id": "1206.6851", "submitter": "Bhaskara Marthi", "authors": "Bhaskara Marthi, Stuart Russell, David Andre", "title": "A compact, hierarchical Q-function decomposition", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-332-340", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work in hierarchical reinforcement learning has faced a dilemma:\neither ignore the values of different possible exit states from a subroutine,\nthereby risking suboptimal behavior, or represent those values explicitly\nthereby incurring a possibly large representation cost because exit values\nrefer to nonlocal aspects of the world (i.e., all subsequent rewards). This\npaper shows that, in many cases, one can avoid both of these problems. The\nsolution is based on recursively decomposing the exit value function in terms\nof Q-functions at higher levels of the hierarchy. This leads to an intuitively\nappealing runtime architecture in which a parent subroutine passes to its child\na value function on the exit states and the child reasons about how its choices\naffect the exit value. We also identify structural conditions on the value\nfunction and transition distributions that allow much more concise\nrepresentations of exit state distributions, leading to further state\nabstraction. In essence, the only variables whose exit values need be\nconsidered are those that the parent cares about and the child affects. We\ndemonstrate the utility of our algorithms on a series of increasingly complex\nenvironments.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:24:43 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Marthi", "Bhaskara", ""], ["Russell", "Stuart", ""], ["Andre", "David", ""]]}, {"id": "1206.6852", "submitter": "Vikash Mansinghka", "authors": "Vikash Mansinghka, Charles Kemp, Thomas Griffiths, Joshua Tenenbaum", "title": "Structured Priors for Structure Learning", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-324-331", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional approaches to Bayes net structure learning typically assume\nlittle regularity in graph structure other than sparseness. However, in many\ncases, we expect more systematicity: variables in real-world systems often\ngroup into classes that predict the kinds of probabilistic dependencies they\nparticipate in. Here we capture this form of prior knowledge in a hierarchical\nBayesian framework, and exploit it to enable structure learning and type\ndiscovery from small datasets. Specifically, we present a nonparametric\ngenerative model for directed acyclic graphs as a prior for Bayes net structure\nlearning. Our model assumes that variables come in one or more classes and that\nthe prior probability of an edge existing between two variables is a function\nonly of their classes. We derive an MCMC algorithm for simultaneous inference\nof the number of classes, the class assignments of variables, and the Bayes net\nstructure over variables. For several realistic, sparse datasets, we show that\nthe bias towards systematicity of connections provided by our model yields more\naccurate learned networks than a traditional, uniform prior approach, and that\nthe classes found by our model are appropriate.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:24:57 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Mansinghka", "Vikash", ""], ["Kemp", "Charles", ""], ["Griffiths", "Thomas", ""], ["Tenenbaum", "Joshua", ""]]}, {"id": "1206.6853", "submitter": "Subramani Mani", "authors": "Subramani Mani, Peter L. Spirtes, Gregory F. Cooper", "title": "A theoretical study of Y structures for causal discovery", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-314-323", "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are several existing algorithms that under appropriate assumptions can\nreliably identify a subset of the underlying causal relationships from\nobservational data. This paper introduces the first computationally feasible\nscore-based algorithm that can reliably identify causal relationships in the\nlarge sample limit for discrete models, while allowing for the possibility that\nthere are unobserved common causes. In doing so, the algorithm does not ever\nneed to assign scores to causal structures with unobserved common causes. The\nalgorithm is based on the identification of so called Y substructures within\nBayesian network structures that can be learned from observational data. An\nexample of a Y substructure is A -> C, B -> C, C -> D. After providing\nbackground on causal discovery, the paper proves the conditions under which the\nalgorithm is reliable in the large sample limit.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:25:15 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Mani", "Subramani", ""], ["Spirtes", "Peter L.", ""], ["Cooper", "Gregory F.", ""]]}, {"id": "1206.6854", "submitter": "Anders L. Madsen", "authors": "Anders L. Madsen", "title": "Belief Update in CLG Bayesian Networks With Lazy Propagation", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-306-313", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years Bayesian networks (BNs) with a mixture of continuous and\ndiscrete variables have received an increasing level of attention. We present\nan architecture for exact belief update in Conditional Linear Gaussian BNs (CLG\nBNs). The architecture is an extension of lazy propagation using operations of\nLauritzen & Jensen [6] and Cowell [2]. By decomposing clique and separator\npotentials into sets of factors, the proposed architecture takes advantage of\nindependence and irrelevance properties induced by the structure of the graph\nand the evidence. The resulting benefits are illustrated by examples. Results\nof a preliminary empirical performance evaluation indicate a significant\npotential of the proposed architecture.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:25:42 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Madsen", "Anders L.", ""]]}, {"id": "1206.6856", "submitter": "Seunghwan Lee", "authors": "Seunghwan Lee", "title": "Reasoning about Uncertainty in Metric Spaces", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-289-297", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We set up a model for reasoning about metric spaces with belief theoretic\nmeasures. The uncertainty in these spaces stems from both probability and\nmetric. To represent both aspect of uncertainty, we choose an expected distance\nfunction as a measure of uncertainty. A formal logical system is constructed\nfor the reasoning about expected distance. Soundness and completeness are shown\nfor this logic. For reasoning on product metric space with uncertainty, a new\nmetric is defined and shown to have good properties.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:26:12 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Lee", "Seunghwan", ""]]}, {"id": "1206.6859", "submitter": "Kathryn Blackmond Laskey", "authors": "Kathryn Blackmond Laskey, Ning Xu, Chun-Hung Chen", "title": "Propagation of Delays in the National Airspace System", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-265-272", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The National Airspace System (NAS) is a large and complex system with\nthousands of interrelated components: administration, control centers,\nairports, airlines, aircraft, passengers, etc. The complexity of the NAS\ncreates many difficulties in management and control. One of the most pressing\nproblems is flight delay. Delay creates high cost to airlines, complaints from\npassengers, and difficulties for airport operations. As demand on the system\nincreases, the delay problem becomes more and more prominent. For this reason,\nit is essential for the Federal Aviation Administration to understand the\ncauses of delay and to find ways to reduce delay. Major contributing factors to\ndelay are congestion at the origin airport, weather, increasing demand, and air\ntraffic management (ATM) decisions such as the Ground Delay Programs (GDP).\nDelay is an inherently stochastic phenomenon. Even if all known causal factors\ncould be accounted for, macro-level national airspace system (NAS) delays could\nnot be predicted with certainty from micro-level aircraft information. This\npaper presents a stochastic model that uses Bayesian Networks (BNs) to model\nthe relationships among different components of aircraft delay and the causal\nfactors that affect delays. A case study on delays of departure flights from\nChicago O'Hare international airport (ORD) to Hartsfield-Jackson Atlanta\nInternational Airport (ATL) reveals how local and system level environmental\nand human-caused factors combine to affect components of delay, and how these\ncomponents contribute to the final arrival delay at the destination airport.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:27:12 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Laskey", "Kathryn Blackmond", ""], ["Xu", "Ning", ""], ["Chen", "Chun-Hung", ""]]}, {"id": "1206.6861", "submitter": "Manabu Kuroki", "authors": "Manabu Kuroki, Zhihong Cai", "title": "Stratified Analysis of `Probabilities of Causation'", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-249-256", "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes new formulas for the probabilities of causation difined\nby Pearl (2000). Tian and Pearl (2000a, 2000b) showed how to bound the\nquantities of the probabilities of causation from experimental and\nobservational data, under the minimal assumptions about the data-generating\nprocess. We derive narrower bounds than Tian-Pearl bounds by making use of the\ncovariate information measured in experimental and observational studies. In\naddition, we provide identifiable case under no-prevention assumption and\ndiscuss the covariate selection problem from the viewpoint of estimation\naccuracy. These results are helpful in providing more evidence for public\npolicy assessment and dicision making problems.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:27:37 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Kuroki", "Manabu", ""], ["Cai", "Zhihong", ""]]}, {"id": "1206.6862", "submitter": "Or Zuk", "authors": "Or Zuk, Shiri Margel, Eytan Domany", "title": "On the Number of Samples Needed to Learn the Correct Structure of a\n  Bayesian Network", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-560-567", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Networks (BNs) are useful tools giving a natural and compact\nrepresentation of joint probability distributions. In many applications one\nneeds to learn a Bayesian Network (BN) from data. In this context, it is\nimportant to understand the number of samples needed in order to guarantee a\nsuccessful learning. Previous work have studied BNs sample complexity, yet it\nmainly focused on the requirement that the learned distribution will be close\nto the original distribution which generated the data. In this work, we study a\ndifferent aspect of the learning, namely the number of samples needed in order\nto learn the correct structure of the network. We give both asymptotic results,\nvalid in the large sample limit, and experimental results, demonstrating the\nlearning behavior for feasible sample sizes. We show that structure learning is\na more difficult task, compared to approximating the correct distribution, in\nthe sense that it requires a much larger number of samples, regardless of the\ncomputational power available for the learner.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:28:06 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Zuk", "Or", ""], ["Margel", "Shiri", ""], ["Domany", "Eytan", ""]]}, {"id": "1206.6864", "submitter": "Zhao Xu", "authors": "Zhao Xu, Volker Tresp, Kai Yu, Hans-Peter Kriegel", "title": "Infinite Hidden Relational Models", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-544-551", "categories": "cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many cases it makes sense to model a relationship symmetrically, not\nimplying any particular directionality. Consider the classical example of a\nrecommendation system where the rating of an item by a user should\nsymmetrically be dependent on the attributes of both the user and the item. The\nattributes of the (known) relationships are also relevant for predicting\nattributes of entities and for predicting attributes of new relations. In\nrecommendation systems, the exploitation of relational attributes is often\nreferred to as collaborative filtering. Again, in many applications one might\nprefer to model the collaborative effect in a symmetrical way. In this paper we\npresent a relational model, which is completely symmetrical. The key innovation\nis that we introduce for each entity (or object) an infinite-dimensional latent\nvariable as part of a Dirichlet process (DP) model. We discuss inference in the\nmodel, which is based on a DP Gibbs sampler, i.e., the Chinese restaurant\nprocess. We extend the Chinese restaurant process to be applicable to\nrelational modeling. Our approach is evaluated in three applications. One is a\nrecommendation system based on the MovieLens data set. The second application\nconcerns the prediction of the function of yeast genes/proteins on the data set\nof KDD Cup 2001 using a multi-relational model. The third application involves\na relational medical domain. The experimental results show that our model gives\nsignificantly improved estimates of attributes describing relationships or\nentities in complex relational models.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:28:29 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Xu", "Zhao", ""], ["Tresp", "Volker", ""], ["Yu", "Kai", ""], ["Kriegel", "Hans-Peter", ""]]}, {"id": "1206.6865", "submitter": "Frank Wood", "authors": "Frank Wood, Thomas Griffiths, Zoubin Ghahramani", "title": "A Non-Parametric Bayesian Method for Inferring Hidden Causes", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-536-543", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a non-parametric Bayesian approach to structure learning with\nhidden causes. Previous Bayesian treatments of this problem define a prior over\nthe number of hidden causes and use algorithms such as reversible jump Markov\nchain Monte Carlo to move between solutions. In contrast, we assume that the\nnumber of hidden causes is unbounded, but only a finite number influence\nobservable variables. This makes it possible to use a Gibbs sampler to\napproximate the distribution over causal structures. We evaluate the\nperformance of both approaches in discovering hidden causes in simulated data,\nand use our non-parametric approach to discover hidden causes in a real medical\ndataset.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:28:41 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Wood", "Frank", ""], ["Griffiths", "Thomas", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "1206.6867", "submitter": "Paul Weng", "authors": "Paul Weng", "title": "Axiomatic Foundations for a Class of Generalized Expected Utility:\n  Algebraic Expected Utility", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-520-527", "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expected Utility: Algebraic Expected Utility In this paper, we provide two\naxiomatizations of algebraic expected utility, which is a particular\ngeneralized expected utility, in a von Neumann-Morgenstern setting, i.e.\nuncertainty representation is supposed to be given and here to be described by\na plausibility measure valued on a semiring, which could be partially ordered.\nWe show that axioms identical to those for expected utility entail that\npreferences are represented by an algebraic expected utility. This algebraic\napproach allows many previous propositions (expected utility, binary\npossibilistic utility,...) to be unified in a same general framework and proves\nthat the obtained utility enjoys the same nice features as expected utility:\nlinearity, dynamic consistency, autoduality of the underlying uncertainty\nmeasure, autoduality of the decision criterion and possibility of modeling\ndecision maker's attitude toward uncertainty.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:29:06 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Weng", "Paul", ""]]}, {"id": "1206.6869", "submitter": "Amarnag Subramanya", "authors": "Amarnag Subramanya, Alvin Raj, Jeff A. Bilmes, Dieter Fox", "title": "Recognizing Activities and Spatial Context Using Wearable Sensors", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-494-502", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new dynamic model with the capability of recognizing both\nactivities that an individual is performing as well as where that ndividual is\nlocated. Our model is novel in that it utilizes a dynamic graphical model to\njointly estimate both activity and spatial context over time based on the\nsimultaneous use of asynchronous observations consisting of GPS measurements,\nand measurements from a small mountable sensor board. Joint inference is quite\ndesirable as it has the ability to improve accuracy of the model. A key goal,\nhowever, in designing our overall system is to be able to perform accurate\ninference decisions while minimizing the amount of hardware an individual must\nwear. This minimization leads to greater comfort and flexibility, decreased\npower requirements and therefore increased battery life, and reduced cost. We\nshow results indicating that our joint measurement model outperforms\nmeasurements from either the sensor board or GPS alone, using two types of\nprobabilistic inference procedures, namely particle filtering and pruned exact\ninference.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:29:30 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Subramanya", "Amarnag", ""], ["Raj", "Alvin", ""], ["Bilmes", "Jeff A.", ""], ["Fox", "Dieter", ""]]}, {"id": "1206.6870", "submitter": "Alexander L. Strehl", "authors": "Alexander L. Strehl, Lihong Li, Michael L. Littman", "title": "Incremental Model-based Learners With Formal Learning-Time Guarantees", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-485-493", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based learning algorithms have been shown to use experience efficiently\nwhen learning to solve Markov Decision Processes (MDPs) with finite state and\naction spaces. However, their high computational cost due to repeatedly solving\nan internal model inhibits their use in large-scale problems. We propose a\nmethod based on real-time dynamic programming (RTDP) to speed up two\nmodel-based algorithms, RMAX and MBIE (model-based interval estimation),\nresulting in computationally much faster algorithms with little loss compared\nto existing bounds. Specifically, our two new learning algorithms, RTDP-RMAX\nand RTDP-IE, have considerably smaller computational demands than RMAX and\nMBIE. We develop a general theoretical framework that allows us to prove that\nboth are efficient learners in a PAC (probably approximately correct) sense. We\nalso present an experimental evaluation of these new algorithms that helps\nquantify the tradeoff between computational and experience demands.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:29:41 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Strehl", "Alexander L.", ""], ["Li", "Lihong", ""], ["Littman", "Michael L.", ""]]}, {"id": "1206.6874", "submitter": "Ricardo Silva", "authors": "Ricardo Silva, Zoubin Ghahramani", "title": "Bayesian Inference for Gaussian Mixed Graph Models", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-453-460", "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce priors and algorithms to perform Bayesian inference in Gaussian\nmodels defined by acyclic directed mixed graphs. Such a class of graphs,\ncomposed of directed and bi-directed edges, is a representation of conditional\nindependencies that is closed under marginalization and arises naturally from\ncausal models which allow for unmeasured confounding. Monte Carlo methods and a\nvariational approximation for such models are presented. Our algorithms for\nBayesian inference allow the evaluation of posterior distributions for several\nquantities of interest, including causal effects that are not identifiable from\ndata alone but could otherwise be inferred where informative prior knowledge\nabout confounding is available.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:30:29 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Silva", "Ricardo", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "1206.6875", "submitter": "Tomi Silander", "authors": "Tomi Silander, Petri Myllymaki", "title": "A simple approach for finding the globally optimal Bayesian network\n  structure", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-445-452", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning the best Bayesian network structure with\nrespect to a decomposable score such as BDe, BIC or AIC. This problem is known\nto be NP-hard, which means that solving it becomes quickly infeasible as the\nnumber of variables increases. Nevertheless, in this paper we show that it is\npossible to learn the best Bayesian network structure with over 30 variables,\nwhich covers many practically interesting cases. Our algorithm is less\ncomplicated and more efficient than the techniques presented earlier. It can be\neasily parallelized, and offers a possibility for efficient exploration of the\nbest networks consistent with different variable orderings. In the experimental\npart of the paper we compare the performance of the algorithm to the previous\nstate-of-the-art algorithm. Free source-code and an online-demo can be found at\nhttp://b-course.hiit.fi/bene.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:30:42 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Silander", "Tomi", ""], ["Myllymaki", "Petri", ""]]}, {"id": "1206.6876", "submitter": "Ilya Shpitser", "authors": "Ilya Shpitser, Judea Pearl", "title": "Identification of Conditional Interventional Distributions", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-437-444", "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The subject of this paper is the elucidation of effects of actions from\ncausal assumptions represented as a directed graph, and statistical knowledge\ngiven as a probability distribution. In particular, we are interested in\npredicting conditional distributions resulting from performing an action on a\nset of variables and, subsequently, taking measurements of another set. We\nprovide a necessary and sufficient graphical condition for the cases where such\ndistributions can be uniquely computed from the available information, as well\nas an algorithm which performs this computation whenever the condition holds.\nFurthermore, we use our results to prove completeness of do-calculus [Pearl,\n1995] for the same identification problem.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:30:55 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Shpitser", "Ilya", ""], ["Pearl", "Judea", ""]]}, {"id": "1206.6877", "submitter": "Prakash P. Shenoy", "authors": "Prakash P. Shenoy", "title": "Inference in Hybrid Bayesian Networks Using Mixtures of Gaussians", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-428-436", "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main goal of this paper is to describe a method for exact inference in\ngeneral hybrid Bayesian networks (BNs) (with a mixture of discrete and\ncontinuous chance variables). Our method consists of approximating general\nhybrid Bayesian networks by a mixture of Gaussians (MoG) BNs. There exists a\nfast algorithm by Lauritzen-Jensen (LJ) for making exact inferences in MoG\nBayesian networks, and there exists a commercial implementation of this\nalgorithm. However, this algorithm can only be used for MoG BNs. Some\nlimitations of such networks are as follows. All continuous chance variables\nmust have conditional linear Gaussian distributions, and discrete chance nodes\ncannot have continuous parents. The methods described in this paper will enable\nus to use the LJ algorithm for a bigger class of hybrid Bayesian networks. This\nincludes networks with continuous chance nodes with non-Gaussian distributions,\nnetworks with no restrictions on the topology of discrete and continuous\nvariables, networks with conditionally deterministic variables that are a\nnonlinear function of their continuous parents, and networks with continuous\nchance variables whose variances are functions of their parents.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:31:08 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Shenoy", "Prakash P.", ""]]}, {"id": "1206.6879", "submitter": "Scott Sanner", "authors": "Scott Sanner, Craig Boutilier", "title": "Practical Linear Value-approximation Techniques for First-order MDPs", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-409-417", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on approximate linear programming (ALP) techniques for\nfirst-order Markov Decision Processes (FOMDPs) represents the value function\nlinearly w.r.t. a set of first-order basis functions and uses linear\nprogramming techniques to determine suitable weights. This approach offers the\nadvantage that it does not require simplification of the first-order value\nfunction, and allows one to solve FOMDPs independent of a specific domain\ninstantiation. In this paper, we address several questions to enhance the\napplicability of this work: (1) Can we extend the first-order ALP framework to\napproximate policy iteration to address performance deficiencies of previous\napproaches? (2) Can we automatically generate basis functions and evaluate\ntheir impact on value function quality? (3) How can we decompose intractable\nproblems with universally quantified rewards into tractable subproblems? We\npropose answers to these questions along with a number of novel optimizations\nand provide a comparative empirical evaluation on logistics problems from the\nICAPS 2004 Probabilistic Planning Competition.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:31:33 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Sanner", "Scott", ""], ["Boutilier", "Craig", ""]]}, {"id": "1206.7051", "submitter": "David Blei", "authors": "Matt Hoffman, David M. Blei, Chong Wang, John Paisley", "title": "Stochastic Variational Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop stochastic variational inference, a scalable algorithm for\napproximating posterior distributions. We develop this technique for a large\nclass of probabilistic models and we demonstrate it with two probabilistic\ntopic models, latent Dirichlet allocation and the hierarchical Dirichlet\nprocess topic model. Using stochastic variational inference, we analyze several\nlarge collections of documents: 300K articles from Nature, 1.8M articles from\nThe New York Times, and 3.8M articles from Wikipedia. Stochastic inference can\neasily handle data sets of this size and outperforms traditional variational\ninference, which can only handle a smaller subset. (We also show that the\nBayesian nonparametric topic model outperforms its parametric counterpart.)\nStochastic variational inference lets us apply complex Bayesian models to\nmassive data sets.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2012 15:23:11 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2013 15:40:02 GMT"}, {"version": "v3", "created": "Mon, 22 Apr 2013 20:23:40 GMT"}], "update_date": "2013-04-24", "authors_parsed": [["Hoffman", "Matt", ""], ["Blei", "David M.", ""], ["Wang", "Chong", ""], ["Paisley", "John", ""]]}, {"id": "1206.7064", "submitter": "Mladen Nikolic", "authors": "Milena Vujosevic-Janicic, Mladen Nikolic, Dusan Tosic, Viktor Kuncak", "title": "Software Verification and Graph Similarity for Automated Evaluation of\n  Students' Assignments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we promote introducing software verification and control flow\ngraph similarity measurement in automated evaluation of students' programs. We\npresent a new grading framework that merges results obtained by combination of\nthese two approaches with results obtained by automated testing, leading to\nimproved quality and precision of automated grading. These two approaches are\nalso useful in providing a comprehensible feedback that can help students to\nimprove the quality of their programs We also present our corresponding tools\nthat are publicly available and open source. The tools are based on LLVM\nlow-level intermediate code representation, so they could be applied to a\nnumber of programming languages. Experimental evaluation of the proposed\ngrading framework is performed on a corpus of university students' programs\nwritten in programming language C. Results of the experiments show that\nautomatically generated grades are highly correlated with manually determined\ngrades suggesting that the presented tools can find real-world applications in\nstudying and grading.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2012 16:10:20 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Vujosevic-Janicic", "Milena", ""], ["Nikolic", "Mladen", ""], ["Tosic", "Dusan", ""], ["Kuncak", "Viktor", ""]]}]