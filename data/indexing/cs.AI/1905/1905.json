[{"id": "1905.00122", "submitter": "Li Chen", "authors": "Li Chen, Carter Yagemann, Evan Downing", "title": "To believe or not to believe: Validating explanation fidelity for\n  dynamic malware analysis", "comments": "Accepted at the IEEE Computer Vision Pattern Recognition 2019\n  Explainable AI Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Converting malware into images followed by vision-based deep learning\nalgorithms has shown superior threat detection efficacy compared with classical\nmachine learning algorithms. When malware are visualized as images,\nvisual-based interpretation schemes can also be applied to extract insights of\nwhy individual samples are classified as malicious. In this work, via two case\nstudies of dynamic malware classification, we extend the local interpretable\nmodel-agnostic explanation algorithm to explain image-based dynamic malware\nclassification and examine its interpretation fidelity. For both case studies,\nwe first train deep learning models via transfer learning on malware images,\ndemonstrate high classification effectiveness, apply an explanation method on\nthe images, and correlate the results back to the samples to validate whether\nthe algorithmic insights are consistent with security domain expertise. In our\nfirst case study, the interpretation framework identifies indirect calls that\nuniquely characterize the underlying exploit behavior of a malware family. In\nour second case study, the interpretation framework extracts insightful\ninformation such as cryptography-related APIs when applied on images created\nfrom API existence, but generate ambiguous interpretation on images created\nfrom API sequences and frequencies. Our findings indicate that current\nimage-based interpretation techniques are promising for explaining vision-based\nmalware classification. We continue to develop image-based interpretation\nschemes specifically for security applications.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 22:45:30 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Chen", "Li", ""], ["Yagemann", "Carter", ""], ["Downing", "Evan", ""]]}, {"id": "1905.00136", "submitter": "Xiaolong Ma", "authors": "Xiaolong Ma, Geng Yuan, Sheng Lin, Zhengang Li, Hao Sun, Yanzhi Wang", "title": "ResNet Can Be Pruned 60x: Introducing Network Purification and Unused\n  Path Removal (P-RM) after Weight Pruning", "comments": "Submitted to ICML workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state-of-art DNN structures involve high computation and great demand for\nmemory storage which pose intensive challenge on DNN framework resources. To\nmitigate the challenges, weight pruning techniques has been studied. However,\nhigh accuracy solution for extreme structured pruning that combines different\ntypes of structured sparsity still waiting for unraveling due to the extremely\nreduced weights in DNN networks. In this paper, we propose a DNN framework\nwhich combines two different types of structured weight pruning (filter and\ncolumn prune) by incorporating alternating direction method of multipliers\n(ADMM) algorithm for better prune performance. We are the first to find\nnon-optimality of ADMM process and unused weights in a structured pruned model,\nand further design an optimization framework which contains the first proposed\nNetwork Purification and Unused Path Removal algorithms which are dedicated to\npost-processing an structured pruned model after ADMM steps. Some high lights\nshows we achieve 232x compression on LeNet-5, 60x compression on ResNet-18\nCIFAR-10 and over 5x compression on AlexNet. We share our models at anonymous\nlink http://bit.ly/2VJ5ktv.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 23:40:51 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Ma", "Xiaolong", ""], ["Yuan", "Geng", ""], ["Lin", "Sheng", ""], ["Li", "Zhengang", ""], ["Sun", "Hao", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1905.00147", "submitter": "Lily Hu", "authors": "Lily Hu and Yiling Chen", "title": "Fair Classification and Social Welfare", "comments": "23 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Now that machine learning algorithms lie at the center of many resource\nallocation pipelines, computer scientists have been unwittingly cast as partial\nsocial planners. Given this state of affairs, important questions follow. What\nis the relationship between fairness as defined by computer scientists and\nnotions of social welfare? In this paper, we present a welfare-based analysis\nof classification and fairness regimes. We translate a loss minimization\nprogram into a social welfare maximization problem with a set of implied\nwelfare weights on individuals and groups--weights that can be analyzed from a\ndistribution justice lens. In the converse direction, we ask what the space of\npossible labelings is for a given dataset and hypothesis class. We provide an\nalgorithm that answers this question with respect to linear hyperplanes in\n$\\mathbb{R}^d$ that runs in $O(n^dd)$. Our main findings on the relationship\nbetween fairness criteria and welfare center on sensitivity analyses of\nfairness-constrained empirical risk minimization programs. We characterize the\nranges of $\\Delta \\epsilon$ perturbations to a fairness parameter $\\epsilon$\nthat yield better, worse, and neutral outcomes in utility for individuals and\nby extension, groups. We show that applying more strict fairness criteria that\nare codified as parity constraints, can worsen welfare outcomes for both\ngroups. More generally, always preferring \"more fair\" classifiers does not\nabide by the Pareto Principle---a fundamental axiom of social choice theory and\nwelfare economics. Recent work in machine learning has rallied around these\nnotions of fairness as critical to ensuring that algorithmic systems do not\nhave disparate negative impact on disadvantaged social groups. By showing that\nthese constraints often fail to translate into improved outcomes for these\ngroups, we cast doubt on their effectiveness as a means to ensure justice.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 01:03:07 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Hu", "Lily", ""], ["Chen", "Yiling", ""]]}, {"id": "1905.00198", "submitter": "Arindam Mitra", "authors": "Arindam Mitra, Peter Clark, Oyvind Tafjord and Chitta Baral", "title": "Declarative Question Answering over Knowledge Bases containing Natural\n  Language Text with Answer Set Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While in recent years machine learning (ML) based approaches have been the\npopular approach in developing end-to-end question answering systems, such\nsystems often struggle when additional knowledge is needed to correctly answer\nthe questions. Proposed alternatives involve translating the question and the\nnatural language text to a logical representation and then use logical\nreasoning. However, this alternative falters when the size of the text gets\nbigger. To address this we propose an approach that does logical reasoning over\npremises written in natural language text. The proposed method uses recent\nfeatures of Answer Set Programming (ASP) to call external NLP modules (which\nmay be based on ML) which perform simple textual entailment. To test our\napproach we develop a corpus based on the life cycle questions and showed that\nOur system achieves up to $18\\%$ performance gain when compared to standard MCQ\nsolvers.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 06:29:02 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Mitra", "Arindam", ""], ["Clark", "Peter", ""], ["Tafjord", "Oyvind", ""], ["Baral", "Chitta", ""]]}, {"id": "1905.00229", "submitter": "Sascha Rosbach", "authors": "Sascha Rosbach, Vinit James, Simon Gro{\\ss}johann, Silviu Homoceanu\n  and Stefan Roth", "title": "Driving with Style: Inverse Reinforcement Learning in General-Purpose\n  Planning for Automated Driving", "comments": "Appeared at IROS 2019. Accepted version. Added/updated footnote,\n  minor correction in preliminaries", "journal-ref": "2019 IEEE/RSJ Int. Conf. on Intelligent Robots and Syst. (IROS),\n  Macau, China, 2019, pp. 2658-2665", "doi": "10.1109/IROS40897.2019.8968205", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Behavior and motion planning play an important role in automated driving.\nTraditionally, behavior planners instruct local motion planners with predefined\nbehaviors. Due to the high scene complexity in urban environments,\nunpredictable situations may occur in which behavior planners fail to match\npredefined behavior templates. Recently, general-purpose planners have been\nintroduced, combining behavior and local motion planning. These general-purpose\nplanners allow behavior-aware motion planning given a single reward function.\nHowever, two challenges arise: First, this function has to map a complex\nfeature space into rewards. Second, the reward function has to be manually\ntuned by an expert. Manually tuning this reward function becomes a tedious\ntask. In this paper, we propose an approach that relies on human driving\ndemonstrations to automatically tune reward functions. This study offers\nimportant insights into the driving style optimization of general-purpose\nplanners with maximum entropy inverse reinforcement learning. We evaluate our\napproach based on the expected value difference between learned and\ndemonstrated policies. Furthermore, we compare the similarity of human driven\ntrajectories with optimal policies of our planner under learned and\nexpert-tuned reward functions. Our experiments show that we are able to learn\nreward functions exceeding the level of manual expert tuning without prior\ndomain knowledge.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 09:18:47 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 14:13:15 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Rosbach", "Sascha", ""], ["James", "Vinit", ""], ["Gro\u00dfjohann", "Simon", ""], ["Homoceanu", "Silviu", ""], ["Roth", "Stefan", ""]]}, {"id": "1905.00270", "submitter": "Xin Liu", "authors": "Hongming Zhang and Xin Liu and Haojie Pan and Yangqiu Song and Cane\n  Wing-Ki Leung", "title": "ASER: A Large-scale Eventuality Knowledge Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding human's language requires complex world knowledge. However,\nexisting large-scale knowledge graphs mainly focus on knowledge about entities\nwhile ignoring knowledge about activities, states, or events, which are used to\ndescribe how entities or things act in the real world. To fill this gap, we\ndevelop ASER (activities, states, events, and their relations), a large-scale\neventuality knowledge graph extracted from more than 11-billion-token\nunstructured textual data. ASER contains 15 relation types belonging to five\ncategories, 194-million unique eventualities, and 64-million unique edges among\nthem. Both intrinsic and extrinsic evaluations demonstrate the quality and\neffectiveness of ASER.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 11:32:13 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 09:10:05 GMT"}, {"version": "v3", "created": "Sat, 25 Jan 2020 10:29:21 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Zhang", "Hongming", ""], ["Liu", "Xin", ""], ["Pan", "Haojie", ""], ["Song", "Yangqiu", ""], ["Leung", "Cane Wing-Ki", ""]]}, {"id": "1905.00328", "submitter": "Hugo Manuel Proen\\c{c}a", "authors": "Hugo M. Proen\\c{c}a and Matthijs van Leeuwen", "title": "Interpretable multiclass classification by MDL-based rule lists", "comments": null, "journal-ref": "Information Sciences 2019", "doi": "10.1016/j.ins.2019.10.050", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretable classifiers have recently witnessed an increase in attention\nfrom the data mining community because they are inherently easier to understand\nand explain than their more complex counterparts. Examples of interpretable\nclassification models include decision trees, rule sets, and rule lists.\nLearning such models often involves optimizing hyperparameters, which typically\nrequires substantial amounts of data and may result in relatively large models.\nIn this paper, we consider the problem of learning compact yet accurate\nprobabilistic rule lists for multiclass classification. Specifically, we\npropose a novel formalization based on probabilistic rule lists and the minimum\ndescription length (MDL) principle. This results in virtually parameter-free\nmodel selection that naturally allows to trade-off model complexity with\ngoodness of fit, by which overfitting and the need for hyperparameter tuning\nare effectively avoided. Finally, we introduce the Classy algorithm, which\ngreedily finds rule lists according to the proposed criterion. We empirically\ndemonstrate that Classy selects small probabilistic rule lists that outperform\nstate-of-the-art classifiers when it comes to the combination of predictive\nperformance and interpretability. We show that Classy is insensitive to its\nonly parameter, i.e., the candidate set, and that compression on the training\nset correlates with classification performance, validating our MDL-based\nselection criterion.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 14:34:33 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 12:49:29 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Proen\u00e7a", "Hugo M.", ""], ["van Leeuwen", "Matthijs", ""]]}, {"id": "1905.00360", "submitter": "Nan Jiang", "authors": "Jinglin Chen, Nan Jiang", "title": "Information-Theoretic Considerations in Batch Reinforcement Learning", "comments": "Published in ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value-function approximation methods that operate in batch mode have\nfoundational importance to reinforcement learning (RL). Finite sample\nguarantees for these methods often crucially rely on two types of assumptions:\n(1) mild distribution shift, and (2) representation conditions that are\nstronger than realizability. However, the necessity (\"why do we need them?\")\nand the naturalness (\"when do they hold?\") of such assumptions have largely\neluded the literature. In this paper, we revisit these assumptions and provide\ntheoretical results towards answering the above questions, and make steps\ntowards a deeper understanding of value-function approximation.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 16:19:28 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Chen", "Jinglin", ""], ["Jiang", "Nan", ""]]}, {"id": "1905.00453", "submitter": "Thanh Tran", "authors": "Thanh Tran, Xinyue Liu, Kyumin Lee, Xiangnan Kong", "title": "Signed Distance-based Deep Memory Recommender", "comments": null, "journal-ref": "Proceedings of the 2019 World Wide Web Conference", "doi": "10.1145/3308558.3313460", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalized recommendation algorithms learn a user's preference for an item\nby measuring a distance/similarity between them. However, some of the existing\nrecommendation models (e.g., matrix factorization) assume a linear relationship\nbetween the user and item. This approach limits the capacity of recommender\nsystems, since the interactions between users and items in real-world\napplications are much more complex than the linear relationship. To overcome\nthis limitation, in this paper, we design and propose a deep learning framework\ncalled Signed Distance-based Deep Memory Recommender, which captures non-linear\nrelationships between users and items explicitly and implicitly, and work well\nin both general recommendation task and shopping basket-based recommendation\ntask. Through an extensive empirical study on six real-world datasets in the\ntwo recommendation tasks, our proposed approach achieved significant\nimprovement over ten state-of-the-art recommendation models.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 19:07:22 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Tran", "Thanh", ""], ["Liu", "Xinyue", ""], ["Lee", "Kyumin", ""], ["Kong", "Xiangnan", ""]]}, {"id": "1905.00501", "submitter": "Ricardo Vinuesa", "authors": "Ricardo Vinuesa, Hossein Azizpour, Iolanda Leite, Madeline Balaam,\n  Virginia Dignum, Sami Domisch, Anna Fell\\\"ander, Simone Langhans, Max Tegmark\n  and Francesco Fuso Nerini", "title": "The role of artificial intelligence in achieving the Sustainable\n  Development Goals", "comments": null, "journal-ref": null, "doi": "10.1038/s41467-019-14108-y", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of artificial intelligence (AI) and its progressively wider\nimpact on many sectors across the society requires an assessment of its effect\non sustainable development. Here we analyze published evidence of positive or\nnegative impacts of AI on the achievement of each of the 17 goals and 169\ntargets of the 2030 Agenda for Sustainable Development. We find that AI can\nsupport the achievement of 128 targets across all SDGs, but it may also inhibit\n58 targets. Notably, AI enables new technologies that improve efficiency and\nproductivity, but it may also lead to increased inequalities among and within\ncountries, thus hindering the achievement of the 2030 Agenda. The fast\ndevelopment of AI needs to be supported by appropriate policy and regulation.\nOtherwise, it would lead to gaps in transparency, accountability, safety and\nethical standards of AI-based technology, which could be detrimental towards\nthe development and sustainable use of AI. Finally, there is a lack of research\nassessing the medium- and long-term impacts of AI. It is therefore essential to\nreinforce the global debate regarding the use of AI and to develop the\nnecessary regulatory insight and oversight for AI-based technologies.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 08:43:50 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Vinuesa", "Ricardo", ""], ["Azizpour", "Hossein", ""], ["Leite", "Iolanda", ""], ["Balaam", "Madeline", ""], ["Dignum", "Virginia", ""], ["Domisch", "Sami", ""], ["Fell\u00e4nder", "Anna", ""], ["Langhans", "Simone", ""], ["Tegmark", "Max", ""], ["Nerini", "Francesco Fuso", ""]]}, {"id": "1905.00502", "submitter": "David Paulius", "authors": "David Paulius, Kelvin Sheng Pei Dong and Yu Sun", "title": "Task Planning with a Weighted Functional Object-Oriented Network", "comments": "ICRA 2021 Submission -- 7 Pages, Accepted to Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reality, there is still much to be done for robots to be able to perform\nmanipulation actions with full autonomy. Complicated manipulation tasks, such\nas cooking, may still require a person to perform some actions that are very\nrisky for a robot to perform. On the other hand, some other actions may be very\nrisky for a human with physical disabilities to perform. Therefore, it is\nnecessary to balance the workload of a robot and a human based on their\nlimitations while minimizing the effort needed from a human in a collaborative\nrobot (cobot) set-up. This paper proposes a new version of our functional\nobject-oriented network (FOON) that integrates weights in its functional units\nto reflect a robot's chance of successfully executing an action of that\nfunctional unit. The paper also presents a task planning algorithm for the\nweighted FOON to allocate manipulation action load to the robot and human to\nachieve optimal performance while minimizing human effort. Through a number of\nexperiments, this paper shows several successful cases in which using the\nproposed weighted FOON and the task planning algorithm allow a robot and a\nhuman to successfully complete complicated tasks together with higher success\nrates than a robot doing them alone.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 21:18:43 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 04:29:36 GMT"}, {"version": "v3", "created": "Sat, 28 Nov 2020 11:06:29 GMT"}, {"version": "v4", "created": "Thu, 25 Mar 2021 22:19:37 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Paulius", "David", ""], ["Dong", "Kelvin Sheng Pei", ""], ["Sun", "Yu", ""]]}, {"id": "1905.00517", "submitter": "Yu Zhang", "authors": "Yu Zhang and Li Wang", "title": "From Abstractions to \"Natural Languages\" for Coordinating Planning\n  Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite significant advancements in developing autonomous agents,\ncommunication between them often relies on a set of pre-specified symbols for a\ngiven domain. In this paper, we investigate the automatic construction of these\nsymbols from abstractions to form \"natural languages\" for such agents. The\nfocus of this initial investigation is on a task planning setting where one\nagent (the speaker) directly communicates a \"plan sketch\" to another agent (the\nlistener) to achieve coordination. In contrast to prior work, we view language\nformation as a fundamental requirement for resolving miscoordination. This view\nenables us to \"compute\" a language from the ground up by mapping physical\nstates to symbols, thus reverse engineering the function of languages.\nLanguages that arise from this process are only approximately expressive of the\nactual plans, meaning that they specify abstractions over the plan space, which\nis not only theoretically appealing as it provides the desired flexibility to\nthe listener to choose its plan during execution, but also practically useful\nsince it both reduces the communication cost of the speaker and computational\ncost of the listener. We formulate this language construction problem and show\nthat it is NEXP-complete. An approximate solution is then developed to relate\nthis problem to task planning problems that have efficient off-the-shelf\nsolutions. Finally, we discuss a multi-agent path-finding domain in our\nevaluation to provide a comprehensive set of results to illustrate the benefits\nof the constructed languages and their applications.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 22:05:42 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 02:16:19 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Zhang", "Yu", ""], ["Wang", "Li", ""]]}, {"id": "1905.00532", "submitter": "Andrea Bajcsy", "authors": "Andrea Bajcsy, Somil Bansal, Eli Bronstein, Varun Tolani, Claire J.\n  Tomlin", "title": "An Efficient Reachability-Based Framework for Provably Safe Autonomous\n  Navigation in Unknown Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world autonomous vehicles often operate in a priori unknown\nenvironments. Since most of these systems are safety-critical, it is important\nto ensure they operate safely in the face of environment uncertainty, such as\nunseen obstacles. Current safety analysis tools enable autonomous systems to\nreason about safety given full information about the state of the environment a\npriori. However, these tools do not scale well to scenarios where the\nenvironment is being sensed in real time, such as during navigation tasks. In\nthis work, we propose a novel, real-time safety analysis method based on\nHamilton-Jacobi reachability that provides strong safety guarantees despite\nenvironment uncertainty. Our safety method is planner-agnostic and provides\nguarantees for a variety of mapping sensors. We demonstrate our approach in\nsimulation and in hardware to provide safety guarantees around a\nstate-of-the-art vision-based, learning-based planner.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 23:55:41 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Bajcsy", "Andrea", ""], ["Bansal", "Somil", ""], ["Bronstein", "Eli", ""], ["Tolani", "Varun", ""], ["Tomlin", "Claire J.", ""]]}, {"id": "1905.00537", "submitter": "Alex Wang", "authors": "Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian\n  Michael, Felix Hill, Omer Levy, Samuel R. Bowman", "title": "SuperGLUE: A Stickier Benchmark for General-Purpose Language\n  Understanding Systems", "comments": "NeurIPS 2019, super.gluebenchmark.com updating acknowledegments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last year, new models and methods for pretraining and transfer\nlearning have driven striking performance improvements across a range of\nlanguage understanding tasks. The GLUE benchmark, introduced a little over one\nyear ago, offers a single-number metric that summarizes progress on a diverse\nset of such tasks, but performance on the benchmark has recently surpassed the\nlevel of non-expert humans, suggesting limited headroom for further research.\nIn this paper we present SuperGLUE, a new benchmark styled after GLUE with a\nnew set of more difficult language understanding tasks, a software toolkit, and\na public leaderboard. SuperGLUE is available at super.gluebenchmark.com.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 00:41:50 GMT"}, {"version": "v2", "created": "Fri, 12 Jul 2019 14:53:39 GMT"}, {"version": "v3", "created": "Thu, 13 Feb 2020 00:28:00 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Wang", "Alex", ""], ["Pruksachatkun", "Yada", ""], ["Nangia", "Nikita", ""], ["Singh", "Amanpreet", ""], ["Michael", "Julian", ""], ["Hill", "Felix", ""], ["Levy", "Omer", ""], ["Bowman", "Samuel R.", ""]]}, {"id": "1905.00547", "submitter": "George Cevora", "authors": "George Cevora", "title": "The relationship between Biological and Artificial Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intelligence can be defined as a predominantly human ability to accomplish\ntasks that are generally hard for computers and animals. Artificial\nIntelligence [AI] is a field attempting to accomplish such tasks with\ncomputers. AI is becoming increasingly widespread, as are claims of its\nrelationship with Biological Intelligence. Often these claims are made to imply\nhigher chances of a given technology succeeding, working on the assumption that\nAI systems which mimic the mechanisms of Biological Intelligence should be more\nsuccessful.\n  In this article I will discuss the similarities and differences between AI\nand the extent of our knowledge about the mechanisms of intelligence in\nbiology, especially within humans. I will also explore the validity of the\nassumption that biomimicry in AI systems aids their advancement, and I will\nargue that existing similarity to biological systems in the way Artificial\nNeural Networks [ANNs] tackle tasks is due to design decisions, rather than\ninherent similarity of underlying mechanisms. This article is aimed at people\nwho understand the basics of AI (especially ANNs), and would like to be better\nable to evaluate the often wild claims about the value of biomimicry in AI.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 13:41:35 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Cevora", "George", ""]]}, {"id": "1905.00557", "submitter": "Mohammad Jafari", "authors": "Mohammad Jafari, Vahid Sarfi, Amir Ghasemkhani, Hanif Livani, Lei Yang\n  and Hao Xu", "title": "Adaptive Intelligent Secondary Control of Microgrids Using a\n  Biologically-Inspired Reinforcement Learning", "comments": "5 pages, 6 figures, 2019 IEEE Power & Energy Society General Meeting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a biologically-inspired adaptive intelligent secondary\ncontroller is developed for microgrids to tackle system dynamics uncertainties,\nfaults, and/or disturbances. The developed adaptive biologically-inspired\ncontroller adopts a novel computational model of emotional learning in\nmammalian limbic system. The learning capability of the proposed\nbiologically-inspired intelligent controller makes it a promising approach to\ndeal with the power system non-linear and volatile dynamics without increasing\nthe controller complexity, and maintain the voltage and frequency stabilities\nby using an efficient reference tracking mechanism. The performance of the\nproposed intelligent secondary controller is validated in terms of the voltage\nand frequency absolute errors in the simulated microgrid. Simulation results\nhighlight the efficiency and robustness of the proposed intelligent controller\nunder the fault conditions and different system uncertainties compared to other\nbenchmark controllers.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 03:00:08 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Jafari", "Mohammad", ""], ["Sarfi", "Vahid", ""], ["Ghasemkhani", "Amir", ""], ["Livani", "Hanif", ""], ["Yang", "Lei", ""], ["Xu", "Hao", ""]]}, {"id": "1905.00587", "submitter": "Jiachen Li", "authors": "Jiachen Li and Hengbo Ma and Wei Zhan and Masayoshi Tomizuka", "title": "Coordination and Trajectory Prediction for Vehicle Interactions via\n  Bayesian Generative Modeling", "comments": "Accepted by 2019 IEEE Intelligent Vehicles Symposium (IV)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coordination recognition and subtle pattern prediction of future trajectories\nplay a significant role when modeling interactive behaviors of multiple agents.\nDue to the essential property of uncertainty in the future evolution,\ndeterministic predictors are not sufficiently safe and robust. In order to\ntackle the task of probabilistic prediction for multiple, interactive entities,\nwe propose a coordination and trajectory prediction system (CTPS), which has a\nhierarchical structure including a macro-level coordination recognition module\nand a micro-level subtle pattern prediction module which solves a probabilistic\ngeneration task. We illustrate two types of representation of the coordination\nvariable: categorized and real-valued, and compare their effects and advantages\nbased on empirical studies. We also bring the ideas of Bayesian deep learning\ninto deep generative models to generate diversified prediction hypotheses. The\nproposed system is tested on multiple driving datasets in various traffic\nscenarios, which achieves better performance than baseline approaches in terms\nof a set of evaluation metrics. The results also show that using categorized\ncoordination can better capture multi-modality and generate more diversified\nsamples than the real-valued coordination, while the latter can generate\nprediction hypotheses with smaller errors with a sacrifice of sample diversity.\nMoreover, employing neural networks with weight uncertainty is able to generate\nsamples with larger variance and diversity.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 06:40:54 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Li", "Jiachen", ""], ["Ma", "Hengbo", ""], ["Zhan", "Wei", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1905.00607", "submitter": "Mohsen Annabestani", "authors": "Mohsen Annabestani, Alireza Rowhanimanesh, Akram Rezaei, Ladan\n  Avazpour, Fatemeh Sheikhhasani", "title": "A knowledge-based intelligent system for control of dirt recognition\n  process in the smart washing machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an intelligence approach based on fuzzy logic to\nmodeling human intelligence in washing clothes. At first, an intelligent\nfeedback loop is designed for perception-based sensing of dirt inspired by\nhuman color understanding. Then, when color stains leak out of some colored\nclothes the human probabilistic decision making is computationally modeled to\ndetect this stain leakage and thus the problem of recognizing dirt from stain\ncan be considered in the washing process. Finally, we discuss the fuzzy control\nof washing clothes and design and simulate a smart controller based on the\nfuzzy intelligence feedback loop.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 08:05:59 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 09:38:56 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Annabestani", "Mohsen", ""], ["Rowhanimanesh", "Alireza", ""], ["Rezaei", "Akram", ""], ["Avazpour", "Ladan", ""], ["Sheikhhasani", "Fatemeh", ""]]}, {"id": "1905.00614", "submitter": "Ross Gruetzemacher", "authors": "Ross Gruetzemacher, David Paradice", "title": "Alternative Techniques for Mapping Paths to HLAI", "comments": "7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The only systematic mapping of the HLAI technical landscape was conducted at\na workshop in 2009 [Adams et al., 2012]. However, the results from it were not\nwhat organizers had hoped for [Goertzel 2014, 2016], merely just a series of\nmilestones, up to 50% of which could be argued to have been completed already.\nWe consider two more recent articles outlining paths to human-like intelligence\n[Mikolov et al., 2016; Lake et al., 2017]. These offer technical and more\nrefined assessments of the requirements for HLAI rather than just milestones.\nWhile useful, they also have limitations. To address these limitations we\npropose the use of alternative techniques for an updated systematic mapping of\nthe paths to HLAI. The newly proposed alternative techniques can model complex\npaths of future technologies using intricate directed graphs. Specifically,\nthere are two classes of alternative techniques that we consider: scenario\nmapping methods and techniques for eliciting expert opinion through digital\nplatforms and crowdsourcing. We assess the viability and utility of both the\nprevious and alternative techniques, finding that the proposed alternative\ntechniques could be very beneficial in advancing the existing body of knowledge\non the plausible frameworks for creating HLAI. In conclusion, we encourage\ndiscussion and debate to initiate efforts to use these proposed techniques for\nmapping paths to HLAI.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 08:26:36 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Gruetzemacher", "Ross", ""], ["Paradice", "David", ""]]}, {"id": "1905.00629", "submitter": "Reshef Meir", "authors": "Reshef Meir, Ofra Amir, Omer Ben-Porat, Tsviel Ben-Shabat, Gal\n  Cohensius, Lirong Xia", "title": "General-Domain Truth Discovery via Average Proximity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Truth discovery is a general name for a broad range of statistical methods\naimed to extract the correct answers to questions, based on multiple answers\ncoming from noisy sources. For example, workers in a crowdsourcing platform. In\nthis paper, we suggest a simple heuristic for estimating workers' competence\nusing average proximity to other workers. We prove that this estimates well the\nactual competence level and enables separating high and low quality workers in\na wide spectrum of domains and statistical models.\n  We then design a simple proximity-based truth discovery algorithm (\\PTD) that\nweighs workers according to their average proximity. The answers for questions\nmay be of different forms such as real-valued, categorical, rankings, or other\ncomplex labels, and \\PTD can be combined with any existing aggregation function\nor voting rule to improve their accuracy.\n  We demonstrate through an extensive empirical study on real and synthetic\ndata that \\PTD and its iterative variants outperform other heuristics and\nstate-of-the-art truth discovery methods in the above domains.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 09:13:08 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 13:49:17 GMT"}, {"version": "v3", "created": "Mon, 15 Feb 2021 11:31:16 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Meir", "Reshef", ""], ["Amir", "Ofra", ""], ["Ben-Porat", "Omer", ""], ["Ben-Shabat", "Tsviel", ""], ["Cohensius", "Gal", ""], ["Xia", "Lirong", ""]]}, {"id": "1905.00646", "submitter": "Lisa Andreevna Chalaguine", "authors": "Lisa A. Chalaguine, Anthony Hunter, Fiona L. Hamilton, Henry W. W.\n  Potts", "title": "Impact of Argument Type and Concerns in Argumentation with a Chatbot", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational agents, also known as chatbots, are versatile tools that have\nthe potential of being used in dialogical argumentation. They could possibly be\ndeployed in tasks such as persuasion for behaviour change (e.g. persuading\npeople to eat more fruit, to take regular exercise, etc.) However, to achieve\nthis, there is a need to develop methods for acquiring appropriate arguments\nand counterargument that reflect both sides of the discussion. For instance, to\npersuade someone to do regular exercise, the chatbot needs to know\ncounterarguments that the user might have for not doing exercise. To address\nthis need, we present methods for acquiring arguments and counterarguments, and\nimportantly, meta-level information that can be useful for deciding when\narguments can be used during an argumentation dialogue. We evaluate these\nmethods in studies with participants and show how harnessing these methods in a\nchatbot can make it more persuasive.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 09:53:24 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Chalaguine", "Lisa A.", ""], ["Hunter", "Anthony", ""], ["Hamilton", "Fiona L.", ""], ["Potts", "Henry W. W.", ""]]}, {"id": "1905.00719", "submitter": "Rongpeng Li", "authors": "Rongpeng Li, Zhifeng Zhao, Xing Xu, Fei Ni, and Honggang Zhang", "title": "Internet of Intelligence: The Collective Advantage for Advancing\n  Communications and Intelligence", "comments": "6 figures; accepted by IEEE Wireless Commun with the title \"The\n  Collective Advantage for Advancing Communications and Intelligence\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The fifth-generation cellular networks (5G) has boosted the unprecedented\nconvergence between the information world and physical world. On the other\nhand, empowered with the enormous amount of data and information, artificial\nintelligence (AI) has been universally applied and pervasive AI is believed to\nbe an integral part of the six-generation cellular networks (6G). Consequently,\nbenefiting from the advancement in communication technology and AI, we boldly\nargue that the conditions for collective intelligence (CI) will be mature in\nthe 6G era and CI will emerge among the widely connected beings and things.\nAfterwards, we highlight the potential huge impact of CI on both communications\nand intelligence. In particular, we introduce a regular language (i.e., the\ninformation economy metalanguage) supporting the future collective\ncommunications to augment human intelligence and explain its potential\napplications in naming Internet information and pushing information centric\nnetworks forward. Meanwhile, we propose a stigmergy-based federated collective\nintelligence and demonstrate its achievement in a simulated scenario where the\nagents collectively work together to form a pattern through simple indirect\ncommunications. In a word, CI could advance both communications and\nintelligence.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 09:09:56 GMT"}, {"version": "v2", "created": "Sun, 5 May 2019 01:37:31 GMT"}, {"version": "v3", "created": "Thu, 9 May 2019 02:18:12 GMT"}, {"version": "v4", "created": "Sun, 12 May 2019 00:09:37 GMT"}, {"version": "v5", "created": "Thu, 10 Oct 2019 02:56:50 GMT"}, {"version": "v6", "created": "Thu, 16 Apr 2020 14:06:33 GMT"}, {"version": "v7", "created": "Sat, 18 Apr 2020 08:25:18 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Li", "Rongpeng", ""], ["Zhao", "Zhifeng", ""], ["Xu", "Xing", ""], ["Ni", "Fei", ""], ["Zhang", "Honggang", ""]]}, {"id": "1905.00741", "submitter": "Janne Karttunen", "authors": "Janne Karttunen, Anssi Kanervisto, Ville Kyrki, Ville Hautam\\\"aki", "title": "From Video Game to Real Robot: The Transfer between Action Spaces", "comments": "Two first authors contributed equally. Accepted by ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has proven to be successful for learning tasks in\nsimulated environments, but applying same techniques for robots in real-world\ndomain is more challenging, as they require hours of training. To address this,\ntransfer learning can be used to train the policy first in a simulated\nenvironment and then transfer it to physical agent. As the simulation never\nmatches reality perfectly, the physics, visuals and action spaces by necessity\ndiffer between these environments to some degree. In this work, we study how\ngeneral video games can be directly used instead of fine-tuned simulations for\nthe sim-to-real transfer. Especially, we study how the agent can learn the new\naction space autonomously, when the game actions do not match the robot\nactions. Our results show that the different action space can be learned by\nre-training only part of neural network and we obtain above 90% mean success\nrate in simulation and robot experiments.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 13:42:51 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 11:39:51 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Karttunen", "Janne", ""], ["Kanervisto", "Anssi", ""], ["Kyrki", "Ville", ""], ["Hautam\u00e4ki", "Ville", ""]]}, {"id": "1905.00753", "submitter": "Gang Huang", "authors": "Chao Wu, Jun Xiao, Gang Huang, Fei Wu", "title": "Galaxy Learning -- A Position Paper", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent rapid development of artificial intelligence (AI, mainly driven by\nmachine learning research, especially deep learning) has achieved phenomenal\nsuccess in various applications. However, to further apply AI technologies in\nreal-world context, several significant issues regarding the AI ecosystem\nshould be addressed. We identify the main issues as data privacy, ownership,\nand exchange, which are difficult to be solved with the current centralized\nparadigm of machine learning training methodology. As a result, we propose a\nnovel model training paradigm based on blockchain, named Galaxy Learning, which\naims to train a model with distributed data and to reserve the data ownership\nfor their owners. In this new paradigm, encrypted models are moved around\ninstead, and are federated once trained. Model training, as well as the\ncommunication, is achieved with blockchain and its smart contracts. Pricing of\ntraining data is determined by its contribution, and therefore it is not about\nthe exchange of data ownership. In this position paper, we describe the\nmotivation, paradigm, design, and challenges as well as opportunities of Galaxy\nLearning.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 11:05:26 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Wu", "Chao", ""], ["Xiao", "Jun", ""], ["Huang", "Gang", ""], ["Wu", "Fei", ""]]}, {"id": "1905.00787", "submitter": "Christoph Benzm\\\"uller", "authors": "Daniel Kirchner, Christoph Benzm\\\"uller, Edward N. Zalta", "title": "Computer Science and Metaphysics: A Cross-Fertilization", "comments": "39 pages, 3 figures", "journal-ref": "Open Philosophy, 2019", "doi": "10.1515/opphil-2019-0015", "report-no": null, "categories": "cs.LO cs.AI cs.CL math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational philosophy is the use of mechanized computational techniques to\nunearth philosophical insights that are either difficult or impossible to find\nusing traditional philosophical methods. Computational metaphysics is\ncomputational philosophy with a focus on metaphysics. In this paper, we (a)\ndevelop results in modal metaphysics whose discovery was computer assisted, and\n(b) conclude that these results work not only to the obvious benefit of\nphilosophy but also, less obviously, to the benefit of computer science, since\nthe new computational techniques that led to these results may be more broadly\napplicable within computer science. The paper includes a description of our\nbackground methodology and how it evolved, and a discussion of our new results.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 16:51:32 GMT"}, {"version": "v2", "created": "Sat, 15 Jun 2019 07:23:18 GMT"}, {"version": "v3", "created": "Thu, 27 Jun 2019 08:32:06 GMT"}, {"version": "v4", "created": "Sun, 11 Aug 2019 12:47:34 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Kirchner", "Daniel", ""], ["Benzm\u00fcller", "Christoph", ""], ["Zalta", "Edward N.", ""]]}, {"id": "1905.00840", "submitter": "EPTCS", "authors": "Tiantian Gao (Stony Brook University)", "title": "Knowledge Authoring and Question Answering with KALM", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646", "journal-ref": "EPTCS 306, 2019, pp. 389-395", "doi": "10.4204/EPTCS.306.52", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge representation and reasoning (KRR) is one of the key areas in\nartificial intelligence (AI) field. It is intended to represent the world\nknowledge in formal languages (e.g., Prolog, SPARQL) and then enhance the\nexpert systems to perform querying and inference tasks. Currently, constructing\nlarge scale knowledge bases (KBs) with high quality is prohibited by the fact\nthat the construction process requires many qualified knowledge engineers who\nnot only understand the domain-specific knowledge but also have sufficient\nskills in knowledge representation. Unfortunately, qualified knowledge\nengineers are in short supply. Therefore, it would be very useful to build a\ntool that allows the user to construct and query the KB simply via text.\nAlthough there is a number of systems developed for knowledge extraction and\nquestion answering, they mainly fail in that these system don't achieve high\nenough accuracy whereas KRR is highly sensitive to erroneous data. In this\nthesis proposal, I will present Knowledge Authoring Logic Machine (KALM), a\nrule-based system which allows the user to author knowledge and query the KB in\ntext. The experimental results show that KALM achieved superior accuracy in\nknowledge authoring and question answering as compared to the state-of-the-art\nsystems.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 16:39:55 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 15:27:01 GMT"}, {"version": "v3", "created": "Wed, 18 Sep 2019 07:13:08 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Gao", "Tiantian", "", "Stony Brook University"]]}, {"id": "1905.00921", "submitter": "Jihwan Lee", "authors": "Han Li, Jihwan Lee, Sidharth Mudgal, Ruhi Sarikaya, Young-Bum Kim", "title": "Continuous Learning for Large-scale Personalized Domain Classification", "comments": "NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain classification is the task of mapping spoken language utterances to\none of the natural language understanding domains in intelligent personal\ndigital assistants (IPDAs). This is a major component in mainstream IPDAs in\nindustry. Apart from official domains, thousands of third-party domains are\nalso created by external developers to enhance the capability of IPDAs. As more\ndomains are developed rapidly, the question of how to continuously accommodate\nthe new domains still remains challenging. Moreover, existing continual\nlearning approaches do not address the problem of incorporating personalized\ninformation dynamically for better domain classification. In this paper, we\npropose CoNDA, a neural network based approach for domain classification that\nsupports incremental learning of new classes. Empirical evaluation shows that\nCoNDA achieves high accuracy and outperforms baselines by a large margin on\nboth incrementally added new domains and existing domains.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 18:20:01 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Li", "Han", ""], ["Lee", "Jihwan", ""], ["Mudgal", "Sidharth", ""], ["Sarikaya", "Ruhi", ""], ["Kim", "Young-Bum", ""]]}, {"id": "1905.00956", "submitter": "Svetlin Penkov", "authors": "Svetlin Penkov, Subramanian Ramamoorthy", "title": "Learning Programmatically Structured Representations with Perceptor\n  Gradients", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the perceptor gradients algorithm -- a novel approach to learning\nsymbolic representations based on the idea of decomposing an agent's policy\ninto i) a perceptor network extracting symbols from raw observation data and\nii) a task encoding program which maps the input symbols to output actions. We\nshow that the proposed algorithm is able to learn representations that can be\ndirectly fed into a Linear-Quadratic Regulator (LQR) or a general purpose A*\nplanner. Our experimental results confirm that the perceptor gradients\nalgorithm is able to efficiently learn transferable symbolic representations as\nwell as generate new observations according to a semantically meaningful\nspecification.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 20:47:26 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Penkov", "Svetlin", ""], ["Ramamoorthy", "Subramanian", ""]]}, {"id": "1905.00966", "submitter": "Sahand Sharifzadeh", "authors": "Sahand Sharifzadeh, Sina Moayed Baharlou, Max Berrendorf, Rajat Koner,\n  Volker Tresp", "title": "Improving Visual Relation Detection using Depth Maps", "comments": "International Conference on Pattern Recognition 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual relation detection methods rely on object information extracted from\nRGB images such as 2D bounding boxes, feature maps, and predicted class\nprobabilities. We argue that depth maps can additionally provide valuable\ninformation on object relations, e.g. helping to detect not only spatial\nrelations, such as standing behind, but also non-spatial relations, such as\nholding. In this work, we study the effect of using different object features\nwith a focus on depth maps. To enable this study, we release a new synthetic\ndataset of depth maps, VG-Depth, as an extension to Visual Genome (VG). We also\nnote that given the highly imbalanced distribution of relations in VG, typical\nevaluation metrics for visual relation detection cannot reveal improvements of\nunder-represented relations. To address this problem, we propose using an\nadditional metric, calling it Macro Recall@K, and demonstrate its remarkable\nperformance on VG. Finally, our experiments confirm that by effective\nutilization of depth maps within a simple, yet competitive framework, the\nperformance of visual relation detection can be improved by a margin of up to\n8%.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 21:14:35 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 13:33:27 GMT"}, {"version": "v3", "created": "Fri, 24 Jan 2020 15:00:23 GMT"}, {"version": "v4", "created": "Sat, 17 Oct 2020 13:58:38 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Sharifzadeh", "Sahand", ""], ["Baharlou", "Sina Moayed", ""], ["Berrendorf", "Max", ""], ["Koner", "Rajat", ""], ["Tresp", "Volker", ""]]}, {"id": "1905.00976", "submitter": "Somdeb Majumdar", "authors": "Shauharda Khadka, Somdeb Majumdar, Tarek Nassar, Zach Dwiel, Evren\n  Tumer, Santiago Miret, Yinyin Liu, Kagan Tumer", "title": "Collaborative Evolutionary Reinforcement Learning", "comments": "Added link to public Github repo. Minor editorial changes. Order of\n  authors modified to reflect ICML submission", "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, Long Beach, California, PMLR 97, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning algorithms have been successfully applied to a\nrange of challenging control tasks. However, these methods typically struggle\nwith achieving effective exploration and are extremely sensitive to the choice\nof hyperparameters. One reason is that most approaches use a noisy version of\ntheir operating policy to explore - thereby limiting the range of exploration.\nIn this paper, we introduce Collaborative Evolutionary Reinforcement Learning\n(CERL), a scalable framework that comprises a portfolio of policies that\nsimultaneously explore and exploit diverse regions of the solution space. A\ncollection of learners - typically proven algorithms like TD3 - optimize over\nvarying time-horizons leading to this diverse portfolio. All learners\ncontribute to and use a shared replay buffer to achieve greater sample\nefficiency. Computational resources are dynamically distributed to favor the\nbest learners as a form of online algorithm selection. Neuroevolution binds\nthis entire process to generate a single emergent learner that exceeds the\ncapabilities of any individual learner. Experiments in a range of continuous\ncontrol benchmarks demonstrate that the emergent learner significantly\noutperforms its composite learners while remaining overall more\nsample-efficient - notably solving the Mujoco Humanoid benchmark where all of\nits composite learners (TD3) fail entirely in isolation.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 21:45:03 GMT"}, {"version": "v2", "created": "Mon, 6 May 2019 21:44:24 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Khadka", "Shauharda", ""], ["Majumdar", "Somdeb", ""], ["Nassar", "Tarek", ""], ["Dwiel", "Zach", ""], ["Tumer", "Evren", ""], ["Miret", "Santiago", ""], ["Liu", "Yinyin", ""], ["Tumer", "Kagan", ""]]}, {"id": "1905.00988", "submitter": "Liting Sun", "authors": "Liting Sun, Wei Zhan, Ching-Yao Chan and Masayoshi Tomizuka", "title": "Behavior Planning of Autonomous Cars with Social Perception", "comments": "To be appear on the 2019 IEEE Intelligent Vehicles Symposium (IV2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous cars have to navigate in dynamic environment which can be full of\nuncertainties. The uncertainties can come either from sensor limitations such\nas occlusions and limited sensor range, or from probabilistic prediction of\nother road participants, or from unknown social behavior in a new area. To\nsafely and efficiently drive in the presence of these uncertainties, the\ndecision-making and planning modules of autonomous cars should intelligently\nutilize all available information and appropriately tackle the uncertainties so\nthat proper driving strategies can be generated. In this paper, we propose a\nsocial perception scheme which treats all road participants as distributed\nsensors in a sensor network. By observing the individual behaviors as well as\nthe group behaviors, uncertainties of the three types can be updated uniformly\nin a belief space. The updated beliefs from the social perception are then\nexplicitly incorporated into a probabilistic planning framework based on Model\nPredictive Control (MPC). The cost function of the MPC is learned via inverse\nreinforcement learning (IRL). Such an integrated probabilistic planning module\nwith socially enhanced perception enables the autonomous vehicles to generate\nbehaviors which are defensive but not overly conservative, and socially\ncompatible. The effectiveness of the proposed framework is verified in\nsimulation on an representative scenario with sensor occlusions.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 22:45:26 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Sun", "Liting", ""], ["Zhan", "Wei", ""], ["Chan", "Ching-Yao", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1905.00991", "submitter": "Francisco Jacob Avila-Camacho FJ Avila-Camacho", "authors": "Jose de Jesus Rubio, Ramon Silva Ortigoza, Francisco Jacob Avila,\n  Adolfo Melendez and Juan Manuel Stein", "title": "A Fuzzy Inference System for the Identification", "comments": "7 Pages, in Spanish", "journal-ref": "IEEE LATIN AMERICA TRANSACTIONS, VOL. 13, NO. 9, SEPTEMBER 2015", "doi": "10.1109/TLA.2015.7350026", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Odor identification is an important area in a wide range of industries like\ncosmetics, food, beverages and medical diagnosis among others. Odor detection\ncould be done through an array of gas sensors conformed as an electronic nose\nwhere a data acquisition module converts sensor signals to a standard output to\nbe analyzed. To facilitate odors detection a system is required for the\nidentification. This paper presents the results of an automated odor\nidentification process implemented by a fuzzy system and an electronic nose.\nFirst, an electronic nose prototype is manufactured to detect organic compounds\nvapor using an array of five tin dioxide gas sensors, an arduino uno board is\nused as a data acquisition section. Second, an intelligent module with a fuzzy\nsystem is considered for the identification of the signals received by the\nelectronic nose. This solution proposes a system to identify odors by using a\npersonal computer. Results show an acceptable precision.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 23:00:01 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Rubio", "Jose de Jesus", ""], ["Ortigoza", "Ramon Silva", ""], ["Avila", "Francisco Jacob", ""], ["Melendez", "Adolfo", ""], ["Stein", "Juan Manuel", ""]]}, {"id": "1905.01000", "submitter": "Mohamed AlHajri", "authors": "Mohamed I. AlHajri, Nazar T. Ali, Raed M. Shubair", "title": "Indoor Localization for IoT Using Adaptive Feature Selection: A Cascaded\n  Machine Learning Approach", "comments": "13 pages", "journal-ref": null, "doi": "10.1109/LAWP.2019.2915047", "report-no": null, "categories": "eess.SP cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Evolving Internet-of-Things (IoT) applications often require the use of\nsensor-based indoor tracking and positioning, for which the performance is\nsignificantly improved by identifying the type of the surrounding indoor\nenvironment. This identification is of high importance since it leads to higher\nlocalization accuracy. This paper presents a novel method based on a cascaded\ntwo-stage machine learning approach for highly-accurate and robust localization\nin indoor environments using adaptive selection and combination of RF features.\nIn the proposed method, machine learning is first used to identify the type of\nthe surrounding indoor environment. Then, in the second stage, machine learning\nis employed to identify the most appropriate selection and combination of RF\nfeatures that yield the highest localization accuracy. Analysis is based on\nk-Nearest Neighbor (k-NN) machine learning algorithm applied on a real dataset\ngenerated from practical measurements of the RF signal in realistic indoor\nenvironments. Received Signal Strength, Channel Transfer Function, and\nFrequency Coherence Function are the primary RF features being explored and\ncombined. Numerical investigations demonstrate that prediction based on the\nconcatenation of primary RF features enhanced significantly as the localization\naccuracy improved by at least 50% to more than 70%.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 01:34:04 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["AlHajri", "Mohamed I.", ""], ["Ali", "Nazar T.", ""], ["Shubair", "Raed M.", ""]]}, {"id": "1905.01004", "submitter": "Saurabh Verma", "authors": "Saurabh Verma, Zhi-Li Zhang", "title": "Stability and Generalization of Graph Convolutional Neural Networks", "comments": "Accepted at The 25th ACM SIGKDD Conference on Knowledge Discovery and\n  Data Mining (KDD 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by convolutional neural networks on 1D and 2D data, graph\nconvolutional neural networks (GCNNs) have been developed for various learning\ntasks on graph data, and have shown superior performance on real-world\ndatasets. Despite their success, there is a dearth of theoretical explorations\nof GCNN models such as their generalization properties. In this paper, we take\na first step towards developing a deeper theoretical understanding of GCNN\nmodels by analyzing the stability of single-layer GCNN models and deriving\ntheir generalization guarantees in a semi-supervised graph learning setting. In\nparticular, we show that the algorithmic stability of a GCNN model depends upon\nthe largest absolute eigenvalue of its graph convolution filter. Moreover, to\nensure the uniform stability needed to provide strong generalization\nguarantees, the largest absolute eigenvalue must be independent of the graph\nsize. Our results shed new insights on the design of new & improved graph\nconvolution filters with guaranteed algorithmic stability. We evaluate the\ngeneralization gap and stability on various real-world graph datasets and show\nthat the empirical results indeed support our theoretical findings. To the best\nof our knowledge, we are the first to study stability bounds on graph learning\nin a semi-supervised setting and derive generalization bounds for GCNN models.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 02:04:51 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 05:50:52 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Verma", "Saurabh", ""], ["Zhang", "Zhi-Li", ""]]}, {"id": "1905.01034", "submitter": "Yi Sun", "authors": "Daniel Kang and Yi Sun and Tom Brown and Dan Hendrycks and Jacob\n  Steinhardt", "title": "Transfer of Adversarial Robustness Between Perturbation Types", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the transfer of adversarial robustness of deep neural networks\nbetween different perturbation types. While most work on adversarial examples\nhas focused on $L_\\infty$ and $L_2$-bounded perturbations, these do not capture\nall types of perturbations available to an adversary. The present work\nevaluates 32 attacks of 5 different types against models adversarially trained\non a 100-class subset of ImageNet. Our empirical results suggest that\nevaluating on a wide range of perturbation sizes is necessary to understand\nwhether adversarial robustness transfers between perturbation types. We further\ndemonstrate that robustness against one perturbation type may not always imply\nand may sometimes hurt robustness against other perturbation types. In light of\nthese results, we recommend evaluation of adversarial defenses take place on a\ndiverse range of perturbation types and sizes.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 04:51:07 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Kang", "Daniel", ""], ["Sun", "Yi", ""], ["Brown", "Tom", ""], ["Hendrycks", "Dan", ""], ["Steinhardt", "Jacob", ""]]}, {"id": "1905.01047", "submitter": "Brojeshwar Bhowmick", "authors": "Sandika Biswas, Sanjana Sinha, Kavya Gupta and Brojeshwar Bhowmick", "title": "Lifting 2d Human Pose to 3d : A Weakly Supervised Approach", "comments": "Accepted in IJCNN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating 3d human pose from monocular images is a challenging problem due\nto the variety and complexity of human poses and the inherent ambiguity in\nrecovering depth from the single view. Recent deep learning based methods show\npromising results by using supervised learning on 3d pose annotated datasets.\nHowever, the lack of large-scale 3d annotated training data captured under\nin-the-wild settings makes the 3d pose estimation difficult for in-the-wild\nposes. Few approaches have utilized training images from both 3d and 2d pose\ndatasets in a weakly-supervised manner for learning 3d poses in unconstrained\nsettings. In this paper, we propose a method which can effectively predict 3d\nhuman pose from 2d pose using a deep neural network trained in a\nweakly-supervised manner on a combination of ground-truth 3d pose and\nground-truth 2d pose. Our method uses re-projection error minimization as a\nconstraint to predict the 3d locations of body joints, and this is crucial for\ntraining on data where the 3d ground-truth is not present. Since minimizing\nre-projection error alone may not guarantee an accurate 3d pose, we also use\nadditional geometric constraints on skeleton pose to regularize the pose in 3d.\nWe demonstrate the superior generalization ability of our method by\ncross-dataset validation on a challenging 3d benchmark dataset MPI-INF-3DHP\ncontaining in the wild 3d poses.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 06:51:11 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Biswas", "Sandika", ""], ["Sinha", "Sanjana", ""], ["Gupta", "Kavya", ""], ["Bhowmick", "Brojeshwar", ""]]}, {"id": "1905.01058", "submitter": "Andreas Pfeuffer", "authors": "Andreas Pfeuffer and Karina Schulz and Klaus Dietmayer", "title": "Semantic Segmentation of Video Sequences with Convolutional LSTMs", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": "IEEE Intelligent Vehicles Symposium 2019 (IV'19)", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the semantic segmentation approaches have been developed for single\nimage segmentation, and hence, video sequences are currently segmented by\nprocessing each frame of the video sequence separately. The disadvantage of\nthis is that temporal image information is not considered, which improves the\nperformance of the segmentation approach. One possibility to include temporal\ninformation is to use recurrent neural networks. However, there are only a few\napproaches using recurrent networks for video segmentation so far. These\napproaches extend the encoder-decoder network architecture of well-known\nsegmentation approaches and place convolutional LSTM layers between encoder and\ndecoder. However, in this paper it is shown that this position is not optimal,\nand that other positions in the network exhibit better performance. Nowadays,\nstate-of-the-art segmentation approaches rarely use the classical\nencoder-decoder structure, but use multi-branch architectures. These\narchitectures are more complex, and hence, it is more difficult to place the\nrecurrent units at a proper position. In this work, the multi-branch\narchitectures are extended by convolutional LSTM layers at different positions\nand evaluated on two different datasets in order to find the best one. It\nturned out that the proposed approach outperforms the pure CNN-based approach\nfor up to 1.6 percent.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 07:52:32 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Pfeuffer", "Andreas", ""], ["Schulz", "Karina", ""], ["Dietmayer", "Klaus", ""]]}, {"id": "1905.01072", "submitter": "Shangtong Zhang", "authors": "Shangtong Zhang, Wendelin Boehmer, Shimon Whiteson", "title": "Deep Residual Reinforcement Learning", "comments": "AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit residual algorithms in both model-free and model-based\nreinforcement learning settings. We propose the bidirectional target network\ntechnique to stabilize residual algorithms, yielding a residual version of DDPG\nthat significantly outperforms vanilla DDPG in the DeepMind Control Suite\nbenchmark. Moreover, we find the residual algorithm an effective approach to\nthe distribution mismatch problem in model-based planning. Compared with the\nexisting TD($k$) method, our residual-based method makes weaker assumptions\nabout the model and yields a greater performance boost.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 08:38:35 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 17:42:24 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2020 21:38:54 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Zhang", "Shangtong", ""], ["Boehmer", "Wendelin", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1905.01235", "submitter": "Priya Goyal", "authors": "Priya Goyal, Dhruv Mahajan, Abhinav Gupta, Ishan Misra", "title": "Scaling and Benchmarking Self-Supervised Visual Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised learning aims to learn representations from the data itself\nwithout explicit manual supervision. Existing efforts ignore a crucial aspect\nof self-supervised learning - the ability to scale to large amount of data\nbecause self-supervision requires no manual labels. In this work, we revisit\nthis principle and scale two popular self-supervised approaches to 100 million\nimages. We show that by scaling on various axes (including data size and\nproblem 'hardness'), one can largely match or even exceed the performance of\nsupervised pre-training on a variety of tasks such as object detection, surface\nnormal estimation (3D) and visual navigation using reinforcement learning.\nScaling these methods also provides many interesting insights into the\nlimitations of current self-supervised techniques and evaluations. We conclude\nthat current self-supervised methods are not 'hard' enough to take full\nadvantage of large scale data and do not seem to learn effective high level\nsemantic representations. We also introduce an extensive benchmark across 9\ndifferent datasets and tasks. We believe that such a benchmark along with\ncomparable evaluation settings is necessary to make meaningful progress. Code\nis at: https://github.com/facebookresearch/fair_self_supervision_benchmark.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 15:50:51 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 13:08:29 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Goyal", "Priya", ""], ["Mahajan", "Dhruv", ""], ["Gupta", "Abhinav", ""], ["Misra", "Ishan", ""]]}, {"id": "1905.01240", "submitter": "Alexandre Galashov", "authors": "Alexandre Galashov, Siddhant M. Jayakumar, Leonard Hasenclever, Dhruva\n  Tirumala, Jonathan Schwarz, Guillaume Desjardins, Wojciech M. Czarnecki, Yee\n  Whye Teh, Razvan Pascanu, Nicolas Heess", "title": "Information asymmetry in KL-regularized RL", "comments": "Accepted as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real world tasks exhibit rich structure that is repeated across\ndifferent parts of the state space or in time. In this work we study the\npossibility of leveraging such repeated structure to speed up and regularize\nlearning. We start from the KL regularized expected reward objective which\nintroduces an additional component, a default policy. Instead of relying on a\nfixed default policy, we learn it from data. But crucially, we restrict the\namount of information the default policy receives, forcing it to learn reusable\nbehaviors that help the policy learn faster. We formalize this strategy and\ndiscuss connections to information bottleneck approaches and to the variational\nEM algorithm. We present empirical results in both discrete and continuous\naction domains and demonstrate that, for certain tasks, learning a default\npolicy alongside the policy can significantly speed up and improve learning.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 15:59:25 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Galashov", "Alexandre", ""], ["Jayakumar", "Siddhant M.", ""], ["Hasenclever", "Leonard", ""], ["Tirumala", "Dhruva", ""], ["Schwarz", "Jonathan", ""], ["Desjardins", "Guillaume", ""], ["Czarnecki", "Wojciech M.", ""], ["Teh", "Yee Whye", ""], ["Pascanu", "Razvan", ""], ["Heess", "Nicolas", ""]]}, {"id": "1905.01258", "submitter": "Francesco Locatello", "authors": "Francesco Locatello, Michael Tschannen, Stefan Bauer, Gunnar R\\\"atsch,\n  Bernhard Sch\\\"olkopf, Olivier Bachem", "title": "Disentangling Factors of Variation Using Few Labels", "comments": null, "journal-ref": "Eighth International Conference on Learning Representations - ICLR\n  2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning disentangled representations is considered a cornerstone problem in\nrepresentation learning. Recently, Locatello et al. (2019) demonstrated that\nunsupervised disentanglement learning without inductive biases is theoretically\nimpossible and that existing inductive biases and unsupervised methods do not\nallow to consistently learn disentangled representations. However, in many\npractical settings, one might have access to a limited amount of supervision,\nfor example through manual labeling of (some) factors of variation in a few\ntraining examples. In this paper, we investigate the impact of such supervision\non state-of-the-art disentanglement methods and perform a large scale study,\ntraining over 52000 models under well-defined and reproducible experimental\nconditions. We observe that a small number of labeled examples (0.01--0.5\\% of\nthe data set), with potentially imprecise and incomplete labels, is sufficient\nto perform model selection on state-of-the-art unsupervised models. Further, we\ninvestigate the benefit of incorporating supervision into the training process.\nOverall, we empirically validate that with little and imprecise supervision it\nis possible to reliably learn disentangled representations.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 16:23:49 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 13:24:55 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Locatello", "Francesco", ""], ["Tschannen", "Michael", ""], ["Bauer", "Stefan", ""], ["R\u00e4tsch", "Gunnar", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Bachem", "Olivier", ""]]}, {"id": "1905.01296", "submitter": "Nicholas Rhinehart", "authors": "Nicholas Rhinehart, Rowan McAllister, Kris Kitani, Sergey Levine", "title": "PRECOG: PREdiction Conditioned On Goals in Visual Multi-Agent Settings", "comments": "To appear at the IEEE International Conference on Computer Vision\n  (ICCV 2019). Website: https://sites.google.com/view/precog", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For autonomous vehicles (AVs) to behave appropriately on roads populated by\nhuman-driven vehicles, they must be able to reason about the uncertain\nintentions and decisions of other drivers from rich perceptual information.\nTowards these capabilities, we present a probabilistic forecasting model of\nfuture interactions between a variable number of agents. We perform both\nstandard forecasting and the novel task of conditional forecasting, which\nreasons about how all agents will likely respond to the goal of a controlled\nagent (here, the AV). We train models on real and simulated data to forecast\nvehicle trajectories given past positions and LIDAR. Our evaluation shows that\nour model is substantially more accurate in multi-agent driving scenarios\ncompared to existing state-of-the-art. Beyond its general ability to perform\nconditional forecasting queries, we show that our model's predictions of all\nagents improve when conditioned on knowledge of the AV's goal, further\nillustrating its capability to model agent interactions.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 17:54:09 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 19:51:38 GMT"}, {"version": "v3", "created": "Mon, 30 Sep 2019 16:45:21 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Rhinehart", "Nicholas", ""], ["McAllister", "Rowan", ""], ["Kitani", "Kris", ""], ["Levine", "Sergey", ""]]}, {"id": "1905.01303", "submitter": "Marc Brittain", "authors": "Marc Brittain, Peng Wei", "title": "Autonomous Air Traffic Controller: A Deep Multi-Agent Reinforcement\n  Learning Approach", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Air traffic control is a real-time safety-critical decision making process in\nhighly dynamic and stochastic environments. In today's aviation practice, a\nhuman air traffic controller monitors and directs many aircraft flying through\nits designated airspace sector. With the fast growing air traffic complexity in\ntraditional (commercial airliners) and low-altitude (drones and eVTOL aircraft)\nairspace, an autonomous air traffic control system is needed to accommodate\nhigh density air traffic and ensure safe separation between aircraft. We\npropose a deep multi-agent reinforcement learning framework that is able to\nidentify and resolve conflicts between aircraft in a high-density, stochastic,\nand dynamic en-route sector with multiple intersections and merging points. The\nproposed framework utilizes an actor-critic model, A2C that incorporates the\nloss function from Proximal Policy Optimization (PPO) to help stabilize the\nlearning process. In addition we use a centralized learning, decentralized\nexecution scheme where one neural network is learned and shared by all agents\nin the environment. We show that our framework is both scalable and efficient\nfor large number of incoming aircraft to achieve extremely high traffic\nthroughput with safety guarantee. We evaluate our model via extensive\nsimulations in the BlueSky environment. Results show that our framework is able\nto resolve 99.97% and 100% of all conflicts both at intersections and merging\npoints, respectively, in extreme high-density air traffic scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 21:03:27 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Brittain", "Marc", ""], ["Wei", "Peng", ""]]}, {"id": "1905.01320", "submitter": "Neil Rabinowitz", "authors": "Neil C. Rabinowitz", "title": "Meta-learners' learning dynamics are unlike learners'", "comments": "26 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning is a tool that allows us to build sample-efficient learning\nsystems. Here we show that, once meta-trained, LSTM Meta-Learners aren't just\nfaster learners than their sample-inefficient deep learning (DL) and\nreinforcement learning (RL) brethren, but that they actually pursue\nfundamentally different learning trajectories. We study their learning dynamics\non three sets of structured tasks for which the corresponding learning dynamics\nof DL and RL systems have been previously described: linear regression (Saxe et\nal., 2013), nonlinear regression (Rahaman et al., 2018; Xu et al., 2018), and\ncontextual bandits (Schaul et al., 2019). In each case, while\nsample-inefficient DL and RL Learners uncover the task structure in a staggered\nmanner, meta-trained LSTM Meta-Learners uncover almost all task structure\nconcurrently, congruent with the patterns expected from Bayes-optimal inference\nalgorithms. This has implications for research areas wherever the learning\nbehaviour itself is of interest, such as safety, curriculum design, and\nhuman-in-the-loop machine learning.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 18:00:26 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Rabinowitz", "Neil C.", ""]]}, {"id": "1905.01334", "submitter": "Thomas Liao", "authors": "Thomas Liao, Grant Wang, Brian Yang, Rene Lee, Kristofer Pister,\n  Sergey Levine, and Roberto Calandra", "title": "Data-efficient Learning of Morphology and Controller for a Microrobot", "comments": "Accepted at ICRA-2019. 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robot design is often a slow and difficult process requiring the iterative\nconstruction and testing of prototypes, with the goal of sequentially\noptimizing the design. For most robots, this process is further complicated by\nthe need, when validating the capabilities of the hardware to solve the desired\ntask, to already have an appropriate controller, which is in turn designed and\ntuned for the specific hardware. In this paper, we propose a novel approach,\nHPC-BBO, to efficiently and automatically design hardware configurations, and\nevaluate them by also automatically tuning the corresponding controller.\nHPC-BBO is based on a hierarchical Bayesian optimization process which\niteratively optimizes morphology configurations (based on the performance of\nthe previous designs during the controller learning process) and subsequently\nlearns the corresponding controllers (exploiting the knowledge collected from\noptimizing for previous morphologies). Moreover, HPC-BBO can select a \"batch\"\nof multiple morphology designs at once, thus parallelizing hardware validation\nand reducing the number of time-consuming production cycles. We validate\nHPC-BBO on the design of the morphology and controller for a simulated 6-legged\nmicrorobot. Experimental results show that HPC-BBO outperforms multiple\ncompetitive baselines, and yields a $360\\%$ reduction in production cycles over\nstandard Bayesian optimization, thus reducing the hypothetical manufacturing\ntime of our microrobot from 21 to 4 months.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 18:28:12 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Liao", "Thomas", ""], ["Wang", "Grant", ""], ["Yang", "Brian", ""], ["Lee", "Rene", ""], ["Pister", "Kristofer", ""], ["Levine", "Sergey", ""], ["Calandra", "Roberto", ""]]}, {"id": "1905.01360", "submitter": "Pablo Hernandez-Leal", "authors": "Chao Gao, Pablo Hernandez-Leal, Bilal Kartal and Matthew E. Taylor", "title": "Skynet: A Top Deep RL Agent in the Inaugural Pommerman Team Competition", "comments": "4th Multidisciplinary Conference on Reinforcement Learning and\n  Decision Making", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Pommerman Team Environment is a recently proposed benchmark which\ninvolves a multi-agent domain with challenges such as partial observability,\ndecentralized execution (without communication), and very sparse and delayed\nrewards. The inaugural Pommerman Team Competition held at NeurIPS 2018 hosted\n25 participants who submitted a team of 2 agents. Our submission\nnn_team_skynet955_skynet955 won 2nd place of the \"learning agents'' category.\nOur team is composed of 2 neural networks trained with state of the art deep\nreinforcement learning algorithms and makes use of concepts like reward\nshaping, curriculum learning, and an automatic reasoning module for action\npruning. Here, we describe these elements and additionally we present a\ncollection of open-sourced agents that can be used for training and testing in\nthe Pommerman environment. Code available at:\nhttps://github.com/BorealisAI/pommerman-baseline\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2019 18:30:58 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Gao", "Chao", ""], ["Hernandez-Leal", "Pablo", ""], ["Kartal", "Bilal", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "1905.01365", "submitter": "Carole Adam", "authors": "Julius Ba\\~ngate, Julie Dugdale (LIG Laboratoire d'Informatique de\n  Grenoble), Elise Beck (IV), Carole Adam (LIG, LIG Laboratoire d'Informatique\n  de Grenoble)", "title": "A multi-agent system approach in evaluating human spatio-temporal\n  vulnerability to seismic risk using social attachment", "comments": null, "journal-ref": "Risk Analysis and Hazard Mitigation, Jun 2018, Sevilla, Spain", "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social attachment theory states that individuals seek the proximity of\nattachment figures (e.g. family members, friends, colleagues, familiar places\nor objects) when faced with threat. During disasters, this means that family\nmembers may seek each other before evacuating, gather personal property before\nheading to familiar exits and places, or follow groups/crowds, etc. This\nhard-wired human tendency should be considered in the assessment of risk and\nthe creation of disaster management plans. Doing so may result in more\nrealistic evacuation procedures and may minimise the number of casualties and\ninjuries. In this context, a dynamic spatio-temporal analysis of seismic risk\nis presented using SOLACE, a multi-agent model of pedestrian behaviour based on\nsocial attachment theory implemented using the Belief-Desire-Intention\napproach. The model focuses on the influence of human, social, physical and\ntemporal factors on successful evacuation. Human factors considered include\nperception and mobility defined by age. Social factors are defined by\nattachment bonds, social groups, population distribution, and cultural norms.\nPhysical factors refer to the location of the epicentre of the earthquake,\nspatial distribution/layout and attributes of environmental objects such as\nbuildings, roads, barriers (cars), placement of safe areas, evacuation routes,\nand the resulting debris/damage from the earthquake. Experiments tested the\ninfluence of time of the day, presence of disabled persons and earthquake\nintensity. Initial results show that factors that influence arrivals in safe\nareas include (a) human factors (age, disability, speed), (b) pre-evacuation\nbehaviours, (c) perception distance (social attachment, time of day), (d)\nsocial interaction during evacuation, and (e) physical and spatial aspects,\nsuch as limitations imposed by debris (damage), and the distance to safe areas.\nTo validate the results, scenarios will be designed with stakeholders, who will\nalso take part in the definition of a serious game. The recommendation of this\nresearch is that both social and physical aspects should be considered when\ndefining vulnerability in the analysis of risk.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 13:12:13 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Ba\u00f1gate", "Julius", "", "LIG Laboratoire d'Informatique de\n  Grenoble"], ["Dugdale", "Julie", "", "LIG Laboratoire d'Informatique de\n  Grenoble"], ["Beck", "Elise", "", "IV"], ["Adam", "Carole", "", "LIG, LIG Laboratoire d'Informatique\n  de Grenoble"]]}, {"id": "1905.01386", "submitter": "Manojkumar Rangasamy Kannadasan", "authors": "Manojkumar Rangasamy Kannadasan, Grigor Aslanyan", "title": "Personalized Query Auto-Completion Through a Lightweight Representation\n  of the User Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Query Auto-Completion (QAC) is a widely used feature in many domains,\nincluding web and eCommerce search, suggesting full queries based on a prefix\ntyped by the user. QAC has been extensively studied in the literature in the\nrecent years, and it has been consistently shown that adding personalization\nfeatures can significantly improve the performance of QAC. In this work we\npropose a novel method for personalized QAC that uses lightweight embeddings\nlearnt through fastText. We construct an embedding for the user context\nqueries, which are the last few queries issued by the user. We also use the\nsame model to get the embedding for the candidate queries to be ranked. We\nintroduce ranking features that compute the distance between the candidate\nqueries and the context queries in the embedding space. These features are then\ncombined with other commonly used QAC ranking features to learn a ranking\nmodel. We apply our method to a large eCommerce search engine (eBay) and show\nthat the ranker with our proposed feature significantly outperforms the\nbaselines on all of the offline metrics measured, which includes Mean\nReciprocal Rank (MRR), Success Rate (SR), Mean Average Precision (MAP), and\nNormalized Discounted Cumulative Gain (NDCG). Our baselines include the Most\nPopular Completion (MPC) model as well as a ranking model without our proposed\nfeatures. The ranking model with the proposed features results in a $20-30\\%$\nimprovement over the MPC model on all metrics. We obtain up to a $5\\%$\nimprovement over the baseline ranking model for all the sessions, which goes up\nto about $10\\%$ when we restrict to sessions that contain the user context.\nMoreover, our proposed features also significantly outperform text based\npersonalization features studied in the literature before, and adding text\nbased features on top of our proposed embedding based features results only in\nminor improvements.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 23:28:18 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Kannadasan", "Manojkumar Rangasamy", ""], ["Aslanyan", "Grigor", ""]]}, {"id": "1905.01489", "submitter": "Senthil Yogamani", "authors": "Senthil Yogamani, Ciaran Hughes, Jonathan Horgan, Ganesh Sistu,\n  Padraig Varley, Derek O'Dea, Michal Uricar, Stefan Milz, Martin Simon, Karl\n  Amende, Christian Witt, Hazem Rashed, Sumanth Chennupati, Sanjaya Nayak,\n  Saquib Mansoor, Xavier Perroton, Patrick Perez", "title": "WoodScape: A multi-task, multi-camera fisheye dataset for autonomous\n  driving", "comments": "Accepted for Oral Presentation at IEEE International Conference on\n  Computer Vision (ICCV) 2019. Please refer to our website\n  https://woodscape.valeo.com and https://github.com/valeoai/woodscape for\n  release status and updates", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fisheye cameras are commonly employed for obtaining a large field of view in\nsurveillance, augmented reality and in particular automotive applications. In\nspite of their prevalence, there are few public datasets for detailed\nevaluation of computer vision algorithms on fisheye images. We release the\nfirst extensive fisheye automotive dataset, WoodScape, named after Robert Wood\nwho invented the fisheye camera in 1906. WoodScape comprises of four surround\nview cameras and nine tasks including segmentation, depth estimation, 3D\nbounding box detection and soiling detection. Semantic annotation of 40 classes\nat the instance level is provided for over 10,000 images and annotation for\nother tasks are provided for over 100,000 images. With WoodScape, we would like\nto encourage the community to adapt computer vision models for fisheye camera\ninstead of using naive rectification.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 13:14:12 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 20:40:58 GMT"}, {"version": "v3", "created": "Fri, 2 Jul 2021 22:16:13 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Yogamani", "Senthil", ""], ["Hughes", "Ciaran", ""], ["Horgan", "Jonathan", ""], ["Sistu", "Ganesh", ""], ["Varley", "Padraig", ""], ["O'Dea", "Derek", ""], ["Uricar", "Michal", ""], ["Milz", "Stefan", ""], ["Simon", "Martin", ""], ["Amende", "Karl", ""], ["Witt", "Christian", ""], ["Rashed", "Hazem", ""], ["Chennupati", "Sumanth", ""], ["Nayak", "Sanjaya", ""], ["Mansoor", "Saquib", ""], ["Perroton", "Xavier", ""], ["Perez", "Patrick", ""]]}, {"id": "1905.01492", "submitter": "Senthil Yogamani", "authors": "Michal Uricar, Pavel Krizek, Ganesh Sistu and Senthil Yogamani", "title": "SoilingNet: Soiling Detection on Automotive Surround-View Cameras", "comments": "Accepted for Oral Presentation at IEEE Intelligent Transportation\n  Systems Conference (ITSC) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cameras are an essential part of sensor suite in autonomous driving.\nSurround-view cameras are directly exposed to external environment and are\nvulnerable to get soiled. Cameras have a much higher degradation in performance\ndue to soiling compared to other sensors. Thus it is critical to accurately\ndetect soiling on the cameras, particularly for higher levels of autonomous\ndriving. We created a new dataset having multiple types of soiling namely\nopaque and transparent. It will be released publicly as part of our WoodScape\ndataset \\cite{yogamani2019woodscape} to encourage further research. We\ndemonstrate high accuracy using a Convolutional Neural Network (CNN) based\narchitecture. We also show that it can be combined with the existing object\ndetection task in a multi-task learning framework. Finally, we make use of\nGenerative Adversarial Networks (GANs) to generate more images for data\naugmentation and show that it works successfully similar to the style transfer.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 13:39:48 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 16:34:40 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Uricar", "Michal", ""], ["Krizek", "Pavel", ""], ["Sistu", "Ganesh", ""], ["Yogamani", "Senthil", ""]]}, {"id": "1905.01537", "submitter": "Madhavun Candadai", "authors": "Zach Dwiel, Madhavun Candadai, Mariano Phielipp, Arjun K. Bansal", "title": "Hierarchical Policy Learning is Sensitive to Goal Space Design", "comments": "Accepted to be presented at Task-Agnostic Reinforcement Learning\n  (TARL) workshop at ICLR'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchy in reinforcement learning agents allows for control at multiple\ntime scales yielding improved sample efficiency, the ability to deal with long\ntime horizons and transferability of sub-policies to tasks outside the training\ndistribution. It is often implemented as a master policy providing goals to a\nsub-policy. Ideally, we would like the goal-spaces to be learned, however,\nproperties of optimal goal spaces still remain unknown and consequently there\nis no method yet to learn optimal goal spaces. Motivated by this, we\nsystematically analyze how various modifications to the ground-truth goal-space\naffect learning in hierarchical models with the aim of identifying important\nproperties of optimal goal spaces. Our results show that, while rotation of\nground-truth goal spaces and noise had no effect, having additional unnecessary\nfactors significantly impaired learning in hierarchical models.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 18:22:32 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 19:47:43 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Dwiel", "Zach", ""], ["Candadai", "Madhavun", ""], ["Phielipp", "Mariano", ""], ["Bansal", "Arjun K.", ""]]}, {"id": "1905.01562", "submitter": "Manuel Lagunas", "authors": "Manuel Lagunas, Sandra Malpica, Ana Serrano, Elena Garces, Diego\n  Gutierrez, Belen Masia", "title": "A Similarity Measure for Material Appearance", "comments": "12 pages, 17 figures", "journal-ref": "ACM Transactions on Graphics (SIGGRAPH 2019)", "doi": "10.1145/3306346.3323036", "report-no": null, "categories": "cs.GR cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a model to measure the similarity in appearance between different\nmaterials, which correlates with human similarity judgments. We first create a\ndatabase of 9,000 rendered images depicting objects with varying materials,\nshape and illumination. We then gather data on perceived similarity from\ncrowdsourced experiments; our analysis of over 114,840 answers suggests that\nindeed a shared perception of appearance similarity exists. We feed this data\nto a deep learning architecture with a novel loss function, which learns a\nfeature space for materials that correlates with such perceived appearance\nsimilarity. Our evaluation shows that our model outperforms existing metrics.\nLast, we demonstrate several applications enabled by our metric, including\nappearance-based search for material suggestions, database visualization,\nclustering and summarization, and gamut mapping.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 22:48:27 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Lagunas", "Manuel", ""], ["Malpica", "Sandra", ""], ["Serrano", "Ana", ""], ["Garces", "Elena", ""], ["Gutierrez", "Diego", ""], ["Masia", "Belen", ""]]}, {"id": "1905.01566", "submitter": "Yasumasa Onoe", "authors": "Yasumasa Onoe, Greg Durrett", "title": "Learning to Denoise Distantly-Labeled Data for Entity Typing", "comments": "NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distantly-labeled data can be used to scale up training of statistical\nmodels, but it is typically noisy and that noise can vary with the distant\nlabeling technique. In this work, we propose a two-stage procedure for handling\nthis type of data: denoise it with a learned model, then train our final model\non clean and denoised distant data with standard supervised training. Our\ndenoising approach consists of two parts. First, a filtering function discards\nexamples from the distantly labeled data that are wholly unusable. Second, a\nrelabeling function repairs noisy labels for the retained examples. Each of\nthese components is a model trained on synthetically-noised examples generated\nfrom a small manually-labeled set. We investigate this approach on the\nultra-fine entity typing task of Choi et al. (2018). Our baseline model is an\nextension of their model with pre-trained ELMo representations, which already\nachieves state-of-the-art performance. Adding distant data that has been\ndenoised with our learned models gives further performance gains over this base\nmodel, outperforming models trained on raw distant data or\nheuristically-denoised distant data.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 23:22:51 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Onoe", "Yasumasa", ""], ["Durrett", "Greg", ""]]}, {"id": "1905.01576", "submitter": "Lin Yang", "authors": "Lin F. Yang, Chengzhuo Ni, Mengdi Wang", "title": "Learning to Control in Metric Space with Optimal Regret", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study online reinforcement learning for finite-horizon deterministic\ncontrol systems with {\\it arbitrary} state and action spaces. Suppose that the\ntransition dynamics and reward function is unknown, but the state and action\nspace is endowed with a metric that characterizes the proximity between\ndifferent states and actions. We provide a surprisingly simple upper-confidence\nreinforcement learning algorithm that uses a function approximation oracle to\nestimate optimistic Q functions from experiences. We show that the regret of\nthe algorithm after $K$ episodes is $O(HL(KH)^{\\frac{d-1}{d}}) $ where $L$ is a\nsmoothness parameter, and $d$ is the doubling dimension of the state-action\nspace with respect to the given metric. We also establish a near-matching\nregret lower bound. The proposed method can be adapted to work for more\nstructured transition systems, including the finite-state case and the case\nwhere value functions are linear combinations of features, where the method\nalso achieve the optimal regret.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 01:42:44 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Yang", "Lin F.", ""], ["Ni", "Chengzhuo", ""], ["Wang", "Mengdi", ""]]}, {"id": "1905.01588", "submitter": "Ming Dong", "authors": "Ming Dong, Jessie Sun, Carl Wang", "title": "A Pattern Recognition Method for Partial Discharge Detection on\n  Insulated Overhead Conductors", "comments": "4 pages,6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today,insulated overhead conductors are increasingly used in many places of\nthe world due to the higher operational reliability, elimination of\nphase-to-phase contact, closer distances between phases and stronger protection\nfor animals. However, the standard protection devices are often not able to\ndetect the conductor phase-to-ground fault and the more frequent tree/tree\nbranch hitting conductor events as these events only lead to partial discharge\n(PD) activities instead of causing overcurrent seen on bare conductors. To\nsolve this problem, in recent years, Technical University of Ostrava (VSB)\ndevised a special meter to measure the voltage signal of the stray electrical\nfield along the insulated overhead conductors, hoping to detect the above\nhazardous PD activities. In 2018, VSB published a large amount of waveform data\nrecorded by their meter on Kaggle, the world's largest data science\ncollaboration platform, looking for promising pattern recognition methods for\nthis application. To tackle this challenge, we developed a unique method based\non Seasonal and Trend decomposition using Loess (STL) and Support Vector\nMachine (SVM) to recognize PD activities on insulated overhead conductors.\nDifferent SVM kernels were tested and compared. Satisfactory classification\nrates on VSB dataset were achieved with the use of Gaussian radial basis\nkernel.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 03:09:48 GMT"}, {"version": "v2", "created": "Sun, 12 May 2019 17:25:37 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Dong", "Ming", ""], ["Sun", "Jessie", ""], ["Wang", "Carl", ""]]}, {"id": "1905.01631", "submitter": "Jiachen Li", "authors": "Jiachen Li and Hengbo Ma and Masayoshi Tomizuka", "title": "Conditional Generative Neural System for Probabilistic Trajectory\n  Prediction", "comments": "Camera ready for IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective understanding of the environment and accurate trajectory prediction\nof surrounding dynamic obstacles are critical for intelligent systems such as\nautonomous vehicles and wheeled mobile robotics navigating in complex scenarios\nto achieve safe and high-quality decision making, motion planning and control.\nDue to the uncertain nature of the future, it is desired to make inference from\na probability perspective instead of deterministic prediction. In this paper,\nwe propose a conditional generative neural system (CGNS) for probabilistic\ntrajectory prediction to approximate the data distribution, with which\nrealistic, feasible and diverse future trajectory hypotheses can be sampled.\nThe system combines the strengths of conditional latent space learning and\nvariational divergence minimization, and leverages both static context and\ninteraction information with soft attention mechanisms. We also propose a\nregularization method for incorporating soft constraints into deep neural\nnetworks with differentiable barrier functions, which can regulate and push the\ngenerated samples into the feasible regions. The proposed system is evaluated\non several public benchmark datasets for pedestrian trajectory prediction and a\nroundabout naturalistic driving dataset collected by ourselves. The\nexperimental results demonstrate that our model achieves better performance\nthan various baseline approaches in terms of prediction accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 08:19:50 GMT"}, {"version": "v2", "created": "Sun, 28 Jul 2019 08:26:20 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Li", "Jiachen", ""], ["Ma", "Hengbo", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1905.01647", "submitter": "Gijs Wijnholds", "authors": "Gijs Wijnholds and Mehrnoosh Sadrzadeh", "title": "A Typedriven Vector Semantics for Ellipsis with Anaphora using Lambek\n  Calculus with Limited Contraction", "comments": "Forthcoming in: Journal of Logic, Language and Information", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a vector space semantics for verb phrase ellipsis with anaphora\nusing type-driven compositional distributional semantics based on the Lambek\ncalculus with limited contraction (LCC) of J\\\"ager (2006). Distributional\nsemantics has a lot to say about the statistical collocation-based meanings of\ncontent words, but provides little guidance on how to treat function words.\nFormal semantics on the other hand, has powerful mechanisms for dealing with\nrelative pronouns, coordinators, and the like. Type-driven compositional\ndistributional semantics brings these two models together. We review previous\ncompositional distributional models of relative pronouns, coordination and a\nrestricted account of ellipsis in the DisCoCat framework of Coecke et al.\n(2010, 2013). We show how DisCoCat cannot deal with general forms of ellipsis,\nwhich rely on copying of information, and develop a novel way of connecting\ntypelogical grammar to distributional semantics by assigning vector\ninterpretable lambda terms to derivations of LCC in the style of Muskens &\nSadrzadeh (2016). What follows is an account of (verb phrase) ellipsis in which\nword meanings can be copied: the meaning of a sentence is now a program with\nnon-linear access to individual word embeddings. We present the theoretical\nsetting, work out examples, and demonstrate our results on a toy distributional\nmodel motivated by data.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 10:30:03 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Wijnholds", "Gijs", ""], ["Sadrzadeh", "Mehrnoosh", ""]]}, {"id": "1905.01652", "submitter": "Sim\\'on Algorta", "authors": "Sim\\'on Algorta and \\\"Ozg\\\"ur \\c{S}im\\c{s}ek", "title": "The Game of Tetris in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The game of Tetris is an important benchmark for research in artificial\nintelligence and machine learning. This paper provides a historical account of\nthe algorithmic developments in Tetris and discusses open challenges.\nHandcrafted controllers, genetic algorithms, and reinforcement learning have\nall contributed to good solutions. However, existing solutions fall far short\nof what can be achieved by expert players playing without time pressure.\nFurther study of the game has the potential to contribute to important areas of\nresearch, including feature discovery, autonomous learning of action\nhierarchies, and sample-efficient reinforcement learning.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 11:10:46 GMT"}, {"version": "v2", "created": "Fri, 10 May 2019 06:12:20 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Algorta", "Sim\u00f3n", ""], ["\u015eim\u015fek", "\u00d6zg\u00fcr", ""]]}, {"id": "1905.01663", "submitter": "Shuo Wan", "authors": "Shuo Wan, Jiaxun Lu, Pingyi Fan, and Khaled B. Letaief", "title": "Towards Big data processing in IoT: network management for online edge\n  data processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.DC cs.IT eess.IV math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heavy data load and wide cover range have always been crucial problems for\ninternet of things (IoT). However, in mobile-edge computing (MEC) network, the\nhuge data can be partly processed at the edge. In this paper, a MEC-based big\ndata analysis network is discussed. The raw data generated by distributed\nnetwork terminals are collected and processed by edge servers. The edge servers\nsplit out a large sum of redundant data and transmit extracted information to\nthe center cloud for further analysis. However, for consideration of limited\nedge computation ability, part of the raw data in huge data sources may be\ndirectly transmitted to the cloud. To manage limited resources online, we\npropose an algorithm based on Lyapunov optimization to jointly optimize the\npolicy of edge processor frequency, transmission power and bandwidth\nallocation. The algorithm aims at stabilizing data processing delay and saving\nenergy without knowing probability distributions of data sources. The proposed\nnetwork management algorithm may contribute to big data processing in future\nIoT.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 11:42:38 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Wan", "Shuo", ""], ["Lu", "Jiaxun", ""], ["Fan", "Pingyi", ""], ["Letaief", "Khaled B.", ""]]}, {"id": "1905.01718", "submitter": "Muhammad Burhan Hafez", "authors": "Muhammad Burhan Hafez, Cornelius Weber, Matthias Kerzel, Stefan\n  Wermter", "title": "Curious Meta-Controller: Adaptive Alternation between Model-Based and\n  Model-Free Control in Deep Reinforcement Learning", "comments": "Accepted at IJCNN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent success in deep reinforcement learning for continuous control has been\ndominated by model-free approaches which, unlike model-based approaches, do not\nsuffer from representational limitations in making assumptions about the world\ndynamics and model errors inevitable in complex domains. However, they require\na lot of experiences compared to model-based approaches that are typically more\nsample-efficient. We propose to combine the benefits of the two approaches by\npresenting an integrated approach called Curious Meta-Controller. Our approach\nalternates adaptively between model-based and model-free control using a\ncuriosity feedback based on the learning progress of a neural model of the\ndynamics in a learned latent space. We demonstrate that our approach can\nsignificantly improve the sample efficiency and achieve near-optimal\nperformance on learning robotic reaching and grasping tasks from raw-pixel\ninput in both dense and sparse reward settings.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 17:18:22 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Hafez", "Muhammad Burhan", ""], ["Weber", "Cornelius", ""], ["Kerzel", "Matthias", ""], ["Wermter", "Stefan", ""]]}, {"id": "1905.01723", "submitter": "Ming-Yu Liu", "authors": "Ming-Yu Liu and Xun Huang and Arun Mallya and Tero Karras and Timo\n  Aila and Jaakko Lehtinen and Jan Kautz", "title": "Few-Shot Unsupervised Image-to-Image Translation", "comments": "The paper will be presented at the International Conference on\n  Computer Vision (ICCV) 2019", "journal-ref": "ICCV 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised image-to-image translation methods learn to map images in a\ngiven class to an analogous image in a different class, drawing on unstructured\n(non-registered) datasets of images. While remarkably successful, current\nmethods require access to many images in both source and destination classes at\ntraining time. We argue this greatly limits their use. Drawing inspiration from\nthe human capability of picking up the essence of a novel object from a small\nnumber of examples and generalizing from there, we seek a few-shot,\nunsupervised image-to-image translation algorithm that works on previously\nunseen target classes that are specified, at test time, only by a few example\nimages. Our model achieves this few-shot generation capability by coupling an\nadversarial training scheme with a novel network design. Through extensive\nexperimental validation and comparisons to several baseline methods on\nbenchmark datasets, we verify the effectiveness of the proposed framework. Our\nimplementation and datasets are available at https://github.com/NVlabs/FUNIT .\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 17:41:31 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 06:11:56 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Liu", "Ming-Yu", ""], ["Huang", "Xun", ""], ["Mallya", "Arun", ""], ["Karras", "Tero", ""], ["Aila", "Timo", ""], ["Lehtinen", "Jaakko", ""], ["Kautz", "Jan", ""]]}, {"id": "1905.01744", "submitter": "Zhiqiang Shen", "authors": "Zhiqiang Shen and Mingyang Huang and Jianping Shi and Xiangyang Xue\n  and Thomas Huang", "title": "Towards Instance-level Image-to-Image Translation", "comments": "Accepted to CVPR 2019. Project page:\n  http://zhiqiangshen.com/projects/INIT/index.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unpaired Image-to-image Translation is a new rising and challenging vision\nproblem that aims to learn a mapping between unaligned image pairs in diverse\ndomains. Recent advances in this field like MUNIT and DRIT mainly focus on\ndisentangling content and style/attribute from a given image first, then\ndirectly adopting the global style to guide the model to synthesize new domain\nimages. However, this kind of approaches severely incurs contradiction if the\ntarget domain images are content-rich with multiple discrepant objects. In this\npaper, we present a simple yet effective instance-aware image-to-image\ntranslation approach (INIT), which employs the fine-grained local (instance)\nand global styles to the target image spatially. The proposed INIT exhibits\nthree import advantages: (1) the instance-level objective loss can help learn a\nmore accurate reconstruction and incorporate diverse attributes of objects; (2)\nthe styles used for target domain of local/global areas are from corresponding\nspatial regions in source domain, which intuitively is a more reasonable\nmapping; (3) the joint training process can benefit both fine and coarse\ngranularity and incorporates instance information to improve the quality of\nglobal translation. We also collect a large-scale benchmark for the new\ninstance-level translation task. We observe that our synthetic images can even\nbenefit real-world vision tasks like generic object detection.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 20:16:41 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Shen", "Zhiqiang", ""], ["Huang", "Mingyang", ""], ["Shi", "Jianping", ""], ["Xue", "Xiangyang", ""], ["Huang", "Thomas", ""]]}, {"id": "1905.01780", "submitter": "Bo Liu", "authors": "Bo Liu", "title": "Anonymized BERT: An Augmentation Approach to the Gendered Pronoun\n  Resolution Challenge", "comments": "6 pages; accepted by 1st ACL Workshop on Gender Bias for NLP at ACL\n  2019; code is at https://github.com/boliu61/gendered-pronoun-resolution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our 7th place solution to the Gendered Pronoun Resolution\nchallenge, which uses BERT without fine-tuning and a novel augmentation\nstrategy designed for contextual embedding token-level tasks. Our method\nanonymizes the referent by replacing candidate names with a set of common\nplaceholder names. Besides the usual benefits of effectively increasing\ntraining data size, this approach diversifies idiosyncratic information\nembedded in names. Using same set of common first names can also help the model\nrecognize names better, shorten token length, and remove gender and regional\nbiases associated with names. The system scored 0.1947 log loss in stage 2,\nwhere the augmentation contributed to an improvements of 0.04. Post-competition\nanalysis shows that, when using different embedding layers, the system scores\n0.1799 which would be third place.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 01:16:33 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 14:46:27 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Liu", "Bo", ""]]}, {"id": "1905.01796", "submitter": "Jinqiang Bai", "authors": "Zhaoxiang Liu, Huan Hu, Jinqiang Bai, Shaohua Li, Shiguo Lian", "title": "Feature Aggregation Network for Video Face Recognition", "comments": "9 pages, 4 figures, Accepted by ICCV 2019 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to learn a compact representation of a video for video face\nrecognition task. We make the following contributions: first, we propose a meta\nattention-based aggregation scheme which adaptively and fine-grained weighs the\nfeature along each feature dimension among all frames to form a compact and\ndiscriminative representation. It makes the best to exploit the valuable or\ndiscriminative part of each frame to promote the performance of face\nrecognition, without discarding or despising low quality frames as usual\nmethods do. Second, we build a feature aggregation network comprised of a\nfeature embedding module and a feature aggregation module. The embedding module\nis a convolutional neural network used to extract a feature vector from a face\nimage, while the aggregation module consists of cascaded two meta attention\nblocks which adaptively aggregate the feature vectors into a single\nfixed-length representation. The network can deal with arbitrary number of\nframes, and is insensitive to frame order. Third, we validate the performance\nof proposed aggregation scheme. Experiments on publicly available datasets,\nsuch as YouTube face dataset and IJB-A dataset, show the effectiveness of our\nmethod, and it achieves competitive performances on both the verification and\nidentification protocols.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 02:37:12 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 09:03:09 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Liu", "Zhaoxiang", ""], ["Hu", "Huan", ""], ["Bai", "Jinqiang", ""], ["Li", "Shaohua", ""], ["Lian", "Shiguo", ""]]}, {"id": "1905.01959", "submitter": "Yan Liang", "authors": "Yan Liang, Xin Liu, Jianwen Zhang, Yangqiu Song", "title": "Relation Discovery with Out-of-Relation Knowledge Base as Supervision", "comments": "Aceepted by NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unsupervised relation discovery aims to discover new relations from a given\ntext corpus without annotated data. However, it does not consider existing\nhuman annotated knowledge bases even when they are relevant to the relations to\nbe discovered. In this paper, we study the problem of how to use\nout-of-relation knowledge bases to supervise the discovery of unseen relations,\nwhere out-of-relation means that relations to discover from the text corpus and\nthose in knowledge bases are not overlapped. We construct a set of constraints\nbetween entity pairs based on the knowledge base embedding and then incorporate\nconstraints into the relation discovery by a variational auto-encoder based\nalgorithm. Experiments show that our new approach can improve the\nstate-of-the-art relation discovery performance by a large margin.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 02:30:59 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Liang", "Yan", ""], ["Liu", "Xin", ""], ["Zhang", "Jianwen", ""], ["Song", "Yangqiu", ""]]}, {"id": "1905.01966", "submitter": "Amirreza Shirani", "authors": "Amirreza Shirani, Bowen Xu, David Lo, Thamar Solorio and Amin Alipour", "title": "Question Relatedness on Stack Overflow: The Task, Dataset, and\n  Corpus-inspired Models", "comments": null, "journal-ref": "AAAI 2019 Reasoning for Complex Question Answering Workshop", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Domain-specific community question answering is becoming an integral part of\nprofessions. Finding related questions and answers in these communities can\nsignificantly improve the effectiveness and efficiency of information seeking.\nStack Overflow is one of the most popular communities that is being used by\nmillions of programmers. In this paper, we analyze the problem of predicting\nknowledge unit (question thread) relatedness in Stack Overflow. In particular,\nwe formulate the question relatedness task as a multi-class classification\nproblem with four degrees of relatedness. We present a large-scale dataset with\nmore than 300K pairs. To the best of our knowledge, this dataset is the largest\ndomain-specific dataset for Question-Question relatedness. We present the steps\nthat we took to collect, clean, process, and assure the quality of the dataset.\nThe proposed dataset Stack Overflow is a useful resource to develop novel\nsolutions, specifically data-hungry neural network models, for the prediction\nof relatedness in technical community question-answering forums. We adopt a\nneural network architecture and a traditional model for this task that\neffectively utilize information from different parts of knowledge units to\ncompute the relatedness between them. These models can be used to benchmark\nnovel models, as they perform well in our task and in a closely similar task.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 01:45:50 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 15:35:32 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Shirani", "Amirreza", ""], ["Xu", "Bowen", ""], ["Lo", "David", ""], ["Solorio", "Thamar", ""], ["Alipour", "Amin", ""]]}, {"id": "1905.01969", "submitter": "Kurt Shuster", "authors": "Samuel Humeau, Kurt Shuster, Marie-Anne Lachaux, Jason Weston", "title": "Poly-encoders: Transformer Architectures and Pre-training Strategies for\n  Fast and Accurate Multi-sentence Scoring", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of deep pre-trained bidirectional transformers has led to remarkable\nprogress in a number of applications (Devlin et al., 2018). For tasks that make\npairwise comparisons between sequences, matching a given input with a\ncorresponding label, two approaches are common: Cross-encoders performing full\nself-attention over the pair and Bi-encoders encoding the pair separately. The\nformer often performs better, but is too slow for practical use. In this work,\nwe develop a new transformer architecture, the Poly-encoder, that learns global\nrather than token level self-attention features. We perform a detailed\ncomparison of all three approaches, including what pre-training and fine-tuning\nstrategies work best. We show our models achieve state-of-the-art results on\nthree existing tasks; that Poly-encoders are faster than Cross-encoders and\nmore accurate than Bi-encoders; and that the best results are obtained by\npre-training on large datasets similar to the downstream tasks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 02:18:00 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 19:07:46 GMT"}, {"version": "v3", "created": "Wed, 12 Feb 2020 20:07:00 GMT"}, {"version": "v4", "created": "Wed, 25 Mar 2020 22:53:51 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Humeau", "Samuel", ""], ["Shuster", "Kurt", ""], ["Lachaux", "Marie-Anne", ""], ["Weston", "Jason", ""]]}, {"id": "1905.01978", "submitter": "Arthur Szlam", "authors": "Yacine Jernite, Kavya Srinet, Jonathan Gray, Arthur Szlam", "title": "CraftAssist Instruction Parsing: Semantic Parsing for a Minecraft\n  Assistant", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a large scale semantic parsing dataset focused on\ninstruction-driven communication with an agent in Minecraft. We describe the\ndata collection process which yields additional 35K human generated\ninstructions with their semantic annotations. We report the performance of\nthree baseline models and find that while a dataset of this size helps us train\na usable instruction parser, it still poses interesting generalization\nchallenges which we hope will help develop better and more robust models.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 19:55:20 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Jernite", "Yacine", ""], ["Srinet", "Kavya", ""], ["Gray", "Jonathan", ""], ["Szlam", "Arthur", ""]]}, {"id": "1905.01984", "submitter": "Bin Guo", "authors": "Qiuyun Zhang, Bin Guo, Hao Wang, Yunji Liang, Shaoyang Hao, Zhiwen Yu", "title": "AI-Powered Text Generation for Harmonious Human-Machine Interaction:\n  Current State and Future Directions", "comments": "Accepted by IEEE UIC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last two decades, the landscape of text generation has undergone\ntremendous changes and is being reshaped by the success of deep learning. New\ntechnologies for text generation ranging from template-based methods to neural\nnetwork-based methods emerged. Meanwhile, the research objectives have also\nchanged from generating smooth and coherent sentences to infusing personalized\ntraits to enrich the diversification of newly generated content. With the rapid\ndevelopment of text generation solutions, one comprehensive survey is urgent to\nsummarize the achievements and track the state of the arts. In this survey\npaper, we present the general systematical framework, illustrate the widely\nutilized models and summarize the classic applications of text generation.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 23:26:38 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Zhang", "Qiuyun", ""], ["Guo", "Bin", ""], ["Wang", "Hao", ""], ["Liang", "Yunji", ""], ["Hao", "Shaoyang", ""], ["Yu", "Zhiwen", ""]]}, {"id": "1905.01986", "submitter": "Robin Burke", "authors": "Himan Abdollahpouri, Gediminas Adomavicius, Robin Burke, Ido Guy,\n  Dietmar Jannach, Toshihiro Kamishima, Jan Krasnodebski and Luiz Pizzato", "title": "Beyond Personalization: Research Directions in Multistakeholder\n  Recommendation", "comments": "64 pages", "journal-ref": "User Model User-Adap Inter 30, 127-158 (2020)", "doi": "10.1007/s11257-019-09256-1", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems are personalized information access applications; they\nare ubiquitous in today's online environment, and effective at finding items\nthat meet user needs and tastes. As the reach of recommender systems has\nextended, it has become apparent that the single-minded focus on the user\ncommon to academic research has obscured other important aspects of\nrecommendation outcomes. Properties such as fairness, balance, profitability,\nand reciprocity are not captured by typical metrics for recommender system\nevaluation. The concept of multistakeholder recommendation has emerged as a\nunifying framework for describing and understanding recommendation settings\nwhere the end user is not the sole focus. This article describes the origins of\nmultistakeholder recommendation, and the landscape of system designs. It\nprovides illustrative examples of current research, as well as outlining open\nquestions and research directions for the field.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 18:50:10 GMT"}, {"version": "v2", "created": "Sun, 15 Dec 2019 14:21:25 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Abdollahpouri", "Himan", ""], ["Adomavicius", "Gediminas", ""], ["Burke", "Robin", ""], ["Guy", "Ido", ""], ["Jannach", "Dietmar", ""], ["Kamishima", "Toshihiro", ""], ["Krasnodebski", "Jan", ""], ["Pizzato", "Luiz", ""]]}, {"id": "1905.01988", "submitter": "Xianbin Hong", "authors": "Xianbin Hong, Gautam Pal, Sheng-Uei Guan, Prudence Wong, Dawei Liu, Ka\n  Lok Man, Xin Huang", "title": "Semi-Unsupervised Lifelong Learning for Sentiment Classification: Less\n  Manual Data Annotation and More Self-Studying", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lifelong machine learning is a novel machine learning paradigm which can\ncontinually accumulate knowledge during learning. The knowledge extracting and\nreusing abilities enable the lifelong machine learning to solve the related\nproblems. The traditional approaches like Na\\\"ive Bayes and some neural network\nbased approaches only aim to achieve the best performance upon a single task.\nUnlike them, the lifelong machine learning in this paper focuses on how to\naccumulate knowledge during learning and leverage them for further tasks.\nMeanwhile, the demand for labelled data for training also is significantly\ndecreased with the knowledge reusing. This paper suggests that the aim of the\nlifelong learning is to use less labelled data and computational cost to\nachieve the performance as well as or even better than the supervised learning.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 23:56:54 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 21:54:10 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Hong", "Xianbin", ""], ["Pal", "Gautam", ""], ["Guan", "Sheng-Uei", ""], ["Wong", "Prudence", ""], ["Liu", "Dawei", ""], ["Man", "Ka Lok", ""], ["Huang", "Xin", ""]]}, {"id": "1905.01994", "submitter": "Chenliang Li", "authors": "Shiqian Chen, Chenliang Li, Feng Ji, Wei Zhou, Haiqing Chen", "title": "Review-Driven Answer Generation for Product-Related Questions in\n  E-Commerce", "comments": null, "journal-ref": "WSDM 2019", "doi": null, "report-no": "https://dl.acm.org/citation.cfm?doid=3289600.3290971", "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The users often have many product-related questions before they make a\npurchase decision in E-commerce. However, it is often time-consuming to examine\neach user review to identify the desired information. In this paper, we propose\na novel review-driven framework for answer generation for product-related\nquestions in E-commerce, named RAGE. We develope RAGE on the basis of the\nmulti-layer convolutional architecture to facilitate speed-up of answer\ngeneration with the parallel computation. For each question, RAGE first\nextracts the relevant review snippets from the reviews of the corresponding\nproduct. Then, we devise a mechanism to identify the relevant information from\nthe noise-prone review snippets and incorporate this information to guide the\nanswer generation. The experiments on two real-world E-Commerce datasets show\nthat the proposed RAGE significantly outperforms the existing alternatives in\nproducing more accurate and informative answers in natural language. Moreover,\nRAGE takes much less time for both model training and answer generation than\nthe existing RNN based generation models.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 01:57:28 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Chen", "Shiqian", ""], ["Li", "Chenliang", ""], ["Ji", "Feng", ""], ["Zhou", "Wei", ""], ["Chen", "Haiqing", ""]]}, {"id": "1905.01995", "submitter": "Lin Li", "authors": "Lin Li, Mengjing Zhang, Zhaohui Chao, Jianwen Xiang", "title": "Using Context Information to Enhance Simple Question Answering", "comments": "under review World Wide Web Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of knowledge bases(KBs),question\nanswering(QA)based on KBs has become a hot research issue. In this paper,we\npropose two frameworks(i.e.,pipeline framework,an end-to-end framework)to focus\nanswering single-relation factoid question. In both of two frameworks,we study\nthe effect of context information on the quality of QA,such as the entity's\nnotable type,out-degree. In the end-to-end framework,we combine char-level\nencoding and self-attention mechanisms,using weight sharing and multi-task\nstrategies to enhance the accuracy of QA. Experimental results show that\ncontext information can get better results of simple QA whether it is the\npipeline framework or the end-to-end framework. In addition,we find that the\nend-to-end framework achieves results competitive with state-of-the-art\napproaches in terms of accuracy and take much shorter time than them.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 12:57:24 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Li", "Lin", ""], ["Zhang", "Mengjing", ""], ["Chao", "Zhaohui", ""], ["Xiang", "Jianwen", ""]]}, {"id": "1905.02005", "submitter": "Alexander Zap", "authors": "Alexander Zap, Tobias Joppen, Johannes F\\\"urnkranz", "title": "Deep Ordinal Reinforcement Learning", "comments": "replaced figures for better visibility, added github repository, more\n  details about source of experimental results, updated target value\n  calculation for standard and ordinal Deep Q-Network", "journal-ref": "Proc. ECML/PKDD (3) 2019: 3-18", "doi": "10.1007/978-3-030-46133-1_1", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning usually makes use of numerical rewards, which have\nnice properties but also come with drawbacks and difficulties. Using rewards on\nan ordinal scale (ordinal rewards) is an alternative to numerical rewards that\nhas received more attention in recent years. In this paper, a general approach\nto adapting reinforcement learning problems to the use of ordinal rewards is\npresented and motivated. We show how to convert common reinforcement learning\nalgorithms to an ordinal variation by the example of Q-learning and introduce\nOrdinal Deep Q-Networks, which adapt deep reinforcement learning to ordinal\nrewards. Additionally, we run evaluations on problems provided by the OpenAI\nGym framework, showing that our ordinal variants exhibit a performance that is\ncomparable to the numerical variations for a number of problems. We also give\nfirst evidence that our ordinal variant is able to produce better results for\nproblems with less engineered and simpler-to-design reward signals.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 12:54:22 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 09:28:24 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Zap", "Alexander", ""], ["Joppen", "Tobias", ""], ["F\u00fcrnkranz", "Johannes", ""]]}, {"id": "1905.02019", "submitter": "Heguang Liu", "authors": "Heguang Liu", "title": "Conditioning LSTM Decoder and Bi-directional Attention Based Question\n  Answering System", "comments": "7 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying neural-networks on Question Answering has gained increasing\npopularity in recent years. In this paper, I implemented a model with\nBi-directional attention flow layer, connected with a Multi-layer LSTM encoder,\nconnected with one start-index decoder and one conditioning end-index decoder.\nI introduce a new end-index decoder layer, conditioning on start-index output.\nThe Experiment shows this has increased model performance by 15.16%. For\nprediction, I proposed a new smart-span equation, rewarding both short answer\nlength and high probability in start-index and end-index, which further\nimproved the prediction accuracy. The best single model achieves an F1 score of\n73.97% and EM score of 64.95% on test set.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 01:07:20 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Liu", "Heguang", ""]]}, {"id": "1905.02092", "submitter": "Neha Soni", "authors": "Neha Soni, Enakshi Khular Sharma, Narotam Singh, Amita Kapoor", "title": "Impact of Artificial Intelligence on Businesses: from Research,\n  Innovation, Market Deployment to Future Shifts in Business Models", "comments": "38 pages, 10 figures, 3 tables. A part of this work has been\n  presented in DIGITS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.AI cs.CY q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fast pace of artificial intelligence (AI) and automation is propelling\nstrategists to reshape their business models. This is fostering the integration\nof AI in the business processes but the consequences of this adoption are\nunderexplored and need attention. This paper focuses on the overall impact of\nAI on businesses - from research, innovation, market deployment to future\nshifts in business models. To access this overall impact, we design a\nthree-dimensional research model, based upon the Neo-Schumpeterian economics\nand its three forces viz. innovation, knowledge, and entrepreneurship. The\nfirst dimension deals with research and innovation in AI. In the second\ndimension, we explore the influence of AI on the global market and the\nstrategic objectives of the businesses and finally, the third dimension\nexamines how AI is shaping business contexts. Additionally, the paper explores\nAI implications on actors and its dark sides.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 12:05:08 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Soni", "Neha", ""], ["Sharma", "Enakshi Khular", ""], ["Singh", "Narotam", ""], ["Kapoor", "Amita", ""]]}, {"id": "1905.02168", "submitter": "Alexander Elkholy", "authors": "Alexander Elkholy, Fangkai Yang, Steven Gustafson", "title": "Interpretable Automated Machine Learning in Maana(TM) Knowledge Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is becoming an essential part of developing solutions for\nmany industrial applications, but the lack of interpretability hinders wide\nindustry adoption to rapidly build, test, deploy and validate machine learning\nmodels, in the sense that the insight of developing machine learning solutions\nare not structurally encoded, justified and transferred. In this paper we\ndescribe Maana Meta-learning Service, an interpretable and interactive\nautomated machine learning service residing in Maana Knowledge Platform that\nperforms machine-guided, user assisted pipeline search and hyper-parameter\ntuning and generates structured knowledge about decisions for pipeline\nprofiling and selection. The service is shipped with Maana Knowledge Platform\nand is validated using benchmark dataset. Furthermore, its capability of\nderiving knowledge from pipeline search facilitates various inference tasks and\ntransferring to similar data science projects.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 17:37:15 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Elkholy", "Alexander", ""], ["Yang", "Fangkai", ""], ["Gustafson", "Steven", ""]]}, {"id": "1905.02185", "submitter": "Takuhiro Kaneko", "authors": "Takuhiro Kaneko, Tatsuya Harada", "title": "Label-Noise Robust Multi-Domain Image-to-Image Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-domain image-to-image translation is a problem where the goal is to\nlearn mappings among multiple domains. This problem is challenging in terms of\nscalability because it requires the learning of numerous mappings, the number\nof which increases proportional to the number of domains. However, generative\nadversarial networks (GANs) have emerged recently as a powerful framework for\nthis problem. In particular, label-conditional extensions (e.g., StarGAN) have\nbecome a promising solution owing to their ability to address this problem\nusing only a single unified model. Nonetheless, a limitation is that they rely\non the availability of large-scale clean-labeled data, which are often\nlaborious or impractical to collect in a real-world scenario. To overcome this\nlimitation, we propose a novel model called the label-noise robust\nimage-to-image translation model (RMIT) that can learn a clean label\nconditional generator even when noisy labeled data are only available. In\nparticular, we propose a novel loss called the virtual cycle consistency loss\nthat is able to regularize cyclic reconstruction independently of noisy labeled\ndata, as well as we introduce advanced techniques to boost the performance in\npractice. Our experimental results demonstrate that RMIT is useful for\nobtaining label-noise robustness in various settings including synthetic and\nreal-world noise.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 17:57:43 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Kaneko", "Takuhiro", ""], ["Harada", "Tatsuya", ""]]}, {"id": "1905.02234", "submitter": "Shreyansh Gandhi", "authors": "Shreyansh Gandhi, Samrat Kokkula, Abon Chaudhuri, Alessandro Magnani,\n  Theban Stanley, Behzad Ahmadi, Venkatesh Kandaswamy, Omer Ovenc, Shie Mannor", "title": "Image Matters: Scalable Detection of Offensive and Non-Compliant Content\n  / Logo in Product Images", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In e-commerce, product content, especially product images have a significant\ninfluence on a customer's journey from product discovery to evaluation and\nfinally, purchase decision. Since many e-commerce retailers sell items from\nother third-party marketplace sellers besides their own, the content published\nby both internal and external content creators needs to be monitored and\nenriched, wherever possible. Despite guidelines and warnings, product listings\nthat contain offensive and non-compliant images continue to enter catalogs.\nOffensive and non-compliant content can include a wide range of objects, logos,\nand banners conveying violent, sexually explicit, racist, or promotional\nmessages. Such images can severely damage the customer experience, lead to\nlegal issues, and erode the company brand. In this paper, we present a computer\nvision driven offensive and non-compliant image detection system for extremely\nlarge image datasets. This paper delves into the unique challenges of applying\ndeep learning to real-world product image data from retail world. We\ndemonstrate how we resolve a number of technical challenges such as lack of\ntraining data, severe class imbalance, fine-grained class definitions etc.\nusing a number of practical yet unique technical strategies. Our system\ncombines state-of-the-art image classification and object detection techniques\nwith budgeted crowdsourcing to develop a solution customized for a massive,\ndiverse, and constantly evolving product catalog.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 18:35:28 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2019 07:38:26 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Gandhi", "Shreyansh", ""], ["Kokkula", "Samrat", ""], ["Chaudhuri", "Abon", ""], ["Magnani", "Alessandro", ""], ["Stanley", "Theban", ""], ["Ahmadi", "Behzad", ""], ["Kandaswamy", "Venkatesh", ""], ["Ovenc", "Omer", ""], ["Mannor", "Shie", ""]]}, {"id": "1905.02249", "submitter": "David Berthelot", "authors": "David Berthelot, Nicholas Carlini, Ian Goodfellow, Nicolas Papernot,\n  Avital Oliver, Colin Raffel", "title": "MixMatch: A Holistic Approach to Semi-Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning has proven to be a powerful paradigm for leveraging\nunlabeled data to mitigate the reliance on large labeled datasets. In this\nwork, we unify the current dominant approaches for semi-supervised learning to\nproduce a new algorithm, MixMatch, that works by guessing low-entropy labels\nfor data-augmented unlabeled examples and mixing labeled and unlabeled data\nusing MixUp. We show that MixMatch obtains state-of-the-art results by a large\nmargin across many datasets and labeled data amounts. For example, on CIFAR-10\nwith 250 labels, we reduce error rate by a factor of 4 (from 38% to 11%) and by\na factor of 2 on STL-10. We also demonstrate how MixMatch can help achieve a\ndramatically better accuracy-privacy trade-off for differential privacy.\nFinally, we perform an ablation study to tease apart which components of\nMixMatch are most important for its success.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 19:56:03 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 18:47:34 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Berthelot", "David", ""], ["Carlini", "Nicholas", ""], ["Goodfellow", "Ian", ""], ["Papernot", "Nicolas", ""], ["Oliver", "Avital", ""], ["Raffel", "Colin", ""]]}, {"id": "1905.02295", "submitter": "Paul Bertin", "authors": "Paul Bertin, Mohammad Hashir, Martin Weiss, Vincent Frappier, Theodore\n  J. Perkins, Genevi\\`eve Boucher and Joseph Paul Cohen", "title": "Analysis of Gene Interaction Graphs as Prior Knowledge for Machine\n  Learning Models", "comments": "Preprint. Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.AI cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gene interaction graphs aim to capture various relationships between genes\nand can represent decades of biology research. When trying to make predictions\nfrom genomic data, those graphs could be used to overcome the curse of\ndimensionality by making machine learning models sparser and more consistent\nwith biological common knowledge. In this work, we focus on assessing how well\nthose graphs capture dependencies seen in gene expression data to evaluate the\nadequacy of the prior knowledge provided by those graphs. We propose a\ncondition graphs should satisfy to provide good prior knowledge and test it\nusing `Single Gene Inference' tasks. We also compare with randomly generated\ngraphs, aiming to measure the true benefit of using biologically relevant\ngraphs in this context, and validate our findings with five clinical tasks. We\nfind some graphs capture relevant dependencies for most genes while being very\nsparse. Our analysis with random graphs finds that dependencies can be captured\nalmost as well at random which suggests that, in terms of gene expression\nlevels, the relevant information about the state of the cell is spread across\nmany genes.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 23:57:14 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 22:21:39 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Bertin", "Paul", ""], ["Hashir", "Mohammad", ""], ["Weiss", "Martin", ""], ["Frappier", "Vincent", ""], ["Perkins", "Theodore J.", ""], ["Boucher", "Genevi\u00e8ve", ""], ["Cohen", "Joseph Paul", ""]]}, {"id": "1905.02303", "submitter": "Alexander Feldman", "authors": "Alexander Feldman and Johan de Kleer and Ion Matei", "title": "Design Space Exploration as Quantified Satisfaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS cs.ET cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present novel algorithms for design and design space exploration. The\ndesigns discovered by these algorithms are compositions of function types\nspecified in component libraries. Our algorithms reduce the design problem to\nquantified satisfiability and use advanced solvers to find solutions that\nrepresent useful systems.\n  The algorithms we present in this paper are sound and complete and are\nguaranteed to discover correct designs of optimal size, if they exist. We apply\nour method to the design of Boolean systems and discover new and more optimal\nclassical digital and quantum circuits for common arithmetic functions such as\naddition and multiplication.\n  The performance of our algorithms is evaluated through extensive\nexperimentation. We created a benchmark consisting of specifications of\nscalable synthetic digital circuits and real-world mirochips. We have generated\nmultiple circuits functionally equivalent to the ones in the benchmark. The\nquantified satisfiability method shows more than four orders of magnitude\nspeed-up, compared to a generate and test method that enumerates all\nnon-isomorphic circuit topologies.\n  Our approach generalizes circuit optimization. It uses arbitrary component\nlibraries and has applications to areas such as digital circuit design,\ndiagnostics, abductive reasoning, test vector generation, and combinatorial\noptimization.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 00:39:16 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 02:01:25 GMT"}, {"version": "v3", "created": "Sun, 31 Jan 2021 22:55:06 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Feldman", "Alexander", ""], ["de Kleer", "Johan", ""], ["Matei", "Ion", ""]]}, {"id": "1905.02331", "submitter": "Wei-Cheng Chang", "authors": "Wei-Cheng Chang, Hsiang-Fu Yu, Kai Zhong, Yiming Yang, Inderjit\n  Dhillon", "title": "Taming Pretrained Transformers for Extreme Multi-label Text\n  Classification", "comments": "KDD 2020 Applied Data Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the extreme multi-label text classification (XMC) problem: given\nan input text, return the most relevant labels from a large label collection.\nFor example, the input text could be a product description on Amazon.com and\nthe labels could be product categories. XMC is an important yet challenging\nproblem in the NLP community. Recently, deep pretrained transformer models have\nachieved state-of-the-art performance on many NLP tasks including sentence\nclassification, albeit with small label sets. However, naively applying deep\ntransformer models to the XMC problem leads to sub-optimal performance due to\nthe large output space and the label sparsity issue. In this paper, we propose\nX-Transformer, the first scalable approach to fine-tuning deep transformer\nmodels for the XMC problem. The proposed method achieves new state-of-the-art\nresults on four XMC benchmark datasets. In particular, on a Wiki dataset with\naround 0.5 million labels, the prec@1 of X-Transformer is 77.28%, a substantial\nimprovement over state-of-the-art XMC approaches Parabel (linear) and\nAttentionXML (neural), which achieve 68.70% and 76.95% precision@1,\nrespectively. We further apply X-Transformer to a product2query dataset from\nAmazon and gained 10.7% relative improvement on prec@1 over Parabel.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 02:32:06 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 18:54:52 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2019 01:13:05 GMT"}, {"version": "v4", "created": "Tue, 23 Jun 2020 19:28:18 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Chang", "Wei-Cheng", ""], ["Yu", "Hsiang-Fu", ""], ["Zhong", "Kai", ""], ["Yang", "Yiming", ""], ["Dhillon", "Inderjit", ""]]}, {"id": "1905.02363", "submitter": "Youngchul Sung", "authors": "Seungyul Han, Youngchul Sung", "title": "Dimension-Wise Importance Sampling Weight Clipping for Sample-Efficient\n  Reinforcement Learning", "comments": "Accepted to the 36th International Conference on Machine Learning\n  (ICML), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In importance sampling (IS)-based reinforcement learning algorithms such as\nProximal Policy Optimization (PPO), IS weights are typically clipped to avoid\nlarge variance in learning. However, policy update from clipped statistics\ninduces large bias in tasks with high action dimensions, and bias from clipping\nmakes it difficult to reuse old samples with large IS weights. In this paper,\nwe consider PPO, a representative on-policy algorithm, and propose its\nimprovement by dimension-wise IS weight clipping which separately clips the IS\nweight of each action dimension to avoid large bias and adaptively controls the\nIS weight to bound policy update from the current policy. This new technique\nenables efficient learning for high action-dimensional tasks and reusing of old\nsamples like in off-policy learning to increase the sample efficiency.\nNumerical results show that the proposed new algorithm outperforms PPO and\nother RL algorithms in various Open AI Gym tasks.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 05:53:11 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 07:09:10 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Han", "Seungyul", ""], ["Sung", "Youngchul", ""]]}, {"id": "1905.02422", "submitter": "Chihye Han", "authors": "Chihye Han, Wonjun Yoon, Gihyun Kwon, Seungkyu Nam, Daeshik Kim", "title": "Representation of White- and Black-Box Adversarial Examples in Deep\n  Neural Networks and Humans: A Functional Magnetic Resonance Imaging Study", "comments": "Copyright 2019 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent success of brain-inspired deep neural networks (DNNs) in solving\ncomplex, high-level visual tasks has led to rising expectations for their\npotential to match the human visual system. However, DNNs exhibit\nidiosyncrasies that suggest their visual representation and processing might be\nsubstantially different from human vision. One limitation of DNNs is that they\nare vulnerable to adversarial examples, input images on which subtle, carefully\ndesigned noises are added to fool a machine classifier. The robustness of the\nhuman visual system against adversarial examples is potentially of great\nimportance as it could uncover a key mechanistic feature that machine vision is\nyet to incorporate. In this study, we compare the visual representations of\nwhite- and black-box adversarial examples in DNNs and humans by leveraging\nfunctional magnetic resonance imaging (fMRI). We find a small but significant\ndifference in representation patterns for different (i.e. white- versus black-\nbox) types of adversarial examples for both humans and DNNs. However, human\nperformance on categorical judgment is not degraded by noise regardless of the\ntype unlike DNN. These results suggest that adversarial examples may be\ndifferentially represented in the human visual system, but unable to affect the\nperceptual experience.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 09:10:48 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Han", "Chihye", ""], ["Yoon", "Wonjun", ""], ["Kwon", "Gihyun", ""], ["Nam", "Seungkyu", ""], ["Kim", "Daeshik", ""]]}, {"id": "1905.02450", "submitter": "Kaitao Song", "authors": "Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu", "title": "MASS: Masked Sequence to Sequence Pre-training for Language Generation", "comments": "Accepted by ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-training and fine-tuning, e.g., BERT, have achieved great success in\nlanguage understanding by transferring knowledge from rich-resource\npre-training task to the low/zero-resource downstream tasks. Inspired by the\nsuccess of BERT, we propose MAsked Sequence to Sequence pre-training (MASS) for\nthe encoder-decoder based language generation tasks. MASS adopts the\nencoder-decoder framework to reconstruct a sentence fragment given the\nremaining part of the sentence: its encoder takes a sentence with randomly\nmasked fragment (several consecutive tokens) as input, and its decoder tries to\npredict this masked fragment. In this way, MASS can jointly train the encoder\nand decoder to develop the capability of representation extraction and language\nmodeling. By further fine-tuning on a variety of zero/low-resource language\ngeneration tasks, including neural machine translation, text summarization and\nconversational response generation (3 tasks and totally 8 datasets), MASS\nachieves significant improvements over the baselines without pre-training or\nwith other pre-training methods. Specially, we achieve the state-of-the-art\naccuracy (37.5 in terms of BLEU score) on the unsupervised English-French\ntranslation, even beating the early attention-based supervised model.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 10:13:04 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 06:46:26 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 11:43:27 GMT"}, {"version": "v4", "created": "Tue, 11 Jun 2019 03:43:41 GMT"}, {"version": "v5", "created": "Fri, 21 Jun 2019 04:36:52 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Song", "Kaitao", ""], ["Tan", "Xu", ""], ["Qin", "Tao", ""], ["Lu", "Jianfeng", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1905.02497", "submitter": "Sudip Mittal", "authors": "Aditya Pingle, Aritran Piplai, Sudip Mittal, Anupam Joshi, James Holt,\n  Richard Zak", "title": "RelExt: Relation Extraction using Deep Learning approaches for\n  Cybersecurity Knowledge Graph Improvement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security Analysts that work in a `Security Operations Center' (SoC) play a\nmajor role in ensuring the security of the organization. The amount of\nbackground knowledge they have about the evolving and new attacks makes a\nsignificant difference in their ability to detect attacks. Open source threat\nintelligence sources, like text descriptions about cyber-attacks, can be stored\nin a structured fashion in a cybersecurity knowledge graph. A cybersecurity\nknowledge graph can be paramount in aiding a security analyst to detect cyber\nthreats because it stores a vast range of cyber threat information in the form\nof semantic triples which can be queried. A semantic triple contains two\ncybersecurity entities with a relationship between them. In this work, we\npropose a system to create semantic triples over cybersecurity text, using deep\nlearning approaches to extract possible relationships. We use the set of\nsemantic triples generated through our system to assert in a cybersecurity\nknowledge graph. Security Analysts can retrieve this data from the knowledge\ngraph, and use this information to form a decision about a cyber-attack.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 12:30:55 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 13:49:36 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Pingle", "Aditya", ""], ["Piplai", "Aritran", ""], ["Mittal", "Sudip", ""], ["Joshi", "Anupam", ""], ["Holt", "James", ""], ["Zak", "Richard", ""]]}, {"id": "1905.02549", "submitter": "Mohsen Annabestani", "authors": "Mohsen Annabestani, Alireza Rowhanimanesh, Aylar Mizani, Akram Rezaei", "title": "Descriptive evaluation of students using fuzzy approximate reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, descriptive evaluation has been introduced as a new model\nfor educational evaluation of Iranian students. The current descriptive\nevaluation method is based on four-valued logic. Assessing all students with\nonly four values is led to a lack of relative justice and the creation of\nunrealistic equality. Also, the complexity of the evaluation process in the\ncurrent method increases teacher errors likelihood. As a suitable solution, in\nthis paper, a fuzzy descriptive evaluation system has been proposed. The\nproposed method is based on fuzzy logic, which is an infinite-valued logic and\nit can perform approximate reasoning on natural language propositions. By the\nproposed fuzzy system, student assessment is performed over the school year\nwith infinite values instead of four values. But to eliminate the diversity of\nassigned values to students, at the end of the school year, the calculated\nvalues for each student will be rounded to the nearest value of the four\nstandard values of the current descriptive evaluation system. It can be\nimplemented easily in an appropriate smartphone app, which makes it much easier\nfor the teachers to evaluate the evaluation process. In this paper, the\nevaluation process of the elementary third-grade mathematics course in Iran\nduring the period from the beginning of the MEHR (The Seventh month of Iran) to\nthe end of BAHMAN (The Eleventh Month of Iran) is examined by the proposed\nsystem. To evaluate the validity of this system, the proposed method has been\nsimulated in MATLAB software.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 13:25:22 GMT"}, {"version": "v2", "created": "Sat, 11 May 2019 13:49:49 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Annabestani", "Mohsen", ""], ["Rowhanimanesh", "Alireza", ""], ["Mizani", "Aylar", ""], ["Rezaei", "Akram", ""]]}, {"id": "1905.02606", "submitter": "Wen Dong", "authors": "Wen Dong and Bo Liu and Fan Yang", "title": "Optimal Control of Complex Systems through Variational Inference with a\n  Discrete Event Decision Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex social systems are composed of interconnected individuals whose\ninteractions result in group behaviors. Optimal control of a real-world complex\nsystem has many applications, including road traffic management, epidemic\nprevention, and information dissemination. However, such real-world complex\nsystem control is difficult to achieve because of high-dimensional and\nnon-linear system dynamics, and the exploding state and action spaces for the\ndecision maker. Prior methods can be divided into two categories:\nsimulation-based and analytical approaches. Existing simulation approaches have\nhigh-variance in Monte Carlo integration, and the analytical approaches suffer\nfrom modeling inaccuracy. We adopted simulation modeling in specifying the\ncomplex dynamics of a complex system, and developed analytical solutions for\nsearching optimal strategies in a complex network with high-dimensional\nstate-action space. To capture the complex system dynamics, we formulate the\ncomplex social network decision making problem as a discrete event decision\nprocess. To address the curse of dimensionality and search in high-dimensional\nstate action spaces in complex systems, we reduce control of a complex system\nto variational inference and parameter learning, introduce Bethe entropy\napproximation, and develop an expectation propagation algorithm. Our proposed\nalgorithm leads to higher system expected rewards, faster convergence, and\nlower variance of value function in a real-world transportation scenario than\nstate-of-the-art analytical and sampling approaches.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 14:26:09 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Dong", "Wen", ""], ["Liu", "Bo", ""], ["Yang", "Fan", ""]]}, {"id": "1905.02662", "submitter": "Mikhail Burtsev", "authors": "Artyom Y. Sorokin and Mikhail S. Burtsev", "title": "Continual and Multi-task Reinforcement Learning With Shared Episodic\n  Memory", "comments": "Presented at the Task-Agnostic Reinforcement Learning Workshop at\n  ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Episodic memory plays an important role in the behavior of animals and\nhumans. It allows the accumulation of information about current state of the\nenvironment in a task-agnostic way. This episodic representation can be later\naccessed by down-stream tasks in order to make their execution more efficient.\nIn this work, we introduce the neural architecture with shared episodic memory\n(SEM) for learning and the sequential execution of multiple tasks. We\nexplicitly split the encoding of episodic memory and task-specific memory into\nseparate recurrent sub-networks. An agent augmented with SEM was able to\neffectively reuse episodic knowledge collected during other tasks to improve\nits policy on a current task in the Taxi problem. Repeated use of episodic\nrepresentation in continual learning experiments facilitated acquisition of\nnovel skills in the same environment.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 16:08:36 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Sorokin", "Artyom Y.", ""], ["Burtsev", "Mikhail S.", ""]]}, {"id": "1905.02680", "submitter": "Carl-Johan Hoel", "authors": "Carl-Johan Hoel, Katherine Driggs-Campbell, Krister Wolff, Leo Laine,\n  Mykel J. Kochenderfer", "title": "Combining Planning and Deep Reinforcement Learning in Tactical Decision\n  Making for Autonomous Driving", "comments": null, "journal-ref": "IEEE Transactions on Intelligent Vehicles, 2019", "doi": "10.1109/TIV.2019.2955905", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tactical decision making for autonomous driving is challenging due to the\ndiversity of environments, the uncertainty in the sensor information, and the\ncomplex interaction with other road users. This paper introduces a general\nframework for tactical decision making, which combines the concepts of planning\nand learning, in the form of Monte Carlo tree search and deep reinforcement\nlearning. The method is based on the AlphaGo Zero algorithm, which is extended\nto a domain with a continuous state space where self-play cannot be used. The\nframework is applied to two different highway driving cases in a simulated\nenvironment and it is shown to perform better than a commonly used baseline\nmethod. The strength of combining planning and learning is also illustrated by\na comparison to using the Monte Carlo tree search or the neural network policy\nseparately.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 12:50:14 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Hoel", "Carl-Johan", ""], ["Driggs-Campbell", "Katherine", ""], ["Wolff", "Krister", ""], ["Laine", "Leo", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1905.02690", "submitter": "Vieri Giuliano Santucci", "authors": "Vieri Giuliano Santucci, Emilio Cartoni, Bruno Castro da Silva,\n  Gianluca Baldassarre", "title": "Autonomous Open-Ended Learning of Interdependent Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomy is fundamental for artificial agents acting in complex real-world\nscenarios. The acquisition of many different skills is pivotal to foster\nversatile autonomous behaviour and thus a main objective for robotics and\nmachine learning. Intrinsic motivations have proven to properly generate a\ntask-agnostic signal to drive the autonomous acquisition of multiple policies\nin settings requiring the learning of multiple tasks. However, in real world\nscenarios tasks may be interdependent so that some of them may constitute the\nprecondition for learning other ones. Despite different strategies have been\nused to tackle the acquisition of interdependent/hierarchical tasks, fully\nautonomous open-ended learning in these scenarios is still an open question.\nBuilding on previous research within the framework of intrinsically-motivated\nopen-ended learning, we propose an architecture for robot control that tackles\nthis problem from the point of view of decision making, i.e. treating the\nselection of tasks as a Markov Decision Process where the system selects the\npolicies to be trained in order to maximise its competence over all the tasks.\nThe system is then tested with a humanoid robot solving interdependent multiple\nreaching tasks.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 16:51:13 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Santucci", "Vieri Giuliano", ""], ["Cartoni", "Emilio", ""], ["da Silva", "Bruno Castro", ""], ["Baldassarre", "Gianluca", ""]]}, {"id": "1905.02691", "submitter": "Patrick M. Pilarski", "authors": "Patrick M. Pilarski, Andrew Butcher, Michael Johanson, Matthew M.\n  Botvinick, Andrew Bolt, Adam S. R. Parker", "title": "Learned human-agent decision-making, communication and joint action in a\n  virtual reality environment", "comments": "5 pages, 3 figures. Accepted to The 4th Multidisciplinary Conference\n  on Reinforcement Learning and Decision Making, July 7-10, 2019, McGill\n  University, Montreal, Quebec, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans make decisions and act alongside other humans to pursue both\nshort-term and long-term goals. As a result of ongoing progress in areas such\nas computing science and automation, humans now also interact with non-human\nagents of varying complexity as part of their day-to-day activities;\nsubstantial work is being done to integrate increasingly intelligent machine\nagents into human work and play. With increases in the cognitive, sensory, and\nmotor capacity of these agents, intelligent machinery for human assistance can\nnow reasonably be considered to engage in joint action with humans---i.e., two\nor more agents adapting their behaviour and their understanding of each other\nso as to progress in shared objectives or goals. The mechanisms, conditions,\nand opportunities for skillful joint action in human-machine partnerships is of\ngreat interest to multiple communities. Despite this, human-machine joint\naction is as yet under-explored, especially in cases where a human and an\nintelligent machine interact in a persistent way during the course of\nreal-time, daily-life experience. In this work, we contribute a virtual reality\nenvironment wherein a human and an agent can adapt their predictions, their\nactions, and their communication so as to pursue a simple foraging task. In a\ncase study with a single participant, we provide an example of human-agent\ncoordination and decision-making involving prediction learning on the part of\nthe human and the machine agent, and control learning on the part of the\nmachine agent wherein audio communication signals are used to cue its human\npartner in service of acquiring shared reward. These comparisons suggest the\nutility of studying human-machine coordination in a virtual reality\nenvironment, and identify further research that will expand our understanding\nof persistent human-machine joint action.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 16:53:48 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Pilarski", "Patrick M.", ""], ["Butcher", "Andrew", ""], ["Johanson", "Michael", ""], ["Botvinick", "Matthew M.", ""], ["Bolt", "Andrew", ""], ["Parker", "Adam S. R.", ""]]}, {"id": "1905.02698", "submitter": "John Mern", "authors": "John Mern and Dorsa Sadigh and Mykel Kochenderfer", "title": "Object Exchangeability in Reinforcement Learning: Extended Abstract", "comments": "In Proceedings of the 18th International Conference on Autonomous\n  Agents and Multiagent Systems (AAMAS 2019), Montreal,Canada, May 13 to 17,\n  2019,IFAAMAS, 3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep reinforcement learning has advanced significantly over the past\nseveral years, sample efficiency remains a major challenge. Careful choice of\ninput representations can help improve efficiency depending on the structure\npresent in the problem. In this work, we present an attention-based method to\nproject inputs into an efficient representation space that is invariant under\nchanges to input ordering. We show that our proposed representation results in\na search space that is a factor of m! smaller for inputs of m objects. Our\nexperiments demonstrate improvements in sample efficiency for policy gradient\nmethods on a variety of tasks. We show that our representation allows us to\nsolve problems that are otherwise intractable when using naive approaches.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 17:20:41 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Mern", "John", ""], ["Sadigh", "Dorsa", ""], ["Kochenderfer", "Mykel", ""]]}, {"id": "1905.02719", "submitter": "Masanari Kimura", "authors": "Masanari Kimura, Masayuki Tanaka", "title": "Intentional Attention Mask Transformation for Robust CNN Classification", "comments": "arXiv admin note: substantial text overlap with arXiv:1904.13078", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks have achieved impressive results in various\ntasks, but interpreting the internal mechanism is a challenging problem. To\ntackle this problem, we exploit a multi-channel attention mechanism in feature\nspace. Our network architecture allows us to obtain an attention mask for each\nfeature while existing CNN visualization methods provide only a common\nattention mask for all features. We apply the proposed multi-channel attention\nmechanism to multi-attribute recognition task. We can obtain different\nattention mask for each feature and for each attribute. Those analyses give us\ndeeper insight into the feature space of CNNs. Furthermore, our proposed\nattention mechanism naturally derives a method for improving the robustness of\nCNNs. From the observation of feature space based on the proposed attention\nmask, we demonstrate that we can obtain robust CNNs by intentionally\nemphasizing features that are important for attributes. The experimental\nresults for the benchmark dataset show that the proposed method gives high\nhuman interpretability while accurately grasping the attributes of the data,\nand improves network robustness.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 08:16:46 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 06:22:10 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Kimura", "Masanari", ""], ["Tanaka", "Masayuki", ""]]}, {"id": "1905.02810", "submitter": "Jingyuan Wang", "authors": "Kai Feng, Han Hong, Ke Tang, Jingyuan Wang", "title": "Decision Making with Machine Learning and ROC Curves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI econ.GN q-fin.EC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Receiver Operating Characteristic (ROC) curve is a representation of the\nstatistical information discovered in binary classification problems and is a\nkey concept in machine learning and data science. This paper studies the\nstatistical properties of ROC curves and its implication on model selection. We\nanalyze the implications of different models of incentive heterogeneity and\ninformation asymmetry on the relation between human decisions and the ROC\ncurves. Our theoretical discussion is illustrated in the context of a large\ndata set of pregnancy outcomes and doctor diagnosis from the Pre-Pregnancy\nCheckups of reproductive age couples in Henan Province provided by the Chinese\nMinistry of Health.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 08:01:23 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Feng", "Kai", ""], ["Hong", "Han", ""], ["Tang", "Ke", ""], ["Wang", "Jingyuan", ""]]}, {"id": "1905.02840", "submitter": "Andrea Giovanni Nuzzolese", "authors": "Valentina Anita Carriero, Aldo Gangemi, Maria Letizia Mancinelli,\n  Ludovica Marinucci, Andrea Giovanni Nuzzolese, Valentina Presutti, Chiara\n  Veninata", "title": "ArCo: the Italian Cultural Heritage Knowledge Graph", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-30796-7_3", "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  ArCo is the Italian Cultural Heritage knowledge graph, consisting of a\nnetwork of seven vocabularies and 169 million triples about 820 thousand\ncultural entities. It is distributed jointly with a SPARQL endpoint, a software\nfor converting catalogue records to RDF, and a rich suite of documentation\nmaterial (testing, evaluation, how-to, examples, etc.). ArCo is based on the\nofficial General Catalogue of the Italian Ministry of Cultural Heritage and\nActivities (MiBAC) - and its associated encoding regulations - which collects\nand validates the catalogue records of (ideally) all Italian Cultural Heritage\nproperties (excluding libraries and archives), contributed by CH administrators\nfrom all over Italy. We present its structure, design methods and tools, its\ngrowing community, and delineate its importance, quality, and impact.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 23:11:06 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Carriero", "Valentina Anita", ""], ["Gangemi", "Aldo", ""], ["Mancinelli", "Maria Letizia", ""], ["Marinucci", "Ludovica", ""], ["Nuzzolese", "Andrea Giovanni", ""], ["Presutti", "Valentina", ""], ["Veninata", "Chiara", ""]]}, {"id": "1905.02843", "submitter": "Venkateshwaran Balasubramanian", "authors": "Erkan Baser, Venkateshwaran Balasubramanian, Prarthana Bhattacharyya,\n  Krzysztof Czarnecki", "title": "FANTrack: 3D Multi-Object Tracking with Feature Association Network", "comments": "8 pages, 10 figures, IEEE Intelligent Vehicles Symposium (IV 19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a data-driven approach to online multi-object tracking (MOT) that\nuses a convolutional neural network (CNN) for data association in a\ntracking-by-detection framework. The problem of multi-target tracking aims to\nassign noisy detections to a-priori unknown and time-varying number of tracked\nobjects across a sequence of frames. A majority of the existing solutions focus\non either tediously designing cost functions or formulating the task of data\nassociation as a complex optimization problem that can be solved effectively.\nInstead, we exploit the power of deep learning to formulate the data\nassociation problem as inference in a CNN. To this end, we propose to learn a\nsimilarity function that combines cues from both image and spatial features of\nobjects. Our solution learns to perform global assignments in 3D purely from\ndata, handles noisy detections and a varying number of targets, and is easy to\ntrain. We evaluate our approach on the challenging KITTI dataset and show\ncompetitive results. Our code is available at\nhttps://git.uwaterloo.ca/wise-lab/fantrack.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 23:26:03 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Baser", "Erkan", ""], ["Balasubramanian", "Venkateshwaran", ""], ["Bhattacharyya", "Prarthana", ""], ["Czarnecki", "Krzysztof", ""]]}, {"id": "1905.02845", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Maria N. Samad, Sayema Asif Mashhadi, Tania Kapoor,\n  Wahab Ali, Fakhri Karray, Mark Crowley", "title": "Feature Selection and Feature Extraction in Pattern Analysis: A\n  Literature Review", "comments": "14 pages, 1 figure, 2 tables, survey (literature review) paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pattern analysis often requires a pre-processing stage for extracting or\nselecting features in order to help the classification, prediction, or\nclustering stage discriminate or represent the data in a better way. The reason\nfor this requirement is that the raw data are complex and difficult to process\nwithout extracting or selecting appropriate features beforehand. This paper\nreviews theory and motivation of different common methods of feature selection\nand extraction and introduces some of their applications. Some numerical\nimplementations are also shown for these methods. Finally, the methods in\nfeature selection and extraction are compared.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 23:41:34 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Samad", "Maria N.", ""], ["Mashhadi", "Sayema Asif", ""], ["Kapoor", "Tania", ""], ["Ali", "Wahab", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "1905.02850", "submitter": "Boris Knyazev", "authors": "Boris Knyazev, Graham W. Taylor, Mohamed R. Amer", "title": "Understanding Attention and Generalization in Graph Neural Networks", "comments": "NeurIPS 2019, camera-ready and supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to better understand attention over nodes in graph neural networks\n(GNNs) and identify factors influencing its effectiveness. We particularly\nfocus on the ability of attention GNNs to generalize to larger, more complex or\nnoisy graphs. Motivated by insights from the work on Graph Isomorphism\nNetworks, we design simple graph reasoning tasks that allow us to study\nattention in a controlled environment. We find that under typical conditions\nthe effect of attention is negligible or even harmful, but under certain\nconditions it provides an exceptional gain in performance of more than 60% in\nsome of our classification tasks. Satisfying these conditions in practice is\nchallenging and often requires optimal initialization or supervised training of\nattention. We propose an alternative recipe and train attention in a\nweakly-supervised fashion that approaches the performance of supervised models,\nand, compared to unsupervised models, improves results on several synthetic as\nwell as real datasets. Source code and datasets are available at\nhttps://github.com/bknyaz/graph_attention_pool.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 00:30:25 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 11:40:58 GMT"}, {"version": "v3", "created": "Mon, 28 Oct 2019 14:51:04 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Knyazev", "Boris", ""], ["Taylor", "Graham W.", ""], ["Amer", "Mohamed R.", ""]]}, {"id": "1905.02876", "submitter": "Giorgos Bouritsas", "authors": "Giorgos Bouritsas, Sergiy Bokhnyak, Stylianos Ploumpis, Michael\n  Bronstein, Stefanos Zafeiriou", "title": "Neural 3D Morphable Models: Spiral Convolutional Networks for 3D Shape\n  Representation Learning and Generation", "comments": "to appear at ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models for 3D geometric data arise in many important applications\nin 3D computer vision and graphics. In this paper, we focus on 3D deformable\nshapes that share a common topological structure, such as human faces and\nbodies. Morphable Models and their variants, despite their linear formulation,\nhave been widely used for shape representation, while most of the recently\nproposed nonlinear approaches resort to intermediate representations, such as\n3D voxel grids or 2D views. In this work, we introduce a novel graph\nconvolutional operator, acting directly on the 3D mesh, that explicitly models\nthe inductive bias of the fixed underlying graph. This is achieved by enforcing\nconsistent local orderings of the vertices of the graph, through the spiral\noperator, thus breaking the permutation invariance property that is adopted by\nall the prior work on Graph Neural Networks. Our operator comes by construction\nwith desirable properties (anisotropic, topology-aware, lightweight,\neasy-to-optimise), and by using it as a building block for traditional deep\ngenerative architectures, we demonstrate state-of-the-art results on a variety\nof 3D shape datasets compared to the linear Morphable Model and other graph\nconvolutional operators.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 02:37:27 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 21:14:27 GMT"}, {"version": "v3", "created": "Sat, 3 Aug 2019 00:14:45 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Bouritsas", "Giorgos", ""], ["Bokhnyak", "Sergiy", ""], ["Ploumpis", "Stylianos", ""], ["Bronstein", "Michael", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "1905.02895", "submitter": "Sudip Mittal", "authors": "Sudip Mittal, Anupam Joshi, Tim Finin", "title": "Cyber-All-Intel: An AI for Security related Threat Intelligence", "comments": "arXiv admin note: substantial text overlap with arXiv:1708.03310", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keeping up with threat intelligence is a must for a security analyst today.\nThere is a volume of information present in `the wild' that affects an\norganization. We need to develop an artificial intelligence system that scours\nthe intelligence sources, to keep the analyst updated about various threats\nthat pose a risk to her organization. A security analyst who is better `tapped\nin' can be more effective.\n  In this paper we present, Cyber-All-Intel an artificial intelligence system\nto aid a security analyst. It is a system for knowledge extraction,\nrepresentation and analytics in an end-to-end pipeline grounded in the\ncybersecurity informatics domain. It uses multiple knowledge representations\nlike, vector spaces and knowledge graphs in a 'VKG structure' to store incoming\nintelligence. The system also uses neural network models to pro-actively\nimprove its knowledge. We have also created a query engine and an alert system\nthat can be used by an analyst to find actionable cybersecurity insights.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 12:15:32 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Mittal", "Sudip", ""], ["Joshi", "Anupam", ""], ["Finin", "Tim", ""]]}, {"id": "1905.02914", "submitter": "Linh Nguyen PhD", "authors": "Dung Tien Pham, Thai Van Nguyen, Hai Xuan Le, Linh Nguyen, Nguyen Huu\n  Thai, Tuan Anh Phan, Hai Tuan Pham, Anh Hoai Duong", "title": "Adaptive neural network based dynamic surface control for uncertain dual\n  arm robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper discusses an adaptive strategy to effectively control nonlinear\nmanipulation motions of a dual arm robot (DAR) under system uncertainties\nincluding parameter variations, actuator nonlinearities and external\ndisturbances. It is proposed that the control scheme is first derived from the\ndynamic surface control (DSC) method, which allows the robot's end-effectors to\nrobustly track the desired trajectories. Moreover, since exactly determining\nthe DAR system's dynamics is impractical due to the system uncertainties, the\nuncertain system parameters are then proposed to be adaptively estimated by the\nuse of the radial basis function network (RBFN). The adaptation mechanism is\nderived from the Lyapunov theory, which theoretically guarantees stability of\nthe closed-loop control system. The effectiveness of the proposed RBFN-DSC\napproach is demonstrated by implementing the algorithm in a synthetic\nenvironment with realistic parameters, where the obtained results are highly\npromising.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 05:03:46 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Pham", "Dung Tien", ""], ["Van Nguyen", "Thai", ""], ["Le", "Hai Xuan", ""], ["Nguyen", "Linh", ""], ["Thai", "Nguyen Huu", ""], ["Phan", "Tuan Anh", ""], ["Pham", "Hai Tuan", ""], ["Duong", "Anh Hoai", ""]]}, {"id": "1905.02940", "submitter": "Yunyou Huang", "authors": "Yunyou Huang, Zhifei Zhang, Nana Wang, Nengquan Li, Mengjia Du,\n  Tianshu Hao and Jianfeng Zhan", "title": "A new direction to promote the implementation of artificial intelligence\n  in natural clinical settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) researchers claim that they have made great\n`achievements' in clinical realms. However, clinicians point out the so-called\n`achievements' have no ability to implement into natural clinical settings. The\nroot cause for this huge gap is that many essential features of natural\nclinical tasks are overlooked by AI system developers without medical\nbackground. In this paper, we propose that the clinical benchmark suite is a\nnovel and promising direction to capture the essential features of the\nreal-world clinical tasks, hence qualifies itself for guiding the development\nof AI systems, promoting the implementation of AI in real-world clinical\npractice.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 07:26:27 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Huang", "Yunyou", ""], ["Zhang", "Zhifei", ""], ["Wang", "Nana", ""], ["Li", "Nengquan", ""], ["Du", "Mengjia", ""], ["Hao", "Tianshu", ""], ["Zhan", "Jianfeng", ""]]}, {"id": "1905.02941", "submitter": "Yufei Han", "authors": "Yufei Han and Xiangliang Zhang", "title": "Robust Federated Training via Collaborative Machine Teaching using\n  Trusted Instances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Federated learning performs distributed model training using local data\nhosted by agents. It shares only model parameter updates for iterative\naggregation at the server. Although it is privacy-preserving by design,\nfederated learning is vulnerable to noise corruption of local agents, as\ndemonstrated in the previous study on adversarial data poisoning threat against\nfederated learning systems. Even a single noise-corrupted agent can bias the\nmodel training. In our work, we propose a collaborative and privacy-preserving\nmachine teaching paradigm with multiple distributed teachers, to improve\nrobustness of the federated training process against local data corruption. We\nassume that each local agent (teacher) have the resources to verify a small\nportions of trusted instances, which may not by itself be adequate for\nlearning. In the proposed collaborative machine teaching method, these trusted\ninstances guide the distributed agents to jointly select a compact while\ninformative training subset from data hosted by their own. Simultaneously, the\nagents learn to add changes of limited magnitudes into the selected data\ninstances, in order to improve the testing performances of the federally\ntrained model despite of the training data corruption. Experiments on toy and\nreal data demonstrate that our approach can identify training set bugs\neffectively and suggest appropriate changes to the labels. Our algorithm is a\nstep toward trustworthy machine learning.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 07:27:04 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Han", "Yufei", ""], ["Zhang", "Xiangliang", ""]]}, {"id": "1905.02947", "submitter": "Soujanya Poria", "authors": "Soujanya Poria, Navonil Majumder, Rada Mihalcea, Eduard Hovy", "title": "Emotion Recognition in Conversation: Research Challenges, Datasets, and\n  Recent Advances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Emotion is intrinsic to humans and consequently emotion understanding is a\nkey part of human-like artificial intelligence (AI). Emotion recognition in\nconversation (ERC) is becoming increasingly popular as a new research frontier\nin natural language processing (NLP) due to its ability to mine opinions from\nthe plethora of publicly available conversational data in platforms such as\nFacebook, Youtube, Reddit, Twitter, and others. Moreover, it has potential\napplications in health-care systems (as a tool for psychological analysis),\neducation (understanding student frustration) and more. Additionally, ERC is\nalso extremely important for generating emotion-aware dialogues that require an\nunderstanding of the user's emotions. Catering to these needs calls for\neffective and scalable conversational emotion-recognition algorithms. However,\nit is a strenuous problem to solve because of several research challenges. In\nthis paper, we discuss these challenges and shed light on the recent research\nin this field. We also describe the drawbacks of these approaches and discuss\nthe reasons why they fail to successfully overcome the research challenges in\nERC.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 07:46:30 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Poria", "Soujanya", ""], ["Majumder", "Navonil", ""], ["Mihalcea", "Rada", ""], ["Hovy", "Eduard", ""]]}, {"id": "1905.03030", "submitter": "Pedro Alejandro Ortega", "authors": "Pedro A. Ortega, Jane X. Wang, Mark Rowland, Tim Genewein, Zeb\n  Kurth-Nelson, Razvan Pascanu, Nicolas Heess, Joel Veness, Alex Pritzel, Pablo\n  Sprechmann, Siddhant M. Jayakumar, Tom McGrath, Kevin Miller, Mohammad Azar,\n  Ian Osband, Neil Rabinowitz, Andr\\'as Gy\\\"orgy, Silvia Chiappa, Simon\n  Osindero, Yee Whye Teh, Hado van Hasselt, Nando de Freitas, Matthew\n  Botvinick, Shane Legg", "title": "Meta-learning of Sequential Strategies", "comments": "DeepMind Technical Report (15 pages, 6 figures). Version V1.1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report we review memory-based meta-learning as a tool for building\nsample-efficient strategies that learn from past experience to adapt to any\ntask within a target class. Our goal is to equip the reader with the conceptual\nfoundations of this tool for building new, scalable agents that operate on\nbroad domains. To do so, we present basic algorithmic templates for building\nnear-optimal predictors and reinforcement learners which behave as if they had\na probabilistic model that allowed them to efficiently exploit task structure.\nFurthermore, we recast memory-based meta-learning within a Bayesian framework,\nshowing that the meta-learned strategies are near-optimal because they amortize\nBayes-filtered data, where the adaptation is implemented in the memory dynamics\nas a state-machine of sufficient statistics. Essentially, memory-based\nmeta-learning translates the hard problem of probabilistic sequential inference\ninto a regression problem.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 12:27:20 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 18:09:19 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Ortega", "Pedro A.", ""], ["Wang", "Jane X.", ""], ["Rowland", "Mark", ""], ["Genewein", "Tim", ""], ["Kurth-Nelson", "Zeb", ""], ["Pascanu", "Razvan", ""], ["Heess", "Nicolas", ""], ["Veness", "Joel", ""], ["Pritzel", "Alex", ""], ["Sprechmann", "Pablo", ""], ["Jayakumar", "Siddhant M.", ""], ["McGrath", "Tom", ""], ["Miller", "Kevin", ""], ["Azar", "Mohammad", ""], ["Osband", "Ian", ""], ["Rabinowitz", "Neil", ""], ["Gy\u00f6rgy", "Andr\u00e1s", ""], ["Chiappa", "Silvia", ""], ["Osindero", "Simon", ""], ["Teh", "Yee Whye", ""], ["van Hasselt", "Hado", ""], ["de Freitas", "Nando", ""], ["Botvinick", "Matthew", ""], ["Legg", "Shane", ""]]}, {"id": "1905.03209", "submitter": "Sharib Ali Dr.", "authors": "Sharib Ali, Felix Zhou, Christian Daul, Barbara Braden, Adam Bailey,\n  Stefano Realdon, James East, Georges Wagni\\`eres, Victor Loschenov, Enrico\n  Grisan, Walter Blondel, Jens Rittscher", "title": "Endoscopy artifact detection (EAD 2019) challenge dataset", "comments": "12 pages, EAD2019 dataset description", "journal-ref": null, "doi": "10.17632/C7FJBXCGJ9.1", "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Endoscopic artifacts are a core challenge in facilitating the diagnosis and\ntreatment of diseases in hollow organs. Precise detection of specific artifacts\nlike pixel saturations, motion blur, specular reflections, bubbles and debris\nis essential for high-quality frame restoration and is crucial for realizing\nreliable computer-assisted tools for improved patient care. At present most\nvideos in endoscopy are currently not analyzed due to the abundant presence of\nmulti-class artifacts in video frames. Through the endoscopic artifact\ndetection (EAD 2019) challenge, we address this key bottleneck problem by\nsolving the accurate identification and localization of endoscopic frame\nartifacts to enable further key quantitative analysis of unusable video frames\nsuch as mosaicking and 3D reconstruction which is crucial for delivering\nimproved patient care. This paper summarizes the challenge tasks and describes\nthe dataset and evaluation criteria established in the EAD 2019 challenge.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 16:53:14 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Ali", "Sharib", ""], ["Zhou", "Felix", ""], ["Daul", "Christian", ""], ["Braden", "Barbara", ""], ["Bailey", "Adam", ""], ["Realdon", "Stefano", ""], ["East", "James", ""], ["Wagni\u00e8res", "Georges", ""], ["Loschenov", "Victor", ""], ["Grisan", "Enrico", ""], ["Blondel", "Walter", ""], ["Rittscher", "Jens", ""]]}, {"id": "1905.03288", "submitter": "Abu Sufian", "authors": "Farhana Sultana, A. Sufian and Paramartha Dutta", "title": "Advancements in Image Classification using Convolutional Neural Network", "comments": "9 pages, 15 figures, 3 Tables. Submitted to 2018 Fourth International\n  Conference on Research in Computational Intelligence and Communication\n  Networks(ICRCICN 2018)", "journal-ref": "2018 Fourth International Conference on Research in Computational\n  Intelligence and Communication Networks (ICRCICN)", "doi": "10.1109/ICRCICN.2018.8718718", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Network (CNN) is the state-of-the-art for image\nclassification task. Here we have briefly discussed different components of\nCNN. In this paper, We have explained different CNN architectures for image\nclassification. Through this paper, we have shown advancements in CNN from\nLeNet-5 to latest SENet model. We have discussed the model description and\ntraining details of each model. We have also drawn a comparison among those\nmodels.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 18:34:19 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Sultana", "Farhana", ""], ["Sufian", "A.", ""], ["Dutta", "Paramartha", ""]]}, {"id": "1905.03334", "submitter": "Da Shen", "authors": "Da Shen, Yuliya Lierler", "title": "SMT-based Constraint Answer Set Solver EZSMT+", "comments": "This is an extended abstract submitted to LPNMR-DC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint answer set programming integrates answer set programming with\nconstraint processing. System EZSMT+ is a constraint answer set programming\ntool that utilizes satisfiability modulo theory solvers for search. Its\ntheoretical foundation lies on generalizations of Niemela's characterization of\nanswer sets of a logic program via so called level rankings.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 20:57:00 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 17:26:41 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Shen", "Da", ""], ["Lierler", "Yuliya", ""]]}, {"id": "1905.03362", "submitter": "Bin Yang", "authors": "Bin Yang, Lin Yang, Xiaochun Li, Wenhan Zhang, Hua Zhou, Yequn Zhang,\n  Yongxiong Ren and Yinbo Shi", "title": "2-bit Model Compression of Deep Convolutional Neural Network on ASIC\n  Engine for Image Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image retrieval utilizes image descriptors to retrieve the most similar\nimages to a given query image. Convolutional neural network (CNN) is becoming\nthe dominant approach to extract image descriptors for image retrieval. For\nlow-power hardware implementation of image retrieval, the drawback of CNN-based\nfeature descriptor is that it requires hundreds of megabytes of storage. To\naddress this problem, this paper applies deep model quantization and\ncompression to CNN in ASIC chip for image retrieval. It is demonstrated that\nthe CNN-based features descriptor can be extracted using as few as 2-bit\nweights quantization to deliver a similar performance as floating-point model\nfor image retrieval. In addition, to implement CNN in ASIC, especially for\nlarge scale images, the limited buffer size of chips should be considered. To\nretrieve large scale images, we propose an improved pooling strategy, region\nnested invariance pooling (RNIP), which uses cropped sub-images for CNN.\nTesting results on chip show that integrating RNIP with the proposed 2-bit CNN\nmodel compression approach is capable of retrieving large scale images.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 21:48:42 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Yang", "Bin", ""], ["Yang", "Lin", ""], ["Li", "Xiaochun", ""], ["Zhang", "Wenhan", ""], ["Zhou", "Hua", ""], ["Zhang", "Yequn", ""], ["Ren", "Yongxiong", ""], ["Shi", "Yinbo", ""]]}, {"id": "1905.03381", "submitter": "Jiong Zhang", "authors": "Jiong Zhang, Hsiang-fu Yu, Inderjit S. Dhillon", "title": "AutoAssist: A Framework to Accelerate Training of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have yielded superior performance in many applications;\nhowever, the gradient computation in a deep model with millions of instances\nlead to a lengthy training process even with modern GPU/TPU hardware\nacceleration. In this paper, we propose AutoAssist, a simple framework to\naccelerate training of a deep neural network. Typically, as the training\nprocedure evolves, the amount of improvement in the current model by a\nstochastic gradient update on each instance varies dynamically. In AutoAssist,\nwe utilize this fact and design a simple instance shrinking operation, which is\nused to filter out instances with relatively low marginal improvement to the\ncurrent model; thus the computationally intensive gradient computations are\nperformed on informative instances as much as possible. We prove that the\nproposed technique outperforms vanilla SGD with existing importance sampling\napproaches for linear SVM problems, and establish an O(1/k) convergence for\nstrongly convex problems. In order to apply the proposed techniques to\naccelerate training of deep models, we propose to jointly train a very\nlightweight Assistant network in addition to the original deep network referred\nto as Boss. The Assistant network is designed to gauge the importance of a\ngiven instance with respect to the current Boss such that a shrinking operation\ncan be applied in the batch generator. With careful design, we train the Boss\nand Assistant in a nonblocking and asynchronous fashion such that overhead is\nminimal. We demonstrate that AutoAssist reduces the number of epochs by 40% for\ntraining a ResNet to reach the same test accuracy on an image classification\ndata set and saves 30% training time needed for a transformer model to yield\nthe same BLEU scores on a translation dataset.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 22:36:37 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Zhang", "Jiong", ""], ["Yu", "Hsiang-fu", ""], ["Dhillon", "Inderjit S.", ""]]}, {"id": "1905.03389", "submitter": "Vladimir Golkov", "authors": "Jan Schuchardt, Vladimir Golkov, Daniel Cremers", "title": "Learning to Evolve", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolution and learning are two of the fundamental mechanisms by which life\nadapts in order to survive and to transcend limitations. These biological\nphenomena inspired successful computational methods such as evolutionary\nalgorithms and deep learning. Evolution relies on random mutations and on\nrandom genetic recombination. Here we show that learning to evolve, i.e.\nlearning to mutate and recombine better than at random, improves the result of\nevolution in terms of fitness increase per generation and even in terms of\nattainable fitness. We use deep reinforcement learning to learn to dynamically\nadjust the strategy of evolutionary algorithms to varying circumstances. Our\nmethods outperform classical evolutionary algorithms on combinatorial and\ncontinuous optimization problems.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 23:35:02 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Schuchardt", "Jan", ""], ["Golkov", "Vladimir", ""], ["Cremers", "Daniel", ""]]}, {"id": "1905.03398", "submitter": "Yuanxin Wu", "authors": "Qi Cai, Tsung-Ching Lin, Yuanxin Wu, Wenxian Yu and Trieu-Kien Truong", "title": "General Method for Prime-point Cyclic Convolution over the Real Field", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general and fast method is conceived for computing the cyclic convolution\nof n points, where n is a prime number. This method fully exploits the internal\nstructure of the cyclic matrix, and hence leads to significant reduction of the\nmultiplication complexity in terms of CPU time by 50%, as compared with\nWinograd's algorithm. In this paper, we only consider the real and complex\nfields due to their most important applications, but in general, the idea\nbehind this method can be extended to any finite field of interest. Clearly, it\nis well-known that the discrete Fourier transform (DFT) can be expressed in\nterms of cyclic convolution, so it can be utilized to compute the DFT when the\nblock length is a prime.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 00:53:30 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Cai", "Qi", ""], ["Lin", "Tsung-Ching", ""], ["Wu", "Yuanxin", ""], ["Yu", "Wenxian", ""], ["Truong", "Trieu-Kien", ""]]}, {"id": "1905.03427", "submitter": "Luiz F. O. Moura Santos", "authors": "Luiz F. O. Moura Santos, Hugo T. Y. Yoshizaki, Claudio B. Cunha", "title": "Variable Neighborhood Search for the Bin Packing Problem with Compatible\n  Categories", "comments": "2018 SCALE Latin American Conference, Boston, USA, April 15th-16th,\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bin Packing with Conflicts (BPC) are problems in which items with\ncompatibility constraints must be packed in the least number of bins, not\nexceeding the capacity of the bins and ensuring that non-conflicting items are\npacked in each bin. In this work, we introduce the Bin Packing Problem with\nCompatible Categories (BPCC), a variant of the BPC in which items belong to\nconflicting or compatible categories, in opposition to the item-by-item\nincompatibility found in previous literature. It is a common problem in the\ncontext of last mile distribution to nanostores located in densely populated\nareas. To efficiently solve real-life sized instances of the problem, we\npropose a Variable Neighborhood Search (VNS) metaheuristic algorithm.\nComputational experiments suggest that the algorithm yields good solutions in\nvery short times while compared to linear integer programming running on a\nhigh-performance computing environment.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 03:14:15 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Santos", "Luiz F. O. Moura", ""], ["Yoshizaki", "Hugo T. Y.", ""], ["Cunha", "Claudio B.", ""]]}, {"id": "1905.03428", "submitter": "Shuo Feng", "authors": "Shuo Feng, Yiheng Feng, Haowei Sun, Shao Bao, Yi Zhang, Henry X. Liu", "title": "Testing Scenario Library Generation for Connected and Automated\n  Vehicles, Part II: Case Studies", "comments": "12 pages, 13 figures", "journal-ref": "IEEE Transactions on Intelligent Transportation Systems, 2020", "doi": "10.1109/TITS.2020.2988309", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing scenario library generation (TSLG) is a critical step for the\ndevelopment and deployment of connected and automated vehicles (CAVs). In Part\nI of this study, a general methodology for TSLG is proposed, and theoretical\nproperties are investigated regarding the accuracy and efficiency of CAV\nevaluation. This paper aims to provide implementation examples and guidelines,\nand to enhance the proposed methodology under high-dimensional scenarios. Three\ntypical cases, including cut-in, highway-exit, and car-following, are designed\nand studied in this paper. For each case, the process of library generation and\nCAV evaluation is elaborated. To address the challenges brought by high\ndimensions, the proposed methodology is further enhanced by reinforcement\nlearning technique. For all three cases, results show that the proposed methods\ncan accelerate the CAV evaluation process by multiple magnitudes with same\nevaluation accuracy, if compared with the on-road test method.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 03:22:37 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 22:17:26 GMT"}, {"version": "v3", "created": "Fri, 21 Feb 2020 21:41:12 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Feng", "Shuo", ""], ["Feng", "Yiheng", ""], ["Sun", "Haowei", ""], ["Bao", "Shao", ""], ["Zhang", "Yi", ""], ["Liu", "Henry X.", ""]]}, {"id": "1905.03493", "submitter": "Sakshi Agarwal", "authors": "Sakshi Agarwal and Lav R. Varshney", "title": "Limits of Deepfake Detection: A Robust Estimation Viewpoint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deepfake detection is formulated as a hypothesis testing problem to classify\nan image as genuine or GAN-generated. A robust statistics view of GANs is\nconsidered to bound the error probability for various GAN implementations in\nterms of their performance. The bounds are further simplified using a Euclidean\napproximation for the low error regime. Lastly, relationships between error\nprobability and epidemic thresholds for spreading processes in networks are\nestablished.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 09:01:08 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Agarwal", "Sakshi", ""], ["Varshney", "Lav R.", ""]]}, {"id": "1905.03494", "submitter": "Yuedong Xu", "authors": "Xinyu You, Xuanjie Li, Yuedong Xu, Hui Feng, Jin Zhao, Huaicheng Yan", "title": "Toward Packet Routing with Fully-distributed Multi-agent Deep\n  Reinforcement Learning", "comments": "12 pages, 10 figures", "journal-ref": "RAWNET workshop collocated with WiOpt 2019 Conference", "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Packet routing is one of the fundamental problems in computer networks in\nwhich a router determines the next-hop of each packet in the queue to get it as\nquickly as possible to its destination. Reinforcement learning (RL) has been\nintroduced to design autonomous packet routing policies with local information\nof stochastic packet arrival and service. However, the curse of dimensionality\nof RL prohibits the more comprehensive representation of dynamic network\nstates, thus limiting its potential benefit. In this paper, we propose a novel\npacket routing framework based on \\emph{multi-agent} deep reinforcement\nlearning (DRL) in which each router possess an \\emph{independent} LSTM\nrecurrent neural network for training and decision making in a \\emph{fully\ndistributed} environment. The LSTM recurrent neural network extracts routing\nfeatures from rich information regarding backlogged packets and past actions,\nand effectively approximates the value function of Q-learning. We further allow\neach route to communicate periodically with direct neighbors so that a broader\nview of network state can be incorporated. Experimental results manifest that\nour multi-agent DRL policy can strike the delicate balance between\ncongestion-aware and shortest routes, and significantly reduce the packet\ndelivery time in general network topologies compared with its counterparts.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 09:01:27 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 14:35:43 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["You", "Xinyu", ""], ["Li", "Xuanjie", ""], ["Xu", "Yuedong", ""], ["Feng", "Hui", ""], ["Zhao", "Jin", ""], ["Yan", "Huaicheng", ""]]}, {"id": "1905.03501", "submitter": "Yunfei Li", "authors": "Xiaoqin Zhang, Yunfei Li, Huimin Ma, Xiong Luo", "title": "Pretrain Soft Q-Learning with Imperfect Demonstrations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretraining reinforcement learning methods with demonstrations has been an\nimportant concept in the study of reinforcement learning since a large amount\nof computing power is spent on online simulations with existing reinforcement\nlearning algorithms. Pretraining reinforcement learning remains a significant\nchallenge in exploiting expert demonstrations whilst keeping exploration\npotentials, especially for value based methods. In this paper, we propose a\npretraining method for soft Q-learning. Our work is inspired by pretraining\nmethods for actor-critic algorithms since soft Q-learning is a value based\nalgorithm that is equivalent to policy gradient. The proposed method is based\non $\\gamma$-discounted biased policy evaluation with entropy regularization,\nwhich is also the updating target of soft Q-learning. Our method is evaluated\non various tasks from Atari 2600. Experiments show that our method effectively\nlearns from imperfect demonstrations, and outperforms other state-of-the-art\nmethods that learn from expert demonstrations.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 09:23:53 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Zhang", "Xiaoqin", ""], ["Li", "Yunfei", ""], ["Ma", "Huimin", ""], ["Luo", "Xiong", ""]]}, {"id": "1905.03554", "submitter": "Serkan Kiranyaz", "authors": "Serkan Kiranyaz, Onur Avci, Osama Abdeljaber, Turker Ince, Moncef\n  Gabbouj, Daniel J. Inman", "title": "1D Convolutional Neural Networks and Applications: A Survey", "comments": "20 pages, 17 figures, MSSP (Elsevier) submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last decade, Convolutional Neural Networks (CNNs) have become the\nde facto standard for various Computer Vision and Machine Learning operations.\nCNNs are feed-forward Artificial Neural Networks (ANNs) with alternating\nconvolutional and subsampling layers. Deep 2D CNNs with many hidden layers and\nmillions of parameters have the ability to learn complex objects and patterns\nproviding that they can be trained on a massive size visual database with\nground-truth labels. With a proper training, this unique ability makes them the\nprimary tool for various engineering applications for 2D signals such as images\nand video frames. Yet, this may not be a viable option in numerous applications\nover 1D signals especially when the training data is scarce or\napplication-specific. To address this issue, 1D CNNs have recently been\nproposed and immediately achieved the state-of-the-art performance levels in\nseveral applications such as personalized biomedical data classification and\nearly diagnosis, structural health monitoring, anomaly detection and\nidentification in power electronics and motor-fault detection. Another major\nadvantage is that a real-time and low-cost hardware implementation is feasible\ndue to the simple and compact configuration of 1D CNNs that perform only 1D\nconvolutions (scalar multiplications and additions). This paper presents a\ncomprehensive review of the general architecture and principals of 1D CNNs\nalong with their major engineering applications, especially focused on the\nrecent progress in this field. Their state-of-the-art performance is\nhighlighted concluding with their unique properties. The benchmark datasets and\nthe principal 1D CNN software used in those applications are also publically\nshared in a dedicated website.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 11:52:10 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Kiranyaz", "Serkan", ""], ["Avci", "Onur", ""], ["Abdeljaber", "Osama", ""], ["Ince", "Turker", ""], ["Gabbouj", "Moncef", ""], ["Inman", "Daniel J.", ""]]}, {"id": "1905.03578", "submitter": "Mohammadreza Zolfaghari", "authors": "Mohammadreza Zolfaghari, \\\"Ozg\\\"un \\c{C}i\\c{c}ek, Syed Mohsin Ali,\n  Farzaneh Mahdisoltani, Can Zhang, Thomas Brox", "title": "Learning Representations for Predicting Future Activities", "comments": "14 pages, ICCV 2019 submission, Code and Models:\n  https://github.com/lmb-freiburg/PreFAct", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IT cs.RO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Foreseeing the future is one of the key factors of intelligence. It involves\nunderstanding of the past and current environment as well as decent experience\nof its possible dynamics. In this work, we address future prediction at the\nabstract level of activities. We propose a network module for learning\nembeddings of the environment's dynamics in a self-supervised way. To take the\nambiguities and high variances in the future activities into account, we use a\nmulti-hypotheses scheme that can represent multiple futures. We demonstrate the\napproach by classifying future activities on the Epic-Kitchens and Breakfast\ndatasets. Moreover, we generate captions that describe the future activities\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 12:45:01 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Zolfaghari", "Mohammadreza", ""], ["\u00c7i\u00e7ek", "\u00d6zg\u00fcn", ""], ["Ali", "Syed Mohsin", ""], ["Mahdisoltani", "Farzaneh", ""], ["Zhang", "Can", ""], ["Brox", "Thomas", ""]]}, {"id": "1905.03592", "submitter": "Vijay Gadepally", "authors": "Vijay Gadepally, Justin Goodwin, Jeremy Kepner, Albert Reuther, Hayley\n  Reynolds, Siddharth Samsi, Jonathan Su, David Martinez", "title": "AI Enabling Technologies: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) has the opportunity to revolutionize the way the\nUnited States Department of Defense (DoD) and Intelligence Community (IC)\naddress the challenges of evolving threats, data deluge, and rapid courses of\naction. Developing an end-to-end artificial intelligence system involves\nparallel development of different pieces that must work together in order to\nprovide capabilities that can be used by decision makers, warfighters and\nanalysts. These pieces include data collection, data conditioning, algorithms,\ncomputing, robust artificial intelligence, and human-machine teaming. While\nmuch of the popular press today surrounds advances in algorithms and computing,\nmost modern AI systems leverage advances across numerous different fields.\nFurther, while certain components may not be as visible to end-users as others,\nour experience has shown that each of these interrelated components play a\nmajor role in the success or failure of an AI system. This article is meant to\nhighlight many of these technologies that are involved in an end-to-end AI\nsystem. The goal of this article is to provide readers with an overview of\nterminology, technical details and recent highlights from academia, industry\nand government. Where possible, we indicate relevant resources that can be used\nfor further reading and understanding.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 15:41:38 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Gadepally", "Vijay", ""], ["Goodwin", "Justin", ""], ["Kepner", "Jeremy", ""], ["Reuther", "Albert", ""], ["Reynolds", "Hayley", ""], ["Samsi", "Siddharth", ""], ["Su", "Jonathan", ""], ["Martinez", "David", ""]]}, {"id": "1905.03617", "submitter": "Sungjae Cho", "authors": "Sungjae Cho, Jaeseo Lim, Chris Hickey, Jung Ae Park, Byoung-Tak Zhang", "title": "Simulating Problem Difficulty in Arithmetic Cognition Through Dynamic\n  Connectionist Models", "comments": "7 pages; 15 figures; 5 tables; Published in the proceedings of the\n  17th International Conference on Cognitive Modelling (ICCM 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present study aims to investigate similarities between how humans and\nconnectionist models experience difficulty in arithmetic problems. Problem\ndifficulty was operationalized by the number of carries involved in solving a\ngiven problem. Problem difficulty was measured in humans by response time, and\nin models by computational steps. The present study found that both humans and\nconnectionist models experience difficulty similarly when solving binary\naddition and subtraction. Specifically, both agents found difficulty to be\nstrictly increasing with respect to the number of carries. Another notable\nsimilarity is that problem difficulty increases more steeply in subtraction\nthan in addition, for both humans and connectionist models. Further\ninvestigation on two model hyperparameters --- confidence threshold and hidden\ndimension --- shows higher confidence thresholds cause the model to take more\ncomputational steps to arrive at the correct answer. Likewise, larger hidden\ndimensions cause the model to take more computational steps to correctly answer\narithmetic problems; however, this effect by hidden dimensions is negligible.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 13:33:59 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 19:07:40 GMT"}, {"version": "v3", "created": "Wed, 2 Oct 2019 04:55:49 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Cho", "Sungjae", ""], ["Lim", "Jaeseo", ""], ["Hickey", "Chris", ""], ["Park", "Jung Ae", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1905.03638", "submitter": "Ruixue Liu", "authors": "Ruixue Liu, Baoyang Chen, Meng Chen, Youzheng Wu, Zhijie Qiu, Xiaodong\n  He", "title": "Mappa Mundi: An Interactive Artistic Mind Map Generator with Artificial\n  Imagination", "comments": "Paper accepted by IJCAI 2019 Demo track", "journal-ref": null, "doi": null, "report-no": "978-0-9992411-4-1", "categories": "cs.AI cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel real-time, collaborative, and interactive AI painting\nsystem, Mappa Mundi, for artistic Mind Map creation. The system consists of a\nvoice-based input interface, an automatic topic expansion module, and an image\nprojection module. The key innovation is to inject Artificial Imagination into\npainting creation by considering lexical and phonological similarities of\nlanguage, learning and inheriting artist's original painting style, and\napplying the principles of Dadaism and impossibility of improvisation. Our\nsystem indicates that AI and artist can collaborate seamlessly to create\nimaginative artistic painting and Mappa Mundi has been applied in art\nexhibition in UCCA, Beijing\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 13:51:46 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 11:22:59 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Liu", "Ruixue", ""], ["Chen", "Baoyang", ""], ["Chen", "Meng", ""], ["Wu", "Youzheng", ""], ["Qiu", "Zhijie", ""], ["He", "Xiaodong", ""]]}, {"id": "1905.03640", "submitter": "Kit Kuksenok", "authors": "Kit Kuksenok, Nina Pra{\\ss}", "title": "Transparency in Maintenance of Recruitment Chatbots", "comments": "4 pages, 3 figures, prepared for CHI2019 (Glasgow) workshop: Where is\n  the Human? Bridging the Gap Between AI and HCI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on experiences with implementing conversational agents in the\nrecruitment domain based on a machine learning (ML) system. Recruitment\nchatbots mediate communication between job-seekers and recruiters by exposing\nML data to recruiter teams. Errors are difficult to understand, communicate,\nand resolve because they may span and combine UX, ML, and software issues. In\nan effort to improve organizational and technical transparency, we came to rely\non a key contact role. Though effective for design and development, the\ncentralization of this role poses challenges for transparency in sustained\nmaintenance of this kind of ML-based mediating system.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 14:04:44 GMT"}], "update_date": "2019-05-18", "authors_parsed": [["Kuksenok", "Kit", ""], ["Pra\u00df", "Nina", ""]]}, {"id": "1905.03652", "submitter": "Baojian Zhou", "authors": "Baojian Zhou, Feng Chen, Yiming Ying", "title": "Stochastic Iterative Hard Thresholding for Graph-structured Sparsity\n  Optimization", "comments": "published in ICML-2019", "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic optimization algorithms update models with cheap per-iteration\ncosts sequentially, which makes them amenable for large-scale data analysis.\nSuch algorithms have been widely studied for structured sparse models where the\nsparsity information is very specific, e.g., convex sparsity-inducing norms or\n$\\ell^0$-norm. However, these norms cannot be directly applied to the problem\nof complex (non-convex) graph-structured sparsity models, which have important\napplication in disease outbreak and social networks, etc. In this paper, we\npropose a stochastic gradient-based method for solving graph-structured\nsparsity constraint problems, not restricted to the least square loss. We prove\nthat our algorithm enjoys a linear convergence up to a constant error, which is\ncompetitive with the counterparts in the batch learning setting. We conduct\nextensive experiments to show the efficiency and effectiveness of the proposed\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 14:24:43 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Zhou", "Baojian", ""], ["Chen", "Feng", ""], ["Ying", "Yiming", ""]]}, {"id": "1905.03658", "submitter": "Jason Ramapuram", "authors": "Jason Ramapuram and Russ Webb", "title": "Improving Discrete Latent Representations With Differentiable\n  Approximation Bridges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern neural network training relies on piece-wise (sub-)differentiable\nfunctions in order to use backpropagation to update model parameters. In this\nwork, we introduce a novel method to allow simple non-differentiable functions\nat intermediary layers of deep neural networks. We do so by training with a\ndifferentiable approximation bridge (DAB) neural network which approximates the\nnon-differentiable forward function and provides gradient updates during\nbackpropagation. We present strong empirical results (performing over 600\nexperiments) in four different domains: unsupervised (image) representation\nlearning, variational (image) density estimation, image classification, and\nsequence sorting to demonstrate that our proposed method improves state of the\nart performance. We demonstrate that training with DAB aided discrete\nnon-differentiable functions improves image reconstruction quality and\nposterior linear separability by 10% against the Gumbel-Softmax relaxed\nestimator [37, 26] as well as providing a 9% improvement in the test\nvariational lower bound in comparison to the state of the art RELAX [16]\ndiscrete estimator. We also observe an accuracy improvement of 77% in neural\nsequence sorting and a 25% improvement against the straight-through estimator\n[5] in an image classification setting. The DAB network is not used for\ninference and expands the class of functions that are usable in neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 14:31:59 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 13:46:02 GMT"}, {"version": "v3", "created": "Sat, 26 Oct 2019 01:41:50 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Ramapuram", "Jason", ""], ["Webb", "Russ", ""]]}, {"id": "1905.03692", "submitter": "Isaac Ronald Ward", "authors": "Isaac Ronald Ward, M. A. Asim K. Jalwana and Mohammed Bennamoun", "title": "Improving Image-Based Localization with Deep Learning: The Impact of the\n  Loss Function", "comments": "Version 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates the impact of the loss function on the performance of\nNeural Networks, in the context of a monocular, RGB-only, image localization\ntask. A common technique used when regressing a camera's pose from an image is\nto formulate the loss as a linear combination of positional and rotational mean\nsquared error (using tuned hyperparameters as coefficients). In this work we\nobserve that changes to rotation and position mutually affect the captured\nimage, and in order to improve performance, a pose regression network's loss\nfunction should include a term which combines the error of both of these\ncoupled quantities. Based on task specific observations and experimental\ntuning, we present said loss term, and create a new model by appending this\nloss term to the loss function of the pre-existing pose regression network\n`PoseNet'. We achieve improvements in the localization accuracy of the network\nfor indoor scenes; with decreases of up to 26.7% and 24.0% in the median\npositional and rotational error respectively, when compared to the default\nPoseNet.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 05:47:37 GMT"}, {"version": "v2", "created": "Sun, 28 Jul 2019 13:06:02 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Ward", "Isaac Ronald", ""], ["Jalwana", "M. A. Asim K.", ""], ["Bennamoun", "Mohammed", ""]]}, {"id": "1905.03700", "submitter": "Birgitta Dresp-Langley", "authors": "John M. Wandeto, Birgitta Dresp-Langley", "title": "Unsupervised automatic classification of Scanning Electron Microscopy\n  (SEM) images of CD4+ cells with varying extent of HIV virion infection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Archiving large sets of medical or cell images in digital libraries may\nrequire ordering randomly scattered sets of image data according to specific\ncriteria, such as the spatial extent of a specific local color or contrast\ncontent that reveals different meaningful states of a physiological structure,\ntissue, or cell in a certain order, indicating progression or recession of a\npathology, or the progressive response of a cell structure to treatment. Here\nwe used a Self Organized Map (SOM)-based, fully automatic and unsupervised,\nclassification procedure described in our earlier work and applied it to sets\nof minimally processed grayscale and/or color processed Scanning Electron\nMicroscopy (SEM) images of CD4+ T-lymphocytes (so-called helper cells) with\nvarying extent of HIV virion infection. It is shown that the quantization error\nin the SOM output after training permits to scale the spatial magnitude and the\ndirection of change (+ or -) in local pixel contrast or color across images of\na series with a reliability that exceeds that of any human expert. The\nprocedure is easily implemented and fast, and represents a promising step\ntowards low-cost automatic digital image archiving with minimal intervention of\na human operator.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 15:15:21 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Wandeto", "John M.", ""], ["Dresp-Langley", "Birgitta", ""]]}, {"id": "1905.03704", "submitter": "Yuenan Hou", "authors": "Yuenan Hou", "title": "Agnostic Lane Detection", "comments": "6 pages, 2 figures, our codes are available at\n  https://github.com/cardwing/Codes-for-Lane-Detection", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Lane detection is an important yet challenging task in autonomous driving,\nwhich is affected by many factors, e.g., light conditions, occlusions caused by\nother vehicles, irrelevant markings on the road and the inherent long and thin\nproperty of lanes. Conventional methods typically treat lane detection as a\nsemantic segmentation task, which assigns a class label to each pixel of the\nimage. This formulation heavily depends on the assumption that the number of\nlanes is pre-defined and fixed and no lane changing occurs, which does not\nalways hold. To make the lane detection model applicable to an arbitrary number\nof lanes and lane changing scenarios, we adopt an instance segmentation\napproach, which first differentiates lanes and background and then classify\neach lane pixel into each lane instance. Besides, a multi-task learning\nparadigm is utilized to better exploit the structural information and the\nfeature pyramid architecture is used to detect extremely thin lanes. Three\npopular lane detection benchmarks, i.e., TuSimple, CULane and BDD100K, are used\nto validate the effectiveness of our proposed algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 05:58:17 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Hou", "Yuenan", ""]]}, {"id": "1905.03706", "submitter": "Elad Levi", "authors": "Eli Brosh, Matan Friedmann, Ilan Kadar, Lev Yitzhak Lavy, Elad Levi,\n  Shmuel Rippa, Yair Lempert, Bruno Fernandez-Ruiz, Roei Herzig, Trevor Darrell", "title": "Accurate Visual Localization for Automotive Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate vehicle localization is a crucial step towards building effective\nVehicle-to-Vehicle networks and automotive applications. Yet standard grade GPS\ndata, such as that provided by mobile phones, is often noisy and exhibits\nsignificant localization errors in many urban areas. Approaches for accurate\nlocalization from imagery often rely on structure-based techniques, and thus\nare limited in scale and are expensive to compute. In this paper, we present a\nscalable visual localization approach geared for real-time performance. We\npropose a hybrid coarse-to-fine approach that leverages visual and GPS location\ncues. Our solution uses a self-supervised approach to learn a compact road\nimage representation. This representation enables efficient visual retrieval\nand provides coarse localization cues, which are fused with vehicle ego-motion\nto obtain high accuracy location estimates. As a benchmark to evaluate the\nperformance of our visual localization approach, we introduce a new large-scale\ndriving dataset based on video and GPS data obtained from a large-scale network\nof connected dash-cams. Our experiments confirm that our approach is highly\neffective in challenging urban environments, reducing localization error by an\norder of magnitude.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 15:48:10 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Brosh", "Eli", ""], ["Friedmann", "Matan", ""], ["Kadar", "Ilan", ""], ["Lavy", "Lev Yitzhak", ""], ["Levi", "Elad", ""], ["Rippa", "Shmuel", ""], ["Lempert", "Yair", ""], ["Fernandez-Ruiz", "Bruno", ""], ["Herzig", "Roei", ""], ["Darrell", "Trevor", ""]]}, {"id": "1905.03709", "submitter": "Victor Schmidt", "authors": "Victor Schmidt, Alexandra Luccioni, S. Karthik Mukkavilli, Narmada\n  Balasooriya, Kris Sankaran, Jennifer Chayes, Yoshua Bengio", "title": "Visualizing the Consequences of Climate Change Using Cycle-Consistent\n  Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a project that aims to generate images that depict accurate,\nvivid, and personalized outcomes of climate change using Cycle-Consistent\nAdversarial Networks (CycleGANs). By training our CycleGAN model on street-view\nimages of houses before and after extreme weather events (e.g. floods, forest\nfires, etc.), we learn a mapping that can then be applied to images of\nlocations that have not yet experienced these events. This visual\ntransformation is paired with climate model predictions to assess likelihood\nand type of climate-related events in the long term (50 years) in order to\nbring the future closer in the viewers mind. The eventual goal of our project\nis to enable individuals to make more informed choices about their climate\nfuture by creating a more visceral understanding of the effects of climate\nchange, while maintaining scientific credibility by drawing on climate model\nprojections.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 15:34:53 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Schmidt", "Victor", ""], ["Luccioni", "Alexandra", ""], ["Mukkavilli", "S. Karthik", ""], ["Balasooriya", "Narmada", ""], ["Sankaran", "Kris", ""], ["Chayes", "Jennifer", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1905.03715", "submitter": "Kin Ng", "authors": "Kin Ng", "title": "Tuned Inception V3 for Recognizing States of Cooking Ingredients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooking is a task that must be performed in a daily basis, and thus it is an\nactivity that many people take for granted. For humans preparing a meal comes\nnaturally, but for robots even preparing a simple sandwich results in an\nextremely difficult task. In robotics, designing kitchen robots is complicated\nsince cooking relies on a variety of physical interactions that are dependent\non different conditions such as changes in the environment, proper execution of\nsequential instructions, along with motions, and detection of the different\nstates in which cooking-ingredients can be in for their correct grasping and\nmanipulation. In this paper, we focus on the challenge of state recognition and\npropose a fine tuned convolutional neural network that makes use of transfer\nlearning by reusing the Inception V3 pre-trained model. The model is trained\nand validated on a cooking dataset consisting of eleven states (e.g. peeled,\ndiced, whole, etc.). The work presented on this paper could provide insight\ninto finding a potential solution to the problem.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 16:38:52 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Ng", "Kin", ""]]}, {"id": "1905.03726", "submitter": "Luca Mossina", "authors": "Luca Mossina and Emmanuel Rachelson and Daniel Delahaye", "title": "A Reinforcement Learning Perspective on the Optimal Control of Mutation\n  Probabilities for the (1+1) Evolutionary Algorithm: First Results on the\n  OneMax Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how Reinforcement Learning can be employed to optimally control\nparameters in evolutionary algorithms. We control the mutation probability of a\n(1+1) evolutionary algorithm on the OneMax function. This problem is modeled as\na Markov Decision Process and solved with Value Iteration via the known\ntransition probabilities. It is then solved via Q-Learning, a Reinforcement\nLearning algorithm, where the exact transition probabilities are not needed.\nThis approach also allows previous expert or empirical knowledge to be included\ninto learning. It opens new perspectives, both formally and computationally,\nfor the problem of parameter control in optimization.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 16:07:37 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Mossina", "Luca", ""], ["Rachelson", "Emmanuel", ""], ["Delahaye", "Daniel", ""]]}, {"id": "1905.03743", "submitter": "Gaurav Mittal", "authors": "Gaurav Mittal, Shubham Agrawal, Anuva Agarwal, Sushant Mehta, Tanya\n  Marwah", "title": "Interactive Image Generation Using Scene Graphs", "comments": "Published at ICLR 2019 Deep Generative Models for Highly Structured\n  Data Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed some exciting developments in the domain of\ngenerating images from scene-based text descriptions. These approaches have\nprimarily focused on generating images from a static text description and are\nlimited to generating images in a single pass. They are unable to generate an\nimage interactively based on an incrementally additive text description\n(something that is more intuitive and similar to the way we describe an image).\nWe propose a method to generate an image incrementally based on a sequence of\ngraphs of scene descriptions (scene-graphs). We propose a recurrent network\narchitecture that preserves the image content generated in previous steps and\nmodifies the cumulative image as per the newly provided scene information. Our\nmodel utilizes Graph Convolutional Networks (GCN) to cater to variable-sized\nscene graphs along with Generative Adversarial image translation networks to\ngenerate realistic multi-object images without needing any intermediate\nsupervision during training. We experiment with Coco-Stuff dataset which has\nmulti-object images along with annotations describing the visual scene and show\nthat our model significantly outperforms other approaches on the same dataset\nin generating visually consistent images for incrementally growing scene\ngraphs.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 16:39:31 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Mittal", "Gaurav", ""], ["Agrawal", "Shubham", ""], ["Agarwal", "Anuva", ""], ["Mehta", "Sushant", ""], ["Marwah", "Tanya", ""]]}, {"id": "1905.03776", "submitter": "Daniel Park", "authors": "Daniel S. Park, Jascha Sohl-Dickstein, Quoc V. Le, Samuel L. Smith", "title": "The Effect of Network Width on Stochastic Gradient Descent and\n  Generalization: an Empirical Study", "comments": "17 pages, 3 tables, 17 figures; accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate how the final parameters found by stochastic gradient descent\nare influenced by over-parameterization. We generate families of models by\nincreasing the number of channels in a base network, and then perform a large\nhyper-parameter search to study how the test error depends on learning rate,\nbatch size, and network width. We find that the optimal SGD hyper-parameters\nare determined by a \"normalized noise scale,\" which is a function of the batch\nsize, learning rate, and initialization conditions. In the absence of batch\nnormalization, the optimal normalized noise scale is directly proportional to\nwidth. Wider networks, with their higher optimal noise scale, also achieve\nhigher test accuracy. These observations hold for MLPs, ConvNets, and ResNets,\nand for two different parameterization schemes (\"Standard\" and \"NTK\"). We\nobserve a similar trend with batch normalization for ResNets. Surprisingly,\nsince the largest stable learning rate is bounded, the largest batch size\nconsistent with the optimal normalized noise scale decreases as the width\nincreases.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 17:58:13 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Park", "Daniel S.", ""], ["Sohl-Dickstein", "Jascha", ""], ["Le", "Quoc V.", ""], ["Smith", "Samuel L.", ""]]}, {"id": "1905.03850", "submitter": "Juan Leni", "authors": "Juan Leni, John Levine, John Quigley", "title": "Solving zero-sum extensive-form games with arbitrary payoff uncertainty\n  models", "comments": "Preprint. License: CC-BY-NC-ND", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling strategic conflict from a game theoretical perspective involves\ndealing with epistemic uncertainty. Payoff uncertainty models are typically\nrestricted to simple probability models due to computational restrictions.\nRecent breakthroughs Artificial Intelligence (AI) research applied to Poker\nhave resulted in novel approximation approaches such as counterfactual regret\nminimization, that can successfully deal with large-scale imperfect games. By\ndrawing from these ideas, this work addresses the problem of arbitrary\ncontinuous payoff distributions. We propose a method, Harsanyi-Counterfactual\nRegret Minimization, to solve two-player zero-sum extensive-form games with\narbitrary payoff distribution models. Given a game $\\Gamma$, using a Harsanyi\ntransformation we generate a new game $\\Gamma^\\#$ to which we later apply\nCounterfactual Regret Minimization to obtain $\\varepsilon$-Nash equilibria. We\ninclude numerical experiments showing how the method can be applied to a\npreviously published problem.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 05:30:01 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Leni", "Juan", ""], ["Levine", "John", ""], ["Quigley", "John", ""]]}, {"id": "1905.03855", "submitter": "Laura Giordano", "authors": "Laura Giordano and Valentina Gliozzi", "title": "A reconstruction of the multipreference closure", "comments": "57 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper describes a preferential approach for dealing with exceptions in\nKLM preferential logics, based on the rational closure. It is well known that\nthe rational closure does not allow an independent handling of the inheritance\nof different defeasible properties of concepts. Several solutions have been\nproposed to face this problem and the lexicographic closure is the most notable\none. In this work, we consider an alternative closure construction, called the\nMulti Preference closure (MP-closure), that has been first considered for\nreasoning with exceptions in DLs. Here, we reconstruct the notion of MP-closure\nin the propositional case and we show that it is a natural variant of Lehmann's\nlexicographic closure. Abandoning Maximal Entropy (an alternative route already\nconsidered but not explored by Lehmann) leads to a construction which exploits\na different lexicographic ordering w.r.t. the lexicographic closure, and\ndetermines a preferential consequence relation rather than a rational\nconsequence relation. We show that, building on the MP-closure semantics,\nrationality can be recovered, at least from the semantic point of view,\nresulting in a rational consequence relation which is stronger than the\nrational closure, but incomparable with the lexicographic closure. We also show\nthat the MP-closure is stronger than the Relevant Closure.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 08:44:24 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 17:47:15 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Giordano", "Laura", ""], ["Gliozzi", "Valentina", ""]]}, {"id": "1905.03899", "submitter": "Aaron Massey", "authors": "Philip Feldman and Aaron Dant and Aaron Massey", "title": "Integrating Artificial Intelligence into Weapon Systems", "comments": "7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The integration of Artificial Intelligence (AI) into weapon systems is one of\nthe most consequential tactical and strategic decisions in the history of\nwarfare. Current AI development is a remarkable combination of accelerating\ncapability, hidden decision mechanisms, and decreasing costs. Implementation of\nthese systems is in its infancy and exists on a spectrum from resilient and\nflexible to simplistic and brittle. Resilient systems should be able to\neffectively handle the complexities of a high-dimensional battlespace.\nSimplistic AI implementations could be manipulated by an adversarial AI that\nidentifies and exploits their weaknesses.\n  In this paper, we present a framework for understanding the development of\ndynamic AI/ML systems that interactively and continuously adapt to their user's\nneeds. We explore the implications of increasingly capable AI in the kill chain\nand how this will lead inevitably to a fully automated, always on system,\nbarring regulation by treaty. We examine the potential of total integration of\ncyber and physical security and how this likelihood must inform the development\nof AI-enabled systems with respect to the \"fog of war\", human morals, and\nethics.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 00:38:35 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Feldman", "Philip", ""], ["Dant", "Aaron", ""], ["Massey", "Aaron", ""]]}, {"id": "1905.03907", "submitter": "Tucker Hermans", "authors": "Kanrun Huang and Tucker Hermans", "title": "Building 3D Object Models during Manipulation by Reconstruction-Aware\n  Trajectory Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object shape provides important information for robotic manipulation; for\ninstance, selecting an effective grasp depends on both the global and local\nshape of the object of interest, while reaching into clutter requires accurate\nsurface geometry to avoid unintended contact with the environment. Model-based\n3D object manipulation is a widely studied problem; however, obtaining the\naccurate 3D object models for multiple objects often requires tedious work. In\nthis letter, we exploit Gaussian process implicit surfaces (GPIS) extracted\nfrom RGB-D sensor data to grasp an unknown object. We propose a\nreconstruction-aware trajectory optimization that makes use of the extracted\nGPIS model plan a motion to improve the ability to estimate the object's 3D\ngeometry, while performing a pick-and-place action. We present a probabilistic\napproach for a robot to autonomously learn and track the object, while achieve\nthe manipulation task.\n  We use a sampling-based trajectory generation method to explore the unseen\nparts of the object using the estimated conditional entropy of the GPIS model.\nWe validate our method with physical robot experiments across eleven different\nobjects of varying shape from the YCB object dataset. Our experiments show that\nour reconstruction-aware trajectory optimization provides higher-quality 3D\nobject reconstruction when compared with directly solving the manipulation task\nor using a heuristic to view unseen portions of the object.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 01:33:29 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Huang", "Kanrun", ""], ["Hermans", "Tucker", ""]]}, {"id": "1905.03929", "submitter": "Yuxiu Hua", "authors": "Yuxiu Hua, Rongpeng Li, Zhifeng Zhao, Xianfu Chen, Honggang Zhang", "title": "GAN-powered Deep Distributional Reinforcement Learning for Resource\n  Management in Network Slicing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Network slicing is a key technology in 5G communications system. Its purpose\nis to dynamically and efficiently allocate resources for diversified services\nwith distinct requirements over a common underlying physical infrastructure.\nTherein, demand-aware resource allocation is of significant importance to\nnetwork slicing. In this paper, we consider a scenario that contains several\nslices in a radio access network with base stations that share the same\nphysical resources (e.g., bandwidth or slots). We leverage deep reinforcement\nlearning (DRL) to solve this problem by considering the varying service demands\nas the environment state and the allocated resources as the environment action.\nIn order to reduce the effects of the annoying randomness and noise embedded in\nthe received service level agreement (SLA) satisfaction ratio (SSR) and\nspectrum efficiency (SE), we primarily propose generative adversarial\nnetwork-powered deep distributional Q network (GAN-DDQN) to learn the\naction-value distribution driven by minimizing the discrepancy between the\nestimated action-value distribution and the target action-value distribution.\nWe put forward a reward-clipping mechanism to stabilize GAN-DDQN training\nagainst the effects of widely-spanning utility values. Moreover, we further\ndevelop Dueling GAN-DDQN, which uses a specially designed dueling generator, to\nlearn the action-value distribution by estimating the state-value distribution\nand the action advantage function. Finally, we verify the performance of the\nproposed GAN-DDQN and Dueling GAN-DDQN algorithms through extensive\nsimulations.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 04:10:43 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 01:58:34 GMT"}, {"version": "v3", "created": "Wed, 20 Nov 2019 14:51:31 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Hua", "Yuxiu", ""], ["Li", "Rongpeng", ""], ["Zhao", "Zhifeng", ""], ["Chen", "Xianfu", ""], ["Zhang", "Honggang", ""]]}, {"id": "1905.03970", "submitter": "Sindhu Padakandla", "authors": "Sindhu Padakandla, Prabuchandran K. J, and Shalabh Bhatnagar", "title": "Reinforcement Learning in Non-Stationary Environments", "comments": null, "journal-ref": "Applied Intelligence 2020", "doi": "10.1007/s10489-020-01758-5", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) methods learn optimal decisions in the presence\nof a stationary environment. However, the stationary assumption on the\nenvironment is very restrictive. In many real world problems like traffic\nsignal control, robotic applications, one often encounters situations with\nnon-stationary environments and in these scenarios, RL methods yield\nsub-optimal decisions. In this paper, we thus consider the problem of\ndeveloping RL methods that obtain optimal decisions in a non-stationary\nenvironment. The goal of this problem is to maximize the long-term discounted\nreward achieved when the underlying model of the environment changes over time.\nTo achieve this, we first adapt a change point algorithm to detect change in\nthe statistics of the environment and then develop an RL algorithm that\nmaximizes the long-run reward accrued. We illustrate that our change point\nmethod detects change in the model of the environment effectively and thus\nfacilitates the RL algorithm in maximizing the long-run reward. We further\nvalidate the effectiveness of the proposed solution on non-stationary random\nMarkov decision processes, a sensor energy management problem and a traffic\nsignal control problem.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 07:05:27 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 12:54:18 GMT"}, {"version": "v3", "created": "Wed, 8 Apr 2020 07:21:45 GMT"}, {"version": "v4", "created": "Tue, 19 May 2020 09:48:13 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Padakandla", "Sindhu", ""], ["J", "Prabuchandran K.", ""], ["Bhatnagar", "Shalabh", ""]]}, {"id": "1905.03985", "submitter": "Elaheh Barati", "authors": "Elaheh Barati, Xuewen Chen, Zichun Zhong", "title": "Attention-based Deep Reinforcement Learning for Multi-view Environments", "comments": "The 18th International Conference on Autonomous Agents and Multiagent\n  Systems (AAMAS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning algorithms, it is a common practice to account for\nonly a single view of the environment to make the desired decisions; however,\nutilizing multiple views of the environment can help to promote the learning of\ncomplicated policies. Since the views may frequently suffer from partial\nobservability, their provided observation can have different levels of\nimportance. In this paper, we present a novel attention-based deep\nreinforcement learning method in a multi-view environment in which each view\ncan provide various representative information about the environment.\nSpecifically, our method learns a policy to dynamically attend to views of the\nenvironment based on their importance in the decision-making process. We\nevaluate the performance of our method on TORCS racing car simulator and three\nother complex 3D environments with obstacles.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 07:39:39 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Barati", "Elaheh", ""], ["Chen", "Xuewen", ""], ["Zhong", "Zichun", ""]]}, {"id": "1905.04016", "submitter": "Baoyuan Wu", "authors": "Yan Xu, Baoyuan Wu, Fumin Shen, Yanbo Fan, Yong Zhang, Heng Tao Shen,\n  Wei Liu", "title": "Exact Adversarial Attack to Image Captioning via Structured Output\n  Learning with Latent Variables", "comments": "Accepted to CVPR 2019. Yan Xu and Baoyuan Wu are co-first authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the robustness of a CNN+RNN based image captioning\nsystem being subjected to adversarial noises. We propose to fool an image\ncaptioning system to generate some targeted partial captions for an image\npolluted by adversarial noises, even the targeted captions are totally\nirrelevant to the image content. A partial caption indicates that the words at\nsome locations in this caption are observed, while words at other locations are\nnot restricted.It is the first work to study exact adversarial attacks of\ntargeted partial captions. Due to the sequential dependencies among words in a\ncaption, we formulate the generation of adversarial noises for targeted partial\ncaptions as a structured output learning problem with latent variables. Both\nthe generalized expectation maximization algorithm and structural SVMs with\nlatent variables are then adopted to optimize the problem. The proposed methods\ngenerate very successful at-tacks to three popular CNN+RNN based image\ncaptioning models. Furthermore, the proposed attack methods are used to\nunderstand the inner mechanism of image captioning systems, providing the\nguidance to further improve automatic image captioning systems towards human\ncaptioning.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 09:00:53 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Xu", "Yan", ""], ["Wu", "Baoyuan", ""], ["Shen", "Fumin", ""], ["Fan", "Yanbo", ""], ["Zhang", "Yong", ""], ["Shen", "Heng Tao", ""], ["Liu", "Wei", ""]]}, {"id": "1905.04020", "submitter": "Thomy Phan", "authors": "Thomy Phan, Lenz Belzner, Marie Kiermeier, Markus Friedrich, Kyrill\n  Schmid, Claudia Linnhoff-Popien", "title": "Memory Bounded Open-Loop Planning in Large POMDPs using Thompson\n  Sampling", "comments": "Presented at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art approaches to partially observable planning like POMCP are\nbased on stochastic tree search. While these approaches are computationally\nefficient, they may still construct search trees of considerable size, which\ncould limit the performance due to restricted memory resources. In this paper,\nwe propose Partially Observable Stacked Thompson Sampling (POSTS), a memory\nbounded approach to open-loop planning in large POMDPs, which optimizes a fixed\nsize stack of Thompson Sampling bandits. We empirically evaluate POSTS in four\nlarge benchmark problems and compare its performance with different tree-based\napproaches. We show that POSTS achieves competitive performance compared to\ntree-based open-loop planning and offers a performance-memory tradeoff, making\nit suitable for partially observable planning with highly restricted\ncomputational and memory resources.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 09:06:50 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Phan", "Thomy", ""], ["Belzner", "Lenz", ""], ["Kiermeier", "Marie", ""], ["Friedrich", "Markus", ""], ["Schmid", "Kyrill", ""], ["Linnhoff-Popien", "Claudia", ""]]}, {"id": "1905.04071", "submitter": "Jan Deriu", "authors": "Jan Deriu, Alvaro Rodrigo, Arantxa Otegi, Guillermo Echegoyen, Sophie\n  Rosset, Eneko Agirre, Mark Cieliebak", "title": "Survey on Evaluation Methods for Dialogue Systems", "comments": null, "journal-ref": "Artificial Intelligence Review, June 2020", "doi": "10.1007/s10462-020-09866-x", "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we survey the methods and concepts developed for the evaluation\nof dialogue systems. Evaluation is a crucial part during the development\nprocess. Often, dialogue systems are evaluated by means of human evaluations\nand questionnaires. However, this tends to be very cost and time intensive.\nThus, much work has been put into finding methods, which allow to reduce the\ninvolvement of human labour. In this survey, we present the main concepts and\nmethods. For this, we differentiate between the various classes of dialogue\nsystems (task-oriented dialogue systems, conversational dialogue systems, and\nquestion-answering dialogue systems). We cover each class by introducing the\nmain technologies developed for the dialogue systems and then by presenting the\nevaluation methods regarding this class.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 11:14:12 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 08:07:53 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Deriu", "Jan", ""], ["Rodrigo", "Alvaro", ""], ["Otegi", "Arantxa", ""], ["Echegoyen", "Guillermo", ""], ["Rosset", "Sophie", ""], ["Agirre", "Eneko", ""], ["Cieliebak", "Mark", ""]]}, {"id": "1905.04077", "submitter": "Carsten Hahn", "authors": "Carsten Hahn, Thomy Phan, Thomas Gabor, Lenz Belzner, Claudia\n  Linnhoff-Popien", "title": "Emergent Escape-based Flocking Behavior using Multi-Agent Reinforcement\n  Learning", "comments": "Accepted at ALIFE 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In nature, flocking or swarm behavior is observed in many species as it has\nbeneficial properties like reducing the probability of being caught by a\npredator. In this paper, we propose SELFish (Swarm Emergent Learning Fish), an\napproach with multiple autonomous agents which can freely move in a continuous\nspace with the objective to avoid being caught by a present predator. The\npredator has the property that it might get distracted by multiple possible\npreys in its vicinity. We show that this property in interaction with\nself-interested agents which are trained with reinforcement learning to solely\nsurvive as long as possible leads to flocking behavior similar to Boids, a\ncommon simulation for flocking behavior. Furthermore we present interesting\ninsights in the swarming behavior and in the process of agents being caught in\nour modeled environment.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 11:30:20 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Hahn", "Carsten", ""], ["Phan", "Thomy", ""], ["Gabor", "Thomas", ""], ["Belzner", "Lenz", ""], ["Linnhoff-Popien", "Claudia", ""]]}, {"id": "1905.04127", "submitter": "Andrei Roibu", "authors": "Andrei Claudiu Roibu", "title": "Design of Artificial Intelligence Agents for Games using Deep\n  Reinforcement Learning", "comments": "Dissertation submitted to the University of Sheffield in partial\n  fulfilment of the requirements for the degree of Master of Engineering. 98\n  pages, 21 Tables, 58 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order perform a large variety of tasks and to achieve human-level\nperformance in complex real-world environments, Artificial Intelligence (AI)\nAgents must be able to learn from their past experiences and gain both\nknowledge and an accurate representation of their environment from raw sensory\ninputs. Traditionally, AI agents have suffered from difficulties in using only\nsensory inputs to obtain a good representation of their environment and then\nmapping this representation to an efficient control policy. Deep reinforcement\nlearning algorithms have provided a solution to this issue. In this study, the\nperformance of different conventional and novel deep reinforcement learning\nalgorithms was analysed. The proposed method utilises two types of algorithms,\none trained with a variant of Q-learning (DQN) and another trained with SARSA\nlearning (DSN) to assess the feasibility of using direct feedback alignment, a\nnovel biologically plausible method for back-propagating the error. These novel\nagents, alongside two similar agents trained with the conventional\nbackpropagation algorithm, were tested by using the OpenAI Gym toolkit on\nseveral classic control theory problems and Atari 2600 video games. The results\nof this investigation open the way into new, biologically-inspired deep\nreinforcement learning algorithms, and their implementation on neuromorphic\nhardware.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 12:43:52 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Roibu", "Andrei Claudiu", ""]]}, {"id": "1905.04175", "submitter": "Fabien Lotte", "authors": "Giuseppe Amato (CNR PISA), Malte Behrmann, Fr\\'ed\\'eric Bimbot\n  (PANAMA), Baptiste Caramiaux (LRI, EX-SITU), Fabrizio Falchi (CNR PISA),\n  Ander Garcia, Joost Geurts (Inria), Jaume Gibert, Guillaume Gravier\n  (LinkMedia), Hadmut Holken, Hartmut Koenitz (HKU), Sylvain Lefebvre (MFX),\n  Antoine Liutkus (LORIA, ZENITH), Fabien Lotte (Potioc, LaBRI), Andrew Perkis\n  (NTNU), Rafael Redondo, Enrico Turrin (FEP), Thierry Vieville (Mnemosyne),\n  Emmanuel Vincent (MULTISPEECH)", "title": "AI in the media and creative industries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thanks to the Big Data revolution and increasing computing capacities,\nArtificial Intelligence (AI) has made an impressive revival over the past few\nyears and is now omnipresent in both research and industry. The creative\nsectors have always been early adopters of AI technologies and this continues\nto be the case. As a matter of fact, recent technological developments keep\npushing the boundaries of intelligent systems in creative applications: the\ncritically acclaimed movie \"Sunspring\", released in 2016, was entirely written\nby AI technology, and the first-ever Music Album, called \"Hello World\",\nproduced using AI has been released this year. Simultaneously, the exploratory\nnature of the creative process is raising important technical challenges for AI\nsuch as the ability for AI-powered techniques to be accurate under limited data\nresources, as opposed to the conventional \"Big Data\" approach, or the ability\nto process, analyse and match data from multiple modalities (text, sound,\nimages, etc.) at the same time. The purpose of this white paper is to\nunderstand future technological advances in AI and their growing impact on\ncreative industries. This paper addresses the following questions: Where does\nAI operate in creative Industries? What is its operative role? How will AI\ntransform creative industries in the next ten years? This white paper aims to\nprovide a realistic perspective of the scope of AI actions in creative\nindustries, proposes a vision of how this technology could contribute to\nresearch and development works in such context, and identifies research and\ndevelopment challenges.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 13:56:52 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Amato", "Giuseppe", "", "CNR PISA"], ["Behrmann", "Malte", "", "PANAMA"], ["Bimbot", "Fr\u00e9d\u00e9ric", "", "PANAMA"], ["Caramiaux", "Baptiste", "", "LRI, EX-SITU"], ["Falchi", "Fabrizio", "", "CNR PISA"], ["Garcia", "Ander", "", "Inria"], ["Geurts", "Joost", "", "Inria"], ["Gibert", "Jaume", "", "LinkMedia"], ["Gravier", "Guillaume", "", "LinkMedia"], ["Holken", "Hadmut", "", "HKU"], ["Koenitz", "Hartmut", "", "HKU"], ["Lefebvre", "Sylvain", "", "MFX"], ["Liutkus", "Antoine", "", "LORIA, ZENITH"], ["Lotte", "Fabien", "", "Potioc, LaBRI"], ["Perkis", "Andrew", "", "NTNU"], ["Redondo", "Rafael", "", "FEP"], ["Turrin", "Enrico", "", "FEP"], ["Vieville", "Thierry", "", "Mnemosyne"], ["Vincent", "Emmanuel", "", "MULTISPEECH"]]}, {"id": "1905.04181", "submitter": "Abdulmajid Murad", "authors": "Abdulmajid Murad, Frank Alexander Kraemer, Kerstin Bach, Gavin Taylor", "title": "Autonomous Management of Energy-Harvesting IoT Nodes Using Deep\n  Reinforcement Learning", "comments": null, "journal-ref": "IEEE 13th International Conference on Self-Adaptive and\n  Self-Organizing Systems (SASO) 2019 Jun 16 (pp. 43-51)", "doi": "10.1109/SASO.2019.00015", "report-no": null, "categories": "cs.LG cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is capable of managing wireless,\nenergy-harvesting IoT nodes by solving the problem of autonomous management in\nnon-stationary, resource-constrained settings. We show that the\nstate-of-the-art policy-gradient approaches to RL are appropriate for the IoT\ndomain and that they outperform previous approaches. Due to the ability to\nmodel continuous observation and action spaces, as well as improved function\napproximation capability, the new approaches are able to solve harder problems,\npermitting reward functions that are better aligned with the actual application\ngoals. We show such a reward function and use policy-gradient approaches to\nlearn capable policies, leading to behavior more appropriate for IoT nodes with\nless manual design effort, increasing the level of autonomy in IoT.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 14:09:13 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Murad", "Abdulmajid", ""], ["Kraemer", "Frank Alexander", ""], ["Bach", "Kerstin", ""], ["Taylor", "Gavin", ""]]}, {"id": "1905.04192", "submitter": "Abraham Woubie Zewoudie Dr.", "authors": "Abraham Woubie, Anssi Kanervisto, Janne Karttunen, and Ville Hautamaki", "title": "Do Autonomous Agents Benefit from Hearing?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mapping states to actions in deep reinforcement learning is mainly based on\nvisual information. The commonly used approach for dealing with visual\ninformation is to extract pixels from images and use them as state\nrepresentation for reinforcement learning agent. But, any vision only agent is\nhandicapped by not being able to sense audible cues. Using hearing, animals are\nable to sense targets that are outside of their visual range. In this work, we\npropose the use of audio as complementary information to visual only in state\nrepresentation. We assess the impact of such multi-modal setup in\nreach-the-goal tasks in ViZDoom environment. Results show that the agent\nimproves its behavior when visual information is accompanied with audio\nfeatures.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 14:25:49 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Woubie", "Abraham", ""], ["Kanervisto", "Anssi", ""], ["Karttunen", "Janne", ""], ["Hautamaki", "Ville", ""]]}, {"id": "1905.04199", "submitter": "Kuruge Darshana Abeyrathna", "authors": "K. Darshana Abeyrathna, Ole-Christoffer Granmo, Xuan Zhang, and Morten\n  Goodwin", "title": "A Scheme for Continuous Input to the Tsetlin Machine with Applications\n  to Forecasting Disease Outbreaks", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we apply a new promising tool for pattern classification,\nnamely, the Tsetlin Machine (TM), to the field of disease forecasting. The TM\nis interpretable because it is based on manipulating expressions in\npropositional logic, leveraging a large team of Tsetlin Automata (TA). Apart\nfrom being interpretable, this approach is attractive due to its low\ncomputational cost and its capacity to handle noise. To attack the problem of\nforecasting, we introduce a preprocessing method that extends the TM so that it\ncan handle continuous input. Briefly stated, we convert continuous input into a\nbinary representation based on thresholding. The resulting extended TM is\nevaluated and analyzed using an artificial dataset. The TM is further applied\nto forecast dengue outbreaks of all the seventeen regions in the Philippines\nusing the spatio-temporal properties of the data. Experimental results show\nthat dengue outbreak forecasts made by the TM are more accurate than those\nobtained by a Support Vector Machine (SVM), Decision Trees (DTs), and several\nmulti-layered Artificial Neural Networks (ANNs), both in terms of forecasting\nprecision and F1-score.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 14:42:10 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 19:08:40 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Abeyrathna", "K. Darshana", ""], ["Granmo", "Ole-Christoffer", ""], ["Zhang", "Xuan", ""], ["Goodwin", "Morten", ""]]}, {"id": "1905.04205", "submitter": "Sven Tomforde", "authors": "Stefan Rudolph, Sven Tomforde, J\\\"org H\\\"ahner", "title": "On the Detection of Mutual Influences and Their Consideration in\n  Reinforcement Learning Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-adaptation has been proposed as a mechanism to counter complexity in\ncontrol problems of technical systems. A major driver behind self-adaptation is\nthe idea to transfer traditional design-time decisions to runtime and into the\nresponsibility of systems themselves. In order to deal with unforeseen events\nand conditions, systems need creativity -- typically realized by means of\nmachine learning capabilities. Such learning mechanisms are based on different\nsources of knowledge. Feedback from the environment used for reinforcement\npurposes is probably the most prominent one within the self-adapting and\nself-organizing (SASO) systems community. However, the impact of other\n(sub-)systems on the success of the individual system's learning performance\nhas mostly been neglected in this context. In this article, we propose a novel\nmethodology to identify effects of actions performed by other systems in a\nshared environment on the utility achievement of an autonomous system. Consider\nsmart cameras (SC) as illustrating example: For goals such as 3D reconstruction\nof objects, the most promising configuration of one SC in terms of\npan/tilt/zoom parameters depends largely on the configuration of other SCs in\nthe vicinity. Since such mutual influences cannot be pre-defined for dynamic\nsystems, they have to be learned at runtime. Furthermore, they have to be taken\ninto consideration when self-improving the own configuration decisions based on\na feedback loop concept, e.g., known from the SASO domain or the Autonomic and\nOrganic Computing initiatives. We define a methodology to detect such\ninfluences at runtime, present an approach to consider this information in a\nreinforcement learning technique, and analyze the behavior in artificial as\nwell as real-world SASO system settings.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 15:04:48 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Rudolph", "Stefan", ""], ["Tomforde", "Sven", ""], ["H\u00e4hner", "J\u00f6rg", ""]]}, {"id": "1905.04206", "submitter": "Kuruge Darshana Abeyrathna", "authors": "K. Darshana Abeyrathna, Ole-Christoffer Granmo, Lei Jiao, and Morten\n  Goodwin", "title": "The Regression Tsetlin Machine: A Tsetlin Machine for Continuous Output\n  Problems", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently introduced Tsetlin Machine (TM) has provided competitive pattern\nclassification accuracy in several benchmarks, composing patterns with\neasy-to-interpret conjunctive clauses in propositional logic. In this paper, we\ngo beyond pattern classification by introducing a new type of TMs, namely, the\nRegression Tsetlin Machine (RTM). In all brevity, we modify the inner inference\nmechanism of the TM so that input patterns are transformed into a single\ncontinuous output, rather than to distinct categories. We achieve this by: (1)\nusing the conjunctive clauses of the TM to capture arbitrarily complex\npatterns; (2) mapping these patterns to a continuous output through a novel\nvoting and normalization mechanism; and (3) employing a feedback scheme that\nupdates the TM clauses to minimize the regression error. The feedback scheme\nuses a new activation probability function that stabilizes the updating of\nclauses, while the overall system converges towards an accurate input-output\nmapping. The performance of the RTM is evaluated using six different artificial\ndatasets with and without noise, in comparison with the Classic Tsetlin Machine\n(CTM) and the Multiclass Tsetlin Machine (MTM). Our empirical results indicate\nthat the RTM obtains the best training and testing results for both noisy and\nnoise-free datasets, with a smaller number of clauses. This, in turn,\ntranslates to higher regression accuracy, using significantly less\ncomputational resources.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 15:05:30 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 19:02:39 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Abeyrathna", "K. Darshana", ""], ["Granmo", "Ole-Christoffer", ""], ["Jiao", "Lei", ""], ["Goodwin", "Morten", ""]]}, {"id": "1905.04210", "submitter": "Felipe Meneguzzi", "authors": "Lu\\'isa R. de A. Santos and Felipe Meneguzzi and Ramon Fraga Pereira\n  and Andr\\'e Grahl Pereira", "title": "An LP-Based Approach for Goal Recognition as Planning", "comments": "8 pages, 4 tables, 3 figures. Published in AAAI 2021. Updated final\n  authorship and text", "journal-ref": "AAAI 2021: 11939-11946", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goal recognition aims to recognize the set of candidate goals that are\ncompatible with the observed behavior of an agent. In this paper, we develop a\nmethod based on the operator-counting framework that efficiently computes\nsolutions that satisfy the observations and uses the information generated to\nsolve goal recognition tasks. Our method reasons explicitly about both partial\nand noisy observations: estimating uncertainty for the former, and satisfying\nobservations given the unreliability of the sensor for the latter. We evaluate\nour approach empirically over a large data set, analyzing its components on how\neach can impact the quality of the solutions. In general, our approach is\nsuperior to previous methods in terms of agreement ratio, accuracy, and spread.\nFinally, our approach paves the way for new research on combinatorial\noptimization to solve goal recognition tasks.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 15:14:30 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 04:24:21 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 08:58:21 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Santos", "Lu\u00edsa R. de A.", ""], ["Meneguzzi", "Felipe", ""], ["Pereira", "Ramon Fraga", ""], ["Pereira", "Andr\u00e9 Grahl", ""]]}, {"id": "1905.04218", "submitter": "Aran Sena", "authors": "Aran Sena, Matthew J Howard", "title": "Quantifying Teaching Behaviour in Robot Learning from Demonstration", "comments": "Preprint for International Journal of Robotics Research (IJRR)\n  submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from demonstration allows for rapid deployment of robot manipulators\nto a great many tasks, by relying on a person showing the robot what to do\nrather than programming it. While this approach provides many opportunities,\nmeasuring, evaluating and improving the person's teaching ability has remained\nlargely unexplored in robot manipulation research. To this end, a model for\nlearning from demonstration is presented here which incorporates the teacher's\nunderstanding of, and influence on, the learner. The proposed model is used to\nclarify the teacher's objectives during learning from demonstration, providing\nnew views on how teaching failures and efficiency can be defined. The benefit\nof this approach is shown in two experiments (N=30 and N=36, respectively),\nwhich highlight the difficulty teachers have in providing effective\ndemonstrations, and show how ~169-180% improvement in teaching efficiency can\nbe achieved through evaluation and feedback shaped by the proposed framework,\nrelative to unguided teaching.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 15:30:25 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Sena", "Aran", ""], ["Howard", "Matthew J", ""]]}, {"id": "1905.04230", "submitter": "Oguz Elibol", "authors": "Oguz H. Elibol, Gokce Keskin, Anil Thomas", "title": "Semi-supervised and Population Based Training for Voice Commands\n  Recognition", "comments": null, "journal-ref": "ICASSP 2019", "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a rapid design methodology that combines automated hyper-parameter\ntuning with semi-supervised training to build highly accurate and robust models\nfor voice commands classification. Proposed approach allows quick evaluation of\nnetwork architectures to fit performance and power constraints of available\nhardware, while ensuring good hyper-parameter choices for each network in\nreal-world scenarios. Leveraging the vast amount of unlabeled data with a\nstudent/teacher based semi-supervised method, classification accuracy is\nimproved from 84% to 94% in the validation set. For model optimization, we\nexplore the hyper-parameter space through population based training and obtain\nan optimized model in the same time frame as it takes to train a single model.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 15:58:38 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Elibol", "Oguz H.", ""], ["Keskin", "Gokce", ""], ["Thomas", "Anil", ""]]}, {"id": "1905.04232", "submitter": "Patrik Christen", "authors": "Patrik Christen and Olivier Del Fabbro", "title": "Automatic Programming of Cellular Automata and Artificial Neural\n  Networks Guided by Philosophy", "comments": "12 pages, 1 figure", "journal-ref": "Rolf Dornberger, editor, New Trends in Business Information\n  Systems and Technology: Digital Innovation and Digital Business\n  Transformation, pages 131-146. Springer, Cham, 2020", "doi": "10.1007/978-3-030-48332-6", "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.NE cs.PL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Many computer models such as cellular automata and artificial neural networks\nhave been developed and successfully applied. However, in some cases, these\nmodels might be restrictive on the possible solutions or their solutions might\nbe difficult to interpret. To overcome this problem, we outline a new approach,\nthe so-called allagmatic method, that automatically programs and executes\nmodels with as little limitations as possible while maintaining human\ninterpretability. Earlier we described a metamodel and its building blocks\naccording to the philosophical concepts of structure (spatial dimension) and\noperation (temporal dimension). They are entity, milieu, and update function\nthat together abstractly describe cellular automata, artificial neural\nnetworks, and possibly any kind of computer model. By automatically combining\nthese building blocks in an evolutionary computation, interpretability might be\nincreased by the relationship to the metamodel, and models might be translated\ninto more interpretable models via the metamodel. We propose generic and\nobject-oriented programming to implement the entities and their milieus as\ndynamic and generic arrays and the update function as a method. We show two\nexperiments where a simple cellular automaton and an artificial neural network\nare automatically programmed, compiled, and executed. A target state is\nsuccessfully evolved and learned in the cellular automaton and artificial\nneural network, respectively. We conclude that the allagmatic method can create\nand execute cellular automaton and artificial neural network models in an\nautomated manner with the guidance of philosophy.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 16:00:09 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 14:03:51 GMT"}, {"version": "v3", "created": "Wed, 24 Jul 2019 10:06:41 GMT"}, {"version": "v4", "created": "Wed, 20 Nov 2019 08:47:05 GMT"}, {"version": "v5", "created": "Sun, 3 May 2020 21:05:20 GMT"}, {"version": "v6", "created": "Mon, 31 Aug 2020 21:45:47 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Christen", "Patrik", ""], ["Del Fabbro", "Olivier", ""]]}, {"id": "1905.04241", "submitter": "Tong Wang", "authors": "Tong Wang and Qihang Lin", "title": "Hybrid Predictive Model: When an Interpretable Model Collaborates with a\n  Black-box Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretable machine learning has become a strong competitor for traditional\nblack-box models. However, the possible loss of the predictive performance for\ngaining interpretability is often inevitable, putting practitioners in a\ndilemma of choosing between high accuracy (black-box models) and\ninterpretability (interpretable models). In this work, we propose a novel\nframework for building a Hybrid Predictive Model (HPM) that integrates an\ninterpretable model with any black-box model to combine their strengths. The\ninterpretable model substitutes the black-box model on a subset of data where\nthe black-box is overkill or nearly overkill, gaining transparency at no or low\ncost of the predictive accuracy. We design a principled objective function that\nconsiders predictive accuracy, model interpretability, and model transparency\n(defined as the percentage of data processed by the interpretable substitute.)\nUnder this framework, we propose two hybrid models, one substituting with\nassociation rules and the other with linear models, and we design customized\ntraining algorithms for both models. We test the hybrid models on structured\ndata and text data where interpretable models collaborate with various\nstate-of-the-art black-box models. Results show that hybrid models obtain an\nefficient trade-off between transparency and predictive performance,\ncharacterized by our proposed efficient frontiers.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 16:21:00 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Wang", "Tong", ""], ["Lin", "Qihang", ""]]}, {"id": "1905.04422", "submitter": "Tiantian Gao", "authors": "Tiantian Gao", "title": "Controlled Natural Languages and Default Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Controlled natural languages (CNLs) are effective languages for knowledge\nrepresentation and reasoning. They are designed based on certain natural\nlanguages with restricted lexicon and grammar. CNLs are unambiguous and simple\nas opposed to their base languages. They preserve the expressiveness and\ncoherence of natural languages. In this report, we focus on a class of CNLs,\ncalled machine-oriented CNLs, which have well-defined semantics that can be\ndeterministically translated into formal languages, such as Prolog, to do\nlogical reasoning. Over the past 20 years, a number of machine-oriented CNLs\nemerged and have been used in many application domains for problem solving and\nquestion answering. However, few of them support non-monotonic inference. In\nour work, we propose non-monotonic extensions of CNL to support defeasible\nreasoning.\n  In the first part of this report, we survey CNLs and compare three\ninfluential systems: Attempto Controlled English (ACE), Processable English\n(PENG), and Computer-processable English (CPL). We compare their language\ndesign, semantic interpretations, and reasoning services. In the second part of\nthis report, we first identify typical non-monotonicity in natural languages,\nsuch as defaults, exceptions and conversational implicatures. Then, we propose\ntheir representation in CNL and the corresponding formalizations in a form of\ndefeasible reasoning known as Logic Programming with Defaults and Argumentation\nTheory (LPDA).\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 02:02:55 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Gao", "Tiantian", ""]]}, {"id": "1905.04423", "submitter": "Lizhong Chen", "authors": "Ting-Ru Lin, Drew Penney, Massoud Pedram, Lizhong Chen", "title": "Optimizing Routerless Network-on-Chip Designs: An Innovative\n  Learning-Based Framework", "comments": "13 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning applied to architecture design presents a promising\nopportunity with broad applications. Recent deep reinforcement learning (DRL)\ntechniques, in particular, enable efficient exploration in vast design spaces\nwhere conventional design strategies may be inadequate. This paper proposes a\nnovel deep reinforcement framework, taking routerless networks-on-chip (NoC) as\nan evaluation case study. The new framework successfully resolves problems with\nprior design approaches being either unreliable due to random searches or\ninflexible due to severe design space restrictions. The framework learns\n(near-)optimal loop placement for routerless NoCs with various design\nconstraints. A deep neural network is developed using parallel threads that\nefficiently explore the immense routerless NoC design space with a Monte Carlo\nsearch tree. Experimental results show that, compared with conventional mesh,\nthe proposed deep reinforcement learning (DRL) routerless design achieves a\n3.25x increase in throughput, 1.6x reduction in packet latency, and 5x\nreduction in power. Compared with the state-of-the-art routerless NoC, DRL\nachieves a 1.47x increase in throughput, 1.18x reduction in packet latency, and\n1.14x reduction in average hop count albeit with slightly more power overhead.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 02:15:44 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Lin", "Ting-Ru", ""], ["Penney", "Drew", ""], ["Pedram", "Massoud", ""], ["Chen", "Lizhong", ""]]}, {"id": "1905.04445", "submitter": "Ilker Yildirim", "authors": "Ilker Yildirim, Basil Saeed, Grace Bennett-Pierre, Tobias Gerstenberg,\n  Joshua Tenenbaum, Hyowon Gweon", "title": "Explaining intuitive difficulty judgments by modeling physical effort\n  and risk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to estimate task difficulty is critical for many real-world\ndecisions such as setting appropriate goals for ourselves or appreciating\nothers' accomplishments. Here we give a computational account of how humans\njudge the difficulty of a range of physical construction tasks (e.g., moving 10\nloose blocks from their initial configuration to their target configuration,\nsuch as a vertical tower) by quantifying two key factors that influence\nconstruction difficulty: physical effort and physical risk. Physical effort\ncaptures the minimal work needed to transport all objects to their final\npositions, and is computed using a hybrid task-and-motion planner. Physical\nrisk corresponds to stability of the structure, and is computed using noisy\nphysics simulations to capture the costs for precision (e.g., attention,\ncoordination, fine motor movements) required for success. We show that the full\neffort-risk model captures human estimates of difficulty and construction time\nbetter than either component alone.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 04:17:57 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 14:56:59 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Yildirim", "Ilker", ""], ["Saeed", "Basil", ""], ["Bennett-Pierre", "Grace", ""], ["Gerstenberg", "Tobias", ""], ["Tenenbaum", "Joshua", ""], ["Gweon", "Hyowon", ""]]}, {"id": "1905.04446", "submitter": "Pravendra Singh", "authors": "Pravendra Singh, Vinay Kumar Verma, Piyush Rai, Vinay P. Namboodiri", "title": "Play and Prune: Adaptive Filter Pruning for Deep Model Compression", "comments": "International Joint Conference on Artificial Intelligence\n  (IJCAI-2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While convolutional neural networks (CNN) have achieved impressive\nperformance on various classification/recognition tasks, they typically consist\nof a massive number of parameters. This results in significant memory\nrequirement as well as computational overheads. Consequently, there is a\ngrowing need for filter-level pruning approaches for compressing CNN based\nmodels that not only reduce the total number of parameters but reduce the\noverall computation as well. We present a new min-max framework for\nfilter-level pruning of CNNs. Our framework, called Play and Prune (PP),\njointly prunes and fine-tunes CNN model parameters, with an adaptive pruning\nrate, while maintaining the model's predictive performance. Our framework\nconsists of two modules: (1) An adaptive filter pruning (AFP) module, which\nminimizes the number of filters in the model; and (2) A pruning rate controller\n(PRC) module, which maximizes the accuracy during pruning. Moreover, unlike\nmost previous approaches, our approach allows directly specifying the desired\nerror tolerance instead of pruning level. Our compressed models can be deployed\nat run-time, without requiring any special libraries or hardware. Our approach\nreduces the number of parameters of VGG-16 by an impressive factor of 17.5X,\nand number of FLOPS by 6.43X, with no loss of accuracy, significantly\noutperforming other state-of-the-art filter pruning methods.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 04:37:10 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Singh", "Pravendra", ""], ["Verma", "Vinay Kumar", ""], ["Rai", "Piyush", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "1905.04598", "submitter": "Hongru Zhu", "authors": "Hongru Zhu, Peng Tang, Jeongho Park, Soojin Park, Alan Yuille", "title": "Robustness of Object Recognition under Extreme Occlusion in Humans and\n  Computational Models", "comments": "To be presented at the 41st Annual Meeting of the Cognitive Science\n  Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most objects in the visual world are partially occluded, but humans can\nrecognize them without difficulty. However, it remains unknown whether object\nrecognition models like convolutional neural networks (CNNs) can handle\nreal-world occlusion. It is also a question whether efforts to make these\nmodels robust to constant mask occlusion are effective for real-world\nocclusion. We test both humans and the above-mentioned computational models in\na challenging task of object recognition under extreme occlusion, where target\nobjects are heavily occluded by irrelevant real objects in real backgrounds.\nOur results show that human vision is very robust to extreme occlusion while\nCNNs are not, even with modifications to handle constant mask occlusion. This\nimplies that the ability to handle constant mask occlusion does not entail\nrobustness to real-world occlusion. As a comparison, we propose another\ncomputational model that utilizes object parts/subparts in a compositional\nmanner to build robustness to occlusion. This performs significantly better\nthan CNN-based models on our task with error patterns similar to humans. These\nfindings suggest that testing under extreme occlusion can better reveal the\nrobustness of visual recognition, and that the principle of composition can\nencourage such robustness.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 22:01:04 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 06:56:11 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Zhu", "Hongru", ""], ["Tang", "Peng", ""], ["Park", "Jeongho", ""], ["Park", "Soojin", ""], ["Yuille", "Alan", ""]]}, {"id": "1905.04610", "submitter": "Scott Lundberg", "authors": "Scott M. Lundberg, Gabriel Erion, Hugh Chen, Alex DeGrave, Jordan M.\n  Prutkin, Bala Nair, Ronit Katz, Jonathan Himmelfarb, Nisha Bansal, Su-In Lee", "title": "Explainable AI for Trees: From Local Explanations to Global\n  Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tree-based machine learning models such as random forests, decision trees,\nand gradient boosted trees are the most popular non-linear predictive models\nused in practice today, yet comparatively little attention has been paid to\nexplaining their predictions. Here we significantly improve the\ninterpretability of tree-based models through three main contributions: 1) The\nfirst polynomial time algorithm to compute optimal explanations based on game\ntheory. 2) A new type of explanation that directly measures local feature\ninteraction effects. 3) A new set of tools for understanding global model\nstructure based on combining many local explanations of each prediction. We\napply these tools to three medical machine learning problems and show how\ncombining many high-quality local explanations allows us to represent global\nstructure while retaining local faithfulness to the original model. These tools\nenable us to i) identify high magnitude but low frequency non-linear mortality\nrisk factors in the general US population, ii) highlight distinct population\nsub-groups with shared risk characteristics, iii) identify non-linear\ninteraction effects among risk factors for chronic kidney disease, and iv)\nmonitor a machine learning model deployed in a hospital by identifying which\nfeatures are degrading the model's performance over time. Given the popularity\nof tree-based machine learning models, these improvements to their\ninterpretability have implications across a broad set of domains.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 23:36:59 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Lundberg", "Scott M.", ""], ["Erion", "Gabriel", ""], ["Chen", "Hugh", ""], ["DeGrave", "Alex", ""], ["Prutkin", "Jordan M.", ""], ["Nair", "Bala", ""], ["Katz", "Ronit", ""], ["Himmelfarb", "Jonathan", ""], ["Bansal", "Nisha", ""], ["Lee", "Su-In", ""]]}, {"id": "1905.04640", "submitter": "Jianyi Wang", "authors": "Yuhang Song, Jianyi Wang, Thomas Lukasiewicz, Zhenghua Xu, Shangtong\n  Zhang, Andrzej Wojcicki, Mai Xu", "title": "Mega-Reward: Achieving Human-Level Play without Extrinsic Rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrinsic rewards were introduced to simulate how human intelligence works;\nthey are usually evaluated by intrinsically-motivated play, i.e., playing games\nwithout extrinsic rewards but evaluated with extrinsic rewards. However, none\nof the existing intrinsic reward approaches can achieve human-level performance\nunder this very challenging setting of intrinsically-motivated play. In this\nwork, we propose a novel megalomania-driven intrinsic reward (called\nmega-reward), which, to our knowledge, is the first approach that achieves\nhuman-level performance in intrinsically-motivated play. Intuitively,\nmega-reward comes from the observation that infants' intelligence develops when\nthey try to gain more control on entities in an environment; therefore,\nmega-reward aims to maximize the control capabilities of agents on given\nentities in a given environment. To formalize mega-reward, a relational\ntransition model is proposed to bridge the gaps between direct and latent\ncontrol. Experimental studies show that mega-reward (i) can greatly outperform\nall state-of-the-art intrinsic reward approaches, (ii) generally achieves the\nsame level of performance as Ex-PPO and professional human-level scores, and\n(iii) has also a superior performance when it is incorporated with extrinsic\nrewards.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 03:48:06 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 09:01:03 GMT"}, {"version": "v3", "created": "Thu, 30 May 2019 03:24:05 GMT"}, {"version": "v4", "created": "Wed, 27 Nov 2019 04:05:44 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Song", "Yuhang", ""], ["Wang", "Jianyi", ""], ["Lukasiewicz", "Thomas", ""], ["Xu", "Zhenghua", ""], ["Zhang", "Shangtong", ""], ["Wojcicki", "Andrzej", ""], ["Xu", "Mai", ""]]}, {"id": "1905.04655", "submitter": "Nikhil Mehta", "authors": "Nikhil Mehta and Dan Goldwasser", "title": "Improving Natural Language Interaction with Robots Using Advice", "comments": "Accepted as a short paper at NAACL 2019 (8 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last few years, there has been growing interest in learning models\nfor physically grounded language understanding tasks, such as the popular\nblocks world domain. These works typically view this problem as a single-step\nprocess, in which a human operator gives an instruction and an automated agent\nis evaluated on its ability to execute it. In this paper we take the first step\ntowards increasing the bandwidth of this interaction, and suggest a protocol\nfor including advice, high-level observations about the task, which can help\nconstrain the agent's prediction. We evaluate our approach on the blocks world\ntask, and show that even simple advice can help lead to significant performance\nimprovements. To help reduce the effort involved in supplying the advice, we\nalso explore model self-generated advice which can still improve results.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 06:11:30 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Mehta", "Nikhil", ""], ["Goldwasser", "Dan", ""]]}, {"id": "1905.04689", "submitter": "Mani A", "authors": "A. Mani", "title": "Rough Contact in General Rough Mereology", "comments": "11 Pages. Women in Logic Workshop, Vancouver'2019: 34th Annual\n  ACM/IEEE Symposium on Logic in Computer Science (LICS) 2019. This preprint\n  uses the same updated framework of arXiv:1811.06560", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Theories of rough mereology have originated from diverse semantic\nconsiderations from contexts relating to study of databases, to human\nreasoning. These ideas of origin, especially in the latter context, are\nintensely complex. In this research, concepts of rough contact relations are\nintroduced and rough mereologies are situated in relation to general spatial\nmereology by the present author. These considerations are restricted to her\nrough mereologies that seek to avoid contamination.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 10:42:20 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Mani", "A.", ""]]}, {"id": "1905.04716", "submitter": "Guanjie Zheng", "authors": "Guanjie Zheng, Xinshi Zang, Nan Xu, Hua Wei, Zhengyao Yu, Vikash\n  Gayah, Kai Xu, Zhenhui Li", "title": "Diagnosing Reinforcement Learning for Traffic Signal Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing availability of traffic data and advance of deep\nreinforcement learning techniques, there is an emerging trend of employing\nreinforcement learning (RL) for traffic signal control. A key question for\napplying RL to traffic signal control is how to define the reward and state.\nThe ultimate objective in traffic signal control is to minimize the travel\ntime, which is difficult to reach directly. Hence, existing studies often\ndefine reward as an ad-hoc weighted linear combination of several traffic\nmeasures. However, there is no guarantee that the travel time will be optimized\nwith the reward. In addition, recent RL approaches use more complicated state\n(e.g., image) in order to describe the full traffic situation. However, none of\nthe existing studies has discussed whether such a complex state representation\nis necessary. This extra complexity may lead to significantly slower learning\nprocess but may not necessarily bring significant performance gain.\n  In this paper, we propose to re-examine the RL approaches through the lens of\nclassic transportation theory. We ask the following questions: (1) How should\nwe design the reward so that one can guarantee to minimize the travel time? (2)\nHow to design a state representation which is concise yet sufficient to obtain\nthe optimal solution? Our proposed method LIT is theoretically supported by the\nclassic traffic signal control methods in transportation field. LIT has a very\nsimple state and reward design, thus can serve as a building block for future\nRL approaches to traffic signal control. Extensive experiments on both\nsynthetic and real datasets show that our method significantly outperforms the\nstate-of-the-art traffic signal control methods.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 13:03:23 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Zheng", "Guanjie", ""], ["Zang", "Xinshi", ""], ["Xu", "Nan", ""], ["Wei", "Hua", ""], ["Yu", "Zhengyao", ""], ["Gayah", "Vikash", ""], ["Xu", "Kai", ""], ["Li", "Zhenhui", ""]]}, {"id": "1905.04722", "submitter": "Guanjie Zheng", "authors": "Guanjie Zheng, Yuanhao Xiong, Xinshi Zang, Jie Feng, Hua Wei, Huichu\n  Zhang, Yong Li, Kai Xu, Zhenhui Li", "title": "Learning Phase Competition for Traffic Signal Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasingly available city data and advanced learning techniques have\nempowered people to improve the efficiency of our city functions. Among them,\nimproving the urban transportation efficiency is one of the most prominent\ntopics. Recent studies have proposed to use reinforcement learning (RL) for\ntraffic signal control. Different from traditional transportation approaches\nwhich rely heavily on prior knowledge, RL can learn directly from the feedback.\nOn the other side, without a careful model design, existing RL methods\ntypically take a long time to converge and the learned models may not be able\nto adapt to new scenarios. For example, a model that is trained well for\nmorning traffic may not work for the afternoon traffic because the traffic flow\ncould be reversed, resulting in a very different state representation. In this\npaper, we propose a novel design called FRAP, which is based on the intuitive\nprinciple of phase competition in traffic signal control: when two traffic\nsignals conflict, priority should be given to one with larger traffic movement\n(i.e., higher demand). Through the phase competition modeling, our model\nachieves invariance to symmetrical cases such as flipping and rotation in\ntraffic flow. By conducting comprehensive experiments, we demonstrate that our\nmodel finds better solutions than existing RL methods in the complicated\nall-phase selection problem, converges much faster during training, and\nachieves superior generalizability for different road structures and traffic\nconditions.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 13:31:04 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Zheng", "Guanjie", ""], ["Xiong", "Yuanhao", ""], ["Zang", "Xinshi", ""], ["Feng", "Jie", ""], ["Wei", "Hua", ""], ["Zhang", "Huichu", ""], ["Li", "Yong", ""], ["Xu", "Kai", ""], ["Li", "Zhenhui", ""]]}, {"id": "1905.04791", "submitter": "Jun Zhang", "authors": "Jun Zhang, Tong Zheng, Shengping Zhang, Meng Wang", "title": "DeepIlluminance: Contextual Illuminance Estimation via Deep Neural\n  Networks", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational color constancy refers to the estimation of the scene\nillumination and makes the perceived color relatively stable under varying\nillumination. In the past few years, deep Convolutional Neural Networks (CNNs)\nhave delivered superior performance in illuminant estimation. Several\nrepresentative methods formulate it as a multi-label prediction problem by\nlearning the local appearance of image patches using CNNs. However, these\napproaches inevitably make incorrect estimations for the ambiguous patches\naffected by their neighborhood contexts. Inaccurate local estimates are likely\nto bring in degraded performance when combining into a global prediction. To\naddress the above issues, we propose a contextual deep network for patch-based\nilluminant estimation equipped with refinement. First, the contextual net with\na center-surround architecture extracts local contextual features from image\npatches, and generates initial illuminant estimates and the corresponding color\ncorrected patches. The patches are sampled based on the observation that pixels\nwith large color differences describe the illumination well. Then, the\nrefinement net integrates the input patches with the corrected patches in\nconjunction with the use of intermediate features to improve the performance.\nTo train such a network with numerous parameters, we propose a stage-wise\ntraining strategy, in which the features and the predicted illuminant from\nprevious stages are provided to the next learning stage with more finer\nestimates recovered. Experiments show that our approach obtains competitive\nperformance on two illuminant estimation benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 20:43:59 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 07:34:03 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Zhang", "Jun", ""], ["Zheng", "Tong", ""], ["Zhang", "Shengping", ""], ["Wang", "Meng", ""]]}, {"id": "1905.04819", "submitter": "Yilun Du", "authors": "Yilun Du, Karthik Narasimhan", "title": "Task-Agnostic Dynamics Priors for Deep Reinforcement Learning", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  While model-based deep reinforcement learning (RL) holds great promise for\nsample efficiency and generalization, learning an accurate dynamics model is\noften challenging and requires substantial interaction with the environment. A\nwide variety of domains have dynamics that share common foundations like the\nlaws of classical mechanics, which are rarely exploited by existing algorithms.\nIn fact, humans continuously acquire and use such dynamics priors to easily\nadapt to operating in new environments. In this work, we propose an approach to\nlearn task-agnostic dynamics priors from videos and incorporate them into an RL\nagent. Our method involves pre-training a frame predictor on task-agnostic\nphysics videos to initialize dynamics models (and fine-tune them) for unseen\ntarget environments. Our frame prediction architecture, SpatialNet, is designed\nspecifically to capture localized physical phenomena and interactions. Our\napproach allows for both faster policy learning and convergence to better\npolicies, outperforming competitive approaches on several different\nenvironments. We also demonstrate that incorporating this prior allows for more\neffective transfer between environments.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 01:16:16 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 01:04:30 GMT"}, {"version": "v3", "created": "Sat, 15 Jun 2019 13:18:50 GMT"}, {"version": "v4", "created": "Thu, 11 Jul 2019 13:11:19 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Du", "Yilun", ""], ["Narasimhan", "Karthik", ""]]}, {"id": "1905.04833", "submitter": "Zheyuan Ryan Shi", "authors": "Zheyuan Ryan Shi, Ariel D. Procaccia, Kevin S. Chan, Sridhar\n  Venkatesan, Noam Ben-Asher, Nandi O. Leslie, Charles Kamhoua, Fei Fang", "title": "Learning and Planning in the Feature Deception Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's high-stakes adversarial interactions feature attackers who constantly\nbreach the ever-improving security measures. Deception mitigates the defender's\nloss by misleading the attacker to make suboptimal decisions. In order to\nformally reason about deception, we introduce the feature deception problem\n(FDP), a domain-independent model and present a learning and planning framework\nfor finding the optimal deception strategy, taking into account the adversary's\npreferences which are initially unknown to the defender. We make the following\ncontributions. (1) We show that we can uniformly learn the adversary's\npreferences using data from a modest number of deception strategies. (2) We\npropose an approximation algorithm for finding the optimal deception strategy\ngiven the learned preferences and show that the problem is NP-hard. (3) We\nperform extensive experiments to validate our methods and results. In addition,\nwe provide a case study of the credit bureau network to illustrate how FDP\nimplements deception on a real-world problem.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 02:18:45 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 02:54:40 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Shi", "Zheyuan Ryan", ""], ["Procaccia", "Ariel D.", ""], ["Chan", "Kevin S.", ""], ["Venkatesan", "Sridhar", ""], ["Ben-Asher", "Noam", ""], ["Leslie", "Nandi O.", ""], ["Kamhoua", "Charles", ""], ["Fang", "Fei", ""]]}, {"id": "1905.04840", "submitter": "Michael Crosscombe", "authors": "Michael Crosscombe, Jonathan Lawry, Palina Bartashevich", "title": "Evidence Propagation and Consensus Formation in Noisy Environments", "comments": "13th international conference on Scalable Uncertainty Management", "journal-ref": null, "doi": "10.1007/978-3-030-35514-2", "report-no": null, "categories": "cs.MA cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the effectiveness of consensus formation in multi-agent systems\nwhere there is both belief updating based on direct evidence and also belief\ncombination between agents. In particular, we consider the scenario in which a\npopulation of agents collaborate on the best-of-n problem where the aim is to\nreach a consensus about which is the best (alternatively, true) state from\namongst a set of states, each with a different quality value (or level of\nevidence). Agents' beliefs are represented within Dempster-Shafer theory by\nmass functions and we investigate the macro-level properties of four well-known\nbelief combination operators for this multi-agent consensus formation problem:\nDempster's rule, Yager's rule, Dubois & Prade's operator and the averaging\noperator. The convergence properties of the operators are considered and\nsimulation experiments are conducted for different evidence rates and noise\nlevels. Results show that a combination of updating on direct evidence and\nbelief combination between agents results in better consensus to the best state\nthan does evidence updating alone. We also find that in this framework the\noperators are robust to noise. Broadly, Yager's rule is shown to be the better\noperator under various parameter values, i.e. convergence to the best state,\nrobustness to noise, and scalability.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 02:57:59 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 15:04:30 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Crosscombe", "Michael", ""], ["Lawry", "Jonathan", ""], ["Bartashevich", "Palina", ""]]}, {"id": "1905.04847", "submitter": "Long Zhou", "authors": "Long Zhou, Jiajun Zhang, Chengqing Zong", "title": "Synchronous Bidirectional Neural Machine Translation", "comments": "Published by TACL 2019, 15 pages, 9 figures, 9 tabels", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing approaches to neural machine translation (NMT) generate the target\nlanguage sequence token by token from left to right. However, this kind of\nunidirectional decoding framework cannot make full use of the target-side\nfuture contexts which can be produced in a right-to-left decoding direction,\nand thus suffers from the issue of unbalanced outputs. In this paper, we\nintroduce a synchronous bidirectional neural machine translation (SB-NMT) that\npredicts its outputs using left-to-right and right-to-left decoding\nsimultaneously and interactively, in order to leverage both of the history and\nfuture information at the same time. Specifically, we first propose a new\nalgorithm that enables synchronous bidirectional decoding in a single model.\nThen, we present an interactive decoding model in which left-to-right\n(right-to-left) generation does not only depend on its previously generated\noutputs, but also relies on future contexts predicted by right-to-left\n(left-to-right) decoding. We extensively evaluate the proposed SB-NMT model on\nlarge-scale NIST Chinese-English, WMT14 English-German, and WMT18\nRussian-English translation tasks. Experimental results demonstrate that our\nmodel achieves significant improvements over the strong Transformer model by\n3.92, 1.49 and 1.04 BLEU points respectively, and obtains the state-of-the-art\nperformance on Chinese-English and English-German translation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 03:34:14 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Zhou", "Long", ""], ["Zhang", "Jiajun", ""], ["Zong", "Chengqing", ""]]}, {"id": "1905.04914", "submitter": "Wei Hu", "authors": "Lingbing Guo and Zequn Sun and Wei Hu", "title": "Learning to Exploit Long-term Relational Dependencies in Knowledge\n  Graphs", "comments": "Accepted by the 36th International Conference on Machine Learning\n  (ICML 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of knowledge graph (KG) embedding. A widely-established\nassumption to this problem is that similar entities are likely to have similar\nrelational roles. However, existing related methods derive KG embeddings mainly\nbased on triple-level learning, which lack the capability of capturing\nlong-term relational dependencies of entities. Moreover, triple-level learning\nis insufficient for the propagation of semantic information among entities,\nespecially for the case of cross-KG embedding. In this paper, we propose\nrecurrent skipping networks (RSNs), which employ a skipping mechanism to bridge\nthe gaps between entities. RSNs integrate recurrent neural networks (RNNs) with\nresidual learning to efficiently capture the long-term relational dependencies\nwithin and between KGs. We design an end-to-end framework to support RSNs on\ndifferent tasks. Our experimental results showed that RSNs outperformed\nstate-of-the-art embedding-based methods for entity alignment and achieved\ncompetitive performance for KG completion.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 08:53:31 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Guo", "Lingbing", ""], ["Sun", "Zequn", ""], ["Hu", "Wei", ""]]}, {"id": "1905.04933", "submitter": "Lihi Dery", "authors": "Lihi Dery, Svetlana Obraztsova, Zinovi Rabinovich and Meir Kalech", "title": "Lie on the Fly: Strategic Voting in an Iterative Preference Elicitation\n  Process", "comments": null, "journal-ref": null, "doi": "10.1007/s10726-019-09637-2", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A voting center is in charge of collecting and aggregating voter preferences.\nIn an iterative process, the center sends comparison queries to voters,\nrequesting them to submit their preference between two items. Voters might\ndiscuss the candidates among themselves, figuring out during the elicitation\nprocess which candidates stand a chance of winning and which do not.\nConsequently, strategic voters might attempt to manipulate by deviating from\ntheir true preferences and instead submit a different response in order to\nattempt to maximize their profit. We provide a practical algorithm for\nstrategic voters which computes the best manipulative vote and maximizes the\nvoter's selfish outcome when such a vote exists. We also provide a careful\nvoting center which is aware of the possible manipulations and avoids\nmanipulative queries when possible. In an empirical study on four real-world\ndomains, we show that in practice manipulation occurs in a low percentage of\nsettings and has a low impact on the final outcome. The careful voting center\nreduces manipulation even further, thus allowing for a non-distorted group\ndecision process to take place. We thus provide a core technology study of a\nvoting process that can be adopted in opinion or information aggregation\nsystems and in crowdsourcing applications, e.g., peer grading in Massive Open\nOnline Courses (MOOCs).\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 09:32:17 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Dery", "Lihi", ""], ["Obraztsova", "Svetlana", ""], ["Rabinovich", "Zinovi", ""], ["Kalech", "Meir", ""]]}, {"id": "1905.04994", "submitter": "Andrea Aler Tubella", "authors": "Andrea Aler Tubella, Andreas Theodorou, Virginia Dignum, Frank Dignum", "title": "Governance by Glass-Box: Implementing Transparent Moral Bounds for AI\n  Behaviour", "comments": "7 pages, 2 figures, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) applications are being used to predict and\nassess behaviour in multiple domains, such as criminal justice and consumer\nfinance, which directly affect human well-being. However, if AI is to improve\npeople's lives, then people must be able to trust AI, which means being able to\nunderstand what the system is doing and why. Even though transparency is often\nseen as the requirement in this case, realistically it might not always be\npossible or desirable, whereas the need to ensure that the system operates\nwithin set moral bounds remains. In this paper, we present an approach to\nevaluate the moral bounds of an AI system based on the monitoring of its inputs\nand outputs. We place a \"glass box\" around the system by mapping moral values\ninto explicit verifiable norms that constrain inputs and outputs, in such a way\nthat if these remain within the box we can guarantee that the system adheres to\nthe value. The focus on inputs and outputs allows for the verification and\ncomparison of vastly different intelligent systems; from deep neural networks\nto agent-based systems. The explicit transformation of abstract moral values\ninto concrete norms brings great benefits in terms of explainability;\nstakeholders know exactly how the system is interpreting and employing relevant\nabstract moral human values and calibrate their trust accordingly. Moreover, by\noperating at a higher level we can check the compliance of the system with\ndifferent interpretations of the same value. These advantages will have an\nimpact on the well-being of AI systems users at large, building their trust and\nproviding them with concrete knowledge on how systems adhere to moral values.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 15:02:20 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 09:33:52 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Tubella", "Andrea Aler", ""], ["Theodorou", "Andreas", ""], ["Dignum", "Virginia", ""], ["Dignum", "Frank", ""]]}, {"id": "1905.05013", "submitter": "Dennis Soemers", "authors": "\\'Eric Piette, Dennis J.N.J. Soemers, Matthew Stephenson, Chiara F.\n  Sironi, Mark H.M. Winands, Cameron Browne", "title": "Ludii -- The Ludemic General Game System", "comments": "Accepted at ECAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While current General Game Playing (GGP) systems facilitate useful research\nin Artificial Intelligence (AI) for game-playing, they are often somewhat\nspecialised and computationally inefficient. In this paper, we describe the\n\"ludemic\" general game system Ludii, which has the potential to provide an\nefficient tool for AI researchers as well as game designers, historians,\neducators and practitioners in related fields. Ludii defines games as\nstructures of ludemes -- high-level, easily understandable game concepts --\nwhich allows for concise and human-understandable game descriptions. We\nformally describe Ludii and outline its main benefits: generality,\nextensibility, understandability and efficiency. Experimentally, Ludii\noutperforms one of the most efficient Game Description Language (GDL)\nreasoners, based on a propositional network, in all games available in the\nTiltyard GGP repository. Moreover, Ludii is also competitive in terms of\nperformance with the more recently proposed Regular Boardgames (RBG) system,\nand has various advantages in qualitative aspects such as generality.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 12:39:39 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 08:01:27 GMT"}, {"version": "v3", "created": "Fri, 21 Feb 2020 15:35:38 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Piette", "\u00c9ric", ""], ["Soemers", "Dennis J. N. J.", ""], ["Stephenson", "Matthew", ""], ["Sironi", "Chiara F.", ""], ["Winands", "Mark H. M.", ""], ["Browne", "Cameron", ""]]}, {"id": "1905.05022", "submitter": "Weipeng Huang", "authors": "Weipeng Huang, Nishma Laitonjam, Guangyuan Piao, Neil Hurley", "title": "Inferring Hierarchical Mixture Structures: A Bayesian Nonparametric\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the problem of hierarchical non-overlapping clustering\nof a dataset. In such a clustering, each data item is associated with exactly\none leaf node and each internal node is associated with all the data items\nstored in the sub-tree beneath it, so that each level of the hierarchy\ncorresponds to a partition of the dataset. We develop a novel Bayesian\nnonparametric method combining the nested Chinese Restaurant Process (nCRP) and\nthe Hierarchical Dirichlet Process (HDP). Compared with other existing Bayesian\napproaches, our solution tackles data with complex latent mixture features\nwhich has not been previously explored in the literature. We discuss the\ndetails of the model and the inference procedure. Furthermore, experiments on\nthree datasets show that our method achieves solid empirical results in\ncomparison with existing algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 13:06:22 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 23:52:30 GMT"}, {"version": "v3", "created": "Wed, 25 Sep 2019 17:43:17 GMT"}, {"version": "v4", "created": "Wed, 1 Jul 2020 21:00:49 GMT"}, {"version": "v5", "created": "Sun, 28 Feb 2021 20:30:22 GMT"}, {"version": "v6", "created": "Tue, 25 May 2021 09:33:34 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Huang", "Weipeng", ""], ["Laitonjam", "Nishma", ""], ["Piao", "Guangyuan", ""], ["Hurley", "Neil", ""]]}, {"id": "1905.05053", "submitter": "Guoxian Yu", "authors": "Shixing Yao, Guoxian Yu, Jun Wang, Carlotta Domeniconi and Xiangliang\n  Zhang", "title": "Multi-View Multiple Clustering", "comments": "7 pages, 5 figures, uses ijcai19.sty", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple clustering aims at exploring alternative clusterings to organize the\ndata into meaningful groups from different perspectives. Existing multiple\nclustering algorithms are designed for single-view data. We assume that the\nindividuality and commonality of multi-view data can be leveraged to generate\nhigh-quality and diverse clusterings. To this end, we propose a novel\nmulti-view multiple clustering (MVMC) algorithm. MVMC first adapts multi-view\nself-representation learning to explore the individuality encoding matrices and\nthe shared commonality matrix of multi-view data. It additionally reduces the\nredundancy (i.e., enhancing the individuality) among the matrices using the\nHilbert-Schmidt Independence Criterion (HSIC), and collects shared information\nby forcing the shared matrix to be smooth across all views. It then uses matrix\nfactorization on the individual matrices, along with the shared matrix, to\ngenerate diverse clusterings of high-quality. We further extend multiple\nco-clustering on multi-view data and propose a solution called multi-view\nmultiple co-clustering (MVMCC). Our empirical study shows that MVMC (MVMCC) can\nexploit multi-view data to generate multiple high-quality and diverse\nclusterings (co-clusterings), with superior performance to the state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 14:20:44 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Yao", "Shixing", ""], ["Yu", "Guoxian", ""], ["Wang", "Jun", ""], ["Domeniconi", "Carlotta", ""], ["Zhang", "Xiangliang", ""]]}, {"id": "1905.05095", "submitter": "Emilio Jorge", "authors": "Arman Rahbar and Emilio Jorge and Devdatt Dubhashi and Morteza Haghir\n  Chehreghani", "title": "Spectral Analysis of Kernel and Neural Embeddings: Optimization and\n  Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the recent results of (Arora et al. 2019). by spectral analysis of\nthe representations corresponding to the kernel and neural embeddings. They\nshowed that in a simple single-layer network, the alignment of the labels to\nthe eigenvectors of the corresponding Gram matrix determines both the\nconvergence of the optimization during training as well as the generalization\nproperties. We generalize their result to the kernel and neural representations\nand show these extensions improve both optimization and generalization of the\nbasic setup studied in (Arora et al. 2019). In particular, we first extend the\nsetup with the Gaussian kernel and the approximations by random Fourier\nfeatures as well as with the embeddings produced by two-layer networks trained\non different tasks. We then study the use of more sophisticated kernels and\nembeddings, those designed optimally for deep neural networks and those\ndeveloped for the classification task of interest given the data and the\ntraining labels, independent of any specific classification model.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 15:38:38 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 12:58:50 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Rahbar", "Arman", ""], ["Jorge", "Emilio", ""], ["Dubhashi", "Devdatt", ""], ["Chehreghani", "Morteza Haghir", ""]]}, {"id": "1905.05138", "submitter": "Claudio Zito", "authors": "Jochen St\\\"uber, Claudio Zito and Rustam Stolkin", "title": "Let's Push Things Forward: A Survey on Robot Pushing", "comments": null, "journal-ref": null, "doi": "10.3389/frobt.2020.00008", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As robot make their way out of factories into human environments, outer\nspace, and beyond, they require the skill to manipulate their environment in\nmultifarious, unforeseeable circumstances. With this regard, pushing is an\nessential motion primitive that dramatically extends a robot's manipulation\nrepertoire. In this work, we review the robotic pushing literature. While\nfocusing on work concerned with predicting the motion of pushed objects, we\nalso cover relevant applications of pushing for planning and control. Beginning\nwith analytical approaches, under which we also subsume physics engines, we\nthen proceed to discuss work on learning models from data. In doing so, we\ndedicate a separate section to deep learning approaches which have seen a\nrecent upsurge in the literature. Concluding remarks and further research\nperspectives are given at the end of the paper.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 16:45:36 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["St\u00fcber", "Jochen", ""], ["Zito", "Claudio", ""], ["Stolkin", "Rustam", ""]]}, {"id": "1905.05176", "submitter": "Catarina Moreira", "authors": "Catarina Moreira, Lauren Fell, Shahram Dehdashti, Peter Bruza, Andreas\n  Wichert", "title": "Towards a Quantum-Like Cognitive Architecture for Decision-Making", "comments": null, "journal-ref": null, "doi": "10.1017/S0140525X19001687", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an alternative and unifying framework for decision-making that, by\nusing quantum mechanics, provides more generalised cognitive and decision\nmodels with the ability to represent more information than classical models.\nThis framework can accommodate and predict several cognitive biases reported in\nLieder & Griffiths without heavy reliance on heuristics nor on assumptions of\nthe computational resources of the mind.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 11:12:23 GMT"}, {"version": "v2", "created": "Sun, 8 Nov 2020 15:49:55 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Moreira", "Catarina", ""], ["Fell", "Lauren", ""], ["Dehdashti", "Shahram", ""], ["Bruza", "Peter", ""], ["Wichert", "Andreas", ""]]}, {"id": "1905.05179", "submitter": "Aditya Modi", "authors": "Aditya Modi, Debadeepta Dey, Alekh Agarwal, Adith Swaminathan, Besmira\n  Nushi, Sean Andrist, Eric Horvitz", "title": "Metareasoning in Modular Software Systems: On-the-Fly Configuration\n  using Reinforcement Learning with Rich Contextual Representations", "comments": "12 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assemblies of modular subsystems are being pressed into service to perform\nsensing, reasoning, and decision making in high-stakes, time-critical tasks in\nsuch areas as transportation, healthcare, and industrial automation. We address\nthe opportunity to maximize the utility of an overall computing system by\nemploying reinforcement learning to guide the configuration of the set of\ninteracting modules that comprise the system. The challenge of doing\nsystem-wide optimization is a combinatorial problem. Local attempts to boost\nthe performance of a specific module by modifying its configuration often leads\nto losses in overall utility of the system's performance as the distribution of\ninputs to downstream modules changes drastically. We present metareasoning\ntechniques which consider a rich representation of the input, monitor the state\nof the entire pipeline, and adjust the configuration of modules on-the-fly so\nas to maximize the utility of a system's operation. We show significant\nimprovement in both real-world and synthetic pipelines across a variety of\nreinforcement learning techniques.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 07:24:48 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Modi", "Aditya", ""], ["Dey", "Debadeepta", ""], ["Agarwal", "Alekh", ""], ["Swaminathan", "Adith", ""], ["Nushi", "Besmira", ""], ["Andrist", "Sean", ""], ["Horvitz", "Eric", ""]]}, {"id": "1905.05180", "submitter": "Libo Xing", "authors": "Libo Xing", "title": "Learning and Exploiting Multiple Subgoals for Fast Exploration in\n  Hierarchical Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical Reinforcement Learning (HRL) exploits temporally extended\nactions, or options, to make decisions from a higher-dimensional perspective to\nalleviate the sparse reward problem, one of the most challenging problems in\nreinforcement learning. The majority of existing HRL algorithms require either\nsignificant manual design with respect to the specific environment or enormous\nexploration to automatically learn options from data. To achieve fast\nexploration without using manual design, we devise a multi-goal HRL algorithm,\nconsisting of a high-level policy Manager and a low-level policy Worker. The\nManager provides the Worker multiple subgoals at each time step. Each subgoal\ncorresponds to an option to control the environment. Although the agent may\nshow some confusion at the beginning of training since it is guided by three\ndiverse subgoals, the agent's behavior policy will quickly learn how to respond\nto multiple subgoals from the high-level controller on different occasions. By\nexploiting multiple subgoals, the exploration efficiency is significantly\nimproved. We conduct experiments in Atari's Montezuma's Revenge environment, a\nwell-known sparse reward environment, and in doing so achieve the same\nperformance as state-of-the-art HRL methods with substantially reduced training\ntime cost.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 03:13:06 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Xing", "Libo", ""]]}, {"id": "1905.05238", "submitter": "Kiran Khatter", "authors": "Kiran Khatter", "title": "Interval Valued Trapezoidal Neutrosophic Set for Prioritization of\n  Non-functional Requirements", "comments": "21 pages, 2 figures, 5 tables", "journal-ref": "J Ambient Intell Human Comput (2020)", "doi": "10.1007/s12652-020-02130-8", "report-no": null, "categories": "cs.AI cs.NE cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the trapezoidal fuzzy number(TrFN); Interval-valued\nintuitionistic fuzzy number(IVIFN); neutrosophic set and its operational laws;\nand, trapezoidal neutrosophic set(TrNS) and its operational laws. Based on the\ncombination of IVIFN and TrNS, an Interval Valued Trapezoidal Neutrosophic Set\n(IVTrNS) is proposed followed by its operational laws. The paper also presents\nthe score and accuracy functions for the proposed Interval Valued Trapezoidal\nNeutrosophic Number (IVTrNN). Then, an interval valued trapezoidal neutrosophic\nweighted arithmetic averaging (IVTrNWAA) operator is introduced to combine the\ntrapezoidal information which is neutrosophic and in the unit interval of real\nnumbers. Finally, a method is developed to handle the problems in the multi\nattribute decision making(MADM) environment using IVTrNWAA operator followed by\na numerical example of NFRs prioritization to illustrate the relevance of the\ndeveloped method.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 06:09:09 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Khatter", "Kiran", ""]]}, {"id": "1905.05248", "submitter": "Philipp Wanko", "authors": "Philipp Wanko", "title": "Design Space Exploration via Answer Set Programming Modulo Theories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of embedded systems, that are ubiquitously used in mobile devices\nand cars, is becoming continuously more complex such that efficient\nsystem-level design methods are becoming crucial. My research aims at\ndeveloping systems that help the designer express the complex design problem in\na declarative way and explore the design space to obtain divers sets of\nsolutions with desirable properties. To that end, we employ knowledge\nrepresentation and reasoning capabilities of ASP in combination with background\ntheories. As a result, for the first time, we proposed a sophisticated\nmethodology that allows for the direct integration of multi-objective\noptimization of non-linear objectives into ASP. This includes unique results of\ndiverse sub-problems covered in several publications which I will present in\nthis work.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 08:44:47 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Wanko", "Philipp", ""]]}, {"id": "1905.05279", "submitter": "Ashwini Pokle", "authors": "Ashwini Pokle, Roberto Mart\\'in-Mart\\'in, Patrick Goebel, Vincent\n  Chow, Hans M. Ewald, Junwei Yang, Zhenkai Wang, Amir Sadeghian, Dorsa Sadigh,\n  Silvio Savarese, Marynel V\\'azquez", "title": "Deep Local Trajectory Replanning and Control for Robot Navigation", "comments": null, "journal-ref": "2019 International Conference on Robotics and Automation (ICRA)", "doi": "10.1109/ICRA.2019.8794062", "report-no": "18904288", "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a navigation system that combines ideas from hierarchical planning\nand machine learning. The system uses a traditional global planner to compute\noptimal paths towards a goal, and a deep local trajectory planner and velocity\ncontroller to compute motion commands. The latter components of the system\nadjust the behavior of the robot through attention mechanisms such that it\nmoves towards the goal, avoids obstacles, and respects the space of nearby\npedestrians. Both the structure of the proposed deep models and the use of\nattention mechanisms make the system's execution interpretable. Our simulation\nexperiments suggest that the proposed architecture outperforms baselines that\ntry to map global plan information and sensor data directly to velocity\ncommands. In comparison to a hand-designed traditional navigation system, the\nproposed approach showed more consistent performance.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 20:47:39 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Pokle", "Ashwini", ""], ["Mart\u00edn-Mart\u00edn", "Roberto", ""], ["Goebel", "Patrick", ""], ["Chow", "Vincent", ""], ["Ewald", "Hans M.", ""], ["Yang", "Junwei", ""], ["Wang", "Zhenkai", ""], ["Sadeghian", "Amir", ""], ["Sadigh", "Dorsa", ""], ["Savarese", "Silvio", ""], ["V\u00e1zquez", "Marynel", ""]]}, {"id": "1905.05288", "submitter": "Jerome Busemeyer", "authors": "Jerome R. Busemeyer, Peter D. Kvam, Timothy J. Pleskac", "title": "Markov versus quantum dynamic models of belief change during evidence\n  monitoring", "comments": "10 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two different dynamic models for belief change during evidence monitoring\nwere evaluated: Markov and quantum. They were empirically tested with an\nexperiment in which participants monitored evidence for an initial period of\ntime, made a probability rating, then monitored more evidence, before making a\nsecond rating. The models were qualitatively tested by manipulating the time\nintervals in a manner that provided a test for interference effects of the\nfirst rating on the second. The Markov model predicted no interference whereas\nthe quantum model predicted interference. A quantitative comparison of the two\nmodels was also carried out using a generalization criterion method: the\nparameters were fit to data from one set of time intervals, and then these same\nparameters were used to predict data from another set of time intervals. The\nresults indicated that some features of both Markov and quantum models are\nneeded to accurately account for the results.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 14:57:46 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 19:20:47 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Busemeyer", "Jerome R.", ""], ["Kvam", "Peter D.", ""], ["Pleskac", "Timothy J.", ""]]}, {"id": "1905.05290", "submitter": "Romain Wallon", "authors": "Stefan Mengel and Romain Wallon", "title": "Graph Width Measures for CNF-Encodings with Auxiliary Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider bounded width CNF-formulas where the width is measured by popular\ngraph width measures on graphs associated to CNF-formulas. Such restricted\ngraph classes, in particular those of bounded treewidth, have been extensively\nstudied for their uses in the design of algorithms for various computational\nproblems on CNF-formulas. Here we consider the expressivity of these formulas\nin the model of clausal encodings with auxiliary variables. We first show that\nbounding the width for many of the measures from the literature leads to a\ndramatic loss of expressivity, restricting the formulas to such of low\ncommunication complexity. We then show that the width of optimal encodings with\nrespect to different measures is strongly linked: there are two classes of\nwidth measures, one containing primal treewidth and the other incidence\ncliquewidth, such that in each class the width of optimal encodings only\ndiffers by constant factors. Moreover, between the two classes the width\ndiffers at most by a factor logarithmic in the number of variables. Both these\nresults are in stark contrast to the setting without auxiliary variables where\nall width measures we consider here differ by more than constant factors and in\nmany cases even by linear factors.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 09:55:21 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 15:49:07 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Mengel", "Stefan", ""], ["Wallon", "Romain", ""]]}, {"id": "1905.05408", "submitter": "Kyunghwan Son", "authors": "Kyunghwan Son, Daewoo Kim, Wan Ju Kang, David Earl Hostallero, Yung Yi", "title": "QTRAN: Learning to Factorize with Transformation for Cooperative\n  Multi-Agent Reinforcement Learning", "comments": "18 pages; Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore value-based solutions for multi-agent reinforcement learning\n(MARL) tasks in the centralized training with decentralized execution (CTDE)\nregime popularized recently. However, VDN and QMIX are representative examples\nthat use the idea of factorization of the joint action-value function into\nindividual ones for decentralized execution. VDN and QMIX address only a\nfraction of factorizable MARL tasks due to their structural constraint in\nfactorization such as additivity and monotonicity. In this paper, we propose a\nnew factorization method for MARL, QTRAN, which is free from such structural\nconstraints and takes on a new approach to transforming the original joint\naction-value function into an easily factorizable one, with the same optimal\nactions. QTRAN guarantees more general factorization than VDN or QMIX, thus\ncovering a much wider class of MARL tasks than does previous methods. Our\nexperiments for the tasks of multi-domain Gaussian-squeeze and modified\npredator-prey demonstrate QTRAN's superior performance with especially larger\nmargins in games whose payoffs penalize non-cooperative behavior more\naggressively.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 06:29:51 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Son", "Kyunghwan", ""], ["Kim", "Daewoo", ""], ["Kang", "Wan Ju", ""], ["Hostallero", "David Earl", ""], ["Yi", "Yung", ""]]}, {"id": "1905.05416", "submitter": "Hao Tang", "authors": "Hao Tang, Wei Wang, Songsong Wu, Xinya Chen, Dan Xu, Nicu Sebe, Yan\n  Yan", "title": "Expression Conditional GAN for Facial Expression-to-Expression\n  Translation", "comments": "5 pages, 5 figures, accepted to ICIP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on the facial expression translation task and propose\na novel Expression Conditional GAN (ECGAN) which can learn the mapping from one\nimage domain to another one based on an additional expression attribute. The\nproposed ECGAN is a generic framework and is applicable to different expression\ngeneration tasks where specific facial expression can be easily controlled by\nthe conditional attribute label. Besides, we introduce a novel face mask loss\nto reduce the influence of background changing. Moreover, we propose an entire\nframework for facial expression generation and recognition in the wild, which\nconsists of two modules, i.e., generation and recognition. Finally, we evaluate\nour framework on several public face datasets in which the subjects have\ndifferent races, illumination, occlusion, pose, color, content and background\nconditions. Even though these datasets are very diverse, both the qualitative\nand quantitative results demonstrate that our approach is able to generate\nfacial expressions accurately and robustly.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 06:52:03 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Tang", "Hao", ""], ["Wang", "Wei", ""], ["Wu", "Songsong", ""], ["Chen", "Xinya", ""], ["Xu", "Dan", ""], ["Sebe", "Nicu", ""], ["Yan", "Yan", ""]]}, {"id": "1905.05450", "submitter": "Tianyi Zhang", "authors": "Tianyi Zhang, Dengji Zhao, Wen Zhang, and Xuming He", "title": "Fixed-price Diffusion Mechanism Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a fixed-price mechanism design setting where a seller sells one\nitem via a social network, but the seller can only directly communicate with\nher neighbours initially. Each other node in the network is a potential buyer\nwith a valuation derived from a common distribution. With a standard\nfixed-price mechanism, the seller can only sell the item among her neighbours.\nTo improve her revenue, she needs more buyers to join in the sale. To achieve\nthis, we propose the very first fixed-price mechanism to incentivize the\nseller's neighbours to inform their neighbours about the sale and to eventually\ninform all buyers in the network to improve seller's revenue. Compared with the\nexisting mechanisms for the same purpose, our mechanism does not require the\nbuyers to reveal their valuations and it is computationally easy. More\nimportantly, it guarantees that the improved revenue is at least 1/2 of the\noptimal.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 08:28:59 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Zhang", "Tianyi", ""], ["Zhao", "Dengji", ""], ["Zhang", "Wen", ""], ["He", "Xuming", ""]]}, {"id": "1905.05471", "submitter": "Richard Csaky", "authors": "Richard Csaky, Patrik Purgai, Gabor Recski", "title": "Improving Neural Conversational Models with Entropy-Based Data Filtering", "comments": "20 pages. same as ACL version:\n  https://www.aclweb.org/anthology/P19-1567", "journal-ref": "Proceedings of the 57th Conference of the ACL (2019) 5650-5669", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current neural network-based conversational models lack diversity and\ngenerate boring responses to open-ended utterances. Priors such as persona,\nemotion, or topic provide additional information to dialog models to aid\nresponse generation, but annotating a dataset with priors is expensive and such\nannotations are rarely available. While previous methods for improving the\nquality of open-domain response generation focused on either the underlying\nmodel or the training objective, we present a method of filtering dialog\ndatasets by removing generic utterances from training data using a simple\nentropy-based approach that does not require human supervision. We conduct\nextensive experiments with different variations of our method, and compare\ndialog models across 17 evaluation metrics to show that training on datasets\nfiltered this way results in better conversational quality as chatbots learn to\noutput more diverse responses.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 09:07:30 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 13:12:36 GMT"}, {"version": "v3", "created": "Fri, 2 Aug 2019 17:54:01 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Csaky", "Richard", ""], ["Purgai", "Patrik", ""], ["Recski", "Gabor", ""]]}, {"id": "1905.05478", "submitter": "Ivan Yanchin", "authors": "Ivan Yanchin and Oleg Petrov", "title": "Parallel genetic algorithm for planning safe and optimal route for ship", "comments": "26 pages, 13 figures, 15 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper represents an algorithm for planning safe and optimal routes for\ntransport facilities with unrestricted movement direction that travel within\nareas with obstacles. Paper explains the algorithm using a ship as an example\nof such a transport facility. This paper also provides a survey of several\nexisting solutions for the problem. The method employs an evolutionary\nalgorithm to plan several locally optimal routes and a parallel genetic\nalgorithm to create the final route by optimising the abovementioned set of\nroutes. The routes are optimized against the arrival time, assuming that the\noptimal route is the route with the lowermost arrival time. It is also possible\nto apply additional restriction to the routes.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 09:24:16 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Yanchin", "Ivan", ""], ["Petrov", "Oleg", ""]]}, {"id": "1905.05481", "submitter": "Wen Zhang", "authors": "Wen Zhang, Yao Zhang, and Dengji Zhao", "title": "Collaborative Data Acquisition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a requester who acquires a set of data (e.g. images) that is not\nowned by one party. In order to collect as many data as possible, crowdsourcing\nmechanisms have been widely used to seek help from the crowd. However, existing\nmechanisms rely on third-party platforms, and the workers from these platforms\nare not necessarily helpful and redundant data are also not properly handled.\nTo combat this problem, we propose a novel crowdsourcing mechanism based on\nsocial networks, where the rewards of the workers are calculated by information\nentropy and a modified Shapley value. This mechanism incentivizes the workers\nfrom the network to not only provide all data they have but also further invite\ntheir neighbours to offer more data. Eventually, the mechanism is able to\nacquire all data from all workers on the network and the requester's cost is no\nmore than the value of the data acquired. The experiments show that our\nmechanism outperforms traditional crowdsourcing mechanisms.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 09:26:42 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 13:46:23 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Zhang", "Wen", ""], ["Zhang", "Yao", ""], ["Zhao", "Dengji", ""]]}, {"id": "1905.05487", "submitter": "Brij Rokad", "authors": "Nikhil Kasukurthi, Brij Rokad, Shiv Bidani and Dr. Aju Dennisan", "title": "American Sign Language Alphabet Recognition using Deep Learning", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tremendous headway has been made in the field of 3D hand pose estimation but\nthe 3D depth cameras are usually inaccessible. We propose a model to recognize\nAmerican Sign Language alphabet from RGB images. Images for the training were\nresized and pre-processed before training the Deep Neural Network. The model\nwas trained on a squeezenet architecture to make it capable of running on\nmobile devices with an accuracy of 83.29%.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 09:51:58 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Kasukurthi", "Nikhil", ""], ["Rokad", "Brij", ""], ["Bidani", "Shiv", ""], ["Dennisan", "Dr. Aju", ""]]}, {"id": "1905.05498", "submitter": "Binyamin Manela", "authors": "Binyamin Manela, Armin Biess", "title": "Bias-Reduced Hindsight Experience Replay with Virtual Goal\n  Prioritization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hindsight Experience Replay (HER) is a multi-goal reinforcement learning\nalgorithm for sparse reward functions. The algorithm treats every failure as a\nsuccess for an alternative (virtual) goal that has been achieved in the\nepisode. Virtual goals are randomly selected, irrespective of which are most\ninstructive for the agent. In this paper, we present two improvements over the\nexisting HER algorithm. First, we prioritize virtual goals from which the agent\nwill learn more valuable information. We call this property the instructiveness\nof the virtual goal and define it by a heuristic measure, which expresses how\nwell the agent will be able to generalize from that virtual goal to actual\ngoals. Secondly, we reduce existing bias in HER by the removal of misleading\nsamples. To test our algorithms, we built two challenging environments with\nsparse reward functions. Our empirical results in both environments show vast\nimprovement in the final success rate and sample efficiency when compared to\nthe original HER algorithm. A video showing experimental results is available\nat https://youtu.be/3cZwfK8Nfps .\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 10:12:12 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 10:02:32 GMT"}, {"version": "v3", "created": "Wed, 18 Mar 2020 11:34:24 GMT"}, {"version": "v4", "created": "Fri, 20 Mar 2020 14:45:47 GMT"}, {"version": "v5", "created": "Sun, 7 Mar 2021 11:36:58 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Manela", "Binyamin", ""], ["Biess", "Armin", ""]]}, {"id": "1905.05526", "submitter": "Jiwei Li", "authors": "Xiaoya Li, Yuxian Meng, Xiaofei Sun, Qinghong Han, Arianna Yuan and\n  Jiwei Li", "title": "Is Word Segmentation Necessary for Deep Learning of Chinese\n  Representations?", "comments": "to appear at ACL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmenting a chunk of text into words is usually the first step of processing\nChinese text, but its necessity has rarely been explored. In this paper, we ask\nthe fundamental question of whether Chinese word segmentation (CWS) is\nnecessary for deep learning-based Chinese Natural Language Processing. We\nbenchmark neural word-based models which rely on word segmentation against\nneural char-based models which do not involve word segmentation in four\nend-to-end NLP benchmark tasks: language modeling, machine translation,\nsentence matching/paraphrase and text classification. Through direct\ncomparisons between these two types of models, we find that char-based models\nconsistently outperform word-based models. Based on these observations, we\nconduct comprehensive experiments to study why word-based models underperform\nchar-based models in these deep learning-based NLP tasks. We show that it is\nbecause word-based models are more vulnerable to data sparsity and the presence\nof out-of-vocabulary (OOV) words, and thus more prone to overfitting. We hope\nthis paper could encourage researchers in the community to rethink the\nnecessity of word segmentation in deep learning-based Chinese Natural Language\nProcessing. \\footnote{Yuxian Meng and Xiaoya Li contributed equally to this\npaper.}\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 11:39:43 GMT"}, {"version": "v2", "created": "Sun, 6 Oct 2019 07:54:54 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Li", "Xiaoya", ""], ["Meng", "Yuxian", ""], ["Sun", "Xiaofei", ""], ["Han", "Qinghong", ""], ["Yuan", "Arianna", ""], ["Li", "Jiwei", ""]]}, {"id": "1905.05567", "submitter": "Gorker Alp Malazgirt", "authors": "Gorker Alp Malazgirt, Osman S. Unsal, Adrian Cristal Kestelman", "title": "TauRieL: Targeting Traveling Salesman Problem with a deep reinforcement\n  learning inspired architecture", "comments": "10 pages, 5 figures, 1 Algorithm, 4 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we propose TauRieL and target Traveling Salesman Problem (TSP)\nsince it has broad applicability in theoretical and applied sciences. TauRieL\nutilizes an actor-critic inspired architecture that adopts ordinary feedforward\nnets to obtain a policy update vector $v$. Then, we use $v$ to improve the\nstate transition matrix from which we generate the policy. Also, the state\ntransition matrix allows the solver to initialize from precomputed solutions\nsuch as nearest neighbors. In an online learning setting, TauRieL unifies the\ntraining and the search where it can generate near-optimal results in seconds.\nThe input to the neural nets in the actor-critic architecture are raw 2-D\ninputs, and the design idea behind this decision is to keep neural nets\nrelatively smaller than the architectures with wide embeddings with the\ntradeoff of omitting any distributed representations of the embeddings.\nConsequently, TauRieL generates TSP solutions two orders of magnitude faster\nper TSP instance as compared to state-of-the-art offline techniques with a\nperformance impact of 6.1\\% in the worst case.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 12:49:32 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Malazgirt", "Gorker Alp", ""], ["Unsal", "Osman S.", ""], ["Kestelman", "Adrian Cristal", ""]]}, {"id": "1905.05570", "submitter": "Hongyuan Mei", "authors": "Hongyuan Mei, Guanghui Qin, Jason Eisner", "title": "Imputing Missing Events in Continuous-Time Event Streams", "comments": "ICML 2019 camera-ready. The first version of this work appeared on\n  OpenReview in September 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Events in the world may be caused by other, unobserved events. We consider\nsequences of events in continuous time. Given a probability model of complete\nsequences, we propose particle smoothing---a form of sequential importance\nsampling---to impute the missing events in an incomplete sequence. We develop a\ntrainable family of proposal distributions based on a type of bidirectional\ncontinuous-time LSTM: Bidirectionality lets the proposals condition on future\nobservations, not just on the past as in particle filtering. Our method can\nsample an ensemble of possible complete sequences (particles), from which we\nform a single consensus prediction that has low Bayes risk under our chosen\nloss metric. We experiment in multiple synthetic and real domains, using\ndifferent missingness mechanisms, and modeling the complete sequences in each\ndomain with a neural Hawkes process (Mei & Eisner 2017). On held-out incomplete\nsequences, our method is effective at inferring the ground-truth unobserved\nevents, with particle smoothing consistently improving upon particle filtering.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 12:55:42 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Mei", "Hongyuan", ""], ["Qin", "Guanghui", ""], ["Eisner", "Jason", ""]]}, {"id": "1905.05637", "submitter": "MyungJae Shin", "authors": "MyungJae Shin, Joongheon Kim", "title": "Randomized Adversarial Imitation Learning for Autonomous Driving", "comments": null, "journal-ref": "International Joint Conference on Artificial Intelligence (IJCAI)\n  2019", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the evolution of various advanced driver assistance system (ADAS)\nplatforms, the design of autonomous driving system is becoming more complex and\nsafety-critical. The autonomous driving system simultaneously activates\nmultiple ADAS functions; and thus it is essential to coordinate various ADAS\nfunctions. This paper proposes a randomized adversarial imitation learning\n(RAIL) method that imitates the coordination of autonomous vehicle equipped\nwith advanced sensors. The RAIL policies are trained through derivative-free\noptimization for the decision maker that coordinates the proper ADAS functions,\ne.g., smart cruise control and lane keeping system. Especially, the proposed\nmethod is also able to deal with the LIDAR data and makes decisions in complex\nmulti-lane highways and multi-agent environments.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 14:27:00 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Shin", "MyungJae", ""], ["Kim", "Joongheon", ""]]}, {"id": "1905.05665", "submitter": "Marcelo Finger", "authors": "Marcelo Finger", "title": "Quantitative Logic Reasoning", "comments": "Appeared as a chapter in Trends in Logic series", "journal-ref": "In W. Carnielli and J. Malinowski, editors, Contradictions, from\n  Consistency to Inconsistency, Trends in Logic, pages 241-272. Springer\n  International Publishing, 2018", "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show several similarities among logic systems that deal\nsimultaneously with deductive and quantitative inference. We claim it is\nappropriate to call the tasks those systems perform as Quantitative Logic\nReasoning. Analogous properties hold throughout that class, for whose members\nthere exists a set of linear algebraic techniques applicable in the study of\nsatisfiability decision problems. In this presentation, we consider as\nQuantitative Logic Reasoning the tasks performed by propositional Probabilistic\nLogic; first-order logic with counting quantifiers over a fragment containing\nunary and limited binary predicates; and propositional Lukasiewicz\nInfinitely-valued Probabilistic Logic\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 15:19:30 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Finger", "Marcelo", ""]]}, {"id": "1905.05675", "submitter": "Radoslaw Martin Cichy", "authors": "Radoslaw Martin Cichy, Gemma Roig, Alex Andonian, Kshitij Dwivedi,\n  Benjamin Lahner, Alex Lascelles, Yalda Mohsenzadeh, Kandan Ramakrishnan, Aude\n  Oliva", "title": "The Algonauts Project: A Platform for Communication between the Sciences\n  of Biological and Artificial Intelligence", "comments": "4 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the last decade, artificial intelligence (AI) models inspired by the brain\nhave made unprecedented progress in performing real-world perceptual tasks like\nobject classification and speech recognition. Recently, researchers of natural\nintelligence have begun using those AI models to explore how the brain performs\nsuch tasks. These developments suggest that future progress will benefit from\nincreased interaction between disciplines. Here we introduce the Algonauts\nProject as a structured and quantitative communication channel for\ninterdisciplinary interaction between natural and artificial intelligence\nresearchers. The project's core is an open challenge with a quantitative\nbenchmark whose goal is to account for brain data through computational models.\nThis project has the potential to provide better models of natural intelligence\nand to gather findings that advance AI. The 2019 Algonauts Project focuses on\nbenchmarking computational models predicting human brain activity when people\nlook at pictures of objects. The 2019 edition of the Algonauts Project is\navailable online: http://algonauts.csail.mit.edu/.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 15:37:22 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Cichy", "Radoslaw Martin", ""], ["Roig", "Gemma", ""], ["Andonian", "Alex", ""], ["Dwivedi", "Kshitij", ""], ["Lahner", "Benjamin", ""], ["Lascelles", "Alex", ""], ["Mohsenzadeh", "Yalda", ""], ["Ramakrishnan", "Kandan", ""], ["Oliva", "Aude", ""]]}, {"id": "1905.05682", "submitter": "Xiang Lin", "authors": "Xiang Lin, Shafiq Joty, Prathyusha Jwalapuram and M Saiful Bari", "title": "A Unified Linear-Time Framework for Sentence-Level Discourse Parsing", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an efficient neural framework for sentence-level discourse\nanalysis in accordance with Rhetorical Structure Theory (RST). Our framework\ncomprises a discourse segmenter to identify the elementary discourse units\n(EDU) in a text, and a discourse parser that constructs a discourse tree in a\ntop-down fashion. Both the segmenter and the parser are based on Pointer\nNetworks and operate in linear time. Our segmenter yields an $F_1$ score of\n95.4, and our parser achieves an $F_1$ score of 81.7 on the aggregated labeled\n(relation) metric, surpassing previous approaches by a good margin and\napproaching human agreement on both tasks (98.3 and 83.0 $F_1$).\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 15:54:57 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 05:05:06 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Lin", "Xiang", ""], ["Joty", "Shafiq", ""], ["Jwalapuram", "Prathyusha", ""], ["Bari", "M Saiful", ""]]}, {"id": "1905.05700", "submitter": "Waleed Yousef", "authors": "Waleed A. Yousef, Omar M. Ibrahime, Taha M. Madbouly, Moustafa A.\n  Mahmoud", "title": "Learning meters of Arabic and English poems with Recurrent Neural\n  Networks: a step forward for language understanding and synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing a piece of writing as a poem or prose is usually easy for the\nmajority of people; however, only specialists can determine which meter a poem\nbelongs to. In this paper, we build Recurrent Neural Network (RNN) models that\ncan classify poems according to their meters from plain text. The input text is\nencoded at the character level and directly fed to the models without feature\nhandcrafting. This is a step forward for machine understanding and synthesis of\nlanguages in general, and Arabic language in particular. Among the 16 poem\nmeters of Arabic and the 4 meters of English the networks were able to\ncorrectly classify poem with an overall accuracy of 96.38\\% and 82.31\\%\nrespectively. The poem datasets used to conduct this research were massive,\nover 1.5 million of verses, and were crawled from different nontechnical\nsources, almost Arabic and English literature sites, and in different\nheterogeneous and unstructured formats. These datasets are now made publicly\navailable in clean, structured, and documented format for other future\nresearch. To the best of the authors' knowledge, this research is the first to\naddress classifying poem meters in a machine learning approach, in general, and\nin RNN featureless based approach, in particular. In addition, the dataset is\nthe first publicly available dataset ready for the purpose of future\ncomputational research.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 21:14:03 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Yousef", "Waleed A.", ""], ["Ibrahime", "Omar M.", ""], ["Madbouly", "Taha M.", ""], ["Mahmoud", "Moustafa A.", ""]]}, {"id": "1905.05701", "submitter": "Aniruddha Uttam Tammewar", "authors": "Aniruddha Tammewar, Alessandra Cervone, Eva-Maria Messner, Giuseppe\n  Riccardi", "title": "Modeling user context for valence prediction from narratives", "comments": "To be published in Interspeech 2019", "journal-ref": "Interspeech 2019", "doi": "10.21437/Interspeech.2019-2489", "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated prediction of valence, one key feature of a person's emotional\nstate, from individuals' personal narratives may provide crucial information\nfor mental healthcare (e.g. early diagnosis of mental diseases, supervision of\ndisease course, etc.). In the Interspeech 2018 ComParE Self-Assessed Affect\nchallenge, the task of valence prediction was framed as a three-class\nclassification problem using 8 seconds fragments from individuals' narratives.\nAs such, the task did not allow for exploring contextual information of the\nnarratives. In this work, we investigate the intrinsic information from\nmultiple narratives recounted by the same individual in order to predict their\ncurrent state-of-mind. Furthermore, with generalizability in mind, we decided\nto focus our experiments exclusively on textual information as the public\navailability of audio narratives is limited compared to text. Our hypothesis\nis, that context modeling might provide insights about emotion triggering\nconcepts (e.g. events, people, places) mentioned in the narratives that are\nlinked to an individual's state of mind. We explore multiple machine learning\ntechniques to model narratives. We find that the models are able to capture\ninter-individual differences, leading to more accurate predictions of an\nindividual's emotional state, as compared to single narratives.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 20:57:14 GMT"}, {"version": "v2", "created": "Sun, 14 Jul 2019 15:03:53 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Tammewar", "Aniruddha", ""], ["Cervone", "Alessandra", ""], ["Messner", "Eva-Maria", ""], ["Riccardi", "Giuseppe", ""]]}, {"id": "1905.05704", "submitter": "Felipe Salvatore", "authors": "Felipe Salvatore, Marcelo Finger, Roberto Hirata Jr", "title": "A logical-based corpus for cross-lingual evaluation", "comments": "To appear in the proceedings of the Deep Learning for low-resource\n  NLP (DeepLo) workshop at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  At present, different deep learning models are presenting high accuracy on\npopular inference datasets such as SNLI, MNLI, and SciTail. However, there are\ndifferent indicators that those datasets can be exploited by using some simple\nlinguistic patterns. This fact poses difficulties to our understanding of the\nactual capacity of machine learning models to solve the complex task of textual\ninference. We propose a new set of syntactic tasks focused on contradiction\ndetection that require specific capacities over linguistic logical forms such\nas: Boolean coordination, quantifiers, definite description, and counting\noperators. We evaluate two kinds of deep learning models that implicitly\nexploit language structure: recurrent models and the Transformer network BERT.\nWe show that although BERT is clearly more efficient to generalize over most\nlogical forms, there is space for improvement when dealing with counting\noperators. Since the syntactic tasks can be implemented in different languages,\nwe show a successful case of cross-lingual transfer learning between English\nand Portuguese.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 19:39:55 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 15:39:36 GMT"}, {"version": "v3", "created": "Wed, 25 Sep 2019 18:03:10 GMT"}, {"version": "v4", "created": "Tue, 1 Oct 2019 17:12:55 GMT"}, {"version": "v5", "created": "Thu, 24 Oct 2019 00:15:50 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Salvatore", "Felipe", ""], ["Finger", "Marcelo", ""], ["Hirata", "Roberto", "Jr"]]}, {"id": "1905.05708", "submitter": "Guillermo Puebla", "authors": "Guillermo Puebla, Andrea E. Martin, Leonidas A. A. Doumas", "title": "The relational processing limits of classic and contemporary neural\n  network models of language processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of neural networks to capture relational knowledge is a matter of\nlong-standing controversy. Recently, some researchers in the PDP side of the\ndebate have argued that (1) classic PDP models can handle relational structure\n(Rogers & McClelland, 2008, 2014) and (2) the success of deep learning\napproaches to text processing suggests that structured representations are\nunnecessary to capture the gist of human language (Rabovsky et al., 2018). In\nthe present study we tested the Story Gestalt model (St. John, 1992), a classic\nPDP model of text comprehension, and a Sequence-to-Sequence with Attention\nmodel (Bahdanau et al., 2015), a contemporary deep learning architecture for\ntext processing. Both models were trained to answer questions about stories\nbased on the thematic roles that several concepts played on the stories. In\nthree critical test we varied the statistical structure of new stories while\nkeeping their relational structure constant with respect to the training data.\nEach model was susceptible to each statistical structure manipulation to a\ndifferent degree, with their performance failing below chance at least under\none manipulation. We argue that the failures of both models are due to the fact\nthat they cannotperform dynamic binding of independent roles and fillers.\nUltimately, these results cast doubts onthe suitability of traditional neural\nnetworks models for explaining phenomena based on relational reasoning,\nincluding language processing.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 11:19:25 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Puebla", "Guillermo", ""], ["Martin", "Andrea E.", ""], ["Doumas", "Leonidas A. A.", ""]]}, {"id": "1905.05709", "submitter": "Yaoqin Zhang", "authors": "Minlie Huang, Xiaoyan Zhu, and Jianfeng Gao", "title": "Challenges in Building Intelligent Open-domain Dialog Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a resurgent interest in developing intelligent open-domain dialog\nsystems due to the availability of large amounts of conversational data and the\nrecent progress on neural approaches to conversational AI. Unlike traditional\ntask-oriented bots, an open-domain dialog system aims to establish long-term\nconnections with users by satisfying the human need for communication,\naffection, and social belonging. This paper reviews the recent works on neural\napproaches that are devoted to addressing three challenges in developing such\nsystems: semantics, consistency, and interactiveness. Semantics requires a\ndialog system to not only understand the content of the dialog but also\nidentify user's social needs during the conversation. Consistency requires the\nsystem to demonstrate a consistent personality to win users trust and gain\ntheir long-term confidence. Interactiveness refers to the system's ability to\ngenerate interpersonal responses to achieve particular social goals such as\nentertainment, conforming, and task completion. The works we select to present\nhere is based on our unique views and are by no means complete. Nevertheless,\nwe hope that the discussion will inspire new research in developing more\nintelligent dialog systems.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 02:46:28 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 13:50:09 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 09:16:35 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Huang", "Minlie", ""], ["Zhu", "Xiaoyan", ""], ["Gao", "Jianfeng", ""]]}, {"id": "1905.05710", "submitter": "Andreas Doerr", "authors": "Andreas Doerr, Michael Volpp, Marc Toussaint, Sebastian Trimpe,\n  Christian Daniel", "title": "Trajectory-Based Off-Policy Deep Reinforcement Learning", "comments": "Includes appendix. Accepted for ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient methods are powerful reinforcement learning algorithms and\nhave been demonstrated to solve many complex tasks. However, these methods are\nalso data-inefficient, afflicted with high variance gradient estimates, and\nfrequently get stuck in local optima. This work addresses these weaknesses by\ncombining recent improvements in the reuse of off-policy data and exploration\nin parameter space with deterministic behavioral policies. The resulting\nobjective is amenable to standard neural network optimization strategies like\nstochastic gradient descent or stochastic gradient Hamiltonian Monte Carlo.\nIncorporation of previous rollouts via importance sampling greatly improves\ndata-efficiency, whilst stochastic optimization schemes facilitate the escape\nfrom local optima. We evaluate the proposed approach on a series of continuous\ncontrol benchmark tasks. The results show that the proposed algorithm is able\nto successfully and reliably learn solutions using fewer system interactions\nthan standard policy gradient methods.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 16:35:00 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Doerr", "Andreas", ""], ["Volpp", "Michael", ""], ["Toussaint", "Marc", ""], ["Trimpe", "Sebastian", ""], ["Daniel", "Christian", ""]]}, {"id": "1905.05713", "submitter": "Alessandro Umbrico", "authors": "Alessandro Umbrico", "title": "Timeline-based Planning and Execution with Uncertainty: Theory, Modeling\n  Methodologies and Practice", "comments": "PhD thesis, Information and Automation, Roma Tre University", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated Planning is one of the main research field of Artificial\nIntelligence since its beginnings. Research in Automated Planning aims at\ndeveloping general reasoners (i.e., planners) capable of automatically solve\ncomplex problems. Broadly speaking, planners rely on a general model\ncharacterizing the possible states of the world and the actions that can be\nperformed in order to change the status of the world. Given a model and an\ninitial known state, the objective of a planner is to synthesize a set of\nactions needed to achieve a particular goal state. The classical approach to\nplanning roughly corresponds to the description given above. The timeline-based\napproach is a particular planning paradigm capable of integrating causal and\ntemporal reasoning within a unified solving process. This approach has been\nsuccessfully applied in many real-world scenarios although a common\ninterpretation of the related planning concepts is missing. Indeed, there are\nsignificant differences among the existing frameworks that apply this\ntechnique. Each framework relies on its own interpretation of timeline-based\nplanning and therefore it is not easy to compare these systems. Thus, the\nobjective of this work is to investigate the timeline-based approach to\nplanning by addressing several aspects ranging from the semantics of the\nrelated planning concepts to the modeling and solving techniques. Specifically,\nthe main contributions of this PhD work consist of: (i) the proposal of a\nformal characterization of the timeline-based approach capable of dealing with\ntemporal uncertainty; (ii) the proposal of a hierarchical modeling and solving\napproach; (iii) the development of a general purpose framework for planning and\nexecution with timelines; (iv) the validation{\\dag}of this approach in\nreal-world manufacturing scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 16:42:33 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Umbrico", "Alessandro", ""]]}, {"id": "1905.05731", "submitter": "Rahul Ramesh", "authors": "Rahul Ramesh, Manan Tomar and Balaraman Ravindran", "title": "Successor Options: An Option Discovery Framework for Reinforcement\n  Learning", "comments": "To appear in the proceedings of the International Joint Conference on\n  Artificial Intelligence 2019 (IJCAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The options framework in reinforcement learning models the notion of a skill\nor a temporally extended sequence of actions. The discovery of a reusable set\nof skills has typically entailed building options, that navigate to bottleneck\nstates. This work adopts a complementary approach, where we attempt to discover\noptions that navigate to landmark states. These states are prototypical\nrepresentatives of well-connected regions and can hence access the associated\nregion with relative ease. In this work, we propose Successor Options, which\nleverages Successor Representations to build a model of the state space. The\nintra-option policies are learnt using a novel pseudo-reward and the model\nscales to high-dimensional spaces easily. Additionally, we also propose an\nIncremental Successor Options model that iterates between constructing\nSuccessor Representations and building options, which is useful when robust\nSuccessor Representations cannot be built solely from primitive actions. We\ndemonstrate the efficacy of our approach on a collection of grid-worlds, and on\nthe high-dimensional robotic control environment of Fetch.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 17:24:11 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Ramesh", "Rahul", ""], ["Tomar", "Manan", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1905.05754", "submitter": "Karim Iskakov", "authors": "Karim Iskakov, Egor Burkov, Victor Lempitsky, Yury Malkov", "title": "Learnable Triangulation of Human Pose", "comments": "Project page: https://saic-violet.github.io/learnable-triangulation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two novel solutions for multi-view 3D human pose estimation based\non new learnable triangulation methods that combine 3D information from\nmultiple 2D views. The first (baseline) solution is a basic differentiable\nalgebraic triangulation with an addition of confidence weights estimated from\nthe input images. The second solution is based on a novel method of volumetric\naggregation from intermediate 2D backbone feature maps. The aggregated volume\nis then refined via 3D convolutions that produce final 3D joint heatmaps and\nallow modelling a human pose prior. Crucially, both approaches are end-to-end\ndifferentiable, which allows us to directly optimize the target metric. We\ndemonstrate transferability of the solutions across datasets and considerably\nimprove the multi-view state of the art on the Human3.6M dataset. Video\ndemonstration, annotations and additional materials will be posted on our\nproject page (https://saic-violet.github.io/learnable-triangulation).\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 17:59:20 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Iskakov", "Karim", ""], ["Burkov", "Egor", ""], ["Lempitsky", "Victor", ""], ["Malkov", "Yury", ""]]}, {"id": "1905.05778", "submitter": "Shi Feng", "authors": "Shi Feng, Eric Wallace, Jordan Boyd-Graber", "title": "Misleading Failures of Partial-input Baselines", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work establishes dataset difficulty and removes annotation artifacts\nvia partial-input baselines (e.g., hypothesis-only models for SNLI or\nquestion-only models for VQA). When a partial-input baseline gets high\naccuracy, a dataset is cheatable. However, the converse is not necessarily\ntrue: the failure of a partial-input baseline does not mean a dataset is free\nof artifacts. To illustrate this, we first design artificial datasets which\ncontain trivial patterns in the full input that are undetectable by any\npartial-input model. Next, we identify such artifacts in the SNLI dataset - a\nhypothesis-only model augmented with trivial patterns in the premise can solve\n15% of the examples that are previously considered \"hard\". Our work provides a\ncaveat for the use of partial-input baselines for dataset verification and\ncreation.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 18:01:41 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 02:39:20 GMT"}, {"version": "v3", "created": "Tue, 18 Jun 2019 17:07:09 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Feng", "Shi", ""], ["Wallace", "Eric", ""], ["Boyd-Graber", "Jordan", ""]]}, {"id": "1905.05809", "submitter": "Dennis Soemers", "authors": "Dennis J. N. J. Soemers, \\'Eric Piette, Matthew Stephenson, Cameron\n  Browne", "title": "Learning Policies from Self-Play with Policy Gradients and MCTS Value\n  Estimates", "comments": "Accepted at the IEEE Conference on Games (CoG) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, state-of-the-art game-playing agents often involve policies\nthat are trained in self-playing processes where Monte Carlo tree search (MCTS)\nalgorithms and trained policies iteratively improve each other. The strongest\nresults have been obtained when policies are trained to mimic the search\nbehaviour of MCTS by minimising a cross-entropy loss. Because MCTS, by design,\nincludes an element of exploration, policies trained in this manner are also\nlikely to exhibit a similar extent of exploration. In this paper, we are\ninterested in learning policies for a project with future goals including the\nextraction of interpretable strategies, rather than state-of-the-art\ngame-playing performance. For these goals, we argue that such an extent of\nexploration is undesirable, and we propose a novel objective function for\ntraining policies that are not exploratory. We derive a policy gradient\nexpression for maximising this objective function, which can be estimated using\nMCTS value estimates, rather than MCTS visit counts. We empirically evaluate\nvarious properties of resulting policies, in a variety of board games.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 19:33:45 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Soemers", "Dennis J. N. J.", ""], ["Piette", "\u00c9ric", ""], ["Stephenson", "Matthew", ""], ["Browne", "Cameron", ""]]}, {"id": "1905.05849", "submitter": "Shaeke Salman", "authors": "Shaeke Salman, Seyedeh Neelufar Payrovnaziri, Xiuwen Liu, Pablo\n  Rengifo-Moreno, Zhe He", "title": "Consensus-based Interpretable Deep Neural Networks with Application to\n  Mortality Prediction", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have achieved remarkable success in various challenging\ntasks. However, the black-box nature of such networks is not acceptable to\ncritical applications, such as healthcare. In particular, the existence of\nadversarial examples and their overgeneralization to irrelevant,\nout-of-distribution inputs with high confidence makes it difficult, if not\nimpossible, to explain decisions by such networks. In this paper, we analyze\nthe underlying mechanism of generalization of deep neural networks and propose\nan ($n$, $k$) consensus algorithm which is insensitive to adversarial examples\nand can reliably reject out-of-distribution samples. Furthermore, the consensus\nalgorithm is able to improve classification accuracy by using multiple trained\ndeep neural networks. To handle the complexity of deep neural networks, we\ncluster linear approximations of individual models and identify highly\ncorrelated clusters among different models to capture feature importance\nrobustly, resulting in improved interpretability. Motivated by the importance\nof building accurate and interpretable prediction models for healthcare, our\nexperimental results on an ICU dataset show the effectiveness of our algorithm\nin enhancing both the prediction accuracy and the interpretability of deep\nneural network models on one-year patient mortality prediction. In particular,\nwhile the proposed method maintains similar interpretability as conventional\nshallow models such as logistic regression, it improves the prediction accuracy\nsignificantly.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 21:26:56 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 05:32:07 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Salman", "Shaeke", ""], ["Payrovnaziri", "Seyedeh Neelufar", ""], ["Liu", "Xiuwen", ""], ["Rengifo-Moreno", "Pablo", ""], ["He", "Zhe", ""]]}, {"id": "1905.05879", "submitter": "Xuesong Yang", "authors": "Kaizhi Qian, Yang Zhang, Shiyu Chang, Xuesong Yang, Mark\n  Hasegawa-Johnson", "title": "AUTOVC: Zero-Shot Voice Style Transfer with Only Autoencoder Loss", "comments": "To Appear in Thirty-sixth International Conference on Machine\n  Learning (ICML 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-parallel many-to-many voice conversion, as well as zero-shot voice\nconversion, remain under-explored areas. Deep style transfer algorithms, such\nas generative adversarial networks (GAN) and conditional variational\nautoencoder (CVAE), are being applied as new solutions in this field. However,\nGAN training is sophisticated and difficult, and there is no strong evidence\nthat its generated speech is of good perceptual quality. On the other hand,\nCVAE training is simple but does not come with the distribution-matching\nproperty of a GAN. In this paper, we propose a new style transfer scheme that\ninvolves only an autoencoder with a carefully designed bottleneck. We formally\nshow that this scheme can achieve distribution-matching style transfer by\ntraining only on a self-reconstruction loss. Based on this scheme, we proposed\nAUTOVC, which achieves state-of-the-art results in many-to-many voice\nconversion with non-parallel data, and which is the first to perform zero-shot\nvoice conversion.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 23:19:04 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 05:44:48 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Qian", "Kaizhi", ""], ["Zhang", "Yang", ""], ["Chang", "Shiyu", ""], ["Yang", "Xuesong", ""], ["Hasegawa-Johnson", "Mark", ""]]}, {"id": "1905.05888", "submitter": "Christoph Salge", "authors": "Christoph Salge, Christian Guckelsberger, Michael Cerny Green, Rodrigo\n  Canaan and Julian Togelius", "title": "Generative Design in Minecraft: Chronicle Challenge", "comments": "5 pages, 1 Figure, accepted as late-breaking paper at ICCC 2019, 10th\n  International Conference on Computational Creativity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Chronicle Challenge as an optional addition to the\nSettlement Generation Challenge in Minecraft. One of the foci of the overall\ncompetition is adaptive procedural content generation (PCG), an arguably\nunder-explored problem in computational creativity. In the base challenge,\nparticipants must generate new settlements that respond to and ideally interact\nwith existing content in the world, such as the landscape or climate. The goal\nis to understand the underlying creative process, and to design better PCG\nsystems. The Chronicle Challenge in particular focuses on the generation of a\nnarrative based on the history of a generated settlement, expressed in natural\nlanguage. We discuss the unique features of the Chronicle Challenge in\ncomparison to other competitions, clarify the characteristics of a chronicle\neligible for submission and describe the evaluation criteria. We furthermore\ndraw on simulation-based approaches in computational storytelling as examples\nto how this challenge could be approached.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 23:53:57 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Salge", "Christoph", ""], ["Guckelsberger", "Christian", ""], ["Green", "Michael Cerny", ""], ["Canaan", "Rodrigo", ""], ["Togelius", "Julian", ""]]}, {"id": "1905.05953", "submitter": "Hongjiang Wei", "authors": "Hongjiang Wei, Steven Cao, Yuyao Zhang, Xiaojun Guan, Fuhua Yan,\n  Kristen W. Yeom, Chunlei Liu", "title": "Learning-based Single-step Quantitative Susceptibility Mapping\n  Reconstruction Without Brain Extraction", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantitative susceptibility mapping (QSM) estimates the underlying tissue\nmagnetic susceptibility from MRI gradient-echo phase signal and typically\nrequires several processing steps. These steps involve phase unwrapping, brain\nvolume extraction, background phase removal and solving an ill-posed inverse\nproblem. The resulting susceptibility map is known to suffer from inaccuracy\nnear the edges of the brain tissues, in part due to imperfect brain extraction,\nedge erosion of the brain tissue and the lack of phase measurement outside the\nbrain. This inaccuracy has thus hindered the application of QSM for measuring\nthe susceptibility of tissues near the brain edges, e.g., quantifying cortical\nlayers and generating superficial venography. To address these challenges, we\npropose a learning-based QSM reconstruction method that directly estimates the\nmagnetic susceptibility from total phase images without the need for brain\nextraction and background phase removal, referred to as autoQSM. The neural\nnetwork has a modified U-net structure and is trained using QSM maps computed\nby a two-step QSM method. 209 healthy subjects with ages ranging from 11 to 82\nyears were employed for patch-wise network training. The network was validated\non data dissimilar to the training data, e.g. in vivo mouse brain data and\nbrains with lesions, which suggests that the network has generalized and\nlearned the underlying mathematical relationship between magnetic field\nperturbation and magnetic susceptibility. AutoQSM was able to recover magnetic\nsusceptibility of anatomical structures near the edges of the brain including\nthe veins covering the cortical surface, spinal cord and nerve tracts near the\nmouse brain boundaries. The advantages of high-quality maps, no need for brain\nvolume extraction and high reconstruction speed demonstrate its potential for\nfuture applications.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 05:55:58 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Wei", "Hongjiang", ""], ["Cao", "Steven", ""], ["Zhang", "Yuyao", ""], ["Guan", "Xiaojun", ""], ["Yan", "Fuhua", ""], ["Yeom", "Kristen W.", ""], ["Liu", "Chunlei", ""]]}, {"id": "1905.05965", "submitter": "Jonathon Schwartz", "authors": "Jonathon Schwartz, Hanna Kurniawati", "title": "Autonomous Penetration Testing using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Penetration testing (pentesting) involves performing a controlled attack on a\ncomputer system in order to assess it's security. Although an effective method\nfor testing security, pentesting requires highly skilled practitioners and\ncurrently there is a growing shortage of skilled cyber security professionals.\nOne avenue for alleviating this problem is automate the pentesting process\nusing artificial intelligence techniques. Current approaches to automated\npentesting have relied on model-based planning, however the cyber security\nlandscape is rapidly changing making maintaining up-to-date models of exploits\na challenge. This project investigated the application of model-free\nReinforcement Learning (RL) to automated pentesting. Model-free RL has the key\nadvantage over model-based planning of not requiring a model of the\nenvironment, instead learning the best policy through interaction with the\nenvironment. We first designed and built a fast, low compute simulator for\ntraining and testing autonomous pentesting agents. We did this by framing\npentesting as a Markov Decision Process with the known configuration of the\nnetwork as states, the available scans and exploits as actions, the reward\ndetermined by the value of machines on the network. We then used this simulator\nto investigate the application of model-free RL to pentesting. We tested the\nstandard Q-learning algorithm using both tabular and neural network based\nimplementations. We found that within the simulated environment both tabular\nand neural network implementations were able to find optimal attack paths for a\nrange of different network topologies and sizes without having a model of\naction behaviour. However, the implemented algorithms were only practical for\nsmaller networks and numbers of actions. Further work is needed in developing\nscalable RL algorithms and testing these algorithms in larger and higher\nfidelity environments.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 06:18:14 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Schwartz", "Jonathon", ""], ["Kurniawati", "Hanna", ""]]}, {"id": "1905.05984", "submitter": "Simon Duque Anton", "authors": "Simon D. Duque Anton, Mathias Strufe, Hans Dieter Schotten", "title": "Modern Problems Require Modern Solutions: Hybrid Concepts for Industrial\n  Intrusion Detection", "comments": "PREPRINT, published in the proceedings of the 24th ITG Fachtagung\n  Mobilkommunikation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of Industry 4.0 brings a disruption into the processing industry.\nIt is characterised by a high degree of intercommunication, embedded\ncomputation, resulting in a decentralised and distributed handling of data.\nAdditionally, cloud-storage and Software-as-a-Service (SaaS) approaches enhance\na centralised storage and handling of data. This often takes place in\nthird-party networks. Furthermore, Industry 4.0 is driven by novel business\ncases. Lot sizes of one, customer individual production, observation of process\nstate and progress in real-time and remote maintenance, just to name a few. All\nof these new business cases make use of the novel technologies. However, cyber\nsecurity has not been an issue in industry. Industrial networks have been\nconsidered physically separated from public networks. Additionally, the high\nlevel of uniqueness of any industrial network was said to prevent attackers\nfrom exploiting flaws. Those assumptions are inherently broken by the concept\nof Industry 4.0. As a result, an abundance of attack vectors is created. In the\npast, attackers have used those attack vectors in spectacular fashions.\nEspecially Small and Mediumsized Enterprises (SMEs) in Germany struggle to\nadapt to these challenges. Reasons are the cost required for technical\nsolutions and security professionals. In order to enable SMEs to cope with the\ngrowing threat in the cyberspace, the research project IUNO Insec aims at\nproviding and improving security solutions that can be used without specialised\nsecurity knowledge. The project IUNO Insec is briefly introduced in this work.\nFurthermore, contributions in the field of intrusion detection, especially\nmachine learning-based solutions, for industrial environments provided by the\nauthors are presented and set into context.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 07:15:32 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 14:08:41 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Anton", "Simon D. Duque", ""], ["Strufe", "Mathias", ""], ["Schotten", "Hans Dieter", ""]]}, {"id": "1905.06023", "submitter": "Hao Song", "authors": "Hao Song, Tom Diethe, Meelis Kull, Peter Flach", "title": "Distribution Calibration for Regression", "comments": "ICML 2019, 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are concerned with obtaining well-calibrated output distributions from\nregression models. Such distributions allow us to quantify the uncertainty that\nthe model has regarding the predicted target value. We introduce the novel\nconcept of distribution calibration, and demonstrate its advantages over the\nexisting definition of quantile calibration. We further propose a post-hoc\napproach to improving the predictions from previously trained regression\nmodels, using multi-output Gaussian Processes with a novel Beta link function.\nThe proposed method is experimentally verified on a set of common regression\nmodels and shows improvements for both distribution-level and quantile-level\ncalibration.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 08:21:04 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Song", "Hao", ""], ["Diethe", "Tom", ""], ["Kull", "Meelis", ""], ["Flach", "Peter", ""]]}, {"id": "1905.06052", "submitter": "Brij Rokad", "authors": "Brij Rokad, Tushar Karumudi, Omkar Acharya and Akshay Jagtap", "title": "Survival of the Fittest in PlayerUnknown BattleGround", "comments": "14 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper was to predict the placement in the multiplayer game\nPUBG (playerunknown battleground). In the game, up to one hundred players\nparachutes onto an island and scavenge for weapons and equipment to kill\nothers, while avoiding getting killed themselves. The available safe area of\nthe game map decreases in size over time, directing surviving players into\ntighter areas to force encounters. The last player or team standing wins the\nround. In this paper specifically, we have tried to predict the placement of\nthe player in the ultimate survival test. The data set has been taken from\nKaggle. Entire dataset has 29 attributes which are categories to 1\nlabel(winPlacePerc), training set has 4.5 million instances and testing set has\n1.9 million. winPlacePerc is continuous category, which makes it harder to\npredict the survival of the fittest. To overcome this problem, we have applied\nmultiple machine learning models to find the optimum prediction. Model consists\nof LightGBM Regression (Light Gradient Boosting Machine Regression), MultiLayer\nPerceptron, M5P (improvement on C4.5) and Random Forest. To measure the error\nrate, Mean Absolute Error has been used. With the final prediction we have\nachieved MAE of 0.02047, 0.065, 0.0592 and 0634 respectively.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 09:39:46 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Rokad", "Brij", ""], ["Karumudi", "Tushar", ""], ["Acharya", "Omkar", ""], ["Jagtap", "Akshay", ""]]}, {"id": "1905.06088", "submitter": "Son Tran", "authors": "Artur d'Avila Garcez, Marco Gori, Luis C. Lamb, Luciano Serafini,\n  Michael Spranger, Son N. Tran", "title": "Neural-Symbolic Computing: An Effective Methodology for Principled\n  Integration of Machine Learning and Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Current advances in Artificial Intelligence and machine learning in general,\nand deep learning in particular have reached unprecedented impact not only\nacross research communities, but also over popular media channels. However,\nconcerns about interpretability and accountability of AI have been raised by\ninfluential thinkers. In spite of the recent impact of AI, several works have\nidentified the need for principled knowledge representation and reasoning\nmechanisms integrated with deep learning-based systems to provide sound and\nexplainable models for such systems. Neural-symbolic computing aims at\nintegrating, as foreseen by Valiant, two most fundamental cognitive abilities:\nthe ability to learn from the environment, and the ability to reason from what\nhas been learned. Neural-symbolic computing has been an active topic of\nresearch for many years, reconciling the advantages of robust learning in\nneural networks and reasoning and interpretability of symbolic representation.\nIn this paper, we survey recent accomplishments of neural-symbolic computing as\na principled methodology for integrated machine learning and reasoning. We\nillustrate the effectiveness of the approach by outlining the main\ncharacteristics of the methodology: principled integration of neural learning\nwith symbolic knowledge representation and reasoning allowing for the\nconstruction of explainable AI systems. The insights provided by\nneural-symbolic computing shed new light on the increasingly prominent need for\ninterpretable and accountable AI systems.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 11:00:48 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Garcez", "Artur d'Avila", ""], ["Gori", "Marco", ""], ["Lamb", "Luis C.", ""], ["Serafini", "Luciano", ""], ["Spranger", "Michael", ""], ["Tran", "Son N.", ""]]}, {"id": "1905.06114", "submitter": "Vuong M. Ngo", "authors": "Ngo Minh Vuong", "title": "Semantic Search using Spreading Activation based on Ontology", "comments": "21 pages, in Vietnamese", "journal-ref": "Science Journal, special issue E-Learning Architecture and\n  Technology (ELATE), Vol.53, 2013, pp. 136-156", "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, the text document retrieval systems have many challenges in\nexploring the semantics of queries and documents. Each query implies\ninformation which does not appear in the query but the documents related with\nthe information are also expected by user. The disadvantage of the previous\nspreading activation algorithms could be many irrelevant concepts added to the\nquery. In this paper, a proposed novel algorithm is only activate and add to\nthe query named entities which are related with original entities in the query\nand explicit relations in the query.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 10:28:57 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Vuong", "Ngo Minh", ""]]}, {"id": "1905.06125", "submitter": "Yao Hengshuai", "authors": "Borislav Mavrin, Shangtong Zhang, Hengshuai Yao, Linglong Kong, Kaiwen\n  Wu, Yaoliang Yu", "title": "Distributional Reinforcement Learning for Efficient Exploration", "comments": null, "journal-ref": "ICML, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In distributional reinforcement learning (RL), the estimated distribution of\nvalue function models both the parametric and intrinsic uncertainties. We\npropose a novel and efficient exploration method for deep RL that has two\ncomponents. The first is a decaying schedule to suppress the intrinsic\nuncertainty. The second is an exploration bonus calculated from the upper\nquantiles of the learned distribution. In Atari 2600 games, our method\noutperforms QR-DQN in 12 out of 14 hard games (achieving 483 \\% average gain\nacross 49 games in cumulative rewards over QR-DQN with a big win in Venture).\nWe also compared our algorithm with QR-DQN in a challenging 3D driving\nsimulator (CARLA). Results show that our algorithm achieves near-optimal safety\nrewards twice faster than QRDQN.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 19:08:55 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Mavrin", "Borislav", ""], ["Zhang", "Shangtong", ""], ["Yao", "Hengshuai", ""], ["Kong", "Linglong", ""], ["Wu", "Kaiwen", ""], ["Yu", "Yaoliang", ""]]}, {"id": "1905.06175", "submitter": "Mohsin Munir", "authors": "Mohsin Munir, Shoaib Ahmed Siddiqui, Ferdinand K\\\"usters, Dominique\n  Mercier, Andreas Dengel, Sheraz Ahmed", "title": "TSXplain: Demystification of DNN Decisions for Time-Series using Natural\n  Language and Statistical Features", "comments": "Pre-print", "journal-ref": null, "doi": "10.1007/978-3-030-30493-5_43", "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks (NN) are considered as black-boxes due to the lack of\nexplainability and transparency of their decisions. This significantly hampers\ntheir deployment in environments where explainability is essential along with\nthe accuracy of the system. Recently, significant efforts have been made for\nthe interpretability of these deep networks with the aim to open up the\nblack-box. However, most of these approaches are specifically developed for\nvisual modalities. In addition, the interpretations provided by these systems\nrequire expert knowledge and understanding for intelligibility. This indicates\na vital gap between the explainability provided by the systems and the novice\nuser. To bridge this gap, we present a novel framework i.e. Time-Series\neXplanation (TSXplain) system which produces a natural language based\nexplanation of the decision taken by a NN. It uses the extracted statistical\nfeatures to describe the decision of a NN, merging the deep learning world with\nthat of statistics. The two-level explanation provides ample description of the\ndecision made by the network to aid an expert as well as a novice user alike.\nOur survey and reliability assessment test confirm that the generated\nexplanations are meaningful and correct. We believe that generating natural\nlanguage based descriptions of the network's decisions is a big step towards\nopening up the black-box.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 13:37:58 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Munir", "Mohsin", ""], ["Siddiqui", "Shoaib Ahmed", ""], ["K\u00fcsters", "Ferdinand", ""], ["Mercier", "Dominique", ""], ["Dengel", "Andreas", ""], ["Ahmed", "Sheraz", ""]]}, {"id": "1905.06184", "submitter": "Simon Marynissen", "authors": "Simon Marynissen", "title": "Extensions to Justification Theory", "comments": "7 pages, extended abstract for LPNMR 2019 doctoral consortium (15th\n  International Conference on Logic Programming and Non-monotonic Reasoning,\n  Saint Joseph's University, Philadelphia, PA (USA))", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Justification theory is a unifying framework for semantics of non-monotonic\nlogics. It is built on the notion of a justification, which intuitively is a\ngraph that explains the truth value of certain facts in a structure. Knowledge\nrepresentation languages covered by justification theory include logic\nprograms, argumentation frameworks, inductive definitions, and nested inductive\nand coinductive definitions. In addition, justifications are also used for\nimplementation purposes. They are used to compute unfounded sets in modern ASP\nsolvers, can be used to check for relevance of atoms in complete search\nalgorithms, and recent lazy grounding algorithms are built on top of them. In\nthis extended abstract, we lay out possible extensions to justification theory.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 12:50:19 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Marynissen", "Simon", ""]]}, {"id": "1905.06209", "submitter": "William Cohen", "authors": "William W. Cohen and Matthew Siegler and Alex Hofer", "title": "Neural Query Language: A Knowledge Base Query Language for Tensorflow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large knowledge bases (KBs) are useful for many AI tasks, but are difficult\nto integrate into modern gradient-based learning systems. Here we describe a\nframework for accessing soft symbolic database using only differentiable\noperators. For example, this framework makes it easy to conveniently write\nneural models that adjust confidences associated with facts in a soft KB;\nincorporate prior knowledge in the form of hand-coded KB access rules; or learn\nto instantiate query templates using information extracted from text. NQL can\nwork well with KBs with millions of tuples and hundreds of thousands of\nentities on a single GPU.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 14:26:24 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Cohen", "William W.", ""], ["Siegler", "Matthew", ""], ["Hofer", "Alex", ""]]}, {"id": "1905.06221", "submitter": "Guanhua Zhang", "authors": "Guanhua Zhang, Bing Bai, Jian Liang, Kun Bai, Shiyu Chang, Mo Yu,\n  Conghui Zhu, Tiejun Zhao", "title": "Selection Bias Explorations and Debias Methods for Natural Language\n  Sentence Matching Datasets", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural Language Sentence Matching (NLSM) has gained substantial attention\nfrom both academics and the industry, and rich public datasets contribute a lot\nto this process. However, biased datasets can also hurt the generalization\nperformance of trained models and give untrustworthy evaluation results. For\nmany NLSM datasets, the providers select some pairs of sentences into the\ndatasets, and this sampling procedure can easily bring unintended pattern,\ni.e., selection bias. One example is the QuoraQP dataset, where some\ncontent-independent naive features are unreasonably predictive. Such features\nare the reflection of the selection bias and termed as the leakage features. In\nthis paper, we investigate the problem of selection bias on six NLSM datasets\nand find that four out of them are significantly biased. We further propose a\ntraining and evaluation framework to alleviate the bias. Experimental results\non QuoraQP suggest that the proposed framework can improve the generalization\nability of trained models, and give more trustworthy evaluation results for\nreal-world adoptions.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 14:51:33 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 09:40:00 GMT"}, {"version": "v3", "created": "Mon, 20 May 2019 03:11:20 GMT"}, {"version": "v4", "created": "Mon, 10 Jun 2019 03:12:43 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Zhang", "Guanhua", ""], ["Bai", "Bing", ""], ["Liang", "Jian", ""], ["Bai", "Kun", ""], ["Chang", "Shiyu", ""], ["Yu", "Mo", ""], ["Zhu", "Conghui", ""], ["Zhao", "Tiejun", ""]]}, {"id": "1905.06247", "submitter": "Yvan Lucas", "authors": "Yvan Lucas, Pierre-Edouard Portier, L\\'ea Laporte, Olivier Caelen,\n  Liyun He-Guelton, Sylvie Calabretto, Michael Granitzer", "title": "Multiple perspectives HMM-based feature engineering for credit card\n  fraud detection", "comments": "Presented as a poster in the conference SAC 2019: 34th ACM/SIGAPP\n  Symposium on Applied Computing in April 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and data mining techniques have been used extensively in\norder to detect credit card frauds. However, most studies consider credit card\ntransactions as isolated events and not as a sequence of transactions.\n  In this article, we model a sequence of credit card transactions from three\ndifferent perspectives, namely (i) does the sequence contain a Fraud? (ii) Is\nthe sequence obtained by fixing the card-holder or the payment terminal? (iii)\nIs it a sequence of spent amount or of elapsed time between the current and\nprevious transactions? Combinations of the three binary perspectives give eight\nsets of sequences from the (training) set of transactions. Each one of these\nsets is modelled with a Hidden Markov Model (HMM). Each HMM associates a\nlikelihood to a transaction given its sequence of previous transactions. These\nlikelihoods are used as additional features in a Random Forest classifier for\nfraud detection. This multiple perspectives HMM-based approach enables an\nautomatic feature engineering in order to model the sequential properties of\nthe dataset with respect to the classification task. This strategy allows for a\n15% increase in the precision-recall AUC compared to the state of the art\nfeature engineering strategy for credit card fraud detection.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 15:29:49 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Lucas", "Yvan", ""], ["Portier", "Pierre-Edouard", ""], ["Laporte", "L\u00e9a", ""], ["Caelen", "Olivier", ""], ["He-Guelton", "Liyun", ""], ["Calabretto", "Sylvie", ""], ["Granitzer", "Michael", ""]]}, {"id": "1905.06335", "submitter": "Lingbo Liu", "authors": "Lingbo Liu, Zhilin Qiu, Guanbin Li, Qing Wang, Wanli Ouyang, Liang Lin", "title": "Contextualized Spatial-Temporal Network for Taxi Origin-Destination\n  Demand Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taxi demand prediction has recently attracted increasing research interest\ndue to its huge potential application in large-scale intelligent transportation\nsystems. However, most of the previous methods only considered the taxi demand\nprediction in origin regions, but neglected the modeling of the specific\nsituation of the destination passengers. We believe it is suboptimal to\npreallocate the taxi into each region based solely on the taxi origin demand.\nIn this paper, we present a challenging and worth-exploring task, called taxi\norigin-destination demand prediction, which aims at predicting the taxi demand\nbetween all region pairs in a future time interval. Its main challenges come\nfrom how to effectively capture the diverse contextual information to learn the\ndemand patterns. We address this problem with a novel Contextualized\nSpatial-Temporal Network (CSTN), which consists of three components for the\nmodeling of local spatial context (LSC), temporal evolution context (TEC) and\nglobal correlation context (GCC) respectively. Firstly, an LSC module utilizes\ntwo convolution neural networks to learn the local spatial dependencies of taxi\ndemand respectively from the origin view and the destination view. Secondly, a\nTEC module incorporates both the local spatial features of taxi demand and the\nmeteorological information to a Convolutional Long Short-term Memory Network\n(ConvLSTM) for the analysis of taxi demand evolution. Finally, a GCC module is\napplied to model the correlation between all regions by computing a global\ncorrelation feature as a weighted sum of all regional features, with the\nweights being calculated as the similarity between the corresponding region\npairs. Extensive experiments and evaluations on a large-scale dataset well\ndemonstrate the superiority of our CSTN over other compared methods for taxi\norigin-destination demand prediction.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 10:21:05 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Liu", "Lingbo", ""], ["Qiu", "Zhilin", ""], ["Li", "Guanbin", ""], ["Wang", "Qing", ""], ["Ouyang", "Wanli", ""], ["Lin", "Liang", ""]]}, {"id": "1905.06379", "submitter": "Ahmed Khalifa", "authors": "Ahmed Khalifa, Dan Gopstein, Julian Togelius", "title": "ELIMINATION from Design to Analysis", "comments": "4 pages, 3 figures, submitted to CoG as a short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Elimination is a word puzzle game for browsers and mobile devices, where all\nlevels are generated by a constrained evolutionary algorithm with no human\nintervention. This paper describes the design of the game and its level\ngeneration methods, and analysis of playtraces from almost a thousand users who\nplayed the game since its release. The analysis corroborates that the level\ngenerator creates a sawtooth-shaped difficulty curve, as intended. The analysis\nalso offers insights into player behavior in this game.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 18:40:05 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Khalifa", "Ahmed", ""], ["Gopstein", "Dan", ""], ["Togelius", "Julian", ""]]}, {"id": "1905.06393", "submitter": "Jie Chen", "authors": "Patrick Ferber, Tengfei Ma, Siyu Huo, Jie Chen, Michael Katz", "title": "IPC: A Benchmark Data Set for Learning with Graph-Structured Data", "comments": "ICML 2019 Workshop on Learning and Reasoning with Graph-Structured\n  Data. The data set is accessible from https://github.com/IBM/IPC-graph-data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Benchmark data sets are an indispensable ingredient of the evaluation of\ngraph-based machine learning methods. We release a new data set, compiled from\nInternational Planning Competitions (IPC), for benchmarking graph\nclassification, regression, and related tasks. Apart from the graph\nconstruction (based on AI planning problems) that is interesting in its own\nright, the data set possesses distinctly different characteristics from\npopularly used benchmarks. The data set, named IPC, consists of two\nself-contained versions, grounded and lifted, both including graphs of large\nand skewedly distributed sizes, posing substantial challenges for the\ncomputation of graph models such as graph kernels and graph neural networks.\nThe graphs in this data set are directed and the lifted version is acyclic,\noffering the opportunity of benchmarking specialized models for directed\n(acyclic) structures. Moreover, the graph generator and the labeling are\ncomputer programmed; thus, the data set may be extended easily if a larger\nscale is desired. The data set is accessible from\n\\url{https://github.com/IBM/IPC-graph-data}.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 19:03:22 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Ferber", "Patrick", ""], ["Ma", "Tengfei", ""], ["Huo", "Siyu", ""], ["Chen", "Jie", ""], ["Katz", "Michael", ""]]}, {"id": "1905.06402", "submitter": "Bence Cserna", "authors": "Bence Cserna, Kevin C. Gall, Wheeler Ruml", "title": "Improved Safe Real-time Heuristic Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental concern in real-time planning is the presence of dead-ends in\nthe state space, from which no goal is reachable. Recently, the SafeRTS\nalgorithm was proposed for searching in such spaces. SafeRTS exploits a\nuser-provided predicate to identify safe states, from which a goal is likely\nreachable, and attempts to maintain a backup plan for reaching a safe state at\nall times. In this paper, we study the SafeRTS approach, identify certain\nproperties of its behavior, and design an improved framework for safe real-time\nsearch. We prove that the new approach performs at least as well as SafeRTS and\npresent experimental results showing that its promise is fulfilled in practice.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 19:22:59 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Cserna", "Bence", ""], ["Gall", "Kevin C.", ""], ["Ruml", "Wheeler", ""]]}, {"id": "1905.06413", "submitter": "Mathieu Ritou", "authors": "Mathieu Ritou (RoMas, IUT NANTES), Farouk Belkadi (IS3P, ECN), Zakaria\n  Yahouni (LS2N, IUT NANTES), Catherine Da Cunha (IS3P, ECN), Florent Laroche\n  (IS3P, ECN), Benoit Furet (RoMas, IUT NANTES)", "title": "Knowledge-based multi-level aggregation for decision aid in the\n  machining industry", "comments": "CIRP Annals - Manufacturing Technology, Elsevier, 2019", "journal-ref": null, "doi": "10.1016/j.cirp.2019.03.009", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of Industry 4.0, data management is a key point for decision\naid approaches. Large amounts of manufacturing digital data are collected on\nthe shop floor. Their analysis can then require a large amount of computing\npower. The Big Data issue can be solved by aggregation, generating smart and\nmeaningful data. This paper presents a new knowledge-based multi-level\naggregation strategy to support decision making. Manufacturing knowledge is\nused at each level to design the monitoring criteria or aggregation operators.\nThe proposed approach has been implemented as a demonstrator and successfully\napplied to a real machining database from the aeronautic industry. Decision\nMaking; Machining; Knowledge based system\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 07:08:47 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Ritou", "Mathieu", "", "RoMas, IUT NANTES"], ["Belkadi", "Farouk", "", "IS3P, ECN"], ["Yahouni", "Zakaria", "", "LS2N, IUT NANTES"], ["Da Cunha", "Catherine", "", "IS3P, ECN"], ["Laroche", "Florent", "", "IS3P, ECN"], ["Furet", "Benoit", "", "RoMas, IUT NANTES"]]}, {"id": "1905.06424", "submitter": "Jan Humplik", "authors": "Jan Humplik, Alexandre Galashov, Leonard Hasenclever, Pedro A. Ortega,\n  Yee Whye Teh, Nicolas Heess", "title": "Meta reinforcement learning as task inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans achieve efficient learning by relying on prior knowledge about the\nstructure of naturally occurring tasks. There is considerable interest in\ndesigning reinforcement learning (RL) algorithms with similar properties. This\nincludes proposals to learn the learning algorithm itself, an idea also known\nas meta learning. One formal interpretation of this idea is as a partially\nobservable multi-task RL problem in which task information is hidden from the\nagent. Such unknown task problems can be reduced to Markov decision processes\n(MDPs) by augmenting an agent's observations with an estimate of the belief\nabout the task based on past experience. However estimating the belief state is\nintractable in most partially-observed MDPs. We propose a method that\nseparately learns the policy and the task belief by taking advantage of various\nkinds of privileged information. Our approach can be very effective at solving\nstandard meta-RL environments, as well as a complex continuous control\nenvironment with sparse rewards and requiring long-term memory.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 20:21:14 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 15:54:03 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Humplik", "Jan", ""], ["Galashov", "Alexandre", ""], ["Hasenclever", "Leonard", ""], ["Ortega", "Pedro A.", ""], ["Teh", "Yee Whye", ""], ["Heess", "Nicolas", ""]]}, {"id": "1905.06462", "submitter": "Praneeth Vepakomma", "authors": "Ramesh Raskar, Praneeth Vepakomma, Tristan Swedish, Aalekh Sharan", "title": "Data Markets to support AI for All: Pricing, Valuation and Governance", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss a data market technique based on intrinsic (relevance and\nuniqueness) as well as extrinsic value (influenced by supply and demand) of\ndata. For intrinsic value, we explain how to perform valuation of data in\nabsolute terms (i.e just by itself), or relatively (i.e in comparison to\nmultiple datasets) or in conditional terms (i.e valuating new data given\ncurrently existing data).\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 04:41:11 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Raskar", "Ramesh", ""], ["Vepakomma", "Praneeth", ""], ["Swedish", "Tristan", ""], ["Sharan", "Aalekh", ""]]}, {"id": "1905.06471", "submitter": "Murat Cubuktepe", "authors": "Murat Cubuktepe, Nils Jansen, Mohammed Alsiekh, and Ufuk Topcu", "title": "Synthesis of Provably Correct Autonomy Protocols for Shared Control", "comments": "Submitted to IEEE Transactions of Automatic Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We synthesize shared control protocols subject to probabilistic temporal\nlogic specifications. More specifically, we develop a framework in which a\nhuman and an autonomy protocol can issue commands to carry out a certain task.\nWe blend these commands into a joint input to a robot. We model the interaction\nbetween the human and the robot as a Markov decision process (MDP) that\nrepresents the shared control scenario. Using inverse reinforcement learning,\nwe obtain an abstraction of the human's behavior and decisions. We use\nrandomized strategies to account for randomness in human's decisions, caused by\nfactors such as complexity of the task specifications or imperfect interfaces.\nWe design the autonomy protocol to ensure that the resulting robot behavior\nsatisfies given safety and performance specifications in probabilistic temporal\nlogic. Additionally, the resulting strategies generate behavior as similar to\nthe behavior induced by the human's commands as possible. We solve the\nunderlying problem efficiently using quasiconvex programming. Case studies\ninvolving autonomous wheelchair navigation and unmanned aerial vehicle mission\nplanning showcase the applicability of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 23:46:58 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Cubuktepe", "Murat", ""], ["Jansen", "Nils", ""], ["Alsiekh", "Mohammed", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1905.06499", "submitter": "Chi Zhang", "authors": "Chi Zhang, Yuehu Liu, Ying Wu, Qilin Zhang, Le Wang", "title": "Bimodal Stereo: Joint Shape and Pose Estimation from Color-Depth Image\n  Pair", "comments": "Preprinted version on May 15, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mutual calibration between color and depth cameras is a challenging topic in\nmulti-modal data registration. In this paper, we are confronted with a \"Bimodal\nStereo\" problem, which aims to solve camera pose from a pair of an uncalibrated\ncolor image and a depth map from different views automatically. To address this\nproblem, an iterative Shape-from-Shading (SfS) based framework is proposed to\nestimate shape and pose simultaneously. In the pipeline, the estimated shape is\nrefined by the shape prior from the given depth map under the estimated pose.\nMeanwhile, the estimated pose is improved by the registration of estimated\nshape and shape from given depth map. We also introduce a shading based\nrefinement in the pipeline to address noisy depth map with holes. Extensive\nexperiments showed that through our method, both the depth map, the recovered\nshape as well as its pose can be desirably refined and recovered.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 02:15:01 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Zhang", "Chi", ""], ["Liu", "Yuehu", ""], ["Wu", "Ying", ""], ["Zhang", "Qilin", ""], ["Wang", "Le", ""]]}, {"id": "1905.06527", "submitter": "Lin Lan", "authors": "Lin Lan, Zhenguo Li, Xiaohong Guan, Pinghui Wang", "title": "Meta Reinforcement Learning with Task Embedding and Shared Policy", "comments": "Accepted to IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite significant progress, deep reinforcement learning (RL) suffers from\ndata-inefficiency and limited generalization. Recent efforts apply\nmeta-learning to learn a meta-learner from a set of RL tasks such that a novel\nbut related task could be solved quickly. Though specific in some ways,\ndifferent tasks in meta-RL are generally similar at a high level. However, most\nmeta-RL methods do not explicitly and adequately model the specific and shared\ninformation among different tasks, which limits their ability to learn training\ntasks and to generalize to novel tasks. In this paper, we propose to capture\nthe shared information on the one hand and meta-learn how to quickly abstract\nthe specific information about a task on the other hand. Methodologically, we\ntrain an SGD meta-learner to quickly optimize a task encoder for each task,\nwhich generates a task embedding based on past experience. Meanwhile, we learn\na policy which is shared across all tasks and conditioned on task embeddings.\nEmpirical results on four simulated tasks demonstrate that our method has\nbetter learning capacity on both training and novel tasks and attains up to 3\nto 4 times higher returns compared to baselines.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 04:42:25 GMT"}, {"version": "v2", "created": "Sun, 19 May 2019 10:31:20 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 02:46:32 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Lan", "Lin", ""], ["Li", "Zhenguo", ""], ["Guan", "Xiaohong", ""], ["Wang", "Pinghui", ""]]}, {"id": "1905.06656", "submitter": "Kai Zhu", "authors": "Kai Zhu, Wei Zhai, Zheng-Jun Zha, Yang Cao", "title": "One-Shot Texture Retrieval with Global Context Metric", "comments": "ijcai2019-lastest", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we tackle one-shot texture retrieval: given an example of a\nnew reference texture, detect and segment all the pixels of the same texture\ncategory within an arbitrary image. To address this problem, we present an\nOS-TR network to encode both reference and query image, leading to achieve\ntexture segmentation towards the reference category. Unlike the existing\ntexture encoding methods that integrate CNN with orderless pooling, we propose\na directionality-aware module to capture the texture variations at each\ndirection, resulting in spatially invariant representation. To segment new\ncategories given only few examples, we incorporate a self-gating mechanism into\nrelation network to exploit global context information for adjusting\nper-channel modulation weights of local relation features. Extensive\nexperiments on benchmark texture datasets and real scenarios demonstrate the\nabove-par segmentation performance and robust generalization across domains of\nour proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 11:00:49 GMT"}, {"version": "v2", "created": "Sun, 12 Apr 2020 03:25:11 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Zhu", "Kai", ""], ["Zhai", "Wei", ""], ["Zha", "Zheng-Jun", ""], ["Cao", "Yang", ""]]}, {"id": "1905.06684", "submitter": "Federico Galatolo", "authors": "Federico A. Galatolo, Mario G.C.A. Cimino, Gigliola Vaglini", "title": "Formal derivation of Mesh Neural Networks with their Forward-Only\n  gradient Propagation", "comments": null, "journal-ref": null, "doi": "10.1007/s11063-021-10490-1", "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the Mesh Neural Network (MNN), a novel architecture which\nallows neurons to be connected in any topology, to efficiently route\ninformation. In MNNs, information is propagated between neurons throughout a\nstate transition function. State and error gradients are then directly computed\nfrom state updates without backward computation. The MNN architecture and the\nerror propagation schema is formalized and derived in tensor algebra. The\nproposed computational model can fully supply a gradient descent process, and\nis potentially suitable for very large scale sparse NNs, due to its\nexpressivity and training efficiency, with respect to NNs based on\nback-propagation and computational graphs.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 12:22:26 GMT"}, {"version": "v2", "created": "Sun, 19 May 2019 13:22:36 GMT"}, {"version": "v3", "created": "Sat, 2 Nov 2019 12:14:11 GMT"}, {"version": "v4", "created": "Mon, 25 May 2020 20:06:51 GMT"}, {"version": "v5", "created": "Wed, 7 Jul 2021 14:37:36 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Galatolo", "Federico A.", ""], ["Cimino", "Mario G. C. A.", ""], ["Vaglini", "Gigliola", ""]]}, {"id": "1905.06712", "submitter": "Hege Haavaldsen", "authors": "Hege Haavaldsen, Max Aasboe, Frank Lindseth", "title": "Autonomous Vehicle Control: End-to-end Learning in Simulated Urban\n  Environments", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In recent years, considerable progress has been made towards a vehicle's\nability to operate autonomously. An end-to-end approach attempts to achieve\nautonomous driving using a single, comprehensive software component. Recent\nbreakthroughs in deep learning have significantly increased end-to-end systems'\ncapabilities, and such systems are now considered a possible alternative to the\ncurrent state-of-the-art solutions. This paper examines end-to-end learning for\nautonomous vehicles in simulated urban environments containing other vehicles,\ntraffic lights, and speed limits. Furthermore, the paper explores end-to-end\nsystems' ability to execute navigational commands and examines whether improved\nperformance can be achieved by utilizing temporal dependencies between\nsubsequent visual cues. Two end-to-end architectures are proposed: a\ntraditional Convolutional Neural Network and an extended design combining a\nConvolutional Neural Network with a recurrent layer. The models are trained\nusing expert driving data from a simulated urban setting, and are evaluated by\ntheir driving performance in an unseen simulated environment. The results of\nthis paper indicate that end-to-end systems can operate autonomously in simple\nurban environments. Moreover, it is found that the exploitation of temporal\ninformation in subsequent images enhances a system's ability to judge movement\nand distance.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 13:04:52 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Haavaldsen", "Hege", ""], ["Aasboe", "Max", ""], ["Lindseth", "Frank", ""]]}, {"id": "1905.06845", "submitter": "Friso H. Kingma", "authors": "Friso H. Kingma, Pieter Abbeel, Jonathan Ho", "title": "Bit-Swap: Recursive Bits-Back Coding for Lossless Compression with\n  Hierarchical Latent Variables", "comments": "Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bits-back argument suggests that latent variable models can be turned\ninto lossless compression schemes. Translating the bits-back argument into\nefficient and practical lossless compression schemes for general latent\nvariable models, however, is still an open problem. Bits-Back with Asymmetric\nNumeral Systems (BB-ANS), recently proposed by Townsend et al. (2019), makes\nbits-back coding practically feasible for latent variable models with one\nlatent layer, but it is inefficient for hierarchical latent variable models. In\nthis paper we propose Bit-Swap, a new compression scheme that generalizes\nBB-ANS and achieves strictly better compression rates for hierarchical latent\nvariable models with Markov chain structure. Through experiments we verify that\nBit-Swap results in lossless compression rates that are empirically superior to\nexisting techniques. Our implementation is available at\nhttps://github.com/fhkingma/bitswap.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 15:32:35 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 17:10:45 GMT"}, {"version": "v3", "created": "Mon, 10 Jun 2019 05:51:17 GMT"}, {"version": "v4", "created": "Wed, 2 Oct 2019 09:57:24 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Kingma", "Friso H.", ""], ["Abbeel", "Pieter", ""], ["Ho", "Jonathan", ""]]}, {"id": "1905.06873", "submitter": "Beno\\^it Choffin", "authors": "Beno\\^it Choffin, Fabrice Popineau, Yolaine Bourda and Jill-J\\^enn Vie", "title": "DAS3H: Modeling Student Learning and Forgetting for Optimally Scheduling\n  Distributed Practice of Skills", "comments": "10 pages, 1 figure, 6 tables, to appear at the 12th International\n  Conference on Educational Data Mining (EDM 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spaced repetition is among the most studied learning strategies in the\ncognitive science literature. It consists in temporally distributing exposure\nto an information so as to improve long-term memorization. Providing students\nwith an adaptive and personalized distributed practice schedule would benefit\nmore than just a generic scheduler. However, the applicability of such adaptive\nschedulers seems to be limited to pure memorization, e.g. flashcards or foreign\nlanguage learning. In this article, we first frame the research problem of\noptimizing an adaptive and personalized spaced repetition scheduler when\nmemorization concerns the application of underlying multiple skills. To this\nend, we choose to rely on a student model for inferring knowledge state and\nmemory dynamics on any skill or combination of skills. We argue that no\nknowledge tracing model takes both memory decay and multiple skill tagging into\naccount for predicting student performance. As a consequence, we propose a new\nstudent learning and forgetting model suited to our research problem: DAS3H\nbuilds on the additive factor models and includes a representation of the\ntemporal distribution of past practice on the skills involved by an item. In\nparticular, DAS3H allows the learning and forgetting curves to differ from one\nskill to another. Finally, we provide empirical evidence on three real-world\neducational datasets that DAS3H outperforms other state-of-the-art EDM models.\nThese results suggest that incorporating both item-skill relationships and\nforgetting effect improves over student models that consider one or the other.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 16:41:03 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Choffin", "Beno\u00eet", ""], ["Popineau", "Fabrice", ""], ["Bourda", "Yolaine", ""], ["Vie", "Jill-J\u00eann", ""]]}, {"id": "1905.06875", "submitter": "Kit Rodolfa", "authors": "Kit T Rodolfa, Adolfo De Unanue, Matt Gee, Rayid Ghani", "title": "A Clinical Approach to Training Effective Data Scientists", "comments": "18 pages, 3 figures, 2 tables", "journal-ref": "Big Data 7:4, 249-261 (2019)", "doi": "10.1089/big.2019.0100", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Like medicine, psychology, or education, data science is fundamentally an\napplied discipline, with most students who receive advanced degrees in the\nfield going on to work on practical problems. Unlike these disciplines,\nhowever, data science education remains heavily focused on theory and methods,\nand practical coursework typically revolves around cleaned or simplified data\nsets that have little analog in professional applications. We believe that the\nenvironment in which new data scientists are trained should more accurately\nreflect that in which they will eventually practice and propose here a data\nscience master's degree program that takes inspiration from the residency model\nused in medicine. Students in the suggested program would spend three years\nworking on a practical problem with an industry, government, or nonprofit\npartner, supplemented with coursework in data science methods and theory. We\nalso discuss how this program can also be implemented in shorter formats to\naugment existing professional masters programs in different disciplines. This\napproach to learning by doing is designed to fill gaps in our current approach\nto data science education and ensure that students develop the skills they need\nto practice data science in a professional context and under the many\nconstraints imposed by that context.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 02:36:28 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Rodolfa", "Kit T", ""], ["De Unanue", "Adolfo", ""], ["Gee", "Matt", ""], ["Ghani", "Rayid", ""]]}, {"id": "1905.06876", "submitter": "Jessica Morley", "authors": "Jessica Morley, Luciano Floridi, Libby Kinsey and Anat Elhalal", "title": "From What to How: An Initial Review of Publicly Available AI Ethics\n  Tools, Methods and Research to Translate Principles into Practices", "comments": "15 pages, links to typology available on the web", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The debate about the ethical implications of Artificial Intelligence dates\nfrom the 1960s. However, in recent years symbolic AI has been complemented and\nsometimes replaced by Neural Networks and Machine Learning techniques. This has\nvastly increased its potential utility and impact on society, with the\nconsequence that the ethical debate has gone mainstream. Such debate has\nprimarily focused on principles - the what of AI ethics - rather than on\npractices, the how. Awareness of the potential issues is increasing at a fast\nrate, but the AI community's ability to take action to mitigate the associated\nrisks is still at its infancy. Therefore, our intention in presenting this\nresearch is to contribute to closing the gap between principles and practices\nby constructing a typology that may help practically-minded developers apply\nethics at each stage of the pipeline, and to signal to researchers where\nfurther work is needed. The focus is exclusively on Machine Learning, but it is\nhoped that the results of this research may be easily applicable to other\nbranches of AI. The article outlines the research method for creating this\ntypology, the initial findings, and provides a summary of future research\nneeds.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 07:38:44 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 12:10:32 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Morley", "Jessica", ""], ["Floridi", "Luciano", ""], ["Kinsey", "Libby", ""], ["Elhalal", "Anat", ""]]}, {"id": "1905.06883", "submitter": "Chen Qian", "authors": "Chen Qian and Lijie Wen and Akhil Kumar", "title": "TraceWalk: Semantic-based Process Graph Embedding for Consistency\n  Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process consistency checking (PCC), an interdiscipline of natural language\nprocessing (NLP) and business process management (BPM), aims to quantify the\ndegree of (in)consistencies between graphical and textual descriptions of a\nprocess. However, previous studies heavily depend on a great deal of complex\nexpert-defined knowledge such as alignment rules and assessment metrics, thus\nsuffer from the problems of low accuracy and poor adaptability when applied in\nopen-domain scenarios. To address the above issues, this paper makes the first\nattempt that uses deep learning to perform PCC. Specifically, we proposed\nTraceWalk, using semantic information of process graphs to learn latent node\nrepresentations, and integrates it into a convolutional neural network (CNN)\nbased model called TraceNet to predict consistencies. The theoretical proof\nformally provides the PCC's lower limit and experimental results demonstrate\nthat our approach performs more accurately than state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 16:15:01 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Qian", "Chen", ""], ["Wen", "Lijie", ""], ["Kumar", "Akhil", ""]]}, {"id": "1905.06900", "submitter": "Nicolas Le Scouarnec", "authors": "Fabien Andr\\'e, Anne-Marie Kermarrec, Nicolas Le Scouarnec", "title": "Derived Codebooks for High-Accuracy Nearest Neighbor Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional Nearest Neighbor (NN) search is central in multimedia search\nsystems. Product Quantization (PQ) is a widespread NN search technique which\nhas a high performance and good scalability. PQ compresses high-dimensional\nvectors into compact codes thanks to a combination of quantizers. Large\ndatabases can, therefore, be stored entirely in RAM, enabling fast responses to\nNN queries. In almost all cases, PQ uses 8-bit quantizers as they offer low\nresponse times. In this paper, we advocate the use of 16-bit quantizers.\nCompared to 8-bit quantizers, 16-bit quantizers boost accuracy but they\nincrease response time by a factor of 3 to 10. We propose a novel approach that\nallows 16-bit quantizers to offer the same response time as 8-bit quantizers,\nwhile still providing a boost of accuracy. Our approach builds on two key\nideas: (i) the construction of derived codebooks that allow a fast and\napproximate distance evaluation, and (ii) a two-pass NN search procedure which\nbuilds a candidate set using the derived codebooks, and then refines it using\n16-bit quantizers. On 1 billion SIFT vectors, with an inverted index, our\napproach offers a Recall@100 of 0.85 in 5.2 ms. By contrast, 16-bit quantizers\nalone offer a Recall@100 of 0.85 in 39 ms, and 8-bit quantizers a Recall@100 of\n0.82 in 3.8 ms.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 16:47:30 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Andr\u00e9", "Fabien", ""], ["Kermarrec", "Anne-Marie", ""], ["Scouarnec", "Nicolas Le", ""]]}, {"id": "1905.06987", "submitter": "Adarsh Kyadige", "authors": "Adarsh Kyadige, Ethan M. Rudd, Konstantin Berlin", "title": "Learning from Context: Exploiting and Interpreting File Path Information\n  for Better Malware Detection", "comments": "Submitted to ACM CCS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) used for static portable executable (PE) malware\ndetection typically employs per-file numerical feature vector representations\nas input with one or more target labels during training. However, there is much\northogonal information that can be gleaned from the \\textit{context} in which\nthe file was seen. In this paper, we propose utilizing a static source of\ncontextual information -- the path of the PE file -- as an auxiliary input to\nthe classifier. While file paths are not malicious or benign in and of\nthemselves, they do provide valuable context for a malicious/benign\ndetermination. Unlike dynamic contextual information, file paths are available\nwith little overhead and can seamlessly be integrated into a multi-view static\nML detector, yielding higher detection rates at very high throughput with\nminimal infrastructural changes. Here we propose a multi-view neural network,\nwhich takes feature vectors from PE file content as well as corresponding file\npaths as inputs and outputs a detection score. To ensure realistic evaluation,\nwe use a dataset of approximately 10 million samples -- files and file paths\nfrom user endpoints of an actual security vendor network. We then conduct an\ninterpretability analysis via LIME modeling to ensure that our classifier has\nlearned a sensible representation and see which parts of the file path most\ncontributed to change in the classifier's score. We find that our model learns\nuseful aspects of the file path for classification, while also learning\nartifacts from customers testing the vendor's product, e.g., by downloading a\ndirectory of malware samples each named as their hash. We prune these artifacts\nfrom our test dataset and demonstrate reductions in false negative rate of\n32.3% at a $10^{-3}$ false positive rate (FPR) and 33.1% at $10^{-4}$ FPR, over\na similar topology single input PE file content only model.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 18:36:55 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Kyadige", "Adarsh", ""], ["Rudd", "Ethan M.", ""], ["Berlin", "Konstantin", ""]]}, {"id": "1905.07026", "submitter": "Vaishak Belle", "authors": "Michael Varley, Vaishak Belle", "title": "Fairness in Machine Learning with Tractable Models", "comments": "In AAAI Workshop: Statistical Relational Artificial Intelligence\n  (StarAI), 2020. (This is the extended version.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning techniques have become pervasive across a range of different\napplications, and are now widely used in areas as disparate as recidivism\nprediction, consumer credit-risk analysis and insurance pricing. The prevalence\nof machine learning techniques has raised concerns about the potential for\nlearned algorithms to become biased against certain groups. Many definitions\nhave been proposed in the literature, but the fundamental task of reasoning\nabout probabilistic events is a challenging one, owing to the intractability of\ninference.\n  The focus of this paper is taking steps towards the application of tractable\nmodels to fairness. Tractable probabilistic models have emerged that guarantee\nthat conditional marginal can be computed in time linear in the size of the\nmodel. In particular, we show that sum product networks (SPNs) enable an\neffective technique for determining the statistical relationships between\nprotected attributes and other training variables. If a subset of these\ntraining variables are found by the SPN to be independent of the training\nattribute then they can be considered `safe' variables, from which we can train\na classification model without concern that the resulting classifier will\nresult in disparate outcomes for different demographic groups.\n  Our initial experiments on the `German Credit' data set indicate that this\nprocessing technique significantly reduces disparate treatment of male and\nfemale credit applicants, with a small reduction in classification accuracy\ncompared to state of the art. We will also motivate the concept of \"fairness\nthrough percentile equivalence\", a new definition predicated on the notion that\nindividuals at the same percentile of their respective distributions should be\ntreated equivalently, and this prevents unfair penalisation of those\nindividuals who lie at the extremities of their respective distributions.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 20:31:26 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 13:25:33 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Varley", "Michael", ""], ["Belle", "Vaishak", ""]]}, {"id": "1905.07028", "submitter": "Vaishak Belle", "authors": "Laszlo Treszkai, Vaishak Belle", "title": "A Correctness Result for Synthesizing Plans With Loops in Stochastic\n  Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finite-state controllers (FSCs), such as plans with loops, are powerful and\ncompact representations of action selection widely used in robotics, video\ngames and logistics. There has been steady progress on synthesizing FSCs in\ndeterministic environments, but the algorithmic machinery needed for lifting\nsuch techniques to stochastic environments is not yet fully understood. While\nthe derivation of FSCs has received some attention in the context of discounted\nexpected reward measures, they are often solved approximately and/or without\ncorrectness guarantees. In essence, that makes it difficult to analyze\nfundamental concerns such as: do all paths terminate, and do the majority of\npaths reach a goal state?\n  In this paper, we present new theoretical results on a generic technique for\nsynthesizing FSCs in stochastic environments, allowing for highly granular\nspecifications on termination and goal satisfaction.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 20:41:57 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Treszkai", "Laszlo", ""], ["Belle", "Vaishak", ""]]}, {"id": "1905.07030", "submitter": "Daoming Lyu", "authors": "Daoming Lyu", "title": "Knowledge-Based Sequential Decision-Making Under Uncertainty", "comments": "5 pages, submitted for the Doctoral Consortium at the 15th\n  International Conference on Logic Programming and Non-monotonic Reasoning\n  (LPNMR 2019). arXiv admin note: text overlap with arXiv:1811.00090", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) algorithms have achieved great success on\nsequential decision-making problems, yet is criticized for the lack of\ndata-efficiency and explainability. Especially, explainability of subtasks is\ncritical in hierarchical decision-making since it enhances the transparency of\nblack-box-style DRL methods and helps the RL practitioners to understand the\nhigh-level behavior of the system better. To improve the data-efficiency and\nexplainability of DRL, declarative knowledge is introduced in this work and a\nnovel algorithm is proposed by integrating DRL with symbolic planning.\nExperimental analysis on publicly available benchmarks validates the\nexplainability of the subtasks and shows that our method can outperform the\nstate-of-the-art approach in terms of data-efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 20:56:03 GMT"}, {"version": "v2", "created": "Sat, 16 May 2020 02:01:40 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Lyu", "Daoming", ""]]}, {"id": "1905.07098", "submitter": "Wenhan Xiong", "authors": "Wenhan Xiong, Mo Yu, Shiyu Chang, Xiaoxiao Guo, William Yang Wang", "title": "Improving Question Answering over Incomplete KBs with Knowledge-Aware\n  Reader", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new end-to-end question answering model, which learns to\naggregate answer evidence from an incomplete knowledge base (KB) and a set of\nretrieved text snippets. Under the assumptions that the structured KB is easier\nto query and the acquired knowledge can help the understanding of unstructured\ntext, our model first accumulates knowledge of entities from a question-related\nKB subgraph; then reformulates the question in the latent space and reads the\ntexts with the accumulated entity knowledge at hand. The evidence from KB and\ntexts are finally aggregated to predict answers. On the widely-used KBQA\nbenchmark WebQSP, our model achieves consistent improvements across settings\nwith different extents of KB incompleteness.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 03:00:46 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 04:35:36 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Xiong", "Wenhan", ""], ["Yu", "Mo", ""], ["Chang", "Shiyu", ""], ["Guo", "Xiaoxiao", ""], ["Wang", "William Yang", ""]]}, {"id": "1905.07102", "submitter": "Darwin Bautista", "authors": "Darwin Bautista and Raimarc Dionido", "title": "Mastering the Game of Sungka from Random Play", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Recent work in reinforcement learning demonstrated that learning solely\nthrough self-play is not only possible, but could also result in novel\nstrategies that humans never would have thought of. However, optimization\nmethods cast as a game between two players require careful tuning to prevent\nsuboptimal results. Hence, we look at random play as an alternative method. In\nthis paper, we train a DQN agent to play Sungka, a two-player turn-based board\ngame wherein the players compete to obtain more stones than the other. We show\nthat even with purely random play, our training algorithm converges very fast\nand is stable. Moreover, we test our trained agent against several baselines\nand show its ability to consistently win against these.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 03:41:10 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Bautista", "Darwin", ""], ["Dionido", "Raimarc", ""]]}, {"id": "1905.07112", "submitter": "Nicholas Carlini", "authors": "Nicholas Carlini", "title": "A critique of the DeepSec Platform for Security Analysis of Deep\n  Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At IEEE S&P 2019, the paper \"DeepSec: A Uniform Platform for Security\nAnalysis of Deep Learning Model\" aims to to \"systematically evaluate the\nexisting adversarial attack and defense methods.\" While the paper's goals are\nlaudable, it fails to achieve them and presents results that are fundamentally\nflawed and misleading. We explain the flaws in the DeepSec work, along with how\nits analysis fails to meaningfully evaluate the various attacks and defenses.\nSpecifically, DeepSec (1) evaluates each defense obliviously, using attacks\ncrafted against undefended models; (2) evaluates attacks and defenses using\nincorrect implementations that greatly under-estimate their effectiveness; (3)\nevaluates the robustness of each defense as an average, not based on the most\neffective attack against that defense; (4) performs several statistical\nanalyses incorrectly and fails to report variance; and, (5) as a result of\nthese errors draws invalid conclusions and makes sweeping generalizations.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 04:26:52 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Carlini", "Nicholas", ""]]}, {"id": "1905.07185", "submitter": "Mark Keane", "authors": "Kelleher Conor and Mark T. Keane", "title": "Plotting Markson's 'Mistress'", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The post-modern novel 'Wittgenstein's Mistress' by David Markson (1988)\npresents the reader with a very challenging non linear narrative, that itself\nappears to one of the novel's themes. We present a distant reading of this work\ndesigned to complement a close reading of it by David Foster Wallace (1990).\nUsing a combination of text analysis, entity recognition and networks, we plot\nrepetitive structures in the novel's narrative relating them to its critical\nanalysis.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 10:14:21 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Conor", "Kelleher", ""], ["Keane", "Mark T.", ""]]}, {"id": "1905.07186", "submitter": "Mark Keane", "authors": "Mark T Keane and Eoin M Kenny", "title": "How Case Based Reasoning Explained Neural Networks: An XAI Survey of\n  Post-Hoc Explanation-by-Example in ANN-CBR Twins", "comments": "15 pages", "journal-ref": "Proceedings of the 27th International Conference on Case Based\n  Reasoning (ICCBR-19), 2019", "doi": "10.1007/978-3-030-29249-2_11", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper surveys an approach to the XAI problem, using post-hoc explanation\nby example, that hinges on twinning Artificial Neural Networks (ANNs) with\nCase-Based Reasoning (CBR) systems, so-called ANN-CBR twins. A systematic\nsurvey of 1100+ papers was carried out to identify the fragmented literature on\nthis topic and to trace it influence through to more recent work involving Deep\nNeural Networks (DNNs). The paper argues that this twin-system approach,\nespecially using ANN-CBR twins, presents one possible coherent, generic\nsolution to the XAI problem (and, indeed, XCBR problem). The paper concludes by\nroad-mapping some future directions for this XAI solution involving (i) further\ntests of feature-weighting techniques, (iii) explorations of how explanatory\ncases might best be deployed (e.g., in counterfactuals, near-miss cases, a\nfortori cases), and (iii) the raising of the unwelcome and, much ignored, issue\nof human user evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 10:14:29 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Keane", "Mark T", ""], ["Kenny", "Eoin M", ""]]}, {"id": "1905.07189", "submitter": "Phong Le", "authors": "Phong Le and Ivan Titov", "title": "Distant Learning for Entity Linking with Automatic Noise Detection", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate entity linkers have been produced for domains and languages where\nannotated data (i.e., texts linked to a knowledge base) is available. However,\nlittle progress has been made for the settings where no or very limited amounts\nof labeled data are present (e.g., legal or most scientific domains). In this\nwork, we show how we can learn to link mentions without having any labeled\nexamples, only a knowledge base and a collection of unannotated texts from the\ncorresponding domain. In order to achieve this, we frame the task as a\nmulti-instance learning problem and rely on surface matching to create initial\nnoisy labels. As the learning signal is weak and our surrogate labels are\nnoisy, we introduce a noise detection component in our model: it lets the model\ndetect and disregard examples which are likely to be noisy. Our method, jointly\nlearning to detect noise and link entities, greatly outperforms the surface\nmatching baseline. For a subset of entity categories, it even approaches the\nperformance of supervised learning.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 10:49:47 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 07:43:50 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Le", "Phong", ""], ["Titov", "Ivan", ""]]}, {"id": "1905.07193", "submitter": "Manan Tomar Mr.", "authors": "Manan Tomar, Akhil Sathuluri, Balaraman Ravindran", "title": "MaMiC: Macro and Micro Curriculum for Robotic Reinforcement Learning", "comments": "To appear in the Proceedings of the 18th International Conference on\n  Autonomous Agents and Multiagent Systems (AAMAS 2019). (Extended Abstract)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shaping in humans and animals has been shown to be a powerful tool for\nlearning complex tasks as compared to learning in a randomized fashion. This\nmakes the problem less complex and enables one to solve the easier sub task at\nhand first. Generating a curriculum for such guided learning involves\nsubjecting the agent to easier goals first, and then gradually increasing their\ndifficulty. This paper takes a similar direction and proposes a dual curriculum\nscheme for solving robotic manipulation tasks with sparse rewards, called\nMaMiC. It includes a macro curriculum scheme which divides the task into\nmultiple sub-tasks followed by a micro curriculum scheme which enables the\nagent to learn between such discovered sub-tasks. We show how combining macro\nand micro curriculum strategies help in overcoming major exploratory\nconstraints considered in robot manipulation tasks without having to engineer\nany complex rewards. We also illustrate the meaning of the individual curricula\nand how they can be used independently based on the task. The performance of\nsuch a dual curriculum scheme is analyzed on the Fetch environments.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 10:55:58 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Tomar", "Manan", ""], ["Sathuluri", "Akhil", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1905.07237", "submitter": "Longxiang Shi", "authors": "Longxiang Shi, Shijian Li, Longbing Cao, Long Yang, Gang Pan", "title": "TBQ($\\sigma$): Improving Efficiency of Trace Utilization for Off-Policy\n  Reinforcement Learning", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy reinforcement learning with eligibility traces is challenging\nbecause of the discrepancy between target policy and behavior policy. One\ncommon approach is to measure the difference between two policies in a\nprobabilistic way, such as importance sampling and tree-backup. However,\nexisting off-policy learning methods based on probabilistic policy measurement\nare inefficient when utilizing traces under a greedy target policy, which is\nineffective for control problems. The traces are cut immediately when a\nnon-greedy action is taken, which may lose the advantage of eligibility traces\nand slow down the learning process. Alternatively, some non-probabilistic\nmeasurement methods such as General Q($\\lambda$) and Naive Q($\\lambda$) never\ncut traces, but face convergence problems in practice. To address the above\nissues, this paper introduces a new method named TBQ($\\sigma$), which\neffectively unifies the tree-backup algorithm and Naive Q($\\lambda$). By\nintroducing a new parameter $\\sigma$ to illustrate the \\emph{degree} of\nutilizing traces, TBQ($\\sigma$) creates an effective integration of\nTB($\\lambda$) and Naive Q($\\lambda$) and continuous role shift between them.\nThe contraction property of TB($\\sigma$) is theoretically analyzed for both\npolicy evaluation and control settings. We also derive the online version of\nTBQ($\\sigma$) and give the convergence proof. We empirically show that, for\n$\\epsilon\\in(0,1]$ in $\\epsilon$-greedy policies, there exists some degree of\nutilizing traces for $\\lambda\\in[0,1]$, which can improve the efficiency in\ntrace utilization for off-policy reinforcement learning, to both accelerate the\nlearning process and improve the performance.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 14:36:48 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Shi", "Longxiang", ""], ["Li", "Shijian", ""], ["Cao", "Longbing", ""], ["Yang", "Long", ""], ["Pan", "Gang", ""]]}, {"id": "1905.07245", "submitter": "Zhewei Wei", "authors": "Yuan Yin and Zhewei Wei", "title": "Scalable Graph Embeddings via Sparse Transpose Proximities", "comments": "ACM SIGKDD2019", "journal-ref": null, "doi": "10.1145/3292500.333086", "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embedding learns low-dimensional representations for nodes in a graph\nand effectively preserves the graph structure. Recently, a significant amount\nof progress has been made toward this emerging research area. However, there\nare several fundamental problems that remain open. First, existing methods fail\nto preserve the out-degree distributions on directed graphs. Second, many\nexisting methods employ random walk based proximities and thus suffer from\nconflicting optimization goals on undirected graphs. Finally, existing\nfactorization methods are unable to achieve scalability and non-linearity\nsimultaneously.\n  This paper presents an in-depth study on graph embedding techniques on both\ndirected and undirected graphs. We analyze the fundamental reasons that lead to\nthe distortion of out-degree distributions and to the conflicting optimization\ngoals. We propose {\\em transpose proximity}, a unified approach that solves\nboth problems. Based on the concept of transpose proximity, we design \\strap, a\nfactorization based graph embedding algorithm that achieves scalability and\nnon-linearity simultaneously. \\strap makes use of the {\\em backward push}\nalgorithm to efficiently compute the sparse {\\em Personalized PageRank (PPR)}\nas its transpose proximities. By imposing the sparsity constraint, we are able\nto apply non-linear operations to the proximity matrix and perform efficient\nmatrix factorization to derive the embedding vectors. Finally, we present an\nextensive experimental study that evaluates the effectiveness of various graph\nembedding algorithms, and we show that \\strap outperforms the state-of-the-art\nmethods in terms of effectiveness and scalability.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 05:20:09 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Yin", "Yuan", ""], ["Wei", "Zhewei", ""]]}, {"id": "1905.07261", "submitter": "Donghyeon Park", "authors": "Donghyeon Park, Keonwoo Kim, Yonggyu Park, Jungwoon Shin and Jaewoo\n  Kang", "title": "KitcheNette: Predicting and Recommending Food Ingredient Pairings using\n  Siamese Neural Networks", "comments": "Accepted and to be appeared in IJCAI-2019", "journal-ref": null, "doi": "10.24963/ijcai.2019/822", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a vast number of ingredients exist in the culinary world, there are\ncountless food ingredient pairings, but only a small number of pairings have\nbeen adopted by chefs and studied by food researchers. In this work, we propose\nKitcheNette which is a model that predicts food ingredient pairing scores and\nrecommends optimal ingredient pairings. KitcheNette employs Siamese neural\nnetworks and is trained on our annotated dataset containing 300K scores of\npairings generated from numerous ingredients in food recipes. As the results\ndemonstrate, our model not only outperforms other baseline models but also can\nrecommend complementary food pairings and discover novel ingredient pairings.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 07:02:20 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Park", "Donghyeon", ""], ["Kim", "Keonwoo", ""], ["Park", "Yonggyu", ""], ["Shin", "Jungwoon", ""], ["Kang", "Jaewoo", ""]]}, {"id": "1905.07264", "submitter": "Marek Herde", "authors": "Tom Hanika, Marek Herde, Jochen Kuhn, Jan Marco Leimeister, Paul\n  Lukowicz, Sarah Oeste-Rei{\\ss}, Albrecht Schmidt, Bernhard Sick, Gerd Stumme,\n  Sven Tomforde and Katharina Anna Zweig", "title": "Collaborative Interactive Learning -- A clarification of terms and a\n  differentiation from other research fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of collaborative interactive learning (CIL) aims at developing and\ninvestigating the technological foundations for a new generation of smart\nsystems that support humans in their everyday life. While the concept of CIL\nhas already been carved out in detail (including the fields of dedicated CIL\nand opportunistic CIL) and many research objectives have been stated, there is\nstill the need to clarify some terms such as information, knowledge, and\nexperience in the context of CIL and to differentiate CIL from recent and\nongoing research in related fields such as active learning, collaborative\nlearning, and others. Both aspects are addressed in this paper.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 14:59:53 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Hanika", "Tom", ""], ["Herde", "Marek", ""], ["Kuhn", "Jochen", ""], ["Leimeister", "Jan Marco", ""], ["Lukowicz", "Paul", ""], ["Oeste-Rei\u00df", "Sarah", ""], ["Schmidt", "Albrecht", ""], ["Sick", "Bernhard", ""], ["Stumme", "Gerd", ""], ["Tomforde", "Sven", ""], ["Zweig", "Katharina Anna", ""]]}, {"id": "1905.07273", "submitter": "Aditya Kuppa", "authors": "Aditya Kuppa, Slawomir Grzonkowski, Muhammad Rizwan Asghar and\n  Nhien-An Le-Khac", "title": "Finding Rats in Cats: Detecting Stealthy Attacks using Group Anomaly\n  Detection", "comments": "Preprint: Modified, Extended Version will be presented at TrustCom\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced attack campaigns span across multiple stages and stay stealthy for\nlong time periods. There is a growing trend of attackers using off-the-shelf\ntools and pre-installed system applications (such as \\emph{powershell} and\n\\emph{wmic}) to evade the detection because the same tools are also used by\nsystem administrators and security analysts for legitimate purposes for their\nroutine tasks. To start investigations, event logs can be collected from\noperational systems; however, these logs are generic enough and it often\nbecomes impossible to attribute a potential attack to a specific attack group.\nRecent approaches in the literature have used anomaly detection techniques,\nwhich aim at distinguishing between malicious and normal behavior of computers\nor network systems. Unfortunately, anomaly detection systems based on point\nanomalies are too rigid in a sense that they could miss the malicious activity\nand classify the attack, not an outlier. Therefore, there is a research\nchallenge to make better detection of malicious activities. To address this\nchallenge, in this paper, we leverage Group Anomaly Detection (GAD), which\ndetects anomalous collections of individual data points.\n  Our approach is to build a neural network model utilizing Adversarial\nAutoencoder (AAE-$\\alpha$) in order to detect the activity of an attacker who\nleverages off-the-shelf tools and system applications. In addition, we also\nbuild \\textit{Behavior2Vec} and \\textit{Command2Vec} sentence embedding deep\nlearning models specific for feature extraction tasks. We conduct extensive\nexperiments to evaluate our models on real-world datasets collected for a\nperiod of two months. The empirical results demonstrate that our approach is\neffective and robust in discovering targeted attacks, pen-tests, and attack\ncampaigns leveraging custom tools.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 17:16:52 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 13:22:04 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Kuppa", "Aditya", ""], ["Grzonkowski", "Slawomir", ""], ["Asghar", "Muhammad Rizwan", ""], ["Le-Khac", "Nhien-An", ""]]}, {"id": "1905.07288", "submitter": "Jakub Sawicki", "authors": "Jakub Sawicki, Maciej Smo{\\l}ka, Marcin {\\L}o\\'s, and Robert Schaefer", "title": "Approximation of the objective insensitivity regions using Hierarchic\n  Memetic Strategy coupled with Covariance Matrix Adaptation Evolutionary\n  Strategy", "comments": "presented at OLA2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most challenging types of ill-posedness in global optimization is\nthe presence of insensitivity regions in design parameter space, so the\nidentification of their shape will be crucial, if ill-posedness is\nirrecoverable. Such problems may be solved using global stochastic search\nfollowed by post-processing of a local sample and a local objective\napproximation. We propose a new approach of this type composed of Hierarchic\nMemetic Strategy (HMS) powered by the Covariance Matrix Adaptation Evolutionary\nStrategy (CMA-ES) well-known as an effective, self-adaptable stochastic\noptimization algorithm and we leverage the distribution density knowledge it\naccumulates to better identify and separate insensitivity regions. The results\nof benchmarks prove that the improved HMS-CMA-ES strategy is effective in both\nthe total computational cost and the accuracy of insensitivity region\napproximation. The reference data for the tests was obtained by means of a\nwell-known effective strategy of multimodal stochastic optimization called the\nNiching Evolutionary Algorithm 2 (NEA2), that also uses CMA-ES as a component.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 14:25:27 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Sawicki", "Jakub", ""], ["Smo\u0142ka", "Maciej", ""], ["\u0141o\u015b", "Marcin", ""], ["Schaefer", "Robert", ""]]}, {"id": "1905.07356", "submitter": "Matthijs Westera", "authors": "Matthijs Westera and Gemma Boleda", "title": "Don't Blame Distributional Semantics if it can't do Entailment", "comments": "To appear in Proceedings of the 13th International Conference on\n  Computational Semantics (IWCS 2019), Gothenburg, Sweden", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributional semantics has had enormous empirical success in Computational\nLinguistics and Cognitive Science in modeling various semantic phenomena, such\nas semantic similarity, and distributional models are widely used in\nstate-of-the-art Natural Language Processing systems. However, the theoretical\nstatus of distributional semantics within a broader theory of language and\ncognition is still unclear: What does distributional semantics model? Can it\nbe, on its own, a fully adequate model of the meanings of linguistic\nexpressions? The standard answer is that distributional semantics is not fully\nadequate in this regard, because it falls short on some of the central aspects\nof formal semantic approaches: truth conditions, entailment, reference, and\ncertain aspects of compositionality. We argue that this standard answer rests\non a misconception: These aspects do not belong in a theory of expression\nmeaning, they are instead aspects of speaker meaning, i.e., communicative\nintentions in a particular context. In a slogan: words do not refer, speakers\ndo. Clearing this up enables us to argue that distributional semantics on its\nown is an adequate model of expression meaning. Our proposal sheds light on the\nrole of distributional semantics in a broader theory of language and cognition,\nits relationship to formal semantics, and its place in computational models.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 16:26:05 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Westera", "Matthijs", ""], ["Boleda", "Gemma", ""]]}, {"id": "1905.07435", "submitter": "Harkirat Behl", "authors": "Harkirat Singh Behl, At{\\i}l{\\i}m G\\\"une\\c{s} Baydin, Philip H.S. Torr", "title": "Alpha MAML: Adaptive Model-Agnostic Meta-Learning", "comments": "6th ICML Workshop on Automated Machine Learning (2019)", "journal-ref": "ICML Workshop on Automated Machine Learning (2019)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-agnostic meta-learning (MAML) is a meta-learning technique to train a\nmodel on a multitude of learning tasks in a way that primes the model for\nfew-shot learning of new tasks. The MAML algorithm performs well on few-shot\nlearning problems in classification, regression, and fine-tuning of policy\ngradients in reinforcement learning, but comes with the need for costly\nhyperparameter tuning for training stability. We address this shortcoming by\nintroducing an extension to MAML, called Alpha MAML, to incorporate an online\nhyperparameter adaptation scheme that eliminates the need to tune meta-learning\nand learning rates. Our results with the Omniglot database demonstrate a\nsubstantial reduction in the need to tune MAML training hyperparameters and\nimprovement to training stability with less sensitivity to hyperparameter\nchoice.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 18:45:25 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Behl", "Harkirat Singh", ""], ["Baydin", "At\u0131l\u0131m G\u00fcne\u015f", ""], ["Torr", "Philip H. S.", ""]]}, {"id": "1905.07443", "submitter": "Tonmoy Saikia", "authors": "Tonmoy Saikia, Yassine Marrakchi, Arber Zela, Frank Hutter, Thomas\n  Brox", "title": "AutoDispNet: Improving Disparity Estimation With AutoML", "comments": "In Proceedings of the 2019 IEEE International Conference on Computer\n  Vision (ICCV)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much research work in computer vision is being spent on optimizing existing\nnetwork architectures to obtain a few more percentage points on benchmarks.\nRecent AutoML approaches promise to relieve us from this effort. However, they\nare mainly designed for comparatively small-scale classification tasks. In this\nwork, we show how to use and extend existing AutoML techniques to efficiently\noptimize large-scale U-Net-like encoder-decoder architectures. In particular,\nwe leverage gradient-based neural architecture search and Bayesian optimization\nfor hyperparameter search. The resulting optimization does not require a\nlarge-scale compute cluster. We show results on disparity estimation that\nclearly outperform the manually optimized baseline and reach state-of-the-art\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 19:05:25 GMT"}, {"version": "v2", "created": "Sun, 6 Oct 2019 20:19:32 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Saikia", "Tonmoy", ""], ["Marrakchi", "Yassine", ""], ["Zela", "Arber", ""], ["Hutter", "Frank", ""], ["Brox", "Thomas", ""]]}, {"id": "1905.07446", "submitter": "Azin Asgarian", "authors": "Azin Asgarian, Shun Zhao, Ahmed B. Ashraf, M. Erin Browne, Kenneth M.\n  Prkachin, Alex Mihailidis, Thomas Hadjistavropoulos, and Babak Taati", "title": "Limitations and Biases in Facial Landmark Detection -- An Empirical\n  Study on Older Adults with Dementia", "comments": "Face and Gesture Analysis for Health Informatics (FGAHI) Workshop at\n  CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate facial expression analysis is an essential step in various clinical\napplications that involve physical and mental health assessments of older\nadults (e.g. diagnosis of pain or depression). Although remarkable progress has\nbeen achieved toward developing robust facial landmark detection methods,\nstate-of-the-art methods still face many challenges when encountering\nuncontrolled environments, different ranges of facial expressions, and\ndifferent demographics of the population. A recent study has revealed that the\nhealth status of individuals can also affect the performance of facial landmark\ndetection methods on front views of faces. In this work, we investigate this\nmatter in a much greater context using seven facial landmark detection methods.\nWe perform our evaluation not only on frontal faces but also on profile faces\nand in various regions of the face. Our results shed light on limitations of\nthe existing methods and challenges of applying these methods in clinical\nsettings by indicating: 1) a significant difference between the performance of\nstate-of-the-art when tested on the profile or frontal faces of individuals\nwith vs. without dementia; 2) insights on the existing bias for all regions of\nthe face; and 3) the presence of this bias despite re-training/fine-tuning with\nvarious configurations of six datasets.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 19:15:15 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Asgarian", "Azin", ""], ["Zhao", "Shun", ""], ["Ashraf", "Ahmed B.", ""], ["Browne", "M. Erin", ""], ["Prkachin", "Kenneth M.", ""], ["Mihailidis", "Alex", ""], ["Hadjistavropoulos", "Thomas", ""], ["Taati", "Babak", ""]]}, {"id": "1905.07465", "submitter": "Luchen Li", "authors": "Luchen Li, Matthieu Komorowski, Aldo A. Faisal", "title": "Optimizing Sequential Medical Treatments with Auto-Encoding Heuristic\n  Search in POMDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Health-related data is noisy and stochastic in implying the true\nphysiological states of patients, limiting information contained in\nsingle-moment observations for sequential clinical decision making. We model\npatient-clinician interactions as partially observable Markov decision\nprocesses (POMDPs) and optimize sequential treatment based on belief states\ninferred from history sequence. To facilitate inference, we build a variational\ngenerative model and boost state representation with a recurrent neural network\n(RNN), incorporating an auxiliary loss from sequence auto-encoding. Meanwhile,\nwe optimize a continuous policy of drug levels with an actor-critic method\nwhere policy gradients are obtained from a stablized off-policy estimate of\nadvantage function, with the value of belief state backed up by parallel\nbest-first suffix trees. We exploit our methodology in optimizing dosages of\nvasopressor and intravenous fluid for sepsis patients using a retrospective\nintensive care dataset and evaluate the learned policy with off-policy policy\nevaluation (OPPE). The results demonstrate that modelling as POMDPs yields\nbetter performance than MDPs, and that incorporating heuristic search improves\nsample efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 20:33:21 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Li", "Luchen", ""], ["Komorowski", "Matthieu", ""], ["Faisal", "Aldo A.", ""]]}, {"id": "1905.07470", "submitter": "Francesco Maurelli", "authors": "Francesco Maurelli, Szymon Krupinski", "title": "A semantic-aided particle filter approach for AUV localization", "comments": "IEEE Oceans'18, Kobe, Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach to AUV localization, based on a\nsemantic-aided particle filter. Particle filters have been used successfully\nfor robotics localization since many years. Most of the approaches are however\nbased on geometric measurements and geometric information and simulations. In\nthe past years more and more efforts from research goes towards cognitive\nrobotics and the marine domain is not exception. Moving from signal to symbol\nbecomes therefore paramount for more complex applications. This paper presents\na contribution in the well-known area of underwater localization, incorporating\nsemantic information. An extension to the standard particle filter approach is\npresented, based on semantic information of the environment. A comparison with\nthe geometric approach shows the advantages of a semantic layer to successfully\nperform self-localization.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 20:45:49 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Maurelli", "Francesco", ""], ["Krupinski", "Szymon", ""]]}, {"id": "1905.07542", "submitter": "Ali Jahani Amiri", "authors": "Ali Jahani Amiri, Shing Yan Loo, Hong Zhang", "title": "Semi-Supervised Monocular Depth Estimation with Left-Right Consistency\n  Using Deep Neural Network", "comments": "Submitted to IROS2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been tremendous research progress in estimating the depth of a\nscene from a monocular camera image. Existing methods for single-image depth\nprediction are exclusively based on deep neural networks, and their training\ncan be unsupervised using stereo image pairs, supervised using LiDAR point\nclouds, or semi-supervised using both stereo and LiDAR. In general,\nsemi-supervised training is preferred as it does not suffer from the weaknesses\nof either supervised training, resulting from the difference in the cameras and\nthe LiDARs field of view, or unsupervised training, resulting from the poor\ndepth accuracy that can be recovered from a stereo pair. In this paper, we\npresent our research in single image depth prediction using semi-supervised\ntraining that outperforms the state-of-the-art. We achieve this through a loss\nfunction that explicitly exploits left-right consistency in a stereo\nreconstruction, which has not been adopted in previous semi-supervised\ntraining. In addition, we describe the correct use of ground truth depth\nderived from LiDAR that can significantly reduce prediction error. The\nperformance of our depth prediction model is evaluated on popular datasets, and\nthe importance of each aspect of our semi-supervised training approach is\ndemonstrated through experimental results. Our deep neural network model has\nbeen made publicly available.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 06:07:56 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Amiri", "Ali Jahani", ""], ["Loo", "Shing Yan", ""], ["Zhang", "Hong", ""]]}, {"id": "1905.07562", "submitter": "Feng Qi", "authors": "Feng Qi and Wenchuan Wu", "title": "Human-like machine thinking: Language guided imagination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human thinking requires the brain to understand the meaning of language\nexpression and to properly organize the thoughts flow using the language.\nHowever, current natural language processing models are primarily limited in\nthe word probability estimation. Here, we proposed a Language guided\nimagination (LGI) network to incrementally learn the meaning and usage of\nnumerous words and syntaxes, aiming to form a human-like machine thinking\nprocess. LGI contains three subsystems: (1) vision system that contains an\nencoder to disentangle the input or imagined scenarios into abstract population\nrepresentations, and an imagination decoder to reconstruct imagined scenario\nfrom higher level representations; (2) Language system, that contains a\nbinarizer to transfer symbol texts into binary vectors, an IPS (mimicking the\nhuman IntraParietal Sulcus, implemented by an LSTM) to extract the quantity\ninformation from the input texts, and a textizer to convert binary vectors into\ntext symbols; (3) a PFC (mimicking the human PreFrontal Cortex, implemented by\nan LSTM) to combine inputs of both language and vision representations, and\npredict text symbols and manipulated images accordingly. LGI has incrementally\nlearned eight different syntaxes (or tasks), with which a machine thinking loop\nhas been formed and validated by the proper interaction between language and\nvision system. The paper provides a new architecture to let the machine learn,\nunderstand and use language in a human-like way that could ultimately enable a\nmachine to construct fictitious 'mental' scenario and possess intelligence.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 09:23:00 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 07:46:23 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Qi", "Feng", ""], ["Wu", "Wenchuan", ""]]}, {"id": "1905.07579", "submitter": "Francesco Sovrano", "authors": "Francesco Sovrano", "title": "Combining Experience Replay with Exploration by Random Network\n  Distillation", "comments": "8 pages, 6 figures, accepted as full-paper at IEEE Conference on\n  Games (CoG) 2019", "journal-ref": null, "doi": "10.1109/CIG.2019.8848046", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our work is a simple extension of the paper \"Exploration by Random Network\nDistillation\". More in detail, we show how to efficiently combine Intrinsic\nRewards with Experience Replay in order to achieve more efficient and robust\nexploration (with respect to PPO/RND) and consequently better results in terms\nof agent performances and sample efficiency. We are able to do it by using a\nnew technique named Prioritized Oversampled Experience Replay (POER), that has\nbeen built upon the definition of what is the important experience useful to\nreplay. Finally, we evaluate our technique on the famous Atari game Montezuma's\nRevenge and some other hard exploration Atari games.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 12:32:03 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Sovrano", "Francesco", ""]]}, {"id": "1905.07628", "submitter": "Aleksandra Faust", "authors": "Aleksandra Faust and Anthony Francis and Dar Mehta", "title": "Evolving Rewards to Automate Reinforcement Learning", "comments": "Accepted to 6th AutoML@ICML", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many continuous control tasks have easily formulated objectives, yet using\nthem directly as a reward in reinforcement learning (RL) leads to suboptimal\npolicies. Therefore, many classical control tasks guide RL training using\ncomplex rewards, which require tedious hand-tuning. We automate the reward\nsearch with AutoRL, an evolutionary layer over standard RL that treats reward\ntuning as hyperparameter optimization and trains a population of RL agents to\nfind a reward that maximizes the task objective. AutoRL, evaluated on four\nMujoco continuous control tasks over two RL algorithms, shows improvements over\nbaselines, with the the biggest uplift for more complex tasks. The video can be\nfound at: \\url{https://youtu.be/svdaOFfQyC8}.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 19:20:04 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Faust", "Aleksandra", ""], ["Francis", "Anthony", ""], ["Mehta", "Dar", ""]]}, {"id": "1905.07687", "submitter": "Chien-Sheng Wu", "authors": "Chien-Sheng Wu", "title": "Learning to Memorize in Neural Task-Oriented Dialogue Systems", "comments": "HKUST MPhil Thesis. 93 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis, we leverage the neural copy mechanism and memory-augmented\nneural networks (MANNs) to address existing challenge of neural task-oriented\ndialogue learning. We show the effectiveness of our strategy by achieving good\nperformance in multi-domain dialogue state tracking, retrieval-based dialogue\nsystems, and generation-based dialogue systems. We first propose a transferable\ndialogue state generator (TRADE) that leverages its copy mechanism to get rid\nof dialogue ontology and share knowledge between domains. We also evaluate\nunseen domain dialogue state tracking and show that TRADE enables zero-shot\ndialogue state tracking and can adapt to new few-shot domains without\nforgetting the previous domains. Second, we utilize MANNs to improve\nretrieval-based dialogue learning. They are able to capture dialogue sequential\ndependencies and memorize long-term information. We also propose a recorded\ndelexicalization copy strategy to replace real entity values with ordered\nentity types. Our models are shown to surpass other retrieval baselines,\nespecially when the conversation has a large number of turns. Lastly, we tackle\ngeneration-based dialogue learning with two proposed models, the\nmemory-to-sequence (Mem2Seq) and global-to-local memory pointer network (GLMP).\nMem2Seq is the first model to combine multi-hop memory attention with the idea\nof the copy mechanism. GLMP further introduces the concept of response\nsketching and double pointers copying. We show that GLMP achieves the\nstate-of-the-art performance on human evaluation.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 04:00:08 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Wu", "Chien-Sheng", ""]]}, {"id": "1905.07696", "submitter": "Guido Governatori", "authors": "Guido Governatori and Antonino Rotolo", "title": "Is Free Choice Permission Admissible in Classical Deontic Logic?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore how, and if, free choice permission (FCP) can be\naccepted when we consider deontic conflicts between certain types of\npermissions and obligations. As is well known, FCP can license, under some\nminimal conditions, the derivation of an indefinite number of permissions. We\ndiscuss this and other drawbacks and present six Hilbert-style classical\ndeontic systems admitting a guarded version of FCP. The systems that we present\nare not too weak from the inferential viewpoint, as far as permission is\nconcerned, and do not commit to weakening any specific logic for obligations.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 07:15:10 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 14:46:08 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Governatori", "Guido", ""], ["Rotolo", "Antonino", ""]]}, {"id": "1905.07727", "submitter": "Mehran Attar", "authors": "Mehran Attar, and Mohammadreza Dabirian", "title": "Reinforcement Learning for Learning of Dynamical Systems in Uncertain\n  Environment: a Tutorial", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a review of model-free reinforcement learning for learning of\ndynamical systems in uncertain environments has discussed. For this purpose,\nthe Markov Decision Process (MDP) will be reviewed. Furthermore, some learning\nalgorithms such as Temporal Difference (TD) learning, Q-Learning, and\nApproximate Q-learning as model-free algorithms which constitute the main part\nof this article have been investigated, and benefits and drawbacks of each\nalgorithm will be discussed. The discussed concepts in each section are\nexplaining with details and examples.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 11:29:01 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Attar", "Mehran", ""], ["Dabirian", "Mohammadreza", ""]]}, {"id": "1905.07773", "submitter": "Aviv Rosenberg", "authors": "Aviv Rosenberg and Yishay Mansour", "title": "Online Convex Optimization in Adversarial Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider online learning in episodic loop-free Markov decision processes\n(MDPs), where the loss function can change arbitrarily between episodes, and\nthe transition function is not known to the learner. We show\n$\\tilde{O}(L|X|\\sqrt{|A|T})$ regret bound, where $T$ is the number of episodes,\n$X$ is the state space, $A$ is the action space, and $L$ is the length of each\nepisode. Our online algorithm is implemented using entropic regularization\nmethodology, which allows to extend the original adversarial MDP model to\nhandle convex performance criteria (different ways to aggregate the losses of a\nsingle episode) , as well as improve previous regret bounds.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 16:56:22 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Rosenberg", "Aviv", ""], ["Mansour", "Yishay", ""]]}, {"id": "1905.07777", "submitter": "Zhiqin Xu", "authors": "Yaoyu Zhang, Zhi-Qin John Xu, Tao Luo, Zheng Ma", "title": "A type of generalization error induced by initialization in deep neural\n  networks", "comments": "Accepted by MSML Revised the proof of Lemma 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How initialization and loss function affect the learning of a deep neural\nnetwork (DNN), specifically its generalization error, is an important problem\nin practice. In this work, by exploiting the linearity of DNN training dynamics\nin the NTK regime \\citep{jacot2018neural,lee2019wide}, we provide an explicit\nand quantitative answer to this problem. Focusing on regression problem, we\nprove that, in the NTK regime, for any loss in a general class of functions,\nthe DNN finds the same \\emph{global} minima---the one that is nearest to the\ninitial value in the parameter space, or equivalently, the one that is closest\nto the initial DNN output in the corresponding reproducing kernel Hilbert\nspace. Using these optimization problems, we quantify the impact of initial\noutput and prove that a random non-zero one increases the generalization error.\nWe further propose an antisymmetrical initialization (ASI) trick that\neliminates this type of error and accelerates the training. To understand\nwhether the above results hold in general, we also perform experiments for DNNs\nin the non-NTK regime, which demonstrate the effectiveness of our theoretical\nresults and the ASI trick in a qualitative sense. Overall, our work serves as a\nbaseline for the further investigation of the impact of initialization and loss\nfunction on the generalization of DNNs, which can potentially guide and improve\nthe training of DNNs in practice.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 17:11:42 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 13:52:46 GMT"}, {"version": "v3", "created": "Mon, 1 Jun 2020 09:54:18 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Zhang", "Yaoyu", ""], ["Xu", "Zhi-Qin John", ""], ["Luo", "Tao", ""], ["Ma", "Zheng", ""]]}, {"id": "1905.07861", "submitter": "Ashley Edwards", "authors": "Ashley D. Edwards, Charles L. Isbell", "title": "Perceptual Values from Observation", "comments": "Accepted into the Workshop on Self-Supervised Learning at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation by observation is an approach for learning from expert\ndemonstrations that lack action information, such as videos. Recent approaches\nto this problem can be placed into two broad categories: training dynamics\nmodels that aim to predict the actions taken between states, and learning\nrewards or features for computing them for Reinforcement Learning (RL). In this\npaper, we introduce a novel approach that learns values, rather than rewards,\ndirectly from observations. We show that by using values, we can significantly\nspeed up RL by removing the need to bootstrap action-values, as compared to\nsparse-reward specifications.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 03:59:44 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Edwards", "Ashley D.", ""], ["Isbell", "Charles L.", ""]]}, {"id": "1905.07870", "submitter": "Qingyun Wang", "authors": "Qingyun Wang, Lifu Huang, Zhiying Jiang, Kevin Knight, Heng Ji, Mohit\n  Bansal and Yi Luan", "title": "PaperRobot: Incremental Draft Generation of Scientific Ideas", "comments": "12 pages. Accepted by ACL 2019 Code and resource is available at\n  https://github.com/EagleW/PaperRobot", "journal-ref": null, "doi": "10.18653/v1/P19-1191", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a PaperRobot who performs as an automatic research assistant by\n(1) conducting deep understanding of a large collection of human-written papers\nin a target domain and constructing comprehensive background knowledge graphs\n(KGs); (2) creating new ideas by predicting links from the background KGs, by\ncombining graph attention and contextual text attention; (3) incrementally\nwriting some key elements of a new paper based on memory-attention networks:\nfrom the input title along with predicted related entities to generate a paper\nabstract, from the abstract to generate conclusion and future work, and finally\nfrom future work to generate a title for a follow-on paper. Turing Tests, where\na biomedical domain expert is asked to compare a system output and a\nhuman-authored string, show PaperRobot generated abstracts, conclusion and\nfuture work sections, and new titles are chosen over human-written ones up to\n30%, 24% and 12% of the time, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 04:41:10 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 15:47:13 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 13:03:52 GMT"}, {"version": "v4", "created": "Fri, 31 May 2019 06:51:13 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Wang", "Qingyun", ""], ["Huang", "Lifu", ""], ["Jiang", "Zhiying", ""], ["Knight", "Kevin", ""], ["Ji", "Heng", ""], ["Bansal", "Mohit", ""], ["Luan", "Yi", ""]]}, {"id": "1905.07953", "submitter": "Wei-Lin Chiang", "authors": "Wei-Lin Chiang, Xuanqing Liu, Si Si, Yang Li, Samy Bengio, Cho-Jui\n  Hsieh", "title": "Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph\n  Convolutional Networks", "comments": "In Proceedings of the 25th ACM SIGKDD International Conference on\n  Knowledge Discovery & Data Mining (KDD'19)", "journal-ref": null, "doi": "10.1145/3292500.3330925", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional network (GCN) has been successfully applied to many\ngraph-based applications; however, training a large-scale GCN remains\nchallenging. Current SGD-based algorithms suffer from either a high\ncomputational cost that exponentially grows with number of GCN layers, or a\nlarge space requirement for keeping the entire graph and the embedding of each\nnode in memory. In this paper, we propose Cluster-GCN, a novel GCN algorithm\nthat is suitable for SGD-based training by exploiting the graph clustering\nstructure. Cluster-GCN works as the following: at each step, it samples a block\nof nodes that associate with a dense subgraph identified by a graph clustering\nalgorithm, and restricts the neighborhood search within this subgraph. This\nsimple but effective strategy leads to significantly improved memory and\ncomputational efficiency while being able to achieve comparable test accuracy\nwith previous algorithms. To test the scalability of our algorithm, we create a\nnew Amazon2M data with 2 million nodes and 61 million edges which is more than\n5 times larger than the previous largest publicly available dataset (Reddit).\nFor training a 3-layer GCN on this data, Cluster-GCN is faster than the\nprevious state-of-the-art VR-GCN (1523 seconds vs 1961 seconds) and using much\nless memory (2.2GB vs 11.2GB). Furthermore, for training 4 layer GCN on this\ndata, our algorithm can finish in around 36 minutes while all the existing GCN\ntraining algorithms fail to train due to the out-of-memory issue. Furthermore,\nCluster-GCN allows us to train much deeper GCN without much time and memory\noverhead, which leads to improved prediction accuracy---using a 5-layer\nCluster-GCN, we achieve state-of-the-art test F1 score 99.36 on the PPI\ndataset, while the previous best result was 98.71 by [16]. Our codes are\npublicly available at\nhttps://github.com/google-research/google-research/tree/master/cluster_gcn.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 09:16:44 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2019 16:42:22 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Chiang", "Wei-Lin", ""], ["Liu", "Xuanqing", ""], ["Si", "Si", ""], ["Li", "Yang", ""], ["Bengio", "Samy", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1905.07961", "submitter": "Bartosz Piotrowski", "authors": "Bartosz Piotrowski, Josef Urban", "title": "Guiding Inferences in Connection Tableau by Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a dataset and experiments on applying recurrent neural networks\n(RNNs) for guiding clause selection in the connection tableau proof calculus.\nThe RNN encodes a sequence of literals from the current branch of the partial\nproof tree to a hidden vector state; using it, the system selects a clause for\nextending the proof tree. The training data and learning setup are described,\nand the results are discussed and compared with state of the art using gradient\nboosted trees. Additionally, we perform a conjecturing experiment in which the\nRNN does not just select an existing clause, but completely constructs the next\ntableau goal.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 09:47:41 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 11:56:26 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Piotrowski", "Bartosz", ""], ["Urban", "Josef", ""]]}, {"id": "1905.08063", "submitter": "Mark Keane", "authors": "Molly S Quinn, Kathleen Campbell, Mark T Keane", "title": "The Unexpected Unexpected and the Expected Unexpected: How People's\n  Conception of the Unexpected is Not That Unexpected", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The answers people give when asked to 'think of the unexpected' for everyday\nevent scenarios appear to be more expected than unexpected. There are expected\nunexpected outcomes that closely adhere to the given information in a scenario,\nbased on familiar disruptions and common plan-failures. There are also\nunexpected unexpected outcomes that are more inventive, that depart from given\ninformation, adding new concepts/actions. However, people seem to tend to\nconceive of the unexpected as the former more than the latter. Study 1 tests\nthese proposals by analysing the object-concepts people mention in their\nreports of the unexpected and the agreement between their answers. Study 2\nshows that object-choices are weakly influenced by recency, the order of\nsentences in the scenario. The implications of these results for ideas in\nphilosophy, psychology and computing is discussed\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 10:14:07 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Quinn", "Molly S", ""], ["Campbell", "Kathleen", ""], ["Keane", "Mark T", ""]]}, {"id": "1905.08069", "submitter": "Mark Keane", "authors": "Mark T. Keane and Eoin M. Kenny", "title": "The Twin-System Approach as One Generic Solution for XAI: An Overview of\n  ANN-CBR Twins for Explaining Deep Learning", "comments": "5 pages", "journal-ref": "IJCAI 2019 Workshop on Explainable Artificial Intelligence (XAI)", "doi": null, "report-no": "http://hdl.handle.net/10197/11071", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of twin systems is proposed to address the eXplainable AI (XAI)\nproblem, where an uninterpretable black-box system is mapped to a white-box\n'twin' that is more interpretable. In this short paper, we overview very recent\nwork that advances a generic solution to the XAI problem, the so called twin\nsystem approach. The most popular twinning in the literature is that between an\nArtificial Neural Networks (ANN ) as a black box and Case Based Reasoning (CBR)\nsystem as a white-box, where the latter acts as an interpretable proxy for the\nformer. We outline how recent work reviving this idea has applied it to deep\nlearning methods. Furthermore, we detail the many fruitful directions in which\nthis work may be taken; such as, determining the most (i) accurate\nfeature-weighting methods to be used, (ii) appropriate deployments for\nexplanatory cases, (iii) useful cases of explanatory value to users.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 12:57:34 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Keane", "Mark T.", ""], ["Kenny", "Eoin M.", ""]]}, {"id": "1905.08085", "submitter": "Jianyi Wang", "authors": "Yuhang Song, Andrzej Wojcicki, Thomas Lukasiewicz, Jianyi Wang, Abi\n  Aryan, Zhenghua Xu, Mai Xu, Zihan Ding, Lianlong Wu", "title": "Arena: A General Evaluation Platform and Building Toolkit for\n  Multi-Agent Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning agents that are not only capable of taking tests, but also\ninnovating is becoming a hot topic in AI. One of the most promising paths\ntowards this vision is multi-agent learning, where agents act as the\nenvironment for each other, and improving each agent means proposing new\nproblems for others. However, existing evaluation platforms are either not\ncompatible with multi-agent settings, or limited to a specific game. That is,\nthere is not yet a general evaluation platform for research on multi-agent\nintelligence. To this end, we introduce Arena, a general evaluation platform\nfor multi-agent intelligence with 35 games of diverse logics and\nrepresentations. Furthermore, multi-agent intelligence is still at the stage\nwhere many problems remain unexplored. Therefore, we provide a building toolkit\nfor researchers to easily invent and build novel multi-agent problems from the\nprovided game set based on a GUI-configurable social tree and five basic\nmulti-agent reward schemes. Finally, we provide Python implementations of five\nstate-of-the-art deep multi-agent reinforcement learning baselines. Along with\nthe baseline implementations, we release a set of 100 best agents/teams that we\ncan train with different training schemes for each game, as the base for\nevaluating agents with population performance. As such, the research community\ncan perform comparisons under a stable and uniform standard. All the\nimplementations and accompanied tutorials have been open-sourced for the\ncommunity at https://sites.google.com/view/arena-unity/.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 14:27:25 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 01:46:20 GMT"}, {"version": "v3", "created": "Thu, 30 May 2019 03:41:14 GMT"}, {"version": "v4", "created": "Sat, 8 Jun 2019 15:16:08 GMT"}, {"version": "v5", "created": "Thu, 28 Nov 2019 03:39:46 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Song", "Yuhang", ""], ["Wojcicki", "Andrzej", ""], ["Lukasiewicz", "Thomas", ""], ["Wang", "Jianyi", ""], ["Aryan", "Abi", ""], ["Xu", "Zhenghua", ""], ["Xu", "Mai", ""], ["Ding", "Zihan", ""], ["Wu", "Lianlong", ""]]}, {"id": "1905.08087", "submitter": "Zheng Tian Mr", "authors": "Zheng Tian, Ying Wen, Zhichen Gong, Faiz Punakkath, Shihao Zou, Jun\n  Wang", "title": "A Regularized Opponent Model with Maximum Entropy Objective", "comments": "Accepted to International Joint Conference on Artificial Intelligence\n  (IJCA2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a single-agent setting, reinforcement learning (RL) tasks can be cast into\nan inference problem by introducing a binary random variable o, which stands\nfor the \"optimality\". In this paper, we redefine the binary random variable o\nin multi-agent setting and formalize multi-agent reinforcement learning (MARL)\nas probabilistic inference. We derive a variational lower bound of the\nlikelihood of achieving the optimality and name it as Regularized Opponent\nModel with Maximum Entropy Objective (ROMMEO). From ROMMEO, we present a novel\nperspective on opponent modeling and show how it can improve the performance of\ntraining agents theoretically and empirically in cooperative games. To optimize\nROMMEO, we first introduce a tabular Q-iteration method ROMMEO-Q with proof of\nconvergence. We extend the exact algorithm to complex environments by proposing\nan approximate version, ROMMEO-AC. We evaluate these two algorithms on the\nchallenging iterated matrix game and differential game respectively and show\nthat they can outperform strong MARL baselines.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 12:30:59 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 12:26:07 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Tian", "Zheng", ""], ["Wen", "Ying", ""], ["Gong", "Zhichen", ""], ["Punakkath", "Faiz", ""], ["Zou", "Shihao", ""], ["Wang", "Jun", ""]]}, {"id": "1905.08088", "submitter": "Yasushi Kawase", "authors": "Yasushi Kawase, Yuko Kuroki, Atsushi Miyauchi", "title": "Graph Mining Meets Crowdsourcing: Extracting Experts for Answer\n  Aggregation", "comments": "Accepted to IJCAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aggregating responses from crowd workers is a fundamental task in the process\nof crowdsourcing. In cases where a few experts are overwhelmed by a large\nnumber of non-experts, most answer aggregation algorithms such as the majority\nvoting fail to identify the correct answers. Therefore, it is crucial to\nextract reliable experts from the crowd workers. In this study, we introduce\nthe notion of \"expert core\", which is a set of workers that is very unlikely to\ncontain a non-expert. We design a graph-mining-based efficient algorithm that\nexactly computes the expert core. To answer the aggregation task, we propose\ntwo types of algorithms. The first one incorporates the expert core into\nexisting answer aggregation algorithms such as the majority voting, whereas the\nsecond one utilizes information provided by the expert core extraction\nalgorithm pertaining to the reliability of workers. We then give a theoretical\njustification for the first type of algorithm. Computational experiments using\nsynthetic and real-world datasets demonstrate that our proposed answer\naggregation algorithms outperform state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 12:49:50 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Kawase", "Yasushi", ""], ["Kuroki", "Yuko", ""], ["Miyauchi", "Atsushi", ""]]}, {"id": "1905.08188", "submitter": "Esther Derman", "authors": "Esther Derman and Daniel Mankowitz and Timothy Mann and Shie Mannor", "title": "A Bayesian Approach to Robust Reinforcement Learning", "comments": "Accepted to UAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust Markov Decision Processes (RMDPs) intend to ensure robustness with\nrespect to changing or adversarial system behavior. In this framework,\ntransitions are modeled as arbitrary elements of a known and properly\nstructured uncertainty set and a robust optimal policy can be derived under the\nworst-case scenario. In this study, we address the issue of learning in RMDPs\nusing a Bayesian approach. We introduce the Uncertainty Robust Bellman Equation\n(URBE) which encourages safe exploration for adapting the uncertainty set to\nnew observations while preserving robustness. We propose a URBE-based\nalgorithm, DQN-URBE, that scales this method to higher dimensional domains. Our\nexperiments show that the derived URBE-based strategy leads to a better\ntrade-off between less conservative solutions and robustness in the presence of\nmodel misspecification. In addition, we show that the DQN-URBE algorithm can\nadapt significantly faster to changing dynamics online compared to existing\nrobust techniques with fixed uncertainty sets.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 16:03:30 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 22:07:27 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Derman", "Esther", ""], ["Mankowitz", "Daniel", ""], ["Mann", "Timothy", ""], ["Mannor", "Shie", ""]]}, {"id": "1905.08222", "submitter": "Xiou Ge", "authors": "Xiou Ge, Richard T. Goodwin, Jeremy R. Gregory, Randolph E. Kirchain,\n  Joana Maria, Lav R. Varshney", "title": "Accelerated Discovery of Sustainable Building Materials", "comments": "Presented at AAAI 2019 Spring Symposium, Towards AI for Collaborative\n  Open Science (TACOS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concrete is the most widely used engineered material in the world with more\nthan 10 billion tons produced annually. Unfortunately, with that scale comes a\nsignificant burden in terms of energy, water, and release of greenhouse gases\nand other pollutants. As such, there is interest in creating concrete formulas\nthat minimize this environmental burden, while satisfying engineering\nperformance requirements. Recent advances in artificial intelligence have\nenabled machines to generate highly plausible artifacts, such as images of\nrealistic looking faces. Semi-supervised generative models allow generation of\nartifacts with specific, desired characteristics. In this work, we use\nConditional Variational Autoencoders (CVAE), a type of semi-supervised\ngenerative model, to discover concrete formulas with desired properties. Our\nmodel is trained using open data from the UCI Machine Learning Repository\njoined with environmental impact data computed using a web-based tool. We\ndemonstrate CVAEs can design concrete formulas with lower emissions and natural\nresource usage while meeting design requirements. To ensure fair comparison\nbetween extant and generated formulas, we also train regression models to\npredict the environmental impacts and strength of discovered formulas. With\nthese results, a construction engineer may create a formula that meets\nstructural needs and best addresses local environmental concerns.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 17:21:39 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Ge", "Xiou", ""], ["Goodwin", "Richard T.", ""], ["Gregory", "Jeremy R.", ""], ["Kirchain", "Randolph E.", ""], ["Maria", "Joana", ""], ["Varshney", "Lav R.", ""]]}, {"id": "1905.08293", "submitter": "Nicholas Denis", "authors": "Nicholas Denis", "title": "Issues concerning realizability of Blackwell optimal policies in\n  reinforcement learning", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  N-discount optimality was introduced as a hierarchical form of policy- and\nvalue-function optimality, with Blackwell optimality lying at the top level of\nthe hierarchy Veinott (1969); Blackwell (1962). We formalize notions of myopic\ndiscount factors, value functions and policies in terms of Blackwell optimality\nin MDPs, and we provide a novel concept of regret, called Blackwell regret,\nwhich measures the regret compared to a Blackwell optimal policy. Our main\nanalysis focuses on long horizon MDPs with sparse rewards. We show that\nselecting the discount factor under which zero Blackwell regret can be achieved\nbecomes arbitrarily hard. Moreover, even with oracle knowledge of such a\ndiscount factor that can realize a Blackwell regret-free value function, an\n$\\epsilon$-Blackwell optimal value function may not even be gain optimal.\nDifficulties associated with this class of problems is discussed, and the\nnotion of a policy gap is defined as the difference in expected return between\na given policy and any other policy that differs at that state; we prove\ncertain properties related to this gap. Finally, we provide experimental\nresults that further support our theoretical results.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 18:54:52 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Denis", "Nicholas", ""]]}, {"id": "1905.08297", "submitter": "Fahmid M. Fahid", "authors": "Fahmid M. Fahid, Zhe Yu, Tim Menzies", "title": "Better Technical Debt Detection via SURVEYing", "comments": "10 pages, 4 figures, 4 tables, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software analytics can be improved by surveying; i.e. rechecking and\n(possibly) revising the labels offered by prior analysis. Surveying is a\ntime-consuming task and effective surveyors must carefully manage their time.\nSpecifically, they must balance the cost of further surveying against the\nadditional benefits of that extra effort. This paper proposes SURVEY0, an\nincremental Logistic Regression estimation method that implements cost/benefit\nanalysis. Some classifier is used to rank the as-yet-unvisited examples\naccording to how interesting they might be. Humans then review the most\ninteresting examples, after which their feedback is used to update an estimator\nfor estimating how many examples are remaining. This paper evaluates SURVEY0 in\nthe context of self-admitted technical debt. As software project mature, they\ncan accumulate \"technical debt\" i.e. developer decisions which are sub-optimal\nand decrease the overall quality of the code. Such decisions are often\ncommented on by programmers in the code; i.e. it is self-admitted technical\ndebt (SATD). Recent results show that text classifiers can automatically detect\nsuch debt. We find that we can significantly outperform prior results by\nSURVEYing the data. Specifically, for ten open-source JAVA projects, we can\nfind 83% of the technical debt via SURVEY0 using just 16% of the comments (and\nif higher levels of recall are required, SURVEY0can adjust towards that with\nsome additional effort).\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 18:58:09 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Fahid", "Fahmid M.", ""], ["Yu", "Zhe", ""], ["Menzies", "Tim", ""]]}, {"id": "1905.08318", "submitter": "Simon Wiedemann", "authors": "Simon Wiedemann, Heiner Kirchhoffer, Stefan Matlage, Paul Haase,\n  Arturo Marban, Talmaj Marinc, David Neumann, Ahmed Osman, Detlev Marpe, Heiko\n  Schwarz, Thomas Wiegand, Wojciech Samek", "title": "DeepCABAC: Context-adaptive binary arithmetic coding for deep neural\n  network compression", "comments": "ICML 2019, Joint Workshop on On-Device Machine Learning and Compact\n  Deep Neural Network Representations (ODML-CDNNR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DeepCABAC, a novel context-adaptive binary arithmetic coder for\ncompressing deep neural networks. It quantizes each weight parameter by\nminimizing a weighted rate-distortion function, which implicitly takes the\nimpact of quantization on to the accuracy of the network into account.\nSubsequently, it compresses the quantized values into a bitstream\nrepresentation with minimal redundancies. We show that DeepCABAC is able to\nreach very high compression ratios across a wide set of different network\narchitectures and datasets. For instance, we are able to compress by x63.6 the\nVGG16 ImageNet model with no loss of accuracy, thus being able to represent the\nentire network with merely 8.7MB.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 13:36:27 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Wiedemann", "Simon", ""], ["Kirchhoffer", "Heiner", ""], ["Matlage", "Stefan", ""], ["Haase", "Paul", ""], ["Marban", "Arturo", ""], ["Marinc", "Talmaj", ""], ["Neumann", "David", ""], ["Osman", "Ahmed", ""], ["Marpe", "Detlev", ""], ["Schwarz", "Heiko", ""], ["Wiegand", "Thomas", ""], ["Samek", "Wojciech", ""]]}, {"id": "1905.08332", "submitter": "Jasprit Singh Gill", "authors": "Jasprit Singh Gill, Pierluigi Pisu, Venkat N. Krovi, Matthias J.\n  Schmid", "title": "Behavior Identification and Prediction for a Probabilistic Risk\n  Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Operation in a real world traffic requires autonomous vehicles to be able to\nplan their motion in complex environments (multiple moving participants).\nPlanning through such environment requires the right search space to be\nprovided for the trajectory or maneuver planners so that the safest motion for\nthe ego vehicle can be identified. Given the current states of the environment\nand its participants, analyzing the risks based on the predicted trajectories\nof all the traffic participants provides the necessary search space for the\nplanning of motion. This paper provides a fresh taxonomy of safety / risks that\nan autonomous vehicle should be able to handle while navigating through\ntraffic. It provides a reference system architecture that needs to be\nimplemented as well as describes a novel way of identifying and predicting the\nbehaviors of the traffic participants using classic Multi Model Adaptive\nEstimation (MMAE). Preliminary simulation results of the implemented model are\nincluded.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 20:25:21 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Gill", "Jasprit Singh", ""], ["Pisu", "Pierluigi", ""], ["Krovi", "Venkat N.", ""], ["Schmid", "Matthias J.", ""]]}, {"id": "1905.08347", "submitter": "Kai Sauerwald", "authors": "Kai Sauerwald and Christoph Beierle", "title": "Decrement Operators in Belief Change", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-29765-7_21", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While research on iterated revision is predominant in the field of iterated\nbelief change, the class of iterated contraction operators received more\nattention in recent years. In this article, we examine a non-prioritized\ngeneralisation of iterated contraction. In particular, the class of weak\ndecrement operators is introduced, which are operators that by multiple steps\nachieve the same as a contraction. Inspired by Darwiche and Pearl's work on\niterated revision the subclass of decrement operators is defined. For both,\ndecrement and weak decrement operators, postulates are presented and for each\nof them a representation theorem in the framework of total preorders is given.\nFurthermore, we present two sub-types of decrement operators.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 21:09:55 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 12:20:37 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Sauerwald", "Kai", ""], ["Beierle", "Christoph", ""]]}, {"id": "1905.08352", "submitter": "Vincent Lostanlen", "authors": "Vincent Lostanlen, Justin Salamon, Andrew Farnsworth, Steve Kelling,\n  Juan Pablo Bello", "title": "Robust sound event detection in bioacoustic sensor networks", "comments": "32 pages, in English. Submitted to PLOS ONE journal in February 2019;\n  revised August 2019; published October 2019", "journal-ref": null, "doi": "10.1371/journal.pone.0214168", "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bioacoustic sensors, sometimes known as autonomous recording units (ARUs),\ncan record sounds of wildlife over long periods of time in scalable and\nminimally invasive ways. Deriving per-species abundance estimates from these\nsensors requires detection, classification, and quantification of animal\nvocalizations as individual acoustic events. Yet, variability in ambient noise,\nboth over time and across sensors, hinders the reliability of current automated\nsystems for sound event detection (SED), such as convolutional neural networks\n(CNN) in the time-frequency domain. In this article, we develop, benchmark, and\ncombine several machine listening techniques to improve the generalizability of\nSED models across heterogeneous acoustic environments. As a case study, we\nconsider the problem of detecting avian flight calls from a ten-hour recording\nof nocturnal bird migration, recorded by a network of six ARUs in the presence\nof heterogeneous background noise. Starting from a CNN yielding\nstate-of-the-art accuracy on this task, we introduce two noise adaptation\ntechniques, respectively integrating short-term (60 milliseconds) and long-term\n(30 minutes) context. First, we apply per-channel energy normalization (PCEN)\nin the time-frequency domain, which applies short-term automatic gain control\nto every subband in the mel-frequency spectrogram. Secondly, we replace the\nlast dense layer in the network by a context-adaptive neural network (CA-NN)\nlayer. Combining them yields state-of-the-art results that are unmatched by\nartificial data augmentation alone. We release a pre-trained version of our\nbest performing system under the name of BirdVoxDetect, a ready-to-use detector\nof avian flight calls in field recordings.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 21:25:48 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 01:31:33 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Lostanlen", "Vincent", ""], ["Salamon", "Justin", ""], ["Farnsworth", "Andrew", ""], ["Kelling", "Steve", ""], ["Bello", "Juan Pablo", ""]]}, {"id": "1905.08359", "submitter": "Moritz Schubotz", "authors": "Andr\\'e Greiner-Petter, Terry Ruas, Moritz Schubotz, Akiko Aizawa,\n  William Grosky, Bela Gipp", "title": "Why Machines Cannot Learn Mathematics, Yet", "comments": "Submitted to 4th Joint Workshop on Bibliometric-enhanced Information\n  Retrieval and Natural Language Processing for Digital Libraries colocated at\n  the 42nd International ACM SIGIR Conference", "journal-ref": "2019 http://ceur-ws.org/Vol-2414/paper14.pdf", "doi": null, "report-no": null, "categories": "cs.DL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, Machine Learning (ML) is seen as the universal solution to improve\nthe effectiveness of information retrieval (IR) methods. However, while\nmathematics is a precise and accurate science, it is usually expressed by less\naccurate and imprecise descriptions, contributing to the relative dearth of\nmachine learning applications for IR in this domain. Generally, mathematical\ndocuments communicate their knowledge with an ambiguous, context-dependent, and\nnon-formal language. Given recent advances in ML, it seems canonical to apply\nML techniques to represent and retrieve mathematics semantically. In this work,\nwe apply popular text embedding techniques to the arXiv collection of STEM\ndocuments and explore how these are unable to properly understand mathematics\nfrom that corpus. In addition, we also investigate the missing aspects that\nwould allow mathematics to be learned by computers.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 21:54:26 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Greiner-Petter", "Andr\u00e9", ""], ["Ruas", "Terry", ""], ["Schubotz", "Moritz", ""], ["Aizawa", "Akiko", ""], ["Grosky", "William", ""], ["Gipp", "Bela", ""]]}, {"id": "1905.08412", "submitter": "Gleb Belov", "authors": "Gleb Belov, Liron Cohen, Maria Garcia de la Banda, Daniel Harabor,\n  Sven Koenig, Xinrui Wei", "title": "Position Paper: From Multi-Agent Pathfinding to Pipe Routing", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 2D Multi-Agent Path Finding (MAPF) problem aims at finding collision-free\npaths for a number of agents, from a set of start locations to a set of goal\npositions in a known 2D environment. MAPF has been studied in theoretical\ncomputer science, robotics, and artificial intelligence over several decades,\ndue to its importance for robot navigation. It is currently experiencing\nsignificant scientific progress due to its relevance in automated warehousing\n(such as those operated by Amazon) and in other contemporary application areas.\nIn this paper, we demonstrate that many recently developed MAPF algorithms\napply more broadly than currently believed in the MAPF research community. In\nparticular, we describe the 3D Pipe Routing (PR) problem, which aims at placing\ncollision-free pipes from given start locations to given goal locations in a\nknown 3D environment. The MAPF and PR problems are similar: a solution to a\nMAPF instance is a set of blocked cells in x-y-t space, while a solution to the\ncorresponding PR instance is a set of blocked cells in x-y-z space. We show how\nto use this similarity to apply several recently developed MAPF algorithms to\nthe PR problem, and discuss their performance on abstract PR instances. We also\ndiscuss further research necessary to tackle real-world pipe-routing instances\nof interest to industry today. This opens up a new direction of industrial\nrelevance for the MAPF research community.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 02:54:41 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Belov", "Gleb", ""], ["Cohen", "Liron", ""], ["de la Banda", "Maria Garcia", ""], ["Harabor", "Daniel", ""], ["Koenig", "Sven", ""], ["Wei", "Xinrui", ""]]}, {"id": "1905.08419", "submitter": "Zhao Kang", "authors": "Zhao Kang, Honghui Xu, Boyu Wang, Hongyuan Zhu, Zenglin Xu", "title": "Clustering with Similarity Preserving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-based clustering has shown promising performance in many tasks. A key\nstep of graph-based approach is the similarity graph construction. In general,\nlearning graph in kernel space can enhance clustering accuracy due to the\nincorporation of nonlinearity. However, most existing kernel-based graph\nlearning mechanisms is not similarity-preserving, hence leads to sub-optimal\nperformance. To overcome this drawback, we propose a more discriminative graph\nlearning method which can preserve the pairwise similarities between samples in\nan adaptive manner for the first time. Specifically, we require the learned\ngraph be close to a kernel matrix, which serves as a measure of similarity in\nraw data. Moreover, the structure is adaptively tuned so that the number of\nconnected components of the graph is exactly equal to the number of clusters.\nFinally, our method unifies clustering and graph learning which can directly\nobtain cluster indicators from the graph itself without performing further\nclustering step. The effectiveness of this approach is examined on both single\nand multiple kernel learning scenarios in several datasets.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 03:11:30 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Kang", "Zhao", ""], ["Xu", "Honghui", ""], ["Wang", "Boyu", ""], ["Zhu", "Hongyuan", ""], ["Xu", "Zenglin", ""]]}, {"id": "1905.08464", "submitter": "Pavel Gurevich", "authors": "Pavel Gurevich, Hannes Stuke", "title": "Robustness Against Outliers For Deep Neural Networks By Gradient\n  Conjugate Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze a new robust method for the reconstruction of probability\ndistributions of observed data in the presence of output outliers. It is based\non a so-called gradient conjugate prior (GCP) network which outputs the\nparameters of a prior. By rigorously studying the dynamics of the GCP learning\nprocess, we derive an explicit formula for correcting the obtained variance of\nthe marginal distribution and removing the bias caused by outliers in the\ntraining set. Assuming a Gaussian (input-dependent) ground truth distribution\ncontaminated with a proportion $\\varepsilon$ of outliers, we show that the\nfitted mean is in a $c e^{-1/\\varepsilon}$-neighborhood of the ground truth\nmean and the corrected variance is in a $b\\varepsilon$-neighborhood of the\nground truth variance, whereas the uncorrected variance of the marginal\ndistribution can even be infinite. We explicitly find $b$ as a function of the\noutput of the GCP network, without a priori knowledge of the outliers (possibly\ninput-dependent) distribution. Experiments with synthetic and real-world data\nsets indicate that the GCP network fitted with a standard optimizer outperforms\nother robust methods for regression.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 07:10:16 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Gurevich", "Pavel", ""], ["Stuke", "Hannes", ""]]}, {"id": "1905.08495", "submitter": "Mengxiao Hu", "authors": "Mengxiao Hu, Jinlong Li", "title": "Exploring Bias in GAN-based Data Augmentation for Small Samples", "comments": "rejected by SIGKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For machine learning task, lacking sufficient samples mean the trained model\nhas low confidence to approach the ground truth function. Until recently, after\nthe generative adversarial networks (GAN) had been proposed, we see the hope of\nsmall samples data augmentation (DA) with realistic fake data, and many works\nvalidated the viability of GAN-based DA. Although most of the works pointed out\nhigher accuracy can be achieved using GAN-based DA, some researchers stressed\nthat the fake data generated from GAN has inherent bias, and in this paper, we\nexplored when the bias is so low that it cannot hurt the performance, we set\nexperiments to depict the bias in different GAN-based DA setting, and from the\nresults, we design a pipeline to inspect specific dataset is\nefficiently-augmentable with GAN-based DA or not. And finally, depending on our\ntrial to reduce the bias, we proposed some advice to mitigate bias in GAN-based\nDA application.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 08:40:42 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Hu", "Mengxiao", ""], ["Li", "Jinlong", ""]]}, {"id": "1905.08513", "submitter": "Ce Ju", "authors": "Ce Ju", "title": "Stochastic Inverse Reinforcement Learning", "comments": "8+2 pages, 5 figures, Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of the inverse reinforcement learning (IRL) problem is to recover\nthe reward functions from expert demonstrations. However, the IRL problem like\nany ill-posed inverse problem suffers the congenital defect that the policy may\nbe optimal for many reward functions, and expert demonstrations may be optimal\nfor many policies. In this work, we generalize the IRL problem to a well-posed\nexpectation optimization problem stochastic inverse reinforcement learning\n(SIRL) to recover the probability distribution over reward functions. We adopt\nthe Monte Carlo expectation-maximization (MCEM) method to estimate the\nparameter of the probability distribution as the first solution to the SIRL\nproblem. The solution is succinct, robust, and transferable for a learning task\nand can generate alternative solutions to the IRL problem. Through our\nformulation, it is possible to observe the intrinsic property for the IRL\nproblem from a global viewpoint, and our approach achieves a considerable\nperformance on the objectworld.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 09:29:18 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 14:11:46 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2020 08:55:28 GMT"}, {"version": "v4", "created": "Wed, 29 Jul 2020 11:31:49 GMT"}, {"version": "v5", "created": "Tue, 8 Sep 2020 06:48:32 GMT"}, {"version": "v6", "created": "Wed, 9 Sep 2020 07:47:59 GMT"}, {"version": "v7", "created": "Fri, 11 Sep 2020 03:42:17 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Ju", "Ce", ""]]}, {"id": "1905.08527", "submitter": "Roberto Dess\\'i", "authors": "Roberto Dess\\`i and Marco Baroni", "title": "CNNs found to jump around more skillfully than RNNs: Compositional\n  generalization in seq2seq convolutional networks", "comments": "accepted as a short paper at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lake and Baroni (2018) introduced the SCAN dataset probing the ability of\nseq2seq models to capture compositional generalizations, such as inferring the\nmeaning of \"jump around\" 0-shot from the component words. Recurrent networks\n(RNNs) were found to completely fail the most challenging generalization cases.\nWe test here a convolutional network (CNN) on these tasks, reporting hugely\nimproved performance with respect to RNNs. Despite the big improvement, the CNN\nhas however not induced systematic rules, suggesting that the difference\nbetween compositional and non-compositional behaviour is not clear-cut.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 10:14:12 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Dess\u00ec", "Roberto", ""], ["Baroni", "Marco", ""]]}, {"id": "1905.08581", "submitter": "Deepika Verma", "authors": "Deepika Verma, Kerstin Bach, Paul Jarle Mork", "title": "Similarity Measure Development for Case-Based Reasoning- A Data-driven\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we demonstrate a data-driven methodology for modelling the\nlocal similarity measures of various attributes in a dataset. We analyse the\nspread in the numerical attributes and estimate their distribution using\npolynomial function to showcase an approach for deriving strong initial value\nranges of numerical attributes and use a non-overlapping distribution for\ncategorical attributes such that the entire similarity range [0,1] is utilized.\nWe use an open source dataset for demonstrating modelling and development of\nthe similarity measures and will present a case-based reasoning (CBR) system\nthat can be used to search for the most relevant similar cases.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 12:33:42 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Verma", "Deepika", ""], ["Bach", "Kerstin", ""], ["Mork", "Paul Jarle", ""]]}, {"id": "1905.08604", "submitter": "Takaharu Yaguchi", "authors": "Takashi Matsubara, Ai Ishikawa and Takaharu Yaguchi", "title": "Deep Energy-Based Modeling of Discrete-Time Physics", "comments": "Accepted to Advances in Neural Information Processing Systems\n  (NeurIPS2020) as an oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.AI cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical phenomena in the real world are often described by energy-based\nmodeling theories, such as Hamiltonian mechanics or the Landau theory, which\nyield various physical laws. Recent developments in neural networks have\nenabled the mimicking of the energy conservation law by learning the underlying\ncontinuous-time differential equations. However, this may not be possible in\ndiscrete time, which is often the case in practical learning and computation.\nMoreover, other physical laws have been overlooked in the previous neural\nnetwork models. In this study, we propose a deep energy-based physical model\nthat admits a specific differential geometric structure. From this structure,\nthe conservation or dissipation law of energy and the mass conservation law\nfollow naturally. To ensure the energetic behavior in discrete time, we also\npropose an automatic discrete differential algorithm that enables neural\nnetworks to employ the discrete gradient method.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 13:21:46 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 04:24:08 GMT"}, {"version": "v3", "created": "Sat, 31 Oct 2020 10:02:24 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Matsubara", "Takashi", ""], ["Ishikawa", "Ai", ""], ["Yaguchi", "Takaharu", ""]]}, {"id": "1905.08616", "submitter": "Alex Wong", "authors": "Alex Wong, Xiaohan Fei, Stephanie Tsuei, Stefano Soatto", "title": "Unsupervised Depth Completion from Visual Inertial Odometry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We describe a method to infer dense depth from camera motion and sparse depth\nas estimated using a visual-inertial odometry system. Unlike other scenarios\nusing point clouds from lidar or structured light sensors, we have few hundreds\nto few thousand points, insufficient to inform the topology of the scene. Our\nmethod first constructs a piecewise planar scaffolding of the scene, and then\nuses it to infer dense depth using the image along with the sparse points. We\nuse a predictive cross-modal criterion, akin to `self-supervision,' measuring\nphotometric consistency across time, forward-backward pose consistency, and\ngeometric compatibility with the sparse point cloud. We also launch the first\nvisual-inertial + depth dataset, which we hope will foster additional\nexploration into combining the complementary strengths of visual and inertial\nsensors. To compare our method to prior work, we adopt the unsupervised KITTI\ndepth completion benchmark, and show state-of-the-art performance on it. Code\navailable at:\nhttps://github.com/alexklwong/unsupervised-depth-completion-visual-inertial-odometry.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 03:47:18 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 23:20:01 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 03:51:28 GMT"}, {"version": "v4", "created": "Wed, 21 Jul 2021 11:21:08 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Wong", "Alex", ""], ["Fei", "Xiaohan", ""], ["Tsuei", "Stephanie", ""], ["Soatto", "Stefano", ""]]}, {"id": "1905.08617", "submitter": "Chongyang Bai", "authors": "Chongyang Bai, Maksim Bolonkin, Judee Burgoon, Chao Chen, Norah\n  Dunbar, Bharat Singh, V. S. Subrahmanian and Zhe Wu", "title": "Automatic Long-Term Deception Detection in Group Interaction Videos", "comments": "ICME 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most work on automated deception detection (ADD) in video has two\nrestrictions: (i) it focuses on a video of one person, and (ii) it focuses on a\nsingle act of deception in a one or two minute video. In this paper, we propose\na new ADD framework which captures long term deception in a group setting. We\nstudy deception in the well-known Resistance game (like Mafia and Werewolf)\nwhich consists of 5-8 players of whom 2-3 are spies. Spies are deceptive\nthroughout the game (typically 30-65 minutes) to keep their identity hidden. We\ndevelop an ensemble predictive model to identify spies in Resistance videos. We\nshow that features from low-level and high-level video analysis are\ninsufficient, but when combined with a new class of features that we call\nLiarRank, produce the best results. We achieve AUCs of over 0.70 in a fully\nautomated setting. Our demo can be found at\nhttp://home.cs.dartmouth.edu/~mbolonkin/scan/demo/\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 15:45:02 GMT"}, {"version": "v2", "created": "Sat, 15 Jun 2019 16:36:53 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Bai", "Chongyang", ""], ["Bolonkin", "Maksim", ""], ["Burgoon", "Judee", ""], ["Chen", "Chao", ""], ["Dunbar", "Norah", ""], ["Singh", "Bharat", ""], ["Subrahmanian", "V. S.", ""], ["Wu", "Zhe", ""]]}, {"id": "1905.08711", "submitter": "Alexander Kozlov", "authors": "Alexander Kozlov, Vadim Andronov, Yana Gritsenko", "title": "Lightweight Network Architecture for Real-Time Action Recognition", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we present a new efficient approach to Human Action Recognition\ncalled Video Transformer Network (VTN). It leverages the latest advances in\nComputer Vision and Natural Language Processing and applies them to video\nunderstanding. The proposed method allows us to create lightweight CNN models\nthat achieve high accuracy and real-time speed using just an RGB mono camera\nand general purpose CPU. Furthermore, we explain how to improve accuracy by\ndistilling from multiple models with different modalities into a single model.\nWe conduct a comparison with state-of-the-art methods and show that our\napproach performs on par with most of them on famous Action Recognition\ndatasets. We benchmark the inference time of the models using the modern\ninference framework and argue that our approach compares favorably with other\nmethods in terms of speed/accuracy trade-off, running at 56 FPS on CPU. The\nmodels and the training code are available.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 15:50:24 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Kozlov", "Alexander", ""], ["Andronov", "Vadim", ""], ["Gritsenko", "Yana", ""]]}, {"id": "1905.08743", "submitter": "Chien-Sheng Wu", "authors": "Chien-Sheng Wu, Andrea Madotto, Ehsan Hosseini-Asl, Caiming Xiong,\n  Richard Socher, Pascale Fung", "title": "Transferable Multi-Domain State Generator for Task-Oriented Dialogue\n  Systems", "comments": "The 57th Annual Meeting of the Association for Computational\n  Linguistics (ACL 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over-dependence on domain ontology and lack of knowledge sharing across\ndomains are two practical and yet less studied problems of dialogue state\ntracking. Existing approaches generally fall short in tracking unknown slot\nvalues during inference and often have difficulties in adapting to new domains.\nIn this paper, we propose a Transferable Dialogue State Generator (TRADE) that\ngenerates dialogue states from utterances using a copy mechanism, facilitating\nknowledge transfer when predicting (domain, slot, value) triplets not\nencountered during training. Our model is composed of an utterance encoder, a\nslot gate, and a state generator, which are shared across domains. Empirical\nresults demonstrate that TRADE achieves state-of-the-art joint goal accuracy of\n48.62% for the five domains of MultiWOZ, a human-human dialogue dataset. In\naddition, we show its transferring ability by simulating zero-shot and few-shot\ndialogue state tracking for unseen domains. TRADE achieves 60.58% joint goal\naccuracy in one of the zero-shot domains, and is able to adapt to few-shot\ncases without forgetting already trained domains.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 16:43:54 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 14:36:57 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Wu", "Chien-Sheng", ""], ["Madotto", "Andrea", ""], ["Hosseini-Asl", "Ehsan", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""], ["Fung", "Pascale", ""]]}, {"id": "1905.08776", "submitter": "Aliaksandra Shysheya Ms", "authors": "Aliaksandra Shysheya (Samsung AI Center, Skolkovo Institute of Science\n  and Technology), Egor Zakharov (Samsung AI Center, Skolkovo Institute of\n  Science and Technology), Kara-Ali Aliev (Samsung AI Center), Renat Bashirov\n  (Samsung AI Center), Egor Burkov (Samsung AI Center, Skolkovo Institute of\n  Science and Technology), Karim Iskakov (Samsung AI Center), Aleksei\n  Ivakhnenko (Samsung AI Center), Yury Malkov (Samsung AI Center), Igor\n  Pasechnik (Samsung AI Center), Dmitry Ulyanov (Samsung AI Center, Skolkovo\n  Institute of Science and Technology), Alexander Vakhitov (Samsung AI Center,\n  Skolkovo Institute of Science and Technology) and Victor Lempitsky (Samsung\n  AI Center, Skolkovo Institute of Science and Technology)", "title": "Textured Neural Avatars", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system for learning full-body neural avatars, i.e. deep networks\nthat produce full-body renderings of a person for varying body pose and camera\nposition. Our system takes the middle path between the classical graphics\npipeline and the recent deep learning approaches that generate images of humans\nusing image-to-image translation. In particular, our system estimates an\nexplicit two-dimensional texture map of the model surface. At the same time, it\nabstains from explicit shape modeling in 3D. Instead, at test time, the system\nuses a fully-convolutional network to directly map the configuration of body\nfeature points w.r.t. the camera to the 2D texture coordinates of individual\npixels in the image frame. We show that such a system is capable of learning to\ngenerate realistic renderings while being trained on videos annotated with 3D\nposes and foreground masks. We also demonstrate that maintaining an explicit\ntexture representation helps our system to achieve better generalization\ncompared to systems that use direct image-to-image translation.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 17:46:16 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Shysheya", "Aliaksandra", "", "Samsung AI Center, Skolkovo Institute of Science\n  and Technology"], ["Zakharov", "Egor", "", "Samsung AI Center, Skolkovo Institute of\n  Science and Technology"], ["Aliev", "Kara-Ali", "", "Samsung AI Center"], ["Bashirov", "Renat", "", "Samsung AI Center"], ["Burkov", "Egor", "", "Samsung AI Center, Skolkovo Institute of\n  Science and Technology"], ["Iskakov", "Karim", "", "Samsung AI Center"], ["Ivakhnenko", "Aleksei", "", "Samsung AI Center"], ["Malkov", "Yury", "", "Samsung AI Center"], ["Pasechnik", "Igor", "", "Samsung AI Center"], ["Ulyanov", "Dmitry", "", "Samsung AI Center, Skolkovo\n  Institute of Science and Technology"], ["Vakhitov", "Alexander", "", "Samsung AI Center,\n  Skolkovo Institute of Science and Technology"], ["Lempitsky", "Victor", "", "Samsung\n  AI Center, Skolkovo Institute of Science and Technology"]]}, {"id": "1905.08793", "submitter": "Konstantinos Pitas", "authors": "Konstantinos Pitas, Mike Davies, Pierre Vandergheynst", "title": "Revisiting hard thresholding for DNN pruning", "comments": "arXiv admin note: substantial text overlap with arXiv:1803.04239", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most common method for DNN pruning is hard thresholding of network\nweights, followed by retraining to recover any lost accuracy. Recently\ndeveloped smart pruning algorithms use the DNN response over the training set\nfor a variety of cost functions to determine redundant network weights, leading\nto less accuracy degradation and possibly less retraining time. For experiments\non the total pruning time (pruning time + retraining time) we show that hard\nthresholding followed by retraining remains the most efficient way of reducing\nthe number of network parameters. However smart pruning algorithms still have\nadvantages when retraining is not possible. In this context we propose a novel\nsmart pruning algorithm based on difference of convex functions optimisation\nand show that it is often orders of magnitude faster than competing approaches\nwhile achieving the lowest classification accuracy degradation. Furthermore we\ninvestigate theoretically the effect of hard thresholding on DNN accuracy. We\nshow that accuracy degradation increases with remaining network depth from the\npruned layer. We also discover a link between the latent dimensionality of the\ntraining data manifold and network robustness to hard thresholding.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 14:59:13 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Pitas", "Konstantinos", ""], ["Davies", "Mike", ""], ["Vandergheynst", "Pierre", ""]]}, {"id": "1905.08842", "submitter": "David A. Plaisted", "authors": "David A. Plaisted", "title": "Properties and Extensions of Alternating Path Relevance - I", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When proving theorems from large sets of logical assertions, it can be\nhelpful to restrict the search for a proof to those assertions that are\nrelevant, that is, closely related to the theorem in some sense. For example,\nin the Watson system, a large knowledge base must rapidly be searched for\nrelevant facts. It is possible to define formal concepts of relevance for\npropositional and first-order logic. Various concepts of relevance have been\ndefined for this, and some have yielded good results on large problems. We\nconsider here in particular a concept based on alternating paths.We present\nefficient graph-based methods for computing alternating path relevance and give\nsome results indicating its effectiveness. We also propose an alternating path\nbased extension of this relevance method to DPLL with an improved time bound,\nand give other extensions to alternating path relevance intended to improve its\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 19:26:00 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Plaisted", "David A.", ""]]}, {"id": "1905.08843", "submitter": "Ahmad Babaeian Jelodar", "authors": "Ahmad Babaeian Jelodar, Yu Sun", "title": "Joint Object and State Recognition using Language Knowledge", "comments": "5 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state of an object is an important piece of knowledge in robotics\napplications. States and objects are intertwined together, meaning that object\ninformation can help recognize the state of an image and vice versa. This paper\naddresses the state identification problem in cooking related images and uses\nstate and object predictions together to improve the classification accuracy of\nobjects and their states from a single image. The pipeline presented in this\npaper includes a CNN with a double classification layer and the Concept-Net\nlanguage knowledge graph on top. The language knowledge creates a semantic\nlikelihood between objects and states. The resulting object and state\nconfidences from the deep architecture are used together with object and state\nrelatedness estimates from a language knowledge graph to produce marginal\nprobabilities for objects and states. The marginal probabilities and\nconfidences of objects (or states) are fused together to improve the final\nobject (or state) classification results. Experiments on a dataset of cooking\nobjects show that using a language knowledge graph on top of a deep neural\nnetwork effectively enhances object and state classification.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 13:26:17 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Jelodar", "Ahmad Babaeian", ""], ["Sun", "Yu", ""]]}, {"id": "1905.08926", "submitter": "Deepali Jain", "authors": "Deepali Jain, Atil Iscen, Ken Caluwaerts", "title": "Hierarchical Reinforcement Learning for Quadruped Locomotion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Legged locomotion is a challenging task for learning algorithms, especially\nwhen the task requires a diverse set of primitive behaviors. To solve these\nproblems, we introduce a hierarchical framework to automatically decompose\ncomplex locomotion tasks. A high-level policy issues commands in a latent space\nand also selects for how long the low-level policy will execute the latent\ncommand. Concurrently, the low-level policy uses the latent command and only\nthe robot's on-board sensors to control the robot's actuators. Our approach\nallows the high-level policy to run at a lower frequency than the low-level\none. We test our framework on a path-following task for a dynamic quadruped\nrobot and we show that steering behaviors automatically emerge in the latent\ncommand space as low-level skills are needed for this task. We then show\nefficient adaptation of the trained policy to a different task by transfer of\nthe trained low-level policy. Finally, we validate the policies on a real\nquadruped robot. To the best of our knowledge, this is the first application of\nend-to-end hierarchical learning to a real robotic locomotion task.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 02:28:39 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Jain", "Deepali", ""], ["Iscen", "Atil", ""], ["Caluwaerts", "Ken", ""]]}, {"id": "1905.08937", "submitter": "Ranjan Satapathy", "authors": "Nidhi Mishra, Manoj Ramanathan, Ranjan Satapathy, Erik Cambria and\n  Nadia Magnenat-Thalmann", "title": "Can a Humanoid Robot be part of the Organizational Workforce? A User\n  Study Leveraging Sentiment Analysis", "comments": "Submitted to IEEE RO-MAN2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hiring robots for the workplaces is a challenging task as robots have to\ncater to customer demands, follow organizational protocols and behave with\nsocial etiquette. In this study, we propose to have a humanoid social robot,\nNadine, as a customer service agent in an open social work environment. The\nobjective of this study is to analyze the effects of humanoid robots on\ncustomers at work environment, and see if it can handle social scenarios. We\npropose to evaluate these objectives through two modes, namely, survey\nquestionnaire and customer feedback. We also propose a novel approach to\nanalyze customer feedback data (text) using sentic computing methods.\nSpecifically, we employ aspect extraction and sentiment analysis to analyze the\ndata. From our framework, we detect sentiment associated to the aspects that\nmainly concerned the customers during their interaction. This allows us to\nunderstand customers expectations and current limitations of robots as\nemployees.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 03:34:59 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 06:22:53 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Mishra", "Nidhi", ""], ["Ramanathan", "Manoj", ""], ["Satapathy", "Ranjan", ""], ["Cambria", "Erik", ""], ["Magnenat-Thalmann", "Nadia", ""]]}, {"id": "1905.08941", "submitter": "Hongyu Guo", "authors": "Hongyu Guo, Yongyi Mao, Richong Zhang", "title": "Augmenting Data with Mixup for Sentence Classification: An Empirical\n  Study", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixup, a recent proposed data augmentation method through linearly\ninterpolating inputs and modeling targets of random samples, has demonstrated\nits capability of significantly improving the predictive accuracy of the\nstate-of-the-art networks for image classification. However, how this technique\ncan be applied to and what is its effectiveness on natural language processing\n(NLP) tasks have not been investigated. In this paper, we propose two\nstrategies for the adaption of Mixup on sentence classification: one performs\ninterpolation on word embeddings and another on sentence embeddings. We conduct\nexperiments to evaluate our methods using several benchmark datasets. Our\nstudies show that such interpolation strategies serve as an effective, domain\nindependent data augmentation approach for sentence classification, and can\nresult in significant accuracy improvement for both CNN and LSTM models.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 03:55:54 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Guo", "Hongyu", ""], ["Mao", "Yongyi", ""], ["Zhang", "Richong", ""]]}, {"id": "1905.08955", "submitter": "Khaled Saleh", "authors": "Khaled Saleh, Ahmed Abobakr, Mohammed Attia, Julie Iskander, Darius\n  Nahavandi, Mohammed Hossny", "title": "Domain Adaptation for Vehicle Detection from Bird's Eye View LiDAR Point\n  Cloud Data", "comments": "Under review for IEEE SMC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point cloud data from 3D LiDAR sensors are one of the most crucial sensor\nmodalities for versatile safety-critical applications such as self-driving\nvehicles. Since the annotations of point cloud data is an expensive and\ntime-consuming process, therefore recently the utilisation of simulated\nenvironments and 3D LiDAR sensors for this task started to get some popularity.\nWith simulated sensors and environments, the process for obtaining an annotated\nsynthetic point cloud data became much easier. However, the generated synthetic\npoint cloud data are still missing the artefacts usually exist in point cloud\ndata from real 3D LiDAR sensors. As a result, the performance of the trained\nmodels on this data for perception tasks when tested on real point cloud data\nis degraded due to the domain shift between simulated and real environments.\nThus, in this work, we are proposing a domain adaptation framework for bridging\nthis gap between synthetic and real point cloud data. Our proposed framework is\nbased on the deep cycle-consistent generative adversarial networks (CycleGAN)\narchitecture. We have evaluated the performance of our proposed framework on\nthe task of vehicle detection from a bird's eye view (BEV) point cloud images\ncoming from real 3D LiDAR sensors. The framework has shown competitive results\nwith an improvement of more than 7% in average precision score over other\nbaseline approaches when tested on real BEV point cloud images.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 05:24:26 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Saleh", "Khaled", ""], ["Abobakr", "Ahmed", ""], ["Attia", "Mohammed", ""], ["Iskander", "Julie", ""], ["Nahavandi", "Darius", ""], ["Hossny", "Mohammed", ""]]}, {"id": "1905.09000", "submitter": "Yousif Hashisho", "authors": "Yousif Hashisho, Mohamad Albadawi, Tom Krause, and Uwe Freiherr von\n  Lukas", "title": "Underwater Color Restoration Using U-Net Denoising Autoencoder", "comments": "6 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Visual inspection of underwater structures by vehicles, e.g. remotely\noperated vehicles (ROVs), plays an important role in scientific, military, and\ncommercial sectors. However, the automatic extraction of information using\nsoftware tools is hindered by the characteristics of water which degrade the\nquality of captured videos. As a contribution for restoring the color of\nunderwater images, Underwater Denoising Autoencoder (UDAE) model is developed\nusing a denoising autoencoder with U-Net architecture. The proposed network\ntakes into consideration the accuracy and the computation cost to enable\nreal-time implementation on underwater visual tasks using end-to-end\nautoencoder network. Underwater vehicles perception is improved by\nreconstructing captured frames; hence obtaining better performance in\nunderwater tasks. Related learning methods use generative adversarial networks\n(GANs) to generate color corrected underwater images, and to our knowledge this\npaper is the first to deal with a single autoencoder capable of producing same\nor better results. Moreover, image pairs are constructed for training the\nproposed network, where it is hard to obtain such dataset from underwater\nscenery. At the end, the proposed model is compared to a state-of-the-art\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 07:49:45 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Hashisho", "Yousif", ""], ["Albadawi", "Mohamad", ""], ["Krause", "Tom", ""], ["von Lukas", "Uwe Freiherr", ""]]}, {"id": "1905.09033", "submitter": "Davide Mazzini", "authors": "Davide Mazzini, Raimondo Schettini", "title": "Spatial Sampling Network for Fast Scene Understanding", "comments": "Accepted at CVPR2019 Workshop on Autonomous Driving", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a network architecture to perform efficient scene understanding.\nThis work presents three main novelties: the first is an Improved Guided\nUpsampling Module that can replace in toto the decoder part in common semantic\nsegmentation networks. Our second contribution is the introduction of a new\nmodule based on spatial sampling to perform Instance Segmentation. It provides\na very fast instance segmentation, needing only thresholding as post-processing\nstep at inference time. Finally, we propose a novel efficient network design\nthat includes the new modules and test it against different datasets for\noutdoor scene understanding. To our knowledge, our network is one of the\nthemost efficient architectures for scene understanding published to date,\nfurthermore being 8.6% more accurate than the fastest competitor on semantic\nsegmentation and almost five times faster than the most efficient network for\ninstance segmentation.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 09:24:17 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Mazzini", "Davide", ""], ["Schettini", "Raimondo", ""]]}, {"id": "1905.09035", "submitter": "Antonino Furnari", "authors": "Antonino Furnari and Giovanni Maria Farinella", "title": "What Would You Expect? Anticipating Egocentric Actions with\n  Rolling-Unrolling LSTMs and Modality Attention", "comments": "Accepted as oral to ICCV [International Conference on Computer\n  Vision] 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Egocentric action anticipation consists in understanding which objects the\ncamera wearer will interact with in the near future and which actions they will\nperform. We tackle the problem proposing an architecture able to anticipate\nactions at multiple temporal scales using two LSTMs to 1) summarize the past,\nand 2) formulate predictions about the future. The input video is processed\nconsidering three complimentary modalities: appearance (RGB), motion (optical\nflow) and objects (object-based features). Modality-specific predictions are\nfused using a novel Modality ATTention (MATT) mechanism which learns to weigh\nmodalities in an adaptive fashion. Extensive evaluations on two large-scale\nbenchmark datasets show that our method outperforms prior art by up to +7% on\nthe challenging EPIC-Kitchens dataset including more than 2500 actions, and\ngeneralizes to EGTEA Gaze+. Our approach is also shown to generalize to the\ntasks of early action recognition and action recognition. Our method is ranked\nfirst in the public leaderboard of the EPIC-Kitchens egocentric action\nanticipation challenge 2019. Please see our web pages for code and examples:\nhttp://iplab.dmi.unict.it/rulstm - https://github.com/fpv-iplab/rulstm.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 09:25:25 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 21:09:08 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Furnari", "Antonino", ""], ["Farinella", "Giovanni Maria", ""]]}, {"id": "1905.09063", "submitter": "Pravin Chandran", "authors": "Raghavendra Bhat, Pravin Chandran, Juby Jose, Viswanath Dibbur,\n  Prakash Sirra Ajith", "title": "NTP : A Neural Network Topology Profiler", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance of end-to-end neural networks on a given hardware platform is a\nfunction of its compute and memory signature, which in-turn, is governed by a\nwide range of parameters such as topology size, primitives used, framework\nused, batching strategy, latency requirements, precision etc. Current\nbenchmarking tools suffer from limitations such as a) being either too granular\nlike DeepBench [1] (or) b) mandate a working implementation that is either\nframework specific or hardware-architecture specific or both (or) c) provide\nonly high level benchmark metrics. In this paper, we present NTP (Neural Net\nTopology Profiler), a sophisticated benchmarking framework, to effectively\nidentify memory and compute signature of an end-to-end topology on multiple\nhardware architectures, without the need for an actual implementation. NTP is\ntightly integrated with hardware specific benchmarking tools to enable\nexhaustive data collection and analysis. Using NTP, a deep learning researcher\ncan quickly establish baselines needed to understand performance of an\nend-to-end neural network topology and make high level architectural decisions.\nFurther, integration of NTP with frameworks like Tensorflow, Pytorch, Intel\nOpenVINO etc. allows for performance comparison along several vectors like a)\nComparison of different frameworks on a given hardware b) Comparison of\ndifferent hardware using a given framework c) Comparison across different\nheterogeneous hardware configurations for given framework etc. These\ncapabilities empower a researcher to effortlessly make architectural decisions\nneeded for achieving optimized performance on any hardware platform. The paper\ndocuments the architectural approach of NTP and demonstrates the capabilities\nof the tool by benchmarking Mozilla DeepSpeech, a popular Speech Recognition\ntopology.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 10:55:22 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 01:51:25 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Bhat", "Raghavendra", ""], ["Chandran", "Pravin", ""], ["Jose", "Juby", ""], ["Dibbur", "Viswanath", ""], ["Ajith", "Prakash Sirra", ""]]}, {"id": "1905.09103", "submitter": "Andrea Galassi", "authors": "Andrea Galassi, Kristian Kersting, Marco Lippi, Xiaoting Shao, Paolo\n  Torroni", "title": "Neural-Symbolic Argumentation Mining: an Argument in Favor of Deep\n  Learning and Reasoning", "comments": null, "journal-ref": "Frontiers in Big Data 2 (2020) 52", "doi": "10.3389/fdata.2019.00052", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning is bringing remarkable contributions to the field of\nargumentation mining, but the existing approaches still need to fill the gap\ntoward performing advanced reasoning tasks. In this position paper, we posit\nthat neural-symbolic and statistical relational learning could play a crucial\nrole in the integration of symbolic and sub-symbolic methods to achieve this\ngoal.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 12:31:08 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 08:55:00 GMT"}, {"version": "v3", "created": "Tue, 28 Jan 2020 16:59:48 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Galassi", "Andrea", ""], ["Kersting", "Kristian", ""], ["Lippi", "Marco", ""], ["Shao", "Xiaoting", ""], ["Torroni", "Paolo", ""]]}, {"id": "1905.09130", "submitter": "Stefano Giovanni Rizzo", "authors": "Stefano Giovanni Rizzo, Ji Lucas, Zoi Kaoudi, Jorge-Arnulfo\n  Quiane-Ruiz, Sanjay Chawla", "title": "AI-CARGO: A Data-Driven Air-Cargo Revenue Management System", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose AI-CARGO, a revenue management system for air-cargo that combines\nmachine learning prediction with decision-making using mathematical\noptimization methods. AI-CARGO addresses a problem that is unique to the\nair-cargo business, namely the wide discrepancy between the quantity (weight or\nvolume) that a shipper will book and the actual received amount at departure\ntime by the airline. The discrepancy results in sub-optimal and inefficient\nbehavior by both the shipper and the airline resulting in the overall loss of\npotential revenue for the airline. AI-CARGO also includes a data cleaning\ncomponent to deal with the heterogeneous forms in which booking data is\ntransmitted to the airline cargo system. AI-CARGO is deployed in the production\nenvironment of a large commercial airline company. We have validated the\nbenefits of AI-CARGO using real and synthetic datasets. Especially, we have\ncarried out simulations using dynamic programming techniques to elicit the\nimpact on offloading costs and revenue generation of our proposed system. Our\nresults suggest that combining prediction within a decision-making framework\ncan help dramatically to reduce offloading costs and optimize revenue\ngeneration.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 13:34:45 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Rizzo", "Stefano Giovanni", ""], ["Lucas", "Ji", ""], ["Kaoudi", "Zoi", ""], ["Quiane-Ruiz", "Jorge-Arnulfo", ""], ["Chawla", "Sanjay", ""]]}, {"id": "1905.09153", "submitter": "Timothy Miller", "authors": "Timothy A Miller", "title": "Simplified Neural Unsupervised Domain Adaptation", "comments": "To be presented at NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation (UDA) is the task of modifying a statistical\nmodel trained on labeled data from a source domain to achieve better\nperformance on data from a target domain, with access to only unlabeled data in\nthe target domain. Existing state-of-the-art UDA approaches use neural networks\nto learn representations that can predict the values of subset of important\nfeatures called \"pivot features.\" In this work, we show that it is possible to\nimprove on these methods by jointly training the representation learner with\nthe task learner, and examine the importance of existing pivot selection\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 14:11:30 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Miller", "Timothy A", ""]]}, {"id": "1905.09165", "submitter": "Soham Pal", "authors": "Soham Pal, Yash Gupta, Aditya Shukla, Aditya Kanade, Shirish Shevade,\n  Vinod Ganapathy", "title": "A framework for the extraction of Deep Neural Networks by leveraging\n  public data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models trained on confidential datasets are increasingly\nbeing deployed for profit. Machine Learning as a Service (MLaaS) has made such\nmodels easily accessible to end-users. Prior work has developed model\nextraction attacks, in which an adversary extracts an approximation of MLaaS\nmodels by making black-box queries to it. However, none of these works is able\nto satisfy all the three essential criteria for practical model extraction: (1)\nthe ability to work on deep learning models, (2) the non-requirement of domain\nknowledge and (3) the ability to work with a limited query budget. We design a\nmodel extraction framework that makes use of active learning and large public\ndatasets to satisfy them. We demonstrate that it is possible to use this\nframework to steal deep classifiers trained on a variety of datasets from image\nand text domains. By querying a model via black-box access for its top\nprediction, our framework improves performance on an average over a uniform\nnoise baseline by 4.70x for image tasks and 2.11x for text tasks respectively,\nwhile using only 30% (30,000 samples) of the public dataset at its disposal.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 14:26:04 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Pal", "Soham", ""], ["Gupta", "Yash", ""], ["Shukla", "Aditya", ""], ["Kanade", "Aditya", ""], ["Shevade", "Shirish", ""], ["Ganapathy", "Vinod", ""]]}, {"id": "1905.09191", "submitter": "Takuya Hiraoka", "authors": "Takuya Hiraoka, Takahisa Imagawa, Tatsuya Mori, Takashi Onishi,\n  Yoshimasa Tsuruoka", "title": "Learning Robust Options by Conditional Value at Risk Optimization", "comments": "NeurIPS 2019. Video demo:\n  https://drive.google.com/open?id=1xXgSeEa_nNG397ZkIayk3CwYPy_BPy8X Source\n  codes:\n  https://github.com/TakuyaHiraoka/Learning-Robust-Options-by-Conditional-Value-at-Risk-Optimization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Options are generally learned by using an inaccurate environment model (or\nsimulator), which contains uncertain model parameters. While there are several\nmethods to learn options that are robust against the uncertainty of model\nparameters, these methods only consider either the worst case or the average\n(ordinary) case for learning options. This limited consideration of the cases\noften produces options that do not work well in the unconsidered case. In this\npaper, we propose a conditional value at risk (CVaR)-based method to learn\noptions that work well in both the average and worst cases. We extend the\nCVaR-based policy gradient method proposed by Chow and Ghavamzadeh (2014) to\ndeal with robust Markov decision processes and then apply the extended method\nto learning robust options. We conduct experiments to evaluate our method in\nmulti-joint robot control tasks (HopperIceBlock, Half-Cheetah, and Walker2D).\nExperimental results show that our method produces options that 1) give better\nworst-case performance than the options learned only to minimize the\naverage-case loss, and 2) give better average-case performance than the options\nlearned only to minimize the worst-case loss.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 15:23:08 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 09:26:07 GMT"}, {"version": "v3", "created": "Tue, 11 Jun 2019 07:21:59 GMT"}, {"version": "v4", "created": "Thu, 31 Oct 2019 06:10:40 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Hiraoka", "Takuya", ""], ["Imagawa", "Takahisa", ""], ["Mori", "Tatsuya", ""], ["Onishi", "Takashi", ""], ["Tsuruoka", "Yoshimasa", ""]]}, {"id": "1905.09221", "submitter": "Loris Bozzato", "authors": "Loris Bozzato, Thomas Eiter, Luciano Serafini", "title": "A Note on Reasoning on $\\textit{DL-Lite}_{\\cal R}$ with Defeasibility", "comments": "Part of this work will appear as a paper in Proceedings of 32nd\n  International Workshop on Description Logics (DL2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation of defeasible information is of interest in description\nlogics, as it is related to the need of accommodating exceptional instances in\nknowledge bases. In this direction, in our previous works we presented a\ndatalog translation for reasoning on (contextualized) OWL RL knowledge bases\nwith a notion of justified exceptions on defeasible axioms. While it covers a\nrelevant fragment of OWL, the resulting reasoning process needs a complex\nencoding in order to capture reasoning on negative information. In this paper,\nwe consider the case of knowledge bases in $\\textit{DL-Lite}_{\\cal R}$, i.e.\nthe language underlying OWL QL. We provide a definition for\n$\\textit{DL-Lite}_{\\cal R}$ knowledge bases with defeasible axioms and study\ntheir properties. The limited form of $\\textit{DL-Lite}_{\\cal R}$ axioms allows\nus to formulate a simpler encoding into datalog (under answer set semantics)\nwith direct rules for reasoning on negative information. The resulting\nmaterialization method gives rise to a complete reasoning procedure for\ninstance checking in $\\textit{DL-Lite}_{\\cal R}$ with defeasible axioms.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 16:18:06 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Bozzato", "Loris", ""], ["Eiter", "Thomas", ""], ["Serafini", "Luciano", ""]]}, {"id": "1905.09264", "submitter": "Sam Kriegman", "authors": "Sam Kriegman, Stephanie Walker, Dylan Shah, Michael Levin, Rebecca\n  Kramer-Bottiglio, Josh Bongard", "title": "Automated shapeshifting for function recovery in damaged robots", "comments": null, "journal-ref": "Proceedings of Robotics: Science and Systems (2019)", "doi": "10.15607/RSS.2019.XV.028", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A robot's mechanical parts routinely wear out from normal functioning and can\nbe lost to injury. For autonomous robots operating in isolated or hostile\nenvironments, repair from a human operator is often not possible. Thus, much\nwork has sought to automate damage recovery in robots. However, every case\nreported in the literature to date has accepted the damaged mechanical\nstructure as fixed, and focused on learning new ways to control it. Here we\nshow for the first time a robot that automatically recovers from unexpected\ndamage by deforming its resting mechanical structure without changing its\ncontrol policy. We found that, especially in the case of \"deep insult\", such as\nremoval of all four of the robot's legs, the damaged machine evolves shape\nchanges that not only recover the original level of function (locomotion) as\nbefore, but can in fact surpass the original level of performance (speed). This\nsuggests that shape change, instead of control readaptation, may be a better\nmethod to recover function after damage in some cases.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 17:50:40 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Kriegman", "Sam", ""], ["Walker", "Stephanie", ""], ["Shah", "Dylan", ""], ["Levin", "Michael", ""], ["Kramer-Bottiglio", "Rebecca", ""], ["Bongard", "Josh", ""]]}, {"id": "1905.09275", "submitter": "Nicholas Watters", "authors": "Nicholas Watters, Loic Matthey, Matko Bosnjak, Christopher P. Burgess,\n  Alexander Lerchner", "title": "COBRA: Data-Efficient Model-Based RL through Unsupervised Object\n  Discovery and Curiosity-Driven Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data efficiency and robustness to task-irrelevant perturbations are\nlong-standing challenges for deep reinforcement learning algorithms. Here we\nintroduce a modular approach to addressing these challenges in a continuous\ncontrol environment, without using hand-crafted or supervised information. Our\nCurious Object-Based seaRch Agent (COBRA) uses task-free intrinsically\nmotivated exploration and unsupervised learning to build object-based models of\nits environment and action space. Subsequently, it can learn a variety of tasks\nthrough model-based search in very few steps and excel on structured hold-out\ntests of policy robustness.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 17:59:32 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 10:36:39 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Watters", "Nicholas", ""], ["Matthey", "Loic", ""], ["Bosnjak", "Matko", ""], ["Burgess", "Christopher P.", ""], ["Lerchner", "Alexander", ""]]}, {"id": "1905.09334", "submitter": "Jonathan Binas", "authors": "Jonathan Binas, Sherjil Ozair, Yoshua Bengio", "title": "The Journey is the Reward: Unsupervised Learning of Influential\n  Trajectories", "comments": "ICML'19 ERL Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised exploration and representation learning become increasingly\nimportant when learning in diverse and sparse environments. The\ninformation-theoretic principle of empowerment formalizes an unsupervised\nexploration objective through an agent trying to maximize its influence on the\nfuture states of its environment. Previous approaches carry certain limitations\nin that they either do not employ closed-loop feedback or do not have an\ninternal state. As a consequence, a privileged final state is taken as an\ninfluence measure, rather than the full trajectory. We provide a model-free\nmethod which takes into account the whole trajectory while still offering the\nbenefits of option-based approaches. We successfully apply our approach to\nsettings with large action spaces, where discovery of meaningful action\nsequences is particularly difficult.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 19:18:39 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Binas", "Jonathan", ""], ["Ozair", "Sherjil", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1905.09340", "submitter": "Mohammad Kachuee Mr.", "authors": "Mohammad Kachuee, Kimmo Karkkainen, Orpaz Goldstein, Sajad Darabi,\n  Majid Sarrafzadeh", "title": "Generative Imputation and Stochastic Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many machine learning applications, we are faced with incomplete datasets.\nIn the literature, missing data imputation techniques have been mostly\nconcerned with filling missing values. However, the existence of missing values\nis synonymous with uncertainties not only over the distribution of missing\nvalues but also over target class assignments that require careful\nconsideration. In this paper, we propose a simple and effective method for\nimputing missing features and estimating the distribution of target assignments\ngiven incomplete data. In order to make imputations, we train a simple and\neffective generator network to generate imputations that a discriminator\nnetwork is tasked to distinguish. Following this, a predictor network is\ntrained using the imputed samples from the generator network to capture the\nclassification uncertainties and make predictions accordingly. The proposed\nmethod is evaluated on CIFAR-10 and MNIST image datasets as well as five\nreal-world tabular classification datasets, under different missingness rates\nand structures. Our experimental results show the effectiveness of the proposed\nmethod in generating imputations as well as providing estimates for the class\nuncertainties in a classification task when faced with missing values.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 19:29:46 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 03:24:52 GMT"}, {"version": "v3", "created": "Fri, 20 Dec 2019 00:38:38 GMT"}, {"version": "v4", "created": "Fri, 4 Sep 2020 04:44:09 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Kachuee", "Mohammad", ""], ["Karkkainen", "Kimmo", ""], ["Goldstein", "Orpaz", ""], ["Darabi", "Sajad", ""], ["Sarrafzadeh", "Majid", ""]]}, {"id": "1905.09342", "submitter": "Junhong Xu", "authors": "Junhong Xu, Kai Yin, Lantao Liu", "title": "Reachable Space Characterization of Markov Decision Processes with Time\n  Variability", "comments": "10 pages, 9 figures, 1 table, accepted by RSS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a solution to a time-varying variant of Markov Decision Processes\nwhich can be used to address decision-theoretic planning problems for\nautonomous systems operating in unstructured outdoor environments. We explore\nthe time variability property of the planning stochasticity and investigate the\nstate reachability, based on which we then develop an efficient iterative\nmethod that offers a good trade-off between solution optimality and time\ncomplexity. The reachability space is constructed by analyzing the means and\nvariances of states' reaching time in the future. We validate our algorithm\nthrough extensive simulations using ocean data, and the results show that our\nmethod achieves a great performance in terms of both solution quality and\ncomputing time.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 19:30:36 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 19:01:00 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Xu", "Junhong", ""], ["Yin", "Kai", ""], ["Liu", "Lantao", ""]]}, {"id": "1905.09355", "submitter": "Sandhya Saisubramanian", "authors": "Sandhya Saisubramanian and Shlomo Zilberstein", "title": "Minimizing the Negative Side Effects of Planning with Reduced Models", "comments": "AAAI Workshop on Artificial Intelligence Safety (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reduced models of large Markov decision processes accelerate planning by\nconsidering a subset of outcomes for each state-action pair. This reduction in\nreachable states leads to replanning when the agent encounters states without a\nprecomputed action during plan execution. However, not all states are suitable\nfor replanning. In the worst case, the agent may not be able to reach the goal\nfrom the newly encountered state. Agents should be better prepared to handle\nsuch risky situations and avoid replanning in risky states. Hence, we consider\nreplanning in states that are unsafe for deliberation as a negative side effect\nof planning with reduced models. While the negative side effects can be\nminimized by always using the full model, this defeats the purpose of using\nreduced models. The challenge is to plan with reduced models, but somehow\naccount for the possibility of encountering risky situations. An agent should\nthus only replan in states that the user has approved as safe for replanning.\nTo that end, we propose planning using a portfolio of reduced models, a\nplanning paradigm that minimizes the negative side effects of planning using\nreduced models by alternating between different outcome selection approaches.\nWe empirically demonstrate the effectiveness of our approach on three domains:\nan electric vehicle charging domain using real-world data from a university\ncampus and two benchmark planning problems.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 20:36:28 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Saisubramanian", "Sandhya", ""], ["Zilberstein", "Shlomo", ""]]}, {"id": "1905.09381", "submitter": "Kaiyu Yang", "authors": "Kaiyu Yang, Jia Deng", "title": "Learning to Prove Theorems via Interacting with Proof Assistants", "comments": "Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans prove theorems by relying on substantial high-level reasoning and\nproblem-specific insights. Proof assistants offer a formalism that resembles\nhuman mathematical reasoning, representing theorems in higher-order logic and\nproofs as high-level tactics. However, human experts have to construct proofs\nmanually by entering tactics into the proof assistant. In this paper, we study\nthe problem of using machine learning to automate the interaction with proof\nassistants. We construct CoqGym, a large-scale dataset and learning environment\ncontaining 71K human-written proofs from 123 projects developed with the Coq\nproof assistant. We develop ASTactic, a deep learning-based model that\ngenerates tactics as programs in the form of abstract syntax trees (ASTs).\nExperiments show that ASTactic trained on CoqGym can generate effective tactics\nand can be used to prove new theorems not previously provable by automated\nmethods. Code is available at https://github.com/princeton-vl/CoqGym.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 17:56:02 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Yang", "Kaiyu", ""], ["Deng", "Jia", ""]]}, {"id": "1905.09397", "submitter": "David Bourgin", "authors": "David D. Bourgin, Joshua C. Peterson, Daniel Reichman, Thomas L.\n  Griffiths, Stuart J. Russell", "title": "Cognitive Model Priors for Predicting Human Decisions", "comments": "ICML 2019", "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, PMLR 97:5133-5141, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human decision-making underlies all economic behavior. For the past four\ndecades, human decision-making under uncertainty has continued to be explained\nby theoretical models based on prospect theory, a framework that was awarded\nthe Nobel Prize in Economic Sciences. However, theoretical models of this kind\nhave developed slowly, and robust, high-precision predictive models of human\ndecisions remain a challenge. While machine learning is a natural candidate for\nsolving these problems, it is currently unclear to what extent it can improve\npredictions obtained by current theories. We argue that this is mainly due to\ndata scarcity, since noisy human behavior requires massive sample sizes to be\naccurately captured by off-the-shelf machine learning methods. To solve this\nproblem, what is needed are machine learning models with appropriate inductive\nbiases for capturing human behavior, and larger datasets. We offer two\ncontributions towards this end: first, we construct \"cognitive model priors\" by\npretraining neural networks with synthetic data generated by cognitive models\n(i.e., theoretical models developed by cognitive psychologists). We find that\nfine-tuning these networks on small datasets of real human decisions results in\nunprecedented state-of-the-art improvements on two benchmark datasets. Second,\nwe present the first large-scale dataset for human decision-making, containing\nover 240,000 human judgments across over 13,000 decision problems. This dataset\nreveals the circumstances where cognitive model priors are useful, and provides\na new standard for benchmarking prediction of human decisions under\nuncertainty.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 23:05:53 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Bourgin", "David D.", ""], ["Peterson", "Joshua C.", ""], ["Reichman", "Daniel", ""], ["Griffiths", "Thomas L.", ""], ["Russell", "Stuart J.", ""]]}, {"id": "1905.09433", "submitter": "Tongwen Huang", "authors": "Tongwen Huang, Zhiqi Zhang, Junlin Zhang", "title": "FiBiNET: Combining Feature Importance and Bilinear feature Interaction\n  for Click-Through Rate Prediction", "comments": "8 pages,5 figures", "journal-ref": "ACM Conference on Recommender Systems (RecSys '19), September\n  16--20, 2019, Copenhagen, Denmark", "doi": "10.1145/3298689.3347043", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Advertising and feed ranking are essential to many Internet companies such as\nFacebook and Sina Weibo. Among many real-world advertising and feed ranking\nsystems, click through rate (CTR) prediction plays a central role. There are\nmany proposed models in this field such as logistic regression, tree based\nmodels, factorization machine based models and deep learning based CTR models.\nHowever, many current works calculate the feature interactions in a simple way\nsuch as Hadamard product and inner product and they care less about the\nimportance of features. In this paper, a new model named FiBiNET as an\nabbreviation for Feature Importance and Bilinear feature Interaction NETwork is\nproposed to dynamically learn the feature importance and fine-grained feature\ninteractions. On the one hand, the FiBiNET can dynamically learn the importance\nof features via the Squeeze-Excitation network (SENET) mechanism; on the other\nhand, it is able to effectively learn the feature interactions via bilinear\nfunction. We conduct extensive experiments on two real-world datasets and show\nthat our shallow model outperforms other shallow models such as factorization\nmachine(FM) and field-aware factorization machine(FFM). In order to improve\nperformance further, we combine a classical deep neural network(DNN) component\nwith the shallow model to be a deep model. The deep FiBiNET consistently\noutperforms the other state-of-the-art deep models such as DeepFM and extreme\ndeep factorization machine(XdeepFM).\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 02:10:17 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Huang", "Tongwen", ""], ["Zhang", "Zhiqi", ""], ["Zhang", "Junlin", ""]]}, {"id": "1905.09438", "submitter": "Alexander Long", "authors": "Alex Long, Joel Mason, Alan Blair, Wei Wang", "title": "Multi-hop Reading Comprehension via Deep Reinforcement Learning based\n  Document Traversal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reading Comprehension has received significant attention in recent years as\nhigh quality Question Answering (QA) datasets have become available. Despite\nstate-of-the-art methods achieving strong overall accuracy, Multi-Hop (MH)\nreasoning remains particularly challenging. To address MH-QA specifically, we\npropose a Deep Reinforcement Learning based method capable of learning\nsequential reasoning across large collections of documents so as to pass a\nquery-aware, fixed-size context subset to existing models for answer\nextraction. Our method is comprised of two stages: a linker, which decomposes\nthe provided support documents into a graph of sentences, and an extractor,\nwhich learns where to look based on the current question and already-visited\nsentences. The result of the linker is a novel graph structure at the sentence\nlevel that preserves logical flow while still allowing rapid movement between\ndocuments. Importantly, we demonstrate that the sparsity of the resultant graph\nis invariant to context size. This translates to fewer decisions required from\nthe Deep-RL trained extractor, allowing the system to scale effectively to\nlarge collections of documents.\n  The importance of sequential decision making in the document traversal step\nis demonstrated by comparison to standard IE methods, and we additionally\nintroduce a BM25-based IR baseline that retrieves documents relevant to the\nquery only. We examine the integration of our method with existing models on\nthe recently proposed QAngaroo benchmark and achieve consistent increases in\naccuracy across the board, as well as a 2-3x reduction in training time.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 02:32:34 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Long", "Alex", ""], ["Mason", "Joel", ""], ["Blair", "Alan", ""], ["Wang", "Wei", ""]]}, {"id": "1905.09447", "submitter": "Mengmi Zhang", "authors": "Mengmi Zhang, Tao Wang, Joo Hwee Lim, Gabriel Kreiman, Jiashi Feng", "title": "Variational Prototype Replays for Continual Learning", "comments": "under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning refers to the ability to acquire and transfer knowledge\nwithout catastrophically forgetting what was previously learned. In this work,\nwe consider \\emph{few-shot} continual learning in classification tasks, and we\npropose a novel method, Variational Prototype Replays, that efficiently\nconsolidates and recalls previous knowledge to avoid catastrophic forgetting.\nIn each classification task, our method learns a set of variational prototypes\nwith their means and variances, where embedding of the samples from the same\nclass can be represented in a prototypical distribution and\nclass-representative prototypes are separated apart. To alleviate catastrophic\nforgetting, our method replays one sample per class from previous tasks, and\ncorrespondingly matches newly predicted embeddings to their nearest\nclass-representative prototypes stored from previous tasks. Compared with\nrecent continual learning approaches, our method can readily adapt to new tasks\nwith more classes without requiring the addition of new units. Furthermore, our\nmethod is more memory efficient since only class-representative prototypes with\ntheir means and variances, as well as only one sample per class from previous\ntasks need to be stored. Without tampering with the performance on initial\ntasks, our method learns novel concepts given a few training examples of each\nclass in new tasks.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 03:25:33 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 19:20:05 GMT"}, {"version": "v3", "created": "Sat, 15 Feb 2020 05:54:07 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Zhang", "Mengmi", ""], ["Wang", "Tao", ""], ["Lim", "Joo Hwee", ""], ["Kreiman", "Gabriel", ""], ["Feng", "Jiashi", ""]]}, {"id": "1905.09509", "submitter": "Mert Ozer", "authors": "Mehmet Yigit Yildirim, Mert Ozer, Hasan Davulcu", "title": "Leveraging Uncertainty in Deep Learning for Selective Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wide and rapid adoption of deep learning by practitioners brought\nunintended consequences in many situations such as in the infamous case of\nGoogle Photos' racist image recognition algorithm; thus, necessitated the\nutilization of the quantified uncertainty for each prediction. There have been\nrecent efforts towards quantifying uncertainty in conventional deep learning\nmethods (e.g., dropout as Bayesian approximation); however, their optimal use\nin decision making is often overlooked and understudied. In this study, we\npropose a mixed-integer programming framework for classification with reject\noption (also known as selective classification), that investigates and combines\nmodel uncertainty and predictive mean to identify optimal classification and\nrejection regions. Our results indicate superior performance of our framework\nboth in non-rejected accuracy and rejection quality on several publicly\navailable datasets. Moreover, we extend our framework to cost-sensitive\nsettings and show that our approach outperforms industry standard methods\nsignificantly for online fraud management in real-world settings.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 07:28:36 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Yildirim", "Mehmet Yigit", ""], ["Ozer", "Mert", ""], ["Davulcu", "Hasan", ""]]}, {"id": "1905.09519", "submitter": "C. Maria Keet", "authors": "C Maria Keet", "title": "The African Wildlife Ontology tutorial ontologies: requirements, design,\n  and content", "comments": "8 pages, 2 figures; submitted to an international journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background. Most tutorial ontologies focus on illustrating one aspect of\nontology development, notably language features and automated reasoners, but\nignore ontology development factors, such as emergent modelling guidelines and\nontological principles. Yet, novices replicate examples from the exercises they\ncarry out. Not providing good examples holistically causes the propagation of\nsub-optimal ontology development, which may negatively affect the quality of a\nreal domain ontology. Results. We identified 22 requirements that a good\ntutorial ontology should satisfy regarding subject domain, logics and\nreasoning, and engineering aspects. We developed a set of ontologies about\nAfrican Wildlife to serve as tutorial ontologies. A majority of the\nrequirements have been met with the set of African Wildlife Ontology tutorial\nontologies, which are introduced in this paper. The African Wildlife Ontology\nis mature and has been used yearly in an ontology engineering course or\ntutorial since 2010 and is included in a recent ontology engineering textbook\nwith relevant examples and exercises. Conclusion. The African Wildlife Ontology\nprovides a wide range of options concerning examples and exercises for ontology\nengineering well beyond illustrating only language features and automated\nreasoning. It assists in demonstrating tasks about ontology quality, such as\nalignment to a foundational ontology and satisfying competency questions,\nversioning, and multilingual ontologies.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 07:59:30 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Keet", "C Maria", ""]]}, {"id": "1905.09557", "submitter": "Jinkui Yao", "authors": "Jinkui Yao and Lianghua Xu", "title": "Knowledge Graph Embedding Bi-Vector Models for Symmetric Relation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph embedding (KGE) models have been proposed to improve the\nperformance of knowledge graph reasoning. However, there is a general\nphenomenon in most of KGEs, as the training progresses, the symmetric relations\ntend to zero vector, if the symmetric triples ratio is high enough in the\ndataset. This phenomenon causes subsequent tasks, e.g. link prediction etc., of\nsymmetric relations to fail. The root cause of the problem is that KGEs do not\nutilize the semantic information of symmetric relations. We propose KGE\nbi-vector models, which represent the symmetric relations as vector pair,\nsignificantly increasing the processing capability of the symmetry relations.\nWe generate the benchmark datasets based on FB15k and WN18 by completing the\nsymmetric relation triples to verify models. The experiment results of our\nmodels clearly affirm the effectiveness and superiority of our models against\nbaseline.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 09:44:50 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Yao", "Jinkui", ""], ["Xu", "Lianghua", ""]]}, {"id": "1905.09565", "submitter": "Zarathustra Amadeus Goertzel", "authors": "Zarathustra Goertzel, Jan Jakub\\r{u}v, Josef Urban", "title": "ENIGMAWatch: ProofWatch Meets ENIGMA", "comments": "12 pages, 5 tables, 3 figures, submitted to TABLEAUX 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we describe a new learning-based proof guidance -- ENIGMAWatch\n-- for saturation-style first-order theorem provers. ENIGMAWatch combines two\nguiding approaches for the given-clause selection implemented for the E ATP\nsystem: ProofWatch and ENIGMA. ProofWatch is motivated by the watchlist (hints)\nmethod and based on symbolic matching of multiple related proofs, while ENIGMA\nis based on statistical machine learning. The two methods are combined by using\nthe evolving information about symbolic proof matching as an additional\ninformation that characterizes the saturation-style proof search for the\nstatistical learning methods. The new system is experimentally evaluated on a\nlarge set of problems from the Mizar Library. We show that the added\nproof-matching information is considered important by the statistical machine\nlearners, and that it leads to improvements in E's Performance over ProofWatch\nand ENIGMA.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 10:05:55 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 13:07:32 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Goertzel", "Zarathustra", ""], ["Jakub\u016fv", "Jan", ""], ["Urban", "Josef", ""]]}, {"id": "1905.09568", "submitter": "Stephan Fahrenkrog-Petersen", "authors": "Stephan A. Fahrenkrog-Petersen, Niek Tax, Irene Teinemaa, Marlon\n  Dumas, Massimiliano de Leoni, Fabrizio Maria Maggi, Matthias Weidlich", "title": "Fire Now, Fire Later: Alarm-Based Systems for Prescriptive Process\n  Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive process monitoring is a family of techniques to analyze events\nproduced during the execution of a business process in order to predict the\nfuture state or the final outcome of running process instances. Existing\ntechniques in this field are able to predict, at each step of a process\ninstance, the likelihood that it will lead to an undesired outcome.These\ntechniques, however, focus on generating predictions and do not prescribe when\nand how process workers should intervene to decrease the cost of undesired\noutcomes. This paper proposes a framework for prescriptive process monitoring,\nwhich extends predictive monitoring with the ability to generate alarms that\ntrigger interventions to prevent an undesired outcome or mitigate its effect.\nThe framework incorporates a parameterized cost model to assess the\ncost-benefit trade-off of generating alarms. We show how to optimize the\ngeneration of alarms given an event log of past process executions and a set of\ncost model parameters. The proposed approaches are empirically evaluated using\na range of real-life event logs. The experimental results show that the net\ncost of undesired outcomes can be minimized by changing the threshold for\ngenerating alarms, as the process instance progresses. Moreover, introducing\ndelays for triggering alarms, instead of triggering them as soon as the\nprobability of an undesired outcome exceeds a threshold, leads to lower net\ncosts.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 10:18:25 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 12:33:08 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Fahrenkrog-Petersen", "Stephan A.", ""], ["Tax", "Niek", ""], ["Teinemaa", "Irene", ""], ["Dumas", "Marlon", ""], ["de Leoni", "Massimiliano", ""], ["Maggi", "Fabrizio Maria", ""], ["Weidlich", "Matthias", ""]]}, {"id": "1905.09604", "submitter": "Dong Hao", "authors": "Bin Li, Dong Hao, Dengji Zhao, Makoto Yokoo", "title": "Diffusion and Auction on Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auction is the common paradigm for resource allocation which is a fundamental\nproblem in human society. Existing research indicates that the two primary\nobjectives, the seller's revenue and the allocation efficiency, are generally\nconflicting in auction design. For the first time, we expand the domain of the\nclassic auction to a social graph and formally identify a new class of auction\nmechanisms on graphs. All mechanisms in this class are incentive-compatible and\nalso promote all buyers to diffuse the auction information to others, whereby\nboth the seller's revenue and the allocation efficiency are significantly\nimproved comparing with the Vickrey auction. It is found that the recently\nproposed information diffusion mechanism is an extreme case with the lowest\nrevenue in this new class. Our work could potentially inspire a new perspective\nfor the efficient and optimal auction design and could be applied into the\nprevalent online social and economic networks.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 11:59:58 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 11:33:43 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Li", "Bin", ""], ["Hao", "Dong", ""], ["Zhao", "Dengji", ""], ["Yokoo", "Makoto", ""]]}, {"id": "1905.09610", "submitter": "Lu\\'is Cruz-Filipe", "authors": "Lu\\'is Cruz-Filipe, Gra\\c{c}a Gaspar, Isabel Nunes", "title": "Hypothetical answers to continuous queries over data streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous queries over data streams may suffer from blocking operations\nand/or unbound wait, which may delay answers until some relevant input arrives\nthrough the data stream. These delays may turn answers, when they arrive,\nobsolete to users who sometimes have to make decisions with no help whatsoever.\nTherefore, it can be useful to provide hypothetical answers - \"given the\ncurrent information, it is possible that X will become true at time t\" -\ninstead of no information at all.\n  In this paper we present a semantics for queries and corresponding answers\nthat covers such hypothetical answers, together with an online algorithm for\nupdating the set of facts that are consistent with the currently available\ninformation.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 12:11:51 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 11:26:13 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Cruz-Filipe", "Lu\u00eds", ""], ["Gaspar", "Gra\u00e7a", ""], ["Nunes", "Isabel", ""]]}, {"id": "1905.09618", "submitter": "Christoph Salge", "authors": "Daniel Ashlock and Christoph Salge", "title": "Automatic Generation of Level Maps with the Do What's Possible\n  Representation", "comments": "8 pages, in proceedings of 2019 IEEE Conference on Games, COG 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic generation of level maps is a popular form of automatic content\ngeneration. In this study, a recently developed technique employing the {\\em do\nwhat's possible} representation is used to create open-ended level maps.\nGeneration of the map can continue indefinitely, yielding a highly scalable\nrepresentation. A parameter study is performed to find good parameters for the\nevolutionary algorithm used to locate high-quality map generators. Variations\non the technique are presented, demonstrating its versatility, and an\nalgorithmic variant is given that both improves performance and changes the\ncharacter of maps located. The ability of the map to adapt to different regions\nwhere the map is permitted to occupy space are also tested.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 12:33:11 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Ashlock", "Daniel", ""], ["Salge", "Christoph", ""]]}, {"id": "1905.09638", "submitter": "William Clements", "authors": "William R. Clements, Bastien Van Delft, Beno\\^it-Marie Robaglia, Reda\n  Bahi Slaoui, S\\'ebastien Toth", "title": "Estimating Risk and Uncertainty in Deep Reinforcement Learning", "comments": "Work presented at the ICML 2020 Workshop on Uncertainty and\n  Robustness in Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning agents are faced with two types of uncertainty.\nEpistemic uncertainty stems from limited data and is useful for exploration,\nwhereas aleatoric uncertainty arises from stochastic environments and must be\naccounted for in risk-sensitive applications. We highlight the challenges\ninvolved in simultaneously estimating both of them, and propose a framework for\ndisentangling and estimating these uncertainties on learned Q-values. We derive\nunbiased estimators of these uncertainties and introduce an uncertainty-aware\nDQN algorithm, which we show exhibits safe learning behavior and outperforms\nother DQN variants on the MinAtar testbed.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 13:13:56 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 12:42:57 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 14:51:03 GMT"}, {"version": "v4", "created": "Mon, 17 Feb 2020 15:09:22 GMT"}, {"version": "v5", "created": "Wed, 9 Sep 2020 15:44:27 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Clements", "William R.", ""], ["Van Delft", "Bastien", ""], ["Robaglia", "Beno\u00eet-Marie", ""], ["Slaoui", "Reda Bahi", ""], ["Toth", "S\u00e9bastien", ""]]}, {"id": "1905.09668", "submitter": "Domingo Esteban", "authors": "Domingo Esteban, Leonel Rozo, Darwin G. Caldwell", "title": "Hierarchical Reinforcement Learning for Concurrent Discovery of Compound\n  and Composable Policies", "comments": "Accepted to IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common strategy to deal with the expensive reinforcement learning (RL) of\ncomplex tasks is to decompose them into a collection of subtasks that are\nusually simpler to learn as well as reusable for new problems. However, when a\nrobot learns the policies for these subtasks, common approaches treat every\npolicy learning process separately. Therefore, all these individual\n(composable) policies need to be learned before tackling the learning process\nof the complex task through policies composition. Moreover, such composition of\nindividual policies is usually performed sequentially, which is not suitable\nfor tasks that require to perform the subtasks concurrently. In this paper, we\npropose to combine a set of composable Gaussian policies corresponding to these\nsubtasks using a set of activation vectors, resulting in a complex Gaussian\npolicy that is a function of the means and covariances matrices of the\ncomposable policies. Moreover, we propose an algorithm for learning both\ncompound and composable policies within the same learning process by exploiting\nthe off-policy data generated from the compound policy. The algorithm is built\non a maximum entropy RL approach to favor exploration during the learning\nprocess. The results of the experiments show that the experience collected with\nthe compound policy permits not only to solve the complex task but also to\nobtain useful composable policies that successfully perform in their\ncorresponding subtasks.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 14:08:35 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 17:29:20 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Esteban", "Domingo", ""], ["Rozo", "Leonel", ""], ["Caldwell", "Darwin G.", ""]]}, {"id": "1905.09673", "submitter": "Jivitesh Sharma", "authors": "Jivitesh Sharma, Per-Arne Andersen, Ole-Chrisoffer Granmo and Morten\n  Goodwin", "title": "Deep Q-Learning with Q-Matrix Transfer Learning for Novel Fire\n  Evacuation Environment", "comments": "21 pages, 14 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We focus on the important problem of emergency evacuation, which clearly\ncould benefit from reinforcement learning that has been largely unaddressed.\nEmergency evacuation is a complex task which is difficult to solve with\nreinforcement learning, since an emergency situation is highly dynamic, with a\nlot of changing variables and complex constraints that makes it difficult to\ntrain on. In this paper, we propose the first fire evacuation environment to\ntrain reinforcement learning agents for evacuation planning. The environment is\nmodelled as a graph capturing the building structure. It consists of realistic\nfeatures like fire spread, uncertainty and bottlenecks. We have implemented the\nenvironment in the OpenAI gym format, to facilitate future research. We also\npropose a new reinforcement learning approach that entails pretraining the\nnetwork weights of a DQN based agents to incorporate information on the\nshortest path to the exit. We achieved this by using tabular Q-learning to\nlearn the shortest path on the building model's graph. This information is\ntransferred to the network by deliberately overfitting it on the Q-matrix.\nThen, the pretrained DQN model is trained on the fire evacuation environment to\ngenerate the optimal evacuation path under time varying conditions. We perform\ncomparisons of the proposed approach with state-of-the-art reinforcement\nlearning algorithms like PPO, VPG, SARSA, A2C and ACKTR. The results show that\nour method is able to outperform state-of-the-art models by a huge margin\nincluding the original DQN based models. Finally, we test our model on a large\nand complex real building consisting of 91 rooms, with the possibility to move\nto any other room, hence giving 8281 actions. We use an attention based\nmechanism to deal with large action spaces. Our model achieves near optimal\nperformance on the real world emergency environment.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 14:15:51 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 16:35:23 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Sharma", "Jivitesh", ""], ["Andersen", "Per-Arne", ""], ["Granmo", "Ole-Chrisoffer", ""], ["Goodwin", "Morten", ""]]}, {"id": "1905.09683", "submitter": "Manfred Eppe", "authors": "Manfred Eppe, Phuong D.H. Nguyen, Stefan Wermter", "title": "From semantics to execution: Integrating action planning with\n  reinforcement learning for robotic causal problem-solving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is an appropriate and successful method to robustly\nperform low-level robot control under noisy conditions. Symbolic action\nplanning is useful to resolve causal dependencies and to break a causally\ncomplex problem down into a sequence of simpler high-level actions. A problem\nwith the integration of both approaches is that action planning is based on\ndiscrete high-level action- and state spaces, whereas reinforcement learning is\nusually driven by a continuous reward function. However, recent advances in\nreinforcement learning, specifically, universal value function approximators\nand hindsight experience replay, have focused on goal-independent methods based\non sparse rewards. In this article, we build on these novel methods to\nfacilitate the integration of action planning with reinforcement learning by\nexploiting the reward-sparsity as a bridge between the high-level and low-level\nstate- and control spaces. As a result, we demonstrate that the integrated\nneuro-symbolic method is able to solve object manipulation problems that\ninvolve tool use and non-trivial causal dependencies under noisy conditions,\nexploiting both data and knowledge.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 14:34:38 GMT"}, {"version": "v2", "created": "Sun, 8 Dec 2019 14:15:02 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Eppe", "Manfred", ""], ["Nguyen", "Phuong D. H.", ""], ["Wermter", "Stefan", ""]]}, {"id": "1905.09688", "submitter": "Ole-Christoffer Granmo", "authors": "Ole-Christoffer Granmo and Sondre Glimsdal and Lei Jiao and Morten\n  Goodwin and Christian W. Omlin and Geir Thore Berge", "title": "The Convolutional Tsetlin Machine", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have obtained astounding successes for\nimportant pattern recognition tasks, but they suffer from high computational\ncomplexity and the lack of interpretability. The recent Tsetlin Machine (TM)\nattempts to address this lack by using easy-to-interpret conjunctive clauses in\npropositional logic to solve complex pattern recognition problems. The TM\nprovides competitive accuracy in several benchmarks, while keeping the\nimportant property of interpretability. It further facilitates hardware-near\nimplementation since inputs, patterns, and outputs are expressed as bits, while\nrecognition and learning rely on straightforward bit manipulation. In this\npaper, we exploit the TM paradigm by introducing the Convolutional Tsetlin\nMachine (CTM), as an interpretable alternative to CNNs. Whereas the TM\ncategorizes an image by employing each clause once to the whole image, the CTM\nuses each clause as a convolution filter. That is, a clause is evaluated\nmultiple times, once per image patch taking part in the convolution. To make\nthe clauses location-aware, each patch is further augmented with its\ncoordinates within the image. The output of a convolution clause is obtained\nsimply by ORing the outcome of evaluating the clause on each patch. In the\nlearning phase of the TM, clauses that evaluate to 1 are contrasted against the\ninput. For the CTM, we instead contrast against one of the patches, randomly\nselected among the patches that made the clause evaluate to 1. Accordingly, the\nstandard Type I and Type II feedback of the classic TM can be employed\ndirectly, without further modification. The CTM obtains a peak test accuracy of\n99.4% on MNIST, 96.31% on Kuzushiji-MNIST, 91.5% on Fashion-MNIST, and 100.0%\non the 2D Noisy XOR Problem, which is competitive with results reported for\nsimple 4-layer CNNs, BinaryConnect, Logistic Circuits and an FPGA-accelerated\nBinary CNN.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 14:47:33 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 06:51:38 GMT"}, {"version": "v3", "created": "Fri, 6 Sep 2019 16:10:14 GMT"}, {"version": "v4", "created": "Mon, 23 Dec 2019 01:33:09 GMT"}, {"version": "v5", "created": "Fri, 27 Dec 2019 11:25:56 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Granmo", "Ole-Christoffer", ""], ["Glimsdal", "Sondre", ""], ["Jiao", "Lei", ""], ["Goodwin", "Morten", ""], ["Omlin", "Christian W.", ""], ["Berge", "Geir Thore", ""]]}, {"id": "1905.09730", "submitter": "Cristian Ivan", "authors": "Cristian Ivan, Bipin Indurkhya", "title": "On modelling the emergence of logical thinking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in machine learning techniques have revived interest in\nbuilding artificial general intelligence using these particular tools. There\nhas been a tremendous success in applying them for narrow intellectual tasks\nsuch as pattern recognition, natural language processing and playing Go. The\nlatter application vastly outperforms the strongest human player in recent\nyears. However, these tasks are formalized by people in such ways that it has\nbecome \"easy\" for automated recipes to find better solutions than humans do. In\nthe sense of John Searle's Chinese Room Argument, the computer playing Go does\nnot actually understand anything from the game. Thinking like a human mind\nrequires to go beyond the curve fitting paradigm of current systems. There is a\nfundamental limit to what they can achieve currently as only very specific\nproblem formalization can increase their performances in particular tasks. In\nthis paper, we argue than one of the most important aspects of the human mind\nis its capacity for logical thinking, which gives rise to many intellectual\nexpressions that differentiate us from animal brains. We propose to model the\nemergence of logical thinking based on Piaget's theory of cognitive\ndevelopment.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 15:46:13 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Ivan", "Cristian", ""], ["Indurkhya", "Bipin", ""]]}, {"id": "1905.09735", "submitter": "Blaise Yvert", "authors": "\\'Eric Fourneret and Blaise Yvert", "title": "Digital Normativity: A challenge for human subjectivization and free\n  will", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the past decade, artificial intelligence has demonstrated its efficiency\nin many different applications and a huge number of algorithms have become\ncentral and ubiquitous in our life. Their growing interest is essentially based\non their capability to synthesize and process large amounts of data, and to\nhelp humans making decisions in a world of increasing complexity. Yet, the\neffectiveness of algorithms in bringing more and more relevant recommendations\nto humans may start to compete with human-alone decisions based on values other\nthan pure efficacy. Here, we examine this tension in light of the emergence of\nseveral forms of digital normativity, and analyze how this normative role of AI\nmay influence the ability of humans to remain subject of their life. The advent\nof AI technology imposes a need to achieve a balance between concrete material\nprogress and progress of the mind to avoid any form of servitude. It has become\nessential that an ethical reflection accompany the current developments of\nintelligent algorithms beyond the sole question of their social acceptability.\nSuch reflection should be anchored where AI technologies are being developed as\nwell as in educational programs where their implications can be explained.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 15:53:21 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Fourneret", "\u00c9ric", ""], ["Yvert", "Blaise", ""]]}, {"id": "1905.09778", "submitter": "Ferdinando Fioretto", "authors": "Ferdinando Fioretto, Terrence W.K. Mak, Pascal Van Hentenryck", "title": "Privacy-Preserving Obfuscation of Critical Infrastructure Networks", "comments": "A version of this paper appears in the Proceedings of the\n  Twenty-Eighth International Joint Conference on Artificial Intelligence\n  (IJCAI-19), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper studies how to release data about a critical infrastructure network\n(e.g., the power network or a transportation network) without disclosing\nsensitive information that can be exploited by malevolent agents, while\npreserving the realism of the network. It proposes a novel obfuscation\nmechanism that combines several privacy-preserving building blocks with a\nbi-level optimization model to significantly improve accuracy. The obfuscation\nis evaluated for both realism and privacy properties on real energy and\ntransportation networks. Experimental results show the obfuscation mechanism\nsubstantially reduces the potential damage of an attack exploiting the released\ndata to harm the real network.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 17:05:17 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 14:17:24 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Fioretto", "Ferdinando", ""], ["Mak", "Terrence W. K.", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "1905.09796", "submitter": "Konstantin Klemmer", "authors": "Konstantin Klemmer, Adriano Koshiyama, Sebastian Flennerhag", "title": "Augmenting correlation structures in spatial data using deep generative\n  models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art deep learning methods have shown a remarkable capacity to\nmodel complex data domains, but struggle with geospatial data. In this paper,\nwe introduce SpaceGAN, a novel generative model for geospatial domains that\nlearns neighbourhood structures through spatial conditioning. We propose to\nenhance spatial representation beyond mere spatial coordinates, by conditioning\neach data point on feature vectors of its spatial neighbours, thus allowing for\na more flexible representation of the spatial structure. To overcome issues of\ntraining convergence, we employ a metric capturing the loss in local spatial\nautocorrelation between real and generated data as stopping criterion for\nSpaceGAN parametrization. This way, we ensure that the generator produces\nsynthetic samples faithful to the spatial patterns observed in the input.\nSpaceGAN is successfully applied for data augmentation and outperforms compared\nto other methods of synthetic spatial data generation. Finally, we propose an\nensemble learning framework for the geospatial domain, taking augmented\nSpaceGAN samples as training data for a set of ensemble learners. We\nempirically show the superiority of this approach over conventional ensemble\nlearning approaches and rivaling spatial data augmentation methods, using\nsynthetic and real-world prediction tasks. Our findings suggest that SpaceGAN\ncan be used as a tool for (1) artificially inflating sparse geospatial data and\n(2) improving generalization of geospatial models.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 17:39:23 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Klemmer", "Konstantin", ""], ["Koshiyama", "Adriano", ""], ["Flennerhag", "Sebastian", ""]]}, {"id": "1905.09855", "submitter": "Chen Tessler", "authors": "Chen Tessler, Guy Tennenholtz, Shie Mannor", "title": "Distributional Policy Optimization: An Alternative Approach for\n  Continuous Control", "comments": "Accepted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify a fundamental problem in policy gradient-based methods in\ncontinuous control. As policy gradient methods require the agent's underlying\nprobability distribution, they limit policy representation to parametric\ndistribution classes. We show that optimizing over such sets results in local\nmovement in the action space and thus convergence to sub-optimal solutions. We\nsuggest a novel distributional framework, able to represent arbitrary\ndistribution functions over the continuous action space. Using this framework,\nwe construct a generative scheme, trained using an off-policy actor-critic\nparadigm, which we call the Generative Actor Critic (GAC). Compared to policy\ngradient methods, GAC does not require knowledge of the underlying probability\ndistribution, thereby overcoming these limitations. Empirical evaluation shows\nthat our approach is comparable and often surpasses current state-of-the-art\nbaselines in continuous domains.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 18:22:06 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 13:26:45 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Tessler", "Chen", ""], ["Tennenholtz", "Guy", ""], ["Mannor", "Shie", ""]]}, {"id": "1905.09865", "submitter": "Long Ho", "authors": "Long V. Ho, Melissa D. Aczon, David Ledbetter, Randall Wetzel", "title": "Interpreting a Recurrent Neural Network's Predictions of ICU Mortality\n  Risk", "comments": null, "journal-ref": null, "doi": "10.1016/j.jbi.2021.103672", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deep learning has demonstrated success in many applications; however, their\nuse in healthcare has been limited due to the lack of transparency into how\nthey generate predictions. Algorithms such as Recurrent Neural Networks (RNNs)\nwhen applied to Electronic Medical Records (EMR) introduce additional barriers\nto transparency because of the sequential processing of the RNN and the\nmulti-modal nature of EMR data. This work seeks to improve transparency by: 1)\nintroducing Learned Binary Masks (LBM) as a method for identifying which EMR\nvariables contributed to an RNN model's risk of mortality (ROM) predictions for\ncritically ill children; and 2) applying KernelSHAP for the same purpose. Given\nan individual patient, LBM and KernelSHAP both generate an attribution matrix\nthat shows the contribution of each input feature to the RNN's sequence of\npredictions for that patient. Attribution matrices can be aggregated in many\nways to facilitate different levels of analysis of the RNN model and its\npredictions. Presented are three methods of aggregations and analyses: 1) over\nvolatile time periods within individual patient predictions, 2) over\npopulations of ICU patients sharing specific diagnoses, and 3) across the\ngeneral population of critically ill children.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 18:41:09 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 22:21:17 GMT"}, {"version": "v3", "created": "Mon, 6 Apr 2020 22:06:12 GMT"}, {"version": "v4", "created": "Tue, 12 Jan 2021 19:38:02 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Ho", "Long V.", ""], ["Aczon", "Melissa D.", ""], ["Ledbetter", "David", ""], ["Wetzel", "Randall", ""]]}, {"id": "1905.09876", "submitter": "Haidar Khan", "authors": "Haidar Khan, Lara Marcuse, B\\\"ulent Yener", "title": "Deep density ratio estimation for change point detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose new objective functions to train deep neural network\nbased density ratio estimators and apply it to a change point detection\nproblem. Existing methods use linear combinations of kernels to approximate the\ndensity ratio function by solving a convex constrained minimization problem.\nApproximating the density ratio function using a deep neural network requires\ndefining a suitable objective function to optimize. We formulate and compare\nobjective functions that can be minimized using gradient descent and show that\nthe network can effectively learn to approximate the density ratio function.\nUsing our deep density ratio estimation objective function results in better\nperformance on a seizure detection task than other (kernel and neural network\nbased) density ratio estimation methods and other window-based change point\ndetection algorithms. We also show that the method can still support other\nneural network architectures, such as convolutional networks.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 19:04:56 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Khan", "Haidar", ""], ["Marcuse", "Lara", ""], ["Yener", "B\u00fclent", ""]]}, {"id": "1905.09957", "submitter": "Jiefeng Chen", "authors": "Jiefeng Chen, Xi Wu, Vaibhav Rastogi, Yingyu Liang, Somesh Jha", "title": "Robust Attribution Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An emerging problem in trustworthy machine learning is to train models that\nproduce robust interpretations for their predictions. We take a step towards\nsolving this problem through the lens of axiomatic attribution of neural\nnetworks. Our theory is grounded in the recent work, Integrated Gradients (IG),\nin axiomatically attributing a neural network's output change to its input\nchange. We propose training objectives in classic robust optimization models to\nachieve robust IG attributions. Our objectives give principled generalizations\nof previous objectives designed for robust predictions, and they naturally\ndegenerate to classic soft-margin training for one-layer neural networks. We\nalso generalize previous theory and prove that the objectives for different\nrobust optimization models are closely related. Experiments demonstrate the\neffectiveness of our method, and also point to intriguing problems which hint\nat the need for better optimization techniques or better neural network\narchitectures for robust attribution training.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 22:35:41 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 17:04:59 GMT"}, {"version": "v3", "created": "Sat, 26 Oct 2019 20:19:08 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Chen", "Jiefeng", ""], ["Wu", "Xi", ""], ["Rastogi", "Vaibhav", ""], ["Liang", "Yingyu", ""], ["Jha", "Somesh", ""]]}, {"id": "1905.10006", "submitter": "Markus N Rabe", "authors": "Aditya Paliwal, Sarah Loos, Markus Rabe, Kshitij Bansal, Christian\n  Szegedy", "title": "Graph Representations for Higher-Order Logic and Theorem Proving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the first use of graph neural networks (GNNs) for\nhigher-order proof search and demonstrates that GNNs can improve upon\nstate-of-the-art results in this domain. Interactive, higher-order theorem\nprovers allow for the formalization of most mathematical theories and have been\nshown to pose a significant challenge for deep learning. Higher-order logic is\nhighly expressive and, even though it is well-structured with a clearly defined\ngrammar and semantics, there still remains no well-established method to\nconvert formulas into graph-based representations. In this paper, we consider\nseveral graphical representations of higher-order logic and evaluate them\nagainst the HOList benchmark for higher-order theorem proving.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 02:42:22 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 00:06:34 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Paliwal", "Aditya", ""], ["Loos", "Sarah", ""], ["Rabe", "Markus", ""], ["Bansal", "Kshitij", ""], ["Szegedy", "Christian", ""]]}, {"id": "1905.10027", "submitter": "Qi Cai", "authors": "Qi Cai, Zhuoran Yang, Jason D. Lee, Zhaoran Wang", "title": "Neural Temporal-Difference and Q-Learning Provably Converge to Global\n  Optima", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal-difference learning (TD), coupled with neural networks, is among the\nmost fundamental building blocks of deep reinforcement learning. However, due\nto the nonlinearity in value function approximation, such a coupling leads to\nnonconvexity and even divergence in optimization. As a result, the global\nconvergence of neural TD remains unclear. In this paper, we prove for the first\ntime that neural TD converges at a sublinear rate to the global optimum of the\nmean-squared projected Bellman error for policy evaluation. In particular, we\nshow how such global convergence is enabled by the overparametrization of\nneural networks, which also plays a vital role in the empirical success of\nneural TD. Beyond policy evaluation, we establish the global convergence of\nneural (soft) Q-learning, which is further connected to that of policy gradient\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 04:36:42 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 07:34:21 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Cai", "Qi", ""], ["Yang", "Zhuoran", ""], ["Lee", "Jason D.", ""], ["Wang", "Zhaoran", ""]]}, {"id": "1905.10033", "submitter": "Andrea Madotto Mr", "authors": "Zhaojiang Lin, Andrea Madotto, Chien-Sheng Wu, Pascale Fung", "title": "Personalizing Dialogue Agents via Meta-Learning", "comments": "Accepted in ACL 2019. Zhaojiang Lin* and Andrea Madotto* contributed\n  equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing personalized dialogue models use human designed persona descriptions\nto improve dialogue consistency. Collecting such descriptions from existing\ndialogues is expensive and requires hand-crafted feature designs. In this\npaper, we propose to extend Model-Agnostic Meta-Learning (MAML)(Finn et al.,\n2017) to personalized dialogue learning without using any persona descriptions.\nOur model learns to quickly adapt to new personas by leveraging only a few\ndialogue samples collected from the same user, which is fundamentally different\nfrom conditioning the response on the persona descriptions. Empirical results\non Persona-chat dataset (Zhang et al., 2018) indicate that our solution\noutperforms non-meta-learning baselines using automatic evaluation metrics, and\nin terms of human-evaluated fluency and consistency.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 05:01:14 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Lin", "Zhaojiang", ""], ["Madotto", "Andrea", ""], ["Wu", "Chien-Sheng", ""], ["Fung", "Pascale", ""]]}, {"id": "1905.10069", "submitter": "Lei Bai", "authors": "Lei Bai and Lina Yao and Salil.S Kanhere and Xianzhi Wang and Quan.Z\n  Sheng", "title": "STG2Seq: Spatial-temporal Graph to Sequence Model for Multi-step\n  Passenger Demand Forecasting", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-step passenger demand forecasting is a crucial task in on-demand\nvehicle sharing services. However, predicting passenger demand over multiple\ntime horizons is generally challenging due to the nonlinear and dynamic\nspatial-temporal dependencies. In this work, we propose to model multi-step\ncitywide passenger demand prediction based on a graph and use a hierarchical\ngraph convolutional structure to capture both spatial and temporal correlations\nsimultaneously. Our model consists of three parts: 1) a long-term encoder to\nencode historical passenger demands; 2) a short-term encoder to derive the\nnext-step prediction for generating multi-step prediction; 3) an\nattention-based output module to model the dynamic temporal and channel-wise\ninformation. Experiments on three real-world datasets show that our model\nconsistently outperforms many baseline methods and state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 07:24:09 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Bai", "Lei", ""], ["Yao", "Lina", ""], ["Kanhere", "Salil. S", ""], ["Wang", "Xianzhi", ""], ["Sheng", "Quan. Z", ""]]}, {"id": "1905.10083", "submitter": "Zhi Zhou", "authors": "Zhi Zhou, Xu Chen, En Li, Liekang Zeng, Ke Luo, Junshan Zhang", "title": "Edge Intelligence: Paving the Last Mile of Artificial Intelligence with\n  Edge Computing", "comments": "Zhi Zhou, Xu Chen, En Li, Liekang Zeng, Ke Luo, and Junshan Zhang,\n  \"Edge Intelligence: Paving the Last Mile of Artificial Intelligence with Edge\n  Computing,\" Proceedings of the IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the breakthroughs in deep learning, the recent years have witnessed a\nbooming of artificial intelligence (AI) applications and services, spanning\nfrom personal assistant to recommendation systems to video/audio surveillance.\nMore recently, with the proliferation of mobile computing and\nInternet-of-Things (IoT), billions of mobile and IoT devices are connected to\nthe Internet, generating zillions Bytes of data at the network edge. Driving by\nthis trend, there is an urgent need to push the AI frontiers to the network\nedge so as to fully unleash the potential of the edge big data. To meet this\ndemand, edge computing, an emerging paradigm that pushes computing tasks and\nservices from the network core to the network edge, has been widely recognized\nas a promising solution. The resulted new inter-discipline, edge AI or edge\nintelligence, is beginning to receive a tremendous amount of interest. However,\nresearch on edge intelligence is still in its infancy stage, and a dedicated\nvenue for exchanging the recent advances of edge intelligence is highly desired\nby both the computer system and artificial intelligence communities. To this\nend, we conduct a comprehensive survey of the recent research efforts on edge\nintelligence. Specifically, we first review the background and motivation for\nartificial intelligence running at the network edge. We then provide an\noverview of the overarching architectures, frameworks and emerging key\ntechnologies for deep learning model towards training/inference at the network\nedge. Finally, we discuss future research opportunities on edge intelligence.\nWe believe that this survey will elicit escalating attentions, stimulate\nfruitful discussions and inspire further research ideas on edge intelligence.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 08:19:05 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Zhou", "Zhi", ""], ["Chen", "Xu", ""], ["Li", "En", ""], ["Zeng", "Liekang", ""], ["Luo", "Ke", ""], ["Zhang", "Junshan", ""]]}, {"id": "1905.10085", "submitter": "Junyu Gao", "authors": "Junyu Gao, Qi Wang, Xuelong Li", "title": "PCC Net: Perspective Crowd Counting via Spatial Convolutional Network", "comments": "accepted by IEEE T-CSVT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowd counting from a single image is a challenging task due to high\nappearance similarity, perspective changes and severe congestion. Many methods\nonly focus on the local appearance features and they cannot handle the\naforementioned challenges. In order to tackle them, we propose a Perspective\nCrowd Counting Network (PCC Net), which consists of three parts: 1) Density Map\nEstimation (DME) focuses on learning very local features for density map\nestimation; 2) Random High-level Density Classification (R-HDC) extracts global\nfeatures to predict the coarse density labels of random patches in images; 3)\nFore-/Background Segmentation (FBS) encodes mid-level features to segments the\nforeground and background. Besides, the DULR module is embedded in PCC Net to\nencode the perspective changes on four directions (Down, Up, Left and Right).\nThe proposed PCC Net is verified on five mainstream datasets, which achieves\nthe state-of-the-art performance on the one and attains the competitive results\non the other four datasets. The source code is available at\nhttps://github.com/gjy3035/PCC-Net.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 08:23:13 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Gao", "Junyu", ""], ["Wang", "Qi", ""], ["Li", "Xuelong", ""]]}, {"id": "1905.10090", "submitter": "Fabio Baruffa", "authors": "David Brayford, Sofia Vallecorsa, Atanas Atanasov, Fabio Baruffa,\n  Walter Riviera", "title": "Deploying AI Frameworks on Secure HPC Systems with Containers", "comments": "6 pages, 2 figures, 2019 IEEE High Performance Extreme Computing\n  Conference", "journal-ref": null, "doi": "10.1109/HPEC.2019.8916576", "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing interest in the usage of Artificial Intelligence techniques\n(AI) from the research community and industry to tackle \"real world\" problems,\nrequires High Performance Computing (HPC) resources to efficiently compute and\nscale complex algorithms across thousands of nodes. Unfortunately, typical data\nscientists are not familiar with the unique requirements and characteristics of\nHPC environments. They usually develop their applications with high-level\nscripting languages or frameworks such as TensorFlow and the installation\nprocess often requires connection to external systems to download open source\nsoftware during the build. HPC environments, on the other hand, are often based\non closed source applications that incorporate parallel and distributed\ncomputing API's such as MPI and OpenMP, while users have restricted\nadministrator privileges, and face security restrictions such as not allowing\naccess to external systems. In this paper we discuss the issues associated with\nthe deployment of AI frameworks in a secure HPC environment and how we\nsuccessfully deploy AI frameworks on SuperMUC-NG with Charliecloud.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 08:45:56 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Brayford", "David", ""], ["Vallecorsa", "Sofia", ""], ["Atanasov", "Atanas", ""], ["Baruffa", "Fabio", ""], ["Riviera", "Walter", ""]]}, {"id": "1905.10144", "submitter": "Refael Vivanti", "authors": "Refael Vivanti, Talya D. Sohlberg-Baris, Shlomo Cohen, Orna Cohen", "title": "Adaptive Symmetric Reward Noising for Reinforcement Learning", "comments": "9 pages, 7 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent reinforcement learning algorithms, though achieving impressive results\nin various fields, suffer from brittle training effects such as regression in\nresults and high sensitivity to initialization and parameters. We claim that\nsome of the brittleness stems from variance differences, i.e. when different\nenvironment areas - states and/or actions - have different rewards variance.\nThis causes two problems: First, the \"Boring Areas Trap\" in algorithms such as\nQ-learning, where moving between areas depends on the current area variance,\nand getting out of a boring area is hard due to its low variance. Second, the\n\"Manipulative Consultant\" problem, when value-estimation functions used in DQN\nand Actor-Critic algorithms influence the agent to prefer boring areas,\nregardless of the mean rewards return, as they maximize estimation precision\nrather than rewards. This sheds a new light on how exploration contribute to\ntraining, as it helps with both challenges. Cognitive experiments in humans\nshowed that noised reward signals may paradoxically improve performance. We\nexplain this using the two mentioned problems, claiming that both humans and\nalgorithms may share similar challenges. Inspired by this result, we propose\nthe Adaptive Symmetric Reward Noising (ASRN), by which we mean adding Gaussian\nnoise to rewards according to their states' estimated variance, thus avoiding\nthe two problems while not affecting the environment's mean rewards behavior.\nWe conduct our experiments in a Multi Armed Bandit problem with variance\ndifferences. We demonstrate that a Q-learning algorithm shows the brittleness\neffect in this problem, and that the ASRN scheme can dramatically improve the\nresults. We show that ASRN helps a DQN algorithm training process reach better\nresults in an end to end autonomous driving task using the AirSim driving\nsimulator.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 10:54:33 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Vivanti", "Refael", ""], ["Sohlberg-Baris", "Talya D.", ""], ["Cohen", "Shlomo", ""], ["Cohen", "Orna", ""]]}, {"id": "1905.10240", "submitter": "Yunpeng Li", "authors": "Yunpeng Li, Dominik Roblek, Marco Tagliasacchi", "title": "From Here to There: Video Inbetweening Using Direct 3D Convolutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of generating plausible and diverse video sequences,\nwhen we are only given a start and an end frame. This task is also known as\ninbetweening, and it belongs to the broader area of stochastic video\ngeneration, which is generally approached by means of recurrent neural networks\n(RNN). In this paper, we propose instead a fully convolutional model to\ngenerate video sequences directly in the pixel domain. We first obtain a latent\nvideo representation using a stochastic fusion mechanism that learns how to\nincorporate information from the start and end frames. Our model learns to\nproduce such latent representation by progressively increasing the temporal\nresolution, and then decode in the spatiotemporal domain using 3D convolutions.\nThe model is trained end-to-end by minimizing an adversarial loss. Experiments\non several widely-used benchmark datasets show that it is able to generate\nmeaningful and diverse in-between video sequences, according to both\nquantitative and qualitative evaluations.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 14:01:08 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 07:55:23 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 07:54:06 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Li", "Yunpeng", ""], ["Roblek", "Dominik", ""], ["Tagliasacchi", "Marco", ""]]}, {"id": "1905.10292", "submitter": "Simon Duque Anton", "authors": "Simon D. Duque Anton and Alexander Hafner and Hans Dieter Schotten", "title": "Devil in the Detail: Attack Scenarios in Industrial Applications", "comments": "Submitted and accepted at the 2019 IEEE Workshop on the Internet of\n  Safe Things", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past years, industrial networks have become increasingly\ninterconnected and opened to private or public networks. This leads to an\nincrease in efficiency and manageability, but also increases the attack\nsurface. Industrial networks often consist of legacy systems that have not been\ndesigned with security in mind. In the last decade, an increase in attacks on\ncyber-physical systems was observed, with drastic consequences on the physical\nwork. In this work, attack vectors on industrial networks are categorised. A\nreal-world process is simulated, attacks are then introduced. Finally, two\nmachine learning-based methods for time series anomaly detection are employed\nto detect the attacks. Matrix Profiles are employed more successfully than a\npredictor Long Short-Term Memory network, a class of neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 15:39:29 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Anton", "Simon D. Duque", ""], ["Hafner", "Alexander", ""], ["Schotten", "Hans Dieter", ""]]}, {"id": "1905.10309", "submitter": "Yanshan Wang", "authors": "Yanshan Wang, Yiqing Zhao, Terry M. Therneau, Elizabeth J. Atkinson,\n  Ahmad P. Tafti, Nan Zhang, Shreyasee Amin, Andrew H. Limper, Hongfang Liu", "title": "Unsupervised Machine Learning for the Discovery of Latent Disease\n  Clusters and Patient Subgroups Using Electronic Health Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has become ubiquitous and a key technology on mining\nelectronic health records (EHRs) for facilitating clinical research and\npractice. Unsupervised machine learning, as opposed to supervised learning, has\nshown promise in identifying novel patterns and relations from EHRs without\nusing human created labels. In this paper, we investigate the application of\nunsupervised machine learning models in discovering latent disease clusters and\npatient subgroups based on EHRs. We utilized Latent Dirichlet Allocation (LDA),\na generative probabilistic model, and proposed a novel model named Poisson\nDirichlet Model (PDM), which extends the LDA approach using a Poisson\ndistribution to model patients' disease diagnoses and to alleviate age and sex\nfactors by considering both observed and expected observations. In the\nempirical experiments, we evaluated LDA and PDM on three patient cohorts with\nEHR data retrieved from the Rochester Epidemiology Project (REP), for the\ndiscovery of latent disease clusters and patient subgroups. We compared the\neffectiveness of LDA and PDM in identifying latent disease clusters through the\nvisualization of disease representations learned by two approaches. We also\ntested the performance of LDA and PDM in differentiating patient subgroups\nthrough survival analysis, as well as statistical analysis. The experimental\nresults show that the proposed PDM could effectively identify distinguished\ndisease clusters by alleviating the impact of age and sex, and that LDA could\nstratify patients into more differentiable subgroups than PDM in terms of\np-values. However, the subgroups discovered by PDM might imply the underlying\npatterns of diseases of greater interest in epidemiology research due to the\nalleviation of age and sex. Both unsupervised machine learning approaches could\nbe leveraged to discover patient subgroups using EHRs but with different foci.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 20:07:22 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Wang", "Yanshan", ""], ["Zhao", "Yiqing", ""], ["Therneau", "Terry M.", ""], ["Atkinson", "Elizabeth J.", ""], ["Tafti", "Ahmad P.", ""], ["Zhang", "Nan", ""], ["Amin", "Shreyasee", ""], ["Limper", "Andrew H.", ""], ["Liu", "Hongfang", ""]]}, {"id": "1905.10404", "submitter": "Aadil Hayat", "authors": "Aadil Hayat, Utsav Singh, Vinay P. Namboodiri", "title": "InfoRL: Interpretable Reinforcement Learning using Information\n  Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in reinforcement learning have proved that given an\nenvironment we can learn to perform a task in that environment if we have\naccess to some form of a reward function (dense, sparse or derived from IRL).\nBut most of the algorithms focus on learning a single best policy to perform a\ngiven set of tasks. In this paper, we focus on an algorithm that learns to not\njust perform a task but different ways to perform the same task. As we know\nwhen the environment is complex enough there always exists multiple ways to\nperform a task. We show that using the concept of information maximization it\nis possible to learn latent codes for discovering multiple ways to perform any\ngiven task in an environment.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 18:47:09 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Hayat", "Aadil", ""], ["Singh", "Utsav", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "1905.10412", "submitter": "Numa Dhamani", "authors": "Numa Dhamani, Paul Azunre, Jeffrey L. Gleason, Craig Corcoran, Garrett\n  Honke, Steve Kramer, Jonathon Morgan", "title": "Using Deep Networks and Transfer Learning to Address Disinformation", "comments": "AI for Social Good Workshop at the International Conference on\n  Machine Learning, Long Beach, United States (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply an ensemble pipeline composed of a character-level convolutional\nneural network (CNN) and a long short-term memory (LSTM) as a general tool for\naddressing a range of disinformation problems. We also demonstrate the ability\nto use this architecture to transfer knowledge from labeled data in one domain\nto related (supervised and unsupervised) tasks. Character-level neural networks\nand transfer learning are particularly valuable tools in the disinformation\nspace because of the messy nature of social media, lack of labeled data, and\nthe multi-channel tactics of influence campaigns. We demonstrate their\neffectiveness in several tasks relevant for detecting disinformation: spam\nemails, review bombing, political sentiment, and conversation clustering.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 19:10:18 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Dhamani", "Numa", ""], ["Azunre", "Paul", ""], ["Gleason", "Jeffrey L.", ""], ["Corcoran", "Craig", ""], ["Honke", "Garrett", ""], ["Kramer", "Steve", ""], ["Morgan", "Jonathon", ""]]}, {"id": "1905.10417", "submitter": "Haitian Sun", "authors": "William W. Cohen, Haitian Sun, R. Alex Hofer, Matthew Siegler", "title": "Differentiable Representations For Multihop Inference Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present efficient differentiable implementations of second-order multi-hop\nreasoning using a large symbolic knowledge base (KB). We introduce a new\noperation which can be used to compositionally construct second-order multi-hop\ntemplates in a neural model, and evaluate a number of alternative\nimplementations, with different time and memory trade offs. These techniques\nscale to KBs with millions of entities and tens of millions of triples, and\nlead to simple models with competitive performance on several learning tasks\nrequiring multi-hop reasoning.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 19:20:03 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Cohen", "William W.", ""], ["Sun", "Haitian", ""], ["Hofer", "R. Alex", ""], ["Siegler", "Matthew", ""]]}, {"id": "1905.10425", "submitter": "Nikita Nangia", "authors": "Nikita Nangia and Samuel R. Bowman", "title": "Human vs. Muppet: A Conservative Estimate of Human Performance on the\n  GLUE Benchmark", "comments": null, "journal-ref": "ACL 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The GLUE benchmark (Wang et al., 2019b) is a suite of language understanding\ntasks which has seen dramatic progress in the past year, with average\nperformance moving from 70.0 at launch to 83.9, state of the art at the time of\nwriting (May 24, 2019). Here, we measure human performance on the benchmark, in\norder to learn whether significant headroom remains for further progress. We\nprovide a conservative estimate of human performance on the benchmark through\ncrowdsourcing: Our annotators are non-experts who must learn each task from a\nbrief set of instructions and 20 examples. In spite of limited training, these\nannotators robustly outperform the state of the art on six of the nine GLUE\ntasks and achieve an average score of 87.1. Given the fast pace of progress\nhowever, the headroom we observe is quite limited. To reproduce the data-poor\nsetting that our annotators must learn in, we also train the BERT model (Devlin\net al., 2019) in limited-data regimes, and conclude that low-resource sentence\nclassification remains a challenge for modern neural network approaches to text\nunderstanding.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 19:55:34 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 16:36:05 GMT"}, {"version": "v3", "created": "Sat, 1 Jun 2019 20:35:31 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Nangia", "Nikita", ""], ["Bowman", "Samuel R.", ""]]}, {"id": "1905.10490", "submitter": "Cleber Amaral Mr.", "authors": "Cleber Jorge Amaral, S\\'ergio Pereira Bernardes, Mateus\n  Concei\\c{c}\\~ao, Jomi Fred H\\\"ubner, Luis Pedro Arenhart Lampert, Ot\\'avio\n  Arruda Matoso, Maicon Rafael Zatelli", "title": "Finding new routes for integrating Multi-Agent Systems using Apache\n  Camel", "comments": "12 pages, 5 figures", "journal-ref": "Presented on Wesaac 2019 (Workshop-School on Agents, Environments,\n  and Applications) - https://gsigma.ufsc.br/wesaac2019/", "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In Multi-Agent Systems (MAS) there are two main models of interaction: among\nagents, and between agents and the environment. Although there are studies\nconsidering these models, there is no practical tool to afford the interaction\nwith external entities with both models. This paper presents a proposal for\nsuch a tool based on the Apache Camel framework by designing two new\ncomponents, namely camel-jason and camel-artifact. By means of these\ncomponents, an external entity is modelled according to its nature, i.e.,\nwhether it is autonomous or non-autonomous, interacting with the MAS\nrespectively as an agent or an artifact. It models coherently external entities\nwhereas Camel provides interoperability with several communication protocols.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 00:26:39 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Amaral", "Cleber Jorge", ""], ["Bernardes", "S\u00e9rgio Pereira", ""], ["Concei\u00e7\u00e3o", "Mateus", ""], ["H\u00fcbner", "Jomi Fred", ""], ["Lampert", "Luis Pedro Arenhart", ""], ["Matoso", "Ot\u00e1vio Arruda", ""], ["Zatelli", "Maicon Rafael", ""]]}, {"id": "1905.10501", "submitter": "Kshitij Bansal", "authors": "Kshitij Bansal, Christian Szegedy, Markus N. Rabe, Sarah M. Loos,\n  Viktor Toman", "title": "Learning to Reason in Large Theories without Imitation", "comments": "Major revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we demonstrate how to do automated theorem proving in the\npresence of a large knowledge base of potential premises without learning from\nhuman proofs. We suggest an exploration mechanism that mixes in additional\npremises selected by a tf-idf (term frequency-inverse document frequency) based\nlookup in a deep reinforcement learning scenario. This helps with exploring and\nlearning which premises are relevant for proving a new theorem. Our experiments\nshow that the theorem prover trained with this exploration mechanism\noutperforms provers that are trained only on human proofs. It approaches the\nperformance of a prover trained by a combination of imitation and reinforcement\nlearning. We perform multiple experiments to understand the importance of the\nunderlying assumptions that make our exploration approach work, thus explaining\nour design choices.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 02:36:25 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 21:53:06 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 23:20:59 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Bansal", "Kshitij", ""], ["Szegedy", "Christian", ""], ["Rabe", "Markus N.", ""], ["Loos", "Sarah M.", ""], ["Toman", "Viktor", ""]]}, {"id": "1905.10510", "submitter": "Chang Xiao", "authors": "Chang Xiao, Peilin Zhong and Changxi Zheng", "title": "Enhancing Adversarial Defense by k-Winners-Take-All", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple change to existing neural network structures for better\ndefending against gradient-based adversarial attacks. Instead of using popular\nactivation functions (such as ReLU), we advocate the use of k-Winners-Take-All\n(k-WTA) activation, a C0 discontinuous function that purposely invalidates the\nneural network model's gradient at densely distributed input data points. The\nproposed k-WTA activation can be readily used in nearly all existing networks\nand training methods with no significant overhead. Our proposal is\ntheoretically rationalized. We analyze why the discontinuities in k-WTA\nnetworks can largely prevent gradient-based search of adversarial examples and\nwhy they at the same time remain innocuous to the network training. This\nunderstanding is also empirically backed. We test k-WTA activation on various\nnetwork structures optimized by a training method, be it adversarial training\nor not. In all cases, the robustness of k-WTA networks outperforms that of\ntraditional networks under white-box attacks.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 03:36:40 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 20:14:15 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 00:27:18 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Xiao", "Chang", ""], ["Zhong", "Peilin", ""], ["Zheng", "Changxi", ""]]}, {"id": "1905.10517", "submitter": "Asaf Shabtai", "authors": "Yoni Birman, Shaked Hindi, Gilad Katz, Asaf Shabtai", "title": "Transferable Cost-Aware Security Policy Implementation for Malware\n  Detection Using Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware detection is an ever-present challenge for all organizational\ngatekeepers, who must maintain high detection rates while minimizing\ninterruptions to the organization's workflow. To improve detection rates,\norganizations often deploy an ensemble of detectors. While effective, this\napproach is computationally expensive, since every file - even clear-cut cases\n- needs to be analyzed by all detectors. Moreover, with an ever-increasing\nnumber of files to process, the use of ensembles may incur unacceptable\nprocessing times and costs (e.g., cloud resources). In this study, we propose\nSPIREL, a reinforcement learning-based method for cost-effective malware\ndetection. Our method enables organizations to directly associate costs to\ncorrect/incorrect classification, computing resources and run-time, and then\ndynamically establishes a security policy. This security policy is then\nimplemented, and for each inspected file, a different set of detectors is\nassigned and a different detection threshold is set. Our evaluation on two\nmalware domains- Portable Executable (PE) and Android Application Package\n(APK)files - shows that SPIREL is both accurate and extremely\nresource-efficient: the proposed method either outperforms the best performing\nbaselines while achieving a modest improvement in efficiency, or reduces the\nrequired running time by ~80% while decreasing the accuracy and F1-score by\nonly 0.5%. We also show that our approach is both highly transferable across\ndifferent datasets and adaptable to changes in individual detector performance.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 04:18:00 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 12:37:06 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Birman", "Yoni", ""], ["Hindi", "Shaked", ""], ["Katz", "Gilad", ""], ["Shabtai", "Asaf", ""]]}, {"id": "1905.10615", "submitter": "Adam Gleave", "authors": "Adam Gleave, Michael Dennis, Cody Wild, Neel Kant, Sergey Levine,\n  Stuart Russell", "title": "Adversarial Policies: Attacking Deep Reinforcement Learning", "comments": "Presented at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) policies are known to be vulnerable to\nadversarial perturbations to their observations, similar to adversarial\nexamples for classifiers. However, an attacker is not usually able to directly\nmodify another agent's observations. This might lead one to wonder: is it\npossible to attack an RL agent simply by choosing an adversarial policy acting\nin a multi-agent environment so as to create natural observations that are\nadversarial? We demonstrate the existence of adversarial policies in zero-sum\ngames between simulated humanoid robots with proprioceptive observations,\nagainst state-of-the-art victims trained via self-play to be robust to\nopponents. The adversarial policies reliably win against the victims but\ngenerate seemingly random and uncoordinated behavior. We find that these\npolicies are more successful in high-dimensional environments, and induce\nsubstantially different activations in the victim policy network than when the\nvictim plays against a normal opponent. Videos are available at\nhttps://adversarialpolicies.github.io/.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 15:23:19 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 19:54:47 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2021 19:25:56 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Gleave", "Adam", ""], ["Dennis", "Michael", ""], ["Wild", "Cody", ""], ["Kant", "Neel", ""], ["Levine", "Sergey", ""], ["Russell", "Stuart", ""]]}, {"id": "1905.10621", "submitter": "Jorge Fandinno", "authors": "Pedro Cabalar, Jorge Fandinno and Luis Fari\\~nas del Cerro", "title": "Dynamic Epistemic Logic with ASP Updates: Application to Conditional\n  Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Epistemic Logic (DEL) is a family of multimodal logics that has\nproved to be very successful for epistemic reasoning in planning tasks. In this\nlogic, the agent's knowledge is captured by modal epistemic operators whereas\nthe system evolution is described in terms of (some subset of) dynamic logic\nmodalities in which actions are usually represented as semantic objects called\nevent models. In this paper, we study a variant of DEL, that wecall DEL[ASP],\nwhere actions are syntactically described by using an Answer Set Programming\n(ASP) representation instead of event models. This representation directly\ninherits high level expressive features like indirect effects, qualifications,\nstate constraints, defaults, or recursive fluents that are common in ASP\ndescriptions of action domains. Besides, we illustrate how this approach can be\napplied for obtaining conditional plans in single-agent, partially observable\ndomains where knowledge acquisition may be represented as indirect effects of\nactions.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 15:52:13 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Cabalar", "Pedro", ""], ["Fandinno", "Jorge", ""], ["del Cerro", "Luis Fari\u00f1as", ""]]}, {"id": "1905.10625", "submitter": "Dongjun Wei", "authors": "Dongjun Wei and Yaxin Liu and Fuqing Zhu and Liangjun Zang and Wei\n  Zhou and Jizhong Han and Songlin Hu", "title": "ESA: Entity Summarization with Attention", "comments": "12pages, accepted in EYRE@CIKM'2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity summarization aims at creating brief but informative descriptions of\nentities from knowledge graphs. While previous work mostly focused on\ntraditional techniques such as clustering algorithms and graph models, we ask\nhow to apply deep learning methods into this task. In this paper we propose\nESA, a neural network with supervised attention mechanisms for entity\nsummarization. Specifically, we calculate attention weights for facts in each\nentity, and rank facts to generate reliable summaries. We explore techniques to\nsolve difficult learning problems presented by the ESA, and demonstrate the\neffectiveness of our model in comparison with the state-of-the-art methods.\nExperimental results show that our model improves the quality of the entity\nsummaries in both F-measure and MAP.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 16:06:42 GMT"}, {"version": "v2", "created": "Sun, 14 Jul 2019 00:50:53 GMT"}, {"version": "v3", "created": "Mon, 25 May 2020 09:17:55 GMT"}, {"version": "v4", "created": "Tue, 26 May 2020 01:06:47 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Wei", "Dongjun", ""], ["Liu", "Yaxin", ""], ["Zhu", "Fuqing", ""], ["Zang", "Liangjun", ""], ["Zhou", "Wei", ""], ["Han", "Jizhong", ""], ["Hu", "Songlin", ""]]}, {"id": "1905.10671", "submitter": "Zhongzhan Huang", "authors": "Zhongzhan Huang, Senwei Liang, Mingfu Liang, Haizhao Yang", "title": "DIANet: Dense-and-Implicit Attention Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention networks have successfully boosted the performance in various\nvision problems. Previous works lay emphasis on designing a new attention\nmodule and individually plug them into the networks. Our paper proposes a\nnovel-and-simple framework that shares an attention module throughout different\nnetwork layers to encourage the integration of layer-wise information and this\nparameter-sharing module is referred as Dense-and-Implicit-Attention (DIA)\nunit. Many choices of modules can be used in the DIA unit. Since Long Short\nTerm Memory (LSTM) has a capacity of capturing long-distance dependency, we\nfocus on the case when the DIA unit is the modified LSTM (refer as DIA-LSTM).\nExperiments on benchmark datasets show that the DIA-LSTM unit is capable of\nemphasizing layer-wise feature interrelation and leads to significant\nimprovement of image classification accuracy. We further empirically show that\nthe DIA-LSTM has a strong regularization ability on stabilizing the training of\ndeep networks by the experiments with the removal of skip connections or Batch\nNormalization in the whole residual network. The code is released at\nhttps://github.com/gbup-group/DIANet.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 20:51:07 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 08:23:50 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Huang", "Zhongzhan", ""], ["Liang", "Senwei", ""], ["Liang", "Mingfu", ""], ["Yang", "Haizhao", ""]]}, {"id": "1905.10672", "submitter": "Anagha Kulkarni", "authors": "Anagha Kulkarni, Siddharth Srivastava, Subbarao Kambhampati", "title": "Signaling Friends and Head-Faking Enemies Simultaneously: Balancing Goal\n  Obfuscation and Goal Legibility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to be useful in the real world, AI agents need to plan and act in\nthe presence of others, who may include adversarial and cooperative entities.\nIn this paper, we consider the problem where an autonomous agent needs to act\nin a manner that clarifies its objectives to cooperative entities while\npreventing adversarial entities from inferring those objectives. We show that\nthis problem is solvable when cooperative entities and adversarial entities use\ndifferent types of sensors and/or prior knowledge. We develop two new solution\napproaches for computing such plans. One approach provides an optimal solution\nto the problem by using an IP solver to provide maximum obfuscation for\nadversarial entities while providing maximum legibility for cooperative\nentities in the environment, whereas the other approach provides a satisficing\nsolution using heuristic-guided forward search to achieve preset levels of\nobfuscation and legibility for adversarial and cooperative entities\nrespectively. We show the feasibility and utility of our algorithms through\nextensive empirical evaluation on problems derived from planning benchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 20:56:07 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 00:06:56 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Kulkarni", "Anagha", ""], ["Srivastava", "Siddharth", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1905.10674", "submitter": "William L Hamilton", "authors": "Avishek Joey Bose, William L. Hamilton", "title": "Compositional Fairness Constraints for Graph Embeddings", "comments": "Proceedings of the 36th International Conference on Machine Learning,\n  Long Beach, California, PMLR 97, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Learning high-quality node embeddings is a key building block for machine\nlearning models that operate on graph data, such as social networks and\nrecommender systems. However, existing graph embedding techniques are unable to\ncope with fairness constraints, e.g., ensuring that the learned representations\ndo not correlate with certain attributes, such as age or gender. Here, we\nintroduce an adversarial framework to enforce fairness constraints on graph\nembeddings. Our approach is compositional---meaning that it can flexibly\naccommodate different combinations of fairness constraints during inference.\nFor instance, in the context of social recommendations, our framework would\nallow one user to request that their recommendations are invariant to both\ntheir age and gender, while also allowing another user to request invariance to\njust their age. Experiments on standard knowledge graph and recommender system\nbenchmarks highlight the utility of our proposed framework.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 21:13:27 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 22:20:27 GMT"}, {"version": "v3", "created": "Fri, 5 Jul 2019 16:42:35 GMT"}, {"version": "v4", "created": "Tue, 16 Jul 2019 22:11:21 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Bose", "Avishek Joey", ""], ["Hamilton", "William L.", ""]]}, {"id": "1905.10681", "submitter": "Ahmed Qureshi", "authors": "Ahmed H. Qureshi, Jacob J. Johnson, Yuzhe Qin, Taylor Henderson, Byron\n  Boots, Michael C. Yip", "title": "Composing Task-Agnostic Policies with Deep Reinforcement Learning", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The composition of elementary behaviors to solve challenging transfer\nlearning problems is one of the key elements in building intelligent machines.\nTo date, there has been plenty of work on learning task-specific policies or\nskills but almost no focus on composing necessary, task-agnostic skills to find\na solution to new problems. In this paper, we propose a novel deep\nreinforcement learning-based skill transfer and composition method that takes\nthe agent's primitive policies to solve unseen tasks. We evaluate our method in\ndifficult cases where training policy through standard reinforcement learning\n(RL) or even hierarchical RL is either not feasible or exhibits high sample\ncomplexity. We show that our method not only transfers skills to new problem\nsettings but also solves the challenging environments requiring both task\nplanning and motion control with high data efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 21:40:38 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2019 20:32:24 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Qureshi", "Ahmed H.", ""], ["Johnson", "Jacob J.", ""], ["Qin", "Yuzhe", ""], ["Henderson", "Taylor", ""], ["Boots", "Byron", ""], ["Yip", "Michael C.", ""]]}, {"id": "1905.10687", "submitter": "Jakob Kruse", "authors": "Jakob Kruse, Gianluca Detommaso, Ullrich K\\\"othe and Robert Scheichl", "title": "HINT: Hierarchical Invertible Neural Transport for Density Estimation\n  and Bayesian Inference", "comments": "Published at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent invertible neural architectures are based on coupling block\ndesigns where variables are divided in two subsets which serve as inputs of an\neasily invertible (usually affine) triangular transformation. While such a\ntransformation is invertible, its Jacobian is very sparse and thus may lack\nexpressiveness. This work presents a simple remedy by noting that subdivision\nand (affine) coupling can be repeated recursively within the resulting subsets,\nleading to an efficiently invertible block with dense, triangular Jacobian. By\nformulating our recursive coupling scheme via a hierarchical architecture, HINT\nallows sampling from a joint distribution p(y,x) and the corresponding\nposterior p(x|y) using a single invertible network. We evaluate our method on\nsome standard data sets and benchmark its full power for density estimation and\nBayesian inference on a novel data set of 2D shapes in Fourier\nparameterization, which enables consistent visualization of samples for\ndifferent dimensionalities.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 22:29:21 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 15:50:48 GMT"}, {"version": "v3", "created": "Thu, 5 Mar 2020 12:25:36 GMT"}, {"version": "v4", "created": "Tue, 25 May 2021 10:09:45 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Kruse", "Jakob", ""], ["Detommaso", "Gianluca", ""], ["K\u00f6the", "Ullrich", ""], ["Scheichl", "Robert", ""]]}, {"id": "1905.10700", "submitter": "Ziang Xiao", "authors": "Ziang Xiao, Michelle X. Zhou, Q. Vera Liao, Gloria Mark, Changyan Chi,\n  Wenxi Chen, and Huahai Yang", "title": "Tell Me About Yourself: Using an AI-Powered Chatbot to Conduct\n  Conversational Surveys with Open-ended Questions", "comments": "The paper is accepted by ACM Transactions on Computer-Human\n  Interaction (TOCHI)", "journal-ref": null, "doi": "10.1145/3381804", "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of increasingly more powerful chatbots offers a new way to collect\ninformation through conversational surveys, where a chatbot asks open-ended\nquestions, interprets a user's free-text responses, and probes answers whenever\nneeded. To investigate the effectiveness and limitations of such a chatbot in\nconducting surveys, we conducted a field study involving about 600\nparticipants. In this study with mostly open-ended questions, half of the\nparticipants took a typical online survey on Qualtrics and the other half\ninteracted with an AI-powered chatbot to complete a conversational survey. Our\ndetailed analysis of over 5200 free-text responses revealed that the chatbot\ndrove a significantly higher level of participant engagement and elicited\nsignificantly better quality responses measured by Gricean Maxims in terms of\ntheir informativeness, relevance, specificity, and clarity. Based on our\nresults, we discuss design implications for creating AI-powered chatbots to\nconduct effective surveys and beyond.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 23:46:29 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 00:07:09 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Xiao", "Ziang", ""], ["Zhou", "Michelle X.", ""], ["Liao", "Q. Vera", ""], ["Mark", "Gloria", ""], ["Chi", "Changyan", ""], ["Chen", "Wenxi", ""], ["Yang", "Huahai", ""]]}, {"id": "1905.10702", "submitter": "Afshin Sadeghi", "authors": "Afshin Sadeghi, Damien Graux, Hamed Shariat Yazdi, Jens Lehmann", "title": "MDE: Multiple Distance Embeddings for Link Prediction in Knowledge\n  Graphs", "comments": "Accepted paper in ECAI 2020", "journal-ref": "24th European Conference on Artificial Intelligence (ECAI), 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade, knowledge graphs became popular for capturing\nstructured domain knowledge. Relational learning models enable the prediction\nof missing links inside knowledge graphs. More specifically, latent distance\napproaches model the relationships among entities via a distance between latent\nrepresentations. Translating embedding models (e.g., TransE) are among the most\npopular latent distance approaches which use one distance function to learn\nmultiple relation patterns. However, they are mostly inefficient in capturing\nsymmetric relations since the representation vector norm for all the symmetric\nrelations becomes equal to zero. They also lose information when learning\nrelations with reflexive patterns since they become symmetric and transitive.\nWe propose the Multiple Distance Embedding model (MDE) that addresses these\nlimitations and a framework to collaboratively combine variant latent\ndistance-based terms. Our solution is based on two principles: 1) we use a\nlimit-based loss instead of a margin ranking loss and, 2) by learning\nindependent embedding vectors for each of the terms we can collectively train\nand predict using contradicting distance terms. We further demonstrate that MDE\nallows modeling relations with (anti)symmetry, inversion, and composition\npatterns. We propose MDE as a neural network model that allows us to map\nnon-linear relations between the embedding vectors and the expected output of\nthe score function. Our empirical results show that MDE performs competitively\nto state-of-the-art embedding models on several benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 23:48:00 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 10:36:32 GMT"}, {"version": "v3", "created": "Wed, 5 Jun 2019 17:19:34 GMT"}, {"version": "v4", "created": "Mon, 10 Jun 2019 20:57:08 GMT"}, {"version": "v5", "created": "Wed, 19 Jun 2019 18:38:58 GMT"}, {"version": "v6", "created": "Thu, 27 Jun 2019 12:40:11 GMT"}, {"version": "v7", "created": "Mon, 8 Jul 2019 11:54:43 GMT"}, {"version": "v8", "created": "Fri, 21 Feb 2020 13:09:08 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Sadeghi", "Afshin", ""], ["Graux", "Damien", ""], ["Yazdi", "Hamed Shariat", ""], ["Lehmann", "Jens", ""]]}, {"id": "1905.10710", "submitter": "Alexander Tong", "authors": "Alexander Tong, Guy Wolf, Smita Krishnaswamy", "title": "Fixing Bias in Reconstruction-based Anomaly Detection with Lipschitz\n  Discriminators", "comments": "6 pages, 4 figures, 2 tables, presented at IEEE MLSP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is of great interest in fields where abnormalities need to\nbe identified and corrected (e.g., medicine and finance). Deep learning methods\nfor this task often rely on autoencoder reconstruction error, sometimes in\nconjunction with other errors. We show that this approach exhibits intrinsic\nbiases that lead to undesirable results. Reconstruction-based methods are\nsensitive to training-data outliers and simple-to-reconstruct points. Instead,\nwe introduce a new unsupervised Lipschitz anomaly discriminator that does not\nsuffer from these biases. Our anomaly discriminator is trained, similar to the\nones used in GANs, to detect the difference between the training data and\ncorruptions of the training data. We show that this procedure successfully\ndetects unseen anomalies with guarantees on those that have a certain\nWasserstein distance from the data or corrupted training set. These additions\nallow us to show improved performance on MNIST, CIFAR10, and health record\ndata.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 01:57:42 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 21:20:55 GMT"}, {"version": "v3", "created": "Sun, 26 Jul 2020 13:49:41 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Tong", "Alexander", ""], ["Wolf", "Guy", ""], ["Krishnaswamy", "Smita", ""]]}, {"id": "1905.10714", "submitter": "Baojian Zhou", "authors": "Baojian Zhou, Feng Chen, Yiming Ying", "title": "Dual Averaging Method for Online Graph-structured Sparsity", "comments": "11 pages, 14 figures", "journal-ref": "The 25th ACM SIGKDD Conference on Knowledge Discovery and Data\n  Mining (KDD '19), August 4--8, 2019", "doi": "10.1145/3292500.3330915", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online learning algorithms update models via one sample per iteration, thus\nefficient to process large-scale datasets and useful to detect malicious events\nfor social benefits, such as disease outbreak and traffic congestion on the\nfly. However, existing algorithms for graph-structured models focused on the\noffline setting and the least square loss, incapable for online setting, while\nmethods designed for online setting cannot be directly applied to the problem\nof complex (usually non-convex) graph-structured sparsity model. To address\nthese limitations, in this paper we propose a new algorithm for\ngraph-structured sparsity constraint problems under online setting, which we\ncall \\textsc{GraphDA}. The key part in \\textsc{GraphDA} is to project both\naveraging gradient (in dual space) and primal variables (in primal space) onto\nlower dimensional subspaces, thus capturing the graph-structured sparsity\neffectively. Furthermore, the objective functions assumed here are generally\nconvex so as to handle different losses for online learning settings. To the\nbest of our knowledge, \\textsc{GraphDA} is the first online learning algorithm\nfor graph-structure constrained optimization problems. To validate our method,\nwe conduct extensive experiments on both benchmark graph and real-world graph\ndatasets. Our experiment results show that, compared to other baseline methods,\n\\textsc{GraphDA} not only improves classification performance, but also\nsuccessfully captures graph-structured features more effectively, hence\nstronger interpretability.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 02:42:16 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Zhou", "Baojian", ""], ["Chen", "Feng", ""], ["Ying", "Yiming", ""]]}, {"id": "1905.10792", "submitter": "Damien Anderson Mr", "authors": "Damien Anderson, Cristina Guerrero-Romero, Diego Perez-Liebana, Philip\n  Rodgers and John Levine", "title": "Ensemble Decision Systems for General Video Game Playing", "comments": "8 Pages, Accepted at COG2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble Decision Systems offer a unique form of decision making that allows\na collection of algorithms to reason together about a problem. Each individual\nalgorithm has its own inherent strengths and weaknesses, and often it is\ndifficult to overcome the weaknesses while retaining the strengths. Instead of\naltering the properties of the algorithm, the Ensemble Decision System augments\nthe performance with other algorithms that have complementing strengths. This\nwork outlines different options for building an Ensemble Decision System as\nwell as providing analysis on its performance compared to the individual\ncomponents of the system with interesting results, showing an increase in the\ngenerality of the algorithms without significantly impeding performance.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 12:11:37 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Anderson", "Damien", ""], ["Guerrero-Romero", "Cristina", ""], ["Perez-Liebana", "Diego", ""], ["Rodgers", "Philip", ""], ["Levine", "John", ""]]}, {"id": "1905.10793", "submitter": "Aron Monszpart", "authors": "S\\'ebastien Ehrhardt, Aron Monszpart, Niloy J. Mitra, Andrea Vedaldi", "title": "Unsupervised Intuitive Physics from Past Experiences", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in learning models of intuitive physics similar to the ones\nthat animals use for navigation, manipulation and planning. In addition to\nlearning general physical principles, however, we are also interested in\nlearning ``on the fly'', from a few experiences, physical properties specific\nto new environments. We do all this in an unsupervised manner, using a\nmeta-learning formulation where the goal is to predict videos containing\ndemonstrations of physical phenomena, such as objects moving and colliding with\na complex background. We introduce the idea of summarizing past experiences in\na very compact manner, in our case using dynamic images, and show that this can\nbe used to solve the problem well and efficiently. Empirically, we show via\nextensive experiments and ablation studies, that our model learns to perform\nphysical predictions that generalize well in time and space, as well as to a\nvariable number of interacting physical objects.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 12:22:56 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Ehrhardt", "S\u00e9bastien", ""], ["Monszpart", "Aron", ""], ["Mitra", "Niloy J.", ""], ["Vedaldi", "Andrea", ""]]}, {"id": "1905.10799", "submitter": "Weiyu Liu", "authors": "Weiyu Liu, Angel Daruna, Zsolt Kira and Sonia Chernova", "title": "Path Ranking with Attention to Type Hierarchies", "comments": "Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of the knowledge base completion problem is to infer missing\ninformation from existing facts in a knowledge base. Prior work has\ndemonstrated the effectiveness of path-ranking based methods, which solve the\nproblem by discovering observable patterns in knowledge graphs, consisting of\nnodes representing entities and edges representing relations. However, these\npatterns either lack accuracy because they rely solely on relations or cannot\neasily generalize due to the direct use of specific entity information. We\nintroduce Attentive Path Ranking, a novel path pattern representation that\nleverages type hierarchies of entities to both avoid ambiguity and maintain\ngeneralization. Then, we present an end-to-end trained attention-based RNN\nmodel to discover the new path patterns from data. Experiments conducted on\nbenchmark knowledge base completion datasets WN18RR and FB15k-237 demonstrate\nthat the proposed model outperforms existing methods on the fact prediction\ntask by statistically significant margins of 26% and 10%, respectively.\nFurthermore, quantitative and qualitative analyses show that the path patterns\nbalance between generalization and discrimination.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 12:57:47 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 18:18:20 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2019 17:34:15 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Liu", "Weiyu", ""], ["Daruna", "Angel", ""], ["Kira", "Zsolt", ""], ["Chernova", "Sonia", ""]]}, {"id": "1905.10819", "submitter": "Ellen Vitercik", "authors": "Maria-Florina Balcan, Tuomas Sandholm, and Ellen Vitercik", "title": "Learning to Optimize Computational Resources: Frugal Training with\n  Generalization Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms typically come with tunable parameters that have a considerable\nimpact on the computational resources they consume. Too often, practitioners\nmust hand-tune the parameters, a tedious and error-prone task. A recent line of\nresearch provides algorithms that return nearly-optimal parameters from within\na finite set. These algorithms can be used when the parameter space is infinite\nby providing as input a random sample of parameters. This data-independent\ndiscretization, however, might miss pockets of nearly-optimal parameters: prior\nresearch has presented scenarios where the only viable parameters lie within an\narbitrarily small region. We provide an algorithm that learns a finite set of\npromising parameters from within an infinite set. Our algorithm can help\ncompile a configuration portfolio, or it can be used to select the input to a\nconfiguration algorithm for finite parameter spaces. Our approach applies to\nany configuration problem that satisfies a simple yet ubiquitous structure: the\nalgorithm's performance is a piecewise constant function of its parameters.\nPrior research has exhibited this structure in domains from integer programming\nto clustering.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 15:43:50 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 14:41:01 GMT"}, {"version": "v3", "created": "Sat, 21 Nov 2020 00:59:08 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Balcan", "Maria-Florina", ""], ["Sandholm", "Tuomas", ""], ["Vitercik", "Ellen", ""]]}, {"id": "1905.10847", "submitter": "Yi Tay", "authors": "Yi Tay, Shuohang Wang, Luu Anh Tuan, Jie Fu, Minh C. Phan, Xingdi\n  Yuan, Jinfeng Rao, Siu Cheung Hui, Aston Zhang", "title": "Simple and Effective Curriculum Pointer-Generator Networks for Reading\n  Comprehension over Long Narratives", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tackles the problem of reading comprehension over long narratives\nwhere documents easily span over thousands of tokens. We propose a curriculum\nlearning (CL) based Pointer-Generator framework for reading/sampling over large\ndocuments, enabling diverse training of the neural model based on the notion of\nalternating contextual difficulty. This can be interpreted as a form of domain\nrandomization and/or generative pretraining during training. To this end, the\nusage of the Pointer-Generator softens the requirement of having the answer\nwithin the context, enabling us to construct diverse training samples for\nlearning. Additionally, we propose a new Introspective Alignment Layer (IAL),\nwhich reasons over decomposed alignments using block-based self-attention. We\nevaluate our proposed method on the NarrativeQA reading comprehension\nbenchmark, achieving state-of-the-art performance, improving existing baselines\nby $51\\%$ relative improvement on BLEU-4 and $17\\%$ relative improvement on\nRouge-L. Extensive ablations confirm the effectiveness of our proposed IAL and\nCL components.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 17:56:11 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Tay", "Yi", ""], ["Wang", "Shuohang", ""], ["Tuan", "Luu Anh", ""], ["Fu", "Jie", ""], ["Phan", "Minh C.", ""], ["Yuan", "Xingdi", ""], ["Rao", "Jinfeng", ""], ["Hui", "Siu Cheung", ""], ["Zhang", "Aston", ""]]}, {"id": "1905.10863", "submitter": "Maurizio Parton", "authors": "Francesco Morandin, Gianluca Amato, Marco Fantozzi, Rosa Gini, Carlo\n  Metta, Maurizio Parton", "title": "SAI: a Sensible Artificial Intelligence that plays with handicap and\n  targets high scores in 9x9 Go (extended version)", "comments": "Added Section 4.4 on minimization of suboptimal moves. Improved\n  Section 5 on future developments. Minor corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new model that can be applied to any perfect information\ntwo-player zero-sum game to target a high score, and thus a perfect play. We\nintegrate this model into the Monte Carlo tree search-policy iteration learning\npipeline introduced by Google DeepMind with AlphaGo. Training this model on 9x9\nGo produces a superhuman Go player, thus proving that it is stable and robust.\nWe show that this model can be used to effectively play with both positional\nand score handicap, and to minimize suboptimal moves. We develop a family of\nagents that can target high scores against any opponent, and recover from very\nsevere disadvantage against weak opponents. To the best of our knowledge, these\nare the first effective achievements in this direction.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 19:29:59 GMT"}, {"version": "v2", "created": "Sat, 22 Jun 2019 10:18:33 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2019 23:22:46 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Morandin", "Francesco", ""], ["Amato", "Gianluca", ""], ["Fantozzi", "Marco", ""], ["Gini", "Rosa", ""], ["Metta", "Carlo", ""], ["Parton", "Maurizio", ""]]}, {"id": "1905.10893", "submitter": "Shuhan Wang", "authors": "Shuhan Wang, Hao Wu, Ji Hun Kim and Erik Andersen", "title": "Adaptive Learning Material Recommendation in Online Language Education", "comments": "The short version of this paper is published at AIED 2019", "journal-ref": "The 20th International Conference on Artificial Intelligence in\n  Education (AIED), 2019", "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommending personalized learning materials for online language learning is\nchallenging because we typically lack data about the student's ability and the\nrelative difficulty of learning materials. This makes it hard to recommend\nappropriate content that matches the student's prior knowledge. In this paper,\nwe propose a refined hierarchical knowledge structure to model vocabulary\nknowledge, which enables us to automatically organize the authentic and\nup-to-date learning materials collected from the internet. Based on this\nknowledge structure, we then introduce a hybrid approach to recommend learning\nmaterials that adapts to a student's language level. We evaluate our work with\nan online Japanese learning tool and the results suggest adding adaptivity into\nmaterial recommendation significantly increases student engagement.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 21:59:49 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Wang", "Shuhan", ""], ["Wu", "Hao", ""], ["Kim", "Ji Hun", ""], ["Andersen", "Erik", ""]]}, {"id": "1905.10907", "submitter": "Douglas Rebstock", "authors": "Douglas Rebstock, Christopher Solinas, Michael Buro", "title": "Learning Policies from Human Data for Skat", "comments": "accepted by IEEE Conference on Games 2019 (CoG-2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision-making in large imperfect information games is difficult. Thanks to\nrecent success in Poker, Counterfactual Regret Minimization (CFR) methods have\nbeen at the forefront of research in these games. However, most of the success\nin large games comes with the use of a forward model and powerful state\nabstractions. In trick-taking card games like Bridge or Skat, large information\nsets and an inability to advance the simulation without fully determinizing the\nstate make forward search problematic. Furthermore, state abstractions can be\nespecially difficult to construct because the precise holdings of each player\ndirectly impact move values.\n  In this paper we explore learning model-free policies for Skat from human\ngame data using deep neural networks (DNN). We produce a new state-of-the-art\nsystem for bidding and game declaration by introducing methods to a) directly\nvary the aggressiveness of the bidder and b) declare games based on expected\nvalue while mitigating issues with rarely observed state-action pairs. Although\ncardplay policies learned through imitation are slightly weaker than the\ncurrent best search-based method, they run orders of magnitude faster. We also\nexplore how these policies could be learned directly from experience in a\nreinforcement learning setting and discuss the value of incorporating human\ndata for this task.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 00:05:44 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Rebstock", "Douglas", ""], ["Solinas", "Christopher", ""], ["Buro", "Michael", ""]]}, {"id": "1905.10911", "submitter": "Douglas Rebstock", "authors": "Douglas Rebstock, Christopher Solinas, Michael Buro, Nathan R.\n  Sturtevant", "title": "Policy Based Inference in Trick-Taking Card Games", "comments": "accepted to IEEE Conference on Games 2019 (CoG-2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trick-taking card games feature a large amount of private information that\nslowly gets revealed through a long sequence of actions. This makes the number\nof histories exponentially large in the action sequence length, as well as\ncreating extremely large information sets. As a result, these games become too\nlarge to solve. To deal with these issues many algorithms employ inference, the\nestimation of the probability of states within an information set. In this\npaper, we demonstrate a Policy Based Inference (PI) algorithm that uses player\nmodelling to infer the probability we are in a given state. We perform\nexperiments in the German trick-taking card game Skat, in which we show that\nthis method vastly improves the inference as compared to previous work, and\nincreases the performance of the state-of-the-art Skat AI system Kermit when it\nis employed into its determinized search algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 00:25:22 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Rebstock", "Douglas", ""], ["Solinas", "Christopher", ""], ["Buro", "Michael", ""], ["Sturtevant", "Nathan R.", ""]]}, {"id": "1905.10922", "submitter": "Anthony Young", "authors": "Anthony P. Young, David Kohan Marzagao and Josh Murphy", "title": "Applying Abstract Argumentation Theory to Cooperative Game Theory", "comments": "15 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply ideas from abstract argumentation theory to study cooperative game\ntheory. Building on Dung's results in his seminal paper, we further the\ncorrespondence between Dung's four argumentation semantics and solution\nconcepts in cooperative game theory by showing that complete extensions (the\ngrounded extension) correspond to Roth's subsolutions (respectively, the\nsupercore). We then investigate the relationship between well-founded\nargumentation frameworks and convex games, where in each case the semantics\n(respectively, solution concepts) coincide; we prove that three-player convex\ngames do not in general have well-founded argumentation frameworks.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 16:40:16 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 21:43:01 GMT"}, {"version": "v3", "created": "Fri, 3 Jan 2020 09:42:12 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Young", "Anthony P.", ""], ["Marzagao", "David Kohan", ""], ["Murphy", "Josh", ""]]}, {"id": "1905.10924", "submitter": "Andr\\'as Kornai", "authors": "Zalan Gyenis and Andras Kornai", "title": "Naive probability", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.HO cs.AI math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a rational, but low resolution model of probability.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 22:32:21 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Gyenis", "Zalan", ""], ["Kornai", "Andras", ""]]}, {"id": "1905.10957", "submitter": "Song Cheng", "authors": "Song Cheng and Qi Liu", "title": "Enhancing Item Response Theory for Cognitive Diagnosis", "comments": "Accepted by CIKM'2019. https://github.com/chsong513/DIRT", "journal-ref": null, "doi": "10.1145/3357384.3358070", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive diagnosis is a fundamental and crucial task in many educational\napplications, e.g., computer adaptive test and cognitive assignments. Item\nResponse Theory (IRT) is a classical cognitive diagnosis method which can\nprovide interpretable parameters (i.e., student latent trait, question\ndiscrimination, and difficulty) for analyzing student performance. However,\ntraditional IRT ignores the rich information in question texts, cannot diagnose\nknowledge concept proficiency, and it is inaccurate to diagnose the parameters\nfor the questions which only appear several times. To this end, in this paper,\nwe propose a general Deep Item Response Theory (DIRT) framework to enhance\ntraditional IRT for cognitive diagnosis by exploiting semantic representation\nfrom question texts with deep learning. In DIRT, we first use a proficiency\nvector to represent students' proficiency in knowledge concepts and embed\nquestion texts and knowledge concepts to dense vectors by Word2Vec. Then, we\ndesign a deep diagnosis module to diagnose parameters in traditional IRT by\ndeep learning techniques. Finally, with the diagnosed parameters, we input them\ninto the logistic-like formula of IRT to predict student performance. Extensive\nexperimental results on real-world data clearly demonstrate the effectiveness\nand interpretation power of DIRT framework.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 03:35:30 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 06:24:05 GMT"}, {"version": "v3", "created": "Sun, 1 Dec 2019 03:08:59 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Cheng", "Song", ""], ["Liu", "Qi", ""]]}, {"id": "1905.10958", "submitter": "Prashan Madumal", "authors": "Prashan Madumal, Tim Miller, Liz Sonenberg, Frank Vetere", "title": "Explainable Reinforcement Learning Through a Causal Lens", "comments": "Accepted to AAAI 2020 - full paper (oral) - main track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prevalent theories in cognitive science propose that humans understand and\nrepresent the knowledge of the world through causal relationships. In making\nsense of the world, we build causal models in our mind to encode cause-effect\nrelations of events and use these to explain why new events happen. In this\npaper, we use causal models to derive causal explanations of behaviour of\nreinforcement learning agents. We present an approach that learns a structural\ncausal model during reinforcement learning and encodes causal relationships\nbetween variables of interest. This model is then used to generate explanations\nof behaviour based on counterfactual analysis of the causal model. We report on\na study with 120 participants who observe agents playing a real-time strategy\ngame (Starcraft II) and then receive explanations of the agents' behaviour. We\ninvestigated: 1) participants' understanding gained by explanations through\ntask prediction; 2) explanation satisfaction and 3) trust. Our results show\nthat causal model explanations perform better on these measures compared to two\nother baseline explanation models.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 03:39:17 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 07:54:08 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Madumal", "Prashan", ""], ["Miller", "Tim", ""], ["Sonenberg", "Liz", ""], ["Vetere", "Frank", ""]]}, {"id": "1905.10982", "submitter": "Hazrat Ali", "authors": "Sulaiman Khan, Hazrat Ali, Zia Ullah, Mohammad Farhad Bulbul", "title": "An Intelligent Monitoring System of Vehicles on Highway Traffic", "comments": "5 pages", "journal-ref": "2018 12th International Conference on Open Source Systems and\n  Technologies (ICOSST), Lahore, Pakistan, 2018, pp. 71-75", "doi": "10.1109/ICOSST.2018.8632192", "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Vehicle speed monitoring and management of highways is the critical problem\nof the road in this modern age of growing technology and population. A poor\nmanagement results in frequent traffic jam, traffic rules violation and fatal\nroad accidents. Using traditional techniques of RADAR, LIDAR and LASAR to\naddress this problem is time-consuming, expensive and tedious. This paper\npresents an efficient framework to produce a simple, cost efficient and\nintelligent system for vehicle speed monitoring. The proposed method uses an HD\n(High Definition) camera mounted on the road side either on a pole or on a\ntraffic signal for recording video frames. On the basis of these frames, a\nvehicle can be tracked by using radius growing method, and its speed can be\ncalculated by calculating vehicle mask and its displacement in consecutive\nframes. The method uses pattern recognition, digital image processing and\nmathematical techniques for vehicle detection, tracking and speed calculation.\nThe validity of the proposed model is proved by testing it on different\nhighways.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 05:45:56 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Khan", "Sulaiman", ""], ["Ali", "Hazrat", ""], ["Ullah", "Zia", ""], ["Bulbul", "Mohammad Farhad", ""]]}, {"id": "1905.10985", "submitter": "Jeff Clune", "authors": "Jeff Clune", "title": "AI-GAs: AI-generating algorithms, an alternate paradigm for producing\n  general artificial intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perhaps the most ambitious scientific quest in human history is the creation\nof general artificial intelligence, which roughly means AI that is as smart or\nsmarter than humans. The dominant approach in the machine learning community is\nto attempt to discover each of the pieces required for intelligence, with the\nimplicit assumption that some future group will complete the Herculean task of\nfiguring out how to combine all of those pieces into a complex thinking\nmachine. I call this the \"manual AI approach\". This paper describes another\nexciting path that ultimately may be more successful at producing general AI.\nIt is based on the clear trend in machine learning that hand-designed solutions\neventually are replaced by more effective, learned solutions. The idea is to\ncreate an AI-generating algorithm (AI-GA), which automatically learns how to\nproduce general AI. Three Pillars are essential for the approach: (1)\nmeta-learning architectures, (2) meta-learning the learning algorithms\nthemselves, and (3) generating effective learning environments. I argue that\neither approach could produce general AI first, and both are scientifically\nworthwhile irrespective of which is the fastest path. Because both are\npromising, yet the ML community is currently committed to the manual approach,\nI argue that our community should increase its research investment in the AI-GA\napproach. To encourage such research, I describe promising work in each of the\nThree Pillars. I also discuss AI-GA-specific safety and ethical considerations.\nBecause it it may be the fastest path to general AI and because it is\ninherently scientifically interesting to understand the conditions in which a\nsimple algorithm can produce general AI (as happened on Earth where Darwinian\nevolution produced human intelligence), I argue that the pursuit of AI-GAs\nshould be considered a new grand challenge of computer science research.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 06:05:16 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2020 04:46:25 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Clune", "Jeff", ""]]}, {"id": "1905.10989", "submitter": "Simon Razniewski", "authors": "Julien Romero, Simon Razniewski, Koninika Pal, Jeff Z. Pan, Archit\n  Sakhadeo, Gerhard Weikum", "title": "Commonsense Properties from Query Logs and Question Answering Forums", "comments": "Updated appendix reporting on Quasimodo v4.3 (2/2021)", "journal-ref": "CIKM 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense knowledge about object properties, human behavior and general\nconcepts is crucial for robust AI applications. However, automatic acquisition\nof this knowledge is challenging because of sparseness and bias in online\nsources. This paper presents Quasimodo, a methodology and tool suite for\ndistilling commonsense properties from non-standard web sources. We devise\nnovel ways of tapping into search-engine query logs and QA forums, and\ncombining the resulting candidate assertions with statistical cues from\nencyclopedias, books and image tags in a corroboration step. Unlike prior work\non commonsense knowledge bases, Quasimodo focuses on salient properties that\nare typically associated with certain objects or concepts. Extensive\nevaluations, including extrinsic use-case studies, show that Quasimodo provides\nbetter coverage than state-of-the-art baselines with comparable quality.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 06:12:56 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 07:01:43 GMT"}, {"version": "v3", "created": "Mon, 2 Sep 2019 08:52:21 GMT"}, {"version": "v4", "created": "Wed, 10 Feb 2021 21:40:55 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Romero", "Julien", ""], ["Razniewski", "Simon", ""], ["Pal", "Koninika", ""], ["Pan", "Jeff Z.", ""], ["Sakhadeo", "Archit", ""], ["Weikum", "Gerhard", ""]]}, {"id": "1905.11011", "submitter": "Mihailo Jovanovic", "authors": "Hesameddin Mohammadi, Meisam Razaviyayn, Mihailo R. Jovanovi\\'c", "title": "Robustness of accelerated first-order algorithms for strongly convex\n  optimization problems", "comments": "45 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the robustness of accelerated first-order algorithms to stochastic\nuncertainties in gradient evaluation. Specifically, for unconstrained, smooth,\nstrongly convex optimization problems, we examine the mean-squared error in the\noptimization variable when the iterates are perturbed by additive white noise.\nThis type of uncertainty may arise in situations where an approximation of the\ngradient is sought through measurements of a real system or in a distributed\ncomputation over a network. Even though the underlying dynamics of first-order\nalgorithms for this class of problems are nonlinear, we establish upper bounds\non the mean-squared deviation from the optimal solution that are tight up to\nconstant factors. Our analysis quantifies fundamental trade-offs between noise\namplification and convergence rates obtained via any acceleration scheme\nsimilar to Nesterov's or heavy-ball methods. To gain additional analytical\ninsight, for strongly convex quadratic problems, we explicitly evaluate the\nsteady-state variance of the optimization variable in terms of the eigenvalues\nof the Hessian of the objective function. We demonstrate that the entire\nspectrum of the Hessian, rather than just the extreme eigenvalues, influence\nrobustness of noisy algorithms. We specialize this result to the problem of\ndistributed averaging over undirected networks and examine the role of network\nsize and topology on the robustness of noisy accelerated algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 07:19:13 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 05:04:02 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Mohammadi", "Hesameddin", ""], ["Razaviyayn", "Meisam", ""], ["Jovanovi\u0107", "Mihailo R.", ""]]}, {"id": "1905.11116", "submitter": "Hongyang Li", "authors": "Hongyang Li and David Eigen and Samuel Dodge and Matthew Zeiler and\n  Xiaogang Wang", "title": "Finding Task-Relevant Features for Few-Shot Learning by Category\n  Traversal", "comments": "CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Few-shot learning is an important area of research. Conceptually, humans are\nreadily able to understand new concepts given just a few examples, while in\nmore pragmatic terms, limited-example training situations are common in\npractice. Recent effective approaches to few-shot learning employ a\nmetric-learning framework to learn a feature similarity comparison between a\nquery (test) example, and the few support (training) examples. However, these\napproaches treat each support class independently from one another, never\nlooking at the entire task as a whole. Because of this, they are constrained to\nuse a single set of features for all possible test-time tasks, which hinders\nthe ability to distinguish the most relevant dimensions for the task at hand.\nIn this work, we introduce a Category Traversal Module that can be inserted as\na plug-and-play module into most metric-learning based few-shot learners. This\ncomponent traverses across the entire support set at once, identifying\ntask-relevant features based on both intra-class commonality and inter-class\nuniqueness in the feature space. Incorporating our module improves performance\nconsiderably (5%-10% relative) over baseline systems on both mini-ImageNet and\ntieredImageNet benchmarks, with overall performance competitive with recent\nstate-of-the-art systems.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 10:55:51 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Li", "Hongyang", ""], ["Eigen", "David", ""], ["Dodge", "Samuel", ""], ["Zeiler", "Matthew", ""], ["Wang", "Xiaogang", ""]]}, {"id": "1905.11169", "submitter": "Miguel Jaques", "authors": "Miguel Jaques, Michael Burke, Timothy Hospedales", "title": "Physics-as-Inverse-Graphics: Unsupervised Physical Parameter Estimation\n  from Video", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a model that is able to perform unsupervised physical parameter\nestimation of systems from video, where the differential equations governing\nthe scene dynamics are known, but labeled states or objects are not available.\nExisting physical scene understanding methods require either object state\nsupervision, or do not integrate with differentiable physics to learn\ninterpretable system parameters and states. We address this problem through a\nphysics-as-inverse-graphics approach that brings together\nvision-as-inverse-graphics and differentiable physics engines, enabling objects\nand explicit state and velocity representations to be discovered. This\nframework allows us to perform long term extrapolative video prediction, as\nwell as vision-based model-predictive control. Our approach significantly\noutperforms related unsupervised methods in long-term future frame prediction\nof systems with interacting objects (such as ball-spring or 3-body\ngravitational systems), due to its ability to build dynamics into the model as\nan inductive bias. We further show the value of this tight vision-physics\nintegration by demonstrating data-efficient learning of vision-actuated\nmodel-based control for a pendulum system. We also show that the controller's\ninterpretability provides unique capabilities in goal-driven control and\nphysical reasoning for zero-data adaptation.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 12:37:14 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 12:14:26 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Jaques", "Miguel", ""], ["Burke", "Michael", ""], ["Hospedales", "Timothy", ""]]}, {"id": "1905.11190", "submitter": "Amir-Hossein Karimi", "authors": "Amir-Hossein Karimi, Gilles Barthe, Borja Balle, Isabel Valera", "title": "Model-Agnostic Counterfactual Explanations for Consequential Decisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive models are being increasingly used to support consequential\ndecision making at the individual level in contexts such as pretrial bail and\nloan approval. As a result, there is increasing social and legal pressure to\nprovide explanations that help the affected individuals not only to understand\nwhy a prediction was output, but also how to act to obtain a desired outcome.\nTo this end, several works have proposed optimization-based methods to generate\nnearest counterfactual explanations. However, these methods are often\nrestricted to a particular subset of models (e.g., decision trees or linear\nmodels) and differentiable distance functions. In contrast, we build on\nstandard theory and tools from formal verification and propose a novel\nalgorithm that solves a sequence of satisfiability problems, where both the\ndistance function (objective) and predictive model (constraints) are\nrepresented as logic formulae. As shown by our experiments on real-world data,\nour algorithm is: i) model-agnostic ({non-}linear, {non-}differentiable,\n{non-}convex); ii) data-type-agnostic (heterogeneous features); iii)\ndistance-agnostic ($\\ell_0, \\ell_1, \\ell_\\infty$, and combinations thereof);\niv) able to generate plausible and diverse counterfactuals for any sample\n(i.e., 100% coverage); and v) at provably optimal distances.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 13:22:39 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 08:00:19 GMT"}, {"version": "v3", "created": "Tue, 8 Oct 2019 10:21:41 GMT"}, {"version": "v4", "created": "Fri, 14 Feb 2020 16:49:52 GMT"}, {"version": "v5", "created": "Fri, 28 Feb 2020 16:24:45 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Karimi", "Amir-Hossein", ""], ["Barthe", "Gilles", ""], ["Balle", "Borja", ""], ["Valera", "Isabel", ""]]}, {"id": "1905.11222", "submitter": "Elita Lobo", "authors": "Elita Lobo, Scott Jordan", "title": "Soft Options Critic", "comments": "In the current version of the paper, there is an error in the\n  definition of the value function, unintended text overlap in the environment\n  description, and incomplete experimentation. These changes will take a\n  significant amount of time to address. Thus, we are withdrawing the paper\n  until these changes can be implemented", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The option-critic architecture (Bacon, Harb, and Precup 2017) and several\nvariants have successfully demonstrated the use of the options framework\nproposed by Sutton et al (Sutton, Precup, and Singh1999) to scale learning and\nplanning in hierarchical tasks. Although most of these frameworks use entropy\nas a regularizer to improve exploration, they do not maximize entropy along\nwith returns at every time step. (Haarnoja et al., 2018d) recently introduced\nan off-policy actor critic algorithm in theSoft Actor Critic paper that\nmaximize returns while maximizing entropy in a constrained manner thus enabling\nlearning of robust options in continuous and discrete action spaces In this\npaper we adopt the architecture of soft-actor critic to investigate the effect\nof maximizing entropy of each options and inter-option policy in options\nframework. We derive the soft options improvement theorem and propose a novel\nsoft-options framework to incorporate maximization of entropy of actions and\noptions in a constrained manner. Our experiments show that the modified\noptions-critic framework generates robust policies which allows fast recovery\nwhen environment is subjected to perturbations and outperforms vanilla\noptions-critic framework in most hierarchical tasks\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 21:27:11 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 21:48:19 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Lobo", "Elita", ""], ["Jordan", "Scott", ""]]}, {"id": "1905.11229", "submitter": "Haoyan Liu", "authors": "Haoyan Liu, Yanming Liu, Ming Yang and Xiaoping Li", "title": "A Novel Demodulation and Estimation Algorithm for Blackout\n  Communication: Extract Principal Components with Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For reentry or near space communication, owing to the influence of the\ntime-varying plasma sheath channel environment, the received IQ baseband\nsignals are severely rotated on the constellation. Researches have shown that\nthe frequency of electron density varies from 20kHz to 100 kHz which is on the\nsame order as the symbol rate of most TT\\&C communication systems and a mass of\nbandwidth will be consumed to track the time-varying channel with traditional\nestimation. In this paper, motivated by principal curve analysis, we propose a\ndeep learning (DL) algorithm which called symmetric manifold network (SMN) to\nextract the curves on the constellation and classify the signals based on the\ncurves. The key advantage is that SMN can achieve joint optimization of\ndemodulation and channel estimation. From our simulation results, the new\nalgorithm significantly reduces the symbol error rate (SER) compared to\nexisting algorithms and enables accurate estimation of fading with extremely\nhigh bandwith utilization rate.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 13:56:49 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 05:07:41 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Liu", "Haoyan", ""], ["Liu", "Yanming", ""], ["Yang", "Ming", ""], ["Li", "Xiaoping", ""]]}, {"id": "1905.11259", "submitter": "Lu Chen", "authors": "Lu Chen, Zhi Chen, Bowen Tan, Sishan Long, Milica Gasic, Kai Yu", "title": "AgentGraph: Towards Universal Dialogue Management with Structured Deep\n  Reinforcement Learning", "comments": "14 pages, 8 figures; Accepted by IEEE/ACM TRANSACTIONS ON AUDIO,\n  SPEECH, AND LANGUAGE PROCESSING", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue policy plays an important role in task-oriented spoken dialogue\nsystems. It determines how to respond to users. The recently proposed deep\nreinforcement learning (DRL) approaches have been used for policy optimization.\nHowever, these deep models are still challenging for two reasons: 1) Many\nDRL-based policies are not sample-efficient. 2) Most models don't have the\ncapability of policy transfer between different domains. In this paper, we\npropose a universal framework, AgentGraph, to tackle these two problems. The\nproposed AgentGraph is the combination of GNN-based architecture and DRL-based\nalgorithm. It can be regarded as one of the multi-agent reinforcement learning\napproaches. Each agent corresponds to a node in a graph, which is defined\naccording to the dialogue domain ontology. When making a decision, each agent\ncan communicate with its neighbors on the graph. Under AgentGraph framework, we\nfurther propose Dual GNN-based dialogue policy, which implicitly decomposes the\ndecision in each turn into a high-level global decision and a low-level local\ndecision. Experiments show that AgentGraph models significantly outperform\ntraditional reinforcement learning approaches on most of the 18 tasks of the\nPyDial benchmark. Moreover, when transferred from the source task to a target\ntask, these models not only have acceptable initial performance but also\nconverge much faster on the target task.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 14:27:13 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Chen", "Lu", ""], ["Chen", "Zhi", ""], ["Tan", "Bowen", ""], ["Long", "Sishan", ""], ["Gasic", "Milica", ""], ["Yu", "Kai", ""]]}, {"id": "1905.11346", "submitter": "Alberto Pozanco", "authors": "Robert C. Holte, Ruben Majadas, Alberto Pozanco, Daniel Borrajo", "title": "Error Analysis and Correction for Weighted A*'s Suboptimality (Extended\n  Version)", "comments": "Published as a short paper in the 12th Annual Symposium on\n  Combinatorial Search, SoCS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weighted A* (wA*) is a widely used algorithm for rapidly, but suboptimally,\nsolving planning and search problems. The cost of the solution it produces is\nguaranteed to be at most W times the optimal solution cost, where W is the\nweight wA* uses in prioritizing open nodes. W is therefore a suboptimality\nbound for the solution produced by wA*. There is broad consensus that this\nbound is not very accurate, that the actual suboptimality of wA*'s solution is\noften much less than W times optimal. However, there is very little published\nevidence supporting that view, and no existing explanation of why W is a poor\nbound. This paper fills in these gaps in the literature. We begin with a\nlarge-scale experiment demonstrating that, across a wide variety of domains and\nheuristics for those domains, W is indeed very often far from the true\nsuboptimality of wA*'s solution. We then analytically identify the potential\nsources of error. Finally, we present a practical method for correcting for two\nof these sources of error and experimentally show that the correction\nfrequently eliminates much of the error.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 17:08:08 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 15:04:48 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Holte", "Robert C.", ""], ["Majadas", "Ruben", ""], ["Pozanco", "Alberto", ""], ["Borrajo", "Daniel", ""]]}, {"id": "1905.11358", "submitter": "Saumya Jetley", "authors": "Laurynas Miksys, Saumya Jetley, Michael Sapienza, Stuart Golodetz,\n  Philip H.S. Torr", "title": "Straight to Shapes++: Real-time Instance Segmentation Made More Accurate", "comments": "Technical report, 27 pages (12 main, 15 supplementary), 17 figures,\n  14 tables", "journal-ref": null, "doi": null, "report-no": "STS-2018", "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instance segmentation is an important problem in computer vision, with\napplications in autonomous driving, drone navigation and robotic manipulation.\nHowever, most existing methods are not real-time, complicating their deployment\nin time-sensitive contexts. In this work, we extend an existing approach to\nreal-time instance segmentation, called `Straight to Shapes' (STS), which makes\nuse of low-dimensional shape embedding spaces to directly regress to object\nshape masks. The STS model can run at 35 FPS on a high-end desktop, but its\naccuracy is significantly worse than that of offline state-of-the-art methods.\nWe leverage recent advances in the design and training of deep instance\nsegmentation models to improve the performance accuracy of the STS model whilst\nkeeping its real-time capabilities intact. In particular, we find that\nparameter sharing, more aggressive data augmentation and the use of structured\nloss for shape mask prediction all provide a useful boost to the network\nperformance. Our proposed approach, `Straight to Shapes++', achieves a\nremarkable 19.7 point improvement in mAP (at IOU of 0.5) over the original\nmethod as evaluated on the PASCAL VOC dataset, thus redefining the accuracy\nfrontier at real-time speeds. Since the accuracy of instance segmentation is\nclosely tied to that of object bounding box prediction, we also study the error\nprofile of the latter and examine the failure modes of our method for future\nimprovements.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 17:35:19 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 11:09:15 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Miksys", "Laurynas", ""], ["Jetley", "Saumya", ""], ["Sapienza", "Michael", ""], ["Golodetz", "Stuart", ""], ["Torr", "Philip H. S.", ""]]}, {"id": "1905.11369", "submitter": "Relja Arandjelovi\\'c", "authors": "Relja Arandjelovi\\'c, Andrew Zisserman", "title": "Object Discovery with a Copy-Pasting GAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of object discovery, where objects are segmented for a\ngiven input image, and the system is trained without using any direct\nsupervision whatsoever. A novel copy-pasting GAN framework is proposed, where\nthe generator learns to discover an object in one image by compositing it into\nanother image such that the discriminator cannot tell that the resulting image\nis fake. After carefully addressing subtle issues, such as preventing the\ngenerator from `cheating', this game results in the generator learning to\nselect objects, as copy-pasting objects is most likely to fool the\ndiscriminator. The system is shown to work well on four very different\ndatasets, including large object appearance variations in challenging cluttered\nbackgrounds.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 17:55:05 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Arandjelovi\u0107", "Relja", ""], ["Zisserman", "Andrew", ""]]}, {"id": "1905.11374", "submitter": "Adarsh Subbaswamy", "authors": "Adarsh Subbaswamy, Bryant Chen, Suchi Saria", "title": "A Universal Hierarchy of Shift-Stable Distributions and the Tradeoff\n  Between Stability and Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many methods which find invariant predictive distributions have been\ndeveloped to learn models that can generalize to new environments without using\nsamples from the target distribution. However, these methods consider differing\ntypes of shifts in environment and have been developed under disparate\nframeworks, making their comparison difficult. In this paper, we provide a\nunifying graphical representation of the data generating process that can\nrepresent all such shifts. We show there is a universal hierarchy of\nshift-stable distributions which correspond to operators on a graph that\ndisable edges. This provides the ability to compare current methods and derive\nnew algorithms that find optimal invariant distributions, all of which can be\nmapped to the hierarchy. We theoretically and empirically show that the degree\nto which stability is desirable depends on how concerned we are about large\nshifts: there is a tradeoff between stability and average performance.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 17:56:39 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 17:12:44 GMT"}, {"version": "v3", "created": "Wed, 16 Oct 2019 23:28:40 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Subbaswamy", "Adarsh", ""], ["Chen", "Bryant", ""], ["Saria", "Suchi", ""]]}, {"id": "1905.11382", "submitter": "Alex Lamb", "authors": "Alex Lamb, Jonathan Binas, Anirudh Goyal, Sandeep Subramanian, Ioannis\n  Mitliagkas, Denis Kazakov, Yoshua Bengio, Michael C. Mozer", "title": "State-Reification Networks: Improving Generalization by Modeling the\n  Distribution of Hidden Representations", "comments": "ICML 2019 [full oral]. arXiv admin note: text overlap with\n  arXiv:1805.08394", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning promises methods that generalize well from finite labeled\ndata. However, the brittleness of existing neural net approaches is revealed by\nnotable failures, such as the existence of adversarial examples that are\nmisclassified despite being nearly identical to a training example, or the\ninability of recurrent sequence-processing nets to stay on track without\nteacher forcing. We introduce a method, which we refer to as \\emph{state\nreification}, that involves modeling the distribution of hidden states over the\ntraining data and then projecting hidden states observed during testing toward\nthis distribution. Our intuition is that if the network can remain in a\nfamiliar manifold of hidden space, subsequent layers of the net should be well\ntrained to respond appropriately. We show that this state-reification method\nhelps neural nets to generalize better, especially when labeled data are\nsparse, and also helps overcome the challenge of achieving robust\ngeneralization with adversarial training.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 09:13:41 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Lamb", "Alex", ""], ["Binas", "Jonathan", ""], ["Goyal", "Anirudh", ""], ["Subramanian", "Sandeep", ""], ["Mitliagkas", "Ioannis", ""], ["Kazakov", "Denis", ""], ["Bengio", "Yoshua", ""], ["Mozer", "Michael C.", ""]]}, {"id": "1905.11393", "submitter": "Jin Zeng", "authors": "Mengyang Chen, Jin Zeng, and Jie Lou", "title": "A Self-Attention Joint Model for Spoken Language Understanding in\n  Situational Dialog Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spoken language understanding (SLU) acts as a critical component in\ngoal-oriented dialog systems. It typically involves identifying the speakers\nintent and extracting semantic slots from user utterances, which are known as\nintent detection (ID) and slot filling (SF). SLU problem has been intensively\ninvestigated in recent years. However, these methods just constrain SF results\ngrammatically, solve ID and SF independently, or do not fully utilize the\nmutual impact of the two tasks. This paper proposes a multi-head self-attention\njoint model with a conditional random field (CRF) layer and a prior mask. The\nexperiments show the effectiveness of our model, as compared with\nstate-of-the-art models. Meanwhile, online education in China has made great\nprogress in the last few years. But there are few intelligent educational\ndialog applications for students to learn foreign languages. Hence, we design\nan intelligent dialog robot equipped with different scenario settings to help\nstudents learn communication skills.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 10:22:20 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Chen", "Mengyang", ""], ["Zeng", "Jin", ""], ["Lou", "Jie", ""]]}, {"id": "1905.11471", "submitter": "Jasdeep Singh", "authors": "Jasdeep Singh, Bryan McCann, Nitish Shirish Keskar, Caiming Xiong,\n  Richard Socher", "title": "XLDA: Cross-Lingual Data Augmentation for Natural Language Inference and\n  Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While natural language processing systems often focus on a single language,\nmultilingual transfer learning has the potential to improve performance,\nespecially for low-resource languages. We introduce XLDA, cross-lingual data\naugmentation, a method that replaces a segment of the input text with its\ntranslation in another language. XLDA enhances performance of all 14 tested\nlanguages of the cross-lingual natural language inference (XNLI) benchmark.\nWith improvements of up to $4.8\\%$, training with XLDA achieves\nstate-of-the-art performance for Greek, Turkish, and Urdu. XLDA is in contrast\nto, and performs markedly better than, a more naive approach that aggregates\nexamples in various languages in a way that each example is solely in one\nlanguage. On the SQuAD question answering task, we see that XLDA provides a\n$1.0\\%$ performance increase on the English evaluation set. Comprehensive\nexperiments suggest that most languages are effective as cross-lingual\naugmentors, that XLDA is robust to a wide range of translation quality, and\nthat XLDA is even more effective for randomly initialized models than for\npretrained models.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 19:44:33 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Singh", "Jasdeep", ""], ["McCann", "Bryan", ""], ["Keskar", "Nitish Shirish", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1905.11474", "submitter": "Sheikh Rabiul Islam", "authors": "Sheikh Rabiul Islam, William Eberle, Sid Bundy, and Sheikh Khaled\n  Ghafoor", "title": "Infusing domain knowledge in AI-based \"black box\" models for better\n  explainability with application in bankruptcy prediction", "comments": "Under review in KDD, 2019 : 2nd KDD Workshop on Anomaly Detection in\n  Finance", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although \"black box\" models such as Artificial Neural Networks, Support\nVector Machines, and Ensemble Approaches continue to show superior performance\nin many disciplines, their adoption in the sensitive disciplines (e.g.,\nfinance, healthcare) is questionable due to the lack of interpretability and\nexplainability of the model. In fact, future adoption of \"black box\" models is\ndifficult because of the recent rule of \"right of explanation\" by the European\nUnion where a user can ask for an explanation behind an algorithmic decision,\nand the newly proposed bill by the US government, the \"Algorithmic\nAccountability Act\", which would require companies to assess their machine\nlearning systems for bias and discrimination and take corrective measures. Top\nBankruptcy Prediction Models are A.I.-based and are in need of better\nexplainability -the extent to which the internal working mechanisms of an AI\nsystem can be explained in human terms. Although explainable artificial\nintelligence is an emerging field of research, infusing domain knowledge for\nbetter explainability might be a possible solution. In this work, we\ndemonstrate a way to collect and infuse domain knowledge into a \"black box\"\nmodel for bankruptcy prediction. Our understanding from the experiments reveals\nthat infused domain knowledge makes the output from the black box model more\ninterpretable and explainable.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 19:49:11 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 06:19:22 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Islam", "Sheikh Rabiul", ""], ["Eberle", "William", ""], ["Bundy", "Sid", ""], ["Ghafoor", "Sheikh Khaled", ""]]}, {"id": "1905.11481", "submitter": "Max Tegmark", "authors": "Silviu-Marian Udrescu (MIT), Max Tegmark (MIT)", "title": "AI Feynman: a Physics-Inspired Method for Symbolic Regression", "comments": "15 pages, 2 figs. Our code is available at\n  https://github.com/SJ001/AI-Feynman and our Feynman Symbolic Regression\n  Database for benchmarking can be downloaded at\n  https://space.mit.edu/home/tegmark/aifeynman.html", "journal-ref": "Science Advances, 6:eaay2631, April 15, 2020", "doi": null, "report-no": null, "categories": "physics.comp-ph cs.AI cs.LG hep-th", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A core challenge for both physics and artificial intellicence (AI) is\nsymbolic regression: finding a symbolic expression that matches data from an\nunknown function. Although this problem is likely to be NP-hard in principle,\nfunctions of practical interest often exhibit symmetries, separability,\ncompositionality and other simplifying properties. In this spirit, we develop a\nrecursive multidimensional symbolic regression algorithm that combines neural\nnetwork fitting with a suite of physics-inspired techniques. We apply it to 100\nequations from the Feynman Lectures on Physics, and it discovers all of them,\nwhile previous publicly available software cracks only 71; for a more difficult\ntest set, we improve the state of the art success rate from 15% to 90%.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 20:03:57 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 16:39:27 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Udrescu", "Silviu-Marian", "", "MIT"], ["Tegmark", "Max", "", "MIT"]]}, {"id": "1905.11503", "submitter": "Hosnieh Sattar", "authors": "Hosnieh Sattar, Katharina Krombholz, Gerard Pons-Moll, Mario Fritz", "title": "Body Shape Privacy in Images: Understanding Privacy and Preventing\n  Automatic Shape Extraction", "comments": null, "journal-ref": "Proc. of the IEEE European Conference on Computer Vision Workshops\n  (ECCVW), CV-COPS@ECCV2020", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern approaches to pose and body shape estimation have recently achieved\nstrong performance even under challenging real-world conditions. Even from a\nsingle image of a clothed person, a realistic looking body shape can be\ninferred that captures a users' weight group and body shape type well. This\nopens up a whole spectrum of applications -- in particular in fashion -- where\nvirtual try-on and recommendation systems can make use of these new and\nautomatized cues. However, a realistic depiction of the undressed body is\nregarded highly private and therefore might not be consented by most people.\nHence, we ask if the automatic extraction of such information can be\neffectively evaded. While adversarial perturbations have been shown to be\neffective for manipulating the output of machine learning models -- in\nparticular, end-to-end deep learning approaches -- state of the art shape\nestimation methods are composed of multiple stages. We perform the first\ninvestigation of different strategies that can be used to effectively\nmanipulate the automatic shape estimation while preserving the overall\nappearance of the original image.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 20:57:52 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 12:11:55 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 11:15:45 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Sattar", "Hosnieh", ""], ["Krombholz", "Katharina", ""], ["Pons-Moll", "Gerard", ""], ["Fritz", "Mario", ""]]}, {"id": "1905.11513", "submitter": "Maulik Kamdar", "authors": "Maulik R. Kamdar, Tymor Hamamsy, Shea Shelton, Ayin Vala, Tome\n  Eftimov, James Zou and Suzanne Tamang", "title": "A Knowledge Graph-based Approach for Exploring the U.S. Opioid Epidemic", "comments": "4 pages, 2 figures, ICLR AI for social good workshop 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The United States is in the midst of an opioid epidemic with recent estimates\nindicating that more than 130 people die every day due to drug overdose. The\nover-prescription and addiction to opioid painkillers, heroin, and synthetic\nopioids, has led to a public health crisis and created a huge social and\neconomic burden. Statistical learning methods that use data from multiple\nclinical centers across the US to detect opioid over-prescribing trends and\npredict possible opioid misuse are required. However, the semantic\nheterogeneity in the representation of clinical data across different centers\nmakes the development and evaluation of such methods difficult and non-trivial.\nWe create the Opioid Drug Knowledge Graph (ODKG) -- a network of opioid-related\ndrugs, active ingredients, formulations, combinations, and brand names. We use\nthe ODKG to normalize drug strings in a clinical data warehouse consisting of\npatient data from over 400 healthcare facilities in 42 different states. We\nshowcase the use of ODKG to generate summary statistics of opioid prescription\ntrends across US regions. These methods and resources can aid the development\nof advanced and scalable models to monitor the opioid epidemic and to detect\nillicit opioid misuse behavior. Our work is relevant to policymakers and pain\nresearchers who wish to systematically assess factors that contribute to opioid\nover-prescribing and iatrogenic opioid addiction in the US.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 21:25:51 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Kamdar", "Maulik R.", ""], ["Hamamsy", "Tymor", ""], ["Shelton", "Shea", ""], ["Vala", "Ayin", ""], ["Eftimov", "Tome", ""], ["Zou", "James", ""], ["Tamang", "Suzanne", ""]]}, {"id": "1905.11520", "submitter": "Valentin Khrulkov", "authors": "Valentin Khrulkov, Ivan Oseledets", "title": "Universality Theorems for Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the fact that generative models are extremely successful in practice,\nthe theory underlying this phenomenon is only starting to catch up with\npractice. In this work we address the question of the universality of\ngenerative models: is it true that neural networks can approximate any data\nmanifold arbitrarily well? We provide a positive answer to this question and\nshow that under mild assumptions on the activation function one can always find\na feedforward neural network that maps the latent space onto a set located\nwithin the specified Hausdorff distance from the desired data manifold. We also\nprove similar theorems for the case of multiclass generative models and cycle\ngenerative models, trained to map samples from one manifold to another and vice\nversa.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 21:44:50 GMT"}, {"version": "v2", "created": "Sun, 13 Dec 2020 23:58:08 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Khrulkov", "Valentin", ""], ["Oseledets", "Ivan", ""]]}, {"id": "1905.11527", "submitter": "Jonathan Efroni", "authors": "Yonathan Efroni, Nadav Merlis, Mohammad Ghavamzadeh, Shie Mannor", "title": "Tight Regret Bounds for Model-Based Reinforcement Learning with Greedy\n  Policies", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art efficient model-based Reinforcement Learning (RL) algorithms\ntypically act by iteratively solving empirical models, i.e., by performing\n\\emph{full-planning} on Markov Decision Processes (MDPs) built by the gathered\nexperience. In this paper, we focus on model-based RL in the finite-state\nfinite-horizon MDP setting and establish that exploring with \\emph{greedy\npolicies} -- act by \\emph{1-step planning} -- can achieve tight minimax\nperformance in terms of regret, $\\tilde{\\mathcal{O}}(\\sqrt{HSAT})$. Thus,\nfull-planning in model-based RL can be avoided altogether without any\nperformance degradation, and, by doing so, the computational complexity\ndecreases by a factor of $S$. The results are based on a novel analysis of\nreal-time dynamic programming, then extended to model-based RL. Specifically,\nwe generalize existing algorithms that perform full-planning to such that act\nby 1-step planning. For these generalizations, we prove regret bounds with the\nsame rate as their full-planning counterparts.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 22:22:49 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 13:04:58 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Efroni", "Yonathan", ""], ["Merlis", "Nadav", ""], ["Ghavamzadeh", "Mohammad", ""], ["Mannor", "Shie", ""]]}, {"id": "1905.11553", "submitter": "Zhiting Hu", "authors": "Jianheng Tang, Tiancheng Zhao, Chenyan Xiong, Xiaodan Liang, Eric P.\n  Xing, Zhiting Hu", "title": "Target-Guided Open-Domain Conversation", "comments": "ACL 2019. Data and code available at\n  https://github.com/squareRoot3/Target-Guided-Conversation. fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world open-domain conversation applications have specific goals to\nachieve during open-ended chats, such as recommendation, psychotherapy,\neducation, etc. We study the problem of imposing conversational goals on\nopen-domain chat agents. In particular, we want a conversational system to chat\nnaturally with human and proactively guide the conversation to a designated\ntarget subject. The problem is challenging as no public data is available for\nlearning such a target-guided strategy. We propose a structured approach that\nintroduces coarse-grained keywords to control the intended content of system\nresponses. We then attain smooth conversation transition through turn-level\nsupervised learning, and drive the conversation towards the target with\ndiscourse-level constraints. We further derive a keyword-augmented conversation\ndataset for the study. Quantitative and human evaluations show our system can\nproduce meaningful and effective conversations, significantly improving over\nother approaches.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 00:55:25 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 01:36:13 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Tang", "Jianheng", ""], ["Zhao", "Tiancheng", ""], ["Xiong", "Chenyan", ""], ["Liang", "Xiaodan", ""], ["Xing", "Eric P.", ""], ["Hu", "Zhiting", ""]]}, {"id": "1905.11581", "submitter": "Chengxu Zhuang", "authors": "Chengxu Zhuang, Xuehao Ding, Divyanshu Murli, Daniel Yamins", "title": "Local Label Propagation for Large-Scale Semi-Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant issue in training deep neural networks to solve supervised\nlearning tasks is the need for large numbers of labelled datapoints. The goal\nof semi-supervised learning is to leverage ubiquitous unlabelled data, together\nwith small quantities of labelled data, to achieve high task performance.\nThough substantial recent progress has been made in developing semi-supervised\nalgorithms that are effective for comparatively small datasets, many of these\ntechniques do not scale readily to the large (unlaballed) datasets\ncharacteristic of real-world applications. In this paper we introduce a novel\napproach to scalable semi-supervised learning, called Local Label Propagation\n(LLP). Extending ideas from recent work on unsupervised embedding learning, LLP\nfirst embeds datapoints, labelled and otherwise, in a common latent space using\na deep neural network. It then propagates pseudolabels from known to unknown\ndatapoints in a manner that depends on the local geometry of the embedding,\ntaking into account both inter-point distance and local data density as a\nweighting on propagation likelihood. The parameters of the deep embedding are\nthen trained to simultaneously maximize pseudolabel categorization performance\nas well as a metric of the clustering of datapoints within each psuedo-label\ngroup, iteratively alternating stages of network training and label\npropagation. We illustrate the utility of the LLP method on the ImageNet\ndataset, achieving results that outperform previous state-of-the-art scalable\nsemi-supervised learning algorithms by large margins, consistently across a\nwide variety of training regimes. We also show that the feature representation\nlearned with LLP transfers well to scene recognition in the Places 205 dataset.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 02:57:42 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Zhuang", "Chengxu", ""], ["Ding", "Xuehao", ""], ["Murli", "Divyanshu", ""], ["Yamins", "Daniel", ""]]}, {"id": "1905.11592", "submitter": "Aly El Gamal", "authors": "Sharan Ramjee and Aly El Gamal", "title": "Efficient Wrapper Feature Selection using Autoencoder and Model Based\n  Elimination", "comments": "6 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a computationally efficient wrapper feature selection method -\ncalled Autoencoder and Model Based Elimination of features using Relevance and\nRedundancy scores (AMBER) - that uses a single ranker model along with\nautoencoders to perform greedy backward elimination of features. The ranker\nmodel is used to prioritize the removal of features that are not critical to\nthe classification task, while the autoencoders are used to prioritize the\nelimination of correlated features. We demonstrate the superior feature\nselection ability of AMBER on 4 well known datasets corresponding to different\ndomain applications via comparing the classification accuracies with other\ncomputationally efficient state-of-the-art feature selection techniques.\nInterestingly, we find that the ranker model that is used for feature selection\ndoes not necessarily have to be the same as the final classifier that is\ntrained on the selected features. Finally, we note how a smaller number of\nfeatures can lead to higher accuracies on some datasets, and hypothesize that\noverfitting the ranker model on the training set facilitates the selection of\nmore salient features.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 03:31:40 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 02:30:07 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Ramjee", "Sharan", ""], ["Gamal", "Aly El", ""]]}, {"id": "1905.11600", "submitter": "Kaushalya Madhawa Mr", "authors": "Kaushalya Madhawa, Katushiko Ishiguro, Kosuke Nakago, Motoki Abe", "title": "GraphNVP: An Invertible Flow Model for Generating Molecular Graphs", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose GraphNVP, the first invertible, normalizing flow-based molecular\ngraph generation model. We decompose the generation of a graph into two steps:\ngeneration of (i) an adjacency tensor and (ii) node attributes. This\ndecomposition yields the exact likelihood maximization on graph-structured\ndata, combined with two novel reversible flows. We empirically demonstrate that\nour model efficiently generates valid molecular graphs with almost no\nduplicated molecules. In addition, we observe that the learned latent space can\nbe used to generate molecules with desired chemical properties.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 04:13:23 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Madhawa", "Kaushalya", ""], ["Ishiguro", "Katushiko", ""], ["Nakago", "Kosuke", ""], ["Abe", "Motoki", ""]]}, {"id": "1905.11602", "submitter": "Peter Karkus", "authors": "Peter Karkus, Xiao Ma, David Hsu, Leslie Pack Kaelbling, Wee Sun Lee\n  and Tomas Lozano-Perez", "title": "Differentiable Algorithm Networks for Composable Robot Learning", "comments": "RSS 2019 camera ready. Video is available at\n  https://youtu.be/4jcYlTSJF4Y", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the Differentiable Algorithm Network (DAN), a\ncomposable architecture for robot learning systems. A DAN is composed of neural\nnetwork modules, each encoding a differentiable robot algorithm and an\nassociated model; and it is trained end-to-end from data. DAN combines the\nstrengths of model-driven modular system design and data-driven end-to-end\nlearning. The algorithms and models act as structural assumptions to reduce the\ndata requirements for learning; end-to-end learning allows the modules to adapt\nto one another and compensate for imperfect models and algorithms, in order to\nachieve the best overall system performance. We illustrate the DAN methodology\nthrough a case study on a simulated robot system, which learns to navigate in\ncomplex 3-D environments with only local visual observations and an image of a\npartially correct 2-D floor map.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 04:18:05 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Karkus", "Peter", ""], ["Ma", "Xiao", ""], ["Hsu", "David", ""], ["Kaelbling", "Leslie Pack", ""], ["Lee", "Wee Sun", ""], ["Lozano-Perez", "Tomas", ""]]}, {"id": "1905.11634", "submitter": "Songyang Zhang", "authors": "Songyang Zhang, Shipeng Yan, Xuming He", "title": "LatentGNN: Learning Efficient Non-local Relations for Visual Recognition", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capturing long-range dependencies in feature representations is crucial for\nmany visual recognition tasks. Despite recent successes of deep convolutional\nnetworks, it remains challenging to model non-local context relations between\nvisual features. A promising strategy is to model the feature context by a\nfully-connected graph neural network (GNN), which augments traditional\nconvolutional features with an estimated non-local context representation.\nHowever, most GNN-based approaches require computing a dense graph affinity\nmatrix and hence have difficulty in scaling up to tackle complex real-world\nvisual problems. In this work, we propose an efficient and yet flexible\nnon-local relation representation based on a novel class of graph neural\nnetworks. Our key idea is to introduce a latent space to reduce the complexity\nof graph, which allows us to use a low-rank representation for the graph\naffinity matrix and to achieve a linear complexity in computation. Extensive\nexperimental evaluations on three major visual recognition tasks show that our\nmethod outperforms the prior works with a large margin while maintaining a low\ncomputation cost.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 06:42:23 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Zhang", "Songyang", ""], ["Yan", "Shipeng", ""], ["He", "Xuming", ""]]}, {"id": "1905.11691", "submitter": "Valeria Fionda", "authors": "Valeria Fionda and Giuseppe Pirr\\'o", "title": "Triple2Vec: Learning Triple Embeddings from Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embedding techniques allow to learn high-quality feature vectors from\ngraph structures and are useful in a variety of tasks, from node classification\nto clustering. Existing approaches have only focused on learning feature\nvectors for the nodes in a (knowledge) graph. To the best of our knowledge,\nnone of them has tackled the problem of embedding of graph edges, that is,\nknowledge graph triples. The approaches that are closer to this task have\nfocused on homogeneous graphs involving only one type of edge and obtain edge\nembeddings by applying some operation (e.g., average) on the embeddings of the\nendpoint nodes. The goal of this paper is to introduce Triple2Vec, a new\ntechnique to directly embed edges in (knowledge) graphs. Trple2Vec builds upon\nthree main ingredients. The first is the notion of line graph. The line graph\nof a graph is another graph representing the adjacency between edges of the\noriginal graph. In particular, the nodes of the line graph are the edges of the\noriginal graph. We show that directly applying existing embedding techniques on\nthe nodes of the line graph to learn edge embeddings is not enough in the\ncontext of knowledge graphs. Thus, we introduce the notion of triple line\ngraph. The second is an edge weighting mechanism both for line graphs derived\nfrom knowledge graphs and homogeneous graphs. The third is a strategy based on\ngraph walks on the weighted triple line graph that can preserve proximity\nbetween nodes. Embeddings are finally generated by adopting the SkipGram model,\nwhere sentences are replaced with graph walks. We evaluate our approach on\ndifferent real world (knowledge) graphs and compared it with related work.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 09:11:12 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Fionda", "Valeria", ""], ["Pirr\u00f3", "Giuseppe", ""]]}, {"id": "1905.11769", "submitter": "Purushottam Kar", "authors": "Ankit Jalan and Purushottam Kar", "title": "Accelerating Extreme Classification via Adaptive Feature Agglomeration", "comments": "A version of this paper without the appendices will appear at the\n  28th International Joint Conference on Artificial Intelligence (IJCAI 2019).\n  Code for this paper is available at https://github.com/purushottamkar/defrag/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extreme classification seeks to assign each data point, the most relevant\nlabels from a universe of a million or more labels. This task is faced with the\ndual challenge of high precision and scalability, with millisecond level\nprediction times being a benchmark. We propose DEFRAG, an adaptive feature\nagglomeration technique to accelerate extreme classification algorithms.\nDespite past works on feature clustering and selection, DEFRAG distinguishes\nitself in being able to scale to millions of features, and is especially\nbeneficial when feature sets are sparse, which is typical of recommendation and\nmulti-label datasets. The method comes with provable performance guarantees and\nperforms efficient task-driven agglomeration to reduce feature dimensionalities\nby an order of magnitude or more. Experiments show that DEFRAG can not only\nreduce training and prediction times of several leading extreme classification\nalgorithms by as much as 40%, but also be used for feature reconstruction to\naddress the problem of missing features, as well as offer superior coverage on\nrare labels.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 12:30:25 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Jalan", "Ankit", ""], ["Kar", "Purushottam", ""]]}, {"id": "1905.11786", "submitter": "Sindy L\\\"owe", "authors": "Sindy L\\\"owe, Peter O'Connor, Bastiaan S. Veeling", "title": "Putting An End to End-to-End: Gradient-Isolated Learning of\n  Representations", "comments": "Honorable Mention for Outstanding New Directions Paper Award at\n  NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel deep learning method for local self-supervised\nrepresentation learning that does not require labels nor end-to-end\nbackpropagation but exploits the natural order in data instead. Inspired by the\nobservation that biological neural networks appear to learn without\nbackpropagating a global error signal, we split a deep neural network into a\nstack of gradient-isolated modules. Each module is trained to maximally\npreserve the information of its inputs using the InfoNCE bound from Oord et al.\n[2018]. Despite this greedy training, we demonstrate that each module improves\nupon the output of its predecessor, and that the representations created by the\ntop module yield highly competitive results on downstream classification tasks\nin the audio and visual domain. The proposal enables optimizing modules\nasynchronously, allowing large-scale distributed training of very deep neural\nnetworks on unlabelled datasets.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 13:00:46 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 15:33:41 GMT"}, {"version": "v3", "created": "Mon, 27 Jan 2020 12:34:15 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["L\u00f6we", "Sindy", ""], ["O'Connor", "Peter", ""], ["Veeling", "Bastiaan S.", ""]]}, {"id": "1905.11804", "submitter": "Haytham Elmousalami", "authors": "Haytham H. Elmousalami", "title": "Prediction of Construction Cost for Field Canals Improvement Projects in\n  Egypt", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Field canals improvement projects (FCIPs) are one of the ambitious projects\nconstructed to save fresh water. To finance this project, Conceptual cost\nmodels are important to accurately predict preliminary costs at the early\nstages of the project. The first step is to develop a conceptual cost model to\nidentify key cost drivers affecting the project. Therefore, input variables\nselection remains an important part of model development, as the poor variables\nselection can decrease model precision. The study discovered the most important\ndrivers of FCIPs based on a qualitative approach and a quantitative approach.\nSubsequently, the study has developed a parametric cost model based on machine\nlearning methods such as regression methods, artificial neural networks, fuzzy\nmodel and case-based reasoning.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 00:33:54 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Elmousalami", "Haytham H.", ""]]}, {"id": "1905.11807", "submitter": "Andrew Powell", "authors": "Andrew Powell", "title": "Artificial Consciousness and Security", "comments": "7 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a possible way to improve computer security by\nimplementing a program which implements the following three features related to\na weak notion of artificial consciousness: (partial) self-monitoring, ability\nto compute the truth of quantifier-free propositions and the ability to\ncommunicate with the user. The integrity of the program could be enhanced by\nusing a trusted computing approach, that is to say a hardware module that is at\nthe root of a chain of trust. This paper outlines a possible approach but does\nnot refer to an implementation (which would need further work), but the author\nbelieves that an implementation using current processors, a debugger, a\nmonitoring program and a trusted processing module is currently possible.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 11:21:05 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Powell", "Andrew", ""]]}, {"id": "1905.11833", "submitter": "Mariya Toneva", "authors": "Mariya Toneva and Leila Wehbe", "title": "Interpreting and improving natural-language processing (in machines)\n  with natural language-processing (in the brain)", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks models for NLP are typically implemented without the explicit\nencoding of language rules and yet they are able to break one performance\nrecord after another. This has generated a lot of research interest in\ninterpreting the representations learned by these networks. We propose here a\nnovel interpretation approach that relies on the only processing system we have\nthat does understand language: the human brain. We use brain imaging recordings\nof subjects reading complex natural text to interpret word and sequence\nembeddings from 4 recent NLP models - ELMo, USE, BERT and Transformer-XL. We\nstudy how their representations differ across layer depth, context length, and\nattention type. Our results reveal differences in the context-related\nrepresentations across these models. Further, in the transformer models, we\nfind an interaction between layer depth and context length, and between layer\ndepth and attention type. We finally hypothesize that altering BERT to better\nalign with brain recordings would enable it to also better understand language.\nProbing the altered BERT using syntactic NLP tasks reveals that the model with\nincreased brain-alignment outperforms the original model. Cognitive\nneuroscientists have already begun using NLP networks to study the brain, and\nthis work closes the loop to allow the interaction between NLP and cognitive\nneuroscience to be a true cross-pollination.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 14:13:09 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 14:52:22 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 17:40:56 GMT"}, {"version": "v4", "created": "Wed, 13 Nov 2019 16:25:28 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Toneva", "Mariya", ""], ["Wehbe", "Leila", ""]]}, {"id": "1905.11838", "submitter": "Palash Dey", "authors": "Palash Dey, Neeldhara Misra, Swaprava Nath, and Garima Shakya", "title": "A Parameterized Perspective on Protecting Elections", "comments": "To appear in IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.CY cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the parameterized complexity of the optimal defense and optimal\nattack problems in voting. In both the problems, the input is a set of voter\ngroups (every voter group is a set of votes) and two integers $k_a$ and $k_d$\ncorresponding to respectively the number of voter groups the attacker can\nattack and the number of voter groups the defender can defend. A voter group\ngets removed from the election if it is attacked but not defended. In the\noptimal defense problem, we want to know if it is possible for the defender to\ncommit to a strategy of defending at most $k_d$ voter groups such that, no\nmatter which $k_a$ voter groups the attacker attacks, the outcome of the\nelection does not change. In the optimal attack problem, we want to know if it\nis possible for the attacker to commit to a strategy of attacking $k_a$ voter\ngroups such that, no matter which $k_d$ voter groups the defender defends, the\noutcome of the election is always different from the original (without any\nattack) one.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 14:20:33 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Dey", "Palash", ""], ["Misra", "Neeldhara", ""], ["Nath", "Swaprava", ""], ["Shakya", "Garima", ""]]}, {"id": "1905.11867", "submitter": "Adish Singla", "authors": "Parameswaran Kamalaruban, Rati Devidze, Volkan Cevher, Adish Singla", "title": "Interactive Teaching Algorithms for Inverse Reinforcement Learning", "comments": "IJCAI'19 paper (extended version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of inverse reinforcement learning (IRL) with the added\ntwist that the learner is assisted by a helpful teacher. More formally, we\ntackle the following algorithmic question: How could a teacher provide an\ninformative sequence of demonstrations to an IRL learner to speed up the\nlearning process? We present an interactive teaching framework where a teacher\nadaptively chooses the next demonstration based on learner's current policy. In\nparticular, we design teaching algorithms for two concrete settings: an\nomniscient setting where a teacher has full knowledge about the learner's\ndynamics and a blackbox setting where the teacher has minimal knowledge. Then,\nwe study a sequential variant of the popular MCE-IRL learner and prove\nconvergence guarantees of our teaching algorithm in the omniscient setting.\nExtensive experiments with a car driving simulator environment show that the\nlearning progress can be speeded up drastically as compared to an uninformative\nteacher.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 15:03:14 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 16:26:55 GMT"}, {"version": "v3", "created": "Wed, 5 Jun 2019 21:51:13 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Kamalaruban", "Parameswaran", ""], ["Devidze", "Rati", ""], ["Cevher", "Volkan", ""], ["Singla", "Adish", ""]]}, {"id": "1905.11887", "submitter": "Poorya Mianjy", "authors": "Poorya Mianjy and Raman Arora", "title": "On Dropout and Nuclear Norm Regularization", "comments": null, "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, PMLR 97:4575-4584, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a formal and complete characterization of the explicit regularizer\ninduced by dropout in deep linear networks with squared loss. We show that (a)\nthe explicit regularizer is composed of an $\\ell_2$-path regularizer and other\nterms that are also re-scaling invariant, (b) the convex envelope of the\ninduced regularizer is the squared nuclear norm of the network map, and (c) for\na sufficiently large dropout rate, we characterize the global optima of the\ndropout objective. We validate our theoretical findings with empirical results.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 15:31:51 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Mianjy", "Poorya", ""], ["Arora", "Raman", ""]]}, {"id": "1905.11940", "submitter": "Boyang Deng", "authors": "Boyang Deng, Simon Kornblith, Geoffrey Hinton", "title": "Cerberus: A Multi-headed Derenderer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  To generalize to novel visual scenes with new viewpoints and new object\nposes, a visual system needs representations of the shapes of the parts of an\nobject that are invariant to changes in viewpoint or pose. 3D graphics\nrepresentations disentangle visual factors such as viewpoints and lighting from\nobject structure in a natural way. It is possible to learn to invert the\nprocess that converts 3D graphics representations into 2D images, provided the\n3D graphics representations are available as labels. When only the unlabeled\nimages are available, however, learning to derender is much harder. We consider\na simple model which is just a set of free floating parts. Each part has its\nown relation to the camera and its own triangular mesh which can be deformed to\nmodel the shape of the part. At test time, a neural network looks at a single\nimage and extracts the shapes of the parts and their relations to the camera.\nEach part can be viewed as one head of a multi-headed derenderer. During\ntraining, the extracted parts are used as input to a differentiable 3D renderer\nand the reconstruction error is backpropagated to train the neural net. We make\nthe learning task easier by encouraging the deformations of the part meshes to\nbe invariant to changes in viewpoint and invariant to the changes in the\nrelative positions of the parts that occur when the pose of an articulated body\nchanges. Cerberus, our multi-headed derenderer, outperforms previous methods\nfor extracting 3D parts from single images without part annotations, and it\ndoes quite well at extracting natural parts of human figures.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 17:00:03 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Deng", "Boyang", ""], ["Kornblith", "Simon", ""], ["Hinton", "Geoffrey", ""]]}, {"id": "1905.11954", "submitter": "Chengxu Zhuang", "authors": "Chengxu Zhuang, Tianwei She, Alex Andonian, Max Sobol Mark, Daniel\n  Yamins", "title": "Unsupervised Learning from Video with Deep Neural Embeddings", "comments": "To appear in CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because of the rich dynamical structure of videos and their ubiquity in\neveryday life, it is a natural idea that video data could serve as a powerful\nunsupervised learning signal for training visual representations in deep neural\nnetworks. However, instantiating this idea, especially at large scale, has\nremained a significant artificial intelligence challenge. Here we present the\nVideo Instance Embedding (VIE) framework, which extends powerful recent\nunsupervised loss functions for learning deep nonlinear embeddings to\nmulti-stream temporal processing architectures on large-scale video datasets.\nWe show that VIE-trained networks substantially advance the state of the art in\nunsupervised learning from video datastreams, both for action recognition in\nthe Kinetics dataset, and object recognition in the ImageNet dataset. We show\nthat a hybrid model with both static and dynamic processing pathways is optimal\nfor both transfer tasks, and provide analyses indicating how the pathways\ndiffer. Taken in context, our results suggest that deep neural embeddings are a\npromising approach to unsupervised visual learning across a wide variety of\ndomains.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 17:24:48 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 21:57:55 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Zhuang", "Chengxu", ""], ["She", "Tianwei", ""], ["Andonian", "Alex", ""], ["Mark", "Max Sobol", ""], ["Yamins", "Daniel", ""]]}, {"id": "1905.12006", "submitter": "Steven James", "authors": "Steven James, Benjamin Rosman, George Konidaris", "title": "Learning Portable Representations for High-Level Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for autonomously learning a portable representation\nthat describes a collection of low-level continuous environments. We show that\nthese abstract representations can be learned in a task-independent egocentric\nspace specific to the agent that, when grounded with problem-specific\ninformation, are provably sufficient for planning. We demonstrate transfer in\ntwo different domains, where an agent learns a portable, task-independent\nsymbolic vocabulary, as well as rules expressed in that vocabulary, and then\nlearns to instantiate those rules on a per-task basis. This reduces the number\nof samples required to learn a representation of a new task.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 18:13:42 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["James", "Steven", ""], ["Rosman", "Benjamin", ""], ["Konidaris", "George", ""]]}, {"id": "1905.12008", "submitter": "Tomasz Kornuta", "authors": "Tomasz Kornuta and Deepta Rajan and Chaitanya Shivade and Alexis\n  Asseman and Ahmet S. Ozcan", "title": "Leveraging Medical Visual Question Answering with Supporting Facts", "comments": "Working notes from the ImageCLEF 2019 VQA-Med competition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this working notes paper, we describe IBM Research AI (Almaden) team's\nparticipation in the ImageCLEF 2019 VQA-Med competition. The challenge consists\nof four question-answering tasks based on radiology images. The diversity of\nimaging modalities, organs and disease types combined with a small imbalanced\ntraining set made this a highly complex problem. To overcome these\ndifficulties, we implemented a modular pipeline architecture that utilized\ntransfer learning and multi-task learning. Our findings led to the development\nof a novel model called Supporting Facts Network (SFN). The main idea behind\nSFN is to cross-utilize information from upstream tasks to improve the accuracy\non harder downstream ones. This approach significantly improved the scores\nachieved in the validation set (18 point improvement in F-1 score). Finally, we\nsubmitted four runs to the competition and were ranked seventh.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 18:15:52 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Kornuta", "Tomasz", ""], ["Rajan", "Deepta", ""], ["Shivade", "Chaitanya", ""], ["Asseman", "Alexis", ""], ["Ozcan", "Ahmet S.", ""]]}, {"id": "1905.12042", "submitter": "Tejas Gokhale", "authors": "Tejas Gokhale, Shailaja Sampat, Zhiyuan Fang, Yezhou Yang, Chitta\n  Baral", "title": "Blocksworld Revisited: Learning and Reasoning to Generate\n  Event-Sequences from Image Pairs", "comments": "10 pages, 5 figures, for associated dataset, see\n  https://asu-active-perception-group.github.io/bird_dataset_web/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The process of identifying changes or transformations in a scene along with\nthe ability of reasoning about their causes and effects, is a key aspect of\nintelligence. In this work we go beyond recent advances in computational\nperception, and introduce a more challenging task, Image-based Event-Sequencing\n(IES). In IES, the task is to predict a sequence of actions required to\nrearrange objects from the configuration in an input source image to the one in\nthe target image. IES also requires systems to possess inductive\ngeneralizability. Motivated from evidence in cognitive development, we compile\nthe first IES dataset, the Blocksworld Image Reasoning Dataset (BIRD) which\ncontains images of wooden blocks in different configurations, and the sequence\nof moves to rearrange one configuration to the other. We first explore the use\nof existing deep learning architectures and show that these end-to-end methods\nunder-perform in inferring temporal event-sequences and fail at inductive\ngeneralization. We then propose a modular two-step approach: Visual Perception\nfollowed by Event-Sequencing, and demonstrate improved performance by combining\nlearning and reasoning. Finally, by showing an extension of our approach on\nnatural images, we seek to pave the way for future research on event sequencing\nfor real world scenes.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 19:26:19 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Gokhale", "Tejas", ""], ["Sampat", "Shailaja", ""], ["Fang", "Zhiyuan", ""], ["Yang", "Yezhou", ""], ["Baral", "Chitta", ""]]}, {"id": "1905.12044", "submitter": "Nicholay Topin", "authors": "Nicholay Topin and Manuela Veloso", "title": "Generation of Policy-Level Explanations for Reinforcement Learning", "comments": "Accepted to Proceedings of the Thirty-Third AAAI Conference on\n  Artificial Intelligence (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though reinforcement learning has greatly benefited from the incorporation of\nneural networks, the inability to verify the correctness of such systems limits\ntheir use. Current work in explainable deep learning focuses on explaining only\na single decision in terms of input features, making it unsuitable for\nexplaining a sequence of decisions. To address this need, we introduce\nAbstracted Policy Graphs, which are Markov chains of abstract states. This\nrepresentation concisely summarizes a policy so that individual decisions can\nbe explained in the context of expected future transitions. Additionally, we\npropose a method to generate these Abstracted Policy Graphs for deterministic\npolicies given a learned value function and a set of observed transitions,\npotentially off-policy transitions used during training. Since no restrictions\nare placed on how the value function is generated, our method is compatible\nwith many existing reinforcement learning methods. We prove that the worst-case\ntime complexity of our method is quadratic in the number of features and linear\nin the number of provided transitions, $O(|F|^2 |tr\\_samples|)$. By applying\nour method to a family of domains, we show that our method scales well in\npractice and produces Abstracted Policy Graphs which reliably capture\nrelationships within these domains.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 19:33:49 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Topin", "Nicholay", ""], ["Veloso", "Manuela", ""]]}, {"id": "1905.12071", "submitter": "Blai Bonet", "authors": "Blai Bonet, Raquel Fuentetaja, Yolanda E-Martin, Daniel Borrajo", "title": "Guarantees for Sound Abstractions for Generalized Planning (Extended\n  Paper)", "comments": "This paper extends IJCAI-19 paper with an appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized planning is about finding plans that solve collections of\nplanning instances, often infinite collections, rather than single instances.\nRecently it has been shown how to reduce the planning problem for generalized\nplanning to the planning problem for a qualitative numerical problem; the\nlatter being a reformulation that simultaneously captures all the instances in\nthe collection. An important thread of research thus consists in finding such\nreformulations, or abstractions, automatically. A recent proposal learns the\nabstractions inductively from a finite and small sample of transitions from\ninstances in the collection. However, as in all inductive processes, the\nlearned abstraction is not guaranteed to be correct for the whole collection.\nIn this work we address this limitation by performing an analysis of the\nabstraction with respect to the collection, and show how to obtain formal\nguarantees for generalization. These guarantees, in the form of first-order\nformulas, may be used to 1) define subcollections of instances on which the\nabstraction is guaranteed to be sound, 2) obtain necessary conditions for\ngeneralization under certain assumptions, and 3) do automated synthesis of\ncomplex invariants for planning problems. Our framework is general, it can be\nextended or combined with other approaches, and it has applications that go\nbeyond generalized planning.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 20:23:53 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 15:18:07 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Bonet", "Blai", ""], ["Fuentetaja", "Raquel", ""], ["E-Martin", "Yolanda", ""], ["Borrajo", "Daniel", ""]]}, {"id": "1905.12080", "submitter": "Giancarlo Kerg", "authors": "Giancarlo Kerg, Kyle Goyette, Maximilian Puelma Touzel, Gauthier\n  Gidel, Eugene Vorontsov, Yoshua Bengio, Guillaume Lajoie", "title": "Non-normal Recurrent Neural Network (nnRNN): learning long time\n  dependencies while improving expressivity with transient dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent strategy to circumvent the exploding and vanishing gradient problem\nin RNNs, and to allow the stable propagation of signals over long time scales,\nis to constrain recurrent connectivity matrices to be orthogonal or unitary.\nThis ensures eigenvalues with unit norm and thus stable dynamics and training.\nHowever this comes at the cost of reduced expressivity due to the limited\nvariety of orthogonal transformations. We propose a novel connectivity\nstructure based on the Schur decomposition and a splitting of the Schur form\ninto normal and non-normal parts. This allows to parametrize matrices with\nunit-norm eigenspectra without orthogonality constraints on eigenbases. The\nresulting architecture ensures access to a larger space of spectrally\nconstrained matrices, of which orthogonal matrices are a subset. This crucial\ndifference retains the stability advantages and training speed of orthogonal\nRNNs while enhancing expressivity, especially on tasks that require\ncomputations over ongoing input sequences.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 20:41:27 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 13:13:02 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Kerg", "Giancarlo", ""], ["Goyette", "Kyle", ""], ["Touzel", "Maximilian Puelma", ""], ["Gidel", "Gauthier", ""], ["Vorontsov", "Eugene", ""], ["Bengio", "Yoshua", ""], ["Lajoie", "Guillaume", ""]]}, {"id": "1905.12096", "submitter": "Roma Patel", "authors": "Yoonseon Oh, Roma Patel, Thao Nguyen, Baichuan Huang, Ellie Pavlick,\n  Stefanie Tellex", "title": "Planning with State Abstractions for Non-Markovian Task Specifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Often times, we specify tasks for a robot using temporal language that can\nalso span different levels of abstraction. The example command ``go to the\nkitchen before going to the second floor'' contains spatial abstraction, given\nthat ``floor'' consists of individual rooms that can also be referred to in\nisolation (\"kitchen\", for example). There is also a temporal ordering of\nevents, defined by the word \"before\". Previous works have used Linear Temporal\nLogic (LTL) to interpret temporal language (such as \"before\"), and Abstract\nMarkov Decision Processes (AMDPs) to interpret hierarchical abstractions (such\nas \"kitchen\" and \"second floor\"), separately. To handle both types of commands\nat once, we introduce the Abstract Product Markov Decision Process (AP-MDP), a\nnovel approach capable of representing non-Markovian reward functions at\ndifferent levels of abstractions. The AP-MDP framework translates LTL into its\ncorresponding automata, creates a product Markov Decision Process (MDP) of the\nLTL specification and the environment MDP, and decomposes the problem into\nsubproblems to enable efficient planning with abstractions. AP-MDP performs\nfaster than a non-hierarchical method of solving LTL problems in over 95% of\ntasks, and this number only increases as the size of the environment domain\nincreases. We also present a neural sequence-to-sequence model trained to\ntranslate language commands into LTL expression, and a new corpus of\nnon-Markovian language commands spanning different levels of abstraction. We\ntest our framework with the collected language commands on a drone,\ndemonstrating that our approach enables a robot to efficiently solve temporal\ncommands at different levels of abstraction.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 21:28:17 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Oh", "Yoonseon", ""], ["Patel", "Roma", ""], ["Nguyen", "Thao", ""], ["Huang", "Baichuan", ""], ["Pavlick", "Ellie", ""], ["Tellex", "Stefanie", ""]]}, {"id": "1905.12100", "submitter": "Owen Marschall", "authors": "Owen Marschall, Kyunghyun Cho, Cristina Savin", "title": "Using local plasticity rules to train recurrent neural networks", "comments": "Abstract submission to Computational and Systems Neuroscience\n  (Cosyne) 2019, accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To learn useful dynamics on long time scales, neurons must use plasticity\nrules that account for long-term, circuit-wide effects of synaptic changes. In\nother words, neural circuits must solve a credit assignment problem to\nappropriately assign responsibility for global network behavior to individual\ncircuit components. Furthermore, biological constraints demand that plasticity\nrules are spatially and temporally local; that is, synaptic changes can depend\nonly on variables accessible to the pre- and postsynaptic neurons. While\nartificial intelligence offers a computational solution for credit assignment,\nnamely backpropagation through time (BPTT), this solution is wildly\nbiologically implausible. It requires both nonlocal computations and unlimited\nmemory capacity, as any synaptic change is a complicated function of the entire\nhistory of network activity. Similar nonlocality issues plague other approaches\nsuch as FORCE (Sussillo et al. 2009). Overall, we are still missing a model for\nlearning in recurrent circuits that both works computationally and uses only\nlocal updates. Leveraging recent advances in machine learning on approximating\ngradients for BPTT, we derive biologically plausible plasticity rules that\nenable recurrent networks to accurately learn long-term dependencies in\nsequential data. The solution takes the form of neurons with segregated voltage\ncompartments, with several synaptic sub-populations that have different\nfunctional properties. The network operates in distinct phases during which\neach synaptic sub-population is updated by its own local plasticity rule. Our\nresults provide new insights into the potential roles of segregated dendritic\ncompartments, branch-specific inhibition, and global circuit phases in\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 21:32:26 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Marschall", "Owen", ""], ["Cho", "Kyunghyun", ""], ["Savin", "Cristina", ""]]}, {"id": "1905.12104", "submitter": "Nicholas Mattei", "authors": "Jaelle Scheuerman, Jason L. Harman, Nicholas Mattei, and K. Brent\n  Venable", "title": "Heuristics in Multi-Winner Approval Voting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real world situations, collective decisions are made using voting.\nMoreover, scenarios such as committee or board elections require voting rules\nthat return multiple winners. In multi-winner approval voting (AV), an agent\nmay vote for as many candidates as they wish. Winners are chosen by tallying up\nthe votes and choosing the top-$k$ candidates receiving the most votes. An\nagent may manipulate the vote to achieve a better outcome by voting in a way\nthat does not reflect their true preferences. In complex and uncertain\nsituations, agents may use heuristics to strategize, instead of incurring the\nadditional effort required to compute the manipulation which most favors them.\nIn this paper, we examine voting behavior in multi-winner approval voting\nscenarios with complete information. We show that people generally manipulate\ntheir vote to obtain a better outcome, but often do not identify the optimal\nmanipulation. Instead, voters tend to prioritize the candidates with the\nhighest utilities. Using simulations, we demonstrate the effectiveness of these\nheuristics in situations where agents only have access to partial information.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 21:44:07 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 16:27:24 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Scheuerman", "Jaelle", ""], ["Harman", "Jason L.", ""], ["Mattei", "Nicholas", ""], ["Venable", "K. Brent", ""]]}, {"id": "1905.12126", "submitter": "Ethan Steinberg", "authors": "Ethan Steinberg, Peter J. Liu", "title": "Using Ontologies To Improve Performance In Massively Multi-label\n  Prediction Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massively multi-label prediction/classification problems arise in\nenvironments like health-care or biology where very precise predictions are\nuseful. One challenge with massively multi-label problems is that there is\noften a long-tailed frequency distribution for the labels, which results in few\npositive examples for the rare labels. We propose a solution to this problem by\nmodifying the output layer of a neural network to create a Bayesian network of\nsigmoids which takes advantage of ontology relationships between the labels to\nhelp share information between the rare and the more common labels. We apply\nthis method to the two massively multi-label tasks of disease prediction (ICD-9\ncodes) and protein function prediction (Gene Ontology terms) and obtain\nsignificant improvements in per-label AUROC and average precision for less\ncommon labels.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 22:55:49 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Steinberg", "Ethan", ""], ["Liu", "Peter J.", ""]]}, {"id": "1905.12127", "submitter": "Shariq Iqbal", "authors": "Shariq Iqbal and Fei Sha", "title": "Coordinated Exploration via Intrinsic Rewards for Multi-Agent\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving tasks with sparse rewards is one of the most important challenges in\nreinforcement learning. In the single-agent setting, this challenge is\naddressed by introducing intrinsic rewards that motivate agents to explore\nunseen regions of their state spaces; however, applying these techniques\nnaively to the multi-agent setting results in agents exploring independently,\nwithout any coordination among themselves. Exploration in cooperative\nmulti-agent settings can be accelerated and improved if agents coordinate their\nexploration. In this paper we introduce a framework for designing intrinsic\nrewards which consider what other agents have explored such that the agents can\ncoordinate. Then, we develop an approach for learning how to dynamically select\nbetween several exploration modalities to maximize extrinsic rewards.\nConcretely, we formulate the approach as a hierarchical policy where a\nhigh-level controller selects among sets of policies trained on diverse\nintrinsic rewards and the low-level controllers learn the action policies of\nall agents under these specific rewards. We demonstrate the effectiveness of\nthe proposed approach in cooperative domains with sparse rewards where\nstate-of-the-art methods fail and challenging multi-stage tasks that\nnecessitate changing modes of coordination.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 23:01:02 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 02:08:26 GMT"}, {"version": "v3", "created": "Sat, 22 May 2021 20:19:01 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Iqbal", "Shariq", ""], ["Sha", "Fei", ""]]}, {"id": "1905.12130", "submitter": "James Aimone", "authors": "James B Aimone, William Severa, and Craig M Vineyard", "title": "Composing Neural Algorithms with Fugu", "comments": "Accepted to 2019 International Conference on Neuromorphic Systems\n  (ICONS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic hardware architectures represent a growing family of potential\npost-Moore's Law Era platforms. Largely due to event-driving processing\ninspired by the human brain, these computer platforms can offer significant\nenergy benefits compared to traditional von Neumann processors. Unfortunately\nthere still remains considerable difficulty in successfully programming,\nconfiguring and deploying neuromorphic systems. We present the Fugu framework\nas an answer to this need. Rather than necessitating a developer attain\nintricate knowledge of how to program and exploit spiking neural dynamics to\nutilize the potential benefits of neuromorphic computing, Fugu is designed to\nprovide a higher level abstraction as a hardware-independent mechanism for\nlinking a variety of scalable spiking neural algorithms from a variety of\nsources. Individual kernels linked together provide sophisticated processing\nthrough compositionality. Fugu is intended to be suitable for a wide-range of\nneuromorphic applications, including machine learning, scientific computing,\nand more brain-inspired neural algorithms. Ultimately, we hope the community\nadopts this and other open standardization attempts allowing for free exchange\nand easy implementations of the ever-growing list of spiking neural algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 23:13:07 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Aimone", "James B", ""], ["Severa", "William", ""], ["Vineyard", "Craig M", ""]]}, {"id": "1905.12149", "submitter": "Po-Wei Wang", "authors": "Po-Wei Wang, Priya L. Donti, Bryan Wilder, Zico Kolter", "title": "SATNet: Bridging deep learning and logical reasoning using a\n  differentiable satisfiability solver", "comments": "Accepted at ICML'19. The code can be found at\n  https://github.com/locuslab/satnet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrating logical reasoning within deep learning architectures has been a\nmajor goal of modern AI systems. In this paper, we propose a new direction\ntoward this goal by introducing a differentiable (smoothed) maximum\nsatisfiability (MAXSAT) solver that can be integrated into the loop of larger\ndeep learning systems. Our (approximate) solver is based upon a fast coordinate\ndescent approach to solving the semidefinite program (SDP) associated with the\nMAXSAT problem. We show how to analytically differentiate through the solution\nto this SDP and efficiently solve the associated backward pass. We demonstrate\nthat by integrating this solver into end-to-end learning systems, we can learn\nthe logical structure of challenging problems in a minimally supervised\nfashion. In particular, we show that we can learn the parity function using\nsingle-bit supervision (a traditionally hard task for deep networks) and learn\nhow to play 9x9 Sudoku solely from examples. We also solve a \"visual Sudok\"\nproblem that maps images of Sudoku puzzles to their associated logical\nsolutions by combining our MAXSAT solver with a traditional convolutional\narchitecture. Our approach thus shows promise in integrating logical structures\nwithin deep learning.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 00:47:35 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Wang", "Po-Wei", ""], ["Donti", "Priya L.", ""], ["Wilder", "Bryan", ""], ["Kolter", "Zico", ""]]}, {"id": "1905.12152", "submitter": "Arushi Gupta", "authors": "Arushi Gupta, Sanjeev Arora", "title": "A Simple Saliency Method That Passes the Sanity Checks", "comments": "Small typo on paragraph 3 of section 3 fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is great interest in \"saliency methods\" (also called \"attribution\nmethods\"), which give \"explanations\" for a deep net's decision, by assigning a\n\"score\" to each feature/pixel in the input. Their design usually involves\ncredit-assignment via the gradient of the output with respect to input.\nRecently Adebayo et al. [arXiv:1810.03292] questioned the validity of many of\nthese methods since they do not pass simple *sanity checks* which test whether\nthe scores shift/vanish when layers of the trained net are randomized, or when\nthe net is retrained using random labels for inputs.\n  We propose a simple fix to existing saliency methods that helps them pass\nsanity checks, which we call \"competition for pixels\". This involves computing\nsaliency maps for all possible labels in the classification task, and using a\nsimple competition among them to identify and remove less relevant pixels from\nthe map. The simplest variant of this is \"Competitive Gradient $\\odot$ Input\n(CGI)\": it is efficient, requires no additional training, and uses only the\ninput and gradient. Some theoretical justification is provided for it\n(especially for ReLU networks) and its performance is empirically demonstrated.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 23:15:11 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 00:55:44 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Gupta", "Arushi", ""], ["Arora", "Sanjeev", ""]]}, {"id": "1905.12171", "submitter": "Shaokai Ye", "authors": "Shaokai Ye, Sia Huat Tan, Kaidi Xu, Yanzhi Wang, Chenglong Bao,\n  Kaisheng Ma", "title": "Brain-inspired reverse adversarial examples", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A human does not have to see all elephants to recognize an animal as an\nelephant. On contrast, current state-of-the-art deep learning approaches\nheavily depend on the variety of training samples and the capacity of the\nnetwork. In practice, the size of network is always limited and it is\nimpossible to access all the data samples. Under this circumstance, deep\nlearning models are extremely fragile to human-imperceivable adversarial\nexamples, which impose threats to all safety critical systems. Inspired by the\nassociation and attention mechanisms of the human brain, we propose reverse\nadversarial examples method that can greatly improve models' robustness on\nunseen data. Experiments show that our reverse adversarial method can improve\naccuracy on average 19.02% on ResNet18, MobileNet, and VGG16 on unseen data\ntransformation. Besides, the proposed method is also applicable to compressed\nmodels and shows potential to compensate the robustness drop brought by model\nquantization - an absolute 30.78% accuracy improvement.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 03:58:55 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Ye", "Shaokai", ""], ["Tan", "Sia Huat", ""], ["Xu", "Kaidi", ""], ["Wang", "Yanzhi", ""], ["Bao", "Chenglong", ""], ["Ma", "Kaisheng", ""]]}, {"id": "1905.12186", "submitter": "Michael Cohen", "authors": "Michael K Cohen, Badri Vellambi, Marcus Hutter", "title": "Asymptotically Unambitious Artificial General Intelligence", "comments": "9 pages with 5 figures; 10 page Appendix with 2 figures", "journal-ref": "Proc.AAAI. 34 (2020) 2467-2476", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General intelligence, the ability to solve arbitrary solvable problems, is\nsupposed by many to be artificially constructible. Narrow intelligence, the\nability to solve a given particularly difficult problem, has seen impressive\nrecent development. Notable examples include self-driving cars, Go engines,\nimage classifiers, and translators. Artificial General Intelligence (AGI)\npresents dangers that narrow intelligence does not: if something smarter than\nus across every domain were indifferent to our concerns, it would be an\nexistential threat to humanity, just as we threaten many species despite no ill\nwill. Even the theory of how to maintain the alignment of an AGI's goals with\nour own has proven highly elusive. We present the first algorithm we are aware\nof for asymptotically unambitious AGI, where \"unambitiousness\" includes not\nseeking arbitrary power. Thus, we identify an exception to the Instrumental\nConvergence Thesis, which is roughly that by default, an AGI would seek power,\nincluding over us.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 02:48:15 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 03:17:31 GMT"}, {"version": "v3", "created": "Thu, 12 Dec 2019 12:17:45 GMT"}, {"version": "v4", "created": "Tue, 21 Jul 2020 13:27:38 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Cohen", "Michael K", ""], ["Vellambi", "Badri", ""], ["Hutter", "Marcus", ""]]}, {"id": "1905.12188", "submitter": "Haoyu Song", "authors": "Haoyu Song, Wei-Nan Zhang, Yiming Cui, Dong Wang and Ting Liu", "title": "Exploiting Persona Information for Diverse Generation of Conversational\n  Responses", "comments": "published as a conference paper at IJCAI 2019 (to appear). 7 pages, 1\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In human conversations, due to their personalities in mind, people can easily\ncarry out and maintain the conversations. Giving conversational context with\npersona information to a chatbot, how to exploit the information to generate\ndiverse and sustainable conversations is still a non-trivial task. Previous\nwork on persona-based conversational models successfully make use of predefined\npersona information and have shown great promise in delivering more realistic\nresponses. And they all learn with the assumption that given a source input,\nthere is only one target response. However, in human conversations, there are\nmassive appropriate responses to a given input message. In this paper, we\npropose a memory-augmented architecture to exploit persona information from\ncontext and incorporate a conditional variational autoencoder model together to\ngenerate diverse and sustainable conversations. We evaluate the proposed model\non a benchmark persona-chat dataset. Both automatic and human evaluations show\nthat our model can deliver more diverse and more engaging persona-based\nresponses than baseline approaches.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 02:50:50 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Song", "Haoyu", ""], ["Zhang", "Wei-Nan", ""], ["Cui", "Yiming", ""], ["Wang", "Dong", ""], ["Liu", "Ting", ""]]}, {"id": "1905.12197", "submitter": "Panpan Cai", "authors": "Panpan Cai, Yuanfu Luo, Aseem Saxena, David Hsu, Wee Sun Lee", "title": "LeTS-Drive: Driving in a Crowd by Learning from Tree Search", "comments": null, "journal-ref": "Proc. Robotics: Science & Systems (RSS), 2019", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous driving in a crowded environment, e.g., a busy traffic\nintersection, is an unsolved challenge for robotics. The robot vehicle must\ncontend with a dynamic and partially observable environment, noisy sensors, and\nmany agents. A principled approach is to formalize it as a Partially Observable\nMarkov Decision Process (POMDP) and solve it through online belief-tree search.\nTo handle a large crowd and achieve real-time performance in this very\nchallenging setting, we propose LeTS-Drive, which integrates online POMDP\nplanning and deep learning. It consists of two phases. In the offline phase, we\nlearn a policy and the corresponding value function by imitating the belief\ntree search. In the online phase, the learned policy and value function guide\nthe belief tree search. LeTS-Drive leverages the robustness of planning and the\nruntime efficiency of learning to enhance the performance of both. Experimental\nresults in simulation show that LeTS-Drive outperforms either planning or\nimitation learning alone and develops sophisticated driving skills.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 03:27:01 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Cai", "Panpan", ""], ["Luo", "Yuanfu", ""], ["Saxena", "Aseem", ""], ["Hsu", "David", ""], ["Lee", "Wee Sun", ""]]}, {"id": "1905.12204", "submitter": "Hyunwook Kang", "authors": "Hyunwook Kang, Aydar Mynbay, James R. Morrison, Jinkyoo Park", "title": "Learning scalable and transferable multi-robot/machine sequential\n  assignment planning via graph embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can the success of reinforcement learning methods for simple combinatorial\noptimization problems be extended to multi-robot sequential assignment\nplanning? In addition to the challenge of achieving near-optimal performance in\nlarge problems, transferability to an unseen number of robots and tasks is\nanother key challenge for real-world applications. In this paper, we suggest a\nmethod that achieves the first success in both challenges for robot/machine\nscheduling problems.\n  Our method comprises of three components. First, we show a robot scheduling\nproblem can be expressed as a random probabilistic graphical model (PGM). We\ndevelop a mean-field inference method for random PGM and use it for Q-function\ninference. Second, we show that transferability can be achieved by carefully\ndesigning two-step sequential encoding of problem state. Third, we resolve the\ncomputational scalability issue of fitted Q-iteration by suggesting a heuristic\nauction-based Q-iteration fitting method enabled by transferability we\nachieved.\n  We apply our method to discrete-time, discrete space problems (Multi-Robot\nReward Collection (MRRC)) and scalably achieve 97% optimality with\ntransferability. This optimality is maintained under stochastic contexts. By\nextending our method to continuous time, continuous space formulation, we claim\nto be the first learning-based method with scalable performance among\nmulti-machine scheduling problems; our method scalability achieves comparable\nperformance to popular metaheuristics in Identical parallel machine scheduling\n(IPMS) problems.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 04:02:41 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 16:51:06 GMT"}, {"version": "v3", "created": "Mon, 30 Sep 2019 18:44:13 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Kang", "Hyunwook", ""], ["Mynbay", "Aydar", ""], ["Morrison", "James R.", ""], ["Park", "Jinkyoo", ""]]}, {"id": "1905.12213", "submitter": "Alessandro Achille", "authors": "Alessandro Achille, Giovanni Paolini, Stefano Soatto", "title": "Where is the Information in a Deep Neural Network?", "comments": null, "journal-ref": null, "doi": null, "report-no": "UCLA-TR:190005", "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whatever information a deep neural network has gleaned from training data is\nencoded in its weights. How this information affects the response of the\nnetwork to future data remains largely an open question. Indeed, even defining\nand measuring information entails some subtleties, since a trained network is a\ndeterministic map, so standard information measures can be degenerate. We\nmeasure information in a neural network via the optimal trade-off between\naccuracy of the response and complexity of the weights, measured by their\ncoding length. Depending on the choice of code, the definition can reduce to\nstandard measures such as Shannon Mutual Information and Fisher Information.\nHowever, the more general definition allows us to relate information to\ngeneralization and invariance, through a novel notion of effective information\nin the activations of a deep network. We establish a novel relation between the\ninformation in the weights and the effective information in the activations,\nand use this result to show that models with low (information) complexity not\nonly generalize better, but are bound to learn invariant representations of\nfuture inputs. These relations hinge not only on the architecture of the model,\nbut also on how it is trained, highlighting the complex inter-dependency\nbetween the class of functions implemented by deep neural networks, the loss\nfunction used for training them from finite data, and the inductive bias\nimplicit in the optimization.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 04:38:54 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 03:15:02 GMT"}, {"version": "v3", "created": "Tue, 21 Apr 2020 06:55:52 GMT"}, {"version": "v4", "created": "Wed, 17 Jun 2020 11:02:47 GMT"}, {"version": "v5", "created": "Mon, 22 Jun 2020 03:34:06 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Achille", "Alessandro", ""], ["Paolini", "Giovanni", ""], ["Soatto", "Stefano", ""]]}, {"id": "1905.12217", "submitter": "Liwei Wu", "authors": "Liwei Wu, Hsiang-Fu Yu, Nikhil Rao, James Sharpnack, Cho-Jui Hsieh", "title": "Graph DNA: Deep Neighborhood Aware Graph Encoding for Collaborative\n  Filtering", "comments": "under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider recommender systems with side information in the\nform of graphs. Existing collaborative filtering algorithms mainly utilize only\nimmediate neighborhood information and have a hard time taking advantage of\ndeeper neighborhoods beyond 1-2 hops. The main caveat of exploiting deeper\ngraph information is the rapidly growing time and space complexity when\nincorporating information from these neighborhoods. In this paper, we propose\nusing Graph DNA, a novel Deep Neighborhood Aware graph encoding algorithm, for\nexploiting deeper neighborhood information. DNA encoding computes approximate\ndeep neighborhood information in linear time using Bloom filters, a\nspace-efficient probabilistic data structure and results in a per-node encoding\nthat is logarithmic in the number of nodes in the graph. It can be used in\nconjunction with both feature-based and graph-regularization-based\ncollaborative filtering algorithms. Graph DNA has the advantages of being\nmemory and time efficient and providing additional regularization when compared\nto directly using higher order graph information. We conduct experiments on\nreal-world datasets, showing graph DNA can be easily used with 4 popular\ncollaborative filtering algorithms and consistently leads to a performance\nboost with little computational and memory overhead.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 04:57:02 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Wu", "Liwei", ""], ["Yu", "Hsiang-Fu", ""], ["Rao", "Nikhil", ""], ["Sharpnack", "James", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1905.12255", "submitter": "Vihan Jain", "authors": "Vihan Jain, Gabriel Magalhaes, Alexander Ku, Ashish Vaswani, Eugene\n  Ie, Jason Baldridge", "title": "Stay on the Path: Instruction Fidelity in Vision-and-Language Navigation", "comments": "Accepted at ACL 2019 as long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Advances in learning and representations have reinvigorated work that\nconnects language to other modalities. A particularly exciting direction is\nVision-and-Language Navigation(VLN), in which agents interpret natural language\ninstructions and visual scenes to move through environments and reach goals.\nDespite recent progress, current research leaves unclear how much of a role\nlanguage understanding plays in this task, especially because dominant\nevaluation metrics have focused on goal completion rather than the sequence of\nactions corresponding to the instructions. Here, we highlight shortcomings of\ncurrent metrics for the Room-to-Room dataset (Anderson et al.,2018b) and\npropose a new metric, Coverage weighted by Length Score (CLS). We also show\nthat the existing paths in the dataset are not ideal for evaluating instruction\nfollowing because they are direct-to-goal shortest paths. We join existing\nshort paths to form more challenging extended paths to create a new data set,\nRoom-for-Room (R4R). Using R4R and CLS, we show that agents that receive\nrewards for instruction fidelity outperform agents that focus on goal\ncompletion.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 07:40:38 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 04:59:49 GMT"}, {"version": "v3", "created": "Fri, 21 Jun 2019 16:55:06 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Jain", "Vihan", ""], ["Magalhaes", "Gabriel", ""], ["Ku", "Alexander", ""], ["Vaswani", "Ashish", ""], ["Ie", "Eugene", ""], ["Baldridge", "Jason", ""]]}, {"id": "1905.12260", "submitter": "Karan Singhal", "authors": "Karan Singhal, Karthik Raman, Balder ten Cate", "title": "Learning Multilingual Word Embeddings Using Image-Text Data", "comments": null, "journal-ref": null, "doi": "10.18653/v1/W19-1807", "report-no": "W19-1807", "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been significant interest recently in learning multilingual word\nembeddings -- in which semantically similar words across languages have similar\nembeddings. State-of-the-art approaches have relied on expensive labeled data,\nwhich is unavailable for low-resource languages, or have involved post-hoc\nunification of monolingual embeddings. In the present paper, we investigate the\nefficacy of multilingual embeddings learned from weakly-supervised image-text\ndata. In particular, we propose methods for learning multilingual embeddings\nusing image-text data, by enforcing similarity between the representations of\nthe image and that of the text. Our experiments reveal that even without using\nany expensive labeled data, a bag-of-words-based embedding model trained on\nimage-text data achieves performance comparable to the state-of-the-art on\ncrosslingual semantic similarity tasks.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 07:55:17 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Singhal", "Karan", ""], ["Raman", "Karthik", ""], ["Cate", "Balder ten", ""]]}, {"id": "1905.12262", "submitter": "Antonio Bruto da Costa", "authors": "Antonio Anastasio Bruto da Costa and Pallab Dasgupta", "title": "Learning Temporal Causal Sequence Relationships from Real-Time\n  Time-Series", "comments": "This article appears in the Journal of Artificial Intelligence", "journal-ref": "Journal of Artificial Intelligence Research, Volume 70 (2021)\n  205-243", "doi": "10.1613/jair.1.12395", "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to mine temporal causal sequences that explain observed events\n(consequents) in time-series traces. Causal explanations of key events in a\ntime-series has applications in design debugging, anomaly detection, planning,\nroot-cause analysis and many more. We make use of decision trees and interval\narithmetic to mine sequences that explain defining events in the time-series.\nWe propose modified decision tree construction metrics to handle the\nnon-determinism introduced by the temporal dimension. The mined sequences are\nexpressed in a readable temporal logic language that is easy to interpret. The\napplication of the proposed methodology is illustrated through various\nexamples.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 07:55:55 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 10:40:20 GMT"}, {"version": "v3", "created": "Sat, 29 Aug 2020 11:39:02 GMT"}, {"version": "v4", "created": "Mon, 7 Sep 2020 15:29:02 GMT"}, {"version": "v5", "created": "Fri, 18 Sep 2020 13:07:07 GMT"}, {"version": "v6", "created": "Sun, 24 Jan 2021 21:50:40 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["da Costa", "Antonio Anastasio Bruto", ""], ["Dasgupta", "Pallab", ""]]}, {"id": "1905.12310", "submitter": "Mingfei Sun", "authors": "Mingfei Sun and Xiaojuan Ma", "title": "Adversarial Imitation Learning from Incomplete Demonstrations", "comments": "Accepted to International Joint Conference on Artificial Intelligence\n  (IJCAI-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning targets deriving a mapping from states to actions, a.k.a.\npolicy, from expert demonstrations. Existing methods for imitation learning\ntypically require any actions in the demonstrations to be fully available,\nwhich is hard to ensure in real applications. Though algorithms for learning\nwith unobservable actions have been proposed, they focus solely on state\ninformation and overlook the fact that the action sequence could still be\npartially available and provide useful information for policy deriving. In this\npaper, we propose a novel algorithm called Action-Guided Adversarial Imitation\nLearning (AGAIL) that learns a policy from demonstrations with incomplete\naction sequences, i.e., incomplete demonstrations. The core idea of AGAIL is to\nseparate demonstrations into state and action trajectories, and train a policy\nwith state trajectories while using actions as auxiliary information to guide\nthe training whenever applicable. Built upon the Generative Adversarial\nImitation Learning, AGAIL has three components: a generator, a discriminator,\nand a guide. The generator learns a policy with rewards provided by the\ndiscriminator, which tries to distinguish state distributions between\ndemonstrations and samples generated by the policy. The guide provides\nadditional rewards to the generator when demonstrated actions for specific\nstates are available. We compare AGAIL to other methods on benchmark tasks and\nshow that AGAIL consistently delivers comparable performance to the\nstate-of-the-art methods even when the action sequence in demonstrations is\nonly partially available.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 10:18:42 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 03:44:25 GMT"}, {"version": "v3", "created": "Sun, 23 Jun 2019 06:11:10 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Sun", "Mingfei", ""], ["Ma", "Xiaojuan", ""]]}, {"id": "1905.12330", "submitter": "Rahma Chaabouni", "authors": "Rahma Chaabouni, Eugene Kharitonov, Alessandro Lazaric, Emmanuel\n  Dupoux and Marco Baroni", "title": "Word-order biases in deep-agent emergent communication", "comments": "Conference: Association for Computational Linguistics (ACL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-processing neural networks led to remarkable progress on many NLP\ntasks. As a consequence, there has been increasing interest in understanding to\nwhat extent they process language as humans do. We aim here to uncover which\nbiases such models display with respect to \"natural\" word-order constraints. We\ntrain models to communicate about paths in a simple gridworld, using miniature\nlanguages that reflect or violate various natural language trends, such as the\ntendency to avoid redundancy or to minimize long-distance dependencies. We\nstudy how the controlled characteristics of our miniature languages affect\nindividual learning and their stability across multiple network generations.\nThe results draw a mixed picture. On the one hand, neural networks show a\nstrong tendency to avoid long-distance dependencies. On the other hand, there\nis no clear preference for the efficient, non-redundant encoding of information\nthat is widely attested in natural language. We thus suggest inoculating a\nnotion of \"effort\" into neural networks, as a possible way to make their\nlinguistic behavior more human-like.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 11:17:59 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 16:52:47 GMT"}, {"version": "v3", "created": "Fri, 14 Jun 2019 08:08:45 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Chaabouni", "Rahma", ""], ["Kharitonov", "Eugene", ""], ["Lazaric", "Alessandro", ""], ["Dupoux", "Emmanuel", ""], ["Baroni", "Marco", ""]]}, {"id": "1905.12345", "submitter": "Weichang Wu", "authors": "Weichang Wu, Junchi Yan, Xiaokang Yang, Hongyuan Zha", "title": "Reinforcement Learning with Policy Mixture Model for Temporal Point\n  Processes Clustering", "comments": "8 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal point process is an expressive tool for modeling event sequences\nover time. In this paper, we take a reinforcement learning view whereby the\nobserved sequences are assumed to be generated from a mixture of latent\npolicies. The purpose is to cluster the sequences with different temporal\npatterns into the underlying policies while learning each of the policy model.\nThe flexibility of our model lies in: i) all the components are networks\nincluding the policy network for modeling the intensity function of temporal\npoint process; ii) to handle varying-length event sequences, we resort to\ninverse reinforcement learning by decomposing the observed sequence into states\n(RNN hidden embedding of history) and actions (time interval to next event) in\norder to learn the reward function, thus achieving better performance or\nincreasing efficiency compared to existing methods using rewards over the\nentire sequence such as log-likelihood or Wasserstein distance. We adopt an\nexpectation-maximization framework with the E-step estimating the cluster\nlabels for each sequence, and the M-step aiming to learn the respective policy.\nExtensive experiments show the efficacy of our method against\nstate-of-the-arts.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 11:49:55 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 03:53:09 GMT"}, {"version": "v3", "created": "Fri, 28 Jun 2019 14:37:36 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Wu", "Weichang", ""], ["Yan", "Junchi", ""], ["Yang", "Xiaokang", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1905.12389", "submitter": "Frank Van Harmelen", "authors": "Frank van Harmelen and Annette ten Teije", "title": "A Boxology of Design Patterns for Hybrid Learning and Reasoning Systems", "comments": "12 pages,55 references", "journal-ref": "Journal of Web Engineering, Vol. 18 1-3, pgs. 97-124, 2019", "doi": "10.13052/jwe1540-9589.18133", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a set of compositional design patterns to describe a large variety\nof systems that combine statistical techniques from machine learning with\nsymbolic techniques from knowledge representation. As in other areas of\ncomputer science (knowledge engineering, software engineering, ontology\nengineering, process mining and others), such design patterns help to\nsystematize the literature, clarify which combinations of techniques serve\nwhich purposes, and encourage re-use of software components. We have validated\nour set of compositional design patterns against a large body of recent\nliterature.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 12:53:10 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["van Harmelen", "Frank", ""], ["Teije", "Annette ten", ""]]}, {"id": "1905.12411", "submitter": "Vuong M. Ngo", "authors": "Vuong M. Ngo and Nhien-An Le-Khac and M-Tahar Kechadi", "title": "Designing and Implementing Data Warehouse for Agricultural Big Data", "comments": "Business intelligent, data warehouse, constellation schema, Big Data,\n  precision agriculture", "journal-ref": "BigData 2019", "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, precision agriculture that uses modern information and\ncommunication technologies is becoming very popular. Raw and semi-processed\nagricultural data are usually collected through various sources, such as:\nInternet of Thing (IoT), sensors, satellites, weather stations, robots, farm\nequipment, farmers and agribusinesses, etc. Besides, agricultural datasets are\nvery large, complex, unstructured, heterogeneous, non-standardized, and\ninconsistent. Hence, the agricultural data mining is considered as Big Data\napplication in terms of volume, variety, velocity and veracity. It is a key\nfoundation to establishing a crop intelligence platform, which will enable\nresource efficient agronomy decision making and recommendations. In this paper,\nwe designed and implemented a continental level agricultural data warehouse by\ncombining Hive, MongoDB and Cassandra. Our data warehouse capabilities: (1)\nflexible schema; (2) data integration from real agricultural multi datasets;\n(3) data science and business intelligent support; (4) high performance; (5)\nhigh storage; (6) security; (7) governance and monitoring; (8) replication and\nrecovery; (9) consistency, availability and partition tolerant; (10)\ndistributed and cloud deployment. We also evaluate the performance of our data\nwarehouse.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 13:18:03 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Ngo", "Vuong M.", ""], ["Le-Khac", "Nhien-An", ""], ["Kechadi", "M-Tahar", ""]]}, {"id": "1905.12425", "submitter": "Aristide Charles Yedia Tossou", "authors": "Aristide Tossou, Debabrota Basu, Christos Dimitrakakis", "title": "Near-optimal Optimistic Reinforcement Learning using Empirical Bernstein\n  Inequalities", "comments": "the algorithm has been simplified (no need to look at lower bound of\n  the reward and transitions). Proof has been significantly clean-up. The\n  previous \"assumption\" is clarified as a condition of the algorithm well-known\n  as sub-modularity. The proof that the bounds satisfy the submodularity is\n  clean-up", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study model-based reinforcement learning in an unknown finite\ncommunicating Markov decision process. We propose a simple algorithm that\nleverages a variance based confidence interval. We show that the proposed\nalgorithm, UCRL-V, achieves the optimal regret\n$\\tilde{\\mathcal{O}}(\\sqrt{DSAT})$ up to logarithmic factors, and so our work\ncloses a gap with the lower bound without additional assumptions on the MDP. We\nperform experiments in a variety of environments that validates the theoretical\nbounds as well as prove UCRL-V to be better than the state-of-the-art\nalgorithms.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 20:15:54 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 18:01:23 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Tossou", "Aristide", ""], ["Basu", "Debabrota", ""], ["Dimitrakakis", "Christos", ""]]}, {"id": "1905.12429", "submitter": "Haizhong Zheng", "authors": "Haizhong Zheng, Earlence Fernandes, Atul Prakash", "title": "Analyzing the Interpretability Robustness of Self-Explaining Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, interpretable models called self-explaining models (SEMs) have been\nproposed with the goal of providing interpretability robustness. We evaluate\nthe interpretability robustness of SEMs and show that explanations provided by\nSEMs as currently proposed are not robust to adversarial inputs. Specifically,\nwe successfully created adversarial inputs that do not change the model outputs\nbut cause significant changes in the explanations. We find that even though\ncurrent SEMs use stable co-efficients for mapping explanations to output\nlabels, they do not consider the robustness of the first stage of the model\nthat creates interpretable basis concepts from the input, leading to non-robust\nexplanations. Our work makes a case for future work to start examining how to\ngenerate interpretable basis concepts in a robust way.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 22:33:35 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2019 22:16:07 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 17:28:02 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Zheng", "Haizhong", ""], ["Fernandes", "Earlence", ""], ["Prakash", "Atul", ""]]}, {"id": "1905.12464", "submitter": "Luigi Portinale", "authors": "Luigi Portinale", "title": "Approaching Adaptation Guided Retrieval in Case-Based Reasoning through\n  Inference in Undirected Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Case-Based Reasoning, when the similarity assumption does not hold, the\nretrieval of a set of cases structurally similar to the query does not\nguarantee to get a reusable or revisable solution. Knowledge about the\nadaptability of solutions has to be exploited, in order to define a method for\nadaptation-guided retrieval. We propose a novel approach to address this\nproblem, where knowledge about the adaptability of the solutions is captured\ninside a metric Markov Random Field (MRF). Nodes of the MRF represent cases and\nedges connect nodes whose solutions are close in the solution space. States of\nthe nodes represent different adaptation levels with respect to the potential\nquery. Metric-based potentials enforce connected nodes to share the same state,\nsince cases having similar solutions should have the same adaptability level\nwith respect to the query. The main goal is to enlarge the set of potentially\nadaptable cases that are retrieved without significantly sacrificing the\nprecision and accuracy of retrieval. We will report on some experiments\nconcerning a retrieval architecture where a simple kNN retrieval (on the\nproblem description) is followed by a further retrieval step based on MRF\ninference.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 14:00:26 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Portinale", "Luigi", ""]]}, {"id": "1905.12556", "submitter": "Ensar Seker", "authors": "Ensar \\c{S}eker", "title": "Use of Artificial Intelligence Techniques / Applications in Cyber\n  Defense", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, considering the speed of the processes and the amount of data used\nin cyber defense, it cannot be expected to have an effective defense by using\nonly human power without the help of automation systems. However, for the\neffective defense against dynamically evolving attacks on networks, it is\ndifficult to develop software with conventional fixed algorithms. This can be\nachieved by using artificial intelligence methods that provide flexibility and\nlearning capability. The likelihood of developing cyber defense capabilities\nthrough increased intelligence of defense systems is quite high. Given the\nproblems associated with cyber defense in real life, it is clear that many\ncyber defense problems can be successfully solved only when artificial\nintelligence methods are used. In this article, the current artificial\nintelligence practices and techniques are reviewed and the use and importance\nof artificial intelligence in cyber defense systems is mentioned. The aim of\nthis article is to be able to explain the use of these methods in the field of\ncyber defense with current examples by considering and analyzing the artificial\nintelligence technologies and methodologies that are currently being developed\nand integrating them with the role and adaptation of the technology and\nmethodology in the defense of cyberspace.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 13:22:50 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["\u015eeker", "Ensar", ""]]}, {"id": "1905.12561", "submitter": "Rahma Chaabouni", "authors": "Rahma Chaabouni, Eugene Kharitonov, Emmanuel Dupoux and Marco Baroni", "title": "Anti-efficient encoding in emergent communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite renewed interest in emergent language simulations with neural\nnetworks, little is known about the basic properties of the induced code, and\nhow they compare to human language. One fundamental characteristic of the\nlatter, known as Zipf's Law of Abbreviation (ZLA), is that more frequent words\nare efficiently associated to shorter strings. We study whether the same\npattern emerges when two neural networks, a \"speaker\" and a \"listener\", are\ntrained to play a signaling game. Surprisingly, we find that networks develop\nan \\emph{anti-efficient} encoding scheme, in which the most frequent inputs are\nassociated to the longest messages, and messages in general are skewed towards\nthe maximum length threshold. This anti-efficient code appears easier to\ndiscriminate for the listener, and, unlike in human communication, the speaker\ndoes not impose a contrasting least-effort pressure towards brevity. Indeed,\nwhen the cost function includes a penalty for longer messages, the resulting\nmessage distribution starts respecting ZLA. Our analysis stresses the\nimportance of studying the basic features of emergent communication in a highly\ncontrolled setup, to ensure the latter will not strand too far from human\nlanguage. Moreover, we present a concrete illustration of how different\nfunctional pressures can lead to successful communication codes that lack basic\nproperties of human language, thus highlighting the role such pressures play in\nthe latter.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 16:14:24 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 16:46:47 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 16:58:54 GMT"}, {"version": "v4", "created": "Tue, 15 Oct 2019 11:56:14 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Chaabouni", "Rahma", ""], ["Kharitonov", "Eugene", ""], ["Dupoux", "Emmanuel", ""], ["Baroni", "Marco", ""]]}, {"id": "1905.12588", "submitter": "Khurram Javed Mr", "authors": "Khurram Javed and Martha White", "title": "Meta-Learning Representations for Continual Learning", "comments": "Accepted at NeurIPS19, 15 pages, 10 figures, open-source,\n  representation learning, continual learning, online learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A continual learning agent should be able to build on top of existing\nknowledge to learn on new data quickly while minimizing forgetting. Current\nintelligent systems based on neural network function approximators arguably do\nthe opposite---they are highly prone to forgetting and rarely trained to\nfacilitate future learning. One reason for this poor behavior is that they\nlearn from a representation that is not explicitly trained for these two goals.\nIn this paper, we propose OML, an objective that directly minimizes\ncatastrophic interference by learning representations that accelerate future\nlearning and are robust to forgetting under online updates in continual\nlearning. We show that it is possible to learn naturally sparse representations\nthat are more effective for online updating. Moreover, our algorithm is\ncomplementary to existing continual learning strategies, such as MER and GEM.\nFinally, we demonstrate that a basic online updating strategy on\nrepresentations learned by OML is competitive with rehearsal based methods for\ncontinual learning. We release an implementation of our method at\nhttps://github.com/khurramjaved96/mrcl .\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 17:09:31 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 20:36:25 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Javed", "Khurram", ""], ["White", "Martha", ""]]}, {"id": "1905.12600", "submitter": "Hanie Sedghi", "authors": "Philip M. Long and Hanie Sedghi", "title": "Generalization bounds for deep convolutional neural networks", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove bounds on the generalization error of convolutional networks. The\nbounds are in terms of the training loss, the number of parameters, the\nLipschitz constant of the loss and the distance from the weights to the initial\nweights. They are independent of the number of pixels in the input, and the\nheight and width of hidden feature maps. We present experiments using CIFAR-10\nwith varying hyperparameters of a deep convolutional network, comparing our\nbounds with practical generalization gaps.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 17:20:36 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 16:54:56 GMT"}, {"version": "v3", "created": "Fri, 26 Jul 2019 16:39:20 GMT"}, {"version": "v4", "created": "Fri, 27 Sep 2019 01:55:42 GMT"}, {"version": "v5", "created": "Sun, 9 Feb 2020 20:00:07 GMT"}, {"version": "v6", "created": "Wed, 8 Apr 2020 05:10:39 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Long", "Philip M.", ""], ["Sedghi", "Hanie", ""]]}, {"id": "1905.12612", "submitter": "Ashish Kumar", "authors": "Ashish Kumar, Saurabh Gupta, Jitendra Malik", "title": "Learning Navigation Subroutines from Egocentric Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning at a higher level of abstraction instead of low level torques\nimproves the sample efficiency in reinforcement learning, and computational\nefficiency in classical planning. We propose a method to learn such\nhierarchical abstractions, or subroutines from egocentric video data of experts\nperforming tasks. We learn a self-supervised inverse model on small amounts of\nrandom interaction data to pseudo-label the expert egocentric videos with agent\nactions. Visuomotor subroutines are acquired from these pseudo-labeled videos\nby learning a latent intent-conditioned policy that predicts the inferred\npseudo-actions from the corresponding image observations. We demonstrate our\nproposed approach in context of navigation, and show that we can successfully\nlearn consistent and diverse visuomotor subroutines from passive egocentric\nvideos. We demonstrate the utility of our acquired visuomotor subroutines by\nusing them as is for exploration, and as sub-policies in a hierarchical RL\nframework for reaching point goals and semantic goals. We also demonstrate\nbehavior of our subroutines in the real world, by deploying them on a real\nrobotic platform. Project website:\nhttps://ashishkumar1993.github.io/subroutines/.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 17:50:19 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 08:10:25 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Kumar", "Ashish", ""], ["Gupta", "Saurabh", ""], ["Malik", "Jitendra", ""]]}, {"id": "1905.12615", "submitter": "Quanquan Gu", "authors": "Pan Xu and Felicia Gao and Quanquan Gu", "title": "An Improved Convergence Analysis of Stochastic Variance-Reduced Policy\n  Gradient", "comments": "10 pages, 2 figures, 1 table. To appear in the proceedings of the\n  35th International Conference on Uncertainty in Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the stochastic variance-reduced policy gradient (SVRPG) method\nproposed by Papini et al. (2018) for reinforcement learning. We provide an\nimproved convergence analysis of SVRPG and show that it can find an\n$\\epsilon$-approximate stationary point of the performance function within\n$O(1/\\epsilon^{5/3})$ trajectories. This sample complexity improves upon the\nbest known result $O(1/\\epsilon^2)$ by a factor of $O(1/\\epsilon^{1/3})$. At\nthe core of our analysis is (i) a tighter upper bound for the variance of\nimportance sampling weights, where we prove that the variance can be controlled\nby the parameter distance between different policies; and (ii) a fine-grained\nanalysis of the epoch length and batch size parameters such that we can\nsignificantly reduce the number of trajectories required in each iteration of\nSVRPG. We also empirically demonstrate the effectiveness of our theoretical\nclaims of batch sizes on reinforcement learning benchmark tasks.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 17:57:23 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Xu", "Pan", ""], ["Gao", "Felicia", ""], ["Gu", "Quanquan", ""]]}, {"id": "1905.12630", "submitter": "Oscar J. Romero", "authors": "Oscar J. Romero", "title": "Cognitively-inspired Agent-based Service Composition for Mobile &\n  Pervasive Computing", "comments": "This paper will appear on AIMS'19 (International Conference on\n  Artificial Intelligence and Mobile Services) on June 25", "journal-ref": "Artificial Intelligence and Mobile Services AIMS 2019", "doi": "10.1007/978-3-030-23367-9_8", "report-no": null, "categories": "cs.SE cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic service composition in mobile and pervasive computing faces many\nchallenges due to the complex and highly dynamic nature of the environment.\nCommon approaches consider service composition as a decision problem whose\nsolution is usually addressed from optimization perspectives which are not\nfeasible in practice due to the intractability of the problem, limited\ncomputational resources of smart devices, service host's mobility, and time\nconstraints to tailor composition plans. Thus, our main contribution is the\ndevelopment of a cognitively-inspired agent-based service composition model\nfocused on bounded rationality rather than optimality, which allows the system\nto compensate for limited resources by selectively filtering out continuous\nstreams of data. Our approach exhibits features such as distributedness,\nmodularity, emergent global functionality, and robustness, which endow it with\ncapabilities to perform decentralized service composition by orchestrating\nmanifold service providers and conflicting goals from multiple users. The\nevaluation of our approach shows promising results when compared against\nstate-of-the-art service composition models.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 20:19:15 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Romero", "Oscar J.", ""]]}, {"id": "1905.12654", "submitter": "Huan Wang", "authors": "Huan Wang, Stephan Zheng, Caiming Xiong, Richard Socher", "title": "On the Generalization Gap in Reparameterizable Reinforcement Learning", "comments": null, "journal-ref": "Proceedings of the 36 th International Conference on Machine\n  Learning, Long Beach, California, PMLR 97, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding generalization in reinforcement learning (RL) is a significant\nchallenge, as many common assumptions of traditional supervised learning theory\ndo not apply. We focus on the special class of reparameterizable RL problems,\nwhere the trajectory distribution can be decomposed using the reparametrization\ntrick. For this problem class, estimating the expected return is efficient and\nthe trajectory can be computed deterministically given peripheral random\nvariables, which enables us to study reparametrizable RL using supervised\nlearning and transfer learning theory. Through these relationships, we derive\nguarantees on the gap between the expected and empirical return for both\nintrinsic and external errors, based on Rademacher complexity as well as the\nPAC-Bayes bound. Our bound suggests the generalization capability of\nreparameterizable RL is related to multiple factors including \"smoothness\" of\nthe environment transition, reward and agent policy function class. We also\nempirically verify the relationship between the generalization gap and these\nfactors through simulations.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 18:05:01 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Wang", "Huan", ""], ["Zheng", "Stephan", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1905.12663", "submitter": "Adam Bielski", "authors": "Adam Bielski, Paolo Favaro", "title": "Emergence of Object Segmentation in Perturbed Generative Models", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Spotlight presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel framework to build a model that can learn how to segment\nobjects from a collection of images without any human annotation. Our method\nbuilds on the observation that the location of object segments can be perturbed\nlocally relative to a given background without affecting the realism of a\nscene. Our approach is to first train a generative model of a layered scene.\nThe layered representation consists of a background image, a foreground image\nand the mask of the foreground. A composite image is then obtained by\noverlaying the masked foreground image onto the background. The generative\nmodel is trained in an adversarial fashion against a discriminator, which\nforces the generative model to produce realistic composite images. To force the\ngenerator to learn a representation where the foreground layer corresponds to\nan object, we perturb the output of the generative model by introducing a\nrandom shift of both the foreground image and mask relative to the background.\nBecause the generator is unaware of the shift before computing its output, it\nmust produce layered representations that are realistic for any such random\nperturbation. Finally, we learn to segment an image by defining an autoencoder\nconsisting of an encoder, which we train, and the pre-trained generator as the\ndecoder, which we freeze. The encoder maps an image to a feature vector, which\nis fed as input to the generator to give a composite image matching the\noriginal input image. Because the generator outputs an explicit layered\nrepresentation of the scene, the encoder learns to detect and segment objects.\nWe demonstrate this framework on real images of several object categories.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 18:17:39 GMT"}, {"version": "v2", "created": "Sat, 2 Nov 2019 17:46:33 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Bielski", "Adam", ""], ["Favaro", "Paolo", ""]]}, {"id": "1905.12666", "submitter": "Anthony Constantinou", "authors": "Anthony C. Constantinou", "title": "Evaluating structure learning algorithms with a balanced scoring\n  function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several structure learning algorithms have been proposed towards discovering\ncausal or Bayesian Network (BN) graphs. The validity of these algorithms tends\nto be evaluated by assessing the relationship between the learnt and the ground\ntruth graph. However, there is no agreed scoring metric to determine this\nrelationship. Moreover, this paper shows that some of the commonly used metrics\ntend to be biased in favour of graphs that minimise edges. While graphs that\nare less complex are desirable, some of the metrics favour underfitted graphs,\nthereby encouraging limited propagation of evidence. This paper proposes the\nBalanced Scoring Function (BSF) that eliminates this bias by adjusting the\nreward function based on the difficulty of discovering an edge, or no edge,\nproportional to their occurrence rate in the ground truth graph. The BSF score\ncan be used in conjunction with other traditional metrics to provide an\nalternative and unbiased assessment about the capability of a structure\nlearning algorithm in discovering causal or BN graphs.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 18:23:17 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 13:35:28 GMT"}, {"version": "v3", "created": "Wed, 2 Sep 2020 10:01:12 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Constantinou", "Anthony C.", ""]]}, {"id": "1905.12717", "submitter": "Shay Moran", "authors": "Akshay Balsubramani, Sanjoy Dasgupta, Yoav Freund, Shay Moran", "title": "An adaptive nearest neighbor rule for classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a variant of the $k$-nearest neighbor classifier in which $k$ is\nchosen adaptively for each query, rather than supplied as a parameter. The\nchoice of $k$ depends on properties of each neighborhood, and therefore may\nsignificantly vary between different points. (For example, the algorithm will\nuse larger $k$ for predicting the labels of points in noisy regions.)\n  We provide theory and experiments that demonstrate that the algorithm\nperforms comparably to, and sometimes better than, $k$-NN with an optimal\nchoice of $k$. In particular, we derive bounds on the convergence rates of our\nclassifier that depend on a local quantity we call the `advantage' which is\nsignificantly weaker than the Lipschitz conditions used in previous convergence\nrate proofs. These generalization bounds hinge on a variant of the seminal\nUniform Convergence Theorem due to Vapnik and Chervonenkis; this variant\nconcerns conditional probabilities and may be of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 20:46:58 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Balsubramani", "Akshay", ""], ["Dasgupta", "Sanjoy", ""], ["Freund", "Yoav", ""], ["Moran", "Shay", ""]]}, {"id": "1905.12726", "submitter": "Marc Brittain", "authors": "Marc Brittain, Josh Bertram, Xuxi Yang, Peng Wei", "title": "Prioritized Sequence Experience Replay", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experience replay is widely used in deep reinforcement learning algorithms\nand allows agents to remember and learn from experiences from the past. In an\neffort to learn more efficiently, researchers proposed prioritized experience\nreplay (PER) which samples important transitions more frequently. In this\npaper, we propose Prioritized Sequence Experience Replay (PSER) a framework for\nprioritizing sequences of experience in an attempt to both learn more\nefficiently and to obtain better performance. We compare the performance of PER\nand PSER sampling techniques in a tabular Q-learning environment and in DQN on\nthe Atari 2600 benchmark. We prove theoretically that PSER is guaranteed to\nconverge faster than PER and empirically show PSER substantially improves upon\nPER.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 15:38:00 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 16:04:29 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Brittain", "Marc", ""], ["Bertram", "Josh", ""], ["Yang", "Xuxi", ""], ["Wei", "Peng", ""]]}, {"id": "1905.12728", "submitter": "Fernando Mart\\'inez Plumed", "authors": "Fernando Mart\\'inez-Plumed, C\\`esar Ferri, David Nieves, Jos\\'e\n  Hern\\'andez-Orallo", "title": "Fairness and Missing Values", "comments": "Preprint submitted to Decision Support Systems Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The causes underlying unfair decision making are complex, being internalised\nin different ways by decision makers, other actors dealing with data and\nmodels, and ultimately by the individuals being affected by these decisions.\nOne frequent manifestation of all these latent causes arises in the form of\nmissing values: protected groups are more reluctant to give information that\ncould be used against them, delicate information for some groups can be erased\nby human operators, or data acquisition may simply be less complete and\nsystematic for minority groups. As a result, missing values and bias in data\nare two phenomena that are tightly coupled. However, most recent techniques,\nlibraries and experimental results dealing with fairness in machine learning\nhave simply ignored missing data. In this paper, we claim that fairness\nresearch should not miss the opportunity to deal properly with missing data. To\nsupport this claim, (1) we analyse the sources of missing data and bias, and we\nmap the common causes, (2) we find that rows containing missing values are\nusually fairer than the rest, which should not be treated as the uncomfortable\nugly data that different techniques and libraries get rid of at the first\noccasion, and (3) we study the trade-off between performance and fairness when\nthe rows with missing values are used (either because the technique deals with\nthem directly or by imputation methods). We end the paper with a series of\nrecommended procedures about what to do with missing data when aiming for fair\ndecision making.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 21:09:20 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Mart\u00ednez-Plumed", "Fernando", ""], ["Ferri", "C\u00e8sar", ""], ["Nieves", "David", ""], ["Hern\u00e1ndez-Orallo", "Jos\u00e9", ""]]}, {"id": "1905.12760", "submitter": "Miko{\\l}aj Bi\\'nkowski", "authors": "Miko{\\l}aj Bi\\'nkowski, R Devon Hjelm and Aaron Courville", "title": "Batch weight for domain adaptation with mass shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain transfer is the task of transferring or translating\nsamples from a source distribution to a different target distribution. Current\nsolutions unsupervised domain transfer often operate on data on which the modes\nof the distribution are well-matched, for instance have the same frequencies of\nclasses between source and target distributions. However, these models do not\nperform well when the modes are not well-matched, as would be the case when\nsamples are drawn independently from two different, but related, domains. This\nmode imbalance is problematic as generative adversarial networks (GANs), a\nsuccessful approach in this setting, are sensitive to mode frequency, which\nresults in a mismatch of semantics between source samples and generated samples\nof the target distribution. We propose a principled method of re-weighting\ntraining samples to correct for such mass shift between the transferred\ndistributions, which we call batch-weight. We also provide rigorous\nprobabilistic setting for domain transfer and new simplified objective for\ntraining transfer networks, an alternative to complex, multi-component loss\nfunctions used in the current state-of-the art image-to-image translation\nmodels. The new objective stems from the discrimination of joint distributions\nand enforces cycle-consistency in an abstract, high-level, rather than\npixel-wise, sense. Lastly, we experimentally show the effectiveness of the\nproposed methods in several image-to-image translation tasks.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 22:43:29 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Bi\u0144kowski", "Miko\u0142aj", ""], ["Hjelm", "R Devon", ""], ["Courville", "Aaron", ""]]}, {"id": "1905.12767", "submitter": "Eugene Ie", "authors": "Eugene Ie, Vihan Jain, Jing Wang, Sanmit Narvekar, Ritesh Agarwal, Rui\n  Wu, Heng-Tze Cheng, Morgane Lustman, Vince Gatto, Paul Covington, Jim\n  McFadden, Tushar Chandra, Craig Boutilier", "title": "Reinforcement Learning for Slate-based Recommender Systems: A Tractable\n  Decomposition and Practical Methodology", "comments": "Short version to appear IJCAI-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most practical recommender systems focus on estimating immediate user\nengagement without considering the long-term effects of recommendations on user\nbehavior. Reinforcement learning (RL) methods offer the potential to optimize\nrecommendations for long-term user engagement. However, since users are often\npresented with slates of multiple items - which may have interacting effects on\nuser choice - methods are required to deal with the combinatorics of the RL\naction space. In this work, we address the challenge of making slate-based\nrecommendations to optimize long-term value using RL. Our contributions are\nthree-fold. (i) We develop SLATEQ, a decomposition of value-based\ntemporal-difference and Q-learning that renders RL tractable with slates. Under\nmild assumptions on user choice behavior, we show that the long-term value\n(LTV) of a slate can be decomposed into a tractable function of its component\nitem-wise LTVs. (ii) We outline a methodology that leverages existing myopic\nlearning-based recommenders to quickly develop a recommender that handles LTV.\n(iii) We demonstrate our methods in simulation, and validate the scalability of\ndecomposed TD-learning using SLATEQ in live experiments on YouTube.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 22:55:28 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 07:27:00 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Ie", "Eugene", ""], ["Jain", "Vihan", ""], ["Wang", "Jing", ""], ["Narvekar", "Sanmit", ""], ["Agarwal", "Ritesh", ""], ["Wu", "Rui", ""], ["Cheng", "Heng-Tze", ""], ["Lustman", "Morgane", ""], ["Gatto", "Vince", ""], ["Covington", "Paul", ""], ["McFadden", "Jim", ""], ["Chandra", "Tushar", ""], ["Boutilier", "Craig", ""]]}, {"id": "1905.12782", "submitter": "Mina Karzand", "authors": "Mina Karzand, and Robert D. Nowak", "title": "MaxiMin Active Learning in Overparameterized Model Classes}", "comments": "43 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating labeled training datasets has become a major bottleneck in Machine\nLearning (ML) pipelines. Active ML aims to address this issue by designing\nlearning algorithms that automatically and adaptively select the most\ninformative examples for labeling so that human time is not wasted labeling\nirrelevant, redundant, or trivial examples. This paper proposes a new approach\nto active ML with nonparametric or overparameterized models such as kernel\nmethods and neural networks. In the context of binary classification, the new\napproach is shown to possess a variety of desirable properties that allow\nactive learning algorithms to automatically and efficiently identify decision\nboundaries and data clusters.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 23:34:44 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 04:18:40 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Karzand", "Mina", ""], ["Nowak", "Robert D.", ""]]}, {"id": "1905.12786", "submitter": "Anjishnu Kumar", "authors": "Daniele Bonadiman, Anjishnu Kumar and Arpit Mittal", "title": "Large Scale Question Paraphrase Retrieval with Smoothed Deep Metric\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of a Question Paraphrase Retrieval (QPR) system is to retrieve\nequivalent questions that result in the same answer as the original question.\nSuch a system can be used to understand and answer rare and noisy\nreformulations of common questions by mapping them to a set of canonical forms.\nThis has large-scale applications for community Question Answering (cQA) and\nopen-domain spoken language question answering systems. In this paper we\ndescribe a new QPR system implemented as a Neural Information Retrieval (NIR)\nsystem consisting of a neural network sentence encoder and an approximate\nk-Nearest Neighbour index for efficient vector retrieval. We also describe our\nmechanism to generate an annotated dataset for question paraphrase retrieval\nexperiments automatically from question-answer logs via distant supervision. We\nshow that the standard loss function in NIR, triplet loss, does not perform\nwell with noisy labels. We propose smoothed deep metric loss (SDML) and with\nour experiments on two QPR datasets we show that it significantly outperforms\ntriplet loss in the noisy label setting.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 23:40:54 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Bonadiman", "Daniele", ""], ["Kumar", "Anjishnu", ""], ["Mittal", "Arpit", ""]]}, {"id": "1905.12807", "submitter": "Ari Kobren", "authors": "Ari Kobren, Pablo Barrio, Oksana Yakhnenko, Johann Hibschman, Ian\n  Langmore", "title": "Constructing High Precision Knowledge Bases with Subjective and Factual\n  Attributes", "comments": "Appears at KDD 2019 Applied Data Science Track, 19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Knowledge bases (KBs) are the backbone of many ubiquitous applications and\nare thus required to exhibit high precision. However, for KBs that store\nsubjective attributes of entities, e.g., whether a movie is \"kid friendly\",\nsimply estimating precision is complicated by the inherent ambiguity in\nmeasuring subjective phenomena. In this work, we develop a method for\nconstructing KBs with tunable precision--i.e., KBs that can be made to operate\nat a specific false positive rate, despite storing both difficult-to-evaluate\nsubjective attributes and more traditional factual attributes. The key to our\napproach is probabilistically modeling user consensus with respect to each\nentity-attribute pair, rather than modeling each pair as either True or False.\nUncertainty in the model is explicitly represented and used to control the KB's\nprecision. We propose three neural networks for fitting the consensus model and\nevaluate each one on data from Google Maps--a large KB of locations and their\nsubjective and factual attributes. The results demonstrate that our learned\nmodels are well-calibrated and thus can successfully be used to control the\nKB's precision. Moreover, when constrained to maintain 95% precision, the best\nconsensus model matches the F-score of a baseline that models each\nentity-attribute pair as a binary variable and does not support tunable\nprecision. When unconstrained, our model dominates the same baseline by 12%\nF-score. Finally, we perform an empirical analysis of attribute-attribute\ncorrelations and show that leveraging them effectively contributes to reduced\nuncertainty and better performance in attribute prediction.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 20:43:23 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 23:45:18 GMT"}, {"version": "v3", "created": "Wed, 31 Jul 2019 13:21:06 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Kobren", "Ari", ""], ["Barrio", "Pablo", ""], ["Yakhnenko", "Oksana", ""], ["Hibschman", "Johann", ""], ["Langmore", "Ian", ""]]}, {"id": "1905.12835", "submitter": "Peng Jin", "authors": "Xingyuan Chen, Yanzhe Li, Peng Jin, Jiuhua Zhang, Xinyu Dai, Jiajun\n  Chen and Gang Song", "title": "Adversarial Sub-sequence for Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial nets (GAN) has been successfully introduced for\ngenerating text to alleviate the exposure bias. However, discriminators in\nthese models only evaluate the entire sequence, which causes feedback sparsity\nand mode collapse. To tackle these problems, we propose a novel mechanism. It\nfirst segments the entire sequence into several sub-sequences. Then these\nsub-sequences, together with the entire sequence, are evaluated individually by\nthe discriminator. At last these feedback signals are all used to guide the\nlearning of GAN. This mechanism learns the generation of both the entire\nsequence and the sub-sequences simultaneously. Learning to generate\nsub-sequences is easy and is helpful in generating an entire sequence. It is\neasy to improve the existing GAN-based models with this mechanism. We rebuild\nthree previous well-designed models with our mechanism, and the experimental\nresults on benchmark data show these models are improved significantly, the\nbest one outperforms the state-of-the-art model.\\footnote[1]{All code and data\nare available at https://github.com/liyzcj/seggan.git\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 02:51:15 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Chen", "Xingyuan", ""], ["Li", "Yanzhe", ""], ["Jin", "Peng", ""], ["Zhang", "Jiuhua", ""], ["Dai", "Xinyu", ""], ["Chen", "Jiajun", ""], ["Song", "Gang", ""]]}, {"id": "1905.12849", "submitter": "Yu Bai", "authors": "Yu Bai, Tengyang Xie, Nan Jiang, Yu-Xiang Wang", "title": "Provably Efficient Q-Learning with Low Switching Cost", "comments": "Published at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We take initial steps in studying PAC-MDP algorithms with limited adaptivity,\nthat is, algorithms that change its exploration policy as infrequently as\npossible during regret minimization. This is motivated by the difficulty of\nrunning fully adaptive algorithms in real-world applications (such as medical\ndomains), and we propose to quantify adaptivity using the notion of local\nswitching cost. Our main contribution, Q-Learning with UCB2 exploration, is a\nmodel-free algorithm for H-step episodic MDP that achieves sublinear regret\nwhose local switching cost in K episodes is $O(H^3SA\\log K)$, and we provide a\nlower bound of $\\Omega(HSA)$ on the local switching cost for any no-regret\nalgorithm. Our algorithm can be naturally adapted to the concurrent setting,\nwhich yields nontrivial results that improve upon prior work in certain\naspects.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 04:35:13 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 02:44:16 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 04:03:32 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Bai", "Yu", ""], ["Xie", "Tengyang", ""], ["Jiang", "Nan", ""], ["Wang", "Yu-Xiang", ""]]}, {"id": "1905.12866", "submitter": "Wenhu Chen", "authors": "Wenhu Chen, Jianshu Chen, Pengda Qin, Xifeng Yan and William Yang Wang", "title": "Semantically Conditioned Dialog Response Generation via Hierarchical\n  Disentangled Self-Attention", "comments": "Accepted to ACL 2019, 9 pages long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantically controlled neural response generation on limited-domain has\nachieved great performance. However, moving towards multi-domain large-scale\nscenarios are shown to be difficult because the possible combinations of\nsemantic inputs grow exponentially with the number of domains. To alleviate\nsuch scalability issue, we exploit the structure of dialog acts to build a\nmulti-layer hierarchical graph, where each act is represented as a root-to-leaf\nroute on the graph. Then, we incorporate such graph structure prior as an\ninductive bias to build a hierarchical disentangled self-attention network,\nwhere we disentangle attention heads to model designated nodes on the dialog\nact graph. By activating different (disentangled) heads at each layer,\ncombinatorially many dialog act semantics can be modeled to control the neural\nresponse generation. On the large-scale Multi-Domain-WOZ dataset, our model can\nyield a significant improvement over the baselines on various automatic and\nhuman evaluation metrics.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 05:57:27 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 05:09:33 GMT"}, {"version": "v3", "created": "Sun, 9 Jun 2019 18:11:47 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Chen", "Wenhu", ""], ["Chen", "Jianshu", ""], ["Qin", "Pengda", ""], ["Yan", "Xifeng", ""], ["Wang", "William Yang", ""]]}, {"id": "1905.12877", "submitter": "Tommy Liu", "authors": "Tommy Liu and Jochen Renz and Peng Zhang and Matthew Stephenson", "title": "Using Restart Heuristics to Improve Agent Performance in Angry Birds", "comments": "To appear: IEEE Conference on Games 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years the Angry Birds AI competition has been held in an\nattempt to develop intelligent agents that can successfully and efficiently\nsolve levels for the video game Angry Birds. Many different agents and\nstrategies have been developed to solve the complex and challenging physical\nreasoning problems associated with such a game. However none of these agents\nattempt one of the key strategies which humans employ to solve Angry Birds\nlevels, which is restarting levels. Restarting is important in Angry Birds\nbecause sometimes the level is no longer solvable or some given shot made has\nlittle to no benefit towards the ultimate goal of the game. This paper proposes\na framework and experimental evaluation for when to restart levels in Angry\nBirds. We demonstrate that restarting is a viable strategy to improve agent\nperformance in many cases.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 06:54:46 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Liu", "Tommy", ""], ["Renz", "Jochen", ""], ["Zhang", "Peng", ""], ["Stephenson", "Matthew", ""]]}, {"id": "1905.12887", "submitter": "Brady Zhou", "authors": "Brady Zhou, Philipp Kr\\\"ahenb\\\"uhl, and Vladlen Koltun", "title": "Does computer vision matter for action?", "comments": "Published in Science Robotics, 4(30), May 2019", "journal-ref": "Science Robotics 22 May 2019: Vol. 4, Issue 30, eaaw6661", "doi": "10.1126/scirobotics.aaw6661", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer vision produces representations of scene content. Much computer\nvision research is predicated on the assumption that these intermediate\nrepresentations are useful for action. Recent work at the intersection of\nmachine learning and robotics calls this assumption into question by training\nsensorimotor systems directly for the task at hand, from pixels to actions,\nwith no explicit intermediate representations. Thus the central question of our\nwork: Does computer vision matter for action? We probe this question and its\noffshoots via immersive simulation, which allows us to conduct controlled\nreproducible experiments at scale. We instrument immersive three-dimensional\nenvironments to simulate challenges such as urban driving, off-road trail\ntraversal, and battle. Our main finding is that computer vision does matter.\nModels equipped with intermediate representations train faster, achieve higher\ntask performance, and generalize better to previously unseen environments. A\nvideo that summarizes the work and illustrates the results can be found at\nhttps://youtu.be/4MfWa2yZ0Jc\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 07:18:33 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 06:33:45 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Zhou", "Brady", ""], ["Kr\u00e4henb\u00fchl", "Philipp", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1905.12897", "submitter": "Seunghyun Yoon", "authors": "Seunghyun Yoon, Franck Dernoncourt, Doo Soon Kim, Trung Bui, Kyomin\n  Jung", "title": "A Compare-Aggregate Model with Latent Clustering for Answer Selection", "comments": "5 pages, Accepted as a conference paper at CIKM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel method for a sentence-level\nanswer-selection task that is a fundamental problem in natural language\nprocessing. First, we explore the effect of additional information by adopting\na pretrained language model to compute the vector representation of the input\ntext and by applying transfer learning from a large-scale corpus. Second, we\nenhance the compare-aggregate model by proposing a novel latent clustering\nmethod to compute additional information within the target corpus and by\nchanging the objective function from listwise to pointwise. To evaluate the\nperformance of the proposed approaches, experiments are performed with the\nWikiQA and TREC-QA datasets. The empirical results demonstrate the superiority\nof our proposed approach, which achieve state-of-the-art performance for both\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 07:44:34 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 08:12:51 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Yoon", "Seunghyun", ""], ["Dernoncourt", "Franck", ""], ["Kim", "Doo Soon", ""], ["Bui", "Trung", ""], ["Jung", "Kyomin", ""]]}, {"id": "1905.12941", "submitter": "Nicolas Perrin-Gilbert", "authors": "Thomas Pierrot, Guillaume Ligner, Scott Reed, Olivier Sigaud, Nicolas\n  Perrin, Alexandre Laterre, David Kas, Karim Beguir, Nando de Freitas", "title": "Learning Compositional Neural Programs with Recursive Tree Search and\n  Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel reinforcement learning algorithm, AlphaNPI, that\nincorporates the strengths of Neural Programmer-Interpreters (NPI) and\nAlphaZero. NPI contributes structural biases in the form of modularity,\nhierarchy and recursion, which are helpful to reduce sample complexity, improve\ngeneralization and increase interpretability. AlphaZero contributes powerful\nneural network guided search algorithms, which we augment with recursion.\nAlphaNPI only assumes a hierarchical program specification with sparse rewards:\n1 when the program execution satisfies the specification, and 0 otherwise.\nUsing this specification, AlphaNPI is able to train NPI models effectively with\nRL for the first time, completely eliminating the need for strong supervision\nin the form of execution traces. The experiments show that AlphaNPI can sort as\nwell as previous strongly supervised NPI variants. The AlphaNPI agent is also\ntrained on a Tower of Hanoi puzzle with two disks and is shown to generalize to\npuzzles with an arbitrary number of disk\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 10:08:00 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 12:25:49 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Pierrot", "Thomas", ""], ["Ligner", "Guillaume", ""], ["Reed", "Scott", ""], ["Sigaud", "Olivier", ""], ["Perrin", "Nicolas", ""], ["Laterre", "Alexandre", ""], ["Kas", "David", ""], ["Beguir", "Karim", ""], ["de Freitas", "Nando", ""]]}, {"id": "1905.12966", "submitter": "Zhengui Xue", "authors": "Zhengui Xue, Zhiwei Lin, Hui Wang and Sally McClean", "title": "Quantifying consensus of rankings based on q-support patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rankings, representing preferences over a set of candidates, are widely used\nin many information systems, e.g., group decision making and information\nretrieval. It is of great importance to evaluate the consensus of the obtained\nrankings from multiple agents. An overall measure of the consensus degree\nprovides an insight into the ranking data. Moreover, it could provide a\nquantitative indicator for consensus comparison between groups and further\nimprovement of a ranking system. Existing studies are insufficient in assessing\nthe overall consensus of a ranking set. They did not provide an evaluation of\nthe consensus degree of preference patterns in most rankings. In this paper, a\nnovel consensus quantifying approach, without the need for any correlation or\ndistance functions as in existing studies of consensus, is proposed based on a\nconcept of q-support patterns of rankings. The q-support patterns represent the\ncommonality embedded in a set of rankings. A method for detecting outliers in a\nset of rankings is naturally derived from the proposed consensus quantifying\napproach. Experimental studies are conducted to demonstrate the effectiveness\nof the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 11:21:22 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 16:45:45 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Xue", "Zhengui", ""], ["Lin", "Zhiwei", ""], ["Wang", "Hui", ""], ["McClean", "Sally", ""]]}, {"id": "1905.12990", "submitter": "Vladislav Ryzhikov Dr", "authors": "Vladislav Ryzhikov, Przemyslaw Andrzej Walega, Michael Zakharyaschev", "title": "Data Complexity and Rewritability of Ontology-Mediated Queries in Metric\n  Temporal Logic under the Event-Based Semantics (Full Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the data complexity of answering queries mediated by metric\ntemporal logic ontologies under the event-based semantics assuming that data\ninstances are finite timed words timestamped with binary fractions. We identify\nclasses of ontology-mediated queries answering which can be done in AC0, NC1,\nL, NL, P, and coNP for data complexity, provide their rewritings to first-order\nlogic and its extensions with primitive recursion, transitive closure or\ndatalog, and establish lower complexity bounds.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 12:08:28 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 09:14:38 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Ryzhikov", "Vladislav", ""], ["Walega", "Przemyslaw Andrzej", ""], ["Zakharyaschev", "Michael", ""]]}, {"id": "1905.13010", "submitter": "Arthur Charlesworth", "authors": "Arthur Charlesworth", "title": "Definitively Identifying an Inherent Limitation to Actual Cognition", "comments": "45 pages, 5 figures; changed author's email address", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A century ago, discoveries of a serious kind of logical error made separately\nby several leading mathematicians led to acceptance of a sharply enhanced\nstandard for rigor within what ultimately became the foundation for Computer\nScience. By 1931, Godel had obtained a definitive and remarkable result: an\ninherent limitation to that foundation. The resulting limitation is not\napplicable to actual human cognition, to even the smallest extent, unless both\nof these extremely brittle assumptions hold: humans are infallible reasoners\nand reason solely via formal inference rules. Both assumptions are contradicted\nby empirical data from well-known Cognitive Science experiments. This article\ninvestigates how a novel multi-part methodology recasts computability theory\nwithin Computer Science to obtain a definitive limitation whose application to\nhuman cognition avoids assumptions contradicting empirical data. The limitation\napplies to individual humans, to finite sets of humans, and more generally to\nany real-world entity.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 17:55:38 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 17:38:27 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Charlesworth", "Arthur", ""]]}, {"id": "1905.13049", "submitter": "Xiaoran Xu", "authors": "Xiaoran Xu, Wei Feng, Zhiqing Sun, Zhi-Hong Deng", "title": "Neural Consciousness Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of reasoning beyond data fitting is substantial to deep learning\nsystems in order to make a leap forward towards artificial general\nintelligence. A lot of efforts have been made to model neural-based reasoning\nas an iterative decision-making process based on recurrent networks and\nreinforcement learning. Instead, inspired by the consciousness prior proposed\nby Yoshua Bengio, we explore reasoning with the notion of attentive awareness\nfrom a cognitive perspective, and formulate it in the form of attentive message\npassing on graphs, called neural consciousness flow (NeuCFlow). Aiming to\nbridge the gap between deep learning systems and reasoning, we propose an\nattentive computation framework with a three-layer architecture, which consists\nof an unconsciousness flow layer, a consciousness flow layer, and an attention\nflow layer. We implement the NeuCFlow model with graph neural networks (GNNs)\nand conditional transition matrices. Our attentive computation greatly reduces\nthe complexity of vanilla GNN-based methods, capable of running on large-scale\ngraphs. We validate our model for knowledge graph reasoning by solving a series\nof knowledge base completion (KBC) tasks. The experimental results show\nNeuCFlow significantly outperforms previous state-of-the-art KBC methods,\nincluding the embedding-based and the path-based. The reproducible code can be\nfound by the link below.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 13:33:55 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Xu", "Xiaoran", ""], ["Feng", "Wei", ""], ["Sun", "Zhiqing", ""], ["Deng", "Zhi-Hong", ""]]}, {"id": "1905.13053", "submitter": "Roman Yampolskiy", "authors": "Roman V. Yampolskiy", "title": "Unpredictability of AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The young field of AI Safety is still in the process of identifying its\nchallenges and limitations. In this paper, we formally describe one such\nimpossibility result, namely Unpredictability of AI. We prove that it is\nimpossible to precisely and consistently predict what specific actions a\nsmarter-than-human intelligent system will take to achieve its objectives, even\nif we know terminal goals of the system. In conclusion, impact of\nUnpredictability on AI Safety is discussed.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 14:37:16 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Yampolskiy", "Roman V.", ""]]}, {"id": "1905.13100", "submitter": "Zsolt Zombori", "authors": "Zsolt Zombori, Adri\\'an Csisz\\'arik, Henryk Michalewski, Cezary\n  Kaliszyk, Josef Urban", "title": "Towards Finding Longer Proofs", "comments": "16 pages, 3 figures, published at TABLEAUX2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a reinforcement learning (RL) based guidance system for automated\ntheorem proving geared towards Finding Longer Proofs (FLoP). Unlike most\nlearning based approaches, we focus on generalising from very little training\ndata and achieving near complete confidence. We use several simple, structured\ndatasets with very long proofs to show that FLoP can successfully generalise a\nsingle training proof to a large class of related problems. On these\nbenchmarks, FLoP is competitive with strong theorem provers despite using very\nlimited search, due to its ability to solve problems that are prohibitively\nlong for other systems.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 15:23:26 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 14:15:58 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Zombori", "Zsolt", ""], ["Csisz\u00e1rik", "Adri\u00e1n", ""], ["Michalewski", "Henryk", ""], ["Kaliszyk", "Cezary", ""], ["Urban", "Josef", ""]]}, {"id": "1905.13118", "submitter": "Usman Raza", "authors": "Aftab Khan, Tim Farnham, Roget Kou, Usman Raza, Thajanee Premalal,\n  Aleksandar Stanoev, William Thompson", "title": "Standing on the Shoulders of Giants: AI-driven Calibration of\n  Localisation Technologies", "comments": "Pre-print version of the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High accuracy localisation technologies exist but are prohibitively expensive\nto deploy for large indoor spaces such as warehouses, factories, and\nsupermarkets to track assets and people. However, these technologies can be\nused to lend their highly accurate localisation capabilities to low-cost,\ncommodity, and less-accurate technologies. In this paper, we bridge this link\nby proposing a technology-agnostic calibration framework based on artificial\nintelligence to assist such low-cost technologies through highly accurate\nlocalisation systems. A single-layer neural network is used to calibrate less\naccurate technology using more accurate one such as BLE using UWB and UWB using\na professional motion tracking system. On a real indoor testbed, we demonstrate\nan increase in accuracy of approximately 70% for BLE and 50% for UWB. Not only\nthe proposed approach requires a very short measurement campaign, the low\ncomplexity of the single-layer neural network also makes it ideal for\ndeployment on constrained devices typically for localisation purposes.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 15:50:14 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Khan", "Aftab", ""], ["Farnham", "Tim", ""], ["Kou", "Roget", ""], ["Raza", "Usman", ""], ["Premalal", "Thajanee", ""], ["Stanoev", "Aleksandar", ""], ["Thompson", "William", ""]]}, {"id": "1905.13148", "submitter": "Qun Song", "authors": "Qun Song, Zhenyu Yan, and Rui Tan", "title": "Moving Target Defense for Deep Visual Sensing against Adversarial\n  Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning based visual sensing has achieved attractive accuracy but is\nshown vulnerable to adversarial example attacks. Specifically, once the\nattackers obtain the deep model, they can construct adversarial examples to\nmislead the model to yield wrong classification results. Deployable adversarial\nexamples such as small stickers pasted on the road signs and lanes have been\nshown effective in misleading advanced driver-assistance systems. Many existing\ncountermeasures against adversarial examples build their security on the\nattackers' ignorance of the defense mechanisms. Thus, they fall short of\nfollowing Kerckhoffs's principle and can be subverted once the attackers know\nthe details of the defense. This paper applies the strategy of moving target\ndefense (MTD) to generate multiple new deep models after system deployment,\nthat will collaboratively detect and thwart adversarial examples. Our MTD\ndesign is based on the adversarial examples' minor transferability to models\ndiffering from the one (e.g., the factory-designed model) used for attack\nconstruction. The post-deployment quasi-secret deep models significantly\nincrease the bar for the attackers to construct effective adversarial examples.\nWe also apply the technique of serial data fusion with early stopping to reduce\nthe inference time by a factor of up to 5 while maintaining the sensing and\ndefense performance. Extensive evaluation based on three datasets including a\nroad sign image database and a GPU-equipped Jetson embedded computing board\nshows the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 08:22:32 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Song", "Qun", ""], ["Yan", "Zhenyu", ""], ["Tan", "Rui", ""]]}, {"id": "1905.13164", "submitter": "Yang Liu", "authors": "Yang Liu and Mirella Lapata", "title": "Hierarchical Transformers for Multi-Document Summarization", "comments": "to appear at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a neural summarization model which can effectively\nprocess multiple input documents and distill Transformer architecture with the\nability to encode documents in a hierarchical manner. We represent\ncross-document relationships via an attention mechanism which allows to share\ninformation as opposed to simply concatenating text spans and processing them\nas a flat sequence. Our model learns latent dependencies among textual units,\nbut can also take advantage of explicit graph representations focusing on\nsimilarity or discourse relations. Empirical results on the WikiSum dataset\ndemonstrate that the proposed architecture brings substantial improvements over\nseveral strong baselines.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 16:49:11 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Liu", "Yang", ""], ["Lapata", "Mirella", ""]]}, {"id": "1905.13178", "submitter": "Risto Miikkulainen", "authors": "Risto Miikkulainen, Bret Greenstein, Babak Hodjat, Jerry Smith", "title": "Better Future through AI: Avoiding Pitfalls and Guiding AI Towards its\n  Full Potential", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) technology is rapidly changing many areas of\nsociety. While there is tremendous potential in this transition, there are\nseveral pitfalls as well. Using the history of computing and the world-wide web\nas a guide, in this article we identify those pitfalls and actions that lead AI\ndevelopment to its full potential. If done right, AI will be instrumental in\nachieving the goals we set for economy, society, and the world in general.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 17:06:11 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Miikkulainen", "Risto", ""], ["Greenstein", "Bret", ""], ["Hodjat", "Babak", ""], ["Smith", "Jerry", ""]]}, {"id": "1905.13192", "submitter": "Simon Du", "authors": "Simon S. Du, Kangcheng Hou, Barnab\\'as P\\'oczos, Ruslan Salakhutdinov,\n  Ruosong Wang, Keyulu Xu", "title": "Graph Neural Tangent Kernel: Fusing Graph Neural Networks with Graph\n  Kernels", "comments": "In NeurIPS 2019. Code available: https://github.com/KangchengHou/gntk", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While graph kernels (GKs) are easy to train and enjoy provable theoretical\nguarantees, their practical performances are limited by their expressive power,\nas the kernel function often depends on hand-crafted combinatorial features of\ngraphs. Compared to graph kernels, graph neural networks (GNNs) usually achieve\nbetter practical performance, as GNNs use multi-layer architectures and\nnon-linear activation functions to extract high-order information of graphs as\nfeatures. However, due to the large number of hyper-parameters and the\nnon-convex nature of the training procedure, GNNs are harder to train.\nTheoretical guarantees of GNNs are also not well-understood. Furthermore, the\nexpressive power of GNNs scales with the number of parameters, and thus it is\nhard to exploit the full power of GNNs when computing resources are limited.\nThe current paper presents a new class of graph kernels, Graph Neural Tangent\nKernels (GNTKs), which correspond to infinitely wide multi-layer GNNs trained\nby gradient descent. GNTKs enjoy the full expressive power of GNNs and inherit\nadvantages of GKs. Theoretically, we show GNTKs provably learn a class of\nsmooth functions on graphs. Empirically, we test GNTKs on graph classification\ndatasets and show they achieve strong performance.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 17:23:23 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 15:30:12 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Du", "Simon S.", ""], ["Hou", "Kangcheng", ""], ["P\u00f3czos", "Barnab\u00e1s", ""], ["Salakhutdinov", "Ruslan", ""], ["Wang", "Ruosong", ""], ["Xu", "Keyulu", ""]]}, {"id": "1905.13195", "submitter": "Raanan Rohekar", "authors": "Raanan Y. Rohekar, Yaniv Gurwicz, Shami Nisimov, Gal Novik", "title": "Modeling Uncertainty by Learning a Hierarchy of Deep Neural Connections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Modeling uncertainty in deep neural networks, despite recent important\nadvances, is still an open problem. Bayesian neural networks are a powerful\nsolution, where the prior over network weights is a design choice, often a\nnormal distribution or other distribution encouraging sparsity. However, this\nprior is agnostic to the generative process of the input data, which might lead\nto unwarranted generalization for out-of-distribution tested data. We suggest\nthe presence of a confounder for the relation between the input data and the\ndiscriminative function given the target label. We propose an approach for\nmodeling this confounder by sharing neural connectivity patterns between the\ngenerative and discriminative networks. This approach leads to a new deep\narchitecture, where networks are sampled from the posterior of local causal\nstructures, and coupled into a compact hierarchy. We demonstrate that sampling\nnetworks from this hierarchy, proportionally to their posterior, is efficient\nand enables estimating various types of uncertainties. Empirical evaluations of\nour method demonstrate significant improvement compared to state-of-the-art\ncalibration and out-of-distribution detection methods.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 17:36:19 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 12:27:49 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Rohekar", "Raanan Y.", ""], ["Gurwicz", "Yaniv", ""], ["Nisimov", "Shami", ""], ["Novik", "Gal", ""]]}, {"id": "1905.13211", "submitter": "Keyulu Xu", "authors": "Keyulu Xu, Jingling Li, Mozhi Zhang, Simon S. Du, Ken-ichi\n  Kawarabayashi, Stefanie Jegelka", "title": "What Can Neural Networks Reason About?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have succeeded in many reasoning tasks. Empirically, these\ntasks require specialized network structures, e.g., Graph Neural Networks\n(GNNs) perform well on many such tasks, but less structured networks fail.\nTheoretically, there is limited understanding of why and when a network\nstructure generalizes better than others, although they have equal expressive\npower. In this paper, we develop a framework to characterize which reasoning\ntasks a network can learn well, by studying how well its computation structure\naligns with the algorithmic structure of the relevant reasoning process. We\nformally define this algorithmic alignment and derive a sample complexity bound\nthat decreases with better alignment. This framework offers an explanation for\nthe empirical success of popular reasoning models, and suggests their\nlimitations. As an example, we unify seemingly different reasoning tasks, such\nas intuitive physics, visual question answering, and shortest paths, via the\nlens of a powerful algorithmic paradigm, dynamic programming (DP). We show that\nGNNs align with DP and thus are expected to solve these tasks. On several\nreasoning tasks, our theory is supported by empirical results.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 17:53:30 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 21:50:31 GMT"}, {"version": "v3", "created": "Sun, 29 Sep 2019 20:42:29 GMT"}, {"version": "v4", "created": "Sat, 15 Feb 2020 06:56:25 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Xu", "Keyulu", ""], ["Li", "Jingling", ""], ["Zhang", "Mozhi", ""], ["Du", "Simon S.", ""], ["Kawarabayashi", "Ken-ichi", ""], ["Jegelka", "Stefanie", ""]]}, {"id": "1905.13225", "submitter": "Ismael Tito Freire Gonz\\'alez", "authors": "Ismael T. Freire, Xerxes D. Arsiwalla, Jordi-Ysard Puigb\\`o, Paul\n  Verschure", "title": "Modeling Theory of Mind in Multi-Agent Games Using Adaptive Feedback\n  Control", "comments": "30 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in cognitive science and AI has been to understand how\nautonomous agents might acquire and predict behavioral and mental states of\nother agents in the course of complex social interactions. How does such an\nagent model the goals, beliefs, and actions of other agents it interacts with?\nWhat are the computational principles to model a Theory of Mind (ToM)? Deep\nlearning approaches to address these questions fall short of a better\nunderstanding of the problem. In part, this is due to the black-box nature of\ndeep networks, wherein computational mechanisms of ToM are not readily\nrevealed. Here, we consider alternative hypotheses seeking to model how the\nbrain might realize a ToM. In particular, we propose embodied and situated\nagent models based on distributed adaptive control theory to predict actions of\nother agents in five different game theoretic tasks (Harmony Game, Hawk-Dove,\nStag-Hunt, Prisoner's Dilemma and Battle of the Exes). Our multi-layer control\nmodels implement top-down predictions from adaptive to reactive layers of\ncontrol and bottom-up error feedback from reactive to adaptive layers. We test\ncooperative and competitive strategies among seven different agent models\n(cooperative, greedy, tit-for-tat, reinforcement-based, rational, predictive\nand other's-model agents). We show that, compared to pure reinforcement-based\nstrategies, probabilistic learning agents modeled on rational, predictive and\nother's-model phenotypes perform better in game-theoretic metrics across tasks.\nOur autonomous multi-agent models capture systems-level processes underlying a\nToM and highlight architectural principles of ToM from a control-theoretic\nperspective.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 18:26:26 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Freire", "Ismael T.", ""], ["Arsiwalla", "Xerxes D.", ""], ["Puigb\u00f2", "Jordi-Ysard", ""], ["Verschure", "Paul", ""]]}, {"id": "1905.13258", "submitter": "Sultan Khan Daud", "authors": "Sultan Daud Khan and Habib Ullah", "title": "A survey of advances in vision-based vehicle re-identification", "comments": "17 pages; 21 figures; journal paper", "journal-ref": "Computer Vision and Image Understanding 2019", "doi": "10.1016/j.cviu.2019.03.001", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle re-identification (V-reID) has become significantly popular in the\ncommunity due to its applications and research significance. In particular, the\nV-reID is an important problem that still faces numerous open challenges. This\npaper reviews different V-reID methods including sensor based methods, hybrid\nmethods, and vision based methods which are further categorized into\nhand-crafted feature based methods and deep feature based methods. The vision\nbased methods make the V-reID problem particularly interesting, and our review\nsystematically addresses and evaluates these methods for the first time. We\nconduct experiments on four comprehensive benchmark datasets and compare the\nperformances of recent hand-crafted feature based methods and deep feature\nbased methods. We present the detail analysis of these methods in terms of mean\naverage precision (mAP) and cumulative matching curve (CMC). These analyses\nprovide objective insight into the strengths and weaknesses of these methods.\nWe also provide the details of different V-reID datasets and critically discuss\nthe challenges and future trends of V-reID methods.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 18:45:40 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Khan", "Sultan Daud", ""], ["Ullah", "Habib", ""]]}, {"id": "1905.13277", "submitter": "Aditya Golatkar", "authors": "Aditya Golatkar, Alessandro Achille, Stefano Soatto", "title": "Time Matters in Regularizing Deep Networks: Weight Decay and Data\n  Augmentation Affect Early Learning Dynamics, Matter Little Near Convergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization is typically understood as improving generalization by\naltering the landscape of local extrema to which the model eventually\nconverges. Deep neural networks (DNNs), however, challenge this view: We show\nthat removing regularization after an initial transient period has little\neffect on generalization, even if the final loss landscape is the same as if\nthere had been no regularization. In some cases, generalization even improves\nafter interrupting regularization. Conversely, if regularization is applied\nonly after the initial transient, it has no effect on the final solution, whose\ngeneralization gap is as bad as if regularization never happened. This suggests\nthat what matters for training deep networks is not just whether or how, but\nwhen to regularize. The phenomena we observe are manifest in different datasets\n(CIFAR-10, CIFAR-100), different architectures (ResNet-18, All-CNN), different\nregularization methods (weight decay, data augmentation), different learning\nrate schedules (exponential, piece-wise constant). They collectively suggest\nthat there is a ``critical period'' for regularizing deep networks that is\ndecisive of the final performance. More analysis should, therefore, focus on\nthe transient rather than asymptotic behavior of learning.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 19:57:39 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Golatkar", "Aditya", ""], ["Achille", "Alessandro", ""], ["Soatto", "Stefano", ""]]}, {"id": "1905.13302", "submitter": "John Pavlopoulos", "authors": "Vasiliki Kougia, John Pavlopoulos and Ion Androutsopoulos", "title": "A Survey on Biomedical Image Captioning", "comments": "SiVL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image captioning applied to biomedical images can assist and accelerate the\ndiagnosis process followed by clinicians. This article is the first survey of\nbiomedical image captioning, discussing datasets, evaluation measures, and\nstate of the art methods. Additionally, we suggest two baselines, a weak and a\nstronger one; the latter outperforms all current state of the art systems on\none of the datasets.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 15:47:28 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Kougia", "Vasiliki", ""], ["Pavlopoulos", "John", ""], ["Androutsopoulos", "Ion", ""]]}, {"id": "1905.13315", "submitter": "Dong Li", "authors": "Dong Li, Qichao Zhang, Dongbin Zhao, Yuzheng Zhuang, Bin Wang, Wulong\n  Liu, Rasul Tutunov, Jun Wang", "title": "Graph Attention Memory for Visual Navigation", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual navigation in complex environments is inefficient with traditional\nreactive policy or general-purposed recurrent policy. To address the long-term\nmemory issue, this paper proposes a graph attention memory (GAM) architecture\nconsisting of memory construction module, graph attention module and control\nmodule. The memory construction module builds the topological graph based on\nsupervised learning by taking the exploration prior. Then, guided attention\nfeatures are extracted with the graph attention module. Finally, the deep\nreinforcement learning based control module makes decisions based on visual\nobservations and guided attention features. Detailed convergence analysis of\nGAM is presented in this paper. We evaluate GAM-based navigation system in two\ncomplex 3D environments. Experimental results show that the GAM-based\nnavigation system significantly improves learning efficiency and outperforms\nall baselines in average success rate.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 08:00:54 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 13:40:49 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Li", "Dong", ""], ["Zhang", "Qichao", ""], ["Zhao", "Dongbin", ""], ["Zhuang", "Yuzheng", ""], ["Wang", "Bin", ""], ["Liu", "Wulong", ""], ["Tutunov", "Rasul", ""], ["Wang", "Jun", ""]]}, {"id": "1905.13320", "submitter": "Kavosh Asadi", "authors": "Kavosh Asadi, Dipendra Misra, Seungchan Kim, Michel L. Littman", "title": "Combating the Compounding-Error Problem with a Multi-step Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning is an appealing framework for creating\nagents that learn, plan, and act in sequential environments. Model-based\nalgorithms typically involve learning a transition model that takes a state and\nan action and outputs the next state---a one-step model. This model can be\ncomposed with itself to enable predicting multiple steps into the future, but\none-step prediction errors can get magnified, leading to unacceptable\ninaccuracy. This compounding-error problem plagues planning and undermines\nmodel-based reinforcement learning. In this paper, we address the\ncompounding-error problem by introducing a multi-step model that directly\noutputs the outcome of executing a sequence of actions. Novel theoretical and\nempirical results indicate that the multi-step model is more conducive to\nefficient value-function estimation, and it yields better action selection\ncompared to the one-step model. These results make a strong case for using\nmulti-step models in the context of model-based reinforcement learning.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 21:30:29 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Asadi", "Kavosh", ""], ["Misra", "Dipendra", ""], ["Kim", "Seungchan", ""], ["Littman", "Michel L.", ""]]}, {"id": "1905.13341", "submitter": "Nan Jiang", "authors": "Nan Jiang", "title": "On Value Functions and the Agent-Environment Boundary", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When function approximation is deployed in reinforcement learning (RL), the\nsame problem may be formulated in different ways, often by treating a\npre-processing step as a part of the environment or as part of the agent. As a\nconsequence, fundamental concepts in RL, such as (optimal) value functions, are\nnot uniquely defined as they depend on where we draw this agent-environment\nboundary, causing problems in theoretical analyses that provide optimality\nguarantees. We address this issue via a simple and novel boundary-invariant\nanalysis of Fitted Q-Iteration, a representative RL algorithm, where the\nassumptions and the guarantees are invariant to the choice of boundary. We also\ndiscuss closely related issues on state resetting and Monte-Carlo Tree Search,\ndeterministic vs stochastic systems, imitation learning, and the verifiability\nof theoretical assumptions from data.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 22:39:57 GMT"}, {"version": "v2", "created": "Sun, 16 Jun 2019 04:58:36 GMT"}, {"version": "v3", "created": "Mon, 1 Jun 2020 03:28:44 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Jiang", "Nan", ""]]}, {"id": "1905.13344", "submitter": "Vaishnavh Nagarajan", "authors": "Vaishnavh Nagarajan, J. Zico Kolter", "title": "Deterministic PAC-Bayesian generalization bounds for deep networks via\n  generalizing noise-resilience", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of overparameterized deep networks to generalize well has been\nlinked to the fact that stochastic gradient descent (SGD) finds solutions that\nlie in flat, wide minima in the training loss -- minima where the output of the\nnetwork is resilient to small random noise added to its parameters. So far this\nobservation has been used to provide generalization guarantees only for neural\nnetworks whose parameters are either \\textit{stochastic} or\n\\textit{compressed}. In this work, we present a general PAC-Bayesian framework\nthat leverages this observation to provide a bound on the original network\nlearned -- a network that is deterministic and uncompressed. What enables us to\ndo this is a key novelty in our approach: our framework allows us to show that\nif on training data, the interactions between the weight matrices satisfy\ncertain conditions that imply a wide training loss minimum, these conditions\nthemselves {\\em generalize} to the interactions between the matrices on test\ndata, thereby implying a wide test loss minimum. We then apply our general\nframework in a setup where we assume that the pre-activation values of the\nnetwork are not too small (although we assume this only on the training data).\nIn this setup, we provide a generalization guarantee for the original\n(deterministic, uncompressed) network, that does not scale with product of the\nspectral norms of the weight matrices -- a guarantee that would not have been\npossible with prior approaches.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 22:45:06 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Nagarajan", "Vaishnavh", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1905.13357", "submitter": "Vaneet Aggarwal", "authors": "Mridul Agarwal and Vaneet Aggarwal and Arnob Ghosh and Nilay Tiwari", "title": "Reinforcement Learning for Mean Field Game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic games provide a framework for interactions among multiple agents\nand enable a myriad of applications. In these games, agents decide on actions\nsimultaneously, the state of every agent moves to the next state, and each\nagent receives a reward. However, finding an equilibrium (if exists) in this\ngame is often difficult when the number of agents becomes large. This paper\nfocuses on finding a mean-field equilibrium (MFE) in an action coupled\nstochastic game setting in an episodic framework. It is assumed that the impact\nof the other agents' can be assumed by the empirical distribution of the mean\nof the actions. All agents know the action distribution and employ lower-myopic\nbest response dynamics to choose the optimal oblivious strategy. This paper\nproposes a posterior sampling based approach for reinforcement learning in the\nmean-field game, where each agent samples a transition probability from the\nprevious transitions. We show that the policy and action distributions converge\nto the optimal oblivious strategy and the limiting distribution, respectively,\nwhich constitute an MFE.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 23:58:22 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 18:29:06 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Agarwal", "Mridul", ""], ["Aggarwal", "Vaneet", ""], ["Ghosh", "Arnob", ""], ["Tiwari", "Nilay", ""]]}, {"id": "1905.13372", "submitter": "Mariya Popova", "authors": "Mariya Popova, Mykhailo Shvets, Junier Oliva, Olexandr Isayev", "title": "MolecularRNN: Generating realistic molecular graphs with optimized\n  properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.MN q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing new molecules with a set of predefined properties is a core problem\nin modern drug discovery and development. There is a growing need for de-novo\ndesign methods that would address this problem. We present MolecularRNN, the\ngraph recurrent generative model for molecular structures. Our model generates\ndiverse realistic molecular graphs after likelihood pretraining on a big\ndatabase of molecules. We perform an analysis of our pretrained models on\nlarge-scale generated datasets of 1 million samples. Further, the model is\ntuned with policy gradient algorithm, provided a critic that estimates the\nreward for the property of interest. We show a significant distribution shift\nto the desired range for lipophilicity, drug-likeness, and melting point\noutperforming state-of-the-art works. With the use of rejection sampling based\non valency constraints, our model yields 100% validity. Moreover, we show that\ninvalid molecules provide a rich signal to the model through the use of\nstructure penalty in our reinforcement learning pipeline.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 01:33:13 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Popova", "Mariya", ""], ["Shvets", "Mykhailo", ""], ["Oliva", "Junier", ""], ["Isayev", "Olexandr", ""]]}, {"id": "1905.13380", "submitter": "Kinzang Chhogyal", "authors": "Kinzang Chhogyal, Abhaya Nayak, Aditya Ghose, Hoa Khanh Dam", "title": "A Value-based Trust Assessment Model for Multi-agent Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An agent's assessment of its trust in another agent is commonly taken to be a\nmeasure of the reliability/predictability of the latter's actions. It is based\non the trustor's past observations of the behaviour of the trustee and requires\nno knowledge of the inner-workings of the trustee. However, in situations that\nare new or unfamiliar, past observations are of little help in assessing trust.\nIn such cases, knowledge about the trustee can help. A particular type of\nknowledge is that of values - things that are important to the trustor and the\ntrustee. In this paper, based on the premise that the more values two agents\nshare, the more they should trust one another, we propose a simple approach to\ntrust assessment between agents based on values, taking into account if agents\ntrust cautiously or boldly, and if they depend on others in carrying out a\ntask.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 02:08:20 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Chhogyal", "Kinzang", ""], ["Nayak", "Abhaya", ""], ["Ghose", "Aditya", ""], ["Dam", "Hoa Khanh", ""]]}, {"id": "1905.13382", "submitter": "Mingbao Lin", "authors": "Mingbao Lin, Rongrong Ji, Shen Chen, Feng Zheng, Xiaoshuai Sun,\n  Baochang Zhang, Liujuan Cao, Guodong Guo, Feiyue Huang", "title": "Supervised Online Hashing via Similarity Distribution Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online hashing has attracted extensive research attention when facing\nstreaming data. Most online hashing methods, learning binary codes based on\npairwise similarities of training instances, fail to capture the semantic\nrelationship, and suffer from a poor generalization in large-scale applications\ndue to large variations. In this paper, we propose to model the similarity\ndistributions between the input data and the hashing codes, upon which a novel\nsupervised online hashing method, dubbed as Similarity Distribution based\nOnline Hashing (SDOH), is proposed, to keep the intrinsic semantic relationship\nin the produced Hamming space. Specifically, we first transform the discrete\nsimilarity matrix into a probability matrix via a Gaussian-based normalization\nto address the extremely imbalanced distribution issue. And then, we introduce\na scaling Student t-distribution to solve the challenging initialization\nproblem, and efficiently bridge the gap between the known and unknown\ndistributions. Lastly, we align the two distributions via minimizing the\nKullback-Leibler divergence (KL-diverence) with stochastic gradient descent\n(SGD), by which an intuitive similarity constraint is imposed to update hashing\nmodel on the new streaming data with a powerful generalizing ability to the\npast data. Extensive experiments on three widely-used benchmarks validate the\nsuperiority of the proposed SDOH over the state-of-the-art methods in the\nonline retrieval task.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 02:12:41 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Lin", "Mingbao", ""], ["Ji", "Rongrong", ""], ["Chen", "Shen", ""], ["Zheng", "Feng", ""], ["Sun", "Xiaoshuai", ""], ["Zhang", "Baochang", ""], ["Cao", "Liujuan", ""], ["Guo", "Guodong", ""], ["Huang", "Feiyue", ""]]}, {"id": "1905.13402", "submitter": "Ashwin Balakrishna", "authors": "Brijen Thananjeyan, Ashwin Balakrishna, Ugo Rosolia, Felix Li, Rowan\n  McAllister, Joseph E. Gonzalez, Sergey Levine, Francesco Borrelli, Ken\n  Goldberg", "title": "Safety Augmented Value Estimation from Demonstrations (SAVED): Safe Deep\n  Model-Based RL for Sparse Cost Robotic Tasks", "comments": "Robotics and Automation Letters and International Conference on\n  Robotics and Automation 2020. First two authors contributed equally", "journal-ref": "Robotics and Automation Letters 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) for robotics is challenging due to the difficulty\nin hand-engineering a dense cost function, which can lead to unintended\nbehavior, and dynamical uncertainty, which makes exploration and constraint\nsatisfaction challenging. We address these issues with a new model-based\nreinforcement learning algorithm, Safety Augmented Value Estimation from\nDemonstrations (SAVED), which uses supervision that only identifies task\ncompletion and a modest set of suboptimal demonstrations to constrain\nexploration and learn efficiently while handling complex constraints. We then\ncompare SAVED with 3 state-of-the-art model-based and model-free RL algorithms\non 6 standard simulation benchmarks involving navigation and manipulation and a\nphysical knot-tying task on the da Vinci surgical robot. Results suggest that\nSAVED outperforms prior methods in terms of success rate, constraint\nsatisfaction, and sample efficiency, making it feasible to safely learn a\ncontrol policy directly on a real robot in less than an hour. For tasks on the\nrobot, baselines succeed less than 5% of the time while SAVED has a success\nrate of over 75% in the first 50 training iterations. Code and supplementary\nmaterial is available at https://tinyurl.com/saved-rl.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 03:54:25 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 02:50:36 GMT"}, {"version": "v3", "created": "Thu, 10 Oct 2019 08:07:58 GMT"}, {"version": "v4", "created": "Wed, 20 Nov 2019 09:24:29 GMT"}, {"version": "v5", "created": "Sat, 8 Feb 2020 05:27:55 GMT"}, {"version": "v6", "created": "Tue, 3 Mar 2020 10:03:00 GMT"}, {"version": "v7", "created": "Sat, 2 May 2020 00:34:47 GMT"}, {"version": "v8", "created": "Sat, 16 May 2020 00:05:52 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Thananjeyan", "Brijen", ""], ["Balakrishna", "Ashwin", ""], ["Rosolia", "Ugo", ""], ["Li", "Felix", ""], ["McAllister", "Rowan", ""], ["Gonzalez", "Joseph E.", ""], ["Levine", "Sergey", ""], ["Borrelli", "Francesco", ""], ["Goldberg", "Ken", ""]]}, {"id": "1905.13417", "submitter": "Lin Song", "authors": "Lin Song, Shiwei Zhang, Gang Yu, Hongbin Sun", "title": "TACNet: Transition-Aware Context Network for Spatio-Temporal Action\n  Detection", "comments": "CVPR-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current state-of-the-art approaches for spatio-temporal action detection have\nachieved impressive results but remain unsatisfactory for temporal extent\ndetection. The main reason comes from that, there are some ambiguous states\nsimilar to the real actions which may be treated as target actions even by a\nwell-trained network. In this paper, we define these ambiguous samples as\n\"transitional states\", and propose a Transition-Aware Context Network (TACNet)\nto distinguish transitional states. The proposed TACNet includes two main\ncomponents, i.e., temporal context detector and transition-aware classifier.\nThe temporal context detector can extract long-term context information with\nconstant time complexity by constructing a recurrent network. The\ntransition-aware classifier can further distinguish transitional states by\nclassifying action and transitional states simultaneously. Therefore, the\nproposed TACNet can substantially improve the performance of spatio-temporal\naction detection. We extensively evaluate the proposed TACNet on UCF101-24 and\nJ-HMDB datasets. The experimental results demonstrate that TACNet obtains\ncompetitive performance on JHMDB and significantly outperforms the\nstate-of-the-art methods on the untrimmed UCF101-24 in terms of both frame-mAP\nand video-mAP.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 05:14:39 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Song", "Lin", ""], ["Zhang", "Shiwei", ""], ["Yu", "Gang", ""], ["Sun", "Hongbin", ""]]}, {"id": "1905.13438", "submitter": "Tianyu Zhao", "authors": "Tianyu Zhao, Shinsuke Mori and Tatsuya Kawahara", "title": "Content Word-based Sentence Decoding and Evaluating for Open-domain\n  Neural Response Generation", "comments": "13 pages, 2 figures, 8 tables (rejected by ACL 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various encoder-decoder models have been applied to response generation in\nopen-domain dialogs, but a majority of conventional models directly learn a\nmapping from lexical input to lexical output without explicitly modeling\nintermediate representations. Utilizing language hierarchy and modeling\nintermediate information have been shown to benefit many language understanding\nand generation tasks. Motivated by Broca's aphasia, we propose to use a content\nword sequence as an intermediate representation for open-domain response\ngeneration. Experimental results show that the proposed method improves content\nrelatedness of produced responses, and our models can often choose correct\ngrammar for generated content words. Meanwhile, instead of evaluating complete\nsentences, we propose to compute conventional metrics on content word\nsequences, which is a better indicator of content relevance.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 06:36:19 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 17:23:45 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Zhao", "Tianyu", ""], ["Mori", "Shinsuke", ""], ["Kawahara", "Tatsuya", ""]]}, {"id": "1905.13449", "submitter": "Tobias Joppen", "authors": "Tobias Joppen, Tilman Str\\\"ubig, Johannes F\\\"urnkranz", "title": "Ordinal Bucketing for Game Trees using Dynamic Quantile Approximation", "comments": "preprint", "journal-ref": "Proc. IEEE CoG 2019", "doi": "10.1109/CIG.2019.8847965", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a simple and cheap ordinal bucketing algorithm that\napproximately generates $q$-quantiles from an incremental data stream. The\nbucketing is done dynamically in the sense that the amount of buckets $q$\nincreases with the number of seen samples. We show how this can be used in\nOrdinal Monte Carlo Tree Search (OMCTS) to yield better bounds on time and\nspace complexity, especially in the presence of noisy rewards. Besides\ncomplexity analysis and quality tests of quantiles, we evaluate our method\nusing OMCTS in the General Video Game Framework (GVGAI). Our results\ndemonstrate its dominance over vanilla Monte Carlo Tree Search in the presence\nof noise, where OMCTS without bucketing has a very bad time and space\ncomplexity.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 07:35:03 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Joppen", "Tobias", ""], ["Str\u00fcbig", "Tilman", ""], ["F\u00fcrnkranz", "Johannes", ""]]}, {"id": "1905.13453", "submitter": "Alon Talmor", "authors": "Alon Talmor, Jonathan Berant", "title": "MultiQA: An Empirical Investigation of Generalization and Transfer in\n  Reading Comprehension", "comments": "accepted as a long paper at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large number of reading comprehension (RC) datasets has been created\nrecently, but little analysis has been done on whether they generalize to one\nanother, and the extent to which existing datasets can be leveraged for\nimproving performance on new ones. In this paper, we conduct such an\ninvestigation over ten RC datasets, training on one or more source RC datasets,\nand evaluating generalization, as well as transfer to a target RC dataset. We\nanalyze the factors that contribute to generalization, and show that training\non a source RC dataset and transferring to a target dataset substantially\nimproves performance, even in the presence of powerful contextual\nrepresentations from BERT (Devlin et al., 2019). We also find that training on\nmultiple source RC datasets leads to robust generalization and transfer, and\ncan reduce the cost of example collection for a new RC dataset. Following our\nanalysis, we propose MultiQA, a BERT-based model, trained on multiple RC\ndatasets, which leads to state-of-the-art performance on five RC datasets. We\nshare our infrastructure for the benefit of the research community.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 08:05:31 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Talmor", "Alon", ""], ["Berant", "Jonathan", ""]]}, {"id": "1905.13456", "submitter": "Changhee Han", "authors": "Changhee Han, Leonardo Rundo, Ryosuke Araki, Yudai Nagano, Yujiro\n  Furukawa, Giancarlo Mauri, Hideki Nakayama, Hideaki Hayashi", "title": "Combining Noise-to-Image and Image-to-Image GANs: Brain MR Image\n  Augmentation for Tumor Detection", "comments": "12 pages, 7 figures, accepted to IEEE ACCESS", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) achieve excellent computer-assisted\ndiagnosis with sufficient annotated training data. However, most medical\nimaging datasets are small and fragmented. In this context, Generative\nAdversarial Networks (GANs) can synthesize realistic/diverse additional\ntraining images to fill the data lack in the real image distribution;\nresearchers have improved classification by augmenting data with noise-to-image\n(e.g., random noise samples to diverse pathological images) or image-to-image\nGANs (e.g., a benign image to a malignant one). Yet, no research has reported\nresults combining noise-to-image and image-to-image GANs for further\nperformance boost. Therefore, to maximize the DA effect with the GAN\ncombinations, we propose a two-step GAN-based DA that generates and refines\nbrain Magnetic Resonance (MR) images with/without tumors separately: (i)\nProgressive Growing of GANs (PGGANs), multi-stage noise-to-image GAN for\nhigh-resolution MR image generation, first generates realistic/diverse 256 X\n256 images; (ii) Multimodal UNsupervised Image-to-image Translation (MUNIT)\nthat combines GANs/Variational AutoEncoders or SimGAN that uses a DA-focused\nGAN loss, further refines the texture/shape of the PGGAN-generated images\nsimilarly to the real ones. We thoroughly investigate CNN-based tumor\nclassification results, also considering the influence of pre-training on\nImageNet and discarding weird-looking GAN-generated images. The results show\nthat, when combined with classic DA, our two-step GAN-based DA can\nsignificantly outperform the classic DA alone, in tumor detection (i.e.,\nboosting sensitivity 93.67% to 97.48%) and also in other medical imaging tasks.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 08:14:19 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 17:53:49 GMT"}, {"version": "v3", "created": "Wed, 9 Oct 2019 12:20:15 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Han", "Changhee", ""], ["Rundo", "Leonardo", ""], ["Araki", "Ryosuke", ""], ["Nagano", "Yudai", ""], ["Furukawa", "Yujiro", ""], ["Mauri", "Giancarlo", ""], ["Nakayama", "Hideki", ""], ["Hayashi", "Hideaki", ""]]}, {"id": "1905.13466", "submitter": "Mengxi Jiang", "authors": "Mengxi Jiang, Zhuliang Yu, Cuihua Li, Yunqi Lei", "title": "Joint Representation of Multiple Geometric Priors via a Shape\n  Decomposition Model for Single Monocular 3D Pose Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aim to recover the 3D human pose from 2D body joints of a\nsingle image. The major challenge in this task is the depth ambiguity since\ndifferent 3D poses may produce similar 2D poses. Although many recent advances\nin this problem are found in both unsupervised and supervised learning\napproaches, the performances of most of these approaches are greatly affected\nby insufficient diversities and richness of training data. To alleviate this\nissue, we propose an unsupervised learning approach, which is capable of\nestimating various complex poses well under limited available training data.\nSpecifically, we propose a Shape Decomposition Model (SDM) in which a 3D pose\nis considered as the superposition of two parts which are global structure\ntogether with some deformations. Based on SDM, we estimate these two parts\nexplicitly by solving two sets of different distributed combination\ncoefficients of geometric priors. In addition, to obtain geometric priors, a\njoint dictionary learning algorithm is proposed to extract both coarse and fine\npose clues simultaneously from limited training data. Quantitative evaluations\non several widely used datasets demonstrate that our approach yields better\nperformances over other competitive approaches. Especially, on some categories\nwith more complex deformations, significant improvements are achieved by our\napproach. Furthermore, qualitative experiments conducted on in-the-wild images\nalso show the effectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 08:47:05 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Jiang", "Mengxi", ""], ["Yu", "Zhuliang", ""], ["Li", "Cuihua", ""], ["Lei", "Yunqi", ""]]}, {"id": "1905.13469", "submitter": "Ben Deverett", "authors": "Ben Deverett, Ryan Faulkner, Meire Fortunato, Greg Wayne, Joel Z.\n  Leibo", "title": "Interval timing in deep reinforcement learning agents", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The measurement of time is central to intelligent behavior. We know that both\nanimals and artificial agents can successfully use temporal dependencies to\nselect actions. In artificial agents, little work has directly addressed (1)\nwhich architectural components are necessary for successful development of this\nability, (2) how this timing ability comes to be represented in the units and\nactions of the agent, and (3) whether the resulting behavior of the system\nconverges on solutions similar to those of biology. Here we studied interval\ntiming abilities in deep reinforcement learning agents trained end-to-end on an\ninterval reproduction paradigm inspired by experimental literature on\nmechanisms of timing. We characterize the strategies developed by recurrent and\nfeedforward agents, which both succeed at temporal reproduction using distinct\nmechanisms, some of which bear specific and intriguing similarities to\nbiological systems. These findings advance our understanding of how agents come\nto represent time, and they highlight the value of experimentally inspired\napproaches to characterizing agent abilities.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 09:05:31 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 15:56:26 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Deverett", "Ben", ""], ["Faulkner", "Ryan", ""], ["Fortunato", "Meire", ""], ["Wayne", "Greg", ""], ["Leibo", "Joel Z.", ""]]}, {"id": "1905.13497", "submitter": "Tassilo Klein", "authors": "Tassilo Klein, Moin Nabi", "title": "Attention Is (not) All You Need for Commonsense Reasoning", "comments": "to appear at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently introduced BERT model exhibits strong performance on several\nlanguage understanding benchmarks. In this paper, we describe a simple\nre-implementation of BERT for commonsense reasoning. We show that the\nattentions produced by BERT can be directly utilized for tasks such as the\nPronoun Disambiguation Problem and Winograd Schema Challenge. Our proposed\nattention-guided commonsense reasoning method is conceptually simple yet\nempirically powerful. Experimental analysis on multiple datasets demonstrates\nthat our proposed system performs remarkably well on all cases while\noutperforming the previously reported state of the art by a margin. While\nresults suggest that BERT seems to implicitly learn to establish complex\nrelationships between entities, solving commonsense reasoning tasks might\nrequire more than unsupervised models learned from huge text corpora.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 10:27:58 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Klein", "Tassilo", ""], ["Nabi", "Moin", ""]]}, {"id": "1905.13516", "submitter": "Dennis Soemers", "authors": "Cameron Browne, Dennis J. N. J. Soemers, \\'Eric Piette, Matthew\n  Stephenson, Michael Conrad, Walter Crist, Thierry Depaulis, Eddie Duggan,\n  Fred Horn, Steven Kelk, Simon M. Lucas, Jo\\~ao Pedro Neto, David Parlett,\n  Abdallah Saffidine, Ulrich Sch\\\"adler, Jorge Nuno Silva, Alex de Voogt, Mark\n  H. M. Winands", "title": "Foundations of Digital Arch{\\ae}oludology", "comments": "Report on Dagstuhl Research Meeting. Authored/edited by all\n  participants. Appendices by Thierry Depaulis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital Archaeoludology (DAL) is a new field of study involving the analysis\nand reconstruction of ancient games from incomplete descriptions and\narchaeological evidence using modern computational techniques. The aim is to\nprovide digital tools and methods to help game historians and other researchers\nbetter understand traditional games, their development throughout recorded\nhuman history, and their relationship to the development of human culture and\nmathematical knowledge. This work is being explored in the ERC-funded Digital\nLudeme Project.\n  The aim of this inaugural international research meeting on DAL is to gather\ntogether leading experts in relevant disciplines - computer science, artificial\nintelligence, machine learning, computational phylogenetics, mathematics,\nhistory, archaeology, anthropology, etc. - to discuss the key themes and\nestablish the foundations for this new field of research, so that it may\ncontinue beyond the lifetime of its initiating project.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 11:22:00 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Browne", "Cameron", ""], ["Soemers", "Dennis J. N. J.", ""], ["Piette", "\u00c9ric", ""], ["Stephenson", "Matthew", ""], ["Conrad", "Michael", ""], ["Crist", "Walter", ""], ["Depaulis", "Thierry", ""], ["Duggan", "Eddie", ""], ["Horn", "Fred", ""], ["Kelk", "Steven", ""], ["Lucas", "Simon M.", ""], ["Neto", "Jo\u00e3o Pedro", ""], ["Parlett", "David", ""], ["Saffidine", "Abdallah", ""], ["Sch\u00e4dler", "Ulrich", ""], ["Silva", "Jorge Nuno", ""], ["de Voogt", "Alex", ""], ["Winands", "Mark H. M.", ""]]}, {"id": "1905.13521", "submitter": "Li-Cheng Lan", "authors": "Li-Cheng Lan, Wei Li, Ting-Han Wei, and I-Chen Wu", "title": "Multiple Policy Value Monte Carlo Tree Search", "comments": "Proceedings of the 28th International Joint Conference on Artificial\n  Intelligence (IJCAI-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many of the strongest game playing programs use a combination of Monte Carlo\ntree search (MCTS) and deep neural networks (DNN), where the DNNs are used as\npolicy or value evaluators. Given a limited budget, such as online playing or\nduring the self-play phase of AlphaZero (AZ) training, a balance needs to be\nreached between accurate state estimation and more MCTS simulations, both of\nwhich are critical for a strong game playing agent. Typically, larger DNNs are\nbetter at generalization and accurate evaluation, while smaller DNNs are less\ncostly, and therefore can lead to more MCTS simulations and bigger search trees\nwith the same budget. This paper introduces a new method called the multiple\npolicy value MCTS (MPV-MCTS), which combines multiple policy value neural\nnetworks (PV-NNs) of various sizes to retain advantages of each network, where\ntwo PV-NNs f_S and f_L are used in this paper. We show through experiments on\nthe game NoGo that a combined f_S and f_L MPV-MCTS outperforms single PV-NN\nwith policy value MCTS, called PV-MCTS. Additionally, MPV-MCTS also outperforms\nPV-MCTS for AZ training.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 11:33:06 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Lan", "Li-Cheng", ""], ["Li", "Wei", ""], ["Wei", "Ting-Han", ""], ["Wu", "I-Chen", ""]]}, {"id": "1905.13531", "submitter": "Adri\\'an Gonz\\'alez Sieira", "authors": "Adri\\'an Gonz\\'alez-Sieira, Manuel Mucientes and Alberto Bugar\\'in", "title": "Graduated Fidelity Lattices for Motion Planning under Uncertainty", "comments": "Text accepted for publication in the 2019 IEEE International\n  Conference on Robotics and Automation (ICRA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach for motion planning in mobile robotics under\nsensing and motion uncertainty based on state lattices with graduated fidelity.\nThe probability of collision is reliably estimated considering the robot shape,\nand the fidelity adapts to the complexity of the environment, improving the\nplanning efficiency while maintaining the performance. Safe and optimal paths\nare found with an informed search algorithm, for which a novel multi-resolution\nheuristic is presented. Results for different scenarios and robot shapes are\ngiven, showing the validity of the proposed methods.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 12:07:57 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Gonz\u00e1lez-Sieira", "Adri\u00e1n", ""], ["Mucientes", "Manuel", ""], ["Bugar\u00edn", "Alberto", ""]]}, {"id": "1905.13551", "submitter": "Baoxiang Wang", "authors": "Baoxiang Wang", "title": "Recurrent Existence Determination Through Policy Optimization", "comments": "International Joint Conference on Artificial Intelligence (IJCAI)\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary determination of the presence of objects is one of the problems where\nhumans perform extraordinarily better than computer vision systems, in terms of\nboth speed and preciseness. One of the possible reasons is that humans can skip\nmost of the clutter and attend only on salient regions. Recurrent attention\nmodels (RAM) are the first computational models to imitate the way humans\nprocess images via the REINFORCE algorithm. Despite that RAM is originally\ndesigned for image recognition, we extend it and present recurrent existence\ndetermination, an attention-based mechanism to solve the existence\ndetermination. Our algorithm employs a novel $k$-maximum aggregation layer and\na new reward mechanism to address the issue of delayed rewards, which would\nhave caused the instability of the training process. The experimental analysis\ndemonstrates significant efficiency and accuracy improvement over existing\napproaches, on both synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 06:40:51 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 21:38:05 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Wang", "Baoxiang", ""]]}, {"id": "1905.13559", "submitter": "Martin Mladenov", "authors": "Martin Mladenov, Ofer Meshi, Jayden Ooi, Dale Schuurmans, Craig\n  Boutilier", "title": "Advantage Amplification in Slowly Evolving Latent-State Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent-state environments with long horizons, such as those faced by\nrecommender systems, pose significant challenges for reinforcement learning\n(RL). In this work, we identify and analyze several key hurdles for RL in such\nenvironments, including belief state error and small action advantage. We\ndevelop a general principle of advantage amplification that can overcome these\nhurdles through the use of temporal abstraction. We propose several aggregation\nmethods and prove they induce amplification in certain settings. We also bound\nthe loss in optimality incurred by our methods in environments where latent\nstate evolves slowly and demonstrate their performance empirically in a\nstylized user-modeling task.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 21:57:02 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Mladenov", "Martin", ""], ["Meshi", "Ofer", ""], ["Ooi", "Jayden", ""], ["Schuurmans", "Dale", ""], ["Boutilier", "Craig", ""]]}, {"id": "1905.13560", "submitter": "Xing Liu", "authors": "Xing Liu, Takayuki Okatani", "title": "Evaluating Artificial Systems for Pairwise Ranking Tasks Sensitive to\n  Individual Differences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owing to the advancement of deep learning, artificial systems are now rival\nto humans in several pattern recognition tasks, such as visual recognition of\nobject categories. However, this is only the case with the tasks for which\ncorrect answers exist independent of human perception. There is another type of\ntasks for which what to predict is human perception itself, in which there are\noften individual differences. Then, there are no longer single \"correct\"\nanswers to predict, which makes evaluation of artificial systems difficult. In\nthis paper, focusing on pairwise ranking tasks sensitive to individual\ndifferences, we propose an evaluation method. Given a ranking result for\nmultiple item pairs that is generated by an artificial system, our method\nquantifies the probability that the same ranking result will be generated by\nhumans, and judges if it is distinguishable from human-generated results. We\nintroduce a probabilistic model of human ranking behavior, and present an\nefficient computation method for the judgment. To estimate model parameters\naccurately from small-size samples, we present a method that uses confidence\nscores given by annotators for ranking each item pair. Taking as an example a\ntask of ranking image pairs according to material attributes of objects, we\ndemonstrate how the proposed method works.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 00:13:16 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Liu", "Xing", ""], ["Okatani", "Takayuki", ""]]}, {"id": "1905.13562", "submitter": "Mohammadreza Nazari", "authors": "Mohammadreza Nazari, Majid Jahani, Lawrence V. Snyder, Martin\n  Tak\\'a\\v{c}", "title": "Don't Forget Your Teacher: A Corrective Reinforcement Learning Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although reinforcement learning (RL) can provide reliable solutions in many\nsettings, practitioners are often wary of the discrepancies between the RL\nsolution and their status quo procedures. Therefore, they may be reluctant to\nadapt to the novel way of executing tasks proposed by RL. On the other hand,\nmany real-world problems require relatively small adjustments from the status\nquo policies to achieve improved performance. Therefore, we propose a\nstudent-teacher RL mechanism in which the RL (the \"student\") learns to maximize\nits reward, subject to a constraint that bounds the difference between the RL\npolicy and the \"teacher\" policy. The teacher can be another RL policy (e.g.,\ntrained under a slightly different setting), the status quo policy, or any\nother exogenous policy. We formulate this problem using a stochastic\noptimization model and solve it using a primal-dual policy gradient algorithm.\nWe prove that the policy is asymptotically optimal. However, a naive\nimplementation suffers from high variance and convergence to a stochastic\noptimal policy. With a few practical adjustments to address these issues, our\nnumerical experiments confirm the effectiveness of our proposed method in\nmultiple GridWorld scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 01:47:18 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Nazari", "Mohammadreza", ""], ["Jahani", "Majid", ""], ["Snyder", "Lawrence V.", ""], ["Tak\u00e1\u010d", "Martin", ""]]}, {"id": "1905.13566", "submitter": "Faraz Torabi", "authors": "Faraz Torabi, Garrett Warnell, Peter Stone", "title": "Recent Advances in Imitation Learning from Observation", "comments": "International Joint Conference on Artificial Intelligence (IJCAI\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning is the process by which one agent tries to learn how to\nperform a certain task using information generated by another, often\nmore-expert agent performing that same task. Conventionally, the imitator has\naccess to both state and action information generated by an expert performing\nthe task (e.g., the expert may provide a kinesthetic demonstration of object\nplacement using a robotic arm). However, requiring the action information\nprevents imitation learning from a large number of existing valuable learning\nresources such as online videos of humans performing tasks. To overcome this\nissue, the specific problem of imitation from observation (IfO) has recently\ngarnered a great deal of attention, in which the imitator only has access to\nthe state information (e.g., video frames) generated by the expert. In this\npaper, we provide a literature review of methods developed for IfO, and then\npoint out some open research problems and potential future work.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 05:54:30 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 03:55:09 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Torabi", "Faraz", ""], ["Warnell", "Garrett", ""], ["Stone", "Peter", ""]]}, {"id": "1905.13570", "submitter": "Tan Zhi-Xuan", "authors": "Tan Zhi-Xuan, Harold Soh, Desmond C. Ong", "title": "Factorized Inference in Deep Markov Models for Incomplete Multimodal\n  Time Series", "comments": "8 pages, 4 figures, accepted to AAAI 2020, code available at:\n  https://github.com/ztangent/multimodal-dmm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrating deep learning with latent state space models has the potential to\nyield temporal models that are powerful, yet tractable and interpretable.\nUnfortunately, current models are not designed to handle missing data or\nmultiple data modalities, which are both prevalent in real-world data. In this\nwork, we introduce a factorized inference method for Multimodal Deep Markov\nModels (MDMMs), allowing us to filter and smooth in the presence of missing\ndata, while also performing uncertainty-aware multimodal fusion. We derive this\nmethod by factorizing the posterior p(z|x) for non-linear state space models,\nand develop a variational backward-forward algorithm for inference. Because our\nmethod handles incompleteness over both time and modalities, it is capable of\ninterpolation, extrapolation, conditional generation, label prediction, and\nweakly supervised learning of multimodal time series. We demonstrate these\ncapabilities on both synthetic and real-world multimodal data under high levels\nof data deletion. Our method performs well even with more than 50% missing\ndata, and outperforms existing deep approaches to inference in latent time\nseries.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 10:20:32 GMT"}, {"version": "v2", "created": "Sun, 11 Aug 2019 11:41:49 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2019 13:34:39 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Zhi-Xuan", "Tan", ""], ["Soh", "Harold", ""], ["Ong", "Desmond C.", ""]]}, {"id": "1905.13601", "submitter": "Tomoyuki Kajiwara", "authors": "Tomoyuki Kajiwara, Chihiro Tanikawa, Yuujin Shimizu, Chenhui Chu,\n  Takashi Yamashiro, Hajime Nagahara", "title": "Using Natural Language Processing to Develop an Automated Orthodontic\n  Diagnostic System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We work on the task of automatically designing a treatment plan from the\nfindings included in the medical certificate written by the dentist. To develop\nan artificial intelligence system that deals with free-form certificates\nwritten by dentists, we annotate the findings and utilized the natural language\nprocessing approach. As a result of the experiment using 990 certificates,\n0.585 F1-score was achieved for the task of extracting orthodontic problems\nfrom findings, and 0.584 correlation coefficient with the human ranking was\nachieved for the treatment prioritization task.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 13:13:51 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Kajiwara", "Tomoyuki", ""], ["Tanikawa", "Chihiro", ""], ["Shimizu", "Yuujin", ""], ["Chu", "Chenhui", ""], ["Yamashiro", "Takashi", ""], ["Nagahara", "Hajime", ""]]}, {"id": "1905.13607", "submitter": "Richard Jiang", "authors": "Gary Storey, Richard Jiang, Shelagh Keogh, Ahmed Bouridane and\n  Chang-Tsun Li", "title": "3DPalsyNet: A Facial Palsy Grading and Motion Recognition Framework\n  using Fully 3D Convolutional Neural Networks", "comments": null, "journal-ref": "IEEE Access 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The capability to perform facial analysis from video sequences has\nsignificant potential to positively impact in many areas of life. One such area\nrelates to the medical domain to specifically aid in the diagnosis and\nrehabilitation of patients with facial palsy. With this application in mind,\nthis paper presents an end-to-end framework, named 3DPalsyNet, for the tasks of\nmouth motion recognition and facial palsy grading. 3DPalsyNet utilizes a 3D CNN\narchitecture with a ResNet backbone for the prediction of these dynamic tasks.\nLeveraging transfer learning from a 3D CNNs pre-trained on the Kinetics data\nset for general action recognition, the model is modified to apply joint\nsupervised learning using center and softmax loss concepts. 3DPalsyNet is\nevaluated on a test set consisting of individuals with varying ranges of facial\npalsy and mouth motions and the results have shown an attractive level of\nclassification accuracy in these task of 82% and 86% respectively. The frame\nduration and the loss function affect was studied in terms of the predictive\nqualities of the proposed 3DPalsyNet, where it was found shorter frame\nduration's of 8 performed best for this specific task. Centre loss and softmax\nhave shown improvements in spatio-temporal feature learning than softmax loss\nalone, this is in agreement with earlier work involving the spatial domain.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 13:24:30 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Storey", "Gary", ""], ["Jiang", "Richard", ""], ["Keogh", "Shelagh", ""], ["Bouridane", "Ahmed", ""], ["Li", "Chang-Tsun", ""]]}, {"id": "1905.13618", "submitter": "Roman Klinger", "authors": "Enrica Troiano and Sebastian Pad\\'o and Roman Klinger", "title": "Crowdsourcing and Validating Event-focused Emotion Corpora for German\n  and English", "comments": "14 pages, 1 figure, accepted for publication at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sentiment analysis has a range of corpora available across multiple\nlanguages. For emotion analysis, the situation is more limited, which hinders\npotential research on cross-lingual modeling and the development of predictive\nmodels for other languages. In this paper, we fill this gap for German by\nconstructing deISEAR, a corpus designed in analogy to the well-established\nEnglish ISEAR emotion dataset. Motivated by Scherer's appraisal theory, we\nimplement a crowdsourcing experiment which consists of two steps. In step 1,\nparticipants create descriptions of emotional events for a given emotion. In\nstep 2, five annotators assess the emotion expressed by the texts. We show that\ntransferring an emotion classification model from the original English ISEAR to\nthe German crowdsourced deISEAR via machine translation does not, on average,\ncause a performance drop.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 13:54:54 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Troiano", "Enrica", ""], ["Pad\u00f3", "Sebastian", ""], ["Klinger", "Roman", ""]]}, {"id": "1905.13655", "submitter": "Nadav Cohen", "authors": "Sanjeev Arora, Nadav Cohen, Wei Hu, Yuping Luo", "title": "Implicit Regularization in Deep Matrix Factorization", "comments": "Published at the conference on Neural Information Processing Systems\n  (NeurIPS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efforts to understand the generalization mystery in deep learning have led to\nthe belief that gradient-based optimization induces a form of implicit\nregularization, a bias towards models of low \"complexity.\" We study the\nimplicit regularization of gradient descent over deep linear neural networks\nfor matrix completion and sensing, a model referred to as deep matrix\nfactorization. Our first finding, supported by theory and experiments, is that\nadding depth to a matrix factorization enhances an implicit tendency towards\nlow-rank solutions, oftentimes leading to more accurate recovery. Secondly, we\npresent theoretical and empirical arguments questioning a nascent view by which\nimplicit regularization in matrix factorization can be captured using simple\nmathematical norms. Our results point to the possibility that the language of\nstandard regularizers may not be rich enough to fully encompass the implicit\nregularization brought forth by gradient-based optimization.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 14:54:36 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 16:46:10 GMT"}, {"version": "v3", "created": "Sat, 26 Oct 2019 07:09:24 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Arora", "Sanjeev", ""], ["Cohen", "Nadav", ""], ["Hu", "Wei", ""], ["Luo", "Yuping", ""]]}, {"id": "1905.13672", "submitter": "Jiaoyan Chen", "authors": "Freddy Lecue and Jiaoyan Chen and Jeff Z. Pan and Huajun Chen", "title": "Augmenting Transfer Learning with Semantic Reasoning", "comments": "7 pages", "journal-ref": "IJCAI 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning aims at building robust prediction models by transferring\nknowledge gained from one problem to another. In the semantic Web, learning\ntasks are enhanced with semantic representations. We exploit their semantics to\naugment transfer learning by dealing with when to transfer with semantic\nmeasurements and what to transfer with semantic embeddings. We further present\na general framework that integrates the above measurements and embeddings with\nexisting transfer learning algorithms for higher performance. It has\ndemonstrated to be robust in two real-world applications: bus delay forecasting\nand air quality forecasting.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 15:21:10 GMT"}, {"version": "v2", "created": "Sun, 23 Jun 2019 21:12:24 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Lecue", "Freddy", ""], ["Chen", "Jiaoyan", ""], ["Pan", "Jeff Z.", ""], ["Chen", "Huajun", ""]]}, {"id": "1905.13686", "submitter": "Federico Baldassarre", "authors": "Federico Baldassarre, Hossein Azizpour", "title": "Explainability Techniques for Graph Convolutional Networks", "comments": "Accepted at the ICML 2019 Workshop \"Learning and Reasoning with\n  Graph-Structured Representations\" (poster + spotlight talk)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Networks are used to make decisions in potentially complex scenarios\nbut it is usually not obvious how or why they made them. In this work, we study\nthe explainability of Graph Network decisions using two main classes of\ntechniques, gradient-based and decomposition-based, on a toy dataset and a\nchemistry task. Our study sets the ground for future development as well as\napplication to real-world problems.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 15:51:29 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Baldassarre", "Federico", ""], ["Azizpour", "Hossein", ""]]}]