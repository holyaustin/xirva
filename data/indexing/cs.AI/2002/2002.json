[{"id": "2002.00149", "submitter": "Zhang-Wei Hong", "authors": "Zhang-Wei Hong, Prabhat Nagarajan, Guilherme Maeda", "title": "Periodic Intra-Ensemble Knowledge Distillation for Reinforcement\n  Learning", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy ensemble reinforcement learning (RL) methods have demonstrated\nimpressive results across a range of RL benchmark tasks. Recent works suggest\nthat directly imitating experts' policies in a supervised manner before or\nduring the course of training enables faster policy improvement for an RL\nagent. Motivated by these recent insights, we propose Periodic Intra-Ensemble\nKnowledge Distillation (PIEKD). PIEKD is a learning framework that uses an\nensemble of policies to act in the environment while periodically sharing\nknowledge amongst policies in the ensemble through knowledge distillation. Our\nexperiments demonstrate that PIEKD improves upon a state-of-the-art RL method\nin sample efficiency on several challenging MuJoCo benchmark tasks.\nAdditionally, we perform ablation studies to better understand PIEKD.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 06:00:12 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Hong", "Zhang-Wei", ""], ["Nagarajan", "Prabhat", ""], ["Maeda", "Guilherme", ""]]}, {"id": "2002.00157", "submitter": "Mateen Ulhaq", "authors": "Mateen Ulhaq and Ivan V. Baji\\'c", "title": "Shared Mobile-Cloud Inference for Collaborative Intelligence", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As AI applications for mobile devices become more prevalent, there is an\nincreasing need for faster execution and lower energy consumption for neural\nmodel inference. Historically, the models run on mobile devices have been\nsmaller and simpler in comparison to large state-of-the-art research models,\nwhich can only run on the cloud. However, cloud-only inference has drawbacks\nsuch as increased network bandwidth consumption and higher latency. In\naddition, cloud-only inference requires the input data (images, audio) to be\nfully transferred to the cloud, creating concerns about potential privacy\nbreaches. We demonstrate an alternative approach: shared mobile-cloud\ninference. Partial inference is performed on the mobile in order to reduce the\ndimensionality of the input data and arrive at a compact feature tensor, which\nis a latent space representation of the input signal. The feature tensor is\nthen transmitted to the server for further inference. This strategy can improve\ninference latency, energy consumption, and network bandwidth usage, as well as\nprovide privacy protection, because the original signal never leaves the\nmobile. Further performance gain can be achieved by compressing the feature\ntensor before its transmission.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 07:12:01 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Ulhaq", "Mateen", ""], ["Baji\u0107", "Ivan V.", ""]]}, {"id": "2002.00212", "submitter": "Yu-Siang Huang", "authors": "Yu-Siang Huang, Yi-Hsuan Yang", "title": "Pop Music Transformer: Beat-based Modeling and Generation of Expressive\n  Pop Piano Compositions", "comments": "Accepted at ACM Multimedia 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A great number of deep learning based models have been recently proposed for\nautomatic music composition. Among these models, the Transformer stands out as\na prominent approach for generating expressive classical piano performance with\na coherent structure of up to one minute. The model is powerful in that it\nlearns abstractions of data on its own, without much human-imposed domain\nknowledge or constraints. In contrast with this general approach, this paper\nshows that Transformers can do even better for music modeling, when we improve\nthe way a musical score is converted into the data fed to a Transformer model.\nIn particular, we seek to impose a metrical structure in the input data, so\nthat Transformers can be more easily aware of the beat-bar-phrase hierarchical\nstructure in music. The new data representation maintains the flexibility of\nlocal tempo changes, and provides hurdles to control the rhythmic and harmonic\nstructure of music. With this approach, we build a Pop Music Transformer that\ncomposes Pop piano music with better rhythmic structure than existing\nTransformer models.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 14:12:35 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 15:05:24 GMT"}, {"version": "v3", "created": "Mon, 10 Aug 2020 07:27:05 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Huang", "Yu-Siang", ""], ["Yang", "Yi-Hsuan", ""]]}, {"id": "2002.00223", "submitter": "Sodiq Adewole", "authors": "Sodiq Adewole, Erfaneh Gharavi, Benjamin Shpringer, Martin Bolger,\n  Vaibhav Sharma, Sung Ming Yang, Donald E. Brown", "title": "Dialogue-based simulation for cultural awareness training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing simulations designed for cultural and interpersonal skill training\nrely on pre-defined responses with a menu option selection interface. Using a\nmultiple-choice interface and restricting trainees' responses may limit the\ntrainees' ability to apply the lessons in real life situations. This systems\nalso uses a simplistic evaluation model, where trainees' selected options are\nmarked as either correct or incorrect. This model may not capture sufficient\ninformation that could drive an adaptive feedback mechanism to improve\ntrainees' cultural awareness. This paper describes the design of a\ndialogue-based simulation for cultural awareness training. The simulation,\nbuilt around a disaster management scenario involving a joint coalition between\nthe US and the Chinese armies. Trainees were able to engage in realistic\ndialogue with the Chinese agent. Their responses, at different points, get\nevaluated by different multi-label classification models. Based on training on\nour dataset, the models score the trainees' responses for cultural awareness in\nthe Chinese culture. Trainees also get feedback that informs the cultural\nappropriateness of their responses. The result of this work showed the\nfollowing; i) A feature-based evaluation model improves the design, modeling\nand computation of dialogue-based training simulation systems; ii) Output from\ncurrent automatic speech recognition (ASR) systems gave comparable end results\ncompared with the output from manual transcription; iii) A multi-label\nclassification model trained as a cultural expert gave results which were\ncomparable with scores assigned by human annotators.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 14:40:17 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Adewole", "Sodiq", ""], ["Gharavi", "Erfaneh", ""], ["Shpringer", "Benjamin", ""], ["Bolger", "Martin", ""], ["Sharma", "Vaibhav", ""], ["Yang", "Sung Ming", ""], ["Brown", "Donald E.", ""]]}, {"id": "2002.00224", "submitter": "Scott McLachlan Dr", "authors": "Scott McLachlan, Kudakwashe Dube, Graham A Hitman, Norman E Fenton,\n  Evangelia Kyrimi", "title": "Bayesian Networks in Healthcare: Distribution by Medical Condition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bayesian networks (BNs) have received increasing research attention that is\nnot matched by adoption in practice and yet have potential to significantly\nbenefit healthcare. Hitherto, research works have not investigated the types of\nmedical conditions being modelled with BNs, nor whether any differences exist\nin how and why they are applied to different conditions. This research seeks to\nidentify and quantify the range of medical conditions for which\nhealthcare-related BN models have been proposed, and the differences in\napproach between the most common medical conditions to which they have been\napplied. We found that almost two-thirds of all healthcare BNs are focused on\nfour conditions: cardiac, cancer, psychological and lung disorders. We believe\nthat a lack of understanding regarding how BNs work and what they are capable\nof exists, and that it is only with greater understanding and promotion that we\nmay ever realise the full potential of BNs to effect positive change in daily\nhealthcare practice.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 14:41:20 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 07:18:20 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["McLachlan", "Scott", ""], ["Dube", "Kudakwashe", ""], ["Hitman", "Graham A", ""], ["Fenton", "Norman E", ""], ["Kyrimi", "Evangelia", ""]]}, {"id": "2002.00269", "submitter": "David Heckerman", "authors": "David Heckerman", "title": "A Tutorial on Learning With Bayesian Networks", "comments": "Previous arXiv submission hid all references--now fixed", "journal-ref": "Original version published in Learning in Graphical Models, M.\n  Jordan, ed., MIT Press, Cambridge, MA, 1999", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Bayesian network is a graphical model that encodes probabilistic\nrelationships among variables of interest. When used in conjunction with\nstatistical techniques, the graphical model has several advantages for data\nanalysis. One, because the model encodes dependencies among all variables, it\nreadily handles situations where some data entries are missing. Two, a Bayesian\nnetwork can be used to learn causal relationships, and hence can be used to\ngain understanding about a problem domain and to predict the consequences of\nintervention. Three, because the model has both a causal and probabilistic\nsemantics, it is an ideal representation for combining prior knowledge (which\noften comes in causal form) and data. Four, Bayesian statistical methods in\nconjunction with Bayesian networks offer an efficient and principled approach\nfor avoiding the overfitting of data. In this paper, we discuss methods for\nconstructing Bayesian networks from prior knowledge and summarize Bayesian\nstatistical methods for using data to improve these models. With regard to the\nlatter task, we describe methods for learning both the parameters and structure\nof a Bayesian network, including techniques for learning with incomplete data.\nIn addition, we relate Bayesian-network methods for learning to techniques for\nsupervised and unsupervised learning. We illustrate the graphical-modeling\napproach using a real-world case study.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 20:03:21 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 22:18:01 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Heckerman", "David", ""]]}, {"id": "2002.00352", "submitter": "Xingwen Zhang", "authors": "Xingwen Zhang, Feng Qi, Zhigang Hua, Shuang Yang", "title": "Solving Billion-Scale Knapsack Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knapsack problems (KPs) are common in industry, but solving KPs is known to\nbe NP-hard and has been tractable only at a relatively small scale. This paper\nexamines KPs in a slightly generalized form and shows that they can be solved\nnearly optimally at scale via distributed algorithms. The proposed approach can\nbe implemented fairly easily with off-the-shelf distributed computing\nframeworks (e.g. MPI, Hadoop, Spark). As an example, our implementation leads\nto one of the most efficient KP solvers known to date -- capable to solve KPs\nat an unprecedented scale (e.g., KPs with 1 billion decision variables and 1\nbillion constraints can be solved within 1 hour). The system has been deployed\nto production and called on a daily basis, yielding significant business\nimpacts at Ant Financial.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 08:51:36 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Zhang", "Xingwen", ""], ["Qi", "Feng", ""], ["Hua", "Zhigang", ""], ["Yang", "Shuang", ""]]}, {"id": "2002.00372", "submitter": "C Anantaram", "authors": "Rupam Patir, Shubham Singhal, C. Anantaram, Vikram Goyal", "title": "Interpretability of Blackbox Machine Learning Models through Dataview\n  Extraction and Shadow Model creation", "comments": "13 pages, 3 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models trained using massive amounts of data tend to capture\none view of the data and its associated mapping. Different deep learning models\nbuilt on the same training data may capture different views of the data based\non the underlying techniques used. For explaining the decisions arrived by\nblackbox deep learning models, we argue that it is essential to reproduce that\nmodel's view of the training data faithfully. This faithful reproduction can\nthen be used for explanation generation. We investigate two methods for data\nview extraction: hill-climbing approach and a GAN-driven approach. We then use\nthis synthesized data for creating shadow models for explanation generation:\nDecision-Tree model and Formal Concept Analysis based model. We evaluate these\napproaches on a Blackbox model trained on public datasets and show its\nusefulness in explanation generation.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 11:47:15 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Patir", "Rupam", ""], ["Singhal", "Shubham", ""], ["Anantaram", "C.", ""], ["Goyal", "Vikram", ""]]}, {"id": "2002.00388", "submitter": "Shaoxiong Ji", "authors": "Shaoxiong Ji and Shirui Pan and Erik Cambria and Pekka Marttinen and\n  Philip S. Yu", "title": "A Survey on Knowledge Graphs: Representation, Acquisition and\n  Applications", "comments": null, "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems, 2021", "doi": "10.1109/TNNLS.2021.3070843", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human knowledge provides a formal understanding of the world. Knowledge\ngraphs that represent structural relations between entities have become an\nincreasingly popular research direction towards cognition and human-level\nintelligence. In this survey, we provide a comprehensive review of knowledge\ngraph covering overall research topics about 1) knowledge graph representation\nlearning, 2) knowledge acquisition and completion, 3) temporal knowledge graph,\nand 4) knowledge-aware applications, and summarize recent breakthroughs and\nperspective directions to facilitate future research. We propose a full-view\ncategorization and new taxonomies on these topics. Knowledge graph embedding is\norganized from four aspects of representation space, scoring function, encoding\nmodels, and auxiliary information. For knowledge acquisition, especially\nknowledge graph completion, embedding methods, path inference, and logical rule\nreasoning, are reviewed. We further explore several emerging topics, including\nmeta relational learning, commonsense reasoning, and temporal knowledge graphs.\nTo facilitate future research on knowledge graphs, we also provide a curated\ncollection of datasets and open-source libraries on different tasks. In the\nend, we have a thorough outlook on several promising research directions.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 13:17:31 GMT"}, {"version": "v2", "created": "Sun, 9 Aug 2020 07:30:24 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2021 20:12:58 GMT"}, {"version": "v4", "created": "Thu, 1 Apr 2021 05:48:44 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Ji", "Shaoxiong", ""], ["Pan", "Shirui", ""], ["Cambria", "Erik", ""], ["Marttinen", "Pekka", ""], ["Yu", "Philip S.", ""]]}, {"id": "2002.00412", "submitter": "Konrad Zolna", "authors": "Konrad Zolna, Chitwan Saharia, Leonard Boussioux, David Yu-Tung Hui,\n  Maxime Chevalier-Boisvert, Dzmitry Bahdanau and Yoshua Bengio", "title": "Combating False Negatives in Adversarial Imitation Learning", "comments": "This is an extended version of the student abstract published at 34th\n  AAAI Conference on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In adversarial imitation learning, a discriminator is trained to\ndifferentiate agent episodes from expert demonstrations representing the\ndesired behavior. However, as the trained policy learns to be more successful,\nthe negative examples (the ones produced by the agent) become increasingly\nsimilar to expert ones. Despite the fact that the task is successfully\naccomplished in some of the agent's trajectories, the discriminator is trained\nto output low values for them. We hypothesize that this inconsistent training\nsignal for the discriminator can impede its learning, and consequently leads to\nworse overall performance of the agent. We show experimental evidence for this\nhypothesis and that the 'False Negatives' (i.e. successful agent episodes)\nsignificantly hinder adversarial imitation learning, which is the first\ncontribution of this paper. Then, we propose a method to alleviate the impact\nof false negatives and test it on the BabyAI environment. This method\nconsistently improves sample efficiency over the baselines by at least an order\nof magnitude.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 14:56:39 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Zolna", "Konrad", ""], ["Saharia", "Chitwan", ""], ["Boussioux", "Leonard", ""], ["Hui", "David Yu-Tung", ""], ["Chevalier-Boisvert", "Maxime", ""], ["Bahdanau", "Dzmitry", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2002.00423", "submitter": "Ibrahim Abdelaziz", "authors": "Ibrahim Abdelaziz, Veronika Thost, Maxwell Crouse, Achille Fokoue", "title": "An Experimental Study of Formula Embeddings for Automated Theorem\n  Proving in First-Order Logic", "comments": "7 pages, preprint, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated theorem proving in first-order logic is an active research area\nwhich is successfully supported by machine learning. While there have been\nvarious proposals for encoding logical formulas into numerical vectors -- from\nsimple strings to more involved graph-based embeddings -- little is known about\nhow these different encodings compare. In this paper, we study and\nexperimentally compare pattern-based embeddings that are applied in current\nsystems with popular graph-based encodings, most of which have not been\nconsidered in the theorem proving context before. Our experiments show that the\nadvantages of simpler encoding schemes in terms of runtime are outdone by more\ncomplex graph-based embeddings, which yield more efficient search strategies\nand simpler proofs. To support this, we present a detailed analysis across\nseveral dimensions of theorem prover performance beyond just proof completion\nrate, thus providing empirical evidence to help guide future research on\nneural-guided theorem proving towards the most promising directions.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 16:07:15 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 16:41:53 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Abdelaziz", "Ibrahim", ""], ["Thost", "Veronika", ""], ["Crouse", "Maxwell", ""], ["Fokoue", "Achille", ""]]}, {"id": "2002.00429", "submitter": "Eduardo C\\'esar Garrido Merch\\'an", "authors": "Eduardo C. Garrido-Merch\\'an, C. Puente, A. Sobrino, J.A. Olivas", "title": "Uncertainty Weighted Causal Graphs", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causality has traditionally been a scientific way to generate knowledge by\nrelating causes to effects. From an imaginery point of view, causal graphs are\na helpful tool for representing and infering new causal information. In\nprevious works, we have generated automatically causal graphs associated to a\ngiven concept by analyzing sets of documents and extracting and representing\nthe found causal information in that visual way. The retrieved information\nshows that causality is frequently imperfect rather than exact, feature\ngathered by the graph. In this work we will attempt to go a step further\nmodelling the uncertainty in the graph through probabilistic improving the\nmanagement of the imprecision in the quoted graph.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 16:32:04 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 13:39:26 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Garrido-Merch\u00e1n", "Eduardo C.", ""], ["Puente", "C.", ""], ["Sobrino", "A.", ""], ["Olivas", "J. A.", ""]]}, {"id": "2002.00434", "submitter": "Ekim Yurtsever", "authors": "Ekim Yurtsever, Linda Capito, Keith Redmill, Umit Ozguner", "title": "Integrating Deep Reinforcement Learning with Model-based Path Planners\n  for Automated Driving", "comments": "6 pages, 5 figures. Accepted for IEEE Intelligent Vehicles Symposium\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated driving in urban settings is challenging. Human participant\nbehavior is difficult to model, and conventional, rule-based Automated Driving\nSystems (ADSs) tend to fail when they face unmodeled dynamics. On the other\nhand, the more recent, end-to-end Deep Reinforcement Learning (DRL) based\nmodel-free ADSs have shown promising results. However, pure learning-based\napproaches lack the hard-coded safety measures of model-based controllers. Here\nwe propose a hybrid approach for integrating a path planning pipe into a vision\nbased DRL framework to alleviate the shortcomings of both worlds. In summary,\nthe DRL agent is trained to follow the path planner's waypoints as close as\npossible. The agent learns this policy by interacting with the environment. The\nreward function contains two major terms: the penalty of straying away from the\npath planner and the penalty of having a collision. The latter has precedence\nin the form of having a significantly greater numerical value. Experimental\nresults show that the proposed method can plan its path and navigate between\nrandomly chosen origin-destination points in CARLA, a dynamic urban simulation\nenvironment. Our code is open-source and available online.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 17:10:19 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 17:03:49 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Yurtsever", "Ekim", ""], ["Capito", "Linda", ""], ["Redmill", "Keith", ""], ["Ozguner", "Umit", ""]]}, {"id": "2002.00444", "submitter": "Senthil Yogamani", "authors": "B Ravi Kiran, Ibrahim Sobh, Victor Talpaert, Patrick Mannion, Ahmad A.\n  Al Sallab, Senthil Yogamani, Patrick P\\'erez", "title": "Deep Reinforcement Learning for Autonomous Driving: A Survey", "comments": "Accepted for publication at IEEE Transactions on Intelligent\n  Transportation Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of deep representation learning, the domain of\nreinforcement learning (RL) has become a powerful learning framework now\ncapable of learning complex policies in high dimensional environments. This\nreview summarises deep reinforcement learning (DRL) algorithms and provides a\ntaxonomy of automated driving tasks where (D)RL methods have been employed,\nwhile addressing key computational challenges in real world deployment of\nautonomous driving agents. It also delineates adjacent domains such as behavior\ncloning, imitation learning, inverse reinforcement learning that are related\nbut are not classical RL algorithms. The role of simulators in training agents,\nmethods to validate, test and robustify existing solutions in RL are discussed.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 18:21:22 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 17:02:01 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Kiran", "B Ravi", ""], ["Sobh", "Ibrahim", ""], ["Talpaert", "Victor", ""], ["Mannion", "Patrick", ""], ["Sallab", "Ahmad A. Al", ""], ["Yogamani", "Senthil", ""], ["P\u00e9rez", "Patrick", ""]]}, {"id": "2002.00509", "submitter": "Eduardo C\\'esar Garrido Merch\\'an", "authors": "Eduardo C. Garrido Merch\\'an, Mart\\'in Molina", "title": "A Machine Consciousness architecture based on Deep Learning and Gaussian\n  Processes", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in machine learning have pushed the tasks that machines\ncan do outside the boundaries of what was thought to be possible years ago.\nMethodologies such as deep learning or generative models have achieved complex\ntasks such as generating art pictures or literature automatically. On the other\nhand, symbolic resources have also been developed further and behave well in\nproblems such as the ones proposed by common sense reasoning. Machine\nConsciousness is a field that has been deeply studied and several theories\nbased in the functionalism philosophical theory like the global workspace\ntheory or information integration have been proposed that try to explain the\nariseness of consciousness in machines. In this work, we propose an\narchitecture that may arise consciousness in a machine based in the global\nworkspace theory and in the assumption that consciousness appear in machines\nthat has cognitive processes and exhibit conscious behaviour. This architecture\nis based in processes that use the recent developments in artificial\nintelligence models which output are these correlated activities. For every one\nof the modules of this architecture, we provide detailed explanations of the\nmodels involved and how they communicate with each other to create the\ncognitive architecture.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 23:18:17 GMT"}, {"version": "v2", "created": "Sat, 14 Mar 2020 00:01:23 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Merch\u00e1n", "Eduardo C. Garrido", ""], ["Molina", "Mart\u00edn", ""]]}, {"id": "2002.00514", "submitter": "Xiaoxiao Li", "authors": "Xiaoxiao Li and Joao Saude", "title": "Explain Graph Neural Networks to Understand Weighted Graph Features in\n  Node Classification", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real data collected from different applications that have additional\ntopological structures and connection information are amenable to be\nrepresented as a weighted graph. Considering the node labeling problem, Graph\nNeural Networks (GNNs) is a powerful tool, which can mimic experts' decision on\nnode labeling. GNNs combine node features, connection patterns, and graph\nstructure by using a neural network to embed node information and pass it\nthrough edges in the graph. We want to identify the patterns in the input data\nused by the GNN model to make a decision and examine if the model works as we\ndesire. However, due to the complex data representation and non-linear\ntransformations, explaining decisions made by GNNs is challenging. In this\nwork, we propose new graph features' explanation methods to identify the\ninformative components and important node features. Besides, we propose a\npipeline to identify the key factors used for node classification. We use four\ndatasets (two synthetic and two real) to validate our methods. Our results\ndemonstrate that our explanation approach can mimic data patterns used for node\nclassification by human interpretation and disentangle different features in\nthe graphs. Furthermore, our explanation methods can be used for understanding\ndata, debugging GNN models, and examine model decisions.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 23:53:21 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Li", "Xiaoxiao", ""], ["Saude", "Joao", ""]]}, {"id": "2002.00539", "submitter": "C.-H. Huck Yang", "authors": "Haoling Zhang, Chao-Han Huck Yang, Hector Zenil, Narsis A. Kiani, Yue\n  Shen, Jesper N. Tegner", "title": "Evolving Neural Networks through a Reverse Encoding Tree", "comments": "Accepted to IEEE Congress on Evolutionary Computation (IEEE CEC)\n  2020. Lecture Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.SY eess.SY q-bio.PE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  NeuroEvolution is one of the most competitive evolutionary learning\nframeworks for designing novel neural networks for use in specific tasks, such\nas logic circuit design and digital gaming. However, the application of\nbenchmark methods such as the NeuroEvolution of Augmenting Topologies (NEAT)\nremains a challenge, in terms of their computational cost and search time\ninefficiency. This paper advances a method which incorporates a type of\ntopological edge coding, named Reverse Encoding Tree (RET), for evolving\nscalable neural networks efficiently. Using RET, two types of approaches --\nNEAT with Binary search encoding (Bi-NEAT) and NEAT with Golden-Section search\nencoding (GS-NEAT) -- have been designed to solve problems in benchmark\ncontinuous learning environments such as logic gates, Cartpole, and Lunar\nLander, and tested against classical NEAT and FS-NEAT as baselines.\nAdditionally, we conduct a robustness test to evaluate the resilience of the\nproposed NEAT algorithms. The results show that the two proposed strategies\ndeliver improved performance, characterized by (1) a higher accumulated reward\nwithin a finite number of time steps; (2) using fewer episodes to solve\nproblems in targeted environments, and (3) maintaining adaptive robustness\nunder noisy perturbations, which outperform the baselines in all tested cases.\nOur analysis also demonstrates that RET expends potential future research\ndirections in dynamic environments. Code is available from\nhttps://github.com/HaolingZHANG/ReverseEncodingTree.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 02:29:51 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 21:00:11 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Zhang", "Haoling", ""], ["Yang", "Chao-Han Huck", ""], ["Zenil", "Hector", ""], ["Kiani", "Narsis A.", ""], ["Shen", "Yue", ""], ["Tegner", "Jesper N.", ""]]}, {"id": "2002.00557", "submitter": "Amol Kelkar", "authors": "Amol Kelkar, Rohan Relan, Vaishali Bhardwaj, Saurabh Vaichal, Chandra\n  Khatri, Peter Relan", "title": "Bertrand-DR: Improving Text-to-SQL using a Discriminative Re-ranker", "comments": "Accepted at WeCNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To access data stored in relational databases, users need to understand the\ndatabase schema and write a query using a query language such as SQL. To\nsimplify this task, text-to-SQL models attempt to translate a user's natural\nlanguage question to corresponding SQL query. Recently, several generative\ntext-to-SQL models have been developed. We propose a novel discriminative\nre-ranker to improve the performance of generative text-to-SQL models by\nextracting the best SQL query from the beam output predicted by the text-to-SQL\ngenerator, resulting in improved performance in the cases where the best query\nwas in the candidate list, but not at the top of the list. We build the\nre-ranker as a schema agnostic BERT fine-tuned classifier. We analyze relative\nstrengths of the text-to-SQL and re-ranker models across different query\nhardness levels, and suggest how to combine the two models for optimal\nperformance. We demonstrate the effectiveness of the re-ranker by applying it\nto two state-of-the-art text-to-SQL models, and achieve top 4 score on the\nSpider leaderboard at the time of writing this article.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 04:52:47 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 22:22:57 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Kelkar", "Amol", ""], ["Relan", "Rohan", ""], ["Bhardwaj", "Vaishali", ""], ["Vaichal", "Saurabh", ""], ["Khatri", "Chandra", ""], ["Relan", "Peter", ""]]}, {"id": "2002.00652", "submitter": "Qian Liu", "authors": "Qian Liu, Bei Chen, Jiaqi Guo, Jian-Guang Lou, Bin Zhou, Dongmei Zhang", "title": "How Far are We from Effective Context Modeling? An Exploratory Study on\n  Semantic Parsing in Context", "comments": "Accepted by IJCAI2020\n  (http://static.ijcai.org/2020-accepted_papers.html). SOLE copyright holder is\n  IJCAI (International Joint Conferences on Artificial Intelligence), all\n  rights reserved", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently semantic parsing in context has received considerable attention,\nwhich is challenging since there are complex contextual phenomena. Previous\nworks verified their proposed methods in limited scenarios, which motivates us\nto conduct an exploratory study on context modeling methods under real-world\nsemantic parsing in context. We present a grammar-based decoding semantic\nparser and adapt typical context modeling methods on top of it. We evaluate 13\ncontext modeling methods on two large complex cross-domain datasets, and our\nbest model achieves state-of-the-art performances on both datasets with\nsignificant improvements. Furthermore, we summarize the most frequent\ncontextual phenomena, with a fine-grained analysis on representative models,\nwhich may shed light on potential research directions. Our code is available at\nhttps://github.com/microsoft/ContextualSP.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 11:28:10 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 10:13:55 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Liu", "Qian", ""], ["Chen", "Bei", ""], ["Guo", "Jiaqi", ""], ["Lou", "Jian-Guang", ""], ["Zhou", "Bin", ""], ["Zhang", "Dongmei", ""]]}, {"id": "2002.00658", "submitter": "Marine Le Morvan", "authors": "Marine Le Morvan (PARIETAL, IJCLab), Nicolas Prost (CMAP, XPOP), Julie\n  Josse (CMAP, XPOP), Erwan Scornet (CMAP), Ga\\\"el Varoquaux (PARIETAL, MILA)", "title": "Linear predictor on linearly-generated data with missing values: non\n  consistency and solutions", "comments": null, "journal-ref": "Proceedings of Machine Learning Research, PMLR, In press", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider building predictors when the data have missing values. We study\nthe seemingly-simple case where the target to predict is a linear function of\nthe fully-observed data and we show that, in the presence of missing values,\nthe optimal predictor may not be linear. In the particular Gaussian case, it\ncan be written as a linear function of multiway interactions between the\nobserved data and the various missing-value indicators. Due to its intrinsic\ncomplexity, we study a simple approximation and prove generalization bounds\nwith finite samples, highlighting regimes for which each method performs best.\nWe then show that multilayer perceptrons with ReLU activation functions can be\nconsistent, and can explore good trade-offs between the true model and\napproximations. Our study highlights the interesting family of models that are\nbeneficial to fit with missing values depending on the amount of data\navailable.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 11:49:35 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 16:48:12 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Morvan", "Marine Le", "", "PARIETAL, IJCLab"], ["Prost", "Nicolas", "", "CMAP, XPOP"], ["Josse", "Julie", "", "CMAP, XPOP"], ["Scornet", "Erwan", "", "CMAP"], ["Varoquaux", "Ga\u00ebl", "", "PARIETAL, MILA"]]}, {"id": "2002.00666", "submitter": "Keehang Kwon", "authors": "Keehang Kwon and Daeseong Kang", "title": "Agent-Based Proof Design via Lemma Flow Diagram", "comments": "three figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss an agent-based approach to proof design and implementation, which\nwe call {\\it Lemma Flow Diagram} (LFD). This approach is based on the multicut\nrule with $shared$ cuts. This approach is modular and easy to use, read and\nautomate. Thus, we consider LFD an appealing alternative to `flow proof' which\nis popular in mathematical education. Some examples are provided.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 12:03:05 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Kwon", "Keehang", ""], ["Kang", "Daeseong", ""]]}, {"id": "2002.00695", "submitter": "Vasileios Iosifidis", "authors": "Vasileios Iosifidis, Besnik Fetahu, Eirini Ntoutsi", "title": "FAE: A Fairness-Aware Ensemble Framework", "comments": "6 pages", "journal-ref": "IEEE International Conference on Big Data, 2019", "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated decision making based on big data and machine learning (ML)\nalgorithms can result in discriminatory decisions against certain protected\ngroups defined upon personal data like gender, race, sexual orientation etc.\nSuch algorithms designed to discover patterns in big data might not only pick\nup any encoded societal biases in the training data, but even worse, they might\nreinforce such biases resulting in more severe discrimination. The majority of\nthus far proposed fairness-aware machine learning approaches focus solely on\nthe pre-, in- or post-processing steps of the machine learning process, that\nis, input data, learning algorithms or derived models, respectively. However,\nthe fairness problem cannot be isolated to a single step of the ML process.\nRather, discrimination is often a result of complex interactions between big\ndata and algorithms, and therefore, a more holistic approach is required. The\nproposed FAE (Fairness-Aware Ensemble) framework combines fairness-related\ninterventions at both pre- and postprocessing steps of the data analysis\nprocess. In the preprocessing step, we tackle the problems of\nunder-representation of the protected group (group imbalance) and of\nclass-imbalance by generating balanced training samples. In the post-processing\nstep, we tackle the problem of class overlapping by shifting the decision\nboundary in the direction of fairness.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 13:05:18 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Iosifidis", "Vasileios", ""], ["Fetahu", "Besnik", ""], ["Ntoutsi", "Eirini", ""]]}, {"id": "2002.00720", "submitter": "Valentin D. Richard", "authors": "Valentin D. Richard", "title": "Introduction of Quantification in Frame Semantics", "comments": "Master report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature Structures (FSs) are a widespread tool used for decompositional\nframeworks of Attribute-Value associations. Even though they thrive in simple\nsystems, they lack a way of representing higher-order entities and relations.\nThis is however needed in Frame Semantics, where semantic dependencies should\nbe able to connect groups of individuals and their properties, especially to\nmodel quantification. To answer this issue, this master report introduces\nwrappings as a way to envelop a sub-FS and treat it as a node. Following the\nwork of [Kallmeyer, Osswald 2013], we extend its syntax, semantics and some\nproperties (translation to FOL, subsumption, unification). We can then expand\nthe proposed pipeline. Lexical minimal model sets are generated from formulas.\nThey unify by FS value equations obtained by LTAG parsing to an underspecified\nsentence representation. The syntactic approach of quantifiers allows us to use\nexisting methods to produce any possible reading. Finally, we give a\ntranscription to type-logical formulas to interact with the context in the view\nof dynamic semantics. Supported by ideas of Frame Types, this system provides a\nworkable and tractable tool for higher-order relations with FS.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 15:52:29 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Richard", "Valentin D.", ""]]}, {"id": "2002.00733", "submitter": "Luke Melas-Kyriazi", "authors": "Luke Melas-Kyriazi, George Han, Celine Liang", "title": "Generation-Distillation for Efficient Natural Language Understanding in\n  Low-Data Settings", "comments": "EMNLP 2019 Workshop on Deep Learning for Low-resource NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past year, the emergence of transfer learning with large-scale\nlanguage models (LM) has led to dramatic performance improvements across a\nbroad range of natural language understanding tasks. However, the size and\nmemory footprint of these large LMs makes them difficult to deploy in many\nscenarios (e.g. on mobile phones). Recent research points to knowledge\ndistillation as a potential solution, showing that when training data for a\ngiven task is abundant, it is possible to distill a large (teacher) LM into a\nsmall task-specific (student) network with minimal loss of performance.\nHowever, when such data is scarce, there remains a significant performance gap\nbetween large pretrained LMs and smaller task-specific models, even when\ntraining via distillation. In this paper, we bridge this gap with a novel\ntraining approach, called generation-distillation, that leverages large\nfinetuned LMs in two ways: (1) to generate new (unlabeled) training examples,\nand (2) to distill their knowledge into a small network using these examples.\nAcross three low-resource text classification datsets, we achieve comparable\nperformance to BERT while using 300x fewer parameters, and we outperform prior\napproaches to distillation for text classification while using 3x fewer\nparameters.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 08:20:46 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Melas-Kyriazi", "Luke", ""], ["Han", "George", ""], ["Liang", "Celine", ""]]}, {"id": "2002.00737", "submitter": "Taeuk Kim", "authors": "Taeuk Kim, Jihun Choi, Daniel Edmiston, and Sang-goo Lee", "title": "Are Pre-trained Language Models Aware of Phrases? Simple but Strong\n  Baselines for Grammar Induction", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent success and popularity of pre-trained language models (LMs)\nin natural language processing, there has been a rise in efforts to understand\ntheir inner workings. In line with such interest, we propose a novel method\nthat assists us in investigating the extent to which pre-trained LMs capture\nthe syntactic notion of constituency. Our method provides an effective way of\nextracting constituency trees from the pre-trained LMs without training. In\naddition, we report intriguing findings in the induced trees, including the\nfact that pre-trained LMs outperform other approaches in correctly demarcating\nadverb phrases in sentences.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 11:06:49 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Kim", "Taeuk", ""], ["Choi", "Jihun", ""], ["Edmiston", "Daniel", ""], ["Lee", "Sang-goo", ""]]}, {"id": "2002.00744", "submitter": "Shoubin Li", "authors": "Shoubin Li, Wenzao Cui, Yujiang Liu, Xuran Ming, Jun Hu, YuanzheHu,\n  Qing Wang", "title": "PEL-BERT: A Joint Model for Protocol Entity Linking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained models such as BERT are widely used in NLP tasks and are\nfine-tuned to improve the performance of various NLP tasks consistently.\nNevertheless, the fine-tuned BERT model trained on our protocol corpus still\nhas a weak performance on the Entity Linking (EL) task. In this paper, we\npropose a model that joints a fine-tuned language model with an RFC Domain\nModel. Firstly, we design a Protocol Knowledge Base as the guideline for\nprotocol EL. Secondly, we propose a novel model, PEL-BERT, to link named\nentities in protocols to categories in Protocol Knowledge Base. Finally, we\nconduct a comprehensive study on the performance of pre-trained language models\non descriptive texts and abstract concepts. Experimental results demonstrate\nthat our model achieves state-of-the-art performance in EL on our annotated\ndataset, outperforming all the baselines.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 16:42:40 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Li", "Shoubin", ""], ["Cui", "Wenzao", ""], ["Liu", "Yujiang", ""], ["Ming", "Xuran", ""], ["Hu", "Jun", ""], ["YuanzheHu", "", ""], ["Wang", "Qing", ""]]}, {"id": "2002.00747", "submitter": "Maartje ter Hoeve", "authors": "Maartje ter Hoeve, Robert Sim, Elnaz Nouri, Adam Fourney, Maarten de\n  Rijke, Ryen W. White", "title": "Conversations with Documents. An Exploration of Document-Centered\n  Assistance", "comments": "Accepted as full paper at CHIIR 2020; 9 pages + Appendix", "journal-ref": null, "doi": "10.1145/3343413.3377971", "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The role of conversational assistants has become more prevalent in helping\npeople increase their productivity. Document-centered assistance, for example\nto help an individual quickly review a document, has seen less significant\nprogress, even though it has the potential to tremendously increase a user's\nproductivity. This type of document-centered assistance is the focus of this\npaper. Our contributions are three-fold: (1) We first present a survey to\nunderstand the space of document-centered assistance and the capabilities\npeople expect in this scenario. (2) We investigate the types of queries that\nusers will pose while seeking assistance with documents, and show that\ndocument-centered questions form the majority of these queries. (3) We present\na set of initial machine learned models that show that (a) we can accurately\ndetect document-centered questions, and (b) we can build reasonably accurate\nmodels for answering such questions. These positive results are encouraging,\nand suggest that even greater results may be attained with continued study of\nthis interesting and novel problem space. Our findings have implications for\nthe design of intelligent systems to support task completion via natural\ninteractions with documents.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 17:10:11 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["ter Hoeve", "Maartje", ""], ["Sim", "Robert", ""], ["Nouri", "Elnaz", ""], ["Fourney", "Adam", ""], ["de Rijke", "Maarten", ""], ["White", "Ryen W.", ""]]}, {"id": "2002.00762", "submitter": "Kartik Talamadupula", "authors": "Mayank Agarwal, Jorge J. Barroso, Tathagata Chakraborti, Eli M. Dow,\n  Kshitij Fadnis, Borja Godoy, Madhavan Pallan, Kartik Talamadupula", "title": "Project CLAI: Instrumenting the Command Line as a New Environment for AI\n  Agents", "comments": "http://ibm.biz/clai-home", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This whitepaper reports on Project CLAI (Command Line AI), which aims to\nbring the power of AI to the command line interface (CLI). The CLAI platform\nsets up the CLI as a new environment for AI researchers to conquer by surfacing\nthe command line as a generic environment that researchers can interface to\nusing a simple sense-act API, much like the traditional AI agent architecture.\nIn this paper, we discuss the design and implementation of the platform in\ndetail, through illustrative use cases of new end user interaction patterns\nenabled by this design, and through quantitative evaluation of the system\nfootprint of a CLAI-enabled terminal. We also report on some early user\nfeedback on CLAI's features from an internal survey.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 05:01:05 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 23:11:15 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Agarwal", "Mayank", ""], ["Barroso", "Jorge J.", ""], ["Chakraborti", "Tathagata", ""], ["Dow", "Eli M.", ""], ["Fadnis", "Kshitij", ""], ["Godoy", "Borja", ""], ["Pallan", "Madhavan", ""], ["Talamadupula", "Kartik", ""]]}, {"id": "2002.00801", "submitter": "Amos Treiber", "authors": "Amos Treiber and Alejandro Molina and Christian Weinert and Thomas\n  Schneider and Kristian Kersting", "title": "CryptoSPN: Privacy-preserving Sum-Product Network Inference", "comments": "Accepted for publication at ECAI'20. Please cite the conference\n  version of this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI algorithms, and machine learning (ML) techniques in particular, are\nincreasingly important to individuals' lives, but have caused a range of\nprivacy concerns addressed by, e.g., the European GDPR. Using cryptographic\ntechniques, it is possible to perform inference tasks remotely on sensitive\nclient data in a privacy-preserving way: the server learns nothing about the\ninput data and the model predictions, while the client learns nothing about the\nML model (which is often considered intellectual property and might contain\ntraces of sensitive data). While such privacy-preserving solutions are\nrelatively efficient, they are mostly targeted at neural networks, can degrade\nthe predictive accuracy, and usually reveal the network's topology.\nFurthermore, existing solutions are not readily accessible to ML experts, as\nprototype implementations are not well-integrated into ML frameworks and\nrequire extensive cryptographic knowledge.\n  In this paper, we present CryptoSPN, a framework for privacy-preserving\ninference of sum-product networks (SPNs). SPNs are a tractable probabilistic\ngraphical model that allows a range of exact inference queries in linear time.\nSpecifically, we show how to efficiently perform SPN inference via secure\nmulti-party computation (SMPC) without accuracy degradation while hiding\nsensitive client and training information with provable security guarantees.\nNext to foundations, CryptoSPN encompasses tools to easily transform existing\nSPNs into privacy-preserving executables. Our empirical results demonstrate\nthat CryptoSPN achieves highly efficient and accurate inference in the order of\nseconds for medium-sized SPNs.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 14:49:18 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Treiber", "Amos", ""], ["Molina", "Alejandro", ""], ["Weinert", "Christian", ""], ["Schneider", "Thomas", ""], ["Kersting", "Kristian", ""]]}, {"id": "2002.00811", "submitter": "Jan Drchal", "authors": "Jan Drchal and Jan Faigl and Petr V\\'a\\v{n}a", "title": "WiSM: Windowing Surrogate Model for Evaluation of Curvature-Constrained\n  Tours with Dubins vehicle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dubins tours represent a solution of the Dubins Traveling Salesman Problem\n(DTSP) that is a variant of the optimization routing problem to determine a\ncurvature-constrained shortest path to visit a set of locations such that the\npath is feasible for Dubins vehicle, which moves only forward and has a limited\nturning radius. The DTSP combines the NP-hard combinatorial optimization to\ndetermine the optimal sequence of visits to the locations, as in the regular\nTSP, with the continuous optimization of the heading angles at the locations,\nwhere the optimal heading values depend on the sequence of visits and vice\nversa. We address the computationally challenging DTSP by fast evaluation of\nthe sequence of visits by the proposed Windowing Surrogate Model (WiSM) which\nestimates the length of the optimal Dubins path connecting a sequence of\nlocations in a Dubins tour. The estimation is sped up by a regression model\ntrained using close to optimum solutions of small Dubins tours that are\ngeneralized for large-scale instances of the addressed DTSP utilizing the\nsliding window technique and a cache for already computed results. The reported\nresults support that the proposed WiSM enables a fast convergence of a\nrelatively simple evolutionary algorithm to high-quality solutions of the DTSP.\nWe show that with an increasing number of locations, our algorithm scales\nsignificantly better than other state-of-the-art DTSP solvers.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 15:06:43 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Drchal", "Jan", ""], ["Faigl", "Jan", ""], ["V\u00e1\u0148a", "Petr", ""]]}, {"id": "2002.00872", "submitter": "Amaury Depierre", "authors": "Amaury Depierre (imagine), Emmanuel Dellandr\\'ea (imagine), Liming\n  Chen (imagine)", "title": "Scoring Graspability based on Grasp Regression for Better Grasp\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grasping objects is one of the most important abilities that a robot needs to\nmaster in order to interact with its environment. Current state-of-the-art\nmethods rely on deep neural networks trained to jointly predict a graspability\nscore together with a regression of an offset with respect to grasp reference\nparameters. However, these two predictions are performed independently, which\ncan lead to a decrease in the actual graspability score when applying the\npredicted offset. Therefore, in this paper, we extend a state-of-the-art neural\nnetwork with a scorer that evaluates the graspability of a given position, and\nintroduce a novel loss function which correlates regression of grasp parameters\nwith graspability score. We show that this novel architecture improves\nperformance from 82.13% for a state-of-the-art grasp detection network to\n85.74% on Jacquard dataset. When the learned model is transferred onto a real\nrobot, the proposed method correlating graspability and grasp regression\nachieves a 92.4% rate compared to 88.1% for the baseline trained without the\ncorrelation.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 16:40:16 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 13:19:44 GMT"}, {"version": "v3", "created": "Wed, 31 Mar 2021 08:09:26 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Depierre", "Amaury", "", "imagine"], ["Dellandr\u00e9a", "Emmanuel", "", "imagine"], ["Chen", "Liming", "", "imagine"]]}, {"id": "2002.00941", "submitter": "Andreea Bobu", "authors": "Andreea Bobu, Andrea Bajcsy, Jaime F. Fisac, Sampada Deglurkar, Anca\n  D. Dragan", "title": "Quantifying Hypothesis Space Misspecification in Learning from\n  Human-Robot Demonstrations and Physical Corrections", "comments": "20 pages. 12 figures, 1 table. IEEE Transactions on Robotics, 2020", "journal-ref": null, "doi": "10.1109/TRO.2020.2971415", "report-no": null, "categories": "cs.RO cs.AI cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human input has enabled autonomous systems to improve their capabilities and\nachieve complex behaviors that are otherwise challenging to generate\nautomatically. Recent work focuses on how robots can use such input - like\ndemonstrations or corrections - to learn intended objectives. These techniques\nassume that the human's desired objective already exists within the robot's\nhypothesis space. In reality, this assumption is often inaccurate: there will\nalways be situations where the person might care about aspects of the task that\nthe robot does not know about. Without this knowledge, the robot cannot infer\nthe correct objective. Hence, when the robot's hypothesis space is\nmisspecified, even methods that keep track of uncertainty over the objective\nfail because they reason about which hypothesis might be correct, and not\nwhether any of the hypotheses are correct. In this paper, we posit that the\nrobot should reason explicitly about how well it can explain human inputs given\nits hypothesis space and use that situational confidence to inform how it\nshould incorporate human input. We demonstrate our method on a 7\ndegree-of-freedom robot manipulator in learning from two important types of\nhuman input: demonstrations of manipulation tasks, and physical corrections\nduring the robot's task execution.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 18:59:23 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 23:59:41 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Bobu", "Andreea", ""], ["Bajcsy", "Andrea", ""], ["Fisac", "Jaime F.", ""], ["Deglurkar", "Sampada", ""], ["Dragan", "Anca D.", ""]]}, {"id": "2002.01014", "submitter": "P. Jonathon Phillips", "authors": "P. Jonathon Phillips and Mark Przybocki", "title": "Four Principles of Explainable AI as Applied to Biometrics and Facial\n  Forensic Algorithms", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Traditionally, researchers in automatic face recognition and biometric\ntechnologies have focused on developing accurate algorithms. With this\ntechnology being integrated into operational systems, engineers and scientists\nare being asked, do these systems meet societal norms? The origin of this line\nof inquiry is `trust' of artificial intelligence (AI) systems. In this paper,\nwe concentrate on adapting explainable AI to face recognition and biometrics,\nand we present four principles of explainable AI to face recognition and\nbiometrics. The principles are illustrated by $\\it{four}$ case studies, which\nshow the challenges and issues in developing algorithms that can produce\nexplanations.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 21:03:20 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Phillips", "P. Jonathon", ""], ["Przybocki", "Mark", ""]]}, {"id": "2002.01059", "submitter": "Albert Zhan", "authors": "Albert Zhan, Stas Tiomkin, Pieter Abbeel", "title": "Preventing Imitation Learning with Adversarial Policy Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning can reproduce policies by observing experts, which poses a\nproblem regarding policy privacy. Policies, such as human, or policies on\ndeployed robots, can all be cloned without consent from the owners. How can we\nprotect against external observers cloning our proprietary policies? To answer\nthis question we introduce a new reinforcement learning framework, where we\ntrain an ensemble of near-optimal policies, whose demonstrations are guaranteed\nto be useless for an external observer. We formulate this idea by a constrained\noptimization problem, where the objective is to improve proprietary policies,\nand at the same time deteriorate the virtual policy of an eventual external\nobserver. We design a tractable algorithm to solve this new optimization\nproblem by modifying the standard policy gradient algorithm. Our formulation\ncan be interpreted in lenses of confidentiality and adversarial behaviour,\nwhich enables a broader perspective of this work. We demonstrate the existence\nof \"non-clonable\" ensembles, providing a solution to the above optimization\nproblem, which is calculated by our modified policy gradient algorithm. To our\nknowledge, this is the first work regarding the protection of policies in\nReinforcement Learning.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 01:57:16 GMT"}, {"version": "v2", "created": "Sun, 2 Aug 2020 23:15:58 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Zhan", "Albert", ""], ["Tiomkin", "Stas", ""], ["Abbeel", "Pieter", ""]]}, {"id": "2002.01065", "submitter": "Eduardo C\\'esar Garrido Merch\\'an", "authors": "Eduardo C. Garrido-Merch\\'an, Cristina Puente, Rafael Palacios", "title": "Fake News Detection by means of Uncertainty Weighted Causal Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Society is experimenting changes in information consumption, as new\ninformation channels such as social networks let people share news that do not\nnecessarily be trust worthy. Sometimes, these sources of information produce\nfake news deliberately with doubtful purposes and the consumers of that\ninformation share it to other users thinking that the information is accurate.\nThis transmission of information represents an issue in our society, as can\ninfluence negatively the opinion of people about certain figures, groups or\nideas. Hence, it is desirable to design a system that is able to detect and\nclassify information as fake and categorize a source of information as trust\nworthy or not. Current systems experiment difficulties performing this task, as\nit is complicated to design an automatic procedure that can classify this\ninformation independent on the context. In this work, we propose a mechanism to\ndetect fake news through a classifier based on weighted causal graphs. These\ngraphs are specific hybrid models that are built through causal relations\nretrieved from texts and consider the uncertainty of causal relations. We take\nadvantage of this representation to use the probability distributions of this\ngraph and built a fake news classifier based on the entropy and KL divergence\nof learned and new information. We believe that the problem of fake news is\naccurately tackled by this model due to its hybrid nature between a symbolic\nand quantitative methodology. We describe the methodology of this classifier\nand add empirical evidence of the usefulness of our proposed approach in the\nform of synthetic experiments and a real experiment involving lung cancer.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 00:28:38 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 05:12:35 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Garrido-Merch\u00e1n", "Eduardo C.", ""], ["Puente", "Cristina", ""], ["Palacios", "Rafael", ""]]}, {"id": "2002.01071", "submitter": "Karam Abdulahhad", "authors": "Karam Abdulahhad", "title": "Concept Embedding for Information Retrieval", "comments": "6 pages", "journal-ref": null, "doi": "10.1007/978-3-319-76941-7_45", "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concepts are used to solve the term-mismatch problem. However, we need an\neffective similarity measure between concepts. Word embedding presents a\npromising solution. We present in this study three approaches to build concepts\nvectors based on words vectors. We use a vector-based measure to estimate\ninter-concepts similarity. Our experiments show promising results. Furthermore,\nwords and concepts become comparable. This could be used to improve conceptual\nindexing process.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 09:18:56 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Abdulahhad", "Karam", ""]]}, {"id": "2002.01080", "submitter": "Sarath Sreedharan", "authors": "Sarath Sreedharan, Utkarsh Soni, Mudit Verma, Siddharth Srivastava,\n  Subbarao Kambhampati", "title": "Bridging the Gap: Providing Post-Hoc Symbolic Explanations for\n  Sequential Decision-Making Problems with Black Box Simulators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As increasingly complex AI systems are introduced into our daily lives, it\nbecomes important for such systems to be capable of explaining the rationale\nfor their decisions and allowing users to contest these decisions. A\nsignificant hurdle to allowing for such explanatory dialogue could be the\nvocabulary mismatch between the user and the AI system. This paper introduces\nmethods for providing contrastive explanations in terms of user-specified\nconcepts for sequential decision-making settings where the system's model of\nthe task may be best represented as a blackbox simulator. We do this by\nbuilding partial symbolic models of the task that can be leveraged to answer\nthe user queries. We empirically test these methods on a popular Atari game\n(Montezuma's Revenge) and modified versions of Sokoban (a well known planning\nbenchmark) and report the results of user studies to evaluate whether people\nfind explanations generated in this form useful.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 01:37:56 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 19:46:15 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Sreedharan", "Sarath", ""], ["Soni", "Utkarsh", ""], ["Verma", "Mudit", ""], ["Srivastava", "Siddharth", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "2002.01088", "submitter": "Thommen George Karimpanal", "authors": "Thommen George Karimpanal", "title": "Neuro-evolutionary Frameworks for Generalized Learning Agents", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent successes of deep learning and deep reinforcement learning have\nfirmly established their statuses as state-of-the-art artificial learning\ntechniques. However, longstanding drawbacks of these approaches, such as their\npoor sample efficiencies and limited generalization capabilities point to a\nneed for re-thinking the way such systems are designed and deployed. In this\npaper, we emphasize how the use of these learning systems, in conjunction with\na specific variation of evolutionary algorithms could lead to the emergence of\nunique characteristics such as the automated acquisition of a variety of\ndesirable behaviors and useful sets of behavior priors. This could pave the way\nfor learning to occur in a generalized and continual manner, with minimal\ninteractions with the environment. We discuss the anticipated improvements from\nsuch neuro-evolutionary frameworks, along with the associated challenges, as\nwell as its potential for application to a number of research areas.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 02:11:56 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Karimpanal", "Thommen George", ""]]}, {"id": "2002.01092", "submitter": "Upol Ehsan", "authors": "Upol Ehsan and Mark O. Riedl", "title": "Human-centered Explainable AI: Towards a Reflective Sociotechnical\n  Approach", "comments": "In Proceedings of HCI International 2020: 22nd International\n  Conference On Human-Computer Interaction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explanations--a form of post-hoc interpretability--play an instrumental role\nin making systems accessible as AI continues to proliferate complex and\nsensitive sociotechnical systems. In this paper, we introduce Human-centered\nExplainable AI (HCXAI) as an approach that puts the human at the center of\ntechnology design. It develops a holistic understanding of \"who\" the human is\nby considering the interplay of values, interpersonal dynamics, and the\nsocially situated nature of AI systems. In particular, we advocate for a\nreflective sociotechnical approach. We illustrate HCXAI through a case study of\nan explanation system for non-technical end-users that shows how technical\nadvancements and the understanding of human factors co-evolve. Building on the\ncase study, we lay out open research questions pertaining to further refining\nour understanding of \"who\" the human is and extending beyond 1-to-1\nhuman-computer interactions. Finally, we propose that a reflective HCXAI\nparadigm-mediated through the perspective of Critical Technical Practice and\nsupplemented with strategies from HCI, such as value-sensitive design and\nparticipatory design--not only helps us understand our intellectual blind\nspots, but it can also open up new design and research spaces.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 02:30:33 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 05:33:14 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Ehsan", "Upol", ""], ["Riedl", "Mark O.", ""]]}, {"id": "2002.01093", "submitter": "Abhinav Gupta", "authors": "Ryan Lowe, Abhinav Gupta, Jakob Foerster, Douwe Kiela, Joelle Pineau", "title": "On the interaction between supervision and self-play in emergent\n  communication", "comments": "The first two authors contributed equally. Accepted at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A promising approach for teaching artificial agents to use natural language\ninvolves using human-in-the-loop training. However, recent work suggests that\ncurrent machine learning methods are too data inefficient to be trained in this\nway from scratch. In this paper, we investigate the relationship between two\ncategories of learning signals with the ultimate goal of improving sample\nefficiency: imitating human language data via supervised learning, and\nmaximizing reward in a simulated multi-agent environment via self-play (as done\nin emergent communication), and introduce the term supervised self-play (S2P)\nfor algorithms using both of these signals. We find that first training agents\nvia supervised learning on human data followed by self-play outperforms the\nconverse, suggesting that it is not beneficial to emerge languages from\nscratch. We then empirically investigate various S2P schedules that begin with\nsupervised learning in two environments: a Lewis signaling game with symbolic\ninputs, and an image-based referential game with natural language descriptions.\nLastly, we introduce population based approaches to S2P, which further improves\nthe performance over single-agent methods.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 02:35:19 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 20:48:08 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Lowe", "Ryan", ""], ["Gupta", "Abhinav", ""], ["Foerster", "Jakob", ""], ["Kiela", "Douwe", ""], ["Pineau", "Joelle", ""]]}, {"id": "2002.01169", "submitter": "Zhen Peng", "authors": "Zhen Peng, Wenbing Huang, Minnan Luo, Qinghua Zheng, Yu Rong, Tingyang\n  Xu, Junzhou Huang", "title": "Graph Representation Learning via Graphical Mutual Information\n  Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The richness in the content of various information networks such as social\nnetworks and communication networks provides the unprecedented potential for\nlearning high-quality expressive representations without external supervision.\nThis paper investigates how to preserve and extract the abundant information\nfrom graph-structured data into embedding space in an unsupervised manner. To\nthis end, we propose a novel concept, Graphical Mutual Information (GMI), to\nmeasure the correlation between input graphs and high-level hidden\nrepresentations. GMI generalizes the idea of conventional mutual information\ncomputations from vector space to the graph domain where measuring mutual\ninformation from two aspects of node features and topological structure is\nindispensable. GMI exhibits several benefits: First, it is invariant to the\nisomorphic transformation of input graphs---an inevitable constraint in many\nexisting graph representation learning algorithms; Besides, it can be\nefficiently estimated and maximized by current mutual information estimation\nmethods such as MINE; Finally, our theoretical analysis confirms its\ncorrectness and rationality. With the aid of GMI, we develop an unsupervised\nlearning model trained by maximizing GMI between the input and output of a\ngraph neural encoder. Considerable experiments on transductive as well as\ninductive node classification and link prediction demonstrate that our method\noutperforms state-of-the-art unsupervised counterparts, and even sometimes\nexceeds the performance of supervised ones.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 08:33:49 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Peng", "Zhen", ""], ["Huang", "Wenbing", ""], ["Luo", "Minnan", ""], ["Zheng", "Qinghua", ""], ["Rong", "Yu", ""], ["Xu", "Tingyang", ""], ["Huang", "Junzhou", ""]]}, {"id": "2002.01245", "submitter": "Kuruge Darshana Abeyrathna", "authors": "K. Darshana Abeyrathna, Ole-Christoffer Granmo, Morten Goodwin", "title": "A Regression Tsetlin Machine with Integer Weighted Clauses for Compact\n  Pattern Representation", "comments": "12 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Regression Tsetlin Machine (RTM) addresses the lack of interpretability\nimpeding state-of-the-art nonlinear regression models. It does this by using\nconjunctive clauses in propositional logic to capture the underlying non-linear\nfrequent patterns in the data. These, in turn, are combined into a continuous\noutput through summation, akin to a linear regression function, however, with\nnon-linear components and unity weights. Although the RTM has solved non-linear\nregression problems with competitive accuracy, the resolution of the output is\nproportional to the number of clauses employed. This means that computation\ncost increases with resolution. To reduce this problem, we here introduce\ninteger weighted RTM clauses. Our integer weighted clause is a compact\nrepresentation of multiple clauses that capture the same sub-pattern-N\nrepeating clauses are turned into one, with an integer weight N. This reduces\ncomputation cost N times, and increases interpretability through a sparser\nrepresentation. We further introduce a novel learning scheme that allows us to\nsimultaneously learn both the clauses and their weights, taking advantage of\nso-called stochastic searching on the line. We evaluate the potential of the\ninteger weighted RTM empirically using six artificial datasets. The results\nshow that the integer weighted RTM is able to acquire on par or better accuracy\nusing significantly less computational resources compared to regular RTMs. We\nfurther show that integer weights yield improved accuracy over real-valued\nones.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 12:06:16 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Abeyrathna", "K. Darshana", ""], ["Granmo", "Ole-Christoffer", ""], ["Goodwin", "Morten", ""]]}, {"id": "2002.01335", "submitter": "Abhinav Gupta", "authors": "Agnieszka S{\\l}owik, Abhinav Gupta, William L. Hamilton, Mateja\n  Jamnik, Sean B. Holden, Christopher Pal", "title": "Structural Inductive Biases in Emergent Communication", "comments": "The first two authors contributed equally. Poster presented at CogSci\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to communicate, humans flatten a complex representation of ideas and\ntheir attributes into a single word or a sentence. We investigate the impact of\nrepresentation learning in artificial agents by developing graph referential\ngames. We empirically show that agents parametrized by graph neural networks\ndevelop a more compositional language compared to bag-of-words and sequence\nmodels, which allows them to systematically generalize to new combinations of\nfamiliar features.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 14:59:08 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 18:57:45 GMT"}, {"version": "v3", "created": "Fri, 23 Jul 2021 22:05:34 GMT"}, {"version": "v4", "created": "Tue, 27 Jul 2021 04:13:03 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["S\u0142owik", "Agnieszka", ""], ["Gupta", "Abhinav", ""], ["Hamilton", "William L.", ""], ["Jamnik", "Mateja", ""], ["Holden", "Sean B.", ""], ["Pal", "Christopher", ""]]}, {"id": "2002.01352", "submitter": "Yi-Shuai Niu", "authors": "Yi-Shuai Niu, Yu You, Wenxu Xu, Wentao Ding, Junpeng Hu, Songquan Yao", "title": "A Difference-of-Convex Programming Approach With Parallel\n  Branch-and-Bound For Sentence Compression Via A Hybrid Extractive Model", "comments": "Full length paper (a short version of this paper for conference\n  proceedings can be found arXiv:1902.07248)", "journal-ref": "Optimization Letters (2021)", "doi": "10.1007/s11590-020-01695-9", "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence compression is an important problem in natural language processing\nwith wide applications in text summarization, search engine and human-AI\ninteraction system etc. In this paper, we design a hybrid extractive sentence\ncompression model combining a probability language model and a parse tree\nlanguage model for compressing sentences by guaranteeing the syntax correctness\nof the compression results. Our compression model is formulated as an integer\nlinear programming problem, which can be rewritten as a Difference-of-Convex\n(DC) programming problem based on the exact penalty technique. We use a\nwell-known efficient DC algorithm -- DCA to handle the penalized problem for\nlocal optimal solutions. Then a hybrid global optimization algorithm combining\nDCA with a parallel branch-and-bound framework, namely PDCABB, is used for\nfinding global optimal solutions. Numerical results demonstrate that our\nsentence compression model can provide excellent compression results evaluated\nby F-score, and indicate that PDCABB is a promising algorithm for solving our\nsentence compression model.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 18:33:31 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2021 14:59:45 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Niu", "Yi-Shuai", ""], ["You", "Yu", ""], ["Xu", "Wenxu", ""], ["Ding", "Wentao", ""], ["Hu", "Junpeng", ""], ["Yao", "Songquan", ""]]}, {"id": "2002.01365", "submitter": "Shangmin Guo", "authors": "Yi Ren, Shangmin Guo, Matthieu Labeau, Shay B. Cohen, Simon Kirby", "title": "Compositional Languages Emerge in a Neural Iterated Learning Model", "comments": "accepted by ICLR-2020", "journal-ref": "ICLR-2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The principle of compositionality, which enables natural language to\nrepresent complex concepts via a structured combination of simpler ones, allows\nus to convey an open-ended set of messages using a limited vocabulary. If\ncompositionality is indeed a natural property of language, we may expect it to\nappear in communication protocols that are created by neural agents in language\ngames. In this paper, we propose an effective neural iterated learning (NIL)\nalgorithm that, when applied to interacting neural agents, facilitates the\nemergence of a more structured type of language. Indeed, these languages\nprovide learning speed advantages to neural agents during training, which can\nbe incrementally amplified via NIL. We provide a probabilistic model of NIL and\nan explanation of why the advantage of compositional language exist. Our\nexperiments confirm our analysis, and also demonstrate that the emerged\nlanguages largely improve the generalizing power of the neural agent\ncommunication.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 15:19:09 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 11:22:04 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Ren", "Yi", ""], ["Guo", "Shangmin", ""], ["Labeau", "Matthieu", ""], ["Cohen", "Shay B.", ""], ["Kirby", "Simon", ""]]}, {"id": "2002.01464", "submitter": "Jiayuan Mao", "authors": "Chi Han, Jiayuan Mao, Chuang Gan, Joshua B. Tenenbaum, Jiajun Wu", "title": "Visual Concept-Metaconcept Learning", "comments": "NeurIPS 2019. First two authors contributed equally. Project page:\n  http://vcml.csail.mit.edu/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans reason with concepts and metaconcepts: we recognize red and green from\nvisual input; we also understand that they describe the same property of\nobjects (i.e., the color). In this paper, we propose the visual\nconcept-metaconcept learner (VCML) for joint learning of concepts and\nmetaconcepts from images and associated question-answer pairs. The key is to\nexploit the bidirectional connection between visual concepts and metaconcepts.\nVisual representations provide grounding cues for predicting relations between\nunseen pairs of concepts. Knowing that red and green describe the same property\nof objects, we generalize to the fact that cube and sphere also describe the\nsame property of objects, since they both categorize the shape of objects.\nMeanwhile, knowledge about metaconcepts empowers visual concept learning from\nlimited, noisy, and even biased data. From just a few examples of purple cubes\nwe can understand a new color purple, which resembles the hue of the cubes\ninstead of the shape of them. Evaluation on both synthetic and real-world\ndatasets validates our claims.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 18:42:30 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Han", "Chi", ""], ["Mao", "Jiayuan", ""], ["Gan", "Chuang", ""], ["Tenenbaum", "Joshua B.", ""], ["Wu", "Jiajun", ""]]}, {"id": "2002.01559", "submitter": "Anne L. Washington", "authors": "Anne L. Washington, Rachel S. Kuo", "title": "Whose Side are Ethics Codes On? Power, Responsibility and the Social\n  Good", "comments": "Conference on Fairness, Accountability, and Transparency (FAT* '20),\n  January 27-30, 2020, Barcelona, Spain. Corrected", "journal-ref": null, "doi": "10.1145/3351095.3372844", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The moral authority of ethics codes stems from an assumption that they serve\na unified society, yet this ignores the political aspects of any shared\nresource. The sociologist Howard S. Becker challenged researchers to clarify\ntheir power and responsibility in the classic essay: Whose Side Are We On.\nBuilding on Becker's hierarchy of credibility, we report on a critical\ndiscourse analysis of data ethics codes and emerging conceptualizations of\nbeneficence, or the \"social good\", of data technology. The analysis revealed\nthat ethics codes from corporations and professional associations conflated\nconsumers with society and were largely silent on agency. Interviews with\ncommunity organizers about social change in the digital era supplement the\nanalysis, surfacing the limits of technical solutions to concerns of\nmarginalized communities. Given evidence that highlights the gulf between the\ndocuments and lived experiences, we argue that ethics codes that elevate\nconsumers may simultaneously subordinate the needs of vulnerable populations.\nUnderstanding contested digital resources is central to the emerging field of\npublic interest technology. We introduce the concept of digital differential\nvulnerability to explain disproportionate exposures to harm within data\ntechnology and suggest recommendations for future ethics codes.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 22:05:09 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Washington", "Anne L.", ""], ["Kuo", "Rachel S.", ""]]}, {"id": "2002.01598", "submitter": "Byungsoo Jeon", "authors": "Byungsoo Jeon, Namyong Park, Seojin Bang", "title": "Dropout Prediction over Weeks in MOOCs via Interpretable Multi-Layer\n  Representation Learning", "comments": "Accepted at AAAI 2020 AI4Edu Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive Open Online Courses (MOOCs) have become popular platforms for online\nlearning. While MOOCs enable students to study at their own pace, this\nflexibility makes it easy for students to drop out of class. In this paper, our\ngoal is to predict if a learner is going to drop out within the next week,\ngiven clickstream data for the current week. To this end, we present a\nmulti-layer representation learning solution based on branch and bound (BB)\nalgorithm, which learns from low-level clickstreams in an unsupervised manner,\nproduces interpretable results, and avoids manual feature engineering. In\nexperiments on Coursera data, we show that our model learns a representation\nthat allows a simple model to perform similarly well to more complex,\ntask-specific models, and how the BB algorithm enables interpretable results.\nIn our analysis of the observed limitations, we discuss promising future\ndirections.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 01:15:34 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Jeon", "Byungsoo", ""], ["Park", "Namyong", ""], ["Bang", "Seojin", ""]]}, {"id": "2002.01605", "submitter": "Zhi-Hua Zhou", "authors": "Yu-Jie Zhang and Peng Zhao and Zhi-Hua Zhou", "title": "Exploratory Machine Learning with Unknown Unknowns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In conventional supervised learning, a training dataset is given with\nground-truth labels from a known label set, and the learned model will classify\nunseen instances to the known labels. In this paper, we study a new problem\nsetting in which there are unknown classes in the training dataset misperceived\nas other labels, and thus their existence appears unknown from the given\nsupervision. We attribute the unknown unknowns to the fact that the training\ndataset is badly advised by the incompletely perceived label space due to the\ninsufficient feature information. To this end, we propose the exploratory\nmachine learning, which examines and investigates the training dataset by\nactively augmenting the feature space to discover potentially unknown labels.\nOur approach consists of three ingredients including rejection model, feature\nacquisition, and model cascade. The effectiveness is validated on both\nsynthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 02:06:56 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Zhang", "Yu-Jie", ""], ["Zhao", "Peng", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "2002.01621", "submitter": "Yunfeng Zhang", "authors": "Yunfeng Zhang, Rachel K. E. Bellamy, Kush R. Varshney", "title": "Joint Optimization of AI Fairness and Utility: A Human-Centered Approach", "comments": "To appear in AIES 2020 proceedings", "journal-ref": null, "doi": "10.1145/3375627.3375862", "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, AI is increasingly being used in many high-stakes decision-making\napplications in which fairness is an important concern. Already, there are many\nexamples of AI being biased and making questionable and unfair decisions. The\nAI research community has proposed many methods to measure and mitigate\nunwanted biases, but few of them involve inputs from human policy makers. We\nargue that because different fairness criteria sometimes cannot be\nsimultaneously satisfied, and because achieving fairness often requires\nsacrificing other objectives such as model accuracy, it is key to acquire and\nadhere to human policy makers' preferences on how to make the tradeoff among\nthese objectives. In this paper, we propose a framework and some exemplar\nmethods for eliciting such preferences and for optimizing an AI model according\nto these preferences.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 03:31:48 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Zhang", "Yunfeng", ""], ["Bellamy", "Rachel K. E.", ""], ["Varshney", "Kush R.", ""]]}, {"id": "2002.01640", "submitter": "Zahra Zahedi", "authors": "Zahra Zahedi, Sailik Sengupta, Subbarao Kambhampati", "title": "`Why didn't you allocate this task to them?' Negotiation-Aware Task\n  Allocation and Contrastive Explanation Generation", "comments": "First two authors are equal contributors", "journal-ref": "CoopAI workshop, NeurIPS2020", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-allocation is an important problem in multi-agent systems. It becomes\nmore challenging when the team-members are humans with imperfect knowledge\nabout their teammates' costs and the overall performance metric. While\ndistributed task-allocation methods let the team-members engage in iterative\ndialog to reach a consensus, the process can take a considerable amount of time\nand communication. On the other hand, a centralized method that simply outputs\nan allocation may result in discontented human team-members who, due to their\nimperfect knowledge and limited computation capabilities, perceive the\nallocation to be unfair. To address these challenges, we propose a centralized\nArtificial Intelligence Task Allocation (AITA) that simulates a negotiation and\nproduces a negotiation-aware task allocation that is fair. If a team-member is\nunhappy with the proposed allocation, we allow them to question the proposed\nallocation using a counterfactual. By using parts of the simulated negotiation,\nwe are able to provide contrastive explanations that providing minimum\ninformation about other's costs to refute their foil. With human studies, we\nshow that (1) the allocation proposed using our method does indeed appear fair\nto the majority, and (2) when a counterfactual is raised, explanations\ngenerated are easy to comprehend and convincing. Finally, we empirically study\nthe effect of different kinds of incompleteness on the explanation-length and\nfind that underestimation of a teammate's costs often increases it.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 04:58:26 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 21:04:57 GMT"}, {"version": "v3", "created": "Thu, 18 Mar 2021 02:30:32 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Zahedi", "Zahra", ""], ["Sengupta", "Sailik", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "2002.01647", "submitter": "Hongyu Li", "authors": "Hongyu Li, Dan Meng, Hong Wang and Xiaolin Li", "title": "Knowledge Federation: A Unified and Hierarchical Privacy-Preserving AI\n  Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With strict protections and regulations of data privacy and security,\nconventional machine learning based on centralized datasets is confronted with\nsignificant challenges, making artificial intelligence (AI) impractical in many\nmission-critical and data-sensitive scenarios, such as finance, government, and\nhealth. In the meantime, tremendous datasets are scattered in isolated silos in\nvarious industries, organizations, different units of an organization, or\ndifferent branches of an international organization. These valuable data\nresources are well underused. To advance AI theories and applications, we\npropose a comprehensive framework (called Knowledge Federation - KF) to address\nthese challenges by enabling AI while preserving data privacy and ownership.\nBeyond the concepts of federated learning and secure multi-party computation,\nKF consists of four levels of federation: (1) information level, low-level\nstatistics and computation of data, meeting the requirements of simple queries,\nsearching and simplistic operators; (2) model level, supporting training,\nlearning, and inference; (3) cognition level, enabling abstract feature\nrepresentation at various levels of abstractions and contexts; (4) knowledge\nlevel, fusing knowledge discovery, representation, and reasoning. We further\nclarify the relationship and differentiation between knowledge federation and\nother related research areas. We have developed a reference implementation of\nKF, called iBond Platform, to offer a production-quality KF platform to enable\nindustrial applications in finance, insurance et al. The iBond platform will\nalso help establish the KF community and a comprehensive ecosystem and usher in\na novel paradigm shift towards secure, privacy-preserving and responsible AI.\nAs far as we know, knowledge federation is the first hierarchical and unified\nframework for secure multi-party computing and learning.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 05:23:35 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 01:54:28 GMT"}, {"version": "v3", "created": "Fri, 22 May 2020 07:34:14 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Li", "Hongyu", ""], ["Meng", "Dan", ""], ["Wang", "Hong", ""], ["Li", "Xiaolin", ""]]}, {"id": "2002.01650", "submitter": "Zhi Chen", "authors": "Zhi Chen, Yijie Bei and Cynthia Rudin", "title": "Concept Whitening for Interpretable Image Recognition", "comments": "Authors' pre-publication version of a 2020 Nature Machine\n  Intelligence article", "journal-ref": "Nature Machine Intelligence, Vol 2, Dec 2020, 772-782", "doi": "10.1038/s42256-020-00265-z", "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What does a neural network encode about a concept as we traverse through the\nlayers? Interpretability in machine learning is undoubtedly important, but the\ncalculations of neural networks are very challenging to understand. Attempts to\nsee inside their hidden layers can either be misleading, unusable, or rely on\nthe latent space to possess properties that it may not have. In this work,\nrather than attempting to analyze a neural network posthoc, we introduce a\nmechanism, called concept whitening (CW), to alter a given layer of the network\nto allow us to better understand the computation leading up to that layer. When\na concept whitening module is added to a CNN, the axes of the latent space are\naligned with known concepts of interest. By experiment, we show that CW can\nprovide us a much clearer understanding for how the network gradually learns\nconcepts over layers. CW is an alternative to a batch normalization layer in\nthat it normalizes, and also decorrelates (whitens) the latent space. CW can be\nused in any layer of the network without hurting predictive performance.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 05:28:09 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 16:55:49 GMT"}, {"version": "v3", "created": "Sat, 3 Oct 2020 05:06:19 GMT"}, {"version": "v4", "created": "Mon, 19 Oct 2020 14:13:19 GMT"}, {"version": "v5", "created": "Mon, 7 Dec 2020 19:09:35 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Chen", "Zhi", ""], ["Bei", "Yijie", ""], ["Rudin", "Cynthia", ""]]}, {"id": "2002.01687", "submitter": "Nicolas Turpault", "authors": "Nicolas Turpault (MULTISPEECH), Romain Serizel (MULTISPEECH), Emmanuel\n  Vincent (MULTISPEECH)", "title": "Limitations of weak labels for embedding and tagging", "comments": null, "journal-ref": "ICASSP 2020 - 45th International Conference on Acoustics, Speech,\n  and Signal Processing, May 2020, Barcelona, Spain", "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many datasets and approaches in ambient sound analysis use weakly labeled\ndata.Weak labels are employed because annotating every data sample with a\nstrong label is too expensive.Yet, their impact on the performance in\ncomparison to strong labels remains unclear.Indeed, weak labels must often be\ndealt with at the same time as other challenges, namely multiple labels per\nsample, unbalanced classes and/or overlapping events.In this paper, we\nformulate a supervised learning problem which involves weak labels.We create a\ndataset that focuses on the difference between strong and weak labels as\nopposed to other challenges. We investigate the impact of weak labels when\ntraining an embedding or an end-to-end classifier.Different experimental\nscenarios are discussed to provide insights into which applications are most\nsensitive to weakly labeled data.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 08:54:08 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 09:27:00 GMT"}, {"version": "v3", "created": "Mon, 4 May 2020 15:14:56 GMT"}, {"version": "v4", "created": "Mon, 7 Dec 2020 13:13:51 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Turpault", "Nicolas", "", "MULTISPEECH"], ["Serizel", "Romain", "", "MULTISPEECH"], ["Vincent", "Emmanuel", "", "MULTISPEECH"]]}, {"id": "2002.01761", "submitter": "Mingchen Li", "authors": "Mingchen Li and Zili Zhou and Yanna Wang", "title": "Multi-Fusion Chinese WordNet (MCW) : Compound of Machine Learning and\n  Manual Correction", "comments": "7 pages. CICLing 2019: International Conference on Computational\n  Linguistics and Intelligent Text Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Princeton WordNet (PWN) is a lexicon-semantic network based on cognitive\nlinguistics, which promotes the development of natural language processing.\nBased on PWN, five Chinese wordnets have been developed to solve the problems\nof syntax and semantics. They include: Northeastern University Chinese WordNet\n(NEW), Sinica Bilingual Ontological WordNet (BOW), Southeast University Chinese\nWordNet (SEW), Taiwan University Chinese WordNet (CWN), Chinese Open WordNet\n(COW). By using them, we found that these word networks have low accuracy and\ncoverage, and cannot completely portray the semantic network of PWN. So we\ndecided to make a new Chinese wordnet called Multi-Fusion Chinese Wordnet (MCW)\nto make up those shortcomings. The key idea is to extend the SEW with the help\nof Oxford bilingual dictionary and Xinhua bilingual dictionary, and then\ncorrect it. More specifically, we used machine learning and manual adjustment\nin our corrections. Two standards were formulated to help our work. We\nconducted experiments on three tasks including relatedness calculation, word\nsimilarity and word sense disambiguation for the comparison of lemma's\naccuracy, at the same time, coverage also was compared. The results indicate\nthat MCW can benefit from coverage and accuracy via our method. However, it\nstill has room for improvement, especially with lemmas. In the future, we will\ncontinue to enhance the accuracy of MCW and expand the concepts in it.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 12:44:01 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Li", "Mingchen", ""], ["Zhou", "Zili", ""], ["Wang", "Yanna", ""]]}, {"id": "2002.01766", "submitter": "Eugenia Oshurko", "authors": "Russ Harmer and Eugenia Oshurko", "title": "Knowledge representation and update in hierarchies of graphs", "comments": "25 pages, 4 figures, submitted to the Journal of Logical and\n  Algebraic Methods in Programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A mathematical theory is presented for the representation of knowledge in the\nform of a directed acyclic hierarchy of objects in a category where all paths\nbetween any given pair of objects are required to be equal. The conditions\nunder which knowledge update, in the form of the sesqui-pushout rewriting of an\nobject in a hierarchy, can be propagated to the rest of the hierarchy, in order\nto maintain all required path equalities, are analysed: some rewrites must be\npropagated forwards, in the direction of the arrows, while others must be\npropagated backwards, against the direction of the arrows, and, depending on\nthe precise form of the hierarchy, certain composability conditions may also be\nnecessary. The implementation of this theory, in the ReGraph Python library for\n(simple) directed graphs with attributes on nodes and edges, is then discussed\nin the context of two significant use cases.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 13:01:55 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Harmer", "Russ", ""], ["Oshurko", "Eugenia", ""]]}, {"id": "2002.01775", "submitter": "Inseop Chung", "authors": "Inseop Chung, SeongUk Park, Jangho Kim, Nojun Kwak", "title": "Feature-map-level Online Adversarial Knowledge Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature maps contain rich information about image intensity and spatial\ncorrelation. However, previous online knowledge distillation methods only\nutilize the class probabilities. Thus in this paper, we propose an online\nknowledge distillation method that transfers not only the knowledge of the\nclass probabilities but also that of the feature map using the adversarial\ntraining framework. We train multiple networks simultaneously by employing\ndiscriminators to distinguish the feature map distributions of different\nnetworks. Each network has its corresponding discriminator which discriminates\nthe feature map from its own as fake while classifying that of the other\nnetwork as real. By training a network to fool the corresponding discriminator,\nit can learn the other network's feature map distribution. We show that our\nmethod performs better than the conventional direct alignment method such as L1\nand is more suitable for online distillation. Also, we propose a novel cyclic\nlearning scheme for training more than two networks together. We have applied\nour method to various network architectures on the classification task and\ndiscovered a significant improvement of performance especially in the case of\ntraining a pair of a small network and a large one.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 13:16:37 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 17:58:38 GMT"}, {"version": "v3", "created": "Fri, 5 Jun 2020 18:15:40 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Chung", "Inseop", ""], ["Park", "SeongUk", ""], ["Kim", "Jangho", ""], ["Kwak", "Nojun", ""]]}, {"id": "2002.01776", "submitter": "Ioannis Caragiannis", "authors": "Ioannis Caragiannis, Christos Kaklamanis, Nikos Karanikolas, George A.\n  Krimpas", "title": "Evaluating approval-based multiwinner voting in terms of robustness to\n  noise", "comments": "Preliminary version appeared in IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approval-based multiwinner voting rules have recently received much attention\nin the Computational Social Choice literature. Such rules aggregate approval\nballots and determine a winning committee of alternatives. To assess\neffectiveness, we propose to employ new noise models that are specifically\ntailored for approval votes and committees. These models take as input a ground\ntruth committee and return random approval votes to be thought of as noisy\nestimates of the ground truth. A minimum robustness requirement for an\napproval-based multiwinner voting rule is to return the ground truth when\napplied to profiles with sufficiently many noisy votes. Our results indicate\nthat approval-based multiwinner voting is always robust to reasonable noise. We\nfurther refine this finding by presenting a hierarchy of rules in terms of how\nrobust to noise they are.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 13:17:43 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 12:31:10 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Caragiannis", "Ioannis", ""], ["Kaklamanis", "Christos", ""], ["Karanikolas", "Nikos", ""], ["Krimpas", "George A.", ""]]}, {"id": "2002.01862", "submitter": "Ziang Xiao", "authors": "Ziang Xiao, Michelle X. Zhou, Wenxi Chen, Huahai Yang, Changyan Chi", "title": "If I Hear You Correctly: Building and Evaluating Interview Chatbots with\n  Active Listening Skills", "comments": "Working draft. To appear in the ACM CHI Conference on Human Factors\n  in Computing Systems (CHI 2020)", "journal-ref": null, "doi": "10.1145/3313831.3376131", "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interview chatbots engage users in a text-based conversation to draw out\ntheir views and opinions. It is, however, challenging to build effective\ninterview chatbots that can handle user free-text responses to open-ended\nquestions and deliver engaging user experience. As the first step, we are\ninvestigating the feasibility and effectiveness of using publicly available,\npractical AI technologies to build effective interview chatbots. To demonstrate\nfeasibility, we built a prototype scoped to enable interview chatbots with a\nsubset of active listening skills - the abilities to comprehend a user's input\nand respond properly. To evaluate the effectiveness of our prototype, we\ncompared the performance of interview chatbots with or without active listening\nskills on four common interview topics in a live evaluation with 206 users. Our\nwork presents practical design implications for building effective interview\nchatbots, hybrid chatbot platforms, and empathetic chatbots beyond interview\ntasks.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 16:52:52 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Xiao", "Ziang", ""], ["Zhou", "Michelle X.", ""], ["Chen", "Wenxi", ""], ["Yang", "Huahai", ""], ["Chi", "Changyan", ""]]}, {"id": "2002.01883", "submitter": "Kavosh Asadi", "authors": "Kavosh Asadi, Neev Parikh, Ronald E. Parr, George D. Konidaris,\n  Michael L. Littman", "title": "Deep Radial-Basis Value Functions for Continuous Control", "comments": "In Proceedings of the 35th AAAI Conference on Artificial Intelligence\n  (AAAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A core operation in reinforcement learning (RL) is finding an action that is\noptimal with respect to a learned value function. This operation is often\nchallenging when the learned value function takes continuous actions as input.\nWe introduce deep radial-basis value functions (RBVFs): value functions learned\nusing a deep network with a radial-basis function (RBF) output layer. We show\nthat the maximum action-value with respect to a deep RBVF can be approximated\neasily and accurately. Moreover, deep RBVFs can represent any true value\nfunction owing to their support for universal function approximation. We extend\nthe standard DQN algorithm to continuous control by endowing the agent with a\ndeep RBVF. We show that the resultant agent, called RBF-DQN, significantly\noutperforms value-function-only baselines, and is competitive with\nstate-of-the-art actor-critic algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 17:44:16 GMT"}, {"version": "v2", "created": "Sun, 14 Mar 2021 01:29:44 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Asadi", "Kavosh", ""], ["Parikh", "Neev", ""], ["Parr", "Ronald E.", ""], ["Konidaris", "George D.", ""], ["Littman", "Michael L.", ""]]}, {"id": "2002.01969", "submitter": "Mohamadreza Ahmadi", "authors": "Mohamadreza Ahmadi, Arun A. Viswanathan, Michel D. Ingham, Kymie Tan,\n  and Aaron D. Ames", "title": "Partially Observable Games for Secure Autonomy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.CR cs.FL cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technology development efforts in autonomy and cyber-defense have been\nevolving independently of each other, over the past decade. In this paper, we\nreport our ongoing effort to integrate these two presently distinct areas into\na single framework. To this end, we propose the two-player partially observable\nstochastic game formalism to capture both high-level autonomous mission\nplanning under uncertainty and adversarial decision making subject to imperfect\ninformation. We show that synthesizing sub-optimal strategies for such games is\npossible under finite-memory assumptions for both the autonomous decision maker\nand the cyber-adversary. We then describe an experimental testbed to evaluate\nthe efficacy of the proposed framework.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 19:31:56 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Ahmadi", "Mohamadreza", ""], ["Viswanathan", "Arun A.", ""], ["Ingham", "Michel D.", ""], ["Tan", "Kymie", ""], ["Ames", "Aaron D.", ""]]}, {"id": "2002.02012", "submitter": "Christopher Cervantes", "authors": "Christopher M Cervantes", "title": "From Route Instructions to Landmark Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Landmarks are central to how people navigate, but most navigation\ntechnologies do not incorporate them into their representations. We propose the\nlandmark graph generation task (creating landmark-based spatial representations\nfrom natural language) and introduce a fully end-to-end neural approach to\ngenerate these graphs. We evaluate our models on the SAIL route instruction\ndataset, as well as on a small set of real-world delivery instructions that we\ncollected, and we show that our approach yields high quality results on both\nour task and the related robotic navigation task.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 22:05:11 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Cervantes", "Christopher M", ""]]}, {"id": "2002.02031", "submitter": "Nabil Hossain", "authors": "Nabil Hossain, John Krumm, Tanvir Sajed and Henry Kautz", "title": "Stimulating Creativity with FunLines: A Case Study of Humor Generation\n  in Headlines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building datasets of creative text, such as humor, is quite challenging. We\nintroduce FunLines, a competitive game where players edit news headlines to\nmake them funny, and where they rate the funniness of headlines edited by\nothers. FunLines makes the humor generation process fun, interactive,\ncollaborative, rewarding and educational, keeping players engaged and providing\nhumor data at a very low cost compared to traditional crowdsourcing approaches.\nFunLines offers useful performance feedback, assisting players in getting\nbetter over time at generating and assessing humor, as our analysis shows. This\nhelps to further increase the quality of the generated dataset. We show the\neffectiveness of this data by training humor classification models that\noutperform a previous benchmark, and we release this dataset to the public.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 22:56:11 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Hossain", "Nabil", ""], ["Krumm", "John", ""], ["Sajed", "Tanvir", ""], ["Kautz", "Henry", ""]]}, {"id": "2002.02046", "submitter": "Milan Cvitkovic", "authors": "Milan Cvitkovic", "title": "Supervised Learning on Relational Databases with Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of data scientists and machine learning practitioners use\nrelational data in their work [State of ML and Data Science 2017, Kaggle,\nInc.]. But training machine learning models on data stored in relational\ndatabases requires significant data extraction and feature engineering efforts.\nThese efforts are not only costly, but they also destroy potentially important\nrelational structure in the data. We introduce a method that uses Graph Neural\nNetworks to overcome these challenges. Our proposed method outperforms\nstate-of-the-art automatic feature engineering methods on two out of three\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 00:57:39 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Cvitkovic", "Milan", ""]]}, {"id": "2002.02058", "submitter": "Takahiro Yabe", "authors": "Toru Shimizu, Takahiro Yabe, Kota Tsubouchi", "title": "Learning Fine Grained Place Embeddings with Spatial Hierarchy from Human\n  Mobility Trajectories", "comments": "submitted to IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Place embeddings generated from human mobility trajectories have become a\npopular method to understand the functionality of places. Place embeddings with\nhigh spatial resolution are desirable for many applications, however,\ndownscaling the spatial resolution deteriorates the quality of embeddings due\nto data sparsity, especially in less populated areas. We address this issue by\nproposing a method that generates fine grained place embeddings, which\nleverages spatial hierarchical information according to the local density of\nobserved data points. The effectiveness of our fine grained place embeddings\nare compared to baseline methods via next place prediction tasks using real\nworld trajectory data from 3 cities in Japan. In addition, we demonstrate the\nvalue of our fine grained place embeddings for land use classification\napplications. We believe that our technique of incorporating spatial\nhierarchical information can complement and reinforce various place embedding\ngenerating methods.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 01:37:40 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Shimizu", "Toru", ""], ["Yabe", "Takahiro", ""], ["Tsubouchi", "Kota", ""]]}, {"id": "2002.02080", "submitter": "Wen-Ji Zhou", "authors": "Wen-Ji Zhou, Yang Yu", "title": "Temporal-adaptive Hierarchical Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical reinforcement learning (HRL) helps address large-scale and\nsparse reward issues in reinforcement learning. In HRL, the policy model has an\ninner representation structured in levels. With this structure, the\nreinforcement learning task is expected to be decomposed into corresponding\nlevels with sub-tasks, and thus the learning can be more efficient. In HRL,\nalthough it is intuitive that a high-level policy only needs to make macro\ndecisions in a low frequency, the exact frequency is hard to be simply\ndetermined. Previous HRL approaches often employed a fixed-time skip strategy\nor learn a terminal condition without taking account of the context, which,\nhowever, not only requires manual adjustments but also sacrifices some decision\ngranularity. In this paper, we propose the \\emph{temporal-adaptive hierarchical\npolicy learning} (TEMPLE) structure, which uses a temporal gate to adaptively\ncontrol the high-level policy decision frequency. We train the TEMPLE structure\nwith PPO and test its performance in a range of environments including 2-D\nrooms, Mujoco tasks, and Atari games. The results show that the TEMPLE\nstructure can lead to improved performance in these environments with a\nsequential adaptive high-level control.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 02:52:21 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Zhou", "Wen-Ji", ""], ["Yu", "Yang", ""]]}, {"id": "2002.02089", "submitter": "Qiwei He", "authors": "Qiwei He, Liansheng Zhuang, Houqiang Li", "title": "Soft Hindsight Experience Replay", "comments": "7 pages, 5 figures, 1 table, submitted to IJCAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient learning in the environment with sparse rewards is one of the most\nimportant challenges in Deep Reinforcement Learning (DRL). In continuous DRL\nenvironments such as robotic arms control, Hindsight Experience Replay (HER)\nhas been shown an effective solution. However, due to the brittleness of\ndeterministic methods, HER and its variants typically suffer from a major\nchallenge for stability and convergence, which significantly affects the final\nperformance. This challenge severely limits the applicability of such methods\nto complex real-world domains. To tackle this challenge, in this paper, we\npropose Soft Hindsight Experience Replay (SHER), a novel approach based on HER\nand Maximum Entropy Reinforcement Learning (MERL), combining the failed\nexperiences reuse and maximum entropy probabilistic inference model. We\nevaluate SHER on Open AI Robotic manipulation tasks with sparse rewards.\nExperimental results show that, in contrast to HER and its variants, our\nproposed SHER achieves state-of-the-art performance, especially in the\ndifficult HandManipulation tasks. Furthermore, our SHER method is more stable,\nachieving very similar performance across different random seeds.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 03:57:04 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["He", "Qiwei", ""], ["Zhuang", "Liansheng", ""], ["Li", "Houqiang", ""]]}, {"id": "2002.02153", "submitter": "Minghong Xu", "authors": "Minghong Xu, Piji Li, Haoran Yang, Pengjie Ren, Zhaochun Ren, Zhumin\n  Chen, Jun Ma", "title": "A Neural Topical Expansion Framework for Unstructured Persona-oriented\n  Dialogue Generation", "comments": "Accepted by ECAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unstructured Persona-oriented Dialogue Systems (UPDS) has been demonstrated\neffective in generating persona consistent responses by utilizing predefined\nnatural language user persona descriptions (e.g., \"I am a vegan\"). However, the\npredefined user persona descriptions are usually short and limited to only a\nfew descriptive words, which makes it hard to correlate them with the\ndialogues. As a result, existing methods either fail to use the persona\ndescription or use them improperly when generating persona consistent\nresponses. To address this, we propose a neural topical expansion framework,\nnamely Persona Exploration and Exploitation (PEE), which is able to extend the\npredefined user persona description with semantically correlated content before\nutilizing them to generate dialogue responses. PEE consists of two main\nmodules: persona exploration and persona exploitation. The former learns to\nextend the predefined user persona description by mining and correlating with\nexisting dialogue corpus using a variational auto-encoder (VAE) based topic\nmodel. The latter learns to generate persona consistent responses by utilizing\nthe predefined and extended user persona description. In order to make persona\nexploitation learn to utilize user persona description more properly, we also\nintroduce two persona-oriented loss functions: Persona-oriented Matching\n(P-Match) loss and Persona-oriented Bag-of-Words (P-BoWs) loss which\nrespectively supervise persona selection in encoder and decoder. Experimental\nresults show that our approach outperforms state-of-the-art baselines, in terms\nof both automatic and human evaluations.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 08:24:33 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Xu", "Minghong", ""], ["Li", "Piji", ""], ["Yang", "Haoran", ""], ["Ren", "Pengjie", ""], ["Ren", "Zhaochun", ""], ["Chen", "Zhumin", ""], ["Ma", "Jun", ""]]}, {"id": "2002.02164", "submitter": "Jesus L. Lobo", "authors": "Jesus L. Lobo, Javier Del Ser, Francisco Herrera", "title": "LUNAR: Cellular Automata for Drifting Data Streams", "comments": "36 pages, 6 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI nlin.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of huges volumes of data produced in the form of fast\nstreams, real-time machine learning has become a challenge of relevance\nemerging in a plethora of real-world applications. Processing such fast streams\noften demands high memory and processing resources. In addition, they can be\naffected by non-stationary phenomena (concept drift), by which learning methods\nhave to detect changes in the distribution of streaming data, and adapt to\nthese evolving conditions. A lack of efficient and scalable solutions is\nparticularly noted in real-time scenarios where computing resources are\nseverely constrained, as it occurs in networks of small, numerous,\ninterconnected processing units (such as the so-called Smart Dust, Utility Fog,\nor Swarm Robotics paradigms). In this work we propose LUNAR, a streamified\nversion of cellular automata devised to successfully meet the aforementioned\nrequirements. It is able to act as a real incremental learner while adapting to\ndrifting conditions. Extensive simulations with synthetic and real data will\nprovide evidence of its competitive behavior in terms of classification\nperformance when compared to long-established and successful online learning\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 09:10:43 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Lobo", "Jesus L.", ""], ["Del Ser", "Javier", ""], ["Herrera", "Francisco", ""]]}, {"id": "2002.02193", "submitter": "Francesco Giannini", "authors": "Giuseppe Marra, Michelangelo Diligenti, Francesco Giannini, Marco Gori\n  and Marco Maggini", "title": "Relational Neural Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has been shown to achieve impressive results in several tasks\nwhere a large amount of training data is available. However, deep learning\nsolely focuses on the accuracy of the predictions, neglecting the reasoning\nprocess leading to a decision, which is a major issue in life-critical\napplications. Probabilistic logic reasoning allows to exploit both statistical\nregularities and specific domain expertise to perform reasoning under\nuncertainty, but its scalability and brittle integration with the layers\nprocessing the sensory data have greatly limited its applications. For these\nreasons, combining deep architectures and probabilistic logic reasoning is a\nfundamental goal towards the development of intelligent agents operating in\ncomplex environments. This paper presents Relational Neural Machines, a novel\nframework allowing to jointly train the parameters of the learners and of a\nFirst--Order Logic based reasoner. A Relational Neural Machine is able to\nrecover both classical learning from supervised data in case of pure\nsub-symbolic learning, and Markov Logic Networks in case of pure symbolic\nreasoning, while allowing to jointly train and perform inference in hybrid\nlearning tasks. Proper algorithmic solutions are devised to make learning and\ninference tractable in large-scale problems. The experiments show promising\nresults in different relational tasks.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 10:53:57 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Marra", "Giuseppe", ""], ["Diligenti", "Michelangelo", ""], ["Giannini", "Francesco", ""], ["Gori", "Marco", ""], ["Maggini", "Marco", ""]]}, {"id": "2002.02202", "submitter": "Zeyue Xue", "authors": "Zeyue Xue, Shuang Luo, Chao Wu, Pan Zhou, Kaigui Bian and Wei Du", "title": "Transfer Heterogeneous Knowledge Among Peer-to-Peer Teammates: A Model\n  Distillation Approach", "comments": "7 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer-to-peer knowledge transfer in distributed environments has emerged as a\npromising method since it could accelerate learning and improve team-wide\nperformance without relying on pre-trained teachers in deep reinforcement\nlearning. However, for traditional peer-to-peer methods such as action\nadvising, they have encountered difficulties in how to efficiently expressed\nknowledge and advice. As a result, we propose a brand new solution to reuse\nexperiences and transfer value functions among multiple students via model\ndistillation. But it is still challenging to transfer Q-function directly since\nit is unstable and not bounded. To address this issue confronted with existing\nworks, we adopt Categorical Deep Q-Network. We also describe how to design an\nefficient communication protocol to exploit heterogeneous knowledge among\nmultiple distributed agents. Our proposed framework, namely Learning and\nTeaching Categorical Reinforcement (LTCR), shows promising performance on\nstabilizing and accelerating learning progress with improved team-wide reward\nin four typical experimental environments.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 11:31:04 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Xue", "Zeyue", ""], ["Luo", "Shuang", ""], ["Wu", "Chao", ""], ["Zhou", "Pan", ""], ["Bian", "Kaigui", ""], ["Du", "Wei", ""]]}, {"id": "2002.02210", "submitter": "Javier Del Ser Dr.", "authors": "Ibai Lana, Javier J. Sanchez-Medina, Eleni I. Vlahogianni, Javier Del\n  Ser", "title": "From Data to Actions in Intelligent Transportation Systems: a\n  Prescription of Functional Requirements for Model Actionability", "comments": "40 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in Data Science permeate every field of Transportation Science and\nEngineering, resulting in developments in the transportation sector that {are}\ndata-driven. Nowadays, Intelligent Transportation Systems (ITS) could be\narguably approached as a ``story'' intensively producing and consuming large\namounts of data. A~diversity of sensing devices densely spread over the\ninfrastructure, vehicles or the travelers' personal devices act as sources of\ndata flows that are eventually fed {into} software running on automatic\ndevices, actuators or control systems producing, in~turn, complex information\nflows {among} users, traffic managers, data analysts, traffic modeling\nscientists, etc. These~information flows provide enormous opportunities to\nimprove model development and decision-making. This work aims to describe how\ndata, coming from diverse ITS sources, can be used to learn and adapt\ndata-driven models for efficiently operating ITS assets, systems and processes;\nin~other words, for data-based models to fully become \\emph{actionable}.\nGrounded in this described data modeling pipeline for ITS, we~define the\ncharacteristics, engineering requisites and challenges intrinsic to its three\ncompounding stages, namely, data fusion, adaptive learning and model\nevaluation. We~deliberately generalize model learning to be adaptive, since,\nin~the core of our paper is the firm conviction that most learners will have to\nadapt to the ever-changing phenomenon scenario underlying the majority of ITS\napplications. Finally, we~provide a prospect of current research lines within\nData Science that can bring notable advances to data-based ITS modeling, which\nwill eventually bridge the gap towards the practicality and actionability of\nsuch models.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 12:02:30 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 14:33:07 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2021 15:17:27 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Lana", "Ibai", ""], ["Sanchez-Medina", "Javier J.", ""], ["Vlahogianni", "Eleni I.", ""], ["Del Ser", "Javier", ""]]}, {"id": "2002.02238", "submitter": "Rishabh Gupta", "authors": "Rishabh Gupta and Rajesh N Rao", "title": "Towards Semantic Noise Cleansing of Categorical Data based on Semantic\n  Infusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Semantic Noise affects text analytics activities for the domain-specific\nindustries significantly. It impedes the text understanding which holds prime\nimportance in the critical decision making tasks. In this work, we formalize\nsemantic noise as a sequence of terms that do not contribute to the narrative\nof the text. We look beyond the notion of standard statistically-based stop\nwords and consider the semantics of terms to exclude the semantic noise. We\npresent a novel Semantic Infusion technique to associate meta-data with the\ncategorical corpus text and demonstrate its near-lossless nature. Based on this\ntechnique, we propose an unsupervised text-preprocessing framework to filter\nthe semantic noise using the context of the terms. Later we present the\nevaluation results of the proposed framework using a web forum dataset from the\nautomobile-domain.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 13:11:46 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Gupta", "Rishabh", ""], ["Rao", "Rajesh N", ""]]}, {"id": "2002.02257", "submitter": "Guilherme Dean Pelegrina", "authors": "Guilherme Dean Pelegrina, Leonardo Tomazeli Duarte, Jo\\~ao Marcos\n  Travassos Romano", "title": "Application of independent component analysis and TOPSIS to deal with\n  dependent criteria in multicriteria decision problems", "comments": null, "journal-ref": "Expert Systems with Applications, Volume 122, Pages 262--280, May\n  2019", "doi": "10.1016/j.eswa.2019.01.008", "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A vast number of multicriteria decision making methods have been developed to\ndeal with the problem of ranking a set of alternatives evaluated in a\nmulticriteria fashion. Very often, these methods assume that the evaluation\namong criteria is statistically independent. However, in actual problems, the\nobserved data may comprise dependent criteria, which, among other problems, may\nresult in biased rankings. In order to deal with this issue, we propose a novel\napproach whose aim is to estimate, from the observed data, a set of independent\nlatent criteria, which can be seen as an alternative representation of the\noriginal decision matrix. A central element of our approach is to formulate the\ndecision problem as a blind source separation problem, which allows us to apply\nindependent component analysis techniques to estimate the latent criteria.\nMoreover, we consider TOPSIS-based approaches to obtain the ranking of\nalternatives from the latent criteria. Results in both synthetic and actual\ndata attest the relevance of the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 13:51:28 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Pelegrina", "Guilherme Dean", ""], ["Duarte", "Leonardo Tomazeli", ""], ["Romano", "Jo\u00e3o Marcos Travassos", ""]]}, {"id": "2002.02274", "submitter": "Sara Ahmadian", "authors": "Sara Ahmadian, Alessandro Epasto, Ravi Kumar, Mohammad Mahdian", "title": "Fair Correlation Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study correlation clustering under fairness constraints.\nFair variants of $k$-median and $k$-center clustering have been studied\nrecently, and approximation algorithms using a notion called fairlet\ndecomposition have been proposed. We obtain approximation algorithms for fair\ncorrelation clustering under several important types of fairness constraints.\n  Our results hinge on obtaining a fairlet decomposition for correlation\nclustering by introducing a novel combinatorial optimization problem. We define\na fairlet decomposition with cost similar to the $k$-median cost and this\nallows us to obtain approximation algorithms for a wide range of fairness\nconstraints.\n  We complement our theoretical results with an in-depth analysis of our\nalgorithms on real graphs where we show that fair solutions to correlation\nclustering can be obtained with limited increase in cost compared to the\nstate-of-the-art (unfair) algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 14:28:21 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 22:27:51 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Ahmadian", "Sara", ""], ["Epasto", "Alessandro", ""], ["Kumar", "Ravi", ""], ["Mahdian", "Mohammad", ""]]}, {"id": "2002.02286", "submitter": "Edward Beeching", "authors": "Edward Beeching, Christian Wolf, Jilles Dibangoye, Olivier Simonin", "title": "EgoMap: Projective mapping and structured egocentric memory for Deep RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tasks involving localization, memorization and planning in partially\nobservable 3D environments are an ongoing challenge in Deep Reinforcement\nLearning. We present EgoMap, a spatially structured neural memory architecture.\nEgoMap augments a deep reinforcement learning agent's performance in 3D\nenvironments on challenging tasks with multi-step objectives. The EgoMap\narchitecture incorporates several inductive biases including a differentiable\ninverse projection of CNN feature vectors onto a top-down spatially structured\nmap. The map is updated with ego-motion measurements through a differentiable\naffine transform. We show this architecture outperforms both standard recurrent\nagents and state of the art agents with structured memory. We demonstrate that\nincorporating these inductive biases into an agent's architecture allows for\nstable training with reward alone, circumventing the expense of acquiring and\nlabelling expert trajectories. A detailed ablation study demonstrates the\nimpact of key aspects of the architecture and through extensive qualitative\nanalysis, we show how the agent exploits its structured internal memory to\nachieve higher performance.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 09:59:59 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 14:00:39 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Beeching", "Edward", ""], ["Wolf", "Christian", ""], ["Dibangoye", "Jilles", ""], ["Simonin", "Olivier", ""]]}, {"id": "2002.02325", "submitter": "Kevin McKee", "authors": "Kevin R. McKee, Ian Gemp, Brian McWilliams, Edgar A.\n  Du\\'e\\~nez-Guzm\\'an, Edward Hughes, and Joel Z. Leibo", "title": "Social diversity and social preferences in mixed-motive reinforcement\n  learning", "comments": "Proceedings of the 19th International Conference on Autonomous Agents\n  and Multiagent Systems (AAMAS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research on reinforcement learning in pure-conflict and pure-common\ninterest games has emphasized the importance of population heterogeneity. In\ncontrast, studies of reinforcement learning in mixed-motive games have\nprimarily leveraged homogeneous approaches. Given the defining characteristic\nof mixed-motive games--the imperfect correlation of incentives between group\nmembers--we study the effect of population heterogeneity on mixed-motive\nreinforcement learning. We draw on interdependence theory from social\npsychology and imbue reinforcement learning agents with Social Value\nOrientation (SVO), a flexible formalization of preferences over group outcome\ndistributions. We subsequently explore the effects of diversity in SVO on\npopulations of reinforcement learning agents in two mixed-motive Markov games.\nWe demonstrate that heterogeneity in SVO generates meaningful and complex\nbehavioral variation among agents similar to that suggested by interdependence\ntheory. Empirical results in these mixed-motive dilemmas suggest agents trained\nin heterogeneous populations develop particularly generalized, high-performing\npolicies relative to those trained in homogeneous populations.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 16:07:02 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 19:35:05 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["McKee", "Kevin R.", ""], ["Gemp", "Ian", ""], ["McWilliams", "Brian", ""], ["Du\u00e9\u00f1ez-Guzm\u00e1n", "Edgar A.", ""], ["Hughes", "Edward", ""], ["Leibo", "Joel Z.", ""]]}, {"id": "2002.02334", "submitter": "Yigit Oktar", "authors": "Yigit Oktar, Erdem Okur, Mehmet Turkan", "title": "Self-recognition in conversational agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In the standard Turing test, a machine has to prove its humanness to the\njudges. By successfully imitating a thinking entity such as a human, this\nmachine then proves that it can also think. Some objections claim that Turing\ntest is not a tool to demonstrate existence of general intelligence or thinking\nactivity. A compelling alternative is the Lovelace test, in which the agent\nmust originate a product that the agent's creator cannot explain. Therefore,\nthe agent must be the owner of an original product. However, for this to happen\nthe agent must exhibit the idea of self and distinguish oneself from others and\nmost importantly from one's creator. Extensive analysis of Turing test urges us\nto confirm that it is a longstanding practical tool, as sustaining the idea of\nself within the Turing test is still possible if the judge decides to act as a\ntextual mirror. Considering self-recognition tests applied on animals through\nmirrors appear to be viable tools to demonstrate the existence of a type of\ngeneral intelligence. Methodology here constructs a textual version of the\nmirror test by placing the agent as the one and only judge to figure out\nwhether the contacted one is an other, a mimicker, or oneself in an\nunsupervised manner. This textual version of the mirror test is objective,\nself-contained, and devoid of humanness. Any agent passing this textual mirror\ntest should have or can acquire a thought mechanism that can be referred to as\nthe inner-voice, answering the original and long lasting question of Turing\n\"Can machines think?\" in a constructive manner still within the bounds of the\nTuring test. Moreover, it is possible that a successful self-recognition might\npave way to stronger notions of self-awareness in artificial beings.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 16:32:46 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 08:55:28 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Oktar", "Yigit", ""], ["Okur", "Erdem", ""], ["Turkan", "Mehmet", ""]]}, {"id": "2002.02342", "submitter": "Xiaoliang Luo", "authors": "Xiaoliang Luo, Brett D. Roads, Bradley C. Love", "title": "The Costs and Benefits of Goal-Directed Attention in Deep Convolutional\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People deploy top-down, goal-directed attention to accomplish tasks, such as\nfinding lost keys. By tuning the visual system to relevant information sources,\nobject recognition can become more efficient (a benefit) and more biased toward\nthe target (a potential cost). Motivated by selective attention in\ncategorisation models, we developed a goal-directed attention mechanism that\ncan process naturalistic (photographic) stimuli. Our attention mechanism can be\nincorporated into any existing deep convolutional neural network (DCNNs). The\nprocessing stages in DCNNs have been related to ventral visual stream. In that\nlight, our attentional mechanism incorporates top-down influences from\nprefrontal cortex (PFC) to support goal-directed behaviour. Akin to how\nattention weights in categorisation models warp representational spaces, we\nintroduce a layer of attention weights to the mid-level of a DCNN that amplify\nor attenuate activity to further a goal. We evaluated the attentional mechanism\nusing photographic stimuli, varying the attentional target. We found that\nincreasing goal-directed attention has benefits (increasing hit rates) and\ncosts (increasing false alarm rates). At a moderate level, attention improves\nsensitivity (i.e., increases $d^\\prime$) at only a moderate increase in bias\nfor tasks involving standard images, blended images, and natural adversarial\nimages chosen to fool DCNNs. These results suggest that goal-directed attention\ncan reconfigure general-purpose DCNNs to better suit the current task goal,\nmuch like PFC modulates activity along the ventral stream. In addition to being\nmore parsimonious and brain consistent, the mid-level attention approach\nperformed better than a standard machine learning approach for transfer\nlearning, namely retraining the final network layer to accommodate the new\ntask.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 16:42:00 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 20:21:42 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2020 11:25:26 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Luo", "Xiaoliang", ""], ["Roads", "Brett D.", ""], ["Love", "Bradley C.", ""]]}, {"id": "2002.02360", "submitter": "Caelan Garrett", "authors": "Caelan Reed Garrett, Yijiang Huang, Tom\\'as Lozano-P\\'erez, and\n  Caitlin Tobin Mueller", "title": "Scalable and Probabilistically Complete Planning for Robotic Spatial\n  Extrusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is increasing demand for automated systems that can fabricate 3D\nstructures. Robotic spatial extrusion has become an attractive alternative to\ntraditional layer-based 3D printing due to a manipulator's flexibility to print\nlarge, directionally-dependent structures. However, existing extrusion planning\nalgorithms require a substantial amount of human input, do not scale to large\ninstances, and lack theoretical guarantees. In this work, we present a rigorous\nformalization of robotic spatial extrusion planning and provide several\nefficient and probabilistically complete planning algorithms. The key planning\nchallenge is, throughout the printing process, satisfying both stiffness\nconstraints that limit the deformation of the structure and geometric\nconstraints that ensure the robot does not collide with the structure. We show\nthat, although these constraints often conflict with each other, a greedy\nbackward state-space search guided by a stiffness-aware heuristic is able to\nsuccessfully balance both constraints. We empirically compare our methods on a\nbenchmark of over 40 simulated extrusion problems. Finally, we apply our\napproach to 3 real-world extrusion problems.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 17:05:55 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Garrett", "Caelan Reed", ""], ["Huang", "Yijiang", ""], ["Lozano-P\u00e9rez", "Tom\u00e1s", ""], ["Mueller", "Caitlin Tobin", ""]]}, {"id": "2002.02369", "submitter": "Michele Merler", "authors": "Michele Merler, Cicero Nogueira dos Santos, Mauro Martino, Alfio M.\n  Gliozzo, John R. Smith", "title": "Covering the News with (AI) Style", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a multi-modal discriminative and generative frame-work capable\nof assisting humans in producing visual content re-lated to a given theme,\nstarting from a collection of documents(textual, visual, or both). This\nframework can be used by edit or to generate images for articles, as well as\nbooks or music album covers. Motivated by a request from the The New York Times\n(NYT) seeking help to use AI to create art for their special section on\nArtificial Intelligence, we demonstrated the application of our system in\nproducing such image.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 22:57:51 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Merler", "Michele", ""], ["Santos", "Cicero Nogueira dos", ""], ["Martino", "Mauro", ""], ["Gliozzo", "Alfio M.", ""], ["Smith", "John R.", ""]]}, {"id": "2002.02376", "submitter": "Roberto Amadini", "authors": "Roberto Amadini", "title": "A Survey on String Constraint Solving", "comments": "Under consideration for \"ACM Computing Surveys\" journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  String constraint solving refers to solving combinatorial problems involving\nconstraints over string variables. String solving approaches have become\npopular over the last years given the massive use of strings in different\napplication domains like formal analysis, automated testing, database query\nprocessing, and cybersecurity. This paper reports a comprehensive survey on\nstring constraint solving by exploring the large number of approaches that have\nbeen proposed over the last decades to solve string constraints.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 01:05:38 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 01:26:11 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 23:40:17 GMT"}, {"version": "v4", "created": "Sun, 1 Mar 2020 22:04:34 GMT"}, {"version": "v5", "created": "Fri, 13 Nov 2020 16:51:38 GMT"}, {"version": "v6", "created": "Wed, 25 Nov 2020 09:55:27 GMT"}, {"version": "v7", "created": "Wed, 7 Apr 2021 07:25:52 GMT"}, {"version": "v8", "created": "Wed, 30 Jun 2021 08:34:27 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Amadini", "Roberto", ""]]}, {"id": "2002.02393", "submitter": "Ke Chen", "authors": "Ke Chen, Gus Xia, Shlomo Dubnov", "title": "Continuous Melody Generation via Disentangled Short-Term Representations\n  and Structural Conditions", "comments": "9 pages, 12 figures, 4 tables. in 14th international conference on\n  semantic computing, ICSC 2020", "journal-ref": "2020 IEEE 14th International Conference on Semantic Computing", "doi": "10.1109/ICSC.2020.00025", "report-no": null, "categories": "cs.SD cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic music generation is an interdisciplinary research topic that\ncombines computational creativity and semantic analysis of music to create\nautomatic machine improvisations. An important property of such a system is\nallowing the user to specify conditions and desired properties of the generated\nmusic. In this paper we designed a model for composing melodies given a user\nspecified symbolic scenario combined with a previous music context. We add\nmanual labeled vectors denoting external music quality in terms of chord\nfunction that provides a low dimensional representation of the harmonic tension\nand resolution. Our model is capable of generating long melodies by regarding\n8-beat note sequences as basic units, and shares consistent rhythm pattern\nstructure with another specific song. The model contains two stages and\nrequires separate training where the first stage adopts a Conditional\nVariational Autoencoder (C-VAE) to build a bijection between note sequences and\ntheir latent representations, and the second stage adopts long short-term\nmemory networks (LSTM) with structural conditions to continue writing future\nmelodies. We further exploit the disentanglement technique via C-VAE to allow\nmelody generation based on pitch contour information separately from\nconditioning on rhythm patterns. Finally, we evaluate the proposed model using\nquantitative analysis of rhythm and the subjective listening study. Results\nshow that the music generated by our model tends to have salient repetition\nstructures, rich motives, and stable rhythm patterns. The ability to generate\nlonger and more structural phrases from disentangled representations combined\nwith semantic scenario specification conditions shows a broad application of\nour model.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 06:23:44 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Chen", "Ke", ""], ["Xia", "Gus", ""], ["Dubnov", "Shlomo", ""]]}, {"id": "2002.02406", "submitter": "Daniel Daza", "authors": "Daniel Daza and Michael Cochez", "title": "Message Passing Query Embedding", "comments": "Presented at ICML 2020 - GRL+ Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works on representation learning for Knowledge Graphs have moved\nbeyond the problem of link prediction, to answering queries of an arbitrary\nstructure. Existing methods are based on ad-hoc mechanisms that require\ntraining with a diverse set of query structures. We propose a more general\narchitecture that employs a graph neural network to encode a graph\nrepresentation of the query, where nodes correspond to entities and variables.\nThe generality of our method allows it to encode a more diverse set of query\ntypes in comparison to previous work. Our method shows competitive performance\nagainst previous models for complex queries, and in contrast with these models,\nit can answer complex queries when trained for link prediction only. We show\nthat the model learns entity embeddings that capture the notion of entity type\nwithout explicit supervision.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 17:40:01 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 11:35:19 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Daza", "Daniel", ""], ["Cochez", "Michael", ""]]}, {"id": "2002.02427", "submitter": "Bilal Ghanem", "authors": "Bilal Ghanem, Jihen Karoui, Farah Benamara, Paolo Rosso, V\\'eronique\n  Moriceau", "title": "Irony Detection in a Multilingual Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes the first multilingual (French, English and Arabic) and\nmulticultural (Indo-European languages vs. less culturally close languages)\nirony detection system. We employ both feature-based models and neural\narchitectures using monolingual word representation. We compare the performance\nof these systems with state-of-the-art systems to identify their capabilities.\nWe show that these monolingual models trained separately on different languages\nusing multilingual word representation or text-based features can open the door\nto irony detection in languages that lack of annotated data for irony.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 18:23:27 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Ghanem", "Bilal", ""], ["Karoui", "Jihen", ""], ["Benamara", "Farah", ""], ["Rosso", "Paolo", ""], ["Moriceau", "V\u00e9ronique", ""]]}, {"id": "2002.02487", "submitter": "Prathyush Sambaturu", "authors": "Prathyush Sambaturu, Aparna Gupta, Ian Davidson, S. S. Ravi, Anil\n  Vullikanti, Andrew Warren", "title": "Efficient Algorithms for Generating Provably Near-Optimal Cluster\n  Descriptors for Explainability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.DM math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving the explainability of the results from machine learning methods has\nbecome an important research goal. Here, we study the problem of making\nclusters more interpretable by extending a recent approach of [Davidson et al.,\nNeurIPS 2018] for constructing succinct representations for clusters. Given a\nset of objects $S$, a partition $\\pi$ of $S$ (into clusters), and a universe\n$T$ of tags such that each element in $S$ is associated with a subset of tags,\nthe goal is to find a representative set of tags for each cluster such that\nthose sets are pairwise-disjoint and the total size of all the representatives\nis minimized. Since this problem is NP-hard in general, we develop\napproximation algorithms with provable performance guarantees for the problem.\nWe also show applications to explain clusters from datasets, including clusters\nof genomic sequences that represent different threat levels.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 19:49:54 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Sambaturu", "Prathyush", ""], ["Gupta", "Aparna", ""], ["Davidson", "Ian", ""], ["Ravi", "S. S.", ""], ["Vullikanti", "Anil", ""], ["Warren", "Andrew", ""]]}, {"id": "2002.02511", "submitter": "Brendan Bena", "authors": "Brendan Bena and Jugal Kalita", "title": "Introducing Aspects of Creativity in Automatic Poetry Generation", "comments": "10 pages, 10 figures, 4 tables, ICON-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poetry Generation involves teaching systems to automatically generate text\nthat resembles poetic work. A deep learning system can learn to generate poetry\non its own by training on a corpus of poems and modeling the particular style\nof language. In this paper, we propose taking an approach that fine-tunes\nGPT-2, a pre-trained language model, to our downstream task of poetry\ngeneration. We extend prior work on poetry generation by introducing creative\nelements. Specifically, we generate poems that express emotion and elicit the\nsame in readers, and poems that use the language of dreams---called dream\npoetry. We are able to produce poems that correctly elicit the emotions of\nsadness and joy 87.5 and 85 percent, respectively, of the time. We produce\ndreamlike poetry by training on a corpus of texts that describe dreams. Poems\nfrom this model are shown to capture elements of dream poetry with scores of no\nless than 3.2 on the Likert scale. We perform crowdsourced human-evaluation for\nall our poems. We also make use of the Coh-Metrix tool, outlining metrics we\nuse to gauge the quality of text generated.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 20:44:12 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Bena", "Brendan", ""], ["Kalita", "Jugal", ""]]}, {"id": "2002.02513", "submitter": "Sriram Ganapathi Subramanian", "authors": "Sriram Ganapathi Subramanian and Pascal Poupart and Matthew E. Taylor\n  and Nidhi Hegde", "title": "Multi Type Mean Field Reinforcement Learning", "comments": "Paper to appear in the Proceedings of International Conference on\n  Autonomous Agents and Multi-Agent Systems (AAMAS) 2020. Revised version has\n  some typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mean field theory provides an effective way of scaling multiagent\nreinforcement learning algorithms to environments with many agents that can be\nabstracted by a virtual mean agent. In this paper, we extend mean field\nmultiagent algorithms to multiple types. The types enable the relaxation of a\ncore assumption in mean field games, which is that all agents in the\nenvironment are playing almost similar strategies and have the same goal. We\nconduct experiments on three different testbeds for the field of many agent\nreinforcement learning, based on the standard MAgents framework. We consider\ntwo different kinds of mean field games: a) Games where agents belong to\npredefined types that are known a priori and b) Games where the type of each\nagent is unknown and therefore must be learned based on observations. We\nintroduce new algorithms for each type of game and demonstrate their superior\nperformance over state of the art algorithms that assume that all agents belong\nto the same type and other baseline algorithms in the MAgent framework.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 20:58:58 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 13:22:40 GMT"}, {"version": "v3", "created": "Mon, 9 Mar 2020 14:38:52 GMT"}, {"version": "v4", "created": "Fri, 12 Jun 2020 14:02:16 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Subramanian", "Sriram Ganapathi", ""], ["Poupart", "Pascal", ""], ["Taylor", "Matthew E.", ""], ["Hegde", "Nidhi", ""]]}, {"id": "2002.02526", "submitter": "Tim Schrills", "authors": "Tim Schrills, Thomas Franke", "title": "How to Answer Why -- Evaluating the Explanations of AI Through Mental\n  Model Analysis", "comments": "2 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To achieve optimal human-system integration in the context of user-AI\ninteraction it is important that users develop a valid representation of how AI\nworks. In most of the everyday interaction with technical systems users\nconstruct mental models (i.e., an abstraction of the anticipated mechanisms a\nsystem uses to perform a given task). If no explicit explanations are provided\nby a system (e.g. by a self-explaining AI) or other sources (e.g. an\ninstructor), the mental model is typically formed based on experiences, i.e.\nthe observations of the user during the interaction. The congruence of this\nmental model and the actual systems functioning is vital, as it is used for\nassumptions, predictions and consequently for decisions regarding system use. A\nkey question for human-centered AI research is therefore how to validly survey\nusers' mental models. The objective of the present research is to identify\nsuitable elicitation methods for mental model analysis. We evaluated whether\nmental models are suitable as an empirical research method. Additionally,\nmethods of cognitive tutoring are integrated. We propose an exemplary method to\nevaluate explainable AI approaches in a human-centered way.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 17:15:58 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Schrills", "Tim", ""], ["Franke", "Thomas", ""]]}, {"id": "2002.02631", "submitter": "Adarsh Kumar", "authors": "Adarsh Kumar, Sandipan Dandapat, Sushil Chordia", "title": "Translating Web Search Queries into Natural Language Questions", "comments": "Eleventh International Conference on Language Resources and\n  Evaluation, LREC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users often query a search engine with a specific question in mind and often\nthese queries are keywords or sub-sentential fragments. For example, if the\nusers want to know the answer for \"What's the capital of USA\", they will most\nprobably query \"capital of USA\" or \"USA capital\" or some keyword-based\nvariation of this. For example, for the user entered query \"capital of USA\",\nthe most probable question intent is \"What's the capital of USA?\". In this\npaper, we are proposing a method to generate well-formed natural language\nquestion from a given keyword-based query, which has the same question intent\nas the query. Conversion of keyword-based web query into a well-formed question\nhas lots of applications, with some of them being in search engines, Community\nQuestion Answering (CQA) website and bots communication. We found a synergy\nbetween query-to-question problem with standard machine translation(MT) task.\nWe have used both Statistical MT (SMT) and Neural MT (NMT) models to generate\nthe questions from the query. We have observed that MT models perform well in\nterms of both automatic and human evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 05:52:06 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Kumar", "Adarsh", ""], ["Dandapat", "Sandipan", ""], ["Chordia", "Sushil", ""]]}, {"id": "2002.02667", "submitter": "Fei Ye", "authors": "Fei Ye, Xuxin Cheng, Pin Wang, Ching-Yao Chan, Jiucai Zhang", "title": "Automated Lane Change Strategy using Proximal Policy Optimization-based\n  Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lane-change maneuvers are commonly executed by drivers to follow a certain\nrouting plan, overtake a slower vehicle, adapt to a merging lane ahead, etc.\nHowever, improper lane change behaviors can be a major cause of traffic flow\ndisruptions and even crashes. While many rule-based methods have been proposed\nto solve lane change problems for autonomous driving, they tend to exhibit\nlimited performance due to the uncertainty and complexity of the driving\nenvironment. Machine learning-based methods offer an alternative approach, as\nDeep reinforcement learning (DRL) has shown promising success in many\napplication domains including robotic manipulation, navigation, and playing\nvideo games. However, applying DRL to autonomous driving still faces many\npractical challenges in terms of slow learning rates, sample inefficiency, and\nsafety concerns. In this study, we propose an automated lane change strategy\nusing proximal policy optimization-based deep reinforcement learning, which\nshows great advantages in learning efficiency while still maintaining stable\nperformance. The trained agent is able to learn a smooth, safe, and efficient\ndriving policy to make lane-change decisions (i.e. when and how) in a\nchallenging situation such as dense traffic scenarios. The effectiveness of the\nproposed policy is validated by using metrics of task success rate and\ncollision rate. The simulation results demonstrate the lane change maneuvers\ncan be efficiently learned and executed in a safe, smooth, and efficient\nmanner.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 08:43:34 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 23:22:20 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Ye", "Fei", ""], ["Cheng", "Xuxin", ""], ["Wang", "Pin", ""], ["Chan", "Ching-Yao", ""], ["Zhang", "Jiucai", ""]]}, {"id": "2002.02697", "submitter": "Sha Luo", "authors": "Sha Luo, Hamidreza Kasaei, Lambert Schomaker", "title": "Accelerating Reinforcement Learning for Reaching using Continuous\n  Curriculum Learning", "comments": null, "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9207427", "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning has shown great promise in the training of robot\nbehavior due to the sequential decision making characteristics. However, the\nrequired enormous amount of interactive and informative training data provides\nthe major stumbling block for progress. In this study, we focus on accelerating\nreinforcement learning (RL) training and improving the performance of\nmulti-goal reaching tasks. Specifically, we propose a precision-based\ncontinuous curriculum learning (PCCL) method in which the requirements are\ngradually adjusted during the training process, instead of fixing the parameter\nin a static schedule. To this end, we explore various continuous curriculum\nstrategies for controlling a training process. This approach is tested using a\nUniversal Robot 5e in both simulation and real-world multi-goal reach\nexperiments. Experimental results support the hypothesis that a static training\nschedule is suboptimal, and using an appropriate decay function for curriculum\nlearning provides superior results in a faster way.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 10:08:18 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 16:16:31 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Luo", "Sha", ""], ["Kasaei", "Hamidreza", ""], ["Schomaker", "Lambert", ""]]}, {"id": "2002.02770", "submitter": "Yaliang Li", "authors": "Liuyi Yao, Zhixuan Chu, Sheng Li, Yaliang Li, Jing Gao, Aidong Zhang", "title": "A Survey on Causal Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference is a critical research topic across many domains, such as\nstatistics, computer science, education, public policy and economics, for\ndecades. Nowadays, estimating causal effect from observational data has become\nan appealing research direction owing to the large amount of available data and\nlow budget requirement, compared with randomized controlled trials. Embraced\nwith the rapidly developed machine learning area, various causal effect\nestimation methods for observational data have sprung up. In this survey, we\nprovide a comprehensive review of causal inference methods under the potential\noutcome framework, one of the well known causal inference framework. The\nmethods are divided into two categories depending on whether they require all\nthree assumptions of the potential outcome framework or not. For each category,\nboth the traditional statistical methods and the recent machine learning\nenhanced methods are discussed and compared. The plausible applications of\nthese methods are also presented, including the applications in advertising,\nrecommendation, medicine and so on. Moreover, the commonly used benchmark\ndatasets as well as the open-source codes are also summarized, which facilitate\nresearchers and practitioners to explore, evaluate and apply the causal\ninference methods.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 21:35:29 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Yao", "Liuyi", ""], ["Chu", "Zhixuan", ""], ["Li", "Sheng", ""], ["Li", "Yaliang", ""], ["Gao", "Jing", ""], ["Zhang", "Aidong", ""]]}, {"id": "2002.02829", "submitter": "Zhimin Hou", "authors": "Zhimin Hou and Kuangen Zhang and Yi Wan and Dongyu Li and Chenglong Fu\n  and Haoyong Yu", "title": "Off-policy Maximum Entropy Reinforcement Learning : Soft Actor-Critic\n  with Advantage Weighted Mixture Policy(SAC-AWMP)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The optimal policy of a reinforcement learning problem is often discontinuous\nand non-smooth. I.e., for two states with similar representations, their\noptimal policies can be significantly different. In this case, representing the\nentire policy with a function approximator (FA) with shared parameters for all\nstates maybe not desirable, as the generalization ability of parameters sharing\nmakes representing discontinuous, non-smooth policies difficult. A common way\nto solve this problem, known as Mixture-of-Experts, is to represent the policy\nas the weighted sum of multiple components, where different components perform\nwell on different parts of the state space. Following this idea and inspired by\na recent work called advantage-weighted information maximization, we propose to\nlearn for each state weights of these components, so that they entail the\ninformation of the state itself and also the preferred action learned so far\nfor the state. The action preference is characterized via the advantage\nfunction. In this case, the weight of each component would only be large for\ncertain groups of states whose representations are similar and preferred action\nrepresentations are also similar. Therefore each component is easy to be\nrepresented. We call a policy parameterized in this way an Advantage Weighted\nMixture Policy (AWMP) and apply this idea to improve soft-actor-critic (SAC),\none of the most competitive continuous control algorithm. Experimental results\ndemonstrate that SAC with AWMP clearly outperforms SAC in four commonly used\ncontinuous control tasks and achieve stable performance across different random\nseeds.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 15:01:20 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Hou", "Zhimin", ""], ["Zhang", "Kuangen", ""], ["Wan", "Yi", ""], ["Li", "Dongyu", ""], ["Fu", "Chenglong", ""], ["Yu", "Haoyong", ""]]}, {"id": "2002.02836", "submitter": "Ivo Danihelka", "authors": "Danilo J. Rezende, Ivo Danihelka, George Papamakarios, Nan Rosemary\n  Ke, Ray Jiang, Theophane Weber, Karol Gregor, Hamza Merzic, Fabio Viola, Jane\n  Wang, Jovana Mitrovic, Frederic Besse, Ioannis Antonoglou, Lars Buesing", "title": "Causally Correct Partial Models for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning, we can learn a model of future observations and\nrewards, and use it to plan the agent's next actions. However, jointly modeling\nfuture observations can be computationally expensive or even intractable if the\nobservations are high-dimensional (e.g. images). For this reason, previous\nworks have considered partial models, which model only part of the observation.\nIn this paper, we show that partial models can be causally incorrect: they are\nconfounded by the observations they don't model, and can therefore lead to\nincorrect planning. To address this, we introduce a general family of partial\nmodels that are provably causally correct, yet remain fast because they do not\nneed to fully model future observations.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 15:18:15 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Rezende", "Danilo J.", ""], ["Danihelka", "Ivo", ""], ["Papamakarios", "George", ""], ["Ke", "Nan Rosemary", ""], ["Jiang", "Ray", ""], ["Weber", "Theophane", ""], ["Gregor", "Karol", ""], ["Merzic", "Hamza", ""], ["Viola", "Fabio", ""], ["Wang", "Jane", ""], ["Mitrovic", "Jovana", ""], ["Besse", "Frederic", ""], ["Antonoglou", "Ioannis", ""], ["Buesing", "Lars", ""]]}, {"id": "2002.02878", "submitter": "Jason  Weston", "authors": "Shrimai Prabhumoye and Margaret Li and Jack Urbanek and Emily Dinan\n  and Douwe Kiela and Jason Weston and Arthur Szlam", "title": "I love your chain mail! Making knights smile in a fantasy game world:\n  Open-domain goal-oriented dialogue agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue research tends to distinguish between chit-chat and goal-oriented\ntasks. While the former is arguably more naturalistic and has a wider use of\nlanguage, the latter has clearer metrics and a straightforward learning signal.\nHumans effortlessly combine the two, for example engaging in chit-chat with the\ngoal of exchanging information or eliciting a specific response. Here, we\nbridge the divide between these two domains in the setting of a rich\nmulti-player text-based fantasy environment where agents and humans engage in\nboth actions and dialogue. Specifically, we train a goal-oriented model with\nreinforcement learning against an imitation-learned ``chit-chat'' model with\ntwo approaches: the policy either learns to pick a topic or learns to pick an\nutterance given the top-K utterances from the chit-chat model. We show that\nboth models outperform an inverse model baseline and can converse naturally\nwith their dialogue partner in order to achieve goals.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 16:22:36 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 20:45:20 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Prabhumoye", "Shrimai", ""], ["Li", "Margaret", ""], ["Urbanek", "Jack", ""], ["Dinan", "Emily", ""], ["Kiela", "Douwe", ""], ["Weston", "Jason", ""], ["Szlam", "Arthur", ""]]}, {"id": "2002.02938", "submitter": "Cameron Reid", "authors": "Cameron Reid", "title": "Student/Teacher Advising through Reward Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning is an important new subfield of multiagent reinforcement\nlearning that aims to help an agent learn about a problem by using knowledge\nthat it has gained solving another problem, or by using knowledge that is\ncommunicated to it by an agent who already knows the problem. This is useful\nwhen one wishes to change the architecture or learning algorithm of an agent\n(so that the new knowledge need not be built \"from scratch\"), when new agents\nare frequently introduced to the environment with no knowledge, or when an\nagent must adapt to similar but different problems. Great progress has been\nmade in the agent-to-agent case using the Teacher/Student framework proposed by\n(Torrey and Taylor 2013). However, that approach requires that learning from a\nteacher be treated differently from learning in every other reinforcement\nlearning context. In this paper, I propose a method which allows the\nteacher/student framework to be applied in a way that fits directly and\nnaturally into the more general reinforcement learning framework by integrating\nthe teacher feedback into the reward signal received by the learning agent. I\nshow that this approach can significantly improve the rate of learning for an\nagent playing a one-player stochastic game; I give examples of potential\npitfalls of the approach; and I propose further areas of research building on\nthis framework.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 18:15:51 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Reid", "Cameron", ""]]}, {"id": "2002.02992", "submitter": "Michael Green", "authors": "Michael Cerny Green, Luvneesh Mugrai, Ahmed Khalifa and Julian\n  Togelius", "title": "Mario Level Generation From Mechanics Using Scene Stitching", "comments": "10 pages, 7 figures, submitted to Foundations of Digital Games\n  Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a level generation method for Super Mario by stitching\ntogether pre-generated \"scenes\" that contain specific mechanics, using\nmechanic-sequences from agent playthroughs as input specifications. Given a\nsequence of mechanics, our system uses an FI-2Pop algorithm and a corpus of\nscenes to perform automated level authoring. The system outputs levels that\nhave a similar mechanical sequence to the target mechanic sequence but with a\ndifferent playthrough experience. We compare our system to a greedy method that\nselects scenes that maximize the target mechanics. Our system is able to\nmaximize the number of matched mechanics while reducing emergent mechanics\nusing the stitching process compared to the greedy approach.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 19:44:44 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Green", "Michael Cerny", ""], ["Mugrai", "Luvneesh", ""], ["Khalifa", "Ahmed", ""], ["Togelius", "Julian", ""]]}, {"id": "2002.03018", "submitter": "Elan Rosenfeld", "authors": "Elan Rosenfeld, Ezra Winston, Pradeep Ravikumar, J. Zico Kolter", "title": "Certified Robustness to Label-Flipping Attacks via Randomized Smoothing", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms are known to be susceptible to data poisoning\nattacks, where an adversary manipulates the training data to degrade\nperformance of the resulting classifier. In this work, we present a unifying\nview of randomized smoothing over arbitrary functions, and we leverage this\nnovel characterization to propose a new strategy for building classifiers that\nare pointwise-certifiably robust to general data poisoning attacks. As a\nspecific instantiation, we utilize our framework to build linear classifiers\nthat are robust to a strong variant of label flipping, where each test example\nis targeted independently. In other words, for each test point, our classifier\nincludes a certification that its prediction would be the same had some number\nof training labels been changed adversarially. Randomized smoothing has\npreviously been used to guarantee---with high probability---test-time\nrobustness to adversarial manipulation of the input to a classifier; we derive\na variant which provides a deterministic, analytical bound, sidestepping the\nprobabilistic certificates that traditionally result from the sampling\nsubprocedure. Further, we obtain these certified bounds with minimal additional\nruntime complexity over standard classification and no assumptions on the train\nor test distributions. We generalize our results to the multi-class case,\nproviding the first multi-class classification algorithm that is certifiably\nrobust to label-flipping attacks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 21:28:30 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 01:16:35 GMT"}, {"version": "v3", "created": "Thu, 6 Aug 2020 03:27:14 GMT"}, {"version": "v4", "created": "Tue, 11 Aug 2020 13:17:30 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Rosenfeld", "Elan", ""], ["Winston", "Ezra", ""], ["Ravikumar", "Pradeep", ""], ["Kolter", "J. Zico", ""]]}, {"id": "2002.03024", "submitter": "Shane Mueller", "authors": "Shane T. Mueller", "title": "Cognitive Anthropomorphism of AI: How Humans and Computers Classify\n  Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern AI image classifiers have made impressive advances in recent years,\nbut their performance often appears strange or violates expectations of users.\nThis suggests humans engage in cognitive anthropomorphism: expecting AI to have\nthe same nature as human intelligence. This mismatch presents an obstacle to\nappropriate human-AI interaction. To delineate this mismatch, I examine known\nproperties of human classification, in comparison to image classifier systems.\nBased on this examination, I offer three strategies for system design that can\naddress the mismatch between human and AI classification: explainable AI, novel\nmethods for training users, and new algorithms that match human cognition.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 21:49:58 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Mueller", "Shane T.", ""]]}, {"id": "2002.03056", "submitter": "Janardan Misra", "authors": "Janardan Misra", "title": "autoNLP: NLP Feature Recommendations for Text Analytics Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While designing machine learning based text analytics applications, often,\nNLP data scientists manually determine which NLP features to use based upon\ntheir knowledge and experience with related problems. This results in increased\nefforts during feature engineering process and renders automated reuse of\nfeatures across semantically related applications inherently difficult. In this\npaper, we argue for standardization in feature specification by outlining\nstructure of a language for specifying NLP features and present an approach for\ntheir reuse across applications to increase likelihood of identifying optimal\nfeatures.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 00:42:21 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Misra", "Janardan", ""]]}, {"id": "2002.03072", "submitter": "Theofanis Karaletsos", "authors": "Christian F. Perez, Felipe Petroski Such, Theofanis Karaletsos", "title": "Generalized Hidden Parameter MDPs Transferable Model-based RL in a\n  Handful of Trials", "comments": "paper presented at AAAI 2020 as oral presentation, 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is broad interest in creating RL agents that can solve many (related)\ntasks and adapt to new tasks and environments after initial training.\nModel-based RL leverages learned surrogate models that describe dynamics and\nrewards of individual tasks, such that planning in a good surrogate can lead to\ngood control of the true system. Rather than solving each task individually\nfrom scratch, hierarchical models can exploit the fact that tasks are often\nrelated by (unobserved) causal factors of variation in order to achieve\nefficient generalization, as in learning how the mass of an item affects the\nforce required to lift it can generalize to previously unobserved masses. We\npropose Generalized Hidden Parameter MDPs (GHP-MDPs) that describe a family of\nMDPs where both dynamics and reward can change as a function of hidden\nparameters that vary across tasks. The GHP-MDP augments model-based RL with\nlatent variables that capture these hidden parameters, facilitating transfer\nacross tasks. We also explore a variant of the model that incorporates explicit\nlatent structure mirroring the causal factors of variation across tasks (for\ninstance: agent properties, environmental factors, and goals). We\nexperimentally demonstrate state-of-the-art performance and sample-efficiency\non a new challenging MuJoCo task using reward and dynamics latent spaces, while\nbeating a previous state-of-the-art baseline with $>10\\times$ less data. Using\ntest-time inference of the latent variables, our approach generalizes in a\nsingle episode to novel combinations of dynamics and reward, and to novel\nrewards.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 02:49:33 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Perez", "Christian F.", ""], ["Such", "Felipe Petroski", ""], ["Karaletsos", "Theofanis", ""]]}, {"id": "2002.03102", "submitter": "Anuraganand Sharma Dr", "authors": "Anuraganand Sharma", "title": "A Constraint Driven Solution Model for Discrete Domains with a Case\n  Study of Exam Timetabling Problems", "comments": "41 pages in double space", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many science and engineering applications require finding solutions to\nplanning and optimization problems by satisfying a set of constraints. These\nconstraint problems (CPs) are typically NP-complete and can be formalized as\nconstraint satisfaction problems (CSPs) or constraint optimization problems\n(COPs). Evolutionary algorithms (EAs) are good solvers for optimization\nproblems ubiquitous in various problem domains, however traditional operators\nfor EAs are 'blind' to constraints or generally use problem dependent objective\nfunctions; as they do not exploit information from the constraints in search\nfor solutions. A variation of EA, Intelligent constraint handling evolutionary\nalgorithm (ICHEA), has been demonstrated to be a versatile constraints-guided\nEA for continuous constrained problems in our earlier works in (Sharma and\nSharma, 2012) where it extracts information from constraints and exploits it in\nthe evolutionary search to make the search more efficient. In this paper ICHEA\nhas been demonstrated to solve benchmark exam timetabling problems, a classic\nCOP. The presented approach demonstrates competitive results with other\nstate-of-the-art approaches in EAs in terms of quality of solutions. ICHEA\nfirst uses its inter-marriage crossover operator to satisfy all the given\nconstraints incrementally and then uses combination of traditional and enhanced\noperators to optimize the solution. Generally CPs solved by EAs are problem\ndependent penalty based fitness functions. We also proposed a generic\npreference based solution model that does not require a problem dependent\nfitness function, however currently it only works for mutually exclusive\nconstraints.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 06:53:38 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Sharma", "Anuraganand", ""]]}, {"id": "2002.03153", "submitter": "Hanan Shteingart", "authors": "Hanan Shteingart, Eran Marom, Igor Itkin, Gil Shabat, Michael\n  Kolomenkin, Moshe Salhov, and Liran Katzir", "title": "Majority Voting and the Condorcet's Jury Theorem", "comments": "1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a striking relationship between a three hundred years old Political\nScience theorem named \"Condorcet's jury theorem\" (1785), which states that\nmajorities are more likely to choose correctly when individual votes are often\ncorrect and independent, and a modern Machine Learning concept called \"Strength\nof Weak Learnability\" (1990), which describes a method for converting a weak\nlearning algorithm into one that achieves arbitrarily high accuracy and stands\nin the basis of Ensemble Learning. Albeit the intuitive statement of\nCondorcet's theorem, we could not find a compact and simple rigorous\nmathematical proof of the theorem neither in classical handbooks of Machine\nLearning nor in published papers. By all means we do not claim to discover or\nreinvent a theory nor a result. We humbly want to offer a more publicly\navailable simple derivation of the theorem. We will find joy in seeing more\nteachers of introduction-to-machine-learning courses use the proof we provide\nhere as an exercise to explain the motivation of ensemble learning.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 12:28:11 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 21:40:12 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Shteingart", "Hanan", ""], ["Marom", "Eran", ""], ["Itkin", "Igor", ""], ["Shabat", "Gil", ""], ["Kolomenkin", "Michael", ""], ["Salhov", "Moshe", ""], ["Katzir", "Liran", ""]]}, {"id": "2002.03256", "submitter": "Margaret Mitchell", "authors": "Margaret Mitchell, Dylan Baker, Nyalleng Moorosi, Emily Denton, Ben\n  Hutchinson, Alex Hanna, Timnit Gebru, Jamie Morgenstern", "title": "Diversity and Inclusion Metrics in Subset Selection", "comments": null, "journal-ref": "AIES 2020: Proceedings of the AAAI/ACM Conference on AI, Ethics,\n  and Society", "doi": "10.1145/3375627.3375832", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ethical concept of fairness has recently been applied in machine learning\n(ML) settings to describe a wide range of constraints and objectives. When\nconsidering the relevance of ethical concepts to subset selection problems, the\nconcepts of diversity and inclusion are additionally applicable in order to\ncreate outputs that account for social power and access differentials. We\nintroduce metrics based on these concepts, which can be applied together,\nseparately, and in tandem with additional fairness constraints. Results from\nhuman subject experiments lend support to the proposed criteria. Social choice\nmethods can additionally be leveraged to aggregate and choose preferable sets,\nand we detail how these may be applied.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 00:29:40 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Mitchell", "Margaret", ""], ["Baker", "Dylan", ""], ["Moorosi", "Nyalleng", ""], ["Denton", "Emily", ""], ["Hutchinson", "Ben", ""], ["Hanna", "Alex", ""], ["Gebru", "Timnit", ""], ["Morgenstern", "Jamie", ""]]}, {"id": "2002.03282", "submitter": "Bo Peng", "authors": "Bo Peng and Jiahai Wang and Zizhen Zhang", "title": "A Deep Reinforcement Learning Algorithm Using Dynamic Attention Model\n  for Vehicle Routing Problems", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent researches show that machine learning has the potential to learn\nbetter heuristics than the one designed by human for solving combinatorial\noptimization problems. The deep neural network is used to characterize the\ninput instance for constructing a feasible solution incrementally. Recently, an\nattention model is proposed to solve routing problems. In this model, the state\nof an instance is represented by node features that are fixed over time.\nHowever, the fact is, the state of an instance is changed according to the\ndecision that the model made at different construction steps, and the node\nfeatures should be updated correspondingly. Therefore, this paper presents a\ndynamic attention model with dynamic encoder-decoder architecture, which\nenables the model to explore node features dynamically and exploit hidden\nstructure information effectively at different construction steps. This paper\nfocuses on a challenging NP-hard problem, vehicle routing problem. The\nexperiments indicate that our model outperforms the previous methods and also\nshows a good generalization performance.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 04:51:53 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Peng", "Bo", ""], ["Wang", "Jiahai", ""], ["Zhang", "Zizhen", ""]]}, {"id": "2002.03389", "submitter": "Samir Passi", "authors": "Samir Passi, Steven J. Jackson", "title": "Trust in Data Science: Collaboration, Translation, and Accountability in\n  Corporate Data Science Projects", "comments": null, "journal-ref": "Proc. ACM Hum.-Comput. Interact. 2, CSCW, Article 136 (November\n  2018), 28 pages", "doi": "10.1145/3274405", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The trustworthiness of data science systems in applied and real-world\nsettings emerges from the resolution of specific tensions through situated,\npragmatic, and ongoing forms of work. Drawing on research in CSCW, critical\ndata studies, and history and sociology of science, and six months of immersive\nethnographic fieldwork with a corporate data science team, we describe four\ncommon tensions in applied data science work: (un)equivocal numbers,\n(counter)intuitive knowledge, (in)credible data, and (in)scrutable models. We\nshow how organizational actors establish and re-negotiate trust under messy and\nuncertain analytic conditions through practices of skepticism, assessment, and\ncredibility. Highlighting the collaborative and heterogeneous nature of\nreal-world data science, we show how the management of trust in applied\ncorporate data science settings depends not only on pre-processing and\nquantification, but also on negotiation and translation. We conclude by\ndiscussing the implications of our findings for data science research and\npractice, both within and beyond CSCW.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 15:50:50 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Passi", "Samir", ""], ["Jackson", "Steven J.", ""]]}, {"id": "2002.03433", "submitter": "Simos Gerasimou", "authors": "Simos Gerasimou, Hasan Ferit Eniser, Alper Sen, Alper Cakan", "title": "Importance-Driven Deep Learning System Testing", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL) systems are key enablers for engineering intelligent\napplications due to their ability to solve complex tasks such as image\nrecognition and machine translation. Nevertheless, using DL systems in safety-\nand security-critical applications requires to provide testing evidence for\ntheir dependable operation. Recent research in this direction focuses on\nadapting testing criteria from traditional software engineering as a means of\nincreasing confidence for their correct behaviour. However, they are inadequate\nin capturing the intrinsic properties exhibited by these systems. We bridge\nthis gap by introducing DeepImportance, a systematic testing methodology\naccompanied by an Importance-Driven (IDC) test adequacy criterion for DL\nsystems. Applying IDC enables to establish a layer-wise functional\nunderstanding of the importance of DL system components and use this\ninformation to assess the semantic diversity of a test set. Our empirical\nevaluation on several DL systems, across multiple DL datasets and with\nstate-of-the-art adversarial generation techniques demonstrates the usefulness\nand effectiveness of DeepImportance and its ability to support the engineering\nof more robust DL systems.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 19:20:56 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Gerasimou", "Simos", ""], ["Eniser", "Hasan Ferit", ""], ["Sen", "Alper", ""], ["Cakan", "Alper", ""]]}, {"id": "2002.03508", "submitter": "Sainyam Galhotra Mr", "authors": "Saba Ahmadi, Sainyam Galhotra, Barna Saha, Roy Schwartz", "title": "Fair Correlation Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we study the problem of correlation clustering under fairness\nconstraints. In the classic correlation clustering problem, we are given a\ncomplete graph where each edge is labeled positive or negative. The goal is to\nobtain a clustering of the vertices that minimizes disagreements -- the number\nof negative edges trapped inside a cluster plus positive edges between\ndifferent clusters.\n  We consider two variations of fairness constraint for the problem of\ncorrelation clustering where each node has a color, and the goal is to form\nclusters that do not over-represent vertices of any color.\n  The first variant aims to generate clusters with minimum disagreements, where\nthe distribution of a feature (e.g. gender) in each cluster is same as the\nglobal distribution. For the case of two colors when the desired ratio of the\nnumber of colors in each cluster is $1:p$, we get\n$\\mathcal{O}(p^2)$-approximation algorithm. Our algorithm could be extended to\nthe case of multiple colors. We prove this problem is NP-hard.\n  The second variant considers relative upper and lower bounds on the number of\nnodes of any color in a cluster. The goal is to avoid violating upper and lower\nbounds corresponding to each color in each cluster while minimizing the total\nnumber of disagreements. Along with our theoretical results, we show the\neffectiveness of our algorithm to generate fair clusters by empirical\nevaluation on real world data sets.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 02:59:17 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Ahmadi", "Saba", ""], ["Galhotra", "Sainyam", ""], ["Saha", "Barna", ""], ["Schwartz", "Roy", ""]]}, {"id": "2002.03514", "submitter": "Ibrahim Abdelaziz", "authors": "Bassem Makni, Ibrahim Abdelaziz, James Hendler", "title": "Explainable Deep RDFS Reasoner", "comments": "StarAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research efforts aiming to bridge the Neural-Symbolic gap for RDFS\nreasoning proved empirically that deep learning techniques can be used to learn\nRDFS inference rules. However, one of their main deficiencies compared to\nrule-based reasoners is the lack of derivations for the inferred triples (i.e.\nexplainability in AI terms). In this paper, we build on these approaches to\nprovide not only the inferred graph but also explain how these triples were\ninferred. In the graph words approach, RDF graphs are represented as a sequence\nof graph words where inference can be achieved through neural machine\ntranslation. To achieve explainability in RDFS reasoning, we revisit this\napproach and introduce a new neural network model that gets the input graph--as\na sequence of graph words-- as well as the encoding of the inferred triple and\noutputs the derivation for the inferred triple. We evaluated our justification\nmodel on two datasets: a synthetic dataset-- LUBM benchmark-- and a real-world\ndataset --ScholarlyData about conferences-- where the lowest validation\naccuracy approached 96%.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 03:20:31 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Makni", "Bassem", ""], ["Abdelaziz", "Ibrahim", ""], ["Hendler", "James", ""]]}, {"id": "2002.03531", "submitter": "Khalid Saqr", "authors": "Khalid M. Saqr, Abdelrahman Elsharawy", "title": "A Novel Kuhnian Ontology for Epistemic Classification of STM Scholarly\n  Articles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Thomas Kuhn proposed his paradigmatic view of scientific discovery five\ndecades ago. The concept of paradigm has not only explained the progress of\nscience, but has also become the central epistemic concept among STM\nscientists. Here, we adopt the principles of Kuhnian philosophy to construct a\nnovel ontology aims at classifying and evaluating the impact of STM scholarly\narticles. First, we explain how the Kuhnian cycle of science describes research\nat different epistemic stages. Second, we show how the Kuhnian cycle could be\nreconstructed into modular ontologies which classify scholarly articles\naccording to their contribution to paradigm-centred knowledge. The proposed\nontology and its scenarios are discussed. To the best of the authors knowledge,\nthis is the first attempt for creating an ontology for describing scholarly\narticles based on the Kuhnian paradigmatic view of science.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 04:00:07 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Saqr", "Khalid M.", ""], ["Elsharawy", "Abdelrahman", ""]]}, {"id": "2002.03532", "submitter": "Jiaxi Tang", "authors": "Jiaxi Tang, Rakesh Shivanna, Zhe Zhao, Dong Lin, Anima Singh, Ed H.\n  Chi, Sagar Jain", "title": "Understanding and Improving Knowledge Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Distillation (KD) is a model-agnostic technique to improve model\nquality while having a fixed capacity budget. It is a commonly used technique\nfor model compression, where a larger capacity teacher model with better\nquality is used to train a more compact student model with better inference\nefficiency. Through distillation, one hopes to benefit from student's\ncompactness, without sacrificing too much on model quality. Despite the large\nsuccess of knowledge distillation, better understanding of how it benefits\nstudent model's training dynamics remains under-explored. In this paper, we\ncategorize teacher's knowledge into three hierarchical levels and study its\neffects on knowledge distillation: (1) knowledge of the `universe', where KD\nbrings a regularization effect through label smoothing; (2) domain knowledge,\nwhere teacher injects class relationships prior to student's logit layer\ngeometry; and (3) instance specific knowledge, where teacher rescales student\nmodel's per-instance gradients based on its measurement on the event\ndifficulty. Using systematic analyses and extensive empirical studies on both\nsynthetic and real-world datasets, we confirm that the aforementioned three\nfactors play a major role in knowledge distillation. Furthermore, based on our\nfindings, we diagnose some of the failure cases of applying KD from recent\nstudies.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 04:21:41 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 23:31:44 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Tang", "Jiaxi", ""], ["Shivanna", "Rakesh", ""], ["Zhao", "Zhe", ""], ["Lin", "Dong", ""], ["Singh", "Anima", ""], ["Chi", "Ed H.", ""], ["Jain", "Sagar", ""]]}, {"id": "2002.03585", "submitter": "Che Wang", "authors": "Che Wang, Keith Ross", "title": "On the Convergence of the Monte Carlo Exploring Starts Algorithm for\n  Reinforcement Learning", "comments": "Preprint, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A simple and natural algorithm for reinforcement learning is Monte Carlo\nExploring States (MCES), where the Q-function is estimated by averaging the\nMonte Carlo returns, and the policy is improved by choosing actions that\nmaximize the current estimate of the Q-function. Exploration is performed by\n\"exploring starts\", that is, each episode begins with a randomly chosen state\nand action and then follows the current policy. Establishing convergence for\nthis algorithm has been an open problem for more than 20 years. We make headway\nwith this problem by proving convergence for Optimal Policy Feed-Forward MDPs,\nwhich are MDPs whose states are not revisited within any episode for an optimal\npolicy. Such MDPs include all deterministic environments (including Cliff\nWalking and other gridworld examples) and a large class of stochastic\nenvironments (including Blackjack). The convergence results presented here make\nprogress for this long-standing open problem in reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 07:54:57 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Wang", "Che", ""], ["Ross", "Keith", ""]]}, {"id": "2002.03620", "submitter": "Anil Yaman", "authors": "Anil Yaman, Giovanni Iacca, Decebal Constantin Mocanu, George\n  Fletcher, Mykola Pechenizkiy", "title": "Novelty Producing Synaptic Plasticity", "comments": null, "journal-ref": null, "doi": "10.1145/3377929.3389976", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A learning process with the plasticity property often requires reinforcement\nsignals to guide the process. However, in some tasks (e.g. maze-navigation), it\nis very difficult (or impossible) to measure the performance of an agent (i.e.\na fitness value) to provide reinforcements since the position of the goal is\nnot known. This requires finding the correct behavior among a vast number of\npossible behaviors without having the knowledge of the reinforcement signals.\nIn these cases, an exhaustive search may be needed. However, this might not be\nfeasible especially when optimizing artificial neural networks in continuous\ndomains. In this work, we introduce novelty producing synaptic plasticity\n(NPSP), where we evolve synaptic plasticity rules to produce as many novel\nbehaviors as possible to find the behavior that can solve the problem. We\nevaluate the NPSP on maze-navigation on deceptive maze environments that\nrequire complex actions and the achievement of subgoals to complete. Our\nresults show that the search heuristic used with the proposed NPSP is indeed\ncapable of producing much more novel behaviors in comparison with a random\nsearch taken as baseline.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 09:52:41 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Yaman", "Anil", ""], ["Iacca", "Giovanni", ""], ["Mocanu", "Decebal Constantin", ""], ["Fletcher", "George", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "2002.03636", "submitter": "Joseph de Vilmarest", "authors": "Joseph de Vilmarest (LPSM (UMR\\_8001)), Olivier Wintenberger (LPSM\n  (UMR\\_8001))", "title": "Stochastic Online Optimization using Kalman Recursion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Extended Kalman Filter in constant dynamics, offering a bayesian\nperspective of stochastic optimization. We obtain high probability bounds on\nthe cumulative excess risk in an unconstrained setting. In order to avoid any\nprojection step we propose a two-phase analysis. First, for linear and logistic\nregressions, we prove that the algorithm enters a local phase where the\nestimate stays in a small region around the optimum. We provide explicit bounds\nwith high probability on this convergence time. Second, for generalized linear\nregressions, we provide a martingale analysis of the excess risk in the local\nphase, improving existing ones in bounded stochastic optimization. The EKF\nappears as a parameter-free online algorithm with O(d^2) cost per iteration\nthat optimally solves some unconstrained optimization problems.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 10:33:35 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 08:15:29 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["de Vilmarest", "Joseph", "", "LPSM"], ["Wintenberger", "Olivier", "", "LPSM"]]}, {"id": "2002.03639", "submitter": "Nimisha Ghosh", "authors": "Nimisha Ghosh, Sayantan Saha, Rourab Paul", "title": "iDCR: Improved Dempster Combination Rule for Multisensor Fault Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data gathered from multiple sensors can be effectively fused for accurate\nmonitoring of many engineering applications. In the last few years, one of the\nmost sought after applications for multi sensor fusion has been fault\ndiagnosis. Dempster-Shafer Theory of Evidence along with Dempsters Combination\nRule is a very popular method for multi sensor fusion which can be successfully\napplied to fault diagnosis. But if the information obtained from the different\nsensors shows high conflict, the classical Dempsters Combination Rule may\nproduce counter-intuitive result. To overcome this shortcoming, this paper\nproposes an improved combination rule for multi sensor data fusion. Numerical\nexamples have been put forward to show the effectiveness of the proposed\nmethod. Comparative analysis has also been carried out with existing methods to\nshow the superiority of the proposed method in multi sensor fault diagnosis.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 10:37:38 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Ghosh", "Nimisha", ""], ["Saha", "Sayantan", ""], ["Paul", "Rourab", ""]]}, {"id": "2002.03647", "submitter": "V\\'ictor Campos", "authors": "V\\'ictor Campos, Alexander Trott, Caiming Xiong, Richard Socher,\n  Xavier Giro-i-Nieto, Jordi Torres", "title": "Explore, Discover and Learn: Unsupervised Discovery of State-Covering\n  Skills", "comments": "17 pages, 11 figures. Code is publicly available at\n  https://github.com/victorcampos7/edl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acquiring abilities in the absence of a task-oriented reward function is at\nthe frontier of reinforcement learning research. This problem has been studied\nthrough the lens of empowerment, which draws a connection between option\ndiscovery and information theory. Information-theoretic skill discovery methods\nhave garnered much interest from the community, but little research has been\nconducted in understanding their limitations. Through theoretical analysis and\nempirical evidence, we show that existing algorithms suffer from a common\nlimitation -- they discover options that provide a poor coverage of the state\nspace. In light of this, we propose 'Explore, Discover and Learn' (EDL), an\nalternative approach to information-theoretic skill discovery. Crucially, EDL\noptimizes the same information-theoretic objective derived from the empowerment\nliterature, but addresses the optimization problem using different machinery.\nWe perform an extensive evaluation of skill discovery methods on controlled\nenvironments and show that EDL offers significant advantages, such as\novercoming the coverage problem, reducing the dependence of learned skills on\nthe initial state, and allowing the user to define a prior over which behaviors\nshould be learned. Code is publicly available at\nhttps://github.com/victorcampos7/edl.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 10:49:53 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 19:44:12 GMT"}, {"version": "v3", "created": "Sat, 21 Mar 2020 12:08:59 GMT"}, {"version": "v4", "created": "Mon, 3 Aug 2020 11:06:21 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Campos", "V\u00edctor", ""], ["Trott", "Alexander", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""], ["Giro-i-Nieto", "Xavier", ""], ["Torres", "Jordi", ""]]}, {"id": "2002.03671", "submitter": "Akira Taniguchi", "authors": "Akira Taniguchi, Shota Isobe, Lotfi El Hafi, Yoshinobu Hagiwara,\n  Tadahiro Taniguchi", "title": "Autonomous Planning Based on Spatial Concepts to Tidy Up Home\n  Environments with Service Robots", "comments": "This paper has been accepted to Advanced Robotics", "journal-ref": null, "doi": "10.1080/01691864.2021.1890212", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tidy-up tasks by service robots in home environments are challenging in\nrobotics applications because they involve various interactions with the\nenvironment. In particular, robots are required not only to grasp, move, and\nrelease various home objects but also to plan the order and positions for\nplacing the objects. In this paper, we propose a novel planning method that can\nefficiently estimate the order and positions of the objects to be tidied up by\nlearning the parameters of a probabilistic generative model. The model allows a\nrobot to learn the distributions of the co-occurrence probability of the\nobjects and places to tidy up using the multimodal sensor information collected\nin a tidied environment. Additionally, we develop an autonomous robotic system\nto perform the tidy-up operation. We evaluate the effectiveness of the proposed\nmethod by an experimental simulation that reproduces the conditions of the Tidy\nUp Here task of the World Robot Summit 2018 international robotics competition.\nThe simulation results show that the proposed method enables the robot to\nsuccessively tidy up several objects and achieves the best task score among the\nconsidered baseline tidy-up methods.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 11:49:58 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 08:16:09 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Taniguchi", "Akira", ""], ["Isobe", "Shota", ""], ["Hafi", "Lotfi El", ""], ["Hagiwara", "Yoshinobu", ""], ["Taniguchi", "Tadahiro", ""]]}, {"id": "2002.03686", "submitter": "Jens D\\\"orpinghaus", "authors": "Jens D\\\"orpinghaus, Andreas Stefan", "title": "Optimization of Retrieval Algorithms on Large Scale Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs have been shown to play an important role in recent\nknowledge mining and discovery, for example in the field of life sciences or\nbioinformatics. Although a lot of research has been done on the field of query\noptimization, query transformation and of course in storing and retrieving\nlarge scale knowledge graphs the field of algorithmic optimization is still a\nmajor challenge and a vital factor in using graph databases. Few researchers\nhave addressed the problem of optimizing algorithms on large scale labeled\nproperty graphs. Here, we present two optimization approaches and compare them\nwith a naive approach of directly querying the graph database. The aim of our\nwork is to determine limiting factors of graph databases like Neo4j and we\ndescribe a novel solution to tackle these challenges. For this, we suggest a\nclassification schema to differ between the complexity of a problem on a graph\ndatabase. We evaluate our optimization approaches on a test system containing a\nknowledge graph derived biomedical publication data enriched with text mining\ndata. This dense graph has more than 71M nodes and 850M relationships. The\nresults are very encouraging and - depending on the problem - we were able to\nshow a speedup of a factor between 44 and 3839.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 12:37:03 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["D\u00f6rpinghaus", "Jens", ""], ["Stefan", "Andreas", ""]]}, {"id": "2002.03766", "submitter": "Daya Gaur", "authors": "Daya Gaur and Muhammad Khan", "title": "Testing Unsatisfiability of Constraint Satisfaction Problems via Tensor\n  Products", "comments": "ISAIM 2020, International Symposium on Artificial Intelligence and\n  Mathematics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the design of stochastic local search methods to prove\nunsatisfiability of a constraint satisfaction problem (CSP). For a binary CSP,\nsuch methods have been designed using the microstructure of the CSP. Here, we\ndevelop a method to decompose the microstructure into graph tensors. We show\nhow to use the tensor decomposition to compute a proof of unsatisfiability\nefficiently and in parallel. We also offer substantial empirical evidence that\nour approach improves the praxis. For instance, one decomposition yields proofs\nof unsatisfiability in half the time without sacrificing the quality. Another\ndecomposition is twenty times faster and effective three-tenths of the times\ncompared to the prior method. Our method is applicable to arbitrary CSPs using\nthe well known dual and hidden variable transformations from an arbitrary CSP\nto a binary CSP.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 18:06:52 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Gaur", "Daya", ""], ["Khan", "Muhammad", ""]]}, {"id": "2002.03776", "submitter": "Eduardo Soares Mr", "authors": "Plamen Angelov, Eduardo Soares", "title": "Towards Deep Machine Reasoning: a Prototype-based Deep Neural Network\n  with Decision Tree Inference", "comments": "Submitted to the IEEE Joint Conference on Neural Networks (IJCNN -\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce the DMR -- a prototype-based method and network\narchitecture for deep learning which is using a decision tree (DT)-based\ninference and synthetic data to balance the classes. It builds upon the\nrecently introduced xDNN method addressing more complex multi-class problems,\nspecifically when classes are highly imbalanced. DMR moves away from a direct\ndecision based on all classes towards a layered DT of pair-wise class\ncomparisons. In addition, it forces the prototypes to be balanced between\nclasses regardless of possible class imbalances of the training data. It has\ntwo novel mechanisms, namely i) using a DT to determine the winning class\nlabel, and ii) balancing the classes by synthesizing data around the prototypes\ndetermined from the available training data. As a result, we improved\nsignificantly the performance of the resulting fully explainable DNN as\nevidenced by the best reported result on the well know benchmark problem\nCaltech-101 surpassing our own recently published \"world record\". Furthermore,\nwe also achieved another \"world record\" for another very hard benchmark\nproblem, namely Caltech-256 as well as surpassed the results of other\napproaches on Faces-1999 problem. In summary, we propose a new approach\nspecifically advantageous for imbalanced multi-class problems that achieved two\nworld records on well known hard benchmark problems and the best result on\nanother problem in terms of accuracy. Moreover, DMR offers full explainability,\ndoes not require GPUs and can continue to learn from new data by adding new\nprototypes preserving the previous ones but not requiring full retraining.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 14:11:07 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Angelov", "Plamen", ""], ["Soares", "Eduardo", ""]]}, {"id": "2002.03841", "submitter": "Hussein Abbass A", "authors": "Hussein A. Abbass, Sondoss Elsawah, Eleni Petraki, Robert Hunjet", "title": "Machine Education: Designing semantically ordered and ontologically\n  guided modular neural networks", "comments": "IEEE Symposium Series on Computational Intelligence, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The literature on machine teaching, machine education, and curriculum design\nfor machines is in its infancy with sparse papers on the topic primarily\nfocusing on data and model engineering factors to improve machine learning. In\nthis paper, we first discuss selected attempts to date on machine teaching and\neducation. We then bring theories and methodologies together from human\neducation to structure and mathematically define the core problems in lesson\ndesign for machine education and the modelling approaches required to support\nthe steps for machine education. Last, but not least, we offer an\nontology-based methodology to guide the development of lesson plans to produce\ntransparent and explainable modular learning machines, including neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 09:43:40 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Abbass", "Hussein A.", ""], ["Elsawah", "Sondoss", ""], ["Petraki", "Eleni", ""], ["Hunjet", "Robert", ""]]}, {"id": "2002.03842", "submitter": "Stefan Br\\\"ase", "authors": "Christian Pachl, Nils Frank, Jan Breitbart, Stefan Br\\\"ase", "title": "Overview of chemical ontologies", "comments": "2 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Ontologies order and interconnect knowledge of a certain field in a formal\nand semantic way so that they are machine-parsable. They try to define allwhere\nacceptable definition of concepts and objects, classify them, provide\nproperties as well as interconnect them with relations (e.g. \"A is a special\ncase of B\"). More precisely, Tom Gruber defines Ontologies as a \"specification\nof a conceptualization; [...] a description (like a formal specification of a\nprogram) of the concepts and relationships that can exist for an agent or a\ncommunity of agents.\" [1] An Ontology is made of Individuals which are\norganized in Classes. Both can have Attributes and Relations among themselves.\nSome complex Ontologies define Restrictions, Rules and Events which change\nattributes or relations. To be computer accessible they are written in certain\nontology languages, like the OBO language or the more used Common Algebraic\nSpecification Language. With the rising of a digitalized, interconnected and\nglobalized world, where common standards have to be found, ontologies are of\ngreat interest. [2] Yet, the development of chemical ontologies is in the\nbeginning. Indeed, some interesting basic approaches towards chemical\nontologies can be found, but nevertheless they suffer from two main flaws.\nFirstly, we found that they are mostly only fragmentary completed or are still\nin an architecture state. Secondly, apparently no chemical ontology is\nwidespread accepted. Therefore, we herein try to describe the major\nontology-developments in the chemical related fields Ontologies about chemical\nanalytical methods, Ontologies about name reactions and Ontologies about\nscientific units.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 10:42:22 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Pachl", "Christian", ""], ["Frank", "Nils", ""], ["Breitbart", "Jan", ""], ["Br\u00e4se", "Stefan", ""]]}, {"id": "2002.03847", "submitter": "Tobias Brudermueller", "authors": "Tobias Brudermueller, Dennis L. Shung, Adrian J. Stanley, Johannes\n  Stegmaier, Smita Krishnaswamy", "title": "Making Logic Learnable With Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural networks are good at learning unspecified functions from\ntraining samples, they cannot be directly implemented in hardware and are often\nnot interpretable or formally verifiable. On the other hand, logic circuits are\nimplementable, verifiable, and interpretable but are not able to learn from\ntraining data in a generalizable way. We propose a novel logic learning\npipeline that combines the advantages of neural networks and logic circuits.\nOur pipeline first trains a neural network on a classification task, and then\ntranslates this, first to random forests, and then to AND-Inverter logic. We\nshow that our pipeline maintains greater accuracy than naive translations to\nlogic, and minimizes the logic such that it is more interpretable and has\ndecreased hardware cost. We show the utility of our pipeline on a network that\nis trained on biomedical data. This approach could be applied to patient care\nto provide risk stratification and guide clinical decision-making.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 15:11:40 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 20:49:30 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 18:07:58 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Brudermueller", "Tobias", ""], ["Shung", "Dennis L.", ""], ["Stanley", "Adrian J.", ""], ["Stegmaier", "Johannes", ""], ["Krishnaswamy", "Smita", ""]]}, {"id": "2002.03910", "submitter": "Rui Liu", "authors": "Qifei Yu, Zhexin Shen, Yijiang Pang and Rui Liu", "title": "Proficiency Constrained Multi-Agent Reinforcement Learning for\n  Environment-Adaptive Multi UAV-UGV Teaming", "comments": "five pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A mixed aerial and ground robot team, which includes both unmanned ground\nvehicles (UGVs) and unmanned aerial vehicles (UAVs), is widely used for\ndisaster rescue, social security, precision agriculture, and military missions.\nHowever, team capability and corresponding configuration vary since robots have\ndifferent motion speeds, perceiving ranges, reaching areas, and resilient\ncapabilities to the dynamic environment. Due to heterogeneous robots inside a\nteam and the resilient capabilities of robots, it is challenging to perform a\ntask with an optimal balance between reasonable task allocations and maximum\nutilization of robot capability. To address this challenge for effective mixed\nground and aerial teaming, this paper developed a novel teaming method,\nproficiency aware multi-agent deep reinforcement learning (Mix-RL), to guide\nground and aerial cooperation by considering the best alignments between robot\ncapabilities, task requirements, and environment conditions. Mix-RL largely\nexploits robot capabilities while being aware of the adaption of robot\ncapabilities to task requirements and environment conditions. Mix-RL's\neffectiveness in guiding mixed teaming was validated with the task \"social\nsecurity for criminal vehicle tracking\".\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 16:19:58 GMT"}, {"version": "v2", "created": "Sun, 14 Mar 2021 20:29:33 GMT"}, {"version": "v3", "created": "Tue, 29 Jun 2021 14:46:56 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Yu", "Qifei", ""], ["Shen", "Zhexin", ""], ["Pang", "Yijiang", ""], ["Liu", "Rui", ""]]}, {"id": "2002.03996", "submitter": "Chandrashekar Lakshminarayanan", "authors": "Chandrashekar Lakshminarayanan and Amit Vikram Singh", "title": "Deep Gated Networks: A framework to understand training and\n  generalisation in deep learning", "comments": "18 Pages, submitted to ICML, added convnets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the role of (stochastic) gradient descent (SGD) in the training\nand generalisation of deep neural networks (DNNs) with ReLU activation has been\nthe object study in the recent past. In this paper, we make use of deep gated\nnetworks (DGNs) as a framework to obtain insights about DNNs with ReLU\nactivation. In DGNs, a single neuronal unit has two components namely the\npre-activation input (equal to the inner product the weights of the layer and\nthe previous layer outputs), and a gating value which belongs to $[0,1]$ and\nthe output of the neuronal unit is equal to the multiplication of\npre-activation input and the gating value. The standard DNN with ReLU\nactivation, is a special case of the DGNs, wherein the gating value is $1/0$\nbased on whether or not the pre-activation input is positive or negative. We\ntheoretically analyse and experiment with several variants of DGNs, each\nvariant suited to understand a particular aspect of either training or\ngeneralisation in DNNs with ReLU activation. Our theory throws light on two\nquestions namely i) why increasing depth till a point helps in training and ii)\nwhy increasing depth beyond a point hurts training? We also present\nexperimental evidence to show that gate adaptation, i.e., the change of gating\nvalue through the course of training is key for generalisation.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:12:20 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 17:25:46 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Lakshminarayanan", "Chandrashekar", ""], ["Singh", "Amit Vikram", ""]]}, {"id": "2002.04017", "submitter": "Yu Bai", "authors": "Yu Bai, Chi Jin", "title": "Provable Self-Play Algorithms for Competitive Reinforcement Learning", "comments": "Appearing at ICML 2020. Fixed typos from v1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-play, where the algorithm learns by playing against itself without\nrequiring any direct supervision, has become the new weapon in modern\nReinforcement Learning (RL) for achieving superhuman performance in practice.\nHowever, the majority of exisiting theory in reinforcement learning only\napplies to the setting where the agent plays against a fixed environment; it\nremains largely open whether self-play algorithms can be provably effective,\nespecially when it is necessary to manage the exploration/exploitation\ntradeoff. We study self-play in competitive reinforcement learning under the\nsetting of Markov games, a generalization of Markov decision processes to the\ntwo-player case. We introduce a self-play algorithm---Value Iteration with\nUpper/Lower Confidence Bound (VI-ULCB)---and show that it achieves regret\n$\\tilde{\\mathcal{O}}(\\sqrt{T})$ after playing $T$ steps of the game, where the\nregret is measured by the agent's performance against a \\emph{fully\nadversarial} opponent who can exploit the agent's strategy at \\emph{any} step.\nWe also introduce an explore-then-exploit style algorithm, which achieves a\nslightly worse regret of $\\tilde{\\mathcal{O}}(T^{2/3})$, but is guaranteed to\nrun in polynomial time even in the worst case. To the best of our knowledge,\nour work presents the first line of provably sample-efficient self-play\nalgorithms for competitive reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:44:50 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 22:29:39 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 17:07:54 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Bai", "Yu", ""], ["Jin", "Chi", ""]]}, {"id": "2002.04021", "submitter": "Daniel Sawyer", "authors": "Daniel P. Sawyer, Miguel L\\'azaro-Gredilla, Dileep George", "title": "A Model of Fast Concept Inference with Object-Factorized Cognitive\n  Programs", "comments": "7 pages, 4 figures, 5 tables, to be presented at CogSci 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of humans to quickly identify general concepts from a handful of\nimages has proven difficult to emulate with robots. Recently, a computer\narchitecture was developed that allows robots to mimic some aspects of this\nhuman ability by modeling concepts as cognitive programs using an instruction\nset of primitive cognitive functions. This allowed a robot to emulate human\nimagination by simulating candidate programs in a world model before\ngeneralizing to the physical world. However, this model used a naive search\nalgorithm that required 30 minutes to discover a single concept, and became\nintractable for programs with more than 20 instructions. To circumvent this\nbottleneck, we present an algorithm that emulates the human cognitive\nheuristics of object factorization and sub-goaling, allowing human-level\ninference speed, improving accuracy, and making the output more explainable.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:48:40 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 16:47:15 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Sawyer", "Daniel P.", ""], ["L\u00e1zaro-Gredilla", "Miguel", ""], ["George", "Dileep", ""]]}, {"id": "2002.04087", "submitter": "Ben Shneiderman", "authors": "Ben Shneiderman", "title": "Human-Centered Artificial Intelligence: Reliable, Safe & Trustworthy", "comments": "15 pages, followed by 4 pages of references, 6 figures", "journal-ref": null, "doi": null, "report-no": "UMD HCIL-2020-01", "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Well-designed technologies that offer high levels of human control and high\nlevels of computer automation can increase human performance, leading to wider\nadoption. The Human-Centered Artificial Intelligence (HCAI) framework clarifies\nhow to (1) design for high levels of human control and high levels of computer\nautomation so as to increase human performance, (2) understand the situations\nin which full human control or full computer control are necessary, and (3)\navoid the dangers of excessive human control or excessive computer control. The\nmethods of HCAI are more likely to produce designs that are Reliable, Safe &\nTrustworthy (RST). Achieving these goals will dramatically increase human\nperformance, while supporting human self-efficacy, mastery, creativity, and\nresponsibility.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 21:02:48 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 19:03:46 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Shneiderman", "Ben", ""]]}, {"id": "2002.04108", "submitter": "Swabha Swayamdipta", "authors": "Ronan Le Bras, Swabha Swayamdipta, Chandra Bhagavatula, Rowan Zellers,\n  Matthew E. Peters, Ashish Sabharwal, Yejin Choi", "title": "Adversarial Filters of Dataset Biases", "comments": "Accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large neural models have demonstrated human-level performance on language and\nvision benchmarks, while their performance degrades considerably on adversarial\nor out-of-distribution samples. This raises the question of whether these\nmodels have learned to solve a dataset rather than the underlying task by\noverfitting to spurious dataset biases. We investigate one recently proposed\napproach, AFLite, which adversarially filters such dataset biases, as a means\nto mitigate the prevalent overestimation of machine performance. We provide a\ntheoretical understanding for AFLite, by situating it in the generalized\nframework for optimum bias reduction. We present extensive supporting evidence\nthat AFLite is broadly applicable for reduction of measurable dataset biases,\nand that models trained on the filtered datasets yield better generalization to\nout-of-distribution tasks. Finally, filtering results in a large drop in model\nperformance (e.g., from 92% to 62% for SNLI), while human performance still\nremains high. Our work thus shows that such filtered datasets can pose new\nresearch challenges for robust generalization by serving as upgraded\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 21:59:21 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 05:37:37 GMT"}, {"version": "v3", "created": "Sat, 11 Jul 2020 00:44:43 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Bras", "Ronan Le", ""], ["Swayamdipta", "Swabha", ""], ["Bhagavatula", "Chandra", ""], ["Zellers", "Rowan", ""], ["Peters", "Matthew E.", ""], ["Sabharwal", "Ashish", ""], ["Choi", "Yejin", ""]]}, {"id": "2002.04109", "submitter": "Beril Sirmacek", "authors": "Nicol\\`o Botteghi, Beril Sirmacek, Khaled A. A. Mustafa, Mannes Poel\n  and Stefano Stramigioli", "title": "On Reward Shaping for Mobile Robot Navigation: A Reinforcement Learning\n  and SLAM Based Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a map-less path planning algorithm based on Deep Reinforcement\nLearning (DRL) for mobile robots navigating in unknown environment that only\nrelies on 40-dimensional raw laser data and odometry information. The planner\nis trained using a reward function shaped based on the online knowledge of the\nmap of the training environment, obtained using grid-based Rao-Blackwellized\nparticle filter, in an attempt to enhance the obstacle awareness of the agent.\nThe agent is trained in a complex simulated environment and evaluated in two\nunseen ones. We show that the policy trained using the introduced reward\nfunction not only outperforms standard reward functions in terms of convergence\nspeed, by a reduction of 36.9\\% of the iteration steps, and reduction of the\ncollision samples, but it also drastically improves the behaviour of the agent\nin unseen environments, respectively by 23\\% in a simpler workspace and by 45\\%\nin a more clustered one. Furthermore, the policy trained in the simulation\nenvironment can be directly and successfully transferred to the real robot. A\nvideo of our experiments can be found at: https://youtu.be/UEV7W6e6ZqI\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 22:00:16 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Botteghi", "Nicol\u00f2", ""], ["Sirmacek", "Beril", ""], ["Mustafa", "Khaled A. A.", ""], ["Poel", "Mannes", ""], ["Stramigioli", "Stefano", ""]]}, {"id": "2002.04175", "submitter": "Sushmita Bhattacharya", "authors": "Sushmita Bhattacharya, Sahil Badyal, Thomas Wheeler, Stephanie Gil,\n  Dimitri Bertsekas", "title": "Reinforcement Learning for POMDP: Partitioned Rollout and Policy\n  Iteration with Application to Autonomous Sequential Repair Problems", "comments": "Total 9 pages, 9 figures, 1 table, submitted and accepted to be\n  published in IEEE RA-L 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider infinite horizon discounted dynamic programming\nproblems with finite state and control spaces, and partial state observations.\nWe discuss an algorithm that uses multistep lookahead, truncated rollout with a\nknown base policy, and a terminal cost function approximation. This algorithm\nis also used for policy improvement in an approximate policy iteration scheme,\nwhere successive policies are approximated by using a neural network\nclassifier. A novel feature of our approach is that it is well suited for\ndistributed computation through an extended belief space formulation and the\nuse of a partitioned architecture, which is trained with multiple neural\nnetworks. We apply our methods in simulation to a class of sequential repair\nproblems where a robot inspects and repairs a pipeline with potentially several\nrupture sites under partial information about the state of the pipeline.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 02:38:38 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Bhattacharya", "Sushmita", ""], ["Badyal", "Sahil", ""], ["Wheeler", "Thomas", ""], ["Gil", "Stephanie", ""], ["Bertsekas", "Dimitri", ""]]}, {"id": "2002.04202", "submitter": "Devleena Das", "authors": "Devleena Das, Sonia Chernova", "title": "Leveraging Rationales to Improve Human Task Performance", "comments": "ACM IUI 2020", "journal-ref": null, "doi": "10.1145/3377325.3377512", "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) systems across many application areas are increasingly\ndemonstrating performance that is beyond that of humans. In response to the\nproliferation of such models, the field of Explainable AI (XAI) has sought to\ndevelop techniques that enhance the transparency and interpretability of\nmachine learning methods. In this work, we consider a question not previously\nexplored within the XAI and ML communities: Given a computational system whose\nperformance exceeds that of its human user, can explainable AI capabilities be\nleveraged to improve the performance of the human? We study this question in\nthe context of the game of Chess, for which computational game engines that\nsurpass the performance of the average player are widely available. We\nintroduce the Rationale-Generating Algorithm, an automated technique for\ngenerating rationales for utility-based computational methods, which we\nevaluate with a multi-day user study against two baselines. The results show\nthat our approach produces rationales that lead to statistically significant\nimprovement in human task performance, demonstrating that rationales\nautomatically generated from an AI's internal task model can be used not only\nto explain what the system is doing, but also to instruct the user and\nultimately improve their task performance.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 04:51:35 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Das", "Devleena", ""], ["Chernova", "Sonia", ""]]}, {"id": "2002.04232", "submitter": "Sutanu Gayen", "authors": "Arnab Bhattacharyya, Sutanu Gayen, Saravanan Kandasamy, Ashwin Maran,\n  N. V. Vinodchandran", "title": "Learning and Sampling of Atomic Interventions from Observations", "comments": "26 pages, 4 figures, a version appeared in ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of efficiently estimating the effect of an intervention\non a single variable (atomic interventions) using observational samples in a\ncausal Bayesian network. Our goal is to give algorithms that are efficient in\nboth time and sample complexity in a non-parametric setting.\n  Tian and Pearl (AAAI `02) have exactly characterized the class of causal\ngraphs for which causal effects of atomic interventions can be identified from\nobservational data. We make their result quantitative. Suppose P is a causal\nmodel on a set $\\vec{V}$ of n observable variables with respect to a given\ncausal graph G with observable distribution $P$. Let $P_x$ denote the\ninterventional distribution over the observables with respect to an\nintervention of a designated variable X with x. Assuming that $G$ has bounded\nin-degree, bounded c-components ($k$), and that the observational distribution\nis identifiable and satisfies certain strong positivity condition, we give an\nalgorithm that takes $m=\\tilde{O}(n\\epsilon^{-2})$ samples from $P$ and $O(mn)$\ntime, and outputs with high probability a description of a distribution\n$\\hat{P}$ such that $d_{\\mathrm{TV}}(P_x, \\hat{P}) \\leq \\epsilon$, and:\n  1. [Evaluation] the description can return in $O(n)$ time the probability\n$\\hat{P}(\\vec{v})$ for any assignment $\\vec{v}$ to $\\vec{V}$\n  2. [Generation] the description can return an iid sample from $\\hat{P}$ in\n$O(n)$ time.\n  We also show lower bounds for the sample complexity showing that our sample\ncomplexity has an optimal dependence on the parameters $n$ and $\\epsilon$, as\nwell as if $k=1$ on the strong positivity parameter.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 07:15:32 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 06:11:17 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Bhattacharyya", "Arnab", ""], ["Gayen", "Sutanu", ""], ["Kandasamy", "Saravanan", ""], ["Maran", "Ashwin", ""], ["Vinodchandran", "N. V.", ""]]}, {"id": "2002.04238", "submitter": "Xiangfeng Wang", "authors": "Yun Hua, Xiangfeng Wang, Bo Jin, Wenhao Li, Junchi Yan, Xiaofeng He,\n  Hongyuan Zha", "title": "HMRL: Hyper-Meta Learning for Sparse Reward Reinforcement Learning\n  Problem", "comments": "13 pages", "journal-ref": "Proceedings of the 27th ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of the success of existing meta reinforcement learning methods, they\nstill have difficulty in learning a meta policy effectively for RL problems\nwith sparse reward. In this respect, we develop a novel meta reinforcement\nlearning framework called Hyper-Meta RL(HMRL), for sparse reward RL problems.\nIt is consisted with three modules including the cross-environment meta state\nembedding module which constructs a common meta state space to adapt to\ndifferent environments; the meta state based environment-specific meta reward\nshaping which effectively extends the original sparse reward trajectory by\ncross-environmental knowledge complementarity and as a consequence the meta\npolicy achieves better generalization and efficiency with the shaped meta\nreward. Experiments with sparse-reward environments show the superiority of\nHMRL on both transferability and policy learning efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 07:31:11 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 06:36:21 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Hua", "Yun", ""], ["Wang", "Xiangfeng", ""], ["Jin", "Bo", ""], ["Li", "Wenhao", ""], ["Yan", "Junchi", ""], ["He", "Xiaofeng", ""], ["Zha", "Hongyuan", ""]]}, {"id": "2002.04242", "submitter": "Rui Liu", "authors": "Boyi Song, Yuntao Peng, Ruijiao Luo, Rui Liu", "title": "An Attention Transfer Model for Human-Assisted Failure Avoidance in\n  Robot Manipulations", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to real-world dynamics and hardware uncertainty, robots inevitably fail\nin task executions, resulting in undesired or even dangerous executions. In\norder to avoid failures and improve robot performance, it is critical to\nidentify and correct abnormal robot executions at an early stage. However, due\nto limited reasoning capability and knowledge storage, it is challenging for\nrobots to self-diagnose and -correct their own abnormality in both planning and\nexecuting. To improve robot self diagnosis capability, in this research a novel\nhuman-to-robot attention transfer (\\textit{\\textbf{H2R-AT}}) method was\ndeveloped to identify robot manipulation errors by leveraging human\ninstructions. \\textit{\\textbf{H2R-AT}} was developed by fusing attention\nmapping mechanism into a novel stacked neural networks model, transferring\nhuman verbal attention into robot visual attention. With the attention\ntransfer, a robot understands \\textit{what} and \\textit{where} human concerns\nare to identify and correct abnormal manipulations. Two representative task\nscenarios: ``serve water for a human in a kitchen\" and ``pick up a defective\ngear in a factory\" were designed in a simulation framework CRAIhri with\nabnormal robot manipulations; and $252$ volunteers were recruited to provide\nabout 12000 verbal reminders to learn and test \\textit{\\textbf{H2R-AT}}. The\nmethod effectiveness was validated by the high accuracy of $73.68\\%$ in\ntransferring attention, and the high accuracy of $66.86\\%$ in avoiding grasping\nfailures.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 07:58:48 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 14:56:52 GMT"}, {"version": "v3", "created": "Tue, 29 Jun 2021 14:52:43 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Song", "Boyi", ""], ["Peng", "Yuntao", ""], ["Luo", "Ruijiao", ""], ["Liu", "Rui", ""]]}, {"id": "2002.04306", "submitter": "Philip Arthur", "authors": "Philip Arthur, Trevor Cohn, Gholamreza Haffari", "title": "Learning Coupled Policies for Simultaneous Machine Translation using\n  Imitation Learning", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach to efficiently learn a simultaneous translation\nmodel with coupled programmer-interpreter policies. First, wepresent an\nalgorithmic oracle to produce oracle READ/WRITE actions for training bilingual\nsentence-pairs using the notion of word alignments. This oracle actions are\ndesigned to capture enough information from the partial input before writing\nthe output. Next, we perform a coupled scheduled sampling to effectively\nmitigate the exposure bias when learning both policies jointly with imitation\nlearning. Experiments on six language-pairs show our method outperforms strong\nbaselines in terms of translation quality while keeping the translation delay\nlow.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 10:56:42 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 05:48:24 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Arthur", "Philip", ""], ["Cohn", "Trevor", ""], ["Haffari", "Gholamreza", ""]]}, {"id": "2002.04326", "submitter": "Weihao Yu", "authors": "Weihao Yu, Zihang Jiang, Yanfei Dong, Jiashi Feng", "title": "ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning", "comments": "ICLR 2020 paper. Project page: http://whyu.me/reclor/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent powerful pre-trained language models have achieved remarkable\nperformance on most of the popular datasets for reading comprehension. It is\ntime to introduce more challenging datasets to push the development of this\nfield towards more comprehensive reasoning of text. In this paper, we introduce\na new Reading Comprehension dataset requiring logical reasoning (ReClor)\nextracted from standardized graduate admission examinations. As earlier studies\nsuggest, human-annotated datasets usually contain biases, which are often\nexploited by models to achieve high accuracy without truly understanding the\ntext. In order to comprehensively evaluate the logical reasoning ability of\nmodels on ReClor, we propose to identify biased data points and separate them\ninto EASY set while the rest as HARD set. Empirical results show that\nstate-of-the-art models have an outstanding ability to capture biases contained\nin the dataset with high accuracy on EASY set. However, they struggle on HARD\nset with poor performance near that of random guess, indicating more research\nis needed to essentially enhance the logical reasoning ability of current\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 11:54:29 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 09:23:26 GMT"}, {"version": "v3", "created": "Sat, 22 Aug 2020 07:14:30 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Yu", "Weihao", ""], ["Jiang", "Zihang", ""], ["Dong", "Yanfei", ""], ["Feng", "Jiashi", ""]]}, {"id": "2002.04335", "submitter": "Eren Sezener", "authors": "Eren Sezener and Peter Dayan", "title": "Static and Dynamic Values of Computation in MCTS", "comments": "Presented in UAI 2020", "journal-ref": "PMLR 124:31-40, 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte-Carlo Tree Search (MCTS) is one of the most-widely used methods for\nplanning, and has powered many recent advances in artificial intelligence. In\nMCTS, one typically performs computations (i.e., simulations) to collect\nstatistics about the possible future consequences of actions, and then chooses\naccordingly. Many popular MCTS methods such as UCT and its variants decide\nwhich computations to perform by trading-off exploration and exploitation. In\nthis work, we take a more direct approach, and explicitly quantify the value of\na computation based on its expected impact on the quality of the action\neventually chosen. Our approach goes beyond the \"myopic\" limitations of\nexisting computation-value-based methods in two senses: (I) we are able to\naccount for the impact of non-immediate (ie, future) computations (II) on\nnon-immediate actions. We show that policies that greedily optimize computation\nvalues are optimal under certain assumptions and obtain results that are\ncompetitive with the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 12:05:58 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 12:28:19 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Sezener", "Eren", ""], ["Dayan", "Peter", ""]]}, {"id": "2002.04477", "submitter": "Ricardo Monge", "authors": "Osvaldo Skliar, Sherry Gapper, Ricardo E. Monge", "title": "A One-to-One Correspondence between Natural Numbers and Binary Trees", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A characterization is provided for each natural number except one (1) by\nmeans of an ordered pair of elements. The first element is a natural number\ncalled the type of the natural number characterized, and the second is a\nnatural number called the order of the number characterized within those of its\ntype. A one-to-one correspondence is specified between the set of binary trees\nsuch that a) a given node has no child nodes (that is, it is a terminal node),\nor b) it has exactly two child nodes. Thus, binary trees such that one of their\nparent nodes has only one child node are excluded from the set considered here.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 03:00:36 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 01:43:15 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Skliar", "Osvaldo", ""], ["Gapper", "Sherry", ""], ["Monge", "Ricardo E.", ""]]}, {"id": "2002.04676", "submitter": "Dmitrii Beloborodov", "authors": "Dmitrii Beloborodov (1), A. E. Ulanov (1), Jakob N. Foerster (2),\n  Shimon Whiteson (2), A. I. Lvovsky (1 and 2) ((1) Russian Quantum Center, (2)\n  University of Oxford)", "title": "Reinforcement Learning Enhanced Quantum-inspired Algorithm for\n  Combinatorial Optimization", "comments": "Submitted to ICML 2020. 9 pages, 3 pdf figures. V2: fixed\n  acknowledgements", "journal-ref": "Machine Learning: Science and Technology, 2, 025009 (2021)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum hardware and quantum-inspired algorithms are becoming increasingly\npopular for combinatorial optimization. However, these algorithms may require\ncareful hyperparameter tuning for each problem instance. We use a reinforcement\nlearning agent in conjunction with a quantum-inspired algorithm to solve the\nIsing energy minimization problem, which is equivalent to the Maximum Cut\nproblem. The agent controls the algorithm by tuning one of its parameters with\nthe goal of improving recently seen solutions. We propose a new Rescaled Ranked\nReward (R3) method that enables stable single-player version of self-play\ntraining that helps the agent to escape local optima. The training on any\nproblem instance can be accelerated by applying transfer learning from an agent\ntrained on randomly generated problems. Our approach allows sampling\nhigh-quality solutions to the Ising problem with high probability and\noutperforms both baseline heuristics and a black-box hyperparameter\noptimization approach.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 20:55:07 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 19:47:49 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Beloborodov", "Dmitrii", "", "1 and 2"], ["Ulanov", "A. E.", "", "1 and 2"], ["Foerster", "Jakob N.", "", "1 and 2"], ["Whiteson", "Shimon", "", "1 and 2"], ["Lvovsky", "A. I.", "", "1 and 2"]]}, {"id": "2002.04711", "submitter": "Said Hanafi", "authors": "Fred Glover, Said Hanafi, and Gintaras Palubeckis", "title": "Bi-objective Optimization of Biclustering with Binary Data", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DM math.CO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering consists of partitioning data objects into subsets called clusters\naccording to some similarity criteria. This paper addresses a generalization\ncalled quasi-clustering that allows overlapping of clusters, and which we link\nto biclustering. Biclustering simultaneously groups the objects and features so\nthat a specific group of objects has a special group of features. In recent\nyears, biclustering has received a lot of attention in several practical\napplications. In this paper we consider a bi-objective optimization of\nbiclustering problem with binary data. First we present an integer programing\nformulations for the bi-objective optimization biclustering. Next we propose a\nconstructive heuristic based on the set intersection operation and its\nefficient implementation for solving a series of mono-objective problems used\ninside the Epsilon-constraint method (obtained by keeping only one objective\nfunction and the other objective function is integrated into constraints).\nFinally, our experimental results show that using CPLEX solver as an exact\nalgorithm for finding an optimal solution drastically increases the\ncomputational cost for large instances, while our proposed heuristic provides\nvery good results and significantly reduces the computational expense.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 21:49:26 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Glover", "Fred", ""], ["Hanafi", "Said", ""], ["Palubeckis", "Gintaras", ""]]}, {"id": "2002.04733", "submitter": "Megan Charity", "authors": "Megan Charity, Michael Cerny Green, Ahmed Khalifa, Julian Togelius", "title": "Mech-Elites: Illuminating the Mechanic Space of GVGAI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a fully automatic method of mechanic illumination for\ngeneral video game level generation. Using the Constrained MAP-Elites algorithm\nand the GVG-AI framework, this system generates the simplest tile based levels\nthat contain specific sets of game mechanics and also satisfy playability\nconstraints. We apply this method to illuminate mechanic space for $4$\ndifferent games in GVG-AI: Zelda, Solarfox, Plants, and RealPortals.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 23:40:09 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Charity", "Megan", ""], ["Green", "Michael Cerny", ""], ["Khalifa", "Ahmed", ""], ["Togelius", "Julian", ""]]}, {"id": "2002.04734", "submitter": "Sam Ganzfried", "authors": "Sam Ganzfried", "title": "Fast Complete Algorithm for Multiplayer Nash Equilibrium", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA econ.TH math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new complete algorithm for computing Nash equilibrium in\nmultiplayer general-sum games, based on a quadratically-constrained feasibility\nprogram formulation. We demonstrate that the algorithm runs significantly\nfaster than the prior fastest complete algorithm on several game classes\npreviously studied and that its runtimes even outperform the best incomplete\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 23:42:14 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 19:14:48 GMT"}, {"version": "v3", "created": "Fri, 22 May 2020 06:00:01 GMT"}, {"version": "v4", "created": "Tue, 26 May 2020 01:59:58 GMT"}, {"version": "v5", "created": "Fri, 5 Jun 2020 21:23:10 GMT"}, {"version": "v6", "created": "Mon, 27 Jul 2020 05:49:22 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Ganzfried", "Sam", ""]]}, {"id": "2002.04758", "submitter": "Tao Yu", "authors": "Tao Yu, Eugene Bagdasaryan, Vitaly Shmatikov", "title": "Salvaging Federated Learning by Local Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a heavily promoted approach for training ML models\non sensitive data, e.g., text typed by users on their smartphones. FL is\nexpressly designed for training on data that are unbalanced and non-iid across\nthe participants. To ensure privacy and integrity of the federated model,\nlatest FL approaches use differential privacy or robust aggregation to limit\nthe influence of \"outlier\" participants.\n  First, we show that on standard tasks such as next-word prediction, many\nparticipants gain no benefit from FL because the federated model is less\naccurate on their data than the models they can train locally on their own.\nSecond, we show that differential privacy and robust aggregation make this\nproblem worse by further destroying the accuracy of the federated model for\nmany participants.\n  Then, we evaluate three techniques for local adaptation of federated models:\nfine-tuning, multi-task learning, and knowledge distillation. We analyze where\neach technique is applicable and demonstrate that all participants benefit from\nlocal adaptation. Participants whose local models are poor obtain big accuracy\nimprovements over conventional FL. Participants whose local models are better\nthan the federated model and who have no incentive to participate in FL today\nimprove less, but sufficiently to make the adapted federated model better than\ntheir local models.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 01:56:16 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Yu", "Tao", ""], ["Bagdasaryan", "Eugene", ""], ["Shmatikov", "Vitaly", ""]]}, {"id": "2002.04793", "submitter": "Qi Zhu", "authors": "Qi Zhu, Zheng Zhang, Yan Fang, Xiang Li, Ryuichi Takanobu, Jinchao Li,\n  Baolin Peng, Jianfeng Gao, Xiaoyan Zhu, Minlie Huang", "title": "ConvLab-2: An Open-Source Toolkit for Building, Evaluating, and\n  Diagnosing Dialogue Systems", "comments": "Accepted by ACL 2020 demo track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ConvLab-2, an open-source toolkit that enables researchers to\nbuild task-oriented dialogue systems with state-of-the-art models, perform an\nend-to-end evaluation, and diagnose the weakness of systems. As the successor\nof ConvLab (Lee et al., 2019b), ConvLab-2 inherits ConvLab's framework but\nintegrates more powerful dialogue models and supports more datasets. Besides,\nwe have developed an analysis tool and an interactive tool to assist\nresearchers in diagnosing dialogue systems. The analysis tool presents rich\nstatistics and summarizes common mistakes from simulated dialogues, which\nfacilitates error analysis and system improvement. The interactive tool\nprovides a user interface that allows developers to diagnose an assembled\ndialogue system by interacting with the system and modifying the output of each\nsystem component.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 04:31:40 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 14:02:43 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Zhu", "Qi", ""], ["Zhang", "Zheng", ""], ["Fang", "Yan", ""], ["Li", "Xiang", ""], ["Takanobu", "Ryuichi", ""], ["Li", "Jinchao", ""], ["Peng", "Baolin", ""], ["Gao", "Jianfeng", ""], ["Zhu", "Xiaoyan", ""], ["Huang", "Minlie", ""]]}, {"id": "2002.04806", "submitter": "Terrence Sejnowski", "authors": "Terrence J. Sejnowski", "title": "The Unreasonable Effectiveness of Deep Learning in Artificial\n  Intelligence", "comments": null, "journal-ref": "Proceedings of the National Academy of Sciences U.S.A. (2020)\n  https://www.pnas.org/content/early/2020/01/23/1907373117", "doi": "10.1073/pnas.1907373117", "report-no": null, "categories": "q-bio.NC cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning networks have been trained to recognize speech, caption\nphotographs and translate text between languages at high levels of performance.\nAlthough applications of deep learning networks to real world problems have\nbecome ubiquitous, our understanding of why they are so effective is lacking.\nThese empirical results should not be possible according to sample complexity\nin statistics and non-convex optimization theory. However, paradoxes in the\ntraining and effectiveness of deep learning networks are being investigated and\ninsights are being found in the geometry of high-dimensional spaces. A\nmathematical theory of deep learning would illuminate how they function, allow\nus to assess the strengths and weaknesses of different network architectures\nand lead to major improvements. Deep learning has provided natural ways for\nhumans to communicate with digital devices and is foundational for building\nartificial general intelligence. Deep learning was inspired by the architecture\nof the cerebral cortex and insights into autonomy and general intelligence may\nbe found in other brain regions that are essential for planning and survival,\nbut major breakthroughs will be needed to achieve these goals.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 05:25:15 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Sejnowski", "Terrence J.", ""]]}, {"id": "2002.04827", "submitter": "Alessandro Antonucci", "authors": "Alessandro Antonucci and Thomas Tiotto", "title": "Approximate MMAP by Marginal Search", "comments": "To be presented at the 33rd International Florida Artificial\n  Intelligence Research Society Conference (Flairs-33)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a heuristic strategy for marginal MAP (MMAP) queries in graphical\nmodels. The algorithm is based on a reduction of the task to a polynomial\nnumber of marginal inference computations. Given an input evidence, the\nmarginals mass functions of the variables to be explained are computed.\nMarginal information gain is used to decide the variables to be explained\nfirst, and their most probable marginal states are consequently moved to the\nevidence. The sequential iteration of this procedure leads to a MMAP\nexplanation and the minimum information gain obtained during the process can be\nregarded as a confidence measure for the explanation. Preliminary experiments\nshow that the proposed confidence measure is properly detecting instances for\nwhich the algorithm is accurate and, for sufficiently high confidence levels,\nthe algorithm gives the exact solution or an approximation whose Hamming\ndistance from the exact one is small.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 07:41:13 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Antonucci", "Alessandro", ""], ["Tiotto", "Thomas", ""]]}, {"id": "2002.04833", "submitter": "Smitha Milli", "authors": "Hong Jun Jeon, Smitha Milli, Anca D. Dragan", "title": "Reward-rational (implicit) choice: A unifying formalism for reward\n  learning", "comments": "Published at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is often difficult to hand-specify what the correct reward function is for\na task, so researchers have instead aimed to learn reward functions from human\nbehavior or feedback. The types of behavior interpreted as evidence of the\nreward function have expanded greatly in recent years. We've gone from\ndemonstrations, to comparisons, to reading into the information leaked when the\nhuman is pushing the robot away or turning it off. And surely, there is more to\ncome. How will a robot make sense of all these diverse types of behavior? Our\nkey insight is that different types of behavior can be interpreted in a single\nunifying formalism - as a reward-rational choice that the human is making,\noften implicitly. The formalism offers both a unifying lens with which to view\npast work, as well as a recipe for interpreting new sources of information that\nare yet to be uncovered. We provide two examples to showcase this: interpreting\na new feedback type, and reading into how the choice of feedback itself leaks\ninformation about the reward.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 08:07:49 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 18:21:03 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 05:17:25 GMT"}, {"version": "v4", "created": "Fri, 11 Dec 2020 17:56:03 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Jeon", "Hong Jun", ""], ["Milli", "Smitha", ""], ["Dragan", "Anca D.", ""]]}, {"id": "2002.04850", "submitter": "Luca Elias Sch\\\"afer", "authors": "Luca E. Sch\\\"afer, Tobias Dietz, Maria Barbati, Jos\\'e Rui Figueira,\n  Salvatore Greco, Stefan Ruzika", "title": "The {0,1}-knapsack problem with qualitative levels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variant of the classical knapsack problem is considered in which each item\nis associated with an integer weight and a qualitative level. We define a\ndominance relation over the feasible subsets of the given item set and show\nthat this relation defines a preorder. We propose a dynamic programming\nalgorithm to compute the entire set of non-dominated rank cardinality vectors\nand we state two greedy algorithms, which efficiently compute a single\nefficient solution.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 09:00:29 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Sch\u00e4fer", "Luca E.", ""], ["Dietz", "Tobias", ""], ["Barbati", "Maria", ""], ["Figueira", "Jos\u00e9 Rui", ""], ["Greco", "Salvatore", ""], ["Ruzika", "Stefan", ""]]}, {"id": "2002.04852", "submitter": "Jorn Op Den Buijs", "authors": "Cliff Laschet, Jorn op den Buijs, Mark H. M. Winands, Steffen Pauws", "title": "Service Selection using Predictive Models and Monte-Carlo Tree Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes a method for automated service selection to improve\ntreatment efficacy and reduce re-hospitalization costs. A predictive model is\ndeveloped using the National Home and Hospice Care Survey (NHHCS) dataset to\nquantify the effect of care services on the risk of re-hospitalization. By\ntaking the patient's characteristics and other selected services into account,\nthe model is able to indicate the overall effectiveness of a combination of\nservices for a specific NHHCS patient. The developed model is incorporated in\nMonte-Carlo Tree Search (MCTS) to determine optimal combinations of services\nthat minimize the risk of emergency re-hospitalization. MCTS serves as a risk\nminimization algorithm in this case, using the predictive model for guidance\nduring the search. Using this method on the NHHCS dataset, a significant\nreduction in risk of re-hospitalization is observed compared to the original\nselections made by clinicians. An 11.89 percentage points risk reduction is\nachieved on average. Higher reductions of roughly 40 percentage points on\naverage are observed for NHHCS patients in the highest risk categories. These\nresults seem to indicate that there is enormous potential for improving service\nselection in the near future.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 09:04:30 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Laschet", "Cliff", ""], ["Buijs", "Jorn op den", ""], ["Winands", "Mark H. M.", ""], ["Pauws", "Steffen", ""]]}, {"id": "2002.04862", "submitter": "Andr\\'e Artelt", "authors": "Andr\\'e Artelt, Barbara Hammer", "title": "Convex Density Constraints for Computing Plausible Counterfactual\n  Explanations", "comments": "Accepted at ICANN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing deployment of machine learning as well as legal regulations\nsuch as EU's GDPR cause a need for user-friendly explanations of decisions\nproposed by machine learning models. Counterfactual explanations are considered\nas one of the most popular techniques to explain a specific decision of a\nmodel. While the computation of \"arbitrary\" counterfactual explanations is well\nstudied, it is still an open research problem how to efficiently compute\nplausible and feasible counterfactual explanations. We build upon recent work\nand propose and study a formal definition of plausible counterfactual\nexplanations. In particular, we investigate how to use density estimators for\nenforcing plausibility and feasibility of counterfactual explanations. For the\npurpose of efficient computations, we propose convex density constraints that\nensure that the resulting counterfactual is located in a region of the data\nspace of high density.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 09:23:42 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 08:14:22 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Artelt", "Andr\u00e9", ""], ["Hammer", "Barbara", ""]]}, {"id": "2002.04936", "submitter": "Wei Shi", "authors": "Wei Shi, Siyuan Zhang, Zhiwei Zhang, Hong Cheng, Jeffrey Xu Yu", "title": "Joint Embedding in Named Entity Linking on Sentence Level", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entity linking is to map an ambiguous mention in documents to an entity\nin a knowledge base. The named entity linking is challenging, given the fact\nthat there are multiple candidate entities for a mention in a document. It is\ndifficult to link a mention when it appears multiple times in a document, since\nthere are conflicts by the contexts around the appearances of the mention. In\naddition, it is difficult since the given training dataset is small due to the\nreason that it is done manually to link a mention to its mapping entity. In the\nliterature, there are many reported studies among which the recent embedding\nmethods learn vectors of entities from the training dataset at document level.\nTo address these issues, we focus on how to link entity for mentions at a\nsentence level, which reduces the noises introduced by different appearances of\nthe same mention in a document at the expense of insufficient information to be\nused. We propose a new unified embedding method by maximizing the relationships\nlearned from knowledge graphs. We confirm the effectiveness of our method in\nour experimental studies.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 12:06:32 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Shi", "Wei", ""], ["Zhang", "Siyuan", ""], ["Zhang", "Zhiwei", ""], ["Cheng", "Hong", ""], ["Yu", "Jeffrey Xu", ""]]}, {"id": "2002.04991", "submitter": "Maximilian Weininger", "authors": "Pranav Ashok, Mathias Jackermeier, Pushpak Jagtap, Jan\n  K\\v{r}et\\'insk\\'y, Maximilian Weininger, Majid Zamani", "title": "dtControl: Decision Tree Learning Algorithms for Controller\n  Representation", "comments": null, "journal-ref": null, "doi": "10.1145/3365365.3383468", "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision tree learning is a popular classification technique most commonly\nused in machine learning applications. Recent work has shown that decision\ntrees can be used to represent provably-correct controllers concisely. Compared\nto representations using lookup tables or binary decision diagrams, decision\ntrees are smaller and more explainable. We present dtControl, an easily\nextensible tool for representing memoryless controllers as decision trees. We\ngive a comprehensive evaluation of various decision tree learning algorithms\napplied to 10 case studies arising out of correct-by-construction controller\nsynthesis. These algorithms include two new techniques, one for using arbitrary\nlinear binary classifiers in the decision tree learning, and one novel approach\nfor determinizing controllers during the decision tree construction. In\nparticular the latter turns out to be extremely efficient, yielding decision\ntrees with a single-digit number of decision nodes on 5 of the case studies.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 17:13:17 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Ashok", "Pranav", ""], ["Jackermeier", "Mathias", ""], ["Jagtap", "Pushpak", ""], ["K\u0159et\u00ednsk\u00fd", "Jan", ""], ["Weininger", "Maximilian", ""], ["Zamani", "Majid", ""]]}, {"id": "2002.05063", "submitter": "Alessandro Antonucci", "authors": "Francesca Mangili and Denis Broggini and Alessandro Antonucci and\n  Marco Alberti and Lorenzo Cimasoni", "title": "A Bayesian Approach to Conversational Recommendation Systems", "comments": "Accepted for oral presentation at the \\emph{AAAI 2020 Workshop on\n  Interactive and Conversational Recommendation Systems} (WICRS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a conversational recommendation system based on a Bayesian\napproach. A probability mass function over the items is updated after any\ninteraction with the user, with information-theoretic criteria optimally\nshaping the interaction and deciding when the conversation should be terminated\nand the most probable item consequently recommended. Dedicated elicitation\ntechniques for the prior probabilities of the parameters modeling the\ninteractions are derived from basic structural judgements. Such prior\ninformation can be combined with historical data to discriminate items with\ndifferent recommendation histories. A case study based on the application of\nthis approach to \\emph{stagend.com}, an online platform for booking\nentertainers, is finally discussed together with an empirical analysis showing\nthe advantages in terms of recommendation quality and efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 15:59:31 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Mangili", "Francesca", ""], ["Broggini", "Denis", ""], ["Antonucci", "Alessandro", ""], ["Alberti", "Marco", ""], ["Cimasoni", "Lorenzo", ""]]}, {"id": "2002.05083", "submitter": "Merlin Carl", "authors": "Merlin Carl", "title": "Using Automated Theorem Provers for Mistake Diagnosis in the Didactics\n  of Mathematics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Diproche system, an automated proof checker for natural language proofs\nspecifically adapted to the context of exercises for beginner's students\nsimilar to the Naproche system by Koepke, Schr\\\"oder, Cramer and others, uses a\nmodification of an automated theorem prover which uses common formal fallacies\nintead of sound deduction rules for mistake diagnosis. We briefly describe the\nconcept of such an `Anti-ATP' and explain the basic techniques used in its\nimplementation.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 16:36:59 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Carl", "Merlin", ""]]}, {"id": "2002.05120", "submitter": "Jason Jo", "authors": "Giulia Zarpellon, Jason Jo, Andrea Lodi and Yoshua Bengio", "title": "Parameterizing Branch-and-Bound Search Trees to Learn Branching Policies", "comments": "AAAI 2021 camera-ready version with supplementary materials, improved\n  readability of figures in main article. Code, data and trained models are\n  available at https://github.com/ds4dm/branch-search-trees", "journal-ref": "Proceedings of the AAAI Conference on Artificial Intelligence\n  2021, 35(5), 3931-3939", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Branch and Bound (B&B) is the exact tree search method typically used to\nsolve Mixed-Integer Linear Programming problems (MILPs). Learning branching\npolicies for MILP has become an active research area, with most works proposing\nto imitate the strong branching rule and specialize it to distinct classes of\nproblems. We aim instead at learning a policy that generalizes across\nheterogeneous MILPs: our main hypothesis is that parameterizing the state of\nthe B&B search tree can aid this type of generalization. We propose a novel\nimitation learning framework, and introduce new input features and\narchitectures to represent branching. Experiments on MILP benchmark instances\nclearly show the advantages of incorporating an explicit parameterization of\nthe state of the search tree to modulate the branching decisions, in terms of\nboth higher accuracy and smaller B&B trees. The resulting policies\nsignificantly outperform the current state-of-the-art method for \"learning to\nbranch\" by effectively allowing generalization to generic unseen instances.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 17:43:23 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 20:32:08 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 18:30:16 GMT"}, {"version": "v4", "created": "Wed, 2 Jun 2021 20:11:03 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Zarpellon", "Giulia", ""], ["Jo", "Jason", ""], ["Lodi", "Andrea", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2002.05131", "submitter": "Justin Kopinsky", "authors": "Erik Demaine and Justin Kopinsky and Jayson Lynch", "title": "Recursed is not Recursive: A Jarring Result", "comments": "Submitted to MFCS2020, 21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recursed is a 2D puzzle platform video game featuring treasure chests that,\nwhen jumped into, instantiate a room that can later be exited (similar to\nfunction calls), optionally generating a jar that returns back to that room\n(similar to continuations). We prove that Recursed is RE-complete and thus\nundecidable (not recursive) by a reduction from the Post Correspondence\nProblem. Our reduction is \"practical\": the reduction from PCP results in fully\nplayable levels that abide by all constraints governing levels (including the\n15x20 room size) designed for the main game. Our reduction is also \"efficient\":\na Turing machine can be simulated by a Recursed level whose size is linear in\nthe encoding size of the Turing machine and whose solution length is polynomial\nin the running time of the Turing machine.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 18:20:37 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 15:17:11 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Demaine", "Erik", ""], ["Kopinsky", "Justin", ""], ["Lynch", "Jayson", ""]]}, {"id": "2002.05149", "submitter": "Daniel Elton", "authors": "Daniel C. Elton", "title": "Self-explaining AI as an alternative to interpretable AI", "comments": "10pgs, 2 column format", "journal-ref": null, "doi": "10.1007/978-3-030-52152-3_10", "report-no": null, "categories": "cs.AI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to explain decisions made by AI systems is highly sought after,\nespecially in domains where human lives are at stake such as medicine or\nautonomous vehicles. While it is often possible to approximate the input-output\nrelations of deep neural networks with a few human-understandable rules, the\ndiscovery of the double descent phenomena suggests that such approximations do\nnot accurately capture the mechanism by which deep neural networks work. Double\ndescent indicates that deep neural networks typically operate by smoothly\ninterpolating between data points rather than by extracting a few high level\nrules. As a result, neural networks trained on complex real world data are\ninherently hard to interpret and prone to failure if asked to extrapolate. To\nshow how we might be able to trust AI despite these problems we introduce the\nconcept of self-explaining AI. Self-explaining AIs are capable of providing a\nhuman-understandable explanation of each decision along with confidence levels\nfor both the decision and explanation. For this approach to work, it is\nimportant that the explanation actually be related to the decision, ideally\ncapturing the mechanism used to arrive at the explanation. Finally, we argue it\nis important that deep learning based systems include a \"warning light\" based\non techniques from applicability domain analysis to warn the user if a model is\nasked to extrapolate outside its training distribution. For a video\npresentation of this talk see https://www.youtube.com/watch?v=Py7PVdcu7WY& .\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 18:50:11 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 17:13:25 GMT"}, {"version": "v3", "created": "Sat, 29 Feb 2020 18:56:25 GMT"}, {"version": "v4", "created": "Fri, 24 Apr 2020 15:26:15 GMT"}, {"version": "v5", "created": "Wed, 17 Jun 2020 13:38:58 GMT"}, {"version": "v6", "created": "Thu, 2 Jul 2020 19:03:24 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Elton", "Daniel C.", ""]]}, {"id": "2002.05156", "submitter": "Matteo Castiglioni", "authors": "Matteo Castiglioni, Andrea Celli, Nicola Gatti", "title": "Public Bayesian Persuasion: Being Almost Optimal and Almost Persuasive", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persuasion studies how an informed principal may influence the behavior of\nagents by the strategic provision of payoff-relevant information. We focus on\nthe fundamental multi-receiver model by Arieli and Babichenko (2019), in which\nthere are no inter-agent externalities. Unlike prior works on this problem, we\nstudy the public persuasion problem in the general setting with: (i) arbitrary\nstate spaces; (ii) arbitrary action spaces; (iii) arbitrary sender's utility\nfunctions. We fully characterize the computational complexity of computing a\nbi-criteria approximation of an optimal public signaling scheme. In particular,\nwe show, in a voting setting of independent interest, that solving this problem\nrequires at least a quasi-polynomial number of steps even in settings with a\nbinary action space, assuming the Exponential Time Hypothesis. In doing so, we\nprove that a relaxed version of the Maximum Feasible Subsystem of Linear\nInequalities problem requires at least quasi-polynomial time to be solved.\nFinally, we close the gap by providing a quasi-polynomial time bi-criteria\napproximation algorithm for arbitrary public persuasion problems that, in\nspecific settings, yields a QPTAS.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 18:59:18 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 13:26:27 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Castiglioni", "Matteo", ""], ["Celli", "Andrea", ""], ["Gatti", "Nicola", ""]]}, {"id": "2002.05160", "submitter": "Mathilde Fekom", "authors": "Mathilde Fekom, Nicolas Vayatis, Argyris Kalogeratos", "title": "Optimal Multiple Stopping Rule for Warm-Starting Sequential Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the Warm-starting Dynamic Thresholding algorithm,\ndeveloped using dynamic programming, for a variant of the standard online\nselection problem. The problem allows job positions to be either free or\nalready occupied at the beginning of the process. Throughout the selection\nprocess, the decision maker interviews one after the other the new candidates\nand reveals a quality score for each of them. Based on that information, she\ncan (re)assign each job at most once by taking immediate and irrevocable\ndecisions. We relax the hard requirement of the class of dynamic programming\nalgorithms to perfectly know the distribution from which the scores of\ncandidates are drawn, by presenting extensions for the partial and\nno-information cases, in which the decision maker can learn the underlying\nscore distribution sequentially while interviewing candidates.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 14:04:43 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Fekom", "Mathilde", ""], ["Vayatis", "Nicolas", ""], ["Kalogeratos", "Argyris", ""]]}, {"id": "2002.05189", "submitter": "Rohan Chitnis", "authors": "Rohan Chitnis, Shubham Tulsiani, Saurabh Gupta, Abhinav Gupta", "title": "Intrinsic Motivation for Encouraging Synergistic Behavior", "comments": "ICLR 2020 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the role of intrinsic motivation as an exploration bias for\nreinforcement learning in sparse-reward synergistic tasks, which are tasks\nwhere multiple agents must work together to achieve a goal they could not\nindividually. Our key idea is that a good guiding principle for intrinsic\nmotivation in synergistic tasks is to take actions which affect the world in\nways that would not be achieved if the agents were acting on their own. Thus,\nwe propose to incentivize agents to take (joint) actions whose effects cannot\nbe predicted via a composition of the predicted effect for each individual\nagent. We study two instantiations of this idea, one based on the true states\nencountered, and another based on a dynamics model trained concurrently with\nthe policy. While the former is simpler, the latter has the benefit of being\nanalytically differentiable with respect to the action taken. We validate our\napproach in robotic bimanual manipulation and multi-agent locomotion tasks with\nsparse rewards; we find that our approach yields more efficient learning than\nboth 1) training with only the sparse reward and 2) using the typical\nsurprise-based formulation of intrinsic motivation, which does not bias toward\nsynergistic behavior. Videos are available on the project webpage:\nhttps://sites.google.com/view/iclr2020-synergistic.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 19:34:51 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Chitnis", "Rohan", ""], ["Tulsiani", "Shubham", ""], ["Gupta", "Saurabh", ""], ["Gupta", "Abhinav", ""]]}, {"id": "2002.05190", "submitter": "Andrea Celli", "authors": "Matteo Castiglioni, Andrea Celli, Alberto Marchesi, Nicola Gatti", "title": "Signaling in Bayesian Network Congestion Games: the Subtle Power of\n  Symmetry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network congestion games are a well-understood model of multi-agent strategic\ninteractions. Despite their ubiquitous applications, it is not clear whether it\nis possible to design information structures to ameliorate the overall\nexperience of the network users. We focus on Bayesian games with atomic\nplayers, where network vagaries are modeled via a (random) state of nature\nwhich determines the costs incurred by the players. A third-party entity---the\nsender---can observe the realized state of the network and exploit this\nadditional information to send a signal to each player. A natural question is\nthe following: is it possible for an informed sender to reduce the overall\nsocial cost via the strategic provision of information to players who update\ntheir beliefs rationally? The paper focuses on the problem of computing optimal\nex ante persuasive signaling schemes, showing that symmetry is a crucial\nproperty for its solution. Indeed, we show that an optimal ex ante persuasive\nsignaling scheme can be computed in polynomial time when players are symmetric\nand have affine cost functions. Moreover, the problem becomes NP-hard when\nplayers are asymmetric, even in non-Bayesian settings.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 19:38:15 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Castiglioni", "Matteo", ""], ["Celli", "Andrea", ""], ["Marchesi", "Alberto", ""], ["Gatti", "Nicola", ""]]}, {"id": "2002.05196", "submitter": "Jasper De Bock", "authors": "Jasper De Bock", "title": "Archimedean Choice Functions: an Axiomatic Foundation for Imprecise\n  Decision Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If uncertainty is modelled by a probability measure, decisions are typically\nmade by choosing the option with the highest expected utility. If an imprecise\nprobability model is used instead, this decision rule can be generalised in\nseveral ways. We here focus on two such generalisations that apply to sets of\nprobability measures: E-admissibility and maximality. Both of them can be\nregarded as special instances of so-called choice functions, a very general\nmathematical framework for decision making. For each of these two decision\nrules, we provide a set of necessary and sufficient conditions on choice\nfunctions that uniquely characterises this rule, thereby providing an axiomatic\nfoundation for imprecise decision making with sets of probabilities. A\nrepresentation theorem for Archimedean choice functions in terms of coherent\nlower previsions lies at the basis of both results.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 19:44:08 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 12:50:12 GMT"}, {"version": "v3", "created": "Wed, 25 Mar 2020 19:39:57 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["De Bock", "Jasper", ""]]}, {"id": "2002.05205", "submitter": "Gabriel Terejanu", "authors": "Gabriel Terejanu, Jawad Chowdhury, Rezaur Rashid, Asif Chowdhury", "title": "Explainable Deep Modeling of Tabular Data using TableGraphNet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vast majority of research on explainability focuses on\npost-explainability rather than explainable modeling. Namely, an explanation\nmodel is derived to explain a complex black box model built with the sole\npurpose of achieving the highest performance possible. In part, this trend\nmight be driven by the misconception that there is a trade-off between\nexplainability and accuracy. Furthermore, the consequential work on Shapely\nvalues, grounded in game theory, has also contributed to a new wave of\npost-explainability research on better approximations for various machine\nlearning models, including deep learning models. We propose a new architecture\nthat inherently produces explainable predictions in the form of additive\nfeature attributions. Our approach learns a graph representation for each\nrecord in the dataset. Attribute centric features are then derived from the\ngraph and fed into a contribution deep set model to produce the final\npredictions. We show that our explainable model attains the same level of\nperformance as black box models. Finally, we provide an augmented model\ntraining approach that leverages the missingness property and yields high\nlevels of consistency (as required for the Shapely values) without loss of\naccuracy.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 20:02:10 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Terejanu", "Gabriel", ""], ["Chowdhury", "Jawad", ""], ["Rashid", "Rezaur", ""], ["Chowdhury", "Asif", ""]]}, {"id": "2002.05229", "submitter": "Ge Liu", "authors": "Ge Liu, Rui Wu, Heng-Tze Cheng, Jing Wang, Jayden Ooi, Lihong Li, Ang\n  Li, Wai Lok Sibon Li, Craig Boutilier, Ed Chi", "title": "Data Efficient Training for Reinforcement Learning with Adaptive\n  Behavior Policy Sharing", "comments": "on Deep Reinforcement Learning workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep Reinforcement Learning (RL) is proven powerful for decision making in\nsimulated environments. However, training deep RL model is challenging in real\nworld applications such as production-scale health-care or recommender systems\nbecause of the expensiveness of interaction and limitation of budget at\ndeployment. One aspect of the data inefficiency comes from the expensive\nhyper-parameter tuning when optimizing deep neural networks. We propose\nAdaptive Behavior Policy Sharing (ABPS), a data-efficient training algorithm\nthat allows sharing of experience collected by behavior policy that is\nadaptively selected from a pool of agents trained with an ensemble of\nhyper-parameters. We further extend ABPS to evolve hyper-parameters during\ntraining by hybridizing ABPS with an adapted version of Population Based\nTraining (ABPS-PBT). We conduct experiments with multiple Atari games with up\nto 16 hyper-parameter/architecture setups. ABPS achieves superior overall\nperformance, reduced variance on top 25% agents, and equivalent performance on\nthe best agent compared to conventional hyper-parameter tuning with independent\ntraining, even though ABPS only requires the same number of environmental\ninteractions as training a single agent. We also show that ABPS-PBT further\nimproves the convergence speed and reduces the variance.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 20:35:31 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Liu", "Ge", ""], ["Wu", "Rui", ""], ["Cheng", "Heng-Tze", ""], ["Wang", "Jing", ""], ["Ooi", "Jayden", ""], ["Li", "Lihong", ""], ["Li", "Ang", ""], ["Li", "Wai Lok Sibon", ""], ["Boutilier", "Craig", ""], ["Chi", "Ed", ""]]}, {"id": "2002.05233", "submitter": "Emanuele Pesce Mr.", "authors": "Emanuele Pesce, Giovanni Montana", "title": "Learning Multi-Agent Coordination through Graph-driven Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the problem of learning collaborative behaviour through\ncommunication in multi-agent systems using deep reinforcement learning. A\nconnectivity-driven communication (CDC) algorithm is proposed to address three\nkey aspects: what agents to involve in the communication, what information\ncontent to share, and how often to share it. The multi-agent system is modelled\nas a weighted graph with nodes representing agents. The unknown edge weights\nreflect the degree of communication between pairs of agents, which depends on a\ndiffusion process on the graph - the heat kernel. An optimal communication\nstrategy, tightly coupled with overall graph topology, is learned end-to-end\nconcurrently with the agents' policy so as to maximise future expected returns.\nEmpirical results show that CDC is capable of superior performance over\nalternative algorithms for a range of cooperative navigation tasks, and that\nthe learned graph structures can be interpretable.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 20:58:33 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 20:00:08 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Pesce", "Emanuele", ""], ["Montana", "Giovanni", ""]]}, {"id": "2002.05259", "submitter": "Philip Bontrager", "authors": "Philip Bontrager and Julian Togelius", "title": "Fully Differentiable Procedural Content Generation through Generative\n  Playing Networks", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To procedurally create interactive content such as environments or game\nlevels, we need agents that can evaluate the content; but to train such agents,\nwe need content they can train on. Generative Playing Networks is a framework\nthat learns agent policies and generates environments in tandem through a\nsymbiotic process. Policies are learned using an actor-critic reinforcement\nlearning algorithm so as to master the environment, and environments are\ncreated by a generator network which tries to provide an appropriate level of\nchallenge for the agent. This is accomplished by the generator learning to make\ncontent based on estimates by the critic. Thus, this process provides an\nimplicit curriculum for the agent, creating more complex environments over\ntime. Unlike previous approaches to procedural content generation, Generative\nPlaying Networks is end-to-end differentiable and does not require\nhuman-designed examples or domain knowledge. We demonstrate the capability of\nthis framework by training an agent and level generator for a 2D dungeon\ncrawler game.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 22:07:23 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Bontrager", "Philip", ""], ["Togelius", "Julian", ""]]}, {"id": "2002.05282", "submitter": "Min Chen", "authors": "Min Chen, Mateu Sbert, Alfie Abdul-Rahman, and Deborah Silver", "title": "A Bounded Measure for Estimating the Benefit of Visualization", "comments": "Comment on version 2: This revised version, which includes a new\n  formal proof, many additions, and a detailed revision report, was submitted\n  to SciVis 2020. Unexpectedly, our revision effort did not have much influence\n  on the SciVis 2020 reviewers who gave an outright rejection with lower scores\n  than EuroVis reviews. We will share these reviews after we have completed our\n  feedback", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GR cs.HC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information theory can be used to analyze the cost-benefit of visualization\nprocesses. However, the current measure of benefit contains an unbounded term\nthat is neither easy to estimate nor intuitive to interpret. In this work, we\npropose to revise the existing cost-benefit measure by replacing the unbounded\nterm with a bounded one. We examine a number of bounded measures that include\nthe Jenson-Shannon divergence and a new divergence measure formulated as part\nof this work. We use visual analysis to support the multi-criteria comparison,\nnarrowing the search down to those options with better mathematical properties.\nWe apply those remaining options to two visualization case studies to\ninstantiate their uses in practical scenarios, while the collected real world\ndata further informs the selection of a bounded measure, which can be used to\nestimate the benefit of visualization.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 23:39:07 GMT"}, {"version": "v2", "created": "Sat, 25 Jul 2020 20:33:33 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Chen", "Min", ""], ["Sbert", "Mateu", ""], ["Abdul-Rahman", "Alfie", ""], ["Silver", "Deborah", ""]]}, {"id": "2002.05294", "submitter": "Jos\\'e Everardo Bessa Maia", "authors": "Jos\\'e E. B. Maia and Levi P. Figueredo", "title": "Cooperative Observation of Targets moving over a Planar Graph with\n  Prediction of Positions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Consider a team with two types of agents: targets and observers. Observers\nare aerial UAVs that observe targets moving on land with their movements\nrestricted to the paths that form a planar graph on the surface. Observers have\nlimited range of vision and targets do not avoid observers. The objective is to\nmaximize the integral of the number of targets observed in the observation\ninterval. Taking advantage of the fact that the future positions of targets in\nthe short term are predictable, we show in this article a modified hill\nclimbing algorithm that surpasses its previous versions in this new setting of\nthe CTO problem.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 00:38:21 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Maia", "Jos\u00e9 E. B.", ""], ["Figueredo", "Levi P.", ""]]}, {"id": "2002.05406", "submitter": "Josef Urban", "authors": "Jan Jakub\\r{u}v, Karel Chvalovsk\\'y, Miroslav Ol\\v{s}\\'ak, Bartosz\n  Piotrowski, Martin Suda, Josef Urban", "title": "ENIGMA Anonymous: Symbol-Independent Inference Guiding Machine (system\n  description)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO cs.NE cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an implementation of gradient boosting and neural guidance of\nsaturation-style automated theorem provers that does not depend on consistent\nsymbol names across problems. For the gradient-boosting guidance, we manually\ncreate abstracted features by considering arity-based encodings of formulas.\nFor the neural guidance, we use symbol-independent graph neural networks (GNNs)\nand their embedding of the terms and clauses. The two methods are efficiently\nimplemented in the E prover and its ENIGMA learning-guided framework.\n  To provide competitive real-time performance of the GNNs, we have developed a\nnew context-based approach to evaluation of generated clauses in E. Clauses are\nevaluated jointly in larger batches and with respect to a large number of\nalready selected clauses (context) by the GNN that estimates their collectively\nmost useful subset in several rounds of message passing. This means that\napproximative inference rounds done by the GNN are efficiently interleaved with\nprecise symbolic inference rounds done inside E. The methods are evaluated on\nthe MPTP large-theory benchmark and shown to achieve comparable real-time\nperformance to state-of-the-art symbol-based methods. The methods also show\nhigh complementarity, solving a large number of hard Mizar problems.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 09:44:38 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 13:59:26 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Jakub\u016fv", "Jan", ""], ["Chvalovsk\u00fd", "Karel", ""], ["Ol\u0161\u00e1k", "Miroslav", ""], ["Piotrowski", "Bartosz", ""], ["Suda", "Martin", ""], ["Urban", "Josef", ""]]}, {"id": "2002.05442", "submitter": "Triet Le", "authors": "Triet H. M. Le, Hao Chen, M. Ali Babar", "title": "Deep Learning for Source Code Modeling and Generation: Models,\n  Applications and Challenges", "comments": null, "journal-ref": "ACM Comput. Surv., 53, 3 (2020), Article 62", "doi": "10.1145/3383458", "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL) techniques for Natural Language Processing have been\nevolving remarkably fast. Recently, the DL advances in language modeling,\nmachine translation and paragraph understanding are so prominent that the\npotential of DL in Software Engineering cannot be overlooked, especially in the\nfield of program learning. To facilitate further research and applications of\nDL in this field, we provide a comprehensive review to categorize and\ninvestigate existing DL methods for source code modeling and generation. To\naddress the limitations of the traditional source code models, we formulate\ncommon program learning tasks under an encoder-decoder framework. After that,\nwe introduce recent DL mechanisms suitable to solve such problems. Then, we\npresent the state-of-the-art practices and discuss their challenges with some\nrecommendations for practitioners and researchers as well.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 11:02:51 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Le", "Triet H. M.", ""], ["Chen", "Hao", ""], ["Babar", "M. Ali", ""]]}, {"id": "2002.05461", "submitter": "Gert de Cooman", "authors": "Gert de Cooman", "title": "Coherent and Archimedean choice in general Banach spaces", "comments": "34 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I introduce and study a new notion of Archimedeanity for binary and\nnon-binary choice between options that live in an abstract Banach space,\nthrough a very general class of choice models, called sets of desirable option\nsets. In order to be able to bring an important diversity of contexts into the\nfold, amongst which choice between horse lottery options, I pay special\nattention to the case where these linear spaces don't include all `constant'\noptions.I consider the frameworks of conservative inference associated with\nArchimedean (and coherent) choice models, and also pay quite a lot of attention\nto representation of general (non-binary) choice models in terms of the\nsimpler, binary ones.The representation theorems proved here provide an\naxiomatic characterisation for, amongst many other choice methods, Levi's\nE-admissibility and Walley-Sen maximality.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 11:57:50 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 14:38:08 GMT"}, {"version": "v3", "created": "Mon, 30 Nov 2020 14:05:35 GMT"}, {"version": "v4", "created": "Fri, 9 Jul 2021 13:03:31 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["de Cooman", "Gert", ""]]}, {"id": "2002.05505", "submitter": "Byungsoo Kim", "authors": "Youngduck Choi, Youngnam Lee, Junghyun Cho, Jineon Baek, Dongmin Shin,\n  Hangyeol Yu, Yugeun Shim, Seewoo Lee, Jonghun Shin, Chan Bae, Byungsoo Kim,\n  Jaewe Heo", "title": "Assessment Modeling: Fundamental Pre-training Tasks for Interactive\n  Educational Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Like many other domains in Artificial Intelligence (AI), there are specific\ntasks in the field of AI in Education (AIEd) for which labels are scarce and\nexpensive, such as predicting exam score or review correctness. A common way of\ncircumventing label-scarce problems is pre-training a model to learn\nrepresentations of the contents of learning items. However, such methods fail\nto utilize the full range of student interaction data available and do not\nmodel student learning behavior. To this end, we propose Assessment Modeling, a\nclass of fundamental pre-training tasks for general interactive educational\nsystems. An assessment is a feature of student-system interactions which can\nserve as a pedagogical evaluation. Examples include the correctness and\ntimeliness of a student's answer. Assessment Modeling is the prediction of\nassessments conditioned on the surrounding context of interactions. Although it\nis natural to pre-train on interactive features available in large amounts,\nlimiting the prediction targets to assessments focuses the tasks' relevance to\nthe label-scarce educational problems and reduces less-relevant noise. While\nthe effectiveness of different combinations of assessments is open for\nexploration, we suggest Assessment Modeling as a first-order guiding principle\nfor selecting proper pre-training tasks for label-scarce educational problems.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 02:00:07 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 04:57:54 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 06:45:40 GMT"}, {"version": "v4", "created": "Wed, 1 Jul 2020 07:00:48 GMT"}, {"version": "v5", "created": "Fri, 14 Aug 2020 01:31:13 GMT"}, {"version": "v6", "created": "Mon, 28 Jun 2021 05:00:25 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Choi", "Youngduck", ""], ["Lee", "Youngnam", ""], ["Cho", "Junghyun", ""], ["Baek", "Jineon", ""], ["Shin", "Dongmin", ""], ["Yu", "Hangyeol", ""], ["Shim", "Yugeun", ""], ["Lee", "Seewoo", ""], ["Shin", "Jonghun", ""], ["Bae", "Chan", ""], ["Kim", "Byungsoo", ""], ["Heo", "Jaewe", ""]]}, {"id": "2002.05513", "submitter": "Ke Zhang", "authors": "Ke Zhang, Meng Li, Zhengchao Zhang, Xi Lin, Fang He", "title": "Multi-Vehicle Routing Problems with Soft Time Windows: A Multi-Agent\n  Reinforcement Learning Approach", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-vehicle routing problem with soft time windows (MVRPSTW) is an\nindispensable constituent in urban logistics distribution systems. Over the\npast decade, numerous methods for MVRPSTW have been proposed, but most are\nbased on heuristic rules that require a large amount of computation time. With\nthe current rapid increase of logistics demands, traditional methods incur the\ndilemma between computational efficiency and solution quality. To efficiently\nsolve the problem, we propose a novel reinforcement learning algorithm called\nthe Multi-Agent Attention Model that can solve routing problem instantly\nbenefit from lengthy offline training. Specifically, the vehicle routing\nproblem is regarded as a vehicle tour generation process, and an\nencoder-decoder framework with attention layers is proposed to generate tours\nof multiple vehicles iteratively. Furthermore, a multi-agent reinforcement\nlearning method with an unsupervised auxiliary network is developed for the\nmodel training. By evaluated on four synthetic networks with different scales,\nthe results demonstrate that the proposed method consistently outperforms\nGoogle OR-Tools and traditional methods with little computation time. In\naddition, we validate the robustness of the well-trained model by varying the\nnumber of customers and the capacities of vehicles.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 14:26:27 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 09:21:32 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Zhang", "Ke", ""], ["Li", "Meng", ""], ["Zhang", "Zhengchao", ""], ["Lin", "Xi", ""], ["He", "Fang", ""]]}, {"id": "2002.05518", "submitter": "Kavosh Asadi", "authors": "Kavosh Asadi, David Abel, Michael L. Littman", "title": "Learning State Abstractions for Transfer in Continuous Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can simple algorithms with a good representation solve challenging\nreinforcement learning problems? In this work, we answer this question in the\naffirmative, where we take \"simple learning algorithm\" to be tabular\nQ-Learning, the \"good representations\" to be a learned state abstraction, and\n\"challenging problems\" to be continuous control tasks. Our main contribution is\na learning algorithm that abstracts a continuous state-space into a discrete\none. We transfer this learned representation to unseen problems to enable\neffective learning. We provide theory showing that learned abstractions\nmaintain a bounded value loss, and we report experiments showing that the\nabstractions empower tabular Q-Learning to learn efficiently in unseen tasks.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 20:42:05 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Asadi", "Kavosh", ""], ["Abel", "David", ""], ["Littman", "Michael L.", ""]]}, {"id": "2002.05522", "submitter": "Jayden Ooi", "authors": "Sungryull Sohn and Yinlam Chow and Jayden Ooi and Ofir Nachum and\n  Honglak Lee and Ed Chi and Craig Boutilier", "title": "BRPO: Batch Residual Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In batch reinforcement learning (RL), one often constrains a learned policy\nto be close to the behavior (data-generating) policy, e.g., by constraining the\nlearned action distribution to differ from the behavior policy by some maximum\ndegree that is the same at each state. This can cause batch RL to be overly\nconservative, unable to exploit large policy changes at frequently-visited,\nhigh-confidence states without risking poor performance at sparsely-visited\nstates. To remedy this, we propose residual policies, where the allowable\ndeviation of the learned policy is state-action-dependent. We derive a new for\nRL method, BRPO, which learns both the policy and allowable deviation that\njointly maximize a lower bound on policy performance. We show that BRPO\nachieves the state-of-the-art performance in a number of tasks.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 01:59:33 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2020 00:45:13 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Sohn", "Sungryull", ""], ["Chow", "Yinlam", ""], ["Ooi", "Jayden", ""], ["Nachum", "Ofir", ""], ["Lee", "Honglak", ""], ["Chi", "Ed", ""], ["Boutilier", "Craig", ""]]}, {"id": "2002.05615", "submitter": "Steven Carr", "authors": "Steven Carr, Nils Jansen and Ufuk Topcu", "title": "Verifiable RNN-Based Policies for POMDPs Under Temporal Logic\n  Constraints", "comments": "8 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) have emerged as an effective representation\nof control policies in sequential decision-making problems. However, a major\ndrawback in the application of RNN-based policies is the difficulty in\nproviding formal guarantees on the satisfaction of behavioral specifications,\ne.g. safety and/or reachability. By integrating techniques from formal methods\nand machine learning, we propose an approach to automatically extract a\nfinite-state controller (FSC) from an RNN, which, when composed with a\nfinite-state system model, is amenable to existing formal verification tools.\nSpecifically, we introduce an iterative modification to the so-called quantized\nbottleneck insertion technique to create an FSC as a randomized policy with\nmemory. For the cases in which the resulting FSC fails to satisfy the\nspecification, verification generates diagnostic information. We utilize this\ninformation to either adjust the amount of memory in the extracted FSC or\nperform focused retraining of the RNN. While generally applicable, we detail\nthe resulting iterative procedure in the context of policy synthesis for\npartially observable Markov decision processes (POMDPs), which is known to be\nnotoriously hard. The numerical experiments show that the proposed approach\noutperforms traditional POMDP synthesis methods by 3 orders of magnitude within\n2% of optimal benchmark values.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 16:38:38 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Carr", "Steven", ""], ["Jansen", "Nils", ""], ["Topcu", "Ufuk", ""]]}, {"id": "2002.05628", "submitter": "Anthony Stein", "authors": "Anthony Stein, Roland Maier, Lukas Rosenbauer, J\\\"org H\\\"ahner", "title": "XCS Classifier System with Experience Replay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  XCS constitutes the most deeply investigated classifier system today. It\nbears strong potentials and comes with inherent capabilities for mastering a\nvariety of different learning tasks. Besides outstanding successes in various\nclassification and regression tasks, XCS also proved very effective in certain\nmulti-step environments from the domain of reinforcement learning. Especially\nin the latter domain, recent advances have been mainly driven by algorithms\nwhich model their policies based on deep neural networks -- among which the\nDeep-Q-Network (DQN) is a prominent representative. Experience Replay (ER)\nconstitutes one of the crucial factors for the DQN's successes, since it\nfacilitates stabilized training of the neural network-based Q-function\napproximators. Surprisingly, XCS barely takes advantage of similar mechanisms\nthat leverage stored raw experiences encountered so far. To bridge this gap,\nthis paper investigates the benefits of extending XCS with ER. On the one hand,\nwe demonstrate that for single-step tasks ER bears massive potential for\nimprovements in terms of sample efficiency. On the shady side, however, we\nreveal that the use of ER might further aggravate well-studied issues not yet\nsolved for XCS when applied to sequential decision problems demanding for\nlong-action-chains.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 16:55:08 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Stein", "Anthony", ""], ["Maier", "Roland", ""], ["Rosenbauer", "Lukas", ""], ["H\u00e4hner", "J\u00f6rg", ""]]}, {"id": "2002.05630", "submitter": "Hugo Caselles-Dupr\\'e", "authors": "Hugo Caselles-Dupr\\'e, Michael Garcia-Ortiz, David Filliat", "title": "On the Sensory Commutativity of Action Sequences for Embodied Agents", "comments": "Accepted to RSS'20 Workshop on Self-Supervised Robot Learning & to\n  the Workshop on Learning in Artificial Open Worlds at ICML20 & Extended\n  abstract at AAMAS21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perception of artificial agents is one the grand challenges of AI research.\nDeep Learning and data-driven approaches are successful on constrained problems\nwhere perception can be learned using supervision, but do not scale to\nopen-worlds. In such case, for autonomous embodied agents with first-person\nsensors, perception can be learned end-to-end to solve particular tasks.\nHowever, literature shows that perception is not a purely passive compression\nmechanism, and that actions play an important role in the formulation of\nabstract representations. We propose to study perception for these embodied\nagents, under the mathematical formalism of group theory in order to make the\nlink between perception and action. In particular, we consider the commutative\nproperties of continuous action sequences with respect to sensory information\nperceived by such an embodied agent. We introduce the Sensory Commutativity\nProbability (SCP) criterion which measures how much an agent's degree of\nfreedom affects the environment in embodied scenarios. We show how to compute\nthis criterion in different environments, including realistic robotic setups.\nWe empirically illustrate how SCP and the commutative properties of action\nsequences can be used to learn about objects in the environment and improve\nsample-efficiency in Reinforcement Learning.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 16:58:23 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 14:32:44 GMT"}, {"version": "v3", "created": "Fri, 29 Jan 2021 10:15:08 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Caselles-Dupr\u00e9", "Hugo", ""], ["Garcia-Ortiz", "Michael", ""], ["Filliat", "David", ""]]}, {"id": "2002.05636", "submitter": "Ryan Steed", "authors": "Ryan Steed and Aylin Caliskan", "title": "A Set of Distinct Facial Traits Learned by Machines Is Not Predictive of\n  Appearance Bias in the Wild", "comments": "11 pages, 7 figures. Revision for AI Ethics", "journal-ref": "AI Ethics (2021)", "doi": "10.1007/s43681-020-00035-y", "report-no": null, "categories": "cs.CY cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Research in social psychology has shown that people's biased, subjective\njudgments about another's personality based solely on their appearance are not\npredictive of their actual personality traits. But researchers and companies\noften utilize computer vision models to predict similarly subjective\npersonality attributes such as \"employability.\" We seek to determine whether\nstate-of-the-art, black box face processing technology can learn human-like\nappearance biases. With features extracted with FaceNet, a widely used face\nrecognition framework, we train a transfer learning model on human subjects'\nfirst impressions of personality traits in other faces as measured by social\npsychologists. We find that features extracted with FaceNet can be used to\npredict human appearance bias scores for deliberately manipulated faces but not\nfor randomly generated faces scored by humans. Additionally, in contrast to\nwork with human biases in social psychology, the model does not find a\nsignificant signal correlating politicians' vote shares with perceived\ncompetence bias. With Local Interpretable Model-Agnostic Explanations (LIME),\nwe provide several explanations for this discrepancy. Our results suggest that\nsome signals of appearance bias documented in social psychology are not\nembedded by the machine learning techniques we investigate. We shed light on\nthe ways in which appearance bias could be embedded in face processing\ntechnology and cast further doubt on the practice of predicting subjective\ntraits based on appearances.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 17:09:27 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 12:39:57 GMT"}, {"version": "v3", "created": "Wed, 13 Jan 2021 17:15:05 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Steed", "Ryan", ""], ["Caliskan", "Aylin", ""]]}, {"id": "2002.05658", "submitter": "Jeannette Wing", "authors": "Jeannette M. Wing", "title": "Ten Research Challenge Areas in Data Science", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although data science builds on knowledge from computer science, mathematics,\nstatistics, and other disciplines, data science is a unique field with many\nmysteries to unlock: challenging scientific questions and pressing questions of\nsocietal importance. This article starts with meta-questions about data science\nas a discipline and then elaborates on ten ideas for the basis of a research\nagenda for data science.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 21:39:57 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Wing", "Jeannette M.", ""]]}, {"id": "2002.05664", "submitter": "Scott McLachlan Dr", "authors": "Scott McLachlan, Evangelia Kyrimi, and Norman Fenton", "title": "Public Authorities as Defendants: Using Bayesian Networks to determine\n  the Likelihood of Success for Negligence claims in the wake of Oakden", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Several countries are currently investigating issues of neglect, poor quality\ncare and abuse in the aged care sector. In most cases it is the State who\nlicense and monitor aged care providers, which frequently introduces a serious\nconflict of interest because the State also operate many of the facilities\nwhere our most vulnerable peoples are cared for. Where issues are raised with\nthe standard of care being provided, the State are seen by many as a\ndeep-pockets defendant and become the target of high-value lawsuits. This paper\ndraws on cases and circumstances from one jurisdiction based on the English\nlegal tradition, Australia, and proposes a Bayesian solution capable of\ndetermining probability for success for citizen plaintiffs who bring negligence\nclaims against a public authority defendant. Use of a Bayesian network trained\non case audit data shows that even when the plaintiff case meets all\nrequirements for a successful negligence litigation, success is not often\nassured. Only in around one-fifth of these cases does the plaintiff succeed\nagainst a public authority as defendant.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 14:24:53 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["McLachlan", "Scott", ""], ["Kyrimi", "Evangelia", ""], ["Fenton", "Norman", ""]]}, {"id": "2002.05671", "submitter": "Mislav Juri\\'c", "authors": "Mislav Juric, Agneza Sandic, Mario Brcic", "title": "AI safety: state of the field through quantitative lens", "comments": "2020 43rd International Convention on Information and Communication\n  Technology, Electronics and Microelectronics (MIPRO)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Last decade has seen major improvements in the performance of artificial\nintelligence which has driven wide-spread applications. Unforeseen effects of\nsuch mass-adoption has put the notion of AI safety into the public eye. AI\nsafety is a relatively new field of research focused on techniques for building\nAI beneficial for humans. While there exist survey papers for the field of AI\nsafety, there is a lack of a quantitative look at the research being conducted.\nThe quantitative aspect gives a data-driven insight about the emerging trends,\nknowledge gaps and potential areas for future research. In this paper,\nbibliometric analysis of the literature finds significant increase in research\nactivity since 2015. Also, the field is so new that most of the technical\nissues are open, including: explainability with its long-term utility, and\nvalue alignment which we have identified as the most important long-term\nresearch topic. Equally, there is a severe lack of research into concrete\npolicies regarding AI. As we expect AI to be the one of the main driving forces\nof changes in society, AI safety is the field under which we need to decide the\ndirection of humanity's future.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 11:26:44 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 11:32:14 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Juric", "Mislav", ""], ["Sandic", "Agneza", ""], ["Brcic", "Mario", ""]]}, {"id": "2002.05700", "submitter": "Gregory Kahn", "authors": "Gregory Kahn, Pieter Abbeel, Sergey Levine", "title": "BADGR: An Autonomous Self-Supervised Learning-Based Navigation System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile robot navigation is typically regarded as a geometric problem, in\nwhich the robot's objective is to perceive the geometry of the environment in\norder to plan collision-free paths towards a desired goal. However, a purely\ngeometric view of the world can can be insufficient for many navigation\nproblems. For example, a robot navigating based on geometry may avoid a field\nof tall grass because it believes it is untraversable, and will therefore fail\nto reach its desired goal. In this work, we investigate how to move beyond\nthese purely geometric-based approaches using a method that learns about\nphysical navigational affordances from experience. Our approach, which we call\nBADGR, is an end-to-end learning-based mobile robot navigation system that can\nbe trained with self-supervised off-policy data gathered in real-world\nenvironments, without any simulation or human supervision. BADGR can navigate\nin real-world urban and off-road environments with geometrically distracting\nobstacles. It can also incorporate terrain preferences, generalize to novel\nenvironments, and continue to improve autonomously by gathering more data.\nVideos, code, and other supplemental material are available on our website\nhttps://sites.google.com/view/badgr\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 18:40:21 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 18:31:03 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Kahn", "Gregory", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "2002.05769", "submitter": "Mark Ho", "authors": "Mark K. Ho, David Abel, Jonathan D. Cohen, Michael L. Littman, Thomas\n  L. Griffiths", "title": "The Efficiency of Human Cognition Reflects Planned Information\n  Processing", "comments": "13 pg (incl. supplemental materials); included in Proceedings of the\n  34th AAAI Conference on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning is useful. It lets people take actions that have desirable long-term\nconsequences. But, planning is hard. It requires thinking about consequences,\nwhich consumes limited computational and cognitive resources. Thus, people\nshould plan their actions, but they should also be smart about how they deploy\nresources used for planning their actions. Put another way, people should also\n\"plan their plans\". Here, we formulate this aspect of planning as a\nmeta-reasoning problem and formalize it in terms of a recursive Bellman\nobjective that incorporates both task rewards and information-theoretic\nplanning costs. Our account makes quantitative predictions about how people\nshould plan and meta-plan as a function of the overall structure of a task,\nwhich we test in two experiments with human participants. We find that people's\nreaction times reflect a planned use of information processing, consistent with\nour account. This formulation of planning to plan provides new insight into the\nfunction of hierarchical planning, state abstraction, and cognitive control in\nboth humans and machines.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 20:34:33 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Ho", "Mark K.", ""], ["Abel", "David", ""], ["Cohen", "Jonathan D.", ""], ["Littman", "Michael L.", ""], ["Griffiths", "Thomas L.", ""]]}, {"id": "2002.05797", "submitter": "Chaoqi Yang", "authors": "Chaoqi Yang, Jinyang Li, Ruijie Wang, Shuochao Yao, Huajie Shao,\n  Dongxin Liu, Shengzhong Liu, Tianshi Wang, Tarek F. Abdelzaher", "title": "Disentangling Overlapping Beliefs by Structured Matrix Factorization", "comments": "conference paper under review, 10 pages+1 reference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much work on social media opinion polarization focuses on identifying\nseparate or orthogonal beliefs from media traces, thereby missing points of\nagreement among different communities. This paper develops a new class of\nNon-negative Matrix Factorization (NMF) algorithms that allow identification of\nboth agreement and disagreement points when beliefs of different communities\npartially overlap. Specifically, we propose a novel Belief Structured Matrix\nFactorization algorithm (BSMF) to identify partially overlapping beliefs in\npolarized public social media. BSMF is totally unsupervised and considers three\ntypes of information: (i) who posted which opinion, (ii) keyword-level message\nsimilarity, and (iii) empirically observed social dependency graphs (e.g.,\nretweet graphs), to improve belief separation. In the space of unsupervised\nbelief separation algorithms, the emphasis was mostly given to the problem of\nidentifying disjoint (e.g., conflicting) beliefs. The case when individuals\nwith different beliefs agree on some subset of points was less explored. We\nobserve that social beliefs overlap even in polarized scenarios. Our proposed\nunsupervised algorithm captures both the latent belief intersections and\ndissimilarities. We discuss the properties of the algorithm and conduct\nextensive experiments on both synthetic data and real-world datasets. The\nresults show that our model outperforms all compared baselines by a great\nmargin.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 22:17:55 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Yang", "Chaoqi", ""], ["Li", "Jinyang", ""], ["Wang", "Ruijie", ""], ["Yao", "Shuochao", ""], ["Shao", "Huajie", ""], ["Liu", "Dongxin", ""], ["Liu", "Shengzhong", ""], ["Wang", "Tianshi", ""], ["Abdelzaher", "Tarek F.", ""]]}, {"id": "2002.05822", "submitter": "Yangchen Pan", "authors": "Yangchen Pan, Jincheng Mei, Amir-massoud Farahmand", "title": "Frequency-based Search-control in Dyna", "comments": "Accepted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning has been empirically demonstrated as a\nsuccessful strategy to improve sample efficiency. In particular, Dyna is an\nelegant model-based architecture integrating learning and planning that\nprovides huge flexibility of using a model. One of the most important\ncomponents in Dyna is called search-control, which refers to the process of\ngenerating state or state-action pairs from which we query the model to acquire\nsimulated experiences. Search-control is critical in improving learning\nefficiency. In this work, we propose a simple and novel search-control strategy\nby searching high frequency regions of the value function. Our main intuition\nis built on Shannon sampling theorem from signal processing, which indicates\nthat a high frequency signal requires more samples to reconstruct. We\nempirically show that a high frequency function is more difficult to\napproximate. This suggests a search-control strategy: we should use states from\nhigh frequency regions of the value function to query the model to acquire more\nsamples. We develop a simple strategy to locally measure the frequency of a\nfunction by gradient and hessian norms, and provide theoretical justification\nfor this approach. We then apply our strategy to search-control in Dyna, and\nconduct experiments to show its property and effectiveness on benchmark\ndomains.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 00:27:58 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Pan", "Yangchen", ""], ["Mei", "Jincheng", ""], ["Farahmand", "Amir-massoud", ""]]}, {"id": "2002.05867", "submitter": "Peter Clark", "authors": "Peter Clark, Oyvind Tafjord, Kyle Richardson", "title": "Transformers as Soft Reasoners over Language", "comments": "IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Beginning with McCarthy's Advice Taker (1959), AI has pursued the goal of\nproviding a system with explicit, general knowledge and having the system\nreason over that knowledge. However, expressing the knowledge in a formal\n(logical or probabilistic) representation has been a major obstacle to this\nresearch. This paper investigates a modern approach to this problem where the\nfacts and rules are provided as natural language sentences, thus bypassing a\nformal representation. We train transformers to reason (or emulate reasoning)\nover these sentences using synthetically generated data. Our models, that we\ncall RuleTakers, provide the first empirical demonstration that this kind of\nsoft reasoning over language is learnable, can achieve high (99%) accuracy, and\ngeneralizes to test data requiring substantially deeper chaining than seen\nduring training (95%+ scores). We also demonstrate that the models transfer\nwell to two hand-authored rulebases, and to rulebases paraphrased into more\nnatural language. These findings are significant as it suggests a new role for\ntransformers, namely as limited \"soft theorem provers\" operating over explicit\ntheories in language. This in turn suggests new possibilities for\nexplainability, correctability, and counterfactual reasoning in\nquestion-answering.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 04:23:28 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 17:33:38 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Clark", "Peter", ""], ["Tafjord", "Oyvind", ""], ["Richardson", "Kyle", ""]]}, {"id": "2002.05936", "submitter": "Marcus Scheunemann", "authors": "Marcus M. Scheunemann, Christoph Salge, Daniel Polani, Kerstin\n  Dautenhahn", "title": "Human Perception of Intrinsically Motivated Autonomy in Human-Robot\n  Interaction", "comments": "32 pages, 3 tables, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A challenge in using robots in human-inhabited environments is to design\nbehavior that is engaging, yet robust to the perturbations induced by human\ninteraction. Our idea is to imbue the robot with intrinsic motivation (IM) so\nthat it can handle new situations and appears as a genuine social other to\nhumans and thus be of more interest to a human interaction partner. Human-robot\ninteraction (HRI) experiments mainly focus on scripted or teleoperated robots,\nthat mimic characteristics such as IM to control isolated behavior factors.\nThis article presents a \"robotologist\" study design that allows comparing\nautonomously generated behaviors with each other, and, for the first time,\nevaluates the human perception of IM-based generated behavior in robots. We\nconducted a within-subjects user study (N=24) where participants interacted\nwith a fully autonomous Sphero BB8 robot with different behavioral regimes: one\nrealizing an adaptive, intrinsically motivated behavior and the other being\nreactive, but not adaptive. A quantitative analysis of post-interaction\nquestionnaires showed a significantly higher perception of the dimension\n\"Warmth\" compared to the reactive baseline behavior. Warmth is considered a\nprimary dimension for social attitude formation in human social cognition. A\nhuman perceived as warm (friendly, trustworthy) experiences more positive\nsocial interactions.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 09:49:36 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 20:40:53 GMT"}, {"version": "v3", "created": "Thu, 11 Feb 2021 17:54:22 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Scheunemann", "Marcus M.", ""], ["Salge", "Christoph", ""], ["Polani", "Daniel", ""], ["Dautenhahn", "Kerstin", ""]]}, {"id": "2002.05954", "submitter": "Sammy Christen", "authors": "Sammy Christen, Lukas Jendele, Emre Aksan, Otmar Hilliges", "title": "Learning Functionally Decomposed Hierarchies for Continuous Control\n  Tasks with Path Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present HiDe, a novel hierarchical reinforcement learning architecture\nthat successfully solves long horizon control tasks and generalizes to unseen\ntest scenarios. Functional decomposition between planning and low-level control\nis achieved by explicitly separating the state-action spaces across the\nhierarchy, which allows the integration of task-relevant knowledge per layer.\nWe propose an RL-based planner to efficiently leverage the information in the\nplanning layer of the hierarchy, while the control layer learns a\ngoal-conditioned control policy. The hierarchy is trained jointly but allows\nfor the composition of different policies such as transferring layers across\nmultiple agents. We experimentally show that our method generalizes across\nunseen test environments and can scale to tasks well beyond 3x horizon length\ncompared to both learning and non-learning based approaches. We evaluate on\ncomplex continuous control tasks with sparse rewards, including navigation and\nrobot manipulation.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 10:19:52 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 12:01:32 GMT"}, {"version": "v3", "created": "Sun, 15 Nov 2020 11:38:36 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Christen", "Sammy", ""], ["Jendele", "Lukas", ""], ["Aksan", "Emre", ""], ["Hilliges", "Otmar", ""]]}, {"id": "2002.06000", "submitter": "Borja Gonzalez Leon", "authors": "Borja G. Le\\'on and Francesco Belardinelli", "title": "Extended Markov Games to Learn Multiple Tasks in Multi-Agent\n  Reinforcement Learning", "comments": "Long version of the correspondent ECAI 2020 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combination of Formal Methods with Reinforcement Learning (RL) has\nrecently attracted interest as a way for single-agent RL to learn multiple-task\nspecifications. In this paper we extend this convergence to multi-agent\nsettings and formally define Extended Markov Games as a general mathematical\nmodel that allows multiple RL agents to concurrently learn various\nnon-Markovian specifications. To introduce this new model we provide formal\ndefinitions and proofs as well as empirical tests of RL algorithms running on\nthis framework. Specifically, we use our model to train two different\nlogic-based multi-agent RL algorithms to solve diverse settings of\nnon-Markovian co-safe LTL specifications.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 12:37:41 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Le\u00f3n", "Borja G.", ""], ["Belardinelli", "Francesco", ""]]}, {"id": "2002.06016", "submitter": "Nicolas Furnon", "authors": "Nicolas Furnon (LORIA, MULTISPEECH), Romain Serizel (LORIA,\n  MULTISPEECH), Irina Illina (LORIA, MULTISPEECH), Slim Essid (LTCI)", "title": "DNN-Based Distributed Multichannel Mask Estimation for Speech\n  Enhancement in Microphone Arrays", "comments": "Submitted to ICASSP2020", "journal-ref": "International Conference on Audio, Signal and Speech Processing\n  (ICASSP), May 2020, Barcelone, Spain", "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multichannel processing is widely used for speech enhancement but several\nlimitations appear when trying to deploy these solutions to the real-world.\nDistributed sensor arrays that consider several devices with a few microphones\nis a viable alternative that allows for exploiting the multiple devices\nequipped with microphones that we are using in our everyday life. In this\ncontext, we propose to extend the distributed adaptive node-specific signal\nestimation approach to a neural networks framework. At each node, a local\nfiltering is performed to send one signal to the other nodes where a mask is\nestimated by a neural network in order to compute a global multi-channel Wiener\nfilter. In an array of two nodes, we show that this additional signal can be\nefficiently taken into account to predict the masks and leads to better speech\nenhancement performances than when the mask estimation relies only on the local\nsignals.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 11:08:00 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 15:58:55 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Furnon", "Nicolas", "", "LORIA, MULTISPEECH"], ["Serizel", "Romain", "", "LORIA,\n  MULTISPEECH"], ["Illina", "Irina", "", "LORIA, MULTISPEECH"], ["Essid", "Slim", "", "LTCI"]]}, {"id": "2002.06036", "submitter": "Victor Adrian Jimenez", "authors": "Jorge Bustos, Victor A. Jimenez, Adrian Will", "title": "A comparison of different types of Niching Genetic Algorithms for\n  variable selection in solar radiation estimation", "comments": "10 pages, two columns, 9 figures, non-published paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variable selection problems generally present more than a single solution\nand, sometimes, it is worth to find as many solutions as possible. The use of\nEvolutionary Algorithms applied to this kind of problem proves to be one of the\nbest methods to find optimal solutions. Moreover, there are variants designed\nto find all or almost all local optima, known as Niching Genetic Algorithms\n(NGA). There are several different NGA methods developed in order to achieve\nthis task. The present work compares the behavior of eight different niching\ntechniques, applied to a climatic database of four weather stations distributed\nin Tucuman, Argentina. The goal is to find different sets of input variables\nthat have been used as the input variable by the estimation method. Final\nresults were evaluated based on low estimation error and low dispersion error,\nas well as a high number of different results and low computational time. A\nsecond experiment was carried out to study the capability of the method to\nidentify critical variables. The best results were obtained with Deterministic\nCrowding. In contrast, Steady State Worst Among Most Similar and Probabilistic\nCrowding showed good results but longer processing times and less ability to\ndetermine the critical factors.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 13:52:04 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Bustos", "Jorge", ""], ["Jimenez", "Victor A.", ""], ["Will", "Adrian", ""]]}, {"id": "2002.06071", "submitter": "Martin d'Hoffschmidt", "authors": "Martin d'Hoffschmidt, Wacim Belblidia, Tom Brendl\\'e, Quentin\n  Heinrich, Maxime Vidal", "title": "FQuAD: French Question Answering Dataset", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances in the field of language modeling have improved\nstate-of-the-art results on many Natural Language Processing tasks. Among them,\nReading Comprehension has made significant progress over the past few years.\nHowever, most results are reported in English since labeled resources available\nin other languages, such as French, remain scarce. In the present work, we\nintroduce the French Question Answering Dataset (FQuAD). FQuAD is a French\nNative Reading Comprehension dataset of questions and answers on a set of\nWikipedia articles that consists of 25,000+ samples for the 1.0 version and\n60,000+ samples for the 1.1 version. We train a baseline model which achieves\nan F1 score of 92.2 and an exact match ratio of 82.1 on the test set. In order\nto track the progress of French Question Answering models we propose a\nleader-board and we have made the 1.0 version of our dataset freely available\nat https://illuin-tech.github.io/FQuAD-explorer/.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 15:23:38 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 17:09:17 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["d'Hoffschmidt", "Martin", ""], ["Belblidia", "Wacim", ""], ["Brendl\u00e9", "Tom", ""], ["Heinrich", "Quentin", ""], ["Vidal", "Maxime", ""]]}, {"id": "2002.06072", "submitter": "Bartosz Bednarczyk", "authors": "Franz Baader, Bartosz Bednarczyk and Sebastian Rudolph", "title": "Satisfiability and Query Answering in Description Logics with Global and\n  Local Cardinality Constraints", "comments": "Technical report for the paper of the same title accepted to ECAI\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and investigate the expressive description logic (DL) ALCSCC++,\nin which the global and local cardinality constraints introduced in previous\npapers can be mixed. On the one hand, we prove that this does not increase the\ncomplexity of satisfiability checking and other standard inference problems. On\nthe other hand, the satisfiability problem becomes undecidable if inverse roles\nare added to the languages. In addition, even without inverse roles,\nconjunctive query entailment in this DL turns out to be undecidable. We prove\nthat decidability of querying can be regained if global and local constraints\nare not mixed and the global constraints are appropriately restricted. The\nlatter result is based on a locally-acyclic model construction, and it reduces\nquery entailment to ABox consistency in the restricted setting, i.e., to ABox\nconsistency w.r.t. restricted cardinality constraints in ALCSCC, for which we\ncan show an ExpTime upper bound.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 15:28:15 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Baader", "Franz", ""], ["Bednarczyk", "Bartosz", ""], ["Rudolph", "Sebastian", ""]]}, {"id": "2002.06075", "submitter": "David Aparicio", "authors": "David Apar\\'icio, Ricardo Barata, Jo\\~ao Bravo, Jo\\~ao Tiago\n  Ascens\\~ao, Pedro Bizarro", "title": "ARMS: Automated rules management system for fraud detection", "comments": "11 pages, 12 figures, submitted to KDD '20 Applied Data Science Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fraud detection is essential in financial services, with the potential of\ngreatly reducing criminal activities and saving considerable resources for\nbusinesses and customers. We address online fraud detection, which consists of\nclassifying incoming transactions as either legitimate or fraudulent in\nreal-time. Modern fraud detection systems consist of a machine learning model\nand rules defined by human experts. Often, the rules performance degrades over\ntime due to concept drift, especially of adversarial nature. Furthermore, they\ncan be costly to maintain, either because they are computationally expensive or\nbecause they send transactions for manual review. We propose ARMS, an automated\nrules management system that evaluates the contribution of individual rules and\noptimizes the set of active rules using heuristic search and a user-defined\nloss-function. It complies with critical domain-specific requirements, such as\nhandling different actions (e.g., accept, alert, and decline), priorities,\nblacklists, and large datasets (i.e., hundreds of rules and millions of\ntransactions). We use ARMS to optimize the rule-based systems of two real-world\nclients. Results show that it can maintain the original systems' performance\n(e.g., recall, or false-positive rate) using only a fraction of the original\nrules (~ 50% in one case, and ~ 20% in the other).\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 15:29:59 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Apar\u00edcio", "David", ""], ["Barata", "Ricardo", ""], ["Bravo", "Jo\u00e3o", ""], ["Ascens\u00e3o", "Jo\u00e3o Tiago", ""], ["Bizarro", "Pedro", ""]]}, {"id": "2002.06084", "submitter": "Xuewen Yu", "authors": "Xuewen Yu, Jim Q. Smith and Linda Nichols", "title": "Bayesian Learning of Causal Relationships for System Reliability", "comments": "8 pages, 4 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal theory is now widely developed with many applications to medicine and\npublic health. However within the discipline of reliability, although causation\nis a key concept in this field, there has been much less theoretical attention.\nIn this paper, we will demonstrate how some aspects of established causal\nmethodology can be translated via trees, and more specifically chain event\ngraphs, into domain of reliability theory to help the probability modeling of\nfailures. We further show how various domain specific concepts of causality\nparticular to reliability can be imported into more generic causal algebras and\nso demonstrate how these disciplines can inform each other. This paper is\ninformed by a detailed analysis of maintenance records associated with a large\nelectrical distribution company. Causal hypotheses embedded within these\nnatural language texts are extracted and analyzed using the new graphical\nframework we introduced here.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 15:40:10 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Yu", "Xuewen", ""], ["Smith", "Jim Q.", ""], ["Nichols", "Linda", ""]]}, {"id": "2002.06095", "submitter": "Alina Patelli PhD", "authors": "Alina Patelli, Victoria Lush, Aniko Ekart, Elisabeth Ilie-Zudor", "title": "Traffic Modelling and Prediction via Symbolic Regression on Road Sensor\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The continuous expansion of the urban traffic sensing infrastructure has led\nto a surge in the volume of widely available road related data. Consequently,\nincreasing effort is being dedicated to the creation of intelligent\ntransportation systems, where decisions on issues ranging from city-wide road\nmaintenance planning to improving the commuting experience are informed by\ncomputational models of urban traffic instead of being left entirely to humans.\nThe automation of traffic management has received substantial attention from\nthe research community, however, most approaches target highways, produce\npredictions valid for a limited time window or require expensive retraining of\navailable models in order to accurately forecast traffic at a new location. In\nthis article, we propose a novel and accurate traffic flow prediction method\nbased on symbolic regression enhanced with a lag operator. Our approach\nproduces robust models suitable for the intricacies of urban roads, much more\ndifficult to predict than highways. Additionally, there is no need to retrain\nthe model for a period of up to 9 weeks. Furthermore, the proposed method\ngenerates models that are transferable to other segments of the road network,\nsimilar to, yet geographically distinct from the ones they were initially\ntrained on. We demonstrate the achievement of these claims by conducting\nextensive experiments on data collected from the Darmstadt urban\ninfrastructure.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 16:03:04 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Patelli", "Alina", ""], ["Lush", "Victoria", ""], ["Ekart", "Aniko", ""], ["Ilie-Zudor", "Elisabeth", ""]]}, {"id": "2002.06100", "submitter": "Emile Van Krieken", "authors": "Emile van Krieken, Erman Acar, Frank van Harmelen", "title": "Analyzing Differentiable Fuzzy Logic Operators", "comments": "45 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years there has been a push to integrate symbolic AI and deep\nlearning, as it is argued that the strengths and weaknesses of these approaches\nare complementary. One such trend in the literature are weakly supervised\nlearning techniques that use operators from fuzzy logics. They employ prior\nbackground knowledge described in logic to benefit the training of a neural\nnetwork from unlabeled and noisy data. By interpreting logical symbols using\nneural networks, this background knowledge can be added to regular loss\nfunctions used in deep learning to integrate reasoning and learning. In this\npaper, we analyze how a large collection of logical operators from the fuzzy\nlogic literature behave in a differentiable setting. We find large differences\nbetween the formal properties of these operators that are of crucial importance\nin a differentiable learning setting. We show that many of these operators,\nincluding some of the best known, are highly unsuitable for use in a\ndifferentiable learning setting. A further finding concerns the treatment of\nimplication in these fuzzy logics, with a strong imbalance between gradients\ndriven by the antecedent and the consequent of the implication. Finally, we\nempirically show that it is possible to use Differentiable Fuzzy Logics for\nsemi-supervised learning. However, to achieve the most significant performance\nimprovement over a supervised baseline, we have to resort to non-standard\ncombinations of logical operators which perform well in learning, but which no\nlonger satisfy the usual logical laws. We end with a discussion on extensions\nto large-scale problems.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 16:11:36 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["van Krieken", "Emile", ""], ["Acar", "Erman", ""], ["van Harmelen", "Frank", ""]]}, {"id": "2002.06137", "submitter": "Nevan Wichers", "authors": "Nevan Wichers", "title": "RL agents Implicitly Learning Human Preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the real world, RL agents should be rewarded for fulfilling human\npreferences. We show that RL agents implicitly learn the preferences of humans\nin their environment. Training a classifier to predict if a simulated human's\npreferences are fulfilled based on the activations of a RL agent's neural\nnetwork gets .93 AUC. Training a classifier on the raw environment state gets\nonly .8 AUC. Training the classifier off of the RL agent's activations also\ndoes much better than training off of activations from an autoencoder. The\nhuman preference classifier can be used as the reward function of an RL agent\nto make RL agent more beneficial for humans.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 17:42:50 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Wichers", "Nevan", ""]]}, {"id": "2002.06177", "submitter": "Gary Marcus", "authors": "Gary Marcus", "title": "The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence", "comments": "5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research in artificial intelligence and machine learning has largely\nemphasized general-purpose learning and ever-larger training sets and more and\nmore compute. In contrast, I propose a hybrid, knowledge-driven,\nreasoning-based approach, centered around cognitive models, that could provide\nthe substrate for a richer, more robust AI than is currently possible.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 18:55:56 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 17:58:30 GMT"}, {"version": "v3", "created": "Wed, 19 Feb 2020 17:48:05 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Marcus", "Gary", ""]]}, {"id": "2002.06198", "submitter": "Yu Chen", "authors": "Yu Chen, S. Yusef Shafi, Yi-fan Chen", "title": "Simulation Pipeline for Traffic Evacuation in Urban Areas and Emergency\n  Traffic Management Policy Improvements through Case Studies", "comments": "38 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic evacuation plays a critical role in saving lives in devastating\ndisasters such as hurricanes, wildfires, floods, earthquakes, etc. An ability\nto evaluate evacuation plans in advance for these rare events, including\nidentifying traffic flow bottlenecks, improving traffic management policies,\nand understanding the robustness of the traffic management policy are critical\nfor emergency management. Given the rareness of such events and the\ncorresponding lack of real data, traffic simulation provides a flexible and\nversatile approach for such scenarios, and furthermore allows dynamic\ninteraction with the simulated evacuation. In this paper, we build a traffic\nsimulation pipeline to explore the above problems, covering many aspects of\nevacuation, including map creation, demand generation, vehicle behavior,\nbottleneck identification, traffic management policy improvement, and results\nanalysis. We apply the pipeline to two case studies in California. The first is\nParadise, which was destroyed by a large wildfire in 2018 and experienced\ncatastrophic traffic jams during the evacuation. The second is Mill Valley,\nwhich has high risk of wildfire and potential traffic issues since the city is\nsituated in a narrow valley.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 03:03:31 GMT"}, {"version": "v2", "created": "Sat, 16 May 2020 20:11:26 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 00:23:31 GMT"}, {"version": "v4", "created": "Sat, 22 Aug 2020 18:26:51 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Chen", "Yu", ""], ["Shafi", "S. Yusef", ""], ["Chen", "Yi-fan", ""]]}, {"id": "2002.06235", "submitter": "John Kelleher", "authors": "Magdalena Kacmajor and John D. Kelleher and Filip Klubicka and Alfredo\n  Maldonado", "title": "Semantic Relatedness and Taxonomic Word Embeddings", "comments": "7 pages 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper connects a series of papers dealing with taxonomic word\nembeddings. It begins by noting that there are different types of semantic\nrelatedness and that different lexical representations encode different forms\nof relatedness. A particularly important distinction within semantic\nrelatedness is that of thematic versus taxonomic relatedness. Next, we present\na number of experiments that analyse taxonomic embeddings that have been\ntrained on a synthetic corpus that has been generated via a random walk over a\ntaxonomy. These experiments demonstrate how the properties of the synthetic\ncorpus, such as the percentage of rare words, are affected by the shape of the\nknowledge graph the corpus is generated from. Finally, we explore the\ninteractions between the relative sizes of natural and synthetic corpora on the\nperformance of embeddings when taxonomic and thematic embeddings are combined.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 20:02:11 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Kacmajor", "Magdalena", ""], ["Kelleher", "John D.", ""], ["Klubicka", "Filip", ""], ["Maldonado", "Alfredo", ""]]}, {"id": "2002.06238", "submitter": "Warren Powell", "authors": "Warren B Powell", "title": "On State Variables, Bandit Problems and POMDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State variables are easily the most subtle dimension of sequential decision\nproblems. This is especially true in the context of active learning problems\n(bandit problems\") where decisions affect what we observe and learn. We\ndescribe our canonical framework that models {\\it any} sequential decision\nproblem, and present our definition of state variables that allows us to claim:\nAny properly modeled sequential decision problem is Markovian. We then present\na novel two-agent perspective of partially observable Markov decision problems\n(POMDPs) that allows us to then claim: Any model of a real decision problem is\n(possibly) non-Markovian. We illustrate these perspectives using the context of\nobserving and treating flu in a population, and provide examples of all four\nclasses of policies in this setting. We close with an indication of how to\nextend this thinking to multiagent problems.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 20:09:59 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Powell", "Warren B", ""]]}, {"id": "2002.06259", "submitter": "Hui Yang", "authors": "Hui Yang, Kaixuan Zhan, Michel Kadoch, Yongshen Liang, Mohamed Cheriet", "title": "BLCS: Brain-Like based Distributed Control Security in Cyber Physical\n  Systems", "comments": "accepted by IEEE Network", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-physical system (CPS) has operated, controlled and coordinated the\nphysical systems integrated by a computing and communication core applied in\nindustry 4.0. To accommodate CPS services, fog radio and optical networks\n(F-RON) has become an important supporting physical cyber infrastructure taking\nadvantage of both the inherent ubiquity of wireless technology and the large\ncapacity of optical networks. However, cyber security is the biggest issue in\nCPS scenario as there is a tradeoff between security control and privacy\nexposure in F-RON. To deal with this issue, we propose a brain-like based\ndistributed control security (BLCS) architecture for F-RON in CPS, by\nintroducing a brain-like security (BLS) scheme. BLCS can accomplish the secure\ncross-domain control among tripartite controllers verification in the scenario\nof decentralized F-RON for distributed computing and communications, which has\nno need to disclose the private information of each domain against\ncyber-attacks. BLS utilizes parts of information to perform control\nidentification through relation network and deep learning of behavior library.\nThe functional modules of BLCS architecture are illustrated including various\ncontrollers and brain-like knowledge base. The interworking procedures in\ndistributed control security modes based on BLS are described. The overall\nfeasibility and efficiency of architecture are experimentally verified on the\nsoftware defined network testbed in terms of average mistrust rate, path\nprovisioning latency, packet loss probability and blocking probability. The\nemulation results are obtained and dissected based on the testbed.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 09:14:10 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Yang", "Hui", ""], ["Zhan", "Kaixuan", ""], ["Kadoch", "Michel", ""], ["Liang", "Yongshen", ""], ["Cheriet", "Mohamed", ""]]}, {"id": "2002.06261", "submitter": "Carlos Aspillaga", "authors": "Carlos Aspillaga, Andr\\'es Carvallo, Vladimir Araujo", "title": "Stress Test Evaluation of Transformer-based Models in Natural Language\n  Understanding Tasks", "comments": "Accepted paper LREC2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been significant progress in recent years in the field of Natural\nLanguage Processing thanks to the introduction of the Transformer architecture.\nCurrent state-of-the-art models, via a large number of parameters and\npre-training on massive text corpus, have shown impressive results on several\ndownstream tasks. Many researchers have studied previous (non-Transformer)\nmodels to understand their actual behavior under different scenarios, showing\nthat these models are taking advantage of clues or failures of datasets and\nthat slight perturbations on the input data can severely reduce their\nperformance. In contrast, recent models have not been systematically tested\nwith adversarial-examples in order to show their robustness under severe stress\nconditions. For that reason, this work evaluates three Transformer-based models\n(RoBERTa, XLNet, and BERT) in Natural Language Inference (NLI) and Question\nAnswering (QA) tasks to know if they are more robust or if they have the same\nflaws as their predecessors. As a result, our experiments reveal that RoBERTa,\nXLNet and BERT are more robust than recurrent neural network models to stress\ntests for both NLI and QA tasks. Nevertheless, they are still very fragile and\ndemonstrate various unexpected behaviors, thus revealing that there is still\nroom for future improvement in this field.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 21:52:41 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 18:45:48 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Aspillaga", "Carlos", ""], ["Carvallo", "Andr\u00e9s", ""], ["Araujo", "Vladimir", ""]]}, {"id": "2002.06276", "submitter": "Jeannette Wing", "authors": "Jeannette M. Wing", "title": "Trustworthy AI", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The promise of AI is huge. AI systems have already achieved good enough\nperformance to be in our streets and in our homes. However, they can be brittle\nand unfair. For society to reap the benefits of AI systems, society needs to be\nable to trust them. Inspired by decades of progress in trustworthy computing,\nwe suggest what trustworthy properties would be desired of AI systems. By\nenumerating a set of new research questions, we explore one approach--formal\nverification--for ensuring trust in AI. Trustworthy AI ups the ante on both\ntrustworthy computing and formal methods.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 22:45:36 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Wing", "Jeannette M.", ""]]}, {"id": "2002.06278", "submitter": "Amir-Hossein Karimi", "authors": "Amir-Hossein Karimi, Bernhard Sch\\\"olkopf, Isabel Valera", "title": "Algorithmic Recourse: from Counterfactual Explanations to Interventions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning is increasingly used to inform consequential\ndecision-making (e.g., pre-trial bail and loan approval), it becomes important\nto explain how the system arrived at its decision, and also suggest actions to\nachieve a favorable decision. Counterfactual explanations -- \"how the world\nwould have (had) to be different for a desirable outcome to occur\" -- aim to\nsatisfy these criteria. Existing works have primarily focused on designing\nalgorithms to obtain counterfactual explanations for a wide range of settings.\nHowever, one of the main objectives of \"explanations as a means to help a\ndata-subject act rather than merely understand\" has been overlooked. In\nlayman's terms, counterfactual explanations inform an individual where they\nneed to get to, but not how to get there. In this work, we rely on causal\nreasoning to caution against the use of counterfactual explanations as a\nrecommendable set of actions for recourse. Instead, we propose a shift of\nparadigm from recourse via nearest counterfactual explanations to recourse\nthrough minimal interventions, moving the focus from explanations to\nrecommendations. Finally, we provide the reader with an extensive discussion on\nhow to realistically achieve recourse beyond structural interventions.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 22:49:42 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 16:48:42 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 21:19:02 GMT"}, {"version": "v4", "created": "Thu, 8 Oct 2020 15:15:33 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Karimi", "Amir-Hossein", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Valera", "Isabel", ""]]}, {"id": "2002.06289", "submitter": "Antoni Rosinol", "authors": "Antoni Rosinol, Arjun Gupta, Marcus Abate, Jingnan Shi, Luca Carlone", "title": "3D Dynamic Scene Graphs: Actionable Spatial Perception with Places,\n  Objects, and Humans", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a unified representation for actionable spatial perception: 3D\nDynamic Scene Graphs. Scene graphs are directed graphs where nodes represent\nentities in the scene (e.g. objects, walls, rooms), and edges represent\nrelations (e.g. inclusion, adjacency) among nodes. Dynamic scene graphs (DSGs)\nextend this notion to represent dynamic scenes with moving agents (e.g. humans,\nrobots), and to include actionable information that supports planning and\ndecision-making (e.g. spatio-temporal relations, topology at different levels\nof abstraction). Our second contribution is to provide the first fully\nautomatic Spatial PerceptIon eNgine(SPIN) to build a DSG from visual-inertial\ndata. We integrate state-of-the-art techniques for object and human detection\nand pose estimation, and we describe how to robustly infer object, robot, and\nhuman nodes in crowded scenes. To the best of our knowledge, this is the first\npaper that reconciles visual-inertial SLAM and dense human mesh tracking.\nMoreover, we provide algorithms to obtain hierarchical representations of\nindoor environments (e.g. places, structures, rooms) and their relations. Our\nthird contribution is to demonstrate the proposed spatial perception engine in\na photo-realistic Unity-based simulator, where we assess its robustness and\nexpressiveness. Finally, we discuss the implications of our proposal on modern\nrobotics applications. 3D Dynamic Scene Graphs can have a profound impact on\nplanning and decision-making, human-robot interaction, long-term autonomy, and\nscene prediction. A video abstract is available at https://youtu.be/SWbofjhyPzI\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 00:46:32 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 22:39:39 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Rosinol", "Antoni", ""], ["Gupta", "Arjun", ""], ["Abate", "Marcus", ""], ["Shi", "Jingnan", ""], ["Carlone", "Luca", ""]]}, {"id": "2002.06290", "submitter": "Michal Warchalski", "authors": "Michal Warchalski, Dimitrije Radojevic, Milos Milosevic", "title": "Deep RL Agent for a Real-Time Action Strategy Game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a reinforcement learning environment based on Heroic - Magic\nDuel, a 1 v 1 action strategy game. This domain is non-trivial for several\nreasons: it is a real-time game, the state space is large, the information\ngiven to the player before and at each step of a match is imperfect, and\ndistribution of actions is dynamic. Our main contribution is a deep\nreinforcement learning agent playing the game at a competitive level that we\ntrained using PPO and self-play with multiple competing agents, employing only\na simple reward of $\\pm 1$ depending on the outcome of a single match. Our best\nself-play agent, obtains around $65\\%$ win rate against the existing AI and\nover $50\\%$ win rate against a top human player.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 01:09:56 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Warchalski", "Michal", ""], ["Radojevic", "Dimitrije", ""], ["Milosevic", "Milos", ""]]}, {"id": "2002.06306", "submitter": "Emmanouil Antonios Platanios", "authors": "Emmanouil Antonios Platanios and Abulhair Saparov and Tom Mitchell", "title": "Jelly Bean World: A Testbed for Never-Ending Learning", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": "International Conference on Learning Representations 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has shown growing success in recent years. However, current\nmachine learning systems are highly specialized, trained for particular\nproblems or domains, and typically on a single narrow dataset. Human learning,\non the other hand, is highly general and adaptable. Never-ending learning is a\nmachine learning paradigm that aims to bridge this gap, with the goal of\nencouraging researchers to design machine learning systems that can learn to\nperform a wider variety of inter-related tasks in more complex environments. To\ndate, there is no environment or testbed to facilitate the development and\nevaluation of never-ending learning systems. To this end, we propose the Jelly\nBean World testbed. The Jelly Bean World allows experimentation over\ntwo-dimensional grid worlds which are filled with items and in which agents can\nnavigate. This testbed provides environments that are sufficiently complex and\nwhere more generally intelligent algorithms ought to perform better than\ncurrent state-of-the-art reinforcement learning approaches. It does so by\nproducing non-stationary environments and facilitating experimentation with\nmulti-task, multi-agent, multi-modal, and curriculum learning settings. We hope\nthat this new freely-available software will prompt new research and interest\nin the development and evaluation of never-ending learning systems and more\nbroadly, general intelligence systems.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 02:43:16 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Platanios", "Emmanouil Antonios", ""], ["Saparov", "Abulhair", ""], ["Mitchell", "Tom", ""]]}, {"id": "2002.06395", "submitter": "Giuseppe Di Molfetta Prof.", "authors": "Balthazar Casal\\'e, Giuseppe Di Molfetta, Hachem Kadri, Liva Ralaivola", "title": "Quantum Bandits", "comments": "All your comments are very welcome!", "journal-ref": "Quantum Machine Intelligence 2, 1-7 (2020)", "doi": "10.1007/s42484-020-00024-8", "report-no": null, "categories": "cs.LG cs.AI quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the quantum version of the bandit problem known as {\\em best arm\nidentification} (BAI). We first propose a quantum modeling of the BAI problem,\nwhich assumes that both the learning agent and the environment are quantum; we\nthen propose an algorithm based on quantum amplitude amplification to solve\nBAI. We formally analyze the behavior of the algorithm on all instances of the\nproblem and we show, in particular, that it is able to get the optimal solution\nquadratically faster than what is known to hold in the classical case.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 15:17:11 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 14:13:18 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Casal\u00e9", "Balthazar", ""], ["Di Molfetta", "Giuseppe", ""], ["Kadri", "Hachem", ""], ["Ralaivola", "Liva", ""]]}, {"id": "2002.06397", "submitter": "Wei Hu", "authors": "Ermei Cao and Difeng Wang and Jiacheng Huang and Wei Hu", "title": "Open Knowledge Enrichment for Long-tail Entities", "comments": "Accepted by the 29th International World Wide Web Conference (WWW\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge bases (KBs) have gradually become a valuable asset for many AI\napplications. While many current KBs are quite large, they are widely\nacknowledged as incomplete, especially lacking facts of long-tail entities,\ne.g., less famous persons. Existing approaches enrich KBs mainly on completing\nmissing links or filling missing values. However, they only tackle a part of\nthe enrichment problem and lack specific considerations regarding long-tail\nentities. In this paper, we propose a full-fledged approach to knowledge\nenrichment, which predicts missing properties and infers true facts of\nlong-tail entities from the open Web. Prior knowledge from popular entities is\nleveraged to improve every enrichment step. Our experiments on the synthetic\nand real-world datasets and comparison with related work demonstrate the\nfeasibility and superiority of the approach.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 15:25:44 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 14:42:41 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Cao", "Ermei", ""], ["Wang", "Difeng", ""], ["Huang", "Jiacheng", ""], ["Hu", "Wei", ""]]}, {"id": "2002.06417", "submitter": "Chao Wang", "authors": "Chao Wang, Stephan Hasler, Manuel Muehlig, Frank Joublin, Antonello\n  Ceravola, Joerg Deigmoeller, Lydia Fischer", "title": "Designing Interaction for Multi-agent Cooperative System in an Office\n  Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future intelligent system will involve very various types of artificial\nagents, such as mobile robots, smart home infrastructure or personal devices,\nwhich share data and collaborate with each other to execute certain\ntasks.Designing an efficient human-machine interface, which can support users\nto express needs to the system, supervise the collaboration progress of\ndifferent entities and evaluate the result, will be challengeable. This paper\npresents the design and implementation of the human-machine interface of\nIntelligent Cyber-Physical system (ICPS),which is a multi-entity coordination\nsystem of robots and other smart devices in a working environment. ICPS gathers\nsensory data from entities and then receives users' command, then optimizes\nplans to utilize the capability of different entities to serve people. Using\nmulti-model interaction methods, e.g. graphical interfaces, speech interaction,\ngestures and facial expressions, ICPS is able to receive inputs from users\nthrough different entities, keep users aware of the progress and accomplish the\ntask efficiently\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 17:36:00 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Wang", "Chao", ""], ["Hasler", "Stephan", ""], ["Muehlig", "Manuel", ""], ["Joublin", "Frank", ""], ["Ceravola", "Antonello", ""], ["Deigmoeller", "Joerg", ""], ["Fischer", "Lydia", ""]]}, {"id": "2002.06432", "submitter": "Tom Silver", "authors": "Tom Silver and Rohan Chitnis", "title": "PDDLGym: Gym Environments from PDDL Problems", "comments": "ICAPS 2020 PRL Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We present PDDLGym, a framework that automatically constructs OpenAI Gym\nenvironments from PDDL domains and problems. Observations and actions in\nPDDLGym are relational, making the framework particularly well-suited for\nresearch in relational reinforcement learning and relational sequential\ndecision-making. PDDLGym is also useful as a generic framework for rapidly\nbuilding numerous, diverse benchmarks from a concise and familiar specification\nlanguage. We discuss design decisions and implementation details, and also\nillustrate empirical variations between the 20 built-in environments in terms\nof planning and model-learning difficulty. We hope that PDDLGym will facilitate\nbridge-building between the reinforcement learning community (from which Gym\nemerged) and the AI planning community (which produced PDDL). We look forward\nto gathering feedback from all those interested and expanding the set of\navailable environments and features accordingly. Code:\nhttps://github.com/tomsilver/pddlgym\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 19:10:21 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 23:33:35 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Silver", "Tom", ""], ["Chitnis", "Rohan", ""]]}, {"id": "2002.06487", "submitter": "Qingfeng Lan", "authors": "Qingfeng Lan, Yangchen Pan, Alona Fyshe, Martha White", "title": "Maxmin Q-learning: Controlling the Estimation Bias of Q-learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Q-learning suffers from overestimation bias, because it approximates the\nmaximum action value using the maximum estimated action value. Algorithms have\nbeen proposed to reduce overestimation bias, but we lack an understanding of\nhow bias interacts with performance, and the extent to which existing\nalgorithms mitigate bias. In this paper, we 1) highlight that the effect of\noverestimation bias on learning efficiency is environment-dependent; 2) propose\na generalization of Q-learning, called \\emph{Maxmin Q-learning}, which provides\na parameter to flexibly control bias; 3) show theoretically that there exists a\nparameter choice for Maxmin Q-learning that leads to unbiased estimation with a\nlower approximation variance than Q-learning; and 4) prove the convergence of\nour algorithm in the tabular case, as well as convergence of several previous\nQ-learning variants, using a novel Generalized Q-learning framework. We\nempirically verify that our algorithm better controls estimation bias in toy\nenvironments, and that it achieves superior performance on several benchmark\nproblems.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 02:02:23 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Lan", "Qingfeng", ""], ["Pan", "Yangchen", ""], ["Fyshe", "Alona", ""], ["White", "Martha", ""]]}, {"id": "2002.06501", "submitter": "Hikaru Ogura", "authors": "Hikaru Ogura and Akiko Takeda", "title": "Convex Fairness Constrained Model Using Causal Effect Estimators", "comments": "10 pages, 5 figures, Accepted for the 2nd Workshop on Fairness,\n  Accountability, Transparency, Ethics and Society on the Web (FATES on the Web\n  2020), held in conjunction with the WWW'20", "journal-ref": null, "doi": "10.1145/3366424.3383556", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen much research on fairness in machine learning. Here,\nmean difference (MD) or demographic parity is one of the most popular measures\nof fairness. However, MD quantifies not only discrimination but also\nexplanatory bias which is the difference of outcomes justified by explanatory\nfeatures. In this paper, we devise novel models, called FairCEEs, which remove\ndiscrimination while keeping explanatory bias. The models are based on\nestimators of causal effect utilizing propensity score analysis. We prove that\nFairCEEs with the squared loss theoretically outperform a naive MD constraint\nmodel. We provide an efficient algorithm for solving FairCEEs in regression and\nbinary classification tasks. In our experiment on synthetic and real-world data\nin these two tasks, FairCEEs outperformed an existing model that considers\nexplanatory bias in specific cases.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 03:40:04 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Ogura", "Hikaru", ""], ["Takeda", "Akiko", ""]]}, {"id": "2002.06506", "submitter": "Yiming Zhang", "authors": "Yiming Zhang, Quan Vuong, Keith W. Ross", "title": "First Order Constrained Optimization in Policy Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning, an agent attempts to learn high-performing\nbehaviors through interacting with the environment, such behaviors are often\nquantified in the form of a reward function. However some aspects of\nbehavior-such as ones which are deemed unsafe and to be avoided-are best\ncaptured through constraints. We propose a novel approach called First Order\nConstrained Optimization in Policy Space (FOCOPS) which maximizes an agent's\noverall reward while ensuring the agent satisfies a set of cost constraints.\nUsing data generated from the current policy, FOCOPS first finds the optimal\nupdate policy by solving a constrained optimization problem in the\nnonparameterized policy space. FOCOPS then projects the update policy back into\nthe parametric policy space. Our approach has an approximate upper bound for\nworst-case constraint violation throughout training and is first-order in\nnature therefore simple to implement. We provide empirical evidence that our\nsimple approach achieves better performance on a set of constrained robotics\nlocomotive tasks.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 05:07:17 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 15:35:09 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Zhang", "Yiming", ""], ["Vuong", "Quan", ""], ["Ross", "Keith W.", ""]]}, {"id": "2002.06684", "submitter": "Rose Wang", "authors": "Rose E. Wang, Michael Everett, Jonathan P. How", "title": "R-MADDPG for Partially Observable Environments and Limited Communication", "comments": "Reinforcement Learning for Real Life (RL4RealLife) Workshop in the\n  36th International Conference on Machine Learning, Long Beach, California,\n  USA, 2019", "journal-ref": "Reinforcement Learning for Real Life (RL4RealLife) Workshop in the\n  36th International Conference on Machine Learning, Long Beach, California,\n  USA, 2019", "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There are several real-world tasks that would benefit from applying\nmultiagent reinforcement learning (MARL) algorithms, including the coordination\namong self-driving cars. The real world has challenging conditions for\nmultiagent learning systems, such as its partial observable and nonstationary\nnature. Moreover, if agents must share a limited resource (e.g. network\nbandwidth) they must all learn how to coordinate resource use. This paper\nintroduces a deep recurrent multiagent actor-critic framework (R-MADDPG) for\nhandling multiagent coordination under partial observable set-tings and limited\ncommunication. We investigate recurrency effects on performance and\ncommunication use of a team of agents. We demonstrate that the resulting\nframework learns time dependencies for sharing missing observations, handling\nresource limitations, and developing different communication patterns among\nagents.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 21:25:44 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 02:55:30 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Wang", "Rose E.", ""], ["Everett", "Michael", ""], ["How", "Jonathan P.", ""]]}, {"id": "2002.06703", "submitter": "Guy Davidson", "authors": "Guy Davidson, Brenden M. Lake", "title": "Investigating Simple Object Representations in Model-Free Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the benefits of augmenting state-of-the-art model-free deep\nreinforcement algorithms with simple object representations. Following the\nFrostbite challenge posited by Lake et al. (2017), we identify object\nrepresentations as a critical cognitive capacity lacking from current\nreinforcement learning agents. We discover that providing the Rainbow model\n(Hessel et al.,2018) with simple, feature-engineered object representations\nsubstantially boosts its performance on the Frostbite game from Atari 2600. We\nthen analyze the relative contributions of the representations of different\ntypes of objects, identify environment states where these representations are\nmost impactful, and examine how these representations aid in generalizing to\nnovel situations.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 23:10:41 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 22:00:30 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Davidson", "Guy", ""], ["Lake", "Brenden M.", ""]]}, {"id": "2002.06726", "submitter": "Ralph Abboud", "authors": "Ralph Abboud, \\.Ismail \\.Ilkan Ceylan, Radoslav Dimitrov", "title": "On the Approximability of Weighted Model Integration on DNF Structures", "comments": "To appear in Proceedings of the Seventeenth International Conference\n  on Principles of Knowledge Representation and Reasoning (KR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weighted model counting (WMC) consists of computing the weighted sum of all\nsatisfying assignments of a propositional formula. WMC is well-known to be\n#P-hard for exact solving, but admits a fully polynomial randomized\napproximation scheme (FPRAS) when restricted to DNF structures. In this work,\nwe study weighted model integration, a generalization of weighted model\ncounting which involves real variables in addition to propositional variables,\nand pose the following question: Does weighted model integration on DNF\nstructures admit an FPRAS? Building on classical results from approximate\nvolume computation and approximate weighted model counting, we show that\nweighted model integration on DNF structures can indeed be approximated for a\nclass of weight functions. Our approximation algorithm is based on three\nsubroutines, each of which can be a weak (i.e., approximate), or a strong\n(i.e., exact) oracle, and in all cases, comes along with accuracy guarantees.\nWe experimentally verify our approach over randomly generated DNF instances of\nvarying sizes, and show that our algorithm scales to large problem instances,\ninvolving up to 1K variables, which are currently out of reach for existing,\ngeneral-purpose weighted model integration solvers.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 00:29:41 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 12:59:45 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 09:27:12 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Abboud", "Ralph", ""], ["Ceylan", "\u0130smail \u0130lkan", ""], ["Dimitrov", "Radoslav", ""]]}, {"id": "2002.06735", "submitter": "George - Cosmin Poru\\c{s}niuc", "authors": "Alexandru \\c{S}erban, George Ila\\c{s}, George-Cosmin Poru\\c{s}niuc", "title": "SpotTheFake: An Initial Report on a New CNN-Enhanced Platform for\n  Counterfeit Goods Detection", "comments": "7 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The counterfeit goods trade represents nowadays more than 3.3% of the whole\nworld trade and thus it's a problem that needs now more than ever a lot of\nattention and a reliable solution that would reduce the negative impact it has\nover the modern society. This paper presents the design and early stage\ndevelopment of a novel counterfeit goods detection platform that makes use of\nthe outstsanding learning capabilities of the classical VGG16 convolutional\nmodel trained through the process of \"transfer learning\" and a multi-stage fake\ndetection procedure that proved to be not only reliable but also very robust in\nthe experiments we have conducted so far using an image dataset of various\ngoods which we gathered ourselves.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 01:51:22 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 16:36:31 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["\u015eerban", "Alexandru", ""], ["Ila\u015f", "George", ""], ["Poru\u015fniuc", "George-Cosmin", ""]]}, {"id": "2002.06746", "submitter": "Yoichi Chikahara", "authors": "Yoichi Chikahara, Shinsaku Sakaue, Akinori Fujino, Hisashi Kashima", "title": "Learning Individually Fair Classifier with Path-Specific Causal-Effect\n  Constraint", "comments": "23 pages, 9 figures, 3 tables; Accepted by AISTATS2021 (to appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is used to make decisions for individuals in various fields,\nwhich require us to achieve good prediction accuracy while ensuring fairness\nwith respect to sensitive features (e.g., race and gender). This problem,\nhowever, remains difficult in complex real-world scenarios. To quantify\nunfairness under such situations, existing methods utilize {\\it path-specific\ncausal effects}. However, none of them can ensure fairness for each individual\nwithout making impractical functional assumptions on the data. In this paper,\nwe propose a far more practical framework for learning an individually fair\nclassifier. To avoid restrictive functional assumptions, we define the {\\it\nprobability of individual unfairness} (PIU) and solve an optimization problem\nwhere PIU's upper bound, which can be estimated from data, is controlled to be\nclose to zero. We elucidate why our method can guarantee fairness for each\nindividual. Experimental results show that our method can learn an individually\nfair classifier at a slight cost of accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 02:46:17 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 08:29:23 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2021 19:36:28 GMT"}, {"version": "v4", "created": "Fri, 26 Feb 2021 04:50:41 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Chikahara", "Yoichi", ""], ["Sakaue", "Shinsaku", ""], ["Fujino", "Akinori", ""], ["Kashima", "Hisashi", ""]]}, {"id": "2002.06748", "submitter": "Zhaohong Sun", "authors": "Haris Aziz, Serge Gaspers, Zhaohong Sun, Toby Walsh", "title": "From Matching with Diversity Constraints to Matching with Regional\n  Quotas", "comments": "Conference version had some missing details", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, several new matching models have been proposed and\nstudied that take into account complex distributional constraints. Relevant\nlines of work include (1) school choice with diversity constraints where\nstudents have (possibly overlapping) types and (2) hospital-doctor matching\nwhere various regional quotas are imposed. In this paper, we present a\npolynomial-time reduction to transform an instance of (1) to an instance of (2)\nand we show how the feasibility and stability of corresponding matchings are\npreserved under the reduction. Our reduction provides a formal connection\nbetween two important strands of work on matching with distributional\nconstraints. We then apply the reduction in two ways. Firstly, we show that it\nis NP-complete to check whether a feasible and stable outcome for (1) exists.\nDue to our reduction, these NP-completeness results carry over to setting (2).\nIn view of this, we help unify some of the results that have been presented in\nthe literature. Secondly, if we have positive results for (2), then we have\ncorresponding results for (1). One key conclusion of our results is that\nfurther developments on axiomatic and algorithmic aspects of hospital-doctor\nmatching with regional quotas will result in corresponding results for school\nchoice with diversity constraints.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 02:51:46 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Aziz", "Haris", ""], ["Gaspers", "Serge", ""], ["Sun", "Zhaohong", ""], ["Walsh", "Toby", ""]]}, {"id": "2002.06806", "submitter": "Wolfgang Fuhl", "authors": "Wolfgang Fuhl, Efe Bozkir, Enkelejda Kasneci", "title": "Reinforcement learning for the privacy preservation and manipulation of\n  eye tracking data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an approach based on reinforcement learning for eye\ntracking data manipulation. It is based on two opposing agents, where one tries\nto classify the data correctly and the second agent looks for patterns in the\ndata, which get manipulated to hide specific information. We show that our\napproach is successfully applicable to preserve the privacy of the subjects.\nFor this purpose, we evaluate our approach iteratively to showcase the behavior\nof the reinforcement learning based approach. In addition, we evaluate the\nimportance of temporal, as well as spatial, information of eye tracking data\nfor specific classification goals. In the last part of our evaluation, we apply\nthe procedure to further public data sets without re-training the autoencoder\nor the data manipulator. The results show that the learned manipulation is\ngeneralized and applicable to unseen data as well.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 07:02:19 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 06:41:49 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Fuhl", "Wolfgang", ""], ["Bozkir", "Efe", ""], ["Kasneci", "Enkelejda", ""]]}, {"id": "2002.06838", "submitter": "Sheng Hu", "authors": "Sheng Hu, Yuqing Ma, Xianglong Liu, Yanlu Wei, Shihao Bai", "title": "Stratified Rule-Aware Network for Abstract Visual Reasoning", "comments": "AAAI 2021 paper. Code: https://github.com/husheng12345/SRAN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract reasoning refers to the ability to analyze information, discover\nrules at an intangible level, and solve problems in innovative ways. Raven's\nProgressive Matrices (RPM) test is typically used to examine the capability of\nabstract reasoning. The subject is asked to identify the correct choice from\nthe answer set to fill the missing panel at the bottom right of RPM (e.g., a\n3$\\times$3 matrix), following the underlying rules inside the matrix. Recent\nstudies, taking advantage of Convolutional Neural Networks (CNNs), have\nachieved encouraging progress to accomplish the RPM test. However, they partly\nignore necessary inductive biases of RPM solver, such as order sensitivity\nwithin each row/column and incremental rule induction. To address this problem,\nin this paper we propose a Stratified Rule-Aware Network (SRAN) to generate the\nrule embeddings for two input sequences. Our SRAN learns multiple granularity\nrule embeddings at different levels, and incrementally integrates the\nstratified embedding flows through a gated fusion module. With the help of\nembeddings, a rule similarity metric is applied to guarantee that SRAN can not\nonly be trained using a tuplet loss but also infer the best answer efficiently.\nWe further point out the severe defects existing in the popular RAVEN dataset\nfor RPM test, which prevent from the fair evaluation of the abstract reasoning\nability. To fix the defects, we propose an answer set generation algorithm\ncalled Attribute Bisection Tree (ABT), forming an improved dataset named\nImpartial-RAVEN (I-RAVEN for short). Extensive experiments are conducted on\nboth PGM and I-RAVEN datasets, showing that our SRAN outperforms the\nstate-of-the-art models by a considerable margin.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 08:44:05 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 08:46:49 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Hu", "Sheng", ""], ["Ma", "Yuqing", ""], ["Liu", "Xianglong", ""], ["Wei", "Yanlu", ""], ["Bai", "Shihao", ""]]}, {"id": "2002.06911", "submitter": "Philipp Wanko", "authors": "Pedro Cabalar and Jorge Fandinno and Torsten Schaub and Philipp Wanko", "title": "An ASP semantics for Constraints involving Conditional Aggregates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We elaborate upon the formal foundations of hybrid Answer Set Programming\n(ASP) and extend its underlying logical framework with aggregate functions over\nconstraint values and variables. This is achieved by introducing the construct\nof conditional expressions, which allow for considering two alternatives while\nevaluating constraints. Which alternative is considered is\ninterpretation-dependent and chosen according to an associated condition. We\nput some emphasis on logic programs with linear constraints and show how common\nASP aggregates can be regarded as particular cases of so-called conditional\nlinear constraints. Finally, we introduce a polynomial-size, modular and\nfaithful translation from our framework into regular (condition-free)\nConstraint ASP, outlining an implementation of conditional aggregates on top of\nexisting hybrid ASP solvers.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 12:25:01 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 15:37:28 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Cabalar", "Pedro", ""], ["Fandinno", "Jorge", ""], ["Schaub", "Torsten", ""], ["Wanko", "Philipp", ""]]}, {"id": "2002.06916", "submitter": "Fran\\c{c}ois Laferri\\`ere", "authors": "Pedro Cabalar (University of Corunna, Spain), Mart\\'in Di\\'eguez\n  (University of Pau, France), Torsten Schaub (1), Fran\\c{c}ois Laferri\\`ere\n  (1) ((1) University of Potsdam, Germany)", "title": "Implementing Dynamic Answer Set Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an implementation of an extension of Answer Set Programming\n(ASP) with language constructs from dynamic (and temporal) logic that provides\nan expressive computational framework for modeling dynamic applications.\nStarting from logical foundations, provided by dynamic and temporal equilibrium\nlogics over finite linear traces, we develop a translation of dynamic formulas\ninto temporal logic programs. This provides us with a normal form result\nestablishing the strong equivalence of formulas in different logics. Our\ntranslation relies on the introduction of auxiliary atoms to guarantee\npolynomial space complexity and to provide an embedding that is doomed to be\nimpossible over the same language. Finally, the reduction of dynamic formulas\nto temporal logic programs allows us to extend ASP with both approaches in a\nuniform way and to implement both extensions via temporal ASP solvers such as\ntelingo\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 12:34:14 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 16:33:34 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Cabalar", "Pedro", "", "University of Corunna, Spain"], ["Di\u00e9guez", "Mart\u00edn", "", "University of Pau, France"], ["Schaub", "Torsten", "", "University of Potsdam, Germany"], ["Laferri\u00e8re", "Fran\u00e7ois", "", "University of Potsdam, Germany"]]}, {"id": "2002.06920", "submitter": "Thomas Guyet", "authors": "Thomas Guyet (LACODAM), Philippe Besnard (IRIT)", "title": "Semantics of negative sequential patterns", "comments": "proceedings of European Conference on Artificial Intelligence (ECAI),\n  Jun 2020, Santiago de Compostela, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of pattern mining, a negative sequential pattern is specified by\nmeans of a sequence consisting of events to occur and of other events, called\nnegative events, to be absent. For instance, containment of the pattern\n$\\langle a\\ \\neg b\\ c\\rangle$ arises with an occurrence of a and a subsequent\noccurrence of c but no occurrence of b in between. This article is to shed\nlight on the ambiguity of such a seemingly intuitive notation and we identify\neight possible semantics for the containment relation between a pattern and a\nsequence. These semantics are illustrated and formally studied, in particular\nwe propose dominance and equivalence relations between them. Also we prove that\nsupport is anti-monotonic for some of these semantics. Some of the results are\ndiscussed with the aim of developing algorithms to extract efficiently frequent\nnegative patterns.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 12:48:37 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 12:46:41 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Guyet", "Thomas", "", "LACODAM"], ["Besnard", "Philippe", "", "IRIT"]]}, {"id": "2002.07019", "submitter": "Mingzhe Wang", "authors": "Mingzhe Wang, Jia Deng", "title": "Learning to Prove Theorems by Learning to Generate Theorems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of automated theorem proving, a key AI task. Deep\nlearning has shown promise for training theorem provers, but there are limited\nhuman-written theorems and proofs available for supervised learning. To address\nthis limitation, we propose to learn a neural generator that automatically\nsynthesizes theorems and proofs for the purpose of training a theorem prover.\nExperiments on real-world tasks demonstrate that synthetic data from our\napproach improves the theorem prover and advances the state of the art of\nautomated theorem proving in Metamath. Code is available at\nhttps://github.com/princeton-vl/MetaGen.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 16:06:02 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 04:33:04 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Wang", "Mingzhe", ""], ["Deng", "Jia", ""]]}, {"id": "2002.07033", "submitter": "Byungsoo Kim", "authors": "Youngduck Choi, Youngnam Lee, Junghyun Cho, Jineon Baek, Byungsoo Kim,\n  Yeongmin Cha, Dongmin Shin, Chan Bae, Jaewe Heo", "title": "Towards an Appropriate Query, Key, and Value Computation for Knowledge\n  Tracing", "comments": "L@S 2020", "journal-ref": null, "doi": "10.1145/3448139.3448188", "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge tracing, the act of modeling a student's knowledge through learning\nactivities, is an extensively studied problem in the field of computer-aided\neducation. Although models with attention mechanism have outperformed\ntraditional approaches such as Bayesian knowledge tracing and collaborative\nfiltering, they share two limitations. Firstly, the models rely on shallow\nattention layers and fail to capture complex relations among exercises and\nresponses over time. Secondly, different combinations of queries, keys and\nvalues for the self-attention layer for knowledge tracing were not extensively\nexplored. Usual practice of using exercises and interactions (exercise-response\npairs) as queries and keys/values respectively lacks empirical support. In this\npaper, we propose a novel Transformer based model for knowledge tracing, SAINT:\nSeparated Self-AttentIve Neural Knowledge Tracing. SAINT has an encoder-decoder\nstructure where exercise and response embedding sequence separately enter the\nencoder and the decoder respectively, which allows to stack attention layers\nmultiple times. To the best of our knowledge, this is the first work to suggest\nan encoder-decoder model for knowledge tracing that applies deep self-attentive\nlayers to exercises and responses separately. The empirical evaluations on a\nlarge-scale knowledge tracing dataset show that SAINT achieves the\nstate-of-the-art performance in knowledge tracing with the improvement of AUC\nby 1.8% compared to the current state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 09:21:19 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 05:14:09 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 06:57:13 GMT"}, {"version": "v4", "created": "Tue, 25 Aug 2020 01:02:22 GMT"}, {"version": "v5", "created": "Mon, 1 Feb 2021 02:42:50 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Choi", "Youngduck", ""], ["Lee", "Youngnam", ""], ["Cho", "Junghyun", ""], ["Baek", "Jineon", ""], ["Kim", "Byungsoo", ""], ["Cha", "Yeongmin", ""], ["Shin", "Dongmin", ""], ["Bae", "Chan", ""], ["Heo", "Jaewe", ""]]}, {"id": "2002.07111", "submitter": "Muhammad Umer", "authors": "Muhammad Umer, Glenn Dawson, Robi Polikar", "title": "Targeted Forgetting and False Memory Formation in Continual Learners\n  through Adversarial Backdoor Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks are well-known to be susceptible to catastrophic\nforgetting when continually learning from sequences of tasks. Various continual\n(or \"incremental\") learning approaches have been proposed to avoid catastrophic\nforgetting, but they are typically adversary agnostic, i.e., they do not\nconsider the possibility of a malicious attack. In this effort, we explore the\nvulnerability of Elastic Weight Consolidation (EWC), a popular continual\nlearning algorithm for avoiding catastrophic forgetting. We show that an\nintelligent adversary can bypass the EWC's defenses, and instead cause gradual\nand deliberate forgetting by introducing small amounts of misinformation to the\nmodel during training. We demonstrate such an adversary's ability to assume\ncontrol of the model via injection of \"backdoor\" attack samples on both\npermuted and split benchmark variants of the MNIST dataset. Importantly, once\nthe model has learned the adversarial misinformation, the adversary can then\ncontrol the amount of forgetting of any task. Equivalently, the malicious actor\ncan create a \"false memory\" about any task by inserting carefully-designed\nbackdoor samples to any fraction of the test instances of that task. Perhaps\nmost damaging, we show this vulnerability to be very acute; neural network\nmemory can be easily compromised with the addition of backdoor samples into as\nlittle as 1% of the training data of even a single task.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 18:13:09 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Umer", "Muhammad", ""], ["Dawson", "Glenn", ""], ["Polikar", "Robi", ""]]}, {"id": "2002.07113", "submitter": "Alaa Abdel-Hakim Ph. D.", "authors": "Alaa E. Abdel-Hakim and Wael Deabes", "title": "Handling Missing Annotations in Supervised Learning Data", "comments": "14 pages, 13 figures, 2 tables", "journal-ref": "Abdel Hakim, Alaa E., and Wael Deabes. \"Can People Really Do\n  Nothing? Handling Annotation Gaps in ADL Sensor Data.\" Algorithms 12, no. 10\n  (2019): 217", "doi": "10.3390/a12100217", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data annotation is an essential stage in supervised learning. However, the\nannotation process is exhaustive and time consuming, specially for large\ndatasets. Activities of Daily Living (ADL) recognition is an example of systems\nthat exploit very large raw sensor data readings. In such systems, sensor\nreadings are collected from activity-monitoring sensors in a 24/7 manner. The\nsize of the generated dataset is so huge that it is almost impossible for a\nhuman annotator to give a certain label to every single instance in the\ndataset. This results in annotation gaps in the input data to the adopting\nsupervised learning system. The performance of the recognition system is\nnegatively affected by these gaps. In this work, we propose and investigate\nthree different paradigms to handle these gaps. In the first paradigm, the gaps\nare taken out by dropping all unlabeled readings. A single \"Unknown\" or\n\"Do-Nothing\" label is given to the unlabeled readings within the operation of\nthe second paradigm. The last paradigm handles these gaps by giving every one\nof them a unique label identifying the encapsulating deterministic labels.\nAlso, we propose a semantic preprocessing method of annotation gaps by\nconstructing a hybrid combination of some of these paradigms for further\nperformance improvement. The performance of the proposed three paradigms and\ntheir hybrid combination is evaluated using an ADL benchmark dataset containing\nmore than $2.5\\times 10^6$ sensor readings that had been collected over more\nthan nine months. The evaluation results emphasize the performance contrast\nunder the operation of each paradigm and support a specific gap handling\napproach for better performance.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 18:23:56 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Abdel-Hakim", "Alaa E.", ""], ["Deabes", "Wael", ""]]}, {"id": "2002.07125", "submitter": "Simon Du", "authors": "Simon S. Du, Jason D. Lee, Gaurav Mahajan, Ruosong Wang", "title": "Agnostic Q-learning with Function Approximation in Deterministic\n  Systems: Tight Bounds on Approximation Error and Sample Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current paper studies the problem of agnostic $Q$-learning with function\napproximation in deterministic systems where the optimal $Q$-function is\napproximable by a function in the class $\\mathcal{F}$ with approximation error\n$\\delta \\ge 0$. We propose a novel recursion-based algorithm and show that if\n$\\delta = O\\left(\\rho/\\sqrt{\\dim_E}\\right)$, then one can find the optimal\npolicy using $O\\left(\\dim_E\\right)$ trajectories, where $\\rho$ is the gap\nbetween the optimal $Q$-value of the best actions and that of the second-best\nactions and $\\dim_E$ is the Eluder dimension of $\\mathcal{F}$. Our result has\ntwo implications:\n  1) In conjunction with the lower bound in [Du et al., ICLR 2020], our upper\nbound suggests that the condition $\\delta =\n\\widetilde{\\Theta}\\left(\\rho/\\sqrt{\\mathrm{dim}_E}\\right)$ is necessary and\nsufficient for algorithms with polynomial sample complexity.\n  2) In conjunction with the lower bound in [Wen and Van Roy, NIPS 2013], our\nupper bound suggests that the sample complexity\n$\\widetilde{\\Theta}\\left(\\mathrm{dim}_E\\right)$ is tight even in the agnostic\nsetting.\n  Therefore, we settle the open problem on agnostic $Q$-learning proposed in\n[Wen and Van Roy, NIPS 2013]. We further extend our algorithm to the stochastic\nreward setting and obtain similar results.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 18:41:49 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Du", "Simon S.", ""], ["Lee", "Jason D.", ""], ["Mahajan", "Gaurav", ""], ["Wang", "Ruosong", ""]]}, {"id": "2002.07147", "submitter": "Aaron Roth", "authors": "Christopher Jung and Sampath Kannan and Changhwa Lee and Mallesh M.\n  Pai and Aaron Roth and Rakesh Vohra", "title": "Fair Prediction with Endogenous Behavior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.TH cs.AI cs.GT cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is increasing regulatory interest in whether machine learning\nalgorithms deployed in consequential domains (e.g. in criminal justice) treat\ndifferent demographic groups \"fairly.\" However, there are several proposed\nnotions of fairness, typically mutually incompatible. Using criminal justice as\nan example, we study a model in which society chooses an incarceration rule.\nAgents of different demographic groups differ in their outside options (e.g.\nopportunity for legal employment) and decide whether to commit crimes. We show\nthat equalizing type I and type II errors across groups is consistent with the\ngoal of minimizing the overall crime rate; other popular notions of fairness\nare not.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:07:25 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Jung", "Christopher", ""], ["Kannan", "Sampath", ""], ["Lee", "Changhwa", ""], ["Pai", "Mallesh M.", ""], ["Roth", "Aaron", ""], ["Vohra", "Rakesh", ""]]}, {"id": "2002.07217", "submitter": "Romain Lopez", "authors": "Romain Lopez, Pierre Boyeau, Nir Yosef, Michael I. Jordan and Jeffrey\n  Regier", "title": "Decision-Making with Auto-Encoding Variational Bayes", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To make decisions based on a model fit with auto-encoding variational Bayes\n(AEVB), practitioners often let the variational distribution serve as a\nsurrogate for the posterior distribution. This approach yields biased estimates\nof the expected risk, and therefore leads to poor decisions for two reasons.\nFirst, the model fit with AEVB may not equal the underlying data distribution.\nSecond, the variational distribution may not equal the posterior distribution\nunder the fitted model. We explore how fitting the variational distribution\nbased on several objective functions other than the ELBO, while continuing to\nfit the generative model based on the ELBO, affects the quality of downstream\ndecisions. For the probabilistic principal component analysis model, we\ninvestigate how importance sampling error, as well as the bias of the model\nparameter estimates, varies across several approximate posteriors when used as\nproposal distributions. Our theoretical results suggest that a posterior\napproximation distinct from the variational distribution should be used for\nmaking decisions. Motivated by these theoretical results, we propose learning\nseveral approximate proposals for the best model and combining them using\nmultiple importance sampling for decision-making. In addition to toy examples,\nwe present a full-fledged case study of single-cell RNA sequencing. In this\nchallenging instance of multiple hypothesis testing, our proposed approach\nsurpasses the current state of the art.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 19:23:36 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 17:34:20 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 18:01:59 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Lopez", "Romain", ""], ["Boyeau", "Pierre", ""], ["Yosef", "Nir", ""], ["Jordan", "Michael I.", ""], ["Regier", "Jeffrey", ""]]}, {"id": "2002.07236", "submitter": "Kourosh Hakhamaneshi", "authors": "Kourosh Hakhamaneshi, Keertana Settaluri, Pieter Abbeel, Vladimir\n  Stojanovic", "title": "GACEM: Generalized Autoregressive Cross Entropy Method for Multi-Modal\n  Black Box Constraint Satisfaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a new method of black-box optimization and constraint\nsatisfaction. Existing algorithms that have attempted to solve this problem are\nunable to consider multiple modes, and are not able to adapt to changes in\nenvironment dynamics. To address these issues, we developed a modified\nCross-Entropy Method (CEM) that uses a masked auto-regressive neural network\nfor modeling uniform distributions over the solution space. We train the model\nusing maximum entropy policy gradient methods from Reinforcement Learning. Our\nalgorithm is able to express complicated solution spaces, thus allowing it to\ntrack a variety of different solution regions. We empirically compare our\nalgorithm with variations of CEM, including one with a Gaussian prior with\nfixed variance, and demonstrate better performance in terms of: number of\ndiverse solutions, better mode discovery in multi-modal problems, and better\nsample efficiency in certain cases.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 20:21:20 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Hakhamaneshi", "Kourosh", ""], ["Settaluri", "Keertana", ""], ["Abbeel", "Pieter", ""], ["Stojanovic", "Vladimir", ""]]}, {"id": "2002.07282", "submitter": "Vikranth Dwaracherla", "authors": "Vikranth Dwaracherla, Benjamin Van Roy", "title": "Langevin DQN", "comments": "5 figures, 14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms that tackle deep exploration -- an important challenge in\nreinforcement learning -- have relied on epistemic uncertainty representation\nthrough ensembles or other hypermodels, exploration bonuses, or visitation\ncount distributions. An open question is whether deep exploration can be\nachieved by an incremental reinforcement learning algorithm that tracks a\nsingle point estimate, without additional complexity required to account for\nepistemic uncertainty. We answer this question in the affirmative. In\nparticular, we develop Langevin DQN, a variation of DQN that differs only in\nperturbing parameter updates with Gaussian noise and demonstrate through a\ncomputational study that the presented algorithm achieves deep exploration. We\nalso offer some intuition to how Langevin DQN achieves deep exploration. In\naddition, we present a modification of the Langevin DQN algorithm to improve\nthe computational efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 22:29:23 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 06:09:20 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Dwaracherla", "Vikranth", ""], ["Van Roy", "Benjamin", ""]]}, {"id": "2002.07338", "submitter": "Yujia Xie", "authors": "Yujia Xie, Tianyi Zhou, Yi Mao, Weizhu Chen", "title": "Conditional Self-Attention for Query-based Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-attention mechanisms have achieved great success on a variety of NLP\ntasks due to its flexibility of capturing dependency between arbitrary\npositions in a sequence. For problems such as query-based summarization (Qsumm)\nand knowledge graph reasoning where each input sequence is associated with an\nextra query, explicitly modeling such conditional contextual dependencies can\nlead to a more accurate solution, which however cannot be captured by existing\nself-attention mechanisms. In this paper, we propose \\textit{conditional\nself-attention} (CSA), a neural network module designed for conditional\ndependency modeling. CSA works by adjusting the pairwise attention between\ninput tokens in a self-attention module with the matching score of the inputs\nto the given query. Thereby, the contextual dependencies modeled by CSA will be\nhighly relevant to the query. We further studied variants of CSA defined by\ndifferent types of attention. Experiments on Debatepedia and HotpotQA benchmark\ndatasets show CSA consistently outperforms vanilla Transformer and previous\nmodels for the Qsumm problem.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 02:22:31 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Xie", "Yujia", ""], ["Zhou", "Tianyi", ""], ["Mao", "Yi", ""], ["Chen", "Weizhu", ""]]}, {"id": "2002.07375", "submitter": "Sankalp Garg", "authors": "Sankalp Garg, Aniket Bajpai, Mausam", "title": "Symbolic Network: Generalized Neural Policies for Relational MDPs", "comments": "In Proceeding of ICML 2020. Code can be found at\n  https://github.com/dair-iitd/symnet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Relational Markov Decision Process (RMDP) is a first-order representation\nto express all instances of a single probabilistic planning domain with\npossibly unbounded number of objects. Early work in RMDPs outputs generalized\n(instance-independent) first-order policies or value functions as a means to\nsolve all instances of a domain at once. Unfortunately, this line of work met\nwith limited success due to inherent limitations of the representation space\nused in such policies or value functions. Can neural models provide the missing\nlink by easily representing more complex generalized policies, thus making them\neffective on all instances of a given domain?\n  We present SymNet, the first neural approach for solving RMDPs that are\nexpressed in the probabilistic planning language of RDDL. SymNet trains a set\nof shared parameters for an RDDL domain using training instances from that\ndomain. For each instance, SymNet first converts it to an instance graph and\nthen uses relational neural models to compute node embeddings. It then scores\neach ground action as a function over the first-order action symbols and node\nembeddings related to the action. Given a new test instance from the same\ndomain, SymNet architecture with pre-trained parameters scores each ground\naction and chooses the best action. This can be accomplished in a single\nforward pass without any retraining on the test instance, thus implicitly\nrepresenting a neural generalized policy for the whole domain. Our experiments\non nine RDDL domains from IPPC demonstrate that SymNet policies are\nsignificantly better than random and sometimes even more effective than\ntraining a state-of-the-art deep reactive policy from scratch.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 05:03:17 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 17:05:59 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Garg", "Sankalp", ""], ["Bajpai", "Aniket", ""], ["Mausam", "", ""]]}, {"id": "2002.07381", "submitter": "Akira Taniguchi", "authors": "Akira Taniguchi, Yoshinobu Hagiwara, Tadahiro Taniguchi, Tetsunari\n  Inamura", "title": "Spatial Concept-Based Navigation with Human Speech Instructions via\n  Probabilistic Inference on Bayesian Generative Model", "comments": "Accepted to Advanced Robotics", "journal-ref": null, "doi": "10.1080/01691864.2020.1817777", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots are required to not only learn spatial concepts autonomously but also\nutilize such knowledge for various tasks in a domestic environment. Spatial\nconcept represents a multimodal place category acquired from the robot's\nspatial experience including vision, speech-language, and self-position. The\naim of this study is to enable a mobile robot to perform navigational tasks\nwith human speech instructions, such as `Go to the kitchen', via probabilistic\ninference on a Bayesian generative model using spatial concepts. Specifically,\npath planning was formalized as the maximization of probabilistic distribution\non the path-trajectory under speech instruction, based on a\ncontrol-as-inference framework. Furthermore, we described the relationship\nbetween probabilistic inference based on the Bayesian generative model and\ncontrol problem including reinforcement learning. We demonstrated path planning\nbased on human instruction using acquired spatial concepts to verify the\nusefulness of the proposed approach in the simulator and in real environments.\nExperimentally, places instructed by the user's speech commands showed high\nprobability values, and the trajectory toward the target place was correctly\nestimated. Our approach, based on probabilistic inference concerning\ndecision-making, can lead to further improvement in robot autonomy.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 05:35:29 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 09:23:29 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Taniguchi", "Akira", ""], ["Hagiwara", "Yoshinobu", ""], ["Taniguchi", "Tadahiro", ""], ["Inamura", "Tetsunari", ""]]}, {"id": "2002.07407", "submitter": "Dimitri Bertsekas", "authors": "Dimitri Bertsekas", "title": "Constrained Multiagent Rollout and Multidimensional Assignment with the\n  Auction Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an extension of the rollout algorithm that applies to constrained\ndeterministic dynamic programming, including challenging combinatorial\noptimization problems. The algorithm relies on a suboptimal policy, called base\nheuristic. Under suitable assumptions, we show that if the base heuristic\nproduces a feasible solution, the rollout algorithm has a cost improvement\nproperty: it produces a feasible solution, whose cost is no worse than the base\nheuristic's cost.\n  We then focus on multiagent problems, where the control at each stage\nconsists of multiple components (one per agent), which are coupled either\nthrough the cost function or the constraints or both. We show that the cost\nimprovement property is maintained with an alternative implementation that has\ngreatly reduced computational requirements, and makes possible the use of\nrollout in problems with many agents. We demonstrate this alternative algorithm\nby applying it to layered graph problems that involve both a spatial and a\ntemporal structure. We consider in some detail a prominent example of such\nproblems: multidimensional assignment, where we use the auction algorithm for\n2-dimensional assignment as a base heuristic. This auction algorithm is\nparticularly well-suited for our context, because through the use of prices, it\ncan advantageously use the solution of an assignment problem as a starting\npoint for solving other related assignment problems, and this can greatly speed\nup the execution of the rollout algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 07:09:06 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 06:28:02 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Bertsekas", "Dimitri", ""]]}, {"id": "2002.07408", "submitter": "Chaoqi Yang", "authors": "Chaoqi Yang, Junwei Lu, Xiaofeng Gao, Haishan Liu, Qiong Chen,\n  Gongshen Liu and Guihai Chen", "title": "MoTiAC: Multi-Objective Actor-Critics for Real-Time Bidding", "comments": "8 Pages, Extensive Experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online real-time bidding (RTB) is known as a complex auction game where ad\nplatforms seek to consider various influential key performance indicators\n(KPIs), like revenue and return on investment (ROI). The trade-off among these\ncompeting goals needs to be balanced on a massive scale. To address the\nproblem, we propose a multi-objective reinforcement learning algorithm, named\nMoTiAC, for the problem of bidding optimization with various goals.\nSpecifically, in MoTiAC, instead of using a fixed and linear combination of\nmultiple objectives, we compute adaptive weights overtime on the basis of how\nwell the current state agrees with the agent's prior. In addition, we provide\ninteresting properties of model updating and further prove that Pareto\noptimality could be guaranteed. We demonstrate the effectiveness of our method\non a real-world commercial dataset. Experiments show that the model outperforms\nall state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 07:16:39 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Yang", "Chaoqi", ""], ["Lu", "Junwei", ""], ["Gao", "Xiaofeng", ""], ["Liu", "Haishan", ""], ["Chen", "Qiong", ""], ["Liu", "Gongshen", ""], ["Chen", "Guihai", ""]]}, {"id": "2002.07418", "submitter": "Peng Zhang", "authors": "Peng Zhang, Jianye Hao, Weixun Wang, Hongyao Tang, Yi Ma, Yihai Duan,\n  Yan Zheng", "title": "KoGuN: Accelerating Deep Reinforcement Learning via Integrating Human\n  Suboptimal Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning agents usually learn from scratch, which requires a\nlarge number of interactions with the environment. This is quite different from\nthe learning process of human. When faced with a new task, human naturally have\nthe common sense and use the prior knowledge to derive an initial policy and\nguide the learning process afterwards. Although the prior knowledge may be not\nfully applicable to the new task, the learning process is significantly sped up\nsince the initial policy ensures a quick-start of learning and intermediate\nguidance allows to avoid unnecessary exploration. Taking this inspiration, we\npropose knowledge guided policy network (KoGuN), a novel framework that\ncombines human prior suboptimal knowledge with reinforcement learning. Our\nframework consists of a fuzzy rule controller to represent human knowledge and\na refine module to fine-tune suboptimal prior knowledge. The proposed framework\nis end-to-end and can be combined with existing policy-based reinforcement\nlearning algorithm. We conduct experiments on both discrete and continuous\ncontrol tasks. The empirical results show that our approach, which combines\nhuman suboptimal knowledge and RL, achieves significant improvement on learning\nefficiency of flat RL algorithms, even with very low-performance human prior\nknowledge.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 07:58:27 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 07:02:41 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Zhang", "Peng", ""], ["Hao", "Jianye", ""], ["Wang", "Weixun", ""], ["Tang", "Hongyao", ""], ["Ma", "Yi", ""], ["Duan", "Yihai", ""], ["Zheng", "Yan", ""]]}, {"id": "2002.07420", "submitter": "Santiago Ontanon", "authors": "Santiago Onta\\~n\\'on", "title": "An Overview of Distance and Similarity Functions for Structured Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notions of distance and similarity play a key role in many machine\nlearning approaches, and artificial intelligence (AI) in general, since they\ncan serve as an organizing principle by which individuals classify objects,\nform concepts and make generalizations. While distance functions for\npropositional representations have been thoroughly studied, work on distance\nfunctions for structured representations, such as graphs, frames or logical\nclauses, has been carried out in different communities and is much less\nunderstood. Specifically, a significant amount of work that requires the use of\na distance or similarity function for structured representations of data\nusually employs ad-hoc functions for specific applications. Therefore, the goal\nof this paper is to provide an overview of this work to identify connections\nbetween the work carried out in different areas and point out directions for\nfuture work.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 08:00:02 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Onta\u00f1\u00f3n", "Santiago", ""]]}, {"id": "2002.07434", "submitter": "Sheng Shi", "authors": "Sheng Shi, Xinfeng Zhang, Wei Fan", "title": "A Modified Perturbed Sampling Method for Local Interpretable\n  Model-agnostic Explanation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainability is a gateway between Artificial Intelligence and society as\nthe current popular deep learning models are generally weak in explaining the\nreasoning process and prediction results. Local Interpretable Model-agnostic\nExplanation (LIME) is a recent technique that explains the predictions of any\nclassifier faithfully by learning an interpretable model locally around the\nprediction. However, the sampling operation in the standard implementation of\nLIME is defective. Perturbed samples are generated from a uniform distribution,\nignoring the complicated correlation between features. This paper proposes a\nnovel Modified Perturbed Sampling operation for LIME (MPS-LIME), which is\nformalized as the clique set construction problem. In image classification,\nMPS-LIME converts the superpixel image into an undirected graph. Various\nexperiments show that the MPS-LIME explanation of the black-box model achieves\nmuch better performance in terms of understandability, fidelity, and\nefficiency.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 09:03:10 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Shi", "Sheng", ""], ["Zhang", "Xinfeng", ""], ["Fan", "Wei", ""]]}, {"id": "2002.07505", "submitter": "Hatem Khalloof", "authors": "Hatem Khalloof, Wilfried Jakob, Shadi Shahoud, Clemens Duepmeier and\n  Veit Hagenmeyer", "title": "A Scalable Method for Scheduling Distributed Energy Resources using\n  Parallelized Population-based Metaheuristics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen an increasing integration of distributed renewable\nenergy resources into existing electric power grids. Due to the uncertain\nnature of renewable energy resources, network operators are faced with new\nchallenges in balancing load and generation. In order to meet the new\nrequirements, intelligent distributed energy resource plants can be used which\nprovide as virtual power plants e.g. demand side management or flexible\ngeneration. However, the calculation of an adequate schedule for the unit\ncommitment of such distributed energy resources is a complex optimization\nproblem which is typically too complex for standard optimization algorithms if\nlarge numbers of distributed energy resources are considered. For solving such\ncomplex optimization tasks, population-based metaheuristics -- as e.g.\nevolutionary algorithms -- represent powerful alternatives. Admittedly,\nevolutionary algorithms do require lots of computational power for solving such\nproblems in a timely manner. One promising solution for this performance\nproblem is the parallelization of the usually time-consuming evaluation of\nalternative solutions. In the present paper, a new generic and highly scalable\nparallel method for unit commitment of distributed energy resources using\nmetaheuristic algorithms is presented. It is based on microservices, container\nvirtualization and the publish/subscribe messaging paradigm for scheduling\ndistributed energy resources. Scalability and applicability of the proposed\nsolution are evaluated by performing parallelized optimizations in a big data\nenvironment for three distinct distributed energy resource scheduling\nscenarios. The new method provides cluster or cloud parallelizability and is\nable to deal with a comparably large number of distributed energy resources.\nThe application of the new proposed method results in very good performance for\nscaling up optimization speed.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 11:51:28 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 13:02:27 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Khalloof", "Hatem", ""], ["Jakob", "Wilfried", ""], ["Shahoud", "Shadi", ""], ["Duepmeier", "Clemens", ""], ["Hagenmeyer", "Veit", ""]]}, {"id": "2002.07575", "submitter": "Dongchuan Yang", "authors": "Shaolong Sun, Dongchuan Yang, Ju-e Guo, Shouyang Wang", "title": "AdaEnsemble Learning Approach for Metro Passenger Flow Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate and timely metro passenger flow forecasting is critical for the\nsuccessful deployment of intelligent transportation systems. However, it is\nquite challenging to propose an efficient and robust forecasting approach due\nto the inherent randomness and variations of metro passenger flow. In this\nstudy, we present a novel adaptive ensemble (AdaEnsemble) learning approach to\naccurately forecast the volume of metro passenger flows, and it combines the\ncomplementary advantages of variational mode decomposition (VMD), seasonal\nautoregressive integrated moving averaging (SARIMA), multilayer perceptron\nnetwork (MLP) and long short-term memory (LSTM) network. The AdaEnsemble\nlearning approach consists of three important stages. The first stage applies\nVMD to decompose the metro passenger flows data into periodic component,\ndeterministic component and volatility component. Then we employ SARIMA model\nto forecast the periodic component, LSTM network to learn and forecast\ndeterministic component and MLP network to forecast volatility component. In\nthe last stage, the diverse forecasted components are reconstructed by another\nMLP network. The empirical results show that our proposed AdaEnsemble learning\napproach not only has the best forecasting performance compared with the\nstate-of-the-art models but also appears to be the most promising and robust\nbased on the historical passenger flow data in Shenzhen subway system and\nseveral standard evaluation measures.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 14:18:53 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 13:34:55 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Sun", "Shaolong", ""], ["Yang", "Dongchuan", ""], ["Guo", "Ju-e", ""], ["Wang", "Shouyang", ""]]}, {"id": "2002.07650", "submitter": "Andrey Malinin Dr.", "authors": "Andrey Malinin, Mark Gales", "title": "Uncertainty Estimation in Autoregressive Structured Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty estimation is important for ensuring safety and robustness of AI\nsystems. While most research in the area has focused on un-structured\nprediction tasks, limited work has investigated general uncertainty estimation\napproaches for structured prediction. Thus, this work aims to investigate\nuncertainty estimation for autoregressive structured prediction tasks within a\nsingle unified and interpretable probabilistic ensemble-based framework. We\nconsider: uncertainty estimation for sequence data at the token-level and\ncomplete sequence-level; interpretations for, and applications of, various\nmeasures of uncertainty; and discuss both the theoretical and practical\nchallenges associated with obtaining them. This work also provides baselines\nfor token-level and sequence-level error detection, and sequence-level\nout-of-domain input detection on the WMT'14 English-French and WMT'17\nEnglish-German translation and LibriSpeech speech recognition datasets.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 15:40:13 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 12:03:10 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 10:31:28 GMT"}, {"version": "v4", "created": "Wed, 9 Dec 2020 09:01:22 GMT"}, {"version": "v5", "created": "Thu, 11 Feb 2021 09:42:35 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Malinin", "Andrey", ""], ["Gales", "Mark", ""]]}, {"id": "2002.07655", "submitter": "Johannes Kleiner", "authors": "Johannes Kleiner and Sean Tull", "title": "The Mathematical Structure of Integrated Information Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.IT math.IT quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrated Information Theory is one of the leading models of consciousness.\nIt aims to describe both the quality and quantity of the conscious experience\nof a physical system, such as the brain, in a particular state. In this\ncontribution, we propound the mathematical structure of the theory, separating\nthe essentials from auxiliary formal tools. We provide a definition of a\ngeneralized IIT which has IIT 3.0 of Tononi et. al., as well as the Quantum IIT\nintroduced by Zanardi et. al. as special cases. This provides an axiomatic\ndefinition of the theory which may serve as the starting point for future\nformal investigations and as an introduction suitable for researchers with a\nformal background.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 15:44:02 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Kleiner", "Johannes", ""], ["Tull", "Sean", ""]]}, {"id": "2002.07775", "submitter": "Jeena Kleenankandy", "authors": "Jeena Kleenankandy, K. A. Abdul Nazeer (Department of Computer Science\n  and Engineering, National Institute of Technology Calicut, Kerala, India)", "title": "An enhanced Tree-LSTM architecture for sentence semantic modeling using\n  typed dependencies", "comments": "Accepted manuscript submitted to Journal of Information Processing\n  and Management ( Elsevier ) on June 11, 2020", "journal-ref": "Information Processing & Management, Elsevier (2020)", "doi": "10.1016/j.ipm.2020.102362", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tree-based Long short term memory (LSTM) network has become state-of-the-art\nfor modeling the meaning of language texts as they can effectively exploit the\ngrammatical syntax and thereby non-linear dependencies among words of the\nsentence. However, most of these models cannot recognize the difference in\nmeaning caused by a change in semantic roles of words or phrases because they\ndo not acknowledge the type of grammatical relations, also known as typed\ndependencies, in sentence structure. This paper proposes an enhanced LSTM\narchitecture, called relation gated LSTM, which can model the relationship\nbetween two inputs of a sequence using a control input. We also introduce a\nTree-LSTM model called Typed Dependency Tree-LSTM that uses the sentence\ndependency parse structure as well as the dependency type to embed sentence\nmeaning into a dense vector. The proposed model outperformed its type-unaware\ncounterpart in two typical NLP tasks - Semantic Relatedness Scoring and\nSentiment Analysis, in a lesser number of training epochs. The results were\ncomparable or competitive with other state-of-the-art models. Qualitative\nanalysis showed that changes in the voice of sentences had little effect on the\nmodel's predicted scores, while changes in nominal (noun) words had a more\nsignificant impact. The model recognized subtle semantic relationships in\nsentence pairs. The magnitudes of learned typed dependencies embeddings were\nalso in agreement with human intuitions. The research findings imply the\nsignificance of grammatical relations in sentence modeling. The proposed models\nwould serve as a base for future researches in this direction.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 18:10:03 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 09:45:26 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Kleenankandy", "Jeena", "", "Department of Computer Science\n  and Engineering, National Institute of Technology Calicut, Kerala, India"], ["Nazeer", "K. A. Abdul", "", "Department of Computer Science\n  and Engineering, National Institute of Technology Calicut, Kerala, India"]]}, {"id": "2002.07911", "submitter": "Sharath Chandra Raparthy", "authors": "Sharath Chandra Raparthy, Bhairav Mehta, Florian Golemo, Liam Paull", "title": "Generating Automatic Curricula via Self-Supervised Active Domain\n  Randomization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goal-directed Reinforcement Learning (RL) traditionally considers an agent\ninteracting with an environment, prescribing a real-valued reward to an agent\nproportional to the completion of some goal. Goal-directed RL has seen large\ngains in sample efficiency, due to the ease of reusing or generating new\nexperience by proposing goals. One approach,self-play, allows an agent to\n\"play\" against itself by alternatively setting and accomplishing goals,\ncreating a learned curriculum through which an agent can learn to accomplish\nprogressively more difficult goals. However, self-play has been limited to goal\ncurriculum learning or learning progressively harder goals within a single\nenvironment. Recent work on robotic agents has shown that varying the\nenvironment during training, for example with domain randomization, leads to\nmore robust transfer. As a result, we extend the self-play framework to jointly\nlearn a goal and environment curriculum, leading to an approach that learns the\nmost fruitful domain randomization strategy with self-play. Our method,\nSelf-Supervised Active Domain Randomization(SS-ADR), generates a coupled\ngoal-task curriculum, where agents learn through progressively more difficult\ntasks and environment variations. By encouraging the agent to try tasks that\nare just outside of its current capabilities, SS-ADR builds a domain\nrandomization curriculum that enables state-of-the-art results on\nvarioussim2real transfer tasks. Our results show that a curriculum of\nco-evolving the environment difficulty together with the difficulty of goals\nset in each environment provides practical benefits in the goal-directed tasks\ntested.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 22:45:29 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 18:24:29 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Raparthy", "Sharath Chandra", ""], ["Mehta", "Bhairav", ""], ["Golemo", "Florian", ""], ["Paull", "Liam", ""]]}, {"id": "2002.07917", "submitter": "Nima Noorshams", "authors": "Nima Noorshams, Saurabh Verma, Aude Hofleitner", "title": "TIES: Temporal Interaction Embeddings For Enhancing Social Media\n  Integrity At Facebook", "comments": "Submitted to KDD 2020 applied DS track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since its inception, Facebook has become an integral part of the online\nsocial community. People rely on Facebook to make connections with others and\nbuild communities. As a result, it is paramount to protect the integrity of\nsuch a rapidly growing network in a fast and scalable manner. In this paper, we\npresent our efforts to protect various social media entities at Facebook from\npeople who try to abuse our platform. We present a novel Temporal Interaction\nEmbeddingS (TIES) model that is designed to capture rogue social interactions\nand flag them for further suitable actions. TIES is a supervised, deep\nlearning, production ready model at Facebook-scale networks. Prior works on\nintegrity problems are mostly focused on capturing either only static or\ncertain dynamic features of social entities. In contrast, TIES can capture both\nthese variant behaviors in a unified model owing to the recent strides made in\nthe domains of graph embedding and deep sequential pattern learning. To show\nthe real-world impact of TIES, we present a few applications especially for\npreventing spread of misinformation, fake account detection, and reducing ads\npayment risks in order to enhance the platform's integrity.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 22:56:40 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Noorshams", "Nima", ""], ["Verma", "Saurabh", ""], ["Hofleitner", "Aude", ""]]}, {"id": "2002.07956", "submitter": "Bhairav Mehta", "authors": "Bhairav Mehta, Tristan Deleu, Sharath Chandra Raparthy, Chris J. Pal,\n  Liam Paull", "title": "Curriculum in Gradient-Based Meta-Reinforcement Learning", "comments": "11 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based meta-learners such as Model-Agnostic Meta-Learning (MAML) have\nshown strong few-shot performance in supervised and reinforcement learning\nsettings. However, specifically in the case of meta-reinforcement learning\n(meta-RL), we can show that gradient-based meta-learners are sensitive to task\ndistributions. With the wrong curriculum, agents suffer the effects of\nmeta-overfitting, shallow adaptation, and adaptation instability. In this work,\nwe begin by highlighting intriguing failure cases of gradient-based meta-RL and\nshow that task distributions can wildly affect algorithmic outputs, stability,\nand performance. To address this problem, we leverage insights from recent\nliterature on domain randomization and propose meta Active Domain Randomization\n(meta-ADR), which learns a curriculum of tasks for gradient-based meta-RL in a\nsimilar as ADR does for sim2real transfer. We show that this approach induces\nmore stable policies on a variety of simulated locomotion and navigation tasks.\nWe assess in- and out-of-distribution generalization and find that the learned\ntask distributions, even in an unstructured task space, greatly improve the\nadaptation performance of MAML. Finally, we motivate the need for better\nbenchmarking in meta-RL that prioritizes \\textit{generalization} over\nsingle-task adaption performance.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 01:40:45 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Mehta", "Bhairav", ""], ["Deleu", "Tristan", ""], ["Raparthy", "Sharath Chandra", ""], ["Pal", "Chris J.", ""], ["Paull", "Liam", ""]]}, {"id": "2002.07985", "submitter": "Zifan Wang", "authors": "Zifan Wang and Piotr Mardziel and Anupam Datta and Matt Fredrikson", "title": "Interpreting Interpretations: Organizing Attribution Methods by Criteria", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by distinct, though related, criteria, a growing number of\nattribution methods have been developed tointerprete deep learning. While each\nrelies on the interpretability of the concept of \"importance\" and our ability\nto visualize patterns, explanations produced by the methods often differ. As a\nresult, input attribution for vision models fail to provide any level of human\nunderstanding of model behaviour. In this work we expand the foundationsof\nhuman-understandable concepts with which attributionscan be interpreted beyond\n\"importance\" and its visualization; we incorporate the logical concepts of\nnecessity andsufficiency, and the concept of proportionality. We definemetrics\nto represent these concepts as quantitative aspectsof an attribution. This\nallows us to compare attributionsproduced by different methods and interpret\nthem in novelways: to what extent does this attribution (or this\nmethod)represent the necessity or sufficiency of the highlighted inputs, and to\nwhat extent is it proportional? We evaluate our measures on a collection of\nmethods explaining convolutional neural networks (CNN) for image\nclassification. We conclude that some attribution methods are more appropriate\nfor interpretation in terms of necessity while others are in terms of\nsufficiency, while no method is always the most appropriate in terms of both.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 03:37:29 GMT"}, {"version": "v2", "created": "Sat, 4 Apr 2020 17:29:09 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Wang", "Zifan", ""], ["Mardziel", "Piotr", ""], ["Datta", "Anupam", ""], ["Fredrikson", "Matt", ""]]}, {"id": "2002.07994", "submitter": "Aadirupa Saha", "authors": "Aadirupa Saha and Aditya Gopalan", "title": "Best-item Learning in Random Utility Models with Subset Choices", "comments": "Accepted to 23rd International Conference on Artificial Intelligence\n  and Statistics (AISTATS), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of PAC learning the most valuable item from a pool of\n$n$ items using sequential, adaptively chosen plays of subsets of $k$ items,\nwhen, upon playing a subset, the learner receives relative feedback sampled\naccording to a general Random Utility Model (RUM) with independent noise\nperturbations to the latent item utilities. We identify a new property of such\na RUM, termed the minimum advantage, that helps in characterizing the\ncomplexity of separating pairs of items based on their relative win/loss\nempirical counts, and can be bounded as a function of the noise distribution\nalone. We give a learning algorithm for general RUMs, based on pairwise\nrelative counts of items and hierarchical elimination, along with a new PAC\nsample complexity guarantee of $O(\\frac{n}{c^2\\epsilon^2} \\log\n\\frac{k}{\\delta})$ rounds to identify an $\\epsilon$-optimal item with\nconfidence $1-\\delta$, when the worst case pairwise advantage in the RUM has\nsensitivity at least $c$ to the parameter gaps of items. Fundamental lower\nbounds on PAC sample complexity show that this is near-optimal in terms of its\ndependence on $n,k$ and $c$.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 03:57:16 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Saha", "Aadirupa", ""], ["Gopalan", "Aditya", ""]]}, {"id": "2002.08024", "submitter": "Hung Le", "authors": "Hung Le, Richard Socher, Steven C.H. Hoi", "title": "Non-Autoregressive Dialog State Tracking", "comments": "Accepted at ICLR 2020. International Conference on Learning\n  Representations (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent efforts in Dialogue State Tracking (DST) for task-oriented dialogues\nhave progressed toward open-vocabulary or generation-based approaches where the\nmodels can generate slot value candidates from the dialogue history itself.\nThese approaches have shown good performance gain, especially in complicated\ndialogue domains with dynamic slot values. However, they fall short in two\naspects: (1) they do not allow models to explicitly learn signals across\ndomains and slots to detect potential dependencies among (domain, slot) pairs;\nand (2) existing models follow auto-regressive approaches which incur high time\ncost when the dialogue evolves over multiple domains and multiple turns. In\nthis paper, we propose a novel framework of Non-Autoregressive Dialog State\nTracking (NADST) which can factor in potential dependencies among domains and\nslots to optimize the models towards better prediction of dialogue states as a\ncomplete set rather than separate slots. In particular, the non-autoregressive\nnature of our method not only enables decoding in parallel to significantly\nreduce the latency of DST for real-time dialogue response generation, but also\ndetect dependencies among slots at token level in addition to slot and domain\nlevel. Our empirical results show that our model achieves the state-of-the-art\njoint accuracy across all domains on the MultiWOZ 2.1 corpus, and the latency\nof our model is an order of magnitude lower than the previous state of the art\nas the dialogue history extends over time.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 06:39:26 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Le", "Hung", ""], ["Socher", "Richard", ""], ["Hoi", "Steven C. H.", ""]]}, {"id": "2002.08037", "submitter": "Tianpei Yang", "authors": "Tianpei Yang, Jianye Hao, Zhaopeng Meng, Zongzhang Zhang, Yujing Hu,\n  Yingfeng Cheng, Changjie Fan, Weixun Wang, Wulong Liu, Zhaodong Wang, and\n  Jiajie Peng", "title": "Efficient Deep Reinforcement Learning via Adaptive Policy Transfer", "comments": "Accepted by IJCAI'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer Learning (TL) has shown great potential to accelerate Reinforcement\nLearning (RL) by leveraging prior knowledge from past learned policies of\nrelevant tasks. Existing transfer approaches either explicitly computes the\nsimilarity between tasks or select appropriate source policies to provide\nguided explorations for the target task. However, how to directly optimize the\ntarget policy by alternatively utilizing knowledge from appropriate source\npolicies without explicitly measuring the similarity is currently missing. In\nthis paper, we propose a novel Policy Transfer Framework (PTF) to accelerate RL\nby taking advantage of this idea. Our framework learns when and which source\npolicy is the best to reuse for the target policy and when to terminate it by\nmodeling multi-policy transfer as the option learning problem. PTF can be\neasily combined with existing deep RL approaches. Experimental results show it\nsignificantly accelerates the learning process and surpasses state-of-the-art\npolicy transfer methods in terms of learning efficiency and final performance\nin both discrete and continuous action spaces.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 07:30:57 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 08:41:30 GMT"}, {"version": "v3", "created": "Mon, 25 May 2020 10:21:28 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Yang", "Tianpei", ""], ["Hao", "Jianye", ""], ["Meng", "Zhaopeng", ""], ["Zhang", "Zongzhang", ""], ["Hu", "Yujing", ""], ["Cheng", "Yingfeng", ""], ["Fan", "Changjie", ""], ["Wang", "Weixun", ""], ["Liu", "Wulong", ""], ["Wang", "Zhaodong", ""], ["Peng", "Jiajie", ""]]}, {"id": "2002.08082", "submitter": "Jieming Shi", "authors": "Jieming Shi, Tianyuan Jin, Renchi Yang, Xiaokui Xiao, Yin Yang", "title": "Realtime Index-Free Single Source SimRank Processing on Web-Scale Graphs", "comments": "To appear in PVLDB 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a graph G and a node u in G, a single source SimRank query evaluates\nthe similarity between u and every node v in G. Existing approaches to single\nsource SimRank computation incur either long query response time, or expensive\npre-computation, which needs to be performed again whenever the graph G\nchanges. Consequently, to our knowledge none of them is ideal for scenarios in\nwhich (i) query processing must be done in realtime, and (ii) the underlying\ngraph G is massive, with frequent updates.\n  Motivated by this, we propose SimPush, a novel algorithm that answers single\nsource SimRank queries without any pre-computation, and at the same time\nachieves significantly higher query processing speed than even the fastest\nknown index-based solutions. Further, SimPush provides rigorous result quality\nguarantees, and its high performance does not rely on any strong assumption of\nthe underlying graph. Specifically, compared to existing methods, SimPush\nemploys a radically different algorithmic design that focuses on (i)\nidentifying a small number of nodes relevant to the query, and subsequently\n(ii) computing statistics and performing residue push from these nodes only.\n  We prove the correctness of SimPush, analyze its time complexity, and compare\nits asymptotic performance with that of existing methods. Meanwhile, we\nevaluate the practical performance of SimPush through extensive experiments on\n8 real datasets. The results demonstrate that SimPush consistently outperforms\nall existing solutions, often by over an order of magnitude. In particular, on\na commodity machine, SimPush answers a single source SimRank query on a web\ngraph containing over 133 million nodes and 5.4 billion edges in under 62\nmilliseconds, with 0.00035 empirical error, while the fastest index-based\ncompetitor needs 1.18 seconds.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 09:38:40 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Shi", "Jieming", ""], ["Jin", "Tianyuan", ""], ["Yang", "Renchi", ""], ["Xiao", "Xiaokui", ""], ["Yang", "Yin", ""]]}, {"id": "2002.08103", "submitter": "Pierre Monnin", "authors": "Pierre Monnin, Miguel Couceiro, Amedeo Napoli, Adrien Coulet", "title": "Knowledge-Based Matching of $n$-ary Tuples", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-57855-8_4", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of data and knowledge sources are accessible by human\nand software agents in the expanding Semantic Web. Sources may differ in\ngranularity or completeness, and thus be complementary. Consequently, they\nshould be reconciled in order to unlock the full potential of their conjoint\nknowledge. In particular, units should be matched within and across sources,\nand their level of relatedness should be classified into equivalent, more\nspecific, or similar. This task is challenging since knowledge units can be\nheterogeneously represented in sources (e.g., in terms of vocabularies). In\nthis paper, we focus on matching n-ary tuples in a knowledge base with a\nrule-based methodology. To alleviate heterogeneity issues, we rely on domain\nknowledge expressed by ontologies. We tested our method on the biomedical\ndomain of pharmacogenomics by searching alignments among 50,435 n-ary tuples\nfrom four different real-world sources. Results highlight noteworthy agreements\nand particularities within and across sources.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 11:01:33 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 18:51:53 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Monnin", "Pierre", ""], ["Couceiro", "Miguel", ""], ["Napoli", "Amedeo", ""], ["Coulet", "Adrien", ""]]}, {"id": "2002.08114", "submitter": "Arindam Pal", "authors": "Subhra Mazumdar, Arindam Pal, Francesco Parisi, V.S. Subrahmanian", "title": "BB_Evac: Fast Location-Sensitive Behavior-Based Building Evacuation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.AI cs.DS cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Past work on evacuation planning assumes that evacuees will follow\ninstructions -- however, there is ample evidence that this is not the case.\nWhile some people will follow instructions, others will follow their own\ndesires. In this paper, we present a formal definition of a behavior-based\nevacuation problem (BBEP) in which a human behavior model is taken into account\nwhen planning an evacuation. We show that a specific form of constraints can be\nused to express such behaviors. We show that BBEPs can be solved exactly via an\ninteger program called BB_IP, and inexactly by a much faster algorithm that we\ncall BB_Evac. We conducted a detailed experimental evaluation of both\nalgorithms applied to buildings (though in principle the algorithms can be\napplied to any graphs) and show that the latter is an order of magnitude faster\nthan BB_IP while producing results that are almost as good on one real-world\nbuilding graph and as well as on several synthetically generated graphs.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 11:34:52 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Mazumdar", "Subhra", ""], ["Pal", "Arindam", ""], ["Parisi", "Francesco", ""], ["Subrahmanian", "V. S.", ""]]}, {"id": "2002.08136", "submitter": "Daniel Molina Dr.", "authors": "Daniel Molina and Javier Poyatos and Javier Del Ser and Salvador\n  Garc\\'ia and Amir Hussain and Francisco Herrera", "title": "Comprehensive Taxonomies of Nature- and Bio-inspired Optimization:\n  Inspiration versus Algorithmic Behavior, Critical Analysis and\n  Recommendations", "comments": "76 pages, 6 figures", "journal-ref": "Cognitive Computation 12:5 (2020) 897-939", "doi": "10.1007/s12559-020-09730-8", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, a great variety of nature- and bio-inspired algorithms has\nbeen reported in the literature. This algorithmic family simulates different\nbiological processes observed in Nature in order to efficiently address complex\noptimization problems. In the last years the number of bio-inspired\noptimization approaches in literature has grown considerably, reaching\nunprecedented levels that dark the future prospects of this field of research.\nThis paper addresses this problem by proposing two comprehensive,\nprinciple-based taxonomies that allow researchers to organize existing and\nfuture algorithmic developments into well-defined categories, considering two\ndifferent criteria: the source of inspiration and the behavior of each\nalgorithm. Using these taxonomies we review more than three hundred\npublications dealing with nature-inspired and bio-inspired algorithms, and\nproposals falling within each of these categories are examined, leading to a\ncritical summary of design trends and similarities between them, and the\nidentification of the most similar classical algorithm for each reviewed paper.\nFrom our analysis we conclude that a poor relationship is often found between\nthe natural inspiration of an algorithm and its behavior. Furthermore,\nsimilarities in terms of behavior between different algorithms are greater than\nwhat is claimed in their public disclosure: specifically, we show that more\nthan one-third of the reviewed bio-inspired solvers are versions of classical\nalgorithms. Grounded on the conclusions of our critical analysis, we give\nseveral recommendations and points of improvement for better methodological\npractices in this active and growing research field.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 12:34:45 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 09:27:38 GMT"}, {"version": "v3", "created": "Fri, 30 Apr 2021 13:54:37 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Molina", "Daniel", ""], ["Poyatos", "Javier", ""], ["Del Ser", "Javier", ""], ["Garc\u00eda", "Salvador", ""], ["Hussain", "Amir", ""], ["Herrera", "Francisco", ""]]}, {"id": "2002.08210", "submitter": "Ernest Wozniak PhD", "authors": "Henrik J. Putzer and Ernest Wozniak", "title": "A Structured Approach to Trustworthy Autonomous/Cognitive Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous systems with cognitive features are on their way into the market.\nWithin complex environments, they promise to implement complex and goal\noriented behavior even in a safety related context. This behavior is based on a\ncertain level of situational awareness (perception) and advanced de-cision\nmaking (deliberation). These systems in many cases are driven by artificial\nintelligence (e.g. neural networks). The problem with such complex systems and\nwith using AI technology is that there is no generally accepted approach to\nensure trustworthiness. This paper presents a framework to exactly fill this\ngap. It proposes a reference lifecycle as a structured approach that is based\non current safety standards and enhanced to meet the requirements of\nautonomous/cog-nitive systems and trustworthiness.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 14:36:27 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Putzer", "Henrik J.", ""], ["Wozniak", "Ernest", ""]]}, {"id": "2002.08242", "submitter": "Hai Xiao", "authors": "Hai Xiao, Jin Shang and Mengyuan Huang", "title": "AI Online Filters to Real World Image Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep artificial neural networks, trained with labeled data sets are widely\nused in numerous vision and robotics applications today. In terms of AI, these\nare called reflex models, referring to the fact that they do not self-evolve or\nactively adapt to environmental changes. As demand for intelligent robot\ncontrol expands to many high level tasks, reinforcement learning and state\nbased models play an increasingly important role. Herein, in computer vision\nand robotics domain, we study a novel approach to add reinforcement controls\nonto the image recognition reflex models to attain better overall performance,\nspecifically to a wider environment range beyond what is expected of the task\nreflex models. Follow a common infrastructure with environment sensing and AI\nbased modeling of self-adaptive agents, we implement multiple types of AI\ncontrol agents. To the end, we provide comparative results of these agents with\nbaseline, and an insightful analysis of their benefit to improve overall image\nrecognition performance in real world.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 08:23:14 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Xiao", "Hai", ""], ["Shang", "Jin", ""], ["Huang", "Mengyuan", ""]]}, {"id": "2002.08247", "submitter": "Amit Dhurandhar", "authors": "Tejaswini Pedapati, Avinash Balakrishnan, Karthikeyan Shanmugam and\n  Amit Dhurandhar", "title": "Learning Global Transparent Models Consistent with Local Contrastive\n  Explanations", "comments": null, "journal-ref": "NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a rich and growing literature on producing local\ncontrastive/counterfactual explanations for black-box models (e.g. neural\nnetworks).\n  In these methods, for an input, an explanation is in the form of a contrast\npoint differing in very few features from the original input and lying in a\ndifferent class. Other works try to build globally interpretable models like\ndecision trees and rule lists based on the data using actual labels or based on\nthe black-box models predictions. Although these interpretable global models\ncan be useful, they may not be consistent with local explanations from a\nspecific black-box of choice. In this work, we explore the question: Can we\nproduce a transparent global model that is simultaneously accurate and\nconsistent with the local (contrastive) explanations of the black-box model? We\nintroduce a natural local consistency metric that quantifies if the local\nexplanations and predictions of the black-box model are also consistent with\nthe proxy global transparent model. Based on a key insight we propose a novel\nmethod where we create custom boolean features from sparse local contrastive\nexplanations of the black-box model and then train a globally transparent model\non just these, and showcase empirically that such models have higher local\nconsistency compared with other known strategies, while still being close in\nperformance to models that are trained with access to the original data.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 15:45:42 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 23:37:44 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 13:01:15 GMT"}, {"version": "v4", "created": "Thu, 29 Oct 2020 00:34:34 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Pedapati", "Tejaswini", ""], ["Balakrishnan", "Avinash", ""], ["Shanmugam", "Karthikeyan", ""], ["Dhurandhar", "Amit", ""]]}, {"id": "2002.08277", "submitter": "Yixiao Zhang", "authors": "Yixiao Zhang, Xiaosong Wang, Ziyue Xu, Qihang Yu, Alan Yuille, Daguang\n  Xu", "title": "When Radiology Report Generation Meets Knowledge Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic radiology report generation has been an attracting research problem\ntowards computer-aided diagnosis to alleviate the workload of doctors in recent\nyears. Deep learning techniques for natural image captioning are successfully\nadapted to generating radiology reports. However, radiology image reporting is\ndifferent from the natural image captioning task in two aspects: 1) the\naccuracy of positive disease keyword mentions is critical in radiology image\nreporting in comparison to the equivalent importance of every single word in a\nnatural image caption; 2) the evaluation of reporting quality should focus more\non matching the disease keywords and their associated attributes instead of\ncounting the occurrence of N-gram. Based on these concerns, we propose to\nutilize a pre-constructed graph embedding module (modeled with a graph\nconvolutional neural network) on multiple disease findings to assist the\ngeneration of reports in this work. The incorporation of knowledge graph allows\nfor dedicated feature learning for each disease finding and the relationship\nmodeling between them. In addition, we proposed a new evaluation metric for\nradiology image reporting with the assistance of the same composed graph.\nExperimental results demonstrate the superior performance of the methods\nintegrated with the proposed graph embedding module on a publicly accessible\ndataset (IU-RR) of chest radiographs compared with previous approaches using\nboth the conventional evaluation metrics commonly adopted for image captioning\nand our proposed ones.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 16:39:42 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Zhang", "Yixiao", ""], ["Wang", "Xiaosong", ""], ["Xu", "Ziyue", ""], ["Yu", "Qihang", ""], ["Yuille", "Alan", ""], ["Xu", "Daguang", ""]]}, {"id": "2002.08303", "submitter": "Rusheng Zhang", "authors": "Rusheng Zhang, Xinze Zhou, Ozan K. Tonguz", "title": "Using AI for Mitigating the Impact of Network Delay in Cloud-based\n  Intelligent Traffic Signal Control", "comments": "6 pages, 3 figures, submitted to IEEE BlackseaComm 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advancements in cloud services, Internet of Things (IoT) and\nCellular networks have made cloud computing an attractive option for\nintelligent traffic signal control (ITSC). Such a method significantly reduces\nthe cost of cables, installation, number of devices used, and maintenance. ITSC\nsystems based on cloud computing lower the cost of the ITSC systems and make it\npossible to scale the system by utilizing the existing powerful cloud\nplatforms.\n  While such systems have significant potential, one of the critical problems\nthat should be addressed is the network delay. It is well known that network\ndelay in message propagation is hard to prevent, which could potentially\ndegrade the performance of the system or even create safety issues for vehicles\nat intersections.\n  In this paper, we introduce a new traffic signal control algorithm based on\nreinforcement learning, which performs well even under severe network delay.\nThe framework introduced in this paper can be helpful for all agent-based\nsystems using remote computing resources where network delay could be a\ncritical concern. Extensive simulation results obtained for different scenarios\nshow the viability of the designed algorithm to cope with network delay.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 17:30:07 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 03:49:44 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Zhang", "Rusheng", ""], ["Zhou", "Xinze", ""], ["Tonguz", "Ozan K.", ""]]}, {"id": "2002.08312", "submitter": "Sumit Purohit", "authors": "Sumit Purohit, Lawrence B. Holder, George Chin", "title": "ITeM: Independent Temporal Motifs to Summarize and Compare Temporal\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks are a fundamental and flexible way of representing various complex\nsystems. Many domains such as communication, citation, procurement, biology,\nsocial media, and transportation can be modeled as a set of entities and their\nrelationships. Temporal networks are a specialization of general networks where\nthe temporal evolution of the system is as important to understand as the\nstructure of the entities and relationships. We present the Independent\nTemporal Motif (ITeM) to characterize temporal graphs from different domains.\nThe ITeMs are edge-disjoint temporal motifs that can be used to model the\nstructure and the evolution of the graph. For a given temporal graph, we\nproduce a feature vector of ITeM frequencies and apply this distribution to the\ntask of measuring the similarity of temporal graphs. We show that ITeM has\nhigher accuracy than other motif frequency-based approaches. We define various\nmetrics based on ITeM that reveal salient properties of a temporal network. We\nalso present importance sampling as a method for efficiently estimating the\nITeM counts. We evaluate our approach on both synthetic and real temporal\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 17:47:46 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 01:26:52 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Purohit", "Sumit", ""], ["Holder", "Lawrence B.", ""], ["Chin", "George", ""]]}, {"id": "2002.08320", "submitter": "Diane Staheli", "authors": "Dennis Ross, Arunesh Sinha, Diane Staheli, Bill Streilein", "title": "Proceedings of the Artificial Intelligence for Cyber Security (AICS)\n  Workshop 2020", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The workshop will focus on the application of artificial intelligence to\nproblems in cyber security. AICS 2020 emphasis will be on human-machine teaming\nwithin the context of cyber security problems and will specifically explore\ncollaboration between human operators and AI technologies. The workshop will\naddress applicable areas of AI, such as machine learning, game theory, natural\nlanguage processing, knowledge representation, automated and assistive\nreasoning and human machine interactions. Further, cyber security application\nareas with a particular emphasis on the characterization and deployment of\nhuman-machine teaming will be the focus.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 18:12:00 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 22:03:20 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Ross", "Dennis", ""], ["Sinha", "Arunesh", ""], ["Staheli", "Diane", ""], ["Streilein", "Bill", ""]]}, {"id": "2002.08493", "submitter": "Gabriele Farina", "authors": "Gabriele Farina, Christian Kroer, and Tuomas Sandholm", "title": "Stochastic Regret Minimization in Extensive-Form Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte-Carlo counterfactual regret minimization (MCCFR) is the\nstate-of-the-art algorithm for solving sequential games that are too large for\nfull tree traversals. It works by using gradient estimates that can be computed\nvia sampling. However, stochastic methods for sequential games have not been\ninvestigated extensively beyond MCCFR. In this paper we develop a new framework\nfor developing stochastic regret minimization methods. This framework allows us\nto use any regret-minimization algorithm, coupled with any gradient estimator.\nThe MCCFR algorithm can be analyzed as a special case of our framework, and\nthis analysis leads to significantly-stronger theoretical on convergence, while\nsimultaneously yielding a simplified proof. Our framework allows us to\ninstantiate several new stochastic methods for solving sequential games. We\nshow extensive experiments on three games, where some variants of our methods\noutperform MCCFR.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 23:05:41 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Farina", "Gabriele", ""], ["Kroer", "Christian", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "2002.08512", "submitter": "Rachel Thomas", "authors": "Rachel Thomas and David Uminsky", "title": "The Problem with Metrics is a Fundamental Problem for AI", "comments": "Accepted to EDSC (Ethics of Data Science Conference) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing a given metric is a central aspect of most current AI approaches,\nyet overemphasizing metrics leads to manipulation, gaming, a myopic focus on\nshort-term goals, and other unexpected negative consequences. This poses a\nfundamental contradiction for AI development. Through a series of real-world\ncase studies, we look at various aspects of where metrics go wrong in practice\nand aspects of how our online environment and current business practices are\nexacerbating these failures. Finally, we propose a framework towards mitigating\nthe harms caused by overemphasis of metrics within AI by: (1) using a slate of\nmetrics to get a fuller and more nuanced picture, (2) combining metrics with\nqualitative accounts, and (3) involving a range of stakeholders, including\nthose who will be most impacted.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 00:56:11 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Thomas", "Rachel", ""], ["Uminsky", "David", ""]]}, {"id": "2002.08526", "submitter": "David Eriksson", "authors": "David Eriksson and Matthias Poloczek", "title": "Scalable Constrained Bayesian Optimization", "comments": "To appear in Proceedings of AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The global optimization of a high-dimensional black-box function under\nblack-box constraints is a pervasive task in machine learning, control, and\nengineering. These problems are challenging since the feasible set is typically\nnon-convex and hard to find, in addition to the curses of dimensionality and\nthe heterogeneity of the underlying functions. In particular, these\ncharacteristics dramatically impact the performance of Bayesian optimization\nmethods, that otherwise have become the de facto standard for sample-efficient\noptimization in unconstrained settings, leaving practitioners with evolutionary\nstrategies or heuristics. We propose the scalable constrained Bayesian\noptimization (SCBO) algorithm that overcomes the above challenges and pushes\nthe applicability of Bayesian optimization far beyond the state-of-the-art. A\ncomprehensive experimental evaluation demonstrates that SCBO achieves excellent\nresults on a variety of benchmarks. To this end, we propose two new control\nproblems that we expect to be of independent value for the scientific\ncommunity.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 01:48:46 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 20:58:24 GMT"}, {"version": "v3", "created": "Sun, 28 Feb 2021 16:05:20 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Eriksson", "David", ""], ["Poloczek", "Matthias", ""]]}, {"id": "2002.08536", "submitter": "Kohei Yata", "authors": "Yusuke Narita, Shota Yasui, Kohei Yata", "title": "Off-policy Bandit and Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI econ.EM stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a method for predicting the performance of reinforcement learning\nand bandit algorithms, given historical data that may have been generated by a\ndifferent algorithm. Our estimator has the property that its prediction\nconverges in probability to the true performance of a counterfactual algorithm\nat the fast $\\sqrt{N}$ rate, as the sample size $N$ increases. We also show a\ncorrect way to estimate the variance of our prediction, thus allowing the\nanalyst to quantify the uncertainty in the prediction. These properties hold\neven when the analyst does not know which among a large number of potentially\nimportant state variables are really important. These theoretical guarantees\nmake our estimator safe to use. We finally apply it to improve advertisement\ndesign by a major advertisement company. We find that our method produces\nsmaller mean squared errors than state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 02:30:02 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 22:44:37 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Narita", "Yusuke", ""], ["Yasui", "Shota", ""], ["Yata", "Kohei", ""]]}, {"id": "2002.08539", "submitter": "Zhixin Liu", "authors": "Lei Gao, Mingxiang Chen, Qichang Chen, Ganzhong Luo, Nuoyi Zhu, Zhixin\n  Liu", "title": "Learn to Design the Heuristics for Vehicle Routing Problem", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an approach to learn the local-search heuristics that\niteratively improves the solution of Vehicle Routing Problem (VRP). A\nlocal-search heuristics is composed of a destroy operator that destructs a\ncandidate solution, and a following repair operator that rebuilds the\ndestructed one into a new one. The proposed neural network, as trained through\nactor-critic framework, consists of an encoder in form of a modified version of\nGraph Attention Network where node embeddings and edge embeddings are\nintegrated, and a GRU-based decoder rendering a pair of destroy and repair\noperators. Experiment results show that it outperforms both the traditional\nheuristics algorithms and the existing neural combinatorial optimization for\nVRP on medium-scale data set, and is able to tackle the large-scale data set\n(e.g., over 400 nodes) which is a considerable challenge in this area.\nMoreover, the need for expertise and handcrafted heuristics design is\neliminated due to the fact that the proposed network learns to design the\nheuristics with a better performance. Our implementation is available online.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 02:39:02 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Gao", "Lei", ""], ["Chen", "Mingxiang", ""], ["Chen", "Qichang", ""], ["Luo", "Ganzhong", ""], ["Zhu", "Nuoyi", ""], ["Liu", "Zhixin", ""]]}, {"id": "2002.08550", "submitter": "Sehoon Ha", "authors": "Sehoon Ha, Peng Xu, Zhenyu Tan, Sergey Levine, Jie Tan", "title": "Learning to Walk in the Real World with Minimal Human Effort", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliable and stable locomotion has been one of the most fundamental\nchallenges for legged robots. Deep reinforcement learning (deep RL) has emerged\nas a promising method for developing such control policies autonomously. In\nthis paper, we develop a system for learning legged locomotion policies with\ndeep RL in the real world with minimal human effort. The key difficulties for\non-robot learning systems are automatic data collection and safety. We overcome\nthese two challenges by developing a multi-task learning procedure and a\nsafety-constrained RL framework. We tested our system on the task of learning\nto walk on three different terrains: flat ground, a soft mattress, and a\ndoormat with crevices. Our system can automatically and efficiently learn\nlocomotion skills on a Minitaur robot with little human intervention. The\nsupplemental video can be found at: \\url{https://youtu.be/cwyiq6dCgOc}.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 03:36:39 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 18:35:02 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 05:46:51 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Ha", "Sehoon", ""], ["Xu", "Peng", ""], ["Tan", "Zhenyu", ""], ["Levine", "Sergey", ""], ["Tan", "Jie", ""]]}, {"id": "2002.08568", "submitter": "Reza Mirzazade Farkhani", "authors": "Yaohui Chen, Mansour Ahmadi, Reza Mirzazade farkhani, Boyu Wang, and\n  Long Lu", "title": "MEUZZ: Smart Seed Scheduling for Hybrid Fuzzing", "comments": "The 23rd International Symposium on Research in Attacks, Intrusions\n  and Defenses (RAID), Donostia / San Sebastian, Spain, October 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Seed scheduling is a prominent factor in determining the yields of hybrid\nfuzzing. Existing hybrid fuzzers schedule seeds based on fixed heuristics that\naim to predict input utilities. However, such heuristics are not generalizable\nas there exists no one-size-fits-all rule applicable to different programs.\nThey may work well on the programs from which they were derived, but not\nothers. To overcome this problem, we design a Machine learning-Enhanced hybrid\nfUZZing system (MEUZZ), which employs supervised machine learning for adaptive\nand generalizable seed scheduling. MEUZZ determines which new seeds are\nexpected to produce better fuzzing yields based on the knowledge learned from\npast seed scheduling decisions made on the same or similar programs. MEUZZ's\nlearning is based on a series of features extracted via code reachability and\ndynamic analysis, which incurs negligible runtime overhead (in microseconds).\nMoreover, MEUZZ automatically infers the data labels by evaluating the fuzzing\nperformance of each selected seed. As a result, MEUZZ is generally applicable\nto, and performs well on, various kinds of programs. Our evaluation shows MEUZZ\nsignificantly outperforms the state-of-the-art grey-box and hybrid fuzzers,\nachieving 27.1% more code coverage than QSYM. The learned models are reusable\nand transferable, which boosts fuzzing performance by 7.1% on average and\nimproves 68% of the 56 cross-program fuzzing campaigns. MEUZZ discovered 47\ndeeply hidden and previously unknown bugs--with 21 confirmed and fixed by the\ndevelopers--when fuzzing 8 well-tested programs with the same configurations as\nused in previous work.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 05:02:25 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 03:27:51 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Chen", "Yaohui", ""], ["Ahmadi", "Mansour", ""], ["farkhani", "Reza Mirzazade", ""], ["Wang", "Boyu", ""], ["Lu", "Long", ""]]}, {"id": "2002.08605", "submitter": "Harikrishna Narasimhan", "authors": "Qijia Jiang, Olaoluwa Adigun, Harikrishna Narasimhan, Mahdi Milani\n  Fard, Maya Gupta", "title": "Optimizing Black-box Metrics with Adaptive Surrogates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of training models with black-box and hard-to-optimize\nmetrics by expressing the metric as a monotonic function of a small number of\neasy-to-optimize surrogates. We pose the training problem as an optimization\nover a relaxed surrogate space, which we solve by estimating local gradients\nfor the metric and performing inexact convex projections. We analyze gradient\nestimates based on finite differences and local linear interpolations, and show\nconvergence of our approach under smoothness assumptions with respect to the\nsurrogates. Experimental results on classification and ranking problems verify\nthe proposal performs on par with methods that know the mathematical\nformulation, and adds notable value when the form of the metric is unknown.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 07:52:08 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Jiang", "Qijia", ""], ["Adigun", "Olaoluwa", ""], ["Narasimhan", "Harikrishna", ""], ["Fard", "Mahdi Milani", ""], ["Gupta", "Maya", ""]]}, {"id": "2002.08627", "submitter": "Scott McLachlan Dr", "authors": "Evangelia Kyrimi, Scott McLachlan, Kudakwashe Dube, Mariana R. Neves,\n  Ali Fahmi, Norman Fenton", "title": "A Comprehensive Scoping Review of Bayesian Networks in Healthcare: Past,\n  Present and Future", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  No comprehensive review of Bayesian networks (BNs) in healthcare has been\npublished in the past, making it difficult to organize the research\ncontributions in the present and identify challenges and neglected areas that\nneed to be addressed in the future. This unique and novel scoping review of BNs\nin healthcare provides an analytical framework for comprehensively\ncharacterizing the domain and its current state. The review shows that: (1) BNs\nin healthcare are not used to their full potential; (2) a generic BN\ndevelopment process is lacking; (3) limitations exists in the way BNs in\nhealthcare are presented in the literature, which impacts understanding,\nconsensus towards systematic methodologies, practice and adoption of BNs; and\n(4) a gap exists between having an accurate BN and a useful BN that impacts\nclinical practice. This review empowers researchers and clinicians with an\nanalytical framework and findings that will enable understanding of the need to\naddress the problems of restricted aims of BNs, ad hoc BN development methods,\nand the lack of BN adoption in practice. To map the way forward, the paper\nproposes future research directions and makes recommendations regarding BN\ndevelopment methods and adoption in practice.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 09:04:38 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 11:02:16 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Kyrimi", "Evangelia", ""], ["McLachlan", "Scott", ""], ["Dube", "Kudakwashe", ""], ["Neves", "Mariana R.", ""], ["Fahmi", "Ali", ""], ["Fenton", "Norman", ""]]}, {"id": "2002.08641", "submitter": "Tanya Motwani", "authors": "Tanya Motwani and Manojkumar Parmar", "title": "A Novel Framework for Selection of GANs for an Application", "comments": "11 pages, 1 figure, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Network (GAN) is a current focal point of research.\nThe body of knowledge is fragmented, leading to a trial-error method while\nselecting an appropriate GAN for a given scenario. We provide a comprehensive\nsummary of the evolution of GANs starting from its inception addressing issues\nlike mode collapse, vanishing gradient, unstable training and non-convergence.\nWe also provide a comparison of various GANs from the application point of\nview, its behaviour and implementation details. We propose a novel framework to\nidentify candidate GANs for a specific use case based on architecture, loss,\nregularization and divergence. We also discuss application of the framework\nusing an example, and we demonstrate a significant reduction in search space.\nThis efficient way to determine potential GANs lowers unit economics of AI\ndevelopment for organizations.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 09:51:48 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 09:48:42 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Motwani", "Tanya", ""], ["Parmar", "Manojkumar", ""]]}, {"id": "2002.08653", "submitter": "Wenhan Wang", "authors": "Wenhan Wang, Ge Li, Bo Ma, Xin Xia, Zhi Jin", "title": "Detecting Code Clones with Graph Neural Networkand Flow-Augmented\n  Abstract Syntax Tree", "comments": "Accepted by SANER 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code clones are semantically similar code fragments pairs that are\nsyntactically similar or different. Detection of code clones can help to reduce\nthe cost of software maintenance and prevent bugs. Numerous approaches of\ndetecting code clones have been proposed previously, but most of them focus on\ndetecting syntactic clones and do not work well on semantic clones with\ndifferent syntactic features. To detect semantic clones, researchers have tried\nto adopt deep learning for code clone detection to automatically learn latent\nsemantic features from data. Especially, to leverage grammar information,\nseveral approaches used abstract syntax trees (AST) as input and achieved\nsignificant progress on code clone benchmarks in various programming languages.\nHowever, these AST-based approaches still can not fully leverage the structural\ninformation of code fragments, especially semantic information such as control\nflow and data flow. To leverage control and data flow information, in this\npaper, we build a graph representation of programs called flow-augmented\nabstract syntax tree (FA-AST). We construct FA-AST by augmenting original ASTs\nwith explicit control and data flow edges. Then we apply two different types of\ngraph neural networks (GNN) on FA-AST to measure the similarity of code pairs.\nAs far as we have concerned, we are the first to apply graph neural networks on\nthe domain of code clone detection.\n  We apply our FA-AST and graph neural networks on two Java datasets: Google\nCode Jam and BigCloneBench. Our approach outperforms the state-of-the-art\napproaches on both Google Code Jam and BigCloneBench tasks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 10:18:37 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Wang", "Wenhan", ""], ["Li", "Ge", ""], ["Ma", "Bo", ""], ["Xia", "Xin", ""], ["Jin", "Zhi", ""]]}, {"id": "2002.08718", "submitter": "Xiaojie Gao", "authors": "Xiaojie Gao, Yueming Jin, Qi Dou, and Pheng-Ann Heng", "title": "Automatic Gesture Recognition in Robot-assisted Surgery with\n  Reinforcement Learning and Tree Search", "comments": "Accepted as a conference paper in ICRA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic surgical gesture recognition is fundamental for improving\nintelligence in robot-assisted surgery, such as conducting complicated tasks of\nsurgery surveillance and skill evaluation. However, current methods treat each\nframe individually and produce the outcomes without effective consideration on\nfuture information. In this paper, we propose a framework based on\nreinforcement learning and tree search for joint surgical gesture segmentation\nand classification. An agent is trained to segment and classify the surgical\nvideo in a human-like manner whose direct decisions are re-considered by tree\nsearch appropriately. Our proposed tree search algorithm unites the outputs\nfrom two designed neural networks, i.e., policy and value network. With the\nintegration of complementary information from distinct models, our framework is\nable to achieve the better performance than baseline methods using either of\nthe neural networks. For an overall evaluation, our developed approach\nconsistently outperforms the existing methods on the suturing task of JIGSAWS\ndataset in terms of accuracy, edit score and F1 score. Our study highlights the\nutilization of tree search to refine actions in reinforcement learning\nframework for surgical robotic applications.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 13:12:38 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Gao", "Xiaojie", ""], ["Jin", "Yueming", ""], ["Dou", "Qi", ""], ["Heng", "Pheng-Ann", ""]]}, {"id": "2002.08762", "submitter": "Konstantinos Bougiatiotis", "authors": "K. Bougiatiotis, R. Fasoulis, F. Aisopos, A. Nentidis, G. Paliouras", "title": "Guiding Graph Embeddings using Path-Ranking Methods for Error Detection\n  innoisy Knowledge Graphs", "comments": "9 pages, 2 figures. To appear in GCLR 2021: AAAI 2021 Workshop on\n  Graphs and more Complex structures for Learning and Reasonin", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays Knowledge Graphs constitute a mainstream approach for the\nrepresentation of relational information on big heterogeneous data, however,\nthey may contain a big amount of imputed noise when constructed automatically.\nTo address this problem, different error detection methodologies have been\nproposed, mainly focusing on path ranking and representation learning. This\nwork presents various mainstream approaches and proposes a hybrid and modular\nmethodology for the task. We compare different methods on two benchmarks and\none real-world biomedical publications dataset, showcasing the potential of our\napproach and providing insights on graph embeddings when dealing with noisy\nKnowledge Graphs.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 11:04:11 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 20:43:10 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Bougiatiotis", "K.", ""], ["Fasoulis", "R.", ""], ["Aisopos", "F.", ""], ["Nentidis", "A.", ""], ["Paliouras", "G.", ""]]}, {"id": "2002.08777", "submitter": "Jodie Lobana", "authors": "NIklas Kuhl, Jodie Lobana, and Christian Meske", "title": "Do you comply with AI? -- Personalized explanations of learning\n  algorithms and their impact on employees' compliance behavior", "comments": "Fortieth International Conference on Information Systems (ICIS) 2019,\n  Munich, Germany. All Authors contributed equally in shared first authorship", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine Learning algorithms are technological key enablers for artificial\nintelligence (AI). Due to the inherent complexity, these learning algorithms\nrepresent black boxes and are difficult to comprehend, therefore influencing\ncompliance behavior. Hence, compliance with the recommendations of such\nartifacts, which can impact employees' task performance significantly, is still\nsubject to research - and personalization of AI explanations seems to be a\npromising concept in this regard. In our work, we hypothesize that, based on\nvarying backgrounds like training, domain knowledge and demographic\ncharacteristics, individuals have different understandings and hence mental\nmodels about the learning algorithm. Personalization of AI explanations,\nrelated to the individuals' mental models, may thus be an instrument to affect\ncompliance and therefore employee task performance. Our preliminary results\nalready indicate the importance of personalized explanations in industry\nsettings and emphasize the importance of this research endeavor.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 14:55:20 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Kuhl", "NIklas", ""], ["Lobana", "Jodie", ""], ["Meske", "Christian", ""]]}, {"id": "2002.08795", "submitter": "Prithviraj Ammanabrolu", "authors": "Prithviraj Ammanabrolu, Ethan Tien, Zhaochen Luo, Mark O. Riedl", "title": "How To Avoid Being Eaten By a Grue: Exploration Strategies for\n  Text-Adventure Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-based games -- in which an agent interacts with the world through\ntextual natural language -- present us with the problem of\ncombinatorially-sized action-spaces. Most current reinforcement learning\nalgorithms are not capable of effectively handling such a large number of\npossible actions per turn. Poor sample efficiency, consequently, results in\nagents that are unable to pass bottleneck states, where they are unable to\nproceed because they do not see the right action sequence to pass the\nbottleneck enough times to be sufficiently reinforced. Building on prior work\nusing knowledge graphs in reinforcement learning, we introduce two new game\nstate exploration strategies. We compare our exploration strategies against\nstrong baselines on the classic text-adventure game, Zork1, where prior agent\nhave been unable to get past a bottleneck where the agent is eaten by a Grue.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 17:18:20 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Ammanabrolu", "Prithviraj", ""], ["Tien", "Ethan", ""], ["Luo", "Zhaochen", ""], ["Riedl", "Mark O.", ""]]}, {"id": "2002.08898", "submitter": "Adarsh Kumar", "authors": "Adarsh Kumar, Peter Ku, Anuj Kumar Goyal, Angeliki Metallinou, Dilek\n  Hakkani-Tur", "title": "MA-DST: Multi-Attention Based Scalable Dialog State Tracking", "comments": "Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task oriented dialog agents provide a natural language interface for users to\ncomplete their goal. Dialog State Tracking (DST), which is often a core\ncomponent of these systems, tracks the system's understanding of the user's\ngoal throughout the conversation. To enable accurate multi-domain DST, the\nmodel needs to encode dependencies between past utterances and slot semantics\nand understand the dialog context, including long-range cross-domain\nreferences. We introduce a novel architecture for this task to encode the\nconversation history and slot semantics more robustly by using attention\nmechanisms at multiple granularities. In particular, we use cross-attention to\nmodel relationships between the context and slots at different semantic levels\nand self-attention to resolve cross-domain coreferences. In addition, our\nproposed architecture does not rely on knowing the domain ontologies beforehand\nand can also be used in a zero-shot setting for new domains or unseen slot\nvalues. Our model improves the joint goal accuracy by 5% (absolute) in the\nfull-data setting and by up to 2% (absolute) in the zero-shot setting over the\npresent state-of-the-art on the MultiWoZ 2.1 dataset.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 05:34:58 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Kumar", "Adarsh", ""], ["Ku", "Peter", ""], ["Goyal", "Anuj Kumar", ""], ["Metallinou", "Angeliki", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "2002.08911", "submitter": "Candace Ross", "authors": "Candace Ross, Boris Katz, Andrei Barbu", "title": "Measuring Social Biases in Grounded Vision and Language Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize the notion of social biases from language embeddings to\ngrounded vision and language embeddings. Biases are present in grounded\nembeddings, and indeed seem to be equally or more significant than for\nungrounded embeddings. This is despite the fact that vision and language can\nsuffer from different biases, which one might hope could attenuate the biases\nin both. Multiple ways exist to generalize metrics measuring bias in word\nembeddings to this new setting. We introduce the space of generalizations\n(Grounded-WEAT and Grounded-SEAT) and demonstrate that three generalizations\nanswer different yet important questions about how biases, language, and vision\ninteract. These metrics are used on a new dataset, the first for grounded bias,\ncreated by augmenting extending standard linguistic bias benchmarks with 10,228\nimages from COCO, Conceptual Captions, and Google Images. Dataset construction\nis challenging because vision datasets are themselves very biased. The presence\nof these biases in systems will begin to have real-world consequences as they\nare deployed, making carefully measuring bias and then mitigating it critical\nto building a fair society.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 17:54:46 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Ross", "Candace", ""], ["Katz", "Boris", ""], ["Barbu", "Andrei", ""]]}, {"id": "2002.08948", "submitter": "Adarsh Subbaswamy", "authors": "Adarsh Subbaswamy, Suchi Saria", "title": "I-SPEC: An End-to-End Framework for Learning Transportable, Shift-Stable\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shifts in environment between development and deployment cause classical\nsupervised learning to produce models that fail to generalize well to new\ntarget distributions. Recently, many solutions which find invariant predictive\ndistributions have been developed. Among these, graph-based approaches do not\nrequire data from the target environment and can capture more stable\ninformation than alternative methods which find stable feature sets. However,\nthese approaches assume that the data generating process is known in the form\nof a full causal graph, which is generally not the case. In this paper, we\npropose I-SPEC, an end-to-end framework that addresses this shortcoming by\nusing data to learn a partial ancestral graph (PAG). Using the PAG we develop\nan algorithm that determines an interventional distribution that is stable to\nthe declared shifts; this subsumes existing approaches which find stable\nfeature sets that are less accurate. We apply I-SPEC to a mortality prediction\nproblem to show it can learn a model that is robust to shifts without needing\nupfront knowledge of the full causal DAG.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 18:56:04 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Subbaswamy", "Adarsh", ""], ["Saria", "Suchi", ""]]}, {"id": "2002.08957", "submitter": "Lashon Booker", "authors": "Lashon B. Booker and Scott A. Musman", "title": "A Model-Based, Decision-Theoretic Perspective on Automated Cyber\n  Response", "comments": "8 pages, 6 figures, 1 table; Presented at the AAAI-20 Workshop on\n  Artificial Intelligence for Cyber Security (AICS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-attacks can occur at machine speeds that are far too fast for\nhuman-in-the-loop (or sometimes on-the-loop) decision making to be a viable\noption. Although human inputs are still important, a defensive Artificial\nIntelligence (AI) system must have considerable autonomy in these\ncircumstances. When the AI system is model-based, its behavior responses can be\naligned with risk-aware cost/benefit tradeoffs that are defined by\nuser-supplied preferences that capture the key aspects of how human operators\nunderstand the system, the adversary and the mission. This paper describes an\napproach to automated cyber response that is designed along these lines. We\ncombine a simulation of the system to be defended with an anytime online\nplanner to solve cyber defense problems characterized as partially observable\nMarkov decision problems (POMDPs).\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 15:30:59 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Booker", "Lashon B.", ""], ["Musman", "Scott A.", ""]]}, {"id": "2002.09040", "submitter": "Tao Chen", "authors": "Miqing Li and Tao Chen and Xin Yao", "title": "How to Evaluate Solutions in Pareto-based Search-Based Software\n  Engineering? A Critical Review and Methodological Guidance", "comments": "This paper has been accepted by IEEE Transactions on Software\n  Engineering, available as full OA:\n  https://ieeexplore.ieee.org/document/9252185", "journal-ref": null, "doi": "10.1109/TSE.2020.3036108", "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With modern requirements, there is an increasing tendency of considering\nmultiple objectives/criteria simultaneously in many Software Engineering (SE)\nscenarios. Such a multi-objective optimization scenario comes with an important\nissue -- how to evaluate the outcome of optimization algorithms, which\ntypically is a set of incomparable solutions (i.e., being Pareto non-dominated\nto each other). This issue can be challenging for the SE community,\nparticularly for practitioners of Search-Based SE (SBSE). On one hand,\nmulti-objective optimization could still be relatively new to SE/SBSE\nresearchers, who may not be able to identify the right evaluation methods for\ntheir problems. On the other hand, simply following the evaluation methods for\ngeneral multi-objective optimization problems may not be appropriate for\nspecific SE problems, especially when the problem nature or decision maker's\npreferences are explicitly/implicitly available. This has been well echoed in\nthe literature by various inappropriate/inadequate selection and\ninaccurate/misleading use of evaluation methods. In this paper, we first carry\nout a systematic and critical review of quality evaluation for multi-objective\noptimization in SBSE. We survey 717 papers published between 2009 and 2019 from\n36 venues in seven repositories, and select 95 prominent studies, through which\nwe identify five important but overlooked issues in the area. We then conduct\nan in-depth analysis of quality evaluation indicators/methods and general\nsituations in SBSE, which, together with the identified issues, enables us to\ncodify a methodological guidance for selecting and using evaluation methods in\ndifferent SBSE scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 22:12:13 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 23:24:54 GMT"}, {"version": "v3", "created": "Tue, 21 Jul 2020 16:05:33 GMT"}, {"version": "v4", "created": "Sat, 28 Nov 2020 13:23:40 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Li", "Miqing", ""], ["Chen", "Tao", ""], ["Yao", "Xin", ""]]}, {"id": "2002.09044", "submitter": "Philip Paquette", "authors": "Philip Paquette", "title": "A Road Map to Strong Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I wrote this paper because technology can really improve people's lives. With\nit, we can live longer in a healthy body, save time through increased\nefficiency and automation, and make better decisions. To get to the next level,\nwe need to start looking at intelligence from a much broader perspective, and\npromote international interdisciplinary collaborations. Section 1 of this paper\ndelves into sociology and social psychology to explain that the mechanisms\nunderlying intelligence are inherently social. Section 2 proposes a method to\nclassify intelligence, and describes the differences between weak and strong\nintelligence. Section 3 examines the Chinese Room argument from a different\nperspective. It demonstrates that a Turing-complete machine cannot have strong\nintelligence, and considers the modifications necessary for a computer to be\nintelligent and have understanding. Section 4 argues that the existential risk\ncaused by the technological explosion of a single agent should not be of\nserious concern. Section 5 looks at the AI control problem and argues that it\nis impossible to build a super-intelligent machine that will do what it\ncreators want. By using insights from biology, it also proposes a solution to\nthe control problem. Section 6 discusses some of the implications of strong\nintelligence. Section 7 lists the main challenges with deep learning, and\nasserts that radical changes will be required to reach strong intelligence.\nSection 8 examines a neuroscience framework that could help explain how a\ncortical column works. Section 9 lays out the broad strokes of a road map\ntowards strong intelligence. Finally, section 10 analyzes the impacts and the\nchallenges of greater intelligence.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 22:22:50 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Paquette", "Philip", ""]]}, {"id": "2002.09054", "submitter": "Lionel Robert", "authors": "Lionel P. Robert, Casey Pierce, Liz Morris, Sangmi Kim, Rasha Alahmad", "title": "Designing Fair AI for Managing Employees in Organizations: A Review,\n  Critique, and Design Agenda", "comments": "66 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Organizations are rapidly deploying artificial intelligence (AI) systems to\nmanage their workers. However, AI has been found at times to be unfair to\nworkers. Unfairness toward workers has been associated with decreased worker\neffort and increased worker turnover. To avoid such problems, AI systems must\nbe designed to support fairness and redress instances of unfairness. Despite\nthe attention related to AI unfairness, there has not been a theoretical and\nsystematic approach to developing a design agenda. This paper addresses the\nissue in three ways. First, we introduce the organizational justice theory,\nthree different fairness types (distributive, procedural, interactional), and\nthe frameworks for redressing instances of unfairness (retributive justice,\nrestorative justice). Second, we review the design literature that specifically\nfocuses on issues of AI fairness in organizations. Third, we propose a design\nagenda for AI fairness in organizations that applies each of the fairness types\nto organizational scenarios. Then, the paper concludes with implications for\nfuture research.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 22:52:43 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Robert", "Lionel P.", ""], ["Pierce", "Casey", ""], ["Morris", "Liz", ""], ["Kim", "Sangmi", ""], ["Alahmad", "Rasha", ""]]}, {"id": "2002.09077", "submitter": "Guannan Zhang", "authors": "Jiaxing Zhang, Hoang Tran, Guannan Zhang", "title": "Accelerating Reinforcement Learning with a\n  Directional-Gaussian-Smoothing Evolution Strategy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolution strategy (ES) has been shown great promise in many challenging\nreinforcement learning (RL) tasks, rivaling other state-of-the-art deep RL\nmethods. Yet, there are two limitations in the current ES practice that may\nhinder its otherwise further capabilities. First, most current methods rely on\nMonte Carlo type gradient estimators to suggest search direction, where the\npolicy parameter is, in general, randomly sampled. Due to the low accuracy of\nsuch estimators, the RL training may suffer from slow convergence and require\nmore iterations to reach optimal solution. Secondly, the landscape of reward\nfunctions can be deceptive and contains many local maxima, causing ES\nalgorithms to prematurely converge and be unable to explore other parts of the\nparameter space with potentially greater rewards. In this work, we employ a\nDirectional Gaussian Smoothing Evolutionary Strategy (DGS-ES) to accelerate RL\ntraining, which is well-suited to address these two challenges with its ability\nto i) provide gradient estimates with high accuracy, and ii) find nonlocal\nsearch direction which lays stress on large-scale variation of the reward\nfunction and disregards local fluctuation. Through several benchmark RL tasks\ndemonstrated herein, we show that DGS-ES is highly scalable, possesses superior\nwall-clock time, and achieves competitive reward scores to other popular policy\ngradient and ES approaches.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 01:05:57 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Zhang", "Jiaxing", ""], ["Tran", "Hoang", ""], ["Zhang", "Guannan", ""]]}, {"id": "2002.09096", "submitter": "Olivia Choudhury", "authors": "Olivia Choudhury, Aris Gkoulalas-Divanis, Theodoros Salonidis, Issa\n  Sylla, Yoonyoung Park, Grace Hsu, Amar Das", "title": "Anonymizing Data for Privacy-Preserving Federated Learning", "comments": "24th European Conference on Artificial Intelligence (ECAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning enables training a global machine learning model from data\ndistributed across multiple sites, without having to move the data. This is\nparticularly relevant in healthcare applications, where data is rife with\npersonal, highly-sensitive information, and data analysis methods must provably\ncomply with regulatory guidelines. Although federated learning prevents sharing\nraw data, it is still possible to launch privacy attacks on the model\nparameters that are exposed during the training process, or on the generated\nmachine learning model. In this paper, we propose the first syntactic approach\nfor offering privacy in the context of federated learning. Unlike the\nstate-of-the-art differential privacy-based frameworks, our approach aims to\nmaximize utility or model performance, while supporting a defensible level of\nprivacy, as demanded by GDPR and HIPAA. We perform a comprehensive empirical\nevaluation on two important problems in the healthcare domain, using real-world\nelectronic health data of 1 million patients. The results demonstrate the\neffectiveness of our approach in achieving high model performance, while\noffering the desired level of privacy. Through comparative studies, we also\nshow that, for varying datasets, experimental setups, and privacy budgets, our\napproach offers higher model performance than differential privacy-based\ntechniques in federated learning.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 02:30:16 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Choudhury", "Olivia", ""], ["Gkoulalas-Divanis", "Aris", ""], ["Salonidis", "Theodoros", ""], ["Sylla", "Issa", ""], ["Park", "Yoonyoung", ""], ["Hsu", "Grace", ""], ["Das", "Amar", ""]]}, {"id": "2002.09247", "submitter": "Russa Biswas", "authors": "Russa Biswas, Mehwish Alam, and Harald Sack", "title": "Is Aligning Embedding Spaces a Challenging Task? A Study on\n  Heterogeneous Embedding Alignment Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Representation Learning of words and Knowledge Graphs (KG) into low\ndimensional vector spaces along with its applications to many real-world\nscenarios have recently gained momentum. In order to make use of multiple KG\nembeddings for knowledge-driven applications such as question answering, named\nentity disambiguation, knowledge graph completion, etc., alignment of different\nKG embedding spaces is necessary. In addition to multilinguality and\ndomain-specific information, different KGs pose the problem of structural\ndifferences making the alignment of the KG embeddings more challenging. This\npaper provides a theoretical analysis and comparison of the state-of-the-art\nalignment methods between two embedding spaces representing entity-entity and\nentity-word. This paper also aims at assessing the capability and short-comings\nof the existing alignment methods on the pretext of different applications.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 12:37:12 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 15:49:22 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Biswas", "Russa", ""], ["Alam", "Mehwish", ""], ["Sack", "Harald", ""]]}, {"id": "2002.09253", "submitter": "C\\'edric Colas", "authors": "C\\'edric Colas, Tristan Karch, Nicolas Lair, Jean-Michel Dussoux,\n  Cl\\'ement Moulin-Frier, Peter Ford Dominey, Pierre-Yves Oudeyer", "title": "Language as a Cognitive Tool to Imagine Goals in Curiosity-Driven\n  Exploration", "comments": "Contains main article and supplementaries", "journal-ref": "NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developmental machine learning studies how artificial agents can model the\nway children learn open-ended repertoires of skills. Such agents need to create\nand represent goals, select which ones to pursue and learn to achieve them.\nRecent approaches have considered goal spaces that were either fixed and\nhand-defined or learned using generative models of states. This limited agents\nto sample goals within the distribution of known effects. We argue that the\nability to imagine out-of-distribution goals is key to enable creative\ndiscoveries and open-ended learning. Children do so by leveraging the\ncompositionality of language as a tool to imagine descriptions of outcomes they\nnever experienced before, targeting them as goals during play. We introduce\nIMAGINE, an intrinsically motivated deep reinforcement learning architecture\nthat models this ability. Such imaginative agents, like children, benefit from\nthe guidance of a social peer who provides language descriptions. To take\nadvantage of goal imagination, agents must be able to leverage these\ndescriptions to interpret their imagined out-of-distribution goals. This\ngeneralization is made possible by modularity: a decomposition between learned\ngoal-achievement reward function and policy relying on deep sets, gated\nattention and object-centered representations. We introduce the Playground\nenvironment and study how this form of goal imagination improves generalization\nand exploration over agents lacking this capacity. In addition, we identify the\nproperties of goal imagination that enable these results and study the impacts\nof modularity and social interactions.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 12:59:57 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 11:38:50 GMT"}, {"version": "v3", "created": "Fri, 12 Jun 2020 09:23:40 GMT"}, {"version": "v4", "created": "Wed, 21 Oct 2020 16:48:51 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Colas", "C\u00e9dric", ""], ["Karch", "Tristan", ""], ["Lair", "Nicolas", ""], ["Dussoux", "Jean-Michel", ""], ["Moulin-Frier", "Cl\u00e9ment", ""], ["Dominey", "Peter Ford", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "2002.09284", "submitter": "Adnan Darwiche", "authors": "Adnan Darwiche and Auguste Hirth", "title": "On The Reasons Behind Decisions", "comments": "To appear in the proceedings of European Conference on Artificial\n  Intelligence (ECAI), Spain, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that some common machine learning classifiers can be\ncompiled into Boolean circuits that have the same input-output behavior. We\npresent a theory for unveiling the reasons behind the decisions made by Boolean\nclassifiers and study some of its theoretical and practical implications. We\ndefine notions such as sufficient, necessary and complete reasons behind\ndecisions, in addition to classifier and decision bias. We show how these\nnotions can be used to evaluate counterfactual statements such as \"a decision\nwill stick even if ... because ... .\" We present efficient algorithms for\ncomputing these notions, which are based on new advances on tractable Boolean\ncircuits, and illustrate them using a case study.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 13:37:29 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Darwiche", "Adnan", ""], ["Hirth", "Auguste", ""]]}, {"id": "2002.09298", "submitter": "Hanan Salam", "authors": "Ahmed Rachid Hazourli and Amine Djeghri and Hanan Salam and Alice\n  Othmani", "title": "Deep Multi-Facial Patches Aggregation Network For Facial Expression\n  Recognition", "comments": "This article arXiv:2002.09298 is an updated version of\n  arXiv:1909.10305", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an approach for Facial Expressions Recognition\n(FER) based on a deep multi-facial patches aggregation network. Deep features\nare learned from facial patches using deep sub-networks and aggregated within\none deep architecture for expression classification . Several problems may\naffect the performance of deep-learning based FER approaches, in particular,\nthe small size of existing FER datasets which might not be sufficient to train\nlarge deep learning networks. Moreover, it is extremely time-consuming to\ncollect and annotate a large number of facial images. To account for this, we\npropose two data augmentation techniques for facial expression generation to\nexpand FER labeled training datasets. We evaluate the proposed framework on\nthree FER datasets. Results show that the proposed approach achieves\nstate-of-art FER deep learning approaches performance when the model is trained\nand tested on images from the same dataset. Moreover, the proposed data\naugmentation techniques improve the expression recognition rate, and thus can\nbe a solution for training deep learning FER models using small datasets. The\naccuracy degrades significantly when testing for dataset bias.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 17:57:06 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Hazourli", "Ahmed Rachid", ""], ["Djeghri", "Amine", ""], ["Salam", "Hanan", ""], ["Othmani", "Alice", ""]]}, {"id": "2002.09320", "submitter": "Adnan Darwiche", "authors": "Adnan Darwiche", "title": "An Advance on Variable Elimination with Applications to Tensor-Based\n  Computation", "comments": "To Appear in Proceedings of the European Conference on Artificial\n  Intelligence (ECAI), Spain, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new results on the classical algorithm of variable elimination,\nwhich underlies many algorithms including for probabilistic inference. The\nresults relate to exploiting functional dependencies, allowing one to perform\ninference and learning efficiently on models that have very large treewidth.\nThe highlight of the advance is that it works with standard (dense) factors,\nwithout the need for sparse factors or techniques based on knowledge\ncompilation that are commonly utilized. This is significant as it permits a\ndirect implementation of the improved variable elimination algorithm using\ntensors and their operations, leading to extremely efficient implementations\nespecially when learning model parameters. Moreover, the proposed technique\ndoes not require knowledge of the specific functional dependencies, only that\nthey exist, so can be used when learning these dependencies. We illustrate the\nefficacy of our proposed algorithm by compiling Bayesian network queries into\ntensor graphs and then learning their parameters from labeled data using a\nstandard tool for tensor computation.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 14:17:44 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Darwiche", "Adnan", ""]]}, {"id": "2002.09380", "submitter": "Y. A. Joarder", "authors": "Y. A. Joarder (1) and Mosabbir Ahmed (2) ((1,2) Department of Computer\n  Science and Engineering, World University of Bangladesh (WUB), Dhaka,\n  Bangladesh)", "title": "A Hybrid Algorithm Based Robust Big Data Clustering for Solving\n  Unhealthy Initialization, Dynamic Centroid Selection and Empty clustering\n  Problems with Analysis", "comments": "18 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big Data is a massive volume of both structured and unstructured data that is\ntoo large and it also difficult to process using traditional techniques.\nClustering algorithms have developed as a powerful learning tool that can\nexactly analyze the volume of data that produced by modern applications.\nClustering in data mining is the grouping of a particular set of objects based\non their characteristics. The main aim of clustering is to classified data into\nclusters such that objects are grouped in the same clusters when they are\ncorresponding according to similarities and features mainly. Till now, K-MEANS\nis the best utilized calculation connected in a wide scope of zones to\nrecognize gatherings where cluster separations are a lot than between gathering\nseparations. Our developed algorithm works with K-MEANS for high quality\nclustering during clustering from big data. Our proposed algorithm EG K-MEANS :\nExtended Generation K-MEANS solves mainly three issues of K-MEANS: unhealthy\ninitialization, dynamic centroid selection and empty clustering. It ensures the\nbest way of preventing unhealthy initialization, dynamic centroid selection and\nempty clustering problems for getting high quality clustering.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 16:09:19 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Joarder", "Y. A.", ""], ["Ahmed", "Mosabbir", ""]]}, {"id": "2002.09440", "submitter": "Ibrahim Abdelaziz", "authors": "Ibrahim Abdelaziz, Julian Dolby, James P. McCusker, Kavitha Srinivas", "title": "Graph4Code: A Machine Interpretable Knowledge Graph for Code", "comments": "Preprint, 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs have proven extremely useful in powering diverse\napplications in semantic search and natural language understanding. Graph4Code\nis a knowledge graph about program code that can similarly power diverse\napplications such as program search, code understanding, refactoring, bug\ndetection, and code automation. The graph uses generic techniques to capture\nthe semantics of Python code: the key nodes in the graph are classes, functions\nand methods in popular Python modules. Edges indicate function usage (e.g., how\ndata flows through function calls, as derived from program analysis of real\ncode), and documentation about functions (e.g., code documentation, usage\ndocumentation, or forum discussions such as StackOverflow). We make extensive\nuse of named graphs in RDF to make the knowledge graph extensible by the\ncommunity. We describe a set of generic extraction techniques that we applied\nto over 1.3M Python files drawn from GitHub, over 2,300 Python modules, as well\nas 47M forum posts to generate a graph with over 2 billion triples. We also\nprovide a number of initial use cases of the knowledge graph in code\nassistance, enforcing best practices, debugging and type inference. The graph\nand all its artifacts are available to the community for use.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 17:40:20 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 19:46:38 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Abdelaziz", "Ibrahim", ""], ["Dolby", "Julian", ""], ["McCusker", "James P.", ""], ["Srinivas", "Kavitha", ""]]}, {"id": "2002.09471", "submitter": "Yue Zhang", "authors": "Yue Zhang, Arti Ramesh", "title": "Learning Fairness-aware Relational Structures", "comments": "Accepted for publication in ECAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of fair machine learning models that effectively avert bias\nand discrimination is an important problem that has garnered attention in\nrecent years. The necessity of encoding complex relational dependencies among\nthe features and variables for competent predictions require the development of\nfair, yet expressive relational models. In this work, we introduce Fair-A3SL, a\nfairness-aware structure learning algorithm for learning relational structures,\nwhich incorporates fairness measures while learning relational graphical model\nstructures. Our approach is versatile in being able to encode a wide range of\nfairness metrics such as statistical parity difference, overestimation,\nequalized odds, and equal opportunity, including recently proposed relational\nfairness measures. While existing approaches employ the fairness measures on\npre-determined model structures post prediction, Fair-A3SL directly learns the\nstructure while optimizing for the fairness measures and hence is able to\nremove any structural bias in the model. We demonstrate the effectiveness of\nour learned model structures when compared with the state-of-the-art fairness\nmodels quantitatively and qualitatively on datasets representing three\ndifferent modeling scenarios: i) a relational dataset, ii) a recidivism\nprediction dataset widely used in studying discrimination, and iii) a\nrecommender systems dataset. Our results show that Fair-A3SL can learn fair,\nyet interpretable and expressive structures capable of making accurate\npredictions.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 18:53:52 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Zhang", "Yue", ""], ["Ramesh", "Arti", ""]]}, {"id": "2002.09473", "submitter": "Hegler Tissot", "authors": "Jianyu Liu and Hegler Tissot", "title": "Clustering as an Evaluation Protocol for Knowledge Embedding\n  Representation of Categorised Multi-relational Data in the Clinical Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning knowledge representation is an increasingly important technology\napplicable in many domain-specific machine learning problems. We discuss the\neffectiveness of traditional Link Prediction or Knowledge Graph Completion\nevaluation protocol when embedding knowledge representation for categorised\nmulti-relational data in the clinical domain. Link prediction uses to split the\ndata into training and evaluation subsets, leading to loss of information along\ntraining and harming the knowledge representation model accuracy. We propose a\nClustering Evaluation Protocol as a replacement alternative to the\ntraditionally used evaluation tasks. We used embedding models trained by a\nknowledge embedding approach which has been evaluated with clinical datasets.\nExperimental results with Pearson and Spearman correlations show strong\nevidence that the novel proposed evaluation protocol is pottentially able to\nreplace link prediction.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 16:04:22 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Liu", "Jianyu", ""], ["Tissot", "Hegler", ""]]}, {"id": "2002.09505", "submitter": "Ashley Edwards", "authors": "Ashley D. Edwards, Himanshu Sahni, Rosanne Liu, Jane Hung, Ankit Jain,\n  Rui Wang, Adrien Ecoffet, Thomas Miconi, Charles Isbell, Jason Yosinski", "title": "Estimating Q(s,s') with Deep Deterministic Dynamics Gradients", "comments": "Accepted into ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel form of value function, $Q(s, s')$, that\nexpresses the utility of transitioning from a state $s$ to a neighboring state\n$s'$ and then acting optimally thereafter. In order to derive an optimal\npolicy, we develop a forward dynamics model that learns to make next-state\npredictions that maximize this value. This formulation decouples actions from\nvalues while still learning off-policy. We highlight the benefits of this\napproach in terms of value function transfer, learning within redundant action\nspaces, and learning off-policy from state observations generated by\nsub-optimal or completely random policies. Code and videos are available at\nhttp://sites.google.com/view/qss-paper.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 19:05:24 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 18:13:00 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Edwards", "Ashley D.", ""], ["Sahni", "Himanshu", ""], ["Liu", "Rosanne", ""], ["Hung", "Jane", ""], ["Jain", "Ankit", ""], ["Wang", "Rui", ""], ["Ecoffet", "Adrien", ""], ["Miconi", "Thomas", ""], ["Isbell", "Charles", ""], ["Yosinski", "Jason", ""]]}, {"id": "2002.09534", "submitter": "Eryk Kopczy\\'nski", "authors": "Eryk Kopczy\\'nski", "title": "Hyperbolic Minesweeper is in P", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that, while Minesweeper is NP-complete, its hyperbolic variant is in\nP. Our proof does not rely on the rules of Minesweeper, but is valid for any\npuzzle based on satisfying local constraints on a graph embedded in the\nhyperbolic plane.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 20:05:04 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Kopczy\u0144ski", "Eryk", ""]]}, {"id": "2002.09595", "submitter": "Andr\\'es P\\'aez", "authors": "Andr\\'es P\\'aez", "title": "The Pragmatic Turn in Explainable Artificial Intelligence (XAI)", "comments": null, "journal-ref": "Minds and Machines, 29(3), 441-459, 2019", "doi": "10.1007/s11023-019-09502-w", "report-no": null, "categories": "cs.AI cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper I argue that the search for explainable models and\ninterpretable decisions in AI must be reformulated in terms of the broader\nproject of offering a pragmatic and naturalistic account of understanding in\nAI. Intuitively, the purpose of providing an explanation of a model or a\ndecision is to make it understandable to its stakeholders. But without a\nprevious grasp of what it means to say that an agent understands a model or a\ndecision, the explanatory strategies will lack a well-defined goal. Aside from\nproviding a clearer objective for XAI, focusing on understanding also allows us\nto relax the factivity condition on explanation, which is impossible to fulfill\nin many machine learning models, and to focus instead on the pragmatic\nconditions that determine the best fit between a model and the methods and\ndevices deployed to understand it. After an examination of the different types\nof understanding discussed in the philosophical and psychological literature, I\nconclude that interpretative or approximation models not only provide the best\nway to achieve the objectual understanding of a machine learning model, but are\nalso a necessary condition to achieve post-hoc interpretability. This\nconclusion is partly based on the shortcomings of the purely functionalist\napproach to post-hoc interpretability that seems to be predominant in most\nrecent literature.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 01:40:01 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["P\u00e1ez", "Andr\u00e9s", ""]]}, {"id": "2002.09598", "submitter": "Barton E. Lee", "authors": "Haris Aziz and Barton E. Lee", "title": "A characterization of proportionally representative committees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A well-known axiom for proportional representation is Proportionality of\nSolid Coalitions (PSC). We characterize committees satisfying PSC as possible\noutcomes of the Minimal Demand rule, which generalizes an approach pioneered by\nMichael Dummett.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 01:48:56 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 22:31:12 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Aziz", "Haris", ""], ["Lee", "Barton E.", ""]]}, {"id": "2002.09599", "submitter": "Raul Puri", "authors": "Raul Puri, Ryan Spring, Mostofa Patwary, Mohammad Shoeybi, Bryan\n  Catanzaro", "title": "Training Question Answering Models From Synthetic Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question and answer generation is a data augmentation method that aims to\nimprove question answering (QA) models given the limited amount of human\nlabeled data. However, a considerable gap remains between synthetic and\nhuman-generated question-answer pairs. This work aims to narrow this gap by\ntaking advantage of large language models and explores several factors such as\nmodel size, quality of pretrained models, scale of data synthesized, and\nalgorithmic choices. On the SQuAD1.1 question answering task, we achieve higher\naccuracy using solely synthetic questions and answers than when using the\nSQuAD1.1 training set questions alone. Removing access to real Wikipedia data,\nwe synthesize questions and answers from a synthetic corpus generated by an 8.3\nbillion parameter GPT-2 model. With no access to human supervision and only\naccess to other models, we are able to train state of the art question\nanswering networks on entirely model-generated data that achieve 88.4 Exact\nMatch (EM) and 93.9 F1 score on the SQuAD1.1 dev set. We further apply our\nmethodology to SQuAD2.0 and show a 2.8 absolute gain on EM score compared to\nprior work using synthetic data.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 01:49:27 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Puri", "Raul", ""], ["Spring", "Ryan", ""], ["Patwary", "Mostofa", ""], ["Shoeybi", "Mohammad", ""], ["Catanzaro", "Bryan", ""]]}, {"id": "2002.09604", "submitter": "Jason Naradowsky", "authors": "Alexander I. Cowen-Rivers, Jason Naradowsky", "title": "Emergent Communication with World Models", "comments": "NeurIPS Workshop on Emergent Communication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce Language World Models, a class of language-conditional\ngenerative model which interpret natural language messages by predicting latent\ncodes of future observations. This provides a visual grounding of the message,\nsimilar to an enhanced observation of the world, which may include objects\noutside of the listening agent's field-of-view. We incorporate this\n\"observation\" into a persistent memory state, and allow the listening agent's\npolicy to condition on it, akin to the relationship between memory and\ncontroller in a World Model. We show this improves effective communication and\ntask success in 2D gridworld speaker-listener navigation tasks. In addition, we\ndevelop two losses framed specifically for our model-based formulation to\npromote positive signalling and positive listening. Finally, because messages\nare interpreted in a generative model, we can visualize the model beliefs to\ngain insight into how the communication channel is utilized.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 02:34:51 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Cowen-Rivers", "Alexander I.", ""], ["Naradowsky", "Jason", ""]]}, {"id": "2002.09622", "submitter": "Jie Fan", "authors": "Jie Fan", "title": "Notes on neighborhood semantics for logics of unknown truths and false\n  beliefs", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we study logics of unknown truths and false beliefs under\nneighborhood semantics. We compare the relative expressivity of the two logics.\nIt turns out that they are incomparable over various classes of neighborhood\nmodels, and the combination of the two logics are equally expressive as\nstandard modal logic over any class of neighborhood models. We propose\nmorphisms for each logic, which can help us explore the frame definability\nproblem, show a general soundness and completeness result, and generalize some\nresults in the literature. We axiomatize the two logics over various classes of\nneighborhood frames. Last but not least, we extend the results to the case of\npublic announcements, which has good applications to Moore sentences and some\nothers.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 04:27:04 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Fan", "Jie", ""]]}, {"id": "2002.09636", "submitter": "Matthew Guzdial", "authors": "Matthew Guzdial and Mark Riedl", "title": "Conceptual Game Expansion", "comments": "14 pages, 6 figures, 2 tables, IEEE Transactions on Games", "journal-ref": null, "doi": "10.1109/TG.2021.3060005", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated game design is the problem of automatically producing games through\ncomputational processes. Traditionally, these methods have relied on the\nauthoring of search spaces by a designer, defining the space of all possible\ngames for the system to author. In this paper, we instead learn representations\nof existing games from gameplay video and use these to approximate a search\nspace of novel games. In a human subject study we demonstrate that these novel\ngames are indistinguishable from human games in terms of challenge, and that\none of the novel games was equivalent to one of the human games in terms of\nfun, frustration, and likeability.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 05:51:54 GMT"}, {"version": "v2", "created": "Sun, 20 Sep 2020 06:25:54 GMT"}, {"version": "v3", "created": "Fri, 19 Feb 2021 00:34:42 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Guzdial", "Matthew", ""], ["Riedl", "Mark", ""]]}, {"id": "2002.09758", "submitter": "Ethan Perez", "authors": "Ethan Perez, Patrick Lewis, Wen-tau Yih, Kyunghyun Cho, Douwe Kiela", "title": "Unsupervised Question Decomposition for Question Answering", "comments": "EMNLP 2020 Camera-Ready. Code available at\n  https://github.com/facebookresearch/UnsupervisedDecomposition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to improve question answering (QA) by decomposing hard questions into\nsimpler sub-questions that existing QA systems are capable of answering. Since\nlabeling questions with decompositions is cumbersome, we take an unsupervised\napproach to produce sub-questions, also enabling us to leverage millions of\nquestions from the internet. Specifically, we propose an algorithm for One-to-N\nUnsupervised Sequence transduction (ONUS) that learns to map one hard,\nmulti-hop question to many simpler, single-hop sub-questions. We answer\nsub-questions with an off-the-shelf QA model and give the resulting answers to\na recomposition model that combines them into a final answer. We show large QA\nimprovements on HotpotQA over a strong baseline on the original, out-of-domain,\nand multi-hop dev sets. ONUS automatically learns to decompose different kinds\nof questions, while matching the utility of supervised and heuristic\ndecomposition methods for QA and exceeding those methods in fluency.\nQualitatively, we find that using sub-questions is promising for shedding light\non why a QA system makes a prediction.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 19:40:35 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 18:49:59 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 18:47:48 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Perez", "Ethan", ""], ["Lewis", "Patrick", ""], ["Yih", "Wen-tau", ""], ["Cho", "Kyunghyun", ""], ["Kiela", "Douwe", ""]]}, {"id": "2002.09811", "submitter": "Florian Richoux", "authors": "Florian Richoux and Jean-Fran\\c{c}ois Baffier", "title": "Learning Interpretable Error Functions for Combinatorial Optimization\n  Problem Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Constraint Programming, constraints are usually represented as predicates\nallowing or forbidding combinations of values. However, some algorithms exploit\na finer representation: error functions. Their usage comes with a price though:\nit makes problem modeling significantly harder. Here, we propose a method to\nautomatically learn an error function corresponding to a constraint, given a\nfunction deciding if assignments are valid or not. This is, to the best of our\nknowledge, the first attempt to automatically learn error functions for hard\nconstraints. Our method uses a variant of neural networks we named\nInterpretable Compositional Networks, allowing us to get interpretable results,\nunlike regular artificial neural networks. Experiments on 5 different\nconstraints show that our system can learn functions that scale to high\ndimensions, and can learn fairly good functions over incomplete spaces.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 02:58:51 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 01:57:45 GMT"}, {"version": "v3", "created": "Fri, 2 Apr 2021 07:37:13 GMT"}, {"version": "v4", "created": "Thu, 8 Jul 2021 02:43:26 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Richoux", "Florian", ""], ["Baffier", "Jean-Fran\u00e7ois", ""]]}, {"id": "2002.09820", "submitter": "Gabriel Fernandez", "authors": "Gabriel I. Fernandez, Colin Togashi, Dennis W. Hong, Lin F. Yang", "title": "Deep Reinforcement Learning with Linear Quadratic Regulator Regions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Practitioners often rely on compute-intensive domain randomization to ensure\nreinforcement learning policies trained in simulation can robustly transfer to\nthe real world. Due to unmodeled nonlinearities in the real system, however,\neven such simulated policies can still fail to perform stably enough to acquire\nexperience in real environments. In this paper we propose a novel method that\nguarantees a stable region of attraction for the output of a policy trained in\nsimulation, even for highly nonlinear systems. Our core technique is to use\n\"bias-shifted\" neural networks for constructing the controller and training the\nnetwork in the simulator. The modified neural networks not only capture the\nnonlinearities of the system but also provably preserve linearity in a certain\nregion of the state space and thus can be tuned to resemble a linear quadratic\nregulator that is known to be stable for the real system. We have tested our\nnew method by transferring simulated policies for a swing-up inverted pendulum\nto real systems and demonstrated its efficacy.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 03:50:49 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 03:46:10 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Fernandez", "Gabriel I.", ""], ["Togashi", "Colin", ""], ["Hong", "Dennis W.", ""], ["Yang", "Lin F.", ""]]}, {"id": "2002.09827", "submitter": "Ron van der Meyden", "authors": "Ron van der Meyden", "title": "A Formal Treatment of Contract Signature", "comments": "28 pages. This is a significantly revised and retitled version of an\n  earlier paper \"Signature in Counterparts, a Formal Treatment\". Revisions\n  include changes to the semantics, addition of a treatment of offer and\n  acceptance, added proof material and discussion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper develops a logical understanding of processes for signature of\nlegal contracts, motivated by applications to legal recognition of smart\ncontracts on blockchain platforms. A number of axioms and rules of inference\nare developed that can be used to justify a \"meeting of the minds\" precondition\nfor contract formation from the fact that certain content has been signed. In\naddition to an \"offer and acceptance\" process, the paper considers \"signature\nin counterparts\", a legal process that permits a contract between two or more\nparties to be brought into force by having the parties independently (possibly,\nremotely) sign different copies of the contract, rather than placing their\nsignatures on a common copy at a physical meeting. It is argued that a\nsatisfactory account of signature in counterparts benefits from a logic with\nsyntactic self-reference. The axioms used are supported by a formal semantics,\nand a number of further properties of the logic are investigated. In\nparticular, it is shown that the logic implies that when a contract has been\nsigned, the parties do not just agree, but are in mutual agreement (a\ncommon-knowledge-like notion) about the terms of the contract.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 04:39:56 GMT"}, {"version": "v2", "created": "Sat, 22 Aug 2020 08:48:28 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["van der Meyden", "Ron", ""]]}, {"id": "2002.09853", "submitter": "Azhar Hussain", "authors": "Azhar Hussain, Tong Wang and Cao Jiahua", "title": "Optimizing Traffic Lights with Multi-agent Deep Reinforcement Learning\n  and V2X communication", "comments": "7 Figure, Table 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider a system to optimize duration of traffic signals using\nmulti-agent deep reinforcement learning and Vehicle-to-Everything (V2X)\ncommunication. This system aims at analyzing independent and shared rewards for\nmulti-agents to control duration of traffic lights. A learning agent traffic\nlight gets information along its lanes within a circular V2X coverage. The\nduration cycles of traffic light are modeled as Markov decision Processes. We\ninvestigate four variations of reward functions. The first two are\nunshared-rewards: based on waiting number, and waiting time of vehicles between\ntwo cycles of traffic light. The third and fourth functions are: shared-rewards\nbased on waiting cars, and waiting time for all agents. Each agent has a memory\nfor optimization through target network and prioritized experience replay. We\nevaluate multi-agents through the Simulation of Urban MObility (SUMO)\nsimulator. The results prove effectiveness of the proposed system to optimize\ntraffic signals and reduce average waiting cars to 41.5 % as compared to the\ntraditional periodic traffic control system.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 07:43:12 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Hussain", "Azhar", ""], ["Wang", "Tong", ""], ["Jiahua", "Cao", ""]]}, {"id": "2002.09880", "submitter": "Dmitry Ignatov", "authors": "Dmitry I. Ignatov, Polina Ivanova, Albina Zamaletdinova", "title": "Mixed Integer Programming for Searching Maximum Quasi-Bicliques", "comments": "This paper draft is stored here for self-archiving purposes", "journal-ref": "Springer Proceedings in Mathematics & Statistics, vol 315.\n  Springer, Cham (2020)", "doi": "10.1007/978-3-030-37157-9_2", "report-no": null, "categories": "cs.DS cs.AI cs.DM cs.SI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is related to the problem of finding the maximal quasi-bicliques\nin a bipartite graph (bigraph). A quasi-biclique in the bigraph is its \"almost\"\ncomplete subgraph. The relaxation of completeness can be understood variously;\nhere, we assume that the subgraph is a $\\gamma$-quasi-biclique if it lacks a\ncertain number of edges to form a biclique such that its density is at least\n$\\gamma \\in (0,1]$. For a bigraph and fixed $\\gamma$, the problem of searching\nfor the maximal quasi-biclique consists of finding a subset of vertices of the\nbigraph such that the induced subgraph is a quasi-biclique and its size is\nmaximal for a given graph. Several models based on Mixed Integer Programming\n(MIP) to search for a quasi-biclique are proposed and tested for working\nefficiency. An alternative model inspired by biclustering is formulated and\ntested; this model simultaneously maximizes both the size of the quasi-biclique\nand its density, using the least-square criterion similar to the one exploited\nby triclustering \\textsc{TriBox}.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 10:25:51 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Ignatov", "Dmitry I.", ""], ["Ivanova", "Polina", ""], ["Zamaletdinova", "Albina", ""]]}, {"id": "2002.09884", "submitter": "Xiao Ma", "authors": "Xiao Ma, Peter Karkus, David Hsu, Wee Sun Lee, Nan Ye", "title": "Discriminative Particle Filter Reinforcement Learning for Complex\n  Partial Observations", "comments": "Accepted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning is successful in decision making for\nsophisticated games, such as Atari, Go, etc. However, real-world decision\nmaking often requires reasoning with partial information extracted from complex\nvisual observations. This paper presents Discriminative Particle Filter\nReinforcement Learning (DPFRL), a new reinforcement learning framework for\ncomplex partial observations. DPFRL encodes a differentiable particle filter in\nthe neural network policy for explicit reasoning with partial observations over\ntime. The particle filter maintains a belief using learned discriminative\nupdate, which is trained end-to-end for decision making. We show that using the\ndiscriminative update instead of standard generative models results in\nsignificantly improved performance, especially for tasks with complex visual\nobservations, because they circumvent the difficulty of modeling complex\nobservations that are irrelevant to decision making. In addition, to extract\nfeatures from the particle belief, we propose a new type of belief feature\nbased on the moment generating function. DPFRL outperforms state-of-the-art\nPOMDP RL models in Flickering Atari Games, an existing POMDP RL benchmark, and\nin Natural Flickering Atari Games, a new, more challenging POMDP RL benchmark\nintroduced in this paper. Further, DPFRL performs well for visual navigation\nwith real-world data in the Habitat environment.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 11:22:43 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Ma", "Xiao", ""], ["Karkus", "Peter", ""], ["Hsu", "David", ""], ["Lee", "Wee Sun", ""], ["Ye", "Nan", ""]]}, {"id": "2002.09919", "submitter": "Yixuan Tang", "authors": "Yixuan Tang, Hwee Tou Ng, Anthony K.H. Tung", "title": "Do Multi-Hop Question Answering Systems Know How to Answer the\n  Single-Hop Sub-Questions?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop question answering (QA) requires a model to retrieve and integrate\ninformation from different parts of a long text to answer a question. Humans\nanswer this kind of complex questions via a divide-and-conquer approach. In\nthis paper, we investigate whether top-performing models for multi-hop\nquestions understand the underlying sub-questions like humans. We adopt a\nneural decomposition model to generate sub-questions for a multi-hop complex\nquestion, followed by extracting the corresponding sub-answers. We show that\nmultiple state-of-the-art multi-hop QA models fail to correctly answer a large\nportion of sub-questions, although their corresponding multi-hop questions are\ncorrectly answered. This indicates that these models manage to answer the\nmulti-hop questions using some partial clues, instead of truly understanding\nthe reasoning paths. We also propose a new model which significantly improves\nthe performance on answering the sub-questions. Our work takes a step forward\ntowards building a more explainable multi-hop QA system.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 15:16:43 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 04:18:57 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Tang", "Yixuan", ""], ["Ng", "Hwee Tou", ""], ["Tung", "Anthony K. H.", ""]]}, {"id": "2002.09925", "submitter": "Yue Jiang", "authors": "Yue Jiang, Wolfgang Stuerzlinger, Matthias Zwicker, Christof Lutteroth", "title": "ORCSolver: An Efficient Solver for Adaptive GUI Layout with\n  OR-Constraints", "comments": "Published at CHI2020", "journal-ref": null, "doi": "10.1145/3313831.3376610", "report-no": null, "categories": "cs.HC cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OR-constrained (ORC) graphical user interface layouts unify conventional\nconstraint-based layouts with flow layouts, which enables the definition of\nflexible layouts that adapt to screens with different sizes, orientations, or\naspect ratios with only a single layout specification. Unfortunately, solving\nORC layouts with current solvers is time-consuming and the needed time\nincreases exponentially with the number of widgets and constraints. To address\nthis challenge, we propose ORCSolver, a novel solving technique for adaptive\nORC layouts, based on a branch-and-bound approach with heuristic preprocessing.\nWe demonstrate that ORCSolver simplifies ORC specifications at runtime and our\napproach can solve ORC layout specifications efficiently at near-interactive\nrates.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 15:46:59 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Jiang", "Yue", ""], ["Stuerzlinger", "Wolfgang", ""], ["Zwicker", "Matthias", ""], ["Lutteroth", "Christof", ""]]}, {"id": "2002.10007", "submitter": "Tomer Galanti", "authors": "Tomer Galanti, Ofir Nabati, Lior Wolf", "title": "A Critical View of the Structural Causal Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the univariate case, we show that by comparing the individual complexities\nof univariate cause and effect, one can identify the cause and the effect,\nwithout considering their interaction at all. In our framework, complexities\nare captured by the reconstruction error of an autoencoder that operates on the\nquantiles of the distribution. Comparing the reconstruction errors of the two\nautoencoders, one for each variable, is shown to perform surprisingly well on\nthe accepted causality directionality benchmarks. Hence, the decision as to\nwhich of the two is the cause and which is the effect may not be based on\ncausality but on complexity.\n  In the multivariate case, where one can ensure that the complexities of the\ncause and effect are balanced, we propose a new adversarial training method\nthat mimics the disentangled structure of the causal model. We prove that in\nthe multidimensional case, such modeling is likely to fit the data only in the\ndirection of causality. Furthermore, a uniqueness result shows that the learned\nmodel is able to identify the underlying causal and residual (noise)\ncomponents. Our multidimensional method outperforms the literature methods on\nboth synthetic and real world datasets.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 22:52:28 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Galanti", "Tomer", ""], ["Nabati", "Ofir", ""], ["Wolf", "Lior", ""]]}, {"id": "2002.10016", "submitter": "Hadi Abdi Khojasteh", "authors": "Hadi Abdi Khojasteh (1), Ebrahim Ansari (1 and 2), Parvin Razzaghi (1\n  and 3), Akbar Karimi (4) ((1) Institute for Advanced Studies in Basic\n  Sciences (IASBS), Zanjan, Iran, (2) Faculty of Mathematics and Physics,\n  Institute of Formal and Applied Linguistics, Charles University, Czechia, (3)\n  Institute for Research in Fundamental Sciences (IPM), Tehran, Iran, (4) IMP\n  Lab, Department of Engineering and Architecture, University of Parma, Parma,\n  Italy)", "title": "Deep Multimodal Image-Text Embeddings for Automatic Cross-Media\n  Retrieval", "comments": "6 pages and 2 figures, Learn more about this project at\n  https://iasbs.ac.ir/~ansari/deeptwitter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the task of matching images and sentences by learning a\nvisual-textual embedding space for cross-modal retrieval. Finding such a space\nis a challenging task since the features and representations of text and image\nare not comparable. In this work, we introduce an end-to-end deep multimodal\nconvolutional-recurrent network for learning both vision and language\nrepresentations simultaneously to infer image-text similarity. The model learns\nwhich pairs are a match (positive) and which ones are a mismatch (negative)\nusing a hinge-based triplet ranking. To learn about the joint representations,\nwe leverage our newly extracted collection of tweets from Twitter. The main\ncharacteristic of our dataset is that the images and tweets are not\nstandardized the same as the benchmarks. Furthermore, there can be a higher\nsemantic correlation between the pictures and tweets contrary to benchmarks in\nwhich the descriptions are well-organized. Experimental results on MS-COCO\nbenchmark dataset show that our model outperforms certain methods presented\npreviously and has competitive performance compared to the state-of-the-art.\nThe code and dataset have been made available publicly.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 23:58:04 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Khojasteh", "Hadi Abdi", "", "1 and 2"], ["Ansari", "Ebrahim", "", "1 and 2"], ["Razzaghi", "Parvin", "", "1\n  and 3"], ["Karimi", "Akbar", ""]]}, {"id": "2002.10029", "submitter": "Tal Friedman", "authors": "Tal Friedman and Guy Van den Broeck", "title": "Symbolic Querying of Vector Spaces: Probabilistic Databases Meets\n  Relational Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose unifying techniques from probabilistic databases and relational\nembedding models with the goal of performing complex queries on incomplete and\nuncertain data. We formalize a probabilistic database model with respect to\nwhich all queries are done. This allows us to leverage the rich literature of\ntheory and algorithms from probabilistic databases for solving problems. While\nthis formalization can be used with any relational embedding model, the lack of\na well-defined joint probability distribution causes simple query problems to\nbecome provably hard. With this in mind, we introduce \\TO, a relational\nembedding model designed to be a tractable probabilistic database, by\nexploiting typical embedding assumptions within the probabilistic framework.\nUsing a principled, efficient inference algorithm that can be derived from its\ndefinition, we empirically demonstrate that \\TOs is an effective and general\nmodel for these querying tasks.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 01:17:25 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 20:01:49 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Friedman", "Tal", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "2002.10066", "submitter": "Yonadav Shavit", "authors": "Yonadav Shavit, Benjamin Edelman, Brian Axelrod", "title": "Causal Strategic Linear Regression", "comments": "18 pages; to appear in the proceedings of ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many predictive decision-making scenarios, such as credit scoring and\nacademic testing, a decision-maker must construct a model that accounts for\nagents' propensity to \"game\" the decision rule by changing their features so as\nto receive better decisions. Whereas the strategic classification literature\nhas previously assumed that agents' outcomes are not causally affected by their\nfeatures (and thus that strategic agents' goal is deceiving the\ndecision-maker), we join concurrent work in modeling agents' outcomes as a\nfunction of their changeable attributes. As our main contribution, we provide\nefficient algorithms for learning decision rules that optimize three distinct\ndecision-maker objectives in a realizable linear setting: accurately predicting\nagents' post-gaming outcomes (prediction risk minimization), incentivizing\nagents to improve these outcomes (agent outcome maximization), and estimating\nthe coefficients of the true underlying model (parameter estimation). Our\nalgorithms circumvent a hardness result of Miller et al. (2020) by allowing the\ndecision maker to test a sequence of decision rules and observe agents'\nresponses, in effect performing causal interventions through the decision\nrules.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 03:57:22 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 22:24:19 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Shavit", "Yonadav", ""], ["Edelman", "Benjamin", ""], ["Axelrod", "Brian", ""]]}, {"id": "2002.10091", "submitter": "Debo Cheng", "authors": "Debo Cheng (1), Jiuyong Li (1), Lin Liu (1), Kui Yu (2), Thuc Duy Lee\n  (1), Jixue Liu (1) ((1) School of Information Technology and Mathematical\n  Sciences, University of South Australia (2) School of Computer Science and\n  Information Engineering, Hefei University of Technology)", "title": "Towards unique and unbiased causal effect estimation from data with\n  hidden variables", "comments": "12 pages,8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal effect estimation from observational data is a crucial but challenging\ntask. Currently, only a limited number of data-driven causal effect estimation\nmethods are available. These methods either provide only a bound estimation of\nthe causal effect of a treatment on the outcome, or generate a unique\nestimation of the causal effect, but making strong assumptions on data and\nhaving low efficiency. In this paper, we identify a practical problem setting\nand propose an approach to achieving unique and unbiased estimation of causal\neffects from data with hidden variables. For the approach, we have developed\nthe theorems to support the discovery of the proper covariate sets for\nconfounding adjustment (adjustment sets). Based on the theorems, two algorithms\nare proposed for finding the proper adjustment sets from data with hidden\nvariables to obtain unbiased and unique causal effect estimation. Experiments\nwith synthetic datasets generated using five benchmark Bayesian networks and\nfour real-world datasets have demonstrated the efficiency and effectiveness of\nthe proposed algorithms, indicating the practicability of the identified\nproblem setting and the potential of the proposed approach in real-world\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 06:42:32 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 23:28:15 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Cheng", "Debo", ""], ["Li", "Jiuyong", ""], ["Liu", "Lin", ""], ["Yu", "Kui", ""], ["Lee", "Thuc Duy", ""], ["Liu", "Jixue", ""]]}, {"id": "2002.10107", "submitter": "Issa Annamoradnejad", "authors": "Issa Annamoradnejad, Mohammadamin Fazli, Jafar Habibi", "title": "Predicting Subjective Features of Questions of QA Websites using BERT", "comments": "5 pages, 4 figures, 2 tables", "journal-ref": "2020 6th International Conference on Web Research (ICWR), Tehran,\n  Iran, 2020, pp. 240-244", "doi": "10.1109/ICWR49608.2020.9122318", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community Question-Answering websites, such as StackOverflow and Quora,\nexpect users to follow specific guidelines in order to maintain content\nquality. These systems mainly rely on community reports for assessing contents,\nwhich has serious problems such as the slow handling of violations, the loss of\nnormal and experienced users' time, the low quality of some reports, and\ndiscouraging feedback to new users. Therefore, with the overall goal of\nproviding solutions for automating moderation actions in Q&A websites, we aim\nto provide a model to predict 20 quality or subjective aspects of questions in\nQA websites. To this end, we used data gathered by the CrowdSource team at\nGoogle Research in 2019 and a fine-tuned pre-trained BERT model on our problem.\nBased on the evaluation by Mean-Squared-Error (MSE), the model achieved a value\nof 0.046 after 2 epochs of training, which did not improve substantially in the\nnext ones. Results confirm that by simple fine-tuning, we can achieve accurate\nmodels in little time and on less amount of data.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 07:56:02 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 08:10:16 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 13:22:04 GMT"}, {"version": "v4", "created": "Wed, 28 Oct 2020 14:37:39 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Annamoradnejad", "Issa", ""], ["Fazli", "Mohammadamin", ""], ["Habibi", "Jafar", ""]]}, {"id": "2002.10126", "submitter": "Insoon Yang", "authors": "Subin Huh, Insoon Yang", "title": "Safe reinforcement learning for probabilistic reachability and safety\n  specifications: A Lyapunov-based approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging applications in robotics and autonomous systems, such as autonomous\ndriving and robotic surgery, often involve critical safety constraints that\nmust be satisfied even when information about system models is limited. In this\nregard, we propose a model-free safety specification method that learns the\nmaximal probability of safe operation by carefully combining probabilistic\nreachability analysis and safe reinforcement learning (RL). Our approach\nconstructs a Lyapunov function with respect to a safe policy to restrain each\npolicy improvement stage. As a result, it yields a sequence of safe policies\nthat determine the range of safe operation, called the safe set, which\nmonotonically expands and gradually converges. We also develop an efficient\nsafe exploration scheme that accelerates the process of identifying the safety\nof unexamined states. Exploiting the Lyapunov shielding, our method regulates\nthe exploratory policy to avoid dangerous states with high confidence. To\nhandle high-dimensional systems, we further extend our approach to deep RL by\nintroducing a Lagrangian relaxation technique to establish a tractable\nactor-critic algorithm. The empirical performance of our method is demonstrated\nthrough continuous control benchmark problems, such as a reaching task on a\nplanar robot arm.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 09:20:03 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Huh", "Subin", ""], ["Yang", "Insoon", ""]]}, {"id": "2002.10149", "submitter": "Emmanuelle-Anna Dietz Saldanha", "authors": "Emmanuelle-Anna Dietz Saldanha, Antonis Kakas", "title": "Cognitive Argumentation and the Suppression Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the challenge of modeling human reasoning, within a new\nframework called Cognitive Argumentation. This framework rests on the\nassumption that human logical reasoning is inherently a process of dialectic\nargumentation and aims to develop a cognitive model for human reasoning that is\ncomputational and implementable. To give logical reasoning a human cognitive\nform the framework relies on cognitive principles, based on empirical and\ntheoretical work in Cognitive Science, to suitably adapt a general and abstract\nframework of computational argumentation from AI. The approach of Cognitive\nArgumentation is evaluated with respect to Byrne's suppression task, where the\naim is not only to capture the suppression effect between different groups of\npeople but also to account for the variation of reasoning within each group.\nTwo main cognitive principles are particularly important to capture human\nconditional reasoning that explain the participants' responses: (i) the\ninterpretation of a condition within a conditional as sufficient and/or\nnecessary and (ii) the mode of reasoning either as predictive or explanatory.\nWe argue that Cognitive Argumentation provides a coherent and cognitively\nadequate model for human conditional reasoning that allows a natural\ndistinction between definite and plausible conclusions, exhibiting the\nimportant characteristics of context-sensitive and defeasible reasoning.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 10:30:39 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Saldanha", "Emmanuelle-Anna Dietz", ""], ["Kakas", "Antonis", ""]]}, {"id": "2002.10172", "submitter": "Iain Johnston", "authors": "Iain G. Johnston", "title": "Optimal strategies in the Fighting Fantasy gaming system: influencing\n  stochastic dynamics by gambling with limited resource", "comments": "Keyword: stochastic game; Markov decision problem; stochastic\n  simulation; dynamic programming; resource allocation; stochastic optimal\n  control; Bellman equation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fighting Fantasy is a popular recreational fantasy gaming system worldwide.\nCombat in this system progresses through a stochastic game involving a series\nof rounds, each of which may be won or lost. Each round, a limited resource\n(`luck') may be spent on a gamble to amplify the benefit from a win or mitigate\nthe deficit from a loss. However, the success of this gamble depends on the\namount of remaining resource, and if the gamble is unsuccessful, benefits are\nreduced and deficits increased. Players thus dynamically choose to expend\nresource to attempt to influence the stochastic dynamics of the game, with\ndiminishing probability of positive return. The identification of the optimal\nstrategy for victory is a Markov decision problem that has not yet been solved.\nHere, we combine stochastic analysis and simulation with dynamic programming to\ncharacterise the dynamical behaviour of the system in the absence and presence\nof gambling policy. We derive a simple expression for the victory probability\nwithout luck-based strategy. We use a backward induction approach to solve the\nBellman equation for the system and identify the optimal strategy for any given\nstate during the game. The optimal control strategies can dramatically enhance\nsuccess probabilities, but take detailed forms; we use stochastic simulation to\napproximate these optimal strategies with simple heuristics that can be\npractically employed. Our findings provide a roadmap to improving success in\nthe games that millions of people play worldwide, and inform a class of\nresource allocation problems with diminishing returns in stochastic games.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 11:31:25 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Johnston", "Iain G.", ""]]}, {"id": "2002.10214", "submitter": "Andrea Borghesi", "authors": "Andrea Borghesi, Federico Baldo, Michele Lombardi, Michela Milano", "title": "Injective Domain Knowledge in Neural Networks for Transprecision\n  Computing", "comments": null, "journal-ref": "Nicosia G. et al. (eds) Machine Learning, Optimization, and Data\n  Science. LOD 2020. Lecture Notes in Computer Science, vol 12565. Springer,\n  Cham", "doi": "10.1007/978-3-030-64583-0_52", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) models are very effective in many learning tasks, due\nto the capability to extract meaningful information from large data sets.\nNevertheless, there are learning problems that cannot be easily solved relying\non pure data, e.g. scarce data or very complex functions to be approximated.\nFortunately, in many contexts domain knowledge is explicitly available and can\nbe used to train better ML models. This paper studies the improvements that can\nbe obtained by integrating prior knowledge when dealing with a non-trivial\nlearning task, namely precision tuning of transprecision computing\napplications. The domain information is injected in the ML models in different\nways: I) additional features, II) ad-hoc graph-based network topology, III)\nregularization schemes. The results clearly show that ML models exploiting\nproblem-specific information outperform the purely data-driven ones, with an\naverage accuracy improvement around 38%.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 12:58:56 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Borghesi", "Andrea", ""], ["Baldo", "Federico", ""], ["Lombardi", "Michele", ""], ["Milano", "Michela", ""]]}, {"id": "2002.10221", "submitter": "Samuel Alexander", "authors": "Samuel Allen Alexander", "title": "The Archimedean trap: Why traditional reinforcement learning will\n  probably not yield AGI", "comments": "16 pages", "journal-ref": "Journal of Artificial General Intelligence 11(1): 70--85 (2020)", "doi": "10.2478/jagi-2020-0004", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After generalizing the Archimedean property of real numbers in such a way as\nto make it adaptable to non-numeric structures, we demonstrate that the real\nnumbers cannot be used to accurately measure non-Archimedean structures. We\nargue that, since an agent with Artificial General Intelligence (AGI) should\nhave no problem engaging in tasks that inherently involve non-Archimedean\nrewards, and since traditional reinforcement learning rewards are real numbers,\ntherefore traditional reinforcement learning probably will not lead to AGI. We\nindicate two possible ways traditional reinforcement learning could be altered\nto remove this roadblock.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 22:01:56 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 03:39:28 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Alexander", "Samuel Allen", ""]]}, {"id": "2002.10241", "submitter": "Sujoy Chatterjee", "authors": "Sujoy Chatterjee, Nicolas Pasquier, Simon Nanty, Maria A. Zuluaga", "title": "Multi-objective Consensus Clustering Framework for Flight Search\n  Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the travel industry, online customers book their travel itinerary\naccording to several features, like cost and duration of the travel or the\nquality of amenities. To provide personalized recommendations for travel\nsearches, an appropriate segmentation of customers is required. Clustering\nensemble approaches were developed to overcome well-known problems of classical\nclustering approaches, that each rely on a different theoretical model and can\nthus identify in the data space only clusters corresponding to this model.\nClustering ensemble approaches combine multiple clustering results, each from a\ndifferent algorithmic configuration, for generating more robust consensus\nclusters corresponding to agreements between initial clusters. We present a new\nclustering ensemble multi-objective optimization-based framework developed for\nanalyzing Amadeus customer search data and improve personalized\nrecommendations. This framework optimizes diversity in the clustering ensemble\nsearch space and automatically determines an appropriate number of clusters\nwithout requiring user's input. Experimental results compare the efficiency of\nthis approach with other existing approaches on Amadeus customer search data in\nterms of internal (Adjusted Rand Index) and external (Amadeus business metric)\nvalidations.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 03:56:02 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 14:41:59 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Chatterjee", "Sujoy", ""], ["Pasquier", "Nicolas", ""], ["Nanty", "Simon", ""], ["Zuluaga", "Maria A.", ""]]}, {"id": "2002.10259", "submitter": "Ondrej Kuzelka", "authors": "Ondrej Kuzelka", "title": "Complex Markov Logic Networks: Expressivity and Liftability", "comments": "Fixed typos in Lemma 1 and Section 7. Paper accepted to UAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study expressivity of Markov logic networks (MLNs). We introduce complex\nMLNs, which use complex-valued weights, and we show that, unlike standard MLNs\nwith real-valued weights, complex MLNs are fully expressive. We then observe\nthat discrete Fourier transform can be computed using weighted first order\nmodel counting (WFOMC) with complex weights and use this observation to design\nan algorithm for computing relational marginal polytopes which needs\nsubstantially less calls to a WFOMC oracle than a recent algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 13:50:59 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 13:04:58 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Kuzelka", "Ondrej", ""]]}, {"id": "2002.10283", "submitter": "Sven Hertling", "authors": "Sven Hertling, Heiko Paulheim", "title": "The Knowledge Graph Track at OAEI -- Gold Standards, Baselines, and the\n  Golden Hammer Bias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Ontology Alignment Evaluation Initiative (OAEI) is an annual evaluation\nof ontology matching tools. In 2018, we have started the Knowledge Graph track,\nwhose goal is to evaluate the simultaneous matching of entities and schemas of\nlarge-scale knowledge graphs. In this paper, we discuss the design of the track\nand two different strategies of gold standard creation. We analyze results and\nexperiences obtained in first editions of the track, and, by revealing a hidden\ntask, we show that all tools submitted to the track (and probably also to other\ntracks) suffer from a bias which we name the golden hammer bias.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 14:35:02 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Hertling", "Sven", ""], ["Paulheim", "Heiko", ""]]}, {"id": "2002.10295", "submitter": "David P\\\"atzel", "authors": "Michael Heider and David P\\\"atzel and J\\\"org H\\\"ahner", "title": "SupRB: A Supervised Rule-based Learning System for Continuous Problems", "comments": "Submitted to the Genetic and Evolutionary Computation Conference 2020\n  (GECCO 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the SupRB learning system, a new Pittsburgh-style learning\nclassifier system (LCS) for supervised learning on multi-dimensional continuous\ndecision problems. SupRB learns an approximation of a quality function from\nexamples (consisting of situations, choices and associated qualities) and is\nthen able to make an optimal choice as well as predict the quality of a choice\nin a given situation. One area of application for SupRB is parametrization of\nindustrial machinery. In this field, acceptance of the recommendations of\nmachine learning systems is highly reliant on operators' trust. While an\nessential and much-researched ingredient for that trust is prediction quality,\nit seems that this alone is not enough. At least as important is a\nhuman-understandable explanation of the reasoning behind a recommendation.\nWhile many state-of-the-art methods such as artificial neural networks fall\nshort of this, LCSs such as SupRB provide human-readable rules that can be\nunderstood very easily. The prevalent LCSs are not directly applicable to this\nproblem as they lack support for continuous choices. This paper lays the\nfoundations for SupRB and shows its general applicability on a simplified model\nof an additive manufacturing problem.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 14:54:54 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Heider", "Michael", ""], ["P\u00e4tzel", "David", ""], ["H\u00e4hner", "J\u00f6rg", ""]]}, {"id": "2002.10312", "submitter": "Anian Ruoss", "authors": "Anian Ruoss, Mislav Balunovi\\'c, Marc Fischer, and Martin Vechev", "title": "Learning Certified Individually Fair Representations", "comments": "Conference Paper at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fair representation learning provides an effective way of enforcing fairness\nconstraints without compromising utility for downstream users. A desirable\nfamily of such fairness constraints, each requiring similar treatment for\nsimilar individuals, is known as individual fairness. In this work, we\nintroduce the first method that enables data consumers to obtain certificates\nof individual fairness for existing and new data points. The key idea is to map\nsimilar individuals to close latent representations and leverage this latent\nproximity to certify individual fairness. That is, our method enables the data\nproducer to learn and certify a representation where for a data point all\nsimilar individuals are at $\\ell_\\infty$-distance at most $\\epsilon$, thus\nallowing data consumers to certify individual fairness by proving\n$\\epsilon$-robustness of their classifier. Our experimental evaluation on five\nreal-world datasets and several fairness constraints demonstrates the\nexpressivity and scalability of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 15:41:34 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2020 18:17:25 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Ruoss", "Anian", ""], ["Balunovi\u0107", "Mislav", ""], ["Fischer", "Marc", ""], ["Vechev", "Martin", ""]]}, {"id": "2002.10329", "submitter": "Christoph Wernhard", "authors": "Jana Kittelmann, Christoph Wernhard", "title": "KBSET -- Knowledge-Based Support for Scholarly Editing and Text\n  Processing with Declarative LaTeX Markup and a Core Written in SWI-Prolog", "comments": "To appear in DECLARE 2019 Revised Selected Papers", "journal-ref": null, "doi": "10.1007/978-3-030-46714-2_12", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  KBSET is an environment that provides support for scholarly editing in two\nflavors: First, as a practical tool KBSET/Letters that accompanies the\ndevelopment of editions of correspondences (in particular from the 18th and\n19th century), completely from source documents to PDF and HTML presentations.\nSecond, as a prototypical tool KBSET/NER for experimentally investigating novel\nforms of working on editions that are centered around automated named entity\nrecognition. KBSET can process declarative application-specific markup that is\nexpressed in LaTeX notation and incorporate large external fact bases that are\ntypically provided in RDF. KBSET includes specially developed LaTeX styles and\na core system that is written in SWI-Prolog, which is used there in many roles,\nutilizing that it realizes the potential of Prolog as a unifying language.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 15:57:41 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Kittelmann", "Jana", ""], ["Wernhard", "Christoph", ""]]}, {"id": "2002.10373", "submitter": "Pedro Zuidberg Dos Martires", "authors": "Pedro Zuidberg Dos Martires, Nitesh Kumar, Andreas Persson, Amy\n  Loutfi, Luc De Raedt", "title": "Symbolic Learning and Reasoning with Noisy Data for Probabilistic\n  Anchoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotic agents should be able to learn from sub-symbolic sensor data, and at\nthe same time, be able to reason about objects and communicate with humans on a\nsymbolic level. This raises the question of how to overcome the gap between\nsymbolic and sub-symbolic artificial intelligence. We propose a semantic world\nmodeling approach based on bottom-up object anchoring using an object-centered\nrepresentation of the world. Perceptual anchoring processes continuous\nperceptual sensor data and maintains a correspondence to a symbolic\nrepresentation. We extend the definitions of anchoring to handle multi-modal\nprobability distributions and we couple the resulting symbol anchoring system\nto a probabilistic logic reasoner for performing inference. Furthermore, we use\nstatistical relational learning to enable the anchoring framework to learn\nsymbolic knowledge in the form of a set of probabilistic logic rules of the\nworld from noisy and sub-symbolic sensor input. The resulting framework, which\ncombines perceptual anchoring and statistical relational learning, is able to\nmaintain a semantic world model of all the objects that have been perceived\nover time, while still exploiting the expressiveness of logical rules to reason\nabout the state of objects which are not directly observed through sensory\ninput data. To validate our approach we demonstrate, on the one hand, the\nability of our system to perform probabilistic reasoning over multi-modal\nprobability distributions, and on the other hand, the learning of probabilistic\nlogical rules from anchored objects produced by perceptual observations. The\nlearned logical rules are, subsequently, used to assess our proposed\nprobabilistic anchoring procedure. We demonstrate our system in a setting\ninvolving object interactions where object occlusions arise and where\nprobabilistic inference is needed to correctly anchor objects.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 16:58:00 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Martires", "Pedro Zuidberg Dos", ""], ["Kumar", "Nitesh", ""], ["Persson", "Andreas", ""], ["Loutfi", "Amy", ""], ["De Raedt", "Luc", ""]]}, {"id": "2002.10433", "submitter": "Sebastian Risi", "authors": "Sebastian Risi and Mike Preuss", "title": "From Chess and Atari to StarCraft and Beyond: How Game AI is Driving the\n  World of AI", "comments": null, "journal-ref": "KI - Kuenstliche Intelligenz (2020)", "doi": "10.1007/s13218-020-00647-w", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reviews the field of Game AI, which not only deals with creating\nagents that can play a certain game, but also with areas as diverse as creating\ngame content automatically, game analytics, or player modelling. While Game AI\nwas for a long time not very well recognized by the larger scientific\ncommunity, it has established itself as a research area for developing and\ntesting the most advanced forms of AI algorithms and articles covering advances\nin mastering video games such as StarCraft 2 and Quake III appear in the most\nprestigious journals. Because of the growth of the field, a single review\ncannot cover it completely. Therefore, we put a focus on important recent\ndevelopments, including that advances in Game AI are starting to be extended to\nareas outside of games, such as robotics or the synthesis of chemicals. In this\narticle, we review the algorithms and methods that have paved the way for these\nbreakthroughs, report on the other important areas of Game AI research, and\nalso point out exciting directions for the future of Game AI.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 18:28:54 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Risi", "Sebastian", ""], ["Preuss", "Mike", ""]]}, {"id": "2002.10451", "submitter": "Mayank Mittal", "authors": "Mayank Mittal, Marco Gallieri, Alessio Quaglino, Seyed Sina Mirrazavi\n  Salehian, Jan Koutn\\'ik", "title": "Neural Lyapunov Model Predictive Control: Learning Safe Global\n  Controllers from Sub-optimal Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With a growing interest in data-driven control techniques, Model Predictive\nControl (MPC) provides an opportunity to exploit the surplus of data reliably,\nparticularly while taking safety and stability into account. In many real-world\nand industrial applications, it is typical to have an existing control\nstrategy, for instance, execution from a human operator. The objective of this\nwork is to improve upon this unknown, safe but suboptimal policy by learning a\nnew controller that retains safety and stability. Learning how to be safe is\nachieved directly from data and from a knowledge of the system constraints. The\nproposed algorithm alternatively learns the terminal cost and updates the MPC\nparameters according to a stability metric. The terminal cost is constructed as\na Lyapunov function neural network with the aim of recovering or extending the\nstable region of the initial demonstrator using a short prediction horizon.\nTheorems that characterize the stability and performance of the learned MPC in\nthe bearing of model uncertainties and sub-optimality due to function\napproximation are presented. The efficacy of the proposed algorithm is\ndemonstrated on non-linear continuous control tasks with soft constraints. The\nproposed approach can improve upon the initial demonstrator also in practice\nand achieve better stability than popular reinforcement learning baselines.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 16:57:38 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 14:37:05 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Mittal", "Mayank", ""], ["Gallieri", "Marco", ""], ["Quaglino", "Alessio", ""], ["Salehian", "Seyed Sina Mirrazavi", ""], ["Koutn\u00edk", "Jan", ""]]}, {"id": "2002.10524", "submitter": "Carlos Martin", "authors": "Carlos Martin, Tuomas Sandholm", "title": "Efficient exploration of zero-sum stochastic games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LG cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the increasingly important and common game-solving setting\nwhere we do not have an explicit description of the game but only oracle access\nto it through gameplay, such as in financial or military simulations and\ncomputer games. During a limited-duration learning phase, the algorithm can\ncontrol the actions of both players in order to try to learn the game and how\nto play it well. After that, the algorithm has to produce a strategy that has\nlow exploitability. Our motivation is to quickly learn strategies that have low\nexploitability in situations where evaluating the payoffs of a queried strategy\nprofile is costly. For the stochastic game setting, we propose using the\ndistribution of state-action value functions induced by a belief distribution\nover possible environments. We compare the performance of various exploration\nstrategies for this task, including generalizations of Thompson sampling and\nBayes-UCB to this new setting. These two consistently outperform other\nstrategies.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 20:30:38 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Martin", "Carlos", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "2002.10539", "submitter": "David Eriksson", "authors": "Eric Hans Lee, David Eriksson, Bolong Cheng, Michael McCourt, David\n  Bindel", "title": "Efficient Rollout Strategies for Bayesian Optimization", "comments": "To appear in UAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) is a class of sample-efficient global optimization\nmethods, where a probabilistic model conditioned on previous observations is\nused to determine future evaluations via the optimization of an acquisition\nfunction. Most acquisition functions are myopic, meaning that they only\nconsider the impact of the next function evaluation. Non-myopic acquisition\nfunctions consider the impact of the next $h$ function evaluations and are\ntypically computed through rollout, in which $h$ steps of BO are simulated.\nThese rollout acquisition functions are defined as $h$-dimensional integrals,\nand are expensive to compute and optimize. We show that a combination of\nquasi-Monte Carlo, common random numbers, and control variates significantly\nreduce the computational burden of rollout. We then formulate a policy-search\nbased approach that removes the need to optimize the rollout acquisition\nfunction. Finally, we discuss the qualitative behavior of rollout policies in\nthe setting of multi-modal objectives and model error.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 20:54:08 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 17:52:49 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2020 03:40:36 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Lee", "Eric Hans", ""], ["Eriksson", "David", ""], ["Cheng", "Bolong", ""], ["McCourt", "Michael", ""], ["Bindel", "David", ""]]}, {"id": "2002.10544", "submitter": "Nikunj Saunshi", "authors": "Sanjeev Arora, Simon S. Du, Sham Kakade, Yuping Luo, and Nikunj\n  Saunshi", "title": "Provable Representation Learning for Imitation Learning via Bi-level\n  Optimization", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common strategy in modern learning systems is to learn a representation\nthat is useful for many tasks, a.k.a. representation learning. We study this\nstrategy in the imitation learning setting for Markov decision processes (MDPs)\nwhere multiple experts' trajectories are available. We formulate representation\nlearning as a bi-level optimization problem where the \"outer\" optimization\ntries to learn the joint representation and the \"inner\" optimization encodes\nthe imitation learning setup and tries to learn task-specific parameters. We\ninstantiate this framework for the imitation learning settings of behavior\ncloning and observation-alone. Theoretically, we show using our framework that\nrepresentation learning can provide sample complexity benefits for imitation\nlearning in both settings. We also provide proof-of-concept experiments to\nverify our theory.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 21:03:52 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Arora", "Sanjeev", ""], ["Du", "Simon S.", ""], ["Kakade", "Sham", ""], ["Luo", "Yuping", ""], ["Saunshi", "Nikunj", ""]]}, {"id": "2002.10563", "submitter": "Behzad Khamidehi", "authors": "Behzad Khamidehi and Elvino S. Sousa", "title": "A Double Q-Learning Approach for Navigation of Aerial Vehicles with\n  Connectivity Constraint", "comments": "Accepted to appear in IEEE ICC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the trajectory optimization problem for an aerial vehicle\nwith the mission of flying between a pair of given initial and final locations.\nThe objective is to minimize the travel time of the aerial vehicle ensuring\nthat the communication connectivity constraint required for the safe operation\nof the aerial vehicle is satisfied. We consider two different criteria for the\nconnectivity constraint of the aerial vehicle which leads to two different\nscenarios. In the first scenario, we assume that the maximum continuous time\nduration that the aerial vehicle is out of the coverage of the ground base\nstations (GBSs) is limited to a given threshold. In the second scenario,\nhowever, we assume that the total time periods that the aerial vehicle is not\ncovered by the GBSs is restricted. Based on these two constraints, we formulate\ntwo trajectory optimization problems. To solve these non-convex problems, we\nuse an approach based on the double Q-learning method which is a model-free\nreinforcement learning technique and unlike the existing algorithms does not\nneed perfect knowledge of the environment. Moreover, in contrast to the\nwell-known Q-learning technique, our double Q-learning algorithm does not\nsuffer from the over-estimation issue. Simulation results show that although\nour algorithm does not require prior information of the environment, it works\nwell and shows near optimal performance.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 22:01:56 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Khamidehi", "Behzad", ""], ["Sousa", "Elvino S.", ""]]}, {"id": "2002.10665", "submitter": "Sumant Pushp", "authors": "Sumant Pushp, Pragya Kashmira, Shyamanta M Hazarika", "title": "Declarative Memory-based Structure for the Representation of Text Data", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the era of intelligent computing, computational progress in text\nprocessing is an essential consideration. Many systems have been developed to\nprocess text over different languages. Though, there is considerable\ndevelopment, they still lack in understanding of the text, i.e., instead of\nkeeping text as knowledge, many treat text as a data. In this work we introduce\na text representation scheme which is influenced by human memory\ninfrastructure. Since texts are declarative in nature, a structural\norganization would foster efficient computation over text. We exploit long term\nepisodic memory to keep text information observed over time. This not only keep\nfragments of text in an organized fashion but also reduces redundancy and\nstores the temporal relation among them. Wordnet has been used to imitate\nsemantic memory, which works at word level to facilitate the understanding\nabout individual words within text. Experimental results of various operation\nperformed over episodic memory and growth of knowledge infrastructure over time\nis reported.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 04:56:47 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Pushp", "Sumant", ""], ["Kashmira", "Pragya", ""], ["Hazarika", "Shyamanta M", ""]]}, {"id": "2002.10697", "submitter": "Faez Ahmed", "authors": "Faez Ahmed, John Dickerson, Mark Fuge", "title": "Forming Diverse Teams from Sequentially Arriving People", "comments": "Journal of Mechanical Design", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative work often benefits from having teams or organizations with\nheterogeneous members. In this paper, we present a method to form such diverse\nteams from people arriving sequentially over time. We define a monotone\nsubmodular objective function that combines the diversity and quality of a team\nand propose an algorithm to maximize the objective while satisfying multiple\nconstraints. This allows us to balance both how diverse the team is and how\nwell it can perform the task at hand. Using crowd experiments, we show that, in\npractice, the algorithm leads to large gains in team diversity. Using\nsimulations, we show how to quantify the additional cost of forming diverse\nteams and how to address the problem of simultaneously maximizing diversity for\nseveral attributes (e.g., country of origin, gender). Our method has\napplications in collaborative work ranging from team formation, the assignment\nof workers to teams in crowdsourcing, and reviewer allocation to journal papers\narriving sequentially. Our code is publicly accessible for further research.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 07:00:07 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Ahmed", "Faez", ""], ["Dickerson", "John", ""], ["Fuge", "Mark", ""]]}, {"id": "2002.10742", "submitter": "Michele Lombardi", "authors": "Mattia Silvestri, Michele Lombardi, Michela Milano", "title": "Injecting Domain Knowledge in Neural Networks: a Controlled Experiment\n  on a Constrained Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given enough data, Deep Neural Networks (DNNs) are capable of learning\ncomplex input-output relations with high accuracy. In several domains, however,\ndata is scarce or expensive to retrieve, while a substantial amount of expert\nknowledge is available. It seems reasonable that if we can inject this\nadditional information in the DNN, we could ease the learning process. One such\ncase is that of Constraint Problems, for which declarative approaches exists\nand pure ML solutions have obtained mixed success. Using a classical\nconstrained problem as a case study, we perform controlled experiments to probe\nthe impact of progressively adding domain and empirical knowledge in the DNN.\nOur results are very encouraging, showing that (at least in our setup)\nembedding domain knowledge at training time can have a considerable effect and\nthat a small amount of empirical knowledge is sufficient to obtain practically\nuseful results.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 08:59:34 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Silvestri", "Mattia", ""], ["Lombardi", "Michele", ""], ["Milano", "Michela", ""]]}, {"id": "2002.10764", "submitter": "Gourab K Patro", "authors": "Gourab K Patro, Arpita Biswas, Niloy Ganguly, Krishna P. Gummadi,\n  Abhijnan Chakraborty", "title": "FairRec: Two-Sided Fairness for Personalized Recommendations in\n  Two-Sided Platforms", "comments": "In Proceedings of The Web Conference (WWW) 2020", "journal-ref": null, "doi": "10.1145/3366423.3380196", "report-no": null, "categories": "cs.AI cs.GT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the problem of fair recommendation in the context of two-sided\nonline platforms, comprising customers on one side and producers on the other.\nTraditionally, recommendation services in these platforms have focused on\nmaximizing customer satisfaction by tailoring the results according to the\npersonalized preferences of individual customers. However, our investigation\nreveals that such customer-centric design may lead to unfair distribution of\nexposure among the producers, which may adversely impact their well-being. On\nthe other hand, a producer-centric design might become unfair to the customers.\nThus, we consider fairness issues that span both customers and producers. Our\napproach involves a novel mapping of the fair recommendation problem to a\nconstrained version of the problem of fairly allocating indivisible goods. Our\nproposed FairRec algorithm guarantees at least Maximin Share (MMS) of exposure\nfor most of the producers and Envy-Free up to One item (EF1) fairness for every\ncustomer. Extensive evaluations over multiple real-world datasets show the\neffectiveness of FairRec in ensuring two-sided fairness while incurring a\nmarginal loss in the overall recommendation quality.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 09:43:48 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 12:54:52 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Patro", "Gourab K", ""], ["Biswas", "Arpita", ""], ["Ganguly", "Niloy", ""], ["Gummadi", "Krishna P.", ""], ["Chakraborty", "Abhijnan", ""]]}, {"id": "2002.10766", "submitter": "Michele Lombardi", "authors": "Fabrizio Detassis, Michele Lombardi, Michela Milano", "title": "Teaching the Old Dog New Tricks: Supervised Learning with Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adding constraint support in Machine Learning has the potential to address\noutstanding issues in data-driven AI systems, such as safety and fairness.\nExisting approaches typically apply constrained optimization techniques to ML\ntraining, enforce constraint satisfaction by adjusting the model design, or use\nconstraints to correct the output. Here, we investigate a different,\ncomplementary, strategy based on \"teaching\" constraint satisfaction to a\nsupervised ML method via the direct use of a state-of-the-art constraint\nsolver: this enables taking advantage of decades of research on constrained\noptimization with limited effort. In practice, we use a decomposition scheme\nalternating master steps (in charge of enforcing the constraints) and learner\nsteps (where any supervised ML model and training algorithm can be employed).\nThe process leads to approximate constraint satisfaction in general, and\nconvergence properties are difficult to establish; despite this fact, we found\nempirically that even a na\\\"ive setup of our approach performs well on ML tasks\nwith fairness constraints, and on classical datasets with synthetic\nconstraints.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 09:47:39 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 16:39:24 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Detassis", "Fabrizio", ""], ["Lombardi", "Michele", ""], ["Milano", "Michela", ""]]}, {"id": "2002.10774", "submitter": "Pietro Di Stefano", "authors": "Pietro G. Di Stefano, James M. Hickey, Vlasios Vasileiou", "title": "Counterfactual fairness: removing direct effects through regularization", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building machine learning models that are fair with respect to an\nunprivileged group is a topical problem. Modern fairness-aware algorithms often\nignore causal effects and enforce fairness through modifications applicable to\nonly a subset of machine learning models. In this work, we propose a new\ndefinition of fairness that incorporates causality through the Controlled\nDirect Effect (CDE). We develop regularizations to tackle classical fairness\nmeasures and present a causal regularization that satisfies our new fairness\ndefinition by removing the impact of unprivileged group variables on the model\noutcomes as measured by the CDE. These regularizations are applicable to any\nmodel trained using by iteratively minimizing a loss through differentiation.\nWe demonstrate our approaches using both gradient boosting and logistic\nregression on: a synthetic dataset, the UCI Adult (Census) Dataset, and a\nreal-world credit-risk dataset. Our results were found to mitigate unfairness\nfrom the predictions with small reductions in model performance.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 10:13:55 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 11:28:34 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Di Stefano", "Pietro G.", ""], ["Hickey", "James M.", ""], ["Vasileiou", "Vlasios", ""]]}, {"id": "2002.10870", "submitter": "Mohammad-Ali Javidian", "authors": "Mohammad Ali Javidian, Marco Valtorta, Pooyan Jamshidi", "title": "AMP Chain Graphs: Minimal Separators and Structure Learning Algorithms", "comments": "This is an arXiv version of the paper that has been accepted for\n  publication in the Journal of Artificial Intelligence Research (JAIR). arXiv\n  admin note: text overlap with arXiv:1211.3295 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of finding a minimal separator in an\nAndersson-Madigan-Perlman chain graph (AMP CG), namely, finding a set Z of\nnodes that separates a given nonadjacent pair of nodes such that no proper\nsubset of Z separates that pair. We analyze several versions of this problem\nand offer polynomial-time algorithms for each. These include finding a minimal\nseparator from a restricted set of nodes, finding a minimal separator for two\ngiven disjoint sets, and testing whether a given separator is minimal. To\naddress the problem of learning the structure of AMP CGs from data, we show\nthat the PC-like algorithm (Pena, 2012) is order-dependent, in the sense that\nthe output can depend on the order in which the variables are given. We propose\nseveral modifications of the PC-like algorithm that remove part or all of this\norder-dependence. We also extend the decomposition-based approach for learning\nBayesian networks (BNs) proposed by (Xie et al., 2006) to learn AMP CGs, which\ninclude BNs as a special case, under the faithfulness assumption. We prove the\ncorrectness of our extension using the minimal separator results. Using\nstandard benchmarks and synthetically generated models and data in our\nexperiments demonstrate the competitive performance of our decomposition-based\nmethod, called LCD-AMP, in comparison with the (modified versions of) PC-like\nalgorithm. The LCD-AMP algorithm usually outperforms the PC-like algorithm, and\nour modifications of the PC-like algorithm learn structures that are more\nsimilar to the underlying ground truth graphs than the original PC-like\nalgorithm, especially in high-dimensional settings. In particular, we\nempirically show that the results of both algorithms are more accurate and\nstabler when the sample size is reasonably large and the underlying graph is\nsparse.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 18:14:14 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 20:38:42 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Javidian", "Mohammad Ali", ""], ["Valtorta", "Marco", ""], ["Jamshidi", "Pooyan", ""]]}, {"id": "2002.10892", "submitter": "Christoph Wernhard", "authors": "Christoph Wernhard", "title": "Facets of the PIE Environment for Proving, Interpolating and Eliminating\n  on the Basis of First-Order Logic", "comments": "To appear in DECLARE 2019 Revised Selected Papers. arXiv admin note:\n  substantial text overlap with arXiv:1908.11137", "journal-ref": null, "doi": "10.1007/978-3-030-46714-2_11", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PIE is a Prolog-embedded environment for automated reasoning on the basis of\nfirst-order logic. Its main focus is on formulas, as constituents of complex\nformalizations that are structured through formula macros, and as outputs of\nreasoning tasks such as second-order quantifier elimination and Craig\ninterpolation. It supports a workflow based on documents that intersperse macro\ndefinitions, invocations of reasoners, and LaTeX-formatted natural language\ntext. Starting from various examples, the paper discusses features and\napplication possibilities of PIE along with current limitations and issues for\nfuture research.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 16:09:10 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Wernhard", "Christoph", ""]]}, {"id": "2002.10917", "submitter": "Davide Venturelli", "authors": "Minh Do, Zhihui Wang, Bryan O'Gorman, Davide Venturelli, Eleanor\n  Rieffel, Jeremy Frank", "title": "Planning for Compilation of a Quantum Algorithm for Graph Coloring", "comments": "8 pages, 4 tables, 5 figures", "journal-ref": "The 24th European Conference on Artificial Intelligence (ECAI\n  2020)", "doi": null, "report-no": null, "categories": "quant-ph cs.AI cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of compiling general quantum algorithms for implementation on\nnear-term quantum processors has been introduced to the AI community. Previous\nwork demonstrated that temporal planning is an attractive approach for part of\nthis compilationtask, specifically, the routing of circuits that implement the\nQuantum Alternating Operator Ansatz (QAOA) applied to the MaxCut problem on a\nquantum processor architecture. In this paper, we extend the earlier work to\nroute circuits that implement QAOA for Graph Coloring problems. QAOA for\ncoloring requires execution of more, and more complex, operations on the chip,\nwhich makes routing a more challenging problem. We evaluate the approach on\nstate-of-the-art hardware architectures from leading quantum computing\ncompanies. Additionally, we apply a planning approach to qubit initialization.\nOur empirical evaluation shows that temporal planning compares well to\nreasonable analytic upper bounds, and that solving qubit initialization with a\nclassical planner generally helps temporal planners in finding shorter-makespan\ncompilations for QAOA for Graph Coloring. These advances suggest that temporal\nplanning can be an effective approach for more complex quantum computing\nalgorithms and architectures.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 03:09:57 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Do", "Minh", ""], ["Wang", "Zhihui", ""], ["O'Gorman", "Bryan", ""], ["Venturelli", "Davide", ""], ["Rieffel", "Eleanor", ""], ["Frank", "Jeremy", ""]]}, {"id": "2002.10943", "submitter": "Balaji Ganesan", "authors": "Lingraj S Vannur, Balaji Ganesan, Lokesh Nagalapatti, Hima Patel, MN\n  Thippeswamy", "title": "Data Augmentation for Personal Knowledge Base Population", "comments": "8 pages, 9 figures, 6 tables. under review. arXiv admin note: text\n  overlap with arXiv:2001.08013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cold start knowledge base population (KBP) is the problem of populating a\nknowledge base from unstructured documents. While artificial neural networks\nhave led to significant improvements in the different tasks that are part of\nKBP, the overall F1 of the end-to-end system remains quite low. This problem is\nmore acute in personal knowledge bases, which present additional challenges\nwith regard to data protection, fairness and privacy. In this work, we present\na system that uses rule based annotators and a graph neural network for missing\nlink prediction, to populate a more complete, fair and diverse knowledge base\nfrom the TACRED dataset.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 07:39:55 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 06:31:40 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Vannur", "Lingraj S", ""], ["Ganesan", "Balaji", ""], ["Nagalapatti", "Lokesh", ""], ["Patel", "Hima", ""], ["Thippeswamy", "MN", ""]]}, {"id": "2002.10948", "submitter": "Dmitry V. Dylov", "authors": "Dmitrii Krylov, Remi Tachet, Romain Laroche, Michael Rosenblum, Dmitry\n  V. Dylov", "title": "Reinforcement Learning Framework for Deep Brain Stimulation Study", "comments": "7 pages + 1 references, 7 figures. arXiv admin note: text overlap\n  with arXiv:1909.12154", "journal-ref": null, "doi": "10.24963/ijcai.2020/394", "report-no": null, "categories": "q-bio.NC cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malfunctioning neurons in the brain sometimes operate synchronously,\nreportedly causing many neurological diseases, e.g. Parkinson's. Suppression\nand control of this collective synchronous activity are therefore of great\nimportance for neuroscience, and can only rely on limited engineering trials\ndue to the need to experiment with live human brains. We present the first\nReinforcement Learning gym framework that emulates this collective behavior of\nneurons and allows us to find suppression parameters for the environment of\nsynthetic degenerate models of neurons. We successfully suppress synchrony via\nRL for three pathological signaling regimes, characterize the framework's\nstability to noise, and further remove the unwanted oscillations by engaging\nmultiple PPO agents.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 16:48:43 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Krylov", "Dmitrii", ""], ["Tachet", "Remi", ""], ["Laroche", "Romain", ""], ["Rosenblum", "Michael", ""], ["Dylov", "Dmitry V.", ""]]}, {"id": "2002.11002", "submitter": "Andrew Cropper", "authors": "Andrew Cropper, Sebastijan Duman\\v{c}i\\'c, and Stephen H. Muggleton", "title": "Turning 30: New Ideas in Inductive Logic Programming", "comments": "IJCAI2020 survey paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common criticisms of state-of-the-art machine learning include poor\ngeneralisation, a lack of interpretability, and a need for large amounts of\ntraining data. We survey recent work in inductive logic programming (ILP), a\nform of machine learning that induces logic programs from data, which has shown\npromise at addressing these limitations. We focus on new methods for learning\nrecursive programs that generalise from few examples, a shift from using\nhand-crafted background knowledge to \\emph{learning} background knowledge, and\nthe use of different technologies, notably answer set programming and neural\nnetworks. As ILP approaches 30, we also discuss directions for future research.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 16:23:11 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 07:27:32 GMT"}, {"version": "v3", "created": "Sun, 1 Mar 2020 13:36:32 GMT"}, {"version": "v4", "created": "Wed, 22 Apr 2020 09:06:19 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Cropper", "Andrew", ""], ["Duman\u010di\u0107", "Sebastijan", ""], ["Muggleton", "Stephen H.", ""]]}, {"id": "2002.11004", "submitter": "Danushka Bollegala", "authors": "Danushka Bollegala, Ryuichi Kiryo, Kosuke Tsujino, Haruki Yukawa", "title": "Language-Independent Tokenisation Rivals Language-Specific Tokenisation\n  for Word Similarity Prediction", "comments": "To appear in the 12th Language Resources and Evaluation (LREC 2020)\n  Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language-independent tokenisation (LIT) methods that do not require labelled\nlanguage resources or lexicons have recently gained popularity because of their\napplicability in resource-poor languages. Moreover, they compactly represent a\nlanguage using a fixed size vocabulary and can efficiently handle unseen or\nrare words. On the other hand, language-specific tokenisation (LST) methods\nhave a long and established history, and are developed using carefully created\nlexicons and training resources. Unlike subtokens produced by LIT methods, LST\nmethods produce valid morphological subwords. Despite the contrasting\ntrade-offs between LIT vs. LST methods, their performance on downstream NLP\ntasks remain unclear. In this paper, we empirically compare the two approaches\nusing semantic similarity measurement as an evaluation task across a diverse\nset of languages. Our experimental results covering eight languages show that\nLST consistently outperforms LIT when the vocabulary size is large, but LIT can\nproduce comparable or better results than LST in many languages with\ncomparatively smaller (i.e. less than 100K words) vocabulary sizes, encouraging\nthe use of LIT when language-specific resources are unavailable, incomplete or\na smaller model is required. Moreover, we find that smoothed inverse frequency\n(SIF) to be an accurate method to create word embeddings from subword\nembeddings for multilingual semantic similarity prediction tasks. Further\nanalysis of the nearest neighbours of tokens show that semantically and\nsyntactically related tokens are closely embedded in subword embedding spaces\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 16:24:42 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Bollegala", "Danushka", ""], ["Kiryo", "Ryuichi", ""], ["Tsujino", "Kosuke", ""], ["Yukawa", "Haruki", ""]]}, {"id": "2002.11018", "submitter": "Mathilde Guillemot", "authors": "Mathilde Guillemot, Catherine Heusele, Rodolphe Korichi, Sylvianne\n  Schnebert, Liming Chen", "title": "Breaking Batch Normalization for better explainability of Deep Neural\n  Networks through Layer-wise Relevance Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of transparency of neural networks stays a major break for their\nuse. The Layerwise Relevance Propagation technique builds heat-maps\nrepresenting the relevance of each input in the model s decision. The relevance\nspreads backward from the last to the first layer of the Deep Neural Network.\nLayer-wise Relevance Propagation does not manage normalization layers, in this\nwork we suggest a method to include normalization layers. Specifically, we\nbuild an equivalent network fusing normalization layers and convolutional or\nfully connected layers. Heatmaps obtained with our method on MNIST and CIFAR 10\ndatasets are more accurate for convolutional layers. Our study also prevents\nfrom using Layerwise Relevance Propagation with networks including a\ncombination of connected layers and normalization layer.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 13:06:55 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Guillemot", "Mathilde", ""], ["Heusele", "Catherine", ""], ["Korichi", "Rodolphe", ""], ["Schnebert", "Sylvianne", ""], ["Chen", "Liming", ""]]}, {"id": "2002.11089", "submitter": "Benjamin Eysenbach", "authors": "Benjamin Eysenbach, Xinyang Geng, Sergey Levine, and Ruslan\n  Salakhutdinov", "title": "Rewriting History with Inverse RL: Hindsight Inference for Policy\n  Improvement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task reinforcement learning (RL) aims to simultaneously learn policies\nfor solving many tasks. Several prior works have found that relabeling past\nexperience with different reward functions can improve sample efficiency.\nRelabeling methods typically ask: if, in hindsight, we assume that our\nexperience was optimal for some task, for what task was it optimal? In this\npaper, we show that hindsight relabeling is inverse RL, an observation that\nsuggests that we can use inverse RL in tandem for RL algorithms to efficiently\nsolve many tasks. We use this idea to generalize goal-relabeling techniques\nfrom prior work to arbitrary classes of tasks. Our experiments confirm that\nrelabeling data using inverse RL accelerates learning in general multi-task\nsettings, including goal-reaching, domains with discrete sets of rewards, and\nthose with linear reward functions.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 18:36:31 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Eysenbach", "Benjamin", ""], ["Geng", "Xinyang", ""], ["Levine", "Sergey", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "2002.11097", "submitter": "I. Elizabeth Kumar", "authors": "I. Elizabeth Kumar, Suresh Venkatasubramanian, Carlos Scheidegger,\n  Sorelle Friedler", "title": "Problems with Shapley-value-based explanations as feature importance\n  measures", "comments": "Accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Game-theoretic formulations of feature importance have become popular as a\nway to \"explain\" machine learning models. These methods define a cooperative\ngame between the features of a model and distribute influence among these input\nelements using some form of the game's unique Shapley values. Justification for\nthese methods rests on two pillars: their desirable mathematical properties,\nand their applicability to specific motivations for explanations. We show that\nmathematical problems arise when Shapley values are used for feature importance\nand that the solutions to mitigate these necessarily induce further complexity,\nsuch as the need for causal reasoning. We also draw on additional literature to\nargue that Shapley values do not provide explanations which suit human-centric\ngoals of explainability.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 18:51:14 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 14:38:36 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Kumar", "I. Elizabeth", ""], ["Venkatasubramanian", "Suresh", ""], ["Scheidegger", "Carlos", ""], ["Friedler", "Sorelle", ""]]}, {"id": "2002.11107", "submitter": "Okyu Kwon", "authors": "Okyu Kwon", "title": "Very simple statistical evidence that AlphaGo has exceeded human limits\n  in playing GO game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning technology is making great progress in solving the challenging\nproblems of artificial intelligence, hence machine learning based on artificial\nneural networks is in the spotlight again. In some areas, artificial\nintelligence based on deep learning is beyond human capabilities. It seemed\nextremely difficult for a machine to beat a human in a Go game, but AlphaGo has\nshown to beat a professional player in the game. By looking at the statistical\ndistribution of the distance in which the Go stones are laid in succession, we\nfind a clear trace that Alphago has surpassed human abilities. The AlphaGo than\nprofessional players and professional players than ordinary players shows the\nlaying of stones in the distance becomes more frequent. In addition, AlphaGo\nshows a much more pronounced difference than that of ordinary players and\nprofessional players.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 01:46:12 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Kwon", "Okyu", ""]]}, {"id": "2002.11164", "submitter": "Aleksandar Kartelj", "authors": "Aleksandar Kartelj, Vladimir Filipovi\\'c, Sini\\v{s}a Vre\\'cica, Rade\n  \\v{Z}ivaljevi\\'c", "title": "Topologically sensitive metaheuristics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.AT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes topologically sensitive metaheuristics, and describes\nconceptual design of topologically sensitive Variable Neighborhood Search\nmethod (TVNS) and topologically sensitive Electromagnetism Metaheuristic (TEM).\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 20:12:47 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Kartelj", "Aleksandar", ""], ["Filipovi\u0107", "Vladimir", ""], ["Vre\u0107ica", "Sini\u0161a", ""], ["\u017divaljevi\u0107", "Rade", ""]]}, {"id": "2002.11174", "submitter": "Corban Rivera", "authors": "Corban G. Rivera, Olivia Lyons, Arielle Summitt, Ayman Fatima, Ji Pak,\n  William Shao, Robert Chalmers, Aryeh Englander, Edward W. Staley, I-Jeng\n  Wang, Ashley J. Llorens", "title": "TanksWorld: A Multi-Agent Environment for AI Safety Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to create artificial intelligence (AI) capable of performing\ncomplex tasks is rapidly outpacing our ability to ensure the safe and assured\noperation of AI-enabled systems. Fortunately, a landscape of AI safety research\nis emerging in response to this asymmetry and yet there is a long way to go. In\nparticular, recent simulation environments created to illustrate AI safety\nrisks are relatively simple or narrowly-focused on a particular issue. Hence,\nwe see a critical need for AI safety research environments that abstract\nessential aspects of complex real-world applications. In this work, we\nintroduce the AI safety TanksWorld as an environment for AI safety research\nwith three essential aspects: competing performance objectives, human-machine\nteaming, and multi-agent competition. The AI safety TanksWorld aims to\naccelerate the advancement of safe multi-agent decision-making algorithms by\nproviding a software framework to support competitions with both system\nperformance and safety objectives. As a work in progress, this paper introduces\nour research objectives and learning environment with reference code and\nbaseline performance metrics to follow in a future work.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 21:00:52 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Rivera", "Corban G.", ""], ["Lyons", "Olivia", ""], ["Summitt", "Arielle", ""], ["Fatima", "Ayman", ""], ["Pak", "Ji", ""], ["Shao", "William", ""], ["Chalmers", "Robert", ""], ["Englander", "Aryeh", ""], ["Staley", "Edward W.", ""], ["Wang", "I-Jeng", ""], ["Llorens", "Ashley J.", ""]]}, {"id": "2002.11195", "submitter": "Ilya A. Surov Mr.", "authors": "Ilya A. Surov", "title": "Quantum Cognitive Triad. Semantic geometry of context representation", "comments": "44 pages, 6 figures", "journal-ref": null, "doi": "10.1007/s10699-020-09712-x", "report-no": null, "categories": "q-bio.NC cs.AI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper describes an algorithm for semantic representation of behavioral\ncontexts relative to a dichotomic decision alternative. The contexts are\nrepresented as quantum qubit states in two-dimensional Hilbert space visualized\nas points on the Bloch sphere. The azimuthal coordinate of this sphere\nfunctions as a one-dimensional semantic space in which the contexts are\naccommodated according to their subjective relevance to the considered\nuncertainty. The contexts are processed in triples defined by knowledge of a\nsubject about a binary situational factor. The obtained triads of context\nrepresentations function as stable cognitive structure at the same time\nallowing a subject to model probabilistically-variative behavior. The developed\nalgorithm illustrates an approach for quantitative subjectively-semantic\nmodeling of behavior based on conceptual and mathematical apparatus of quantum\ntheory.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 17:29:10 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 14:43:28 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Surov", "Ilya A.", ""]]}, {"id": "2002.11197", "submitter": "Chad Peters", "authors": "Chad Peters, Babak Esfandiari, Mohamad Zalat and Robert West", "title": "Behavior Cloning in OpenAI using Case Based Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from Observation (LfO), also known as Behavioral Cloning, is an\napproach for building software agents by recording the behavior of an expert\n(human or artificial) and using the recorded data to generate the required\nbehavior. jLOAF is a platform that uses Case-Based Reasoning to achieve LfO. In\nthis paper we interface jLOAF with the popular OpenAI Gym environment. Our\nexperimental results show how our approach can be used to provide a baseline\nfor comparison in this domain, as well as identify the strengths and weaknesses\nwhen dealing with environmental complexity.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 22:41:56 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Peters", "Chad", ""], ["Esfandiari", "Babak", ""], ["Zalat", "Mohamad", ""], ["West", "Robert", ""]]}, {"id": "2002.11262", "submitter": "Abdul Dakkak", "authors": "Abdul Dakkak, Cheng Li, Jinjun Xiong, Wen-Mei Hwu", "title": "DLSpec: A Deep Learning Task Exchange Specification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Learning (DL) innovations are being introduced at a rapid pace. However,\nthe current lack of standard specification of DL tasks makes sharing, running,\nreproducing, and comparing these innovations difficult. To address this\nproblem, we propose DLSpec, a model-, dataset-, software-, and\nhardware-agnostic DL specification that captures the different aspects of DL\ntasks. DLSpec has been tested by specifying and running hundreds of DL tasks.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 02:27:50 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Dakkak", "Abdul", ""], ["Li", "Cheng", ""], ["Xiong", "Jinjun", ""], ["Hwu", "Wen-Mei", ""]]}, {"id": "2002.11310", "submitter": "Xin Ye", "authors": "Xin Ye and Yezhou Yang", "title": "From Seeing to Moving: A Survey on Learning for Visual Indoor Navigation\n  (VIN)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Indoor Navigation (VIN) task has drawn increasing attention from the\ndata-driven machine learning communities especially with the recently reported\nsuccess from learning-based methods. Due to the innate complexity of this task,\nresearchers have tried approaching the problem from a variety of different\nangles, the full scope of which has not yet been captured within an overarching\nreport. This survey first summarizes the representative work of learning-based\napproaches for the VIN task and then identifies and discusses lingering issues\nimpeding the VIN performance, as well as motivates future research in these key\nareas worth exploring for the community.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 05:27:30 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 20:47:08 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Ye", "Xin", ""], ["Yang", "Yezhou", ""]]}, {"id": "2002.11319", "submitter": "Milo M. Lin", "authors": "Paul J. Blazek, Milo M. Lin", "title": "A neural network model of perception and reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How perception and reasoning arise from neuronal network activity is poorly\nunderstood. This is reflected in the fundamental limitations of connectionist\nartificial intelligence, typified by deep neural networks trained via\ngradient-based optimization. Despite success on many tasks, such networks\nremain unexplainable black boxes incapable of symbolic reasoning and concept\ngeneralization. Here we show that a simple set of biologically consistent\norganizing principles confer these capabilities to neuronal networks. To\ndemonstrate, we implement these principles in a novel machine learning\nalgorithm, based on concept construction instead of optimization, to design\ndeep neural networks that reason with explainable neuron activity. On a range\nof tasks including NP-hard problems, their reasoning capabilities grant\nadditional cognitive functions, like deliberating through self-analysis,\ntolerating adversarial attacks, and learning transferable rules from simple\nexamples to solve problems of unencountered complexity. The networks also\nnaturally display properties of biological nervous systems inherently absent in\ncurrent deep neural networks, including sparsity, modularity, and both\ndistributed and localized firing patterns. Because they do not sacrifice\nperformance, compactness, or training time on standard learning tasks, these\nnetworks provide a new black-box-free approach to artificial intelligence. They\nlikewise serve as a quantitative framework to understand the emergence of\ncognition from neuronal networks.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 06:26:04 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Blazek", "Paul J.", ""], ["Lin", "Milo M.", ""]]}, {"id": "2002.11385", "submitter": "Xingbo Fu", "authors": "Xingbo Fu, Feng Gao, Jiang Wu", "title": "When Do Drivers Concentrate? Attention-based Driver Behavior Modeling\n  With Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driver distraction a significant risk to driving safety. Apart from spatial\ndomain, research on temporal inattention is also necessary. This paper aims to\nfigure out the pattern of drivers' temporal attention allocation. In this\npaper, we propose an actor-critic method - Attention-based Twin Delayed Deep\nDeterministic policy gradient (ATD3) algorithm to approximate a driver' s\naction according to observations and measure the driver' s attention allocation\nfor consecutive time steps in car-following model. Considering reaction time,\nwe construct the attention mechanism in the actor network to capture temporal\ndependencies of consecutive observations. In the critic network, we employ Twin\nDelayed Deep Deterministic policy gradient algorithm (TD3) to address\noverestimated value estimates persisting in the actor-critic algorithm. We\nconduct experiments on real-world vehicle trajectory datasets and show that the\naccuracy of our proposed approach outperforms seven baseline algorithms.\nMoreover, the results reveal that the attention of the drivers in smooth\nvehicles is uniformly distributed in previous observations while they keep\ntheir attention to recent observations when sudden decreases of relative speeds\noccur. This study is the first contribution to drivers' temporal attention and\nprovides scientific support for safety measures in transportation systems from\nthe perspective of data mining.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 09:56:36 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 06:09:55 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Fu", "Xingbo", ""], ["Gao", "Feng", ""], ["Wu", "Jiang", ""]]}, {"id": "2002.11485", "submitter": "Christopher A. Tucker", "authors": "Christopher A. Tucker", "title": "A machine-learning software-systems approach to capture social,\n  regulatory, governance, and climate problems", "comments": "7 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper will discuss the role of an artificially-intelligent computer\nsystem as critique-based, implicit-organizational, and an inherently necessary\ndevice, deployed in synchrony with parallel governmental policy, as a genuine\nmeans of capturing nation-population complexity in quantitative form, public\ncontentment in societal-cooperative economic groups, regulatory proposition,\nand governance-effectiveness domains. It will discuss a solution involving a\nwell-known algorithm and proffer an improved mechanism for\nknowledge-representation, thereby increasing range of utility, scope of\ninfluence (in terms of differentiating class sectors) and operational\nefficiency. It will finish with a discussion of these and other historical\nimplications.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 13:00:52 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Tucker", "Christopher A.", ""]]}, {"id": "2002.11503", "submitter": "Manuel Fernandez-Carmona", "authors": "Manuel Fernandez-Carmona, Nicola Bellotto", "title": "Wavelet-based Temporal Forecasting Models of Human Activities for\n  Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach for temporal modelling of long-term\nhuman activities based on wavelet transforms. The model is applied to binary\nsmart-home sensors to forecast their signals, which are used then as temporal\npriors to infer anomalies in office and Active & Assisted Living (AAL)\nscenarios. Such inference is performed by a new extension of Hybrid Markov\nLogic Networks (HMLNs) that merges different anomaly indicators, including\nactivity levels detected by sensors, expert rules and the new temporal models.\nThe latter in particular allow the inference system to discover deviations from\nlong-term activity patterns, which cannot by detected by simpler\nfrequency-based models. Two new publicly available datasets were collected\nusing several smart-sensors to evaluate the wavelet-based temporal models and\ntheir application to signal forecasting and anomaly detection. The experimental\nresults show the effectiveness of the proposed techniques and their successful\napplication to detect unexpected activities in office and AAL settings.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 14:08:46 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Fernandez-Carmona", "Manuel", ""], ["Bellotto", "Nicola", ""]]}, {"id": "2002.11505", "submitter": "Janne H. Korhonen", "authors": "Vitaly Aksenov and Dan Alistarh and Janne H. Korhonen", "title": "Relaxed Scheduling for Scalable Belief Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to leverage large-scale hardware parallelism has been one of the\nkey enablers of the accelerated recent progress in machine learning.\nConsequently, there has been considerable effort invested into developing\nefficient parallel variants of classic machine learning algorithms. However,\ndespite the wealth of knowledge on parallelization, some classic machine\nlearning algorithms often prove hard to parallelize efficiently while\nmaintaining convergence.\n  In this paper, we focus on efficient parallel algorithms for the key machine\nlearning task of inference on graphical models, in particular on the\nfundamental belief propagation algorithm. We address the challenge of\nefficiently parallelizing this classic paradigm by showing how to leverage\nscalable relaxed schedulers in this context. We present an extensive empirical\nstudy, showing that our approach outperforms previous parallel belief\npropagation implementations both in terms of scalability and in terms of\nwall-clock convergence time, on a range of practical applications.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 10:28:04 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 15:54:24 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Aksenov", "Vitaly", ""], ["Alistarh", "Dan", ""], ["Korhonen", "Janne H.", ""]]}, {"id": "2002.11507", "submitter": "Kashif Zia Dr.", "authors": "Kashif Zia", "title": "A Simulation Model Demonstrating the Impact of Social Aspects on Social\n  Internet of Things", "comments": "22 pages, 11 figures, 1 table. Presented in The 21st International\n  Conference on Information Integration and Web-based Applications & Services\n  (iiWAS2019), 2-4 December 2019, Munich Germany", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In addition to seamless connectivity and smartness, the objects in the\nInternet of Things (IoT) are expected to have the social capabilities -- these\nobjects are termed as ``social objects''. In this paper, an intuitive paradigm\nof social interactions between these objects are argued and modeled. The impact\nof social behavior on the interaction pattern of social objects is studied\ntaking Peer-to-Peer (P2P) resource sharing as an example application. The model\nproposed in this paper studies the implications of competitive vs. cooperative\nsocial paradigm, while peers attempt to attain the shared resources / services.\nThe simulation results divulge that the social capabilities of the peers impart\na significant increase in the quality of interactions between social objects.\nThrough an agent-based simulation study, it is proved that cooperative strategy\nis more efficient than competitive strategy. Moreover, cooperation with an\nunderpinning on real-life networking structure and mobility does not negatively\nimpact the efficiency of the system at all; rather it helps.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 07:18:39 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Zia", "Kashif", ""]]}, {"id": "2002.11508", "submitter": "Amar Isli", "authors": "Amar Isli", "title": "A binarized-domains arc-consistency algorithm for TCSPs: its\n  computational analysis and its use as a filtering procedure in solution\n  search algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  TCSPs (Temporal Constraint Satisfaction Problems), as defined in [Dechter et\nal., 1991], get rid of unary constraints by binarizing them after having added\nan \"origin of the world\" variable. In this work, we look at the constraints\nbetween the \"origin of the world\" variable and the other variables, as the\n(binarized) domains of these other variables. With this in mind, we define a\nnotion of arc-consistency for TCSPs, which we will refer to as\nbinarized-domains Arc-Consistency, or bdArc-Consistency for short. We provide\nan algorithm achieving bdArc-Consistency for a TCSP, which we will refer to as\nbdAC-3, for it is an adaptation of Mackworth's [1977] well-known\narc-consistency algorithm AC-3. We show that if a convex TCSP, referred to in\n[Dechter et al., 1991] as an STP (Simple Temporal Problem), is\nbdArc-Consistent, and its \"origin of the world\" variable disconnected from none\nof the other variables, its binarized domains are minimal. We provide two\npolynomial backtrack-free procedures: one for the task of getting, from a\nbdArc-Consistent STP, either that it is inconsistent or, in case of\nconsistency, a bdArc-Consistent STP refinement whose \"origin of the world\"\nvariable is disconnected from none of the other variables; the other for the\ntask of getting a solution from a bdArc-Consistent STP whose \"origin of the\nworld\" variable is disconnected from none of the other variables. We then show\nhow to use our results both in a general TCSP solver and in a TCSP-based job\nshop scheduler. From our work can be extracted a one-to-all all-to-one shortest\npaths algorithm of an IR-labelled directed graph. Finally, we show that an\nexisting adaptation to TCSPs of Mackworth's [1977] path-consistency algorithm\nPC-2 is not guaranteed to always terminate, and correct it.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 18:15:03 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 16:40:30 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Isli", "Amar", ""]]}, {"id": "2002.11522", "submitter": "Alexandru Cristian Mara", "authors": "Alexandru Mara, Jefrey Lijffijt and Tijl De Bie", "title": "Benchmarking Network Embedding Models for Link Prediction: Are We Making\n  Progress?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embedding methods map a network's nodes to vectors in an embedding\nspace, in such a way that these representations are useful for estimating some\nnotion of similarity or proximity between pairs of nodes in the network. The\nquality of these node representations is then showcased through results of\ndownstream prediction tasks. Commonly used benchmark tasks such as link\nprediction, however, present complex evaluation pipelines and an abundance of\ndesign choices. This, together with a lack of standardized evaluation setups\ncan obscure the real progress in the field. In this paper, we aim to shed light\non the state-of-the-art of network embedding methods for link prediction and\nshow, using a consistent evaluation pipeline, that only thin progress has been\nmade over the last years. The newly conducted benchmark that we present here,\nincluding 17 embedding methods, also shows that many approaches are\noutperformed even by simple heuristics. Finally, we argue that standardized\nevaluation tools can repair this situation and boost future progress in this\nfield.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 16:59:09 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 14:45:59 GMT"}, {"version": "v3", "created": "Wed, 1 Apr 2020 08:57:10 GMT"}, {"version": "v4", "created": "Mon, 25 May 2020 11:37:54 GMT"}, {"version": "v5", "created": "Thu, 3 Sep 2020 12:48:59 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Mara", "Alexandru", ""], ["Lijffijt", "Jefrey", ""], ["De Bie", "Tijl", ""]]}, {"id": "2002.11573", "submitter": "Junjia Liu", "authors": "Junjia Liu, Jiaying Shou, Zhuang Fu, Hangfei Zhou, Rongli Xie, Jun\n  Zhang, Jian Fei and Yanna Zhao", "title": "Efficient reinforcement learning control for continuum robots based on\n  Inexplicit Prior Knowledge", "comments": "11 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared to rigid robots that are generally studied in reinforcement\nlearning, the physical characteristics of some sophisticated robots such as\nsoft or continuum robots are higher complicated. Moreover, recent reinforcement\nlearning methods are data-inefficient and can not be directly deployed to the\nrobot without simulation. In this paper, we propose an efficient reinforcement\nlearning method based on inexplicit prior knowledge in response to such\nproblems. We first corroborate the method by simulation and employed directly\nin the real world. By using our method, we can achieve active visual tracking\nand distance maintenance of a tendon-driven robot which will be critical in\nminimally invasive procedures. Codes are available at\nhttps://github.com/Skylark0924/TendonTrack.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 15:47:11 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 17:02:25 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Liu", "Junjia", ""], ["Shou", "Jiaying", ""], ["Fu", "Zhuang", ""], ["Zhou", "Hangfei", ""], ["Xie", "Rongli", ""], ["Zhang", "Jun", ""], ["Fei", "Jian", ""], ["Zhao", "Yanna", ""]]}, {"id": "2002.11611", "submitter": "Eren Sezener", "authors": "Eren Sezener, Marcus Hutter, David Budden, Jianan Wang, Joel Veness", "title": "Online Learning in Contextual Bandits using Gated Linear Networks", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new and completely online contextual bandit algorithm called\nGated Linear Contextual Bandits (GLCB). This algorithm is based on Gated Linear\nNetworks (GLNs), a recently introduced deep learning architecture with\nproperties well-suited to the online setting. Leveraging data-dependent gating\nproperties of the GLN we are able to estimate prediction uncertainty with\neffectively zero algorithmic overhead. We empirically evaluate GLCB compared to\n9 state-of-the-art algorithms that leverage deep neural networks, on a standard\nbenchmark suite of discrete and continuous contextual bandit problems. GLCB\nobtains median first-place despite being the only online method, and we further\nsupport these results with a theoretical study of its convergence properties.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 11:50:43 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 09:38:19 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Sezener", "Eren", ""], ["Hutter", "Marcus", ""], ["Budden", "David", ""], ["Wang", "Jianan", ""], ["Veness", "Joel", ""]]}, {"id": "2002.11624", "submitter": "Byungsoo Kim", "authors": "Youngnam Lee, Dongmin Shin, HyunBin Loh, Jaemin Lee, Piljae Chae,\n  Junghyun Cho, Seoyon Park, Jinhwan Lee, Jineon Baek, Byungsoo Kim, Youngduck\n  Choi", "title": "Deep Attentive Study Session Dropout Prediction in Mobile Learning\n  Environment", "comments": "CSEDU 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Student dropout prediction provides an opportunity to improve student\nengagement, which maximizes the overall effectiveness of learning experiences.\nHowever, researches on student dropout were mainly conducted on school dropout\nor course dropout, and study session dropout in a mobile learning environment\nhas not been considered thoroughly. In this paper, we investigate the study\nsession dropout prediction problem in a mobile learning environment. First, we\ndefine the concept of the study session, study session dropout and study\nsession dropout prediction task in a mobile learning environment. Based on the\ndefinitions, we propose a novel Transformer based model for predicting study\nsession dropout, DAS: Deep Attentive Study Session Dropout Prediction in Mobile\nLearning Environment. DAS has an encoder-decoder structure which is composed of\nstacked multi-head attention and point-wise feed-forward networks. The deep\nattentive computations in DAS are capable of capturing complex relations among\ndynamic student interactions. To the best of our knowledge, this is the first\nattempt to investigate study session dropout in a mobile learning environment.\nEmpirical evaluations on a large-scale dataset show that DAS achieves the best\nperformance with a significant improvement in area under the receiver operating\ncharacteristic curve compared to baseline models.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 06:05:42 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 04:35:20 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 06:54:26 GMT"}, {"version": "v4", "created": "Fri, 14 Aug 2020 01:27:49 GMT"}, {"version": "v5", "created": "Tue, 2 Feb 2021 04:59:06 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Lee", "Youngnam", ""], ["Shin", "Dongmin", ""], ["Loh", "HyunBin", ""], ["Lee", "Jaemin", ""], ["Chae", "Piljae", ""], ["Cho", "Junghyun", ""], ["Park", "Seoyon", ""], ["Lee", "Jinhwan", ""], ["Baek", "Jineon", ""], ["Kim", "Byungsoo", ""], ["Choi", "Youngduck", ""]]}, {"id": "2002.11635", "submitter": "Manuel Kaspar", "authors": "Manuel Kaspar, Juan David Munoz Osorio, J\\\"urgen Bock", "title": "Sim2Real Transfer for Reinforcement Learning without Dynamics\n  Randomization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we show how to use the Operational Space Control framework (OSC)\nunder joint and cartesian constraints for reinforcement learning in cartesian\nspace. Our method is therefore able to learn fast and with adjustable degrees\nof freedom, while we are able to transfer policies without additional dynamics\nrandomizations on a KUKA LBR iiwa peg in-hole task. Before learning in\nsimulation starts, we perform a system identification for aligning the\nsimulation environment as far as possible with the dynamics of a real robot.\nAdding constraints to the OSC controller allows us to learn in a safe way on\nthe real robot or to learn a flexible, goal conditioned policy that can be\neasily transferred from simulation to the real robot.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 11:10:21 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Kaspar", "Manuel", ""], ["Osorio", "Juan David Munoz", ""], ["Bock", "J\u00fcrgen", ""]]}, {"id": "2002.11660", "submitter": "Nicolas Maudet", "authors": "Aur\\'elie Beynier and Nicolas Maudet and Simon Rey and Parham Shams", "title": "An Optimal Procedure to Check Pareto-Optimality in House Markets with\n  Single-Peaked Preferences", "comments": "Was initially part of our submission arXiv:1906.10250. We followed\n  recommendations to make a distinct contribution with this material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the problem of allocating one resource per agent with initial\nendowments (house markets) has seen a renewed interest: indeed, while in the\ndomain of strict preferences the Top Trading Cycle algorithm is known to be the\nonly procedure guaranteeing Pareto-optimality, individual rationality, and\nstrategy proofness. However, the situation differs in the single-peaked domain.\nIndeed, Bade presented the Crawler, an alternative procedure enjoying the same\nproperties, with the additional advantage of being implementable in obviously\ndominant strategies. In this paper we further investigate the Crawler and\npropose the Diver, a variant which checks optimally whether an allocation is\nPareto-optimal for single-peaked preferences, thus improving over known\ntechniques used for checking Pareto-optimality in more general domains. We also\nprove that the Diver is asymptotically optimal in terms of communication\ncomplexity.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 17:24:55 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Beynier", "Aur\u00e9lie", ""], ["Maudet", "Nicolas", ""], ["Rey", "Simon", ""], ["Shams", "Parham", ""]]}, {"id": "2002.11675", "submitter": "Fabrizio Albertetti", "authors": "Fabrizio Albertetti, Hatem Ghorbel", "title": "Workload Prediction of Business Processes -- An Approach Based on\n  Process Mining and Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in the interconnectedness and digitization of industrial\nmachines, known as Industry 4.0, pave the way for new analytical techniques.\nIndeed, the availability and the richness of production-related data enables\nnew data-driven methods. In this paper, we propose a process mining approach\naugmented with artificial intelligence that (1) reconstructs the historical\nworkload of a company and (2) predicts the workload using neural networks. Our\nmethod relies on logs, representing the history of business processes related\nto manufacturing. These logs are used to quantify the supply and demand and are\nfed into a recurrent neural network model to predict customer orders. The\ncorresponding activities to fulfill these orders are then sampled from history\nwith a replay mechanism, based on criteria such as trace frequency and\nactivities similarity. An evaluation and illustration of the method is\nperformed on the administrative processes of Heraeus Materials SA. The workload\nprediction on a one-year test set achieves an MAPE score of 19% for a one-week\nforecast. The case study suggests a reasonable accuracy and confirms that a\ngood understanding of the historical workload combined to articulated\npredictions are of great help for supporting management decisions and can\ndecrease costs with better resources planning on a medium-term level.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 08:19:23 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Albertetti", "Fabrizio", ""], ["Ghorbel", "Hatem", ""]]}, {"id": "2002.11684", "submitter": "Nilesh Tripuraneni", "authors": "Nilesh Tripuraneni, Chi Jin, Michael I. Jordan", "title": "Provable Meta-Learning of Linear Representations", "comments": "Lower bound slightly improved to include task diversity parameter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning, or learning-to-learn, seeks to design algorithms that can\nutilize previous experience to rapidly learn new skills or adapt to new\nenvironments. Representation learning -- a key tool for performing\nmeta-learning -- learns a data representation that can transfer knowledge\nacross multiple tasks, which is essential in regimes where data is scarce.\nDespite a recent surge of interest in the practice of meta-learning, the\ntheoretical underpinnings of meta-learning algorithms are lacking, especially\nin the context of learning transferable representations. In this paper, we\nfocus on the problem of multi-task linear regression -- in which multiple\nlinear regression models share a common, low-dimensional linear representation.\nHere, we provide provably fast, sample-efficient algorithms to address the dual\nchallenges of (1) learning a common set of features from multiple, related\ntasks, and (2) transferring this knowledge to new, unseen tasks. Both are\ncentral to the general problem of meta-learning. Finally, we complement these\nresults by providing information-theoretic lower bounds on the sample\ncomplexity of learning these linear features.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 18:21:34 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 20:40:37 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2020 22:20:33 GMT"}, {"version": "v4", "created": "Thu, 4 Feb 2021 22:15:30 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Tripuraneni", "Nilesh", ""], ["Jin", "Chi", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2002.11697", "submitter": "Tathagata Chakraborti", "authors": "Tathagata Chakraborti, Sarath Sreedharan, Subbarao Kambhampati", "title": "The Emerging Landscape of Explainable AI Planning and Decision Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide a comprehensive outline of the different threads of\nwork in Explainable AI Planning (XAIP) that has emerged as a focus area in the\nlast couple of years and contrast that with earlier efforts in the field in\nterms of techniques, target users, and delivery mechanisms. We hope that the\nsurvey will provide guidance to new researchers in automated planning towards\nthe role of explanations in the effective design of human-in-the-loop systems,\nas well as provide the established researcher with some perspective on the\nevolution of the exciting world of explainable planning.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 18:40:47 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Chakraborti", "Tathagata", ""], ["Sreedharan", "Sarath", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "2002.11708", "submitter": "Alexander Li", "authors": "Alexander C. Li, Lerrel Pinto, Pieter Abbeel", "title": "Generalized Hindsight for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key reasons for the high sample complexity in reinforcement\nlearning (RL) is the inability to transfer knowledge from one task to another.\nIn standard multi-task RL settings, low-reward data collected while trying to\nsolve one task provides little to no signal for solving that particular task\nand is hence effectively wasted. However, we argue that this data, which is\nuninformative for one task, is likely a rich source of information for other\ntasks. To leverage this insight and efficiently reuse data, we present\nGeneralized Hindsight: an approximate inverse reinforcement learning technique\nfor relabeling behaviors with the right tasks. Intuitively, given a behavior\ngenerated under one task, Generalized Hindsight returns a different task that\nthe behavior is better suited for. Then, the behavior is relabeled with this\nnew task before being used by an off-policy RL optimizer. Compared to standard\nrelabeling techniques, Generalized Hindsight provides a substantially more\nefficient reuse of samples, which we empirically demonstrate on a suite of\nmulti-task navigation and manipulation tasks. Videos and code can be accessed\nhere: https://sites.google.com/view/generalized-hindsight.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 18:57:05 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Li", "Alexander C.", ""], ["Pinto", "Lerrel", ""], ["Abbeel", "Pieter", ""]]}, {"id": "2002.11710", "submitter": "Joseph Tassone", "authors": "Joseph Tassone and Salimur Choudhury", "title": "Algorithms for Optimizing Fleet Scheduling of Air Ambulances", "comments": "14 pages, 4 figures, 16 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proper scheduling of air assets can be the difference between life and death\nfor a patient. While poor scheduling can be incredibly problematic during\nhospital transfers, it can be potentially catastrophic in the case of a\ndisaster. These issues are amplified in the case of an air emergency medical\nservice (EMS) system where populations are dispersed, and resources are\nlimited. There are exact methodologies existing for scheduling missions,\nalthough actual calculation times can be quite significant given a large enough\nproblem space. For this research, known coordinates of air and health\nfacilities were used in conjunction with a formulated integer linear\nprogramming model. This was the programmed through Gurobi so that performance\ncould be compared against custom algorithmic solutions. Two methods were\ndeveloped, one based on neighbourhood search and the other on Tabu search.\nWhile both were able to achieve results quite close to the Gurobi solution, the\nTabu search outperformed the former algorithm. Additionally, it was able to do\nso in a greatly decreased time, with Gurobi actually being unable to resolve to\noptimal in larger examples. Parallel variations were also developed with the\ncompute unified device architecture (CUDA), though did not improve the timing\ngiven the smaller sample size.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 21:49:46 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Tassone", "Joseph", ""], ["Choudhury", "Salimur", ""]]}, {"id": "2002.11714", "submitter": "Taniya Seth", "authors": "Taniya Seth and Pranab K. Muhuri", "title": "Type-2 Fuzzy Set based Hesitant Fuzzy Linguistic Term Sets for\n  Linguistic Decision Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approaches based on computing with words find good applicability in decision\nmaking systems. Predominantly finding their basis in type-1 fuzzy sets,\ncomputing with words approaches employ type-1 fuzzy sets as semantics of the\nlinguistic terms. However, type-2 fuzzy sets have been proven to be\nscientifically more appropriate to represent linguistic information in\npractical systems. They take into account both the intra-uncertainty as well as\nthe inter-uncertainty in cases where the linguistic information comes from a\ngroup of experts. Hence in this paper, we propose to introduce linguistic terms\nwhose semantics are denoted by interval type-2 fuzzy sets within the hesitant\nfuzzy linguistic term set framework, resulting in type-2 fuzzy sets based\nhesitant fuzzy linguistic term sets. We also introduce a novel method of\ncomputing type-2 fuzzy envelopes out of multiple interval type-2 fuzzy sets\nwith trapezoidal membership functions. Furthermore, the proposed framework with\ninterval type-2 fuzzy sets is applied on a supplier performance evaluation\nscenario. Since humans are predominantly involved in the entire process of\nsupply chain, their feedback is crucial while deciding many factors. Towards\nthe end of the paper, we compare our presented model with various existing\nmodels and demonstrate the advantages of the former.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 08:49:52 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Seth", "Taniya", ""], ["Muhuri", "Pranab K.", ""]]}, {"id": "2002.11717", "submitter": "Constance Thierry", "authors": "Constance Thierry (1), Jean-Christophe Dubois (1), Yolande Le Gall\n  (1), Arnaud Martin ((1) Universit\\'e de Rennes 1, France)", "title": "Modelisation de l'incertitude et de l'imprecision de donnees de\n  crowdsourcing : MONITOR", "comments": "in French. Extraction et Gestion des Connaissances (EGC), Jan 2020,\n  Bruxelles, Belgique", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsourcing is defined as the outsourcing of tasks to a crowd of\ncontributors. The crowd is very diverse on these platforms and includes\nmalicious contributors attracted by the remuneration of tasks and not\nconscientiously performing them. It is essential to identify these contributors\nin order to avoid considering their responses. As not all contributors have the\nsame aptitude for a task, it seems appropriate to give weight to their answers\naccording to their qualifications. This paper, published at the ICTAI 2019\nconference, proposes a method, MONITOR, for estimating the profile of the\ncontributor and aggregating the responses using belief function theory.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 14:58:11 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Thierry", "Constance", "", "Universit\u00e9 de Rennes 1, France"], ["Dubois", "Jean-Christophe", "", "Universit\u00e9 de Rennes 1, France"], ["Gall", "Yolande Le", "", "Universit\u00e9 de Rennes 1, France"], ["Martin", "Arnaud", ""]]}, {"id": "2002.11776", "submitter": "Tom Hanika", "authors": "Tom Hanika and Johannes Hirth", "title": "Knowledge Cores in Large Formal Contexts", "comments": "13 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge computation tasks are often infeasible for large data sets. This is\nin particular true when deriving knowledge bases in formal concept analysis\n(FCA). Hence, it is essential to come up with techniques to cope with this\nproblem. Many successful methods are based on random processes to reduce the\nsize of the investigated data set. This, however, makes them hardly\ninterpretable with respect to the discovered knowledge. Other approaches\nrestrict themselves to highly supported subsets and omit rare and interesting\npatterns. An essentially different approach is used in network science, called\n$k$-cores. These are able to reflect rare patterns if they are well connected\nin the data set. In this work, we study $k$-cores in the realm of FCA by\nexploiting the natural correspondence to bi-partite graphs. This structurally\nmotivated approach leads to a comprehensible extraction of knowledge cores from\nlarge formal contexts data sets.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 20:15:56 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Hanika", "Tom", ""], ["Hirth", "Johannes", ""]]}, {"id": "2002.11833", "submitter": "Jean Harb", "authors": "Jean Harb, Tom Schaul, Doina Precup and Pierre-Luc Bacon", "title": "Policy Evaluation Networks", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many reinforcement learning algorithms use value functions to guide the\nsearch for better policies. These methods estimate the value of a single policy\nwhile generalizing across many states. The core idea of this paper is to flip\nthis convention and estimate the value of many policies, for a single set of\nstates. This approach opens up the possibility of performing direct gradient\nascent in policy space without seeing any new data. The main challenge for this\napproach is finding a way to represent complex policies that facilitates\nlearning and generalization. To address this problem, we introduce a scalable,\ndifferentiable fingerprinting mechanism that retains essential policy\ninformation in a concise embedding. Our empirical results demonstrate that\ncombining these three elements (learned Policy Evaluation Network, policy\nfingerprints, gradient ascent) can produce policies that outperform those that\ngenerated the training data, in zero-shot manner.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 23:00:27 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Harb", "Jean", ""], ["Schaul", "Tom", ""], ["Precup", "Doina", ""], ["Bacon", "Pierre-Luc", ""]]}, {"id": "2002.11867", "submitter": "Zhiqian Chen", "authors": "Zhiqian Chen, Fanglan Chen, Lei Zhang, Taoran Ji, Kaiqun Fu, Liang\n  Zhao, Feng Chen, Lingfei Wu, Charu Aggarwal and Chang-Tien Lu", "title": "Bridging the Gap between Spatial and Spectral Domains: A Survey on Graph\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning's success has been widely recognized in a variety of machine\nlearning tasks, including image classification, audio recognition, and natural\nlanguage processing. As an extension of deep learning beyond these domains,\ngraph neural networks (GNNs) are designed to handle the non-Euclidean\ngraph-structure which is intractable to previous deep learning techniques.\nExisting GNNs are presented using various techniques, making direct comparison\nand cross-reference more complex. Although existing studies categorize GNNs\ninto spatial-based and spectral-based techniques, there hasn't been a thorough\nexamination of their relationship. To close this gap, this study presents a\nsingle framework that systematically incorporates most GNNs. We organize\nexisting GNNs into spatial and spectral domains, as well as expose the\nconnections within each domain. A review of spectral graph theory and\napproximation theory builds a strong relationship across the spatial and\nspectral domains in further investigation.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 01:15:10 GMT"}, {"version": "v2", "created": "Sun, 1 Mar 2020 01:53:31 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 12:31:13 GMT"}, {"version": "v4", "created": "Wed, 21 Jul 2021 15:54:42 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Chen", "Zhiqian", ""], ["Chen", "Fanglan", ""], ["Zhang", "Lei", ""], ["Ji", "Taoran", ""], ["Fu", "Kaiqun", ""], ["Zhao", "Liang", ""], ["Chen", "Feng", ""], ["Wu", "Lingfei", ""], ["Aggarwal", "Charu", ""], ["Lu", "Chang-Tien", ""]]}, {"id": "2002.11869", "submitter": "Anurag Sarkar", "authors": "Anurag Sarkar, Zhihan Yang, Seth Cooper", "title": "Controllable Level Blending between Games using Variational Autoencoders", "comments": "6 pages, 11 figures, Sixth Experimental AI in Games Workshop at AIIDE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work explored blending levels from existing games to create levels\nfor a new game that mixes properties of the original games. In this paper, we\nuse Variational Autoencoders (VAEs) for improving upon such techniques. VAEs\nare artificial neural networks that learn and use latent representations of\ndatasets to generate novel outputs. We train a VAE on level data from Super\nMario Bros. and Kid Icarus, enabling it to capture the latent space spanning\nboth games. We then use this space to generate level segments that combine\nproperties of levels from both games. Moreover, by applying evolutionary search\nin the latent space, we evolve level segments satisfying specific constraints.\nWe argue that these affordances make the VAE-based approach especially suitable\nfor co-creative level design and compare its performance with similar\ngenerative models like the GAN and the VAE-GAN.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 01:38:35 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Sarkar", "Anurag", ""], ["Yang", "Zhihan", ""], ["Cooper", "Seth", ""]]}, {"id": "2002.11874", "submitter": "Junjia Liu", "authors": "Junjia Liu, Huimin Zhang, Zhuang Fu and Yao Wang", "title": "Learning Scalable Multi-Agent Coordination by Spatial Differentiation\n  for Traffic Signal Control", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The intelligent control of the traffic signal is critical to the optimization\nof transportation systems. To achieve global optimal traffic efficiency in\nlarge-scale road networks, recent works have focused on coordination among\nintersections, which have shown promising results. However, existing studies\npaid more attention to observations sharing among intersections (both explicit\nand implicit) and did not care about the consequences after decisions. In this\npaper, we design a multiagent coordination framework based on Deep\nReinforcement Learning methods for traffic signal control, defined as\n{\\gamma}-Reward that includes both original {\\gamma}-Reward and\n{\\gamma}-Attention-Reward. Specifically, we propose the Spatial Differentiation\nmethod for coordination which uses the temporal-spatial information in the\nreplay buffer to amend the reward of each action. A concise theoretical\nanalysis that proves the proposed model can converge to Nash equilibrium is\ngiven. By extending the idea of Markov Chain to the dimension of space-time,\nthis truly decentralized coordination mechanism replaces the graph attention\nmethod and realizes the decoupling of the road network, which is more scalable\nand more in line with practice. The simulation results show that the proposed\nmodel remains a state-of-the-art performance even not use a centralized\nsetting. Code is available in https://github.com/Skylark0924/Gamma Reward.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 02:16:00 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 11:58:50 GMT"}, {"version": "v3", "created": "Wed, 16 Sep 2020 07:25:54 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Liu", "Junjia", ""], ["Zhang", "Huimin", ""], ["Fu", "Zhuang", ""], ["Wang", "Yao", ""]]}, {"id": "2002.11882", "submitter": "Thanh Thi Nguyen", "authors": "Ngoc Duy Nguyen, Thanh Thi Nguyen, Doug Creighton, Saeid Nahavandi", "title": "A Visual Communication Map for Multi-Agent Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.13433.62563", "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep reinforcement learning has been applied successfully to solve various\nreal-world problems and the number of its applications in the multi-agent\nsettings has been increasing. Multi-agent learning distinctly poses significant\nchallenges in the effort to allocate a concealed communication medium. Agents\nreceive thorough knowledge from the medium to determine subsequent actions in a\ndistributed nature. Apparently, the goal is to leverage the cooperation of\nmultiple agents to achieve a designated objective efficiently. Recent studies\ntypically combine a specialized neural network with reinforcement learning to\nenable communication between agents. This approach, however, limits the number\nof agents or necessitates the homogeneity of the system. In this paper, we have\nproposed a more scalable approach that not only deals with a great number of\nagents but also enables collaboration between dissimilar functional agents and\ncompatibly combined with any deep reinforcement learning methods. Specifically,\nwe create a global communication map to represent the status of each agent in\nthe system visually. The visual map and the environmental state are fed to a\nshared-parameter network to train multiple agents concurrently. Finally, we\nselect the Asynchronous Advantage Actor-Critic (A3C) algorithm to demonstrate\nour proposed scheme, namely Visual communication map for Multi-agent A3C\n(VMA3C). Simulation results show that the use of visual communication map\nimproves the performance of A3C regarding learning speed, reward achievement,\nand robustness in multi-agent problems.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 02:38:21 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 12:12:47 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Nguyen", "Ngoc Duy", ""], ["Nguyen", "Thanh Thi", ""], ["Creighton", "Doug", ""], ["Nahavandi", "Saeid", ""]]}, {"id": "2002.11883", "submitter": "Thanh Thi Nguyen", "authors": "Ngoc Duy Nguyen, Thanh Thi Nguyen, Hai Nguyen, Doug Creighton, Saeid\n  Nahavandi", "title": "Review, Analysis and Design of a Comprehensive Deep Reinforcement\n  Learning Framework", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.16789.06883", "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The integration of deep learning to reinforcement learning (RL) has enabled\nRL to perform efficiently in high-dimensional environments. Deep RL methods\nhave been applied to solve many complex real-world problems in recent years.\nHowever, development of a deep RL-based system is challenging because of\nvarious issues such as the selection of a suitable deep RL algorithm, its\nnetwork configuration, training time, training methods, and so on. This paper\nproposes a comprehensive software framework that not only plays a vital role in\ndesigning a connect-the-dots deep RL architecture but also provides a guideline\nto develop a realistic RL application in a short time span. We have designed\nand developed a deep RL-based software framework that strictly ensures\nflexibility, robustness, and scalability. By inheriting the proposed\narchitecture, software managers can foresee any challenges when designing a\ndeep RL-based system. As a result, they can expedite the design process and\nactively control every stage of software development, which is especially\ncritical in agile development environments. To enforce generalization, the\nproposed architecture does not depend on a specific RL algorithm, a network\nconfiguration, the number of agents, or the type of agents. Using our\nframework, software developers can develop and integrate new RL algorithms or\nnew types of agents, and can flexibly change network configuration or the\nnumber of agents.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 02:38:47 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 12:05:04 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Nguyen", "Ngoc Duy", ""], ["Nguyen", "Thanh Thi", ""], ["Nguyen", "Hai", ""], ["Creighton", "Doug", ""], ["Nahavandi", "Saeid", ""]]}, {"id": "2002.11895", "submitter": "EPTCS", "authors": "Pedro Quaresma (University of Coimbra, Portugal), Walther Neuper (Graz\n  University of Technology, Austria), Jo\\~ao Marcos (UFRN, Brazil)", "title": "Proceedings 8th International Workshop on Theorem Proving Components for\n  Educational Software", "comments": null, "journal-ref": "EPTCS 313, 2020", "doi": "10.4204/EPTCS.313", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This EPTCS volume contains the proceedings of the ThEdu'19 workshop, promoted\non August 25, 2019, as a satellite event of CADE-27, in Natal, Brazil.\nRepresenting the eighth installment of the ThEdu series, ThEdu'19 was a vibrant\nworkshop, with an invited talk by Sarah Winkler, four contributions, and the\nfirst edition of a Geometry Automated Provers Competition. After the workshop\nan open call for papers was issued and attracted seven submissions, six of\nwhich have been accepted by the reviewers, and collected in the present\npost-proceedings volume.\n  The ThEdu series pursues the smooth transition from an intuitive way of doing\nmathematics at secondary school to a more formal approach to the subject in\nSTEM education, while favoring software support for this transition by\nexploiting the power of theorem-proving technologies.\n  The volume editors hope that this collection of papers will further promote\nthe development of theorem-proving-based software, and that it will collaborate\non improving mutual understanding between computer mathematicians and\nstakeholders in education.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 03:10:08 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Quaresma", "Pedro", "", "University of Coimbra, Portugal"], ["Neuper", "Walther", "", "Graz\n  University of Technology, Austria"], ["Marcos", "Jo\u00e3o", "", "UFRN, Brazil"]]}, {"id": "2002.11909", "submitter": "Yi Chu", "authors": "Yi Chu, Chuan Luo, Holger H. Hoos, QIngwei Lin, Haihang You", "title": "Improving the Performance of Stochastic Local Search for Maximum Vertex\n  Weight Clique Problem Using Programming by Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The maximum vertex weight clique problem (MVWCP) is an important\ngeneralization of the maximum clique problem (MCP) that has a wide range of\nreal-world applications. In situations where rigorous guarantees regarding the\noptimality of solutions are not required, MVWCP is usually solved using\nstochastic local search (SLS) algorithms, which also define the state of the\nart for solving this problem. However, there is no single SLS algorithm which\ngives the best performance across all classes of MVWCP instances, and it is\nchallenging to effectively identify the most suitable algorithm for each class\nof MVWCP instances. In this work, we follow the paradigm of Programming by\nOptimization (PbO) to develop a new, flexible and highly parametric SLS\nframework for solving MVWCP, combining, for the first time, a broad range of\neffective heuristic mechanisms. By automatically configuring this PbO-MWC\nframework, we achieve substantial advances in the state-of-the-art in solving\nMVWCP over a broad range of prominent benchmarks, including two derived from\nreal-world applications in transplantation medicine (kidney exchange) and\nassessment of research excellence.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 04:22:19 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Chu", "Yi", ""], ["Luo", "Chuan", ""], ["Hoos", "Holger H.", ""], ["Lin", "QIngwei", ""], ["You", "Haihang", ""]]}, {"id": "2002.11952", "submitter": "Christian Wagner", "authors": "Philipp Leinen, Malte Esders, Kristof T. Sch\\\"utt, Christian Wagner,\n  Klaus-Robert M\\\"uller, F. Stefan Tautz", "title": "Autonomous robotic nanofabrication with reinforcement learning", "comments": "3 figures", "journal-ref": "Sci. Adv. 6, eabb6987 (2020)", "doi": "10.1126/sciadv.abb6987", "report-no": null, "categories": "cond-mat.mes-hall cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to handle single molecules as effectively as macroscopic\nbuilding-blocks would enable the construction of complex supramolecular\nstructures inaccessible to self-assembly. The fundamental challenges\nobstructing this goal are the uncontrolled variability and poor observability\nof atomic-scale conformations. Here, we present a strategy to work around both\nobstacles, and demonstrate autonomous robotic nanofabrication by manipulating\nsingle molecules. Our approach employs reinforcement learning (RL), which finds\nsolution strategies even in the face of large uncertainty and sparse feedback.\nWe demonstrate the potential of our RL approach by removing molecules\nautonomously with a scanning probe microscope from a supramolecular structure\n-- an exemplary task of subtractive manufacturing at the nanoscale. Our RL\nagent reaches an excellent performance, enabling us to automate a task which\npreviously had to be performed by a human. We anticipate that our work opens\nthe way towards autonomous agents for the robotic construction of functional\nsupramolecular structures with speed, precision and perseverance beyond our\ncurrent capabilities.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 07:37:20 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 12:48:43 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Leinen", "Philipp", ""], ["Esders", "Malte", ""], ["Sch\u00fctt", "Kristof T.", ""], ["Wagner", "Christian", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Tautz", "F. Stefan", ""]]}, {"id": "2002.12001", "submitter": "Saaduddin Mahmud", "authors": "Saaduddin Mahmud, Md. Mosaddek Khan, Moumita Choudhury, Long\n  Tran-Thanh and Nicholas R. Jennings", "title": "Learning Optimal Temperature Region for Solving Mixed Integer Functional\n  DCOPs", "comments": "Proceedings of the Twenty-Ninth International Joint Conference on\n  Artificial Intelligence Main track. Pages 268-275", "journal-ref": null, "doi": "10.24963/ijcai.2020/38", "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Constraint Optimization Problems (DCOPs) are an important\nframework for modeling coordinated decision-making problems in multi-agent\nsystems with a set of discrete variables. Later works have extended DCOPs to\nmodel problems with a set of continuous variables, named Functional DCOPs\n(F-DCOPs). In this paper, we combine both of these frameworks into the Mixed\nInteger Functional DCOP (MIF-DCOP) framework that can deal with problems\nregardless of their variables' type. We then propose a novel algorithm $-$\nDistributed Parallel Simulated Annealing (DPSA), where agents cooperatively\nlearn the optimal parameter configuration for the algorithm while also solving\nthe given problem using the learned knowledge. Finally, we empirically evaluate\nour approach in DCOP, F-DCOP, and MIF-DCOP settings and show that DPSA produces\nsolutions of significantly better quality than the state-of-the-art non-exact\nalgorithms in their corresponding settings.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 09:46:40 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 06:17:37 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Mahmud", "Saaduddin", ""], ["Khan", "Md. Mosaddek", ""], ["Choudhury", "Moumita", ""], ["Tran-Thanh", "Long", ""], ["Jennings", "Nicholas R.", ""]]}, {"id": "2002.12086", "submitter": "Jiri Vahala", "authors": "Tomas Brazdil, Krishnendu Chatterjee, Petr Novotny, Jiri Vahala", "title": "Reinforcement Learning of Risk-Constrained Policies in Markov Decision\n  Processes", "comments": "Published on AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov decision processes (MDPs) are the defacto frame-work for sequential\ndecision making in the presence ofstochastic uncertainty. A classical\noptimization criterion forMDPs is to maximize the expected discounted-sum\npay-off, which ignores low probability catastrophic events withhighly negative\nimpact on the system. On the other hand,risk-averse policies require the\nprobability of undesirableevents to be below a given threshold, but they do not\naccountfor optimization of the expected payoff. We consider MDPswith\ndiscounted-sum payoff with failure states which repre-sent catastrophic\noutcomes. The objective of risk-constrainedplanning is to maximize the expected\ndiscounted-sum payoffamong risk-averse policies that ensure the probability to\nen-counter a failure state is below a desired threshold. Our maincontribution\nis an efficient risk-constrained planning algo-rithm that combines UCT-like\nsearch with a predictor learnedthrough interaction with the MDP (in the style\nof AlphaZero)and with a risk-constrained action selection via linear\npro-gramming. We demonstrate the effectiveness of our approachwith experiments\non classical MDPs from the literature, in-cluding benchmarks with an order of\n10^6 states.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 13:36:36 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Brazdil", "Tomas", ""], ["Chatterjee", "Krishnendu", ""], ["Novotny", "Petr", ""], ["Vahala", "Jiri", ""]]}, {"id": "2002.12133", "submitter": "Aritz D. Martinez", "authors": "Aritz D. Martinez, Eneko Osaba, Javier Del Ser and Francisco Herrera", "title": "Simultaneously Evolving Deep Reinforcement Learning Models using\n  Multifactorial Optimization", "comments": "8 pages, 5 figures, submitted to IEEE Conference on Evolutionary\n  Computation 2020 (IEEE CEC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Multifactorial Optimization (MFO) has gained a notable\nmomentum in the research community. MFO is known for its inherent capability to\nefficiently address multiple optimization tasks at the same time, while\ntransferring information among such tasks to improve their convergence speed.\nOn the other hand, the quantum leap made by Deep Q Learning (DQL) in the\nMachine Learning field has allowed facing Reinforcement Learning (RL) problems\nof unprecedented complexity. Unfortunately, complex DQL models usually find it\ndifficult to converge to optimal policies due to the lack of exploration or\nsparse rewards. In order to overcome these drawbacks, pre-trained models are\nwidely harnessed via Transfer Learning, extrapolating knowledge acquired in a\nsource task to the target task. Besides, meta-heuristic optimization has been\nshown to reduce the lack of exploration of DQL models. This work proposes a MFO\nframework capable of simultaneously evolving several DQL models towards solving\ninterrelated RL tasks. Specifically, our proposed framework blends together the\nbenefits of meta-heuristic optimization, Transfer Learning and DQL to automate\nthe process of knowledge transfer and policy learning of distributed RL agents.\nA thorough experimentation is presented and discussed so as to assess the\nperformance of the framework, its comparison to the traditional methodology for\nTransfer Learning in terms of convergence, speed and policy quality , and the\nintertask relationships found and exploited over the search process.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 10:36:57 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 10:47:41 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Martinez", "Aritz D.", ""], ["Osaba", "Eneko", ""], ["Del Ser", "Javier", ""], ["Herrera", "Francisco", ""]]}, {"id": "2002.12156", "submitter": "Mohammadhosein Hasanbeig", "authors": "Mohammadhosein Hasanbeig, Alessandro Abate, Daniel Kroening", "title": "Cautious Reinforcement Learning with Logical Constraints", "comments": "Accepted to AAMAS 2020. arXiv admin note: text overlap with\n  arXiv:1902.00778", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the concept of an adaptive safe padding that forces\nReinforcement Learning (RL) to synthesise optimal control policies while\nensuring safety during the learning process. Policies are synthesised to\nsatisfy a goal, expressed as a temporal logic formula, with maximal\nprobability. Enforcing the RL agent to stay safe during learning might limit\nthe exploration, however we show that the proposed architecture is able to\nautomatically handle the trade-off between efficient progress in exploration\n(towards goal satisfaction) and ensuring safety. Theoretical guarantees are\navailable on the optimality of the synthesised policies and on the convergence\nof the learning algorithm. Experimental results are provided to showcase the\nperformance of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 00:01:08 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 10:26:21 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Hasanbeig", "Mohammadhosein", ""], ["Abate", "Alessandro", ""], ["Kroening", "Daniel", ""]]}, {"id": "2002.12174", "submitter": "Bei Peng", "authors": "Tabish Rashid, Bei Peng, Wendelin B\\\"ohmer, Shimon Whiteson", "title": "Optimistic Exploration even with a Pessimistic Initialisation", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimistic initialisation is an effective strategy for efficient exploration\nin reinforcement learning (RL). In the tabular case, all provably efficient\nmodel-free algorithms rely on it. However, model-free deep RL algorithms do not\nuse optimistic initialisation despite taking inspiration from these provably\nefficient tabular algorithms. In particular, in scenarios with only positive\nrewards, Q-values are initialised at their lowest possible values due to\ncommonly used network initialisation schemes, a pessimistic initialisation.\nMerely initialising the network to output optimistic Q-values is not enough,\nsince we cannot ensure that they remain optimistic for novel state-action\npairs, which is crucial for exploration. We propose a simple count-based\naugmentation to pessimistically initialised Q-values that separates the source\nof optimism from the neural network. We show that this scheme is provably\nefficient in the tabular setting and extend it to the deep RL setting. Our\nalgorithm, Optimistic Pessimistically Initialised Q-Learning (OPIQ), augments\nthe Q-value estimates of a DQN-based agent with count-derived bonuses to ensure\noptimism during both action selection and bootstrapping. We show that OPIQ\noutperforms non-optimistic DQN variants that utilise a pseudocount-based\nintrinsic motivation in hard exploration tasks, and that it predicts optimistic\nestimates for novel state-action pairs.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 17:15:53 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Rashid", "Tabish", ""], ["Peng", "Bei", ""], ["B\u00f6hmer", "Wendelin", ""], ["Whiteson", "Shimon", ""]]}, {"id": "2002.12196", "submitter": "Aniruddha Uttam Tammewar", "authors": "Aniruddha Tammewar, Alessandra Cervone, Eva-Maria Messner, Giuseppe\n  Riccardi", "title": "Annotation of Emotion Carriers in Personal Narratives", "comments": "published in LREC 2020\n  http://www.lrec-conf.org/proceedings/lrec2020/pdf/2020.lrec-1.188.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in the problem of understanding personal narratives (PN) -\nspoken or written - recollections of facts, events, and thoughts. In PN,\nemotion carriers are the speech or text segments that best explain the\nemotional state of the user. Such segments may include entities, verb or noun\nphrases. Advanced automatic understanding of PNs requires not only the\nprediction of the user emotional state but also to identify which events (e.g.\n\"the loss of relative\" or \"the visit of grandpa\") or people ( e.g. \"the old\ngroup of high school mates\") carry the emotion manifested during the personal\nrecollection. This work proposes and evaluates an annotation model for\nidentifying emotion carriers in spoken personal narratives. Compared to other\ntext genres such as news and microblogs, spoken PNs are particularly\nchallenging because a narrative is usually unstructured, involving multiple\nsub-events and characters as well as thoughts and associated emotions perceived\nby the narrator. In this work, we experiment with annotating emotion carriers\nfrom speech transcriptions in the Ulm State-of-Mind in Speech (USoMS) corpus, a\ndataset of German PNs. We believe this resource could be used for experiments\nin the automatic extraction of emotion carriers from PN, a task that could\nprovide further advancements in narrative understanding.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 15:42:39 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 10:11:09 GMT"}, {"version": "v3", "created": "Fri, 15 May 2020 19:52:35 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Tammewar", "Aniruddha", ""], ["Cervone", "Alessandra", ""], ["Messner", "Eva-Maria", ""], ["Riccardi", "Giuseppe", ""]]}, {"id": "2002.12261", "submitter": "Min Hun Lee", "authors": "Min Hun Lee, Daniel P. Siewiorek, Asim Smailagic, Alexandre\n  Bernardino, and Sergi Berm\\'udez i Badia", "title": "Opportunities of a Machine Learning-based Decision Support System for\n  Stroke Rehabilitation Assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rehabilitation assessment is critical to determine an adequate intervention\nfor a patient. However, the current practices of assessment mainly rely on\ntherapist's experience, and assessment is infrequently executed due to the\nlimited availability of a therapist. In this paper, we identified the needs of\ntherapists to assess patient's functional abilities (e.g. alternative\nperspective on assessment with quantitative information on patient's exercise\nmotions). As a result, we developed an intelligent decision support system that\ncan identify salient features of assessment using reinforcement learning to\nassess the quality of motion and summarize patient specific analysis. We\nevaluated this system with seven therapists using the dataset from 15 patient\nperforming three exercises. The evaluation demonstrates that our system is\npreferred over a traditional system without analysis while presenting more\nuseful information and significantly increasing the agreement over therapists'\nevaluation from 0.6600 to 0.7108 F1-scores ($p <0.05$). We discuss the\nimportance of presenting contextually relevant and salient information and\nadaptation to develop a human and machine collaborative decision making system.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 17:04:07 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 17:22:42 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Lee", "Min Hun", ""], ["Siewiorek", "Daniel P.", ""], ["Smailagic", "Asim", ""], ["Bernardino", "Alexandre", ""], ["Badia", "Sergi Berm\u00fadez i", ""]]}, {"id": "2002.12278", "submitter": "Arnab Sharma", "authors": "Arnab Sharma and Heike Wehrheim", "title": "Testing Monotonicity of Machine Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, machine learning (ML) models are increasingly applied in decision\nmaking. This induces an urgent need for quality assurance of ML models with\nrespect to (often domain-dependent) requirements. Monotonicity is one such\nrequirement. It specifies a software as 'learned' by an ML algorithm to give an\nincreasing prediction with the increase of some attribute values. While there\nexist multiple ML algorithms for ensuring monotonicity of the generated model,\napproaches for checking monotonicity, in particular of black-box models, are\nlargely lacking. In this work, we propose verification-based testing of\nmonotonicity, i.e., the formal computation of test inputs on a white-box model\nvia verification technology, and the automatic inference of this approximating\nwhite-box model from the black-box model under test. On the white-box model,\nthe space of test inputs can be systematically explored by a directed\ncomputation of test cases. The empirical evaluation on 90 black-box models\nshows verification-based testing can outperform adaptive random testing as well\nas property-based techniques with respect to effectiveness and efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 17:38:06 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Sharma", "Arnab", ""], ["Wehrheim", "Heike", ""]]}, {"id": "2002.12292", "submitter": "Roberta Raileanu", "authors": "Roberta Raileanu and Tim Rockt\\\"aschel", "title": "RIDE: Rewarding Impact-Driven Exploration for Procedurally-Generated\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration in sparse reward environments remains one of the key challenges\nof model-free reinforcement learning. Instead of solely relying on extrinsic\nrewards provided by the environment, many state-of-the-art methods use\nintrinsic rewards to encourage exploration. However, we show that existing\nmethods fall short in procedurally-generated environments where an agent is\nunlikely to visit a state more than once. We propose a novel type of intrinsic\nreward which encourages the agent to take actions that lead to significant\nchanges in its learned state representation. We evaluate our method on multiple\nchallenging procedurally-generated tasks in MiniGrid, as well as on tasks with\nhigh-dimensional observations used in prior work. Our experiments demonstrate\nthat this approach is more sample efficient than existing exploration methods,\nparticularly for procedurally-generated MiniGrid environments. Furthermore, we\nanalyze the learned behavior as well as the intrinsic reward received by our\nagent. In contrast to previous approaches, our intrinsic reward does not\ndiminish during the course of training and it rewards the agent substantially\nmore for interacting with objects that it can control.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 18:03:16 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 16:12:58 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Raileanu", "Roberta", ""], ["Rockt\u00e4schel", "Tim", ""]]}, {"id": "2002.12336", "submitter": "Thanard Kurutach", "authors": "Kara Liu, Thanard Kurutach, Christine Tung, Pieter Abbeel, Aviv Tamar", "title": "Hallucinative Topological Memory for Zero-Shot Visual Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In visual planning (VP), an agent learns to plan goal-directed behavior from\nobservations of a dynamical system obtained offline, e.g., images obtained from\nself-supervised robot interaction. Most previous works on VP approached the\nproblem by planning in a learned latent space, resulting in low-quality visual\nplans, and difficult training algorithms. Here, instead, we propose a simple VP\nmethod that plans directly in image space and displays competitive performance.\nWe build on the semi-parametric topological memory (SPTM) method: image samples\nare treated as nodes in a graph, the graph connectivity is learned from image\nsequence data, and planning can be performed using conventional graph search\nmethods. We propose two modifications on SPTM. First, we train an energy-based\ngraph connectivity function using contrastive predictive coding that admits\nstable training. Second, to allow zero-shot planning in new domains, we learn a\nconditional VAE model that generates images given a context of the domain, and\nuse these hallucinated samples for building the connectivity graph and\nplanning. We show that this simple approach significantly outperform the\nstate-of-the-art VP methods, in terms of both plan interpretability and success\nrate when using the plan to guide a trajectory-following controller.\nInterestingly, our method can pick up non-trivial visual properties of objects,\nsuch as their geometry, and account for it in the plans.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 18:54:42 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Liu", "Kara", ""], ["Kurutach", "Thanard", ""], ["Tung", "Christine", ""], ["Abbeel", "Pieter", ""], ["Tamar", "Aviv", ""]]}, {"id": "2002.12361", "submitter": "Tom Jurgenson", "authors": "Tom Jurgenson, Or Avner, Edward Groshev, Aviv Tamar", "title": "Sub-Goal Trees -- a Framework for Goal-Based Reinforcement Learning", "comments": "ICML2020, 8 pages, 10 figures. arXiv admin note: text overlap with\n  arXiv:1906.05329", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many AI problems, in robotics and other domains, are goal-based, essentially\nseeking trajectories leading to various goal states. Reinforcement learning\n(RL), building on Bellman's optimality equation, naturally optimizes for a\nsingle goal, yet can be made multi-goal by augmenting the state with the goal.\nInstead, we propose a new RL framework, derived from a dynamic programming\nequation for the all pairs shortest path (APSP) problem, which naturally solves\nmulti-goal queries. We show that this approach has computational benefits for\nboth standard and approximate dynamic programming. Interestingly, our\nformulation prescribes a novel protocol for computing a trajectory: instead of\npredicting the next state given its predecessor, as in standard RL, a\ngoal-conditioned trajectory is constructed by first predicting an intermediate\nstate between start and goal, partitioning the trajectory into two. Then,\nrecursively, predicting intermediate points on each sub-segment, until a\ncomplete trajectory is obtained. We call this trajectory structure a sub-goal\ntree. Building on it, we additionally extend the policy gradient methodology to\nrecursively predict sub-goals, resulting in novel goal-based algorithms.\nFinally, we apply our method to neural motion planning, where we demonstrate\nsignificant improvements compared to standard RL on navigating a 7-DoF robot\narm between obstacles.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 12:32:13 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 15:42:22 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Jurgenson", "Tom", ""], ["Avner", "Or", ""], ["Groshev", "Edward", ""], ["Tamar", "Aviv", ""]]}, {"id": "2002.12399", "submitter": "Jayden Ooi", "authors": "Andy Su, Jayden Ooi, Tyler Lu, Dale Schuurmans, Craig Boutilier", "title": "ConQUR: Mitigating Delusional Bias in Deep Q-learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Delusional bias is a fundamental source of error in approximate Q-learning.\nTo date, the only techniques that explicitly address delusion require\ncomprehensive search using tabular value estimates. In this paper, we develop\nefficient methods to mitigate delusional bias by training Q-approximators with\nlabels that are \"consistent\" with the underlying greedy policy class. We\nintroduce a simple penalization scheme that encourages Q-labels used across\ntraining batches to remain (jointly) consistent with the expressible policy\nclass. We also propose a search framework that allows multiple Q-approximators\nto be generated and tracked, thus mitigating the effect of premature (implicit)\npolicy commitments. Experimental results demonstrate that these methods can\nimprove the performance of Q-learning in a variety of Atari games, sometimes\ndramatically.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 19:22:51 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Su", "Andy", ""], ["Ooi", "Jayden", ""], ["Lu", "Tyler", ""], ["Schuurmans", "Dale", ""], ["Boutilier", "Craig", ""]]}, {"id": "2002.12411", "submitter": "Ali Ayub", "authors": "Ali Ayub and Alan Wagner", "title": "Cognitively-Inspired Model for Incremental Learning Using a Few Examples", "comments": "Added link to the code in the paper", "journal-ref": "The IEEE/CVF Conference on Computer Vision and Pattern Recognition\n  (CVPR) Workshops, 2020", "doi": "10.1109/CVPRW50498.2020.00119", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incremental learning attempts to develop a classifier which learns\ncontinuously from a stream of data segregated into different classes. Deep\nlearning approaches suffer from catastrophic forgetting when learning classes\nincrementally, while most incremental learning approaches require a large\namount of training data per class. We examine the problem of incremental\nlearning using only a few training examples, referred to as Few-Shot\nIncremental Learning (FSIL). To solve this problem, we propose a novel approach\ninspired by the concept learning model of the hippocampus and the neocortex\nthat represents each image class as centroids and does not suffer from\ncatastrophic forgetting. We evaluate our approach on three class-incremental\nlearning benchmarks: Caltech-101, CUBS-200-2011 and CIFAR-100 for incremental\nand few-shot incremental learning and show that our approach achieves\nstate-of-the-art results in terms of classification accuracy over all learned\nclasses.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 19:52:42 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 05:09:37 GMT"}, {"version": "v3", "created": "Thu, 30 Jul 2020 06:55:06 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Ayub", "Ali", ""], ["Wagner", "Alan", ""]]}, {"id": "2002.12427", "submitter": "Amit Sarker", "authors": "Amit Sarker, Abdullahil Baki Arif, Moumita Choudhury, Md. Mosaddek\n  Khan", "title": "C-CoCoA: A Continuous Cooperative Constraint Approximation Algorithm to\n  Solve Functional DCOPs", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Constraint Optimization Problems (DCOPs) have been widely used to\ncoordinate interactions (i.e. constraints) in cooperative multi-agent systems.\nThe traditional DCOP model assumes that variables owned by the agents can take\nonly discrete values and constraints' cost functions are defined for every\npossible value assignment of a set of variables. While this formulation is\noften reasonable, there are many applications where the variables are\ncontinuous decision variables and constraints are in functional form. To\novercome this limitation, Functional DCOP (F-DCOP) model is proposed that is\nable to model problems with continuous variables. The existing F-DCOPs\nalgorithms experience huge computation and communication overhead. This paper\napplies continuous non-linear optimization methods on Cooperative Constraint\nApproximation (CoCoA) algorithm. We empirically show that our algorithm is able\nto provide high-quality solutions at the expense of smaller communication cost\nand execution time compared to the existing F-DCOP algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 20:44:25 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Sarker", "Amit", ""], ["Arif", "Abdullahil Baki", ""], ["Choudhury", "Moumita", ""], ["Khan", "Md. Mosaddek", ""]]}, {"id": "2002.12441", "submitter": "Heytem Zitoun", "authors": "Heytem Zitoun, Claude Michel, Laurent Michel, Michel Rueher", "title": "An efficient constraint based framework forhandling floating point SMT\n  problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the 2019 version of \\us{}, a novel Constraint\nProgramming framework for floating point verification problems expressed with\nthe SMT language of SMTLIB. SMT solvers decompose their task by delegating to\nspecific theories (e.g., floating point, bit vectors, arrays, ...) the task to\nreason about combinatorial or otherwise complex constraints for which the SAT\nencoding would be cumbersome or ineffective. This decomposition and encoding\nprocesses lead to the obfuscation of the high-level constraints and a loss of\ninformation on the structure of the combinatorial model. In \\us{}, constraints\nover the floats are first class objects, and the purpose is to expose and\nexploit structures of floating point domains to enhance the search process. A\nsymbolic phase rewrites each SMTLIB instance to elementary constraints, and\neliminates auxiliary variables whose presence is counterproductive. A\ndiversification technique within the search steers it away from costly\nenumerations in unproductive areas of the search space. The empirical\nevaluation demonstrates that the 2019 version of \\us{} is competitive on\ncomputationally challenging floating point benchmarks that induce significant\nsearch efforts even for other CP solvers. It highlights that the ability to\nharness both inference and search is critical. Indeed, it yields a factor 3\nimprovement over Colibri and is up to 10 times faster than SMT solvers. The\nevaluation was conducted over 214 benchmarks (The Griggio suite) which is a\nstandard within SMTLIB.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 21:11:22 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Zitoun", "Heytem", ""], ["Michel", "Claude", ""], ["Michel", "Laurent", ""], ["Rueher", "Michel", ""]]}, {"id": "2002.12445", "submitter": "Sebastian Sardina", "authors": "Daniel Ciolek, Nicol\\'as D'Ippolito, Alberto Pozanco, Sebastian\n  Sardina", "title": "Multi-tier Automated Planning for Adaptive Behavior (Extended Version)", "comments": "Shorter version in ICAPS'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A planning domain, as any model, is never complete and inevitably makes\nassumptions on the environment's dynamic. By allowing the specification of just\none domain model, the knowledge engineer is only able to make one set of\nassumptions, and to specify a single objective-goal. Borrowing from work in\nSoftware Engineering, we propose a multi-tier framework for planning that\nallows the specification of different sets of assumptions, and of different\ncorresponding objectives. The framework aims to support the synthesis of\nadaptive behavior so as to mitigate the intrinsic risk in any planning modeling\ntask. After defining the multi-tier planning task and its solution concept, we\nshow how to solve problem instances by a succinct compilation to a form of\nnon-deterministic planning. In doing so, our technique justifies the\napplicability of planning with both fair and unfair actions, and the need for\nmore efforts in developing planning systems supporting dual fairness\nassumptions.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 21:16:01 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Ciolek", "Daniel", ""], ["D'Ippolito", "Nicol\u00e1s", ""], ["Pozanco", "Alberto", ""], ["Sardina", "Sebastian", ""]]}, {"id": "2002.12447", "submitter": "Heytem Zitoun", "authors": "Heytem Zitoun, Claude Michel, Laurent Michel, Michel Rueher", "title": "Bringing freedom in variable choice when searching counter-examples in\n  floating point programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program verification techniques typically focus on finding counter-examples\nthat violate properties of a program. Constraint programming offers a\nconvenient way to verify programs by modeling their state transformations and\nspecifying searches that seek counter-examples. Floating-point computations\npresent additional challenges for verification given the semantic subtleties of\nfloating point arithmetic. % This paper focuses on search strategies for CSPs\nusing floating point numbers constraint systems and dedicated to program\nverification. It introduces a new search heuristic based on the global number\nof occurrences that outperforms state-of-the-art strategies. More importantly,\nit demonstrates that a new technique that only branches on input variables of\nthe verified program improve performance. It composes with a diversification\ntechnique that prevents the selection of the same variable within a fixed\nhorizon further improving performances and reduces disparities between various\nvariable choice heuristics. The result is a robust methodology that can tailor\nthe search strategy according to the sought properties of the counter example.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 21:20:38 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Zitoun", "Heytem", ""], ["Michel", "Claude", ""], ["Michel", "Laurent", ""], ["Rueher", "Michel", ""]]}, {"id": "2002.12450", "submitter": "Juliana Ferreira J", "authors": "Juliana Jansen Ferreira and Mateus de Souza Monteiro", "title": "Do ML Experts Discuss Explainability for AI Systems? A discussion case\n  in the industry for a domain-specific solution", "comments": "7 pages, IUI workshop on Explainable Smart Systems and Algorithmic\n  Transparency in Emerging Technologies (ExSS-ATEC'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The application of Artificial Intelligence (AI) tools in different domains\nare becoming mandatory for all companies wishing to excel in their industries.\nOne major challenge for a successful application of AI is to combine the\nmachine learning (ML) expertise with the domain knowledge to have the best\nresults applying AI tools. Domain specialists have an understanding of the data\nand how it can impact their decisions. ML experts have the ability to use\nAI-based tools dealing with large amounts of data and generating insights for\ndomain experts. But without a deep understanding of the data, ML experts are\nnot able to tune their models to get optimal results for a specific domain.\nTherefore, domain experts are key users for ML tools and the explainability of\nthose AI tools become an essential feature in that context. There are a lot of\nefforts to research AI explainability for different contexts, users and goals.\nIn this position paper, we discuss interesting findings about how ML experts\ncan express concerns about AI explainability while defining features of an ML\ntool to be developed for a specific domain. We analyze data from two brainstorm\nsessions done to discuss the functionalities of an ML tool to support\ngeoscientists (domain experts) on analyzing seismic data (domain-specific data)\nwith ML resources.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 21:23:27 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Ferreira", "Juliana Jansen", ""], ["Monteiro", "Mateus de Souza", ""]]}, {"id": "2002.12466", "submitter": "Josiah Putman", "authors": "Josiah Putman, Lisa Oh, Luyang Zhao, Evan Honnold, Galen Brown, Weifu\n  Wang, Devin Balkcom", "title": "Piecewise linear regressions for approximating distance metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a data structure that summarizes distances between\nconfigurations across a robot configuration space, using a binary space\npartition whose cells contain parameters used for a locally linear\napproximation of the distance function. Querying the data structure is\nextremely fast, particularly when compared to the graph search required for\nquerying Probabilistic Roadmaps, and memory requirements are promising. The\npaper explores the use of the data structure constructed for a single robot to\nprovide a heuristic for challenging multi-robot motion planning problems.\nPotential applications also include the use of remote computation to analyze\nthe space of robot motions, which then might be transmitted on-demand to robots\nwith fewer computational resources.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 22:23:58 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Putman", "Josiah", ""], ["Oh", "Lisa", ""], ["Zhao", "Luyang", ""], ["Honnold", "Evan", ""], ["Brown", "Galen", ""], ["Wang", "Weifu", ""], ["Balkcom", "Devin", ""]]}, {"id": "2002.12475", "submitter": "Alec Koppel", "authors": "Junyu Zhang, Amrit Singh Bedi, Mengdi Wang, Alec Koppel", "title": "Cautious Reinforcement Learning via Distributional Risk in the Dual\n  Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the estimation of risk-sensitive policies in reinforcement learning\nproblems defined by a Markov Decision Process (MDPs) whose state and action\nspaces are countably finite. Prior efforts are predominately afflicted by\ncomputational challenges associated with the fact that risk-sensitive MDPs are\ntime-inconsistent. To ameliorate this issue, we propose a new definition of\nrisk, which we call caution, as a penalty function added to the dual objective\nof the linear programming (LP) formulation of reinforcement learning. The\ncaution measures the distributional risk of a policy, which is a function of\nthe policy's long-term state occupancy distribution. To solve this problem in\nan online model-free manner, we propose a stochastic variant of primal-dual\nmethod that uses Kullback-Lieber (KL) divergence as its proximal term. We\nestablish that the number of iterations/samples required to attain\napproximately optimal solutions of this scheme matches tight dependencies on\nthe cardinality of the state and action spaces, but differs in its dependence\non the infinity norm of the gradient of the risk measure. Experiments\ndemonstrate the merits of this approach for improving the reliability of reward\naccumulation without additional computational burdens.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 23:18:04 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Zhang", "Junyu", ""], ["Bedi", "Amrit Singh", ""], ["Wang", "Mengdi", ""], ["Koppel", "Alec", ""]]}, {"id": "2002.12499", "submitter": "Dibya Ghosh", "authors": "William Fedus, Dibya Ghosh, John D. Martin, Marc G. Bellemare, Yoshua\n  Bengio, Hugo Larochelle", "title": "On Catastrophic Interference in Atari 2600 Games", "comments": "First two authors contributed equally. Code available to reproduce\n  experiments at\n  https://github.com/google-research/google-research/tree/master/memento", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free deep reinforcement learning is sample inefficient. One hypothesis\n-- speculated, but not confirmed -- is that catastrophic interference within an\nenvironment inhibits learning. We test this hypothesis through a large-scale\nempirical study in the Arcade Learning Environment (ALE) and, indeed, find\nsupporting evidence. We show that interference causes performance to plateau;\nthe network cannot train on segments beyond the plateau without degrading the\npolicy used to reach there. By synthetically controlling for interference, we\ndemonstrate performance boosts across architectures, learning algorithms and\nenvironments. A more refined analysis shows that learning one segment of a game\noften increases prediction errors elsewhere. Our study provides a clear\nempirical link between catastrophic interference and sample efficiency in\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 00:55:03 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 17:36:46 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Fedus", "William", ""], ["Ghosh", "Dibya", ""], ["Martin", "John D.", ""], ["Bellemare", "Marc G.", ""], ["Bengio", "Yoshua", ""], ["Larochelle", "Hugo", ""]]}, {"id": "2002.12500", "submitter": "Akanksha Saran", "authors": "Akanksha Saran, Ruohan Zhang, Elaine Schaertl Short and Scott Niekum", "title": "Efficiently Guiding Imitation Learning Agents with Human Gaze", "comments": "AAMAS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human gaze is known to be an intention-revealing signal in human\ndemonstrations of tasks. In this work, we use gaze cues from human\ndemonstrators to enhance the performance of agents trained via three popular\nimitation learning methods -- behavioral cloning (BC), behavioral cloning from\nobservation (BCO), and Trajectory-ranked Reward EXtrapolation (T-REX). Based on\nsimilarities between the attention of reinforcement learning agents and human\ngaze, we propose a novel approach for utilizing gaze data in a computationally\nefficient manner, as part of an auxiliary loss function, which guides a network\nto have higher activations in image regions where the human's gaze fixated.\nThis work is a step towards augmenting any existing convolutional imitation\nlearning agent's training with auxiliary gaze data. Our auxiliary\ncoverage-based gaze loss (CGL) guides learning toward a better reward function\nor policy, without adding any additional learnable parameters and without\nrequiring gaze data at test time. We find that our proposed approach improves\nthe performance by 95% for BC, 343% for BCO, and 390% for T-REX, averaged over\n20 different Atari games. We also find that compared to a prior\nstate-of-the-art imitation learning method assisted by human gaze (AGIL), our\nmethod achieves better performance, and is more efficient in terms of learning\nwith fewer demonstrations. We further interpret trained CGL agents with a\nsaliency map visualization method to explain their performance. At last, we\nshow that CGL can help alleviate a well-known causal confusion problem in\nimitation learning.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 00:55:30 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 19:18:57 GMT"}, {"version": "v3", "created": "Thu, 25 Mar 2021 15:46:26 GMT"}, {"version": "v4", "created": "Wed, 21 Apr 2021 21:39:21 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Saran", "Akanksha", ""], ["Zhang", "Ruohan", ""], ["Short", "Elaine Schaertl", ""], ["Niekum", "Scott", ""]]}, {"id": "2002.12551", "submitter": "EPTCS", "authors": "Ludovic Font (\\'Ecole Polytechnique de Montr\\'eal), S\\'ebastien Cyr\n  (Universit\\'e de Montr\\'eal), Philippe R. Richard (Universit\\'e de\n  Montr\\'eal), Michel Gagnon (\\'Ecole Polytechnique de Montr\\'eal)", "title": "Automating the Generation of High School Geometry Proofs using Prolog in\n  an Educational Context", "comments": "In Proceedings ThEdu'19, arXiv:2002.11895", "journal-ref": "EPTCS 313, 2020, pp. 1-16", "doi": "10.4204/EPTCS.313.1", "report-no": null, "categories": "cs.AI cs.HC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When working on intelligent tutor systems designed for mathematics education\nand its specificities, an interesting objective is to provide relevant help to\nthe students by anticipating their next steps. This can only be done by\nknowing, beforehand, the possible ways to solve a problem. Hence the need for\nan automated theorem prover that provide proofs as they would be written by a\nstudent. To achieve this objective, logic programming is a natural tool due to\nthe similarity of its reasoning with a mathematical proof by inference. In this\npaper, we present the core ideas we used to implement such a prover, from its\nencoding in Prolog to the generation of the complete set of proofs. However,\nwhen dealing with educational aspects, there are many challenges to overcome.\nWe also present the main issues we encountered, as well as the chosen\nsolutions.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 05:23:16 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Font", "Ludovic", "", "\u00c9cole Polytechnique de Montr\u00e9al"], ["Cyr", "S\u00e9bastien", "", "Universit\u00e9 de Montr\u00e9al"], ["Richard", "Philippe R.", "", "Universit\u00e9 de\n  Montr\u00e9al"], ["Gagnon", "Michel", "", "\u00c9cole Polytechnique de Montr\u00e9al"]]}, {"id": "2002.12556", "submitter": "EPTCS", "authors": "Nuno Baeta (University of Coimbra), Pedro Quaresma (University of\n  Coimbra), Zolt\\'an Kov\\'acs (The Private University College of Education of\n  the Diocese of Linz)", "title": "Towards a Geometry Automated Provers Competition", "comments": "In Proceedings ThEdu'19, arXiv:2002.11895", "journal-ref": "EPTCS 313, 2020, pp. 93-100", "doi": "10.4204/EPTCS.313.6", "report-no": null, "categories": "cs.AI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The geometry automated theorem proving area distinguishes itself by a large\nnumber of specific methods and implementations, different approaches\n(synthetic, algebraic, semi-synthetic) and different goals and applications\n(from research in the area of artificial intelligence to applications in\neducation).\n  Apart from the usual measures of efficiency (e.g. CPU time), the possibility\nof visual and/or readable proofs is also an expected output against which the\ngeometry automated theorem provers (GATP) should be measured.\n  The implementation of a competition between GATP would allow to create a test\nbench for GATP developers to improve the existing ones and to propose new ones.\nIt would also allow to establish a ranking for GATP that could be used by\n\"clients\" (e.g. developers of educational e-learning systems) to choose the\nbest implementation for a given intended use.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 05:24:29 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Baeta", "Nuno", "", "University of Coimbra"], ["Quaresma", "Pedro", "", "University of\n  Coimbra"], ["Kov\u00e1cs", "Zolt\u00e1n", "", "The Private University College of Education of\n  the Diocese of Linz"]]}, {"id": "2002.12636", "submitter": "Alexander Tschantz", "authors": "Alexander Tschantz, Beren Millidge, Anil K. Seth, Christopher L.\n  Buckley", "title": "Reinforcement Learning through Active Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT cs.SY eess.SY math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The central tenet of reinforcement learning (RL) is that agents seek to\nmaximize the sum of cumulative rewards. In contrast, active inference, an\nemerging framework within cognitive and computational neuroscience, proposes\nthat agents act to maximize the evidence for a biased generative model. Here,\nwe illustrate how ideas from active inference can augment traditional RL\napproaches by (i) furnishing an inherent balance of exploration and\nexploitation, and (ii) providing a more flexible conceptualization of reward.\nInspired by active inference, we develop and implement a novel objective for\ndecision making, which we term the free energy of the expected future. We\ndemonstrate that the resulting algorithm successfully balances exploration and\nexploitation, simultaneously achieving robust performance on several\nchallenging RL benchmarks with sparse, well-shaped, and no rewards.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 10:28:21 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Tschantz", "Alexander", ""], ["Millidge", "Beren", ""], ["Seth", "Anil K.", ""], ["Buckley", "Christopher L.", ""]]}, {"id": "2002.12760", "submitter": "Amar Isli", "authors": "Amar Isli", "title": "A spatio-temporalisation of ALC(D) and its translation into alternating\n  automata augmented with spatial constraints", "comments": "See footnote 1 on the first page of the paper. arXiv admin note:\n  substantial text overlap with arXiv:cs/0307040 and text overlap with\n  arXiv:2002.11510", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this work is to provide a family of qualitative theories for\nspatial change in general, and for motion of spatial scenes in particular. To\nachieve this, we consider a spatio-temporalisation MTALC(Dx), of the well-known\nALC(D) family of Description Logics (DLs) with a concrete domain: the MTALC(Dx)\nconcepts are interpreted over infinite k-ary Sigma-trees, with the nodes\nstanding for time points, and Sigma including, additionally to its uses in\nclassical k-ary Sigma-trees, the description of the snapshot of an n-object\nspatial scene of interest; the roles split into m+n immediate-successor\n(accessibility) relations, which are serial, irreflexive and antisymmetric, and\nof which m are general, not necessarily functional, the other n functional; the\nconcrete domain Dx is generated by an RCC8-like spatial Relation Algebra (RA)\nx, and is used to guide the change by imposing spatial constraints on objects\nof the \"followed\" spatial scene, eventually at different time points of the\ninput trees. In order to capture the expressiveness of most modal temporal\nlogics encountered in the literature, we introduce weakly cyclic Terminological\nBoxes (TBoxes) of MTALC(Dx), whose axioms capture the decreasing property of\nmodal temporal operators. We show the important result that satisfiability of\nan MTALC(Dx) concept with respect to a weakly cyclic TBox can be reduced to the\nemptiness problem of a Buchi weak alternating automaton augmented with spatial\nconstraints. In another work, complementary to this one, also submitted to this\nconference, we thoroughly investigate Buchi automata augmented with spatial\nconstraints, and provide, in particular, a translation of an alternating into a\nnondeterministic, and an effective decision procedure for the emptiness problem\nof the latter.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 17:20:16 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Isli", "Amar", ""]]}, {"id": "2002.12788", "submitter": "Rupayan Chakraborty", "authors": "Rupayan Chakraborty, Meghna Pandharipande, Chitralekha Bhat, and Sunil\n  Kumar Kopparapu", "title": "Identification of Dementia Using Audio Biomarkers", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dementia is a syndrome, generally of a chronic nature characterized by a\ndeterioration in cognitive function, especially in the geriatric population and\nis severe enough to impact their daily activities. Early diagnosis of dementia\nis essential to provide timely treatment to alleviate the effects and sometimes\nto slow the progression of dementia. Speech has been known to provide an\nindication of a person's cognitive state. The objective of this work is to use\nspeech processing and machine learning techniques to automatically identify the\nstage of dementia such as mild cognitive impairment (MCI) or Alzheimers disease\n(AD). Non-linguistic acoustic parameters are used for this purpose, making this\na language independent approach. We analyze the patients audio excerpts from a\nclinician-participant conversations taken from the Pitt corpus of DementiaBank\ndatabase, to identify the speech parameters that best distinguish between MCI,\nAD and healthy (HC) speech. We analyze the contribution of various types of\nacoustic features such as spectral, temporal, cepstral their feature-level\nfusion and selection towards the identification of dementia stage.\nAdditionally, we compare the performance of using feature-level fusion and\nscore-level fusion. An accuracy of 82% is achieved using score-level fusion\nwith an absolute improvement of 5% over feature-level fusion.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 13:54:00 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Chakraborty", "Rupayan", ""], ["Pandharipande", "Meghna", ""], ["Bhat", "Chitralekha", ""], ["Kopparapu", "Sunil Kumar", ""]]}, {"id": "2002.12909", "submitter": "Laura Greige", "authors": "Laura Greige, Peter Chin", "title": "Reinforcement Learning in FlipIt", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning has shown much success in games such as chess,\nbackgammon and Go. However, in most of these games, agents have full knowledge\nof the environment at all times. In this paper, we describe a deep learning\nmodel that successfully optimizes its score using reinforcement learning in a\ngame with incomplete and imperfect information. We apply our model to FlipIt, a\ntwo-player game in which both players, the attacker and the defender, compete\nfor ownership of a shared resource and only receive information on the current\nstate (such as the current owner of the resource, or the time since the\nopponent last moved, etc.) upon making a move. Our model is a deep neural\nnetwork combined with Q-learning and is trained to maximize the defender's time\nof ownership of the resource. Despite the imperfect observations, our model\nsuccessfully learns an optimal cost-effective counter-strategy and shows the\nadvantages of the use of deep reinforcement learning in game theoretic\nscenarios. Our results show that it outperforms the Greedy strategy against\ndistributions such as periodic and exponential distributions without any prior\nknowledge of the opponent's strategy, and we generalize the model to $n$-player\ngames.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 18:26:24 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Greige", "Laura", ""], ["Chin", "Peter", ""]]}]