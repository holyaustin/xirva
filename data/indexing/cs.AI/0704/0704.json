[{"id": "0704.0047", "submitter": "Igor Grabec", "authors": "T. Kosel and I. Grabec", "title": "Intelligent location of simultaneously active acoustic emission sources:\n  Part I", "comments": "5 pages, 5 eps figures, uses IEEEtran.cls", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": null, "abstract": "  The intelligent acoustic emission locator is described in Part I, while Part\nII discusses blind source separation, time delay estimation and location of two\nsimultaneously active continuous acoustic emission sources.\n  The location of acoustic emission on complicated aircraft frame structures is\na difficult problem of non-destructive testing. This article describes an\nintelligent acoustic emission source locator. The intelligent locator comprises\na sensor antenna and a general regression neural network, which solves the\nlocation problem based on learning from examples. Locator performance was\ntested on different test specimens. Tests have shown that the accuracy of\nlocation depends on sound velocity and attenuation in the specimen, the\ndimensions of the tested area, and the properties of stored data. The location\naccuracy achieved by the intelligent locator is comparable to that obtained by\nthe conventional triangulation method, while the applicability of the\nintelligent locator is more general since analysis of sonic ray paths is\navoided. This is a promising method for non-destructive testing of aircraft\nframe structures by the acoustic emission method.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2007 13:06:50 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Kosel", "T.", ""], ["Grabec", "I.", ""]]}, {"id": "0704.0050", "submitter": "Igor Grabec", "authors": "T. Kosel and I. Grabec", "title": "Intelligent location of simultaneously active acoustic emission sources:\n  Part II", "comments": "5 pages, 7 eps figures, uses IEEEtran.cls", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": null, "abstract": "  Part I describes an intelligent acoustic emission locator, while Part II\ndiscusses blind source separation, time delay estimation and location of two\ncontinuous acoustic emission sources.\n  Acoustic emission (AE) analysis is used for characterization and location of\ndeveloping defects in materials. AE sources often generate a mixture of various\nstatistically independent signals. A difficult problem of AE analysis is\nseparation and characterization of signal components when the signals from\nvarious sources and the mode of mixing are unknown. Recently, blind source\nseparation (BSS) by independent component analysis (ICA) has been used to solve\nthese problems. The purpose of this paper is to demonstrate the applicability\nof ICA to locate two independent simultaneously active acoustic emission\nsources on an aluminum band specimen. The method is promising for\nnon-destructive testing of aircraft frame structures by acoustic emission\nanalysis.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2007 18:53:13 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Kosel", "T.", ""], ["Grabec", "I.", ""]]}, {"id": "0704.0304", "submitter": "Carlos Gershenson", "authors": "Carlos Gershenson", "title": "The World as Evolving Information", "comments": "16 pages. Extended version, three more laws of information, two\n  classifications, and discussion added. To be published (soon) in\n  International Conference on Complex Systems 2007 Proceedings", "journal-ref": "Minai, A., Braha, D., and Bar-Yam, Y., eds. Unifying Themes in\n  Complex Systems VII, pp. 100-115. Springer, Berlin Heidelberg, 2012", "doi": "10.1007/978-3-642-18003-3_10", "report-no": null, "categories": "cs.IT cs.AI math.IT q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the benefits of describing the world as information,\nespecially in the study of the evolution of life and cognition. Traditional\nstudies encounter problems because it is difficult to describe life and\ncognition in terms of matter and energy, since their laws are valid only at the\nphysical scale. However, if matter and energy, as well as life and cognition,\nare described in terms of information, evolution can be described consistently\nas information becoming more complex.\n  The paper presents eight tentative laws of information, valid at multiple\nscales, which are generalizations of Darwinian, cybernetic, thermodynamic,\npsychological, philosophical, and complexity principles. These are further used\nto discuss the notions of life, cognition and their evolution.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2007 02:08:48 GMT"}, {"version": "v2", "created": "Thu, 30 Aug 2007 20:03:59 GMT"}, {"version": "v3", "created": "Wed, 13 Oct 2010 19:49:16 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Gershenson", "Carlos", ""]]}, {"id": "0704.0985", "submitter": "Mohd Abubakr", "authors": "Mohd Abubakr, R.M.Vinay", "title": "Architecture for Pseudo Acausal Evolvable Embedded Systems", "comments": "4 pages, 2 figures. Submitted to SASO 2007", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": null, "abstract": "  Advances in semiconductor technology are contributing to the increasing\ncomplexity in the design of embedded systems. Architectures with novel\ntechniques such as evolvable nature and autonomous behavior have engrossed lot\nof attention. This paper demonstrates conceptually evolvable embedded systems\ncan be characterized basing on acausal nature. It is noted that in acausal\nsystems, future input needs to be known, here we make a mechanism such that the\nsystem predicts the future inputs and exhibits pseudo acausal nature. An\nembedded system that uses theoretical framework of acausality is proposed. Our\nmethod aims at a novel architecture that features the hardware evolability and\nautonomous behavior alongside pseudo acausality. Various aspects of this\narchitecture are discussed in detail along with the limitations.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2007 13:40:49 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Abubakr", "Mohd", ""], ["Vinay", "R. M.", ""]]}, {"id": "0704.1028", "submitter": "Jianlin Cheng", "authors": "Jianlin Cheng", "title": "A neural network approach to ordinal regression", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": null, "abstract": "  Ordinal regression is an important type of learning, which has properties of\nboth classification and regression. Here we describe a simple and effective\napproach to adapt a traditional neural network to learn ordinal categories. Our\napproach is a generalization of the perceptron method for ordinal regression.\nOn several benchmark datasets, our method (NNRank) outperforms a neural network\nclassification method. Compared with the ordinal regression methods using\nGaussian processes and support vector machines, NNRank achieves comparable\nperformance. Moreover, NNRank has the advantages of traditional neural\nnetworks: learning in both online and batch modes, handling very large training\ndatasets, and making rapid predictions. These features make NNRank a useful and\ncomplementary tool for large-scale data processing tasks such as information\nretrieval, web page ranking, collaborative filtering, and protein ranking in\nBioinformatics.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2007 17:36:00 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Cheng", "Jianlin", ""]]}, {"id": "0704.1394", "submitter": "Tarik Had\\v{z}i\\'c", "authors": "Tarik Hadzic, Rune Moller Jensen, Henrik Reif Andersen", "title": "Calculating Valid Domains for BDD-Based Interactive Configuration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  In these notes we formally describe the functionality of Calculating Valid\nDomains from the BDD representing the solution space of valid configurations.\nThe formalization is largely based on the CLab configuration framework.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2007 10:59:56 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Hadzic", "Tarik", ""], ["Jensen", "Rune Moller", ""], ["Andersen", "Henrik Reif", ""]]}, {"id": "0704.1409", "submitter": "Yao Hengshuai", "authors": "Yao HengShuai", "title": "Preconditioned Temporal Difference Learning", "comments": "This paper has been withdrawn by the author. Look at the ICML version\n  instead: http://icml2008.cs.helsinki.fi/papers/111.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": null, "abstract": "  This paper has been withdrawn by the author. This draft is withdrawn for its\npoor quality in english, unfortunately produced by the author when he was just\nstarting his science route. Look at the ICML version instead:\nhttp://icml2008.cs.helsinki.fi/papers/111.pdf\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2007 13:17:01 GMT"}, {"version": "v2", "created": "Thu, 12 Apr 2007 03:33:26 GMT"}, {"version": "v3", "created": "Fri, 8 Jun 2012 14:08:19 GMT"}], "update_date": "2012-06-11", "authors_parsed": [["HengShuai", "Yao", ""]]}, {"id": "0704.1675", "submitter": "Kristina Lerman", "authors": "Anon Plangprasopchok and Kristina Lerman", "title": "Exploiting Social Annotation for Automatic Resource Discovery", "comments": "6 pages, submitted to AAAI07 workshop on Information Integration on\n  the Web", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.DL", "license": null, "abstract": "  Information integration applications, such as mediators or mashups, that\nrequire access to information resources currently rely on users manually\ndiscovering and integrating them in the application. Manual resource discovery\nis a slow process, requiring the user to sift through results obtained via\nkeyword-based search. Although search methods have advanced to include evidence\nfrom document contents, its metadata and the contents and link structure of the\nreferring pages, they still do not adequately cover information sources --\noften called ``the hidden Web''-- that dynamically generate documents in\nresponse to a query. The recently popular social bookmarking sites, which allow\nusers to annotate and share metadata about various information sources, provide\nrich evidence for resource discovery. In this paper, we describe a\nprobabilistic model of the user annotation process in a social bookmarking\nsystem del.icio.us. We then use the model to automatically find resources\nrelevant to a particular information domain. Our experimental results on data\nobtained from \\emph{del.icio.us} show this approach as a promising method for\nhelping automate the resource discovery task.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2007 23:24:19 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Plangprasopchok", "Anon", ""], ["Lerman", "Kristina", ""]]}, {"id": "0704.1676", "submitter": "Kristina Lerman", "authors": "Kristina Lerman, Anon Plangprasopchok and Chio Wong", "title": "Personalizing Image Search Results on Flickr", "comments": "12 pages, submitted to AAAI07 workshop on Intelligent Information\n  Personalization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CY cs.DL cs.HC", "license": null, "abstract": "  The social media site Flickr allows users to upload their photos, annotate\nthem with tags, submit them to groups, and also to form social networks by\nadding other users as contacts. Flickr offers multiple ways of browsing or\nsearching it. One option is tag search, which returns all images tagged with a\nspecific keyword. If the keyword is ambiguous, e.g., ``beetle'' could mean an\ninsect or a car, tag search results will include many images that are not\nrelevant to the sense the user had in mind when executing the query. We claim\nthat users express their photography interests through the metadata they add in\nthe form of contacts and image annotations. We show how to exploit this\nmetadata to personalize search results for the user, thereby improving search\nperformance. First, we show that we can significantly improve search precision\nby filtering tag search results by user's contacts or a larger social network\nthat includes those contact's contacts. Secondly, we describe a probabilistic\nmodel that takes advantage of tag information to discover latent topics\ncontained in the search results. The users' interests can similarly be\ndescribed by the tags they used for annotating their images. The latent topics\nfound by the model are then used to personalize search results by finding\nimages on topics that are of interest to the user.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2007 23:31:04 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Lerman", "Kristina", ""], ["Plangprasopchok", "Anon", ""], ["Wong", "Chio", ""]]}, {"id": "0704.1783", "submitter": "Francesco Santini", "authors": "Stefano Bistarelli, Ugo Montanari, Francesca Rossi, Francesco Santini", "title": "Unicast and Multicast Qos Routing with Soft Constraint Logic Programming", "comments": "45 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.NI", "license": null, "abstract": "  We present a formal model to represent and solve the unicast/multicast\nrouting problem in networks with Quality of Service (QoS) requirements. To\nattain this, first we translate the network adapting it to a weighted graph\n(unicast) or and-or graph (multicast), where the weight on a connector\ncorresponds to the multidimensional cost of sending a packet on the related\nnetwork link: each component of the weights vector represents a different QoS\nmetric value (e.g. bandwidth, cost, delay, packet loss). The second step\nconsists in writing this graph as a program in Soft Constraint Logic\nProgramming (SCLP): the engine of this framework is then able to find the best\npaths/trees by optimizing their costs and solving the constraints imposed on\nthem (e.g. delay < 40msec), thus finding a solution to QoS routing problems.\nMoreover, c-semiring structures are a convenient tool to model QoS metrics. At\nlast, we provide an implementation of the framework over scale-free networks\nand we suggest how the performance can be improved.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2007 15:53:44 GMT"}, {"version": "v2", "created": "Sun, 29 Apr 2007 15:40:10 GMT"}, {"version": "v3", "created": "Mon, 21 Apr 2008 17:25:06 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Bistarelli", "Stefano", ""], ["Montanari", "Ugo", ""], ["Rossi", "Francesca", ""], ["Santini", "Francesco", ""]]}, {"id": "0704.2010", "submitter": "Juliana Bernardes", "authors": "Juliana S Bernardes, Alberto Davila, Vitor Santos Costa, Gerson\n  Zaverucha", "title": "A study of structural properties on profiles HMMs", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Profile hidden Markov Models (pHMMs) are a popular and very\nuseful tool in the detection of the remote homologue protein families.\nUnfortunately, their performance is not always satisfactory when proteins are\nin the 'twilight zone'. We present HMMER-STRUCT, a model construction algorithm\nand tool that tries to improve pHMM performance by using structural information\nwhile training pHMMs. As a first step, HMMER-STRUCT constructs a set of pHMMs.\nEach pHMM is constructed by weighting each residue in an aligned protein\naccording to a specific structural property of the residue. Properties used\nwere primary, secondary and tertiary structures, accessibility and packing.\nHMMER-STRUCT then prioritizes the results by voting. Results: We used the SCOP\ndatabase to perform our experiments. Throughout, we apply leave-one-family-out\ncross-validation over protein superfamilies. First, we used the MAMMOTH-mult\nstructural aligner to align the training set proteins. Then, we performed two\nsets of experiments. In a first experiment, we compared structure weighted\nmodels against standard pHMMs and against each other. In a second experiment,\nwe compared the voting model against individual pHMMs. We compare method\nperformance through ROC curves and through Precision/Recall curves, and assess\nsignificance through the paired two tailed t-test. Our results show significant\nperformance improvements of all structurally weighted models over default\nHMMER, and a significant improvement in sensitivity of the combined models over\nboth the original model and the structurally weighted models.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2007 13:10:35 GMT"}, {"version": "v2", "created": "Thu, 11 Dec 2008 18:47:26 GMT"}], "update_date": "2008-12-11", "authors_parsed": [["Bernardes", "Juliana S", ""], ["Davila", "Alberto", ""], ["Costa", "Vitor Santos", ""], ["Zaverucha", "Gerson", ""]]}, {"id": "0704.2083", "submitter": "Hassan Satori", "authors": "H. Satori, M. Harti and N. Chenfour", "title": "Introduction to Arabic Speech Recognition Using CMUSphinx System", "comments": "4 pages, 3 figures and 2 tables, was in Information and Communication\n  Technologies International Symposium proceeding ICTIS07 Fes (2007)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": null, "abstract": "  In this paper Arabic was investigated from the speech recognition problem\npoint of view. We propose a novel approach to build an Arabic Automated Speech\nRecognition System (ASR). This system is based on the open source CMU Sphinx-4,\nfrom the Carnegie Mellon University. CMU Sphinx is a large-vocabulary;\nspeaker-independent, continuous speech recognition system based on discrete\nHidden Markov Models (HMMs). We build a model using utilities from the\nOpenSource CMU Sphinx. We will demonstrate the possible adaptability of this\nsystem to Arabic voice recognition.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2007 01:04:01 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Satori", "H.", ""], ["Harti", "M.", ""], ["Chenfour", "N.", ""]]}, {"id": "0704.2201", "submitter": "Hassan Satori", "authors": "H. Satori, M. Harti and N. Chenfour", "title": "Arabic Speech Recognition System using CMU-Sphinx4", "comments": "5 pages, 3 figures and 2 tables, in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": null, "abstract": "  In this paper we present the creation of an Arabic version of Automated\nSpeech Recognition System (ASR). This system is based on the open source\nSphinx-4, from the Carnegie Mellon University. Which is a speech recognition\nsystem based on discrete hidden Markov models (HMMs). We investigate the\nchanges that must be made to the model to adapt Arabic voice recognition.\n  Keywords: Speech recognition, Acoustic model, Arabic language, HMMs,\nCMUSphinx-4, Artificial intelligence.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2007 17:04:26 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Satori", "H.", ""], ["Harti", "M.", ""], ["Chenfour", "N.", ""]]}, {"id": "0704.3157", "submitter": "Giorgio Terracina", "authors": "Giorgio Terracina, Nicola Leone, Vincenzino Lio, Claudio Panetta", "title": "Experimenting with recursive queries in database and logic programming\n  systems", "comments": "To appear in Theory and Practice of Logic Programming (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": null, "abstract": "  This paper considers the problem of reasoning on massive amounts of (possibly\ndistributed) data. Presently, existing proposals show some limitations: {\\em\n(i)} the quantity of data that can be handled contemporarily is limited, due to\nthe fact that reasoning is generally carried out in main-memory; {\\em (ii)} the\ninteraction with external (and independent) DBMSs is not trivial and, in\nseveral cases, not allowed at all; {\\em (iii)} the efficiency of present\nimplementations is still not sufficient for their utilization in complex\nreasoning tasks involving massive amounts of data. This paper provides a\ncontribution in this setting; it presents a new system, called DLV$^{DB}$,\nwhich aims to solve these problems. Moreover, the paper reports the results of\na thorough experimental analysis we have carried out for comparing our system\nwith several state-of-the-art systems (both logic and databases) on some\nclassical deductive problems; the other tested systems are: LDL++, XSB, Smodels\nand three top-level commercial DBMSs. DLV$^{DB}$ significantly outperforms even\nthe commercial Database Systems on recursive queries. To appear in Theory and\nPractice of Logic Programming (TPLP)\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2007 10:58:40 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Terracina", "Giorgio", ""], ["Leone", "Nicola", ""], ["Lio", "Vincenzino", ""], ["Panetta", "Claudio", ""]]}, {"id": "0704.3359", "submitter": "Alex Smola J", "authors": "Quoc Le and Alexander Smola", "title": "Direct Optimization of Ranking Measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": null, "abstract": "  Web page ranking and collaborative filtering require the optimization of\nsophisticated performance measures. Current Support Vector approaches are\nunable to optimize them directly and focus on pairwise comparisons instead. We\npresent a new approach which allows direct optimization of the relevant loss\nfunctions. This is achieved via structured estimation in Hilbert spaces. It is\nmost related to Max-Margin-Markov networks optimization of multivariate\nperformance measures. Key to our approach is that during training the ranking\nproblem can be viewed as a linear assignment problem, which can be solved by\nthe Hungarian Marriage algorithm. At test time, a sort operation is sufficient,\nas our algorithm assigns a relevance score to every (document, query) pair.\nExperiments show that the our algorithm is fast and that it works very well.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2007 12:36:55 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Le", "Quoc", ""], ["Smola", "Alexander", ""]]}, {"id": "0704.3395", "submitter": "Marko A. Rodriguez", "authors": "Marko A. Rodriguez", "title": "General-Purpose Computing on a Semantic Network Substrate", "comments": null, "journal-ref": "Emergent Web Intelligence: Advanced Semantic Technologies,\n  Advanced Information and Knowledge Processing series, Springer-Verlag, pages\n  57-104, ISBN:978-1-84996-076-2, June 2010", "doi": null, "report-no": "LA-UR-07-2885", "categories": "cs.AI cs.PL", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  This article presents a model of general-purpose computing on a semantic\nnetwork substrate. The concepts presented are applicable to any semantic\nnetwork representation. However, due to the standards and technological\ninfrastructure devoted to the Semantic Web effort, this article is presented\nfrom this point of view. In the proposed model of computing, the application\nprogramming interface, the run-time program, and the state of the computing\nvirtual machine are all represented in the Resource Description Framework\n(RDF). The implementation of the concepts presented provides a practical\ncomputing paradigm that leverages the highly-distributed and standardized\nrepresentational-layer of the Semantic Web.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2007 15:37:52 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2007 20:08:21 GMT"}, {"version": "v3", "created": "Sun, 7 Oct 2007 21:44:01 GMT"}, {"version": "v4", "created": "Sun, 6 Jun 2010 05:29:22 GMT"}], "update_date": "2010-06-08", "authors_parsed": [["Rodriguez", "Marko A.", ""]]}, {"id": "0704.3433", "submitter": "Tshilidzi Marwala", "authors": "Tshilidzi Marwala and Bodie Crossingham", "title": "Bayesian approach to rough set", "comments": "20 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  This paper proposes an approach to training rough set models using Bayesian\nframework trained using Markov Chain Monte Carlo (MCMC) method. The prior\nprobabilities are constructed from the prior knowledge that good rough set\nmodels have fewer rules. Markov Chain Monte Carlo sampling is conducted through\nsampling in the rough set granule space and Metropolis algorithm is used as an\nacceptance criteria. The proposed method is tested to estimate the risk of HIV\ngiven demographic data. The results obtained shows that the proposed approach\nis able to achieve an average accuracy of 58% with the accuracy varying up to\n66%. In addition the Bayesian rough set give the probabilities of the estimated\nHIV status as well as the linguistic rules describing how the demographic\nparameters drive the risk of HIV.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2007 19:50:59 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Marwala", "Tshilidzi", ""], ["Crossingham", "Bodie", ""]]}, {"id": "0704.3453", "submitter": "Tshilidzi Marwala", "authors": "S. Mohamed, D. Rubin, and T. Marwala", "title": "An Adaptive Strategy for the Classification of G-Protein Coupled\n  Receptors", "comments": "9 pages, 5 tables, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.QM", "license": null, "abstract": "  One of the major problems in computational biology is the inability of\nexisting classification models to incorporate expanding and new domain\nknowledge. This problem of static classification models is addressed in this\npaper by the introduction of incremental learning for problems in\nbioinformatics. Many machine learning tools have been applied to this problem\nusing static machine learning structures such as neural networks or support\nvector machines that are unable to accommodate new information into their\nexisting models. We utilize the fuzzy ARTMAP as an alternate machine learning\nsystem that has the ability of incrementally learning new data as it becomes\navailable. The fuzzy ARTMAP is found to be comparable to many of the widespread\nmachine learning systems. The use of an evolutionary strategy in the selection\nand combination of individual classifiers into an ensemble system, coupled with\nthe incremental learning ability of the fuzzy ARTMAP is proven to be suitable\nas a pattern classifier. The algorithm presented is tested using data from the\nG-Coupled Protein Receptors Database and shows good accuracy of 83%. The system\npresented is also generally applicable, and can be used in problems in genomics\nand proteomics.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2007 21:23:31 GMT"}], "update_date": "2007-06-25", "authors_parsed": [["Mohamed", "S.", ""], ["Rubin", "D.", ""], ["Marwala", "T.", ""]]}, {"id": "0704.3515", "submitter": "Jegor Uglov Mr", "authors": "J. Uglov, V. Schetinin, C. Maple", "title": "Comparing Robustness of Pairwise and Multiclass Neural-Network Systems\n  for Face Recognition", "comments": null, "journal-ref": null, "doi": "10.1155/2008/468693", "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  Noise, corruptions and variations in face images can seriously hurt the\nperformance of face recognition systems. To make such systems robust,\nmulticlass neuralnetwork classifiers capable of learning from noisy data have\nbeen suggested. However on large face data sets such systems cannot provide the\nrobustness at a high level. In this paper we explore a pairwise neural-network\nsystem as an alternative approach to improving the robustness of face\nrecognition. In our experiments this approach is shown to outperform the\nmulticlass neural-network system in terms of the predictive accuracy on the\nface images corrupted by noise.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2007 11:29:19 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["Uglov", "J.", ""], ["Schetinin", "V.", ""], ["Maple", "C.", ""]]}, {"id": "0704.3886", "submitter": "W Saba", "authors": "Walid S. Saba", "title": "A Note on Ontology and Ordinary Language", "comments": "19 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": null, "abstract": "  We argue for a compositional semantics grounded in a strongly typed ontology\nthat reflects our commonsense view of the world and the way we talk about it.\nAssuming such a structure we show that the semantics of various natural\nlanguage phenomena may become nearly trivial.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2007 17:55:39 GMT"}, {"version": "v2", "created": "Tue, 1 May 2007 13:43:32 GMT"}, {"version": "v3", "created": "Wed, 2 May 2007 18:13:22 GMT"}, {"version": "v4", "created": "Thu, 3 May 2007 08:34:47 GMT"}, {"version": "v5", "created": "Fri, 4 May 2007 17:49:03 GMT"}, {"version": "v6", "created": "Mon, 7 May 2007 16:04:50 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Saba", "Walid S.", ""]]}, {"id": "0704.3905", "submitter": "Marc Schoenauer", "authors": "Christian Gagn\\'e (INFORMATIQUE WGZ INC.), Mich\\`ele Sebag (INRIA\n  Futurs), Marc Schoenauer (INRIA Futurs), Marco Tomassini (ISI)", "title": "Ensemble Learning for Free with Evolutionary Algorithms ?", "comments": null, "journal-ref": "Dans GECCO (2007)", "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  Evolutionary Learning proceeds by evolving a population of classifiers, from\nwhich it generally returns (with some notable exceptions) the single\nbest-of-run classifier as final result. In the meanwhile, Ensemble Learning,\none of the most efficient approaches in supervised Machine Learning for the\nlast decade, proceeds by building a population of diverse classifiers. Ensemble\nLearning with Evolutionary Computation thus receives increasing attention. The\nEvolutionary Ensemble Learning (EEL) approach presented in this paper features\ntwo contributions. First, a new fitness function, inspired by co-evolution and\nenforcing the classifier diversity, is presented. Further, a new selection\ncriterion based on the classification margin is proposed. This criterion is\nused to extract the classifier ensemble from the final population only\n(Off-line) or incrementally along evolution (On-line). Experiments on a set of\nbenchmark problems show that Off-line outperforms single-hypothesis\nevolutionary learning and state-of-art Boosting and generates smaller\nclassifier ensembles.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2007 09:29:22 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Gagn\u00e9", "Christian", "", "INFORMATIQUE WGZ INC."], ["Sebag", "Mich\u00e8le", "", "INRIA\n  Futurs"], ["Schoenauer", "Marc", "", "INRIA Futurs"], ["Tomassini", "Marco", "", "ISI"]]}]