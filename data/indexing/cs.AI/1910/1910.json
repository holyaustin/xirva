[{"id": "1910.00057", "submitter": "Goutham Ramakrishnan", "authors": "Goutham Ramakrishnan, Yun Chan Lee, Aws Albarghouthi", "title": "Synthesizing Action Sequences for Modifying Model Decisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a model makes a consequential decision, e.g., denying someone a loan, it\nneeds to additionally generate actionable, realistic feedback on what the\nperson can do to favorably change the decision. We cast this problem through\nthe lens of program synthesis, in which our goal is to synthesize an optimal\n(realistically cheapest or simplest) sequence of actions that if a person\nexecutes successfully can change their classification. We present a novel and\ngeneral approach that combines search-based program synthesis and test-time\nadversarial attacks to construct action sequences over a domain-specific set of\nactions. We demonstrate the effectiveness of our approach on a number of deep\nneural networks.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 18:57:13 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 14:03:48 GMT"}, {"version": "v3", "created": "Wed, 9 Oct 2019 16:22:00 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Ramakrishnan", "Goutham", ""], ["Lee", "Yun Chan", ""], ["Albarghouthi", "Aws", ""]]}, {"id": "1910.00063", "submitter": "Daniel Larsson", "authors": "Daniel T. Larsson, Dipankar Maity, Panagiotis Tsiotras", "title": "Q-Search Trees: An Information-Theoretic Approach Towards Hierarchical\n  Abstractions for Agents with Computational Limitations", "comments": null, "journal-ref": "2020 IEEE Transactions on Robotics (T-RO)", "doi": "10.1109/TRO.2020.3003219", "report-no": null, "categories": "cs.RO cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a framework to obtain graph abstractions for\ndecision-making by an agent where the abstractions emerge as a function of the\nagent's limited computational resources. We discuss the connection of the\nproposed approach with information-theoretic signal compression, and formulate\na novel optimization problem to obtain tree-based abstractions as a function of\nthe agent's computational resources. The structural properties of the new\nproblem are discussed in detail, and two algorithmic approaches are proposed to\nobtain solutions to this optimization problem. We discuss the quality of, and\nprove relationships between, solutions obtained by the two proposed algorithms.\nThe framework is demonstrated to generate a hierarchy of abstractions for a\nnon-trivial environment.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 19:21:41 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Larsson", "Daniel T.", ""], ["Maity", "Dipankar", ""], ["Tsiotras", "Panagiotis", ""]]}, {"id": "1910.00084", "submitter": "Gengchen Mai", "authors": "Gengchen Mai, Krzysztof Janowicz, Bo Yan, Rui Zhu, Ling Cai, Ni Lao", "title": "Contextual Graph Attention for Answering Logical Queries over Incomplete\n  Knowledge Graphs", "comments": "8 pages, 3 figures, camera ready version of article accepted to K-CAP\n  2019, Marina del Rey, California, United States", "journal-ref": "K-CAP 2019, Nov. 19 - 21, 2019, Marina del Rey, CA, USA", "doi": "10.1145/3360901.3364432", "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, several studies have explored methods for using KG embedding to\nanswer logical queries. These approaches either treat embedding learning and\nquery answering as two separated learning tasks, or fail to deal with the\nvariability of contributions from different query paths. We proposed to\nleverage a graph attention mechanism to handle the unequal contribution of\ndifferent query paths. However, commonly used graph attention assumes that the\ncenter node embedding is provided, which is unavailable in this task since the\ncenter node is to be predicted. To solve this problem we propose a multi-head\nattention-based end-to-end logical query answering model, called Contextual\nGraph Attention model(CGA), which uses an initial neighborhood aggregation\nlayer to generate the center embedding, and the whole model is trained jointly\non the original KG structure as well as the sampled query-answer pairs. We also\nintroduce two new datasets, DB18 and WikiGeo19, which are rather large in size\ncompared to the existing datasets and contain many more relation types, and use\nthem to evaluate the performance of the proposed model. Our result shows that\nthe proposed CGA with fewer learnable parameters consistently outperforms the\nbaseline models on both datasets as well as Bio dataset.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 20:20:48 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Mai", "Gengchen", ""], ["Janowicz", "Krzysztof", ""], ["Yan", "Bo", ""], ["Zhu", "Rui", ""], ["Cai", "Ling", ""], ["Lao", "Ni", ""]]}, {"id": "1910.00087", "submitter": "Longsheng Jiang", "authors": "Longsheng Jiang, Yue Wang", "title": "Respect Your Emotion: Human-Multi-Robot Teaming based on Regret Decision\n  Model", "comments": "8 pages, 4 figures, conference", "journal-ref": "IEEE 15th International Conference on Automation Science and\n  Engineering (CASE), Vancouver, BC, Canada, August 22-26, 2019", "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Often, when modeling human decision-making behaviors in the context of\nhuman-robot teaming, the emotion aspect of human is ignored. Nevertheless, the\ninfluence of emotion, in some cases, is not only undeniable but beneficial.\nThis work studies the human-like characteristics brought by regret emotion in\none-human-multi-robot teaming for the application of domain search. In such\napplication, the task management load is outsourced to the robots to reduce the\nhuman's workload, freeing the human to do more important work. The regret\ndecision model is first used by each robot for deciding whether to request\nhuman service, then is extended for optimally queuing the requests from\nmultiple robots. For the movement of the robots in the domain search, we\ndesigned a path planning algorithm based on dynamic programming for each robot.\nThe simulation shows that the human-like characteristics, namely, risk-seeking\nand risk-aversion, indeed bring some appealing effects for balancing the\nworkload and performance in the human-multi-robot team.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 18:21:42 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Jiang", "Longsheng", ""], ["Wang", "Yue", ""]]}, {"id": "1910.00089", "submitter": "Marco Pegoraro", "authors": "Marco Pegoraro and Wil M.P. van der Aalst", "title": "Mining Uncertain Event Data in Process Mining", "comments": "18 pages, 7 figures, 3 tables", "journal-ref": "International Conference on Process Mining (ICPM), Aachen,\n  Germany, 2019, pp. 89-96", "doi": "10.1109/ICPM.2019.00023", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, more and more process data are automatically recorded by\ninformation systems, and made available in the form of event logs. Process\nmining techniques enable process-centric analysis of data, including\nautomatically discovering process models and checking if event data conform to\na certain model. In this paper we analyze the previously unexplored setting of\nuncertain event logs: logs where quantified uncertainty is recorded together\nwith the corresponding data. We define a taxonomy of uncertain event logs and\nmodels, and we examine the challenges that uncertainty poses on process\ndiscovery and conformance checking. Finally, we show how upper and lower bounds\nfor conformance can be obtained aligning an uncertain trace onto a regular\nprocess model.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 08:38:52 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 09:28:00 GMT"}, {"version": "v3", "created": "Mon, 9 Mar 2020 15:53:22 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Pegoraro", "Marco", ""], ["van der Aalst", "Wil M. P.", ""]]}, {"id": "1910.00091", "submitter": "Wendelin B\\\"ohmer", "authors": "Wendelin B\\\"ohmer, Vitaly Kurin, Shimon Whiteson", "title": "Deep Coordination Graphs", "comments": "Accepted at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the deep coordination graph (DCG) for collaborative\nmulti-agent reinforcement learning. DCG strikes a flexible trade-off between\nrepresentational capacity and generalization by factoring the joint value\nfunction of all agents according to a coordination graph into payoffs between\npairs of agents. The value can be maximized by local message passing along the\ngraph, which allows training of the value function end-to-end with Q-learning.\nPayoff functions are approximated with deep neural networks that employ\nparameter sharing and low-rank approximations to significantly improve sample\nefficiency. We show that DCG can solve predator-prey tasks that highlight the\nrelative overgeneralization pathology, as well as challenging StarCraft II\nmicromanagement tasks.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 17:25:41 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 16:13:15 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2020 16:12:47 GMT"}, {"version": "v4", "created": "Tue, 23 Jun 2020 17:28:04 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["B\u00f6hmer", "Wendelin", ""], ["Kurin", "Vitaly", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1910.00101", "submitter": "Maymoonah Toubeh", "authors": "Maymoonah Toubeh and Pratap Tokekar", "title": "Risk-Aware Planning by Confidence Estimation using Deep Learning-Based\n  Perception", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes the use of Bayesian approximations of uncertainty from\ndeep learning in a robot planner, showing that this produces more cautious\nactions in safety-critical scenarios. The case study investigated is motivated\nby a setup where an aerial robot acts as a \"scout\" for a ground robot. This is\nuseful when the below area is unknown or dangerous, with applications in space\nexploration, military, or search-and-rescue. Images taken from the aerial view\nare used to provide a less obstructed map to guide the navigation of the robot\non the ground. Experiments are conducted using a deep learning semantic image\nsegmentation, followed by a path planner based on the resulting cost map, to\nprovide an empirical analysis of the proposed method. A comparison with similar\napproaches is presented to portray the usefulness of certain techniques, or\nvariations within a technique, in similar experimental settings. The method is\nanalyzed to assess the impact of variations in the uncertainty extraction, as\nwell as the absence of an uncertainty metric, on the overall system with the\nuse of a defined metric which measures surprise to the planner. The analysis is\nperformed on multiple datasets, showing a similar trend of lower surprise when\nuncertainty information is incorporated in the planning, given threshold values\nof the hyperparameters in the uncertainty extraction have been met. We find\nthat taking uncertainty into account leads to paths that could be 18% less\nrisky on an average.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 15:20:41 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Toubeh", "Maymoonah", ""], ["Tokekar", "Pratap", ""]]}, {"id": "1910.00105", "submitter": "Kuno Kim", "authors": "Kuno Kim, Yihong Gu, Jiaming Song, Shengjia Zhao, Stefano Ermon", "title": "Domain Adaptive Imitation Learning", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the question of how to imitate tasks across domains with\ndiscrepancies such as embodiment, viewpoint, and dynamics mismatch. Many prior\nworks require paired, aligned demonstrations and an additional RL step that\nrequires environment interactions. However, paired, aligned demonstrations are\nseldom obtainable and RL procedures are expensive. We formalize the Domain\nAdaptive Imitation Learning (DAIL) problem, which is a unified framework for\nimitation learning in the presence of viewpoint, embodiment, and dynamics\nmismatch. Informally, DAIL is the process of learning how to perform a task\noptimally, given demonstrations of the task in a distinct domain. We propose a\ntwo step approach to DAIL: alignment followed by adaptation. In the alignment\nstep we execute a novel unsupervised MDP alignment algorithm, Generative\nAdversarial MDP Alignment (GAMA), to learn state and action correspondences\nfrom \\emph{unpaired, unaligned} demonstrations. In the adaptation step we\nleverage the correspondences to zero-shot imitate tasks across domains. To\ndescribe when DAIL is feasible via alignment and adaptation, we introduce a\ntheory of MDP alignability. We experimentally evaluate GAMA against baselines\nin embodiment, viewpoint, and dynamics mismatch scenarios where aligned\ndemonstrations don't exist and show the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 20:58:55 GMT"}, {"version": "v2", "created": "Sat, 18 Jul 2020 18:36:20 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Kim", "Kuno", ""], ["Gu", "Yihong", ""], ["Song", "Jiaming", ""], ["Zhao", "Shengjia", ""], ["Ermon", "Stefano", ""]]}, {"id": "1910.00120", "submitter": "Dimitri Bertsekas", "authors": "Dimitri Bertsekas", "title": "Multiagent Rollout Algorithms and Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider finite and infinite horizon dynamic programming problems, where\nthe control at each stage consists of several distinct decisions, each one made\nby one of several agents. We introduce an approach, whereby at every stage,\neach agent's decision is made by executing a local rollout algorithm that uses\na base policy, together with some coordinating information from the other\nagents. The amount of local computation required at every stage by each agent\nis independent of the number of agents, while the amount of total computation\n(over all agents) grows linearly with the number of agents. By contrast, with\nthe standard rollout algorithm, the amount of total computation grows\nexponentially with the number of agents. Despite the drastic reduction in\nrequired computation, we show that our algorithm has the fundamental cost\nimprovement property of rollout: an improved performance relative to the base\npolicy. We also discuss possibilities to improve further the method's\ncomputational efficiency through limited agent coordination and parallelization\nof the agents' computations. Finally, we explore related approximate policy\niteration algorithms for infinite horizon problems, and we prove that the cost\nimprovement property steers the algorithm towards convergence to an\nagent-by-agent optimal policy.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 21:39:07 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 11:47:13 GMT"}, {"version": "v3", "created": "Mon, 13 Apr 2020 20:55:05 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Bertsekas", "Dimitri", ""]]}, {"id": "1910.00128", "submitter": "Toby Walsh", "authors": "Toby Walsh", "title": "SAT vs CSP: a commentary", "comments": "See https://freuder.wordpress.com/cp-anniversary-project/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2000, I published a relatively comprehensive study of mappings between\npropositional satisfiability (SAT) and constraint satisfaction problems (CSPs)\n[Wal00]. I analysed four different mappings of SAT problems into CSPs, and two\nof CSPs into SAT problems. For each mapping, I compared the impact of achieving\narc-consistency on the CSP with unit propagation on the corresponding SAT\nproblems, and lifted these results to CSP algorithms that maintain (some level\nof ) arc-consistency during search like FC and MAC, and to the Davis- Putnam\nprocedure (which performs unit propagation at each search node). These results\nhelped provide some insight into the relationship between propositional\nsatisfiability and constraint satisfaction that set the scene for an important\nand valuable body of work that followed. I discuss here what prompted the\npaper, and what followed.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 13:17:17 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Walsh", "Toby", ""]]}, {"id": "1910.00192", "submitter": "Denis Newman-Griffis", "authors": "Denis Newman-Griffis and Eric Fosler-Lussier", "title": "Writing habits and telltale neighbors: analyzing clinical concept usage\n  patterns with sublanguage embeddings", "comments": "LOUHI 2019 (co-located with EMNLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language processing techniques are being applied to increasingly\ndiverse types of electronic health records, and can benefit from in-depth\nunderstanding of the distinguishing characteristics of medical document types.\nWe present a method for characterizing the usage patterns of clinical concepts\namong different document types, in order to capture semantic differences beyond\nthe lexical level. By training concept embeddings on clinical documents of\ndifferent types and measuring the differences in their nearest neighborhood\nstructures, we are able to measure divergences in concept usage while\ncorrecting for noise in embedding learning. Experiments on the MIMIC-III corpus\ndemonstrate that our approach captures clinically-relevant differences in\nconcept usage and provides an intuitive way to explore semantic characteristics\nof clinical document collections.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 04:07:15 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Newman-Griffis", "Denis", ""], ["Fosler-Lussier", "Eric", ""]]}, {"id": "1910.00193", "submitter": "Sam Ganzfried", "authors": "Sam Ganzfried, Conner Laughlin, Charles Morefield", "title": "Parallel Algorithm for Approximating Nash Equilibrium in Multiplayer\n  Stochastic Games with Application to Naval Strategic Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.CR cs.MA econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world domains contain multiple agents behaving strategically with\nprobabilistic transitions and uncertain (potentially infinite) duration. Such\nsettings can be modeled as stochastic games. While algorithms have been\ndeveloped for solving (i.e., computing a game-theoretic solution concept such\nas Nash equilibrium) two-player zero-sum stochastic games, research on\nalgorithms for non-zero-sum and multiplayer stochastic games is limited. We\npresent a new algorithm for these settings, which constitutes the first\nparallel algorithm for multiplayer stochastic games. We present experimental\nresults on a 4-player stochastic game motivated by a naval strategic planning\nscenario, showing that our algorithm is able to quickly compute strategies\nconstituting Nash equilibrium up to a very small degree of approximation error.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 04:08:14 GMT"}, {"version": "v2", "created": "Sat, 25 Jan 2020 02:07:18 GMT"}, {"version": "v3", "created": "Fri, 21 Feb 2020 03:35:08 GMT"}, {"version": "v4", "created": "Fri, 13 Mar 2020 18:54:19 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Ganzfried", "Sam", ""], ["Laughlin", "Conner", ""], ["Morefield", "Charles", ""]]}, {"id": "1910.00211", "submitter": "Harshad Khadilkar", "authors": "Hardik Meisheri and Vinita Baniwal and Nazneen N Sultana and Balaraman\n  Ravindran and Harshad Khadilkar", "title": "Reinforcement Learning for Multi-Objective Optimization of Online\n  Decisions in High-Dimensional Systems", "comments": "22 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a purely data-driven solution to a class of sequential\ndecision-making problems with a large number of concurrent online decisions,\nwith applications to computing systems and operations research. We assume that\nwhile the micro-level behaviour of the system can be broadly captured by\nanalytical expressions or simulation, the macro-level or emergent behaviour is\ncomplicated by non-linearity, constraints, and stochasticity. If we represent\nthe set of concurrent decisions to be computed as a vector, each element of the\nvector is assumed to be a continuous variable, and the number of such elements\nis arbitrarily large and variable from one problem instance to another. We\nfirst formulate the decision-making problem as a canonical reinforcement\nlearning (RL) problem, which can be solved using purely data-driven techniques.\nWe modify a standard approach known as advantage actor critic (A2C) to ensure\nits suitability to the problem at hand, and compare its performance to that of\nbaseline approaches on the specific instance of a multi-product inventory\nmanagement task. The key modifications include a parallelised formulation of\nthe decision-making task, and a training procedure that explicitly recognises\nthe quantitative relationship between different decisions. We also present\nexperimental results probing the learned policies, and their robustness to\nvariations in the data.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 06:16:48 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Meisheri", "Hardik", ""], ["Baniwal", "Vinita", ""], ["Sultana", "Nazneen N", ""], ["Ravindran", "Balaraman", ""], ["Khadilkar", "Harshad", ""]]}, {"id": "1910.00246", "submitter": "Phuc Nguyen Tri", "authors": "Phuc Nguyen and Natthawut Kertkeidkachorn and Ryutaro Ichise and\n  Hideaki Takeda", "title": "MTab: Matching Tabular Data to Knowledge Graph using Probability Models", "comments": "SemTab 2019. MTab", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents the design of our system, namely MTab, for Semantic Web\nChallenge on Tabular Data to Knowledge Graph Matching (SemTab 2019). MTab\ncombines the voting algorithm and the probability models to solve critical\nproblems of the matching tasks. Results on SemTab 2019 show that MTab obtains\npromising performance for the three matching tasks.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 08:20:56 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 02:55:29 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Nguyen", "Phuc", ""], ["Kertkeidkachorn", "Natthawut", ""], ["Ichise", "Ryutaro", ""], ["Takeda", "Hideaki", ""]]}, {"id": "1910.00290", "submitter": "Marco Valentino", "authors": "Mokanarangan Thayaparan, Marco Valentino, Viktor Schlegel, Andre\n  Freitas", "title": "Identifying Supporting Facts for Multi-hop Question Answering with\n  Document Graph Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in reading comprehension have resulted in models that surpass\nhuman performance when the answer is contained in a single, continuous passage\nof text. However, complex Question Answering (QA) typically requires multi-hop\nreasoning - i.e. the integration of supporting facts from different sources, to\ninfer the correct answer. This paper proposes Document Graph Network (DGN), a\nmessage passing architecture for the identification of supporting facts over a\ngraph-structured representation of text. The evaluation on HotpotQA shows that\nDGN obtains competitive results when compared to a reading comprehension\nbaseline operating on raw text, confirming the relevance of structured\nrepresentations for supporting multi-hop reasoning.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 10:26:08 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Thayaparan", "Mokanarangan", ""], ["Valentino", "Marco", ""], ["Schlegel", "Viktor", ""], ["Freitas", "Andre", ""]]}, {"id": "1910.00293", "submitter": "Bruno Yun", "authors": "C\\'esar Prout\\'e, Bruno Yun, Madalina Croitoru", "title": "Distance-Based Approaches to Repair Semantics in Ontology-based Data\n  Access", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the presence of inconsistencies, repair techniques thrive to restore\nconsistency by reasoning with several repairs. However, since the number of\nrepairs can be large, standard inconsistent tolerant semantics usually yield\nfew answers. In this paper, we use the notion of syntactic distance between\nrepairs following the intuition that it can allow us to cluster some repairs\n\"close\" to each other. In this way, we propose a generic framework to answer\nqueries in a more personalise fashion.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 10:28:32 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Prout\u00e9", "C\u00e9sar", ""], ["Yun", "Bruno", ""], ["Croitoru", "Madalina", ""]]}, {"id": "1910.00309", "submitter": "Marek Szyku{\\l}a", "authors": "Jakub Kowalski, Maksymilian Mika, Jakub Sutowicz, Marek Szyku{\\l}a", "title": "A note on the empirical comparison of RBG and Ludii", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an experimental comparison of the efficiency of three General Game\nPlaying systems in their current versions: Regular Boardgames (RBG 1.0),\nLudii~0.3.0, and a Game Description Language (GDL) propnet. We show that in\ngeneral, RBG is currently the fastest GGP system. For example, for chess, we\ndemonstrate that RBG is about 37 times faster than Ludii, and Ludii is about 3\ntimes slower than a GDL propnet. Referring to the recent comparison [An\nEmpirical Evaluation of Two General Game Systems: Ludii and RBG, CoG 2019], we\nshow evidences that the benchmark presented there contains a number of\nsignificant flaws that lead to wrong conclusions.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 11:24:02 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 17:52:21 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Kowalski", "Jakub", ""], ["Mika", "Maksymilian", ""], ["Sutowicz", "Jakub", ""], ["Szyku\u0142a", "Marek", ""]]}, {"id": "1910.00334", "submitter": "Ana Roxin", "authors": "Nicolas Bus (CSTB), Ana Roxin (Le2i), Guillaume Picinbono (CSTB),\n  Muhammad Fahad (CSTB)", "title": "Towards French Smart Building Code: Compliance Checking Based on\n  Semantic Rules", "comments": null, "journal-ref": "Linked Data for Architecture and Construction (LDAC'2018), Jun\n  2018, Londres, United Kingdom", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manually checking models for compliance against building regulation is a\ntime-consuming task for architects and construction engineers. There is thus a\nneed for algorithms that process information from construction projects and\nreport non-compliant elements. Still automated code-compliance checking raises\nseveral obstacles. Building regulations are usually published as human readable\ntexts and their content is often ambiguous or incomplete. Also, the vocabulary\nused for expressing such regulations is very different from the vocabularies\nused to express Building Information Models (BIM). Furthermore, the high level\nof details associated to BIM-contained geometries induces complex calculations.\nFinally, the level of complexity of the IFC standard also hinders the\nautomation of IFC processing tasks. Model chart, formal rules and\npre-processors approach allows translating construction regulations into\nsemantic queries. We further demonstrate the usefulness of this approach\nthrough several use cases. We argue our approach is a step forward in bridging\nthe gap between regulation texts and automated checking algorithms. Finally\nwith the recent building ontology BOT recommended by the W3C Linked Building\nData Community Group, we identify perspectives for standardizing and extending\nour approach.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 12:18:42 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Bus", "Nicolas", "", "CSTB"], ["Roxin", "Ana", "", "Le2i"], ["Picinbono", "Guillaume", "", "CSTB"], ["Fahad", "Muhammad", "", "CSTB"]]}, {"id": "1910.00399", "submitter": "David Isele", "authors": "David Isele, Alireza Nakhaei, and Kikuo Fujimura", "title": "Safe Reinforcement Learning on Autonomous Vehicles", "comments": null, "journal-ref": "IROS 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There have been numerous advances in reinforcement learning, but the\ntypically unconstrained exploration of the learning process prevents the\nadoption of these methods in many safety critical applications. Recent work in\nsafe reinforcement learning uses idealized models to achieve their guarantees,\nbut these models do not easily accommodate the stochasticity or\nhigh-dimensionality of real world systems. We investigate how prediction\nprovides a general and intuitive framework to constraint exploration, and show\nhow it can be used to safely learn intersection handling behaviors on an\nautonomous vehicle.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 20:36:28 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Isele", "David", ""], ["Nakhaei", "Alireza", ""], ["Fujimura", "Kikuo", ""]]}, {"id": "1910.00412", "submitter": "Eric M\\\"uller-Budack", "authors": "Eric M\\\"uller-Budack, Jonas Theiner, Robert Rein, Ralph Ewerth", "title": "\"Does 4-4-2 exist?\" -- An Analytics Approach to Understand and Classify\n  Football Team Formations in Single Match Situations", "comments": "Accepted at MMSports 2019 (Workshop of ACM Multimedia 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The chances to win a football match can be significantly increased if the\nright tactic is chosen and the behavior of the opposite team is well\nanticipated. For this reason, every professional football club employs a team\nof game analysts. However, at present game performance analysis is done\nmanually and therefore highly time-consuming. Consequently, automated tools to\nsupport the analysis process are required. In this context, one of the main\ntasks is to summarize team formations by patterns such as 4-4-2. In this paper,\nwe introduce an analytics approach that automatically classifies and visualizes\nthe team formation based on the players' position data. We focus on single\nmatch situations instead of complete halftimes or matches to provide a more\ndetailed analysis. A detailed analysis of individual match situations depending\non ball possession and match segment length is provided. For this purpose, a\nvisual summary is utilized that summarizes the team formation in a match\nsegment. An expert annotation study is conducted that demonstrates 1) the\ncomplexity of the task and 2) the usefulness of the visualization of single\nsituations to understand team formations. The suggested classification approach\noutperforms existing methods for formation classification. In particular, our\napproach gives insights about the shortcomings of using patterns like 4-4-2 to\ndescribe team formations.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 16:14:46 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["M\u00fcller-Budack", "Eric", ""], ["Theiner", "Jonas", ""], ["Rein", "Robert", ""], ["Ewerth", "Ralph", ""]]}, {"id": "1910.00413", "submitter": "Mieczys{\\l}aw K{\\l}opotek", "authors": "Mieczys{\\l}aw A. K{\\l}opotek", "title": "A Note On $k$-Means Probabilistic Poverty", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is proven, by example, that the version of $k$-means with random\ninitialization does not have the property \\emph{probabilistic $k$-richness}.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 05:14:43 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["K\u0142opotek", "Mieczys\u0142aw A.", ""]]}, {"id": "1910.00462", "submitter": "Ivan Donadello", "authors": "Ivan Donadello and Luciano Serafini", "title": "Compensating Supervision Incompleteness with Prior Knowledge in Semantic\n  Image Interpretation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic Image Interpretation is the task of extracting a structured semantic\ndescription from images. This requires the detection of visual relationships:\ntriples (subject,relation,object) describing a semantic relation between a\nsubject and an object. A pure supervised approach to visual relationship\ndetection requires a complete and balanced training set for all the possible\ncombinations of (subject, relation, object). However, such training sets are\nnot available and would require a prohibitive human effort. This implies the\nability of predicting triples which do not appear in the training set. This\nproblem is called zero-shot learning. State-of-the-art approaches to zero-shot\nlearning exploit similarities among relationships in the training set or\nexternal linguistic knowledge. In this paper, we perform zero-shot learning by\nusing Logic Tensor Networks, a novel Statistical Relational Learning framework\nthat exploits both the similarities with other seen relationships and\nbackground knowledge, expressed with logical constraints between subjects,\nrelations and objects. The experiments on the Visual Relationship Dataset show\nthat the use of logical constraints outperforms the current methods. This\nimplies that background knowledge can be used to alleviate the incompleteness\nof training sets.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 14:56:08 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Donadello", "Ivan", ""], ["Serafini", "Luciano", ""]]}, {"id": "1910.00505", "submitter": "G\\\"okberk Ko\\c{c}ak", "authors": "G\\\"okberk Ko\\c{c}ak, \\\"Ozg\\\"ur Akg\\\"un, Tias Guns, Ian Miguel", "title": "Towards Improving Solution Dominance with Incomparability Conditions: A\n  case-study using Generator Itemset Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Finding interesting patterns is a challenging task in data mining. Constraint\nbased mining is a well-known approach to this, and one for which constraint\nprogramming has been shown to be a well-suited and generic framework. Dominance\nprogramming has been proposed as an extension that can capture an even wider\nclass of constraint-based mining problems, by allowing to compare relations\nbetween patterns. In this paper, in addition to specifying a dominance\nrelation, we introduce the ability to specify an incomparability condition.\nUsing these two concepts we devise a generic framework that can do a batch-wise\nsearch that avoids checking incomparable solutions. We extend the ESSENCE\nlanguage and underlying modelling pipeline to support this. We use generator\nitemset mining problem as a test case and give a declarative specification for\nthat. We also present preliminary experimental results on this specific problem\nclass with a CP solver backend to show that using the incomparability condition\nduring search can improve the efficiency of dominance programming and reduces\nthe need for post-processing to filter dominated solutions.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 15:58:13 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Ko\u00e7ak", "G\u00f6kberk", ""], ["Akg\u00fcn", "\u00d6zg\u00fcr", ""], ["Guns", "Tias", ""], ["Miguel", "Ian", ""]]}, {"id": "1910.00528", "submitter": "Shruti Mishra", "authors": "Shruti Mishra, Abbas Abdolmaleki, Arthur Guez, Piotr Trochim, Doina\n  Precup", "title": "Augmenting learning using symmetry in a biologically-inspired domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Invariances to translation, rotation and other spatial transformations are a\nhallmark of the laws of motion, and have widespread use in the natural sciences\nto reduce the dimensionality of systems of equations. In supervised learning,\nsuch as in image classification tasks, rotation, translation and scale\ninvariances are used to augment training datasets. In this work, we use data\naugmentation in a similar way, exploiting symmetry in the quadruped domain of\nthe DeepMind control suite (Tassa et al. 2018) to add to the trajectories\nexperienced by the actor in the actor-critic algorithm of Abdolmaleki et al.\n(2018). In a data-limited regime, the agent using a set of experiences\naugmented through symmetry is able to learn faster. Our approach can be used to\ninject knowledge of invariances in the domain and task to augment learning in\nrobots, and more generally, to speed up learning in realistic robotics\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 16:29:14 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Mishra", "Shruti", ""], ["Abdolmaleki", "Abbas", ""], ["Guez", "Arthur", ""], ["Trochim", "Piotr", ""], ["Precup", "Doina", ""]]}, {"id": "1910.00571", "submitter": "Felix Hill Mr", "authors": "Felix Hill, Andrew Lampinen, Rosalia Schneider, Stephen Clark, Matthew\n  Botvinick, James L. McClelland and Adam Santoro", "title": "Environmental drivers of systematicity and generalization in a situated\n  agent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The question of whether deep neural networks are good at generalising beyond\ntheir immediate training experience is of critical importance for\nlearning-based approaches to AI. Here, we consider tests of out-of-sample\ngeneralisation that require an agent to respond to never-seen-before\ninstructions by manipulating and positioning objects in a 3D Unity simulated\nroom. We first describe a comparatively generic agent architecture that\nexhibits strong performance on these tests. We then identify three aspects of\nthe training regime and environment that make a significant difference to its\nperformance: (a) the number of object/word experiences in the training set; (b)\nthe visual invariances afforded by the agent's perspective, or frame of\nreference; and (c) the variety of visual input inherent in the perceptual\naspect of the agent's perception. Our findings indicate that the degree of\ngeneralisation that networks exhibit can depend critically on particulars of\nthe environment in which a given task is instantiated. They further suggest\nthat the propensity for neural networks to generalise in systematic ways may\nincrease if, like human children, those networks have access to many frames of\nrichly varying, multi-modal observations as they learn.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 17:51:45 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 12:06:37 GMT"}, {"version": "v3", "created": "Tue, 4 Feb 2020 13:02:19 GMT"}, {"version": "v4", "created": "Wed, 19 Feb 2020 13:16:22 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Hill", "Felix", ""], ["Lampinen", "Andrew", ""], ["Schneider", "Rosalia", ""], ["Clark", "Stephen", ""], ["Botvinick", "Matthew", ""], ["McClelland", "James L.", ""], ["Santoro", "Adam", ""]]}, {"id": "1910.00584", "submitter": "Arpan Kusari", "authors": "Arpan Kusari", "title": "CWAE-IRL: Formulating a supervised approach to Inverse Reinforcement\n  Learning problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse reinforcement learning (IRL) is used to infer the reward function\nfrom the actions of an expert running a Markov Decision Process (MDP). A novel\napproach using variational inference for learning the reward function is\nproposed in this research. Using this technique, the intractable posterior\ndistribution of the continuous latent variable (the reward function in this\ncase) is analytically approximated to appear to be as close to the prior belief\nwhile trying to reconstruct the future state conditioned on the current state\nand action. The reward function is derived using a well-known deep generative\nmodel known as Conditional Variational Auto-encoder (CVAE) with Wasserstein\nloss function, thus referred to as Conditional Wasserstein Auto-encoder-IRL\n(CWAE-IRL), which can be analyzed as a combination of the backward and forward\ninference. This can then form an efficient alternative to the previous\napproaches to IRL while having no knowledge of the system dynamics of the\nagent. Experimental results on standard benchmarks such as objectworld and\npendulum show that the proposed algorithm can effectively learn the latent\nreward function in complex, high-dimensional environments.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 14:06:23 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Kusari", "Arpan", ""]]}, {"id": "1910.00610", "submitter": "Yi-Lin Tuan", "authors": "Yi-Lin Tuan, Yun-Nung Chen, Hung-yi Lee", "title": "DyKgChat: Benchmarking Dialogue Generation Grounding on Dynamic\n  Knowledge Graphs", "comments": "Accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven, knowledge-grounded neural conversation models are capable of\ngenerating more informative responses. However, these models have not yet\ndemonstrated that they can zero-shot adapt to updated, unseen knowledge graphs.\nThis paper proposes a new task about how to apply dynamic knowledge graphs in\nneural conversation model and presents a novel TV series conversation corpus\n(DyKgChat) for the task. Our new task and corpus aids in understanding the\ninfluence of dynamic knowledge graphs on responses generation. Also, we propose\na preliminary model that selects an output from two networks at each time step:\na sequence-to-sequence model (Seq2Seq) and a multi-hop reasoning model, in\norder to support dynamic knowledge graphs. To benchmark this new task and\nevaluate the capability of adaptation, we introduce several evaluation metrics\nand the experiments show that our proposed approach outperforms previous\nknowledge-grounded conversation models. The proposed corpus and model can\nmotivate the future research directions.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 18:29:08 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Tuan", "Yi-Lin", ""], ["Chen", "Yun-Nung", ""], ["Lee", "Hung-yi", ""]]}, {"id": "1910.00614", "submitter": "Murugeswari Issakkimuthu", "authors": "Murugeswari Issakkimuthu, Alan Fern, Prasad Tadepalli", "title": "The Choice Function Framework for Online Policy Improvement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are notable examples of online search improving over hand-coded or\nlearned policies (e.g. AlphaZero) for sequential decision making. It is not\nclear, however, whether or not policy improvement is guaranteed for many of\nthese approaches, even when given a perfect evaluation function and transition\nmodel. Indeed, simple counter examples show that seemingly reasonable online\nsearch procedures can hurt performance compared to the original policy. To\naddress this issue, we introduce the choice function framework for analyzing\nonline search procedures for policy improvement. A choice function specifies\nthe actions to be considered at every node of a search tree, with all other\nactions being pruned. Our main contribution is to give sufficient conditions\nfor stationary and non-stationary choice functions to guarantee that the value\nachieved by online search is no worse than the original policy. In addition, we\ndescribe a general parametric class of choice functions that satisfy those\nconditions and present an illustrative use case of the framework's empirical\nutility.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 18:41:55 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 16:35:38 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Issakkimuthu", "Murugeswari", ""], ["Fern", "Alan", ""], ["Tadepalli", "Prasad", ""]]}, {"id": "1910.00699", "submitter": "Yugandhar Sarkale", "authors": "Yugandhar Sarkale, Saeed Nozhati, Edwin K. P. Chong, Bruce R.\n  Ellingwood", "title": "Decision Automation for Electric Power Network Recovery", "comments": "Submitted to IEEE Transactions on Automation Science and Engineering\n  (13 pages and 6 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY math.OC stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Critical infrastructure systems such as electric power networks, water\nnetworks, and transportation systems play a major role in the welfare of any\ncommunity. In the aftermath of disasters, their recovery is of paramount\nimportance; orderly and efficient recovery involves the assignment of limited\nresources (a combination of human repair workers and machines) to repair\ndamaged infrastructure components. The decision maker must also deal with\nuncertainty in the outcome of the resource-allocation actions during recovery.\nThe manual assignment of resources seldom is optimal despite the expertise of\nthe decision maker because of the large number of choices and uncertainties in\nconsequences of sequential decisions. This combinatorial assignment problem\nunder uncertainty is known to be \\mbox{NP-hard}. We propose a novel decision\ntechnique that addresses the massive number of decision choices for large-scale\nreal-world problems; in addition, our method also features an experiential\nlearning component that adaptively determines the utilization of the\ncomputational resources based on the performance of a small number of choices.\nOur framework is closed-loop, and naturally incorporates all the attractive\nfeatures of such a decision-making system. In contrast to myopic approaches,\nwhich do not account for the future effects of the current choices, our\nmethodology has an anticipatory learning component that effectively\nincorporates \\emph{lookahead} into the solutions. To this end, we leverage the\ntheory of regression analysis, Markov decision processes (MDPs), multi-armed\nbandits, and stochastic models of community damage from natural disasters to\ndevelop a method for near-optimal recovery of communities. Our method\ncontributes to the general problem of MDPs with massive action spaces with\napplication to recovery of communities affected by hazards.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 22:30:02 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 16:59:33 GMT"}, {"version": "v3", "created": "Fri, 18 Oct 2019 22:53:35 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Sarkale", "Yugandhar", ""], ["Nozhati", "Saeed", ""], ["Chong", "Edwin K. P.", ""], ["Ellingwood", "Bruce R.", ""]]}, {"id": "1910.00714", "submitter": "Clebeson Santos Msc", "authors": "Clebeson Canuto, Plinio Moreno, Jorge Samatelo, Raquel Vassallo,\n  Jos\\'e Santos-Victor", "title": "Action Anticipation for Collaborative Environments: The Impact of\n  Contextual Information and Uncertainty-Based Prediction", "comments": "27 pages, 16 figures, Neurocomputing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To interact with humans in collaborative environments, machines need to be\nable to predict (i.e., anticipate) future events, and execute actions in a\ntimely manner. However, the observation of the human limb movements may not be\nsufficient to anticipate their actions unambiguously. In this work, we consider\ntwo additional sources of information (i.e., context) over time, gaze, movement\nand object information, and study how these additional contextual cues improve\nthe action anticipation performance. We address action anticipation as a\nclassification task, where the model takes the available information as the\ninput and predicts the most likely action. We propose to use the uncertainty\nabout each prediction as an online decision-making criterion for action\nanticipation. Uncertainty is modeled as a stochastic process applied to a\ntime-based neural network architecture, which improves the conventional\nclass-likelihood (i.e., deterministic) criterion. The main contributions of\nthis paper are four-fold: (i) We propose a novel and effective decision-making\ncriterion that can be used to anticipate actions even in situations of high\nambiguity; (ii) we propose a deep architecture that outperforms previous\nresults in the action anticipation task when using the Acticipate collaborative\ndataset; (iii) we show that contextual information is important to disambiguate\nthe interpretation of similar actions; and (iv) we also provide a formal\ndescription of three existing performance metrics that can be easily used to\nevaluate action anticipation models.Our results on the Acticipate dataset\nshowed the importance of contextual information and the uncertainty criterion\nfor action anticipation. We achieve an average accuracy of 98.75% in the\nanticipation task using only an average of 25% of observations.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 23:30:08 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 06:17:03 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Canuto", "Clebeson", ""], ["Moreno", "Plinio", ""], ["Samatelo", "Jorge", ""], ["Vassallo", "Raquel", ""], ["Santos-Victor", "Jos\u00e9", ""]]}, {"id": "1910.00722", "submitter": "Sudhir Sornapudi", "authors": "Sudhir Sornapudi, G. T. Brown, Zhiyun Xue, Rodney Long, Lisa Allen,\n  Sameer Antani", "title": "Comparing Deep Learning Models for Multi-cell Classification in\n  Liquid-based Cervical Cytology Images", "comments": "AMIA 2019 Annual Symposium, Washington DC", "journal-ref": "AMIA Annu Symp Proc. 2019 (2019) 820-827", "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Liquid-based cytology (LBC) is a reliable automated technique for the\nscreening of Papanicolaou (Pap) smear data. It is an effective technique for\ncollecting a majority of the cervical cells and aiding cytopathologists in\nlocating abnormal cells. Most methods published in the research literature rely\non accurate cell segmentation as a prior, which remains challenging due to a\nvariety of factors, e.g., stain consistency, presence of clustered cells, etc.\nWe propose a method for automatic classification of cervical slide images\nthrough generation of labeled cervical patch data and extracting deep\nhierarchical features by fine-tuning convolution neural networks, as well as a\nnovel graph-based cell detection approach for cellular level evaluation. The\nresults show that the proposed pipeline can classify images of both single cell\nand overlapping cells. The VGG-19 model is found to be the best at classifying\nthe cervical cytology patch data with 95 % accuracy under precision-recall\ncurve.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 00:20:23 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Sornapudi", "Sudhir", ""], ["Brown", "G. T.", ""], ["Xue", "Zhiyun", ""], ["Long", "Rodney", ""], ["Allen", "Lisa", ""], ["Antani", "Sameer", ""]]}, {"id": "1910.00767", "submitter": "Rohit K. Dubey Mr", "authors": "Rohit K. Dubey, Samuel S. Sohn, Christoph Hoelscher, Mubbasir Kapadia", "title": "Cognitive Agent Based Simulation Model For Improving Disaster Response\n  Procedures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the event of a disaster, saving human lives is of utmost importance. For\ndeveloping proper evacuation procedures and guidance systems, behavioural data\non how people respond during panic and stress is crucial. In the absence of\nreal human data on building evacuation, there is a need for a crowd simulator\nto model egress and decision-making under uncertainty. In this paper, we\npropose an agent-based simulation tool, which is grounded in human cognition\nand decision-making, for evaluating and improving the effectiveness of building\nevacuation procedures and guidance systems during a disaster. Specifically, we\npropose a predictive agent-wayfinding framework based on information theory\nthat is applied at intersections with variable route choices where it fuses N\ndynamic information sources. The proposed framework can be used to visualize\ntrajectories and prediction results (i.e., total evacuation time, number of\npeople evacuated) for different combinations of reinforcing or contradicting\ninformation sources (i.e., signage, crowd flow, familiarity, and spatial\nlayout). This tool can enable designers to recreate various disaster scenarios\nand generate simulation data for improving the evacuation procedures and\nexisting guidance systems.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 03:54:11 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Dubey", "Rohit K.", ""], ["Sohn", "Samuel S.", ""], ["Hoelscher", "Christoph", ""], ["Kapadia", "Mubbasir", ""]]}, {"id": "1910.00775", "submitter": "Taesup Kim", "authors": "Taesup Kim, Sungjin Ahn, Yoshua Bengio", "title": "Variational Temporal Abstraction", "comments": "Accepted in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a variational approach to learning and inference of temporally\nhierarchical structure and representation for sequential data. We propose the\nVariational Temporal Abstraction (VTA), a hierarchical recurrent state space\nmodel that can infer the latent temporal structure and thus perform the\nstochastic state transition hierarchically. We also propose to apply this model\nto implement the jumpy-imagination ability in imagination-augmented\nagent-learning in order to improve the efficiency of the imagination. In\nexperiments, we demonstrate that our proposed method can model 2D and 3D visual\nsequence datasets with interpretable temporal structure discovery and that its\napplication to jumpy imagination enables more efficient agent-learning in a 3D\nnavigation task.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 04:37:23 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Kim", "Taesup", ""], ["Ahn", "Sungjin", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1910.00861", "submitter": "Wangjin Lee", "authors": "Wangjin Lee, Hyeryun Park, Jooyoung Yoon, Kyeongmo Kim, and Jinwook\n  Choi", "title": "Clinical Text Generation through Leveraging Medical Concept and\n  Relations", "comments": "This is a revised version of one uploaded in openreview.net\n  (https://openreview.net/forum?id=Skg6L9ZTpV)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With a neural sequence generation model, this study aims to develop a method\nof writing the patient clinical texts given a brief medical history. As a\nproof-of-a-concept, we have demonstrated that it can be workable to use medical\nconcept embedding in clinical text generation. Our model was based on the\nSequence-to-Sequence architecture and trained with a large set of de-identified\nclinical text data. The quantitative result shows that our concept embedding\nmethod decreased the perplexity of the baseline architecture. Also, we discuss\nthe analyzed results from a human evaluation performed by medical doctors.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 10:17:28 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Lee", "Wangjin", ""], ["Park", "Hyeryun", ""], ["Yoon", "Jooyoung", ""], ["Kim", "Kyeongmo", ""], ["Choi", "Jinwook", ""]]}, {"id": "1910.01047", "submitter": "Markus Hecher", "authors": "Johannes Klaus Fichte, Markus Hecher, Andreas Pfandler", "title": "Lower Bounds for QBFs of Bounded Treewidth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI cs.DM cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of deciding the validity (QSAT) of quantified Boolean formulas\n(QBF) is a vivid research area in both theory and practice. In the field of\nparameterized algorithmics, the well-studied graph measure treewidth turned out\nto be a successful parameter. A well-known result by Chen in parameterized\ncomplexity is that QSAT when parameterized by the treewidth of the primal graph\nof the input formula together with the quantifier depth of the formula is\nfixed-parameter tractable. More precisely, the runtime of such an algorithm is\npolynomial in the formula size and exponential in the treewidth, where the\nexponential function in the treewidth is a tower, whose height is the\nquantifier depth. A natural question is whether one can significantly improve\nthese results and decrease the tower while assuming the Exponential Time\nHypothesis (ETH). In the last years, there has been a growing interest in the\nquest of establishing lower bounds under ETH, showing mostly problem-specific\nlower bounds up to the third level of the polynomial hierarchy. Still, an\nimportant question is to settle this as general as possible and to cover the\nwhole polynomial hierarchy. In this work, we show lower bounds based on the ETH\nfor arbitrary QBFs parameterized by treewidth (and quantifier depth). More\nformally, we establish lower bounds for QSAT and treewidth, namely, that under\nETH there cannot be an algorithm that solves QSAT of quantifier depth i in\nruntime significantly better than i-fold exponential in the treewidth and\npolynomial in the input size. In doing so, we provide a versatile reduction\ntechnique to compress treewidth that encodes the essence of dynamic programming\non arbitrary tree decompositions. Further, we describe a general methodology\nfor a more fine-grained analysis of problems parameterized by treewidth that\nare at higher levels of the polynomial hierarchy.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 16:09:22 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 21:05:13 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Fichte", "Johannes Klaus", ""], ["Hecher", "Markus", ""], ["Pfandler", "Andreas", ""]]}, {"id": "1910.01055", "submitter": "Srivatsan Krishnan", "authors": "Maximilian Lam, Sharad Chitlangia, Srivatsan Krishnan, Zishen Wan,\n  Gabriel Barth-Maron, Aleksandra Faust, Vijay Janapa Reddi", "title": "Quantized Reinforcement Learning (QUARL)", "comments": "Equal contribution from first three authors Updating the manuscript\n  with ActorQ results with Deepmind's ACME", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has achieved significant milestones, however, the\ncomputational demands of reinforcement learning training and inference remain\nsubstantial. Quantization is an effective method to reduce the computational\noverheads of neural networks, though in the context of reinforcement learning,\nit is unknown whether quantization's computational benefits outweigh the\naccuracy costs introduced by the corresponding quantization error. To quantify\nthis tradeoff we perform a broad study applying quantization to reinforcement\nlearning. We apply standard quantization techniques such as post-training\nquantization (PTQ) and quantization aware training (QAT) to a comprehensive set\nof reinforcement learning tasks (Atari, Gym), algorithms (A2C, DDPG, DQN, D4PG,\nPPO), and models (MLPs, CNNs) and show that policies may be quantized to 8-bits\nwithout degrading reward, enabling significant inference speedups on\nresource-constrained edge devices. Motivated by the effectiveness of standard\nquantization techniques on reinforcement learning policies, we introduce a\nnovel quantization algorithm, \\textit{ActorQ}, for quantized actor-learner\ndistributed reinforcement learning training. By leveraging full precision\noptimization on the learner and quantized execution on the actors,\n\\textit{ActorQ} enables 8-bit inference while maintaining convergence. We\ndevelop a system for quantized reinforcement learning training around\n\\textit{ActorQ} and demonstrate end to end speedups of $>$ 1.5 $\\times$ - 2.5\n$\\times$ over full precision training on a range of tasks (Deepmind Control\nSuite). Finally, we break down the various runtime costs of distributed\nreinforcement learning training (such as communication time, inference time,\nmodel load time, etc) and evaluate the effects of quantization on these system\nattributes.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 16:22:29 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 21:44:52 GMT"}, {"version": "v3", "created": "Sat, 7 Dec 2019 00:57:49 GMT"}, {"version": "v4", "created": "Mon, 18 Jan 2021 20:05:26 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Lam", "Maximilian", ""], ["Chitlangia", "Sharad", ""], ["Krishnan", "Srivatsan", ""], ["Wan", "Zishen", ""], ["Barth-Maron", "Gabriel", ""], ["Faust", "Aleksandra", ""], ["Reddi", "Vijay Janapa", ""]]}, {"id": "1910.01062", "submitter": "Chen Tessler", "authors": "Chen Tessler, Nadav Merlis and Shie Mannor", "title": "Stabilizing Deep Reinforcement Learning with Conservative Updates", "comments": "Under review at IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, advances in deep learning have enabled the application of\nreinforcement learning algorithms in complex domains. However, they lack the\ntheoretical guarantees which are present in the tabular setting and suffer from\nmany stability and reproducibility problems \\citep{henderson2018deep}. In this\nwork, we suggest a simple approach for improving stability and providing\nprobabilistic performance improvement in off-policy actor-critic deep\nreinforcement learning regimes. Experiments on continuous action spaces, in the\nMuJoCo control suite, show that our proposed method reduces the variance of the\nprocess and improves the overall performance.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 16:32:25 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 09:56:55 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Tessler", "Chen", ""], ["Merlis", "Nadav", ""], ["Mannor", "Shie", ""]]}, {"id": "1910.01075", "submitter": "Nan Rosemary Ke", "authors": "Nan Rosemary Ke, Olexa Bilaniuk, Anirudh Goyal, Stefan Bauer, Hugo\n  Larochelle, Bernhard Sch\\\"olkopf, Michael C. Mozer, Chris Pal, Yoshua Bengio", "title": "Learning Neural Causal Models from Unknown Interventions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Promising results have driven a recent surge of interest in continuous\noptimization methods for Bayesian network structure learning from observational\ndata. However, there are theoretical limitations on the identifiability of\nunderlying structures obtained from observational data alone. Interventional\ndata provides much richer information about the underlying data-generating\nprocess. However, the extension and application of methods designed for\nobservational data to include interventions is not straightforward and remains\nan open problem. In this paper we provide a general framework based on\ncontinuous optimization and neural networks to create models for the\ncombination of observational and interventional data. The proposed method is\neven applicable in the challenging and realistic case that the identity of the\nintervened upon variable is unknown. We examine the proposed method in the\nsetting of graph recovery both de novo and from a partially-known edge set. We\nestablish strong benchmark results on several structure learning tasks,\nincluding structure recovery of both synthetic graphs as well as standard\ngraphs from the Bayesian Network Repository.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 16:50:15 GMT"}, {"version": "v2", "created": "Sun, 23 Aug 2020 04:23:05 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Ke", "Nan Rosemary", ""], ["Bilaniuk", "Olexa", ""], ["Goyal", "Anirudh", ""], ["Bauer", "Stefan", ""], ["Larochelle", "Hugo", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Mozer", "Michael C.", ""], ["Pal", "Chris", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1910.01077", "submitter": "Konrad Zolna", "authors": "Konrad Zolna, Scott Reed, Alexander Novikov, Sergio Gomez Colmenarejo,\n  David Budden, Serkan Cabi, Misha Denil, Nando de Freitas, Ziyu Wang", "title": "Task-Relevant Adversarial Imitation Learning", "comments": "Accepted to CoRL 2020 (see presentation here:\n  https://youtu.be/ZgQvFGuEgFU )", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that a critical vulnerability in adversarial imitation is the\ntendency of discriminator networks to learn spurious associations between\nvisual features and expert labels. When the discriminator focuses on\ntask-irrelevant features, it does not provide an informative reward signal,\nleading to poor task performance. We analyze this problem in detail and propose\na solution that outperforms standard Generative Adversarial Imitation Learning\n(GAIL). Our proposed method, Task-Relevant Adversarial Imitation Learning\n(TRAIL), uses constrained discriminator optimization to learn informative\nrewards. In comprehensive experiments, we show that TRAIL can solve challenging\nrobotic manipulation tasks from pixels by imitating human operators without\naccess to any task rewards, and clearly outperforms comparable baseline\nimitation agents, including those trained via behaviour cloning and\nconventional GAIL.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 16:53:37 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 18:30:23 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Zolna", "Konrad", ""], ["Reed", "Scott", ""], ["Novikov", "Alexander", ""], ["Colmenarejo", "Sergio Gomez", ""], ["Budden", "David", ""], ["Cabi", "Serkan", ""], ["Denil", "Misha", ""], ["de Freitas", "Nando", ""], ["Wang", "Ziyu", ""]]}, {"id": "1910.01208", "submitter": "Lifeng Zhou", "authors": "Lifeng Zhou, Vasileios Tzoumas, George J. Pappas, and Pratap Tokekar", "title": "Distributed Attack-Robust Submodular Maximization for Multi-Robot\n  Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we design algorithms to protect swarm-robotics applications\nagainst attacks that result in robot removals. We focus on applications\nrequiring the robots to jointly select actions, e.g., which trajectory to\nfollow, among a set of available ones. Such applications are central in\nlarge-scale robotic applications, such as multi-robot motion planning for\ntarget tracking. But the current attack-robust algorithms are centralized. In\nthis paper, we propose a general-purpose distributed algorithm towards robust\noptimization at scale, with local communications only. We name it Distributed\nRobust Maximization (DRM). DRM proposes a divide-and-conquer approach that\ndistributively partitions the problem among cliques of robots. Then, the\ncliques optimize in parallel, independently of each other. We prove DRM\nachieves a close-to-optimal performance. We demonstrate DRM's performance in\nboth Gazebo and MATLAB simulations, in scenarios of active target tracking with\nswarms of robots. In the simulations, DRM achieves computational speed-ups,\nbeing 3-4 orders faster than the centralized algorithms; yet, it nearly matches\nthe tracking performance of the centralized counterparts. However, DRM\noverestimates the number of attacks in each clique. To amend this\nconservativeness of DRM, in this paper we also introduce an Improved\nDistributed Robust Maximization (IDRM) algorithm. IDRM infers the number of\nattacks in each clique less conservatively than DRM by leveraging 3-hop\nneighboring communications. We verify IDRM improves DRM's performance in\nsimulations.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 20:35:40 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 01:19:20 GMT"}, {"version": "v3", "created": "Sun, 1 Nov 2020 13:44:35 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Zhou", "Lifeng", ""], ["Tzoumas", "Vasileios", ""], ["Pappas", "George J.", ""], ["Tokekar", "Pratap", ""]]}, {"id": "1910.01215", "submitter": "Xingyou Song", "authors": "Xingyou Song, Wenbo Gao, Yuxiang Yang, Krzysztof Choromanski, Aldo\n  Pacchiano, Yunhao Tang", "title": "ES-MAML: Simple Hessian-Free Meta Learning", "comments": "Published as a conference paper in ICLR 2020. Code can be found in\n  http://github.com/google-research/google-research/tree/master/es_maml", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce ES-MAML, a new framework for solving the model agnostic meta\nlearning (MAML) problem based on Evolution Strategies (ES). Existing algorithms\nfor MAML are based on policy gradients, and incur significant difficulties when\nattempting to estimate second derivatives using backpropagation on stochastic\npolicies. We show how ES can be applied to MAML to obtain an algorithm which\navoids the problem of estimating second derivatives, and is also conceptually\nsimple and easy to implement. Moreover, ES-MAML can handle new types of\nnonsmooth adaptation operators, and other techniques for improving performance\nand estimation of ES methods become applicable. We show empirically that\nES-MAML is competitive with existing methods and often yields better adaptation\nwith fewer queries.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 19:28:33 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 20:39:22 GMT"}, {"version": "v3", "created": "Sat, 11 Jan 2020 15:30:11 GMT"}, {"version": "v4", "created": "Tue, 7 Jul 2020 15:49:16 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Song", "Xingyou", ""], ["Gao", "Wenbo", ""], ["Yang", "Yuxiang", ""], ["Choromanski", "Krzysztof", ""], ["Pacchiano", "Aldo", ""], ["Tang", "Yunhao", ""]]}, {"id": "1910.01240", "submitter": "Shresth Verma", "authors": "Shresth Verma, Haritha S. Nair, Gaurav Agarwal, Joydip Dhar, Anupam\n  Shukla", "title": "Deep Reinforcement Learning for Single-Shot Diagnosis and Adaptation in\n  Damaged Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotics has proved to be an indispensable tool in many industrial as well as\nsocial applications, such as warehouse automation, manufacturing, disaster\nrobotics, etc. In most of these scenarios, damage to the agent while\naccomplishing mission-critical tasks can result in failure. To enable robotic\nadaptation in such situations, the agent needs to adopt policies which are\nrobust to a diverse set of damages and must do so with minimum computational\ncomplexity. We thus propose a damage aware control architecture which diagnoses\nthe damage prior to gait selection while also incorporating domain\nrandomization in the damage space for learning a robust policy. To implement\ndamage awareness, we have used a Long Short Term Memory based supervised\nlearning network which diagnoses the damage and predicts the type of damage.\nThe main novelty of this approach is that only a single policy is trained to\nadapt against a wide variety of damages and the diagnosis is done in a single\ntrial at the time of damage.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 22:16:40 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Verma", "Shresth", ""], ["Nair", "Haritha S.", ""], ["Agarwal", "Gaurav", ""], ["Dhar", "Joydip", ""], ["Shukla", "Anupam", ""]]}, {"id": "1910.01288", "submitter": "Shuai Yang", "authors": "Shuai Yang and Hao Wang and Kui Yu and Fuyuan Cao and Xindong Wu", "title": "Towards Efficient Local Causal Structure Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local causal structure learning aims to discover and distinguish direct\ncauses (parents) and direct effects (children) of a variable of interest from\ndata. While emerging successes have been made, existing methods need to search\na large space to distinguish direct causes from direct effects of a target\nvariable \\emph{T}. To tackle this issue, we propose a novel Efficient Local\nCausal Structure learning algorithm, named ELCS. Specifically, we first propose\nthe concept of N-structures, then design an efficient Markov Blanket (MB)\ndiscovery subroutine to integrate MB learning with N-structures to learn the MB\nof \\emph{T} and simultaneously distinguish direct causes from direct effects of\n\\emph{T}. With the proposed MB subroutine, ELCS starts from the target\nvariable, sequentially finds MBs of variables connected to the target variable\nand simultaneously constructs local causal structures over MBs until the direct\ncauses and direct effects of the target variable have been distinguished. Using\neight Bayesian networks the extensive experiments have validated that ELCS\nachieves better accuracy and efficiency than the state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 03:15:51 GMT"}, {"version": "v2", "created": "Sat, 18 Jan 2020 03:49:48 GMT"}, {"version": "v3", "created": "Sun, 10 Jan 2021 02:23:05 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Yang", "Shuai", ""], ["Wang", "Hao", ""], ["Yu", "Kui", ""], ["Cao", "Fuyuan", ""], ["Wu", "Xindong", ""]]}, {"id": "1910.01380", "submitter": "Zhe Hou", "authors": "Hadrien Bride, Jin Song Dong, Ryan Green, Zhe Hou, Brendan Mahony and\n  Martin Oxenham", "title": "GRAVITAS: A Model Checking Based Planning and Goal Reasoning Framework\n  for Autonomous Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While AI techniques have found many successful applications in autonomous\nsystems, many of them permit behaviours that are difficult to interpret and may\nlead to uncertain results. We follow the \"verification as planning\" paradigm\nand propose to use model checking techniques to solve planning and goal\nreasoning problems for autonomous systems. We give a new formulation of Goal\nTask Network (GTN) that is tailored for our model checking based framework. We\nthen provide a systematic method that models GTNs in the model checker Process\nAnalysis Toolkit (PAT). We present our planning and goal reasoning system as a\nframework called Goal Reasoning And Verification for Independent Trusted\nAutonomous Systems (GRAVITAS) and discuss how it helps provide trustworthy\nplans in an uncertain environment. Finally, we demonstrate the proposed ideas\nin an experiment that simulates a survey mission performed by the REMUS-100\nautonomous underwater vehicle.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 10:09:04 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Bride", "Hadrien", ""], ["Dong", "Jin Song", ""], ["Green", "Ryan", ""], ["Hou", "Zhe", ""], ["Mahony", "Brendan", ""], ["Oxenham", "Martin", ""]]}, {"id": "1910.01423", "submitter": "Zeynep Kiziltan", "authors": "Alan M. Frisch, Brahim Hnich, Zeynep Kiziltan, Ian Miguel, Toby Walsh", "title": "A Commentary on \"Breaking Row and Column Symmetries in Matrix Models\"", "comments": "Appeared in the virtual volume celebrating the first 25 years of the\n  CP conference (https://freuder.wordpress.com/cp-anniversary-project/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The CP 2002 paper entitled \"Breaking Row and Column Symmetries in Matrix\nModels\" by Flener et al.\n(https://link.springer.com/chapter/10.1007%2F3-540-46135-3_31) describes some\nof the first work for identifying and analyzing row and column symmetry in\nmatrix models and for efficiently and effectively dealing with such symmetry\nusing static symmetry-breaking ordering constraints. This commentary provides a\nretrospective on that work and highlights some of the subsequent work on the\ntopic.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 12:08:35 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Frisch", "Alan M.", ""], ["Hnich", "Brahim", ""], ["Kiziltan", "Zeynep", ""], ["Miguel", "Ian", ""], ["Walsh", "Toby", ""]]}, {"id": "1910.01442", "submitter": "Chuang Gan", "authors": "Kexin Yi, Chuang Gan, Yunzhu Li, Pushmeet Kohli, Jiajun Wu, Antonio\n  Torralba, Joshua B. Tenenbaum", "title": "CLEVRER: CoLlision Events for Video REpresentation and Reasoning", "comments": "The first two authors contributed equally to this work. Accepted as\n  Oral Spotlight as ICLR 2020. Project page: http://clevrer.csail.mit.edu/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to reason about temporal and causal events from videos lies at\nthe core of human intelligence. Most video reasoning benchmarks, however, focus\non pattern recognition from complex visual and language input, instead of on\ncausal structure. We study the complementary problem, exploring the temporal\nand causal structures behind videos of objects with simple visual appearance.\nTo this end, we introduce the CoLlision Events for Video REpresentation and\nReasoning (CLEVRER), a diagnostic video dataset for systematic evaluation of\ncomputational models on a wide range of reasoning tasks. Motivated by the\ntheory of human casual judgment, CLEVRER includes four types of questions:\ndescriptive (e.g., \"what color\"), explanatory (\"what is responsible for\"),\npredictive (\"what will happen next\"), and counterfactual (\"what if\"). We\nevaluate various state-of-the-art models for visual reasoning on our benchmark.\nWhile these models thrive on the perception-based task (descriptive), they\nperform poorly on the causal tasks (explanatory, predictive and\ncounterfactual), suggesting that a principled approach for causal reasoning\nshould incorporate the capability of both perceiving complex visual and\nlanguage inputs, and understanding the underlying dynamics and causal\nrelations. We also study an oracle model that explicitly combines these\ncomponents via symbolic representations.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 13:16:36 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 00:09:07 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Yi", "Kexin", ""], ["Gan", "Chuang", ""], ["Li", "Yunzhu", ""], ["Kohli", "Pushmeet", ""], ["Wu", "Jiajun", ""], ["Torralba", "Antonio", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1910.01459", "submitter": "Changkun Ou", "authors": "Changkun Ou, Yifei Zhan, Yaxi Chen", "title": "Identifying Malicious Players in GWAP-based Disaster Monitoring\n  Crowdsourcing System", "comments": null, "journal-ref": "In IEEE ICAIBD' 19: Proceedings of the 2nd International\n  Conference on Artificial Intelligence and Big Data. Chengdu, Sichuan, China,\n  May 25-28, 2019", "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Disaster monitoring is challenging due to the lake of infrastructures in\nmonitoring areas. Based on the theory of Game-With-A-Purpose (GWAP), this paper\ncontributes to a novel large-scale crowdsourcing disaster monitoring system.\nThe system analyzes tagged satellite pictures from anonymous players, and then\nreports aggregated and evaluated monitoring results to its stakeholders. An\nalgorithm based on directed graph centralities is presented to address the core\nissues of malicious user detection and disaster level calculation. Our method\ncan be easily applied in other human computation systems. In the end, some\nissues with possible solutions are discussed for our future work.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 14:49:11 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Ou", "Changkun", ""], ["Zhan", "Yifei", ""], ["Chen", "Yaxi", ""]]}, {"id": "1910.01465", "submitter": "Johannes Ackermann", "authors": "Johannes Ackermann, Volker Gabler, Takayuki Osa, Masashi Sugiyama", "title": "Reducing Overestimation Bias in Multi-Agent Domains Using Double\n  Centralized Critics", "comments": "Accepted for the Deep RL Workshop at NeurIPS 2019; Changes for v2:\n  Changed Figures 3,4, due to an error in the implementation of MATD3. Please\n  refer to this version for fair evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real world tasks require multiple agents to work together. Multi-agent\nreinforcement learning (RL) methods have been proposed in recent years to solve\nthese tasks, but current methods often fail to efficiently learn policies. We\nthus investigate the presence of a common weakness in single-agent RL, namely\nvalue function overestimation bias, in the multi-agent setting. Based on our\nfindings, we propose an approach that reduces this bias by using double\ncentralized critics. We evaluate it on six mixed cooperative-competitive tasks,\nshowing a significant advantage over current methods. Finally, we investigate\nthe application of multi-agent methods to high-dimensional robotic tasks and\nshow that our approach can be used to learn decentralized policies in this\ndomain.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 13:40:46 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 16:00:20 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Ackermann", "Johannes", ""], ["Gabler", "Volker", ""], ["Osa", "Takayuki", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1910.01490", "submitter": "Yang Qu", "authors": "Yang Qu, Ming-Xi Wang", "title": "The option pricing model based on time values: an application of the\n  universal approximation theory on unbounded domains", "comments": "To appear in IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a time value related decision function to treat a classical option\npricing problem raised by Hutchinson-Lo-Poggio. In numerical experiments, the\nnew decision function significantly improves the original model of\nHutchinson-Lo-Poggio with faster convergence and better generalization\nperformance. By proving a novel universal approximation theorem, we show that\nour decision function rather than Hutchinson-Lo-Poggio's can be approximated on\nthe entire domain of definition by neural networks. Thus the experimental\nresults are partially explained by the representation properties of networks.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 12:52:58 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 22:18:49 GMT"}, {"version": "v3", "created": "Mon, 19 Apr 2021 18:48:33 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Qu", "Yang", ""], ["Wang", "Ming-Xi", ""]]}, {"id": "1910.01508", "submitter": "Jos\\'e Su\\'arez-Varela", "authors": "Krzysztof Rusek, Jos\\'e Su\\'arez-Varela, Paul Almasan, Pere\n  Barlet-Ros, Albert Cabellos-Aparicio", "title": "RouteNet: Leveraging Graph Neural Networks for network modeling and\n  optimization in SDN", "comments": "12 pages", "journal-ref": "IEEE Journal on Selected Areas in Communication (JSAC), vol. 38,\n  no. 10, pp. 2260-2270, 2020", "doi": "10.1109/JSAC.2020.3000405", "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network modeling is a key enabler to achieve efficient network operation in\nfuture self-driving Software-Defined Networks. However, we still lack\nfunctional network models able to produce accurate predictions of Key\nPerformance Indicators (KPI) such as delay, jitter or loss at limited cost. In\nthis paper we propose RouteNet, a novel network model based on Graph Neural\nNetwork (GNN) that is able to understand the complex relationship between\ntopology, routing, and input traffic to produce accurate estimates of the\nper-source/destination per-packet delay distribution and loss. RouteNet\nleverages the ability of GNNs to learn and model graph-structured information\nand as a result, our model is able to generalize over arbitrary topologies,\nrouting schemes and traffic intensity. In our evaluation, we show that RouteNet\nis able to predict accurately the delay distribution (mean delay and jitter)\nand loss even in topologies, routing and traffic unseen in the training (worst\ncase MRE=15.4%). Also, we present several use cases where we leverage the KPI\npredictions of our GNN model to achieve efficient routing optimization and\nnetwork planning.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 14:26:28 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 17:06:04 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Rusek", "Krzysztof", ""], ["Su\u00e1rez-Varela", "Jos\u00e9", ""], ["Almasan", "Paul", ""], ["Barlet-Ros", "Pere", ""], ["Cabellos-Aparicio", "Albert", ""]]}, {"id": "1910.01539", "submitter": "Uwe Petersohn", "authors": "Uwe Petersohn, Sandra Zimmer, Jens Lehmann", "title": "Method for the semantic indexing of concept hierarchies, uniform\n  representation, use of relational database systems and generic and case-based\n  reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a method for semantic indexing and describes its\napplication in the field of knowledge representation. Starting point of the\nsemantic indexing is the knowledge represented by concept hierarchies. The goal\nis to assign keys to nodes (concepts) that are hierarchically ordered and\nsyntactically and semantically correct. With the indexing algorithm, keys are\ncomputed such that concepts are partially unifiable with all more specific\nconcepts and only semantically correct concepts are allowed to be added. The\nkeys represent terminological relationships. Correctness and completeness of\nthe underlying indexing algorithm are proven. The use of classical relational\ndatabases for the storage of instances is described. Because of the uniform\nrepresentation, inference can be done using case-based reasoning and generic\nproblem solving methods.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 14:54:13 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Petersohn", "Uwe", ""], ["Zimmer", "Sandra", ""], ["Lehmann", "Jens", ""]]}, {"id": "1910.01708", "submitter": "Scott Fujimoto", "authors": "Scott Fujimoto, Edoardo Conti, Mohammad Ghavamzadeh, Joelle Pineau", "title": "Benchmarking Batch Deep Reinforcement Learning Algorithms", "comments": "Deep RL Workshop NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Widely-used deep reinforcement learning algorithms have been shown to fail in\nthe batch setting--learning from a fixed data set without interaction with the\nenvironment. Following this result, there have been several papers showing\nreasonable performances under a variety of environments and batch settings. In\nthis paper, we benchmark the performance of recent off-policy and batch\nreinforcement learning algorithms under unified settings on the Atari domain,\nwith data generated by a single partially-trained behavioral policy. We find\nthat under these conditions, many of these algorithms underperform DQN trained\nonline with the same amount of data, as well as the partially-trained\nbehavioral policy. To introduce a strong baseline, we adapt the\nBatch-Constrained Q-learning algorithm to a discrete-action setting, and show\nit outperforms all existing algorithms at this task.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 20:15:55 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Fujimoto", "Scott", ""], ["Conti", "Edoardo", ""], ["Ghavamzadeh", "Mohammad", ""], ["Pineau", "Joelle", ""]]}, {"id": "1910.01723", "submitter": "Kolby Nottingham", "authors": "Kolby Nottingham, Anand Balakrishnan, Jyotirmoy Deshmukh, Connor\n  Christopherson, Joshua Greaves, David Wingate", "title": "Using Logical Specifications of Objectives in Multi-Objective\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the multi-objective reinforcement learning (MORL) paradigm, the relative\nimportance of each environment objective is often unknown prior to training, so\nagents must learn to specialize their behavior to optimize different\ncombinations of environment objectives that are specified post-training. These\nare typically linear combinations, so the agent is effectively parameterized by\na weight vector that describes how to balance competing environment objectives.\nHowever, many real world behaviors require non-linear combinations of\nobjectives. Additionally, the conversion between desired behavior and\nweightings is often unclear.\n  In this work, we explore the use of a language based on propositional logic\nwith quantitative semantics--in place of weight vectors--for specifying\nnon-linear behaviors in an interpretable way. We use a recurrent encoder to\nencode logical combinations of objectives, and train a MORL agent to generalize\nover these encodings. We test our agent in several environments with various\nobjectives and show that our agent can generalize to many never-before-seen\nspecifications with performance comparable to single policy baseline agents. We\nalso demonstrate our agent's ability to generate meaningful policies when\npresented with novel specifications and quickly specialize to novel\nspecifications.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 21:16:04 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 16:15:34 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Nottingham", "Kolby", ""], ["Balakrishnan", "Anand", ""], ["Deshmukh", "Jyotirmoy", ""], ["Christopherson", "Connor", ""], ["Greaves", "Joshua", ""], ["Wingate", "David", ""]]}, {"id": "1910.01741", "submitter": "Denis Yarats", "authors": "Denis Yarats, Amy Zhang, Ilya Kostrikov, Brandon Amos, Joelle Pineau,\n  Rob Fergus", "title": "Improving Sample Efficiency in Model-Free Reinforcement Learning from\n  Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training an agent to solve control tasks directly from high-dimensional\nimages with model-free reinforcement learning (RL) has proven difficult. A\npromising approach is to learn a latent representation together with the\ncontrol policy. However, fitting a high-capacity encoder using a scarce reward\nsignal is sample inefficient and leads to poor performance. Prior work has\nshown that auxiliary losses, such as image reconstruction, can aid efficient\nrepresentation learning. However, incorporating reconstruction loss into an\noff-policy learning algorithm often leads to training instability. We explore\nthe underlying reasons and identify variational autoencoders, used by previous\ninvestigations, as the cause of the divergence. Following these findings, we\npropose effective techniques to improve training stability. This results in a\nsimple approach capable of matching state-of-the-art model-free and model-based\nalgorithms on MuJoCo control tasks. Furthermore, our approach demonstrates\nrobustness to observational noise, surpassing existing approaches in this\nsetting. Code, results, and videos are anonymously available at\nhttps://sites.google.com/view/sac-ae/home.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 15:50:03 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 00:34:50 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 15:42:09 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Yarats", "Denis", ""], ["Zhang", "Amy", ""], ["Kostrikov", "Ilya", ""], ["Amos", "Brandon", ""], ["Pineau", "Joelle", ""], ["Fergus", "Rob", ""]]}, {"id": "1910.01751", "submitter": "Suraj Nair", "authors": "Suraj Nair, Yuke Zhu, Silvio Savarese, Li Fei-Fei", "title": "Causal Induction from Visual Observations for Goal Directed Tasks", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal reasoning has been an indispensable capability for humans and other\nintelligent animals to interact with the physical world. In this work, we\npropose to endow an artificial agent with the capability of causal reasoning\nfor completing goal-directed tasks. We develop learning-based approaches to\ninducing causal knowledge in the form of directed acyclic graphs, which can be\nused to contextualize a learned goal-conditional policy to perform tasks in\nnovel environments with latent causal structures. We leverage attention\nmechanisms in our causal induction model and goal-conditional policy, enabling\nus to incrementally generate the causal graph from the agent's visual\nobservations and to selectively use the induced graph for determining actions.\nOur experiments show that our method effectively generalizes towards completing\nnew tasks in novel environments with previously unseen causal structures.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 22:32:40 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Nair", "Suraj", ""], ["Zhu", "Yuke", ""], ["Savarese", "Silvio", ""], ["Fei-Fei", "Li", ""]]}, {"id": "1910.01803", "submitter": "Sajad Darabi", "authors": "Sajad Darabi, Mohammad Kachuee, Majid Sarrafzadeh", "title": "Unsupervised Representation for EHR Signals and Codes as Patient Status\n  Vector", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective modeling of electronic health records presents many challenges as\nthey contain large amounts of irregularity most of which are due to the varying\nprocedures and diagnosis a patient may have. Despite the recent progress in\nmachine learning, unsupervised learning remains largely at open, especially in\nthe healthcare domain. In this work, we present a two-step unsupervised\nrepresentation learning scheme to summarize the multi-modal clinical time\nseries consisting of signals and medical codes into a patient status vector.\nFirst, an auto-encoder step is used to reduce sparse medical codes and clinical\ntime series into a distributed representation. Subsequently, the concatenation\nof the distributed representations is further fine-tuned using a forecasting\ntask. We evaluate the usefulness of the representation on two downstream tasks:\nmortality and readmission. Our proposed method shows improved generalization\nperformance for both short duration ICU visits and long duration ICU visits.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 05:42:50 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Darabi", "Sajad", ""], ["Kachuee", "Mohammad", ""], ["Sarrafzadeh", "Majid", ""]]}, {"id": "1910.01806", "submitter": "Ekaterina Nikonova", "authors": "Ekaterina Nikonova, Jakub Gemrot", "title": "Deep Q-Network for Angry Birds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Angry Birds is a popular video game in which the player is provided with a\nsequence of birds to shoot from a slingshot. The task of the game is to destroy\nall green pigs with maximum possible score. Angry Birds appears to be a\ndifficult task to solve for artificially intelligent agents due to the\nsequential decision-making, non-deterministic game environment, enormous state\nand action spaces and requirement to differentiate between multiple birds,\ntheir abilities and optimum tapping times. We describe the application of Deep\nReinforcement learning by implementing Double Dueling Deep Q-network to play\nAngry Birds game. One of our main goals was to build an agent that is able to\ncompete with previous participants and humans on the first 21 levels. In order\nto do so, we have collected a dataset of game frames that we used to train our\nagent on. We present different approaches and settings for DQN agent. We\nevaluate our agent using results of the previous participants of AIBirds\ncompetition, results of volunteer human players and present the results of\nAIBirds 2018 competition.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 06:11:45 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 09:29:15 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Nikonova", "Ekaterina", ""], ["Gemrot", "Jakub", ""]]}, {"id": "1910.01837", "submitter": "Johannes Rabold", "authors": "Johannes Rabold, Hannah Deininger, Michael Siebers, Ute Schmid", "title": "Enriching Visual with Verbal Explanations for Relational Concepts --\n  Combining LIME with Aleph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing number of deep learning applications, there is a growing\ndemand for explanations. Visual explanations provide information about which\nparts of an image are relevant for a classifier's decision. However,\nhighlighting of image parts (e.g., an eye) cannot capture the relevance of a\nspecific feature value for a class (e.g., that the eye is wide open).\nFurthermore, highlighting cannot convey whether the classification depends on\nthe mere presence of parts or on a specific spatial relation between them.\nConsequently, we present an approach that is capable of explaining a\nclassifier's decision in terms of logic rules obtained by the Inductive Logic\nProgramming system Aleph. The examples and the background knowledge needed for\nAleph are based on the explanation generation method LIME. We demonstrate our\napproach with images of a blocksworld domain. First, we show that our approach\nis capable of identifying a single relation as important explanatory construct.\nAfterwards, we present the more complex relational concept of towers. Finally,\nwe show how the generated relational rules can be explicitly related with the\ninput image, resulting in richer explanations.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 08:51:41 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Rabold", "Johannes", ""], ["Deininger", "Hannah", ""], ["Siebers", "Michael", ""], ["Schmid", "Ute", ""]]}, {"id": "1910.01865", "submitter": "Fabien Petitcolas", "authors": "Marc Joye and Fabien A. P. Petitcolas", "title": "PINFER: Privacy-Preserving Inference for Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The foreseen growing role of outsourced machine learning services is raising\nconcerns about the privacy of user data. Several technical solutions are being\nproposed to address the issue. Hardware security modules in cloud data centres\nappear limited to enterprise customers due to their complexity, while general\nmulti-party computation techniques require a large number of message exchanges.\nThis paper proposes a variety of protocols for privacy-preserving regression\nand classification that (i) only require additively homomorphic encryption\nalgorithms, (ii) limit interactions to a mere request and response, and (iii)\nthat can be used directly for important machine-learning algorithms such as\nlogistic regression and SVM classification. The basic protocols are then\nextended and applied to feed-forward neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 10:49:27 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Joye", "Marc", ""], ["Petitcolas", "Fabien A. P.", ""]]}, {"id": "1910.01913", "submitter": "Benjamin Eysenbach", "authors": "Benjamin Eysenbach and Sergey Levine", "title": "If MaxEnt RL is the Answer, What is the Question?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimentally, it has been observed that humans and animals often make\ndecisions that do not maximize their expected utility, but rather choose\noutcomes randomly, with probability proportional to expected utility.\nProbability matching, as this strategy is called, is equivalent to maximum\nentropy reinforcement learning (MaxEnt RL). However, MaxEnt RL does not\noptimize expected utility. In this paper, we formally show that MaxEnt RL does\noptimally solve certain classes of control problems with variability in the\nreward function. In particular, we show (1) that MaxEnt RL can be used to solve\na certain class of POMDPs, and (2) that MaxEnt RL is equivalent to a two-player\ngame where an adversary chooses the reward function. These results suggest a\ndeeper connection between MaxEnt RL, robust control, and POMDPs, and provide\ninsight for the types of problems for which we might expect MaxEnt RL to\nproduce effective solutions. Specifically, our results suggest that domains\nwith uncertainty in the task goal may be especially well-suited for MaxEnt RL\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 12:50:34 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Eysenbach", "Benjamin", ""], ["Levine", "Sergey", ""]]}, {"id": "1910.01917", "submitter": "Ragesh K Ramachandran", "authors": "Ragesh K. Ramachandran, Lifeng Zhou James A. Preiss, and Gaurav S.\n  Sukhatme", "title": "Resilient Coverage: Exploring the Local-to-Global Trade-off", "comments": "8 pages, 5 figures, submitted to IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a centralized control framework to select suitable robots from a\nheterogeneous pool and place them at appropriate locations to monitor a region\nfor events of interest. In the event of a robot failure, the framework\nrepositions robots in a user-defined local neighborhood of the failed robot to\ncompensate for the coverage loss. The central controller augments the team with\nadditional robots from the robot pool when simply repositioning robots fails to\nattain a user-specified level of desired coverage. The size of the local\nneighborhood around the failed robot and the desired coverage over the region\nare two objectives that can be manipulated to achieve a user-specified balance.\nWe investigate the trade-off between the coverage compensation achieved through\nlocal repositioning and the computation required to plan the new robot\nlocations. We also study the relationship between the size of the local\nneighborhood and the number of additional robots added to the team for a given\nuser-specified level of desired coverage. We use extensive simulations and an\nexperiment with a team of seven quadrotors to verify the effectiveness of our\nframework. Additionally, we show that to reach a high level of coverage in a\nneighborhood with a large robot population, it is more efficient to enlarge the\nneighborhood size, instead of adding additional robots and repositioning them.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 04:41:13 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 16:37:27 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Ramachandran", "Ragesh K.", ""], ["Preiss", "Lifeng Zhou James A.", ""], ["Sukhatme", "Gaurav S.", ""]]}, {"id": "1910.01990", "submitter": "Preslav Nakov", "authors": "Daniel Kopev, Ahmed Ali, Ivan Koychev, Preslav Nakov", "title": "Detecting Deception in Political Debates Using Acoustic and Textual\n  Features", "comments": null, "journal-ref": "ASRU-2019", "doi": null, "report-no": null, "categories": "cs.CL cs.AI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present work on deception detection, where, given a spoken claim, we aim\nto predict its factuality. While previous work in the speech community has\nrelied on recordings from staged setups where people were asked to tell the\ntruth or to lie and their statements were recorded, here we use real-world\npolitical debates. Thanks to the efforts of fact-checking organizations, it is\npossible to obtain annotations for statements in the context of a political\ndiscourse as true, half-true, or false. Starting with such data from the\nCLEF-2018 CheckThat! Lab, which was limited to text, we performed alignment to\nthe corresponding videos, thus producing a multimodal dataset. We further\ndeveloped a multimodal deep-learning architecture for the task of deception\ndetection, which yielded sizable improvements over the state of the art for the\nCLEF-2018 Lab task 2. Our experiments show that the use of the acoustic signal\nconsistently helped to improve the performance compared to using textual and\nmetadata features only, based on several different evaluation measures. We\nrelease the new dataset to the research community, hoping to help advance the\noverall field of multimodal deception detection.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 15:28:01 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Kopev", "Daniel", ""], ["Ali", "Ahmed", ""], ["Koychev", "Ivan", ""], ["Nakov", "Preslav", ""]]}, {"id": "1910.01994", "submitter": "Robert Kwiatkowski", "authors": "Robert Kwiatkowski and Hod Lipson", "title": "Zero Shot Learning on Simulated Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a method for leveraging data from one source to learn\nhow to do multiple new tasks. Task transfer is achieved using a self-model that\nencapsulates the dynamics of a system and serves as an environment for\nreinforcement learning. To study this approach, we train a self-models on\nvarious robot morphologies, using randomly sampled actions. Using a self-model,\nan initial state and corresponding actions, we can predict the next state. This\npredictive self-model is then used by a standard reinforcement learning\nalgorithm to accomplish tasks without ever seeing a state from the \"real\"\nenvironment. These trained policies allow the robots to successfully achieve\ntheir goals in the \"real\" environment. We demonstrate that not only is training\non the self-model far more data efficient than learning even a single task, but\nalso that it allows for learning new tasks without necessitating any additional\ndata collection, essentially allowing zero-shot learning of new tasks.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 15:35:40 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Kwiatkowski", "Robert", ""], ["Lipson", "Hod", ""]]}, {"id": "1910.02001", "submitter": "Preslav Nakov", "authors": "Atanas Atanasov, Gianmarco De Francisci Morales, Preslav Nakov", "title": "Predicting the Role of Political Trolls in Social Media", "comments": null, "journal-ref": "CoNLL-2019", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the political roles of \"Internet trolls\" in social media.\nPolitical trolls, such as the ones linked to the Russian Internet Research\nAgency (IRA), have recently gained enormous attention for their ability to sway\npublic opinion and even influence elections. Analysis of the online traces of\ntrolls has shown different behavioral patterns, which target different slices\nof the population. However, this analysis is manual and labor-intensive, thus\nmaking it impractical as a first-response tool for newly-discovered troll\nfarms. In this paper, we show how to automate this analysis by using machine\nlearning in a realistic setting. In particular, we show how to classify trolls\naccording to their political role ---left, news feed, right--- by using\nfeatures extracted from social media, i.e., Twitter, in two scenarios: (i) in a\ntraditional supervised learning scenario, where labels for trolls are\navailable, and (ii) in a distant supervision scenario, where labels for trolls\nare not available, and we rely on more-commonly-available labels for news\noutlets mentioned by the trolls. Technically, we leverage the community\nstructure and the text of the messages in the online social network of trolls\nrepresented as a graph, from which we extract several types of learned\nrepresentations, i.e.,~embeddings, for the trolls. Experiments on the \"IRA\nRussian Troll\" dataset show that our methodology improves over the\nstate-of-the-art in the first scenario, while providing a compelling case for\nthe second scenario, which has not been explored in the literature thus far.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 15:50:30 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Atanasov", "Atanas", ""], ["Morales", "Gianmarco De Francisci", ""], ["Nakov", "Preslav", ""]]}, {"id": "1910.02035", "submitter": "Shuai Zheng", "authors": "Shuai Zheng, Chetan Gupta, Susumu Serita", "title": "Manufacturing Dispatching using Reinforcement and Transfer Learning", "comments": "ECML PKDD 2019 (The European Conference on Machine Learning and\n  Principles and Practice of Knowledge Discovery in Databases, 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient dispatching rule in manufacturing industry is key to ensure product\non-time delivery and minimum past-due and inventory cost. Manufacturing,\nespecially in the developed world, is moving towards on-demand manufacturing\nmeaning a high mix, low volume product mix. This requires efficient dispatching\nthat can work in dynamic and stochastic environments, meaning it allows for\nquick response to new orders received and can work over a disparate set of shop\nfloor settings. In this paper we address this problem of dispatching in\nmanufacturing. Using reinforcement learning (RL), we propose a new design to\nformulate the shop floor state as a 2-D matrix, incorporate job slack time into\nstate representation, and design lateness and tardiness rewards function for\ndispatching purpose. However, maintaining a separate RL model for each\nproduction line on a manufacturing shop floor is costly and often infeasible.\nTo address this, we enhance our deep RL model with an approach for dispatching\npolicy transfer. This increases policy generalization and saves time and cost\nfor model training and data collection. Experiments show that: (1) our approach\nperforms the best in terms of total discounted reward and average lateness,\ntardiness, (2) the proposed policy transfer approach reduces training time and\nincreases policy generalization.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 16:52:46 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Zheng", "Shuai", ""], ["Gupta", "Chetan", ""], ["Serita", "Susumu", ""]]}, {"id": "1910.02052", "submitter": "V Ratna Saripalli", "authors": "V. Ratna Saripalli, Gopal Avinash, Dibyajyoti Pati, Michael Potter,\n  Charles W. Anderson", "title": "AI Assisted Annotator using Reinforcement Learning", "comments": "10 pages", "journal-ref": null, "doi": "10.1007/s42979-020-00356-z", "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Healthcare data suffers from both noise and lack of ground truth. The cost of\ndata increases as it is cleaned and annotated in healthcare. Unlike other data\nsets, medical data annotation, which is critical to accurate ground truth,\nrequires medical domain expertise for a better patient outcome. In this work,\nwe report on the use of reinforcement learning to mimic the decision making\nprocess of annotators for medical events, to automate annotation and labelling.\nThe reinforcement agent learns to annotate alarm data based on annotations done\nby an expert. Our method shows promising results on medical alarm data sets. We\ntrained DQN and A2C agents using the data from monitoring devices annotated by\nan expert. Initial results from these RL agents learning the expert annotation\nbehavior are promising. The A2C agent performs better in terms of learning the\nsparse events in a given state, thereby choosing more right actions compared to\nDQN agent. To the best of our knowledge, this is the first reinforcement\nlearning application for the automation of medical events annotation, which has\nfar-reaching practical use.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 22:57:42 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 00:33:28 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 21:38:28 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Saripalli", "V. Ratna", ""], ["Avinash", "Gopal", ""], ["Pati", "Dibyajyoti", ""], ["Potter", "Michael", ""], ["Anderson", "Charles W.", ""]]}, {"id": "1910.02097", "submitter": "Heinrich Jiang", "authors": "Ofir Nachum, Heinrich Jiang", "title": "Group-based Fair Learning Leads to Counter-intuitive Predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of machine learning (ML) methods have been proposed recently to\nmaximize model predictive accuracy while enforcing notions of group parity or\nfairness across sub-populations. We propose a desirable property for these\nprocedures, slack-consistency: For any individual, the predictions of the model\nshould be monotonic with respect to allowed slack (i.e., maximum allowed\ngroup-parity violation). Such monotonicity can be useful for individuals to\nunderstand the impact of enforcing fairness on their predictions. Surprisingly,\nwe find that standard ML methods for enforcing fairness violate this basic\nproperty. Moreover, this undesirable behavior arises in situations agnostic to\nthe complexity of the underlying model or approximate optimizations, suggesting\nthat the simple act of incorporating a constraint can lead to drastically\nunintended behavior in ML. We present a simple theoretical method for enforcing\nslack-consistency, while encouraging further discussions on the unintended\nbehaviors potentially induced when enforcing group-based parity.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 18:20:50 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Nachum", "Ofir", ""], ["Jiang", "Heinrich", ""]]}, {"id": "1910.02109", "submitter": "Dianbo Liu Dr", "authors": "Dianbo Liu, Kathe Fox, Griffin Weber, Tim Miller", "title": "Confederated Machine Learning on Horizontally and Vertically Separated\n  Medical Data for Large-Scale Health System Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Health information is generally fragmented across silos. Though it is\ntechnically feasible to unite data for analysis in a manner that underpins a\nrapid learning healthcare system, privacy concerns and regulatory barriers\nlimit data centralization. Machine learning can be conducted in a federated\nmanner on patient datasets with the same set of variables, but separated across\nsites of care. But federated learning cannot handle the situation where\ndifferent data types for a given patient are separated vertically across\ndifferent organizations and when patient ID matching across different\ninstitutions is difficult. We call methods that enable machine learning model\ntraining on data separated by two or more degrees confederated machine\nlearning. We proposed and evaluated a confederated learning to training machine\nlearning model to stratify the risk of several diseases among when data are\nhorizontally separated by individual, vertically separated by data type, and\nseparated by identity without patient ID matching.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 19:14:46 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 02:46:02 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 17:42:03 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Liu", "Dianbo", ""], ["Fox", "Kathe", ""], ["Weber", "Griffin", ""], ["Miller", "Tim", ""]]}, {"id": "1910.02130", "submitter": "Mahsa Ghasemi", "authors": "Mahsa Ghasemi, Ufuk Topcu", "title": "Online Active Perception for Partially Observable Markov Decision\n  Processes with Limited Budget", "comments": "Accepted for publication in Conference on Decision and Control (CDC)\n  Proceedings, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active perception strategies enable an agent to selectively gather\ninformation in a way to improve its performance. In applications in which the\nagent does not have prior knowledge about the available information sources, it\nis crucial to synthesize active perception strategies at runtime. We consider a\nsetting in which at runtime an agent is capable of gathering information under\na limited budget. We pose the problem in the context of partially observable\nMarkov decision processes. We propose a generalized greedy strategy that\nselects a subset of information sources with near-optimality guarantees on\nuncertainty reduction. Our theoretical analysis establishes that the proposed\nactive perception strategy achieves near-optimal performance in terms of\nexpected cumulative reward. We demonstrate the resulting strategies in\nsimulations on a robotic navigation problem.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 20:09:04 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Ghasemi", "Mahsa", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1910.02136", "submitter": "Sumit Mukherjee", "authors": "Anusua Trivedi, Sumit Mukherjee, Edmund Tse, Anne Ewing, Juan Lavista\n  Ferres", "title": "Risks of Using Non-verified Open Data: A case study on using Machine\n  Learning techniques for predicting Pregnancy Outcomes in India", "comments": "Presented at NeurIPS 2019 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial intelligence (AI) has evolved considerably in the last few years.\nWhile applications of AI is now becoming more common in fields like retail and\nmarketing, application of AI in solving problems related to developing\ncountries is still an emerging topic. Specially, AI applications in\nresource-poor settings remains relatively nascent. There is a huge scope of AI\nbeing used in such settings. For example, researchers have started exploring AI\napplications to reduce poverty and deliver a broad range of critical public\nservices. However, despite many promising use cases, there are many dataset\nrelated challenges that one has to overcome in such projects. These challenges\noften take the form of missing data, incorrectly collected data and improperly\nlabeled variables, among other factors. As a result, we can often end up using\ndata that is not representative of the problem we are trying to solve. In this\ncase study, we explore the challenges of using such an open dataset from India,\nto predict an important health outcome. We highlight how the use of AI without\nproper understanding of reporting metrics can lead to erroneous conclusions.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 20:27:20 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 20:21:56 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Trivedi", "Anusua", ""], ["Mukherjee", "Sumit", ""], ["Tse", "Edmund", ""], ["Ewing", "Anne", ""], ["Ferres", "Juan Lavista", ""]]}, {"id": "1910.02140", "submitter": "Abhishek Naik", "authors": "Abhishek Naik, Roshan Shariff, Niko Yasui, Hengshuai Yao, Richard S.\n  Sutton", "title": "Discounted Reinforcement Learning Is Not an Optimization Problem", "comments": "Accepted for presentation at the Optimization Foundations of\n  Reinforcement Learning Workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discounted reinforcement learning is fundamentally incompatible with function\napproximation for control in continuing tasks. It is not an optimization\nproblem in its usual formulation, so when using function approximation there is\nno optimal policy. We substantiate these claims, then go on to address some\nmisconceptions about discounting and its connection to the average reward\nformulation. We encourage researchers to adopt rigorous optimization\napproaches, such as maximizing average reward, for reinforcement learning in\ncontinuing tasks.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 20:52:39 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 04:21:29 GMT"}, {"version": "v3", "created": "Wed, 27 Nov 2019 07:28:55 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Naik", "Abhishek", ""], ["Shariff", "Roshan", ""], ["Yasui", "Niko", ""], ["Yao", "Hengshuai", ""], ["Sutton", "Richard S.", ""]]}, {"id": "1910.02181", "submitter": "Chaitanya Ahuja", "authors": "Chaitanya Ahuja, Shugao Ma, Louis-Philippe Morency, Yaser Sheikh", "title": "To React or not to React: End-to-End Visual Pose Forecasting for\n  Personalized Avatar during Dyadic Conversations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non verbal behaviours such as gestures, facial expressions, body posture, and\npara-linguistic cues have been shown to complement or clarify verbal messages.\nHence to improve telepresence, in form of an avatar, it is important to model\nthese behaviours, especially in dyadic interactions. Creating such personalized\navatars not only requires to model intrapersonal dynamics between a avatar's\nspeech and their body pose, but it also needs to model interpersonal dynamics\nwith the interlocutor present in the conversation. In this paper, we introduce\na neural architecture named Dyadic Residual-Attention Model (DRAM), which\nintegrates intrapersonal (monadic) and interpersonal (dyadic) dynamics using\nselective attention to generate sequences of body pose conditioned on audio and\nbody pose of the interlocutor and audio of the human operating the avatar. We\nevaluate our proposed model on dyadic conversational data consisting of pose\nand audio of both participants, confirming the importance of adaptive attention\nbetween monadic and dyadic dynamics when predicting avatar pose. We also\nconduct a user study to analyze judgments of human observers. Our results\nconfirm that the generated body pose is more natural, models intrapersonal\ndynamics and interpersonal dynamics better than non-adaptive monadic/dyadic\nmodels.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 00:19:36 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Ahuja", "Chaitanya", ""], ["Ma", "Shugao", ""], ["Morency", "Louis-Philippe", ""], ["Sheikh", "Yaser", ""]]}, {"id": "1910.02182", "submitter": "Pasha Khosravi", "authors": "Pasha Khosravi, YooJung Choi, Yitao Liang, Antonio Vergari, Guy Van\n  den Broeck", "title": "On Tractable Computation of Expected Predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing expected predictions of discriminative models is a fundamental task\nin machine learning that appears in many interesting applications such as\nfairness, handling missing values, and data analysis. Unfortunately, computing\nexpectations of a discriminative model with respect to a probability\ndistribution defined by an arbitrary generative model has been proven to be\nhard in general. In fact, the task is intractable even for simple models such\nas logistic regression and a naive Bayes distribution. In this paper, we\nidentify a pair of generative and discriminative models that enables tractable\ncomputation of expectations, as well as moments of any order, of the latter\nwith respect to the former in case of regression. Specifically, we consider\nexpressive probabilistic circuits with certain structural constraints that\nsupport tractable probabilistic inference. Moreover, we exploit the tractable\ncomputation of high-order moments to derive an algorithm to approximate the\nexpectations for classification scenarios in which exact computations are\nintractable. Our framework to compute expected predictions allows for handling\nof missing data during prediction time in a principled and accurate way and\nenables reasoning about the behavior of discriminative models. We empirically\nshow our algorithm to consistently outperform standard imputation techniques on\na variety of datasets. Finally, we illustrate how our framework can be used for\nexploratory data analysis.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 00:20:41 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 21:47:20 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Khosravi", "Pasha", ""], ["Choi", "YooJung", ""], ["Liang", "Yitao", ""], ["Vergari", "Antonio", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "1910.02202", "submitter": "Nguyen Vo", "authors": "Nguyen Vo, Kyumin Lee", "title": "Learning from Fact-checkers: Analysis and Generation of Fact-checking\n  Language", "comments": "SIGIR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In fighting against fake news, many fact-checking systems comprised of\nhuman-based fact-checking sites (e.g., snopes.com and politifact.com) and\nautomatic detection systems have been developed in recent years. However,\nonline users still keep sharing fake news even when it has been debunked. It\nmeans that early fake news detection may be insufficient and we need another\ncomplementary approach to mitigate the spread of misinformation. In this paper,\nwe introduce a novel application of text generation for combating fake news. In\nparticular, we (1) leverage online users named \\emph{fact-checkers}, who cite\nfact-checking sites as credible evidences to fact-check information in public\ndiscourse; (2) analyze linguistic characteristics of fact-checking tweets; and\n(3) propose and build a deep learning framework to generate responses with\nfact-checking intention to increase the fact-checkers' engagement in\nfact-checking activities. Our analysis reveals that the fact-checkers tend to\nrefute misinformation and use formal language (e.g. few swear words and\nInternet slangs). Our framework successfully generates relevant responses, and\noutperforms competing models by achieving up to 30\\% improvements. Our\nqualitative study also confirms that the superiority of our generated responses\ncompared with responses generated from the existing models.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 03:23:45 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Vo", "Nguyen", ""], ["Lee", "Kyumin", ""]]}, {"id": "1910.02208", "submitter": "Yanqiu Wu", "authors": "Che Wang, Yanqiu Wu, Quan Vuong, Keith Ross", "title": "Striving for Simplicity and Performance in Off-Policy DRL: Output\n  Normalization and Non-Uniform Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to develop off-policy DRL algorithms that not only exceed\nstate-of-the-art performance but are also simple and minimalistic. For standard\ncontinuous control benchmarks, Soft Actor-Critic (SAC), which employs entropy\nmaximization, currently provides state-of-the-art performance. We first\ndemonstrate that the entropy term in SAC addresses action saturation due to the\nbounded nature of the action spaces, with this insight, we propose a\nstreamlined algorithm with a simple normalization scheme or with inverted\ngradients. We show that both approaches can match SAC's sample efficiency\nperformance without the need of entropy maximization, we then propose a simple\nnon-uniform sampling method for selecting transitions from the replay buffer\nduring training. Extensive experimental results demonstrate that our proposed\nsampling scheme leads to state of the art sample efficiency on challenging\ncontinuous control tasks. We combine all of our findings into one simple\nalgorithm, which we call Streamlined Off Policy with Emphasizing Recent\nExperience, for which we provide robust public-domain code.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 04:22:35 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 14:02:08 GMT"}, {"version": "v3", "created": "Sun, 9 Feb 2020 15:22:40 GMT"}, {"version": "v4", "created": "Sat, 5 Dec 2020 09:02:08 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Wang", "Che", ""], ["Wu", "Yanqiu", ""], ["Vuong", "Quan", ""], ["Ross", "Keith", ""]]}, {"id": "1910.02227", "submitter": "Richard Evans", "authors": "Richard Evans, Jose Hernandez-Orallo, Johannes Welbl, Pushmeet Kohli,\n  Marek Sergot", "title": "Making sense of sensory input", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper attempts to answer a central question in unsupervised learning:\nwhat does it mean to \"make sense\" of a sensory sequence? In our formalization,\nmaking sense involves constructing a symbolic causal theory that both explains\nthe sensory sequence and also satisfies a set of unity conditions. The unity\nconditions insist that the constituents of the causal theory -- objects,\nproperties, and laws -- must be integrated into a coherent whole. On our\naccount, making sense of sensory input is a type of program synthesis, but it\nis unsupervised program synthesis.\n  Our second contribution is a computer implementation, the Apperception\nEngine, that was designed to satisfy the above requirements. Our system is able\nto produce interpretable human-readable causal theories from very small amounts\nof data, because of the strong inductive bias provided by the unity conditions.\nA causal theory produced by our system is able to predict future sensor\nreadings, as well as retrodict earlier readings, and impute (fill in the blanks\nof) missing sensory readings, in any combination.\n  We tested the engine in a diverse variety of domains, including cellular\nautomata, rhythms and simple nursery tunes, multi-modal binding problems,\nocclusion tasks, and sequence induction intelligence tests. In each domain, we\ntest our engine's ability to predict future sensor values, retrodict earlier\nsensor values, and impute missing sensory data. The engine performs well in all\nthese domains, significantly out-performing neural net baselines. We note in\nparticular that in the sequence induction intelligence tests, our system\nachieved human-level performance. This is notable because our system is not a\nbespoke system designed specifically to solve intelligence tests, but a\ngeneral-purpose system that was designed to make sense of any sensory sequence.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 07:48:55 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 03:16:30 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Evans", "Richard", ""], ["Hernandez-Orallo", "Jose", ""], ["Welbl", "Johannes", ""], ["Kohli", "Pushmeet", ""], ["Sergot", "Marek", ""]]}, {"id": "1910.02240", "submitter": "Mingyang Geng", "authors": "Mingyang Geng, Kele Xu, Yiying Li, Shuqi Liu, Bo Ding, Huaimin Wang", "title": "Attention-based Fault-tolerant Approach for Multi-agent Reinforcement\n  Learning Systems", "comments": "13 pages. arXiv admin note: text overlap with arXiv:1812.00922 by\n  other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of multi-agent reinforcement learning systems is to provide\ninteracting agents with the ability to collaboratively learn and adapt to the\nbehavior of other agents. In many real-world applications, the agents can only\nacquire a partial view of the world. However, in realistic settings, one or\nmore agents that show arbitrarily faulty or malicious behavior may suffice to\nlet the current coordination mechanisms fail. In this paper, we study a\npractical scenario considering the security issues in the presence of agents\nwith arbitrarily faulty or malicious behavior. Under these circumstances,\nlearning an optimal policy becomes particularly challenging, even in the\nunrealistic case that an agent's policy can be made conditional upon all other\nagents' observations. To overcome these difficulties, we present an\nAttention-based Fault-Tolerant (FT-Attn) algorithm which selects correct and\nrelevant information for each agent at every time-step. The multi-head\nattention mechanism enables the agents to learn effective communication\npolicies through experience concurrently to the action policies. Empirical\nresults have shown that FT-Attn beats previous state-of-the-art methods in some\ncomplex environments and can adapt to various kinds of noisy environments\nwithout tuning the complexity of the algorithm. Furthermore, FT-Attn can\neffectively deal with the complex situation where an agent needs to reach\nmultiple agents' correct observation at the same time.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 09:51:04 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Geng", "Mingyang", ""], ["Xu", "Kele", ""], ["Li", "Yiying", ""], ["Liu", "Shuqi", ""], ["Ding", "Bo", ""], ["Wang", "Huaimin", ""]]}, {"id": "1910.02244", "submitter": "Laurent Meunier", "authors": "Laurent Meunier, Jamal Atif, Olivier Teytaud", "title": "Yet another but more efficient black-box adversarial attack: tiling and\n  evolution strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new black-box attack achieving state of the art performances.\nOur approach is based on a new objective function, borrowing ideas from\n$\\ell_\\infty$-white box attacks, and particularly designed to fit\nderivative-free optimization requirements. It only requires to have access to\nthe logits of the classifier without any other information which is a more\nrealistic scenario. Not only we introduce a new objective function, we extend\nprevious works on black box adversarial attacks to a larger spectrum of\nevolution strategies and other derivative-free optimization methods. We also\nhighlight a new intriguing property that deep neural networks are not robust to\nsingle shot tiled attacks. Our models achieve, with a budget limited to\n$10,000$ queries, results up to $99.2\\%$ of success rate against InceptionV3\nclassifier with $630$ queries to the network on average in the untargeted\nattacks setting, which is an improvement by $90$ queries of the current state\nof the art. In the targeted setting, we are able to reach, with a limited\nbudget of $100,000$, $100\\%$ of success rate with a budget of $6,662$ queries\non average, i.e. we need $800$ queries less than the current state of the art.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 10:36:47 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 10:48:51 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Meunier", "Laurent", ""], ["Atif", "Jamal", ""], ["Teytaud", "Olivier", ""]]}, {"id": "1910.02321", "submitter": "Nuno Louren\\c{c}o", "authors": "In\\^es Valentim, Nuno Louren\\c{c}o, Nuno Antunes", "title": "The Impact of Data Preparation on the Fairness of Software Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are widely adopted in scenarios that directly affect\npeople. The development of software systems based on these models raises\nsocietal and legal concerns, as their decisions may lead to the unfair\ntreatment of individuals based on attributes like race or gender. Data\npreparation is key in any machine learning pipeline, but its effect on fairness\nis yet to be studied in detail. In this paper, we evaluate how the fairness and\neffectiveness of the learned models are affected by the removal of the\nsensitive attribute, the encoding of the categorical attributes, and instance\nselection methods (including cross-validators and random undersampling). We\nused the Adult Income and the German Credit Data datasets, which are widely\nstudied and known to have fairness concerns. We applied each data preparation\ntechnique individually to analyse the difference in predictive performance and\nfairness, using statistical parity difference, disparate impact, and the\nnormalised prejudice index. The results show that fairness is affected by\ntransformations made to the training data, particularly in imbalanced datasets.\nRemoving the sensitive attribute is insufficient to eliminate all the\nunfairness in the predictions, as expected, but it is key to achieve fairer\nmodels. Additionally, the standard random undersampling with respect to the\ntrue labels is sometimes more prejudicial than performing no random\nundersampling.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 19:50:16 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Valentim", "In\u00eas", ""], ["Louren\u00e7o", "Nuno", ""], ["Antunes", "Nuno", ""]]}, {"id": "1910.02330", "submitter": "Adish Singla", "authors": "Ahana Ghosh, Sebastian Tschiatschek, Hamed Mahdavi, Adish Singla", "title": "Towards Deployment of Robust AI Agents for Human-Machine Partnerships", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of designing AI agents that can robustly cooperate with\npeople in human-machine partnerships. Our work is inspired by real-life\nscenarios in which an AI agent, e.g., a virtual assistant, has to cooperate\nwith new users after its deployment. We model this problem via a parametric MDP\nframework where the parameters correspond to a user's type and characterize her\nbehavior. In the test phase, the AI agent has to interact with a user of\nunknown type. Our approach to designing a robust AI agent relies on observing\nthe user's actions to make inferences about the user's type and adapting its\npolicy to facilitate efficient cooperation. We show that without being\nadaptive, an AI agent can end up performing arbitrarily bad in the test phase.\nWe develop two algorithms for computing policies that automatically adapt to\nthe user in the test phase. We demonstrate the effectiveness of our approach in\nsolving a two-agent collaborative task.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 21:04:27 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 23:19:40 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Ghosh", "Ahana", ""], ["Tschiatschek", "Sebastian", ""], ["Mahdavi", "Hamed", ""], ["Singla", "Adish", ""]]}, {"id": "1910.02365", "submitter": "Chen Chen", "authors": "Chen Chen, Lisong Qiu, Zhenxin Fu, Dongyan Zhao, Junfei Liu, Rui Yan", "title": "Multilingual Dialogue Generation with Shared-Private Memory", "comments": "Accepted by NLPCC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing dialog systems are all monolingual, where features shared among\ndifferent languages are rarely explored. In this paper, we introduce a novel\nmultilingual dialogue system. Specifically, we augment the sequence to sequence\nframework with improved shared-private memory. The shared memory learns common\nfeatures among different languages and facilitates a cross-lingual transfer to\nboost dialogue systems, while the private memory is owned by each separate\nlanguage to capture its unique feature. Experiments conducted on Chinese and\nEnglish conversation corpora of different scales show that our proposed\narchitecture outperforms the individually learned model with the help of the\nother language, where the improvement is particularly distinct when the\ntraining data is limited.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 04:02:55 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Chen", "Chen", ""], ["Qiu", "Lisong", ""], ["Fu", "Zhenxin", ""], ["Zhao", "Dongyan", ""], ["Liu", "Junfei", ""], ["Yan", "Rui", ""]]}, {"id": "1910.02409", "submitter": "Terence Broad", "authors": "Terence Broad, Mick Grierson", "title": "Searching for an (un)stable equilibrium: experiments in training\n  generative models without data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper details a developing artistic practice around an ongoing series of\nworks called (un)stable equilibrium. These works are the product of using\nmodern machine toolkits to train generative models without data, an approach\nakin to traditional generative art where dynamical systems are explored\nintuitively for their latent generative possibilities. We discuss some of the\nguiding principles that have been learnt in the process of experimentation,\npresent details of the implementation of the first series of works and discuss\npossibilities for future experimentation.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 10:23:06 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Broad", "Terence", ""], ["Grierson", "Mick", ""]]}, {"id": "1910.02426", "submitter": "Dimitri Bertsekas", "authors": "Dimitri Bertsekas", "title": "Biased Aggregation, Rollout, and Enhanced Policy Improvement for\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new aggregation framework for approximate dynamic programming,\nwhich provides a connection with rollout algorithms, approximate policy\niteration, and other single and multistep lookahead methods. The central novel\ncharacteristic is the use of a bias function $V$ of the state, which biases the\nvalues of the aggregate cost function towards their correct levels. The\nclassical aggregation framework is obtained when $V\\equiv0$, but our scheme\nworks best when $V$ is a known reasonably good approximation to the optimal\ncost function $J^*$.\n  When $V$ is equal to the cost function $J_{\\mu}$ of some known policy $\\mu$\nand there is only one aggregate state, our scheme is equivalent to the rollout\nalgorithm based on $\\mu$ (i.e., the result of a single policy improvement\nstarting with the policy $\\mu$). When $V=J_{\\mu}$ and there are multiple\naggregate states, our aggregation approach can be used as a more powerful form\nof improvement of $\\mu$. Thus, when combined with an approximate policy\nevaluation scheme, our approach can form the basis for a new and enhanced form\nof approximate policy iteration.\n  When $V$ is a generic bias function, our scheme is equivalent to\napproximation in value space with lookahead function equal to $V$ plus a local\ncorrection within each aggregate state. The local correction levels are\nobtained by solving a low-dimensional aggregate DP problem, yielding an\narbitrarily close approximation to $J^*$, when the number of aggregate states\nis sufficiently large. Except for the bias function, the aggregate DP problem\nis similar to the one of the classical aggregation framework, and its\nalgorithmic solution by simulation or other methods is nearly identical to one\nfor classical aggregation, assuming values of $V$ are available when needed.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 11:51:00 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Bertsekas", "Dimitri", ""]]}, {"id": "1910.02453", "submitter": "Karl Schlechta", "authors": "Karl Schlechta", "title": "A Short Remark on Analogical Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the problem of defining a logic for analogical reasoning, and\nsketch a solution in the style of the semantics for Counterfactual\nConditionals, Preferential Structures, etc.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 14:14:04 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Schlechta", "Karl", ""]]}, {"id": "1910.02461", "submitter": "Majid Khonji", "authors": "Majid Khonji, Jorge Dias, and Lakmal Seneviratne", "title": "Risk-Aware Reasoning for Autonomous Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant barrier to deploying autonomous vehicles (AVs) on a massive\nscale is safety assurance. Several technical challenges arise due to the\nuncertain environment in which AVs operate such as road and weather conditions,\nerrors in perception and sensory data, and also model inaccuracy. In this\npaper, we propose a system architecture for risk-aware AVs capable of reasoning\nabout uncertainty and deliberately bounding the risk of collision below a given\nthreshold. We discuss key challenges in the area, highlight recent research\ndevelopments, and propose future research directions in three subsystems.\nFirst, a perception subsystem that detects objects within a scene while\nquantifying the uncertainty that arises from different sensing and\ncommunication modalities. Second, an intention recognition subsystem that\npredicts the driving-style and the intention of agent vehicles (and\npedestrians). Third, a planning subsystem that takes into account the\nuncertainty, from perception and intention recognition subsystems, and\npropagates all the way to control policies that explicitly bound the risk of\ncollision. We believe that such a white-box approach is crucial for future\nadoption of AVs on a large scale.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 15:15:57 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Khonji", "Majid", ""], ["Dias", "Jorge", ""], ["Seneviratne", "Lakmal", ""]]}, {"id": "1910.02481", "submitter": "Yuan Yang", "authors": "Yuan Yang, Le Song", "title": "Learn to Explain Efficiently via Neural Logic Inductive Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The capability of making interpretable and self-explanatory decisions is\nessential for developing responsible machine learning systems. In this work, we\nstudy the learning to explain problem in the scope of inductive logic\nprogramming (ILP). We propose Neural Logic Inductive Learning (NLIL), an\nefficient differentiable ILP framework that learns first-order logic rules that\ncan explain the patterns in the data. In experiments, compared with the\nstate-of-the-art methods, we find NLIL can search for rules that are x10 times\nlonger while remaining x3 times faster. We also show that NLIL can scale to\nlarge image datasets, i.e. Visual Genome, with 1M entities.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 17:20:31 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 23:00:27 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 19:01:05 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Yang", "Yuan", ""], ["Song", "Le", ""]]}, {"id": "1910.02486", "submitter": "Orsolya Csisz\\'ar", "authors": "Orsolya Csisz\\'ar, G\\'abor Csisz\\'ar, J\\'ozsef Dombi", "title": "Interpretable neural networks based on continuous-valued logic and\n  multicriteria decision operators", "comments": null, "journal-ref": "j.knosys.2020", "doi": "10.1016/j.knosys.2020.105972", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining neural networks with continuous logic and multicriteria decision\nmaking tools can reduce the black box nature of neural models. In this study,\nwe show that nilpotent logical systems offer an appropriate mathematical\nframework for a hybridization of continuous nilpotent logic and neural models,\nhelping to improve the interpretability and safety of machine learning. In our\nconcept, perceptrons model soft inequalities; namely membership functions and\ncontinuous logical operators. We design the network architecture before\ntraining, using continuous logical operators and multicriteria decision tools\nwith given weights working in the hidden layers. Designing the structure\nappropriately leads to a drastic reduction in the number of parameters to be\nlearned. The theoretical basis offers a straightforward choice of activation\nfunctions (the cutting function or its differentiable approximation, the\nsquashing function), and also suggests an explanation to the great success of\nthe rectified linear unit (ReLU). In this study, we focus on the architecture\nof a hybrid model and introduce the building blocks for future application in\ndeep neural networks. The concept is illustrated with some toy examples taken\nfrom an extended version of the tensorflow playground.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 18:20:59 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 07:39:08 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Csisz\u00e1r", "Orsolya", ""], ["Csisz\u00e1r", "G\u00e1bor", ""], ["Dombi", "J\u00f3zsef", ""]]}, {"id": "1910.02516", "submitter": "Andrew McGough", "authors": "Alexander J. M. Kell and Matthew Forshaw and A. Stephen McGough", "title": "Optimising energy and overhead for large parameter space simulations", "comments": "Accepted for IGSC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many systems require optimisation over multiple objectives, where objectives\nare characteristics of the system such as energy consumed or increase in time\nto perform the work. Optimisation is performed by selecting the `best' set of\ninput parameters to elicit the desired objectives. However, the parameter\nsearch space can often be far larger than can be searched in a reasonable time.\nAdditionally, the objectives are often mutually exclusive -- leading to a\ndecision being made as to which objective is more important or optimising over\na combination of the objectives. This work is an application of a Genetic\nAlgorithm to identify the Pareto frontier for finding the optimal parameter\nsets for all combinations of objectives. A Pareto frontier can be used to\nidentify the sets of optimal parameters for which each is the `best' for a\ngiven combination of objectives -- thus allowing decisions to be made with full\nknowledge. We demonstrate this approach for the HTC-Sim simulation system in\nthe case where a Reinforcement Learning scheduler is tuned for the two\nobjectives of energy consumption and task overhead. Demonstrating that this\napproach can reduce the energy consumed by ~36% over previously published work\nwithout significantly increasing the overhead.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 20:21:16 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Kell", "Alexander J. M.", ""], ["Forshaw", "Matthew", ""], ["McGough", "A. Stephen", ""]]}, {"id": "1910.02517", "submitter": "Preslav Nakov", "authors": "Giovanni Da San Martino, Seunghak Yu, Alberto Barr\\'on-Cede\\~no,\n  Rostislav Petrov, Preslav Nakov", "title": "Fine-Grained Analysis of Propaganda in News Articles", "comments": null, "journal-ref": "EMNLP-2019", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Propaganda aims at influencing people's mindset with the purpose of advancing\na specific agenda. Previous work has addressed propaganda detection at the\ndocument level, typically labelling all articles from a propagandistic news\noutlet as propaganda. Such noisy gold labels inevitably affect the quality of\nany learning system trained on them. A further issue with most existing systems\nis the lack of explainability. To overcome these limitations, we propose a\nnovel task: performing fine-grained analysis of texts by detecting all\nfragments that contain propaganda techniques as well as their type. In\nparticular, we create a corpus of news articles manually annotated at the\nfragment level with eighteen propaganda techniques and we propose a suitable\nevaluation measure. We further design a novel multi-granularity neural network,\nand we show that it outperforms several strong BERT-based baselines.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 20:26:12 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Martino", "Giovanni Da San", ""], ["Yu", "Seunghak", ""], ["Barr\u00f3n-Cede\u00f1o", "Alberto", ""], ["Petrov", "Rostislav", ""], ["Nakov", "Preslav", ""]]}, {"id": "1910.02551", "submitter": "Ilia Sucholutsky", "authors": "Ilia Sucholutsky, Matthias Schonlau", "title": "Soft-Label Dataset Distillation and Text Dataset Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dataset distillation is a method for reducing dataset sizes by learning a\nsmall number of synthetic samples containing all the information of a large\ndataset. This has several benefits like speeding up model training, reducing\nenergy consumption, and reducing required storage space. Currently, each\nsynthetic sample is assigned a single `hard' label, and also, dataset\ndistillation can currently only be used with image data.\n  We propose to simultaneously distill both images and their labels, thus\nassigning each synthetic sample a `soft' label (a distribution of labels). Our\nalgorithm increases accuracy by 2-4% over the original algorithm for several\nimage classification tasks. Using `soft' labels also enables distilled datasets\nto consist of fewer samples than there are classes as each sample can encode\ninformation for multiple classes. For example, training a LeNet model with 10\ndistilled images (one per class) results in over 96% accuracy on MNIST, and\nalmost 92% accuracy when trained on just 5 distilled images.\n  We also extend the dataset distillation algorithm to distill sequential\ndatasets including texts. We demonstrate that text distillation outperforms\nother methods across multiple datasets. For example, models attain almost their\noriginal accuracy on the IMDB sentiment analysis task using just 20 distilled\nsentences.\n  Our code can be found at\n$\\href{https://github.com/ilia10000/dataset-distillation}{\\text{https://github.com/ilia10000/dataset-distillation}}$.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 23:57:22 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 21:01:12 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 04:09:03 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Sucholutsky", "Ilia", ""], ["Schonlau", "Matthias", ""]]}, {"id": "1910.02610", "submitter": "Jifan Chen", "authors": "Jifan Chen, Shih-ting Lin, Greg Durrett", "title": "Multi-hop Question Answering via Reasoning Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop question answering requires models to gather information from\ndifferent parts of a text to answer a question. Most current approaches learn\nto address this task in an end-to-end way with neural networks, without\nmaintaining an explicit representation of the reasoning process. We propose a\nmethod to extract a discrete reasoning chain over the text, which consists of a\nseries of sentences leading to the answer. We then feed the extracted chains to\na BERT-based QA model to do final answer prediction. Critically, we do not rely\non gold annotated chains or \"supporting facts:\" at training time, we derive\npseudogold reasoning chains using heuristics based on named entity recognition\nand coreference resolution. Nor do we rely on these annotations at test time,\nas our model learns to extract chains from raw text alone. We test our approach\non two recently proposed large multi-hop question answering datasets: WikiHop\nand HotpotQA, and achieve state-of-art performance on WikiHop and strong\nperformance on HotpotQA. Our analysis shows the properties of chains that are\ncrucial for high performance: in particular, modeling extraction sequentially\nis important, as is dealing with each candidate sentence in a context-aware\nway. Furthermore, human evaluation shows that our extracted chains allow humans\nto give answers with high confidence, indicating that these are a strong\nintermediate abstraction for this task.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 04:58:43 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 04:29:57 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Chen", "Jifan", ""], ["Lin", "Shih-ting", ""], ["Durrett", "Greg", ""]]}, {"id": "1910.02646", "submitter": "Mustafa Mukadam", "authors": "Mustafa Mukadam, Ching-An Cheng, Dieter Fox, Byron Boots, Nathan\n  Ratliff", "title": "Riemannian Motion Policy Fusion through Learnable Lyapunov Function\n  Reshaping", "comments": "Conference on Robot Learning (CoRL), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RMPflow is a recently proposed policy-fusion framework based on differential\ngeometry. While RMPflow has demonstrated promising performance, it requires the\nuser to provide sensible subtask policies as Riemannian motion policies (RMPs:\na motion policy and an importance matrix function), which can be a difficult\ndesign problem in its own right. We propose RMPfusion, a variation of RMPflow,\nto address this issue. RMPfusion supplements RMPflow with weight functions that\ncan hierarchically reshape the Lyapunov functions of the subtask RMPs according\nto the current configuration of the robot and environment. This extra\nflexibility can remedy imperfect subtask RMPs provided by the user, improving\nthe combined policy's performance. These weight functions can be learned by\nback-propagation. Moreover, we prove that, under mild restrictions on the\nweight functions, RMPfusion always yields a globally Lyapunov-stable motion\npolicy. This implies that we can treat RMPfusion as a structured policy class\nin policy optimization that is guaranteed to generate stable policies, even\nduring the immature phase of learning. We demonstrate these properties of\nRMPfusion in imitation learning experiments both in simulation and on a\nreal-world robot.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 07:37:34 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 05:34:04 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Mukadam", "Mustafa", ""], ["Cheng", "Ching-An", ""], ["Fox", "Dieter", ""], ["Boots", "Byron", ""], ["Ratliff", "Nathan", ""]]}, {"id": "1910.02758", "submitter": "Hector Zenil", "authors": "Santiago Hern\\'andez-Orozco, Hector Zenil, J\\\"urgen Riedel, Adam\n  Uccello, Narsis A. Kiani, Jesper Tegn\\'er", "title": "Algorithmic Probability-guided Supervised Machine Learning on\n  Non-differentiable Spaces", "comments": "33 pages including appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how complexity theory can be introduced in machine learning to help\nbring together apparently disparate areas of current research. We show that\nthis new approach requires less training data and is more generalizable as it\nshows greater resilience to random attacks. We investigate the shape of the\ndiscrete algorithmic space when performing regression or classification using a\nloss function parametrized by algorithmic complexity, demonstrating that the\nproperty of differentiation is not necessary to achieve results similar to\nthose obtained using differentiable programming approaches such as deep\nlearning. In doing so we use examples which enable the two approaches to be\ncompared (small, given the computational power required for estimations of\nalgorithmic complexity). We find and report that (i) machine learning can\nsuccessfully be performed on a non-smooth surface using algorithmic complexity;\n(ii) that parameter solutions can be found using an algorithmic-probability\nclassifier, establishing a bridge between a fundamentally discrete theory of\ncomputability and a fundamentally continuous mathematical theory of\noptimization methods; (iii) a formulation of an algorithmically directed search\ntechnique in non-smooth manifolds can be defined and conducted; (iv)\nexploitation techniques and numerical methods for algorithmic search to\nnavigate these discrete non-differentiable spaces can be performed; in\napplication of the (a) identification of generative rules from data\nobservations; (b) solutions to image classification problems more resilient\nagainst pixel attacks compared to neural networks; (c) identification of\nequation parameters from a small data-set in the presence of noise in\ncontinuous ODE system problem, (d) classification of Boolean NK networks by (1)\nnetwork topology, (2) underlying Boolean function, and (3) number of incoming\nedges.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 12:48:58 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 23:41:44 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Hern\u00e1ndez-Orozco", "Santiago", ""], ["Zenil", "Hector", ""], ["Riedel", "J\u00fcrgen", ""], ["Uccello", "Adam", ""], ["Kiani", "Narsis A.", ""], ["Tegn\u00e9r", "Jesper", ""]]}, {"id": "1910.02789", "submitter": "Guy Tennenholtz", "authors": "Erez Schwartz, Guy Tennenholtz, Chen Tessler, Shie Mannor", "title": "Language is Power: Representing States Using Natural Language in\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in reinforcement learning have shown its potential to tackle\ncomplex real-life tasks. However, as the dimensionality of the task increases,\nreinforcement learning methods tend to struggle. To overcome this, we explore\nmethods for representing the semantic information embedded in the state. While\nprevious methods focused on information in its raw form (e.g., raw visual\ninput), we propose to represent the state using natural language. Language can\nrepresent complex scenarios and concepts, making it a favorable candidate for\nrepresentation. Empirical evidence, within the domain of ViZDoom, suggests that\nnatural language based agents are more robust, converge faster and perform\nbetter than vision based agents, showing the benefit of using natural language\nrepresentations for reinforcement learning.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 11:06:17 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 07:16:02 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Schwartz", "Erez", ""], ["Tennenholtz", "Guy", ""], ["Tessler", "Chen", ""], ["Mannor", "Shie", ""]]}, {"id": "1910.02812", "submitter": "Atil Iscen", "authors": "Atil Iscen, Ken Caluwaerts, Jie Tan, Tingnan Zhang, Erwin Coumans,\n  Vikas Sindhwani, Vincent Vanhoucke", "title": "Policies Modulating Trajectory Generators", "comments": null, "journal-ref": "In Proceedings of The 2nd Conference on Robot Learning, volume 87\n  of Proceedings of Machine Learning Research, pages 916-926. PMLR, 29-31 Oct\n  2018", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an architecture for learning complex controllable behaviors by\nhaving simple Policies Modulate Trajectory Generators (PMTG), a powerful\ncombination that can provide both memory and prior knowledge to the controller.\nThe result is a flexible architecture that is applicable to a class of problems\nwith periodic motion for which one has an insight into the class of\ntrajectories that might lead to a desired behavior. We illustrate the basics of\nour architecture using a synthetic control problem, then go on to learn\nspeed-controlled locomotion for a quadrupedal robot by using Deep Reinforcement\nLearning and Evolutionary Strategies. We demonstrate that a simple linear\npolicy, when paired with a parametric Trajectory Generator for quadrupedal\ngaits, can induce walking behaviors with controllable speed from 4-dimensional\nIMU observations alone, and can be learned in under 1000 rollouts. We also\ntransfer these policies to a real robot and show locomotion with controllable\nforward velocity.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 14:20:05 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Iscen", "Atil", ""], ["Caluwaerts", "Ken", ""], ["Tan", "Jie", ""], ["Zhang", "Tingnan", ""], ["Coumans", "Erwin", ""], ["Sindhwani", "Vikas", ""], ["Vanhoucke", "Vincent", ""]]}, {"id": "1910.02830", "submitter": "Viraj Prabhu", "authors": "Viraj Prabhu, Anitha Kannan, Geoffrey J. Tso, Namit Katariya, Manish\n  Chablani, David Sontag, Xavier Amatriain", "title": "Open Set Medical Diagnosis", "comments": "Abbreviated version to appear at Machine Learning for Healthcare\n  (ML4H) Workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-learned diagnosis models have shown promise as medical aides but are\ntrained under a closed-set assumption, i.e. that models will only encounter\nconditions on which they have been trained. However, it is practically\ninfeasible to obtain sufficient training data for every human condition, and\nonce deployed such models will invariably face previously unseen conditions. We\nframe machine-learned diagnosis as an open-set learning problem, and study how\nstate-of-the-art approaches compare. Further, we extend our study to a setting\nwhere training data is distributed across several healthcare sites that do not\nallow data pooling, and experiment with different strategies of building\nopen-set diagnostic ensembles. Across both settings, we observe consistent\ngains from explicitly modeling unseen conditions, but find the optimal training\nstrategy to vary across settings.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 14:45:47 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Prabhu", "Viraj", ""], ["Kannan", "Anitha", ""], ["Tso", "Geoffrey J.", ""], ["Katariya", "Namit", ""], ["Chablani", "Manish", ""], ["Sontag", "David", ""], ["Amatriain", "Xavier", ""]]}, {"id": "1910.02835", "submitter": "Steve Heim", "authors": "Steve Heim, Alexander von Rohr, Sebastian Trimpe, and Alexander\n  Badri-Spr\\\"owitz", "title": "A Learnable Safety Measure", "comments": "10 pages, Conference on Robot Learning CoRL 2019, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Failures are challenging for learning to control physical systems since they\nrisk damage, time-consuming resets, and often provide little gradient\ninformation. Adding safety constraints to exploration typically requires a lot\nof prior knowledge and domain expertise. We present a safety measure which\nimplicitly captures how the system dynamics relate to a set of failure states.\nNot only can this measure be used as a safety function, but also to directly\ncompute the set of safe state-action pairs. Further, we show a model-free\napproach to learn this measure by active sampling using Gaussian processes.\nWhile safety can only be guaranteed after learning the safety measure, we show\nthat failures can already be greatly reduced by using the estimated measure\nduring learning.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 14:53:15 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Heim", "Steve", ""], ["von Rohr", "Alexander", ""], ["Trimpe", "Sebastian", ""], ["Badri-Spr\u00f6witz", "Alexander", ""]]}, {"id": "1910.02876", "submitter": "Ali Shafti", "authors": "Petros Christodoulou, Robert Tjarko Lange, Ali Shafti, A. Aldo Faisal", "title": "Reinforcement Learning with Structured Hierarchical Grammar\n  Representations of Actions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From a young age humans learn to use grammatical principles to hierarchically\ncombine words into sentences. Action grammars is the parallel idea, that there\nis an underlying set of rules (a \"grammar\") that govern how we hierarchically\ncombine actions to form new, more complex actions. We introduce the Action\nGrammar Reinforcement Learning (AG-RL) framework which leverages the concept of\naction grammars to consistently improve the sample efficiency of Reinforcement\nLearning agents. AG-RL works by using a grammar inference algorithm to infer\nthe \"action grammar\" of an agent midway through training. The agent's action\nspace is then augmented with macro-actions identified by the grammar. We apply\nthis framework to Double Deep Q-Learning (AG-DDQN) and a discrete action\nversion of Soft Actor-Critic (AG-SAC) and find that it improves performance in\n8 out of 8 tested Atari games (median +31%, max +668%) and 19 out of 20 tested\nAtari games (median +96%, maximum +3,756%) respectively without substantive\nhyperparameter tuning. We also show that AG-SAC beats the model-free\nstate-of-the-art for sample efficiency in 17 out of the 20 tested Atari games\n(median +62%, maximum +13,140%), again without substantive hyperparameter\ntuning.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 15:59:20 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 10:23:19 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Christodoulou", "Petros", ""], ["Lange", "Robert Tjarko", ""], ["Shafti", "Ali", ""], ["Faisal", "A. Aldo", ""]]}, {"id": "1910.02915", "submitter": "Chaitanya Malaviya", "authors": "Chaitanya Malaviya, Chandra Bhagavatula, Antoine Bosselut, Yejin Choi", "title": "Commonsense Knowledge Base Completion with Structural and Semantic\n  Context", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic KB completion for commonsense knowledge graphs (e.g., ATOMIC and\nConceptNet) poses unique challenges compared to the much studied conventional\nknowledge bases (e.g., Freebase). Commonsense knowledge graphs use free-form\ntext to represent nodes, resulting in orders of magnitude more nodes compared\nto conventional KBs (18x more nodes in ATOMIC compared to Freebase\n(FB15K-237)). Importantly, this implies significantly sparser graph structures\n- a major challenge for existing KB completion methods that assume densely\nconnected graphs over a relatively smaller set of nodes. In this paper, we\npresent novel KB completion models that can address these challenges by\nexploiting the structural and semantic context of nodes. Specifically, we\ninvestigate two key ideas: (1) learning from local graph structure, using graph\nconvolutional networks and automatic graph densification and (2) transfer\nlearning from pre-trained language models to knowledge graphs for enhanced\ncontextual representation of knowledge. We describe our method to incorporate\ninformation from both these sources in a joint model and provide the first\nempirical results for KB completion on ATOMIC and evaluation with ranking\nmetrics on ConceptNet. Our results demonstrate the effectiveness of language\nmodel representations in boosting link prediction performance and the\nadvantages of learning from local graph structure (+1.5 points in MRR for\nConceptNet) when training on subgraphs for computational efficiency. Further\nanalysis on model predictions shines light on the types of commonsense\nknowledge that language models capture well.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 17:16:04 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 20:02:50 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Malaviya", "Chaitanya", ""], ["Bhagavatula", "Chandra", ""], ["Bosselut", "Antoine", ""], ["Choi", "Yejin", ""]]}, {"id": "1910.03014", "submitter": "Jeremy Frank", "authors": "Jeremy D. Frank", "title": "Artificial Intelligence: Powering Human Exploration of the Moon and Mars", "comments": "Presented at AAAI FSS-19: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade, the NASA Autonomous Systems and Operations (ASO)\nproject has developed and demonstrated numerous autonomy enabling technologies\nemploying AI techniques. Our work has employed AI in three distinct ways to\nenable autonomous mission operations capabilities. Crew Autonomy gives\nastronauts tools to assist in the performance of each of these mission\noperations functions. Vehicle System Management uses AI techniques to turn the\nastronaut's spacecraft into a robot, allowing it to operate when astronauts are\nnot present, or to reduce astronaut workload. AI technology also enables\nAutonomous Robots as crew assistants or proxies when the crew are not present.\nWe first describe human spaceflight mission operations capabilities. We then\ndescribe the ASO project, and the development and demonstration performed by\nASO since 2011. We will describe the AI techniques behind each of these\ndemonstrations, which include a variety of symbolic automated reasoning and\nmachine learning based approaches. Finally, we conclude with an assessment of\nfuture development needs for AI to enable NASA's future Exploration missions.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 19:04:02 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Frank", "Jeremy D.", ""]]}, {"id": "1910.03016", "submitter": "Ruosong Wang", "authors": "Simon S. Du and Sham M. Kakade and Ruosong Wang and Lin F. Yang", "title": "Is a Good Representation Sufficient for Sample Efficient Reinforcement\n  Learning?", "comments": "To appear in ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep learning methods provide effective means to learn good\nrepresentations. However, is a good representation itself sufficient for sample\nefficient reinforcement learning? This question has largely been studied only\nwith respect to (worst-case) approximation error, in the more classical\napproximate dynamic programming literature. With regards to the statistical\nviewpoint, this question is largely unexplored, and the extant body of\nliterature mainly focuses on conditions which permit sample efficient\nreinforcement learning with little understanding of what are necessary\nconditions for efficient reinforcement learning.\n  This work shows that, from the statistical viewpoint, the situation is far\nsubtler than suggested by the more traditional approximation viewpoint, where\nthe requirements on the representation that suffice for sample efficient RL are\neven more stringent. Our main results provide sharp thresholds for\nreinforcement learning methods, showing that there are hard limitations on what\nconstitutes good function approximation (in terms of the dimensionality of the\nrepresentation), where we focus on natural representational conditions relevant\nto value-based, model-based, and policy-based learning. These lower bounds\nhighlight that having a good (value-based, model-based, or policy-based)\nrepresentation in and of itself is insufficient for efficient reinforcement\nlearning, unless the quality of this approximation passes certain hard\nthresholds. Furthermore, our lower bounds also imply exponential separations on\nthe sample complexity between 1) value-based learning with perfect\nrepresentation and value-based learning with a good-but-not-perfect\nrepresentation, 2) value-based learning and policy-based learning, 3)\npolicy-based learning and supervised learning and 4) reinforcement learning and\nimitation learning.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 19:04:43 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 04:04:19 GMT"}, {"version": "v3", "created": "Sun, 3 Nov 2019 01:00:13 GMT"}, {"version": "v4", "created": "Fri, 28 Feb 2020 03:31:55 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Du", "Simon S.", ""], ["Kakade", "Sham M.", ""], ["Wang", "Ruosong", ""], ["Yang", "Lin F.", ""]]}, {"id": "1910.03042", "submitter": "Dian Yu", "authors": "Dian Yu, Michelle Cohn, Yi Mang Yang, Chun-Yen Chen, Weiming Wen,\n  Jiaping Zhang, Mingyang Zhou, Kevin Jesse, Austin Chau, Antara Bhowmick,\n  Shreenath Iyer, Giritheja Sreenivasulu, Sam Davidson, Ashwin Bhandare, Zhou\n  Yu", "title": "Gunrock: A Social Bot for Complex and Engaging Long Conversations", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gunrock is the winner of the 2018 Amazon Alexa Prize, as evaluated by\ncoherence and engagement from both real users and Amazon-selected expert\nconversationalists. We focus on understanding complex sentences and having\nin-depth conversations in open domains. In this paper, we introduce some\ninnovative system designs and related validation analysis. Overall, we found\nthat users produce longer sentences to Gunrock, which are directly related to\nusers' engagement (e.g., ratings, number of turns). Additionally, users'\nbackstory queries about Gunrock are positively correlated to user satisfaction.\nFinally, we found dialog flows that interleave facts and personal opinions and\nstories lead to better user satisfaction.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 19:24:36 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Yu", "Dian", ""], ["Cohn", "Michelle", ""], ["Yang", "Yi Mang", ""], ["Chen", "Chun-Yen", ""], ["Wen", "Weiming", ""], ["Zhang", "Jiaping", ""], ["Zhou", "Mingyang", ""], ["Jesse", "Kevin", ""], ["Chau", "Austin", ""], ["Bhowmick", "Antara", ""], ["Iyer", "Shreenath", ""], ["Sreenivasulu", "Giritheja", ""], ["Davidson", "Sam", ""], ["Bhandare", "Ashwin", ""], ["Yu", "Zhou", ""]]}, {"id": "1910.03055", "submitter": "Teny Handhayani", "authors": "Teny Handhayani and James Cussens", "title": "Kernel-based Approach to Handle Mixed Data for Inferring Causal Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal learning is a beneficial approach to analyze the cause and effect\nrelationships among variables in a dataset. A causal graph can be generated\nfrom a dataset using a particular causal algorithm, for instance, the PC\nalgorithm or Fast Causal Inference (FCI). Generating a causal graph from a\ndataset that contains different data types (mixed data) is not trivial. This\nresearch offers an easy way to handle the mixed data so that it can be used to\nlearn causal graphs using the existing application of the PC algorithm and FCI.\nThis research proposes using kernel functions and Kernel Alignment to handle\nmixed data. Two main steps of this approach are computing a kernel matrix for\neach variable and calculating a pseudo-correlation matrix using Kernel\nAlignment. Kernel Alignment is used as a substitute for the correlation matrix\nfor the conditional independence test for Gaussian data in the PC Algorithm and\nFCI. The advantage of this idea is that is possible to handle any data type by\nusing a suitable kernel function to compute a kernel matrix for an observed\nvariable. The proposed method is successfully applied to learn a causal graph\nfrom mixed data containing categorical, binary, ordinal, and continuous\nvariables.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 19:57:08 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Handhayani", "Teny", ""], ["Cussens", "James", ""]]}, {"id": "1910.03065", "submitter": "Oana-Maria Camburu", "authors": "Oana-Maria Camburu, Brendan Shillingford, Pasquale Minervini, Thomas\n  Lukasiewicz, Phil Blunsom", "title": "Make Up Your Mind! Adversarial Generation of Inconsistent Natural\n  Language Explanations", "comments": null, "journal-ref": "Short Paper at ACL, 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To increase trust in artificial intelligence systems, a promising research\ndirection consists of designing neural models capable of generating natural\nlanguage explanations for their predictions. In this work, we show that such\nmodels are nonetheless prone to generating mutually inconsistent explanations,\nsuch as \"Because there is a dog in the image\" and \"Because there is no dog in\nthe [same] image\", exposing flaws in either the decision-making process of the\nmodel or in the generation of the explanations. We introduce a simple yet\neffective adversarial framework for sanity checking models against the\ngeneration of inconsistent natural language explanations. Moreover, as part of\nthe framework, we address the problem of adversarial attacks with full target\nsequences, a scenario that was not previously addressed in sequence-to-sequence\nattacks. Finally, we apply our framework on a state-of-the-art neural natural\nlanguage inference model that provides natural language explanations for its\npredictions. Our framework shows that this model is capable of generating a\nsignificant number of inconsistent explanations.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 20:14:23 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 14:56:58 GMT"}, {"version": "v3", "created": "Sat, 2 May 2020 10:37:06 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Camburu", "Oana-Maria", ""], ["Shillingford", "Brendan", ""], ["Minervini", "Pasquale", ""], ["Lukasiewicz", "Thomas", ""], ["Blunsom", "Phil", ""]]}, {"id": "1910.03094", "submitter": "Michael V Sullins", "authors": "Ian A. Kash, Michael Sullins, Katja Hofmann", "title": "Combining No-regret and Q-learning", "comments": "Presented as conference paper at AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual Regret Minimization (CFR) has found success in settings like\npoker which have both terminal states and perfect recall. We seek to understand\nhow to relax these requirements. As a first step, we introduce a simple\nalgorithm, local no-regret learning (LONR), which uses a Q-learning-like update\nrule to allow learning without terminal states or perfect recall. We prove its\nconvergence for the basic case of MDPs (and limited extensions of them) and\npresent empirical results showing that it achieves last iterate convergence in\na number of settings, most notably NoSDE games, a class of Markov games\nspecifically designed to be challenging to learn where no prior algorithm is\nknown to achieve convergence to a stationary equilibrium even on average.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 21:13:55 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 16:58:54 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Kash", "Ian A.", ""], ["Sullins", "Michael", ""], ["Hofmann", "Katja", ""]]}, {"id": "1910.03137", "submitter": "Xiaojun Xu", "authors": "Xiaojun Xu, Qi Wang, Huichen Li, Nikita Borisov, Carl A. Gunter, Bo Li", "title": "Detecting AI Trojans Using Meta Neural Analysis", "comments": "Accepted by IEEE S&P 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning Trojan attacks, an adversary trains a corrupted model\nthat obtains good performance on normal data but behaves maliciously on data\nsamples with certain trigger patterns. Several approaches have been proposed to\ndetect such attacks, but they make undesirable assumptions about the attack\nstrategies or require direct access to the trained models, which restricts\ntheir utility in practice.\n  This paper addresses these challenges by introducing a Meta Neural Trojan\nDetection (MNTD) pipeline that does not make assumptions on the attack\nstrategies and only needs black-box access to models. The strategy is to train\na meta-classifier that predicts whether a given target model is Trojaned. To\ntrain the meta-model without knowledge of the attack strategy, we introduce a\ntechnique called jumbo learning that samples a set of Trojaned models following\na general distribution. We then dynamically optimize a query set together with\nthe meta-classifier to distinguish between Trojaned and benign models.\n  We evaluate MNTD with experiments on vision, speech, tabular data and natural\nlanguage text datasets, and against different Trojan attacks such as data\npoisoning attack, model manipulation attack, and latent attack. We show that\nMNTD achieves 97% detection AUC score and significantly outperforms existing\ndetection approaches. In addition, MNTD generalizes well and achieves high\ndetection performance against unforeseen attacks. We also propose a robust MNTD\npipeline which achieves 90% detection AUC even when the attacker aims to evade\nthe detection with full knowledge of the system.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 00:00:23 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 15:35:55 GMT"}, {"version": "v3", "created": "Tue, 25 Aug 2020 00:24:01 GMT"}, {"version": "v4", "created": "Thu, 1 Oct 2020 17:06:03 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Xu", "Xiaojun", ""], ["Wang", "Qi", ""], ["Li", "Huichen", ""], ["Borisov", "Nikita", ""], ["Gunter", "Carl A.", ""], ["Li", "Bo", ""]]}, {"id": "1910.03144", "submitter": "Yizheng Zhang", "authors": "Yizheng Zhang and Andre Rosendo", "title": "Tactical Reward Shaping: Bypassing Reinforcement Learning with\n  Strategy-Based Goals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) has shown its promising capabilities to\nlearn optimal policies directly from trial and error. However, learning can be\nhindered if the goal of the learning, defined by the reward function, is \"not\noptimal\". We demonstrate that by setting the goal/target of competition in a\ncounter-intuitive but intelligent way, instead of heuristically trying\nsolutions through many hours the DRL simulation can quickly converge into a\nwinning strategy. The ICRA-DJI RoboMaster AI Challenge is a game of cooperation\nand competition between robots in a partially observable environment, quite\nsimilar to the Counter-Strike game. Unlike the traditional approach to games,\nwhere the reward is given at winning the match or hitting the enemy, our DRL\nalgorithm rewards our robots when in a geometric-strategic advantage, which\nimplicitly increases the winning chances. Furthermore, we use Deep Q Learning\n(DQL) to generate multi-agent paths for moving, which improves the cooperation\nbetween two robots by avoiding the collision. Finally, we implement a variant\nA* algorithm with the same implicit geometric goal as DQL and compare results.\nWe conclude that a well-set goal can put in question the need for learning\nalgorithms, with geometric-based searches outperforming DQL in many orders of\nmagnitude.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 00:38:28 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Zhang", "Yizheng", ""], ["Rosendo", "Andre", ""]]}, {"id": "1910.03295", "submitter": "Xusheng Luo", "authors": "Xusheng Luo, Yonghua Yang, Kenny Q. Zhu, Yu Gong and Keping Yang", "title": "Conceptualize and Infer User Needs in E-commerce", "comments": "9 pages, 6 figures. Accepted by CIKM 2019 Applied Research Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding latent user needs beneath shopping behaviors is critical to\ne-commercial applications. Without a proper definition of user needs in\ne-commerce, most industry solutions are not driven directly by user needs at\ncurrent stage, which prevents them from further improving user satisfaction.\nRepresenting implicit user needs explicitly as nodes like \"outdoor barbecue\" or\n\"keep warm for kids\" in a knowledge graph, provides new imagination for various\ne- commerce applications. Backed by such an e-commerce knowledge graph, we\npropose a supervised learning algorithm to conceptualize user needs from their\ntransaction history as \"concept\" nodes in the graph and infer those concepts\nfor each user through a deep attentive model. Offline experiments demonstrate\nthe effectiveness and stability of our model, and online industry strength\ntests show substantial advantages of such user needs understanding.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 09:29:56 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Luo", "Xusheng", ""], ["Yang", "Yonghua", ""], ["Zhu", "Kenny Q.", ""], ["Gong", "Yu", ""], ["Yang", "Keping", ""]]}, {"id": "1910.03398", "submitter": "Sahba Aghajani Pedram", "authors": "Sahba Aghajani Pedram, Peter Walker Ferguson, Changyeob Shin, Ankur\n  Mehta, Erik P. Dutson, Farshid Alambeigi, Jacob Rosen", "title": "Toward Synergic Learning for Autonomous Manipulation of Deformable\n  Tissues via Surgical Robots: An Approximate Q-Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a synergic learning algorithm to address the task\nof indirect manipulation of an unknown deformable tissue. Tissue manipulation\nis a common yet challenging task in various surgical interventions, which makes\nit a good candidate for robotic automation. We propose using a linear\napproximate Q-learning method in which human knowledge contributes to selecting\nuseful yet simple features of tissue manipulation while the algorithm learns to\ntake optimal actions and accomplish the task. The algorithm is implemented and\nevaluated on a simulation using the OpenCV and CHAI3D libraries. Successful\nsimulation results for four different configurations which are based on\nrealistic tissue manipulation scenarios are presented. Results indicate that\nwith a careful selection of relatively simple and intuitive features, the\ndeveloped Q-learning algorithm can successfully learn an optimal policy without\nany prior knowledge of tissue dynamics or camera intrinsic/extrinsic\ncalibration parameters.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 13:53:35 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 17:27:24 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Pedram", "Sahba Aghajani", ""], ["Ferguson", "Peter Walker", ""], ["Shin", "Changyeob", ""], ["Mehta", "Ankur", ""], ["Dutson", "Erik P.", ""], ["Alambeigi", "Farshid", ""], ["Rosen", "Jacob", ""]]}, {"id": "1910.03455", "submitter": "Abby Stylianou", "authors": "Abby Stylianou, Richard Souvenir and Robert Pless", "title": "TraffickCam: Explainable Image Matching For Sex Trafficking\n  Investigations", "comments": "Presented at AAAI FSS-19: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Investigations of sex trafficking sometimes have access to photographs of\nvictims in hotel rooms. These images directly link victims to places, which can\nhelp verify where victims have been trafficked or where traffickers might\noperate in the future. Current machine learning approaches give promising\nresults in image search to find the matching hotel. This paper explores\napproaches to make this end-to-end system better support government and law\nenforcement requirements, including improved performance, visualization\napproaches that explain what parts of the image led to a match, and\ninfrastructure to support exporting the results of a query.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 15:24:30 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Stylianou", "Abby", ""], ["Souvenir", "Richard", ""], ["Pless", "Robert", ""]]}, {"id": "1910.03466", "submitter": "Paul Kantor", "authors": "Vicki Bier, Paul B. Kantor, Gary Lupyan, Xiaojin Zhu", "title": "Can We Distinguish Machine Learning from Human Learning?", "comments": "14pp. 5 fig. Working Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What makes a task relatively more or less difficult for a machine compared to\na human? Much AI/ML research has focused on expanding the range of tasks that\nmachines can do, with a focus on whether machines can beat humans. Allowing for\ndifferences in scale, we can seek interesting (anomalous) pairs of tasks T, T'.\nWe define interesting in this way: The \"harder to learn\" relation is reversed\nwhen comparing human intelligence (HI) to AI. While humans seems to be able to\nunderstand problems by formulating rules, ML using neural networks does not\nrely on constructing rules. We discuss a novel approach where the challenge is\nto \"perform well under rules that have been created by human beings.\" We\nsuggest that this provides a rigorous and precise pathway for understanding the\ndifference between the two kinds of learning. Specifically, we suggest a large\nand extensible class of learning tasks, formulated as learning under rules.\nWith these tasks, both the AI and HI will be studied with rigor and precision.\nThe immediate goal is to find interesting groundtruth rule pairs. In the long\nterm, the goal will be to understand, in a generalizable way, what\ndistinguishes interesting pairs from ordinary pairs, and to define saliency\nbehind interesting pairs. This may open new ways of thinking about AI, and\nprovide unexpected insights into human learning.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 15:37:03 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Bier", "Vicki", ""], ["Kantor", "Paul B.", ""], ["Lupyan", "Gary", ""], ["Zhu", "Xiaojin", ""]]}, {"id": "1910.03515", "submitter": "Carol Smith", "authors": "Carol J. Smith", "title": "Designing Trustworthy AI: A Human-Machine Teaming Framework to Guide\n  Development", "comments": "Presented at AAAI FSS-19: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Artificial intelligence (AI) holds great promise to empower us with knowledge\nand augment our effectiveness. We can -- and must -- ensure that we keep humans\nsafe and in control, particularly with regard to government and public sector\napplications that affect broad populations. How can AI development teams\nharness the power of AI systems and design them to be valuable to humans?\nDiverse teams are needed to build trustworthy artificial intelligent systems,\nand those teams need to coalesce around a shared set of ethics. There are many\ndiscussions in the AI field about ethics and trust, but there are few\nframeworks available for people to use as guidance when creating these systems.\nThe Human-Machine Teaming (HMT) Framework for Designing Ethical AI Experiences\ndescribed in this paper, when used with a set of technical ethics, will guide\nAI development teams to create AI systems that are accountable, de-risked,\nrespectful, secure, honest, and usable. To support the team's efforts,\nactivities to understand people's needs and concerns will be introduced along\nwith the themes to support the team's efforts. For example, usability testing\ncan help determine if the audience understands how the AI system works and\ncomplies with the HMT Framework. The HMT Framework is based on reviews of\nexisting ethical codes and best practices in human-computer interaction and\nsoftware development. Human-machine teams are strongest when human users can\ntrust AI systems to behave as expected, safely, securely, and understandably.\nUsing the HMT Framework to design trustworthy AI systems will provide support\nto teams in identifying potential issues ahead of time and making great\nexperiences for humans.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 16:19:49 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Smith", "Carol J.", ""]]}, {"id": "1910.03544", "submitter": "Jianguo Zhang", "authors": "Jian-Guo Zhang, Kazuma Hashimoto, Chien-Sheng Wu, Yao Wan, Philip S.\n  Yu, Richard Socher, Caiming Xiong", "title": "Find or Classify? Dual Strategy for Slot-Value Predictions on\n  Multi-Domain Dialog State Tracking", "comments": "14 pages, accepted at the 9th Joint Conference on Lexical and\n  Computational Semantics (*SEM 2020). This version fixes small errors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialog state tracking (DST) is a core component in task-oriented dialog\nsystems. Existing approaches for DST mainly fall into one of two categories,\nnamely, ontology-based and ontology-free methods. An ontology-based method\nselects a value from a candidate-value list for each target slot, while an\nontology-free method extracts spans from dialog contexts. Recent work\nintroduced a BERT-based model to strike a balance between the two methods by\npre-defining categorical and non-categorical slots. However, it is not clear\nenough which slots are better handled by either of the two slot types, and the\nway to use the pre-trained model has not been well investigated. In this paper,\nwe propose a simple yet effective dual-strategy model for DST, by adapting a\nsingle BERT-style reading comprehension model to jointly handle both the\ncategorical and non-categorical slots. Our experiments on the MultiWOZ datasets\nshow that our method significantly outperforms the BERT-based counterpart,\nfinding that the key is a deep interaction between the domain-slot and context\ninformation. When evaluated on noisy (MultiWOZ 2.0) and cleaner (MultiWOZ 2.1)\nsettings, our method performs competitively and robustly across the two\ndifferent settings. Our method sets the new state of the art in the noisy\nsetting, while performing more robustly than the best model in the cleaner\nsetting. We also conduct a comprehensive error analysis on the dataset,\nincluding the effects of the dual strategy for each slot, to facilitate future\nresearch.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 17:08:39 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 08:04:12 GMT"}, {"version": "v3", "created": "Tue, 29 Sep 2020 08:37:44 GMT"}, {"version": "v4", "created": "Wed, 28 Oct 2020 10:07:01 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Zhang", "Jian-Guo", ""], ["Hashimoto", "Kazuma", ""], ["Wu", "Chien-Sheng", ""], ["Wan", "Yao", ""], ["Yu", "Philip S.", ""], ["Socher", "Richard", ""], ["Xiong", "Caiming", ""]]}, {"id": "1910.03650", "submitter": "Jean Mercat", "authors": "Jean Mercat, Thomas Gilles, Nicole El Zoghby, Guillaume Sandou,\n  Dominique Beauvois, Guillermo Pita Gil", "title": "Multi-Head Attention for Multi-Modal Joint Vehicle Motion Forecasting", "comments": "7 pages, 4 figures, under review at ICRA and RA-L", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel vehicle motion forecasting method based on\nmulti-head attention. It produces joint forecasts for all vehicles on a road\nscene as sequences of multi-modal probability density functions of their\npositions. Its architecture uses multi-head attention to account for complete\ninteractions between all vehicles, and long short-term memory layers for\nencoding and forecasting. It relies solely on vehicle position tracks, does not\nneed maneuver definitions, and does not represent the scene with a spatial\ngrid. This allows it to be more versatile than similar model while combining\nany forecasting capabilities, namely joint forecast with interactions,\nuncertainty estimation, and multi-modality. The resulting prediction likelihood\noutperforms state-of-the-art models on the same dataset.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 19:16:56 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 22:03:23 GMT"}, {"version": "v3", "created": "Fri, 20 Dec 2019 12:36:57 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Mercat", "Jean", ""], ["Gilles", "Thomas", ""], ["Zoghby", "Nicole El", ""], ["Sandou", "Guillaume", ""], ["Beauvois", "Dominique", ""], ["Gil", "Guillermo Pita", ""]]}, {"id": "1910.03655", "submitter": "Alane Suhr", "authors": "Alane Suhr, Claudia Yan, Jacob Schluger, Stanley Yu, Hadi Khader,\n  Marwa Mouallem, Iris Zhang, Yoav Artzi", "title": "Executing Instructions in Situated Collaborative Interactions", "comments": "EMNLP 2019 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a collaborative scenario where a user not only instructs a system to\ncomplete tasks, but also acts alongside it. This allows the user to adapt to\nthe system abilities by changing their language or deciding to simply\naccomplish some tasks themselves, and requires the system to effectively\nrecover from errors as the user strategically assigns it new goals. We build a\ngame environment to study this scenario, and learn to map user instructions to\nsystem actions. We introduce a learning approach focused on recovery from\ncascading errors between instructions, and modeling methods to explicitly\nreason about instructions with multiple goals. We evaluate with a new\nevaluation protocol using recorded interactions and online games with human\nusers, and observe how users adapt to the system abilities.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 19:22:58 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 14:25:12 GMT"}, {"version": "v3", "created": "Wed, 8 Jan 2020 15:27:46 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Suhr", "Alane", ""], ["Yan", "Claudia", ""], ["Schluger", "Jacob", ""], ["Yu", "Stanley", ""], ["Khader", "Hadi", ""], ["Mouallem", "Marwa", ""], ["Zhang", "Iris", ""], ["Artzi", "Yoav", ""]]}, {"id": "1910.03728", "submitter": "Nil Stolt Anso", "authors": "Nil Stolt Ans\\'o", "title": "Investigation on the generalization of the Sampled Policy Gradient\n  algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Sampled Policy Gradient (SPG) algorithm is a new offline actor-critic\nvariant that samples in the action space to approximate the policy gradient. It\ndoes so by using the critic to evaluate the sampled actions. SPG offers\ntheoretical promise over similar algorithms such as DPG as it searches the\naction-Q-value space independently of the local gradient, enabling it to avoid\nlocal minima. This paper aims to compare SPG to two similar actor-critic\nalgorithms, CACLA and DPG. The comparison is made across two different\nenvironments, two different network architectures, as well as training on\non-policy transitions in contrast to using an experience buffer. Results seem\nto show that although SPG does often not perform the worst, it doesn't always\nmatch the performance of the best performing algorithm at a particular task.\nFurther experiments are required to get a better estimate of the qualities of\nSPG.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 00:26:13 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Ans\u00f3", "Nil Stolt", ""]]}, {"id": "1910.03741", "submitter": "Haoran Wei", "authors": "Haoran Wei, Mariefel Olarte, Garrett B. Goh", "title": "Multiple-objective Reinforcement Learning for Inverse Design and\n  Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of the inverse chemical design is to develop new molecules with given\noptimized molecular properties or objectives. Recently, generative deep\nlearning (DL) networks are considered as the state-of-the-art in inverse\nchemical design and have achieved early success in generating molecular\nstructures with desired properties in the pharmaceutical and material chemistry\nfields. However, satisfying a large number (larger than 10 objectives) of\nmolecular objectives is a limitation of current generative models. To improve\nthe model's ability to handle a large number of molecule design objectives, we\ndeveloped a Reinforcement Learning (RL) based generative framework to optimize\nchemical molecule generation. Our use of Curriculum Learning (CL) to fine-tune\nthe pre-trained generative network allowed the model to satisfy up to 21\nobjectives and increase the generative network's robustness. The experiments\nshow that the proposed multiple-objective RL-based generative model can\ncorrectly identify unknown molecules with an 83 to 100 percent success rate,\ncompared to the baseline approach of 0 percent. Additionally, this proposed\ngenerative model is not limited to just chemistry research challenges; we\nanticipate that problems that utilize RL with multiple-objectives will benefit\nfrom this framework.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 01:40:17 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Wei", "Haoran", ""], ["Olarte", "Mariefel", ""], ["Goh", "Garrett B.", ""]]}, {"id": "1910.03743", "submitter": "Haoran Wei", "authors": "Haoran Wei, Yuanbo Wang, Lidia Mangu, Keith Decker", "title": "Model-based Reinforcement Learning for Predictions and Control for Limit\n  Order Books", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build a profitable electronic trading agent with Reinforcement Learning\nthat places buy and sell orders in the stock market. An environment model is\nbuilt only with historical observational data, and the RL agent learns the\ntrading policy by interacting with the environment model instead of with the\nreal-market to minimize the risk and potential monetary loss. Trained in\nunsupervised and self-supervised fashion, our environment model learned a\ntemporal and causal representation of the market in latent space through deep\nneural networks. We demonstrate that the trading policy trained entirely within\nthe environment model can be transferred back into the real market and maintain\nits profitability. We believe that this environment model can serve as a robust\nsimulator that predicts market movement as well as trade impact for further\nstudies.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 01:42:27 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Wei", "Haoran", ""], ["Wang", "Yuanbo", ""], ["Mangu", "Lidia", ""], ["Decker", "Keith", ""]]}, {"id": "1910.03756", "submitter": "Qingyang Wu", "authors": "Qingyang Wu, Yichi Zhang, Yu Li, Zhou Yu", "title": "Alternating Recurrent Dialog Model with Large-scale Pre-trained Language\n  Models", "comments": "EACL 2021 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing dialog system models require extensive human annotations and are\ndifficult to generalize to different tasks. The recent success of large\npre-trained language models such as BERT and GPT-2 (Devlin et al., 2019;\nRadford et al., 2019) have suggested the effectiveness of incorporating\nlanguage priors in down-stream NLP tasks. However, how much pre-trained\nlanguage models can help dialog response generation is still under exploration.\nIn this paper, we propose a simple, general, and effective framework:\nAlternating Roles Dialog Model (ARDM). ARDM models each speaker separately and\ntakes advantage of the large pre-trained language model. It requires no\nsupervision from human annotations such as belief states or dialog acts to\nachieve effective conversations. ARDM outperforms or is on par with\nstate-of-the-art methods on two popular task-oriented dialog datasets:\nCamRest676 and MultiWOZ. Moreover, we can generalize ARDM to more challenging,\nnon-collaborative tasks such as persuasion. In persuasion tasks, ARDM is\ncapable of generating human-like responses to persuade people to donate to a\ncharity.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 02:31:37 GMT"}, {"version": "v2", "created": "Sun, 10 Nov 2019 02:01:13 GMT"}, {"version": "v3", "created": "Mon, 26 Apr 2021 19:48:38 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Wu", "Qingyang", ""], ["Zhang", "Yichi", ""], ["Li", "Yu", ""], ["Yu", "Zhou", ""]]}, {"id": "1910.03799", "submitter": "Gutha Jaya Krishna", "authors": "Gutha Jaya Krishna, Vadlamani Ravi", "title": "Large Scale Global Optimization by Hybrid Evolutionary Computation", "comments": "29 Pages, 8 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In management, business, economics, science, engineering, and research\ndomains, Large Scale Global Optimization (LSGO) plays a predominant and vital\nrole. Though LSGO is applied in many of the application domains, it is a very\ntroublesome and a perverse task. The Congress on Evolutionary Computation (CEC)\nbegan an LSGO competition to come up with algorithms with a bunch of standard\nbenchmark unconstrained LSGO functions. Therefore, in this paper, we propose a\nhybrid meta-heuristic algorithm, which combines an Improved and Modified\nHarmony Search (IMHS), along with a Modified Differential Evolution (MDE) with\nan alternate selection strategy. Harmony Search (HS) does the job of\nexploration and exploitation, and Differential Evolution does the job of giving\na perturbation to the exploration of IMHS, as harmony search suffers from being\nstuck at the basin of local optimal. To judge the performance of the suggested\nalgorithm, we compare the proposed algorithm with ten excellent meta-heuristic\nalgorithms on fifteen LSGO benchmark functions, which have 1000 continuous\ndecision variables, of the CEC 2013 LSGO special session. The experimental\nresults consistently show that our proposed hybrid meta-heuristic performs\nstatistically on par with some algorithms in a few problems, while it turned\nout to be the best in a couple of problems.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 05:41:58 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Krishna", "Gutha Jaya", ""], ["Ravi", "Vadlamani", ""]]}, {"id": "1910.03827", "submitter": "Jekan Thangavelautham", "authors": "Himangshu Kalita and Jekan Thangavelautham", "title": "Automated Multidisciplinary Design and Control of Hopping Robots for\n  Exploration of Extreme Environments on the Moon and Mars", "comments": "11 pages, 13 figures, International Astronautical Congress 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO astro-ph.IM cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The next frontier in solar system exploration will be missions targeting\nextreme and rugged environments such as caves, canyons, cliffs and crater rims\nof the Moon, Mars and icy moons. These environments are time capsules into\nearly formation of the solar system and will provide vital clues of how our\nearly solar system gave way to the current planets and moons. These sites will\nalso provide vital clues to the past and present habitability of these\nenvironments. Current landers and rovers are unable to access these areas of\nhigh interest due to limitations in precision landing techniques, need for\nlarge and sophisticated science instruments and a mission assurance and\noperations culture where risks are minimized at all costs. Our past work has\nshown the advantages of using multiple spherical hopping robots called SphereX\nfor exploring these extreme environments. Our previous work was based on\nperforming exploration with a human-designed baseline design of a SphereX\nrobot. However, the design of SphereX is a complex task that involves a large\nnumber of design variables and multiple engineering disciplines. In this work\nwe propose to use Automated Multidisciplinary Design and Control Optimization\n(AMDCO) techniques to find near optimal design solutions in terms of mass,\nvolume, power, and control for SphereX for different mission scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 07:53:35 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Kalita", "Himangshu", ""], ["Thangavelautham", "Jekan", ""]]}, {"id": "1910.03857", "submitter": "Marcin B. Tomczak", "authors": "Marcin B. Tomczak, Dongho Kim, Peter Vrancx and Kee-Eung Kim", "title": "Policy Optimization Through Approximate Importance Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent policy optimization approaches (Schulman et al., 2015a; 2017) have\nachieved substantial empirical successes by constructing new proxy optimization\nobjectives. These proxy objectives allow stable and low variance policy\nlearning, but require small policy updates to ensure that the proxy objective\nremains an accurate approximation of the target policy value. In this paper we\nderive an alternative objective that obtains the value of the target policy by\napplying importance sampling (IS). However, the basic importance sampled\nobjective is not suitable for policy optimization, as it incurs too high\nvariance in policy updates. We therefore introduce an approximation that allows\nus to directly trade-off the bias of approximation with the variance in policy\nupdates. We show that our approximation unifies previously developed approaches\nand allows us to interpolate between them. We develop a practical algorithm by\noptimizing the introduced objective with proximal policy optimization\ntechniques (Schulman et al., 2017). We also provide a theoretical analysis of\nthe introduced policy optimization objective demonstrating bias-variance\ntrade-off. We empirically demonstrate that the resulting algorithm improves\nupon state of the art on-policy policy optimization on continuous control\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 09:06:35 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 16:14:43 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Tomczak", "Marcin B.", ""], ["Kim", "Dongho", ""], ["Vrancx", "Peter", ""], ["Kim", "Kee-Eung", ""]]}, {"id": "1910.03880", "submitter": "Marcin B. Tomczak", "authors": "Marcin B. Tomczak, Sergio Valcarcel Macua, Enrique Munoz de Cote and\n  Peter Vrancx", "title": "Compatible features for Monotonic Policy Improvement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent policy optimization approaches have achieved substantial empirical\nsuccess by constructing surrogate optimization objectives. The Approximate\nPolicy Iteration objective (Schulman et al., 2015a; Kakade and Langford, 2002)\nhas become a standard optimization target for reinforcement learning problems.\nUsing this objective in practice requires an estimator of the advantage\nfunction. Policy optimization methods such as those proposed in Schulman et al.\n(2015b) estimate the advantages using a parametric critic. In this work we\nestablish conditions under which the parametric approximation of the critic\ndoes not introduce bias to the updates of surrogate objective. These results\nhold for a general class of parametric policies, including deep neural\nnetworks. We obtain a result analogous to the compatible features derived for\nthe original Policy Gradient Theorem (Sutton et al., 1999). As a result, we\nalso identify a previously unknown bias that current state-of-the-art policy\noptimization algorithms (Schulman et al., 2015a, 2017) have introduced by not\nemploying these compatible features.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 10:16:19 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 12:49:10 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Tomczak", "Marcin B.", ""], ["Macua", "Sergio Valcarcel", ""], ["de Cote", "Enrique Munoz", ""], ["Vrancx", "Peter", ""]]}, {"id": "1910.03891", "submitter": "Wenqiang Liu", "authors": "Wenqiang Liu, Hongyun Cai, Xu Cheng, Sifa Xie, Yipeng Yu, Hanyu Zhang", "title": "Learning High-order Structural and Attribute information by Knowledge\n  Graph Attention Networks for Enhancing Knowledge Graph Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of representation learning of knowledge graph is to encode both\nentities and relations into a low-dimensional embedding spaces. Many recent\nworks have demonstrated the benefits of knowledge graph embedding on knowledge\ngraph completion task, such as relation extraction. However, we observe that:\n1) existing method just take direct relations between entities into\nconsideration and fails to express high-order structural relationship between\nentities; 2) these methods just leverage relation triples of KGs while ignoring\na large number of attribute triples that encoding rich semantic information. To\novercome these limitations, this paper propose a novel knowledge graph\nembedding method, named KANE, which is inspired by the recent developments of\ngraph convolutional networks (GCN). KANE can capture both high-order structural\nand attribute information of KGs in an efficient, explicit and unified manner\nunder the graph convolutional networks framework. Empirical results on three\ndatasets show that KANE significantly outperforms seven state-of-arts methods.\nFurther analysis verify the efficiency of our method and the benefits brought\nby the attention mechanism.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 10:33:59 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 02:58:00 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Liu", "Wenqiang", ""], ["Cai", "Hongyun", ""], ["Cheng", "Xu", ""], ["Xie", "Sifa", ""], ["Yu", "Yipeng", ""], ["Zhang", "Hanyu", ""]]}, {"id": "1910.03990", "submitter": "Mihai Boicu", "authors": "Gheorghe Tecuci, Dorin Marcu, Mihai Boicu, Steven Meckl, Chirag\n  Uttamsingh", "title": "Toward a Computational Theory of Evidence-Based Reasoning for\n  Instructable Cognitive Agents", "comments": "Presented at AAAI FSS-19: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA. (8 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evidence-based reasoning is at the core of many problem-solving and\ndecision-making tasks in a wide variety of domains. Generalizing from the\nresearch and development of cognitive agents in several such domains, this\npaper presents progress toward a computational theory for the development of\ninstructable cognitive agents for evidence-based reasoning tasks. The paper\nalso illustrates the application of this theory to the development of four\nprototype cognitive agents in domains that are critical to the government and\nthe public sector. Two agents function as cognitive assistants, one in\nintelligence analysis, and the other in science education. The other two agents\noperate autonomously, one in cybersecurity and the other in intelligence,\nsurveillance, and reconnaissance. The paper concludes with the directions of\nfuture research on the proposed computational theory.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 13:52:03 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Tecuci", "Gheorghe", ""], ["Marcu", "Dorin", ""], ["Boicu", "Mihai", ""], ["Meckl", "Steven", ""], ["Uttamsingh", "Chirag", ""]]}, {"id": "1910.03997", "submitter": "Martin Hahner", "authors": "Martin Hahner, Dengxin Dai, Christos Sakaridis, Jan-Nico Zaech, Luc\n  Van Gool", "title": "Semantic Understanding of Foggy Scenes with Purely Synthetic Data", "comments": "independent class IoU scores corrected for BiSiNet architecture", "journal-ref": null, "doi": "10.1109/ITSC.2019.8917518", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses the problem of semantic scene understanding under foggy\nroad conditions. Although marked progress has been made in semantic scene\nunderstanding over the recent years, it is mainly concentrated on clear weather\noutdoor scenes. Extending semantic segmentation methods to adverse weather\nconditions like fog is crucially important for outdoor applications such as\nself-driving cars. In this paper, we propose a novel method, which uses purely\nsynthetic data to improve the performance on unseen real-world foggy scenes\ncaptured in the streets of Zurich and its surroundings. Our results highlight\nthe potential and power of photo-realistic synthetic images for training and\nespecially fine-tuning deep neural nets. Our contributions are threefold, 1) we\ncreated a purely synthetic, high-quality foggy dataset of 25,000 unique outdoor\nscenes, that we call Foggy Synscapes and plan to release publicly 2) we show\nthat with this data we outperform previous approaches on real-world foggy test\ndata 3) we show that a combination of our data and previously used data can\neven further improve the performance on real-world foggy data.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 14:04:59 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 07:42:58 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Hahner", "Martin", ""], ["Dai", "Dengxin", ""], ["Sakaridis", "Christos", ""], ["Zaech", "Jan-Nico", ""], ["Van Gool", "Luc", ""]]}, {"id": "1910.04023", "submitter": "Ignacio Arroyo-Fern\\'andez", "authors": "Ignacio Arroyo-Fern\\'andez and Mauricio Carrasco-Ru\\'iz and J. Anibal\n  Arias-Aguilar", "title": "On the Possibility of Rewarding Structure Learning Agents: Mutual\n  Information on Linguistic Random Sets", "comments": "Paper accepted to the Workshop on Sets & Partitions (NeurIPS 2019,\n  Vancouver, Canada)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.IT math.IT stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a first attempt to elucidate a theoretical and empirical approach\nto design the reward provided by a natural language environment to some\nstructure learning agent. To this end, we revisit the Information Theory of\nunsupervised induction of phrase-structure grammars to characterize the\nbehavior of simulated actions modeled as set-valued random variables (random\nsets of linguistic samples) constituting semantic structures. Our results\nshowed empirical evidence of that simulated semantic structures (Open\nInformation Extraction triplets) can be distinguished from randomly constructed\nones by observing the Mutual Information among their constituents. This\nsuggests the possibility of rewarding structure learning agents without using\npretrained structural analyzers (oracle actors/experts).\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 14:33:37 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 01:34:52 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2019 01:48:19 GMT"}, {"version": "v4", "created": "Wed, 4 Dec 2019 16:56:56 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Arroyo-Fern\u00e1ndez", "Ignacio", ""], ["Carrasco-Ru\u00edz", "Mauricio", ""], ["Arias-Aguilar", "J. Anibal", ""]]}, {"id": "1910.04040", "submitter": "Matthias Hutsebaut-Buysse", "authors": "Matthias Hutsebaut-Buysse, Kevin Mets, Steven Latr\\'e", "title": "Fast Task-Adaptation for Tasks Labeled Using Natural Language in\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over its lifetime, a reinforcement learning agent is often tasked with\ndifferent tasks. How to efficiently adapt a previously learned control policy\nfrom one task to another, remains an open research question. In this paper, we\ninvestigate how instructions formulated in natural language can enable faster\nand more effective task adaptation. This can serve as the basis for developing\nlanguage instructed skills, which can be used in a lifelong learning setting.\nOur method is capable of assessing, given a set of developed base control\npolicies, which policy will adapt best to a new unseen task.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 15:01:05 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Hutsebaut-Buysse", "Matthias", ""], ["Mets", "Kevin", ""], ["Latr\u00e9", "Steven", ""]]}, {"id": "1910.04077", "submitter": "M. Sadegh Talebi", "authors": "Mahsa Asadi, Mohammad Sadegh Talebi, Hippolyte Bourel and\n  Odalric-Ambrym Maillard", "title": "Model-Based Reinforcement Learning Exploiting State-Action Equivalence", "comments": "ACML 2019. Recipient of the Best Student Paper Award", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging an equivalence property in the state-space of a Markov Decision\nProcess (MDP) has been investigated in several studies. This paper studies\nequivalence structure in the reinforcement learning (RL) setup, where\ntransition distributions are no longer assumed to be known. We present a notion\nof similarity between transition probabilities of various state-action pairs of\nan MDP, which naturally defines an equivalence structure in the state-action\nspace. We present equivalence-aware confidence sets for the case where the\nlearner knows the underlying structure in advance. These sets are provably\nsmaller than their corresponding equivalence-oblivious counterparts. In the\nmore challenging case of an unknown equivalence structure, we present an\nalgorithm called ApproxEquivalence that seeks to find an (approximate)\nequivalence structure, and define confidence sets using the approximate\nequivalence. To illustrate the efficacy of the presented confidence sets, we\npresent C-UCRL, as a natural modification of UCRL2 for RL in undiscounted MDPs.\nIn the case of a known equivalence structure, we show that C-UCRL improves over\nUCRL2 in terms of regret by a factor of $\\sqrt{SA/C}$, in any communicating MDP\nwith $S$ states, $A$ actions, and $C$ classes, which corresponds to a massive\nimprovement when $C \\ll SA$. To the best of our knowledge, this is the first\nwork providing regret bounds for RL when an equivalence structure in the MDP is\nefficiently exploited. In the case of an unknown equivalence structure, we show\nthrough numerical experiments that C-UCRL combined with ApproxEquivalence\noutperforms UCRL2 in ergodic MDPs.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 15:50:05 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Asadi", "Mahsa", ""], ["Talebi", "Mohammad Sadegh", ""], ["Bourel", "Hippolyte", ""], ["Maillard", "Odalric-Ambrym", ""]]}, {"id": "1910.04098", "submitter": "Louis Kirsch", "authors": "Louis Kirsch, Sjoerd van Steenkiste, J\\\"urgen Schmidhuber", "title": "Improving Generalization in Meta Reinforcement Learning using Learned\n  Objectives", "comments": "Accepted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Biological evolution has distilled the experiences of many learners into the\ngeneral learning algorithms of humans. Our novel meta reinforcement learning\nalgorithm MetaGenRL is inspired by this process. MetaGenRL distills the\nexperiences of many complex agents to meta-learn a low-complexity neural\nobjective function that decides how future individuals will learn. Unlike\nrecent meta-RL algorithms, MetaGenRL can generalize to new environments that\nare entirely different from those used for meta-training. In some cases, it\neven outperforms human-engineered RL algorithms. MetaGenRL uses off-policy\nsecond-order gradients during meta-training that greatly increase its sample\nefficiency.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 16:20:48 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 16:56:33 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Kirsch", "Louis", ""], ["van Steenkiste", "Sjoerd", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1910.04142", "submitter": "Arunkumar Byravan", "authors": "Arunkumar Byravan, Jost Tobias Springenberg, Abbas Abdolmaleki, Roland\n  Hafner, Michael Neunert, Thomas Lampe, Noah Siegel, Nicolas Heess, Martin\n  Riedmiller", "title": "Imagined Value Gradients: Model-Based Policy Optimization with\n  Transferable Latent Dynamics Models", "comments": "To appear at the 3rd annual Conference on Robot Learning, Osaka,\n  Japan (CoRL 2019). 24 pages including appendix (main paper - 8 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are masters at quickly learning many complex tasks, relying on an\napproximate understanding of the dynamics of their environments. In much the\nsame way, we would like our learning agents to quickly adapt to new tasks. In\nthis paper, we explore how model-based Reinforcement Learning (RL) can\nfacilitate transfer to new tasks. We develop an algorithm that learns an\naction-conditional, predictive model of expected future observations, rewards\nand values from which a policy can be derived by following the gradient of the\nestimated value along imagined trajectories. We show how robust policy\noptimization can be achieved in robot manipulation tasks even with approximate\nmodels that are learned directly from vision and proprioception. We evaluate\nthe efficacy of our approach in a transfer learning scenario, re-using\npreviously learned models on tasks with different reward structures and visual\ndistractors, and show a significant improvement in learning speed compared to\nstrong off-policy baselines. Videos with results can be found at\nhttps://sites.google.com/view/ivg-corl19\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 17:37:52 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Byravan", "Arunkumar", ""], ["Springenberg", "Jost Tobias", ""], ["Abdolmaleki", "Abbas", ""], ["Hafner", "Roland", ""], ["Neunert", "Michael", ""], ["Lampe", "Thomas", ""], ["Siegel", "Noah", ""], ["Heess", "Nicolas", ""], ["Riedmiller", "Martin", ""]]}, {"id": "1910.04214", "submitter": "Gal Yona", "authors": "Gal Yona and Amirata Ghorbani and James Zou", "title": "Who's responsible? Jointly quantifying the contribution of the learning\n  algorithm and training data", "comments": "To appear in AAAI/ACM Conference on AI, Ethics, and Society (2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A learning algorithm $A$ trained on a dataset $D$ is revealed to have poor\nperformance on some subpopulation at test time. Where should the responsibility\nfor this lay? It can be argued that the data is responsible, if for example\ntraining $A$ on a more representative dataset $D'$ would have improved the\nperformance. But it can similarly be argued that $A$ itself is at fault, if\ntraining a different variant $A'$ on the same dataset $D$ would have improved\nperformance. As ML becomes widespread and such failure cases more common, these\ntypes of questions are proving to be far from hypothetical. With this\nmotivation in mind, in this work we provide a rigorous formulation of the joint\ncredit assignment problem between a learning algorithm $A$ and a dataset $D$.\nWe propose Extended Shapley as a principled framework for this problem, and\nexperiment empirically with how it can be used to address questions of ML\naccountability.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 19:39:08 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 08:28:05 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Yona", "Gal", ""], ["Ghorbani", "Amirata", ""], ["Zou", "James", ""]]}, {"id": "1910.04281", "submitter": "Nicholas Waytowich", "authors": "Vinicius G. Goecks, Gregory M. Gremillion, Vernon J. Lawhern, John\n  Valasek, Nicholas R. Waytowich", "title": "Integrating Behavior Cloning and Reinforcement Learning for Improved\n  Performance in Dense and Sparse Reward Environments", "comments": "9 pages, 5 Figures. AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates how to efficiently transition and update policies,\ntrained initially with demonstrations, using off-policy actor-critic\nreinforcement learning. It is well-known that techniques based on Learning from\nDemonstrations, for example behavior cloning, can lead to proficient policies\ngiven limited data. However, it is currently unclear how to efficiently update\nthat policy using reinforcement learning as these approaches are inherently\noptimizing different objective functions. Previous works have used loss\nfunctions, which combine behavior cloning losses with reinforcement learning\nlosses to enable this update. However, the components of these loss functions\nare often set anecdotally, and their individual contributions are not well\nunderstood. In this work, we propose the Cycle-of-Learning (CoL) framework that\nuses an actor-critic architecture with a loss function that combines behavior\ncloning and 1-step Q-learning losses with an off-policy pre-training step from\nhuman demonstrations. This enables transition from behavior cloning to\nreinforcement learning without performance degradation and improves\nreinforcement learning in terms of overall performance and training time.\nAdditionally, we carefully study the composition of these combined losses and\ntheir impact on overall policy learning. We show that our approach outperforms\nstate-of-the-art techniques for combining behavior cloning and reinforcement\nlearning for both dense and sparse reward scenarios. Our results also suggest\nthat directly including the behavior cloning loss on demonstration data helps\nto ensure stable learning and ground future policy updates.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 22:32:23 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 19:08:25 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Goecks", "Vinicius G.", ""], ["Gremillion", "Gregory M.", ""], ["Lawhern", "Vernon J.", ""], ["Valasek", "John", ""], ["Waytowich", "Nicholas R.", ""]]}, {"id": "1910.04365", "submitter": "Erdem B{\\i}y{\\i}k", "authors": "Erdem B{\\i}y{\\i}k, Malayandi Palan, Nicholas C. Landolfi, Dylan P.\n  Losey, Dorsa Sadigh", "title": "Asking Easy Questions: A User-Friendly Approach to Active Reward\n  Learning", "comments": "Proceedings of the 3rd Conference on Robot Learning (CoRL), October\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots can learn the right reward function by querying a human expert.\nExisting approaches attempt to choose questions where the robot is most\nuncertain about the human's response; however, they do not consider how easy it\nwill be for the human to answer! In this paper we explore an information gain\nformulation for optimally selecting questions that naturally account for the\nhuman's ability to answer. Our approach identifies questions that optimize the\ntrade-off between robot and human uncertainty, and determines when these\nquestions become redundant or costly. Simulations and a user study show our\nmethod not only produces easy questions, but also ultimately results in faster\nreward learning.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 04:52:46 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["B\u0131y\u0131k", "Erdem", ""], ["Palan", "Malayandi", ""], ["Landolfi", "Nicholas C.", ""], ["Losey", "Dylan P.", ""], ["Sadigh", "Dorsa", ""]]}, {"id": "1910.04376", "submitter": "Daochen Zha", "authors": "Daochen Zha, Kwei-Herng Lai, Yuanpu Cao, Songyi Huang, Ruzhe Wei,\n  Junyu Guo, Xia Hu", "title": "RLCard: A Toolkit for Reinforcement Learning in Card Games", "comments": "AAAI-20 Workshop on Reinforcement Learning in Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RLCard is an open-source toolkit for reinforcement learning research in card\ngames. It supports various card environments with easy-to-use interfaces,\nincluding Blackjack, Leduc Hold'em, Texas Hold'em, UNO, Dou Dizhu and Mahjong.\nThe goal of RLCard is to bridge reinforcement learning and imperfect\ninformation games, and push forward the research of reinforcement learning in\ndomains with multiple agents, large state and action space, and sparse reward.\nIn this paper, we provide an overview of the key components in RLCard, a\ndiscussion of the design principles, a brief introduction of the interfaces,\nand comprehensive evaluations of the environments. The codes and documents are\navailable at https://github.com/datamllab/rlcard\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 05:56:16 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 17:23:55 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Zha", "Daochen", ""], ["Lai", "Kwei-Herng", ""], ["Cao", "Yuanpu", ""], ["Huang", "Songyi", ""], ["Wei", "Ruzhe", ""], ["Guo", "Junyu", ""], ["Hu", "Xia", ""]]}, {"id": "1910.04383", "submitter": "Dusko Pavlovic", "authors": "Dusko Pavlovic and Temra Pavlovic", "title": "Causality and deceit: Do androids watch action movies?", "comments": "29 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We seek causes through science, religion, and in everyday life. We get\nexcited when a big rock causes a big splash, and we get scared when it tumbles\nwithout a cause. But our causal cognition is usually biased. The 'why' is\ninfluenced by the 'who'. It is influenced by the 'self', and by 'others'. We\nshare rituals, we watch action movies, and we influence each other to believe\nin the same causes. Human mind is packed with subjectivity because shared\ncognitive biases bring us together. But they also make us vulnerable.\n  An artificial mind is deemed to be more objective than the human mind. After\nmany years of science-fiction fantasies about even-minded androids, they are\nnow sold as personal or expert assistants, as brand advocates, as policy or\ncandidate supporters, as network influencers. Artificial agents have been\nstunningly successful in disseminating artificial causal beliefs among humans.\nAs malicious artificial agents continue to manipulate human cognitive biases,\nand deceive human communities into ostensive but expansive causal illusions,\nthe hope for defending us has been vested into developing benevolent artificial\nagents, tasked with preventing and mitigating cognitive distortions inflicted\nupon us by their malicious cousins. Can the distortions of human causal\ncognition be corrected on a more solid foundation of artificial causal\ncognition?\n  In the present paper, we study a simple model of causal cognition, viewed as\na quest for causal models. We show that, under very mild and hard to avoid\nassumptions, there are always self-confirming causal models, which perpetrate\nself-deception, and seem to preclude a royal road to objectivity.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 06:24:18 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Pavlovic", "Dusko", ""], ["Pavlovic", "Temra", ""]]}, {"id": "1910.04386", "submitter": "Thomas Kerdreux", "authors": "Vivien Cabannes and Thomas Kerdreux and Louis Thiry and Tina Campana\n  and Charly Ferrandes", "title": "Dialog on a canvas with a machine", "comments": "Accepted for poster at creativity workshop NeurIPS 2019", "journal-ref": "creativity workshop NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.GR cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new form of human-machine interaction. It is a pictorial game\nconsisting of interactive rounds of creation between artists and a machine.\nThey repetitively paint one after the other. At its rounds, the computer\npartially completes the drawing using machine learning algorithms, and projects\nits additions directly on the canvas, which the artists are free to insert or\nmodify. Alongside fostering creativity, the process is designed to question the\ngrowing interaction between humans and machines.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 06:33:28 GMT"}, {"version": "v2", "created": "Sun, 13 Oct 2019 15:40:26 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Cabannes", "Vivien", ""], ["Kerdreux", "Thomas", ""], ["Thiry", "Louis", ""], ["Campana", "Tina", ""], ["Ferrandes", "Charly", ""]]}, {"id": "1910.04404", "submitter": "J\\\"org P. M\\\"uller", "authors": "Sarit Kraus, Amos Azaria, Jelena Fiosina, Maike Greve, Noam Hazon,\n  Lutz Kolbe, Tim-Benjamin Lembcke, J\\\"org P. M\\\"uller, S\\\"oren Schleibaum,\n  Mark Vollrath", "title": "AI for Explaining Decisions in Multi-Agent Environments", "comments": "This paper has been submitted to the Blue Sky Track of the AAAI 2020\n  conference. At the time of submission, it is under review. The tentative\n  notification date will be November 10, 2019. Current version: Name of first\n  author had been added in metadata", "journal-ref": null, "doi": "10.1609/aaai.v34i09.7077", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explanation is necessary for humans to understand and accept decisions made\nby an AI system when the system's goal is known. It is even more important when\nthe AI system makes decisions in multi-agent environments where the human does\nnot know the systems' goals since they may depend on other agents' preferences.\nIn such situations, explanations should aim to increase user satisfaction,\ntaking into account the system's decision, the user's and the other agents'\npreferences, the environment settings and properties such as fairness, envy and\nprivacy. Generating explanations that will increase user satisfaction is very\nchallenging; to this end, we propose a new research direction: xMASE. We then\nreview the state of the art and discuss research directions towards efficient\nmethodologies and algorithms for generating explanations that will increase\nusers' satisfaction from AI system's decisions in multi-agent environments.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 07:37:29 GMT"}, {"version": "v2", "created": "Sat, 12 Oct 2019 21:20:35 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Kraus", "Sarit", ""], ["Azaria", "Amos", ""], ["Fiosina", "Jelena", ""], ["Greve", "Maike", ""], ["Hazon", "Noam", ""], ["Kolbe", "Lutz", ""], ["Lembcke", "Tim-Benjamin", ""], ["M\u00fcller", "J\u00f6rg P.", ""], ["Schleibaum", "S\u00f6ren", ""], ["Vollrath", "Mark", ""]]}, {"id": "1910.04417", "submitter": "Xiaojian Ma", "authors": "Chao Yang, Xiaojian Ma, Wenbing Huang, Fuchun Sun, Huaping Liu,\n  Junzhou Huang, Chuang Gan", "title": "Imitation Learning from Observations by Minimizing Inverse Dynamics\n  Disagreement", "comments": "Accepted to NeurIPS 2019 as a spotlight. Chao Yang and Xiaojian Ma\n  contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies Learning from Observations (LfO) for imitation learning\nwith access to state-only demonstrations. In contrast to Learning from\nDemonstration (LfD) that involves both action and state supervision, LfO is\nmore practical in leveraging previously inapplicable resources (e.g. videos),\nyet more challenging due to the incomplete expert guidance. In this paper, we\ninvestigate LfO and its difference with LfD in both theoretical and practical\nperspectives. We first prove that the gap between LfD and LfO actually lies in\nthe disagreement of inverse dynamics models between the imitator and the\nexpert, if following the modeling approach of GAIL. More importantly, the upper\nbound of this gap is revealed by a negative causal entropy which can be\nminimized in a model-free way. We term our method as\nInverse-Dynamics-Disagreement-Minimization (IDDM) which enhances the\nconventional LfO method through further bridging the gap to LfD. Considerable\nempirical results on challenging benchmarks indicate that our method attains\nconsistent improvements over other LfO counterparts.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 08:07:17 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 20:10:53 GMT"}, {"version": "v3", "created": "Sun, 20 Oct 2019 19:21:27 GMT"}, {"version": "v4", "created": "Mon, 18 Nov 2019 00:17:12 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Yang", "Chao", ""], ["Ma", "Xiaojian", ""], ["Huang", "Wenbing", ""], ["Sun", "Fuchun", ""], ["Liu", "Huaping", ""], ["Huang", "Junzhou", ""], ["Gan", "Chuang", ""]]}, {"id": "1910.04424", "submitter": "Boris Ruf", "authors": "Boris Ruf, Matteo Sammarco, Marcin Detyniecki", "title": "Contract Statements Knowledge Service for Chatbots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Towards conversational agents that are capable of handling more complex\nquestions on contractual conditions, formalizing contract statements in a\nmachine readable way is crucial. However, constructing a formal model which\ncaptures the full scope of a contract proves difficult due to the overall\ncomplexity its set of rules represent. Instead, this paper presents a top-down\napproach to the problem. After identifying the most relevant contract\nstatements, we model their underlying rules in a novel knowledge engineering\nmethod. A user-friendly tool we developed for this purpose allows to do so\neasily and at scale. Then, we expose the statements as service so they can get\nsmoothly integrated in any chatbot framework.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 08:25:42 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Ruf", "Boris", ""], ["Sammarco", "Matteo", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "1910.04450", "submitter": "Siyuan Li", "authors": "Siyuan Li, Rui Wang, Minxue Tang, Chongjie Zhang", "title": "Hierarchical Reinforcement Learning with Advantage-Based Auxiliary\n  Rewards", "comments": "Camera ready version for NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical Reinforcement Learning (HRL) is a promising approach to solving\nlong-horizon problems with sparse and delayed rewards. Many existing HRL\nalgorithms either use pre-trained low-level skills that are unadaptable, or\nrequire domain-specific information to define low-level rewards. In this paper,\nwe aim to adapt low-level skills to downstream tasks while maintaining the\ngenerality of reward design. We propose an HRL framework which sets auxiliary\nrewards for low-level skill training based on the advantage function of the\nhigh-level policy. This auxiliary reward enables efficient, simultaneous\nlearning of the high-level policy and low-level skills without using\ntask-specific knowledge. In addition, we also theoretically prove that\noptimizing low-level skills with this auxiliary reward will increase the task\nreturn for the joint policy. Experimental results show that our algorithm\ndramatically outperforms other state-of-the-art HRL methods in Mujoco domains.\nWe also find both low-level and high-level policies trained by our algorithm\ntransferable.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 09:39:15 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Li", "Siyuan", ""], ["Wang", "Rui", ""], ["Tang", "Minxue", ""], ["Zhang", "Chongjie", ""]]}, {"id": "1910.04489", "submitter": "Pavel Naumov", "authors": "Pavel Naumov, Kevin Ros", "title": "Strategic Coalitions in Stochastic Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article introduces a notion of a stochastic game with failure states and\nproposes two logical systems with modality \"coalition has a strategy to\ntransition to a non-failure state with a given probability while achieving a\ngiven goal.\" The logical properties of this modality depend on whether the\nmodal language allows the empty coalition. The main technical results are a\ncompleteness theorem for a logical system with the empty coalition, a strong\ncompleteness theorem for the logical system without the empty coalition, and an\nincompleteness theorem which shows that there is no strongly complete logical\nsystem in the language with the empty coalition.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 11:33:15 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Naumov", "Pavel", ""], ["Ros", "Kevin", ""]]}, {"id": "1910.04519", "submitter": "Patrick Schrempf", "authors": "Mattias Appelgren, Patrick Schrempf, Mat\\'u\\v{s} Falis, Satoshi Ikeda,\n  Alison Q O'Neil", "title": "Language Transfer for Early Warning of Epidemics from Social Media", "comments": "Artificial Intelligence for Humanitarian Assistance and Disaster\n  Response Workshop (AI+HADR) at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statements on social media can be analysed to identify individuals who are\nexperiencing red flag medical symptoms, allowing early detection of the spread\nof disease such as influenza. Since disease does not respect cultural borders\nand may spread between populations speaking different languages, we would like\nto build multilingual models. However, the data required to train models for\nevery language may be difficult, expensive and time-consuming to obtain,\nparticularly for low-resource languages. Taking Japanese as our target\nlanguage, we explore methods by which data in one language might be used to\nbuild models for a different language. We evaluate strategies of training on\nmachine translated data and of zero-shot transfer through the use of\nmultilingual models. We find that the choice of source language impacts the\nperformance, with Chinese-Japanese being a better language pair than\nEnglish-Japanese. Training on machine translated data shows promise, especially\nwhen used in conjunction with a small amount of target language data.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 12:42:19 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Appelgren", "Mattias", ""], ["Schrempf", "Patrick", ""], ["Falis", "Mat\u00fa\u0161", ""], ["Ikeda", "Satoshi", ""], ["O'Neil", "Alison Q", ""]]}, {"id": "1910.04527", "submitter": "Vaishak Belle", "authors": "Vaishak Belle", "title": "The Quest for Interpretable and Responsible Artificial Intelligence", "comments": "This is a slightly edited version of an article to appear in The\n  Biochemist, Portland Press, October 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) provides many opportunities to improve private\nand public life. Discovering patterns and structures in large troves of data in\nan automated manner is a core component of data science, and currently drives\napplications in computational biology, finance, law and robotics. However, such\na highly positive impact is coupled with significant challenges: How do we\nunderstand the decisions suggested by these systems in order that we can trust\nthem? How can they be held accountable for those decisions?\n  In this short survey, we cover some of the motivations and trends in the area\nthat attempt to address such questions.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 12:56:14 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Belle", "Vaishak", ""]]}, {"id": "1910.04643", "submitter": "Saurabh Joshi", "authors": "Ruben Martins and Saurabh Joshi and Vasco Manquinho and Ines Lynce", "title": "Reflections on \"Incremental Cardinality Constraints for MaxSAT\"", "comments": "10 pages, 1 algorithm, 1 table, 4 figures, article invited as part of\n  \"Virtual Volume\" for 25th anniversary of CP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To celebrate the first 25 years of the International Conference on Principles\nand Practice of Constraint Programming (CP) the editors invited the authors of\nthe most cited paper of each year to write a commentary on their paper. This\nreport describes our reflections on the CP 2014 paper \"Incremental Cardinality\nConstraints for MaxSAT\" and its impact on the Maximum Satisfiability community\nand beyond.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 15:26:47 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Martins", "Ruben", ""], ["Joshi", "Saurabh", ""], ["Manquinho", "Vasco", ""], ["Lynce", "Ines", ""]]}, {"id": "1910.04700", "submitter": "Zackory Erickson", "authors": "Zackory Erickson, Vamsee Gangaram, Ariel Kapusta, C. Karen Liu, and\n  Charles C. Kemp", "title": "Assistive Gym: A Physics Simulation Framework for Assistive Robotics", "comments": "8 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous robots have the potential to serve as versatile caregivers that\nimprove quality of life for millions of people worldwide. Yet, conducting\nresearch in this area presents numerous challenges, including the risks of\nphysical interaction between people and robots. Physics simulations have been\nused to optimize and train robots for physical assistance, but have typically\nfocused on a single task. In this paper, we present Assistive Gym, an open\nsource physics simulation framework for assistive robots that models multiple\ntasks. It includes six simulated environments in which a robotic manipulator\ncan attempt to assist a person with activities of daily living (ADLs): itch\nscratching, drinking, feeding, body manipulation, dressing, and bathing.\nAssistive Gym models a person's physical capabilities and preferences for\nassistance, which are used to provide a reward function. We present baseline\npolicies trained using reinforcement learning for four different commercial\nrobots in the six environments. We demonstrate that modeling human motion\nresults in better assistance and we compare the performance of different\nrobots. Overall, we show that Assistive Gym is a promising tool for assistive\nrobotics research.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 16:56:55 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Erickson", "Zackory", ""], ["Gangaram", "Vamsee", ""], ["Kapusta", "Ariel", ""], ["Liu", "C. Karen", ""], ["Kemp", "Charles C.", ""]]}, {"id": "1910.04729", "submitter": "Muhammad Burhan Hafez", "authors": "Muhammad Burhan Hafez, Cornelius Weber, Matthias Kerzel and Stefan\n  Wermter", "title": "Efficient Intrinsically Motivated Robotic Grasping with\n  Learning-Adaptive Imagination in Latent Space", "comments": "In: Proceedings of the Joint IEEE International Conference on\n  Development and Learning and on Epigenetic Robotics (ICDL-EpiRob), Oslo,\n  Norway, Aug. 19-22, 2019", "journal-ref": null, "doi": "10.1109/DEVLRN.2019.8850723", "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining model-based and model-free deep reinforcement learning has shown\ngreat promise for improving sample efficiency on complex control tasks while\nstill retaining high performance. Incorporating imagination is a recent effort\nin this direction inspired by human mental simulation of motor behavior. We\npropose a learning-adaptive imagination approach which, unlike previous\napproaches, takes into account the reliability of the learned dynamics model\nused for imagining the future. Our approach learns an ensemble of disjoint\nlocal dynamics models in latent space and derives an intrinsic reward based on\nlearning progress, motivating the controller to take actions leading to data\nthat improves the models. The learned models are used to generate imagined\nexperiences, augmenting the training set of real experiences. We evaluate our\napproach on learning vision-based robotic grasping and show that it\nsignificantly improves sample efficiency and achieves near-optimal performance\nin a sparse reward environment.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 17:43:05 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Hafez", "Muhammad Burhan", ""], ["Weber", "Cornelius", ""], ["Kerzel", "Matthias", ""], ["Wermter", "Stefan", ""]]}, {"id": "1910.04803", "submitter": "Dong Chen", "authors": "Dong Chen, Longsheng Jiang, Yue Wang, Zhaojian Li", "title": "Autonomous Driving using Safe Reinforcement Learning by Incorporating a\n  Regret-based Human Lane-Changing Decision Model", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is expected that many human drivers will still prefer to drive themselves\neven if the self-driving technologies are ready. Therefore, human-driven\nvehicles and autonomous vehicles (AVs) will coexist in a mixed traffic for a\nlong time. To enable AVs to safely and efficiently maneuver in this mixed\ntraffic, it is critical that the AVs can understand how humans cope with risks\nand make driving-related decisions. On the other hand, the driving environment\nis highly dynamic and ever-changing, and it is thus difficult to enumerate all\nthe scenarios and hard-code the controllers. To face up these challenges, in\nthis work, we incorporate a human decision-making model in reinforcement\nlearning to control AVs for safe and efficient operations. Specifically, we\nadapt regret theory to describe a human driver's lane-changing behavior, and\nfit the personalized models to individual drivers for predicting their\nlane-changing decisions. The predicted decisions are incorporated in the safety\nconstraints for reinforcement learning in training and in implementation. We\nthen use an extended version of double deep Q-network (DDQN) to train our AV\ncontroller within the safety set. By doing so, the amount of collisions in\ntraining is reduced to zero, while the training accuracy is not impinged.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 18:33:42 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Chen", "Dong", ""], ["Jiang", "Longsheng", ""], ["Wang", "Yue", ""], ["Li", "Zhaojian", ""]]}, {"id": "1910.04836", "submitter": "Shiwali Mohan", "authors": "Shiwali Mohan and Anusha Venkatakrishnan and Andrea Hartzler", "title": "Designing an AI Health Coach and Studying its Utility in Promoting\n  Regular Aerobic Exercise", "comments": null, "journal-ref": "ACM Transactions of Interactive Intelligent Syststems 10, 2,\n  Article 14 (May 2020), 30 pages", "doi": "10.1145/3366501", "report-no": null, "categories": "cs.HC cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our research aims to develop interactive, social agents that can coach people\nto learn new tasks, skills, and habits. In this paper, we focus on coaching\nsedentary, overweight individuals (i.e., trainees) to exercise regularly. We\nemploy adaptive goal setting in which the intelligent health coach generates,\ntracks, and revises personalized exercise goals for a trainee. The goals become\nincrementally more difficult as the trainee progresses through the training\nprogram. Our approach is model-based - the coach maintains a parameterized\nmodel of the trainee's aerobic capability that drives its expectation of the\ntrainee's performance. The model is continually revised based on trainee-coach\ninteractions. The coach is embodied in a smartphone application, NutriWalking,\nwhich serves as a medium for coach-trainee interaction. We adopt a task-centric\nevaluation approach for studying the utility of the proposed algorithm in\npromoting regular aerobic exercise. We show that our approach can adapt the\ntrainee program not only to several trainees with different capabilities, but\nalso to how a trainee's capability improves as they begin to exercise more.\nExperts rate the goals selected by the coach better than other plausible goals,\ndemonstrating that our approach is consistent with clinical recommendations.\nFurther, in a 6-week observational study with sedentary participants, we show\nthat the proposed approach helps increase exercise volume performed each week.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 20:07:15 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 17:58:21 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Mohan", "Shiwali", ""], ["Venkatakrishnan", "Anusha", ""], ["Hartzler", "Andrea", ""]]}, {"id": "1910.04854", "submitter": "Daniel Seita", "authors": "Daniel Seita, Aditya Ganapathi, Ryan Hoque, Minho Hwang, Edward Cen,\n  Ajay Kumar Tanwani, Ashwin Balakrishna, Brijen Thananjeyan, Jeffrey\n  Ichnowski, Nawid Jamali, Katsu Yamane, Soshi Iba, John Canny, Ken Goldberg", "title": "Deep Imitation Learning of Sequential Fabric Smoothing From an\n  Algorithmic Supervisor", "comments": "Supplementary material is available at\n  https://sites.google.com/view/fabric-smoothing ; Version 2 has significant\n  improvements with new results and figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential pulling policies to flatten and smooth fabrics have applications\nfrom surgery to manufacturing to home tasks such as bed making and folding\nclothes. Due to the complexity of fabric states and dynamics, we apply deep\nimitation learning to learn policies that, given color (RGB), depth (D), or\ncombined color-depth (RGBD) images of a rectangular fabric sample, estimate\npick points and pull vectors to spread the fabric to maximize coverage. To\ngenerate data, we develop a fabric simulator and an algorithmic supervisor that\nhas access to complete state information. We train policies in simulation using\ndomain randomization and dataset aggregation (DAgger) on three tiers of\ndifficulty in the initial randomized configuration. We present results\ncomparing five baseline policies to learned policies and report systematic\ncomparisons of RGB vs D vs RGBD images as inputs. In simulation, learned\npolicies achieve comparable or superior performance to analytic baselines. In\n180 physical experiments with the da Vinci Research Kit (dVRK) surgical robot,\nRGBD policies trained in simulation attain coverage of 83% to 95% depending on\ndifficulty tier, suggesting that effective fabric smoothing policies can be\nlearned from an algorithmic supervisor and that depth sensing is a valuable\naddition to color alone. Supplementary material is available at\nhttps://sites.google.com/view/fabric-smoothing.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 22:06:14 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 22:26:31 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Seita", "Daniel", ""], ["Ganapathi", "Aditya", ""], ["Hoque", "Ryan", ""], ["Hwang", "Minho", ""], ["Cen", "Edward", ""], ["Tanwani", "Ajay Kumar", ""], ["Balakrishna", "Ashwin", ""], ["Thananjeyan", "Brijen", ""], ["Ichnowski", "Jeffrey", ""], ["Jamali", "Nawid", ""], ["Yamane", "Katsu", ""], ["Iba", "Soshi", ""], ["Canny", "John", ""], ["Goldberg", "Ken", ""]]}, {"id": "1910.04872", "submitter": "Rodolfo Corona", "authors": "Rodolfo Corona, Stephan Alaniz, Zeynep Akata", "title": "Modeling Conceptual Understanding in Image Reference Games", "comments": "Published in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An agent who interacts with a wide population of other agents needs to be\naware that there may be variations in their understanding of the world.\nFurthermore, the machinery which they use to perceive may be inherently\ndifferent, as is the case between humans and machines. In this work, we present\nboth an image reference game between a speaker and a population of listeners\nwhere reasoning about the concepts other agents can comprehend is necessary and\na model formulation with this capability. We focus on reasoning about the\nconceptual understanding of others, as well as adapting to novel gameplay\npartners and dealing with differences in perceptual machinery. Our experiments\non three benchmark image/attribute datasets suggest that our learner indeed\nencodes information directly pertaining to the understanding of other agents,\nand that leveraging this information is crucial for maximizing gameplay\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 21:06:47 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 05:36:54 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Corona", "Rodolfo", ""], ["Alaniz", "Stephan", ""], ["Akata", "Zeynep", ""]]}, {"id": "1910.04999", "submitter": "Javier Segovia Aguas", "authors": "Javier Segovia-Aguas, Sergio Jim\\'enez, Anders Jonsson", "title": "Generalized Planning With Procedural Domain Control Knowledge", "comments": "ICAPS 2016, 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized planning is the task of generating a single solution that is\nvalid for a set of planning problems. In this paper we show how to represent\nand compute generalized plans using procedural Domain Control Knowledge (DCK).\nWe define a {\\it divide and conquer} approach that first generates the\nprocedural DCK solving a set of planning problems representative of certain\nsubtasks and then compile it as callable procedures of the overall generalized\nplanning problem. Our procedure calling mechanism allows nested and recursive\nprocedure calls and is implemented in PDDL so that classical planners can\ncompute and exploit procedural DCK. Experiments show that an off-the-shelf\nclassical planner, using procedural DCK as callable procedures, can compute\ngeneralized plans in a wide range of domains including non-trivial ones, such\nas sorting variable-size lists or DFS traversal of binary trees with variable\nsize.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 07:16:04 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Segovia-Aguas", "Javier", ""], ["Jim\u00e9nez", "Sergio", ""], ["Jonsson", "Anders", ""]]}, {"id": "1910.05040", "submitter": "Yimin Jing", "authors": "Yimin Jing, Deyi Xiong, Yan Zhen", "title": "BiPaR: A Bilingual Parallel Dataset for Multilingual and Cross-lingual\n  Reading Comprehension on Novels", "comments": "Accepted as a long paper at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents BiPaR, a bilingual parallel novel-style machine reading\ncomprehension (MRC) dataset, developed to support multilingual and\ncross-lingual reading comprehension. The biggest difference between BiPaR and\nexisting reading comprehension datasets is that each triple (Passage, Question,\nAnswer) in BiPaR is written parallelly in two languages. We collect 3,667\nbilingual parallel paragraphs from Chinese and English novels, from which we\nconstruct 14,668 parallel question-answer pairs via crowdsourced workers\nfollowing a strict quality control procedure. We analyze BiPaR in depth and\nfind that BiPaR offers good diversification in prefixes of questions, answer\ntypes and relationships between questions and passages. We also observe that\nanswering questions of novels requires reading comprehension skills of\ncoreference resolution, multi-sentence reasoning, and understanding of implicit\ncausality, etc. With BiPaR, we build monolingual, multilingual, and\ncross-lingual MRC baseline models. Even for the relatively simple monolingual\nMRC on this dataset, experiments show that a strong BERT baseline is over 30\npoints behind human in terms of both EM and F1 score, indicating that BiPaR\nprovides a challenging testbed for monolingual, multilingual and cross-lingual\nMRC on novels. The dataset is available at https://multinlp.github.io/BiPaR/.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 09:16:29 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Jing", "Yimin", ""], ["Xiong", "Deyi", ""], ["Zhen", "Yan", ""]]}, {"id": "1910.05054", "submitter": "Weisi Guo", "authors": "Zhiyong Du, Yansha Deng, Weisi Guo, Arumugam Nallanathan, Qihui Wu", "title": "Green Deep Reinforcement Learning for Radio Resource Management:\n  Architecture, Algorithm Compression and Challenge", "comments": "under review in IEEE Communications Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI heralds a step-change in the performance and capability of wireless\nnetworks and other critical infrastructures. However, it may also cause\nirreversible environmental damage due to their high energy consumption. Here,\nwe address this challenge in the context of 5G and beyond, where there is a\ncomplexity explosion in radio resource management (RRM). On the one hand, deep\nreinforcement learning (DRL) provides a powerful tool for scalable optimization\nfor high dimensional RRM problems in a dynamic environment. On the other hand,\nDRL algorithms consume a high amount of energy over time and risk compromising\nprogress made in green radio research. This paper reviews and analyzes how to\nachieve green DRL for RRM via both architecture and algorithm innovations.\nArchitecturally, a cloud based training and distributed decision-making DRL\nscheme is proposed, where RRM entities can make lightweight deep local\ndecisions whilst assisted by on-cloud training and updating. On the algorithm\nlevel, compression approaches are introduced for both deep neural networks and\nthe underlying Markov Decision Processes, enabling accurate low-dimensional\nrepresentations of challenges. To scale learning across geographic areas, a\nspatial transfer learning scheme is proposed to further promote the learning\nefficiency of distributed DRL entities by exploiting the traffic demand\ncorrelations. Together, our proposed architecture and algorithms provide a\nvision for green and on-demand DRL capability.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 09:51:15 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Du", "Zhiyong", ""], ["Deng", "Yansha", ""], ["Guo", "Weisi", ""], ["Nallanathan", "Arumugam", ""], ["Wu", "Qihui", ""]]}, {"id": "1910.05065", "submitter": "Leonidas Doumas", "authors": "Leonidas A. A. Doumas, Guillermo Puebla, Andrea E. Martin, John E.\n  Hummel", "title": "Relation learning in a neurocomputational architecture supports\n  cross-domain transfer", "comments": "Includes supplemental material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  People readily generalise prior knowledge to novel situations and stimuli.\nAdvances in machine learning and artificial intelligence have begun to\napproximate and even surpass human performance in specific domains, but machine\nlearning systems struggle to generalise information to untrained situations. We\npresent and model that demonstrates human-like extrapolatory generalisation by\nlearning and explicitly representing an open-ended set of relations\ncharacterising regularities within the domains it is exposed to. First, when\ntrained to play one video game (e.g., Breakout). the model generalises to a new\ngame (e.g., Pong) with different rules, dimensions, and characteristics in a\nsingle shot. Second, the model can learn representations from a different\ndomain (e.g., 3D shape images) that support learning a video game and\ngeneralising to a new game in one shot. By exploiting well-established\nprinciples from cognitive psychology and neuroscience, the model learns\nstructured representations without feedback, and without requiring knowledge of\nthe relevant relations to be given a priori. We present additional simulations\nshowing that the representations that the model learns support cross-domain\ngeneralisation. The model's ability to generalise between different games\ndemonstrates the flexible generalisation afforded by a capacity to learn not\nonly statistical relations, but also other relations that are useful for\ncharacterising the domain to be learned. In turn, this kind of flexible,\nrelational generalisation is only possible because the model is capable of\nrepresenting relations explicitly, a capacity that is notably absent in extant\nstatistical machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 10:21:06 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Doumas", "Leonidas A. A.", ""], ["Puebla", "Guillermo", ""], ["Martin", "Andrea E.", ""], ["Hummel", "John E.", ""]]}, {"id": "1910.05113", "submitter": "Deepak P", "authors": "Savitha Sam Abraham, Deepak P, Sowmya S Sundaram", "title": "Fairness in Clustering with Multiple Sensitive Attributes", "comments": "Proceedings of the 23rd International Conference on Extending\n  Database Technology (EDBT 2020), 30th March-2nd April, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A clustering may be considered as fair on pre-specified sensitive attributes\nif the proportions of sensitive attribute groups in each cluster reflect that\nin the dataset. In this paper, we consider the task of fair clustering for\nscenarios involving multiple multi-valued or numeric sensitive attributes. We\npropose a fair clustering method, \\textit{FairKM} (Fair K-Means), that is\ninspired by the popular K-Means clustering formulation. We outline a\ncomputational notion of fairness which is used along with a cluster coherence\nobjective, to yield the FairKM clustering method. We empirically evaluate our\napproach, wherein we quantify both the quality and fairness of clusters, over\nreal-world datasets. Our experimental evaluation illustrates that the clusters\ngenerated by FairKM fare significantly better on both clustering quality and\nfair representation of sensitive attribute groups compared to the clusters from\na state-of-the-art baseline fair clustering method.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 12:28:52 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 16:52:25 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Abraham", "Savitha Sam", ""], ["P", "Deepak", ""], ["Sundaram", "Sowmya S", ""]]}, {"id": "1910.05126", "submitter": "Gyunam Park", "authors": "Gyunam Park and Minseok Song", "title": "Prediction-based Resource Allocation using Bayesian Neural Networks and\n  Minimum Cost and Maximum Flow Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive business process monitoring aims at providing predictions about\nrunning instances by analyzing logs of completed cases in a business process.\nRecently, a lot of research focuses on increasing productivity and efficiency\nin a business process by forecasting potential problems during its executions.\nHowever, most of the studies lack suggesting concrete actions to improve the\nprocess. They leave it up to the subjective judgment of a user. In this paper,\nwe propose a novel method to connect the results from predictive business\nprocess monitoring to actual business process improvements. More in detail, we\noptimize the resource allocation in a non-clairvoyant online environment, where\nwe have limited information required for scheduling, by exploiting the\npredictions. The proposed method integrates the offline prediction model\nconstruction that predicts the processing time and the next activity of an\nongoing instance using Bayesian Neural Networks (BNNs) with the online resource\nallocation that is extended from the minimum cost and maximum flow algorithm.\nTo validate the proposed method, we performed experiments using an artificial\nevent log and a real-life event log from a global financial organization.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 12:35:12 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Park", "Gyunam", ""], ["Song", "Minseok", ""]]}, {"id": "1910.05291", "submitter": "Serhii Havrylov", "authors": "Shangmin Guo, Yi Ren, Serhii Havrylov, Stella Frank, Ivan Titov, Kenny\n  Smith", "title": "The Emergence of Compositional Languages for Numeric Concepts Through\n  Iterated Learning in Neural Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since first introduced, computer simulation has been an increasingly\nimportant tool in evolutionary linguistics. Recently, with the development of\ndeep learning techniques, research in grounded language learning has also\nstarted to focus on facilitating the emergence of compositional languages\nwithout pre-defined elementary linguistic knowledge. In this work, we explore\nthe emergence of compositional languages for numeric concepts in multi-agent\ncommunication systems. We demonstrate that compositional language for encoding\nnumeric concepts can emerge through iterated learning in populations of deep\nneural network agents. However, language properties greatly depend on the input\nrepresentations given to agents. We found that compositional languages only\nemerge if they require less iterations to be fully learnt than other\nnon-degenerate languages for agents on a given input representation.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 16:34:01 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Guo", "Shangmin", ""], ["Ren", "Yi", ""], ["Havrylov", "Serhii", ""], ["Frank", "Stella", ""], ["Titov", "Ivan", ""], ["Smith", "Kenny", ""]]}, {"id": "1910.05387", "submitter": "Amanda Gentzel", "authors": "Amanda Gentzel, Dan Garant, and David Jensen", "title": "The Case for Evaluating Causal Models Using Interventional Measures and\n  Empirical Data", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference is central to many areas of artificial intelligence,\nincluding complex reasoning, planning, knowledge-base construction, robotics,\nexplanation, and fairness. An active community of researchers develops and\nenhances algorithms that learn causal models from data, and this work has\nproduced a series of impressive technical advances. However, evaluation\ntechniques for causal modeling algorithms have remained somewhat primitive,\nlimiting what we can learn from experimental studies of algorithm performance,\nconstraining the types of algorithms and model representations that researchers\nconsider, and creating a gap between theory and practice. We argue for more\nfrequent use of evaluation techniques that examine interventional measures\nrather than structural or observational measures, and that evaluate those\nmeasures on empirical data rather than synthetic data. We survey the current\npractice in evaluation and show that the techniques we recommend are rarely\nused in practice. We show that such techniques are feasible and that data sets\nare available to conduct such evaluations. We also show that these techniques\nproduce substantially different results than using structural measures and\nsynthetic data.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 19:54:30 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 21:22:15 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Gentzel", "Amanda", ""], ["Garant", "Dan", ""], ["Jensen", "David", ""]]}, {"id": "1910.05389", "submitter": "Ziyu Yao", "authors": "Ziyu Yao, Yu Su, Huan Sun, Wen-tau Yih", "title": "Model-based Interactive Semantic Parsing: A Unified Framework and A\n  Text-to-SQL Case Study", "comments": "14 pages, 4 figures, accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a promising paradigm, interactive semantic parsing has shown to improve\nboth semantic parsing accuracy and user confidence in the results. In this\npaper, we propose a new, unified formulation of the interactive semantic\nparsing problem, where the goal is to design a model-based intelligent agent.\nThe agent maintains its own state as the current predicted semantic parse,\ndecides whether and where human intervention is needed, and generates a\nclarification question in natural language. A key part of the agent is a world\nmodel: it takes a percept (either an initial question or subsequent feedback\nfrom the user) and transitions to a new state. We then propose a simple yet\nremarkably effective instantiation of our framework, demonstrated on two\ntext-to-SQL datasets (WikiSQL and Spider) with different state-of-the-art base\nsemantic parsers. Compared to an existing interactive semantic parsing approach\nthat treats the base parser as a black box, our approach solicits less user\nfeedback but yields higher run-time accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 19:56:47 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Yao", "Ziyu", ""], ["Su", "Yu", ""], ["Sun", "Huan", ""], ["Yih", "Wen-tau", ""]]}, {"id": "1910.05651", "submitter": "AmirEmad Ghassami", "authors": "AmirEmad Ghassami, Saber Salehkaleybar, Negar Kiyavash", "title": "Interventional Experiment Design for Causal Structure Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that from purely observational data, a causal DAG is identifiable\nonly up to its Markov equivalence class, and for many ground truth DAGs, the\ndirection of a large portion of the edges will be remained unidentified. The\ngolden standard for learning the causal DAG beyond Markov equivalence is to\nperform a sequence of interventions in the system and use the data gathered\nfrom the interventional distributions. We consider a setup in which given a\nbudget $k$, we design $k$ interventions non-adaptively. We cast the problem of\nfinding the best intervention target set as an optimization problem which aims\nto maximize the number of edges whose directions are identified due to the\nperformed interventions. First, we consider the case that the underlying causal\nstructure is a tree. For this case, we propose an efficient exact algorithm for\nthe worst-case gain setup, as well as an approximate algorithm for the average\ngain setup. We then show that the proposed approach for the average gain setup\ncan be extended to the case of general causal structures. In this case, besides\nthe design of interventions, calculating the objective function is also\nchallenging. We propose an efficient exact calculator as well as two estimators\nfor this task. We evaluate the proposed methods using synthetic as well as real\ndata.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 21:48:22 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Ghassami", "AmirEmad", ""], ["Salehkaleybar", "Saber", ""], ["Kiyavash", "Negar", ""]]}, {"id": "1910.05664", "submitter": "Yonadav Shavit", "authors": "Yonadav Shavit, William S. Moses", "title": "Extracting Incentives from Black-Box Decisions", "comments": "Accepted to the NeurIPS 2019 Workshop on Robust AI in Financial\n  Services: Data, Fairness, Explainability, Trustworthiness, and Privacy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An algorithmic decision-maker incentivizes people to act in certain ways to\nreceive better decisions. These incentives can dramatically influence subjects'\nbehaviors and lives, and it is important that both decision-makers and\ndecision-recipients have clarity on which actions are incentivized by the\nchosen model. While for linear functions, the changes a subject is incentivized\nto make may be clear, we prove that for many non-linear functions (e.g. neural\nnetworks, random forests), classical methods for interpreting the behavior of\nmodels (e.g. input gradients) provide poor advice to individuals on which\nactions they should take. In this work, we propose a mathematical framework for\nunderstanding algorithmic incentives as the challenge of solving a Markov\nDecision Process, where the state includes the set of input features, and the\nreward is a function of the model's output. We can then leverage the many\ntoolkits for solving MDPs (e.g. tree-based planning, reinforcement learning) to\nidentify the optimal actions each individual is incentivized to take to improve\ntheir decision under a given model. We demonstrate the utility of our method by\nestimating the maximally-incentivized actions in two real-world settings: a\nrecidivism risk predictor we train using ProPublica's COMPAS dataset, and an\nonline credit scoring tool published by the Fair Isaac Corporation (FICO).\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 01:17:29 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Shavit", "Yonadav", ""], ["Moses", "William S.", ""]]}, {"id": "1910.05789", "submitter": "Micah Carroll", "authors": "Micah Carroll, Rohin Shah, Mark K. Ho, Thomas L. Griffiths, Sanjit A.\n  Seshia, Pieter Abbeel, Anca Dragan", "title": "On the Utility of Learning about Humans for Human-AI Coordination", "comments": "Published at NeurIPS 2019\n  (http://papers.nips.cc/paper/8760-on-the-utility-of-learning-about-humans-for-human-ai-coordination)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While we would like agents that can coordinate with humans, current\nalgorithms such as self-play and population-based training create agents that\ncan coordinate with themselves. Agents that assume their partner to be optimal\nor similar to them can converge to coordination protocols that fail to\nunderstand and be understood by humans. To demonstrate this, we introduce a\nsimple environment that requires challenging coordination, based on the popular\ngame Overcooked, and learn a simple model that mimics human play. We evaluate\nthe performance of agents trained via self-play and population-based training.\nThese agents perform very well when paired with themselves, but when paired\nwith our human model, they are significantly worse than agents designed to play\nwith the human model. An experiment with a planning algorithm yields the same\nconclusion, though only when the human-aware planner is given the exact human\nmodel that it is playing with. A user study with real humans shows this pattern\nas well, though less strongly. Qualitatively, we find that the gains come from\nhaving the agent adapt to the human's gameplay. Given this result, we suggest\nseveral approaches for designing agents that learn about humans in order to\nbetter coordinate with them. Code is available at\nhttps://github.com/HumanCompatibleAI/overcooked_ai.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 17:17:52 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 00:51:44 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Carroll", "Micah", ""], ["Shah", "Rohin", ""], ["Ho", "Mark K.", ""], ["Griffiths", "Thomas L.", ""], ["Seshia", "Sanjit A.", ""], ["Abbeel", "Pieter", ""], ["Dragan", "Anca", ""]]}, {"id": "1910.05810", "submitter": "Samuel Sohn", "authors": "Samuel S. Sohn and Seonghyeon Moon and Honglu Zhou and Sejong Yoon and\n  Vladimir Pavlovic and Mubbasir Kapadia", "title": "Deep Crowd-Flow Prediction in Built Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the behavior of crowds in complex environments is a key\nrequirement in a multitude of application areas, including crowd and disaster\nmanagement, architectural design, and urban planning. Given a crowd's immediate\nstate, current approaches simulate crowd movement to arrive at a future state.\nHowever, most applications require the ability to predict hundreds of possible\nsimulation outcomes (e.g., under different environment and crowd situations) at\nreal-time rates, for which these approaches are prohibitively expensive.\n  In this paper, we propose an approach to instantly predict the long-term flow\nof crowds in arbitrarily large, realistic environments. Central to our approach\nis a novel CAGE representation consisting of Capacity, Agent, Goal, and\nEnvironment-oriented information, which efficiently encodes and decodes crowd\nscenarios into compact, fixed-size representations that are environmentally\nlossless. We present a framework to facilitate the accurate and efficient\nprediction of crowd flow in never-before-seen crowd scenarios. We conduct a\nseries of experiments to evaluate the efficacy of our approach and showcase\npositive results.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 18:43:55 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Sohn", "Samuel S.", ""], ["Moon", "Seonghyeon", ""], ["Zhou", "Honglu", ""], ["Yoon", "Sejong", ""], ["Pavlovic", "Vladimir", ""], ["Kapadia", "Mubbasir", ""]]}, {"id": "1910.05865", "submitter": "Yifan Xu", "authors": "Yifan Xu, Lu Dai, Udaikaran Singh, Kening Zhang, Zhuowen Tu", "title": "Neural Program Synthesis By Self-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural inductive program synthesis is a task generating instructions that can\nproduce desired outputs from given inputs. In this paper, we focus on the\ngeneration of a chunk of assembly code that can be executed to match a state\nchange inside the CPU and RAM. We develop a neural program synthesis algorithm,\nAutoAssemblet, learned via self-learning reinforcement learning that explores\nthe large code space efficiently. Policy networks and value networks are\nlearned to reduce the breadth and depth of the Monte Carlo Tree Search,\nresulting in better synthesis performance. We also propose an effective\nmulti-entropy policy sampling technique to alleviate online update\ncorrelations. We apply AutoAssemblet to basic programming tasks and show\nsignificant higher success rates compared to several competing baselines.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 23:44:37 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Xu", "Yifan", ""], ["Dai", "Lu", ""], ["Singh", "Udaikaran", ""], ["Zhang", "Kening", ""], ["Tu", "Zhuowen", ""]]}, {"id": "1910.05915", "submitter": "Shengluan Hou", "authors": "Shengluan Hou and Ruqian Lu", "title": "Knowledge-guided Unsupervised Rhetorical Parsing for Text Summarization", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic text summarization (ATS) has recently achieved impressive\nperformance thanks to recent advances in deep learning and the availability of\nlarge-scale corpora. To make the summarization results more faithful, this\npaper presents an unsupervised approach that combines rhetorical structure\ntheory, deep neural model and domain knowledge concern for ATS. This\narchitecture mainly contains three components: domain knowledge base\nconstruction based on representation learning, attentional encoder-decoder\nmodel for rhetorical parsing and subroutine-based model for text summarization.\nDomain knowledge can be effectively used for unsupervised rhetorical parsing\nthus rhetorical structure trees for each document can be derived. In the\nunsupervised rhetorical parsing module, the idea of translation was adopted to\nalleviate the problem of data scarcity. The subroutine-based summarization\nmodel purely depends on the derived rhetorical structure trees and can generate\ncontent-balanced results. To evaluate the summary results without golden\nstandard, we proposed an unsupervised evaluation metric, whose hyper-parameters\nwere tuned by supervised learning. Experimental results show that, on a\nlarge-scale Chinese dataset, our proposed approach can obtain comparable\nperformances compared with existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 04:48:16 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Hou", "Shengluan", ""], ["Lu", "Ruqian", ""]]}, {"id": "1910.05923", "submitter": "Bolin Wei", "authors": "Bolin Wei, Ge Li, Xin Xia, Zhiyi Fu, Zhi Jin", "title": "Code Generation as a Dual Task of Code Summarization", "comments": "To appear at the 33rd Conference on Neural Information Processing\n  Systems (NeurIPS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code summarization (CS) and code generation (CG) are two crucial tasks in the\nfield of automatic software development. Various neural network-based\napproaches are proposed to solve these two tasks separately. However, there\nexists a specific intuitive correlation between CS and CG, which have not been\nexploited in previous work. In this paper, we apply the relations between two\ntasks to improve the performance of both tasks. In other words, exploiting the\nduality between the two tasks, we propose a dual training framework to train\nthe two tasks simultaneously. In this framework, we consider the dualities on\nprobability and attention weights, and design corresponding regularization\nterms to constrain the duality. We evaluate our approach on two datasets\ncollected from GitHub, and experimental results show that our dual framework\ncan improve the performance of CS and CG tasks over baselines.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 05:54:00 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Wei", "Bolin", ""], ["Li", "Ge", ""], ["Xia", "Xin", ""], ["Fu", "Zhiyi", ""], ["Jin", "Zhi", ""]]}, {"id": "1910.05927", "submitter": "Yuping Luo", "authors": "Kefan Dong, Yuping Luo, Tengyu Ma", "title": "On the Expressivity of Neural Networks for Deep Reinforcement Learning", "comments": "Accepted in ICML 2020. Title of previous version was \"Bootstrapping\n  the Expressivity with Model-based Planning\". Code is available at\n  https://github.com/roosephu/boots", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare the model-free reinforcement learning with the model-based\napproaches through the lens of the expressive power of neural networks for\npolicies, $Q$-functions, and dynamics. We show, theoretically and empirically,\nthat even for one-dimensional continuous state space, there are many MDPs whose\noptimal $Q$-functions and policies are much more complex than the dynamics. We\nhypothesize many real-world MDPs also have a similar property. For these MDPs,\nmodel-based planning is a favorable algorithm, because the resulting policies\ncan approximate the optimal policy significantly better than a neural network\nparameterization can, and model-free or model-based policy optimization rely on\npolicy parameterization. Motivated by the theory, we apply a simple multi-step\nmodel-based bootstrapping planner (BOOTS) to bootstrap a weak $Q$-function into\na stronger policy. Empirical results show that applying BOOTS on top of\nmodel-based or model-free policy optimization algorithms at the test time\nimproves the performance on MuJoCo benchmark tasks.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 06:17:49 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 01:07:35 GMT"}, {"version": "v3", "created": "Sun, 6 Sep 2020 12:15:54 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Dong", "Kefan", ""], ["Luo", "Yuping", ""], ["Ma", "Tengyu", ""]]}, {"id": "1910.06001", "submitter": "Xinle Liang", "authors": "Xinle Liang, Yang Liu, Tianjian Chen, Ming Liu and Qiang Yang", "title": "Federated Transfer Reinforcement Learning for Autonomous Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is widely used in autonomous driving tasks and\ntraining RL models typically involves in a multi-step process: pre-training RL\nmodels on simulators, uploading the pre-trained model to real-life robots, and\nfine-tuning the weight parameters on robot vehicles. This sequential process is\nextremely time-consuming and more importantly, knowledge from the fine-tuned\nmodel stays local and can not be re-used or leveraged collaboratively. To\ntackle this problem, we present an online federated RL transfer process for\nreal-time knowledge extraction where all the participant agents make\ncorresponding actions with the knowledge learned by others, even when they are\nacting in very different environments. To validate the effectiveness of the\nproposed approach, we constructed a real-life collision avoidance system with\nMicrosoft Airsim simulator and NVIDIA JetsonTX2 car agents, which cooperatively\nlearn from scratch to avoid collisions in indoor environment with obstacle\nobjects. We demonstrate that with the proposed framework, the simulator car\nagents can transfer knowledge to the RC cars in real-time, with 27% increase in\nthe average distance with obstacles and 42% decrease in the collision counts.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 09:15:31 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Liang", "Xinle", ""], ["Liu", "Yang", ""], ["Chen", "Tianjian", ""], ["Liu", "Ming", ""], ["Yang", "Qiang", ""]]}, {"id": "1910.06048", "submitter": "Kashyap Popat", "authors": "Kashyap Popat, Subhabrata Mukherjee, Andrew Yates, Gerhard Weikum", "title": "STANCY: Stance Classification Based on Consistency Cues", "comments": "Accepted at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Controversial claims are abundant in online media and discussion forums. A\nbetter understanding of such claims requires analyzing them from different\nperspectives. Stance classification is a necessary step for inferring these\nperspectives in terms of supporting or opposing the claim. In this work, we\npresent a neural network model for stance classification leveraging BERT\nrepresentations and augmenting them with a novel consistency constraint.\nExperiments on the Perspectrum dataset, consisting of claims and users'\nperspectives from various debate websites, demonstrate the effectiveness of our\napproach over state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 11:39:45 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Popat", "Kashyap", ""], ["Mukherjee", "Subhabrata", ""], ["Yates", "Andrew", ""], ["Weikum", "Gerhard", ""]]}, {"id": "1910.06079", "submitter": "Tomek Korbak", "authors": "Tomasz Korbak and Julian Zubek and {\\L}ukasz Kuci\\'nski and Piotr\n  Mi{\\l}o\\'s and Joanna R\\k{a}czaszek-Leonardi", "title": "Developmentally motivated emergence of compositional communication via\n  template transfer", "comments": "Accepted for NeurIPS 2019 workshop Emergent Communication: Towards\n  Natural Language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores a novel approach to achieving emergent compositional\ncommunication in multi-agent systems. We propose a training regime implementing\ntemplate transfer, the idea of carrying over learned biases across contexts. In\nour method, a sender-receiver pair is first trained with disentangled loss\nfunctions and then the receiver is transferred to train a new sender with a\nstandard loss. Unlike other methods (e.g. the obverter algorithm), our approach\ndoes not require imposing inductive biases on the architecture of the agents.\nWe experimentally show the emergence of compositional communication using\ntopographical similarity, zero-shot generalization and context independence as\nevaluation metrics. The presented approach is connected to an important line of\nwork in semiotics and developmental psycholinguistics: it supports a conjecture\nthat compositional communication is scaffolded on simpler communication\nprotocols.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 16:04:53 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Korbak", "Tomasz", ""], ["Zubek", "Julian", ""], ["Kuci\u0144ski", "\u0141ukasz", ""], ["Mi\u0142o\u015b", "Piotr", ""], ["R\u0105czaszek-Leonardi", "Joanna", ""]]}, {"id": "1910.06144", "submitter": "Javier S\\'anchez-Monedero", "authors": "Javier Sanchez-Monedero, Lina Dencik and Lilian Edwards", "title": "What does it mean to solve the problem of discrimination in hiring?\n  Social, technical and legal perspectives from the UK on automated hiring\n  systems", "comments": "12 pages", "journal-ref": "Conference on Fairness, Accountability, and Transparency (FAT*\n  '20), January 27-30, 2020, Barcelona, Spain", "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ability to get and keep a job is a key aspect of participating in society\nand sustaining livelihoods. Yet the way decisions are made on who is eligible\nfor jobs, and why, are rapidly changing with the advent and growth in uptake of\nautomated hiring systems (AHSs) powered by data-driven tools. Key concerns\nabout such AHSs include the lack of transparency and potential limitation of\naccess to jobs for specific profiles. In relation to the latter, however,\nseveral of these AHSs claim to detect and mitigate discriminatory practices\nagainst protected groups and promote diversity and inclusion at work. Yet\nwhilst these tools have a growing user-base around the world, such claims of\nbias mitigation are rarely scrutinised and evaluated, and when done so, have\nalmost exclusively been from a US socio-legal perspective. In this paper, we\nintroduce a perspective outside the US by critically examining how three\nprominent automated hiring systems (AHSs) in regular use in the UK, HireVue,\nPymetrics and Applied, understand and attempt to mitigate bias and\ndiscrimination. Using publicly available documents, we describe how their tools\nare designed, validated and audited for bias, highlighting assumptions and\nlimitations, before situating these in the socio-legal context of the UK. The\nUK has a very different legal background to the US in terms not only of hiring\nand equality law, but also in terms of data protection (DP) law. We argue that\nthis might be important for addressing concerns about transparency and could\nmean a challenge to building bias mitigation into AHSs definitively capable of\nmeeting EU legal standards. This is significant as these AHSs, especially those\ndeveloped in the US, may obscure rather than improve systemic discrimination in\nthe workplace.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 10:56:43 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 11:29:18 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Sanchez-Monedero", "Javier", ""], ["Dencik", "Lina", ""], ["Edwards", "Lilian", ""]]}, {"id": "1910.06266", "submitter": "Dinesh Verma", "authors": "D. Verma, S. Calo", "title": "Using AI/ML to gain situational understanding from passive network\n  observations", "comments": "Presented at AAAI FSS-19: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data available in the network traffic fromany Government building\ncontains a significant amount ofinformation. An analysis of the traffic can\nyield insightsand situational understanding about what is happening inthe\nbuilding. However, the use of traditional network packet inspection, either\ndeep or shallow, is useful for only a limited understanding of the environment,\nwith applicability limited to some aspects of network and security management.\nIf weuse AI/ML based techniques to understand the network traffic, we can gain\nsignificant insights which increase our situational awareness of what is\nhappening in the environment.At IBM, we have created a system which uses a\ncombination of network domain knowledge and machine learning techniques to\nconvert network traffic into actionable insights about the on premise\nenvironment. These insights include characterization of the communicating\ndevices, discovering unauthorized devices that may violate policy requirements,\nidentifying hidden components and vulnerability points, detecting leakage of\nsensitive information, and identifying the presence of people and devices.In\nthis paper, we will describe the overall design of this system, the major\nuse-cases that have been identified for it, and the lessons learnt when\ndeploying this system for some of those use-cases\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 16:46:33 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Verma", "D.", ""], ["Calo", "S.", ""]]}, {"id": "1910.06358", "submitter": "Christopher Frye", "authors": "Christopher Frye, Colin Rowat, Ilya Feige", "title": "Asymmetric Shapley values: incorporating causal knowledge into\n  model-agnostic explainability", "comments": "To appear in NeurIPS 2020; 9 pages, 2 figures, 2 appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explaining AI systems is fundamental both to the development of high\nperforming models and to the trust placed in them by their users. The Shapley\nframework for explainability has strength in its general applicability combined\nwith its precise, rigorous foundation: it provides a common, model-agnostic\nlanguage for AI explainability and uniquely satisfies a set of intuitive\nmathematical axioms. However, Shapley values are too restrictive in one\nsignificant regard: they ignore all causal structure in the data. We introduce\na less restrictive framework, Asymmetric Shapley values (ASVs), which are\nrigorously founded on a set of axioms, applicable to any AI system, and\nflexible enough to incorporate any causal structure known to be respected by\nthe data. We demonstrate that ASVs can (i) improve model explanations by\nincorporating causal information, (ii) provide an unambiguous test for unfair\ndiscrimination in model predictions, (iii) enable sequentially incremental\nexplanations in time-series models, and (iv) support feature-selection studies\nwithout the need for model retraining.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 18:08:32 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 19:15:21 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Frye", "Christopher", ""], ["Rowat", "Colin", ""], ["Feige", "Ilya", ""]]}, {"id": "1910.06404", "submitter": "Xibai Lou", "authors": "Xibai Lou, Yang Yang and Changhyun Choi", "title": "Learning to Generate 6-DoF Grasp Poses with Reachability Awareness", "comments": "Published as a conference paper at ICRA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the stringent requirements of unstructured real-world where a\nplethora of unknown objects reside in arbitrary locations of the surface, we\npropose a voxel-based deep 3D Convolutional Neural Network (3D CNN) that\ngenerates feasible 6-DoF grasp poses in unrestricted workspace with\nreachability awareness. Unlike the majority of works that predict if a proposed\ngrasp pose within the restricted workspace will be successful solely based on\ngrasp pose stability, our approach further learns a reachability predictor that\nevaluates if the grasp pose is reachable or not from robot's own experience. To\navoid the laborious real training data collection, we exploit the power of\nsimulation to train our networks on a large-scale synthetic dataset. This work\nis an early attempt that simultaneously evaluates grasping reachability from\nlearned knowledge while proposing feasible grasp poses with 3D CNN.\nExperimental results in both simulation and real-world demonstrate that our\napproach outperforms several other methods and achieves 82.5% grasping success\nrate on unknown objects.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 20:13:36 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 16:58:02 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 21:24:00 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Lou", "Xibai", ""], ["Yang", "Yang", ""], ["Choi", "Changhyun", ""]]}, {"id": "1910.06428", "submitter": "Soheil Ghafurian", "authors": "Bairavi Venkatesh, Tosha Shah, Antong Chen, Soheil Ghafurian", "title": "Restoration of marker occluded hematoxylin and eosin stained whole slide\n  histology images using generative adversarial networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is common for pathologists to annotate specific regions of the tissue,\nsuch as tumor, directly on the glass slide with markers. Although this practice\nwas helpful prior to the advent of histology whole slide digitization, it often\noccludes important details which are increasingly relevant to immuno-oncology\ndue to recent advancements in digital pathology imaging techniques. The current\nwork uses a generative adversarial network with cycle loss to remove these\nannotations while still maintaining the underlying structure of the tissue by\nsolving an image-to-image translation problem. We train our network on up to\n300 whole slide images with marker inks and show that 70% of the corrected\nimage patches are indistinguishable from originally uncontaminated image tissue\nto a human expert. This portion increases 97% when we replace the human expert\nwith a deep residual network. We demonstrated the fidelity of the method to the\noriginal image by calculating the correlation between image gradient\nmagnitudes. We observed a revival of up to 94,000 nuclei per slide in our\ndataset, the majority of which were located on tissue border.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 21:22:54 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Venkatesh", "Bairavi", ""], ["Shah", "Tosha", ""], ["Chen", "Antong", ""], ["Ghafurian", "Soheil", ""]]}, {"id": "1910.06456", "submitter": "Shaika Chowdhury", "authors": "Shaika Chowdhury, Chenwei Zhang, Philip S.Yu and Yuan Luo", "title": "Mixed Pooling Multi-View Attention Autoencoder for Representation\n  Learning in Healthcare", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed representations have been used to support downstream tasks in\nhealthcare recently. Healthcare data (e.g., electronic health records) contain\nmultiple modalities of data from heterogeneous sources that can provide\ncomplementary information, alongside an added dimension to learning\npersonalized patient representations. To this end, in this paper we propose a\nnovel unsupervised encoder-decoder model, namely Mixed Pooling Multi-View\nAttention Autoencoder (MPVAA), that generates patient representations\nencapsulating a holistic view of their medical profile. Specifically, by first\nlearning personalized graph embeddings pertaining to each patient's\nheterogeneous healthcare data, it then integrates the non-linear relationships\namong them into a unified representation through multi-view attention\nmechanism. Additionally, a mixed pooling strategy is incorporated in the\nencoding step to learn diverse information specific to each data modality.\nExperiments conducted for multiple tasks demonstrate the effectiveness of the\nproposed model over the state-of-the-art representation learning methods in\nhealthcare.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 22:59:51 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Chowdhury", "Shaika", ""], ["Zhang", "Chenwei", ""], ["Yu", "Philip S.", ""], ["Luo", "Yuan", ""]]}, {"id": "1910.06624", "submitter": "Niki Pfeifer", "authors": "Niki Pfeifer", "title": "Probability Logic", "comments": "16 pages, handbook chapter contribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.LO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter presents probability logic as a rationality framework for human\nreasoning under uncertainty. Selected formal-normative aspects of probability\nlogic are discussed in the light of experimental evidence. Specifically,\nprobability logic is characterized as a generalization of bivalent\ntruth-functional propositional logic (short \"logic\"), as being connexive, and\nas being nonmonotonic. The chapter discusses selected argument forms and\nassociated uncertainty propagation rules. Throughout the chapter, the\ndescriptive validity of probability logic is compared to logic, which was used\nas the gold standard of reference for assessing the rationality of human\nreasoning in the 20th century.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 10:01:51 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Pfeifer", "Niki", ""]]}, {"id": "1910.06636", "submitter": "Guillaume Escamocher", "authors": "Guillaume Escamocher, Barry O'Sullivan", "title": "Solving Logic Grid Puzzles with an Algorithm that Imitates Human\n  Behavior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present in this paper our solver for logic grid puzzles. The approach used\nby our algorithm mimics the way a human would try to solve the same problem.\nEvery progress made during the solving process is accompanied by a detailed\nexplanation of our program's reasoning. Since this reasoning is based on the\nsame heuristics that a human would employ, the user can easily follow the given\nexplanation.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 10:18:07 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Escamocher", "Guillaume", ""], ["O'Sullivan", "Barry", ""]]}, {"id": "1910.06658", "submitter": "Linas Petkevicius", "authors": "Povilas Daniusis, Shubham Juneja, Lukas Valatka, Linas Petkevicius", "title": "Topological Navigation Graph Framework", "comments": null, "journal-ref": null, "doi": "10.1007/s10514-021-09980-x", "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the utilisation of reactive trajectory imitation controllers for\ngoal-directed mobile robot navigation. We propose a topological navigation\ngraph (TNG) - an imitation-learning-based framework for navigating through\nenvironments with intersecting trajectories. The TNG framework represents the\nenvironment as a directed graph composed of deep neural networks. Each vertex\nof the graph corresponds to a trajectory and is represented by a trajectory\nidentification classifier and a trajectory imitation controller. For trajectory\nfollowing, we propose the novel use of neural object detection architectures.\nThe edges of TNG correspond to intersections between trajectories and are all\nrepresented by a classifier. We provide empirical evaluation of the proposed\nnavigation framework and its components in simulated and real-world\nenvironments, demonstrating that TNG allows us to utilise non-goal-directed,\nimitation-learning methods for goal-directed autonomous navigation.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 11:19:00 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 18:02:46 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Daniusis", "Povilas", ""], ["Juneja", "Shubham", ""], ["Valatka", "Lukas", ""], ["Petkevicius", "Linas", ""]]}, {"id": "1910.06707", "submitter": "Junjie Yin", "authors": "Junjie Yin, Zixun Chen, Kelai Zhou, Chongyuan Yu", "title": "A Deep Learning Based Chatbot for Campus Psychological Therapy", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Evebot, an innovative, sequence to sequence\n(Seq2seq) based, fully generative conversational system for the diagnosis of\nnegative emotions and prevention of depression through positively suggestive\nresponses. The system consists of an assembly of deep-learning based models,\nincluding Bi-LSTM based model for detecting negative emotions of users and\nobtaining psychological counselling related corpus for training the chatbot,\nanti-language sequence to sequence neural network, and maximum mutual\ninformation (MMI) model. As adolescents are reluctant to show their negative\nemotions in physical interaction, traditional methods of emotion analysis and\ncomforting methods may not work. Therefore, this system puts emphasis on using\nvirtual platform to detect signs of depression or anxiety, channel adolescents'\nstress and mood, and thus prevent the emergence of mental illness. We launched\nthe integrated chatbot system onto an online platform for real-world campus\napplications. Through a one-month user study, we observe better results in the\nincrease in positivity than other public chatbots in the control group.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 15:34:28 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Yin", "Junjie", ""], ["Chen", "Zixun", ""], ["Zhou", "Kelai", ""], ["Yu", "Chongyuan", ""]]}, {"id": "1910.06708", "submitter": "Tianxing Wu", "authors": "Tianxing Wu, Arijit Khan, Huan Gao, Cheng Li", "title": "Efficiently Embedding Dynamic Knowledge Graphs", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph (KG) embedding encodes the entities and relations from a KG\ninto low-dimensional vector spaces to support various applications such as KG\ncompletion, question answering, and recommender systems. In real world,\nknowledge graphs (KGs) are dynamic and evolve over time with addition or\ndeletion of triples. However, most existing models focus on embedding static\nKGs while neglecting dynamics. To adapt to the changes in a KG, these models\nneed to be re-trained on the whole KG with a high time cost.\n  In this paper, to tackle the aforementioned problem, we propose a new\ncontext-aware Dynamic Knowledge Graph Embedding (DKGE) method which supports\nthe embedding learning in an online fashion. DKGE introduces two different\nrepresentations (i.e., knowledge embedding and contextual element embedding)\nfor each entity and each relation, in the joint modeling of entities and\nrelations as well as their contexts, by employing two attentive graph\nconvolutional networks, a gate strategy, and translation operations. This\neffectively helps limit the impacts of a KG update in certain regions, not in\nthe entire graph, so that DKGE can rapidly acquire the updated KG embedding by\na proposed online learning algorithm. Furthermore, DKGE can also learn KG\nembedding from scratch. Experiments on the tasks of link prediction and\nquestion answering in a dynamic environment demonstrate the effectiveness and\nefficiency of DKGE.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 13:12:59 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Wu", "Tianxing", ""], ["Khan", "Arijit", ""], ["Gao", "Huan", ""], ["Li", "Cheng", ""]]}, {"id": "1910.06710", "submitter": "Tiffany Callahan", "authors": "Tiffany J. Callahan (1), Harrison Pielke-Lombardo (1), Ignacio J.\n  Tripodi (1 and 2), and Lawrence E. Hunter (1) ((1) Computational Bioscience\n  Program, Department of Pharmacology, University of Colorado Denver Anschutz\n  Medical Campus, (2) Computer Science, University of Colorado Boulder)", "title": "Knowledge-based Biomedical Data Science 2019", "comments": "Manuscript 43 pages with 3 tables; Supplemental material 43 pages\n  with 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge-based biomedical data science (KBDS) involves the design and\nimplementation of computer systems that act as if they knew about biomedicine.\nSuch systems depend on formally represented knowledge in computer systems,\noften in the form of knowledge graphs. Here we survey the progress in the last\nyear in systems that use formally represented knowledge to address data science\nproblems in both clinical and biological domains, as well as on approaches for\ncreating knowledge graphs. Major themes include the relationships between\nknowledge graphs and machine learning, the use of natural language processing,\nand the expansion of knowledge-based approaches to novel domains, such as\nChinese Traditional Medicine and biodiversity.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 17:28:16 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Callahan", "Tiffany J.", "", "1 and 2"], ["Pielke-Lombardo", "Harrison", "", "1 and 2"], ["Tripodi", "Ignacio J.", "", "1 and 2"], ["Hunter", "Lawrence E.", ""]]}, {"id": "1910.06718", "submitter": "Rina Panigrahy", "authors": "Rina Panigrahy", "title": "How does the Mind store Information?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How we store information in our mind has been a major intriguing open\nquestion. We approach this question not from a physiological standpoint as to\nhow information is physically stored in the brain, but from a conceptual and\nalgorithm standpoint as to the right data structures to be used to organize and\nindex information. Here we propose a memory architecture directly based on the\nrecursive sketching ideas from the paper \"Recursive Sketches for Modular Deep\nNetworks\", ICML 2019 (arXiv:1905.12730), to store information in memory as\nconcise sketches. We also give a high level, informal exposition of the\nrecursive sketching idea from the paper that makes use of subspace embeddings\nto capture deep network computations into a concise sketch. These sketches form\nan implicit knowledge graph that can be used to find related information via\nsketches from the past while processing an event.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 04:07:16 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Panigrahy", "Rina", ""]]}, {"id": "1910.06764", "submitter": "Emilio Parisotto", "authors": "Emilio Parisotto, H. Francis Song, Jack W. Rae, Razvan Pascanu, Caglar\n  Gulcehre, Siddhant M. Jayakumar, Max Jaderberg, Raphael Lopez Kaufman, Aidan\n  Clark, Seb Noury, Matthew M. Botvinick, Nicolas Heess, Raia Hadsell", "title": "Stabilizing Transformers for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owing to their ability to both effectively integrate information over long\ntime horizons and scale to massive amounts of data, self-attention\narchitectures have recently shown breakthrough success in natural language\nprocessing (NLP), achieving state-of-the-art results in domains such as\nlanguage modeling and machine translation. Harnessing the transformer's ability\nto process long time horizons of information could provide a similar\nperformance boost in partially observable reinforcement learning (RL) domains,\nbut the large-scale transformers used in NLP have yet to be successfully\napplied to the RL setting. In this work we demonstrate that the standard\ntransformer architecture is difficult to optimize, which was previously\nobserved in the supervised learning setting but becomes especially pronounced\nwith RL objectives. We propose architectural modifications that substantially\nimprove the stability and learning speed of the original Transformer and XL\nvariant. The proposed architecture, the Gated Transformer-XL (GTrXL), surpasses\nLSTMs on challenging memory environments and achieves state-of-the-art results\non the multi-task DMLab-30 benchmark suite, exceeding the performance of an\nexternal memory architecture. We show that the GTrXL, trained using the same\nlosses, has stability and performance that consistently matches or exceeds a\ncompetitive LSTM baseline, including on more reactive tasks where memory is\nless critical. GTrXL offers an easy-to-train, simple-to-implement but\nsubstantially more expressive architectural alternative to the standard\nmulti-layer LSTM ubiquitously used for RL agents in partially observable\nenvironments.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 20:02:15 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Parisotto", "Emilio", ""], ["Song", "H. Francis", ""], ["Rae", "Jack W.", ""], ["Pascanu", "Razvan", ""], ["Gulcehre", "Caglar", ""], ["Jayakumar", "Siddhant M.", ""], ["Jaderberg", "Max", ""], ["Kaufman", "Raphael Lopez", ""], ["Clark", "Aidan", ""], ["Noury", "Seb", ""], ["Botvinick", "Matthew M.", ""], ["Heess", "Nicolas", ""], ["Hadsell", "Raia", ""]]}, {"id": "1910.06772", "submitter": "Jonathan Richens", "authors": "Jonathan G. Richens, Ciaran M. Lee, Saurabh Johri", "title": "Counterfactual diagnosis", "comments": "Restructured and new subsections. Improved figures. Introduction\n  rewritten", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning promises to revolutionize clinical decision making and\ndiagnosis. In medical diagnosis a doctor aims to explain a patient's symptoms\nby determining the diseases \\emph{causing} them. However, existing diagnostic\nalgorithms are purely associative, identifying diseases that are strongly\ncorrelated with a patients symptoms and medical history. We show that this\ninability to disentangle correlation from causation can result in sub-optimal\nor dangerous diagnoses. To overcome this, we reformulate diagnosis as a\ncounterfactual inference task and derive new counterfactual diagnostic\nalgorithms. We show that this approach is closer to the diagnostic reasoning of\nclinicians and significantly improves the accuracy and safety of the resulting\ndiagnoses. We compare our counterfactual algorithm to the standard Bayesian\ndiagnostic algorithm and a cohort of 44 doctors using a test set of clinical\nvignettes. While the Bayesian algorithm achieves an accuracy comparable to the\naverage doctor, placing in the top 48% of doctors in our cohort, our\ncounterfactual algorithm places in the top 25% of doctors, achieving expert\nclinical accuracy. This improvement is achieved simply by changing how we query\nour model, without requiring any additional model improvements. Our results\nshow that counterfactual reasoning is a vital missing ingredient for applying\nmachine learning to medical diagnosis.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 14:07:43 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 23:55:42 GMT"}, {"version": "v3", "created": "Fri, 13 Mar 2020 18:14:43 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Richens", "Jonathan G.", ""], ["Lee", "Ciaran M.", ""], ["Johri", "Saurabh", ""]]}, {"id": "1910.06862", "submitter": "Lars Buesing", "authors": "Lars Buesing, Nicolas Heess, Theophane Weber", "title": "Approximate Inference in Discrete Distributions with Monte Carlo Tree\n  Search and Value Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A plethora of problems in AI, engineering and the sciences are naturally\nformalized as inference in discrete probabilistic models. Exact inference is\noften prohibitively expensive, as it may require evaluating the (unnormalized)\ntarget density on its entire domain. Here we consider the setting where only a\nlimited budget of calls to the unnormalized density oracle is available,\nraising the challenge of where in the domain to allocate these function calls\nin order to construct a good approximate solution. We formulate this problem as\nan instance of sequential decision-making under uncertainty and leverage\nmethods from reinforcement learning for probabilistic inference with budget\nconstraints. In particular, we propose the TreeSample algorithm, an adaptation\nof Monte Carlo Tree Search to approximate inference. This algorithm caches all\nprevious queries to the density oracle in an explicit search tree, and\ndynamically allocates new queries based on a \"best-first\" heuristic for\nexploration, using existing upper confidence bound methods. Our non-parametric\ninference method can be effectively combined with neural networks that compile\napproximate conditionals of the target, which are then used to guide the\ninference search and enable generalization across multiple target\ndistributions. We show empirically that TreeSample outperforms standard\napproximate inference methods on synthetic factor graphs.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 15:24:41 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Buesing", "Lars", ""], ["Heess", "Nicolas", ""], ["Weber", "Theophane", ""]]}, {"id": "1910.06864", "submitter": "Yuzhe Ou", "authors": "Xujiang Zhao, Yuzhe Ou, Lance Kaplan, Feng Chen, Jin-Hee Cho", "title": "Quantifying Classification Uncertainty using Regularized Evidential\n  Neural Networks", "comments": "Presented at AAAI FSS-19: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional deep neural nets (NNs) have shown the state-of-the-art\nperformance in the task of classification in various applications. However, NNs\nhave not considered any types of uncertainty associated with the class\nprobabilities to minimize risk due to misclassification under uncertainty in\nreal life. Unlike Bayesian neural nets indirectly infering uncertainty through\nweight uncertainties, evidential neural networks (ENNs) have been recently\nproposed to support explicit modeling of the uncertainty of class\nprobabilities. It treats predictions of an NN as subjective opinions and learns\nthe function by collecting the evidence leading to these opinions by a\ndeterministic NN from data. However, an ENN is trained as a black box without\nexplicitly considering different types of inherent data uncertainty, such as\nvacuity (uncertainty due to a lack of evidence) or dissonance (uncertainty due\nto conflicting evidence). This paper presents a new approach, called a {\\em\nregularized ENN}, that learns an ENN based on regularizations related to\ndifferent characteristics of inherent data uncertainty. Via the experiments\nwith both synthetic and real-world datasets, we demonstrate that the proposed\nregularized ENN can better learn of an ENN modeling different types of\nuncertainty in the class probabilities for classification tasks.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 15:26:20 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Zhao", "Xujiang", ""], ["Ou", "Yuzhe", ""], ["Kaplan", "Lance", ""], ["Chen", "Feng", ""], ["Cho", "Jin-Hee", ""]]}, {"id": "1910.06902", "submitter": "Kumar Sankar Ray", "authors": "Sandip Paul, Kumar Sankar Ray, Diganta Saha", "title": "A Unified Framework for Nonmonotonic Reasoning with Vagueness and\n  Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An interval-valued fuzzy answer set programming paradigm is proposed for\nnonmonotonic reasoning with vague and uncertain information. The set of\nsub-intervals of $[0,1]$ is considered as truth-space. The intervals are\nordered using preorder-based truth and knowledge ordering. The preorder based\nordering is an enhanced version of bilattice-based ordering. The system can\nrepresent and reason with prioritized rules, rules with exceptions. An\niterative method for answer set computation is proposed. The sufficient\nconditions for termination of iterations are identified for a class of logic\nprograms using the notion of difference equations.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 10:18:40 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 08:58:49 GMT"}, {"version": "v3", "created": "Fri, 3 Jan 2020 08:04:05 GMT"}, {"version": "v4", "created": "Wed, 5 Aug 2020 12:11:43 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Paul", "Sandip", ""], ["Ray", "Kumar Sankar", ""], ["Saha", "Diganta", ""]]}, {"id": "1910.06907", "submitter": "Utku Kose", "authors": "Utku Kose", "title": "Techniques for Adversarial Examples Threatening the Safety of Artificial\n  Intelligence Based Systems", "comments": "International Science and Innovation Congress 2019, pp. 643-655, 13\n  pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Artificial intelligence is known as the most effective technological field\nfor rapid developments shaping the future of the world. Even today, it is\npossible to see intense use of intelligence systems in all fields of the life.\nAlthough advantages of the Artificial Intelligence are widely observed, there\nis also a dark side employing efforts to design hacking oriented techniques\nagainst Artificial Intelligence. Thanks to such techniques, it is possible to\ntrick intelligent systems causing directed results for unsuccessful outputs.\nThat is critical for also cyber wars of the future as it is predicted that the\nwars will be done unmanned, autonomous intelligent systems. Moving from the\nexplanations, objective of this study is to provide information regarding\nadversarial examples threatening the Artificial Intelligence and focus on\ndetails of some techniques, which are used for creating adversarial examples.\nAdversarial examples are known as training data, which can trick a Machine\nLearning technique to learn incorrectly about the target problem and cause an\nunsuccessful or maliciously directed intelligent system at the end. The study\nenables the readers to learn enough about details of recent techniques for\ncreating adversarial examples.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 21:56:59 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Kose", "Utku", ""]]}, {"id": "1910.06985", "submitter": "Katja Ried", "authors": "Katja Ried and Benjamin Eva and Thomas M\\\"uller and Hans J. Briegel", "title": "How a minimal learning agent can infer the existence of unobserved\n  variables in a complex environment", "comments": "28 pages plus references, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to a mainstream position in contemporary cognitive science and\nphilosophy, the use of abstract compositional concepts is both a necessary and\na sufficient condition for the presence of genuine thought. In this article, we\nshow how the ability to develop and utilise abstract conceptual structures can\nbe achieved by a particular kind of learning agents. More specifically, we\nprovide and motivate a concrete operational definition of what it means for\nthese agents to be in possession of abstract concepts, before presenting an\nexplicit example of a minimal architecture that supports this capability. We\nthen proceed to demonstrate how the existence of abstract conceptual structures\ncan be operationally useful in the process of employing previously acquired\nknowledge in the face of new experiences, thereby vindicating the natural\nconjecture that the cognitive functions of abstraction and generalisation are\nclosely related.\n  Keywords: concept formation, projective simulation, reinforcement learning,\ntransparent artificial intelligence, theory formation, explainable artificial\nintelligence (XAI)\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 18:08:08 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Ried", "Katja", ""], ["Eva", "Benjamin", ""], ["M\u00fcller", "Thomas", ""], ["Briegel", "Hans J.", ""]]}, {"id": "1910.06988", "submitter": "Rogerio Bonatti", "authors": "Rogerio Bonatti and Wenshan Wang and Cherie Ho and Aayush Ahuja and\n  Mirko Gschwindt and Efe Camci and Erdal Kayacan and Sanjiban Choudhury and\n  Sebastian Scherer", "title": "Autonomous Aerial Cinematography In Unstructured Environments With\n  Learned Artistic Decision-Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aerial cinematography is revolutionizing industries that require live and\ndynamic camera viewpoints such as entertainment, sports, and security. However,\nsafely piloting a drone while filming a moving target in the presence of\nobstacles is immensely taxing, often requiring multiple expert human operators.\nHence, there is demand for an autonomous cinematographer that can reason about\nboth geometry and scene context in real-time. Existing approaches do not\naddress all aspects of this problem; they either require high-precision\nmotion-capture systems or GPS tags to localize targets, rely on prior maps of\nthe environment, plan for short time horizons, or only follow artistic\nguidelines specified before flight.\n  In this work, we address the problem in its entirety and propose a complete\nsystem for real-time aerial cinematography that for the first time combines:\n(1) vision-based target estimation; (2) 3D signed-distance mapping for\nocclusion estimation; (3) efficient trajectory optimization for long\ntime-horizon camera motion; and (4) learning-based artistic shot selection. We\nextensively evaluate our system both in simulation and in field experiments by\nfilming dynamic targets moving through unstructured environments. Our results\nindicate that our system can operate reliably in the real world without\nrestrictive assumptions. We also provide in-depth analysis and discussions for\neach module, with the hope that our design tradeoffs can generalize to other\nrelated applications. Videos of the complete system can be found at:\nhttps://youtu.be/ookhHnqmlaU.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 18:17:58 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Bonatti", "Rogerio", ""], ["Wang", "Wenshan", ""], ["Ho", "Cherie", ""], ["Ahuja", "Aayush", ""], ["Gschwindt", "Mirko", ""], ["Camci", "Efe", ""], ["Kayacan", "Erdal", ""], ["Choudhury", "Sanjiban", ""], ["Scherer", "Sebastian", ""]]}, {"id": "1910.07004", "submitter": "Tomer Libal", "authors": "Tomer Libal and Alexander Steen", "title": "The NAI Suite -- Drafting and Reasoning over Legal Texts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A prototype for automated reasoning over legal texts, called NAI, is\npresented. As an input, NAI accepts formalized logical representations of such\nlegal texts that can be created and curated using an integrated annotation\ninterface. The prototype supports automated reasoning over the given text\nrepresentation and multiple quality assurance procedures. The pragmatics of the\nNAI suite as well its feasibility in practical applications is studied on a\nfragment of the Smoking Prohibition (Children in Motor Vehicles) (Scotland) Act\n2016 of the Scottish Parliament.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 18:57:11 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Libal", "Tomer", ""], ["Steen", "Alexander", ""]]}, {"id": "1910.07072", "submitter": "Chen-Yu Wei", "authors": "Chen-Yu Wei, Mehdi Jafarnia-Jahromi, Haipeng Luo, Hiteshi Sharma,\n  Rahul Jain", "title": "Model-free Reinforcement Learning in Infinite-horizon Average-reward\n  Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free reinforcement learning is known to be memory and computation\nefficient and more amendable to large scale problems. In this paper, two\nmodel-free algorithms are introduced for learning infinite-horizon\naverage-reward Markov Decision Processes (MDPs). The first algorithm reduces\nthe problem to the discounted-reward version and achieves\n$\\mathcal{O}(T^{2/3})$ regret after $T$ steps, under the minimal assumption of\nweakly communicating MDPs. To our knowledge, this is the first model-free\nalgorithm for general MDPs in this setting. The second algorithm makes use of\nrecent advances in adaptive algorithms for adversarial multi-armed bandits and\nimproves the regret to $\\mathcal{O}(\\sqrt{T})$, albeit with a stronger ergodic\nassumption. This result significantly improves over the $\\mathcal{O}(T^{3/4})$\nregret achieved by the only existing model-free algorithm by Abbasi-Yadkori et\nal. (2019a) for ergodic MDPs in the infinite-horizon average-reward setting.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 22:01:31 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 15:23:05 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Wei", "Chen-Yu", ""], ["Jafarnia-Jahromi", "Mehdi", ""], ["Luo", "Haipeng", ""], ["Sharma", "Hiteshi", ""], ["Jain", "Rahul", ""]]}, {"id": "1910.07089", "submitter": "Subbarao Kambhampati", "authors": "Subbarao Kambhampati", "title": "Challenges of Human-Aware AI Systems", "comments": "To appear in AI Magazine (Written version of AAAI 2018 Presidential\n  Address. Video and slides at http://bit.ly/2tHyzAh )", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From its inception, AI has had a rather ambivalent relationship to\nhumans---swinging between their augmentation and replacement. Now, as AI\ntechnologies enter our everyday lives at an ever increasing pace, there is a\ngreater need for AI systems to work synergistically with humans. To do this\neffectively, AI systems must pay more attention to aspects of intelligence that\nhelped humans work with each other---including social intelligence. I will\ndiscuss the research challenges in designing such human-aware AI systems,\nincluding modeling the mental states of humans in the loop, recognizing their\ndesires and intentions, providing proactive support, exhibiting explicable\nbehavior, giving cogent explanations on demand, and engendering trust. I will\nsurvey the progress made so far on these challenges, and highlight some\npromising directions. I will also touch on the additional ethical quandaries\nthat such systems pose. I will end by arguing that the quest for human-aware AI\nsystems broadens the scope of AI enterprise, necessitates and facilitates true\ninter-disciplinary collaborations, and can go a long way towards increasing\npublic acceptance of AI technologies.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 22:34:50 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Kambhampati", "Subbarao", ""]]}, {"id": "1910.07093", "submitter": "Jean Oh", "authors": "Jean Oh, Martial Hebert, Hae-Gon Jeon, Xavier Perez, Chia Dai, Yeeho\n  Song", "title": "Explainable Semantic Mapping for First Responders", "comments": "Artificial Intelligence for Humanitarian Assistance and Disaster\n  Response Workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key challenges in the semantic mapping problem in postdisaster\nenvironments is how to analyze a large amount of data efficiently with minimal\nsupervision. To address this challenge, we propose a deep learning-based\nsemantic mapping tool consisting of three main ideas. First, we develop a\nfrugal semantic segmentation algorithm that uses only a small amount of labeled\ndata. Next, we investigate on the problem of learning to detect a new class of\nobject using just a few training examples. Finally, we develop an explainable\ncost map learning algorithm that can be quickly trained to generate\ntraversability cost maps using only raw sensor data such as aerial-view\nimagery. This paper presents an overview of the proposed idea and the lessons\nlearned.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 22:58:19 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Oh", "Jean", ""], ["Hebert", "Martial", ""], ["Jeon", "Hae-Gon", ""], ["Perez", "Xavier", ""], ["Dai", "Chia", ""], ["Song", "Yeeho", ""]]}, {"id": "1910.07113", "submitter": "Matthias Plappert", "authors": "OpenAI, Ilge Akkaya, Marcin Andrychowicz, Maciek Chociej, Mateusz\n  Litwin, Bob McGrew, Arthur Petron, Alex Paino, Matthias Plappert, Glenn\n  Powell, Raphael Ribas, Jonas Schneider, Nikolas Tezak, Jerry Tworek, Peter\n  Welinder, Lilian Weng, Qiming Yuan, Wojciech Zaremba, Lei Zhang", "title": "Solving Rubik's Cube with a Robot Hand", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that models trained only in simulation can be used to solve a\nmanipulation problem of unprecedented complexity on a real robot. This is made\npossible by two key components: a novel algorithm, which we call automatic\ndomain randomization (ADR) and a robot platform built for machine learning. ADR\nautomatically generates a distribution over randomized environments of\never-increasing difficulty. Control policies and vision state estimators\ntrained with ADR exhibit vastly improved sim2real transfer. For control\npolicies, memory-augmented models trained on an ADR-generated distribution of\nenvironments show clear signs of emergent meta-learning at test time. The\ncombination of ADR with our custom robot platform allows us to solve a Rubik's\ncube with a humanoid robot hand, which involves both control and state\nestimation problems. Videos summarizing our results are available:\nhttps://openai.com/blog/solving-rubiks-cube/\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 00:59:05 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["OpenAI", "", ""], ["Akkaya", "Ilge", ""], ["Andrychowicz", "Marcin", ""], ["Chociej", "Maciek", ""], ["Litwin", "Mateusz", ""], ["McGrew", "Bob", ""], ["Petron", "Arthur", ""], ["Paino", "Alex", ""], ["Plappert", "Matthias", ""], ["Powell", "Glenn", ""], ["Ribas", "Raphael", ""], ["Schneider", "Jonas", ""], ["Tezak", "Nikolas", ""], ["Tworek", "Jerry", ""], ["Welinder", "Peter", ""], ["Weng", "Lilian", ""], ["Yuan", "Qiming", ""], ["Zaremba", "Wojciech", ""], ["Zhang", "Lei", ""]]}, {"id": "1910.07117", "submitter": "Tianxing He", "authors": "Tianxing He and Jun Liu and Kyunghyun Cho and Myle Ott and Bing Liu\n  and James Glass and Fuchun Peng", "title": "Analyzing the Forgetting Problem in the Pretrain-Finetuning of Dialogue\n  Response Models", "comments": null, "journal-ref": "EACL 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study how the finetuning stage in the pretrain-finetune\nframework changes the behavior of a pretrained neural language generator. We\nfocus on the transformer encoder-decoder model for the open-domain dialogue\nresponse generation task. Our major finding is that after standard finetuning,\nthe model forgets some of the important language generation skills acquired\nduring large-scale pretraining. We demonstrate the forgetting phenomenon\nthrough a set of detailed behavior analysis from the perspectives of knowledge\ntransfer, context sensitivity, and function space projection. As a preliminary\nattempt to alleviate the forgetting problem, we propose an intuitive finetuning\nstrategy named \"mix-review\". We find that mix-review effectively regularizes\nthe finetuning process, and the forgetting problem is alleviated to some\nextent. Finally, we discuss interesting behavior of the resulting dialogue\nmodel and its implications.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 01:10:10 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 23:38:37 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 19:43:05 GMT"}, {"version": "v4", "created": "Thu, 23 Apr 2020 17:56:28 GMT"}, {"version": "v5", "created": "Sat, 16 Jan 2021 19:14:41 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["He", "Tianxing", ""], ["Liu", "Jun", ""], ["Cho", "Kyunghyun", ""], ["Ott", "Myle", ""], ["Liu", "Bing", ""], ["Glass", "James", ""], ["Peng", "Fuchun", ""]]}, {"id": "1910.07150", "submitter": "Jiewen Wu", "authors": "Jiewen Wu, Luis Fernando D'Haro, Nancy F. Chen, Pavitra Krishnaswamy,\n  Rafael E. Banchs", "title": "Joint Learning of Word and Label Embeddings for Sequence Labelling in\n  Spoken Language Understanding", "comments": "Accepted for publication at ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an architecture to jointly learn word and label embeddings for\nslot filling in spoken language understanding. The proposed approach encodes\nlabels using a combination of word embeddings and straightforward word-label\nassociation from the training data. Compared to the state-of-the-art methods,\nour approach does not require label embeddings as part of the input and\ntherefore lends itself nicely to a wide range of model architectures. In\naddition, our architecture computes contextual distances between words and\nlabels to avoid adding contextual windows, thus reducing memory footprint. We\nvalidate the approach on established spoken dialogue datasets and show that it\ncan achieve state-of-the-art performance with much fewer trainable parameters.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 03:28:14 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Wu", "Jiewen", ""], ["D'Haro", "Luis Fernando", ""], ["Chen", "Nancy F.", ""], ["Krishnaswamy", "Pavitra", ""], ["Banchs", "Rafael E.", ""]]}, {"id": "1910.07151", "submitter": "Peng Yang", "authors": "Peng Yang and Qi Yang and Ke Tang and Xin Yao", "title": "Parallel Exploration via Negatively Correlated Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective exploration is a key to successful search. The recently proposed\nNegatively Correlated Search (NCS) tries to achieve this by parallel\nexploration, where a set of search processes are driven to be negatively\ncorrelated so that different promising areas of the search space can be visited\nsimultaneously. Various applications have verified the advantages of such novel\nsearch behaviors. Nevertheless, the mathematical understandings are still\nlacking as the previous NCS was mostly devised by intuition. In this paper, a\nmore principled NCS is presented, explaining that the parallel exploration is\nequivalent to the explicit maximization of both the population diversity and\nthe population solution qualities, and can be optimally obtained by partially\ngradient descending both models with respect to each search process. For\nempirical assessments, the reinforcement learning tasks that largely demand\nexploration ability is considered. The new NCS is applied to the popular\nreinforcement learning problems, i.e., playing Atari games, to directly train a\ndeep convolution network with 1.7 million connection weights in the\nenvironments with uncertain and delayed rewards. Empirical results show that\nthe significant advantages of NCS over the compared state-of-the-art methods\ncan be highly owed to the effective parallel exploration ability.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 03:30:29 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 07:44:06 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Yang", "Peng", ""], ["Yang", "Qi", ""], ["Tang", "Ke", ""], ["Yao", "Xin", ""]]}, {"id": "1910.07162", "submitter": "Han Zhao", "authors": "Han Zhao, Amanda Coston, Tameem Adel, Geoffrey J. Gordon", "title": "Conditional Learning of Fair Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel algorithm for learning fair representations that can\nsimultaneously mitigate two notions of disparity among different demographic\nsubgroups in the classification setting. Two key components underpinning the\ndesign of our algorithm are balanced error rate and conditional alignment of\nrepresentations. We show how these two components contribute to ensuring\naccuracy parity and equalized false-positive and false-negative rates across\ngroups without impacting demographic parity. Furthermore, we also demonstrate\nboth in theory and on two real-world experiments that the proposed algorithm\nleads to a better utility-fairness trade-off on balanced datasets compared with\nexisting algorithms on learning fair representations for classification.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 04:12:50 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 18:10:34 GMT"}, {"version": "v3", "created": "Sat, 15 Feb 2020 00:10:35 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Zhao", "Han", ""], ["Coston", "Amanda", ""], ["Adel", "Tameem", ""], ["Gordon", "Geoffrey J.", ""]]}, {"id": "1910.07186", "submitter": "Yihao Feng", "authors": "Ziyang Tang, Yihao Feng, Lihong Li, Dengyong Zhou, Qiang Liu", "title": "Doubly Robust Bias Reduction in Infinite Horizon Off-Policy Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Infinite horizon off-policy policy evaluation is a highly challenging task\ndue to the excessively large variance of typical importance sampling (IS)\nestimators. Recently, Liu et al. (2018a) proposed an approach that\nsignificantly reduces the variance of infinite-horizon off-policy evaluation by\nestimating the stationary density ratio, but at the cost of introducing\npotentially high biases due to the error in density ratio estimation. In this\npaper, we develop a bias-reduced augmentation of their method, which can take\nadvantage of a learned value function to obtain higher accuracy. Our method is\ndoubly robust in that the bias vanishes when either the density ratio or the\nvalue function estimation is perfect. In general, when either of them is\naccurate, the bias can also be reduced. Both theoretical and empirical results\nshow that our method yields significant advantages over previous methods.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 06:33:17 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Tang", "Ziyang", ""], ["Feng", "Yihao", ""], ["Li", "Lihong", ""], ["Zhou", "Dengyong", ""], ["Liu", "Qiang", ""]]}, {"id": "1910.07203", "submitter": "Margaux Nattaf", "authors": "Arnaud Malapert, Margaux Nattaf (G-SCOP)", "title": "A new CP-approach for a parallel machine scheduling problem with time\n  constraints on machine qualifications", "comments": null, "journal-ref": "Integration of Constraint Programming, Artificial Intelligence,\n  and Operations Research, pp.426-442, 2019", "doi": "10.1007/978-3-030-19212-9_28", "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the scheduling of job families on parallel machines with\ntime constraints on machine qualifications. In this problem, each job belongs\nto a family and a family can only be executed on a subset of qualified\nmachines. In addition, machines can lose their qualifications during the\nschedule. Indeed, if no job of a family is scheduled on a machine during a\ngiven amount of time, the machine loses its qualification for this family. The\ngoal is to minimize the sum of job completion times, i.e. the flow time, while\nmaximizing the number of qualifications at the end of the schedule. The paper\npresents a new Constraint Programming (CP) model taking more advantages of the\nCP feature to model machine disqualifications. This model is compared with two\nexisting models: an Integer Linear Programming (ILP) model and a Constraint\nProgramming model. The experiments show that the new CP model outperforms the\nother model when the priority is given to the number of disqualifications\nobjective. Furthermore, it is competitive with the other model when the flow\ntime objective is prioritized.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 08:03:30 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Malapert", "Arnaud", "", "G-SCOP"], ["Nattaf", "Margaux", "", "G-SCOP"]]}, {"id": "1910.07207", "submitter": "Petros Christodoulou Mr", "authors": "Petros Christodoulou", "title": "Soft Actor-Critic for Discrete Action Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Soft Actor-Critic is a state-of-the-art reinforcement learning algorithm for\ncontinuous action settings that is not applicable to discrete action settings.\nMany important settings involve discrete actions, however, and so here we\nderive an alternative version of the Soft Actor-Critic algorithm that is\napplicable to discrete action settings. We then show that, even without any\nhyperparameter tuning, it is competitive with the tuned model-free\nstate-of-the-art on a selection of games from the Atari suite.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 08:11:08 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 09:17:44 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Christodoulou", "Petros", ""]]}, {"id": "1910.07265", "submitter": "Jeroen Berrevoets", "authors": "Jeroen Berrevoets, Sam Verboven, Wouter Verbeke", "title": "Optimising Individual-Treatment-Effect Using Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying causal inference models in areas such as economics, healthcare and\nmarketing receives great interest from the machine learning community. In\nparticular, estimating the individual-treatment-effect (ITE) in settings such\nas precision medicine and targeted advertising has peaked in application.\nOptimising this ITE under the strong-ignorability-assumption -- meaning all\nconfounders expressing influence on the outcome of a treatment are registered\nin the data -- is often referred to as uplift modeling (UM). While these\ntechniques have proven useful in many settings, they suffer vividly in a\ndynamic environment due to concept drift. Take for example the negative\ninfluence on a marketing campaign when a competitor product is released. To\ncounter this, we propose the uplifted contextual multi-armed bandit (U-CMAB), a\nnovel approach to optimise the ITE by drawing upon bandit literature.\nExperiments on real and simulated data indicate that our proposed approach\ncompares favourably against the state-of-the-art. All our code can be found\nonline at https://github.com/vub-dl/u-cmab.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 10:33:31 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Berrevoets", "Jeroen", ""], ["Verboven", "Sam", ""], ["Verbeke", "Wouter", ""]]}, {"id": "1910.07278", "submitter": "Jorge Fandinno", "authors": "Emmanuelle-Anna Dietz Saldanha and Jorge Fandinno", "title": "On the Relation between Weak Completion Semantics and Answer Set\n  Semantics", "comments": "12th Workshop on Answer Set Programming and Other Computing\n  Paradigms, Philadelphia, PA (USA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Weak Completion Semantics (WCS) is a computational cognitive theory that\nhas shown to be successful in modeling episodes of human reasoning. As the WCS\nis a recently developed logic programming approach, this paper investigates the\ncorrespondence of the WCS with respect to the well-established Answer Set\nSemantics (ASP). The underlying three-valued logic of both semantics is\ndifferent and their models are evaluated with respect to different program\ntransformations. We first illustrate these differences by the formal\nrepresentation of some examples of a well-known psychological experiment, the\nsuppression task. After that, we will provide a translation from logic programs\nunderstood under the WCS into logic programs understood under the ASP. In\nparticular, we will show that logic programs under the WCS can be represented\nas logic programs under the ASP by means of a definition completion, where all\ndefined atoms in a program must be false when their definitions are false.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 10:54:46 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Saldanha", "Emmanuelle-Anna Dietz", ""], ["Fandinno", "Jorge", ""]]}, {"id": "1910.07294", "submitter": "Ozsel Kilinc", "authors": "Ozsel Kilinc, Yang Hu, Giovanni Montana", "title": "Reinforcement Learning for Robotic Manipulation using Simulated\n  Locomotion Demonstrations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning robotic manipulation through reinforcement learning (RL) using only\nsparse reward signals is still considered a largely unsolved problem.\nLeveraging human demonstrations can make the learning process more sample\nefficient, but obtaining high-quality demonstrations can be costly or\nunfeasible. In this paper we propose a novel approach that introduces\nobject-level demonstrations, i.e. examples of where the objects should be at\nany state. These demonstrations are generated automatically through RL hence\nrequire no expert knowledge. We observe that, during a manipulation task, an\nobject is moved from an initial to a final position. When seen from the point\nof view of the object being manipulated, this induces a locomotion task that\ncan be decoupled from the manipulation task and learnt through a\nphysically-realistic simulator. The resulting object-level trajectories, called\nsimulated locomotion demonstrations (SLDs), are then leveraged to define\nauxiliary rewards that are used to learn the manipulation policy. The proposed\napproach has been evaluated on 13 tasks of increasing complexity, and has been\ndemonstrated to achieve higher success rate and faster learning rates compared\nto alternative algorithms. SLDs are especially beneficial for tasks like\nmulti-object stacking and non-rigid object manipulation.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 11:38:43 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 10:19:13 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 21:58:30 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Kilinc", "Ozsel", ""], ["Hu", "Yang", ""], ["Montana", "Giovanni", ""]]}, {"id": "1910.07323", "submitter": "Adrien Dufraux", "authors": "Adrien Dufraux, Emmanuel Vincent, Awni Hannun, Armelle Brun, Matthijs\n  Douze", "title": "Lead2Gold: Towards exploiting the full potential of noisy transcriptions\n  for speech recognition", "comments": "8 pages, 4 tables, Accepted for publication in ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transcriptions used to train an Automatic Speech Recognition (ASR) system\nmay contain errors. Usually, either a quality control stage discards\ntranscriptions with too many errors, or the noisy transcriptions are used as\nis. We introduce Lead2Gold, a method to train an ASR system that exploits the\nfull potential of noisy transcriptions. Based on a noise model of transcription\nerrors, Lead2Gold searches for better transcriptions of the training data with\na beam search that takes this noise model into account. The beam search is\ndifferentiable and does not require a forced alignment step, thus the whole\nsystem is trained end-to-end. Lead2Gold can be viewed as a new loss function\nthat can be used on top of any sequence-to-sequence deep neural network. We\nconduct proof-of-concept experiments on noisy transcriptions generated from\nletter corruptions with different noise levels. We show that Lead2Gold obtains\na better ASR accuracy than a competitive baseline which does not account for\nthe (artificially-introduced) transcription noise.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 12:55:34 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Dufraux", "Adrien", ""], ["Vincent", "Emmanuel", ""], ["Hannun", "Awni", ""], ["Brun", "Armelle", ""], ["Douze", "Matthijs", ""]]}, {"id": "1910.07474", "submitter": "Robert Walecki Mr", "authors": "Robert Walecki, Kostis Gourgoulias, Adam Baker, Chris Hart, Chris\n  Lucas, Max Zwiessele, Albert Buchard, Maria Lomeli, Yura Perov, Saurabh Johri", "title": "Universal Marginaliser for Deep Amortised Inference for Probabilistic\n  Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic programming languages (PPLs) are powerful modelling tools which\nallow to formalise our knowledge about the world and reason about its inherent\nuncertainty. Inference methods used in PPL can be computationally costly due to\nsignificant time burden and/or storage requirements; or they can lack\ntheoretical guarantees of convergence and accuracy when applied to large scale\ngraphical models. To this end, we present the Universal Marginaliser (UM), a\nnovel method for amortised inference, in PPL. We show how combining samples\ndrawn from the original probabilistic program prior with an appropriate\naugmentation method allows us to train one neural network to approximate any of\nthe corresponding conditional marginal distributions, with any separation into\nlatent and observed variables, and thus amortise the cost of inference.\nFinally, we benchmark the method on multiple probabilistic programs, in Pyro,\nwith different model structure.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 17:01:02 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Walecki", "Robert", ""], ["Gourgoulias", "Kostis", ""], ["Baker", "Adam", ""], ["Hart", "Chris", ""], ["Lucas", "Chris", ""], ["Zwiessele", "Max", ""], ["Buchard", "Albert", ""], ["Lomeli", "Maria", ""], ["Perov", "Yura", ""], ["Johri", "Saurabh", ""]]}, {"id": "1910.07475", "submitter": "Patrick Lewis", "authors": "Patrick Lewis, Barlas O\\u{g}uz, Ruty Rinott, Sebastian Riedel, Holger\n  Schwenk", "title": "MLQA: Evaluating Cross-lingual Extractive Question Answering", "comments": "To appear in ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering (QA) models have shown rapid progress enabled by the\navailability of large, high-quality benchmark datasets. Such annotated datasets\nare difficult and costly to collect, and rarely exist in languages other than\nEnglish, making training QA systems in other languages challenging. An\nalternative to building large monolingual training datasets is to develop\ncross-lingual systems which can transfer to a target language without requiring\ntraining data in that language. In order to develop such systems, it is crucial\nto invest in high quality multilingual evaluation benchmarks to measure\nprogress. We present MLQA, a multi-way aligned extractive QA evaluation\nbenchmark intended to spur research in this area. MLQA contains QA instances in\n7 languages, namely English, Arabic, German, Spanish, Hindi, Vietnamese and\nSimplified Chinese. It consists of over 12K QA instances in English and 5K in\neach other language, with each QA instance being parallel between 4 languages\non average. MLQA is built using a novel alignment context strategy on Wikipedia\narticles, and serves as a cross-lingual extension to existing extractive QA\ndatasets. We evaluate current state-of-the-art cross-lingual representations on\nMLQA, and also provide machine-translation-based baselines. In all cases,\ntransfer results are shown to be significantly behind training-language\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 17:05:21 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 05:46:56 GMT"}, {"version": "v3", "created": "Sun, 3 May 2020 10:13:02 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Lewis", "Patrick", ""], ["O\u011fuz", "Barlas", ""], ["Rinott", "Ruty", ""], ["Riedel", "Sebastian", ""], ["Schwenk", "Holger", ""]]}, {"id": "1910.07492", "submitter": "Rishad Shafik", "authors": "Sergey Mileiko, Thanasin Bunnam, Fei Xia, Rishad Shafik, Alex\n  Yakovlev, Shidhartha Das", "title": "Neural Network Design for Energy-Autonomous AI Applications using\n  Temporal Encoding", "comments": null, "journal-ref": null, "doi": "10.1098/rsta.2019.0166", "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Networks (NNs) are steering a new generation of artificial\nintelligence (AI) applications at the micro-edge. Examples include wireless\nsensors, wearables and cybernetic systems that collect data and process them to\nsupport real-world decisions and controls. For energy autonomy, these\napplications are typically powered by energy harvesters. As harvesters and\nother power sources which provide energy autonomy inevitably have power\nvariations, the circuits need to robustly operate over a dynamic power\nenvelope. In other words, the NN hardware needs to be able to function\ncorrectly under unpredictable and variable supply voltages.\n  In this paper, we propose a novel NN design approach using the principle of\npulse width modulation (PWM). PWM signals represent information with their duty\ncycle values which may be made independent of the voltages and frequencies of\nthe carrier signals. We design a PWM-based perceptron which can serve as the\nfundamental building block for NNs, by using an entirely new method of\nrealising arithmetic in the PWM domain. We analyse the proposed approach\nbuilding from a 3x3 perceptron circuit to a complex multi-layer NN. Using\nhandwritten character recognition as an exemplar of AI applications, we\ndemonstrate the power elasticity, resilience and efficiency of the proposed NN\ndesign in the presence of functional and parametric variations including large\nvoltage variations in the power supply.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 16:34:50 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Mileiko", "Sergey", ""], ["Bunnam", "Thanasin", ""], ["Xia", "Fei", ""], ["Shafik", "Rishad", ""], ["Yakovlev", "Alex", ""], ["Das", "Shidhartha", ""]]}, {"id": "1910.07497", "submitter": "Pritam Sarkar", "authors": "Pritam Sarkar, Ali Etemad", "title": "Self-supervised Learning for ECG-based Emotion Recognition", "comments": "Accepted, 45th IEEE International Conference on Acoustics, Speech,\n  and Signal Processing", "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9053985", "report-no": null, "categories": "cs.LG cs.AI eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present an electrocardiogram (ECG) -based emotion recognition system using\nself-supervised learning. Our proposed architecture consists of two main\nnetworks, a signal transformation recognition network and an emotion\nrecognition network. First, unlabelled data are used to successfully train the\nformer network to detect specific pre-determined signal transformations in the\nself-supervised learning step. Next, the weights of the convolutional layers of\nthis network are transferred to the emotion recognition network, and two dense\nlayers are trained in order to classify arousal and valence scores. We show\nthat our self-supervised approach helps the model learn the ECG feature\nmanifold required for emotion recognition, performing equal or better than the\nfully-supervised version of the model. Our proposed method outperforms the\nstate-of-the-art in ECG-based emotion recognition with two publicly available\ndatasets, SWELL and AMIGOS. Further analysis highlights the advantage of our\nself-supervised approach in requiring significantly less data to achieve\nacceptable results.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 15:19:08 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 02:50:53 GMT"}, {"version": "v3", "created": "Sun, 5 Apr 2020 03:30:45 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Sarkar", "Pritam", ""], ["Etemad", "Ali", ""]]}, {"id": "1910.07563", "submitter": "Alun Preece", "authors": "Alun Preece, Dave Braines, Federico Cerutti, Tien Pham", "title": "Explainable AI for Intelligence Augmentation in Multi-Domain Operations", "comments": "Presented at AAAI FSS-19: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Central to the concept of multi-domain operations (MDO) is the utilization of\nan intelligence, surveillance, and reconnaissance (ISR) network consisting of\noverlapping systems of remote and autonomous sensors, and human intelligence,\ndistributed among multiple partners. Realising this concept requires\nadvancement in both artificial intelligence (AI) for improved distributed data\nanalytics and intelligence augmentation (IA) for improved human-machine\ncognition. The contribution of this paper is threefold: (1) we map the\ncoalition situational understanding (CSU) concept to MDO ISR requirements,\npaying particular attention to the need for assured and explainable AI to allow\nrobust human-machine decision-making where assets are distributed among\nmultiple partners; (2) we present illustrative vignettes for AI and IA in MDO\nISR, including human-machine teaming, dense urban terrain analysis, and\nenhanced asset interoperability; (3) we appraise the state-of-the-art in\nexplainable AI in relation to the vignettes with a focus on human-machine\ncollaboration to achieve more rapid and agile coalition decision-making. The\nunion of these three elements is intended to show the potential value of a CSU\napproach in the context of MDO ISR, grounded in three distinct use cases,\nhighlighting how the need for explainability in the multi-partner coalition\nsetting is key.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 18:23:49 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Preece", "Alun", ""], ["Braines", "Dave", ""], ["Cerutti", "Federico", ""], ["Pham", "Tien", ""]]}, {"id": "1910.07581", "submitter": "Mayank Agrawal", "authors": "Mayank Agrawal, Joshua C. Peterson, Thomas L. Griffiths", "title": "Scaling up Psychology via Scientific Regret Minimization: A Case Study\n  in Moral Decisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Do large datasets provide value to psychologists? Without a systematic\nmethodology for working with such datasets, there is a valid concern that\nanalyses will produce noise artifacts rather than true effects. In this paper,\nwe offer a way to enable researchers to systematically build models and\nidentify novel phenomena in large datasets. One traditional approach is to\nanalyze the residuals of models---the biggest errors they make in predicting\nthe data---to discover what might be missing from those models. However, once a\ndataset is sufficiently large, machine learning algorithms approximate the true\nunderlying function better than the data, suggesting instead that the\npredictions of these data-driven models should be used to guide model-building.\nWe call this approach \"Scientific Regret Minimization\" (SRM) as it focuses on\nminimizing errors for cases that we know should have been predictable. We\ndemonstrate this methodology on a subset of the Moral Machine dataset, a public\ncollection of roughly forty million moral decisions. Using SRM, we found that\nincorporating a set of deontological principles that capture dimensions along\nwhich groups of agents can vary (e.g. sex and age) improves a computational\nmodel of human moral judgment. Furthermore, we were able to identify and\nindependently validate three interesting moral phenomena: criminal\ndehumanization, age of responsibility, and asymmetric notions of\nresponsibility.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 19:25:06 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 00:13:23 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Agrawal", "Mayank", ""], ["Peterson", "Joshua C.", ""], ["Griffiths", "Thomas L.", ""]]}, {"id": "1910.07601", "submitter": "Yanpei Shi", "authors": "Yanpei Shi, Thomas Hain", "title": "Contextual Joint Factor Acoustic Embeddings", "comments": "Published at SLT2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding acoustic information into fixed length representations is of\ninterest for a whole range of applications in speech and audio technology. Two\nnovel unsupervised approaches to generate acoustic embeddings by modelling of\nacoustic context are proposed. The first approach is a contextual joint factor\nsynthesis encoder, where the encoder in an encoder/decoder framework is trained\nto extract joint factors from surrounding audio frames to best generate the\ntarget output. The second approach is a contextual joint factor analysis\nencoder, where the encoder is trained to analyse joint factors from the source\nsignal that correlates best with the neighbouring audio. To evaluate the\neffectiveness of our approaches compared to prior work, two tasks are conducted\n-- phone classification and speaker recognition -- and test on different TIMIT\ndata sets. Experimental results show that one of the proposed approaches\noutperforms phone classification baselines, yielding a classification accuracy\nof 74.1%. When using additional out-of-domain data for training, an additional\n3% improvements can be obtained, for both for phone classification and speaker\nrecognition tasks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 20:36:41 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 15:40:15 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Shi", "Yanpei", ""], ["Hain", "Thomas", ""]]}, {"id": "1910.07613", "submitter": "Dylan Losey", "authors": "Dylan P. Losey, Mengxi Li, Jeannette Bohg, Dorsa Sadigh", "title": "Learning from My Partner's Actions: Roles in Decentralized Robot Teams", "comments": "Conference on Robot Learning (CoRL), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When teams of robots collaborate to complete a task, communication is often\nnecessary. Like humans, robot teammates should implicitly communicate through\ntheir actions: but interpreting our partner's actions is typically difficult,\nsince a given action may have many different underlying reasons. Here we\npropose an alternate approach: instead of not being able to infer whether an\naction is due to exploration, exploitation, or communication, we define\nseparate roles for each agent. Because each role defines a distinct reason for\nacting (e.g., only exploit, only communicate), teammates now correctly\ninterpret the meaning behind their partner's actions. Our results suggest that\nleveraging and alternating roles leads to performance comparable to teams that\nexplicitly exchange messages. You can find more images and videos of our\nexperimental setups at http://ai.stanford.edu/blog/learning-from-partners/.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 21:07:39 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 21:30:17 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Losey", "Dylan P.", ""], ["Li", "Mengxi", ""], ["Bohg", "Jeannette", ""], ["Sadigh", "Dorsa", ""]]}, {"id": "1910.07615", "submitter": "Junha Roh", "authors": "Junha Roh, Chris Paxton, Andrzej Pronobis, Ali Farhadi, Dieter Fox", "title": "Conditional Driving from Natural Language Instructions", "comments": "Accepted by the 3rd Conference on Robot Learning, Osaka, Japan (CoRL\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Widespread adoption of self-driving cars will depend not only on their safety\nbut largely on their ability to interact with human users. Just like human\ndrivers, self-driving cars will be expected to understand and safely follow\nnatural-language directions that suddenly alter the pre-planned route according\nto user's preference or in presence of ambiguities, particularly in locations\nwith poor or outdated map coverage. To this end, we propose a language-grounded\ndriving agent implementing a hierarchical policy using recurrent layers and\ngated attention. The hierarchical approach enables us to reason both in terms\nof high-level language instructions describing long time horizons and\nlow-level, complex, continuous state/action spaces required for real-time\ncontrol of a self-driving car. We train our policy with conditional imitation\nlearning from realistic language data collected from human drivers and\nnavigators. Through quantitative and interactive experiments within the CARLA\nframework, we show that our model can successfully interpret language\ninstructions and follow them safely, even when generalizing to previously\nunseen environments. Code and video are available at\nhttps://sites.google.com/view/language-grounded-driving.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 21:14:08 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Roh", "Junha", ""], ["Paxton", "Chris", ""], ["Pronobis", "Andrzej", ""], ["Farhadi", "Ali", ""], ["Fox", "Dieter", ""]]}, {"id": "1910.07728", "submitter": "Shiwali Mohan", "authors": "Shiwali Mohan", "title": "Exploring the Role of Common Model of Cognition in Designing Adaptive\n  Coaching Interactions for Health Behavior Change", "comments": "Accepted for publication in the ACM Transactions on Interactive\n  Intelligent Systems - https://dl.acm.org/journal/tiis", "journal-ref": "ACM Transactions of Interactive Intelligent Syststems 11, 1,\n  Article 1 (April 2021), 30 pages", "doi": "10.1145/3375790", "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our research aims to develop intelligent collaborative agents that are\nhuman-aware - they can model, learn, and reason about their human partner's\nphysiological, cognitive, and affective states. In this paper, we study how\nadaptive coaching interactions can be designed to help people develop\nsustainable healthy behaviors. We leverage the common model of cognition - CMC\n[26] - as a framework for unifying several behavior change theories that are\nknown to be useful in human-human coaching. We motivate a set of interactive\nsystem desiderata based on the CMC-based view of behavior change. Then, we\npropose PARCoach - an interactive system that addresses the desiderata.\nPARCoach helps a trainee pick a relevant health goal, set an implementation\nintention, and track their behavior. During this process, the trainee\nidentifies a specific goal-directed behavior as well as the situational context\nin which they will perform it. PARCcoach uses this information to send\nnotifications to the trainee, reminding them of their chosen behavior and the\ncontext. We report the results from a 4-week deployment with 60 participants.\nOur results support the CMC-based view of behavior change and demonstrate that\nthe desiderata for proposed interactive system design is useful in producing\nbehavior change.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 06:18:37 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 20:23:14 GMT"}, {"version": "v3", "created": "Fri, 11 Sep 2020 00:40:35 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Mohan", "Shiwali", ""]]}, {"id": "1910.07780", "submitter": "Sagar Verma", "authors": "Sagar Verma and Richa Verma and P.B. Sujit", "title": "MAPEL: Multi-Agent Pursuer-Evader Learning using Situation Report", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we consider a territory guarding game involving pursuers,\nevaders and a target in an environment that contains obstacles. The goal of the\nevaders is to capture the target, while that of the pursuers is to capture the\nevaders before they reach the target. All the agents have limited sensing range\nand can only detect each other when they are in their observation space. We\nfocus on the challenge of effective cooperation between agents of a team.\nFinding exact solutions for such multi-agent systems is difficult because of\nthe inherent complexity. We present Multi-Agent Pursuer-Evader Learning\n(MAPEL), a class of algorithms that use spatio-temporal graph representation to\nlearn structured cooperation. The key concept is that the learning takes place\nin a decentralized manner and agents use situation report updates to learn\nabout the whole environment from each others' partial observations. We use\nRecurrent Neural Networks (RNNs) to parameterize the spatio-temporal graph. An\nagent in MAPEL only updates all the other agents if an opponent or the target\nis inside its observation space by using situation report. We present two\nmethods for cooperation via situation report update: a) Peer-to-Peer Situation\nReport (P2PSR) and b) Ring Situation Report (RSR). We present a detailed\nanalysis of how these two cooperation methods perform when the number of agents\nin the game are increased. We provide empirical results to show how agents\ncooperate under these two methods.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 09:16:11 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Verma", "Sagar", ""], ["Verma", "Richa", ""], ["Sujit", "P. B.", ""]]}, {"id": "1910.07799", "submitter": "Guangping Li", "authors": "Fabian Klute, Guangping Li, Raphael L\\\"offler, Martin N\\\"ollenburg,\n  Manuela Schmidt", "title": "Exploring Semi-Automatic Map Labeling", "comments": "Extended version of a paper appearing in SIGSPATIAL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Label placement in maps is a very challenging task that is critical for the\noverall map quality. Most previous work focused on designing and implementing\nfully automatic solutions, but the resulting visual and aesthetic quality has\nnot reached the same level of sophistication that skilled human cartographers\nachieve. We investigate a different strategy that combines the strengths of\nhumans and algorithms. In our proposed method, first an initial labeling is\ncomputed that has many well-placed labels but is not claiming to be perfect.\nInstead it serves as a starting point for an expert user who can then\ninteractively and locally modify the labeling where necessary. In an iterative\nhuman-in-the-loop process alternating between user modifications and local\nalgorithmic updates and refinements the labeling can be tuned to the user's\nneeds. We demonstrate our approach by performing different possible\nmodification steps in a sample workflow with a prototypical interactive\nlabeling editor. Further, we report computational performance results from a\nsimulation experiment in QGIS, which investigates the differences between exact\nand heuristic algorithms for semi-automatic map labeling. To that end, we\ncompare several alternatives for recomputing the labeling after local\nmodifications and updates, as a major ingredient for an interactive labeling\neditor.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 09:57:45 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Klute", "Fabian", ""], ["Li", "Guangping", ""], ["L\u00f6ffler", "Raphael", ""], ["N\u00f6llenburg", "Martin", ""], ["Schmidt", "Manuela", ""]]}, {"id": "1910.07882", "submitter": "Boyuan Chen", "authors": "Boyuan Chen, Shuran Song, Hod Lipson, Carl Vondrick", "title": "Visual Hide and Seek", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We train embodied agents to play Visual Hide and Seek where a prey must\nnavigate in a simulated environment in order to avoid capture from a predator.\nWe place a variety of obstacles in the environment for the prey to hide behind,\nand we only give the agents partial observations of their environment using an\negocentric perspective. Although we train the model to play this game from\nscratch, experiments and visualizations suggest that the agent learns to\npredict its own visibility in the environment. Furthermore, we quantitatively\nanalyze how agent weaknesses, such as slower speed, effect the learned policy.\nOur results suggest that, although agent weaknesses make the learning problem\nmore challenging, they also cause more useful features to be learned. Our\nproject website is available at: http://www.cs.columbia.edu/\n~bchen/visualhideseek/.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 01:27:09 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Chen", "Boyuan", ""], ["Song", "Shuran", ""], ["Lipson", "Hod", ""], ["Vondrick", "Carl", ""]]}, {"id": "1910.07999", "submitter": "Ramya Akula", "authors": "Ramya Akula, Niloofar Yousefi and Ivan Garibay", "title": "DeepFork: Supervised Prediction of Information Diffusion in GitHub", "comments": "12 Pages, 7 Figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information spreads on complex social networks extremely fast, in other\nwords, a piece of information can go viral within no time. Often it is hard to\nbarricade this diffusion prior to the significant occurrence of chaos, be it a\nsocial media or an online coding platform. GitHub is one such trending online\nfocal point for any business to reach their potential contributors and\ncustomers, simultaneously. By exploiting such software development paradigm,\nmillions of free software emerged lately in diverse communities. To understand\nhuman influence, information spread and evolution of transmitted information\namong assorted users in GitHub, we developed a deep neural network model:\nDeepFork, a supervised machine learning based approach that aims to predict\ninformation diffusion in complex social networks; considering node as well as\ntopological features. In our empirical studies, we observed that information\ndiffusion can be detected by link prediction using supervised learning.\nDeepFork outperforms other machine learning models as it better learns the\ndiscriminative patterns from the input features. DeepFork aids in understanding\ninformation spread and evolution through a bipartite network of users and\nrepositories i.e., information flow from a user to repository to user.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 16:18:45 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Akula", "Ramya", ""], ["Yousefi", "Niloofar", ""], ["Garibay", "Ivan", ""]]}, {"id": "1910.08091", "submitter": "Yura Perov N", "authors": "Yura Perov, Logan Graham, Kostis Gourgoulias, Jonathan G. Richens,\n  Ciar\\'an M. Lee, Adam Baker, Saurabh Johri", "title": "MultiVerse: Causal Reasoning using Importance Sampling in Probabilistic\n  Programming", "comments": "Logan and Yura have made equal contributions to the paper. Accepted\n  to the 2nd Symposium on Advances in Approximate Bayesian Inference\n  (Vancouver, Canada, 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.PL stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We elaborate on using importance sampling for causal reasoning, in particular\nfor counterfactual inference. We show how this can be implemented natively in\nprobabilistic programming. By considering the structure of the counterfactual\nquery, one can significantly optimise the inference process. We also consider\ndesign choices to enable further optimisations. We introduce MultiVerse, a\nprobabilistic programming prototype engine for approximate causal reasoning. We\nprovide experimental results and compare with Pyro, an existing probabilistic\nprogramming framework with some of causal reasoning tools.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 18:00:24 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 10:05:13 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Perov", "Yura", ""], ["Graham", "Logan", ""], ["Gourgoulias", "Kostis", ""], ["Richens", "Jonathan G.", ""], ["Lee", "Ciar\u00e1n M.", ""], ["Baker", "Adam", ""], ["Johri", "Saurabh", ""]]}, {"id": "1910.08137", "submitter": "Christian Muise", "authors": "Christian Muise, Tathagata Chakraborti, Shubham Agarwal, Ondrej\n  Bajgar, Arunima Chaudhary, Luis A. Lastras-Montano, Josef Ondrej, Miroslav\n  Vodolan, Charlie Wiecha", "title": "Planning for Goal-Oriented Dialogue Systems", "comments": "42 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating complex multi-turn goal-oriented dialogue agents is a difficult\nproblem that has seen a considerable focus from many leaders in the tech\nindustry, including IBM, Google, Amazon, and Microsoft. This is in large part\ndue to the rapidly growing market demand for dialogue agents capable of\ngoal-oriented behaviour. Due to the business process nature of these\nconversations, end-to-end machine learning systems are generally not a viable\noption, as the generated dialogue agents must be deployable and verifiable on\nbehalf of the businesses authoring them.\n  In this work, we propose a paradigm shift in the creation of goal-oriented\ncomplex dialogue systems that dramatically eliminates the need for a designer\nto manually specify a dialogue tree, which nearly all current systems have to\nresort to when the interaction pattern falls outside standard patterns such as\nslot filling. We propose a declarative representation of the dialogue agent to\nbe processed by state-of-the-art planning technology. Our proposed approach\ncovers all aspects of the process; from model solicitation to the execution of\nthe generated plans/dialogue agents. Along the way, we introduce novel planning\nencodings for declarative dialogue synthesis, a variety of interfaces for\nworking with the specification as a dialogue architect, and a robust executor\nfor generalized contingent plans. We have created prototype implementations of\nall components, and in this paper, we further demonstrate the resulting system\nempirically.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 20:00:10 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Muise", "Christian", ""], ["Chakraborti", "Tathagata", ""], ["Agarwal", "Shubham", ""], ["Bajgar", "Ondrej", ""], ["Chaudhary", "Arunima", ""], ["Lastras-Montano", "Luis A.", ""], ["Ondrej", "Josef", ""], ["Vodolan", "Miroslav", ""], ["Wiecha", "Charlie", ""]]}, {"id": "1910.08143", "submitter": "Huazhe Xu", "authors": "Huazhe Xu, Boyuan Chen, Yang Gao, Trevor Darrell", "title": "Zero-shot Policy Learning with Spatial Temporal RewardDecomposition on\n  Contingency-aware Observation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a long-standing challenge to enable an intelligent agent to learn in\none environment and generalize to an unseen environment without further data\ncollection and finetuning. In this paper, we consider a zero shot\ngeneralization problem setup that complies with biological intelligent agents'\nlearning and generalization processes. The agent is first presented with\nprevious experiences in the training environment, along with task description\nin the form of trajectory-level sparse rewards. Later when it is placed in the\nnew testing environment, it is asked to perform the task without any\ninteraction with the testing environment. We find this setting natural for\nbiological creatures and at the same time, challenging for previous methods.\nBehavior cloning, state-of-art RL along with other zero-shot learning methods\nperform poorly on this benchmark. Given a set of experiences in the training\nenvironment, our method learns a neural function that decomposes the sparse\nreward into particular regions in a contingency-aware observation as a per step\nreward. Based on such decomposed rewards, we further learn a dynamics model and\nuse Model Predictive Control (MPC) to obtain a policy. Since the rewards are\ndecomposed to finer-granularity observations, they are naturally generalizable\nto new environments that are composed of similar basic elements. We demonstrate\nour method on a wide range of environments, including a classic video game --\nSuper Mario Bros, as well as a robotic continuous control task. Please refer to\nthe project page for more visualized results.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 20:15:36 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 05:06:09 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Xu", "Huazhe", ""], ["Chen", "Boyuan", ""], ["Gao", "Yang", ""], ["Darrell", "Trevor", ""]]}, {"id": "1910.08194", "submitter": "Jiaming Shen", "authors": "Jiaming Shen, Zeqiu Wu, Dongming Lei, Chao Zhang, Xiang Ren, Michelle\n  T. Vanni, Brian M. Sadler, Jiawei Han", "title": "HiExpan: Task-Guided Taxonomy Construction by Hierarchical Tree\n  Expansion", "comments": "KDD 2018 accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taxonomies are of great value to many knowledge-rich applications. As the\nmanual taxonomy curation costs enormous human effects, automatic taxonomy\nconstruction is in great demand. However, most existing automatic taxonomy\nconstruction methods can only build hypernymy taxonomies wherein each edge is\nlimited to expressing the \"is-a\" relation. Such a restriction limits their\napplicability to more diverse real-world tasks where the parent-child may carry\ndifferent relations. In this paper, we aim to construct a task-guided taxonomy\nfrom a domain-specific corpus and allow users to input a \"seed\" taxonomy,\nserving as the task guidance. We propose an expansion-based taxonomy\nconstruction framework, namely HiExpan, which automatically generates key term\nlist from the corpus and iteratively grows the seed taxonomy. Specifically,\nHiExpan views all children under each taxonomy node forming a coherent set and\nbuilds the taxonomy by recursively expanding all these sets. Furthermore,\nHiExpan incorporates a weakly-supervised relation extraction module to extract\nthe initial children of a newly-expanded node and adjusts the taxonomy tree by\noptimizing its global structure. Our experiments on three real datasets from\ndifferent domains demonstrate the effectiveness of HiExpan for building\ntask-guided taxonomies.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 23:02:34 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Shen", "Jiaming", ""], ["Wu", "Zeqiu", ""], ["Lei", "Dongming", ""], ["Zhang", "Chao", ""], ["Ren", "Xiang", ""], ["Vanni", "Michelle T.", ""], ["Sadler", "Brian M.", ""], ["Han", "Jiawei", ""]]}, {"id": "1910.08210", "submitter": "Victor Zhong", "authors": "Victor Zhong, Tim Rockt\\\"aschel, Edward Grefenstette", "title": "RTFM: Generalising to Novel Environment Dynamics via Reading", "comments": "ICLR 2020; 17 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining policies that can generalise to new environments in reinforcement\nlearning is challenging. In this work, we demonstrate that language\nunderstanding via a reading policy learner is a promising vehicle for\ngeneralisation to new environments. We propose a grounded policy learning\nproblem, Read to Fight Monsters (RTFM), in which the agent must jointly reason\nover a language goal, relevant dynamics described in a document, and\nenvironment observations. We procedurally generate environment dynamics and\ncorresponding language descriptions of the dynamics, such that agents must read\nto understand new environment dynamics instead of memorising any particular\ninformation. In addition, we propose txt2$\\pi$, a model that captures three-way\ninteractions between the goal, document, and observations. On RTFM, txt2$\\pi$\ngeneralises to new environments with dynamics not seen during training via\nreading. Furthermore, our model outperforms baselines such as FiLM and\nlanguage-conditioned CNNs on RTFM. Through curriculum learning, txt2$\\pi$\nproduces policies that excel on complex RTFM tasks requiring several reasoning\nand coreference steps.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 00:49:15 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 21:26:05 GMT"}, {"version": "v3", "created": "Fri, 10 Jan 2020 21:49:27 GMT"}, {"version": "v4", "created": "Tue, 28 Jan 2020 18:37:02 GMT"}, {"version": "v5", "created": "Wed, 12 Feb 2020 20:22:15 GMT"}, {"version": "v6", "created": "Mon, 1 Feb 2021 20:46:03 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Zhong", "Victor", ""], ["Rockt\u00e4schel", "Tim", ""], ["Grefenstette", "Edward", ""]]}, {"id": "1910.08243", "submitter": "Lee Martie", "authors": "Lee Martie, Mohammad Arif Ul Alam, Gaoyuan Zhang, Ryan R. Anderson", "title": "Reflecting After Learning for Understanding", "comments": "Presented at the Advances in Cognitive Systems conference\n  (http://www.cogsys.org/conference/2019) and to be published in the Advances\n  in Cognitive Systems journal (http://www.cogsys.org/journal)", "journal-ref": "Advances in Cognitive Systems 8 (2019) 53-71", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, image classification is a common way for systems to process visual\ncontent. Although neural network approaches to classification have seen great\nprogress in reducing error rates, it is not clear what this means for a\ncognitive system that needs to make sense of the multiple and competing\npredictions from its own classifiers. As a step to address this, we present a\nnovel framework that uses meta-reasoning and meta-operations to unify\npredictions into abstractions, properties, or relationships. Using the\nframework on images from ImageNet, we demonstrate systems that unify 41% to 46%\nof predictions in general and unify 67% to 75% of predictions when the systems\ncan explain their conceptual differences. We also demonstrate a system in \"the\nwild\" by feeding live video images through it and show it unifying 51% of\npredictions in general and 69% of predictions when their differences can be\nexplained conceptually by the system. In a survey given to 24 participants, we\nfound that 87% of the unified predictions describe their corresponding images.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 03:37:30 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Martie", "Lee", ""], ["Alam", "Mohammad Arif Ul", ""], ["Zhang", "Gaoyuan", ""], ["Anderson", "Ryan R.", ""]]}, {"id": "1910.08282", "submitter": "Kun Zhou", "authors": "Kun Zhou, Kai Zhang, Yu Wu, Shujie Liu, Jingsong Yu", "title": "Unsupervised Context Rewriting for Open Domain Conversation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context modeling has a pivotal role in open domain conversation. Existing\nworks either use heuristic methods or jointly learn context modeling and\nresponse generation with an encoder-decoder framework. This paper proposes an\nexplicit context rewriting method, which rewrites the last utterance by\nconsidering context history. We leverage pseudo-parallel data and elaborate a\ncontext rewriting network, which is built upon the CopyNet with the\nreinforcement learning method. The rewritten utterance is beneficial to\ncandidate retrieval, explainable context modeling, as well as enabling to\nemploy a single-turn framework to the multi-turn scenario. The empirical\nresults show that our model outperforms baselines in terms of the rewriting\nquality, the multi-turn response generation, and the end-to-end retrieval-based\nchatbots.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 06:49:55 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 11:41:45 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Zhou", "Kun", ""], ["Zhang", "Kai", ""], ["Wu", "Yu", ""], ["Liu", "Shujie", ""], ["Yu", "Jingsong", ""]]}, {"id": "1910.08293", "submitter": "Steven Y. Feng", "authors": "Aaron W. Li, Veronica Jiang, Steven Y. Feng, Julia Sprague, Wei Zhou,\n  Jesse Hoey", "title": "ALOHA: Artificial Learning of Human Attributes for Dialogue Agents", "comments": "AAAI 2020; Code available at https://github.com/newpro/aloha-chatbot", "journal-ref": null, "doi": "10.1609/aaai.v34i05.6328", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For conversational AI and virtual assistants to communicate with humans in a\nrealistic way, they must exhibit human characteristics such as expression of\nemotion and personality. Current attempts toward constructing human-like\ndialogue agents have presented significant difficulties. We propose Human Level\nAttributes (HLAs) based on tropes as the basis of a method for learning\ndialogue agents that can imitate the personalities of fictional characters.\nTropes are characteristics of fictional personalities that are observed\nrecurrently and determined by viewers' impressions. By combining detailed HLA\ndata with dialogue data for specific characters, we present a dataset,\nHLA-Chat, that models character profiles and gives dialogue agents the ability\nto learn characters' language styles through their HLAs. We then introduce a\nthree-component system, ALOHA (which stands for Artificial Learning of Human\nAttributes), that combines character space mapping, character community\ndetection, and language style retrieval to build a character (or personality)\nspecific language model. Our preliminary experiments demonstrate that two\nvariations of ALOHA, combined with our proposed dataset, can outperform\nbaseline models at identifying the correct dialogue responses of chosen target\ncharacters, and are stable regardless of the character's identity, the genre of\nthe show, and the context of the dialogue.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 07:52:01 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 19:18:03 GMT"}, {"version": "v3", "created": "Mon, 21 Sep 2020 07:52:11 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Li", "Aaron W.", ""], ["Jiang", "Veronica", ""], ["Feng", "Steven Y.", ""], ["Sprague", "Julia", ""], ["Zhou", "Wei", ""], ["Hoey", "Jesse", ""]]}, {"id": "1910.08294", "submitter": "Elizabeth Jasmi George", "authors": "Elizabeth Jasmi George and Radhika Mamidi", "title": "Towards Computing Inferences from English News Headlines", "comments": "PACLING 2019 Long paper, 15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Newspapers are a popular form of written discourse, read by many people,\nthanks to the novelty of the information provided by the news content in it. A\nheadline is the most widely read part of any newspaper due to its appearance in\na bigger font and sometimes in colour print. In this paper, we suggest and\nimplement a method for computing inferences from English news headlines,\nexcluding the information from the context in which the headlines appear. This\nmethod attempts to generate the possible assumptions a reader formulates in\nmind upon reading a fresh headline. The generated inferences could be useful\nfor assessing the impact of the news headline on readers including children.\nThe understandability of the current state of social affairs depends greatly on\nthe assimilation of the headlines. As the inferences that are independent of\nthe context depend mainly on the syntax of the headline, dependency trees of\nheadlines are used in this approach, to find the syntactical structure of the\nheadlines and to compute inferences out of them.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 07:56:08 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["George", "Elizabeth Jasmi", ""], ["Mamidi", "Radhika", ""]]}, {"id": "1910.08526", "submitter": "Sharmistha Mishra", "authors": "David Landsman, Huiting Ma, Jesse Knight, Kevin Gough, Sharmistha\n  Mishra", "title": "A flexible integer linear programming formulation for scheduling\n  clinician on-call service in hospitals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scheduling of personnel in a hospital environment is vital to improving the\nservice provided to patients and balancing the workload assigned to clinicians.\nMany approaches have been tried and successfully applied to generate efficient\nschedules in such settings. However, due to the computational complexity of the\nscheduling problem in general, most approaches resort to heuristics to find a\nnon-optimal solution in a reasonable amount of time. We designed an integer\nlinear programming formulation to find an optimal schedule in a clinical\ndivision of a hospital. Our formulation mitigates issues related to\ncomputational complexity by minimizing the set of constraints, yet retains\nsufficient flexibility so that it can be adapted to a variety of clinical\ndivisions.\n  We then conducted a case study for our approach using data from the\nInfectious Diseases division at St. Michael's Hospital in Toronto, Canada. We\nanalyzed and compared the results of our approach to manually-created schedules\nat the hospital, and found improved adherence to departmental constraints and\nclinician preferences. We used simulated data to examine the sensitivity of the\nruntime of our linear program for various parameters and observed reassuring\nresults, signifying the practicality and generalizability of our approach in\ndifferent real-world scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 17:45:57 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Landsman", "David", ""], ["Ma", "Huiting", ""], ["Knight", "Jesse", ""], ["Gough", "Kevin", ""], ["Mishra", "Sharmistha", ""]]}, {"id": "1910.08549", "submitter": "Achim Rettinger", "authors": "Achim Rettinger, Viktoria Bogdanova, Philipp Niemann", "title": "Towards Learning Cross-Modal Perception-Trace Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning is a key element of state-of-the-art deep learning\napproaches. It enables to transform raw data into structured vector space\nembeddings. Such embeddings are able to capture the distributional semantics of\ntheir context, e.g. by word windows on natural language sentences, graph walks\non knowledge graphs or convolutions on images. So far, this context is manually\ndefined, resulting in heuristics which are solely optimized for computational\nperformance on certain tasks like link-prediction. However, such heuristic\nmodels of context are fundamentally different to how humans capture\ninformation. For instance, when reading a multi-modal webpage (i) humans do not\nperceive all parts of a document equally: Some words and parts of images are\nskipped, others are revisited several times which makes the perception trace\nhighly non-sequential; (ii) humans construct meaning from a document's content\nby shifting their attention between text and image, among other things, guided\nby layout and design elements. In this paper we empirically investigate the\ndifference between human perception and context heuristics of basic embedding\nmodels. We conduct eye tracking experiments to capture the underlying\ncharacteristics of human perception of media documents containing a mixture of\ntext and images. Based on that, we devise a prototypical computational\nperception-trace model, called CMPM. We evaluate empirically how CMPM can\nimprove a basic skip-gram embedding approach. Our results suggest, that even\nwith a basic human-inspired computational perception model, there is a huge\npotential for improving embeddings since such a model does inherently capture\nmultiple modalities, as well as layout and design elements.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 15:20:38 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Rettinger", "Achim", ""], ["Bogdanova", "Viktoria", ""], ["Niemann", "Philipp", ""]]}, {"id": "1910.08625", "submitter": "Bruce Cox", "authors": "Petar D. Jackovich, Bruce A. Cox, and Raymond R. Hill", "title": "Comparing Greedy Constructive Heuristic Subtour Elimination Methods for\n  the Traveling Salesman Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper further defines the class of fragment constructive heuristics used\nto compute feasible solutions for the Traveling Salesman Problem into\narc-greedy and node-greedy subclasses. Since these subclasses of heuristics can\ncreate subtours, two known methodologies for subtour elimination on symmetric\ninstances are reviewed and are expanded to cover asymmetric problem instances.\nThis paper introduces a third novel methodology, the Greedy Tracker, and\ncompares it to both known methodologies. Computational results are generated\nacross multiple symmetric and asymmetric instances. The results demonstrate the\nGreedy Tracker is the fastest method for preventing subtours for instances\nbelow 400 nodes. A distinction between fragment constructive heuristics and the\nsubtour elimination methodology used to ensure the feasibility of resulting\nsolutions enables the introduction of a new node-greedy fragment heuristic\ncalled Ordered Greedy.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 19:13:27 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Jackovich", "Petar D.", ""], ["Cox", "Bruce A.", ""], ["Hill", "Raymond R.", ""]]}, {"id": "1910.08629", "submitter": "Yongfeng Zhang", "authors": "Shaoyun Shi, Hanxiong Chen, Min Zhang, Yongfeng Zhang", "title": "Neural Logic Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the great success of deep neural networks in many\nresearch areas. The fundamental idea behind the design of most neural networks\nis to learn similarity patterns from data for prediction and inference, which\nlacks the ability of logical reasoning. However, the concrete ability of\nlogical reasoning is critical to many theoretical and practical problems. In\nthis paper, we propose Neural Logic Network (NLN), which is a dynamic neural\narchitecture that builds the computational graph according to input logical\nexpressions. It learns basic logical operations as neural modules, and conducts\npropositional logical reasoning through the network for inference. Experiments\non simulated data show that NLN achieves significant performance on solving\nlogical equations. Further experiments on real-world data show that NLN\nsignificantly outperforms state-of-the-art models on collaborative filtering\nand personalized recommendation tasks.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 01:53:37 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Shi", "Shaoyun", ""], ["Chen", "Hanxiong", ""], ["Zhang", "Min", ""], ["Zhang", "Yongfeng", ""]]}, {"id": "1910.08639", "submitter": "Ilya Kuzovkin", "authors": "Ashish Kumar, Toby Buckley, John B. Lanier, Qiaozhi Wang, Alicia\n  Kavelaars, Ilya Kuzovkin", "title": "OffWorld Gym: open-access physical robotics environment for real-world\n  reinforcement learning benchmark and research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Success stories of applied machine learning can be traced back to the\ndatasets and environments that were put forward as challenges for the\ncommunity. The challenge that the community sets as a benchmark is usually the\nchallenge that the community eventually solves. The ultimate challenge of\nreinforcement learning research is to train real agents to operate in the real\nenvironment, but until now there has not been a common real-world RL benchmark.\nIn this work, we present a prototype real-world environment from OffWorld Gym\n-- a collection of real-world environments for reinforcement learning in\nrobotics with free public remote access. Close integration into existing\necosystem allows the community to start using OffWorld Gym without any prior\nexperience in robotics and takes away the burden of managing a physical\nrobotics system, abstracting it under a familiar API. We introduce a navigation\ntask, where a robot has to reach a visual beacon on an uneven terrain using\nonly the camera input and provide baseline results in both the real environment\nand the simulated replica. To start training, visit https://gym.offworld.ai\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 21:58:24 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 08:51:54 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 05:19:37 GMT"}, {"version": "v4", "created": "Tue, 15 Dec 2020 02:59:34 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Kumar", "Ashish", ""], ["Buckley", "Toby", ""], ["Lanier", "John B.", ""], ["Wang", "Qiaozhi", ""], ["Kavelaars", "Alicia", ""], ["Kuzovkin", "Ilya", ""]]}, {"id": "1910.08647", "submitter": "Pavel Naumov", "authors": "Pavel Naumov and Jia Tao", "title": "Blameworthiness in Security Games", "comments": "34th AAAI Conference on Artificial Intelligence (AAAI-20), February\n  7-12, 2020, New York, New York, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security games are an example of a successful real-world application of game\ntheory. The paper defines blameworthiness of the defender and the attacker in\nsecurity games using the principle of alternative possibilities and provides a\nsound and complete logical system for reasoning about blameworthiness in such\ngames. Two of the axioms of this system capture the asymmetry of information in\nsecurity games.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 22:22:35 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 20:50:51 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Naumov", "Pavel", ""], ["Tao", "Jia", ""]]}, {"id": "1910.08677", "submitter": "Atiye Alaeddini", "authors": "Atiye Alaeddini and Daniel Klein", "title": "Optimal Immunization Policy Using Dynamic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decisions in public health are almost always made in the context of\nuncertainty. Policy makers are responsible for making important decisions,\nfaced with the daunting task of choosing from amongst many possible options.\nThis task is called planning under uncertainty, and is particularly acute when\naddressing complex systems, such as issues of global health and development.\nUncertainty leads to cautious or incorrect decisions that cost time, money, and\nhuman life. It is with this understanding that we pursue greater clarity on,\nand methods to address optimal policy making in health. Decision making under\nuncertainty is a challenging task, and all too often this uncertainty is\naveraged away to simplify results for policy makers. Our goal in this work is\nto implement dynamic programming which provides basis for compiling planning\nresults into reactive strategies. We present here a description of an AI-based\nmethod and illustrate how this method can improve our ability to find an\noptimal vaccination strategy. We model the problem as a partially observable\nMarkov decision process, POMDP and show how a re-active policy can be computed\nusing dynamic programming. In this paper, we developed a framework for optimal\nhealth policy design in an uncertain dynamic setting. We apply a stochastic\ndynamic programming approach to identify the optimal time to change the health\nintervention policy and the value of decision relevant information for\nimproving the impact of the policy.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 01:52:52 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 16:09:58 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Alaeddini", "Atiye", ""], ["Klein", "Daniel", ""]]}, {"id": "1910.08719", "submitter": "Hareesh Kumar", "authors": "Hareesh Kumar, Priyanka Mary Mammen, Krithi Ramamritham", "title": "Explainable AI: Deep Reinforcement Learning Agents for Residential\n  Demand Side Cost Savings in Smart Grids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by recent advancements in Deep Reinforcement Learning (RL), we have\ndeveloped an RL agent to manage the operation of storage devices in a household\nand is designed to maximize demand-side cost savings. The proposed technique is\ndata-driven, and the RL agent learns from scratch how to efficiently use the\nenergy storage device given variable tariff structures. In most of the studies,\nthe RL agent is considered as a black box, and how the agent has learned is\noften ignored. We explain the learning progression of the RL agent, and the\nstrategies it follows based on the capacity of the storage device.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 07:57:54 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 17:39:15 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Kumar", "Hareesh", ""], ["Mammen", "Priyanka Mary", ""], ["Ramamritham", "Krithi", ""]]}, {"id": "1910.08747", "submitter": "Hu Weizhen", "authors": "Min Jiang, Weizhen Hu, Liming Qiu, Minghui Shi, Kay Chen Tan", "title": "Solving dynamic multi-objective optimization problems via support vector\n  machine", "comments": null, "journal-ref": null, "doi": "10.1109/ICACI.2018.8377567", "report-no": null, "categories": "cs.AI cs.LG cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Multi-objective Optimization Problems (DMOPs) refer to optimization\nproblems that objective functions will change with time. Solving DMOPs implies\nthat the Pareto Optimal Set (POS) at different moments can be accurately found,\nand this is a very difficult job due to the dynamics of the optimization\nproblems. The POS that have been obtained in the past can help us to find the\nPOS of the next time more quickly and accurately. Therefore, in this paper we\npresent a Support Vector Machine (SVM) based Dynamic Multi-Objective\nEvolutionary optimization Algorithm, called SVM-DMOEA. The algorithm uses the\nPOS that has been obtained to train a SVM and then take the trained SVM to\nclassify the solutions of the dynamic optimization problem at the next moment,\nand thus it is able to generate an initial population which consists of\ndifferent individuals recognized by the trained SVM. The initial populuation\ncan be fed into any population based optimization algorithm, e.g., the\nNondominated Sorting Genetic Algorithm II (NSGA-II), to get the POS at that\nmoment. The experimental results show the validity of our proposed approach.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 11:06:33 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Jiang", "Min", ""], ["Hu", "Weizhen", ""], ["Qiu", "Liming", ""], ["Shi", "Minghui", ""], ["Tan", "Kay Chen", ""]]}, {"id": "1910.08780", "submitter": "Egor Rotinov", "authors": "Egor Rotinov", "title": "Reverse Experience Replay", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes an improvement in Deep Q-learning called Reverse\nExperience Replay (also RER) that solves the problem of sparse rewards and\nhelps to deal with reward maximizing tasks by sampling transitions successively\nin reverse order. On tasks with enough experience for training and enough\nExperience Replay memory capacity, Deep Q-learning Network with Reverse\nExperience Replay shows competitive results against both Double DQN, with a\nstandard Experience Replay, and vanilla DQN. Also, RER achieves significantly\nincreased results in tasks with a lack of experience and Replay memory\ncapacity.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 14:37:13 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 18:13:59 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Rotinov", "Egor", ""]]}, {"id": "1910.08918", "submitter": "Tadahiro Taniguchi", "authors": "Tadahiro Taniguchi, Tomoaki Nakamura, Masahiro Suzuki, Ryo Kuniyasu,\n  Kaede Hayashi, Akira Taniguchi, Takato Horii, Takayuki Nagai", "title": "Neuro-SERKET: Development of Integrative Cognitive System through the\n  Composition of Deep Probabilistic Generative Models", "comments": "New Gener. Comput. (2020)", "journal-ref": null, "doi": "10.1007/s00354-019-00084-w", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a framework for the development of an integrative\ncognitive system based on probabilistic generative models (PGMs) called\nNeuro-SERKET. Neuro-SERKET is an extension of SERKET, which can compose\nelemental PGMs developed in a distributed manner and provide a scheme that\nallows the composed PGMs to learn throughout the system in an unsupervised way.\nIn addition to the head-to-tail connection supported by SERKET, Neuro-SERKET\nsupports tail-to-tail and head-to-head connections, as well as neural\nnetwork-based modules, i.e., deep generative models. As an example of a\nNeuro-SERKET application, an integrative model was developed by composing a\nvariational autoencoder (VAE), a Gaussian mixture model (GMM), latent Dirichlet\nallocation (LDA), and automatic speech recognition (ASR). The model is called\nVAE+GMM+LDA+ASR. The performance of VAE+GMM+LDA+ASR and the validity of\nNeuro-SERKET were demonstrated through a multimodal categorization task using\nimage data and a speech signal of numerical digits.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 07:35:39 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 04:41:41 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Taniguchi", "Tadahiro", ""], ["Nakamura", "Tomoaki", ""], ["Suzuki", "Masahiro", ""], ["Kuniyasu", "Ryo", ""], ["Hayashi", "Kaede", ""], ["Taniguchi", "Akira", ""], ["Horii", "Takato", ""], ["Nagai", "Takayuki", ""]]}, {"id": "1910.08925", "submitter": "Dong Dai", "authors": "Di Zhang, Dong Dai, Youbiao He, Forrest Sheng Bao, Bing Xie", "title": "RLScheduler: An Automated HPC Batch Job Scheduler Using Reinforcement\n  Learning", "comments": "14 pages; conference accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today high-performance computing (HPC) platforms are still dominated by batch\njobs. Accordingly, effective batch job scheduling is crucial to obtain high\nsystem efficiency. Existing HPC batch job schedulers typically leverage\nheuristic priority functions to prioritize and schedule jobs. But, once\nconfigured and deployed by the experts, such priority functions can hardly\nadapt to the changes of job loads, optimization goals, or system settings,\npotentially leading to degraded system efficiency when changes occur. To\naddress this fundamental issue, we present RLScheduler, an automated HPC batch\njob scheduler built on reinforcement learning. RLScheduler relies on minimal\nmanual interventions or expert knowledge, but can learn high-quality scheduling\npolicies via its own continuous 'trial and error'. We introduce a new\nkernel-based neural network structure and trajectory filtering mechanism in\nRLScheduler to improve and stabilize the learning process. Through extensive\nevaluations, we confirm that RLScheduler can learn high-quality scheduling\npolicies towards various workloads and various optimization goals with\nrelatively low computation cost. Moreover, we show that the learned models\nperform stably even when applied to unseen workloads, making them practical for\nproduction use.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 08:14:28 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 15:11:44 GMT"}, {"version": "v3", "created": "Wed, 2 Sep 2020 00:58:23 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Zhang", "Di", ""], ["Dai", "Dong", ""], ["He", "Youbiao", ""], ["Bao", "Forrest Sheng", ""], ["Xie", "Bing", ""]]}, {"id": "1910.08926", "submitter": "Mohamed Karim Belaid", "authors": "Van Bach Nguyen, Belaid Mohamed Karim, Bao Long Vu, J\\\"org\n  Schl\\\"otterer, Michael Granitzer", "title": "Policy Learning for Malaria Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Sequential decision making is a typical problem in reinforcement learning\nwith plenty of algorithms to solve it. However, only a few of them can work\neffectively with a very small number of observations. In this report, we\nintroduce the progress to learn the policy for Malaria Control as a\nReinforcement Learning problem in the KDD Cup Challenge 2019 and propose\ndiverse solutions to deal with the limited observations problem. We apply the\nGenetic Algorithm, Bayesian Optimization, Q-learning with sequence breaking to\nfind the optimal policy for five years in a row with only 20 episodes/100\nevaluations. We evaluate those algorithms and compare their performance with\nRandom Search as a baseline. Among these algorithms, Q-Learning with sequence\nbreaking has been submitted to the challenge and got ranked 7th in KDD Cup.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 08:19:40 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Nguyen", "Van Bach", ""], ["Karim", "Belaid Mohamed", ""], ["Vu", "Bao Long", ""], ["Schl\u00f6tterer", "J\u00f6rg", ""], ["Granitzer", "Michael", ""]]}, {"id": "1910.08942", "submitter": "Leonardo Andr\\'es Espinosa Leal EspinosaLeal", "authors": "Leonardo A. Espinosa Leal, Magnus Westerlund, Anthony Chapman", "title": "Autonomous Industrial Management via Reinforcement Learning:\n  Self-Learning Agents for Decision-Making -- A Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industry has always been in the pursuit of becoming more economically\nefficient and the current focus has been to reduce human labour using modern\ntechnologies. Even with cutting edge technologies, which range from packaging\nrobots to AI for fault detection, there is still some ambiguity on the aims of\nsome new systems, namely, whether they are automated or autonomous. In this\npaper we indicate the distinctions between automated and autonomous system as\nwell as review the current literature and identify the core challenges for\ncreating learning mechanisms of autonomous agents. We discuss using different\ntypes of extended realities, such as digital twins, to train reinforcement\nlearning agents to learn specific tasks through generalization. Once\ngeneralization is achieved, we discuss how these can be used to develop\nself-learning agents. We then introduce self-play scenarios and how they can be\nused to teach self-learning agents through a supportive environment which\nfocuses on how the agents can adapt to different real-world environments.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 10:10:21 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Leal", "Leonardo A. Espinosa", ""], ["Westerlund", "Magnus", ""], ["Chapman", "Anthony", ""]]}, {"id": "1910.08955", "submitter": "Christoph Benzm\\\"uller", "authors": "Christoph Benzm\\\"uller and David Fuenmayor", "title": "Computer-supported Analysis of Positive Properties, Ultrafilters and\n  Modal Collapse in Variants of G\\\"odel's Ontological Argument", "comments": "21 pages, 6 figures; to appear in the Bulletin of the Section of\n  Logic", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CL math.GN math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Three variants of Kurt G\\\"odel's ontological argument, proposed by Dana\nScott, C. Anthony Anderson and Melvin Fitting, are encoded and rigorously\nassessed on the computer. In contrast to Scott's version of G\\\"odel's argument\nthe two variants contributed by Anderson and Fitting avoid modal collapse.\nAlthough they appear quite different on a cursory reading they are in fact\nclosely related. This has been revealed in the computer-supported formal\nanalysis presented in this article. Key to our formal analysis is the\nutilization of suitably adapted notions of (modal) ultrafilters, and a careful\ndistinction between extensions and intensions of positive properties.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 11:54:05 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 12:32:15 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Benzm\u00fcller", "Christoph", ""], ["Fuenmayor", "David", ""]]}, {"id": "1910.09056", "submitter": "Saeid Naderiparizi", "authors": "Saeid Naderiparizi, Adam \\'Scibior, Andreas Munk, Mehrdad Ghadiri,\n  At{\\i}l{\\i}m G\\\"une\\c{s} Baydin, Bradley Gram-Hansen, Christian Schroeder de\n  Witt, Robert Zinkov, Philip H.S. Torr, Tom Rainforth, Yee Whye Teh, Frank\n  Wood", "title": "Amortized Rejection Sampling in Universal Probabilistic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing approaches to amortized inference in probabilistic programs with\nunbounded loops can produce estimators with infinite variance. An instance of\nthis is importance sampling inference in programs that explicitly include\nrejection sampling as part of the user-programmed generative procedure. In this\npaper we develop a new and efficient amortized importance sampling estimator.\nWe prove finite variance of our estimator and empirically demonstrate our\nmethod's correctness and efficiency compared to existing alternatives on\ngenerative programs containing rejection sampling loops and discuss how to\nimplement our method in a generic probabilistic programming framework.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 20:04:20 GMT"}, {"version": "v2", "created": "Sat, 30 Nov 2019 00:11:55 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Naderiparizi", "Saeid", ""], ["\u015acibior", "Adam", ""], ["Munk", "Andreas", ""], ["Ghadiri", "Mehrdad", ""], ["Baydin", "At\u0131l\u0131m G\u00fcne\u015f", ""], ["Gram-Hansen", "Bradley", ""], ["de Witt", "Christian Schroeder", ""], ["Zinkov", "Robert", ""], ["Torr", "Philip H. S.", ""], ["Rainforth", "Tom", ""], ["Teh", "Yee Whye", ""], ["Wood", "Frank", ""]]}, {"id": "1910.09093", "submitter": "Benjamin Petit", "authors": "Benjamin Petit, Loren Amdahl-Culleton, Yao Liu, Jimmy Smith,\n  Pierre-Luc Bacon", "title": "All-Action Policy Gradient Methods: A Numerical Integration Approach", "comments": "9 pages, 2 figures. NeurIPS 2019 Optimization Foundations of\n  Reinforcement Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While often stated as an instance of the likelihood ratio trick [Rubinstein,\n1989], the original policy gradient theorem [Sutton, 1999] involves an integral\nover the action space. When this integral can be computed, the resulting\n\"all-action\" estimator [Sutton, 2001] provides a conditioning effect [Bratley,\n1987] reducing the variance significantly compared to the REINFORCE estimator\n[Williams, 1992]. In this paper, we adopt a numerical integration perspective\nto broaden the applicability of the all-action estimator to general spaces and\nto any function class for the policy or critic components, beyond the Gaussian\ncase considered by [Ciosek, 2018]. In addition, we provide a new theoretical\nresult on the effect of using a biased critic which offers more guidance than\nthe previous \"compatible features\" condition of [Sutton, 1999]. We demonstrate\nthe benefit of our approach in continuous control tasks with nonlinear function\napproximation. Our results show improved performance and sample efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 00:42:48 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Petit", "Benjamin", ""], ["Amdahl-Culleton", "Loren", ""], ["Liu", "Yao", ""], ["Smith", "Jimmy", ""], ["Bacon", "Pierre-Luc", ""]]}, {"id": "1910.09137", "submitter": "Qian Yang", "authors": "Qian Yang", "title": "Two Case Studies of Experience Prototyping Machine Learning Systems in\n  the Wild", "comments": "This is an accepted position paper for the ACM CHI'19 Workshop\n  <Emerging Perspectives in Human-Centered Machine Learning>", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Throughout the course of my Ph.D., I have been designing the user experience\n(UX) of various machine learning (ML) systems. In this workshop, I share two\nprojects as case studies in which people engage with ML in much more\ncomplicated and nuanced ways than the technical HCML work might assume. The\nfirst case study describes how cardiology teams in three hospitals used a\nclinical decision-support system that helps them decide whether and when to\nimplant an artificial heart to a heart failure patient. I demonstrate that\nphysicians cannot draw on their decision-making experience by seeing only\npatient data on paper. They are also confused by some fundamental premises upon\nwhich ML operates. For example, physicians asked: Are ML predictions made based\non clinicians' best efforts? Is it ethical to make decisions based on previous\npatients' collective outcomes? In the second case study, my collaborators and I\ndesigned an intelligent text editor, with the goal of improving authors'\nwriting experience with NLP (Natural Language Processing) technologies. We\nprototyped a number of generative functionalities where the system provides\nphrase-or-sentence-level writing suggestions upon user request. When writing\nwith the prototype, however, authors shared that they need to \"see where the\nsentence is going two paragraphs later\" in order to decide whether the\nsuggestion aligns with their writing; Some even considered adopting machine\nsuggestions as plagiarism, therefore \"is simply wrong\".\n  By sharing these unexpected and intriguing responses from these real-world ML\nusers, I hope to start a discussion about such previously-unknown complexities\nand nuances of -- as the workshop proposal states -- \"putting ML at the service\nof people in a way that is accessible, useful, and trustworthy to all\".\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 03:43:12 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Yang", "Qian", ""]]}, {"id": "1910.09153", "submitter": "Lu Bai", "authors": "Lu Bai, Lixin Cui, Lixiang Xu, Yue Wang, Zhihong Zhang, Edwin R.\n  Hancock", "title": "Entropic Dynamic Time Warping Kernels for Co-evolving Financial Time\n  Series Analysis", "comments": "Previously, the original version of this manuscript appeared as\n  arXiv:1902.09947v2, that was submitted as a replacement by a mistake. Now,\n  that article has been replaced to correct the error, and this manuscript is\n  distinct from that article", "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems, 2020", "doi": "10.1109/TNNLS.2020.3006738", "report-no": null, "categories": "q-fin.ST cs.AI cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we develop a novel framework to measure the similarity between\ndynamic financial networks, i.e., time-varying financial networks.\nParticularly, we explore whether the proposed similarity measure can be\nemployed to understand the structural evolution of the financial networks with\ntime. For a set of time-varying financial networks with each vertex\nrepresenting the individual time series of a different stock and each edge\nbetween a pair of time series representing the absolute value of their Pearson\ncorrelation, our start point is to compute the commute time matrix associated\nwith the weighted adjacency matrix of the network structures, where each\nelement of the matrix can be seen as the enhanced correlation value between\npairwise stocks. For each network, we show how the commute time matrix allows\nus to identify a reliable set of dominant correlated time series as well as an\nassociated dominant probability distribution of the stock belonging to this\nset. Furthermore, we represent each original network as a discrete dominant\nShannon entropy time series computed from the dominant probability\ndistribution. With the dominant entropy time series for each pair of financial\nnetworks to hand, we develop a similarity measure based on the classical\ndynamic time warping framework, for analyzing the financial time-varying\nnetworks. We show that the proposed similarity measure is positive definite and\nthus corresponds to a kernel measure on graphs. The proposed kernel bridges the\ngap between graph kernels and the classical dynamic time warping framework for\nmultiple financial time series analysis. Experiments on time-varying networks\nextracted through New York Stock Exchange (NYSE) database demonstrate the\neffectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 05:08:09 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Bai", "Lu", ""], ["Cui", "Lixin", ""], ["Xu", "Lixiang", ""], ["Wang", "Yue", ""], ["Zhang", "Zhihong", ""], ["Hancock", "Edwin R.", ""]]}, {"id": "1910.09191", "submitter": "Zhuang Liu", "authors": "Zhuang Liu, Xuanlin Li, Bingyi Kang, Trevor Darrell", "title": "Regularization Matters in Policy Optimization -- An Empirical Study on\n  Continuous Control", "comments": "Published at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (Deep RL) has been receiving increasingly more\nattention thanks to its encouraging performance on a variety of control tasks.\nYet, conventional regularization techniques in training neural networks (e.g.,\n$L_2$ regularization, dropout) have been largely ignored in RL methods,\npossibly because agents are typically trained and evaluated in the same\nenvironment, and because the deep RL community focuses more on high-level\nalgorithm designs. In this work, we present the first comprehensive study of\nregularization techniques with multiple policy optimization algorithms on\ncontinuous control tasks. Interestingly, we find conventional regularization\ntechniques on the policy networks can often bring large improvement, especially\non harder tasks. Our findings are shown to be robust against training\nhyperparameter variations. We also compare these techniques with the more\nwidely used entropy regularization. In addition, we study regularizing\ndifferent components and find that only regularizing the policy network is\ntypically the best. We further analyze why regularization may help\ngeneralization in RL from four perspectives - sample complexity, reward\ndistribution, weight norm, and noise robustness. We hope our study provides\nguidance for future practices in regularizing policy optimization algorithms.\nOur code is available at https://github.com/xuanlinli17/iclr2021_rlreg .\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 08:00:33 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 10:19:31 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 13:53:13 GMT"}, {"version": "v4", "created": "Tue, 23 Feb 2021 04:57:59 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Liu", "Zhuang", ""], ["Li", "Xuanlin", ""], ["Kang", "Bingyi", ""], ["Darrell", "Trevor", ""]]}, {"id": "1910.09260", "submitter": "Jingjing Wang", "authors": "Jingjing Wang, Changlong Sun, Shoushan Li, Jiancheng Wang, Luo Si, Min\n  Zhang, Xiaozhong Liu, Guodong Zhou", "title": "Human-Like Decision Making: Document-level Aspect Sentiment\n  Classification via Hierarchical Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, neural networks have shown promising results on Document-level\nAspect Sentiment Classification (DASC). However, these approaches often offer\nlittle transparency w.r.t. their inner working mechanisms and lack\ninterpretability. In this paper, to simulating the steps of analyzing aspect\nsentiment in a document by human beings, we propose a new Hierarchical\nReinforcement Learning (HRL) approach to DASC. This approach incorporates\nclause selection and word selection strategies to tackle the data noise problem\nin the task of DASC. First, a high-level policy is proposed to select\naspect-relevant clauses and discard noisy clauses. Then, a low-level policy is\nproposed to select sentiment-relevant words and discard noisy words inside the\nselected clauses. Finally, a sentiment rating predictor is designed to provide\nreward signals to guide both clause and word selection. Experimental results\ndemonstrate the impressive effectiveness of the proposed approach to DASC over\nthe state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 10:55:46 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Wang", "Jingjing", ""], ["Sun", "Changlong", ""], ["Li", "Shoushan", ""], ["Wang", "Jiancheng", ""], ["Si", "Luo", ""], ["Zhang", "Min", ""], ["Liu", "Xiaozhong", ""], ["Zhou", "Guodong", ""]]}, {"id": "1910.09281", "submitter": "Joshua Hare", "authors": "Joshua Hare", "title": "Dealing with Sparse Rewards in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successfully navigating a complex environment to obtain a desired outcome is\na difficult task, that up to recently was believed to be capable only by\nhumans. This perception has been broken down over time, especially with the\nintroduction of deep reinforcement learning, which has greatly increased the\ndifficulty of tasks that can be automated. However, for traditional\nreinforcement learning agents this requires an environment to be able to\nprovide frequent extrinsic rewards, which are not known or accessible for many\nreal-world environments. This project aims to explore and contrast existing\nreinforcement learning solutions that circumnavigate the difficulties of an\nenvironment that provide sparse rewards. Different reinforcement solutions will\nbe implemented over a several video game environments with varying difficulty\nand varying frequency of rewards, as to properly investigate the applicability\nof these solutions. This project introduces a novel reinforcement learning\nsolution by combining aspects of two existing state of the art sparse reward\nsolutions, curiosity driven exploration and unsupervised auxiliary tasks.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 12:06:28 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 14:18:31 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Hare", "Joshua", ""]]}, {"id": "1910.09292", "submitter": "Shengluan Hou", "authors": "Ruqian Lu and Shengluan Hou", "title": "On Semi-Supervised Multiple Representation Behavior Learning", "comments": "18 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel paradigm of semi-supervised learning (SSL)--the\nsemi-supervised multiple representation behavior learning (SSMRBL). SSMRBL aims\nto tackle the difficulty of learning a grammar for natural language parsing\nwhere the data are natural language texts and the 'labels' for marking data are\nparsing trees and/or grammar rule pieces. We call such 'labels' as compound\nstructured labels which require a hard work for training. SSMRBL is an\nincremental learning process that can learn more than one representation, which\nis an appropriate solution for dealing with the scarce of labeled training data\nin the age of big data and with the heavy workload of learning compound\nstructured labels. We also present a typical example of SSMRBL, regarding\nbehavior learning in form of a grammatical approach towards domain-based\nmultiple text summarization (DBMTS). DBMTS works under the framework of\nrhetorical structure theory (RST). SSMRBL includes two representations: text\nembedding (for representing information contained in the texts) and grammar\nmodel (for representing parsing as a behavior). The first representation was\nlearned as embedded digital vectors called impacts in a low dimensional space.\nThe grammar model was learned in an iterative way. Then an automatic\ndomain-oriented multi-text summarization approach was proposed based on the two\nrepresentations discussed above. Experimental results on large-scale Chinese\ndataset SogouCA indicate that the proposed method brings a good performance\neven if only few labeled texts are used for training with respect to our\ndefined automated metrics.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 12:23:48 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Lu", "Ruqian", ""], ["Hou", "Shengluan", ""]]}, {"id": "1910.09311", "submitter": "Giuseppe Giacopelli", "authors": "Giuseppe Giacopelli", "title": "Studying Topology of Time Lines Graph leads to an alternative approach\n  to the Newcomb's Paradox", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Newcomb's paradox is one of the most known paradox in Game Theory about\nthe Oracles. We will define the graph associated to the time lines of the Game.\nAfter this Studying its topology and using only the Expected Utility Principle\nwe will formulate a solution of the paradox able to explain all the classical\ncases.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 18:03:11 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Giacopelli", "Giuseppe", ""]]}, {"id": "1910.09329", "submitter": "Nikolaos Stylianou", "authors": "Nikolaos Stylianou, Ioannis Vlahavas", "title": "A Neural Entity Coreference Resolution Review", "comments": "52 pages, 8 figures, 4 tables, Published in Expert Systems with\n  Applications", "journal-ref": "Expert Systems with Applications, Volume 168, 15 April 2021,\n  114466", "doi": "10.1016/j.eswa.2020.114466", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity Coreference Resolution is the task of resolving all mentions in a\ndocument that refer to the same real world entity and is considered as one of\nthe most difficult tasks in natural language understanding. It is of great\nimportance for downstream natural language processing tasks such as entity\nlinking, machine translation, summarization, chatbots, etc. This work aims to\ngive a detailed review of current progress on solving Coreference Resolution\nusing neural-based approaches. It also provides a detailed appraisal of the\ndatasets and evaluation metrics in the field, as well as the subtask of Pronoun\nResolution that has seen various improvements in the recent years. We highlight\nthe advantages and disadvantages of the approaches, the challenges of the task,\nthe lack of agreed-upon standards in the task and propose a way to further\nexpand the boundaries of the field.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 12:59:32 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 12:24:28 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Stylianou", "Nikolaos", ""], ["Vlahavas", "Ioannis", ""]]}, {"id": "1910.09335", "submitter": "Wen Zhang", "authors": "Wen Zhang, Dengji Zhao, Hanyu Chen", "title": "Redistribution Mechanism on Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Redistribution mechanisms have been proposed for more efficient resource\nallocation but not for profit. We consider redistribution mechanism design in a\nsetting where participants are connected and the resource owner is only\nconnected to some of them. In this setting, to make the resource allocation\nmore efficient, the resource owner has to inform the others who are not her\nneighbours, but her neighbours do not want more participants to compete with\nthem. Hence, the goal is to design a redistribution mechanism such that\nparticipants are incentivized to invite more participants and the resource\nowner does not earn or lose much money from the allocation. We first show that\nexisting redistribution mechanisms cannot be directly applied in the network\nsetting and prove the impossibility to achieve efficiency without a deficit.\nThen we propose a novel network-based redistribution mechanism such that all\nparticipants on the network are invited, the allocation is more efficient and\nthe resource owner has no deficit.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 13:06:23 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 13:38:19 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Zhang", "Wen", ""], ["Zhao", "Dengji", ""], ["Chen", "Hanyu", ""]]}, {"id": "1910.09358", "submitter": "Homayun Afrabandpey", "authors": "Homayun Afrabandpey, Tomi Peltola, Juho Piironen, Aki Vehtari and\n  Samuel Kaski", "title": "A Decision-Theoretic Approach for Model Interpretability in Bayesian\n  Framework", "comments": "This version contains more experiments including a comparison with\n  baseline methods from the literature and complemented some of the existing\n  results in the previous version", "journal-ref": "Machine Learning (2020)", "doi": "10.1007/s10994-020-05901-8", "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A salient approach to interpretable machine learning is to restrict modeling\nto simple models. In the Bayesian framework, this can be pursued by restricting\nthe model structure and prior to favor interpretable models. Fundamentally,\nhowever, interpretability is about users' preferences, not the data generation\nmechanism; it is more natural to formulate interpretability as a utility\nfunction. In this work, we propose an interpretability utility, which\nexplicates the trade-off between explanation fidelity and interpretability in\nthe Bayesian framework. The method consists of two steps. First, a reference\nmodel, possibly a black-box Bayesian predictive model which does not compromise\naccuracy, is fitted to the training data. Second, a proxy model from an\ninterpretable model family that best mimics the predictive behaviour of the\nreference model is found by optimizing the interpretability utility function.\nThe approach is model agnostic -- neither the interpretable model nor the\nreference model are restricted to a certain class of models -- and the\noptimization problem can be solved using standard tools. Through experiments on\nreal-word data sets, using decision trees as interpretable models and Bayesian\nadditive regression models as reference models, we show that for the same level\nof interpretability, our approach generates more accurate models than the\nalternative of restricting the prior. We also propose a systematic way to\nmeasure stability of interpretabile models constructed by different\ninterpretability approaches and show that our proposed approach generates more\nstable models.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 13:22:44 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 21:34:35 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Afrabandpey", "Homayun", ""], ["Peltola", "Tomi", ""], ["Piironen", "Juho", ""], ["Vehtari", "Aki", ""], ["Kaski", "Samuel", ""]]}, {"id": "1910.09417", "submitter": "Amir Emad Marvasti", "authors": "Amir Emad Marvasti, Ehsan Emad Marvasti, Ulas Bagci, Hassan Foroosh", "title": "Maximum Probability Theorem: A Framework for Probabilistic Learning", "comments": "in IEEE Transactions on Artificial Intelligence", "journal-ref": null, "doi": "10.1109/TAI.2021.3086046", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a theoretical framework of probabilistic learning derived by\nMaximum Probability (MP) Theorem shown in the current paper. In this\nprobabilistic framework, a model is defined as an event in the probability\nspace, and a model or the associated event -- either the true underlying model\nor the parameterized model -- have a quantified probability measure. This\nquantification of a model's probability measure is derived by the MP Theorem,\nin which we have shown that an event's probability measure has an upper-bound\ngiven its conditional distribution on an arbitrary random variable. Through\nthis alternative framework, the notion of model parameters is encompassed in\nthe definition of the model or the associated event. Therefore, this framework\ndeviates from the conventional approach of assuming a prior on the model\nparameters. Instead, the regularizing effects of assuming prior over parameters\nis seen through maximizing probabilities of models or according to information\ntheory, minimizing the information content of a model. The probability of a\nmodel in our framework is invariant to reparameterization and is solely\ndependent on the model's likelihood function. Also, rather than maximizing the\nposterior in a conventional Bayesian setting, the objective function in our\nalternative framework is defined as the probability of set operations (e.g.\nintersection) on the event of the true underlying model and the event of the\nmodel at hand. Our theoretical framework, as a derivation of MP theorem, adds\nclarity to probabilistic learning through solidifying the definition of\nprobabilistic models, quantifying their probabilities, and providing a visual\nunderstanding of objective functions.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 14:46:05 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 16:03:30 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 19:54:26 GMT"}, {"version": "v4", "created": "Tue, 8 Jun 2021 18:39:08 GMT"}, {"version": "v5", "created": "Mon, 14 Jun 2021 16:18:59 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Marvasti", "Amir Emad", ""], ["Marvasti", "Ehsan Emad", ""], ["Bagci", "Ulas", ""], ["Foroosh", "Hassan", ""]]}, {"id": "1910.09437", "submitter": "Tahar M Kechadi", "authors": "M-Tahar Kechadi, Kok Seng Low, G.Goncalves", "title": "Recurrent neural network approach for cyclic job shop scheduling problem", "comments": "Journal of Manufacturing Systems, Volume 32, Issue 4, October 2013,\n  Pages 689-699", "journal-ref": null, "doi": "10.1016/j.jmsy.2013.02.001", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While cyclic scheduling is involved in numerous real-world applications,\nsolving the derived problem is still of exponential complexity. This paper\nfocuses specifically on modelling the manufacturing application as a cyclic job\nshop problem and we have developed an efficient neural network approach to\nminimise the cycle time of a schedule. Our approach introduces an interesting\nmodel for a manufacturing production, and it is also very efficient, adaptive\nand flexible enough to work with other techniques. Experimental results\nvalidated the approach and confirmed our hypotheses about the system model and\nthe efficiency of neural networks for such a class of problems.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 15:13:48 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Kechadi", "M-Tahar", ""], ["Low", "Kok Seng", ""], ["Goncalves", "G.", ""]]}, {"id": "1910.09441", "submitter": "Qingyang Tan", "authors": "Qingyang Tan, Tingxiang Fan, Jia Pan, Dinesh Manocha", "title": "DeepMNavigate: Deep Reinforced Multi-Robot Navigation Unifying Local &\n  Global Collision Avoidance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel algorithm (DeepMNavigate) for global multi-agent\nnavigation in dense scenarios using deep reinforcement learning (DRL). Our\napproach uses local and global information for each robot from motion\ninformation maps. We use a three-layer CNN that takes these maps as input to\ngenerate a suitable action to drive each robot to its goal position. Our\napproach is general, learns an optimal policy using a multi-scenario,\nmulti-state training algorithm, and can directly handle raw sensor measurements\nfor local observations. We demonstrate the performance on dense, complex\nbenchmarks with narrow passages and environments with tens of agents. We\nhighlight the algorithm's benefits over prior learning methods and geometric\ndecentralized algorithms in complex scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 15:20:36 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 16:01:07 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2020 05:34:47 GMT"}, {"version": "v4", "created": "Wed, 3 Jun 2020 04:03:06 GMT"}, {"version": "v5", "created": "Tue, 28 Jul 2020 23:02:16 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Tan", "Qingyang", ""], ["Fan", "Tingxiang", ""], ["Pan", "Jia", ""], ["Manocha", "Dinesh", ""]]}, {"id": "1910.09472", "submitter": "Giorgio Terracina", "authors": "Francesco Calimeri, Francesco Cauteruccio, Luca Cinelli, Aldo\n  Marzullo, Claudio Stamile, Giorgio Terracina, Francoise Durand-Dubief,\n  Dominique Sappey-Marinier", "title": "A Logic-Based Framework Leveraging Neural Networks for Studying the\n  Evolution of Neurological Disorders", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deductive formalisms have been strongly developed in recent years; among\nthem, Answer Set Programming (ASP) gained some momentum, and has been lately\nfruitfully employed in many real-world scenarios. Nonetheless, in spite of a\nlarge number of success stories in relevant application areas, and even in\nindustrial contexts, deductive reasoning cannot be considered the ultimate,\ncomprehensive solution to AI; indeed, in several contexts, other approaches\nresult to be more useful. Typical Bioinformatics tasks, for instance\nclassification, are currently carried out mostly by Machine Learning (ML) based\nsolutions. In this paper, we focus on the relatively new problem of analyzing\nthe evolution of neurological disorders. In this context, ML approaches already\ndemonstrated to be a viable solution for classification tasks; here, we show\nhow ASP can play a relevant role in the brain evolution simulation task. In\nparticular, we propose a general and extensible framework to support physicians\nand researchers at understanding the complex mechanisms underlying neurological\ndisorders. The framework relies on a combined use of ML and ASP, and is general\nenough to be applied in several other application scenarios, which are outlined\nin the paper.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 16:01:48 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Calimeri", "Francesco", ""], ["Cauteruccio", "Francesco", ""], ["Cinelli", "Luca", ""], ["Marzullo", "Aldo", ""], ["Stamile", "Claudio", ""], ["Terracina", "Giorgio", ""], ["Durand-Dubief", "Francoise", ""], ["Sappey-Marinier", "Dominique", ""]]}, {"id": "1910.09508", "submitter": "Dongge Han", "authors": "Dongge Han, Wendelin Boehmer, Michael Wooldridge, Alex Rogers", "title": "Multi-agent Hierarchical Reinforcement Learning with Dynamic Termination", "comments": "PRICAI 2019", "journal-ref": null, "doi": "10.1007/978-3-030-29911-8_7", "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a multi-agent system, an agent's optimal policy will typically depend on\nthe policies chosen by others. Therefore, a key issue in multi-agent systems\nresearch is that of predicting the behaviours of others, and responding\npromptly to changes in such behaviours. One obvious possibility is for each\nagent to broadcast their current intention, for example, the currently executed\noption in a hierarchical reinforcement learning framework. However, this\napproach results in inflexibility of agents if options have an extended\nduration and are dynamic. While adjusting the executed option at each step\nimproves flexibility from a single-agent perspective, frequent changes in\noptions can induce inconsistency between an agent's actual behaviour and its\nbroadcast intention. In order to balance flexibility and predictability, we\npropose a dynamic termination Bellman equation that allows the agents to\nflexibly terminate their options. We evaluate our model empirically on a set of\nmulti-agent pursuit and taxi tasks, and show that our agents learn to adapt\nflexibly across scenarios that require different termination behaviours.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 16:54:49 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Han", "Dongge", ""], ["Boehmer", "Wendelin", ""], ["Wooldridge", "Michael", ""], ["Rogers", "Alex", ""]]}, {"id": "1910.09544", "submitter": "Daniel Muller", "authors": "Daniel Muller, Tshilidzi Marwala", "title": "Relative Net Utility and the Saint Petersburg Paradox", "comments": "extension of the discussion about the paradox, additional examples,\n  and proofreading", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.AI q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The famous Saint Petersburg Paradox (St. Petersburg Paradox) shows that the\ntheory of expected value does not capture the real-world economics of\ndecision-making problems. Over the years, many economic theories were developed\nto resolve the paradox and explain gaps in the economic value theory in the\nevaluation of economic decisions, the subjective utility of the expected\noutcomes, and risk aversion as observed in the game of the St. Petersburg\nParadox. In this paper, we use the concept of the relative net utility to\nresolve the St. Petersburg Paradox. Because the net utility concept is able to\nexplain both behavioral economics and the St. Petersburg Paradox, it is deemed\nto be a universal approach to handling utility. This paper shows how the\ninformation content of the notion of net utility value allows us to capture a\nbroader context of the impact of a decision's possible achievements. It\ndiscusses the necessary conditions that the utility function has to conform to\navoid the paradox. Combining these necessary conditions allows us to define the\ntheorem of indifference in the evaluation of economic decisions and to present\nthe role of the relative net utility and net utility polarity in a value\nrational decision-making process.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 07:01:14 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 05:15:45 GMT"}, {"version": "v3", "created": "Mon, 18 May 2020 11:45:02 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Muller", "Daniel", ""], ["Marwala", "Tshilidzi", ""]]}, {"id": "1910.09664", "submitter": "Valts Blukis", "authors": "Valts Blukis, Yannick Terme, Eyvind Niklasson, Ross A. Knepper, Yoav\n  Artzi", "title": "Learning to Map Natural Language Instructions to Physical Quadcopter\n  Control using Simulated Flight", "comments": "Conference on Robot Learning (CoRL) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a joint simulation and real-world learning framework for mapping\nnavigation instructions and raw first-person observations to continuous\ncontrol. Our model estimates the need for environment exploration, predicts the\nlikelihood of visiting environment positions during execution, and controls the\nagent to both explore and visit high-likelihood positions. We introduce\nSupervised Reinforcement Asynchronous Learning (SuReAL). Learning uses both\nsimulation and real environments without requiring autonomous flight in the\nphysical environment during training, and combines supervised learning for\npredicting positions to visit and reinforcement learning for continuous\ncontrol. We evaluate our approach on a natural language instruction-following\ntask with a physical quadcopter, and demonstrate effective execution and\nexploration behavior.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 21:19:33 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Blukis", "Valts", ""], ["Terme", "Yannick", ""], ["Niklasson", "Eyvind", ""], ["Knepper", "Ross A.", ""], ["Artzi", "Yoav", ""]]}, {"id": "1910.09713", "submitter": "Simon Le Cleac'h", "authors": "Simon Le Cleac'h, Mac Schwager, Zachary Manchester", "title": "ALGAMES: A Fast Solver for Constrained Dynamic Games", "comments": "10 pages, 8 figures, submitted to Robotics: Science and Systems\n  Conference (RSS) 2020", "journal-ref": "Proceedings of Robotics: Science and Systems, 2020", "doi": "10.15607/RSS.2020.XVI.091", "report-no": null, "categories": "cs.RO cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic games are an effective paradigm for dealing with the control of\nmultiple interacting actors. This paper introduces ALGAMES (Augmented\nLagrangian GAME-theoretic Solver), a solver that handles trajectory\noptimization problems with multiple actors and general nonlinear state and\ninput constraints. Its novelty resides in satisfying the first order optimality\nconditions with a quasi-Newton root-finding algorithm and rigorously enforcing\nconstraints using an augmented Lagrangian formulation. We evaluate our solver\nin the context of autonomous driving on scenarios with a strong level of\ninteractions between the vehicles. We assess the robustness of the solver using\nMonte Carlo simulations. It is able to reliably solve complex problems like\nramp merging with three vehicles three times faster than a state-of-the-art\nDDP-based approach. A model predictive control (MPC) implementation of the\nalgorithm demonstrates real-time performance on complex autonomous driving\nscenarios with an update frequency higher than 60 Hz.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 00:44:37 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 22:55:48 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Cleac'h", "Simon Le", ""], ["Schwager", "Mac", ""], ["Manchester", "Zachary", ""]]}, {"id": "1910.09715", "submitter": "David Heckerman", "authors": "David Heckerman and Chris Meek", "title": "Embedded Bayesian Network Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": "Microsoft Research Technical Report MS-TR-97-06, March 1997", "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-dimensional probability models for local distribution functions in a\nBayesian network include decision trees, decision graphs, and causal\nindependence models. We describe a new probability model for discrete Bayesian\nnetworks, which we call an embedded Bayesian network classifier or EBNC. The\nmodel for a node $Y$ given parents $\\bf X$ is obtained from a (usually\ndifferent) Bayesian network for $Y$ and $\\bf X$ in which $\\bf X$ need not be\nthe parents of $Y$. We show that an EBNC is a special case of a softmax\npolynomial regression model. Also, we show how to identify a non-redundant set\nof parameters for an EBNC, and describe an asymptotic approximation for\nlearning the structure of Bayesian networks that contain EBNCs. Unlike the\ndecision tree, decision graph, and causal independence models, we are unaware\nof a semantic justification for the use of these models. Experiments are needed\nto determine whether the models presented in this paper are useful in practice.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 01:02:51 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Heckerman", "David", ""], ["Meek", "Chris", ""]]}, {"id": "1910.09721", "submitter": "Samuel Alexander", "authors": "Samuel Allen Alexander", "title": "Intelligence via ultrafilters: structural properties of some\n  intelligence comparators of deterministic Legg-Hutter agents", "comments": "22 pages", "journal-ref": "Journal of Artificial General Intelligence 10(1) 24--45, 2019", "doi": "10.2478/jagi-2019-0003", "report-no": null, "categories": "cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Legg and Hutter, as well as subsequent authors, considered intelligent agents\nthrough the lens of interaction with reward-giving environments, attempting to\nassign numeric intelligence measures to such agents, with the guiding principle\nthat a more intelligent agent should gain higher rewards from environments in\nsome aggregate sense. In this paper, we consider a related question: rather\nthan measure numeric intelligence of one Legg- Hutter agent, how can we compare\nthe relative intelligence of two Legg-Hutter agents? We propose an elegant\nanswer based on the following insight: we can view Legg-Hutter agents as\ncandidates in an election, whose voters are environments, letting each\nenvironment vote (via its rewards) which agent (if either) is more intelligent.\nThis leads to an abstract family of comparators simple enough that we can prove\nsome structural theorems about them. It is an open question whether these\nstructural theorems apply to more practical intelligence measures.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 01:50:20 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 19:09:54 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Alexander", "Samuel Allen", ""]]}, {"id": "1910.09755", "submitter": "Yash Pote", "authors": "Yash Pote, Saurabh Joshi and Kuldeep S. Meel", "title": "Phase Transition Behavior of Cardinality and XOR Constraints", "comments": null, "journal-ref": "https://doi.org/10.24963/ijcai.2019/162", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The runtime performance of modern SAT solvers is deeply connected to the\nphase transition behavior of CNF formulas. While CNF solving has witnessed\nsignificant runtime improvement over the past two decades, the same does not\nhold for several other classes such as the conjunction of cardinality and XOR\nconstraints, denoted as CARD-XOR formulas. The problem of determining the\nsatisfiability of CARD-XOR formulas is a fundamental problem with a wide\nvariety of applications ranging from discrete integration in the field of\nartificial intelligence to maximum likelihood decoding in coding theory. The\nruntime behavior of random CARD-XOR formulas is unexplored in prior work. In\nthis paper, we present the first rigorous empirical study to characterize the\nruntime behavior of 1-CARD-XOR formulas. We show empirical evidence of a\nsurprising phase-transition that follows a non-linear tradeoff between CARD and\nXOR constraints.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 03:53:00 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Pote", "Yash", ""], ["Joshi", "Saurabh", ""], ["Meel", "Kuldeep S.", ""]]}, {"id": "1910.09760", "submitter": "Weiguo Zheng", "authors": "Weiguo Zheng and Mei Zhang", "title": "Question Answering over Knowledge Graphs via Structural Query Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language question answering over knowledge graphs is an important and\ninteresting task as it enables common users to gain accurate answers in an easy\nand intuitive manner. However, it remains a challenge to bridge the gap between\nunstructured questions and structured knowledge graphs. To address the problem,\na natural discipline is building a structured query to represent the input\nquestion. Searching the structured query over the knowledge graph can produce\nanswers to the question. Distinct from the existing methods that are based on\nsemantic parsing or templates, we propose an effective approach powered by a\nnovel notion, structural query pattern, in this paper. Given an input question,\nwe first generate its query sketch that is compatible with the underlying\nstructure of the knowledge graph. Then, we complete the query graph by labeling\nthe nodes and edges under the guidance of the structural query pattern.\nFinally, answers can be retrieved by executing the constructed query graph over\nthe knowledge graph. Evaluations on three question answering benchmarks show\nthat our proposed approach outperforms state-of-the-art methods significantly.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 04:21:06 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 10:33:13 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Zheng", "Weiguo", ""], ["Zhang", "Mei", ""]]}, {"id": "1910.09879", "submitter": "Weiguo Zheng", "authors": "Weiguo Zheng and Mei Zhang", "title": "Towards Combinational Relation Linking over Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a natural language phrase, relation linking aims to find a relation\n(predicate or property) from the underlying knowledge graph to match the\nphrase. It is very useful in many applications, such as natural language\nquestion answering, personalized recommendation and text summarization.\nHowever, the previous relation linking algorithms usually produce a single\nrelation for the input phrase and pay little attention to a more general and\nchallenging problem, i.e., combinational relation linking that extracts a\nsubgraph pattern to match the compound phrase (e.g. mother-in-law). In this\npaper, we focus on the task of combinational relation linking over knowledge\ngraphs. To resolve the problem, we design a systematic method based on the\ndata-driven relation assembly technique, which is performed under the guidance\nof meta patterns. We also introduce external knowledge to enhance the system\nunderstanding ability. Finally, we conduct extensive experiments over the real\nknowledge graph to study the performance of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 10:35:41 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 10:31:25 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Zheng", "Weiguo", ""], ["Zhang", "Mei", ""]]}, {"id": "1910.09956", "submitter": "Charlotte Blease Dr", "authors": "Charlotte Blease, Cosima Locher, Marisa Leon-Carlyle, P. Murali\n  Doraiswamy", "title": "Artificial Intelligence and the Future of Psychiatry: Qualitative\n  Findings from a Global Physician Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The potential for machine learning to disrupt the medical profession is the\nsubject of ongoing debate within biomedical informatics. This study aimed to\nexplore psychiatrists' opinions about the potential impact of innovations in\nartificial intelligence and machine learning on psychiatric practice. In Spring\n2019, we conducted a web-based survey of 791 psychiatrists from 22 countries\nworldwide. The survey measured opinions about the likelihood future technology\nwould fully replace physicians in performing ten key psychiatric tasks. This\nstudy involved qualitative descriptive analysis of written response to three\nopen-ended questions in the survey. Comments were classified into four major\ncategories in relation to the impact of future technology on\npatient-psychiatric interactions, the quality of patient medical care, the\nprofession of psychiatry, and health systems. Overwhelmingly, psychiatrists\nwere skeptical that technology could fully replace human empathy. Many\npredicted that 'man and machine' would increasingly collaborate in undertaking\nclinical decisions, with mixed opinions about the benefits and harms of such an\narrangement. Participants were optimistic that technology might improve\nefficiencies and access to care, and reduce costs. Ethical and regulatory\nconsiderations received limited attention. This study presents timely\ninformation of psychiatrists' view about the scope of artificial intelligence\nand machine learning on psychiatric practice. Psychiatrists expressed divergent\nviews about the value and impact of future technology with worrying omissions\nabout practice guidelines, and ethical and regulatory issues.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 13:25:18 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Blease", "Charlotte", ""], ["Locher", "Cosima", ""], ["Leon-Carlyle", "Marisa", ""], ["Doraiswamy", "P. Murali", ""]]}, {"id": "1910.09959", "submitter": "Yijiong Lin", "authors": "Yijiong Lin, Jiancong Huang, Matthieu Zimmer, Juan Rojas, and Paul\n  Weng", "title": "Towards More Sample Efficiency in Reinforcement Learning with Data\n  Augmentation", "comments": "NeurIPS 2019 Workshop on Robot Learning: Control and Interaction in\n  the Real World (accepted after double-blind peer review). arXiv admin note:\n  substantial text overlap with arXiv:1909.10707", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) is a promising approach for adaptive robot\ncontrol, but its current application to robotics is currently hindered by high\nsample requirements. We propose two novel data augmentation techniques for DRL\nin order to reuse more efficiently observed data. The first one called\nKaleidoscope Experience Replay exploits reflectional symmetries, while the\nsecond called Goal-augmented Experience Replay takes advantage of lax goal\ndefinitions. Our preliminary experimental results show a large increase in\nlearning speed.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 03:37:05 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 03:13:48 GMT"}, {"version": "v3", "created": "Fri, 15 Nov 2019 09:10:53 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Lin", "Yijiong", ""], ["Huang", "Jiancong", ""], ["Zimmer", "Matthieu", ""], ["Rojas", "Juan", ""], ["Weng", "Paul", ""]]}, {"id": "1910.09986", "submitter": "Haodi Zhang", "authors": "Haodi Zhang, Zihang Gao, Yi Zhou, Hao Zhang, Kaishun Wu, Fangzhen Lin", "title": "Faster and Safer Training by Embedding High-Level Knowledge into Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has been successfully used in many dynamic\ndecision making domains, especially those with very large state spaces.\nHowever, it is also well-known that deep reinforcement learning can be very\nslow and resource intensive. The resulting system is often brittle and\ndifficult to explain. In this paper, we attempt to address some of these\nproblems by proposing a framework of Rule-interposing Learning (RIL) that\nembeds high level rules into the deep reinforcement learning. With some good\nrules, this framework not only can accelerate the learning process, but also\nkeep it away from catastrophic explorations, thus making the system relatively\nstable even during the very early stage of training. Moreover, given the rules\nare high level and easy to interpret, they can be easily maintained, updated\nand shared with other similar tasks.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 13:56:47 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Zhang", "Haodi", ""], ["Gao", "Zihang", ""], ["Zhou", "Yi", ""], ["Zhang", "Hao", ""], ["Wu", "Kaishun", ""], ["Lin", "Fangzhen", ""]]}, {"id": "1910.09998", "submitter": "Tingxiang Fan", "authors": "Tingxiang Fan, Pinxin Long, Wenxi Liu, Jia Pan, Ruigang Yang, Dinesh\n  Manocha", "title": "Learning Resilient Behaviors for Navigation Under Uncertainty", "comments": "accepted to ICRA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has great potential to acquire complex, adaptive\nbehaviors for autonomous agents automatically. However, the underlying neural\nnetwork polices have not been widely deployed in real-world applications,\nespecially in these safety-critical tasks (e.g., autonomous driving). One of\nthe reasons is that the learned policy cannot perform flexible and resilient\nbehaviors as traditional methods to adapt to diverse environments. In this\npaper, we consider the problem that a mobile robot learns adaptive and\nresilient behaviors for navigating in unseen uncertain environments while\navoiding collisions. We present a novel approach for uncertainty-aware\nnavigation by introducing an uncertainty-aware predictor to model the\nenvironmental uncertainty, and we propose a novel uncertainty-aware navigation\nnetwork to learn resilient behaviors in the prior unknown environments. To\ntrain the proposed uncertainty-aware network more stably and efficiently, we\npresent the temperature decay training paradigm, which balances exploration and\nexploitation during the training process. Our experimental evaluation\ndemonstrates that our approach can learn resilient behaviors in diverse\nenvironments and generate adaptive trajectories according to environmental\nuncertainties.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 14:15:20 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 08:58:23 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 07:15:15 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Fan", "Tingxiang", ""], ["Long", "Pinxin", ""], ["Liu", "Wenxi", ""], ["Pan", "Jia", ""], ["Yang", "Ruigang", ""], ["Manocha", "Dinesh", ""]]}, {"id": "1910.10021", "submitter": "Thibaut Vidal", "authors": "Jordana Mecler, Anand Subramanian, Thibaut Vidal", "title": "A simple and effective hybrid genetic search for the job sequencing and\n  tool switching problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The job sequencing and tool switching problem (SSP) has been extensively\nstudied in the field of operations research, due to its practical relevance and\nmethodological interest. Given a machine that can load a limited amount of\ntools simultaneously and a number of jobs that require a subset of the\navailable tools, the SSP seeks a job sequence that minimizes the number of tool\nswitches in the machine. To solve this problem, we propose a simple and\nefficient hybrid genetic search based on a generic solution representation, a\ntailored decoding operator, efficient local searches and diversity management\ntechniques. To guide the search, we introduce a secondary objective designed to\nbreak ties. These techniques allow to explore structurally different solutions\nand escape local optima. As shown in our computational experiments on classical\nbenchmark instances, our algorithm significantly outperforms all previous\napproaches while remaining simple to apprehend and easy to implement. We\nfinally report results on a new set of larger instances to stimulate future\nresearch and comparative analyses.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 21:41:06 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Mecler", "Jordana", ""], ["Subramanian", "Anand", ""], ["Vidal", "Thibaut", ""]]}, {"id": "1910.10034", "submitter": "Matthew Walter", "authors": "Siddharth Patki, Ethan Fahnestock, Thomas M. Howard, Matthew R. Walter", "title": "Language-guided Semantic Mapping and Mobile Manipulation in Partially\n  Observable Environments", "comments": "To appear at 2019 Conference on Robot Learning (CoRL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in data-driven models for grounded language understanding\nhave enabled robots to interpret increasingly complex instructions. Two\nfundamental limitations of these methods are that most require a full model of\nthe environment to be known a priori, and they attempt to reason over a world\nrepresentation that is flat and unnecessarily detailed, which limits\nscalability. Recent semantic mapping methods address partial observability by\nexploiting language as a sensor to infer a distribution over topological,\nmetric and semantic properties of the environment. However, maintaining a\ndistribution over highly detailed maps that can support grounding of diverse\ninstructions is computationally expensive and hinders real-time human-robot\ncollaboration. We propose a novel framework that learns to adapt perception\naccording to the task in order to maintain compact distributions over semantic\nmaps. Experiments with a mobile manipulator demonstrate more efficient\ninstruction following in a priori unknown environments.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 15:09:02 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Patki", "Siddharth", ""], ["Fahnestock", "Ethan", ""], ["Howard", "Thomas M.", ""], ["Walter", "Matthew R.", ""]]}, {"id": "1910.10045", "submitter": "Javier Del Ser Dr.", "authors": "Alejandro Barredo Arrieta, Natalia D\\'iaz-Rodr\\'iguez, Javier Del Ser,\n  Adrien Bennetot, Siham Tabik, Alberto Barbado, Salvador Garc\\'ia, Sergio\n  Gil-L\\'opez, Daniel Molina, Richard Benjamins, Raja Chatila, Francisco\n  Herrera", "title": "Explainable Artificial Intelligence (XAI): Concepts, Taxonomies,\n  Opportunities and Challenges toward Responsible AI", "comments": "67 pages, 13 figures, accepted for its publication in Information\n  Fusion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last years, Artificial Intelligence (AI) has achieved a notable\nmomentum that may deliver the best of expectations over many application\nsectors across the field. For this to occur, the entire community stands in\nfront of the barrier of explainability, an inherent problem of AI techniques\nbrought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not\npresent in the last hype of AI. Paradigms underlying this problem fall within\nthe so-called eXplainable AI (XAI) field, which is acknowledged as a crucial\nfeature for the practical deployment of AI models. This overview examines the\nexisting literature in the field of XAI, including a prospect toward what is\nyet to be reached. We summarize previous efforts to define explainability in\nMachine Learning, establishing a novel definition that covers prior conceptual\npropositions with a major focus on the audience for which explainability is\nsought. We then propose and discuss about a taxonomy of recent contributions\nrelated to the explainability of different Machine Learning models, including\nthose aimed at Deep Learning methods for which a second taxonomy is built. This\nliterature analysis serves as the background for a series of challenges faced\nby XAI, such as the crossroads between data fusion and explainability. Our\nprospects lead toward the concept of Responsible Artificial Intelligence,\nnamely, a methodology for the large-scale implementation of AI methods in real\norganizations with fairness, model explainability and accountability at its\ncore. Our ultimate goal is to provide newcomers to XAI with a reference\nmaterial in order to stimulate future research advances, but also to encourage\nexperts and professionals from other disciplines to embrace the benefits of AI\nin their activity sectors, without any prior bias for its lack of\ninterpretability.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 15:27:30 GMT"}, {"version": "v2", "created": "Thu, 26 Dec 2019 08:09:25 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Arrieta", "Alejandro Barredo", ""], ["D\u00edaz-Rodr\u00edguez", "Natalia", ""], ["Del Ser", "Javier", ""], ["Bennetot", "Adrien", ""], ["Tabik", "Siham", ""], ["Barbado", "Alberto", ""], ["Garc\u00eda", "Salvador", ""], ["Gil-L\u00f3pez", "Sergio", ""], ["Molina", "Daniel", ""], ["Benjamins", "Richard", ""], ["Chatila", "Raja", ""], ["Herrera", "Francisco", ""]]}, {"id": "1910.10232", "submitter": "Luckeciano Melo", "authors": "Luckeciano C. Melo, Marcos R. O. A. Maximo, Adilson Marques da Cunha", "title": "Bottom-Up Meta-Policy Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite of the recent progress in agents that learn through interaction,\nthere are several challenges in terms of sample efficiency and generalization\nacross unseen behaviors during training. To mitigate these problems, we propose\nand apply a first-order Meta-Learning algorithm called Bottom-Up Meta-Policy\nSearch (BUMPS), which works with two-phase optimization procedure: firstly, in\na meta-training phase, it distills few expert policies to create a meta-policy\ncapable of generalizing knowledge to unseen tasks during training; secondly, it\napplies a fast adaptation strategy named Policy Filtering, which evaluates few\npolicies sampled from the meta-policy distribution and selects which best\nsolves the task. We conducted all experiments in the RoboCup 3D Soccer\nSimulation domain, in the context of kick motion learning. We show that, given\nour experimental setup, BUMPS works in scenarios where simple multi-task\nReinforcement Learning does not. Finally, we performed experiments in a way to\nevaluate each component of the algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 21:12:54 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 11:41:39 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Melo", "Luckeciano C.", ""], ["Maximo", "Marcos R. O. A.", ""], ["da Cunha", "Adilson Marques", ""]]}, {"id": "1910.10255", "submitter": "Hanchen Wang", "authors": "Hanchen Wang, Nina Grgic-Hlaca, Preethi Lahoti, Krishna P. Gummadi,\n  Adrian Weller", "title": "An Empirical Study on Learning Fairness Metrics for COMPAS Data with\n  Human Supervision", "comments": "Accepted at NeurIPS 2019 HCML Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The notion of individual fairness requires that similar people receive\nsimilar treatment. However, this is hard to achieve in practice since it is\ndifficult to specify the appropriate similarity metric. In this work, we\nattempt to learn such similarity metric from human annotated data. We gather a\nnew dataset of human judgments on a criminal recidivism prediction (COMPAS)\ntask. By assuming the human supervision obeys the principle of individual\nfairness, we leverage prior work on metric learning, evaluate the performance\nof several metric learning methods on our dataset, and show that the learned\nmetrics outperform the Euclidean and Precision metric under various criteria.\nWe do not provide a way to directly learn a similarity metric satisfying the\nindividual fairness, but to provide an empirical study on how to derive the\nsimilarity metric from human supervisors, then future work can use this as a\ntool to understand human supervision.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 22:22:59 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 14:47:27 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Wang", "Hanchen", ""], ["Grgic-Hlaca", "Nina", ""], ["Lahoti", "Preethi", ""], ["Gummadi", "Krishna P.", ""], ["Weller", "Adrian", ""]]}, {"id": "1910.10258", "submitter": "Seng Loke", "authors": "Seng W. Loke", "title": "Robot-Friendly Cities", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots are increasingly tested in public spaces, towards a future where urban\nenvironments are not only for humans but for autonomous systems. While robots\nare promising, for convenience and efficiency, there are challenges associated\nwith building cities crowded with machines. This paper provides an overview of\nthe problems and some solutions, and calls for greater attention on this\nmatter.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 22:28:25 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Loke", "Seng W.", ""]]}, {"id": "1910.10346", "submitter": "Yanhong Annie Liu", "authors": "Yanhong A. Liu and Scott D. Stoller", "title": "Knowledge of Uncertain Worlds: Programming with Logical Constraints", "comments": null, "journal-ref": "Journal of Logic and Computation. 2021", "doi": "10.1093/logcom/exaa077", "report-no": null, "categories": "cs.LO cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming with logic for sophisticated applications must deal with\nrecursion and negation, which together have created significant challenges in\nlogic, leading to many different, conflicting semantics of rules. This paper\ndescribes a unified language, DA logic, for design and analysis logic, based on\nthe unifying founded semantics and constraint semantics, that support the power\nand ease of programming with different intended semantics. The key idea is to\nprovide meta-constraints, supports the use of uncertain information in the form\nof either undefined values or possible combinations of values or both, and\npromote the use of knowledge units that can be instantiated by any new\npredicates, including predicates with additional arguments.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 04:30:51 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 03:49:52 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 03:44:58 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Liu", "Yanhong A.", ""], ["Stoller", "Scott D.", ""]]}, {"id": "1910.10363", "submitter": "Yan Gao", "authors": "Yan Gao, Jian-Guang Lou, Dongmei Zhang", "title": "A Hybrid Semantic Parsing Approach for Tabular Data Analysis", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach to translating natural language\nquestions to SQL queries for given tables, which meets three requirements as a\nreal-world data analysis application: cross-domain, multilingualism and\nenabling quick-start. Our proposed approach consists of: (1) a novel data\nabstraction step before the parser to make parsing table-agnosticism; (2) a set\nof semantic rules for parsing abstracted data-analysis questions to\nintermediate logic forms as tree derivations to reduce the search space; (3) a\nneural-based model as a local scoring function on a span-based semantic parser\nfor structured optimization and efficient inference. Experiments show that our\napproach outperforms state-of-the-art algorithms on a large open benchmark\ndataset WikiSQL. We also achieve promising results on a small dataset for more\ncomplex queries in both English and Chinese, which demonstrates our language\nexpansion and quick-start ability.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 05:41:39 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 05:05:39 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Gao", "Yan", ""], ["Lou", "Jian-Guang", ""], ["Zhang", "Dongmei", ""]]}, {"id": "1910.10380", "submitter": "Dhananjay Raju", "authors": "Dhananjay Raju, Suda Bharadwaj and Ufuk Topcu", "title": "Online Synthesis for Runtime Enforcement of Safety in Multi-Agent\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A shield is attached to a system to guarantee safety by correcting the\nsystem's behavior at runtime. Existing methods that employ design-time\nsynthesis of shields do not scale to multi-agent systems. Moreover, such\nshields are typically implemented in a centralized manner, requiring global\ninformation on the state of all agents in the system. We address these\nlimitations through a new approach where the shields are synthesized at runtime\nand do not require global information. There is a shield onboard every agent,\nwhich can only modify the behavior of the corresponding agent. In this\napproach, which is fundamentally decentralized, the shield on every agent has\ntwo components: a pathfinder that corrects the behavior of the agent and an\nordering mechanism that dynamically modifies the priority of the agent. The\ncurrent priority determines if the shield uses the pathfinder to modify\nbehavior of the agent. We derive an upper bound on the maximum deviation for\nany agent from its original behavior. We prove that the worst-case synthesis\ntime is quadratic in the number of agents at runtime as opposed to exponential\nat design-time for existing methods. We test the performance of the\ndecentralized, runtime shield synthesis approach on a collision-avoidance\nproblem. For 50 agents in a 50x50 grid, the synthesis at runtime requires a few\nseconds per agent whenever a potential collision is detected. In contrast, the\ncentralized design-time synthesis of shields for a similar setting is\nintractable beyond 4 agents in a 5x5 grid.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 06:32:30 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 20:24:14 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Raju", "Dhananjay", ""], ["Bharadwaj", "Suda", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1910.10393", "submitter": "Shilpesh Garg", "authors": "Shilpesh Garg", "title": "RTOP: A Conceptual and Computational Framework for General Intelligence", "comments": "17 pages, added architecture and flow diagram", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel general intelligence model is proposed with three types of learning.\nA unified sequence of the foreground percept trace and the command trace\ntranslates into direct and time-hop observation paths to form the basis of Raw\nlearning. Raw learning includes the formation of image-image associations,\nwhich lead to the perception of temporal and spatial relationships among\nobjects and object parts; and the formation of image-audio associations, which\nserve as the building blocks of language. Offline identification of similar\nsegments in the observation paths and their subsequent reduction into a common\nsegment through merging of memory nodes leads to Generalized learning.\nGeneralization includes the formation of interpolated sensory nodes for robust\nand generic matching, the formation of sensory properties nodes for specific\nmatching and superimposition, and the formation of group nodes for simpler\nlogic pathways. Online superimposition of memory nodes across multiple\npredictions, primarily the superimposition of images on the internal projection\ncanvas, gives rise to Innovative learning and thought. The learning of actions\nhappens the same way as raw learning while the action determination happens\nthrough the utility model built into the raw learnings, the utility function\nbeing the pleasure and pain of the physical senses.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 07:40:19 GMT"}, {"version": "v2", "created": "Sat, 11 Jan 2020 09:56:58 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Garg", "Shilpesh", ""]]}, {"id": "1910.10481", "submitter": "Christian Huyck", "authors": "Dan Diaper and Chris Huyck", "title": "The Task Analysis Cell Assembly Perspective", "comments": "39 Pages; 94 with two appendices; third appendix is a linked dynamic\n  file", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An entirely novel synthesis combines the applied cognitive psychology of a\ntask analytic approach with a neural cell assembly perspective that models both\nbrain and mind function during task performance; similar cell assemblies could\nbe implemented as an artificially intelligent neural network. A simplified cell\nassembly model is introduced and this leads to several new representational\nformats that, in combination, are demonstrated as suitable for analysing tasks.\nThe advantages of using neural models are exposed and compared with previous\nresearch that has used symbolic artificial intelligence production systems,\nwhich make no attempt to model neurophysiology. For cognitive scientists, the\napproach provides an easy and practical introduction to thinking about brains,\nminds and artificial intelligence in terms of cell assemblies. In the future,\nsubsequent developments have the potential to lead to a new, general theory of\npsychology and neurophysiology, supported by cell assembly based artificial\nintelligences.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 11:51:13 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 08:24:20 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Diaper", "Dan", ""], ["Huyck", "Chris", ""]]}, {"id": "1910.10486", "submitter": "Haochen Liu", "authors": "Haochen Liu, Jamell Dacon, Wenqi Fan, Hui Liu, Zitao Liu and Jiliang\n  Tang", "title": "Does Gender Matter? Towards Fairness in Dialogue Systems", "comments": "Accepted by COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there are increasing concerns about the fairness of Artificial\nIntelligence (AI) in real-world applications such as computer vision and\nrecommendations. For example, recognition algorithms in computer vision are\nunfair to black people such as poorly detecting their faces and inappropriately\nidentifying them as \"gorillas\". As one crucial application of AI, dialogue\nsystems have been extensively applied in our society. They are usually built\nwith real human conversational data; thus they could inherit some fairness\nissues which are held in the real world. However, the fairness of dialogue\nsystems has not been well investigated. In this paper, we perform a pioneering\nstudy about the fairness issues in dialogue systems. In particular, we\nconstruct a benchmark dataset and propose quantitative measures to understand\nfairness in dialogue models. Our studies demonstrate that popular dialogue\nmodels show significant prejudice towards different genders and races. Besides,\nto mitigate the bias in dialogue systems, we propose two simple but effective\ndebiasing methods. Experiments show that our methods can reduce the bias in\ndialogue systems significantly. The dataset and the implementation are released\nto foster fairness research in dialogue systems.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 22:17:02 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 15:12:39 GMT"}, {"version": "v3", "created": "Sat, 31 Oct 2020 19:04:07 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Liu", "Haochen", ""], ["Dacon", "Jamell", ""], ["Fan", "Wenqi", ""], ["Liu", "Hui", ""], ["Liu", "Zitao", ""], ["Tang", "Jiliang", ""]]}, {"id": "1910.10492", "submitter": "Haozheng Luo", "authors": "Haozheng Luo, Ningwei Liu, Charles Feng", "title": "Question Classification with Deep Contextualized Transformer", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-73103-8_32", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The latest work for Question and Answer problems is to use the Stanford Parse\nTree. We build on prior work and develop a new method to handle the Question\nand Answer problem with the Deep Contextualized Transformer to manage some\naberrant expressions. We also conduct extensive evaluations of the SQuAD and\nSwDA dataset and show significant improvement over QA problem classification of\nindustry needs. We also investigate the impact of different models for the\naccuracy and efficiency of the problem answers. It shows that our new method is\nmore effective for solving QA problems with higher accuracy\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 23:00:22 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 17:15:23 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Luo", "Haozheng", ""], ["Liu", "Ningwei", ""], ["Feng", "Charles", ""]]}, {"id": "1910.10537", "submitter": "William Clements", "authors": "Reda Bahi Slaoui, William R. Clements, Jakob N. Foerster, S\\'ebastien\n  Toth", "title": "Robust Visual Domain Randomization for Reinforcement Learning", "comments": "Accepted at the BeTR-RL Workshop at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Producing agents that can generalize to a wide range of visually different\nenvironments is a significant challenge in reinforcement learning. One method\nfor overcoming this issue is visual domain randomization, whereby at the start\nof each training episode some visual aspects of the environment are randomized\nso that the agent is exposed to many possible variations. However, domain\nrandomization is highly inefficient and may lead to policies with high variance\nacross domains. Instead, we propose a regularization method whereby the agent\nis only trained on one variation of the environment, and its learned state\nrepresentations are regularized during training to be invariant across domains.\nWe conduct experiments that demonstrate that our technique leads to more\nefficient and robust learning than standard domain randomization, while\nachieving equal generalization scores.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 12:58:08 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 09:11:04 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Slaoui", "Reda Bahi", ""], ["Clements", "William R.", ""], ["Foerster", "Jakob N.", ""], ["Toth", "S\u00e9bastien", ""]]}, {"id": "1910.10547", "submitter": "Tahar M Kechadi", "authors": "Nhien-An Le-Khac, Lamine M. Aouad, M-Tahar Kechadi", "title": "Knowledge Map: Toward a New Approach Supporting the Knowledge Management\n  in Distributed Data Mining", "comments": "Third International Conference on Autonomic and Autonomous Systems\n  (ICAS'07)", "journal-ref": null, "doi": "10.1109/CONIELECOMP.2007.80", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed data mining (DDM) deals with the problem of finding patterns or\nmodels, called knowledge, in an environment with distributed data and\ncomputations. Today, a massive amounts of data which are often geographically\ndistributed and owned by different organisation are being mined. As\nconsequence, a large mount of knowledge are being produced. This causes\nproblems of not only knowledge management but also visualization in data\nmining. Besides, the main aim of DDM is to exploit fully the benefit of\ndistributed data analysis while minimising the communication. Existing DDM\ntechniques perform partial analysis of local data at individual sites and then\ngenerate a global model by aggregating these local results. These two steps are\nnot independent since naive approaches to local analysis may produce an\nincorrect and ambiguous global data model. The integrating and cooperating of\nthese two steps need an effective knowledge management, concretely an efficient\nmap of knowledge in order to take the advantage of mined knowledge to guide\nmining the data. In this paper, we present \"knowledge map\", a representation of\nknowledge about mined knowledge. This new approach aims to manage efficiently\nmined knowledge in large scale distributed platform such as Grid. This\nknowledge map is used to facilitate not only the visualization, evaluation of\nmining results but also the coordinating of local mining process and existing\nknowledge to increase the accuracy of final model.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 13:14:18 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Le-Khac", "Nhien-An", ""], ["Aouad", "Lamine M.", ""], ["Kechadi", "M-Tahar", ""]]}, {"id": "1910.10562", "submitter": "Chirag Gupta", "authors": "Chirag Gupta, Arun K. Kuchibhotla, Aaditya K. Ramdas", "title": "Nested conformal prediction and quantile out-of-bag ensemble methods", "comments": "38 pages, 5 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conformal prediction is a popular tool for providing valid prediction sets\nfor classification and regression problems, without relying on any\ndistributional assumptions on the data. While the traditional description of\nconformal prediction starts with a nonconformity score, we provide an alternate\n(but equivalent) view that starts with a sequence of nested sets and calibrates\nthem to find a valid prediction set. The nested framework subsumes all\nnonconformity scores, including recent proposals based on quantile regression\nand density estimation. While these ideas were originally derived based on\nsample splitting, our framework seamlessly extends them to other aggregation\nschemes like cross-conformal, jackknife+ and out-of-bag methods. We use the\nframework to derive a new algorithm (QOOB, pronounced cube) that combines four\nideas: quantile regression, cross-conformalization, ensemble methods and\nout-of-bag predictions. We develop a computationally efficient implementation\nof cross-conformal, that is also used by QOOB. In a detailed numerical\ninvestigation, QOOB performs either the best or close to the best on all\nsimulated and real datasets.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 13:44:38 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 15:26:16 GMT"}, {"version": "v3", "created": "Fri, 12 Mar 2021 03:29:28 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Gupta", "Chirag", ""], ["Kuchibhotla", "Arun K.", ""], ["Ramdas", "Aaditya K.", ""]]}, {"id": "1910.10579", "submitter": "Richard Preen", "authors": "Richard J. Preen and Stewart W. Wilson and Larry Bull", "title": "Autoencoding with a Classifier System", "comments": null, "journal-ref": "IEEE Transactions on Evolutionary Computation (2021)", "doi": "10.1109/TEVC.2021.3079320", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoencoders are data-specific compression algorithms learned automatically\nfrom examples. The predominant approach has been to construct single large\nglobal models that cover the domain. However, training and evaluating models of\nincreasing size comes at the price of additional time and computational cost.\nConditional computation, sparsity, and model pruning techniques can reduce\nthese costs while maintaining performance. Learning classifier systems (LCS)\nare a framework for adaptively subdividing input spaces into an ensemble of\nsimpler local approximations that together cover the domain. LCS perform\nconditional computation through the use of a population of individual\ngating/guarding components, each associated with a local approximation. This\narticle explores the use of an LCS to adaptively decompose the input domain\ninto a collection of small autoencoders where local solutions of different\ncomplexity may emerge. In addition to benefits in convergence time and\ncomputational cost, it is shown possible to reduce code size as well as the\nresulting decoder computational cost when compared with the global model\nequivalent.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 14:27:29 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 17:51:44 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 10:09:48 GMT"}, {"version": "v4", "created": "Thu, 6 Aug 2020 14:32:16 GMT"}, {"version": "v5", "created": "Tue, 27 Oct 2020 17:55:15 GMT"}, {"version": "v6", "created": "Mon, 2 Nov 2020 09:59:31 GMT"}, {"version": "v7", "created": "Thu, 25 Feb 2021 16:14:08 GMT"}, {"version": "v8", "created": "Wed, 12 May 2021 13:20:17 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Preen", "Richard J.", ""], ["Wilson", "Stewart W.", ""], ["Bull", "Larry", ""]]}, {"id": "1910.10593", "submitter": "Petar Veli\\v{c}kovi\\'c", "authors": "Petar Veli\\v{c}kovi\\'c, Rex Ying, Matilde Padovano, Raia Hadsell,\n  Charles Blundell", "title": "Neural Execution of Graph Algorithms", "comments": "To appear at ICLR 2020. 13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) are a powerful representational tool for solving\nproblems on graph-structured inputs. In almost all cases so far, however, they\nhave been applied to directly recovering a final solution from raw inputs,\nwithout explicit guidance on how to structure their problem-solving. Here,\ninstead, we focus on learning in the space of algorithms: we train several\nstate-of-the-art GNN architectures to imitate individual steps of classical\ngraph algorithms, parallel (breadth-first search, Bellman-Ford) as well as\nsequential (Prim's algorithm). As graph algorithms usually rely on making\ndiscrete decisions within neighbourhoods, we hypothesise that\nmaximisation-based message passing neural networks are best-suited for such\nobjectives, and validate this claim empirically. We also demonstrate how\nlearning in the space of algorithms can yield new opportunities for positive\ntransfer between tasks---showing how learning a shortest-path algorithm can be\nsubstantially improved when simultaneously learning a reachability algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 14:50:45 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 16:47:33 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Veli\u010dkovi\u0107", "Petar", ""], ["Ying", "Rex", ""], ["Padovano", "Matilde", ""], ["Hadsell", "Raia", ""], ["Blundell", "Charles", ""]]}, {"id": "1910.10597", "submitter": "Aditya Modi", "authors": "Aditya Modi, Nan Jiang, Ambuj Tewari, Satinder Singh", "title": "Sample Complexity of Reinforcement Learning using Linearly Combined\n  Model Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) methods have been shown to be capable of learning\nintelligent behavior in rich domains. However, this has largely been done in\nsimulated domains without adequate focus on the process of building the\nsimulator. In this paper, we consider a setting where we have access to an\nensemble of pre-trained and possibly inaccurate simulators (models). We\napproximate the real environment using a state-dependent linear combination of\nthe ensemble, where the coefficients are determined by the given state features\nand some unknown parameters. Our proposed algorithm provably learns a\nnear-optimal policy with a sample complexity polynomial in the number of\nunknown parameters, and incurs no dependence on the size of the state (or\naction) space. As an extension, we also consider the more challenging problem\nof model selection, where the state features are unknown and can be chosen from\na large candidate set. We provide exponential lower bounds that illustrate the\nfundamental hardness of this problem, and develop a provably efficient\nalgorithm under additional natural assumptions.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 15:02:30 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Modi", "Aditya", ""], ["Jiang", "Nan", ""], ["Tewari", "Ambuj", ""], ["Singh", "Satinder", ""]]}, {"id": "1910.10620", "submitter": "Luckeciano Melo", "authors": "Luckeciano C. Melo and Marcos R. O. A. Maximo", "title": "Learning Humanoid Robot Running Skills through Proximal Policy\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the current level of evolution of Soccer 3D, motion control is a key\nfactor in team's performance. Recent works takes advantages of model-free\napproaches based on Machine Learning to exploit robot dynamics in order to\nobtain faster locomotion skills, achieving running policies and, therefore,\nopening a new research direction in the Soccer 3D environment.\n  In this work, we present a methodology based on Deep Reinforcement Learning\nthat learns running skills without any prior knowledge, using a neural network\nwhose inputs are related to robot's dynamics. Our results outperformed the\nprevious state-of-the-art sprint velocity reported in Soccer 3D literature by a\nsignificant margin. It also demonstrated improvement in sample efficiency,\nbeing able to learn how to run in just few hours.\n  We reported our results analyzing the training procedure and also evaluating\nthe policies in terms of speed, reliability and human similarity. Finally, we\npresented key factors that lead us to improve previous results and shared some\nideas for future work.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 13:08:11 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Melo", "Luckeciano C.", ""], ["Maximo", "Marcos R. O. A.", ""]]}, {"id": "1910.10777", "submitter": "Hagit Grushka-Cohen", "authors": "Hagit Grushka-Cohen, Ofer Biller, Oded Sofer, Lior Rokach and Bracha\n  Shapira", "title": "Diversifying Database Activity Monitoring with Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Database activity monitoring (DAM) systems are commonly used by organizations\nto protect the organizational data, knowledge and intellectual properties. In\norder to protect organizations database DAM systems have two main roles,\nmonitoring (documenting activity) and alerting to anomalous activity. Due to\nhigh-velocity streams and operating costs, such systems are restricted to\nexamining only a sample of the activity. Current solutions use policies,\nmanually crafted by experts, to decide which transactions to monitor and log.\nThis limits the diversity of the data collected. Bandit algorithms, which use\nreward functions as the basis for optimization while adding diversity to the\nrecommended set, have gained increased attention in recommendation systems for\nimproving diversity.\n  In this work, we redefine the data sampling problem as a special case of the\nmulti-armed bandit (MAB) problem and present a novel algorithm, which combines\nexpert knowledge with random exploration. We analyze the effect of diversity on\ncoverage and downstream event detection tasks using a simulated dataset. In\ndoing so, we find that adding diversity to the sampling using the bandit-based\napproach works well for this task and maximizing population coverage without\ndecreasing the quality in terms of issuing alerts about events.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 19:39:51 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Grushka-Cohen", "Hagit", ""], ["Biller", "Ofer", ""], ["Sofer", "Oded", ""], ["Rokach", "Lior", ""], ["Shapira", "Bracha", ""]]}, {"id": "1910.10786", "submitter": "Reazul Hasan Russel", "authors": "Bahram Behzadian, Reazul Hasan Russel, Marek Petrik, Chin Pang Ho", "title": "Optimizing Percentile Criterion Using Robust MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of computing reliable policies in reinforcement\nlearning problems with limited data. In particular, we compute policies that\nachieve good returns with high confidence when deployed. This objective, known\nas the \\emph{percentile criterion}, can be optimized using Robust MDPs~(RMDPs).\nRMDPs generalize MDPs to allow for uncertain transition probabilities chosen\nadversarially from given ambiguity sets. We show that the RMDP solution's\nsub-optimality depends on the spans of the ambiguity sets along the value\nfunction. We then propose new algorithms that minimize the span of ambiguity\nsets defined by weighted $L_1$ and $L_\\infty$ norms. Our primary focus is on\nBayesian guarantees, but we also describe how our methods apply to frequentist\nguarantees and derive new concentration inequalities for weighted $L_1$ and\n$L_\\infty$ norms. Experimental results indicate that our optimized ambiguity\nsets improve significantly on prior construction methods.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 20:00:11 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 13:08:55 GMT"}, {"version": "v3", "created": "Thu, 25 Feb 2021 22:34:25 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Behzadian", "Bahram", ""], ["Russel", "Reazul Hasan", ""], ["Petrik", "Marek", ""], ["Ho", "Chin Pang", ""]]}, {"id": "1910.10808", "submitter": "Rusheng Zhang", "authors": "Rusheng Zhang, Romain Leteurtre, Benjamin Striner, Ammar Alanazi,\n  Abdullah Alghafis, Ozan K. Tonguz", "title": "Partially Detected Intelligent Traffic Signal Control: Environmental\n  Adaptation", "comments": "Accepted by ICMLA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partially Detected Intelligent Traffic Signal Control (PD-ITSC) systems that\ncan optimize traffic signals based on limited detected information could be a\ncost-efficient solution for mitigating traffic congestion in the future. In\nthis paper, we focus on a particular problem in PD-ITSC - adaptation to\nchanging environments. To this end, we investigate different reinforcement\nlearning algorithms, including Q-learning, Proximal Policy Optimization (PPO),\nAdvantage Actor-Critic (A2C), and Actor-Critic with Kronecker-Factored Trust\nRegion (ACKTR). Our findings suggest that RL algorithms can find optimal\nstrategies under partial vehicle detection; however, policy-based algorithms\ncan adapt to changing environments more efficiently than value-based\nalgorithms. We use these findings to draw conclusions about the value of\ndifferent models for PD-ITSC systems.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 21:01:53 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Zhang", "Rusheng", ""], ["Leteurtre", "Romain", ""], ["Striner", "Benjamin", ""], ["Alanazi", "Ammar", ""], ["Alghafis", "Abdullah", ""], ["Tonguz", "Ozan K.", ""]]}, {"id": "1910.10840", "submitter": "Patrik Reizinger", "authors": "Patrik Reizinger and M\\'arton Szemenyei", "title": "Attention-based Curiosity-driven Exploration in Deep Reinforcement\n  Learning", "comments": "Submitted to ICASSP2020, 5 pages, 8 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning enables to train an agent via interaction with the\nenvironment. However, in the majority of real-world scenarios, the extrinsic\nfeedback is sparse or not sufficient, thus intrinsic reward formulations are\nneeded to successfully train the agent. This work investigates and extends the\nparadigm of curiosity-driven exploration. First, a probabilistic approach is\ntaken to exploit the advantages of the attention mechanism, which is\nsuccessfully applied in other domains of Deep Learning. Combining them, we\npropose new methods, such as AttA2C, an extension of the Actor-Critic\nframework. Second, another curiosity-based approach - ICM - is extended. The\nproposed model utilizes attention to emphasize features for the dynamic models\nwithin ICM, moreover, we also modify the loss function, resulting in a new\ncuriosity formulation, which we call rational curiosity. The corresponding\nimplementation can be found at https://github.com/rpatrik96/AttA2C/.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 23:31:21 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Reizinger", "Patrik", ""], ["Szemenyei", "M\u00e1rton", ""]]}, {"id": "1910.10843", "submitter": "Kevin Huang", "authors": "Kevin Huang, Yun Tang, Jing Huang, Xiaodong He, and Bowen Zhou", "title": "Relation Module for Non-answerable Prediction on Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine reading comprehension(MRC) has attracted significant amounts of\nresearch attention recently, due to an increase of challenging reading\ncomprehension datasets. In this paper, we aim to improve a MRC model's ability\nto determine whether a question has an answer in a given context (e.g. the\nrecently proposed SQuAD 2.0 task). Our solution is a relation module that is\nadaptable to any MRC model. The relation module consists of both semantic\nextraction and relational information. We first extract high level semantics as\nobjects from both question and context with multi-head self-attentive pooling.\nThese semantic objects are then passed to a relation network, which generates\nrelationship scores for each object pair in a sentence. These scores are used\nto determine whether a question is non-answerable. We test the relation module\non the SQuAD 2.0 dataset using both BiDAF and BERT models as baseline readers.\nWe obtain 1.8% gain of F1 on top of the BiDAF reader, and 1.0% on top of the\nBERT base model. These results show the effectiveness of our relation module on\nMRC\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 23:55:23 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Huang", "Kevin", ""], ["Tang", "Yun", ""], ["Huang", "Jing", ""], ["He", "Xiaodong", ""], ["Zhou", "Bowen", ""]]}, {"id": "1910.10871", "submitter": "Andrew Tomkins", "authors": "Benjamin Spector and Ravi Kumar and Andrew Tomkins", "title": "Preventing Adversarial Use of Datasets through Fair Core-Set\n  Construction", "comments": "6 pages, 2 figures, NeurIPS 2019 Privacy In Machine Learning Workshop\n  (PriML 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose improving the privacy properties of a dataset by publishing only a\nstrategically chosen \"core-set\" of the data containing a subset of the\ninstances. The core-set allows strong performance on primary tasks, but forces\npoor performance on unwanted tasks. We give methods for both linear models and\nneural networks and demonstrate their efficacy on data.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 01:28:58 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Spector", "Benjamin", ""], ["Kumar", "Ravi", ""], ["Tomkins", "Andrew", ""]]}, {"id": "1910.10897", "submitter": "Avnish Narayan", "authors": "Tianhe Yu, Deirdre Quillen, Zhanpeng He, Ryan Julian, Avnish Narayan,\n  Hayden Shively, Adithya Bellathur, Karol Hausman, Chelsea Finn, Sergey Levine", "title": "Meta-World: A Benchmark and Evaluation for Multi-Task and Meta\n  Reinforcement Learning", "comments": "This is an update version of a manuscript that originally appeared at\n  CoRL 2019. Videos are here: meta-world.github.io, open-sourced code are\n  available at: https://github.com/rlworkgroup/metaworld, and the baselines can\n  be found at https://github.com/rlworkgroup/garage", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-reinforcement learning algorithms can enable robots to acquire new\nskills much more quickly, by leveraging prior experience to learn how to learn.\nHowever, much of the current research on meta-reinforcement learning focuses on\ntask distributions that are very narrow. For example, a commonly used\nmeta-reinforcement learning benchmark uses different running velocities for a\nsimulated robot as different tasks. When policies are meta-trained on such\nnarrow task distributions, they cannot possibly generalize to more quickly\nacquire entirely new tasks. Therefore, if the aim of these methods is to enable\nfaster acquisition of entirely new behaviors, we must evaluate them on task\ndistributions that are sufficiently broad to enable generalization to new\nbehaviors. In this paper, we propose an open-source simulated benchmark for\nmeta-reinforcement learning and multi-task learning consisting of 50 distinct\nrobotic manipulation tasks. Our aim is to make it possible to develop\nalgorithms that generalize to accelerate the acquisition of entirely new,\nheld-out tasks. We evaluate 7 state-of-the-art meta-reinforcement learning and\nmulti-task learning algorithms on these tasks. Surprisingly, while each task\nand its variations (e.g., with different object positions) can be learned with\nreasonable success, these algorithms struggle to learn with multiple tasks at\nthe same time, even with as few as ten distinct training tasks. Our analysis\nand open-source environments pave the way for future research in multi-task\nlearning and meta-learning that can enable meaningful generalization, thereby\nunlocking the full potential of these methods.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 03:19:46 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 18:45:16 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Yu", "Tianhe", ""], ["Quillen", "Deirdre", ""], ["He", "Zhanpeng", ""], ["Julian", "Ryan", ""], ["Narayan", "Avnish", ""], ["Shively", "Hayden", ""], ["Bellathur", "Adithya", ""], ["Hausman", "Karol", ""], ["Finn", "Chelsea", ""], ["Levine", "Sergey", ""]]}, {"id": "1910.10900", "submitter": "Lin Shao", "authors": "Lin Shao, Fabio Ferreira, Mikael Jorda, Varun Nambiar, Jianlan Luo,\n  Eugen Solowjow, Juan Aparicio Ojea, Oussama Khatib, Jeannette Bohg", "title": "UniGrasp: Learning a Unified Model to Grasp with Multifingered Robotic\n  Hands", "comments": "Accepted to IEEE Robotics and Automation Letters with ICRA 2020\n  option", "journal-ref": null, "doi": "10.1109/LRA.2020.2969946", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To achieve a successful grasp, gripper attributes such as its geometry and\nkinematics play a role as important as the object geometry. The majority of\nprevious work has focused on developing grasp methods that generalize over\nnovel object geometry but are specific to a certain robot hand. We propose\nUniGrasp, an efficient data-driven grasp synthesis method that considers both\nthe object geometry and gripper attributes as inputs. UniGrasp is based on a\nnovel deep neural network architecture that selects sets of contact points from\nthe input point cloud of the object. The proposed model is trained on a large\ndataset to produce contact points that are in force closure and reachable by\nthe robot hand. By using contact points as output, we can transfer between a\ndiverse set of multifingered robotic hands. Our model produces over 90% valid\ncontact points in Top10 predictions in simulation and more than 90% successful\ngrasps in real world experiments for various known two-fingered and\nthree-fingered grippers. Our model also achieves 93%, 83% and 90% successful\ngrasps in real world experiments for an unseen two-fingered gripper and two\nunseen multi-fingered anthropomorphic robotic hands.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 03:33:50 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 22:49:14 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Shao", "Lin", ""], ["Ferreira", "Fabio", ""], ["Jorda", "Mikael", ""], ["Nambiar", "Varun", ""], ["Luo", "Jianlan", ""], ["Solowjow", "Eugen", ""], ["Ojea", "Juan Aparicio", ""], ["Khatib", "Oussama", ""], ["Bohg", "Jeannette", ""]]}, {"id": "1910.10902", "submitter": "Chunnnan Wang", "authors": "Chunnan Wang, Hongzhi Wang, Tianyu Mu, Jianzhong Li, Hong Gao", "title": "Auto-Model: Utilizing Research Papers and HPO Techniques to Deal with\n  the CASH problem", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many fields, a mass of algorithms with completely different\nhyperparameters have been developed to address the same type of problems.\nChoosing the algorithm and hyperparameter setting correctly can promote the\noverall performance greatly, but users often fail to do so due to the absence\nof knowledge. How to help users to effectively and quickly select the suitable\nalgorithm and hyperparameter settings for the given task instance is an\nimportant research topic nowadays, which is known as the CASH problem. In this\npaper, we design the Auto-Model approach, which makes full use of known\ninformation in the related research paper and introduces hyperparameter\noptimization techniques, to solve the CASH problem effectively. Auto-Model\ntremendously reduces the cost of algorithm implementations and hyperparameter\nconfiguration space, and thus capable of dealing with the CASH problem\nefficiently and easily. To demonstrate the benefit of Auto-Model, we compare it\nwith classical Auto-Weka approach. The experimental results show that our\nproposed approach can provide superior results and achieves better performance\nin a short time.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 03:44:10 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 05:35:59 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Wang", "Chunnan", ""], ["Wang", "Hongzhi", ""], ["Mu", "Tianyu", ""], ["Li", "Jianzhong", ""], ["Gao", "Hong", ""]]}, {"id": "1910.10942", "submitter": "Simon Leglaive", "authors": "Simon Leglaive (IETR), Xavier Alameda-Pineda (PERCEPTION), Laurent\n  Girin (GIPSA-CRISSP, PERCEPTION), Radu Horaud (PERCEPTION)", "title": "A Recurrent Variational Autoencoder for Speech Enhancement", "comments": null, "journal-ref": "ICASSP 2020 - 2020 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP), May 2020, Barcelona, Spain", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a generative approach to speech enhancement based on a\nrecurrent variational autoencoder (RVAE). The deep generative speech model is\ntrained using clean speech signals only, and it is combined with a nonnegative\nmatrix factorization noise model for speech enhancement. We propose a\nvariational expectation-maximization algorithm where the encoder of the RVAE is\nfine-tuned at test time, to approximate the distribution of the latent\nvariables given the noisy speech observations. Compared with previous\napproaches based on feed-forward fully-connected architectures, the proposed\nrecurrent deep generative speech model induces a posterior temporal dynamic\nover the latent variables, which is shown to improve the speech enhancement\nresults.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 06:54:36 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 09:36:23 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Leglaive", "Simon", "", "IETR"], ["Alameda-Pineda", "Xavier", "", "PERCEPTION"], ["Girin", "Laurent", "", "GIPSA-CRISSP, PERCEPTION"], ["Horaud", "Radu", "", "PERCEPTION"]]}, {"id": "1910.10985", "submitter": "Tingguang Li", "authors": "Tingguang Li, Krishnan Srinivasan, Max Qing-Hu Meng, Wenzhen Yuan and\n  Jeannette Bohg", "title": "Learning Hierarchical Control for Robust In-Hand Manipulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotic in-hand manipulation has been a long-standing challenge due to the\ncomplexity of modelling hand and object in contact and of coordinating finger\nmotion for complex manipulation sequences. To address these challenges, the\nmajority of prior work has either focused on model-based, low-level controllers\nor on model-free deep reinforcement learning that each have their own\nlimitations. We propose a hierarchical method that relies on traditional,\nmodel-based controllers on the low-level and learned policies on the mid-level.\nThe low-level controllers can robustly execute different manipulation\nprimitives (reposing, sliding, flipping). The mid-level policy orchestrates\nthese primitives. We extensively evaluate our approach in simulation with a\n3-fingered hand that controls three degrees of freedom of elongated objects. We\nshow that our approach can move objects between almost all the possible poses\nin the workspace while keeping them firmly grasped. We also show that our\napproach is robust to inaccuracies in the object models and to observation\nnoise. Finally, we show how our approach generalizes to objects of other\nshapes.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 09:16:09 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Li", "Tingguang", ""], ["Srinivasan", "Krishnan", ""], ["Meng", "Max Qing-Hu", ""], ["Yuan", "Wenzhen", ""], ["Bohg", "Jeannette", ""]]}, {"id": "1910.11015", "submitter": "Nargiz Humbatova", "authors": "Nargiz Humbatova, Gunel Jahangirova, Gabriele Bavota, Vincenzo Riccio,\n  Andrea Stocco, Paolo Tonella", "title": "Taxonomy of Real Faults in Deep Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The growing application of deep neural networks in safety-critical domains\nmakes the analysis of faults that occur in such systems of enormous importance.\nIn this paper we introduce a large taxonomy of faults in deep learning (DL)\nsystems. We have manually analysed 1059 artefacts gathered from GitHub commits\nand issues of projects that use the most popular DL frameworks (TensorFlow,\nKeras and PyTorch) and from related Stack Overflow posts. Structured interviews\nwith 20 researchers and practitioners describing the problems they have\nencountered in their experience have enriched our taxonomy with a variety of\nadditional faults that did not emerge from the other two sources. Our final\ntaxonomy was validated with a survey involving an additional set of 21\ndevelopers, confirming that almost all fault categories (13/15) were\nexperienced by at least 50% of the survey participants.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 10:23:59 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 14:43:38 GMT"}, {"version": "v3", "created": "Thu, 7 Nov 2019 13:19:46 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Humbatova", "Nargiz", ""], ["Jahangirova", "Gunel", ""], ["Bavota", "Gabriele", ""], ["Riccio", "Vincenzo", ""], ["Stocco", "Andrea", ""], ["Tonella", "Paolo", ""]]}, {"id": "1910.11024", "submitter": "Tim Quatmann", "authors": "Florent Delgrange, Joost-Pieter Katoen, Tim Quatmann, Mickael Randour", "title": "Simple Strategies in Multi-Objective MDPs (Technical Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the verification of multiple expected reward objectives at once\non Markov decision processes (MDPs). This enables a trade-off analysis among\nmultiple objectives by obtaining the Pareto front. We focus on strategies that\nare easy to employ and implement. That is, strategies that are pure (no\nrandomization) and have bounded memory. We show that checking whether a point\nis achievable by a pure stationary strategy is NP-complete, even for two\nobjectives, and we provide an MILP encoding to solve the corresponding problem.\nThe bounded memory case can be reduced to the stationary one by a product\nconstruction. Experimental results using \\Storm and Gurobi show the feasibility\nof our algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 10:48:21 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 02:42:06 GMT"}, {"version": "v3", "created": "Mon, 17 Feb 2020 18:01:29 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Delgrange", "Florent", ""], ["Katoen", "Joost-Pieter", ""], ["Quatmann", "Tim", ""], ["Randour", "Mickael", ""]]}, {"id": "1910.11099", "submitter": "Kaidi Xu", "authors": "Kaidi Xu, Gaoyuan Zhang, Sijia Liu, Quanfu Fan, Mengshu Sun, Hongge\n  Chen, Pin-Yu Chen, Yanzhi Wang, Xue Lin", "title": "Adversarial T-shirt! Evading Person Detectors in A Physical World", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that deep neural networks (DNNs) are vulnerable to adversarial\nattacks. The so-called physical adversarial examples deceive DNN-based\ndecisionmakers by attaching adversarial patches to real objects. However, most\nof the existing works on physical adversarial attacks focus on static objects\nsuch as glass frames, stop signs and images attached to cardboard. In this\nwork, we proposed adversarial T-shirts, a robust physical adversarial example\nfor evading person detectors even if it could undergo non-rigid deformation due\nto a moving person's pose changes. To the best of our knowledge, this is the\nfirst work that models the effect of deformation for designing physical\nadversarial examples with respect to-rigid objects such as T-shirts. We show\nthat the proposed method achieves74% and 57% attack success rates in the\ndigital and physical worlds respectively against YOLOv2. In contrast, the\nstate-of-the-art physical attack method to fool a person detector only achieves\n18% attack success rate. Furthermore, by leveraging min-max optimization, we\nextend our method to the ensemble attack setting against two object detectors\nYOLO-v2 and Faster R-CNN simultaneously.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 02:20:17 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 00:37:43 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 03:06:26 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Xu", "Kaidi", ""], ["Zhang", "Gaoyuan", ""], ["Liu", "Sijia", ""], ["Fan", "Quanfu", ""], ["Sun", "Mengshu", ""], ["Chen", "Hongge", ""], ["Chen", "Pin-Yu", ""], ["Wang", "Yanzhi", ""], ["Lin", "Xue", ""]]}, {"id": "1910.11124", "submitter": "Hammad Ayyubi", "authors": "Hammad A. Ayyubi, Md. Mehrab Tanjim and David J. Kriegman", "title": "Enforcing Reasoning in Visual Commonsense Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The task of Visual Commonsense Reasoning is extremely challenging in the\nsense that the model has to not only be able to answer a question given an\nimage, but also be able to learn to reason. The baselines introduced in this\ntask are quite limiting because two networks are trained for predicting answers\nand rationales separately. Question and image is used as input to train answer\nprediction network while question, image and correct answer are used as input\nin the rationale prediction network. As rationale is conditioned on the correct\nanswer, it is based on the assumption that we can solve Visual Question\nAnswering task without any error - which is over ambitious. Moreover, such an\napproach makes both answer and rationale prediction two completely independent\nVQA tasks rendering cognition task meaningless. In this paper, we seek to\naddress these issues by proposing an end-to-end trainable model which considers\nboth answers and their reasons jointly. Specifically, we first predict the\nanswer for the question and then use the chosen answer to predict the\nrationale. However, a trivial design of such a model becomes non-differentiable\nwhich makes it difficult to train. We solve this issue by proposing four\napproaches - softmax, gumbel-softmax, reinforcement learning based sampling and\ndirect cross entropy against all pairs of answers and rationales. We\ndemonstrate through experiments that our model performs competitively against\ncurrent state-of-the-art. We conclude with an analysis of presented approaches\nand discuss avenues for further work.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 02:33:18 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 10:09:58 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Ayyubi", "Hammad A.", ""], ["Tanjim", "Md. Mehrab", ""], ["Kriegman", "David J.", ""]]}, {"id": "1910.11161", "submitter": "Fei Hu", "authors": "Fei Hu, Wei Liu, Ajmal Saeed Mian, and Li Li", "title": "Diversifying Topic-Coherent Response Generation for Natural Multi-turn\n  Conversations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although response generation (RG) diversification for single-turn dialogs has\nbeen well developed, it is less investigated for natural multi-turn\nconversations. Besides, past work focused on diversifying responses without\nconsidering topic coherence to the context, producing uninformative replies. In\nthis paper, we propose the Topic-coherent Hierarchical Recurrent\nEncoder-Decoder model (THRED) to diversify the generated responses without\ndeviating the contextual topics for multi-turn conversations. In overall, we\nbuild a sequence-to-sequence net (Seq2Seq) to model multi-turn conversations.\nAnd then we resort to the latent Variable Hierarchical Recurrent\nEncoder-Decoder model (VHRED) to learn global contextual distribution of\ndialogs. Besides, we construct a dense topic matrix which implies word-level\ncorrelations of the conversation corpora. The topic matrix is used to learn\nlocal topic distribution of the contextual utterances. By incorporating both\nthe global contextual distribution and the local topic distribution, THRED\nproduces both diversified and topic-coherent replies. In addition, we propose\nan explicit metric (\\emph{TopicDiv}) to measure the topic divergence between\nthe post and generated response, and we also propose an overall metric\ncombining the diversification metric (\\emph{Distinct}) and \\emph{TopicDiv}. We\nevaluate our model comparing with three baselines (Seq2Seq, HRED and VHRED) on\ntwo real-world corpora, respectively, and demonstrate its outstanding\nperformance in both diversification and topic coherence.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 14:18:55 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Hu", "Fei", ""], ["Liu", "Wei", ""], ["Mian", "Ajmal Saeed", ""], ["Li", "Li", ""]]}, {"id": "1910.11262", "submitter": "Gabriele Valentini", "authors": "Gabriele Valentini", "title": "How robots in a large group make decisions as a whole? From biological\n  inspiration to the design of distributed algorithms", "comments": "journal article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA nlin.AO q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nature provides us with abundant examples of how large numbers of individuals\ncan make decisions without the coordination of a central authority. Social\ninsects, birds, fishes, and many other living collectives, rely on simple\ninteraction mechanisms to do so. They individually gather information from the\nenvironment; small bits of a much larger picture that are then shared locally\namong the members of the collective and processed together to output a commonly\nagreed choice. Throughout evolution, Nature found solutions to collective\ndecision-making problems that are intriguing to engineers for their robustness\nto malfunctioning or lost individuals, their flexibility in face of dynamic\nenvironments, and their ability to scale with large numbers of members. In the\nlast decades, whereas biologists amassed large amounts of experimental\nevidence, engineers took inspiration from these and other examples to design\ndistributed algorithms that, while maintaining the same properties of their\nnatural counterparts, come with guarantees on their performance in the form of\npredictive mathematical models. In this paper, we review the fundamental\nprocesses that lead to a collective decision. We discuss examples of collective\ndecisions in biological systems and show how similar processes can be\nengineered to design artificial ones. During this journey, we review a\nframework to design distributed decision-making algorithms that are modular,\ncan be instantiated and extended in different ways, and are supported by a suit\nof predictive mathematical models.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 16:11:35 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 18:10:32 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Valentini", "Gabriele", ""]]}, {"id": "1910.11292", "submitter": "Nadav Oved", "authors": "Nadav Oved, Amir Feder, Roi Reichart", "title": "Predicting In-game Actions from Interviews of NBA Players", "comments": "First two authors contributed equally. To be published in the\n  Computational Linguistics journal. Code is available at:\n  https://github.com/nadavo/mood", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sports competitions are widely researched in computer and social science,\nwith the goal of understanding how players act under uncertainty. While there\nis an abundance of computational work on player metrics prediction based on\npast performance, very few attempts to incorporate out-of-game signals have\nbeen made. Specifically, it was previously unclear whether linguistic signals\ngathered from players' interviews can add information which does not appear in\nperformance metrics. To bridge that gap, we define text classification tasks of\npredicting deviations from mean in NBA players' in-game actions, which are\nassociated with strategic choices, player behavior and risk, using their choice\nof language prior to the game. We collected a dataset of transcripts from key\nNBA players' pre-game interviews and their in-game performance metrics,\ntotalling in 5,226 interview-metric pairs. We design neural models for players'\naction prediction based on increasingly more complex aspects of the language\nsignals in their open-ended interviews. Our models can make their predictions\nbased on the textual signal alone, or on a combination with signals from\npast-performance metrics. Our text-based models outperform strong baselines\ntrained on performance metrics only, demonstrating the importance of language\nusage for action prediction. Moreover, the models that employ both textual\ninput and past-performance metrics produced the best results. Finally, as\nneural networks are notoriously difficult to interpret, we propose a method for\ngaining further insight into what our models have learned. Particularly, we\npresent an LDA-based analysis, where we interpret model predictions in terms of\ncorrelated topics. We find that our best performing textual model is most\nassociated with topics that are intuitively related to each prediction task and\nthat better models yield higher correlation with more informative topics.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 17:10:34 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 01:29:32 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 17:46:33 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Oved", "Nadav", ""], ["Feder", "Amir", ""], ["Reichart", "Roi", ""]]}, {"id": "1910.11424", "submitter": "Abhinav Gupta", "authors": "Cinjon Resnick, Abhinav Gupta, Jakob Foerster, Andrew M. Dai,\n  Kyunghyun Cho", "title": "Capacity, Bandwidth, and Compositionality in Emergent Language Learning", "comments": "The first two authors contributed equally. Accepted at AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent works have discussed the propensity, or lack thereof, for\nemergent languages to exhibit properties of natural languages. A favorite in\nthe literature is learning compositionality. We note that most of those works\nhave focused on communicative bandwidth as being of primary importance. While\nimportant, it is not the only contributing factor. In this paper, we\ninvestigate the learning biases that affect the efficacy and compositionality\nof emergent languages. Our foremost contribution is to explore how capacity of\na neural network impacts its ability to learn a compositional language. We\nadditionally introduce a set of evaluation metrics with which we analyze the\nlearned languages. Our hypothesis is that there should be a specific range of\nmodel capacity and channel bandwidth that induces compositional structure in\nthe resulting language and consequently encourages systematic generalization.\nWhile we empirically see evidence for the bottom of this range, we curiously do\nnot find evidence for the top part of the range and believe that this is an\nopen question for the community.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 21:06:38 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2020 22:36:24 GMT"}, {"version": "v3", "created": "Wed, 15 Apr 2020 07:54:53 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Resnick", "Cinjon", ""], ["Gupta", "Abhinav", ""], ["Foerster", "Jakob", ""], ["Dai", "Andrew M.", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1910.11432", "submitter": "Chengshu Li", "authors": "Chengshu Li, Fei Xia, Roberto Martin-Martin, Silvio Savarese", "title": "HRL4IN: Hierarchical Reinforcement Learning for Interactive Navigation\n  with Mobile Manipulators", "comments": "Conference on Robot Learning (CoRL) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most common navigation tasks in human environments require auxiliary arm\ninteractions, e.g. opening doors, pressing buttons and pushing obstacles away.\nThis type of navigation tasks, which we call Interactive Navigation, requires\nthe use of mobile manipulators: mobile bases with manipulation capabilities.\nInteractive Navigation tasks are usually long-horizon and composed of\nheterogeneous phases of pure navigation, pure manipulation, and their\ncombination. Using the wrong part of the embodiment is inefficient and hinders\nprogress. We propose HRL4IN, a novel Hierarchical RL architecture for\nInteractive Navigation tasks. HRL4IN exploits the exploration benefits of HRL\nover flat RL for long-horizon tasks thanks to temporally extended commitments\ntowards subgoals. Different from other HRL solutions, HRL4IN handles the\nheterogeneous nature of the Interactive Navigation task by creating subgoals in\ndifferent spaces in different phases of the task. Moreover, HRL4IN selects\ndifferent parts of the embodiment to use for each phase, improving energy\nefficiency. We evaluate HRL4IN against flat PPO and HAC, a state-of-the-art HRL\nalgorithm, on Interactive Navigation in two environments - a 2D grid-world\nenvironment and a 3D environment with physics simulation. We show that HRL4IN\nsignificantly outperforms its baselines in terms of task performance and energy\nefficiency. More information is available at\nhttps://sites.google.com/view/hrl4in.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 21:34:29 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Li", "Chengshu", ""], ["Xia", "Fei", ""], ["Martin-Martin", "Roberto", ""], ["Savarese", "Silvio", ""]]}, {"id": "1910.11471", "submitter": "K.M. Tahsin Hassan Rahit", "authors": "K.M. Tahsin Hassan Rahit, Rashidul Hasan Nabil and Md Hasibul Huq", "title": "Machine Translation from Natural Language to Code using Long-Short Term\n  Memory", "comments": "8 pages, 3 figures, conference", "journal-ref": "Proceedings of the Future Technologies Conference (FTC) 2019.\n  Advances in Intelligent Systems and Computing, vol 1069. Springer, Cham", "doi": "10.1007/978-3-030-32520-6_6", "report-no": null, "categories": "cs.CL cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making computer programming language more understandable and easy for the\nhuman is a longstanding problem. From assembly language to present day's\nobject-oriented programming, concepts came to make programming easier so that a\nprogrammer can focus on the logic and the architecture rather than the code and\nlanguage itself. To go a step further in this journey of removing\nhuman-computer language barrier, this paper proposes machine learning approach\nusing Recurrent Neural Network (RNN) and Long-Short Term Memory (LSTM) to\nconvert human language into programming language code. The programmer will\nwrite expressions for codes in layman's language, and the machine learning\nmodel will translate it to the targeted programming language. The proposed\napproach yields result with 74.40% accuracy. This can be further improved by\nincorporating additional techniques, which are also discussed in this paper.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 00:46:07 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Rahit", "K. M. Tahsin Hassan", ""], ["Nabil", "Rashidul Hasan", ""], ["Huq", "Md Hasibul", ""]]}, {"id": "1910.11683", "submitter": "Antony Thomas", "authors": "Antony Thomas, Fulvio Mastrogiovanni and Marco Baglietto", "title": "Task-Motion Planning for Navigation in Belief Space", "comments": "Accepted for publication in the proceedings of the International\n  Symposium on Robotics Research (ISRR) 2019. arXiv admin note: text overlap\n  with arXiv:1908.10227", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an integrated Task-Motion Planning (TMP) framework for navigation\nin large-scale environment. Autonomous robots operating in real world complex\nscenarios require planning in the discrete (task) space and the continuous\n(motion) space. In knowledge intensive domains, on the one hand, a robot has to\nreason at the highest-level, for example the regions to navigate to; on the\nother hand, the feasibility of the respective navigation tasks have to be\nchecked at the execution level. This presents a need for motion-planning-aware\ntask planners. We discuss a probabilistically complete approach that leverages\nthis task-motion interaction for navigating in indoor domains, returning a plan\nthat is optimal at the task-level. Furthermore, our framework is intended for\nmotion planning under motion and sensing uncertainty, which is formally known\nas belief space planning. The underlying methodology is validated with a\nsimulated office environment in Gazebo. In addition, we discuss the limitations\nand provide suggestions for improvements and future work.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 10:11:50 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Thomas", "Antony", ""], ["Mastrogiovanni", "Fulvio", ""], ["Baglietto", "Marco", ""]]}, {"id": "1910.11689", "submitter": "Michael Everett", "authors": "Michael Everett, Yu Fan Chen, Jonathan P. How", "title": "Collision Avoidance in Pedestrian-Rich Environments with Deep\n  Reinforcement Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:1805.01956", "journal-ref": null, "doi": "10.1109/ACCESS.2021.3050338", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collision avoidance algorithms are essential for safe and efficient robot\noperation among pedestrians. This work proposes using deep reinforcement (RL)\nlearning as a framework to model the complex interactions and cooperation with\nnearby, decision-making agents, such as pedestrians and other robots. Existing\nRL-based works assume homogeneity of agent properties, use specific motion\nmodels over short timescales, or lack a principled method to handle a large,\npossibly varying number of agents. Therefore, this work develops an algorithm\nthat learns collision avoidance among a variety of heterogeneous,\nnon-communicating, dynamic agents without assuming they follow any particular\nbehavior rules. It extends our previous work by introducing a strategy using\nLong Short-Term Memory (LSTM) that enables the algorithm to use observations of\nan arbitrary number of other agents, instead of a small, fixed number of\nneighbors. The proposed algorithm is shown to outperform a classical collision\navoidance algorithm, another deep RL-based algorithm, and scales with the\nnumber of agents better (fewer collisions, shorter time to goal) than our\npreviously published learning-based approach. Analysis of the LSTM provides\ninsights into how observations of nearby agents affect the hidden state and\nquantifies the performance impact of various agent ordering heuristics. The\nlearned policy generalizes to several applications beyond the training\nscenarios: formation control (arrangement into letters), demonstrations on a\nfleet of four multirotors and on a fully autonomous robotic vehicle capable of\ntraveling at human walking speed among pedestrians.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 04:26:50 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 19:07:11 GMT"}, {"version": "v3", "created": "Sun, 26 Apr 2020 20:47:18 GMT"}, {"version": "v4", "created": "Mon, 25 Jan 2021 16:59:05 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Everett", "Michael", ""], ["Chen", "Yu Fan", ""], ["How", "Jonathan P.", ""]]}, {"id": "1910.11737", "submitter": "Dengji Zhao", "authors": "Dengji Zhao, Yiqing Huang, Liat Cohen, Tal Grinshpoun", "title": "Coalitional Games with Stochastic Characteristic Functions and Private\n  Types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research on coalitional games has focused on how to share the reward\namong a coalition such that players are incentivised to collaborate together.\nIt assumes that the (deterministic or stochastic) characteristic function is\nknown in advance. This paper studies a new setting (a task allocation problem)\nwhere the characteristic function is not known and it is controlled by some\nprivate information from the players. Hence, the challenge here is twofold: (i)\nincentivize players to reveal their private information truthfully, (ii)\nincentivize them to collaborate together. We show that existing reward\ndistribution mechanisms or auctions cannot solve the challenge. Hence, we\npropose the very first mechanism for the problem from the perspective of both\nmechanism design and coalitional games.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 14:06:09 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Zhao", "Dengji", ""], ["Huang", "Yiqing", ""], ["Cohen", "Liat", ""], ["Grinshpoun", "Tal", ""]]}, {"id": "1910.11797", "submitter": "Thibault Gauthier", "authors": "Thibault Gauthier", "title": "Deep Reinforcement Learning for Synthesizing Functions in Higher-Order\n  Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper describes a deep reinforcement learning framework based on\nself-supervised learning within the proof assistant HOL4. A close interaction\nbetween the machine learning modules and the HOL4 library is achieved by the\nchoice of tree neural networks (TNNs) as machine learning models and the\ninternal use of HOL4 terms to represent tree structures of TNNs. Recursive\nimprovement is possible when a task is expressed as a search problem. In this\ncase, a Monte Carlo Tree Search (MCTS) algorithm guided by a TNN can be used to\nexplore the search space and produce better examples for training the next TNN.\nAs an illustration, term synthesis tasks on combinators and Diophantine\nequations are specified and learned. We achieve a success rate of 65% on\ncombinator synthesis problems outperforming state-of-the-art ATPs run with\ntheir best general set of strategies. We set a precedent for statistically\nguided synthesis of Diophantine equations by solving 78.5% of the generated\ntest problems.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 15:27:22 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 11:20:27 GMT"}, {"version": "v3", "created": "Fri, 24 Apr 2020 08:11:57 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Gauthier", "Thibault", ""]]}, {"id": "1910.11856", "submitter": "Mikel Artetxe", "authors": "Mikel Artetxe, Sebastian Ruder, Dani Yogatama", "title": "On the Cross-lingual Transferability of Monolingual Representations", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art unsupervised multilingual models (e.g., multilingual BERT)\nhave been shown to generalize in a zero-shot cross-lingual setting. This\ngeneralization ability has been attributed to the use of a shared subword\nvocabulary and joint training across multiple languages giving rise to deep\nmultilingual abstractions. We evaluate this hypothesis by designing an\nalternative approach that transfers a monolingual model to new languages at the\nlexical level. More concretely, we first train a transformer-based masked\nlanguage model on one language, and transfer it to a new language by learning a\nnew embedding matrix with the same masked language modeling objective, freezing\nparameters of all other layers. This approach does not rely on a shared\nvocabulary or joint training. However, we show that it is competitive with\nmultilingual BERT on standard cross-lingual classification benchmarks and on a\nnew Cross-lingual Question Answering Dataset (XQuAD). Our results contradict\ncommon beliefs of the basis of the generalization ability of multilingual\nmodels and suggest that deep monolingual models learn some abstractions that\ngeneralize across languages. We also release XQuAD as a more comprehensive\ncross-lingual benchmark, which comprises 240 paragraphs and 1190\nquestion-answer pairs from SQuAD v1.1 translated into ten languages by\nprofessional translators.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 17:30:20 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 16:55:33 GMT"}, {"version": "v3", "created": "Tue, 26 May 2020 22:45:22 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Artetxe", "Mikel", ""], ["Ruder", "Sebastian", ""], ["Yogatama", "Dani", ""]]}, {"id": "1910.11914", "submitter": "Lea Marion Trenkwalder", "authors": "Walter L. Boyajian and Jens Clausen and Lea M. Trenkwalder and Vedran\n  Dunjko and Hans J. Briegel", "title": "On the convergence of projective-simulation-based reinforcement learning\n  in Markov decision processes", "comments": "20 pages, 2 figures, v3: a few minor updates to match journal\n  version. Order of authors changed", "journal-ref": "Quantum Mach. Intell. 2, 13 (2020)", "doi": "10.1007/s42484-020-00023-9", "report-no": null, "categories": "cs.LG cs.AI quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the interest in leveraging quantum effects for enhancing\nmachine learning tasks has significantly increased. Many algorithms speeding up\nsupervised and unsupervised learning were established. The first framework in\nwhich ways to exploit quantum resources specifically for the broader context of\nreinforcement learning were found is projective simulation. Projective\nsimulation presents an agent-based reinforcement learning approach designed in\na manner which may support quantum walk-based speed-ups. Although classical\nvariants of projective simulation have been benchmarked against common\nreinforcement learning algorithms, very few formal theoretical analyses have\nbeen provided for its performance in standard learning scenarios. In this\npaper, we provide a detailed formal discussion of the properties of this model.\nSpecifically, we prove that one version of the projective simulation model,\nunderstood as a reinforcement learning approach, converges to optimal behavior\nin a large class of Markov decision processes. This proof shows that a\nphysically-inspired approach to reinforcement learning can guarantee to\nconverge.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 19:46:04 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 17:31:01 GMT"}, {"version": "v3", "created": "Thu, 12 Nov 2020 15:49:08 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Boyajian", "Walter L.", ""], ["Clausen", "Jens", ""], ["Trenkwalder", "Lea M.", ""], ["Dunjko", "Vedran", ""], ["Briegel", "Hans J.", ""]]}, {"id": "1910.12020", "submitter": "Azam Rabiee", "authors": "Ehsan Jeihaninejad, Azam Rabiee", "title": "D-Point Trigonometric Path Planning based on Q-Learning in Uncertain\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the optimum path for a robot for moving from start to the goal\nposition through obstacles is still a challenging issue. This paper presents a\nnovel path planning method, named D-point trigonometric, based on Q-learning\nalgorithm for dynamic and uncertain environments, in which all the obstacles\nand the target are moving. We define a new state, action and reward functions\nfor the Q-learning by which the agent can find the best action in every state\nto reach the goal in the most appropriate path. The D-point approach minimizes\nthe possible number of states. Moreover, the experiments in Unity3D confirmed\nthe high convergence speed, the high hit rate, as well as the low dependency on\nenvironmental parameters of the proposed method compared with an opponent\napproach.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 08:37:17 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Jeihaninejad", "Ehsan", ""], ["Rabiee", "Azam", ""]]}, {"id": "1910.12025", "submitter": "Azam Rabiee", "authors": "Ehsan Jeihaninejad and Azam Rabiee", "title": "On the Efficiency of the Neuro-Fuzzy Classifier for User Knowledge\n  Modeling Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User knowledge modeling systems are used as the most effective technology for\ngrabbing new user's attention. Moreover, the quality of service (QOS) is\nincreased by these intelligent services. This paper proposes two user knowledge\nclassifiers based on artificial neural networks used as one of the influential\nparts of knowledge modeling systems. We employed multi-layer perceptron (MLP)\nand adaptive neural fuzzy inference system (ANFIS) as the classifiers.\nMoreover, we used real data contains the user's degree of study time,\nrepetition number, their performance in exam, as well as the learning\npercentage, as our classifier's inputs. Compared with well-known methods like\nKNN and Bayesian classifiers used in other research with the same data sets,\nour experiments present better performance. Although, the number of samples in\nthe train set is not large enough, the performance of the neuro-fuzzy\nclassifier in the test set is 98.6% which is the best result in comparison with\nothers. However, the comparison of MLP toward the ANFIS results presents\nperformance reduction, although the MLP performance is more efficient than\nother methods like Bayesian and KNN. As our goal is evaluating and reporting\nthe efficiency of a neuro-fuzzy classifier for user knowledge modeling systems,\nwe utilized many different evaluation metrics such as Receiver Operating\nCharacteristic and the Area Under its Curve, Total Accuracy, and Kappa\nstatistics.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 09:05:09 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Jeihaninejad", "Ehsan", ""], ["Rabiee", "Azam", ""]]}, {"id": "1910.12134", "submitter": "Shengyi Huang", "authors": "Shengyi Huang, Santiago Onta\\~n\\'on", "title": "Comparing Observation and Action Representations for Deep Reinforcement\n  Learning in $\\mu$RTS", "comments": "Presented in the AIIDE 2019 Workshop on Artificial Intelligence for\n  Strategy Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a preliminary study comparing different observation and\naction space representations for Deep Reinforcement Learning (DRL) in the\ncontext of Real-time Strategy (RTS) games. Specifically, we compare two\nrepresentations: (1) a global representation where the observation represents\nthe whole game state, and the RL agent needs to choose which unit to issue\nactions to, and which actions to execute; and (2) a local representation where\nthe observation is represented from the point of view of an individual unit,\nand the RL agent picks actions for each unit independently. We evaluate these\nrepresentations in $\\mu$RTS showing that the local representation seems to\noutperform the global representation when training agents with the task of\nharvesting resources.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 20:30:36 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 03:03:22 GMT"}, {"version": "v3", "created": "Wed, 22 Apr 2020 22:43:13 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Huang", "Shengyi", ""], ["Onta\u00f1\u00f3n", "Santiago", ""]]}, {"id": "1910.12154", "submitter": "Daniel Seita", "authors": "Daniel Seita, David Chan, Roshan Rao, Chen Tang, Mandi Zhao, John\n  Canny", "title": "ZPD Teaching Strategies for Deep Reinforcement Learning from\n  Demonstrations", "comments": "Deep Reinforcement Learning Workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from demonstrations is a popular tool for accelerating and reducing\nthe exploration requirements of reinforcement learning. When providing expert\ndemonstrations to human students, we know that the demonstrations must fall\nwithin a particular range of difficulties called the \"Zone of Proximal\nDevelopment (ZPD)\". If they are too easy the student learns nothing, but if\nthey are too difficult the student is unable to follow along. This raises the\nquestion: Given a set of potential demonstrators, which among them is best\nsuited for teaching any particular learner? Prior work, such as the popular\nDeep Q-learning from Demonstrations (DQfD) algorithm has generally focused on\nsingle demonstrators. In this work we consider the problem of choosing among\nmultiple demonstrators of varying skill levels. Our results align with\nintuition from human learners: it is not always the best policy to draw\ndemonstrations from the best performing demonstrator (in terms of reward). We\nshow that careful selection of teaching strategies can result in sample\nefficiency gains in the learner's environment across nine Atari games\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 23:05:43 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Seita", "Daniel", ""], ["Chan", "David", ""], ["Rao", "Roshan", ""], ["Tang", "Chen", ""], ["Zhao", "Mandi", ""], ["Canny", "John", ""]]}, {"id": "1910.12179", "submitter": "Che Wang", "authors": "Xinyue Chen, Zijian Zhou, Zheng Wang, Che Wang, Yanqiu Wu, Keith Ross", "title": "BAIL: Best-Action Imitation Learning for Batch Deep Reinforcement\n  Learning", "comments": "27 pages(15 pages for appendix); Published in 34th Conference on\n  Neural Information Processing Systems (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has recently been a surge in research in batch Deep Reinforcement\nLearning (DRL), which aims for learning a high-performing policy from a given\ndataset without additional interactions with the environment. We propose a new\nalgorithm, Best-Action Imitation Learning (BAIL), which strives for both\nsimplicity and performance. BAIL learns a V function, uses the V function to\nselect actions it believes to be high-performing, and then uses those actions\nto train a policy network using imitation learning. For the MuJoCo benchmark,\nwe provide a comprehensive experimental study of BAIL, comparing its\nperformance to four other batch Q-learning and imitation-learning schemes for a\nlarge variety of batch datasets. Our experiments show that BAIL's performance\nis much higher than the other schemes, and is also computationally much faster\nthan the batch Q-learning schemes.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 04:43:19 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 11:26:19 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 05:28:24 GMT"}, {"version": "v4", "created": "Mon, 2 Nov 2020 07:11:07 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Chen", "Xinyue", ""], ["Zhou", "Zijian", ""], ["Wang", "Zheng", ""], ["Wang", "Che", ""], ["Wu", "Yanqiu", ""], ["Ross", "Keith", ""]]}, {"id": "1910.12191", "submitter": "Sabri Boughorbel", "authors": "Sabri Boughorbel, Fethi Jarray, Neethu Venugopal, Shabir Moosa,\n  Haithum Elhadi, Michel Makhlouf", "title": "Federated Uncertainty-Aware Learning for Distributed Hospital EHR Data", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have shown that applying Machine Learning to Electronic Health\nRecords (EHR) can strongly accelerate precision medicine. This requires\ndeveloping models based on diverse EHR sources. Federated Learning (FL) has\nenabled predictive modeling using distributed training which lifted the need of\nsharing data and compromising privacy. Since models are distributed in FL, it\nis attractive to devise ensembles of Deep Neural Networks that also assess\nmodel uncertainty. We propose a new FL model called Federated Uncertainty-Aware\nLearning Algorithm (FUALA) that improves on Federated Averaging (FedAvg) in the\ncontext of EHR. FUALA embeds uncertainty information in two ways: It reduces\nthe contribution of models with high uncertainty in the aggregated model. It\nalso introduces model ensembling at prediction time by keeping the last layers\nof each hospital from the final round. In FUALA, the Federator (central node)\nsends at each round the average model to all hospitals as well as a randomly\nassigned hospital model update to estimate its generalization on that hospital\nown data. Each hospital sends back its model update as well a generalization\nestimation of the assigned model. At prediction time, the model outputs C\npredictions for each sample where C is the number of hospital models. The\nexperimental analysis conducted on a cohort of 87K deliveries for the task of\npreterm-birth prediction showed that the proposed approach outperforms FedAvg\nwhen evaluated on out-of-distribution data. We illustrated how uncertainty\ncould be measured using the proposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 06:33:34 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Boughorbel", "Sabri", ""], ["Jarray", "Fethi", ""], ["Venugopal", "Neethu", ""], ["Moosa", "Shabir", ""], ["Elhadi", "Haithum", ""], ["Makhlouf", "Michel", ""]]}, {"id": "1910.12196", "submitter": "Fanchao Qi", "authors": "Yuan Zang, Fanchao Qi, Chenghao Yang, Zhiyuan Liu, Meng Zhang, Qun\n  Liu, Maosong Sun", "title": "Word-level Textual Adversarial Attacking as Combinatorial Optimization", "comments": "Accepted at ACL 2020 as a long paper (a typo is corrected as compared\n  with the official conference camera-ready version). 16 pages, 3 figures", "journal-ref": null, "doi": "10.18653/v1/2020.acl-main.540", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks are carried out to reveal the vulnerability of deep\nneural networks. Textual adversarial attacking is challenging because text is\ndiscrete and a small perturbation can bring significant change to the original\ninput. Word-level attacking, which can be regarded as a combinatorial\noptimization problem, is a well-studied class of textual attack methods.\nHowever, existing word-level attack models are far from perfect, largely\nbecause unsuitable search space reduction methods and inefficient optimization\nalgorithms are employed. In this paper, we propose a novel attack model, which\nincorporates the sememe-based word substitution method and particle swarm\noptimization-based search algorithm to solve the two problems separately. We\nconduct exhaustive experiments to evaluate our attack model by attacking BiLSTM\nand BERT on three benchmark datasets. Experimental results demonstrate that our\nmodel consistently achieves much higher attack success rates and crafts more\nhigh-quality adversarial examples as compared to baseline methods. Also,\nfurther experiments show our model has higher transferability and can bring\nmore robustness enhancement to victim models by adversarial training. All the\ncode and data of this paper can be obtained on\nhttps://github.com/thunlp/SememePSO-Attack.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 06:54:27 GMT"}, {"version": "v2", "created": "Sun, 10 Nov 2019 11:20:10 GMT"}, {"version": "v3", "created": "Sat, 2 May 2020 09:54:31 GMT"}, {"version": "v4", "created": "Wed, 9 Dec 2020 09:38:21 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Zang", "Yuan", ""], ["Qi", "Fanchao", ""], ["Yang", "Chenghao", ""], ["Liu", "Zhiyuan", ""], ["Zhang", "Meng", ""], ["Liu", "Qun", ""], ["Sun", "Maosong", ""]]}, {"id": "1910.12207", "submitter": "Jialin Lu", "authors": "Jialin Lu, Martin Ester", "title": "An Active Approach for Model Interpretation", "comments": "NeurIPS 2019 workshop on Human-Centric Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model interpretation, or explanation of a machine learning classifier, aims\nto extract generalizable knowledge from a trained classifier into a\nhuman-understandable format, for various purposes such as model assessment,\ndebugging and trust. From a computaional viewpoint, it is formulated as\napproximating the target classifier using a simpler interpretable model, such\nas rule models like a decision set/list/tree. Often, this approximation is\nhandled as standard supervised learning and the only difference is that the\nlabels are provided by the target classifier instead of ground truth. This\nparadigm is particularly popular because there exists a variety of well-studied\nsupervised algorithms for learning an interpretable classifier. However, we\nargue that this paradigm is suboptimal for it does not utilize the unique\nproperty of the model interpretation problem, that is, the ability to generate\nsynthetic instances and query the target classifier for their labels. We call\nthis the active-query property, suggesting that we should consider model\ninterpretation from an active learning perspective. Following this insight, we\nargue that the active-query property should be employed when designing a model\ninterpretation algorithm, and that the generation of synthetic instances should\nbe integrated seamlessly with the algorithm that learns the model\ninterpretation. In this paper, we demonstrate that by doing so, it is possible\nto achieve more faithful interpretation with simpler model complexity. As a\ntechnical contribution, we present an active algorithm Active Decision Set\nInduction (ADS) to learn a decision set, a set of if-else rules, for model\ninterpretation. ADS performs a local search over the space of all decision\nsets. In every iteration, ADS computes confidence intervals for the value of\nthe objective function of all local actions and utilizes active-query to\ndetermine the best one.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 08:37:38 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Lu", "Jialin", ""], ["Ester", "Martin", ""]]}, {"id": "1910.12274", "submitter": "Elad Yom-Tov", "authors": "Brit Youngmann, Ran Gilad-Bachrach, Danny Karmon, Elad Yom-Tov", "title": "Algorithmic Copywriting: Automated Generation of Health-Related\n  Advertisements to Improve their Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search advertising, a popular method for online marketing, has been employed\nto improve health by eliciting positive behavioral change. However, writing\neffective advertisements requires expertise and experimentation, which may not\nbe available to health authorities wishing to elicit such changes, especially\nwhen dealing with public health crises such as epidemic outbreaks.\n  Here we develop a framework, comprised of two neural networks models, that\nautomatically generate ads. First, it employs a generator model, which create\nads from web pages. It then employs a translation model, which transcribes ads\nto improve performance.\n  We trained the networks using 114K health-related ads shown on Microsoft\nAdvertising. We measure ads performance using the click-through rates (CTR).\n  Our experiments show that the generated advertisements received approximately\nthe same CTR as human-authored ads. The marginal contribution of the generator\nmodel was, on average, 28\\% lower than that of human-authored ads, while the\ntranslator model received, on average, 32\\% more clicks than human-authored\nads. Our analysis shows that the translator model produces ads reflecting\nhigher values of psychological attributes associated with a user action,\nincluding higher valance and arousal, and more calls-to-actions. In contrast,\nlevels of these attributes in ads produced by the generator model are similar\nto those of human-authored ads.\n  Our results demonstrate the ability to automatically generate useful\nadvertisements for the health domain. We believe that our work offers health\nauthorities an improved ability to nudge people towards healthier behaviors\nwhile saving the time and cost needed to build effective advertising campaigns.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 14:51:53 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 18:00:36 GMT"}, {"version": "v3", "created": "Sun, 12 Jul 2020 07:22:00 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Youngmann", "Brit", ""], ["Gilad-Bachrach", "Ran", ""], ["Karmon", "Danny", ""], ["Yom-Tov", "Elad", ""]]}, {"id": "1910.12283", "submitter": "Chen Joya", "authors": "Xianfeng Liang, Likang Wu, Joya Chen, Yang Liu, Runlong Yu, Min Hou,\n  Han Wu, Yuyang Ye, Qi Liu, Enhong Chen", "title": "Long-term Joint Scheduling for Urban Traffic", "comments": "KDD Cup 2019 Special PaddlePaddle Award", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the traffic congestion in modern cities has become a growing worry\nfor the residents. As presented in Baidu traffic report, the commuting stress\nindex has reached surprising 1.973 in Beijing during rush hours, which results\nin longer trip time and increased vehicular queueing. Previous works have\ndemonstrated that by reasonable scheduling, e.g, rebalancing bike-sharing\nsystems and optimized bus transportation, the traffic efficiency could be\nsignificantly improved with little resource consumption. However, there are\nstill two disadvantages that restrict their performance: (1) they only consider\nsingle scheduling in a short time, but ignoring the layout after first\nreposition, and (2) they only focus on the single transport. However, the\nmulti-modal characteristics of urban public transportation are largely\nunder-exploited. In this paper, we propose an efficient and economical\nmulti-modal traffic scheduling scheme named JLRLS based on spatio -temporal\nprediction, which adopts reinforcement learning to obtain optimal long-term and\njoint schedule. In JLRLS, we combines multiple transportation to conduct\nscheduling by their own characteristics, which potentially helps the system to\nreach the optimal performance. Our implementation of an example by PaddlePaddle\nis available at https://github.com/bigdata-ustc/Long-term-Joint-Scheduling,\nwith an explaining video at https://youtu.be/t5M2wVPhTyk.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 15:16:59 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Liang", "Xianfeng", ""], ["Wu", "Likang", ""], ["Chen", "Joya", ""], ["Liu", "Yang", ""], ["Yu", "Runlong", ""], ["Hou", "Min", ""], ["Wu", "Han", ""], ["Ye", "Yuyang", ""], ["Liu", "Qi", ""], ["Chen", "Enhong", ""]]}, {"id": "1910.12294", "submitter": "Andreagiovanni Reina", "authors": "Andreagiovanni Reina, Viktor Ioannou, Junjin Chen, Lu Lu, Charles\n  Kent, James A. R. Marshall", "title": "Robots as Actors in a Film: No War, A Robot Story", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Will the Third World War be fought by robots? This short film is a\nlight-hearted comedy that aims to trigger an interesting discussion and\nreflexion on the terrifying killer-robot stories that increasingly fill us with\ndread when we read the news headlines. The fictional scenario takes inspiration\nfrom current scientific research and describes a future where robots are asked\nby humans to join the war. Robots are divided, sparking protests in robot\nsociety... will robots join the conflict or will they refuse to be employed in\nhuman warfare? Food for thought for engineers, roboticists and anyone imagining\nwhat the upcoming robot revolution could look like. We let robots pop on camera\nto tell a story, taking on the role of actors playing in the film, instructed\nthrough code on how to \"act\" for each scene.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 16:10:03 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Reina", "Andreagiovanni", ""], ["Ioannou", "Viktor", ""], ["Chen", "Junjin", ""], ["Lu", "Lu", ""], ["Kent", "Charles", ""], ["Marshall", "James A. R.", ""]]}, {"id": "1910.12346", "submitter": "Xiangyu Zhang", "authors": "Xiangyu Zhang, Sayan Mukherjee, Alvin R. Lebeck", "title": "A Case for Quantifying Statistical Robustness of Specialized\n  Probabilistic AI Accelerators", "comments": "Appears as a poster in 2019 IBM IEEE CAS/EDS - AI Compute Symposium,\n  Yorktown Heights, NY, Oct. 2019. Fixed Fig. 1c in the revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical machine learning often uses probabilistic algorithms, such as\nMarkov Chain Monte Carlo (MCMC), to solve a wide range of problems. Many\naccelerators are proposed using specialized hardware to address sampling\ninefficiency, the critical performance bottleneck of probabilistic algorithms.\nThese accelerators usually improve the hardware efficiency by using some\napproximation techniques, such as reducing bit representation, truncating small\nvalues to zero, or simplifying the Random Number Generator (RNG). Understanding\nthe influence of these approximations on result quality is crucial to meeting\nthe quality requirements of real applications. Although a common approach is to\ncompare the end-point result quality using community-standard benchmarks and\nmetrics, we claim a probabilistic architecture should provide some measure (or\nguarantee) of statistical robustness.\n  This work takes a first step towards quantifying the statistical robustness\nof specialized hardware MCMC accelerators by proposing three pillars of\nstatistical robustness: sampling quality, convergence diagnostic, and goodness\nof fit. Each pillar has at least one quantitative metric without the need to\nknow the ground truth data. We apply this method to analyze the statistical\nrobustness of an MCMC accelerator proposed by previous work, with some\nmodifications, as a case study. The method also applies to other probabilistic\naccelerators and can be used in design space exploration.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 20:42:31 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 03:33:29 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Zhang", "Xiangyu", ""], ["Mukherjee", "Sayan", ""], ["Lebeck", "Alvin R.", ""]]}, {"id": "1910.12354", "submitter": "Vladislav Kurenkov", "authors": "Vladislav Kurenkov, Bulat Maksudov, Adil Khan", "title": "Task-Oriented Language Grounding for Language Input with Multiple\n  Sub-Goals of Non-Linear Order", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we analyze the performance of general deep reinforcement\nlearning algorithms for a task-oriented language grounding problem, where\nlanguage input contains multiple sub-goals and their order of execution is\nnon-linear.\n  We generate a simple instructional language for the GridWorld environment,\nthat is built around three language elements (order connectors) defining the\norder of execution: one linear - \"comma\" and two non-linear - \"but first\", \"but\nbefore\". We apply one of the deep reinforcement learning baselines - Double DQN\nwith frame stacking and ablate several extensions such as Prioritized\nExperience Replay and Gated-Attention architecture.\n  Our results show that the introduction of non-linear order connectors\nimproves the success rate on instructions with a higher number of sub-goals in\n2-3 times, but it still does not exceed 20%. Also, we observe that the usage of\nGated-Attention provides no competitive advantage against concatenation in this\nsetting. Source code and experiments' results are available at\nhttps://github.com/vkurenkov/language-grounding-multigoal\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 21:11:42 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Kurenkov", "Vladislav", ""], ["Maksudov", "Bulat", ""], ["Khan", "Adil", ""]]}, {"id": "1910.12415", "submitter": "Phillip Smith Mr", "authors": "Phillip Smith, Aldeida Aleti, Vincent C.S. Lee, Robert Hunjet, Asad\n  Khan", "title": "Robotic Hierarchical Graph Neurons. A novel implementation of HGN for\n  swarm robotic behaviour control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the use of a novel form of Hierarchical Graph Neurons\n(HGN) for in-operation behaviour selection in a swarm of robotic agents. This\nnew HGN is called Robotic-HGN (R-HGN), as it matches robot environment\nobservations to environment labels via fusion of match probabilities from both\ntemporal and intra-swarm collections. This approach is novel for HGN as it\naddresses robotic observations being pseudo-continuous numbers, rather than\ncategorical values. Additionally, the proposed approach is memory and\ncomputation-power conservative and thus is acceptable for use in mobile devices\nsuch as single-board computers, which are often used in mobile robotic agents.\nThis R-HGN approach is validated against individual behaviour implementation\nand random behaviour selection. This contrast is made in two sets of simulated\nenvironments: environments designed to challenge the held behaviours of the\nR-HGN, and randomly generated environments which are more challenging for the\nrobotic swarm than R-HGN training conditions. R-HGN has been found to enable\nappropriate behaviour selection in both these sets, allowing significant swarm\nperformance in pre-trained and unexpected environment conditions.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 03:11:22 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Smith", "Phillip", ""], ["Aleti", "Aldeida", ""], ["Lee", "Vincent C. S.", ""], ["Hunjet", "Robert", ""], ["Khan", "Asad", ""]]}, {"id": "1910.12450", "submitter": "Gabriele Farina", "authors": "Gabriele Farina and Chun Kai Ling and Fei Fang and Tuomas Sandholm", "title": "Efficient Regret Minimization Algorithm for Extensive-Form Correlated\n  Equilibrium", "comments": "Full version of NeurIPS 2019 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-play methods based on regret minimization have become the state of the\nart for computing Nash equilibria in large two-players zero-sum extensive-form\ngames. These methods fundamentally rely on the hierarchical structure of the\nplayers' sequential strategy spaces to construct a regret minimizer that\nrecursively minimizes regret at each decision point in the game tree. In this\npaper, we introduce the first efficient regret minimization algorithm for\ncomputing extensive-form correlated equilibria in large two-player general-sum\ngames with no chance moves. Designing such an algorithm is significantly more\nchallenging than designing one for the Nash equilibrium counterpart, as the\nconstraints that define the space of correlation plans lack the hierarchical\nstructure and might even form cycles. We show that some of the constraints are\nredundant and can be excluded from consideration, and present an efficient\nalgorithm that generates the space of extensive-form correlation plans\nincrementally from the remaining constraints. This structural decomposition is\nachieved via a special convexity-preserving operation that we coin scaled\nextension. We show that a regret minimizer can be designed for a scaled\nextension of any two convex sets, and that from the decomposition we then\nobtain a global regret minimizer. Our algorithm produces feasible iterates.\nExperiments show that it significantly outperforms prior approaches and for\nlarger problems it is the only viable option.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 05:28:23 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Farina", "Gabriele", ""], ["Ling", "Chun Kai", ""], ["Fang", "Fei", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "1910.12453", "submitter": "Yunzhi Zhang", "authors": "Yunzhi Zhang, Ignasi Clavera, Boren Tsai, Pieter Abbeel", "title": "Asynchronous Methods for Model-Based Reinforcement Learning", "comments": "10 pages, CoRL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Significant progress has been made in the area of model-based reinforcement\nlearning. State-of-the-art algorithms are now able to match the asymptotic\nperformance of model-free methods while being significantly more data\nefficient. However, this success has come at a price: state-of-the-art\nmodel-based methods require significant computation interleaved with data\ncollection, resulting in run times that take days, even if the amount of agent\ninteraction might be just hours or even minutes. When considering the goal of\nlearning in real-time on real robots, this means these state-of-the-art\nmodel-based algorithms still remain impractical. In this work, we propose an\nasynchronous framework for model-based reinforcement learning methods that\nbrings down the run time of these algorithms to be just the data collection\ntime. We evaluate our asynchronous framework on a range of standard MuJoCo\nbenchmarks. We also evaluate our asynchronous framework on three real-world\nrobotic manipulation tasks. We show how asynchronous learning not only speeds\nup learning w.r.t wall-clock time through parallelization, but also further\nreduces the sample complexity of model-based approaches by means of improving\nthe exploration and by means of effectively avoiding the policy overfitting to\nthe deficiencies of learned dynamics models.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 05:45:39 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Zhang", "Yunzhi", ""], ["Clavera", "Ignasi", ""], ["Tsai", "Boren", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1910.12507", "submitter": "Genet Asefa Gesese", "authors": "Genet Asefa Gesese, Russa Biswas, Mehwish Alam, Harald Sack", "title": "A Survey on Knowledge Graph Embeddings with Literals: Which model links\n  better Literal-ly?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graphs (KGs) are composed of structured information about a\nparticular domain in the form of entities and relations. In addition to the\nstructured information KGs help in facilitating interconnectivity and\ninteroperability between different resources represented in the Linked Data\nCloud. KGs have been used in a variety of applications such as entity linking,\nquestion answering, recommender systems, etc. However, KG applications suffer\nfrom high computational and storage costs. Hence, there arises the necessity\nfor a representation able to map the high dimensional KGs into low dimensional\nspaces, i.e., embedding space, preserving structural as well as relational\ninformation. This paper conducts a survey of KG embedding models which not only\nconsider the structured information contained in the form of entities and\nrelations in a KG but also the unstructured information represented as literals\nsuch as text, numerical values, images, etc. Along with a theoretical analysis\nand comparison of the methods proposed so far for generating KG embeddings with\nliterals, an empirical evaluation of the different methods under identical\nsettings has been performed for the general task of link prediction.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 09:06:00 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 07:14:35 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Gesese", "Genet Asefa", ""], ["Biswas", "Russa", ""], ["Alam", "Mehwish", ""], ["Sack", "Harald", ""]]}, {"id": "1910.12544", "submitter": "Yi-Ching Huang", "authors": "Yi-Ching Huang and Yu-Ting Cheng and Lin-Lin Chen and Jane Yung-jen\n  Hsu", "title": "Human-AI Co-Learning for Data-Driven AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human and AI are increasingly interacting and collaborating to accomplish\nvarious complex tasks in the context of diverse application domains (e.g.,\nhealthcare, transportation, and creative design). Two dynamic, learning\nentities (AI and human) have distinct mental model, expertise, and ability;\nsuch fundamental difference/mismatch offers opportunities for bringing new\nperspectives to achieve better results. However, this mismatch can cause\nunexpected failure and result in serious consequences. While recent research\nhas paid much attention to enhancing interpretability or explainability to\nallow machine to explain how it makes a decision for supporting humans, this\nresearch argues that there is urging the need for both human and AI should\ndevelop specific, corresponding ability to interact and collaborate with each\nother to form a human-AI team to accomplish superior results. This research\nintroduces a conceptual framework called \"Co-Learning,\" in which people can\nlearn with/from and grow with AI partners over time. We characterize three key\nconcepts of co-learning: \"mutual understanding,\" \"mutual benefits,\" and \"mutual\ngrowth\" for facilitating human-AI collaboration on complex problem solving. We\nwill present proof-of-concepts to investigate whether and how our approach can\nhelp human-AI team to understand and benefit each other, and ultimately improve\nproductivity and creativity on creative problem domains. The insights will\ncontribute to the design of Human-AI collaboration.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 10:40:15 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Huang", "Yi-Ching", ""], ["Cheng", "Yu-Ting", ""], ["Chen", "Lin-Lin", ""], ["Hsu", "Jane Yung-jen", ""]]}, {"id": "1910.12580", "submitter": "Wanita Sherchan", "authors": "Wanita Sherchan, Simon Harris, Sue Ann Chen, Nebula Alam, Khoi-Nguyen\n  Tran, Adam J. Makarucha, Christopher J. Butler", "title": "Assessing Regulatory Risk in Personal Financial Advice Documents: a\n  Pilot Study", "comments": "Presented at AAAI FSS-19: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assessing regulatory compliance of personal financial advice is currently a\ncomplex manual process. In Australia, only 5%- 15% of advice documents are\naudited annually and 75% of these are found to be non-compliant(ASI 2018b).\nThis paper describes a pilot with an Australian government regulation agency\nwhere Artificial Intelligence (AI) models based on techniques such natural\nlanguage processing (NLP), machine learning and deep learning were developed to\nmethodically characterise the regulatory risk status of personal financial\nadvice documents. The solution provides traffic light rating of advice\ndocuments for various risk factors enabling comprehensive coverage of documents\nin the review and allowing rapid identification of documents that are at high\nrisk of non-compliance with government regulations. This pilot serves as a case\nstudy of public-private partnership in developing AI systems for government and\npublic sector.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 05:50:10 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Sherchan", "Wanita", ""], ["Harris", "Simon", ""], ["Chen", "Sue Ann", ""], ["Alam", "Nebula", ""], ["Tran", "Khoi-Nguyen", ""], ["Makarucha", "Adam J.", ""], ["Butler", "Christopher J.", ""]]}, {"id": "1910.12586", "submitter": "Yongkai Wu", "authors": "Yongkai Wu, Lu Zhang, Xintao Wu, Hanghang Tong", "title": "PC-Fairness: A Unified Framework for Measuring Causality-based Fairness", "comments": "Accepted as a poster to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent trend of fair machine learning is to define fairness as\ncausality-based notions which concern the causal connection between protected\nattributes and decisions. However, one common challenge of all causality-based\nfairness notions is identifiability, i.e., whether they can be uniquely\nmeasured from observational data, which is a critical barrier to applying these\nnotions to real-world situations. In this paper, we develop a framework for\nmeasuring different causality-based fairness. We propose a unified definition\nthat covers most of previous causality-based fairness notions, namely the\npath-specific counterfactual fairness (PC fairness). Based on that, we propose\na general method in the form of a constrained optimization problem for bounding\nthe path-specific counterfactual fairness under all unidentifiable situations.\nExperiments on synthetic and real-world datasets show the correctness and\neffectiveness of our method.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 23:00:53 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Wu", "Yongkai", ""], ["Zhang", "Lu", ""], ["Wu", "Xintao", ""], ["Tong", "Hanghang", ""]]}, {"id": "1910.12611", "submitter": "Shaoxiong Ji", "authors": "Shaoxiong Ji and Shirui Pan and Xue Li and Erik Cambria and Guodong\n  Long and Zi Huang", "title": "Suicidal Ideation Detection: A Review of Machine Learning Methods and\n  Applications", "comments": "IEEE Transactions on Computational Social Systems", "journal-ref": "IEEE Transactions on Computational Social Systems, 8(1), 2021, pp.\n  214-226", "doi": "10.1109/TCSS.2020.3021467", "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suicide is a critical issue in modern society. Early detection and prevention\nof suicide attempts should be addressed to save people's life. Current suicidal\nideation detection methods include clinical methods based on the interaction\nbetween social workers or experts and the targeted individuals and machine\nlearning techniques with feature engineering or deep learning for automatic\ndetection based on online social contents. This paper is the first survey that\ncomprehensively introduces and discusses the methods from these categories.\nDomain-specific applications of suicidal ideation detection are reviewed\naccording to their data sources, i.e., questionnaires, electronic health\nrecords, suicide notes, and online user content. Several specific tasks and\ndatasets are introduced and summarized to facilitate further research. Finally,\nwe summarize the limitations of current work and provide an outlook of further\nresearch directions.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 02:10:42 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 11:04:42 GMT"}, {"version": "v3", "created": "Tue, 1 Sep 2020 09:49:48 GMT"}, {"version": "v4", "created": "Sun, 6 Sep 2020 06:12:03 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Ji", "Shaoxiong", ""], ["Pan", "Shirui", ""], ["Li", "Xue", ""], ["Cambria", "Erik", ""], ["Long", "Guodong", ""], ["Huang", "Zi", ""]]}, {"id": "1910.12619", "submitter": "Laura Hollink", "authors": "Laura Hollink, Aysenur Bilgin, Jacco van Ossenbruggen", "title": "Is it a Fruit, an Apple or a Granny Smith? Predicting the Basic Level in\n  a Concept Hierarchy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The \"basic level\", according to experiments in cognitive psychology, is the\nlevel of abstraction in a hierarchy of concepts at which humans perform tasks\nquicker and with greater accuracy than at other levels. We argue that\napplications that use concept hierarchies - such as knowledge graphs,\nontologies or taxonomies - could significantly improve their user interfaces if\nthey `knew' which concepts are the basic level concepts. This paper examines to\nwhat extent the basic level can be learned from data. We test the utility of\nthree types of concept features, that were inspired by the basic level theory:\nlexical features, structural features and frequency features. We evaluate our\napproach on WordNet, and create a training set of manually labelled examples\nthat includes concepts from different domains. Our findings include that the\nbasic level concepts can be accurately identified within one domain. Concepts\nthat are difficult to label for humans are also harder to classify\nautomatically. Our experiments provide insight into how classification\nperformance across domains could be improved, which is necessary for\nidentification of basic level concepts on a larger scale.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 12:26:32 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Hollink", "Laura", ""], ["Bilgin", "Aysenur", ""], ["van Ossenbruggen", "Jacco", ""]]}, {"id": "1910.12639", "submitter": "Wenbo Zhang", "authors": "Wenbo Zhang, Osbert Bastani, Vijay Kumar", "title": "MAMPS: Safe Multi-Agent Reinforcement Learning via Model Predictive\n  Shielding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.MA cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is a promising approach to learning control policies\nfor performing complex multi-agent robotics tasks. However, a policy learned in\nsimulation often fails to guarantee even simple safety properties such as\nobstacle avoidance. To ensure safety, we propose multi-agent model predictive\nshielding (MAMPS), an algorithm that provably guarantees safety for an\narbitrary learned policy. In particular, it operates by using the learned\npolicy as often as possible, but instead uses a backup policy in cases where it\ncannot guarantee the safety of the learned policy. Using a multi-agent\nsimulation environment, we show how MAMPS can achieve good performance while\nensuring safety.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 01:26:04 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2019 03:03:04 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Zhang", "Wenbo", ""], ["Bastani", "Osbert", ""], ["Kumar", "Vijay", ""]]}, {"id": "1910.12760", "submitter": "Sofiene Jerbi", "authors": "Sofiene Jerbi, Lea M. Trenkwalder, Hendrik Poulsen Nautrup, Hans J.\n  Briegel, Vedran Dunjko", "title": "Quantum enhancements for deep reinforcement learning in large spaces", "comments": "Significant number of new analyses and results", "journal-ref": "PRX Quantum 2, 010328 (2021)", "doi": "10.1103/PRXQuantum.2.010328", "report-no": null, "categories": "quant-ph cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decade, the field of quantum machine learning has drawn\nsignificant attention due to the prospect of bringing genuine computational\nadvantages to now widespread algorithmic methods. However, not all domains of\nmachine learning have benefited equally from quantum enhancements. Notably,\ndeep learning and reinforcement learning, despite their tremendous success in\nthe classical domain, both individually and combined, remain relatively\nunaddressed by the quantum community. Arguably, one reason behind this is the\nsystematic use in these domains of models and methods without prominent\ncomputational bottlenecks, leaving little room for quantum improvements. In\nthis work, we study the state-of-the-art neural-network approaches for\nreinforcement learning with quantum enhancements in mind. We demonstrate the\nsubstantial learning advantage that models with a sampling bottleneck can\nprovide over conventional neural network architectures in complex learning\nenvironments. These so-called energy-based models, like deep energy-based\nreinforcement learning, and deep projective simulation that we also introduce\nin this work, effectively allow to trade off learning performance for\nefficiency of computation. To alleviate the additional computational costs, we\npropose to leverage future and near-term quantum algorithms, resulting in\noverall more advantageous learning algorithms. This is achieved using\ncutting-edge and new quantum computing machinery to speed-up classical sampling\nmethods and by employing generalized models to gain an additional quantum\nadvantage.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 15:41:19 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 17:32:44 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Jerbi", "Sofiene", ""], ["Trenkwalder", "Lea M.", ""], ["Nautrup", "Hendrik Poulsen", ""], ["Briegel", "Hans J.", ""], ["Dunjko", "Vedran", ""]]}, {"id": "1910.12903", "submitter": "Xiaoyu Cao", "authors": "Xiaoyu Cao, Jinyuan Jia and Neil Zhenqiang Gong", "title": "IPGuard: Protecting Intellectual Property of Deep Neural Networks via\n  Fingerprinting the Classification Boundary", "comments": "Accepted by AsiaCCS'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A deep neural network (DNN) classifier represents a model owner's\nintellectual property as training a DNN classifier often requires lots of\nresource. Watermarking was recently proposed to protect the intellectual\nproperty of DNN classifiers. However, watermarking suffers from a key\nlimitation: it sacrifices the utility/accuracy of the model owner's classifier\nbecause it tampers the classifier's training or fine-tuning process. In this\nwork, we propose IPGuard, the first method to protect intellectual property of\nDNN classifiers that provably incurs no accuracy loss for the classifiers. Our\nkey observation is that a DNN classifier can be uniquely represented by its\nclassification boundary. Based on this observation, IPGuard extracts some data\npoints near the classification boundary of the model owner's classifier and\nuses them to fingerprint the classifier. A DNN classifier is said to be a\npirated version of the model owner's classifier if they predict the same labels\nfor most fingerprinting data points. IPGuard is qualitatively different from\nwatermarking. Specifically, IPGuard extracts fingerprinting data points near\nthe classification boundary of a classifier that is already trained, while\nwatermarking embeds watermarks into a classifier during its training or\nfine-tuning process. We extensively evaluate IPGuard on CIFAR-10, CIFAR-100,\nand ImageNet datasets. Our results show that IPGuard can robustly identify\npost-processed versions of the model owner's classifier as pirated versions of\nthe classifier, and IPGuard can identify classifiers, which are not the model\nowner's classifier nor its post-processed versions, as non-pirated versions of\nthe classifier.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 18:39:49 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 15:54:57 GMT"}, {"version": "v3", "created": "Sat, 11 Apr 2020 17:19:58 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 19:27:24 GMT"}, {"version": "v5", "created": "Sat, 31 Oct 2020 15:19:17 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Cao", "Xiaoyu", ""], ["Jia", "Jinyuan", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "1910.12908", "submitter": "Bj\\\"orn L\\\"utjens", "authors": "Bj\\\"orn L\\\"utjens, Michael Everett, Jonathan P. How", "title": "Certified Adversarial Robustness for Deep Reinforcement Learning", "comments": "Published at Conference on Robot Learning (CoRL) 2019; (v2) contains\n  minor updates to related works; (v3) acknowledged AWS", "journal-ref": "Proceedings of Machine Learning Research (PMLR) Vol. 100, 2019", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Network-based systems are now the state-of-the-art in many\nrobotics tasks, but their application in safety-critical domains remains\ndangerous without formal guarantees on network robustness. Small perturbations\nto sensor inputs (from noise or adversarial examples) are often enough to\nchange network-based decisions, which was already shown to cause an autonomous\nvehicle to swerve into oncoming traffic. In light of these dangers, numerous\nalgorithms have been developed as defensive mechanisms from these adversarial\ninputs, some of which provide formal robustness guarantees or certificates.\nThis work leverages research on certified adversarial robustness to develop an\nonline certified defense for deep reinforcement learning algorithms. The\nproposed defense computes guaranteed lower bounds on state-action values during\nexecution to identify and choose the optimal action under a worst-case\ndeviation in input space due to possible adversaries or noise. The approach is\ndemonstrated on a Deep Q-Network policy and is shown to increase robustness to\nnoise and adversaries in pedestrian collision avoidance scenarios and a classic\ncontrol task.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 18:45:38 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 00:29:33 GMT"}, {"version": "v3", "created": "Fri, 6 Mar 2020 19:20:21 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["L\u00fctjens", "Bj\u00f6rn", ""], ["Everett", "Michael", ""], ["How", "Jonathan P.", ""]]}, {"id": "1910.12911", "submitter": "Maximilian Igl", "authors": "Maximilian Igl, Kamil Ciosek, Yingzhen Li, Sebastian Tschiatschek,\n  Cheng Zhang, Sam Devlin, Katja Hofmann", "title": "Generalization in Reinforcement Learning with Selective Noise Injection\n  and Information Bottleneck", "comments": "Published at Neurips 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability for policies to generalize to new environments is key to the\nbroad application of RL agents. A promising approach to prevent an agent's\npolicy from overfitting to a limited set of training environments is to apply\nregularization techniques originally developed for supervised learning.\nHowever, there are stark differences between supervised learning and RL. We\ndiscuss those differences and propose modifications to existing regularization\ntechniques in order to better adapt them to RL. In particular, we focus on\nregularization techniques relying on the injection of noise into the learned\nfunction, a family that includes some of the most widely used approaches such\nas Dropout and Batch Normalization. To adapt them to RL, we propose Selective\nNoise Injection (SNI), which maintains the regularizing effect the injected\nnoise has, while mitigating the adverse effects it has on the gradient quality.\nFurthermore, we demonstrate that the Information Bottleneck (IB) is a\nparticularly well suited regularization technique for RL as it is effective in\nthe low-data regime encountered early on in training RL agents. Combining the\nIB with SNI, we significantly outperform current state of the art results,\nincluding on the recently proposed generalization benchmark Coinrun.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 18:51:54 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Igl", "Maximilian", ""], ["Ciosek", "Kamil", ""], ["Li", "Yingzhen", ""], ["Tschiatschek", "Sebastian", ""], ["Zhang", "Cheng", ""], ["Devlin", "Sam", ""], ["Hofmann", "Katja", ""]]}, {"id": "1910.12952", "submitter": "Rajabi Masoumi Mina", "authors": "Mina Rajabi, Hajar Sadeghizadeh, Zahra Mola-Amini, Niloofar Ahmadyrad", "title": "Hybrid Adaptive Neuro-Fuzzy Inference System for Diagnosing the Liver\n  Disorders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, a hybrid method based on an Adaptive Neuro-Fuzzy Inference\nSystem (ANFIS) and Particle Swarm Optimization (PSO) for diagnosing Liver\ndisorders (ANFIS-PSO) is introduced. This smart diagnosis method deals with a\ncombination of making an inference system and optimization process which tries\nto tune the hyper-parameters of ANFIS based on the data-set. The Liver diseases\ncharacteristics are taken from the UCI Repository of Machine Learning\nDatabases. The number of these characteristic attributes are 7, and the sample\nnumber is 354. The right diagnosis performance of the ANFIS-PSO intelligent\nmedical system for liver disease is evaluated by using classification accuracy,\nsensitivity and specificity analysis, respectively. According to the\nexperimental results, the performance of ANFIS-PSO can be more considerable\nthan traditional FIS and ANFIS without optimization phase.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 05:53:54 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Rajabi", "Mina", ""], ["Sadeghizadeh", "Hajar", ""], ["Mola-Amini", "Zahra", ""], ["Ahmadyrad", "Niloofar", ""]]}, {"id": "1910.12969", "submitter": "Qin Lin", "authors": "Qin Lin, Wenshuo Wang, Yihuan Zhang, John Dolan", "title": "Measuring Similarity of Interactive Driving Behaviors Using Matrix\n  Profile", "comments": "ACC final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding multi-vehicle interactive behaviors with temporal sequential\nobservations is crucial for autonomous vehicles to make appropriate decisions\nin an uncertain traffic environment. On-demand similarity measures are\nsignificant for autonomous vehicles to deal with massive interactive driving\nbehaviors by clustering and classifying diverse scenarios. This paper proposes\na general approach for measuring spatiotemporal similarity of interactive\nbehaviors using a multivariate matrix profile technique. The key attractive\nfeatures of the approach are its superior space and time complexity, real-time\nonline computing for streaming traffic data, and possible capability of\nleveraging hardware for parallel computation. The proposed approach is\nvalidated through automatically discovering similar interactive driving\nbehaviors at intersections from sequential data.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 20:58:43 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 15:20:43 GMT"}, {"version": "v3", "created": "Wed, 11 Mar 2020 21:46:05 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Lin", "Qin", ""], ["Wang", "Wenshuo", ""], ["Zhang", "Yihuan", ""], ["Dolan", "John", ""]]}, {"id": "1910.13012", "submitter": "Nick Petosa", "authors": "Nick Petosa and Tucker Balch", "title": "Multiplayer AlphaZero", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The AlphaZero algorithm has achieved superhuman performance in two-player,\ndeterministic, zero-sum games where perfect information of the game state is\navailable. This success has been demonstrated in Chess, Shogi, and Go where\nlearning occurs solely through self-play. Many real-world applications (e.g.,\nequity trading) require the consideration of a multiplayer environment. In this\nwork, we suggest novel modifications of the AlphaZero algorithm to support\nmultiplayer environments, and evaluate the approach in two simple 3-player\ngames. Our experiments show that multiplayer AlphaZero learns successfully and\nconsistently outperforms a competing approach: Monte Carlo tree search. These\nresults suggest that our modified AlphaZero can learn effective strategies in\nmultiplayer game scenarios. Our work supports the use of AlphaZero in\nmultiplayer games and suggests future research for more complex environments.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 00:06:01 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 03:02:04 GMT"}, {"version": "v3", "created": "Mon, 9 Dec 2019 06:20:54 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Petosa", "Nick", ""], ["Balch", "Tucker", ""]]}, {"id": "1910.13045", "submitter": "Fengqi You", "authors": "Akshay Ajagekar, Travis Humble, Fengqi You", "title": "Quantum Computing based Hybrid Solution Strategies for Large-scale\n  Discrete-Continuous Optimization Problems", "comments": null, "journal-ref": null, "doi": "10.1016/j.compchemeng.2019.106630", "report-no": null, "categories": "quant-ph cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computing (QC) has gained popularity due to its unique capabilities\nthat are quite different from that of classical computers in terms of speed and\nmethods of operations. This paper proposes hybrid models and methods that\neffectively leverage the complementary strengths of deterministic algorithms\nand QC techniques to overcome combinatorial complexity for solving large-scale\nmixed-integer programming problems. Four applications, namely the molecular\nconformation problem, job-shop scheduling problem, manufacturing cell formation\nproblem, and the vehicle routing problem, are specifically addressed.\nLarge-scale instances of these application problems across multiple scales\nranging from molecular design to logistics optimization are computationally\nchallenging for deterministic optimization algorithms on classical computers.\nTo address the computational challenges, hybrid QC-based algorithms are\nproposed and extensive computational experimental results are presented to\ndemonstrate their applicability and efficiency. The proposed QC-based solution\nstrategies enjoy high computational efficiency in terms of solution quality and\ncomputation time, by utilizing the unique features of both classical and\nquantum computers.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 02:30:51 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Ajagekar", "Akshay", ""], ["Humble", "Travis", ""], ["You", "Fengqi", ""]]}, {"id": "1910.13088", "submitter": "Tuhin Sahai", "authors": "Tuhin Sahai, Anurag Mishra, Jose Miguel Pasini, and Susmit Jha", "title": "Estimating the Density of States of Boolean Satisfiability Problems on\n  Classical and Quantum Computing Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.AI cs.LO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a Boolean formula $\\phi(x)$ in conjunctive normal form (CNF), the\ndensity of states counts the number of variable assignments that violate\nexactly $e$ clauses, for all values of $e$. Thus, the density of states is a\nhistogram of the number of unsatisfied clauses over all possible assignments.\nThis computation generalizes both maximum-satisfiability (MAX-SAT) and model\ncounting problems and not only provides insight into the entire solution space,\nbut also yields a measure for the \\emph{hardness} of the problem instance.\nConsequently, in real-world scenarios, this problem is typically infeasible\neven when using state-of-the-art algorithms. While finding an exact answer to\nthis problem is a computationally intensive task, we propose a novel approach\nfor estimating density of states based on the concentration of measure\ninequalities. The methodology results in a quadratic unconstrained binary\noptimization (QUBO), which is particularly amenable to quantum annealing-based\nsolutions. We present the overall approach and compare results from the D-Wave\nquantum annealer against the best-known classical algorithms such as the\nHamze-de Freitas-Selby (HFS) algorithm and satisfiability modulo theory (SMT)\nsolvers.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 05:09:56 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Sahai", "Tuhin", ""], ["Mishra", "Anurag", ""], ["Pasini", "Jose Miguel", ""], ["Jha", "Susmit", ""]]}, {"id": "1910.13105", "submitter": "Bo Chen", "authors": "Bo Chen, Jing Zhang, Xiaobin Tang, Hong Chen, Cuiping Li", "title": "JarKA: Modeling Attribute Interactions for Cross-lingual Knowledge\n  Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract. Cross-lingual knowledge alignment is the cornerstone in building a\ncomprehensive knowledge graph (KG), which can benefit various knowledge-driven\napplications. As the structures of KGs are usually sparse, attributes of\nentities may play an important role in aligning the entities. However, the\nheterogeneity of the attributes across KGs prevents from accurately embedding\nand comparing entities. To deal with the issue, we propose to model the\ninteractions between attributes, instead of globally embedding an entity with\nall the attributes. We further propose a joint framework to merge the\nalignments inferred from the attributes and the structures. Experimental\nresults show that the proposed model outperforms the state-of-art baselines by\nup to 38.48% HitRatio@1. The results also demonstrate that our model can infer\nthe alignments between attributes, relationships and values, in addition to\nentities.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 06:41:30 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 08:15:00 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Chen", "Bo", ""], ["Zhang", "Jing", ""], ["Tang", "Xiaobin", ""], ["Chen", "Hong", ""], ["Li", "Cuiping", ""]]}, {"id": "1910.13108", "submitter": "Cao Liu", "authors": "Cao Liu, Kang Liu, Shizhu He, Zaiqing Nie and Jun Zhao", "title": "Generating Questions for Knowledge Bases via Incorporating Diversified\n  Contexts and Answer-Aware Loss", "comments": "Accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the task of question generation over knowledge bases. Conventional\nmethods for this task neglect two crucial research issues: 1) the given\npredicate needs to be expressed; 2) the answer to the generated question needs\nto be definitive. In this paper, we strive toward the above two issues via\nincorporating diversified contexts and answer-aware loss. Specifically, we\npropose a neural encoder-decoder model with multi-level copy mechanisms to\ngenerate such questions. Furthermore, the answer aware loss is introduced to\nmake generated questions corresponding to more definitive answers. Experiments\ndemonstrate that our model achieves state-of-the-art performance. Meanwhile,\nsuch generated question can express the given predicate and correspond to a\ndefinitive answer.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 06:45:24 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Liu", "Cao", ""], ["Liu", "Kang", ""], ["He", "Shizhu", ""], ["Nie", "Zaiqing", ""], ["Zhao", "Jun", ""]]}, {"id": "1910.13114", "submitter": "Hongfei Yu", "authors": "Xiangyu Duan, Hoongfei Yu, Mingming Yin, Min Zhang, Weihua Luo, Yue\n  Zhang", "title": "Contrastive Attention Mechanism for Abstractive Sentence Summarization", "comments": "accepted by EMNLP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a contrastive attention mechanism to extend the\nsequence-to-sequence framework for abstractive sentence summarization task,\nwhich aims to generate a brief summary of a given source sentence. The proposed\ncontrastive attention mechanism accommodates two categories of attention: one\nis the conventional attention that attends to relevant parts of the source\nsentence, the other is the opponent attention that attends to irrelevant or\nless relevant parts of the source sentence. Both attentions are trained in an\nopposite way so that the contribution from the conventional attention is\nencouraged and the contribution from the opponent attention is discouraged\nthrough a novel softmax and softmin functionality. Experiments on benchmark\ndatasets show that, the proposed contrastive attention mechanism is more\nfocused on the relevant parts for the summary than the conventional attention\nmechanism, and greatly advances the state-of-the-art performance on the\nabstractive sentence summarization task. We release the code at\nhttps://github.com/travel-go/Abstractive-Text-Summarization\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 06:56:46 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 05:33:27 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Duan", "Xiangyu", ""], ["Yu", "Hoongfei", ""], ["Yin", "Mingming", ""], ["Zhang", "Min", ""], ["Luo", "Weihua", ""], ["Zhang", "Yue", ""]]}, {"id": "1910.13122", "submitter": "Araz Taeihagh", "authors": "Hazel Si Min Lim, and Araz Taeihagh", "title": "Algorithmic decision-making in AVs: Understanding ethical and technical\n  concerns for smart cities", "comments": null, "journal-ref": "Sustainability, 2019, 11(20), 5791", "doi": "10.3390/su11205791", "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Autonomous Vehicles (AVs) are increasingly embraced around the world to\nadvance smart mobility and more broadly, smart, and sustainable cities.\nAlgorithms form the basis of decision-making in AVs, allowing them to perform\ndriving tasks autonomously, efficiently, and more safely than human drivers and\noffering various economic, social, and environmental benefits. However,\nalgorithmic decision-making in AVs can also introduce new issues that create\nnew safety risks and perpetuate discrimination. We identify bias, ethics, and\nperverse incentives as key ethical issues in the AV algorithms' decision-making\nthat can create new safety risks and discriminatory outcomes. Technical issues\nin the AVs' perception, decision-making and control algorithms, limitations of\nexisting AV testing and verification methods, and cybersecurity vulnerabilities\ncan also undermine the performance of the AV system. This article investigates\nthe ethical and technical concerns surrounding algorithmic decision-making in\nAVs by exploring how driving decisions can perpetuate discrimination and create\nnew safety risks for the public. We discuss steps taken to address these\nissues, highlight the existing research gaps and the need to mitigate these\nissues through the design of AV's algorithms and of policies and regulations to\nfully realise AVs' benefits for smart and sustainable cities.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 07:50:02 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Lim", "Hazel Si Min", ""], ["Taeihagh", "Araz", ""]]}, {"id": "1910.13197", "submitter": "Ghodai Abdelrahman", "authors": "Ghodai Abdelrahman and Qing Wang", "title": "Knowledge Tracing with Sequential Key-Value Memory Networks", "comments": null, "journal-ref": "Proceedings of the 42Nd International ACM SIGIR Conference on\n  Research and Development in Information Retrieval (2019)", "doi": "10.1145/3331184.3331195", "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Can machines trace human knowledge like humans? Knowledge tracing (KT) is a\nfundamental task in a wide range of applications in education, such as massive\nopen online courses (MOOCs), intelligent tutoring systems, educational games,\nand learning management systems. It models dynamics in a student's knowledge\nstates in relation to different learning concepts through their interactions\nwith learning activities. Recently, several attempts have been made to use deep\nlearning models for tackling the KT problem. Although these deep learning\nmodels have shown promising results, they have limitations: either lack the\nability to go deeper to trace how specific concepts in a knowledge state are\nmastered by a student, or fail to capture long-term dependencies in an exercise\nsequence. In this paper, we address these limitations by proposing a novel deep\nlearning model for knowledge tracing, namely Sequential Key-Value Memory\nNetworks (SKVMN). This model unifies the strengths of recurrent modelling\ncapacity and memory capacity of the existing deep learning KT models for\nmodelling student learning. We have extensively evaluated our proposed model on\nfive benchmark datasets. The experimental results show that (1) SKVMN\noutperforms the state-of-the-art KT models on all datasets, (2) SKVMN can\nbetter discover the correlation between latent concepts and questions, and (3)\nSKVMN can trace the knowledge state of students dynamics, and a leverage\nsequential dependencies in an exercise sequence for improved predication\naccuracy.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 11:10:50 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Abdelrahman", "Ghodai", ""], ["Wang", "Qing", ""]]}, {"id": "1910.13213", "submitter": "Yat Long Lo", "authors": "Yat Long Lo and Sina Ghiassian", "title": "Overcoming Catastrophic Interference in Online Reinforcement Learning\n  with Dynamic Self-Organizing Maps", "comments": "9 Pages, 7 Figures, NeurIPS Workshop on Biological and Artificial\n  Reinforcement Learning, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using neural networks in the reinforcement learning (RL) framework has\nachieved notable successes. Yet, neural networks tend to forget what they\nlearned in the past, especially when they learn online and fully incrementally,\na setting in which the weights are updated after each sample is received and\nthe sample is then discarded. Under this setting, an update can lead to overly\nglobal generalization by changing too many weights. The global generalization\ninterferes with what was previously learned and deteriorates performance, a\nphenomenon known as catastrophic interference. Many previous works use\nmechanisms such as experience replay (ER) buffers to mitigate interference by\nperforming minibatch updates, ensuring the data distribution is approximately\nindependent-and-identically-distributed (i.i.d.). But using ER would become\ninfeasible in terms of memory as problem complexity increases. Thus, it is\ncrucial to look for more memory-efficient alternatives. Interference can be\naverted if we replace global updates with more local ones, so only weights\nresponsible for the observed data sample are updated. In this work, we propose\nthe use of dynamic self-organizing map (DSOM) with neural networks to induce\nsuch locality in the updates without ER buffers. Our method learns a DSOM to\nproduce a mask to reweigh each hidden unit's output, modulating its degree of\nuse. It prevents interference by replacing global updates with local ones,\nconditioned on the agent's state. We validate our method on standard RL\nbenchmarks including Mountain Car and Lunar Lander, where existing methods\noften fail to learn without ER. Empirically, we show that our online and fully\nincremental method is on par with and in some cases, better than\nstate-of-the-art in terms of final performance and learning speed. We provide\nvisualizations and quantitative measures to show that our method indeed\nmitigates interference.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 11:50:39 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Lo", "Yat Long", ""], ["Ghiassian", "Sina", ""]]}, {"id": "1910.13272", "submitter": "Tyler Westenbroek", "authors": "Tyler Westenbroek, David Fridovich-Keil, Eric Mazumdar, Shreyas Arora,\n  Valmik Prabhu, S. Shankar Sastry, and Claire J. Tomlin", "title": "Feedback Linearization for Unknown Systems via Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel approach to control design for nonlinear systems which\nleverages model-free policy optimization techniques to learn a linearizing\ncontroller for a physical plant with unknown dynamics. Feedback linearization\nis a technique from nonlinear control which renders the input-output dynamics\nof a nonlinear plant \\emph{linear} under application of an appropriate feedback\ncontroller. Once a linearizing controller has been constructed, desired output\ntrajectories for the nonlinear plant can be tracked using a variety of linear\ncontrol techniques. However, the calculation of a linearizing controller\nrequires a precise dynamics model for the system. As a result, model-based\napproaches for learning exact linearizing controllers generally require a\nsimple, highly structured model of the system with easily identifiable\nparameters. In contrast, the model-free approach presented in this paper is\nable to approximate the linearizing controller for the plant using general\nfunction approximation architectures. Specifically, we formulate a\ncontinuous-time optimization problem over the parameters of a learned\nlinearizing controller whose optima are the set of parameters which best\nlinearize the plant. We derive conditions under which the learning problem is\n(strongly) convex and provide guarantees which ensure the true linearizing\ncontroller for the plant is recovered. We then discuss how model-free policy\noptimization algorithms can be used to solve a discrete-time approximation to\nthe problem using data collected from the real-world plant. The utility of the\nframework is demonstrated in simulation and on a real-world robotic platform.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 13:52:04 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 22:34:56 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Westenbroek", "Tyler", ""], ["Fridovich-Keil", "David", ""], ["Mazumdar", "Eric", ""], ["Arora", "Shreyas", ""], ["Prabhu", "Valmik", ""], ["Sastry", "S. Shankar", ""], ["Tomlin", "Claire J.", ""]]}, {"id": "1910.13351", "submitter": "Donald Wunsch", "authors": "Donald C. Wunsch", "title": "Admiring the Great Mountain: A Celebration Special Issue in Honor of\n  Stephen Grossbergs 80th Birthday", "comments": "Editorial for Special Issue of Neural Networks in honor of\n  Grossberg's 80th birthday", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This editorial summarizes selected key contributions of Prof. Stephen\nGrossberg and describes the papers in this 80th birthday special issue in his\nhonor. His productivity, creativity, and vision would each be enough to mark a\nscientist of the first caliber. In combination, they have resulted in\ncontributions that have changed the entire discipline of neural networks.\nGrossberg has been tremendously influential in engineering, dynamical systems,\nand artificial intelligence as well. Indeed, he has been one of the most\nimportant mentors and role models in my career, and has done so with\nextraordinary generosity and encouragement. All authors in this special issue\nhave taken great pleasure in hereby commemorating his extraordinary career and\ncontributions.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 09:17:01 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Wunsch", "Donald C.", ""]]}, {"id": "1910.13399", "submitter": "Matteo Turchetta", "authors": "Matteo Turchetta, Andreas Krause, Sebastian Trimpe", "title": "Robust Model-free Reinforcement Learning with Multi-objective Bayesian\n  Optimization", "comments": "Submitted to IEEE Conference on Robotics and Automation 2020 (ICRA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning (RL), an autonomous agent learns to perform complex\ntasks by maximizing an exogenous reward signal while interacting with its\nenvironment. In real-world applications, test conditions may differ\nsubstantially from the training scenario and, therefore, focusing on pure\nreward maximization during training may lead to poor results at test time. In\nthese cases, it is important to trade-off between performance and robustness\nwhile learning a policy. While several results exist for robust, model-based\nRL, the model-free case has not been widely investigated. In this paper, we\ncast the robust, model-free RL problem as a multi-objective optimization\nproblem. To quantify the robustness of a policy, we use delay margin and gain\nmargin, two robustness indicators that are common in control theory. We show\nhow these metrics can be estimated from data in the model-free setting. We use\nmulti-objective Bayesian optimization (MOBO) to solve efficiently this\nexpensive-to-evaluate, multi-objective optimization problem. We show the\nbenefits of our robust formulation both in sim-to-real and pure hardware\nexperiments to balance a Furuta pendulum.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 17:00:05 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Turchetta", "Matteo", ""], ["Krause", "Andreas", ""], ["Trimpe", "Sebastian", ""]]}, {"id": "1910.13406", "submitter": "Meire Fortunato", "authors": "Meire Fortunato, Melissa Tan, Ryan Faulkner, Steven Hansen, Adri\\`a\n  Puigdom\\`enech Badia, Gavin Buttimore, Charlie Deck, Joel Z Leibo, Charles\n  Blundell", "title": "Generalization of Reinforcement Learners with Working and Episodic\n  Memory", "comments": "NeurIPS 2019. Equal contribution of first 4 authors", "journal-ref": "33rd Conference on Neural Information Processing Systems (Neurips\n  2019)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory is an important aspect of intelligence and plays a role in many deep\nreinforcement learning models. However, little progress has been made in\nunderstanding when specific memory systems help more than others and how well\nthey generalize. The field also has yet to see a prevalent consistent and\nrigorous approach for evaluating agent performance on holdout data. In this\npaper, we aim to develop a comprehensive methodology to test different kinds of\nmemory in an agent and assess how well the agent can apply what it learns in\ntraining to a holdout set that differs from the training set along dimensions\nthat we suggest are relevant for evaluating memory-specific generalization. To\nthat end, we first construct a diverse set of memory tasks that allow us to\nevaluate test-time generalization across multiple dimensions. Second, we\ndevelop and perform multiple ablations on an agent architecture that combines\nmultiple memory systems, observe its baseline models, and investigate its\nperformance against the task suite.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 17:07:53 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 01:08:38 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Fortunato", "Meire", ""], ["Tan", "Melissa", ""], ["Faulkner", "Ryan", ""], ["Hansen", "Steven", ""], ["Badia", "Adri\u00e0 Puigdom\u00e8nech", ""], ["Buttimore", "Gavin", ""], ["Deck", "Charlie", ""], ["Leibo", "Joel Z", ""], ["Blundell", "Charles", ""]]}, {"id": "1910.13493", "submitter": "Daniel Kumor", "authors": "Daniel Kumor, Bryant Chen, Elias Bareinboim", "title": "Efficient Identification in Linear Structural Causal Models with\n  Instrumental Cutsets", "comments": "To appear at 33rd Conference on Neural Information Processing Systems\n  (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": "R-49", "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most common mistakes made when performing data analysis is\nattributing causal meaning to regression coefficients. Formally, a causal\neffect can only be computed if it is identifiable from a combination of\nobservational data and structural knowledge about the domain under\ninvestigation (Pearl, 2000, Ch. 5). Building on the literature of instrumental\nvariables (IVs), a plethora of methods has been developed to identify causal\neffects in linear systems. Almost invariably, however, the most powerful such\nmethods rely on exponential-time procedures. In this paper, we investigate\ngraphical conditions to allow efficient identification in arbitrary linear\nstructural causal models (SCMs). In particular, we develop a method to\nefficiently find unconditioned instrumental subsets, which are generalizations\nof IVs that can be used to tame the complexity of many canonical algorithms\nfound in the literature. Further, we prove that determining whether an effect\ncan be identified with TSID (Weihs et al., 2017), a method more powerful than\nunconditioned instrumental sets and other efficient identification algorithms,\nis NP-Complete. Finally, building on the idea of flow constraints, we introduce\na new and efficient criterion called Instrumental Cutsets (IC), which is able\nto solve for parameters missed by all other existing polynomial-time\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 19:36:32 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Kumor", "Daniel", ""], ["Chen", "Bryant", ""], ["Bareinboim", "Elias", ""]]}, {"id": "1910.13503", "submitter": "David Alvarez-Melis", "authors": "David Alvarez-Melis, Hal Daum\\'e III, Jennifer Wortman Vaughan, Hanna\n  Wallach", "title": "Weight of Evidence as a Basis for Human-Oriented Explanations", "comments": "Human-Centric Machine Learning (HCML) Workshop @ NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability is an elusive but highly sought-after characteristic of\nmodern machine learning methods. Recent work has focused on interpretability\nvia $\\textit{explanations}$, which justify individual model predictions. In\nthis work, we take a step towards reconciling machine explanations with those\nthat humans produce and prefer by taking inspiration from the study of\nexplanation in philosophy, cognitive science, and the social sciences. We\nidentify key aspects in which these human explanations differ from current\nmachine explanations, distill them into a list of desiderata, and formalize\nthem into a framework via the notion of $\\textit{weight of evidence}$ from\ninformation theory. Finally, we instantiate this framework in two simple\napplications and show it produces intuitive and comprehensible explanations.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 19:53:23 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Alvarez-Melis", "David", ""], ["Daum\u00e9", "Hal", "III"], ["Vaughan", "Jennifer Wortman", ""], ["Wallach", "Hanna", ""]]}, {"id": "1910.13513", "submitter": "Minh Ho\\`ang H\\`a", "authors": "Minh Ho\\`ang H\\`a, Tat Dat Nguyen, Thinh Nguyen Duy, Hoang Giang Pham,\n  Thuy Do, Louis-Martin Rousseau", "title": "A new constraint programming model and a linear programming-based\n  adaptive large neighborhood search for the vehicle routing problem with\n  synchronization constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a vehicle routing problem which seeks to minimize cost subject to\ntime window and synchronization constraints. In this problem, the fleet of\nvehicles is categorized into regular and special vehicles. Some customers\nrequire both vehicles' services, whose starting service times at the customer\nare synchronized. Despite its important real-world application, this problem\nhas rarely been studied in the literature. To solve the problem, we propose a\nConstraint Programming (CP) model and an Adaptive Large Neighborhood Search\n(ALNS) in which the design of insertion operators is based on solving linear\nprogramming (LP) models to check the insertion feasibility. A number of\nacceleration techniques is also proposed to significantly reduce the\ncomputational time. The computational experiments show that our new CP model\nfinds better solutions than an existing CP-based ANLS, when used on small\ninstances with 25 customers and with a much shorter running time. Our LP-based\nALNS dominates the cp-ALNS, in terms of solution quality, when it provides\nsolutions with better objective values, on average, for all instance classes.\nThis demonstrates the advantage of using linear programming instead of\nconstraint programming when dealing with a variant of vehicle routing problems\nwith relatively tight constraints, which is often considered to be more\nfavorable for CP-based methods.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 03:55:05 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["H\u00e0", "Minh Ho\u00e0ng", ""], ["Nguyen", "Tat Dat", ""], ["Duy", "Thinh Nguyen", ""], ["Pham", "Hoang Giang", ""], ["Do", "Thuy", ""], ["Rousseau", "Louis-Martin", ""]]}, {"id": "1910.13520", "submitter": "Dattaraj Rao", "authors": "Dattaraj Jagdish Rao, Shraddha Mane", "title": "Digital Twin approach to Clinical DSS with Explainable AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a digital twin approach to improve healthcare decision support\nsystems with a combination of domain knowledge and data. Domain knowledge helps\nbuild decision thresholds that doctors can use to determine a risk or recommend\na treatment or test based on the specific patient condition. However, these\nassessments tend to be highly subjective and differ from doctor to doctor and\nfrom patient to patient. We propose a system where we collate this subjective\nrisk by compiling data from different doctors treating different patients and\nbuild a machine learning model that learns from this knowledge. Then using\nstate-of-the-art explainability concepts we derive explanations from this\nmodel. These explanations give us a summary of different doctor domain\nknowledge applied in different cases to give a more generic perspective. Also\nthese explanations are specific to a particular patient and are customized for\ntheir condition. This is a form of a digital twin for the patient that can now\nbe used to enhance decision boundaries for earlier defined decision tables that\nhelp in diagnosis. We will show an example of running this analysis for a liver\ndisease risk diagnosis.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 11:19:25 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Rao", "Dattaraj Jagdish", ""], ["Mane", "Shraddha", ""]]}, {"id": "1910.13526", "submitter": "Qin Lin", "authors": "Qin Lin, Sicco Verwer, John Dolan", "title": "Learning a Safety Verifiable Adaptive Cruise Controller from Human\n  Driving Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.FL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning provides a way to automatically construct a controller by\nmimicking human behavior from data. For safety-critical systems such as\nautonomous vehicles, it can be problematic to use controllers learned from data\nbecause they cannot be guaranteed to be collision-free. Recently, a method has\nbeen proposed for learning a multi-mode hybrid automaton cruise controller\n(MOHA). Besides being accurate, the logical nature of this model makes it\nsuitable for formal verification. In this paper, we demonstrate this capability\nusing the SpaceEx hybrid model checker as follows. After learning, we translate\nthe automaton model into constraints and equations required by SpaceEx. We then\nverify that a pure MOHA controller is not collision-free. By adding a safety\nstate based on headway in time, a rule that human drivers should follow anyway,\nwe do obtain a provably safe cruise control. Moreover, the safe controller\nremains more human-like than existing cruise controllers.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 20:51:13 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Lin", "Qin", ""], ["Verwer", "Sicco", ""], ["Dolan", "John", ""]]}, {"id": "1910.13607", "submitter": "Atoosa Kasirzadeh", "authors": "Atoosa Kasirzadeh", "title": "Mathematical decisions and non-causal elements of explainable AI", "comments": "A shorter version of this paper was presented at the NeurIPS 2019,\n  Human-Centric Machine Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The social implications of algorithmic decision-making in sensitive contexts\nhave generated lively debates among multiple stakeholders, such as moral and\npolitical philosophers, computer scientists, and the public. Yet, the lack of a\ncommon language and a conceptual framework for an appropriate bridging of the\nmoral, technical, and political aspects of the debate prevents the discussion\nto be as effective as it can be. Social scientists and psychologists are\ncontributing to this debate by gathering a wealth of empirical data, yet a\nphilosophical analysis of the social implications of algorithmic\ndecision-making remains comparatively impoverished. In attempting to address\nthis lacuna, this paper argues that a hierarchy of different types of\nexplanations for why and how an algorithmic decision outcome is achieved can\nestablish the relevant connection between the moral and technical aspects of\nalgorithmic decision-making. In particular, I offer a multi-faceted conceptual\nframework for the explanations and the interpretations of algorithmic\ndecisions, and I claim that this framework can lay the groundwork for a focused\ndiscussion among multiple stakeholders about the social implications of\nalgorithmic decision-making, as well as AI governance and ethics more\ngenerally.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 00:58:44 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 07:08:33 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Kasirzadeh", "Atoosa", ""]]}, {"id": "1910.13616", "submitter": "Risto Vuorio", "authors": "Risto Vuorio, Shao-Hua Sun, Hexiang Hu, and Joseph J. Lim", "title": "Multimodal Model-Agnostic Meta-Learning via Task-Aware Modulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-agnostic meta-learners aim to acquire meta-learned parameters from\nsimilar tasks to adapt to novel tasks from the same distribution with few\ngradient updates. With the flexibility in the choice of models, those\nframeworks demonstrate appealing performance on a variety of domains such as\nfew-shot image classification and reinforcement learning. However, one\nimportant limitation of such frameworks is that they seek a common\ninitialization shared across the entire task distribution, substantially\nlimiting the diversity of the task distributions that they are able to learn\nfrom. In this paper, we augment MAML with the capability to identify the mode\nof tasks sampled from a multimodal task distribution and adapt quickly through\ngradient updates. Specifically, we propose a multimodal MAML (MMAML) framework,\nwhich is able to modulate its meta-learned prior parameters according to the\nidentified mode, allowing more efficient fast adaptation. We evaluate the\nproposed model on a diverse set of few-shot learning tasks, including\nregression, image classification, and reinforcement learning. The results not\nonly demonstrate the effectiveness of our model in modulating the meta-learned\nprior in response to the characteristics of tasks but also show that training\non a multimodal distribution can produce an improvement over unimodal training.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 01:35:19 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Vuorio", "Risto", ""], ["Sun", "Shao-Hua", ""], ["Hu", "Hexiang", ""], ["Lim", "Joseph J.", ""]]}, {"id": "1910.13641", "submitter": "EPTCS", "authors": "Georgiana Caltais (Konstanz University), Jean Krivine (CNRS)", "title": "Proceedings of the 4th Workshop on Formal Reasoning about Causation,\n  Responsibility, and Explanations in Science and Technology", "comments": null, "journal-ref": "EPTCS 308, 2019", "doi": "10.4204/EPTCS.308", "report-no": null, "categories": "cs.AI cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fourth edition of the international workshop on Causation, Responsibility\nand Explanation took place in Prague (Czech Republic) as part of ETAPS 2019.\nThe program consisted in 5 invited speakers and 4 regular papers, whose\nselection was based on a careful reviewing process and that are included in\nthese proceedings.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 02:58:45 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Caltais", "Georgiana", "", "Konstanz University"], ["Krivine", "Jean", "", "CNRS"]]}, {"id": "1910.13645", "submitter": "Xin Qin", "authors": "Xin Qin, Nikos Ar\\'echiga, Andrew Best, Jyotirmoy Deshmukh", "title": "Automatic Testing With Reusable Adversarial Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous systems such as self-driving cars and general-purpose robots are\nsafety-critical systems that operate in highly uncertain and dynamic\nenvironments. We propose an interactive multi-agent framework where the\nsystem-under-design is modeled as an ego agent and its environment is modeled\nby a number of adversarial (ado) agents. For example, a self-driving car is an\nego agent whose behavior is influenced by ado agents such as pedestrians,\nbicyclists, traffic lights, road geometry etc. Given a logical specification of\nthe correct behavior of the ego agent, and a set of constraints that encode\nreasonable adversarial behavior, our framework reduces the adversarial testing\nproblem to the problem of synthesizing controllers for (constrained) ado agents\nthat cause the ego agent to violate its specifications. Specifically, we\nexplore the use of tabular and deep reinforcement learning approaches for\nsynthesizing adversarial agents. We show that ado agents trained in this\nfashion are better than traditional falsification or testing techniques because\nthey can generalize to ego agents and environments that differ from the\noriginal ego agent. We demonstrate the efficacy of our technique on two\nreal-world case studies from the domain of self-driving cars.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 03:18:10 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 07:46:56 GMT"}, {"version": "v3", "created": "Mon, 5 Jul 2021 22:27:14 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Qin", "Xin", ""], ["Ar\u00e9chiga", "Nikos", ""], ["Best", "Andrew", ""], ["Deshmukh", "Jyotirmoy", ""]]}, {"id": "1910.13676", "submitter": "Kartik Srivastava", "authors": "Kartik Srivastava, Akash Kumar Singh and Guruprasad M. Hegde", "title": "Multi Modal Semantic Segmentation using Synthetic Data", "comments": "Accepted in 3rd Edition of Deep Learning for Automated Driving (DLAD)\n  workshop, IEEE International Conference on Intelligent Transportation Systems\n  (ITSC'19) [see\n  https://sites.google.com/view/dlad-bp-itsc2019/schedule?authuser=0#h.p_gI84BCoB0_bJ]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic understanding of scenes in three-dimensional space (3D) is a\nquintessential part of robotics oriented applications such as autonomous\ndriving as it provides geometric cues such as size, orientation and true\ndistance of separation to objects which are crucial for taking mission critical\ndecisions. As a first step, in this work we investigate the possibility of\nsemantically classifying different parts of a given scene in 3D by learning the\nunderlying geometric context in addition to the texture cues BUT in the absence\nof labelled real-world datasets. To this end we generate a large number of\nsynthetic scenes, their pixel-wise labels and corresponding 3D representations\nusing CARLA software framework. We then build a deep neural network that learns\nunderlying category specific 3D representation and texture cues from color\ninformation of the rendered synthetic scenes. Further on we apply the learned\nmodel on different real world datasets to evaluate its performance. Our\npreliminary investigation of results show that the neural network is able to\nlearn the geometric context from synthetic scenes and effectively apply this\nknowledge to classify each point of a 3D representation of a scene in\nreal-world.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 05:13:33 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Srivastava", "Kartik", ""], ["Singh", "Akash Kumar", ""], ["Hegde", "Guruprasad M.", ""]]}, {"id": "1910.13701", "submitter": "Aakash Maroti", "authors": "Aakash Maroti", "title": "RBED: Reward Based Epsilon Decay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $\\varepsilon$-greedy is a policy used to balance exploration and exploitation\nin many reinforcement learning setting. In cases where the agent uses some\non-policy algorithm to learn optimal behaviour, it makes sense for the agent to\nexplore more initially and eventually exploit more as it approaches the target\nbehaviour. This shift from heavy exploration to heavy exploitation can be\nrepresented as decay in the $\\varepsilon$ value, where $\\varepsilon$ depicts\nthe how much an agent is allowed to explore. This paper proposes a new approach\nto this $\\varepsilon$ decay where the decay is based on feedback from the\nenvironment. This paper also compares and contrasts one such approach based on\nrewards and compares it against standard exponential decay. The new approach,\nin the environments tested, produces more consistent results that on average\nperform better.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 07:28:33 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Maroti", "Aakash", ""]]}, {"id": "1910.13726", "submitter": "Matteo Turchetta", "authors": "Matteo Turchetta, Felix Berkenkamp, Andreas Krause", "title": "Safe Exploration for Interactive Machine Learning", "comments": "Accepted at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Interactive Machine Learning (IML), we iteratively make decisions and\nobtain noisy observations of an unknown function. While IML methods, e.g.,\nBayesian optimization and active learning, have been successful in\napplications, on real-world systems they must provably avoid unsafe decisions.\nTo this end, safe IML algorithms must carefully learn about a priori unknown\nconstraints without making unsafe decisions. Existing algorithms for this\nproblem learn about the safety of all decisions to ensure convergence. This is\nsample-inefficient, as it explores decisions that are not relevant for the\noriginal IML objective. In this paper, we introduce a novel framework that\nrenders any existing unsafe IML algorithm safe. Our method works as an add-on\nthat takes suggested decisions as input and exploits regularity assumptions in\nterms of a Gaussian process prior in order to efficiently learn about their\nsafety. As a result, we only explore the safe set when necessary for the IML\nproblem. We apply our framework to safe Bayesian optimization and to safe\nexploration in deterministic Markov Decision Processes (MDP), which have been\nanalyzed separately before. Our method outperforms other algorithms\nempirically.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 09:12:48 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Turchetta", "Matteo", ""], ["Berkenkamp", "Felix", ""], ["Krause", "Andreas", ""]]}, {"id": "1910.13800", "submitter": "Abhishek Ghose", "authors": "Abhishek Ghose", "title": "Rational Kernels: A survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many kinds of data are naturally amenable to being treated as sequences. An\nexample is text data, where a text may be seen as a sequence of words. Another\nexample is clickstream data, where a data instance is a sequence of clicks made\nby a visitor to a website. This is also common for data originating in the\ndomains of speech processing and computational biology. Using such data with\nstatistical learning techniques can often prove to be cumbersome since most of\nthem only allow fixed-length feature vectors as input. In casting the data to\nfixed-length feature vectors to suit these techniques, we lose the convenience,\nand possibly information, a good sequence-based representation can offer. The\nframework of rational kernels partly addresses this problem by providing an\nelegant representation for sequences, for algorithms that use kernel functions.\nIn this report, we take a comprehensive look at this framework, its various\nextensions and applications. We start with an overview of the core ideas, where\nwe look at the characterization of rational kernels, and then extend our\ndiscussion to extensions, applications and use at scale. Rational kernels\nrepresent a family of kernels, and thus, learning an appropriate rational\nkernel instead of picking one, suggests a convenient way to use them; we\nexplore this idea in our concluding section. Rational kernels are not as\npopular as the many other learning techniques in use today; however, we hope\nthat this summary effectively shows that not only is their theory\nwell-developed, but also that various practical aspects have been carefully\nstudied over time.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 19:16:44 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Ghose", "Abhishek", ""]]}, {"id": "1910.13880", "submitter": "Yevgeniy Vorobeychik", "authors": "Yi Li and Yevgeniy Vorobeychik", "title": "Path Planning Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Path planning is a fundamental and extensively explored problem in robotic\ncontrol. We present a novel economic perspective on path planning.\nSpecifically, we investigate strategic interactions among path planning agents\nusing a game theoretic path planning framework. Our focus is on economic\ntension between two important objectives: efficiency in the agents' achieving\ntheir goals, and safety in navigating towards these. We begin by developing a\nnovel mathematical formulation for path planning that trades off these\nobjectives, when behavior of other agents is fixed. We then use this\nformulation for approximating Nash equilibria in path planning games, as well\nas to develop a multi-agent cooperative path planning formulation. Through\nseveral case studies, we show that in a path planning game, safety is often\nsignificantly compromised compared to a cooperative solution.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 14:26:30 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Li", "Yi", ""], ["Vorobeychik", "Yevgeniy", ""]]}, {"id": "1910.14002", "submitter": "Vaneet Aggarwal", "authors": "Ashutosh Singh and Abubakr Alabbasi and Vaneet Aggarwal", "title": "A Distributed Model-Free Algorithm for Multi-hop Ride-sharing using Deep\n  Reinforcement Learning", "comments": "This is an extended version of the work presented in NeurIPS Workshop\n  2019. arXiv admin note: text overlap with arXiv:1903.03882", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growth of autonomous vehicles, ridesharing systems, and self driving\ntechnology will bring a shift in the way ride hailing platforms plan out their\nservices. However, these advances in technology coupled with road congestion,\nenvironmental concerns, fuel usage, vehicles emissions, and the high cost of\nthe vehicle usage have brought more attention to better utilize the use of\nvehicles and their capacities. In this paper, we propose a novel multi-hop\nride-sharing (MHRS) algorithm that uses deep reinforcement learning to learn\noptimal vehicle dispatch and matching decisions by interacting with the\nexternal environment. By allowing customers to transfer between vehicles, i.e.,\nride with one vehicle for sometime and then transfer to another one, MHRS helps\nin attaining 30\\% lower cost and 20\\% more efficient utilization of fleets, as\ncompared to the ride-sharing algorithms. This flexibility of multi-hop feature\ngives a seamless experience to customers and ride-sharing companies, and thus\nimproves ride-sharing services.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 17:40:32 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Singh", "Ashutosh", ""], ["Alabbasi", "Abubakr", ""], ["Aggarwal", "Vaneet", ""]]}, {"id": "1910.14033", "submitter": "Coline Devin", "authors": "Coline Devin, Daniel Geng, Pieter Abbeel, Trevor Darrell, Sergey\n  Levine", "title": "Plan Arithmetic: Compositional Plan Vectors for Multi-Task Control", "comments": "In NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous agents situated in real-world environments must be able to master\nlarge repertoires of skills. While a single short skill can be learned quickly,\nit would be impractical to learn every task independently. Instead, the agent\nshould share knowledge across behaviors such that each task can be learned\nefficiently, and such that the resulting model can generalize to new tasks,\nespecially ones that are compositions or subsets of tasks seen previously. A\npolicy conditioned on a goal or demonstration has the potential to share\nknowledge between tasks if it sees enough diversity of inputs. However, these\nmethods may not generalize to a more complex task at test time. We introduce\ncompositional plan vectors (CPVs) to enable a policy to perform compositions of\ntasks without additional supervision. CPVs represent trajectories as the sum of\nthe subtasks within them. We show that CPVs can be learned within a one-shot\nimitation learning framework without any additional supervision or information\nabout task hierarchy, and enable a demonstration-conditioned policy to\ngeneralize to tasks that sequence twice as many skills as the tasks seen during\ntraining.\n  Analogously to embeddings such as word2vec in NLP, CPVs can also support\nsimple arithmetic operations -- for example, we can add the CPVs for two\ndifferent tasks to command an agent to compose both tasks, without any\nadditional training.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 17:50:42 GMT"}, {"version": "v2", "created": "Sun, 2 Aug 2020 01:00:16 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Devin", "Coline", ""], ["Geng", "Daniel", ""], ["Abbeel", "Pieter", ""], ["Darrell", "Trevor", ""], ["Levine", "Sergey", ""]]}, {"id": "1910.14124", "submitter": "Sam Witty", "authors": "Sam Witty, Alexander Lew, David Jensen, Vikash Mansinghka", "title": "Bayesian causal inference via probabilistic program synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Causal inference can be formalized as Bayesian inference that combines a\nprior distribution over causal models and likelihoods that account for both\nobservations and interventions. We show that it is possible to implement this\napproach using a sufficiently expressive probabilistic programming language.\nPriors are represented using probabilistic programs that generate source code\nin a domain specific language. Interventions are represented using\nprobabilistic programs that edit this source code to modify the original\ngenerative process. This approach makes it straightforward to incorporate data\nfrom atomic interventions, as well as shift interventions, variance-scaling\ninterventions, and other interventions that modify causal structure. This\napproach also enables the use of general-purpose inference machinery for\nprobabilistic programs to infer probable causal structures and parameters from\ndata. This abstract describes a prototype of this approach in the Gen\nprobabilistic programming language.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 20:46:43 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Witty", "Sam", ""], ["Lew", "Alexander", ""], ["Jensen", "David", ""], ["Mansinghka", "Vikash", ""]]}, {"id": "1910.14138", "submitter": "Nerio Borges PhD", "authors": "Nerio Borges and Ram\\'on Pino P\\'erez", "title": "Belief revision and 3-valued logics: Characterization of 19,683 belief\n  change operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In most classical models of belief change, epistemic states are represented\nby theories (AGM) or formulas (Katsuno-Mendelzon) and the new pieces of\ninformation by formulas. The Representation Theorem for revision operators says\nthat operators are represented by total preorders. This important\nrepresentation is exploited by Darwiche and Pearl to shift the notion of\nepistemic state to a more abstract one, where the paradigm of epistemic state\nis indeed that of a total preorder over interpretations. In this work, we\nintroduce a 3-valued logic where the formulas can be identified with a\ngeneralisation of total preorders of three levels: a ranking function mapping\ninterpretations into the truth values. Then we analyse some sort of changes in\nthis kind of structures and give syntactical characterizations of them.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 21:10:39 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Borges", "Nerio", ""], ["P\u00e9rez", "Ram\u00f3n Pino", ""]]}, {"id": "1910.14139", "submitter": "Andrew Davison", "authors": "Andrew J. Davison and Joseph Ortiz", "title": "FutureMapping 2: Gaussian Belief Propagation for Spatial AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We argue the case for Gaussian Belief Propagation (GBP) as a strong\nalgorithmic framework for the distributed, generic and incremental\nprobabilistic estimation we need in Spatial AI as we aim at high performance\nsmart robots and devices which operate within the constraints of real products.\nProcessor hardware is changing rapidly, and GBP has the right character to take\nadvantage of highly distributed processing and storage while estimating global\nquantities, as well as great flexibility. We present a detailed tutorial on\nGBP, relating to the standard factor graph formulation used in robotics and\ncomputer vision, and give several simulation examples with code which\ndemonstrate its properties.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 21:12:14 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Davison", "Andrew J.", ""], ["Ortiz", "Joseph", ""]]}, {"id": "1910.14164", "submitter": "Jacopo Tagliabue", "authors": "Jacopo Tagliabue, Reuben Cohn-Gordon", "title": "Lexical Learning as an Online Optimal Experiment: Building Efficient\n  Search Engines through Human-Machine Collaboration", "comments": null, "journal-ref": "WIP and Demo track, HCOMP 2019", "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information retrieval (IR) systems need to constantly update their knowledge\nas target objects and user queries change over time. Due to the power-law\nnature of linguistic data, learning lexical concepts is a problem resisting\nstandard machine learning approaches: while manual intervention is always\npossible, a more general and automated solution is desirable. In this work, we\npropose a novel end-to-end framework that models the interaction between a\nsearch engine and users as a virtuous human-in-the-loop inference. The proposed\nframework is the first to our knowledge combining ideas from psycholinguistics\nand experiment design to maximize efficiency in IR. We provide a brief overview\nof the main components and initial simulations in a toy world, showing how\ninference works end-to-end and discussing preliminary results and next steps.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 22:35:36 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Tagliabue", "Jacopo", ""], ["Cohn-Gordon", "Reuben", ""]]}, {"id": "1910.14217", "submitter": "EPTCS", "authors": "Shakil M. Khan (Ryerson University), Mikhail Soutchanski (Ryerson\n  University)", "title": "Towards A Logical Account of Epistemic Causality", "comments": "In Proceedings CREST 2019, arXiv:1910.13641", "journal-ref": "EPTCS 308, 2019, pp. 1-16", "doi": "10.4204/EPTCS.308.1", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning about observed effects and their causes is important in multi-agent\ncontexts. While there has been much work on causality from an objective\nstandpoint, causality from the point of view of some particular agent has\nreceived much less attention. In this paper, we address this issue by\nincorporating an epistemic dimension to an existing formal model of causality.\nWe define what it means for an agent to know the causes of an effect. Then\nusing a counterexample, we prove that epistemic causality is a different notion\nfrom its objective counterpart.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 02:29:44 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Khan", "Shakil M.", "", "Ryerson University"], ["Soutchanski", "Mikhail", "", "Ryerson\n  University"]]}, {"id": "1910.14229", "submitter": "Yue Ma", "authors": "Yue Ma, Xiaojie Wang, Zhenjiang Dong, Hong Chen", "title": "Cascaded LSTMs based Deep Reinforcement Learning for Goal-driven\n  Dialogue", "comments": "12 pages, 3 figures, appear in NLPCC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a deep neural network model for joint modeling Natural\nLanguage Understanding (NLU) and Dialogue Management (DM) in goal-driven\ndialogue systems. There are three parts in this model. A Long Short-Term Memory\n(LSTM) at the bottom of the network encodes utterances in each dialogue turn\ninto a turn embedding. Dialogue embeddings are learned by a LSTM at the middle\nof the network, and updated by the feeding of all turn embeddings. The top part\nis a forward Deep Neural Network which converts dialogue embeddings into the\nQ-values of different dialogue actions. The cascaded LSTMs based reinforcement\nlearning network is jointly optimized by making use of the rewards received at\neach dialogue turn as the only supervision information. There is no explicit\nNLU and dialogue states in the network. Experimental results show that our\nmodel outperforms both traditional Markov Decision Process (MDP) model and\nsingle LSTM with Deep Q-Network on meeting room booking tasks. Visualization of\ndialogue embeddings illustrates that the model can learn the representation of\ndialogue states.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 03:08:10 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Ma", "Yue", ""], ["Wang", "Xiaojie", ""], ["Dong", "Zhenjiang", ""], ["Chen", "Hong", ""]]}, {"id": "1910.14257", "submitter": "Aaron Babier", "authors": "Aaron Babier, Rafid Mahmood, Andrea L. McNiven, Adam Diamant, Timothy\n  C. Y. Chan", "title": "The importance of evaluating the complete automated knowledge-based\n  planning pipeline", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We determine how prediction methods combine with optimization methods in\ntwo-stage knowledge-based planning (KBP) pipelines to produce radiation therapy\ntreatment plans. We trained two dose prediction methods, a generative\nadversarial network (GAN) and a random forest (RF) with the same 130 treatment\nplans. The models were applied to 87 out-of-sample patients to create two sets\nof predicted dose distributions that were used as input to two optimization\nmodels. The first optimization model, inverse planning (IP), estimates weights\nfor dose-objectives from a predicted dose distribution and generates new plans\nusing conventional inverse planning. The second optimization model, dose\nmimicking (DM), minimizes the sum of one-sided quadratic penalties between the\npredictions and the generated plans using several dose-objectives. Altogether,\nfour KBP pipelines (GAN-IP, GAN-DM, RF-IP, and RF-DM) were constructed and\nbenchmarked against the corresponding clinical plans using clinical criteria;\nthe error of both prediction methods was also evaluated. The best performing\nplans were GAN-IP plans, which satisfied the same criteria as their\ncorresponding clinical plans (78%) more often than any other KBP pipeline.\nHowever, GAN did not necessarily provide the best prediction for the\nsecond-stage optimization models. Specifically, both the RF-IP and RF-DM plans\nsatisfied all clinical criteria 25% and 15% more often than GAN-DM plans (the\nworst performing planning), respectively. GAN predictions also had a higher\nmean absolute error (3.9 Gy) than those from RF (3.6 Gy). We find that\nstate-of-the-art prediction methods when paired with different optimization\nalgorithms, produce treatment plans with considerable variation in quality.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 04:45:00 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Babier", "Aaron", ""], ["Mahmood", "Rafid", ""], ["McNiven", "Andrea L.", ""], ["Diamant", "Adam", ""], ["Chan", "Timothy C. Y.", ""]]}, {"id": "1910.14361", "submitter": "Victor Bapst", "authors": "Victor Bapst, Alvaro Sanchez-Gonzalez, Omar Shams, Kimberly\n  Stachenfeld, Peter W. Battaglia, Satinder Singh, Jessica B. Hamrick", "title": "Object-oriented state editing for HRL", "comments": "8 pages; accepted to the Perception as Generative Reasoning workshop\n  of the 33rd Conference on Neural InformationProcessing Systems (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce agents that use object-oriented reasoning to consider alternate\nstates of the world in order to more quickly find solutions to problems.\nSpecifically, a hierarchical controller directs a low-level agent to behave as\nif objects in the scene were added, deleted, or modified. The actions taken by\nthe controller are defined over a graph-based representation of the scene, with\nactions corresponding to adding, deleting, or editing the nodes of a graph. We\npresent preliminary results on three environments, demonstrating that our\napproach can achieve similar levels of reward as non-hierarchical agents, but\nwith better data efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 10:48:45 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Bapst", "Victor", ""], ["Sanchez-Gonzalez", "Alvaro", ""], ["Shams", "Omar", ""], ["Stachenfeld", "Kimberly", ""], ["Battaglia", "Peter W.", ""], ["Singh", "Satinder", ""], ["Hamrick", "Jessica B.", ""]]}, {"id": "1910.14409", "submitter": "Vasisht Duddu", "authors": "Vasisht Duddu, D. Vijay Rao", "title": "Quantifying (Hyper) Parameter Leakage in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine Learning models, extensively used for various multimedia\napplications, are offered to users as a blackbox service on the Cloud on a\npay-per-query basis. Such blackbox models are commercially valuable to\nadversaries, making them vulnerable to extraction attacks to reverse engineer\nthe proprietary model thereby violating the model privacy and Intellectual\nProperty. Here, the adversary first extracts the model architecture or\nhyperparameters through side channel leakage, followed by stealing the\nfunctionality of the target model by training the reconstructed architecture on\na synthetic dataset. While the attacks proposed in literature are empirical,\nthere is a need for a theoretical framework to measure the information leaked\nunder such extraction attacks. To this extent, in this work, we propose a novel\nprobabilistic framework, Airavata, to estimate the information leakage in such\nmodel extraction attacks. This framework captures the fact that extracting the\nexact target model is difficult due to experimental uncertainty while inferring\nmodel hyperparameters and stochastic nature of training to steal the target\nmodel functionality. Specifically, we use Bayesian Networks to capture\nuncertainty in estimating the target model under various extraction attacks\nbased on the subjective notion of probability. We validate the proposed\nframework under different adversary assumptions commonly adopted in literature\nto reason about the attack efficacy. This provides a practical tool to infer\nactionable details about extracting blackbox models and help identify the best\nattack combination which maximises the knowledge extracted (or information\nleaked) from the target model.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 12:05:00 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2020 06:57:41 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Duddu", "Vasisht", ""], ["Rao", "D. Vijay", ""]]}, {"id": "1910.14436", "submitter": "Djallel Bouneffouf", "authors": "Charu Aggarwal, Djallel Bouneffouf, Horst Samulowitz, Beat Buesser,\n  Thanh Hoang, Udayan Khurana, Sijia Liu, Tejaswini Pedapati, Parikshit Ram,\n  Ambrish Rawat, Martin Wistuba and Alexander Gray", "title": "How can AI Automate End-to-End Data Science?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data science is labor-intensive and human experts are scarce but heavily\ninvolved in every aspect of it. This makes data science time consuming and\nrestricted to experts with the resulting quality heavily dependent on their\nexperience and skills. To make data science more accessible and scalable, we\nneed its democratization. Automated Data Science (AutoDS) is aimed towards that\ngoal and is emerging as an important research and business topic. We introduce\nand define the AutoDS challenge, followed by a proposal of a general AutoDS\nframework that covers existing approaches but also provides guidance for the\ndevelopment of new methods. We categorize and review the existing literature\nfrom multiple aspects of the problem setup and employed techniques. Then we\nprovide several views on how AI could succeed in automating end-to-end AutoDS.\nWe hope this survey can serve as insightful guideline for the AutoDS field and\nprovide inspiration for future research.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 12:54:48 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Aggarwal", "Charu", ""], ["Bouneffouf", "Djallel", ""], ["Samulowitz", "Horst", ""], ["Buesser", "Beat", ""], ["Hoang", "Thanh", ""], ["Khurana", "Udayan", ""], ["Liu", "Sijia", ""], ["Pedapati", "Tejaswini", ""], ["Ram", "Parikshit", ""], ["Rawat", "Ambrish", ""], ["Wistuba", "Martin", ""], ["Gray", "Alexander", ""]]}, {"id": "1910.14442", "submitter": "Fei Xia", "authors": "Fei Xia, William B. Shen, Chengshu Li, Priya Kasimbeg, Micael Tchapmi,\n  Alexander Toshev, Li Fei-Fei, Roberto Mart\\'in-Mart\\'in, Silvio Savarese", "title": "Interactive Gibson Benchmark: A Benchmark for Interactive Navigation in\n  Cluttered Environments", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Interactive Gibson Benchmark, the first comprehensive benchmark\nfor training and evaluating Interactive Navigation: robot navigation strategies\nwhere physical interaction with objects is allowed and even encouraged to\naccomplish a task. For example, the robot can move objects if needed in order\nto clear a path leading to the goal location. Our benchmark comprises two novel\nelements: 1) a new experimental setup, the Interactive Gibson Environment,\nwhich simulates high fidelity visuals of indoor scenes, and high fidelity\nphysical dynamics of the robot and common objects found in these scenes; 2) a\nset of Interactive Navigation metrics which allows one to study the interplay\nbetween navigation and physical interaction. We present and evaluate multiple\nlearning-based baselines in Interactive Gibson, and provide insights into\nregimes of navigation with different trade-offs between navigation path\nefficiency and disturbance of surrounding objects. We make our benchmark\npublicly available(https://sites.google.com/view/interactivegibsonenv) and\nencourage researchers from all disciplines in robotics (e.g. planning,\nlearning, control) to propose, evaluate, and compare their Interactive\nNavigation solutions in Interactive Gibson.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 01:04:37 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 07:08:01 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Xia", "Fei", ""], ["Shen", "William B.", ""], ["Li", "Chengshu", ""], ["Kasimbeg", "Priya", ""], ["Tchapmi", "Micael", ""], ["Toshev", "Alexander", ""], ["Fei-Fei", "Li", ""], ["Mart\u00edn-Mart\u00edn", "Roberto", ""], ["Savarese", "Silvio", ""]]}, {"id": "1910.14464", "submitter": "Jordan Boyd-Graber", "authors": "Jordan Boyd-Graber, Benjamin B\\\"orschinger", "title": "What Question Answering can Learn from Trivia Nerds", "comments": null, "journal-ref": "ACL 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In addition to the traditional task of getting machines to answer questions,\na major research question in question answering is to create interesting,\nchallenging questions that can help systems learn how to answer questions and\nalso reveal which systems are the best at answering questions. We argue that\ncreating a question answering dataset -- and the ubiquitous leaderboard that\ngoes with it -- closely resembles running a trivia tournament: you write\nquestions, have agents (either humans or machines) answer the questions, and\ndeclare a winner. However, the research community has ignored the decades of\nhard-learned lessons from decades of the trivia community creating vibrant,\nfair, and effective question answering competitions. After detailing problems\nwith existing QA datasets, we outline the key lessons -- removing ambiguity,\ndiscriminating skill, and adjudicating disputes -- that can transfer to QA\nresearch and how they might be implemented for the QA community.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 13:38:01 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 15:27:05 GMT"}, {"version": "v3", "created": "Tue, 21 Apr 2020 12:41:05 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Boyd-Graber", "Jordan", ""], ["B\u00f6rschinger", "Benjamin", ""]]}, {"id": "1910.14472", "submitter": "Zongqing Lu", "authors": "Jiechuan Jiang and Zongqing Lu", "title": "Learning Fairness in Multi-Agent Systems", "comments": "NeurIPS'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness is essential for human society, contributing to stability and\nproductivity. Similarly, fairness is also the key for many multi-agent systems.\nTaking fairness into multi-agent learning could help multi-agent systems become\nboth efficient and stable. However, learning efficiency and fairness\nsimultaneously is a complex, multi-objective, joint-policy optimization. To\ntackle these difficulties, we propose FEN, a novel hierarchical reinforcement\nlearning model. We first decompose fairness for each agent and propose\nfair-efficient reward that each agent learns its own policy to optimize. To\navoid multi-objective conflict, we design a hierarchy consisting of a\ncontroller and several sub-policies, where the controller maximizes the\nfair-efficient reward by switching among the sub-policies that provides diverse\nbehaviors to interact with the environment. FEN can be trained in a fully\ndecentralized way, making it easy to be deployed in real-world applications.\nEmpirically, we show that FEN easily learns both fairness and efficiency and\nsignificantly outperforms baselines in a variety of multi-agent scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 13:59:37 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Jiang", "Jiechuan", ""], ["Lu", "Zongqing", ""]]}, {"id": "1910.14481", "submitter": "Dushyant Rao", "authors": "Dushyant Rao, Francesco Visin, Andrei A. Rusu, Yee Whye Teh, Razvan\n  Pascanu, Raia Hadsell", "title": "Continual Unsupervised Representation Learning", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning aims to improve the ability of modern learning systems to\ndeal with non-stationary distributions, typically by attempting to learn a\nseries of tasks sequentially. Prior art in the field has largely considered\nsupervised or reinforcement learning tasks, and often assumes full knowledge of\ntask labels and boundaries. In this work, we propose an approach (CURL) to\ntackle a more general problem that we will refer to as unsupervised continual\nlearning. The focus is on learning representations without any knowledge about\ntask identity, and we explore scenarios when there are abrupt changes between\ntasks, smooth transitions from one task to another, or even when the data is\nshuffled. The proposed approach performs task inference directly within the\nmodel, is able to dynamically expand to capture new concepts over its lifetime,\nand incorporates additional rehearsal-based techniques to deal with\ncatastrophic forgetting. We demonstrate the efficacy of CURL in an unsupervised\nlearning setting with MNIST and Omniglot, where the lack of labels ensures no\ninformation is leaked about the task. Further, we demonstrate strong\nperformance compared to prior art in an i.i.d setting, or when adapting the\ntechnique to supervised tasks such as incremental class learning.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 14:18:45 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Rao", "Dushyant", ""], ["Visin", "Francesco", ""], ["Rusu", "Andrei A.", ""], ["Teh", "Yee Whye", ""], ["Pascanu", "Razvan", ""], ["Hadsell", "Raia", ""]]}]