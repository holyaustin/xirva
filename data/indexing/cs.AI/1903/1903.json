[{"id": "1903.00035", "submitter": "Yizhe Zhang", "authors": "Yizhe Zhang, Lin Yang, Hao Zheng, Peixian Liang, Colleen Mangold,\n  Raquel G. Loreto, David P. Hughes, Danny Z. Chen", "title": "SPDA: Superpixel-based Data Augmentation for Biomedical Image\n  Segmentation", "comments": "To appear in MIDL2019 and PMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised training a deep neural network aims to \"teach\" the network to\nmimic human visual perception that is represented by image-and-label pairs in\nthe training data. Superpixelized (SP) images are visually perceivable to\nhumans, but a conventionally trained deep learning model often performs poorly\nwhen working on SP images. To better mimic human visual perception, we think it\nis desirable for the deep learning model to be able to perceive not only raw\nimages but also SP images. In this paper, we propose a new superpixel-based\ndata augmentation (SPDA) method for training deep learning models for\nbiomedical image segmentation. Our method applies a superpixel generation\nscheme to all the original training images to generate superpixelized images.\nThe SP images thus obtained are then jointly used with the original training\nimages to train a deep learning model. Our experiments of SPDA on four\nbiomedical image datasets show that SPDA is effective and can consistently\nimprove the performance of state-of-the-art fully convolutional networks for\nbiomedical image segmentation in 2D and 3D images. Additional studies also\ndemonstrate that SPDA can practically reduce the generalization gap.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 19:17:51 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Zhang", "Yizhe", ""], ["Yang", "Lin", ""], ["Zheng", "Hao", ""], ["Liang", "Peixian", ""], ["Mangold", "Colleen", ""], ["Loreto", "Raquel G.", ""], ["Hughes", "David P.", ""], ["Chen", "Danny Z.", ""]]}, {"id": "1903.00111", "submitter": "Zahra Zahedi", "authors": "Sailik Sengupta, Zahra Zahedi, Subbarao Kambhampati", "title": "To Monitor Or Not: Observing Robot's Behavior based on a Game-Theoretic\n  Model of Trust", "comments": "First two authors contributed equally and names are ordered based on\n  a coin flip", "journal-ref": "21st International Workshop on Trust in Agent Societies, 2019", "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In scenarios where a robot generates and executes a plan, there may be\ninstances where this generated plan is less costly for the robot to execute but\nincomprehensible to the human. When the human acts as a supervisor and is held\naccountable for the robot's plan, the human may be at a higher risk if the\nincomprehensible behavior is deemed to be infeasible or unsafe. In such cases,\nthe robot, who may be unaware of the human's exact expectations, may choose to\nexecute (1) the most constrained plan (i.e. one preferred by all possible\nsupervisors) incurring the added cost of executing highly sub-optimal behavior\nwhen the human is monitoring it and (2) deviate to a more optimal plan when the\nhuman looks away. While robots do not have human-like ulterior motives (such as\nbeing lazy), such behavior may occur because the robot has to cater to the\nneeds of different human supervisors. In such settings, the robot, being a\nrational agent, should take any chance it gets to deviate to a lower cost plan.\nOn the other hand, continuous monitoring of the robot's behavior is often\ndifficult for humans because it costs them valuable resources (e.g., time,\ncognitive overload, etc.). Thus, to optimize the cost for monitoring while\nensuring the robots follow the safe behavior, we model this problem in the\ngame-theoretic framework of trust. In settings where the human does not\ninitially trust the robot, pure-strategy Nash Equilibrium provides a useful\npolicy for the human.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 00:05:13 GMT"}, {"version": "v2", "created": "Sat, 6 Apr 2019 00:57:36 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2020 23:19:36 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Sengupta", "Sailik", ""], ["Zahedi", "Zahra", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1903.00194", "submitter": "Xiang Gu", "authors": "Xiang Gu, Sina Ghiassian, Richard S. Sutton", "title": "Should All Temporal Difference Learning Use Emphasis?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emphatic Temporal Difference (ETD) learning has recently been proposed as a\nconvergent off-policy learning method. ETD was proposed mainly to address\nconvergence issues of conventional Temporal Difference (TD) learning under\noff-policy training but it is different from conventional TD learning even\nunder on-policy training. A simple counterexample provided back in 2017 pointed\nto a potential class of problems where ETD converges but TD diverges. In this\npaper, we empirically show that ETD converges on a few other well-known\non-policy experiments whereas TD either diverges or performs poorly. We also\nshow that ETD outperforms TD on the mountain car prediction problem. Our\nresults, together with a similar pattern observed under off-policy training in\nprior works, suggest that ETD might be a good substitute over conventional TD.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 08:09:18 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Gu", "Xiang", ""], ["Ghiassian", "Sina", ""], ["Sutton", "Richard S.", ""]]}, {"id": "1903.00206", "submitter": "Anna Dai", "authors": "Anna Dai, Zhifeng Zhao, Honggang Zhang, Rongpeng Li, Yugeng Zhou", "title": "Evaluation Mechanism of Collective Intelligence for Heterogeneous Agents\n  Group", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Collective intelligence is manifested when multiple agents coherently work in\nobservation, interaction, decision-making and action. In this paper, we define\nand quantify the intelligence level of heterogeneous agents group with the\nimproved Anytime Universal Intelligence Test(AUIT), based on an extension of\nthe existing evaluation of homogeneous agents group. The relationship of\nintelligence level with agents composition, group size, spatial complexity and\ntesting time is analyzed. The intelligence level of heterogeneous agents groups\nis compared with the homogeneous ones to analyze the effects of heterogeneity\non collective intelligence. Our work will help to understand the essence of\ncollective intelligence more deeply and reveal the effect of various key\nfactors on group intelligence level.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 08:45:59 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 14:00:27 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Dai", "Anna", ""], ["Zhao", "Zhifeng", ""], ["Zhang", "Honggang", ""], ["Li", "Rongpeng", ""], ["Zhou", "Yugeng", ""]]}, {"id": "1903.00336", "submitter": "Jasper De Bock", "authors": "Jasper De Bock and Gert de Cooman", "title": "Interpreting, axiomatising and representing coherent choice functions in\n  terms of desirability", "comments": "arXiv admin note: text overlap with arXiv:1806.01044", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Choice functions constitute a simple, direct and very general mathematical\nframework for modelling choice under uncertainty. In particular, they are able\nto represent the set-valued choices that appear in imprecise-probabilistic\ndecision making. We provide these choice functions with a clear interpretation\nin terms of desirability, use this interpretation to derive a set of basic\ncoherence axioms, and show that this notion of coherence leads to a\nrepresentation in terms of sets of strict preference orders. By imposing\nadditional properties such as totality, the mixing property and Archimedeanity,\nwe obtain representation in terms of sets of strict total orders, lexicographic\nprobability systems, coherent lower previsions or linear previsions.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 13:27:07 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 10:51:23 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["De Bock", "Jasper", ""], ["de Cooman", "Gert", ""]]}, {"id": "1903.00401", "submitter": "Karl Moritz Hermann", "authors": "Karl Moritz Hermann, Mateusz Malinowski, Piotr Mirowski, Andras\n  Banki-Horvath, Keith Anderson, Raia Hadsell", "title": "Learning To Follow Directions in Street View", "comments": null, "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Navigating and understanding the real world remains a key challenge in\nmachine learning and inspires a great variety of research in areas such as\nlanguage grounding, planning, navigation and computer vision. We propose an\ninstruction-following task that requires all of the above, and which combines\nthe practicality of simulated environments with the challenges of ambiguous,\nnoisy real world data. StreetNav is built on top of Google Street View and\nprovides visually accurate environments representing real places. Agents are\ngiven driving instructions which they must learn to interpret in order to\nsuccessfully navigate in this environment. Since humans equipped with driving\ninstructions can readily navigate in previously unseen cities, we set a high\nbar and test our trained agents for similar cognitive capabilities. Although\ndeep reinforcement learning (RL) methods are frequently evaluated only on data\nthat closely follow the training distribution, our dataset extends to multiple\ncities and has a clean train/test separation. This allows for thorough testing\nof generalisation ability. This paper presents the StreetNav environment and\ntasks, models that establish strong baselines, and extensive analysis of the\ntask and the trained agents.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 16:50:02 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 22:38:35 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Hermann", "Karl Moritz", ""], ["Malinowski", "Mateusz", ""], ["Mirowski", "Piotr", ""], ["Banki-Horvath", "Andras", ""], ["Anderson", "Keith", ""], ["Hadsell", "Raia", ""]]}, {"id": "1903.00445", "submitter": "Kevin Chen", "authors": "Kevin Chen, Juan Pablo de Vicente, Gabriel Sepulveda, Fei Xia, Alvaro\n  Soto, Marynel Vazquez, Silvio Savarese", "title": "A Behavioral Approach to Visual Navigation with Graph Localization\n  Networks", "comments": "Video: https://youtu.be/nN3B1F90CFM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by research in psychology, we introduce a behavioral approach for\nvisual navigation using topological maps. Our goal is to enable a robot to\nnavigate from one location to another, relying only on its visual input and the\ntopological map of the environment. We propose using graph neural networks for\nlocalizing the agent in the map, and decompose the action space into primitive\nbehaviors implemented as convolutional or recurrent neural networks. Using the\nGibson simulator, we verify that our approach outperforms relevant baselines\nand is able to navigate in both seen and unseen environments.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 18:16:03 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Chen", "Kevin", ""], ["de Vicente", "Juan Pablo", ""], ["Sepulveda", "Gabriel", ""], ["Xia", "Fei", ""], ["Soto", "Alvaro", ""], ["Vazquez", "Marynel", ""], ["Savarese", "Silvio", ""]]}, {"id": "1903.00519", "submitter": "Laura Rieger", "authors": "Laura Rieger and Lars Kai Hansen", "title": "Aggregating explanation methods for stable and robust explainability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite a growing literature on explaining neural networks, no consensus has\nbeen reached on how to explain a neural network decision or how to evaluate an\nexplanation. Our contributions in this paper are twofold. First, we investigate\nschemes to combine explanation methods and reduce model uncertainty to obtain a\nsingle aggregated explanation. We provide evidence that the aggregation is\nbetter at identifying important features, than on individual methods.\nAdversarial attacks on explanations is a recent active research topic. As our\nsecond contribution, we present evidence that aggregate explanations are much\nmore robust to attacks than individual explanation methods.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 20:11:06 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 12:41:00 GMT"}, {"version": "v3", "created": "Sat, 25 Jan 2020 21:41:23 GMT"}, {"version": "v4", "created": "Wed, 4 Mar 2020 12:51:36 GMT"}, {"version": "v5", "created": "Fri, 20 Mar 2020 08:52:24 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Rieger", "Laura", ""], ["Hansen", "Lars Kai", ""]]}, {"id": "1903.00545", "submitter": "Frank Wang", "authors": "Frank Wang and Danjue Li", "title": "A Nonlinear Model for Time Synchronization", "comments": "7 pages, accepted by 2019 Workshop on Synchronization and Timing\n  Services", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current algorithms are based on linear model, for example, Precision Time\nProtocol (PTP) which requires frequent synchronization in order to handle the\neffects of clock frequency drift. This paper introduces a nonlinear approach to\nclock time synchronize. This approach can accurately model the frequency shift.\nTherefore, the required time interval to synchronize clocks can be longer.\nMeanwhile, it also offers better performance and relaxes the synchronization\nprocess. The idea of the nonlinear algorithm and some numerical examples will\nbe presented in this paper in detail.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 21:32:39 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Wang", "Frank", ""], ["Li", "Danjue", ""]]}, {"id": "1903.00556", "submitter": "Yunpu Ma", "authors": "Yunpu Ma, Volker Tresp, Liming Zhao, Yuyi Wang", "title": "Variational Quantum Circuit Model for Knowledge Graphs Embedding", "comments": null, "journal-ref": "Advanced Quantum Technologies, 2019", "doi": null, "report-no": null, "categories": "quant-ph cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose the first quantum Ans\\\"atze for the statistical\nrelational learning on knowledge graphs using parametric quantum circuits. We\nintroduce two types of variational quantum circuits for knowledge graph\nembedding. Inspired by the classical representation learning, we first consider\nlatent features for entities as coefficients of quantum states, while\npredicates are characterized by parametric gates acting on the quantum states.\nFor the first model, the quantum advantages disappear when it comes to the\noptimization of this model. Therefore, we introduce a second quantum circuit\nmodel where embeddings of entities are generated from parameterized quantum\ngates acting on the pure quantum state. The benefit of the second method is\nthat the quantum embeddings can be trained efficiently meanwhile preserving the\nquantum advantages. We show the proposed methods can achieve comparable results\nto the state-of-the-art classical models, e.g., RESCAL, DistMult. Furthermore,\nafter optimizing the models, the complexity of inductive inference on the\nknowledge graphs might be reduced with respect to the number of entities.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 13:52:30 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Ma", "Yunpu", ""], ["Tresp", "Volker", ""], ["Zhao", "Liming", ""], ["Wang", "Yuyi", ""]]}, {"id": "1903.00606", "submitter": "Yuu Jinnai", "authors": "Yuu Jinnai, Jee Won Park, David Abel, George Konidaris", "title": "Discovering Options for Exploration by Minimizing Cover Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main challenges in reinforcement learning is solving tasks with\nsparse reward. We show that the difficulty of discovering a distant rewarding\nstate in an MDP is bounded by the expected cover time of a random walk over the\ngraph induced by the MDP's transition dynamics. We therefore propose to\naccelerate exploration by constructing options that minimize cover time. The\nproposed algorithm finds an option which provably diminishes the expected\nnumber of steps to visit every state in the state space by a uniform random\nwalk. We show empirically that the proposed algorithm improves the learning\ntime in several domains with sparse rewards.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 02:17:52 GMT"}, {"version": "v2", "created": "Sat, 16 Mar 2019 18:26:07 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Jinnai", "Yuu", ""], ["Park", "Jee Won", ""], ["Abel", "David", ""], ["Konidaris", "George", ""]]}, {"id": "1903.00686", "submitter": "Tom Hanika", "authors": "Dominik D\\\"urrschnabel and Tom Hanika and Gerd Stumme", "title": "DimDraw -- A novel tool for drawing concept lattices", "comments": "4 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.AI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concept lattice drawings are an important tool to visualize complex relations\nin data in a simple manner to human readers. Many attempts were made to\ntransfer classical graph drawing approaches to order diagrams. Although those\nmethods are satisfying for some lattices they unfortunately perform poorly in\ngeneral. In this work we present a novel tool to draw concept lattices that is\npurely motivated by the order structure.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 11:44:39 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["D\u00fcrrschnabel", "Dominik", ""], ["Hanika", "Tom", ""], ["Stumme", "Gerd", ""]]}, {"id": "1903.00714", "submitter": "Xihan Li", "authors": "Xihan Li, Jia Zhang, Jiang Bian, Yunhai Tong, and Tie-Yan Liu", "title": "A Cooperative Multi-Agent Reinforcement Learning Framework for Resource\n  Balancing in Complex Logistics Network", "comments": "Accepted by AAMAS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resource balancing within complex transportation networks is one of the most\nimportant problems in real logistics domain. Traditional solutions on these\nproblems leverage combinatorial optimization with demand and supply\nforecasting. However, the high complexity of transportation routes, severe\nuncertainty of future demand and supply, together with non-convex business\nconstraints make it extremely challenging in the traditional resource\nmanagement field. In this paper, we propose a novel sophisticated multi-agent\nreinforcement learning approach to address these challenges. In particular,\ninspired by the externalities especially the interactions among resource\nagents, we introduce an innovative cooperative mechanism for state and reward\ndesign resulting in more effective and efficient transportation. Extensive\nexperiments on a simulated ocean transportation service demonstrate that our\nnew approach can stimulate cooperation among agents and lead to much better\nperformance. Compared with traditional solutions based on combinatorial\noptimization, our approach can give rise to a significant improvement in terms\nof both performance and stability.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 14:55:40 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Li", "Xihan", ""], ["Zhang", "Jia", ""], ["Bian", "Jiang", ""], ["Tong", "Yunhai", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1903.00715", "submitter": "Yang Yu", "authors": "Ruo-Ze Liu, Haifeng Guo, Xiaozhong Ji, Yang Yu, Zhen-Jia Pang, Zitai\n  Xiao, Yuzhou Wu, Tong Lu", "title": "Efficient Reinforcement Learning for StarCraft by Abstract Forward\n  Models and Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Injecting human knowledge is an effective way to accelerate reinforcement\nlearning (RL). However, these methods are underexplored. This paper presents\nour discovery that an abstract forward model (Thought-game (TG)) combined with\ntransfer learning is an effective way. We take StarCraft II as the study\nenvironment. With the help of a designed TG, the agent can learn a 99\\%\nwin-rate on a 64$\\times$64 map against the Level-7 built-in AI, using only 1.08\nhours in a single commercial machine. We also show that the TG method is not as\nrestrictive as it was thought to be. It can work with roughly designed TGs, and\ncan also be useful when the environment changes. Comparing with previous\nmodel-based RL, we show TG is more effective. We also present a TG hypothesis\nthat gives the influence of fidelity levels of TG. For real games that have\nunequal state and action spaces, we proposed a novel XfrNet of which usefulness\nis validated while achieving a 90\\% win-rate against the cheating Level-10 AI.\nWe argue the TG method might shed light on further studies of efficient RL with\nhuman knowledge.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 15:02:03 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 05:30:22 GMT"}, {"version": "v3", "created": "Sat, 30 Jan 2021 19:53:22 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Liu", "Ruo-Ze", ""], ["Guo", "Haifeng", ""], ["Ji", "Xiaozhong", ""], ["Yu", "Yang", ""], ["Pang", "Zhen-Jia", ""], ["Xiao", "Zitai", ""], ["Wu", "Yuzhou", ""], ["Lu", "Tong", ""]]}, {"id": "1903.00718", "submitter": "Maria Maleshkova", "authors": "Sebastian R. Bader, Maria Maleshkova", "title": "Virtual Representations for Iterative IoT Deployment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central vision of the Internet of Things is the representation of the\nphysical world in a consistent virtual environment. Especially in the context\nof smart factories the connection of the different, heterogeneous production\nmodules through a digital shop floor promises faster conversion rates,\ndata-driven maintenance or automated machine configurations for use cases,\nwhich have not been known at design time. Nevertheless, these scenarios demand\nIoT representations of all participating machines and components, which\nrequires high installation efforts and hardware adjustments.\n  We propose an incremental process for bringing the shop floor closer to the\nIoT vision. Currently the majority of systems, components or parts are not yet\nconnected with the internet and might not even provide the possibility to be\ntechnically equipped with sensors. However, those could be essential parts for\na realistic digital shop floor representation. We, therefore, propose Virtual\nRepresentations, which are capable of independently calculating a physical\nobject's condition by dynamically collecting and interpreting already available\ndata through RESTful Web APIs. The internal logic of such Virtual\nRepresentations are further adjustable at runtime, since changes to its\nrespective physical object, its environment or updates to the resource itself\nshould not cause any downtime.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 15:14:15 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Bader", "Sebastian R.", ""], ["Maleshkova", "Maria", ""]]}, {"id": "1903.00742", "submitter": "Joel Leibo", "authors": "Joel Z. Leibo, Edward Hughes, Marc Lanctot, Thore Graepel", "title": "Autocurricula and the Emergence of Innovation from Social Interaction: A\n  Manifesto for Multi-Agent Intelligence Research", "comments": "16 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.MA cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolution has produced a multi-scale mosaic of interacting adaptive units.\nInnovations arise when perturbations push parts of the system away from stable\nequilibria into new regimes where previously well-adapted solutions no longer\nwork. Here we explore the hypothesis that multi-agent systems sometimes display\nintrinsic dynamics arising from competition and cooperation that provide a\nnaturally emergent curriculum, which we term an autocurriculum. The solution of\none social task often begets new social tasks, continually generating novel\nchallenges, and thereby promoting innovation. Under certain conditions these\nchallenges may become increasingly complex over time, demanding that agents\naccumulate ever more innovations.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 18:13:25 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 15:25:43 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Leibo", "Joel Z.", ""], ["Hughes", "Edward", ""], ["Lanctot", "Marc", ""], ["Graepel", "Thore", ""]]}, {"id": "1903.00743", "submitter": "Udayan Khurana", "authors": "Udayan Khurana and Horst Samulowitz", "title": "Automating Predictive Modeling Process using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building a good predictive model requires an array of activities such as data\nimputation, feature transformations, estimator selection, hyper-parameter\nsearch and ensemble construction. Given the large, complex and heterogenous\nspace of options, off-the-shelf optimization methods are infeasible for\nrealistic response times. In practice, much of the predictive modeling process\nis conducted by experienced data scientists, who selectively make use of\navailable tools. Over time, they develop an understanding of the behavior of\noperators, and perform serial decision making under uncertainty, colloquially\nreferred to as educated guesswork. With an unprecedented demand for application\nof supervised machine learning, there is a call for solutions that\nautomatically search for a good combination of parameters across these tasks to\nminimize the modeling error. We introduce a novel system called APRL\n(Autonomous Predictive modeler via Reinforcement Learning), that uses past\nexperience through reinforcement learning to optimize such sequential decision\nmaking from within a set of diverse actions under a time constraint on a\npreviously unseen predictive learning problem. APRL actions are taken to\noptimize the performance of a final ensemble. This is in contrast to other\nsystems, which maximize individual model accuracy first and create ensembles as\na disconnected post-processing step. As a result, APRL is able to reduce up to\n71\\% of classification error on average over a wide variety of problems.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 18:22:19 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Khurana", "Udayan", ""], ["Samulowitz", "Horst", ""]]}, {"id": "1903.00745", "submitter": "Esra Erdem", "authors": "Faseeh Ahmad and Esra Erdem and Volkan Patoglu", "title": "A Formal Framework for Robot Construction Problems: A Hybrid Planning\n  Approach", "comments": "8 pages (double-column), 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study robot construction problems where multiple autonomous robots\nrearrange stacks of prefabricated blocks to build stable structures. These\nproblems are challenging due to ramifications of actions, true concurrency, and\nrequirements of supportedness of blocks by other blocks and stability of the\nstructure at all times. We propose a formal hybrid planning framework to solve\na wide range of robot construction problems, based on Answer Set Programming.\nThis framework not only decides for a stable final configuration of the\nstructure, but also computes the order of manipulation tasks for multiple\nautonomous robots to build the structure from an initial configuration, while\nsimultaneously ensuring the stability, supportedness and other desired\nproperties of the partial construction at each step of the plan. We prove the\nsoundness and completeness of our formal method with respect to these\nproperties. We introduce a set of challenging robot construction benchmark\ninstances, including bridge building and stack overhanging scenarios, discuss\nthe usefulness of our framework over these instances, and demonstrate the\napplicability of our method using a bimanual Baxter robot.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 19:00:20 GMT"}, {"version": "v2", "created": "Sun, 17 Mar 2019 19:38:46 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Ahmad", "Faseeh", ""], ["Erdem", "Esra", ""], ["Patoglu", "Volkan", ""]]}, {"id": "1903.00750", "submitter": "Sainyam Galhotra Mr", "authors": "Sainyam Galhotra, Sandhya Saisubramanian and Shlomo Zilberstein", "title": "Lexicographically Ordered Multi-Objective Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a rich model for multi-objective clustering with lexicographic\nordering over objectives and a slack. The slack denotes the allowed\nmultiplicative deviation from the optimal objective value of the higher\npriority objective to facilitate improvement in lower-priority objectives. We\nthen propose an algorithm called Zeus to solve this class of problems, which is\ncharacterized by a makeshift function. The makeshift fine tunes the clusters\nformed by the processed objectives so as to improve the clustering with respect\nto the unprocessed objectives, given the slack. We present makeshift for\nsolving three different classes of objectives and analyze their solution\nguarantees. Finally, we empirically demonstrate the effectiveness of our\napproach on three applications using real-world data.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 19:32:00 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Galhotra", "Sainyam", ""], ["Saisubramanian", "Sandhya", ""], ["Zilberstein", "Shlomo", ""]]}, {"id": "1903.00780", "submitter": "Alex Beutel", "authors": "Alex Beutel, Jilin Chen, Tulsee Doshi, Hai Qian, Li Wei, Yi Wu, Lukasz\n  Heldt, Zhe Zhao, Lichan Hong, Ed H. Chi, Cristos Goodrow", "title": "Fairness in Recommendation Ranking through Pairwise Comparisons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems are one of the most pervasive applications of machine\nlearning in industry, with many services using them to match users to products\nor information. As such it is important to ask: what are the possible fairness\nrisks, how can we quantify them, and how should we address them? In this paper\nwe offer a set of novel metrics for evaluating algorithmic fairness concerns in\nrecommender systems. In particular we show how measuring fairness based on\npairwise comparisons from randomized experiments provides a tractable means to\nreason about fairness in rankings from recommender systems. Building on this\nmetric, we offer a new regularizer to encourage improving this metric during\nmodel training and thus improve fairness in the resulting rankings. We apply\nthis pairwise regularization to a large-scale, production recommender system\nand show that we are able to significantly improve the system's pairwise\nfairness.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 22:29:42 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Beutel", "Alex", ""], ["Chen", "Jilin", ""], ["Doshi", "Tulsee", ""], ["Qian", "Hai", ""], ["Wei", "Li", ""], ["Wu", "Yi", ""], ["Heldt", "Lukasz", ""], ["Zhao", "Zhe", ""], ["Hong", "Lichan", ""], ["Chi", "Ed H.", ""], ["Goodrow", "Cristos", ""]]}, {"id": "1903.00821", "submitter": "Lei Tai", "authors": "Lei Tai, Peng Yun, Yuying Chen, Congcong Liu, Haoyang Ye, Ming Liu", "title": "Visual-based Autonomous Driving Deployment from a Stochastic and\n  Uncertainty-aware Perspective", "comments": "IROS 2019 camera-ready version, 7 pages, video:\n  https://youtu.be/ZYtsb9-1zXk", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end visual-based imitation learning has been widely applied in\nautonomous driving. When deploying the trained visual-based driving policy, a\ndeterministic command is usually directly applied without considering the\nuncertainty of the input data. Such kind of policies may bring dramatical\ndamage when applied in the real world. In this paper, we follow the recent\nreal-to-sim pipeline by translating the testing world image back to the\ntraining domain when using the trained policy. In the translating process, a\nstochastic generator is used to generate various images stylized under the\ntraining domain randomly or directionally. Based on those translated images,\nthe trained uncertainty-aware imitation learning policy would output both the\npredicted action and the data uncertainty motivated by the aleatoric loss\nfunction. Through the uncertainty-aware imitation learning policy, we can\neasily choose the safest one with the lowest uncertainty among the generated\nimages. Experiments in the Carla navigation benchmark show that our strategy\noutperforms previous methods, especially in dynamic environments.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 03:59:41 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 06:27:18 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Tai", "Lei", ""], ["Yun", "Peng", ""], ["Chen", "Yuying", ""], ["Liu", "Congcong", ""], ["Ye", "Haoyang", ""], ["Liu", "Ming", ""]]}, {"id": "1903.00840", "submitter": "Amir Zadeh", "authors": "Amir Zadeh, Yao-Chong Lim, Paul Pu Liang, Louis-Philippe Morency", "title": "Variational Auto-Decoder: A Method for Neural Generative Modeling from\n  Incomplete Data", "comments": "Link to code and data available from\n  https://github.com/A2Zadeh/Variational-Autodecoder", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a generative model from partial data (data with missingness) is a\nchallenging area of machine learning research. We study a specific\nimplementation of the Auto-Encoding Variational Bayes (AEVB) algorithm, named\nin this paper as a Variational Auto-Decoder (VAD). VAD is a generic framework\nwhich uses Variational Bayes and Markov Chain Monte Carlo (MCMC) methods to\nlearn a generative model from partial data. The main distinction between VAD\nand Variational Auto-Encoder (VAE) is the encoder component, as VAD does not\nhave one. Using a proposed efficient inference method from a multivariate\nGaussian approximate posterior, VAD models allow inference to be performed via\nsimple gradient ascent rather than MCMC sampling from a probabilistic decoder.\nThis technique reduces the inference computational cost, allows for using more\ncomplex optimization techniques during latent space inference (which are shown\nto be crucial due to a high degree of freedom in the VAD latent space), and\nkeeps the framework simple to implement. Through extensive experiments over\nseveral datasets and different missing ratios, we show that encoders cannot\nefficiently marginalize the input volatility caused by imputed missing values.\nWe study multimodal datasets in this paper, which is a particular area of\nimpact for VAD models.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 06:19:55 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 02:47:29 GMT"}, {"version": "v3", "created": "Sun, 24 Mar 2019 00:39:41 GMT"}, {"version": "v4", "created": "Wed, 3 Apr 2019 21:04:05 GMT"}, {"version": "v5", "created": "Sun, 26 May 2019 13:45:51 GMT"}, {"version": "v6", "created": "Sun, 3 Jan 2021 08:27:20 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Zadeh", "Amir", ""], ["Lim", "Yao-Chong", ""], ["Liang", "Paul Pu", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1903.00900", "submitter": "Jiang Rong", "authors": "Jiang Rong, Tao Qin and Bo An", "title": "Competitive Bridge Bidding with Deep Neural Networks", "comments": "This paper was submitted to AAMAS on Nov. 12, 2018, accepted on Jan.\n  23, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The game of bridge consists of two stages: bidding and playing. While playing\nis proved to be relatively easy for computer programs, bidding is very\nchallenging. During the bidding stage, each player knowing only his/her own\ncards needs to exchange information with his/her partner and interfere with\nopponents at the same time. Existing methods for solving perfect-information\ngames cannot be directly applied to bidding. Most bridge programs are based on\nhuman-designed rules, which, however, cannot cover all situations and are\nusually ambiguous and even conflicting with each other. In this paper, we, for\nthe first time, propose a competitive bidding system based on deep learning\ntechniques, which exhibits two novelties. First, we design a compact\nrepresentation to encode the private and public information available to a\nplayer for bidding. Second, based on the analysis of the impact of other\nplayers' unknown cards on one's final rewards, we design two neural networks to\ndeal with imperfect information, the first one inferring the cards of the\npartner and the second one taking the outputs of the first one as part of its\ninput to select a bid. Experimental results show that our bidding system\noutperforms the top rule-based program.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 13:17:21 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 17:55:08 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Rong", "Jiang", ""], ["Qin", "Tao", ""], ["An", "Bo", ""]]}, {"id": "1903.00904", "submitter": "Xuhong Wang", "authors": "Xuhong Wang, Ying Du, Shijie Lin, Ping Cui, Yuntian Shen and Yupu Yang", "title": "adVAE: A self-adversarial variational autoencoder with Gaussian anomaly\n  prior knowledge for anomaly detection", "comments": "This paper has been accepted by Knowledge-based Systems", "journal-ref": null, "doi": "10.1016/j.knosys.2019.105187", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep generative models have become increasingly popular in\nunsupervised anomaly detection. However, deep generative models aim at\nrecovering the data distribution rather than detecting anomalies. Besides, deep\ngenerative models have the risk of overfitting training samples, which has\ndisastrous effects on anomaly detection performance. To solve the above two\nproblems, we propose a Self-adversarial Variational Autoencoder with a Gaussian\nanomaly prior assumption. We assume that both the anomalous and the normal\nprior distribution are Gaussian and have overlaps in the latent space.\nTherefore, a Gaussian transformer net T is trained to synthesize anomalous but\nnear-normal latent variables. Keeping the original training objective of\nVariational Autoencoder, besides, the generator G tries to distinguish between\nthe normal latent variables and the anomalous ones synthesized by T, and the\nencoder E is trained to discriminate whether the output of G is real. These new\nobjectives we added not only give both G and E the ability to discriminate but\nalso introduce additional regularization to prevent overfitting. Compared with\nthe SOTA baselines, the proposed model achieves significant improvements in\nextensive experiments. Datasets and our model are available at a Github\nrepository.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 13:26:19 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 03:37:40 GMT"}, {"version": "v3", "created": "Thu, 14 Nov 2019 12:20:13 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Wang", "Xuhong", ""], ["Du", "Ying", ""], ["Lin", "Shijie", ""], ["Cui", "Ping", ""], ["Shen", "Yuntian", ""], ["Yang", "Yupu", ""]]}, {"id": "1903.00905", "submitter": "Anirudha Vishvakarma", "authors": "Anirudha Vishvakarma", "title": "MILDNet: A Lightweight Single Scaled Deep Ranking Architecture", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-scale deep CNN architecture [1, 2, 3] successfully captures both fine\nand coarse level image descriptors for visual similarity task, but they come up\nwith expensive memory overhead and latency. In this paper, we propose a\ncompeting novel CNN architecture, called MILDNet, which merits by being vastly\ncompact (about 3 times). Inspired by the fact that successive CNN layers\nrepresent the image with increasing levels of abstraction, we compressed our\ndeep ranking model to a single CNN by coupling activations from multiple\nintermediate layers along with the last layer. Trained on the famous\nStreet2shop dataset [4], we demonstrate that our approach performs as good as\nthe current state-of-the-art models with only one third of the parameters,\nmodel size, training time and significant reduction in inference time. The\nsignificance of intermediate layers on image retrieval task has also been shown\nto be performing on popular datasets Holidays, Oxford, Paris [5]. So even\nthough our experiments are done on ecommerce domain, it is applicable to other\ndomains as well. We further did an ablation study to validate our hypothesis by\nchecking the impact on adding each intermediate layer. With this we also\npresent two more useful variants of MILDNet, a mobile model (12 times smaller)\nfor on-edge devices and a compactly featured model (512-d feature embeddings)\nfor systems with less RAMs and to reduce the ranking cost. Further we present\nan intuitive way to automatically create a tailored in-house triplet training\ndataset, which is very hard to create manually. This solution too can also be\ndeployed as an all-inclusive visual similarity solution. Finally, we present\nour entire production level architecture which currently powers visual\nsimilarity at Fynd.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 13:26:37 GMT"}, {"version": "v2", "created": "Thu, 14 Mar 2019 02:54:09 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Vishvakarma", "Anirudha", ""]]}, {"id": "1903.00925", "submitter": "Jasmine Collins", "authors": "Jasmine Collins and Johannes Balle and Jonathon Shlens", "title": "Accelerating Training of Deep Neural Networks with a Standardization\n  Loss", "comments": "Technical report. Results presented at WiML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant advance in accelerating neural network training has been the\ndevelopment of normalization methods, permitting the training of deep models\nboth faster and with better accuracy. These advances come with practical\nchallenges: for instance, batch normalization ties the prediction of individual\nexamples with other examples within a batch, resulting in a network that is\nheavily dependent on batch size. Layer normalization and group normalization\nare data-dependent and thus must be continually used, even at test-time. To\naddress the issues that arise from using explicit normalization techniques, we\npropose to replace existing normalization methods with a simple, secondary\nobjective loss that we term a standardization loss. This formulation is\nflexible and robust across different batch sizes and surprisingly, this\nsecondary objective accelerates learning on the primary training objective.\nBecause it is a training loss, it is simply removed at test-time, and no\nfurther effort is needed to maintain normalized activations. We find that a\nstandardization loss accelerates training on both small- and large-scale image\nclassification experiments, works with a variety of architectures, and is\nlargely robust to training across different batch sizes.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 15:17:06 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Collins", "Jasmine", ""], ["Balle", "Johannes", ""], ["Shlens", "Jonathon", ""]]}, {"id": "1903.00934", "submitter": "Jamilu Awwalu", "authors": "Suleiman Adamu, Jamilu Awwalu", "title": "The Role of Artificial Intelligence (AI) in Adaptive eLearning System\n  (AES) Content Formation: Risks and Opportunities involved", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial Intelligence (AI) plays varying roles in supporting both existing\nand emerging technologies. In the area of Learning and Tutoring, it plays key\nrole in Intelligent Tutoring Systems (ITS). The fusion of ITS with Adaptive\nHypermedia and Multimedia (AHAM) form the backbone of Adaptive eLearning\nSystems (AES) which provides personalized experiences to learners. This\nexperience is important because it facilitates the accurate delivery of the\nlearning modules in specific to the learner capacity and readiness. AES types\nvary, with Adaptive Web Based eLearning Systems (AWBES) being the popular type\nbecause of wider access offered by the web technology.The retrieval and\naggregation of contents for any eLearning system is critical whichis determined\nby the relevance of learning material to the needs of the learner.In this\npaper, we discuss components of AES, role of AI in AES content aggregation,\npossible risks and available opportunities.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 16:10:54 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Adamu", "Suleiman", ""], ["Awwalu", "Jamilu", ""]]}, {"id": "1903.01003", "submitter": "Mohamed Akrout", "authors": "Ismail Akrout, Amal Feriani, Mohamed Akrout", "title": "Hacking Google reCAPTCHA v3 using Reinforcement Learning", "comments": "Accepted for the Conference on Reinforcement Learning and Decision\n  Making (RLDM) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Reinforcement Learning (RL) methodology to bypass Google\nreCAPTCHA v3. We formulate the problem as a grid world where the agent learns\nhow to move the mouse and click on the reCAPTCHA button to receive a high\nscore. We study the performance of the agent when we vary the cell size of the\ngrid world and show that the performance drops when the agent takes big steps\ntoward the goal. Finally, we used a divide and conquer strategy to defeat the\nreCAPTCHA system for any grid resolution. Our proposed method achieves a\nsuccess rate of 97.4% on a 100x100 grid and 96.7% on a 1000x1000 screen\nresolution.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 22:10:47 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 05:22:08 GMT"}, {"version": "v3", "created": "Thu, 18 Apr 2019 16:22:33 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Akrout", "Ismail", ""], ["Feriani", "Amal", ""], ["Akrout", "Mohamed", ""]]}, {"id": "1903.01004", "submitter": "Edouard Leurent", "authors": "Nicolas Carrara, Edouard Leurent, Romain Laroche, Tanguy Urvoy,\n  Odalric-Ambrym Maillard, Olivier Pietquin", "title": "Budgeted Reinforcement Learning in Continuous State Space", "comments": "N. Carrara and E. Leurent have equally contributed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Budgeted Markov Decision Process (BMDP) is an extension of a Markov\nDecision Process to critical applications requiring safety constraints. It\nrelies on a notion of risk implemented in the shape of a cost signal\nconstrained to lie below an - adjustable - threshold. So far, BMDPs could only\nbe solved in the case of finite state spaces with known dynamics. This work\nextends the state-of-the-art to continuous spaces environments and unknown\ndynamics. We show that the solution to a BMDP is a fixed point of a novel\nBudgeted Bellman Optimality operator. This observation allows us to introduce\nnatural extensions of Deep Reinforcement Learning algorithms to address\nlarge-scale BMDPs. We validate our approach on two simulated applications:\nspoken dialogue and autonomous driving.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 22:24:01 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 17:37:51 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 21:50:33 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Carrara", "Nicolas", ""], ["Leurent", "Edouard", ""], ["Laroche", "Romain", ""], ["Urvoy", "Tanguy", ""], ["Maillard", "Odalric-Ambrym", ""], ["Pietquin", "Olivier", ""]]}, {"id": "1903.01021", "submitter": "Michael Cohen", "authors": "Michael K. Cohen, Elliot Catt, Marcus Hutter", "title": "A Strongly Asymptotically Optimal Agent in General Environments", "comments": "7 pages, 3 figures", "journal-ref": "Proc.IJCAI (2019) 2179-2186", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning agents are expected to eventually perform well.\nTypically, this takes the form of a guarantee about the asymptotic behavior of\nan algorithm given some assumptions about the environment. We present an\nalgorithm for a policy whose value approaches the optimal value with\nprobability 1 in all computable probabilistic environments, provided the agent\nhas a bounded horizon. This is known as strong asymptotic optimality, and it\nwas previously unknown whether it was possible for a policy to be strongly\nasymptotically optimal in the class of all computable probabilistic\nenvironments. Our agent, Inquisitive Reinforcement Learner (Inq), is more\nlikely to explore the more it expects an exploratory action to reduce its\nuncertainty about which environment it is in, hence the term inquisitive.\nExploring inquisitively is a strategy that can be applied generally; for more\nmanageable environment classes, inquisitiveness is tractable. We conducted\nexperiments in \"grid-worlds\" to compare the Inquisitive Reinforcement Learner\nto other weakly asymptotically optimal agents.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 00:02:58 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 04:30:13 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Cohen", "Michael K.", ""], ["Catt", "Elliot", ""], ["Hutter", "Marcus", ""]]}, {"id": "1903.01026", "submitter": "Hossein Aboutalebi", "authors": "Hossein Aboutalebi, Doina Precup, Tibor Schuster", "title": "Learning Modular Safe Policies in the Bandit Setting with Application to\n  Adaptive Clinical Trials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stochastic multi-armed bandit problem is a well-known model for studying\nthe exploration-exploitation trade-off. It has significant possible\napplications in adaptive clinical trials, which allow for dynamic changes in\nthe treatment allocation probabilities of patients. However, most bandit\nlearning algorithms are designed with the goal of minimizing the expected\nregret. While this approach is useful in many areas, in clinical trials, it can\nbe sensitive to outlier data, especially when the sample size is small. In this\npaper, we define and study a new robustness criterion for bandit problems.\nSpecifically, we consider optimizing a function of the distribution of returns\nas a regret measure. This provides practitioners more flexibility to define an\nappropriate regret measure. The learning algorithm we propose to solve this\ntype of problem is a modification of the BESA algorithm [Baransi et al., 2014],\nwhich considers a more general version of regret. We present a regret bound for\nour approach and evaluate it empirically both on synthetic problems as well as\non a dataset from the clinical trial literature. Our approach compares\nfavorably to a suite of standard bandit algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 00:42:41 GMT"}, {"version": "v2", "created": "Sun, 24 Mar 2019 17:59:48 GMT"}, {"version": "v3", "created": "Sun, 9 Jun 2019 15:18:08 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Aboutalebi", "Hossein", ""], ["Precup", "Doina", ""], ["Schuster", "Tibor", ""]]}, {"id": "1903.01063", "submitter": "Yuxiang Yang", "authors": "Yuxiang Yang, Ken Caluwaerts, Atil Iscen, Jie Tan, Chelsea Finn", "title": "NoRML: No-Reward Meta Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficiently adapting to new environments and changes in dynamics is critical\nfor agents to successfully operate in the real world. Reinforcement learning\n(RL) based approaches typically rely on external reward feedback for\nadaptation. However, in many scenarios this reward signal might not be readily\navailable for the target task, or the difference between the environments can\nbe implicit and only observable from the dynamics. To this end, we introduce a\nmethod that allows for self-adaptation of learned policies: No-Reward Meta\nLearning (NoRML). NoRML extends Model Agnostic Meta Learning (MAML) for RL and\nuses observable dynamics of the environment instead of an explicit reward\nfunction in MAML's finetune step. Our method has a more expressive update step\nthan MAML, while maintaining MAML's gradient based foundation. Additionally, in\norder to allow more targeted exploration, we implement an extension to MAML\nthat effectively disconnects the meta-policy parameters from the fine-tuned\npolicies' parameters. We first study our method on a number of synthetic\ncontrol problems and then validate our method on common benchmark environments,\nshowing that NoRML outperforms MAML when the dynamics change between tasks.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 04:00:38 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Yang", "Yuxiang", ""], ["Caluwaerts", "Ken", ""], ["Iscen", "Atil", ""], ["Tan", "Jie", ""], ["Finn", "Chelsea", ""]]}, {"id": "1903.01153", "submitter": "Diego Aineto", "authors": "Diego Aineto, Sergio Jim\\'enez and Eva Onaindia", "title": "Learning STRIPS Action Models with Classical Planning", "comments": "8+1 pages, 4 figures, 6 tables", "journal-ref": "Twenty-Eighth International Conference on Automated Planning and\n  Scheduling (ICAPS 2018), pp. 399-407, Year 2018", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach for learning STRIPS action models from\nexamples that compiles this inductive learning task into a classical planning\ntask. Interestingly, the compilation approach is flexible to different amounts\nof available input knowledge; the learning examples can range from a set of\nplans (with their corresponding initial and final states) to just a pair of\ninitial and final states (no intermediate action or state is given). Moreover,\nthe compilation accepts partially specified action models and it can be used to\nvalidate whether the observation of a plan execution follows a given STRIPS\naction model, even if this model is not fully specified.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 09:55:33 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Aineto", "Diego", ""], ["Jim\u00e9nez", "Sergio", ""], ["Onaindia", "Eva", ""]]}, {"id": "1903.01165", "submitter": "Gabriel Istrate", "authors": "Gabriel Istrate, Cosmin Bonchi\\c{s}, Alin Br\\^indu\\c{s}escu", "title": "Attacking Power Indices by Manipulating Player Reliability", "comments": "A revised version of this manuscript will appear in the Proceedings\n  of AAMAS'2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the manipulation of power indices in TU-cooperative games by\nstimulating (subject to a budget constraint) changes in the propensity of other\nplayers to participate to the game.\n  We display several algorithms that show that the problem is often tractable\nfor so-called network centrality games and influence attribution games, as well\nas an example when optimal manipulation is intractable, even though computing\npower indices is feasible.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 10:44:19 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 05:49:49 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Istrate", "Gabriel", ""], ["Bonchi\u015f", "Cosmin", ""], ["Br\u00eendu\u015fescu", "Alin", ""]]}, {"id": "1903.01209", "submitter": "Hoda Heidari", "authors": "Hoda Heidari, Vedant Nanda, and Krishna P. Gummadi", "title": "On the Long-term Impact of Algorithmic Decision Policies: Effort\n  Unfairness and Feature Segregation through Social Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing notions of algorithmic fairness are one-shot: they ensure some\nform of allocative equality at the time of decision making, but do not account\nfor the adverse impact of the algorithmic decisions today on the long-term\nwelfare and prosperity of certain segments of the population. We take a broader\nperspective on algorithmic fairness. We propose an effort-based measure of\nfairness and present a data-driven framework for characterizing the long-term\nimpact of algorithmic policies on reshaping the underlying population.\nMotivated by the psychological literature on \\emph{social learning} and the\neconomic literature on equality of opportunity, we propose a micro-scale model\nof how individuals may respond to decision-making algorithms. We employ\nexisting measures of segregation from sociology and economics to quantify the\nresulting macro-scale population-level change. Importantly, we observe that\ndifferent models may shift the group-conditional distribution of qualifications\nin different directions. Our findings raise a number of important questions\nregarding the formalization of fairness for decision-making models.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 12:38:00 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 13:15:44 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Heidari", "Hoda", ""], ["Nanda", "Vedant", ""], ["Gummadi", "Krishna P.", ""]]}, {"id": "1903.01267", "submitter": "Daniel Angelov", "authors": "Daniel Angelov, Yordan Hristov, Subramanian Ramamoorthy", "title": "Using Causal Analysis to Learn Specifications from Task Demonstrations", "comments": null, "journal-ref": "Proceedings of the 18th International Conference on Autonomous\n  Agents and MultiAgent Systems, Pages 1341-1349, Montreal QC, Canada, May 13 -\n  17, 2019", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning models of user behaviour is an important problem that is broadly\napplicable across many application domains requiring human-robot interaction.\nIn this work we show that it is possible to learn a generative model for\ndistinct user behavioral types, extracted from human demonstrations, by\nenforcing clustering of preferred task solutions within the latent space. We\nuse this model to differentiate between user types and to find cases with\noverlapping solutions. Moreover, we can alter an initially guessed solution to\nsatisfy the preferences that constitute a particular user type by\nbackpropagating through the learned differentiable model. An advantage of\nstructuring generative models in this way is that it allows us to extract\ncausal relationships between symbols that might form part of the user's\nspecification of the task, as manifested in the demonstrations. We show that\nthe proposed method is capable of correctly distinguishing between three user\ntypes, who differ in degrees of cautiousness in their motion, while performing\nthe task of moving objects with a kinesthetically driven robot in a tabletop\nenvironment. Our method successfully identifies the correct type, within the\nspecified time, in 99% [97.8 - 99.8] of the cases, which outperforms an IRL\nbaseline. We also show that our proposed method correctly changes a default\ntrajectory to one satisfying a particular user specification even with unseen\nobjects. The resulting trajectory is shown to be directly implementable on a\nPR2 humanoid robot completing the same task.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 14:26:13 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Angelov", "Daniel", ""], ["Hristov", "Yordan", ""], ["Ramamoorthy", "Subramanian", ""]]}, {"id": "1903.01292", "submitter": "Piotr Mirowski", "authors": "Piotr Mirowski, Andras Banki-Horvath, Keith Anderson, Denis\n  Teplyashin, Karl Moritz Hermann, Mateusz Malinowski, Matthew Koichi Grimes,\n  Karen Simonyan, Koray Kavukcuoglu, Andrew Zisserman, Raia Hadsell", "title": "The StreetLearn Environment and Dataset", "comments": "13 pages, 6 figures, 4 tables. arXiv admin note: text overlap with\n  arXiv:1804.00168", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Navigation is a rich and well-grounded problem domain that drives progress in\nmany different areas of research: perception, planning, memory, exploration,\nand optimisation in particular. Historically these challenges have been\nseparately considered and solutions built that rely on stationary datasets -\nfor example, recorded trajectories through an environment. These datasets\ncannot be used for decision-making and reinforcement learning, however, and in\ngeneral the perspective of navigation as an interactive learning task, where\nthe actions and behaviours of a learning agent are learned simultaneously with\nthe perception and planning, is relatively unsupported. Thus, existing\nnavigation benchmarks generally rely on static datasets (Geiger et al., 2013;\nKendall et al., 2015) or simulators (Beattie et al., 2016; Shah et al., 2018).\nTo support and validate research in end-to-end navigation, we present\nStreetLearn: an interactive, first-person, partially-observed visual\nenvironment that uses Google Street View for its photographic content and broad\ncoverage, and give performance baselines for a challenging goal-driven\nnavigation task. The environment code, baseline agent code, and the dataset are\navailable at http://streetlearn.cc\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 16:21:22 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Mirowski", "Piotr", ""], ["Banki-Horvath", "Andras", ""], ["Anderson", "Keith", ""], ["Teplyashin", "Denis", ""], ["Hermann", "Karl Moritz", ""], ["Malinowski", "Mateusz", ""], ["Grimes", "Matthew Koichi", ""], ["Simonyan", "Karen", ""], ["Kavukcuoglu", "Koray", ""], ["Zisserman", "Andrew", ""], ["Hadsell", "Raia", ""]]}, {"id": "1903.01344", "submitter": "Zhou Fan", "authors": "Zhou Fan, Rui Su, Weinan Zhang and Yong Yu", "title": "Hybrid Actor-Critic Reinforcement Learning in Parameterized Action Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a hybrid architecture of actor-critic algorithms for\nreinforcement learning in parameterized action space, which consists of\nmultiple parallel sub-actor networks to decompose the structured action space\ninto simpler action spaces along with a critic network to guide the training of\nall sub-actor networks. While this paper is mainly focused on parameterized\naction space, the proposed architecture, which we call hybrid actor-critic, can\nbe extended for more general action spaces which has a hierarchical structure.\nWe present an instance of the hybrid actor-critic architecture based on\nproximal policy optimization (PPO), which we refer to as hybrid proximal policy\noptimization (H-PPO). Our experiments test H-PPO on a collection of tasks with\nparameterized action space, where H-PPO demonstrates superior performance over\nprevious methods of parameterized action reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 16:33:15 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 08:32:06 GMT"}, {"version": "v3", "created": "Thu, 30 May 2019 13:02:58 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Fan", "Zhou", ""], ["Su", "Rui", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""]]}, {"id": "1903.01365", "submitter": "Giulio Bacchiani", "authors": "Giulio Bacchiani, Daniele Molinari, Marco Patander", "title": "Microscopic Traffic Simulation by Cooperative Multi-agent Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expert human drivers perform actions relying on traffic laws and their\nprevious experience. While traffic laws are easily embedded into an artificial\nbrain, modeling human complex behaviors which come from past experience is a\nmore challenging task. One of these behaviors is the capability of\ncommunicating intentions and negotiating the right of way through driving\nactions, as when a driver is entering a crowded roundabout and observes other\ncars movements to guess the best time to merge in. In addition, each driver has\nits own unique driving style, which is conditioned by both its personal\ncharacteristics, such as age and quality of sight, and external factors, such\nas being late or in a bad mood. For these reasons, the interaction between\ndifferent drivers is not trivial to simulate in a realistic manner. In this\npaper, this problem is addressed by developing a microscopic simulator using a\nDeep Reinforcement Learning Algorithm based on a combination of visual frames,\nrepresenting the perception around the vehicle, and a vector of numerical\nparameters. In particular, the algorithm called Asynchronous Advantage\nActor-Critic has been extended to a multi-agent scenario in which every agent\nneeds to learn to interact with other similar agents. Moreover, the model\nincludes a novel architecture such that the driving style of each vehicle is\nadjustable by tuning some of its input parameters, permitting to simulate\ndrivers with different levels of aggressiveness and desired cruising speeds.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 17:05:38 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Bacchiani", "Giulio", ""], ["Molinari", "Daniele", ""], ["Patander", "Marco", ""]]}, {"id": "1903.01434", "submitter": "Manoj Kumar", "authors": "Manoj Kumar, Mohammad Babaeizadeh, Dumitru Erhan, Chelsea Finn, Sergey\n  Levine, Laurent Dinh, Durk Kingma", "title": "VideoFlow: A Conditional Flow-Based Model for Stochastic Video\n  Generation", "comments": "ICLR 2020 Camera-Ready. Previous title: VideoFlow: A Flow-Based\n  Generative Model for Video", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models that can model and predict sequences of future events can,\nin principle, learn to capture complex real-world phenomena, such as physical\ninteractions. However, a central challenge in video prediction is that the\nfuture is highly uncertain: a sequence of past observations of events can imply\nmany possible futures. Although a number of recent works have studied\nprobabilistic models that can represent uncertain futures, such models are\neither extremely expensive computationally as in the case of pixel-level\nautoregressive models, or do not directly optimize the likelihood of the data.\nTo our knowledge, our work is the first to propose multi-frame video prediction\nwith normalizing flows, which allows for direct optimization of the data\nlikelihood, and produces high-quality stochastic predictions. We describe an\napproach for modeling the latent space dynamics, and demonstrate that\nflow-based generative models offer a viable and competitive approach to\ngenerative modelling of video.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 18:55:45 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 17:40:04 GMT"}, {"version": "v3", "created": "Wed, 12 Feb 2020 16:55:25 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Kumar", "Manoj", ""], ["Babaeizadeh", "Mohammad", ""], ["Erhan", "Dumitru", ""], ["Finn", "Chelsea", ""], ["Levine", "Sergey", ""], ["Dinh", "Laurent", ""], ["Kingma", "Durk", ""]]}, {"id": "1903.01498", "submitter": "Yuliang Li", "authors": "Sara Evensen, Aaron Feng, Alon Halevy, Jinfeng Li, Vivian Li, Yuliang\n  Li, Huining Liu, George Mihaila, John Morales, Natalie Nuno, Ekaterina\n  Pavlovic, Wang-Chiew Tan, Xiaolan Wang", "title": "Voyageur: An Experiential Travel Search Engine", "comments": "Demo paper accepted to the Web Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe Voyageur, which is an application of experiential search to the\ndomain of travel. Unlike traditional search engines for online services,\nexperiential search focuses on the experiential aspects of the service under\nconsideration. In particular, Voyageur needs to handle queries for subjective\naspects of the service (e.g., quiet hotel, friendly staff) and combine these\nwith objective attributes, such as price and location. Voyageur also highlights\ninteresting facts and tips about the services the user is considering to\nprovide them with further insights into their choices.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 19:25:15 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Evensen", "Sara", ""], ["Feng", "Aaron", ""], ["Halevy", "Alon", ""], ["Li", "Jinfeng", ""], ["Li", "Vivian", ""], ["Li", "Yuliang", ""], ["Liu", "Huining", ""], ["Mihaila", "George", ""], ["Morales", "John", ""], ["Nuno", "Natalie", ""], ["Pavlovic", "Ekaterina", ""], ["Tan", "Wang-Chiew", ""], ["Wang", "Xiaolan", ""]]}, {"id": "1903.01534", "submitter": "Changhao Chen", "authors": "Changhao Chen, Stefano Rosa, Yishu Miao, Chris Xiaoxuan Lu, Wei Wu,\n  Andrew Markham, Niki Trigoni", "title": "Selective Sensor Fusion for Neural Visual-Inertial Odometry", "comments": "Accepted by CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning approaches for Visual-Inertial Odometry (VIO) have proven\nsuccessful, but they rarely focus on incorporating robust fusion strategies for\ndealing with imperfect input sensory data. We propose a novel end-to-end\nselective sensor fusion framework for monocular VIO, which fuses monocular\nimages and inertial measurements in order to estimate the trajectory whilst\nimproving robustness to real-life issues, such as missing and corrupted data or\nbad sensor synchronization. In particular, we propose two fusion modalities\nbased on different masking strategies: deterministic soft fusion and stochastic\nhard fusion, and we compare with previously proposed direct fusion baselines.\nDuring testing, the network is able to selectively process the features of the\navailable sensor modalities and produce a trajectory at scale. We present a\nthorough investigation on the performances on three public autonomous driving,\nMicro Aerial Vehicle (MAV) and hand-held VIO datasets. The results demonstrate\nthe effectiveness of the fusion strategies, which offer better performances\ncompared to direct fusion, particularly in presence of corrupted data. In\naddition, we study the interpretability of the fusion networks by visualising\nthe masking layers in different scenarios and with varying data corruption,\nrevealing interesting correlations between the fusion networks and imperfect\nsensory input data.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 20:51:37 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Chen", "Changhao", ""], ["Rosa", "Stefano", ""], ["Miao", "Yishu", ""], ["Lu", "Chris Xiaoxuan", ""], ["Wu", "Wei", ""], ["Markham", "Andrew", ""], ["Trigoni", "Niki", ""]]}, {"id": "1903.01537", "submitter": "Navyata Sanghvi", "authors": "Navyata Sanghvi, Ryo Yonetani, Kris Kitani", "title": "MGpi: A Computational Model of Multiagent Group Perception and\n  Interaction", "comments": "To be published in: Proceedings of the 19th International Conference\n  on Autonomous Agents and Multiagent Systems (AAMAS 2020), May 2020, Auckland,\n  New Zealand", "journal-ref": "Proceedings of the 19th International Conference on Autonomous\n  Agents and Multiagent Systems (AAMAS 2020), pp. 1196-1205", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Toward enabling next-generation robots capable of socially intelligent\ninteraction with humans, we present a $\\mathbf{computational\\; model}$ of\ninteractions in a social environment of multiple agents and multiple groups.\nThe Multiagent Group Perception and Interaction (MGpi) network is a deep neural\nnetwork that predicts the appropriate social action to execute in a group\nconversation (e.g., speak, listen, respond, leave), taking into account\nneighbors' observable features (e.g., location of people, gaze orientation,\ndistraction, etc.). A central component of MGpi is the Kinesic-Proxemic-Message\n(KPM) gate, that performs social signal gating to extract important information\nfrom a group conversation. In particular, KPM gate filters incoming social cues\nfrom nearby agents by observing their body gestures (kinesics) and spatial\nbehavior (proxemics). The MGpi network and its KPM gate are learned via\nimitation learning, using demonstrations from our designed $\\mathbf{social\\;\ninteraction\\; simulator}$. Further, we demonstrate the efficacy of the KPM gate\nas a social attention mechanism, achieving state-of-the-art performance on the\ntask of $\\mathbf{group\\; identification}$ without using explicit group\nannotations, layout assumptions, or manually chosen parameters.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 21:04:22 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 20:39:57 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Sanghvi", "Navyata", ""], ["Yonetani", "Ryo", ""], ["Kitani", "Kris", ""]]}, {"id": "1903.01567", "submitter": "Jayesh Gupta", "authors": "Bohan Wu, Jayesh K. Gupta, Mykel J. Kochenderfer", "title": "Model Primitive Hierarchical Lifelong Reinforcement Learning", "comments": "9 pages, 10 figures. Accepted as a full paper at AAMAS 2019", "journal-ref": "International Conference on Autonomous Agents and Multiagent\n  Systems (AAMAS 2019)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning interpretable and transferable subpolicies and performing task\ndecomposition from a single, complex task is difficult. Some traditional\nhierarchical reinforcement learning techniques enforce this decomposition in a\ntop-down manner, while meta-learning techniques require a task distribution at\nhand to learn such decompositions. This paper presents a framework for using\ndiverse suboptimal world models to decompose complex task solutions into\nsimpler modular subpolicies. This framework performs automatic decomposition of\na single source task in a bottom up manner, concurrently learning the required\nmodular subpolicies as well as a controller to coordinate them. We perform a\nseries of experiments on high dimensional continuous action control tasks to\ndemonstrate the effectiveness of this approach at both complex single task\nlearning and lifelong learning. Finally, we perform ablation studies to\nunderstand the importance and robustness of different elements in the framework\nand limitations to this approach.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 22:14:23 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Wu", "Bohan", ""], ["Gupta", "Jayesh K.", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1903.01602", "submitter": "Chih-Yao Ma", "authors": "Chih-Yao Ma, Zuxuan Wu, Ghassan AlRegib, Caiming Xiong, Zsolt Kira", "title": "The Regretful Agent: Heuristic-Aided Navigation through Progress\n  Estimation", "comments": "CVPR 2019 (Oral), our code is available at\n  https://github.com/chihyaoma/regretful-agent", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep learning continues to make progress for challenging perception tasks,\nthere is increased interest in combining vision, language, and decision-making.\nSpecifically, the Vision and Language Navigation (VLN) task involves navigating\nto a goal purely from language instructions and visual information without\nexplicit knowledge of the goal. Recent successful approaches have made in-roads\nin achieving good success rates for this task but rely on beam search, which\nthoroughly explores a large number of trajectories and is unrealistic for\napplications such as robotics. In this paper, inspired by the intuition of\nviewing the problem as search on a navigation graph, we propose to use a\nprogress monitor developed in prior work as a learnable heuristic for search.\nWe then propose two modules incorporated into an end-to-end architecture: 1) A\nlearned mechanism to perform backtracking, which decides whether to continue\nmoving forward or roll back to a previous state (Regret Module) and 2) A\nmechanism to help the agent decide which direction to go next by showing\ndirections that are visited and their associated progress estimate (Progress\nMarker). Combined, the proposed approach significantly outperforms current\nstate-of-the-art methods using greedy action selection, with 5% absolute\nimprovement on the test server in success rates, and more importantly 8% on\nsuccess rates normalized by the path length. Our code is available at\nhttps://github.com/chihyaoma/regretful-agent .\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 00:17:12 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Ma", "Chih-Yao", ""], ["Wu", "Zuxuan", ""], ["AlRegib", "Ghassan", ""], ["Xiong", "Caiming", ""], ["Kira", "Zsolt", ""]]}, {"id": "1903.01620", "submitter": "Pasha Khosravi", "authors": "Pasha Khosravi, Yitao Liang, YooJung Choi, Guy Van den Broeck", "title": "What to Expect of Classifiers? Reasoning about Logistic Regression with\n  Missing Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While discriminative classifiers often yield strong predictive performance,\nmissing feature values at prediction time can still be a challenge. Classifiers\nmay not behave as expected under certain ways of substituting the missing\nvalues, since they inherently make assumptions about the data distribution they\nwere trained on. In this paper, we propose a novel framework that classifies\nexamples with missing features by computing the expected prediction with\nrespect to a feature distribution. Moreover, we use geometric programming to\nlearn a naive Bayes distribution that embeds a given logistic regression\nclassifier and can efficiently take its expected predictions. Empirical\nevaluations show that our model achieves the same performance as the logistic\nregression with all features observed, and outperforms standard imputation\ntechniques when features go missing during prediction time. Furthermore, we\ndemonstrate that our method can be used to generate \"sufficient explanations\"\nof logistic regression classifications, by removing features that do not affect\nthe classification.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 01:16:10 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 19:36:26 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Khosravi", "Pasha", ""], ["Liang", "Yitao", ""], ["Choi", "YooJung", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "1903.01669", "submitter": "Vijaya Sai Krishna Gottipati", "authors": "Sai Krishna, Keehong Seo, Dhaivat Bhatt, Vincent Mai, Krishna Murthy,\n  Liam Paull", "title": "Deep Active Localization", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Active localization is the problem of generating robot actions that allow it\nto maximally disambiguate its pose within a reference map. Traditional\napproaches to this use an information-theoretic criterion for action selection\nand hand-crafted perceptual models. In this work we propose an end-to-end\ndifferentiable method for learning to take informative actions that is\ntrainable entirely in simulation and then transferable to real robot hardware\nwith zero refinement. The system is composed of two modules: a convolutional\nneural network for perception, and a deep reinforcement learned planning\nmodule. We introduce a multi-scale approach to the learned perceptual model\nsince the accuracy needed to perform action selection with reinforcement\nlearning is much less than the accuracy needed for robot control. We\ndemonstrate that the resulting system outperforms using the traditional\napproach for either perception or planning. We also demonstrate our approaches\nrobustness to different map configurations and other nuisance parameters\nthrough the use of domain randomization in training. The code is also\ncompatible with the OpenAI gym framework, as well as the Gazebo simulator.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 05:00:08 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Krishna", "Sai", ""], ["Seo", "Keehong", ""], ["Bhatt", "Dhaivat", ""], ["Mai", "Vincent", ""], ["Murthy", "Krishna", ""], ["Paull", "Liam", ""]]}, {"id": "1903.01710", "submitter": "Elodie Chanthery", "authors": "Elodie Chanthery (LAAS, LAAS-DISCO), Louise Trav\\'e-Massuy\\`es\n  (LAAS-DISCO), Yannick Pencol\\'e (LAAS-DISCO), R\\'egis De Ferluc, Brice\n  Dellandrea", "title": "Applying Active Diagnosis to Space Systems by On-Board Control\n  Procedures", "comments": "IEEE Transactions on Aerospace and Electronic Systems, Institute of\n  Electrical and Electronics Engineers, In press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The instrumentation of real systems is often designed for control purposes\nand control inputs are designed to achieve nominal control objectives. Hence,\nthe available measurements may not be sufficient to isolate faults with\ncertainty and diagnoses are ambiguous. Active diagnosis formulates a planning\nproblem to generate a sequence of actions that, applied to the system, enforce\ndiagnosability and allow to iteratively refine ambiguous diagnoses. This paper\nanalyses the requirements for applying active diagnosis to space systems and\nproposes ActHyDiag as an effective framework to solve this problem. It presents\nthe results of applying ActHyDiag to a real space case study and of\nimplementing the generated plans in the form of On-Board Control Procedures.\nThe case study is a redundant Spacewire Network where up to 6 instruments,\nmonitored and controlled by the on-board software hosted in the Satellite\nManagement Unit, are transferring science data to a mass memory unit through\nSpacewire routers. Experiments have been conducted on a real physical benchmark\ndeveloped by Thales Alenia Space and demonstrate the effectiveness of the plans\nproposed by ActHyDiag.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 07:44:35 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Chanthery", "Elodie", "", "LAAS, LAAS-DISCO"], ["Trav\u00e9-Massuy\u00e8s", "Louise", "", "LAAS-DISCO"], ["Pencol\u00e9", "Yannick", "", "LAAS-DISCO"], ["De Ferluc", "R\u00e9gis", ""], ["Dellandrea", "Brice", ""]]}, {"id": "1903.01712", "submitter": "Zhengwei Bai", "authors": "Zhengwei Bai, Baigen Cai, Wei Shangguan, Linguo Chai", "title": "Deep Learning Based Motion Planning For Autonomous Vehicle Using\n  Spatiotemporal LSTM Network", "comments": "5 pages, 8 figures, Accepted to 2018 Chinese Automation Congress\n  (CAC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motion Planning, as a fundamental technology of automatic navigation for the\nautonomous vehicle, is still an open challenging issue in the real-life traffic\nsituation and is mostly applied by the model-based approaches. However, due to\nthe complexity of the traffic situations and the uncertainty of the edge cases,\nit is hard to devise a general motion planning system for the autonomous\nvehicle. In this paper, we proposed a motion planning model based on deep\nlearning (named as spatiotemporal LSTM network), which is able to generate a\nreal-time reflection based on spatiotemporal information extraction. To be\nspecific, the model based on spatiotemporal LSTM network has three main\nstructure. Firstly, the Convolutional Long-short Term Memory (Conv-LSTM) is\nused to extract hidden features through sequential image data. Then, the 3D\nConvolutional Neural Network(3D-CNN) is applied to extract the spatiotemporal\ninformation from the multi-frame feature information. Finally, the fully\nconnected neural networks are used to construct a control model for autonomous\nvehicle steering angle. The experiments demonstrated that the proposed method\ncan generate a robust and accurate visual motion planning results for the\nautonomous vehicle.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 07:46:47 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Bai", "Zhengwei", ""], ["Cai", "Baigen", ""], ["Shangguan", "Wei", ""], ["Chai", "Linguo", ""]]}, {"id": "1903.01865", "submitter": "Maximiliano Celmo David Budan", "authors": "Maximiliano C. D. Bud\\'an, Gerardo I. Simari, Ignacio Viglizzo and\n  Guillermo R. Simari", "title": "An Approach to Characterize Graded Entailment of Arguments through a\n  Label-based Framework", "comments": null, "journal-ref": "Internation Journal of Approximate Reasoning - 2017", "doi": "10.1016/j.ijar.2016.12.016", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Argumentation theory is a powerful paradigm that formalizes a type of\ncommonsense reasoning that aims to simulate the human ability to resolve a\nspecific problem in an intelligent manner. A classical argumentation process\ntakes into account only the properties related to the intrinsic logical\nsoundness of an argument in order to determine its acceptability status.\nHowever, these properties are not always the only ones that matter to establish\nthe argument's acceptability---there exist other qualities, such as strength,\nweight, social votes, trust degree, relevance level, and certainty degree,\namong others.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 14:48:14 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Bud\u00e1n", "Maximiliano C. D.", ""], ["Simari", "Gerardo I.", ""], ["Viglizzo", "Ignacio", ""], ["Simari", "Guillermo R.", ""]]}, {"id": "1903.01874", "submitter": "Maximiliano Celmo David Budan", "authors": "Maximiliano C. D. Bud\\'an, Maria Laura Cobo, Diego C. Martinez and\n  Guillermo R. Simari", "title": "Bipolar in Temporal Argumentation Framework", "comments": null, "journal-ref": "Internation Journal of Approximate Reassoning - 2017", "doi": "10.1016/j.ijar.2017.01.013", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Timed Argumentation Framework (TAF) is a formalism where arguments are only\nvalid for consideration in a given period of time, called availability\nintervals, which are defined for every individual argument. The original\nproposal is based on a single, abstract notion of attack between arguments that\nremains static and permanent in time. Thus, in general, when identifying the\nset of acceptable arguments, the outcome associated with a TAF will vary over\ntime. In this work we introduce an extension of TAF adding the capability of\nmodeling a support relation between arguments. In this sense, the resulting\nframework provides a suitable model for different time-dependent issues. Thus,\nthe main contribution here is to provide an enhanced framework for modeling a\npositive (support) and negative (attack) interaction varying over time, which\nare relevant in many real-world situations. This leads to a Timed Bipolar\nArgumentation Framework (T-BAF), where classical argument extensions can be\ndefined. The proposal aims at advancing in the integration of temporal\nargumentation in different application domain.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 14:57:23 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Bud\u00e1n", "Maximiliano C. D.", ""], ["Cobo", "Maria Laura", ""], ["Martinez", "Diego C.", ""], ["Simari", "Guillermo R.", ""]]}, {"id": "1903.01885", "submitter": "M\\'ario C\\'esar San Felice", "authors": "Pedro H. D. B. Hokama, M\\'ario C. San Felice, Evandro C. Bracht,\n  F\\'abio L. Usberti", "title": "Evolutionary framework for two-stage stochastic resource allocation\n  problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resource allocation problems are a family of problems in which resources must\nbe selected to satisfy given demands. This paper focuses on the two-stage\nstochastic generalization of resource allocation problems where future demands\nare expressed in a finite number of possible scenarios. The goal is to select\ncost effective resources to be acquired in the present time (first stage), and\nto implement a complete solution for each scenario (second stage), while\nminimizing the total expected cost of the choices in both stages.\n  We propose an evolutionary framework for solving general two-stage stochastic\nresource allocation problems. In each iteration of our framework, a local\nsearch algorithm selects resources to be acquired in the first stage. A genetic\nmetaheuristic then completes the solutions for each scenario and relevant\ninformation is passed onto the next iteration, thereby supporting the\nacquisition of promising resources in the following first stage.\nExperimentation on numerous instances of the two-stage stochastic Steiner tree\nproblem suggests that our evolutionary framework is powerful enough to address\nlarge instances of a wide variety of two-stage stochastic resource allocation\nproblems.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 17:30:38 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Hokama", "Pedro H. D. B.", ""], ["Felice", "M\u00e1rio C. San", ""], ["Bracht", "Evandro C.", ""], ["Usberti", "F\u00e1bio L.", ""]]}, {"id": "1903.01920", "submitter": "Guillermo Simari", "authors": "Edgardo Ferretti, Luciano H. Tamargo, Alejandro J. Garcia, Marcelo L.\n  Errecalde, and Guillermo R. Simari", "title": "An approach to Decision Making based on Dynamic Argumentation Systems", "comments": null, "journal-ref": "Artif. Intell. 242: 107-131 (2017)", "doi": "10.1016/j.artint.2016.10.004", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a formalism for single-agent decision making that\nis based on Dynamic Argumentation Frameworks. The formalism can be used to\njustify a choice, which is based on the current situation the agent is\ninvolved. Taking advantage of the inference mechanism of the argumentation\nformalism, it is possible to consider preference relations and conflicts among\nthe available alternatives for that reasoning. With this formalization, given a\nparticular set of evidence, the justified conclusions supported by warranted\narguments will be used by the agent's decision rules to determine which\nalternatives will be selected. We also present an algorithm that implements a\nchoice function based on our formalization. Finally, we complete our\npresentation by introducing formal results that relate the proposed framework\nwith approaches of classical decision theory.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 16:14:16 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Ferretti", "Edgardo", ""], ["Tamargo", "Luciano H.", ""], ["Garcia", "Alejandro J.", ""], ["Errecalde", "Marcelo L.", ""], ["Simari", "Guillermo R.", ""]]}, {"id": "1903.01923", "submitter": "Jos\\'e Rui Figueira", "authors": "Milosz Kadzinski, Jan Badura, Jose Rui Figueira", "title": "Using a Segmenting Description approach in Multiple Criteria Decision\n  Aiding", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for analyzing a set of parameters in a multiple\ncriteria ranking method. Unlike the existing techniques, we do not use any\noptimization technique, instead incorporating and extending a Segmenting\nDescription approach. While considering a value-based preference disaggregation\nmethod, we demonstrate the usefulness of the introduced algorithm in a\nmulti-purpose decision analysis exploiting a system of inequalities that models\nthe Decision Maker's preferences. Specifically, we discuss how it can be\napplied for verifying the consistency between the revealed and estimated\npreferences as well as for identifying the sources of potential incoherence.\nMoreover, we employ the method for conducting robustness analysis, i.e.,\ndiscovering a set of all compatible parameter values and verifying the\nstability of suggested recommendation in view of multiplicity of feasible\nsolutions. In addition, we make clear its suitability for generating arguments\nabout the validity of outcomes and the role of particular criteria. We discuss\nthe favorable characteristics of the Segmenting Description approach which\nenhance its suitability for use in Multiple Criteria Decision Aiding. These\ninclude keeping in memory an entire process of transforming a system of\ninequalities and avoiding the need for processing the inequalities contained in\nthe basic system which is subsequently enriched with some hypothesis to be\nverified. The applicability of the proposed method is exemplified on a\nnumerical study.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 16:25:49 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Kadzinski", "Milosz", ""], ["Badura", "Jan", ""], ["Figueira", "Jose Rui", ""]]}, {"id": "1903.01930", "submitter": "Matteo Stefanini", "authors": "Matteo Stefanini, Riccardo Lancellotti, Lorenzo Baraldi, Simone\n  Calderara", "title": "A Deep Learning based approach to VM behavior identification in cloud\n  systems", "comments": "Accepted at CLOSER2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing data centers are growing in size and complexity to the point\nwhere monitoring and management of the infrastructure become a challenge due to\nscalability issues. A possible approach to cope with the size of such data\ncenters is to identify VMs exhibiting a similar behavior. Existing literature\ndemonstrated that clustering together VMs that show a similar behavior may\nimprove the scalability of both monitoring andmanagement of a data center.\nHowever, available techniques suffer from a trade-off between accuracy and time\nto achieve this result. Throughout this paper we propose a different approach\nwhere, instead of an unsupervised clustering, we rely on classifiers based on\ndeep learning techniques to assigna newly deployed VMs to a cluster of\nalready-known VMs. The two proposed classifiers, namely DeepConv and DeepFFT\nuse a convolution neural network and (in the latter model) exploits Fast\nFourier Transformation to classify the VMs. Our proposal is validated using a\nset of traces describing the behavior of VMs from a realcloud data center. The\nexperiments compare our proposal with state-of-the-art solutions available in\nliterature, demonstrating that our proposal achieve better performance.\nFurthermore, we show that our solution issignificantly faster than the\nalternatives as it can produce a perfect classification even with just a few\nsamples of data, making our proposal viable also toclassify on-demand VMs that\nare characterized by a short life span.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 16:49:00 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Stefanini", "Matteo", ""], ["Lancellotti", "Riccardo", ""], ["Baraldi", "Lorenzo", ""], ["Calderara", "Simone", ""]]}, {"id": "1903.01959", "submitter": "Tao Chen", "authors": "Tao Chen, Saurabh Gupta, Abhinav Gupta", "title": "Learning Exploration Policies for Navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous past works have tackled the problem of task-driven navigation. But,\nhow to effectively explore a new environment to enable a variety of down-stream\ntasks has received much less attention. In this work, we study how agents can\nautonomously explore realistic and complex 3D environments without the context\nof task-rewards. We propose a learning-based approach and investigate different\npolicy architectures, reward functions, and training paradigms. We find that\nthe use of policies with spatial memory that are bootstrapped with imitation\nlearning and finally finetuned with coverage rewards derived purely from\non-board sensors can be effective at exploring novel environments. We show that\nour learned exploration policies can explore better than classical approaches\nbased on geometry alone and generic learning-based exploration techniques.\nFinally, we also show how such task-agnostic exploration can be used for\ndown-stream tasks. Code and Videos are available at:\nhttps://sites.google.com/view/exploration-for-nav.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 18:03:47 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Chen", "Tao", ""], ["Gupta", "Saurabh", ""], ["Gupta", "Abhinav", ""]]}, {"id": "1903.01964", "submitter": "Kristijonas \\v{C}yras", "authors": "Amin Karamlou, Kristijonas \\v{C}yras, Francesca Toni", "title": "Complexity Results and Algorithms for Bipolar Argumentation", "comments": "Paper accepted for publication at AAMAS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bipolar Argumentation Frameworks (BAFs) admit several interpretations of the\nsupport relation and diverging definitions of semantics. Recently, several\nclasses of BAFs have been captured as instances of bipolar Assumption-Based\nArgumentation, a class of Assumption-Based Argumentation (ABA). In this paper,\nwe establish the complexity of bipolar ABA, and consequently of several classes\nof BAFs. In addition to the standard five complexity problems, we analyse the\nrarely-addressed extension enumeration problem too. We also advance\nbacktracking-driven algorithms for enumerating extensions of bipolar ABA\nframeworks, and consequently of BAFs under several interpretations. We prove\nsoundness and completeness of our algorithms, describe their implementation and\nprovide a scalability evaluation. We thus contribute to the study of the as yet\nuninvestigated complexity problems of (variously interpreted) BAFs as well as\nof bipolar ABA, and provide the lacking implementations thereof.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 18:15:37 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Karamlou", "Amin", ""], ["\u010cyras", "Kristijonas", ""], ["Toni", "Francesca", ""]]}, {"id": "1903.01966", "submitter": "Maximiliano Celmo David Budan", "authors": "Maximiliano C. D. Bud\\'an, Mar\\'ia Laura Cobo, Diego I. Mart\\'inez and\n  Antonino Rotolo", "title": "Dealing with Qualitative and Quantitative Features in Legal Domains", "comments": "arXiv admin note: text overlap with arXiv:1903.01865", "journal-ref": "International Conference on Legal Knowledge and Information\n  Systems - 2018", "doi": "10.3233/978-1-61499-935-5-176", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we enrich a formalism for argumentation by including a formal\ncharacterization of features related to the knowledge, in order to capture\nproper reasoning in legal domains. We add meta-data information to the\narguments in the form of labels representing quantitative and qualitative data\nabout them. These labels are propagated through an argumentative graph\naccording to the relations of support, conflict, and aggregation between\narguments.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 18:18:41 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Bud\u00e1n", "Maximiliano C. D.", ""], ["Cobo", "Mar\u00eda Laura", ""], ["Mart\u00ednez", "Diego I.", ""], ["Rotolo", "Antonino", ""]]}, {"id": "1903.01998", "submitter": "Hongyu Shen", "authors": "Hongyu Shen, E. A. Huerta, Eamonn O'Shea, Prayush Kumar, Zhizhen Zhao", "title": "Statistically-informed deep learning for gravitational wave parameter\n  estimation", "comments": "v3: 14 pages, 6 figures, First application of Neural Networks for\n  gravitational wave parameter posterior estimation across multiple events with\n  single training", "journal-ref": null, "doi": null, "report-no": null, "categories": "gr-qc astro-ph.HE cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce deep learning models for gravitational wave parameter estimation\nthat combine a modified $\\texttt{WaveNet}$ architecture with\n$\\textit{constrastive learning}$ and $\\textit{normalizing flow}$. To ascertain\nthe statistical consistency of these models, we validated their predictions\nagainst a Gaussian conjugate prior family whose posterior distribution is\ndescribed by a closed analytical expression. Upon confirming that our models\nproduce statistically consistent results, we used them to estimate the\nastrophysical parameters of five binary black holes: $\\texttt{GW150914}$,\n$\\texttt{GW170104}$, $\\texttt{GW170814}$, $\\texttt{GW190521}$ and\n$\\texttt{GW190630}$. Our findings indicate that our deep learning approach\npredicts posterior distributions that encode physical correlations, and that\nour data-driven median results and $90\\%$ confidence intervals are consistent\nwith those obtained with gravitational wave Bayesian analyses. This methodology\nrequires a single V100 $\\texttt{NVIDIA}$ GPU to produce median values and\nposterior distributions within two milliseconds for each event. This neural\nnetwork, and a tutorial for its use, are available at the $\\texttt{Data and\nLearning Hub for Science}$.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 19:00:02 GMT"}, {"version": "v2", "created": "Sun, 15 Sep 2019 17:39:55 GMT"}, {"version": "v3", "created": "Wed, 10 Mar 2021 01:48:35 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Shen", "Hongyu", ""], ["Huerta", "E. A.", ""], ["O'Shea", "Eamonn", ""], ["Kumar", "Prayush", ""], ["Zhao", "Zhizhen", ""]]}, {"id": "1903.02020", "submitter": "Prasoon Goyal", "authors": "Prasoon Goyal, Scott Niekum, Raymond J. Mooney", "title": "Using Natural Language for Reward Shaping in Reinforcement Learning", "comments": "IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent reinforcement learning (RL) approaches have shown strong performance\nin complex domains such as Atari games, but are often highly sample\ninefficient. A common approach to reduce interaction time with the environment\nis to use reward shaping, which involves carefully designing reward functions\nthat provide the agent intermediate rewards for progress towards the goal.\nHowever, designing appropriate shaping rewards is known to be difficult as well\nas time-consuming. In this work, we address this problem by using natural\nlanguage instructions to perform reward shaping. We propose the LanguagE-Action\nReward Network (LEARN), a framework that maps free-form natural language\ninstructions to intermediate rewards based on actions taken by the agent. These\nintermediate language-based rewards can seamlessly be integrated into any\nstandard reinforcement learning algorithm. We experiment with Montezuma's\nRevenge from the Atari Learning Environment, a popular benchmark in RL. Our\nexperiments on a diverse set of 15 tasks demonstrate that, for the same number\nof interactions with the environment, language-based rewards lead to successful\ncompletion of the task 60% more often on average, compared to learning without\nlanguage.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 19:20:35 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 04:58:07 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Goyal", "Prasoon", ""], ["Niekum", "Scott", ""], ["Mooney", "Raymond J.", ""]]}, {"id": "1903.02044", "submitter": "Ryan De Iaco", "authors": "Ryan De Iaco, Stephen L. Smith, Krzysztof Czarnecki", "title": "Learning a Lattice Planner Control Set for Autonomous Vehicles", "comments": "Accepted to the 2019 IEEE Intelligent Vehicles Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a method to compute a sparse lattice planner control\nset that is suited to a particular task by learning from a representative\ndataset of vehicle paths. To do this, we use a scoring measure similar to the\nFr\\'echet distance and propose an algorithm for evaluating a given control set\naccording to the scoring measure. Control actions are then selected from a\ndense control set according to an objective function that rewards improvements\nin matching the dataset while also encouraging sparsity. This method is\nevaluated across several experiments involving real and synthetic datasets, and\nit is shown to generate smaller control sets when compared to the previous\nstate-of-the-art lattice control set computation technique, with these smaller\ncontrol sets maintaining a high degree of manoeuvrability in the required task.\nThis results in a planning time speedup of up to 4.31x when using the learned\ncontrol set over the state-of-the-art computed control set. In addition, we\nshow the learned control sets are better able to capture the driving style of\nthe dataset in terms of path curvature.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 20:36:03 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2019 17:08:17 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["De Iaco", "Ryan", ""], ["Smith", "Stephen L.", ""], ["Czarnecki", "Krzysztof", ""]]}, {"id": "1903.02054", "submitter": "Karthikeyan Shanmugam", "authors": "Dmitriy Katz, Karthikeyan Shanmugam, Chandler Squires, Caroline Uhler", "title": "Size of Interventional Markov Equivalence Classes in Random DAG Models", "comments": "19 pages, 5 figures. Accepted to AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directed acyclic graph (DAG) models are popular for capturing causal\nrelationships. From observational and interventional data, a DAG model can only\nbe determined up to its \\emph{interventional Markov equivalence class} (I-MEC).\nWe investigate the size of MECs for random DAG models generated by uniformly\nsampling and ordering an Erd\\H{o}s-R\\'{e}nyi graph. For constant density, we\nshow that the expected $\\log$ observational MEC size asymptotically (in the\nnumber of vertices) approaches a constant. We characterize I-MEC size in a\nsimilar fashion in the above settings with high precision. We show that the\nasymptotic expected number of interventions required to fully identify a DAG is\na constant. These results are obtained by exploiting Meek rules and coupling\narguments to provide sharp upper and lower bounds on the asymptotic quantities,\nwhich are then calculated numerically up to high precision. Our results have\nimportant consequences for experimental design of interventions and the\ndevelopment of algorithms for causal inference.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 21:09:37 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Katz", "Dmitriy", ""], ["Shanmugam", "Karthikeyan", ""], ["Squires", "Chandler", ""], ["Uhler", "Caroline", ""]]}, {"id": "1903.02079", "submitter": "Nazeeh Ghatasheh", "authors": "Nazeeh Ghatasheh, Hossam Faris, Ibrahim Aljarah, Rizik M. H. Al-Sayyed", "title": "Optimizing Software Effort Estimation Models Using Firefly Algorithm", "comments": "9 pages", "journal-ref": "Journal of Software Engineering and Applications, 8, 133-142\n  (2018)", "doi": "10.4236/jsea.2015.83014", "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.SE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Software development effort estimation is considered a fundamental task for\nsoftware development life cycle as well as for managing project cost, time and\nquality. Therefore, accurate estimation is a substantial factor in projects\nsuccess and reducing the risks. In recent years, software effort estimation has\nreceived a considerable amount of attention from researchers and became a\nchallenge for software industry. In the last two decades, many researchers and\npractitioners proposed statistical and machine learning-based models for\nsoftware effort estimation. In this work, Firefly Algorithm is proposed as a\nmetaheuristic optimization method for optimizing the parameters of three\nCOCOMO-based models. These models include the basic COCOMO model and other two\nmodels proposed in the literature as extensions of the basic COCOMO model. The\ndeveloped estimation models are evaluated using different evaluation metrics.\nExperimental results show high accuracy and significant error minimization of\nFirefly Algorithm over other metaheuristic optimization algorithms including\nGenetic Algorithms and Particle Swarm Optimization.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 23:34:43 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Ghatasheh", "Nazeeh", ""], ["Faris", "Hossam", ""], ["Aljarah", "Ibrahim", ""], ["Al-Sayyed", "Rizik M. H.", ""]]}, {"id": "1903.02140", "submitter": "Hui Jiang", "authors": "Hui Jiang", "title": "Why Learning of Large-Scale Neural Networks Behaves Like Convex\n  Optimization", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present some theoretical work to explain why simple\ngradient descent methods are so successful in solving non-convex optimization\nproblems in learning large-scale neural networks (NN). After introducing a\nmathematical tool called canonical space, we have proved that the objective\nfunctions in learning NNs are convex in the canonical model space. We further\nelucidate that the gradients between the original NN model space and the\ncanonical space are related by a pointwise linear transformation, which is\nrepresented by the so-called disparity matrix. Furthermore, we have proved that\ngradient descent methods surely converge to a global minimum of zero loss\nprovided that the disparity matrices maintain full rank. If this full-rank\ncondition holds, the learning of NNs behaves in the same way as normal convex\noptimization. At last, we have shown that the chance to have singular disparity\nmatrices is extremely slim in large NNs. In particular, when over-parameterized\nNNs are randomly initialized, the gradient decent algorithms converge to a\nglobal minimum of zero loss in probability.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 02:21:37 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Jiang", "Hui", ""]]}, {"id": "1903.02156", "submitter": "Piji Li", "authors": "Piji Li, Zihao Wang, Lidong Bing, Wai Lam", "title": "Persona-Aware Tips Generation", "comments": "Accepted to WWW'2019, 11 pages", "journal-ref": null, "doi": "10.1145/3308558.3313496", "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tips, as a compacted and concise form of reviews, were paid less attention by\nresearchers. In this paper, we investigate the task of tips generation by\nconsidering the `persona' information which captures the intrinsic language\nstyle of the users or the different characteristics of the product items. In\norder to exploit the persona information, we propose a framework based on\nadversarial variational auto-encoders (aVAE) for persona modeling from the\nhistorical tips and reviews of users and items. The latent variables from aVAE\nare regarded as persona embeddings. Besides representing persona using the\nlatent embeddings, we design a persona memory for storing the persona related\nwords for users and items. Pointer Network is used to retrieve persona wordings\nfrom the memory when generating tips. Moreover, the persona embeddings are used\nas latent factors by a rating prediction component to predict the sentiment of\na user over an item. Finally, the persona embeddings and the sentiment\ninformation are incorporated into a recurrent neural networks based tips\ngeneration component. Extensive experimental results are reported and discussed\nto elaborate the peculiarities of our framework.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 03:36:29 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 12:42:59 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Li", "Piji", ""], ["Wang", "Zihao", ""], ["Bing", "Lidong", ""], ["Lam", "Wai", ""]]}, {"id": "1903.02166", "submitter": "Jon McCormack", "authors": "Jon McCormack, Toby Gifford, Patrick Hutchings", "title": "Autonomy, Authenticity, Authorship and Intention in computer generated\n  art", "comments": "Accepted for EvoMUSART 2019: 8th International Conference on\n  Computational Intelligence in Music, Sound, Art and Design. April 2019,\n  Leipzig, Germany", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines five key questions surrounding computer generated art.\nDriven by the recent public auction of a work of `AI Art' we selectively\nsummarise many decades of research and commentary around topics of autonomy,\nauthenticity, authorship and intention in computer generated art, and use this\nresearch to answer contemporary questions often asked about art made by\ncomputers that concern these topics. We additionally reflect on whether current\ntechniques in deep learning and Generative Adversarial Networks significantly\nchange the answers provided by many decades of prior research.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 04:06:20 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["McCormack", "Jon", ""], ["Gifford", "Toby", ""], ["Hutchings", "Patrick", ""]]}, {"id": "1903.02172", "submitter": "Marwan Mattar", "authors": "Marwan Mattar, Roozbeh Mottaghi, Julian Togelius, Danny Lange", "title": "AAAI-2019 Workshop on Games and Simulations for Artificial Intelligence", "comments": "AAAI-2019 Workshop on Games and Simulations for Artificial\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume represents the accepted submissions from the AAAI-2019 Workshop\non Games and Simulations for Artificial Intelligence held on January 29, 2019\nin Honolulu, Hawaii, USA. https://www.gamesim.ai\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 04:49:07 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Mattar", "Marwan", ""], ["Mottaghi", "Roozbeh", ""], ["Togelius", "Julian", ""], ["Lange", "Danny", ""]]}, {"id": "1903.02173", "submitter": "Gan Sun", "authors": "Gan Sun, Yang Cong, Qianqian Wang, Bineng Zhong, Yun Fu", "title": "Representative Task Self-selection for Flexible Clustered Lifelong\n  Learning", "comments": "15 pages, 33 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the lifelong machine learning paradigm whose objective is to learn a\nsequence of tasks depending on previous experiences, e.g., knowledge library or\ndeep network weights. However, the knowledge libraries or deep networks for\nmost recent lifelong learning models are with prescribed size, and can\ndegenerate the performance for both learned tasks and coming ones when facing\nwith a new task environment (cluster). To address this challenge, we propose a\nnovel incremental clustered lifelong learning framework with two knowledge\nlibraries: feature learning library and model knowledge library, called\nFlexible Clustered Lifelong Learning (FCL3). Specifically, the feature learning\nlibrary modeled by an autoencoder architecture maintains a set of\nrepresentation common across all the observed tasks, and the model knowledge\nlibrary can be self-selected by identifying and adding new representative\nmodels (clusters). When a new task arrives, our proposed FCL3model firstly\ntransfers knowledge from these libraries to encode the new task,\ni.e.,effectively and selectively soft-assigning this new task to multiple\nrepresentative models over feature learning library. Then, 1) the new task with\na higher outlier probability will be judged as a new representative, and used\nto redefine both feature learning library and representative models over time;\nor 2) the new task with lower outlier probability will only refine the feature\nlearning library. For model optimization, we cast this lifelong learning\nproblem as an alternating direction minimization problem as a new task comes.\nFinally, we evaluate the proposed framework by analyzing several multi-task\ndatasets, and the experimental results demonstrate that our FCL3 model can\nachieve better performance than most lifelong learning frameworks, even batch\nclustered multi-task learning models.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 04:49:55 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 17:12:27 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Sun", "Gan", ""], ["Cong", "Yang", ""], ["Wang", "Qianqian", ""], ["Zhong", "Bineng", ""], ["Fu", "Yun", ""]]}, {"id": "1903.02183", "submitter": "Shumpei Kubosawa", "authors": "Shumpei Kubosawa, Takashi Onishi and Yoshimasa Tsuruoka", "title": "Synthesizing Chemical Plant Operation Procedures using Knowledge,\n  Dynamic Simulation and Deep Reinforcement Learning", "comments": "Proceedings of the SICE Annual Conference 2018 (pp.1376-1379)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chemical plants are complex and dynamical systems consisting of many\ncomponents for manipulation and sensing, whose state transitions depend on\nvarious factors such as time, disturbance, and operation procedures. For the\npurpose of supporting human operators of chemical plants, we are developing an\nAI system that can semi-automatically synthesize operation procedures for\nefficient and stable operation. Our system can provide not only appropriate\noperation procedures but also reasons why the procedures are considered to be\nvalid. This is achieved by integrating automated reasoning and deep\nreinforcement learning technologies with a chemical plant simulator and\nexternal knowledge. Our preliminary experimental results demonstrate that it\ncan synthesize a procedure that achieves a much faster recovery from a\nmalfunction compared to standard PID control.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 05:44:15 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Kubosawa", "Shumpei", ""], ["Onishi", "Takashi", ""], ["Tsuruoka", "Yoshimasa", ""]]}, {"id": "1903.02345", "submitter": "Aldo Faisal", "authors": "Matthieu Komorowski, Leo A. Celi, Omar Badawi, Anthony C. Gordon and\n  A. Aldo Faisal", "title": "Understanding the Artificial Intelligence Clinician and optimal\n  treatment strategies for sepsis in intensive care", "comments": "13 pages and a number of figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this document, we explore in more detail our published work (Komorowski,\nCeli, Badawi, Gordon, & Faisal, 2018) for the benefit of the AI in Healthcare\nresearch community. In the above paper, we developed the AI Clinician system,\nwhich demonstrated how reinforcement learning could be used to make useful\nrecommendations towards optimal treatment decisions from intensive care data.\nSince publication a number of authors have reviewed our work (e.g. Abbasi,\n2018; Bos, Azoulay, & Martin-Loeches, 2019; Saria, 2018). Given the difference\nof our framework to previous work, the fact that we are bridging two very\ndifferent academic communities (intensive care and machine learning) and that\nour work has impact on a number of other areas with more traditional\ncomputer-based approaches (biosignal processing and control, biomedical\nengineering), we are providing here additional details on our recent\npublication.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 12:59:28 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Komorowski", "Matthieu", ""], ["Celi", "Leo A.", ""], ["Badawi", "Omar", ""], ["Gordon", "Anthony C.", ""], ["Faisal", "A. Aldo", ""]]}, {"id": "1903.02409", "submitter": "Prashan Madumal", "authors": "Prashan Madumal, Tim Miller, Liz Sonenberg, Frank Vetere", "title": "A Grounded Interaction Protocol for Explainable Artificial Intelligence", "comments": "To appear in 18th International Conference on Autonomous Agents and\n  Multiagent Systems (AAMAS 2019) as a full paper. arXiv admin note:\n  substantial text overlap with arXiv:1806.08055", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable Artificial Intelligence (XAI) systems need to include an\nexplanation model to communicate the internal decisions, behaviours and actions\nto the interacting humans. Successful explanation involves both cognitive and\nsocial processes. In this paper we focus on the challenge of meaningful\ninteraction between an explainer and an explainee and investigate the\nstructural aspects of an interactive explanation to propose an interaction\nprotocol. We follow a bottom-up approach to derive the model by analysing\ntranscripts of different explanation dialogue types with 398 explanation\ndialogues. We use grounded theory to code and identify key components of an\nexplanation dialogue. We formalize the model using the agent dialogue framework\n(ADF) as a new dialogue type and then evaluate it in a human-agent interaction\nstudy with 101 dialogues from 14 participants. Our results show that the\nproposed model can closely follow the explanation dialogues of human-agent\nconversations.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 09:44:16 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Madumal", "Prashan", ""], ["Miller", "Tim", ""], ["Sonenberg", "Liz", ""], ["Vetere", "Frank", ""]]}, {"id": "1903.02511", "submitter": "Miguel Vasco", "authors": "Miguel Vasco, Francisco S. Melo, David Martins de Matos, Ana Paiva,\n  Tetsunari Inamura", "title": "Learning multimodal representations for sample-efficient recognition of\n  human actions", "comments": "7 pages, 6 figures, submitted to 2019 IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans interact in rich and diverse ways with the environment. However, the\nrepresentation of such behavior by artificial agents is often limited. In this\nwork we present \\textit{motion concepts}, a novel multimodal representation of\nhuman actions in a household environment. A motion concept encompasses a\nprobabilistic description of the kinematics of the action along with its\ncontextual background, namely the location and the objects held during the\nperformance. Furthermore, we present Online Motion Concept Learning (OMCL), a\nnew algorithm which learns novel motion concepts from action demonstrations and\nrecognizes previously learned motion concepts. The algorithm is evaluated on a\nvirtual-reality household environment with the presence of a human avatar. OMCL\noutperforms standard motion recognition algorithms on an one-shot recognition\ntask, attesting to its potential for sample-efficient recognition of human\nactions.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 17:37:21 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Vasco", "Miguel", ""], ["Melo", "Francisco S.", ""], ["de Matos", "David Martins", ""], ["Paiva", "Ana", ""], ["Inamura", "Tetsunari", ""]]}, {"id": "1903.02526", "submitter": "Jiameng Fan", "authors": "Jiameng Fan, Wenchao Li", "title": "Safety-Guided Deep Reinforcement Learning via Online Gaussian Process\n  Estimation", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important facet of reinforcement learning (RL) has to do with how the\nagent goes about exploring the environment. Traditional exploration strategies\ntypically focus on efficiency and ignore safety. However, for practical\napplications, ensuring safety of the agent during exploration is crucial since\nperforming an unsafe action or reaching an unsafe state could result in\nirreversible damage to the agent. The main challenge of safe exploration is\nthat characterizing the unsafe states and actions is difficult for large\ncontinuous state or action spaces and unknown environments. In this paper, we\npropose a novel approach to incorporate estimations of safety to guide\nexploration and policy search in deep reinforcement learning. By using a cost\nfunction to capture trajectory-based safety, our key idea is to formulate the\nstate-action value function of this safety cost as a candidate Lyapunov\nfunction and extend control-theoretic results to approximate its derivative\nusing online Gaussian Process (GP) estimation. We show how to use these\nstatistical models to guide the agent in unknown environments to obtain\nhigh-performance control policies with provable stability certificates.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 18:02:08 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 02:59:27 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Fan", "Jiameng", ""], ["Li", "Wenchao", ""]]}, {"id": "1903.02531", "submitter": "Somil Bansal", "authors": "Somil Bansal, Varun Tolani, Saurabh Gupta, Jitendra Malik, Claire\n  Tomlin", "title": "Combining Optimal Control and Learning for Visual Navigation in Novel\n  Environments", "comments": "Project website: https://vtolani95.github.io/WayPtNav/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based control is a popular paradigm for robot navigation because it can\nleverage a known dynamics model to efficiently plan robust robot trajectories.\nHowever, it is challenging to use model-based methods in settings where the\nenvironment is a priori unknown and can only be observed partially through\non-board sensors on the robot. In this work, we address this short-coming by\ncoupling model-based control with learning-based perception. The learning-based\nperception module produces a series of waypoints that guide the robot to the\ngoal via a collision-free path. These waypoints are used by a model-based\nplanner to generate a smooth and dynamically feasible trajectory that is\nexecuted on the physical system using feedback control. Our experiments in\nsimulated real-world cluttered environments and on an actual ground vehicle\ndemonstrate that the proposed approach can reach goal locations more reliably\nand efficiently in novel environments as compared to purely geometric\nmapping-based or end-to-end learning-based alternatives. Our approach does not\nrely on detailed explicit 3D maps of the environment, works well with low frame\nrates, and generalizes well from simulation to the real world. Videos\ndescribing our approach and experiments are available on the project website.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 18:11:32 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 22:32:51 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Bansal", "Somil", ""], ["Tolani", "Varun", ""], ["Gupta", "Saurabh", ""], ["Malik", "Jitendra", ""], ["Tomlin", "Claire", ""]]}, {"id": "1903.02601", "submitter": "Bracha Shapira", "authors": "Rami Puzis, Hadar Polad, Bracha Shapira", "title": "Attack Graph Obfuscation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Before executing an attack, adversaries usually explore the victim's network\nin an attempt to infer the network topology and identify vulnerabilities in the\nvictim's servers and personal computers. Falsifying the information collected\nby the adversary post penetration may significantly slower lateral movement and\nincrease the amount of noise generated within the victim's network. We\ninvestigate the effect of fake vulnerabilities within a real enterprise network\non the attacker performance. We use the attack graphs to model the path of an\nattacker making its way towards a target in a given network. We use\ncombinatorial optimization in order to find the optimal assignments of fake\nvulnerabilities. We demonstrate the feasibility of our deception-based defense\nby presenting results of experiments with a large scale real network. We show\nthat adding fake vulnerabilities forces the adversary to invest a significant\namount of effort, in terms of time and exploitability cost.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 20:21:11 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Puzis", "Rami", ""], ["Polad", "Hadar", ""], ["Shapira", "Bracha", ""]]}, {"id": "1903.02610", "submitter": "Gabriel Loaiza-Ganem", "authors": "Gabriel Loaiza-Ganem, Sean M. Perkins, Karen E. Schroeder, Mark M.\n  Churchland, John P. Cunningham", "title": "Deep Random Splines for Point Process Intensity Estimation of Neural\n  Population Data", "comments": "Accepted at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes are the leading class of distributions on random\nfunctions, but they suffer from well known issues including difficulty scaling\nand inflexibility with respect to certain shape constraints (such as\nnonnegativity). Here we propose Deep Random Splines, a flexible class of random\nfunctions obtained by transforming Gaussian noise through a deep neural network\nwhose output are the parameters of a spline. Unlike Gaussian processes, Deep\nRandom Splines allow us to readily enforce shape constraints while inheriting\nthe richness and tractability of deep generative models. We also present an\nobservational model for point process data which uses Deep Random Splines to\nmodel the intensity function of each point process and apply it to neural\npopulation data to obtain a low-dimensional representation of spiking activity.\nInference is performed via a variational autoencoder that uses a novel\nrecurrent encoder architecture that can handle multiple point processes as\ninput. We use a newly collected dataset where a primate completes a pedaling\ntask, and observe better dimensionality reduction with our model than with\ncompeting alternatives.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 21:01:03 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 00:28:06 GMT"}, {"version": "v3", "created": "Fri, 27 Sep 2019 19:39:54 GMT"}, {"version": "v4", "created": "Thu, 10 Oct 2019 01:20:17 GMT"}, {"version": "v5", "created": "Thu, 21 Nov 2019 03:46:59 GMT"}, {"version": "v6", "created": "Sun, 29 Dec 2019 23:52:01 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Loaiza-Ganem", "Gabriel", ""], ["Perkins", "Sean M.", ""], ["Schroeder", "Karen E.", ""], ["Churchland", "Mark M.", ""], ["Cunningham", "John P.", ""]]}, {"id": "1903.02703", "submitter": "Dengji Zhao", "authors": "Dengji Zhao, Bin Li, Junping Xu, Dong Hao, Nicholas R. Jennings", "title": "Selling Multiple Items via Social Networks", "comments": "Published at AAMAS18, this version updates a typo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a market where a seller sells multiple units of a commodity in a\nsocial network. Each node/buyer in the social network can only directly\ncommunicate with her neighbours, i.e. the seller can only sell the commodity to\nher neighbours if she could not find a way to inform other buyers. In this\npaper, we design a novel promotion mechanism that incentivizes all buyers, who\nare aware of the sale, to invite all their neighbours to join the sale, even\nthough there is no guarantee that their efforts will be paid. While traditional\nsale promotions such as sponsored search auctions cannot guarantee a positive\nreturn for the advertiser (the seller), our mechanism guarantees that the\nseller's revenue is better than not using the advertising. More importantly,\nthe seller does not need to pay if the advertising is not beneficial to her.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 02:54:38 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Zhao", "Dengji", ""], ["Li", "Bin", ""], ["Xu", "Junping", ""], ["Hao", "Dong", ""], ["Jennings", "Nicholas R.", ""]]}, {"id": "1903.02710", "submitter": "Emilio Parisotto", "authors": "Emilio Parisotto and Soham Ghosh and Sai Bhargav Yalamanchi and Varsha\n  Chinnaobireddy and Yuhuai Wu and Ruslan Salakhutdinov", "title": "Concurrent Meta Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art meta reinforcement learning algorithms typically assume the\nsetting of a single agent interacting with its environment in a sequential\nmanner. A negative side-effect of this sequential execution paradigm is that,\nas the environment becomes more and more challenging, and thus requiring more\ninteraction episodes for the meta-learner, it needs the agent to reason over\nlonger and longer time-scales. To combat the difficulty of long time-scale\ncredit assignment, we propose an alternative parallel framework, which we name\n\"Concurrent Meta-Reinforcement Learning\" (CMRL), that transforms the temporal\ncredit assignment problem into a multi-agent reinforcement learning one. In\nthis multi-agent setting, a set of parallel agents are executed in the same\nenvironment and each of these \"rollout\" agents are given the means to\ncommunicate with each other. The goal of the communication is to coordinate, in\na collaborative manner, the most efficient exploration of the shared task the\nagents are currently assigned. This coordination therefore represents the\nmeta-learning aspect of the framework, as each agent can be assigned or assign\nitself a particular section of the current task's state space. This framework\nis in contrast to standard RL methods that assume that each parallel rollout\noccurs independently, which can potentially waste computation if many of the\nrollouts end up sampling the same part of the state space. Furthermore, the\nparallel setting enables us to define several reward sharing functions and\nauxiliary losses that are non-trivial to apply in the sequential setting. We\ndemonstrate the effectiveness of our proposed CMRL at improving over sequential\nmethods in a variety of challenging tasks.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 03:28:41 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Parisotto", "Emilio", ""], ["Ghosh", "Soham", ""], ["Yalamanchi", "Sai Bhargav", ""], ["Chinnaobireddy", "Varsha", ""], ["Wu", "Yuhuai", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1903.02716", "submitter": "Rongqi Li", "authors": "Yujie Chen, Yu Qian, Yichen Yao, Zili Wu, Rongqi Li, Yinzhi Zhou,\n  Haoyuan Hu, Yinghui Xu", "title": "Can Sophisticated Dispatching Strategy Acquired by Reinforcement\n  Learning? - A Case Study in Dynamic Courier Dispatching System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a courier dispatching problem (CDP) raised from an\nonline pickup-service platform of Alibaba. The CDP aims to assign a set of\ncouriers to serve pickup requests with stochastic spatial and temporal arrival\nrate among urban regions. The objective is to maximize the revenue of served\nrequests given a limited number of couriers over a period of time. Many online\nalgorithms such as dynamic matching and vehicle routing strategy from existing\nliterature could be applied to tackle this problem. However, these methods rely\non appropriately predefined optimization objectives at each decision point,\nwhich is hard in dynamic situations. This paper formulates the CDP as a Markov\ndecision process (MDP) and proposes a data-driven approach to derive the\noptimal dispatching rule-set under different scenarios. Our method stacks\nmulti-layer images of the spatial-and-temporal map and apply multi-agent\nreinforcement learning (MARL) techniques to evolve dispatching models. This\nmethod solves the learning inefficiency caused by traditional centralized MDP\nmodeling. Through comprehensive experiments on both artificial dataset and\nreal-world dataset, we show: 1) By utilizing historical data and considering\nlong-term revenue gains, MARL achieves better performance than myopic online\nalgorithms; 2) MARL is able to construct the mapping between complex scenarios\nto sophisticated decisions such as the dispatching rule. 3) MARL has the\nscalability to adopt in large-scale real-world scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 03:49:07 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Chen", "Yujie", ""], ["Qian", "Yu", ""], ["Yao", "Yichen", ""], ["Wu", "Zili", ""], ["Li", "Rongqi", ""], ["Zhou", "Yinzhi", ""], ["Hu", "Haoyuan", ""], ["Xu", "Yinghui", ""]]}, {"id": "1903.02741", "submitter": "Chi Zhang", "authors": "Chi Zhang, Feng Gao, Baoxiong Jia, Yixin Zhu, Song-Chun Zhu", "title": "RAVEN: A Dataset for Relational and Analogical Visual rEasoNing", "comments": "CVPR 2019 paper. Supplementary:\n  http://wellyzhang.github.io/attach/cvpr19zhang_supp.pdf Project:\n  http://wellyzhang.github.io/project/raven.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dramatic progress has been witnessed in basic vision tasks involving\nlow-level perception, such as object recognition, detection, and tracking.\nUnfortunately, there is still an enormous performance gap between artificial\nvision systems and human intelligence in terms of higher-level vision problems,\nespecially ones involving reasoning. Earlier attempts in equipping machines\nwith high-level reasoning have hovered around Visual Question Answering (VQA),\none typical task associating vision and language understanding. In this work,\nwe propose a new dataset, built in the context of Raven's Progressive Matrices\n(RPM) and aimed at lifting machine intelligence by associating vision with\nstructural, relational, and analogical reasoning in a hierarchical\nrepresentation. Unlike previous works in measuring abstract reasoning using\nRPM, we establish a semantic link between vision and reasoning by providing\nstructure representation. This addition enables a new type of abstract\nreasoning by jointly operating on the structure representation. Machine\nreasoning ability using modern computer vision is evaluated in this newly\nproposed dataset. Additionally, we also provide human performance as a\nreference. Finally, we show consistent improvement across all models by\nincorporating a simple neural module that combines visual understanding and\nstructure reasoning.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 06:28:44 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Zhang", "Chi", ""], ["Gao", "Feng", ""], ["Jia", "Baoxiong", ""], ["Zhu", "Yixin", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1903.02875", "submitter": "Chongwen Huang", "authors": "Chongwen Huang, George C. Alexandropoulos, Alessio Zappone, Chau Yuen,\n  and M\\'erouane Debbah", "title": "Deep Learning for UL/DL Channel Calibration in Generic Massive MIMO\n  Systems", "comments": "6-pages, accepted by ICC WC Symposium 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the fundamental challenges to realize massive Multiple-Input\nMultiple-Output (MIMO) communications is the accurate acquisition of channel\nstate information for a plurality of users at the base station. This is usually\naccomplished in the UpLink (UL) direction profiting from the time division\nduplexing mode. In practical base station transceivers, there exist inevitably\nnonlinear hardware components, like signal amplifiers and various analog\nfilters, which complicates the calibration task. To deal with this challenge,\nwe design a deep neural network for channel calibration between the UL and\nDownLink (DL) directions. During the initial training phase, the deep neural\nnetwork is trained from both UL and DL channel measurements. We then leverage\nthe trained deep neural network with the instantaneously estimated UL channel\nto calibrate the DL one, which is not observable during the UL transmission\nphase. Our numerical results confirm the merits of the proposed approach, and\nshow that it can achieve performance comparable to conventional approaches,\nlike the Agros method and methods based on least squares, that however assume\nlinear hardware behavior models. More importantly, considering generic\nnonlinear relationships between the UL and DL channels, it is demonstrated that\nour deep neural network approach exhibits robust performance, even when the\nnumber of training sequences is limited.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 12:33:00 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 13:57:27 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Huang", "Chongwen", ""], ["Alexandropoulos", "George C.", ""], ["Zappone", "Alessio", ""], ["Yuen", "Chau", ""], ["Debbah", "M\u00e9rouane", ""]]}, {"id": "1903.02891", "submitter": "Felix Sattler", "authors": "Felix Sattler, Simon Wiedemann, Klaus-Robert M\\\"uller, Wojciech Samek", "title": "Robust and Communication-Efficient Federated Learning from Non-IID Data", "comments": "17 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning allows multiple parties to jointly train a deep learning\nmodel on their combined data, without any of the participants having to reveal\ntheir local data to a centralized server. This form of privacy-preserving\ncollaborative learning however comes at the cost of a significant communication\noverhead during training. To address this problem, several compression methods\nhave been proposed in the distributed training literature that can reduce the\namount of required communication by up to three orders of magnitude. These\nexisting methods however are only of limited utility in the Federated Learning\nsetting, as they either only compress the upstream communication from the\nclients to the server (leaving the downstream communication uncompressed) or\nonly perform well under idealized conditions such as iid distribution of the\nclient data, which typically can not be found in Federated Learning. In this\nwork, we propose Sparse Ternary Compression (STC), a new compression framework\nthat is specifically designed to meet the requirements of the Federated\nLearning environment. Our experiments on four different learning tasks\ndemonstrate that STC distinctively outperforms Federated Averaging in common\nFederated Learning scenarios where clients either a) hold non-iid data, b) use\nsmall batch sizes during training, or where c) the number of clients is large\nand the participation rate in every communication round is low. We furthermore\nshow that even if the clients hold iid data and use medium sized batches for\ntraining, STC still behaves pareto-superior to Federated Averaging in the sense\nthat it achieves fixed target accuracies on our benchmarks within both fewer\ntraining iterations and a smaller communication budget.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 13:10:30 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Sattler", "Felix", ""], ["Wiedemann", "Simon", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""]]}, {"id": "1903.02978", "submitter": "Nico Herbig", "authors": "Nico Herbig, Santanu Pal, Josef van Genabith, Antonio Kr\\\"uger", "title": "Integrating Artificial and Human Intelligence for Efficient Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current advances in machine translation increase the need for translators to\nswitch from traditional translation to post-editing of machine-translated text,\na process that saves time and improves quality. Human and artificial\nintelligence need to be integrated in an efficient way to leverage the\nadvantages of both for the translation task. This paper outlines approaches at\nthis boundary of AI and HCI and discusses open research questions to further\nadvance the field.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 15:14:42 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Herbig", "Nico", ""], ["Pal", "Santanu", ""], ["van Genabith", "Josef", ""], ["Kr\u00fcger", "Antonio", ""]]}, {"id": "1903.03061", "submitter": "Tahar Kechadi M", "authors": "Damir Kahvedzic, Tahar Kechadi", "title": "DIALOG: A framework for modeling, analysis and reuse of digital forensic\n  knowledge", "comments": null, "journal-ref": "Digital Investigation Volume 6, Supplement, September 2009, Pages\n  S23-S33", "doi": "10.1016/j.diin.2009.06.014", "report-no": null, "categories": "cs.DL cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents DIALOG (Digital Investigation Ontology); a framework for\nthe management, reuse, and analysis of Digital Investigation knowledge. DIALOG\nprovides a general, application independent vocabulary that can be used to\ndescribe an investigation at different levels of detail. DIALOG is defined to\nencapsulate all concepts of the digital forensics field and the relationships\nbetween them. In particular, we concentrate on the Windows Registry, where\nregistry keys are modeled in terms of both their structure and function.\nRegistry analysis software tools are modeled in a similar manner and we\nillustrate how the interpretation of their results can be done using the\nreasoning capabilities of ontology\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 13:47:02 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Kahvedzic", "Damir", ""], ["Kechadi", "Tahar", ""]]}, {"id": "1903.03078", "submitter": "Manolis Pitsikalis", "authors": "Manolis Pitsikalis, Alexander Artikis, Richard Dreo, Cyril Ray, Elena\n  Camossi and Anne-Laure Jousselme", "title": "Composite Event Recognition for Maritime Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maritime monitoring systems support safe shipping as they allow for the\nreal-time detection of dangerous, suspicious and illegal vessel activities. We\npresent such a system using the Run-Time Event Calculus, a composite event\nrecognition system with formal, declarative semantics. For effective\nrecognition, we developed a library of maritime patterns in close collaboration\nwith domain experts. We present a thorough evaluation of the system and the\npatterns both in terms of predictive accuracy and computational efficiency,\nusing real-world datasets of vessel position streams and contextual\ngeographical information.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 18:10:00 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 13:47:52 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 12:17:36 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Pitsikalis", "Manolis", ""], ["Artikis", "Alexander", ""], ["Dreo", "Richard", ""], ["Ray", "Cyril", ""], ["Camossi", "Elena", ""], ["Jousselme", "Anne-Laure", ""]]}, {"id": "1903.03094", "submitter": "Jason  Weston", "authors": "Jack Urbanek, Angela Fan, Siddharth Karamcheti, Saachi Jain, Samuel\n  Humeau, Emily Dinan, Tim Rockt\\\"aschel, Douwe Kiela, Arthur Szlam, Jason\n  Weston", "title": "Learning to Speak and Act in a Fantasy Text Adventure Game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a large scale crowdsourced text adventure game as a research\nplatform for studying grounded dialogue. In it, agents can perceive, emote, and\nact whilst conducting dialogue with other agents. Models and humans can both\nact as characters within the game. We describe the results of training\nstate-of-the-art generative and retrieval models in this setting. We show that\nin addition to using past dialogue, these models are able to effectively use\nthe state of the underlying world to condition their predictions. In\nparticular, we show that grounding on the details of the local environment,\nincluding location descriptions, and the objects (and their affordances) and\ncharacters (and their previous actions) present within it allows better\npredictions of agent behavior and dialogue. We analyze the ingredients\nnecessary for successful grounding in this setting, and how each of these\nfactors relate to agents that can talk and act successfully.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 18:45:52 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Urbanek", "Jack", ""], ["Fan", "Angela", ""], ["Karamcheti", "Siddharth", ""], ["Jain", "Saachi", ""], ["Humeau", "Samuel", ""], ["Dinan", "Emily", ""], ["Rockt\u00e4schel", "Tim", ""], ["Kiela", "Douwe", ""], ["Szlam", "Arthur", ""], ["Weston", "Jason", ""]]}, {"id": "1903.03099", "submitter": "Ondrej Kuzelka", "authors": "Ondrej Kuzelka and Vyacheslav Kungurtsev", "title": "Lifted Weight Learning of Markov Logic Networks Revisited", "comments": "Appearing in the proceedings of the 22nd International Conference on\n  Artificial Intelligence and Statistics (AISTATS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study lifted weight learning of Markov logic networks. We show that there\nis an algorithm for maximum-likelihood learning of 2-variable Markov logic\nnetworks which runs in time polynomial in the domain size. Our results are\nbased on existing lifted-inference algorithms and recent algorithmic results on\ncomputing maximum entropy distributions.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 18:50:10 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Kuzelka", "Ondrej", ""], ["Kungurtsev", "Vyacheslav", ""]]}, {"id": "1903.03166", "submitter": "Satwik Kottur", "authors": "Satwik Kottur, Jos\\'e M. F. Moura, Devi Parikh, Dhruv Batra, Marcus\n  Rohrbach", "title": "CLEVR-Dialog: A Diagnostic Dataset for Multi-Round Reasoning in Visual\n  Dialog", "comments": "13 pages, 11 figures, 3 tables, accepted as a short paper at NAACL\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Dialog is a multimodal task of answering a sequence of questions\ngrounded in an image, using the conversation history as context. It entails\nchallenges in vision, language, reasoning, and grounding. However, studying\nthese subtasks in isolation on large, real datasets is infeasible as it\nrequires prohibitively-expensive complete annotation of the 'state' of all\nimages and dialogs.\n  We develop CLEVR-Dialog, a large diagnostic dataset for studying multi-round\nreasoning in visual dialog. Specifically, we construct a dialog grammar that is\ngrounded in the scene graphs of the images from the CLEVR dataset. This\ncombination results in a dataset where all aspects of the visual dialog are\nfully annotated. In total, CLEVR-Dialog contains 5 instances of 10-round\ndialogs for about 85k CLEVR images, totaling to 4.25M question-answer pairs.\n  We use CLEVR-Dialog to benchmark performance of standard visual dialog\nmodels; in particular, on visual coreference resolution (as a function of the\ncoreference distance). This is the first analysis of its kind for visual dialog\nmodels that was not possible without this dataset. We hope the findings from\nCLEVR-Dialog will help inform the development of future models for visual\ndialog. Our dataset and code are publicly available.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 20:18:39 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 18:04:43 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Kottur", "Satwik", ""], ["Moura", "Jos\u00e9 M. F.", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""], ["Rohrbach", "Marcus", ""]]}, {"id": "1903.03171", "submitter": "Scott H. Hawley", "authors": "Scott H. Hawley", "title": "Challenges for an Ontology of Artificial Intelligence", "comments": "20 pages, accepted for publication in Journal of the American\n  Scientific Affiliation. In press, expected publication March 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Of primary importance in formulating a response to the increasing prevalence\nand power of artificial intelligence (AI) applications in society are questions\nof ontology. Questions such as: What \"are\" these systems? How are they to be\nregarded? How does an algorithm come to be regarded as an agent? We discuss\nthree factors which hinder discussion and obscure attempts to form a clear\nontology of AI: (1) the various and evolving definitions of AI, (2) the\ntendency for pre-existing technologies to be assimilated and regarded as\n\"normal,\" and (3) the tendency of human beings to anthropomorphize. This list\nis not intended as exhaustive, nor is it seen to preclude entirely a clear\nontology, however, these challenges are a necessary set of topics for\nconsideration. Each of these factors is seen to present a 'moving target' for\ndiscussion, which poses a challenge for both technical specialists and\nnon-practitioners of AI systems development (e.g., philosophers and\ntheologians) to speak meaningfully given that the corpus of AI structures and\ncapabilities evolves at a rapid pace. Finally, we present avenues for moving\nforward, including opportunities for collaborative synthesis for scholars in\nphilosophy and science.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 19:30:56 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Hawley", "Scott H.", ""]]}, {"id": "1903.03176", "submitter": "Kenneth Young", "authors": "Kenny Young and Tian Tian", "title": "MinAtar: An Atari-Inspired Testbed for Thorough and Reproducible\n  Reinforcement Learning Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Arcade Learning Environment (ALE) is a popular platform for evaluating\nreinforcement learning agents. Much of the appeal comes from the fact that\nAtari games demonstrate aspects of competency we expect from an intelligent\nagent and are not biased toward any particular solution approach. The challenge\nof the ALE includes (1) the representation learning problem of extracting\npertinent information from raw pixels, and (2) the behavioural learning problem\nof leveraging complex, delayed associations between actions and rewards. Often,\nthe research questions we are interested in pertain more to the latter, but the\nrepresentation learning problem adds significant computational expense. We\nintroduce MinAtar, short for miniature Atari, a new set of environments that\ncapture the general mechanics of specific Atari games while simplifying the\nrepresentational complexity to focus more on the behavioural challenges.\nMinAtar consists of analogues of five Atari games: Seaquest, Breakout, Asterix,\nFreeway and Space Invaders. Each MinAtar environment provides the agent with a\n10x10xn binary state representation. Each game plays out on a 10x10 grid with n\nchannels corresponding to game-specific objects, such as ball, paddle and brick\nin the game Breakout. To investigate the behavioural challenges posed by\nMinAtar, we evaluated a smaller version of the DQN architecture as well as\nonline actor-critic with eligibility traces. With the representation learning\nproblem simplified, we can perform experiments with significantly less\ncomputational expense. In our experiments, we use the saved compute time to\nperform step-size parameter sweeps and more runs than is typical for the ALE.\nExperiments like this improve reproducibility, and allow us to draw more\nconfident conclusions. We hope that MinAtar can allow researchers to thoroughly\ninvestigate behavioural challenges similar to those inherent in the ALE.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 20:34:36 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 00:36:50 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Young", "Kenny", ""], ["Tian", "Tian", ""]]}, {"id": "1903.03182", "submitter": "Josef Urban", "authors": "Karel Chvalovsk\\'y and Jan Jakub\\r{u}v and Martin Suda and Josef Urban", "title": "ENIGMA-NG: Efficient Neural and Gradient-Boosted Inference Guidance for\n  E", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an efficient implementation of clause guidance in\nsaturation-based automated theorem provers extending the ENIGMA approach.\nUnlike in the first ENIGMA implementation where fast linear classifier is\ntrained and used together with manually engineered features, we have started to\nexperiment with more sophisticated state-of-the-art machine learning methods\nsuch as gradient boosted trees and recursive neural networks. In particular the\nlatter approach poses challenges in terms of efficiency of clause evaluation,\nhowever, we show that deep integration of the neural evaluation with the ATP\ndata-structures can largely amortize this cost and lead to competitive\nreal-time results. Both methods are evaluated on a large dataset of theorem\nproving problems and compared with the previous approaches. The resulting\nmethods improve on the manually designed clause guidance, providing the first\npractically convincing application of gradient-boosted and neural clause\nguidance in saturation-style automated theorem provers.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 20:54:12 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Chvalovsk\u00fd", "Karel", ""], ["Jakub\u016fv", "Jan", ""], ["Suda", "Martin", ""], ["Urban", "Josef", ""]]}, {"id": "1903.03187", "submitter": "Xuesu Xiao", "authors": "Xuesu Xiao, Jan Dufek, Robin Murphy", "title": "Explicit-risk-aware Path Planning with Reward Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a path planner that minimizes risk (e.g. motion\nexecution) while maximizing accumulated reward (e.g., quality of sensor\nviewpoint) motivated by visual assistance or tracking scenarios in unstructured\nor confined environments. In these scenarios, the robot should maintain the\nbest viewpoint as it moves to the goal. However, in unstructured or confined\nenvironments, some paths may increase the risk of collision; therefore there is\na tradeoff between risk and reward. Conventional state-dependent risk or\nprobabilistic uncertainty modeling do not consider path-level risk or is\ndifficult to acquire. This risk-reward planner explicitly represents risk as a\nfunction of motion plans, i.e., paths. Without manual assignment of the\nnegative impact to the planner caused by risk, this planner takes in a\npre-established viewpoint quality map and plans target location and path\nleading to it simultaneously, in order to maximize overall reward along the\nentire path while minimizing risk. Exact and approximate algorithms are\npresented, whose solution is further demonstrated on a physical tethered aerial\nvehicle. Other than the visual assistance problem, the proposed framework also\nprovides a new planning paradigm to address minimum-risk planning under\ndynamical risk and absence of substructure optimality and to balance the\ntrade-off between reward and risk.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 21:22:04 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Xiao", "Xuesu", ""], ["Dufek", "Jan", ""], ["Murphy", "Robin", ""]]}, {"id": "1903.03205", "submitter": "Guangming Lang", "authors": "Guangming Lang", "title": "Three-Way Decisions-Based Conflict Analysis Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Three-way decision theory, which trisects the universe with less risks or\ncosts, is considered as a powerful mathematical tool for handling uncertainty\nin incomplete and imprecise information tables, and provides an effective tool\nfor conflict analysis decision making in real-time situations. In this paper,\nwe propose the concepts of the agreement, disagreement and neutral subsets of a\nstrategy with two evaluation functions, which establish the three-way\ndecisions-based conflict analysis models(TWDCAMs) for trisecting the universe\nof agents, and employ a pair of two-way decisions models to interpret the\nmechanism of the three-way decision rules for an agent. Subsequently, we\ndevelop the concepts of the agreement, disagreement and neutral strategies of\nan agent group with two evaluation functions, which build the TWDCAMs for\ntrisecting the universe of issues, and take a couple of two-way decisions\nmodels to explain the mechanism of the three-way decision rules for an issue.\nFinally, we reconstruct Fan, Qi and Wei's conflict analysis models(FQWCAMs) and\nSun, Ma and Zhao's conflict analysis models(SMZCAMs) with two evaluation\nfunctions, and interpret FQWCAMs and SMZCAMs with a pair of two-day decisions\nmodels, which illustrates that FQWCAMs and SMZCAMs are special cases of\nTWDCAMs.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 22:17:14 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Lang", "Guangming", ""]]}, {"id": "1903.03216", "submitter": "Dong-Ki Kim", "authors": "Dong-Ki Kim, Miao Liu, Shayegan Omidshafiei, Sebastian Lopez-Cot,\n  Matthew Riemer, Golnaz Habibi, Gerald Tesauro, Sami Mourad, Murray Campbell,\n  Jonathan P. How", "title": "Learning Hierarchical Teaching Policies for Cooperative Agents", "comments": "Presented at AAMAS 2020; arXiv version added with the appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collective learning can be greatly enhanced when agents effectively exchange\nknowledge with their peers. In particular, recent work studying agents that\nlearn to teach other teammates has demonstrated that action advising\naccelerates team-wide learning. However, the prior work has simplified the\nlearning of advising policies by using simple function approximations and only\nconsidered advising with primitive (low-level) actions, limiting the\nscalability of learning and teaching to complex domains. This paper introduces\na novel learning-to-teach framework, called hierarchical multiagent teaching\n(HMAT), that improves scalability to complex environments by using the deep\nrepresentation for student policies and by advising with more expressive\nextended action sequences over multiple levels of temporal abstraction. Our\nempirical evaluations demonstrate that HMAT improves team-wide learning\nprogress in large, complex domains where previous approaches fail. HMAT also\nlearns teaching policies that can effectively transfer knowledge to different\nteammates with knowledge of different tasks, even when the teammates have\nheterogeneous action spaces.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 23:12:30 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 20:13:48 GMT"}, {"version": "v3", "created": "Mon, 16 Sep 2019 15:08:14 GMT"}, {"version": "v4", "created": "Fri, 29 Nov 2019 05:26:30 GMT"}, {"version": "v5", "created": "Mon, 2 Mar 2020 16:50:32 GMT"}, {"version": "v6", "created": "Mon, 18 May 2020 15:50:48 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Kim", "Dong-Ki", ""], ["Liu", "Miao", ""], ["Omidshafiei", "Shayegan", ""], ["Lopez-Cot", "Sebastian", ""], ["Riemer", "Matthew", ""], ["Habibi", "Golnaz", ""], ["Tesauro", "Gerald", ""], ["Mourad", "Sami", ""], ["Campbell", "Murray", ""], ["How", "Jonathan P.", ""]]}, {"id": "1903.03227", "submitter": "Bohan Wu", "authors": "Bohan Wu, Iretiayo Akinola and Peter K. Allen", "title": "Pixel-Attentive Policy Gradient for Multi-Fingered Grasping in Cluttered\n  Scenes", "comments": "Accepted at IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances in on-policy reinforcement learning (RL) methods enabled\nlearning agents in virtual environments to master complex tasks with\nhigh-dimensional and continuous observation and action spaces. However,\nleveraging this family of algorithms in multi-fingered robotic grasping remains\na challenge due to large sim-to-real fidelity gaps and the high sample\ncomplexity of on-policy RL algorithms. This work aims to bridge these gaps by\nfirst reinforcement-learning a multi-fingered robotic grasping policy in\nsimulation that operates in the pixel space of the input: a single depth image.\nUsing a mapping from pixel space to Cartesian space according to the depth map,\nthis method transfers to the real world with high fidelity and introduces a\nnovel attention mechanism that substantially improves grasp success rate in\ncluttered environments. Finally, the direct-generative nature of this method\nallows learning of multi-fingered grasps that have flexible end-effector\npositions, orientations and rotations, as well as all degrees of freedom of the\nhand.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 00:26:57 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 17:43:56 GMT"}, {"version": "v3", "created": "Tue, 9 Jul 2019 16:52:54 GMT"}, {"version": "v4", "created": "Sat, 21 Sep 2019 18:15:23 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Wu", "Bohan", ""], ["Akinola", "Iretiayo", ""], ["Allen", "Peter K.", ""]]}, {"id": "1903.03234", "submitter": "Srinivasan Sivanandan", "authors": "Vaibhav Saxena, Srinivasan Sivanandan, Pulkit Mathur", "title": "Dyna-AIL : Adversarial Imitation Learning by Planning", "comments": "8 pages, 6 figures, pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial methods for imitation learning have been shown to perform well on\nvarious control tasks. However, they require a large number of environment\ninteractions for convergence. In this paper, we propose an end-to-end\ndifferentiable adversarial imitation learning algorithm in a Dyna-like\nframework for switching between model-based planning and model-free learning\nfrom expert data. Our results on both discrete and continuous environments show\nthat our approach of using model-based planning along with model-free learning\nconverges to an optimal policy with fewer number of environment interactions in\ncomparison to the state-of-the-art learning methods.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 00:54:49 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Saxena", "Vaibhav", ""], ["Sivanandan", "Srinivasan", ""], ["Mathur", "Pulkit", ""]]}, {"id": "1903.03252", "submitter": "Alex Kearney", "authors": "Alex Kearney, Vivek Veeriah, Jaden Travnik, Patrick M. Pilarski,\n  Richard S. Sutton", "title": "Learning Feature Relevance Through Step Size Adaptation in\n  Temporal-Difference Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a long history of using meta learning as representation learning,\nspecifically for determining the relevance of inputs. In this paper, we examine\nan instance of meta-learning in which feature relevance is learned by adapting\nstep size parameters of stochastic gradient descent---building on a variety of\nprior work in stochastic approximation, machine learning, and artificial neural\nnetworks. In particular, we focus on stochastic meta-descent introduced in the\nIncremental Delta-Bar-Delta (IDBD) algorithm for setting individual step sizes\nfor each feature of a linear function approximator. Using IDBD, a feature with\nlarge or small step sizes will have a large or small impact on generalization\nfrom training examples. As a main contribution of this work, we extend IDBD to\ntemporal-difference (TD) learning---a form of learning which is effective in\nsequential, non i.i.d. problems. We derive a variety of IDBD generalizations\nfor TD learning, demonstrating that they are able to distinguish which features\nare relevant and which are not. We demonstrate that TD IDBD is effective at\nlearning feature relevance in both an idealized gridworld and a real-world\nrobotic prediction task.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 02:29:22 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Kearney", "Alex", ""], ["Veeriah", "Vivek", ""], ["Travnik", "Jaden", ""], ["Pilarski", "Patrick M.", ""], ["Sutton", "Richard S.", ""]]}, {"id": "1903.03258", "submitter": "Daniel Molina", "authors": "Daniel Molina, Kislay Kumar, Siddharth Srivastava", "title": "Learn and Link: Learning Critical Regions for Efficient Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new approach to learning for motion planning (MP) where\ncritical regions of an environment are learned from a given set of motion plans\nand used to improve performance on new environments and problem instances. We\nintroduce a new suite of sampling-based motion planners, Learn and Link. Our\nplanners leverage critical regions to overcome the limitations of uniform\nsampling, while still maintaining guarantees of correctness inherent to\nsampling-based algorithms. We also show that convolutional neural networks\n(CNNs) can be used to identify critical regions for motion planning problems.\nWe evaluate Learn and Link against planners from the Open Motion Planning\nLibrary (OMPL) using an extensive suite of experiments on challenging motion\nplanning problems. We show that our approach requires far less planning time\nthan existing sampling-based planners.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 03:00:48 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 22:35:09 GMT"}, {"version": "v3", "created": "Fri, 24 Jan 2020 00:46:51 GMT"}, {"version": "v4", "created": "Sat, 7 Mar 2020 19:44:57 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Molina", "Daniel", ""], ["Kumar", "Kislay", ""], ["Srivastava", "Siddharth", ""]]}, {"id": "1903.03282", "submitter": "Tianwen Jiang", "authors": "Tianwen Jiang, Ming Liu, Bing Qin, Ting Liu", "title": "Attribute Acquisition in Ontology based on Representation Learning of\n  Hierarchical Classes and Attributes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribute acquisition for classes is a key step in ontology construction,\nwhich is often achieved by community members manually. This paper investigates\nan attention-based automatic paradigm called TransATT for attribute\nacquisition, by learning the representation of hierarchical classes and\nattributes in Chinese ontology. The attributes of an entity can be acquired by\nmerely inspecting its classes, because the entity can be regard as the instance\nof its classes and inherit their attributes. For explicitly describing of the\nclass of an entity unambiguously, we propose class-path to represent the\nhierarchical classes in ontology, instead of the terminal class word of the\nhypernym-hyponym relation (i.e., is-a relation) based hierarchy. The high\nperformance of TransATT on attribute acquisition indicates the promising\nability of the learned representation of class-paths and attributes. Moreover,\nwe construct a dataset named \\textbf{BigCilin11k}. To the best of our\nknowledge, this is the first Chinese dataset with abundant hierarchical classes\nand entities with attributes.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 04:44:59 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Jiang", "Tianwen", ""], ["Liu", "Ming", ""], ["Qin", "Bing", ""], ["Liu", "Ting", ""]]}, {"id": "1903.03289", "submitter": "Tianwen Jiang", "authors": "Tianwen Jiang, Sendong Zhao, Jing Liu, Jin-Ge Yao, Ming Liu, Bing Qin,\n  Ting Liu, Chin-Yew Lin", "title": "Towards Time-Aware Distant Supervision for Relation Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distant supervision for relation extraction heavily suffers from the wrong\nlabeling problem. To alleviate this issue in news data with the timestamp, we\ntake a new factor time into consideration and propose a novel time-aware\ndistant supervision framework (Time-DS). Time-DS is composed of a time series\ninstance-popularity and two strategies. Instance-popularity is to encode the\nstrong relevance of time and true relation mention. Therefore,\ninstance-popularity would be an effective clue to reduce the noises generated\nthrough distant supervision labeling. The two strategies, i.e., hard filter and\ncurriculum learning are both ways to implement instance-popularity for better\nrelation extraction in the manner of Time-DS. The curriculum learning is a more\nsophisticated and flexible way to exploit instance-popularity to eliminate the\nbad effects of noises, thus get better relation extraction performance.\nExperiments on our collected multi-source news corpus show that Time-DS\nachieves significant improvements for relation extraction.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 05:10:00 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Jiang", "Tianwen", ""], ["Zhao", "Sendong", ""], ["Liu", "Jing", ""], ["Yao", "Jin-Ge", ""], ["Liu", "Ming", ""], ["Qin", "Bing", ""], ["Liu", "Ting", ""], ["Lin", "Chin-Yew", ""]]}, {"id": "1903.03294", "submitter": "Sanjiang Li", "authors": "Sanjiang Li and Xueqing Yan", "title": "Let's Play Mahjong!", "comments": "20 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mahjong is a very popular tile-based game commonly played by four players.\nEach player begins with a hand of 13 tiles and, in turn, players draw and\ndiscard (i.e., change) tiles until they complete a legal hand using a 14th\ntile. In this paper, we initiate a mathematical and AI study of the Mahjong\ngame and try to answer two fundamental questions: how bad is a hand of 14\ntiles? and which tile should I discard? We define and characterise the notion\nof deficiency and present an optimal policy to discard a tile in order to\nincrease the chance of completing a legal hand within $k$ tile changes for each\n$k\\geq 1$.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 05:43:21 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Li", "Sanjiang", ""], ["Yan", "Xueqing", ""]]}, {"id": "1903.03332", "submitter": "Sourav Medya", "authors": "Sahil Manchanda and Akash Mittal and Anuj Dhawan and Sourav Medya and\n  Sayan Ranu and Ambuj Singh", "title": "Learning Heuristics over Large Graphs via Deep Reinforcement Learning", "comments": "To appear in NeurIPS 2020\n  https://papers.nips.cc/paper/2020/hash/e7532dbeff7ef901f2e70daacb3f452d-Abstract.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been an increased interest in discovering heuristics for\ncombinatorial problems on graphs through machine learning. While existing\ntechniques have primarily focused on obtaining high-quality solutions,\nscalability to billion-sized graphs has not been adequately addressed. In\naddition, the impact of budget-constraint, which is necessary for many\npractical scenarios, remains to be studied. In this paper, we propose a\nframework called GCOMB to bridge these gaps. GCOMB trains a Graph Convolutional\nNetwork (GCN) using a novel probabilistic greedy mechanism to predict the\nquality of a node. To further facilitate the combinatorial nature of the\nproblem, GCOMB utilizes a Q-learning framework, which is made efficient through\nimportance sampling. We perform extensive experiments on real graphs to\nbenchmark the efficiency and efficacy of GCOMB. Our results establish that\nGCOMB is 100 times faster and marginally better in quality than\nstate-of-the-art algorithms for learning combinatorial algorithms.\nAdditionally, a case-study on the practical combinatorial problem of Influence\nMaximization (IM) shows GCOMB is 150 times faster than the specialized IM\nalgorithm IMM with similar quality.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 09:23:08 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 03:31:07 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 08:01:08 GMT"}, {"version": "v4", "created": "Wed, 2 Dec 2020 12:17:04 GMT"}, {"version": "v5", "created": "Thu, 3 Dec 2020 05:51:59 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Manchanda", "Sahil", ""], ["Mittal", "Akash", ""], ["Dhawan", "Anuj", ""], ["Medya", "Sourav", ""], ["Ranu", "Sayan", ""], ["Singh", "Ambuj", ""]]}, {"id": "1903.03408", "submitter": "Marc Maliar", "authors": "Marc Maliar", "title": "How Machine (Deep) Learning Helps Us Understand Human Learning: the\n  Value of Big Ideas", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  I use simulation of two multilayer neural networks to gain intuition into the\ndeterminants of human learning. The first network, the teacher, is trained to\nachieve a high accuracy in handwritten digit recognition. The second network,\nthe student, learns to reproduce the output of the first network. I show that\nlearning from the teacher is more effective than learning from the data under\nthe appropriate degree of regularization. Regularization allows the teacher to\ndistinguish the trends and to deliver \"big ideas\" to the student. I also model\nother learning situations such as expert and novice teachers, high- and\nlow-ability students and biased learning experience due to, e.g., poverty and\ntrauma. The results from computer simulation accord remarkably well with\nfinding of the modern psychological literature. The code is written in MATLAB\nand will be publicly available from the author's web page.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 16:06:42 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 20:55:49 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Maliar", "Marc", ""]]}, {"id": "1903.03411", "submitter": "Thiago Freitas Dos Santos", "authors": "Thiago Freitas dos Santos, Paulo E. Santos, Leonardo A. Ferreira,\n  Reinaldo A. C. Bianchi, Pedro Cabalar", "title": "Heuristics, Answer Set Programming and Markov Decision Process for\n  Solving a Set of Spatial Puzzles", "comments": "Submitted to Journal of Heuristics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial puzzles composed of rigid objects, flexible strings and holes offer\ninteresting domains for reasoning about spatial entities that are common in the\nhuman daily-life's activities. The goal of this work is to investigate the\nautomated solution of this kind of puzzles adapting an algorithm that combines\nAnswer Set Programming (ASP) with Markov Decision Process (MDP), algorithm\noASP(MDP), to use heuristics accelerating the learning process. ASP is applied\nto represent the domain as an MDP, while a Reinforcement Learning algorithm\n(Q-Learning) is used to find the optimal policies. In this work, the heuristics\nwere obtained from the solution of relaxed versions of the puzzles. Experiments\nwere performed on deterministic, non-deterministic and non-stationary versions\nof the puzzles. Results show that the proposed approach can accelerate the\nlearning process, presenting an advantage when compared to the non-heuristic\nversions of oASP(MDP) and Q-Learning.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 01:18:29 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Santos", "Thiago Freitas dos", ""], ["Santos", "Paulo E.", ""], ["Ferreira", "Leonardo A.", ""], ["Bianchi", "Reinaldo A. C.", ""], ["Cabalar", "Pedro", ""]]}, {"id": "1903.03414", "submitter": "Bo Zhang", "authors": "Jinyu Yang, Bo Zhang", "title": "Artificial Intelligence in Intelligent Tutoring Robots: A Systematic\n  Review and Design Guidelines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study provides a systematic review of the recent advances in designing\nthe intelligent tutoring robot (ITR), and summarises the status quo of applying\nartificial intelligence (AI) techniques. We first analyse the environment of\nthe ITR and propose a relationship model for describing interactions of ITR\nwith the students, the social milieu and the curriculum. Then, we transform the\nrelationship model into the perception-planning-action model for exploring what\nAI techniques are suitable to be applied in the ITR. This article provides\ninsights on promoting human-robot teaching-learning process and AI-assisted\neducational techniques, illustrating the design guidelines and future research\nperspectives in intelligent tutoring robots.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 07:39:58 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Yang", "Jinyu", ""], ["Zhang", "Bo", ""]]}, {"id": "1903.03418", "submitter": "Marcel Kvassay", "authors": "Marcel Kvassay", "title": "The meta-problem and the transfer of knowledge between theories of\n  consciousness: a software engineer's take", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This contribution examines two radically different explanations of our\nphenomenal intuitions, one reductive and one strongly non-reductive, and\nidentifies two germane ideas that could benefit many other theories of\nconsciousness. Firstly, the ability of sophisticated agent architectures with a\npurely physical implementation to support certain functional forms of qualia or\nproto-qualia appears to entail the possibility of machine consciousness with\nqualia, not only for reductive theories but also for the nonreductive ones that\nregard consciousness as ubiquitous in Nature. Secondly, analysis of\nintrospective psychological material seems to hint that, under the threshold of\nour ordinary waking awareness, there exist further 'submerged' or 'subliminal'\nlayers of consciousness which constitute a hidden foundation and support and\nanother source of our phenomenal intuitions. These 'submerged' layers might\nhelp explain certain puzzling phenomena concerning subliminal perception, such\nas the apparently 'unconscious' multisensory integration and learning of\nsubliminal stimuli.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 19:17:44 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Kvassay", "Marcel", ""]]}, {"id": "1903.03424", "submitter": "Michael Heller", "authors": "Michael Heller", "title": "The Homunculus Brain and Categorical Logic", "comments": "21 pages, one diagram, no figures", "journal-ref": "Philosophical Problems in Science 69, 2020, 253-280", "doi": "10.1007/978-3-030-40245-7_13", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interaction between syntax (formal language) and its semantics (meanings\nof language) is one which has been well studied in categorical logic. The\nresults of this particular study are employed to understand how the brain is\nable to create meanings. To emphasize the toy character of the proposed model,\nwe prefer to speak of the homunculus brain rather than the brain per se. The\nhomunculus brain consists of neurons, each of which is modeled by a category,\nand axons between neurons, which are modeled by functors between the\ncorresponding neuron-categories. Each neuron (category) has its own program\nenabling its working, i.e. a theory of this neuron. In analogy to what is known\nfrom categorical logic, we postulate the existence of a pair of adjoint\nfunctors, called Lang and Syn, from a category, now called BRAIN, of\ncategories, to a category, now called MIND, of theories. Our homunculus is a\nkind of ``mathematical robot'', the neuronal architecture of which is not\nimportant. Its only aim is to provide us with the opportunity to study how such\na simple brain-like structure could ``create meanings'' and perform abstraction\noperations out of its purely syntactic program. The pair of adjoint functors\nLang and Syn model the mutual dependencies between the syntactical structure of\na given theory of MIND and the internal logic of its semantics given by a\ncategory of BRAIN. In this way, a formal language (syntax) and its meanings\n(semantics) are interwoven with each other in a manner corresponding to the\nadjointness of the functors Lang and Syn. Higher cognitive functions of\nabstraction and realization of concepts are also modelled by a corresponding\npair of adjoint functors. The categories BRAIN and MIND interact with each\nother with their entire structures and, at the same time, these very structures\nare shaped by this interaction.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 18:42:00 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 11:33:07 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Heller", "Michael", ""]]}, {"id": "1903.03425", "submitter": "Thilo Hagendorff", "authors": "Thilo Hagendorff", "title": "The Ethics of AI Ethics -- An Evaluation of Guidelines", "comments": "16 pages, 1 table", "journal-ref": "Minds & Machines, 2020", "doi": "10.1007/s11023-020-09517-8", "report-no": null, "categories": "cs.AI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current advances in research, development and application of artificial\nintelligence (AI) systems have yielded a far-reaching discourse on AI ethics.\nIn consequence, a number of ethics guidelines have been released in recent\nyears. These guidelines comprise normative principles and recommendations aimed\nto harness the \"disruptive\" potentials of new AI technologies. Designed as a\ncomprehensive evaluation, this paper analyzes and compares these guidelines\nhighlighting overlaps but also omissions. As a result, I give a detailed\noverview of the field of AI ethics. Finally, I also examine to what extent the\nrespective ethical principles and values are implemented in the practice of\nresearch, development and application of AI systems - and how the effectiveness\nin the demands of AI ethics can be improved.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 15:50:35 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 08:44:31 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Hagendorff", "Thilo", ""]]}, {"id": "1903.03438", "submitter": "Krzysztof Czarnecki", "authors": "Krzysztof Czarnecki and Rick Salay", "title": "Towards a Framework to Manage Perceptual Uncertainty for Safe Automated\n  Driving", "comments": null, "journal-ref": "In: Gallina B., Skavhaug A., Schoitsch E., Bitsch F. (eds)\n  Computer Safety, Reliability, and Security. SAFECOMP 2018. Lecture Notes in\n  Computer Science, vol 11094. Springer, Cham", "doi": "10.1007/978-3-319-99229-7_37", "report-no": null, "categories": "cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Perception is a safety-critical function of autonomous vehicles and machine\nlearning (ML) plays a key role in its implementation. This position paper\nidentifies (1) perceptual uncertainty as a performance measure used to define\nsafety requirements and (2) its influence factors when using supervised ML.\nThis work is a first step towards a framework for measuring and controling the\neffects of these factors and supplying evidence to support claims about\nperceptual uncertainty.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 19:37:26 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Czarnecki", "Krzysztof", ""], ["Salay", "Rick", ""]]}, {"id": "1903.03443", "submitter": "Shrisha Rao", "authors": "Nanda Kishore Sreenivas, Shrisha Rao", "title": "Egocentric Bias and Doubt in Cognitive Agents", "comments": "Full paper in AAMAS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling social interactions based on individual behavior has always been an\narea of interest, but prior literature generally presumes rational behavior.\nThus, such models may miss out on capturing the effects of biases humans are\nsusceptible to. This work presents a method to model egocentric bias, the\nreal-life tendency to emphasize one's own opinion heavily when presented with\nmultiple opinions. We use a symmetric distribution centered at an agent's own\nopinion, as opposed to the Bounded Confidence (BC) model used in prior work. We\nconsider a game of iterated interactions where an agent cooperates based on its\nopinion about an opponent. Our model also includes the concept of domain-based\nself-doubt, which varies as the interaction succeeds or not. An increase in\ndoubt makes an agent reduce its egocentricity in subsequent interactions, thus\nenabling the agent to learn reactively. The agent system is modeled with\nfactions not having a single leader, to overcome some of the issues associated\nwith leader-follower factions. We find that agents belonging to factions\nperform better than individual agents. We observe that an intermediate level of\negocentricity helps the agent perform at its best, which concurs with\nconventional wisdom that neither overconfidence nor low self-esteem brings\nbenefits.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 12:18:01 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Sreenivas", "Nanda Kishore", ""], ["Rao", "Shrisha", ""]]}, {"id": "1903.03445", "submitter": "Enzo Ferrante", "authors": "Nicolas Roulet and Diego Fernandez Slezak and Enzo Ferrante", "title": "Joint Learning of Brain Lesion and Anatomy Segmentation from\n  Heterogeneous Datasets", "comments": "Accepted for publication at MIDL 2019. Open reviews available at:\n  https://openreview.net/forum?id=Syest0rxlN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain lesion and anatomy segmentation in magnetic resonance images are\nfundamental tasks in neuroimaging research and clinical practice. Given enough\ntraining data, convolutional neuronal networks (CNN) proved to outperform all\nexistent techniques in both tasks independently. However, to date, little work\nhas been done regarding simultaneous learning of brain lesion and anatomy\nsegmentation from disjoint datasets.\n  In this work we focus on training a single CNN model to predict brain tissue\nand lesion segmentations using heterogeneous datasets labeled independently,\naccording to only one of these tasks (a common scenario when using publicly\navailable datasets). We show that label contradiction issues can arise in this\ncase, and propose a novel adaptive cross entropy (ACE) loss function that makes\nsuch training possible. We provide quantitative evaluation in two different\nscenarios, benchmarking the proposed method in comparison with a multi-network\napproach. Our experiments suggest that ACE loss enables training of single\nmodels when standard cross entropy and Dice loss functions tend to fail.\nMoreover, we show that it is possible to achieve competitive results when\ncomparing with multiple networks trained for independent tasks.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 13:49:44 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 15:23:14 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Roulet", "Nicolas", ""], ["Slezak", "Diego Fernandez", ""], ["Ferrante", "Enzo", ""]]}, {"id": "1903.03495", "submitter": "Mohamed Akrout", "authors": "Mohamed Akrout, Amir-massoud Farahmand, Tory Jarmain, Latif Abid", "title": "Improving Skin Condition Classification with a Visual Symptom Checker\n  Trained using Reinforcement Learning", "comments": "Accepted for the Conference on Medical Image Computing and Computer\n  Assisted Intervention (MICCAI) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a visual symptom checker that combines a pre-trained Convolutional\nNeural Network (CNN) with a Reinforcement Learning (RL) agent as a Question\nAnswering (QA) model. This method increases the classification confidence and\naccuracy of the visual symptom checker, and decreases the average number of\nquestions asked to narrow down the differential diagnosis. A Deep Q-Network\n(DQN)-based RL agent learns how to ask the patient about the presence of\nsymptoms in order to maximize the probability of correctly identifying the\nunderlying condition. The RL agent uses the visual information provided by CNN\nin addition to the answers to the asked questions to guide the QA system. We\ndemonstrate that the RL-based approach increases the accuracy more than 20%\ncompared to the CNN-only approach, which only uses the visual information to\npredict the condition. Moreover, the increased accuracy is up to 10% compared\nto the approach that uses the visual information provided by CNN along with a\nconventional decision tree-based QA system. We finally show that the RL-based\napproach not only outperforms the decision tree-based approach, but also\nnarrows down the diagnosis faster in terms of the average number of asked\nquestions.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 15:24:31 GMT"}, {"version": "v2", "created": "Sat, 30 Mar 2019 16:09:27 GMT"}, {"version": "v3", "created": "Fri, 26 Jul 2019 22:45:22 GMT"}, {"version": "v4", "created": "Wed, 7 Aug 2019 23:32:01 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Akrout", "Mohamed", ""], ["Farahmand", "Amir-massoud", ""], ["Jarmain", "Tory", ""], ["Abid", "Latif", ""]]}, {"id": "1903.03511", "submitter": "Zhenfeng Cao", "authors": "Zhenfeng Cao", "title": "Realizing Continual Learning through Modeling a Learning System as a\n  Fiber Bundle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A human brain is capable of continual learning by nature; however the current\nmainstream deep neural networks suffer from a phenomenon named catastrophic\nforgetting (i.e., learning a new set of patterns suddenly and completely would\nresult in fully forgetting what has already been learned). In this paper we\npropose a generic learning model, which regards a learning system as a fiber\nbundle. By comparing the learning performance of our model with conventional\nones whose neural networks are multilayer perceptrons through a variety of\nmachine-learning experiments, we found our proposed model not only enjoys a\ndistinguished capability of continual learning but also bears a high\ninformation capacity. In addition, we found in some learning scenarios the\nlearning performance can be further enhanced by making the learning time-aware\nto mimic the episodic memory in human brain. Last but not least, we found that\nthe properties of forgetting in our model correspond well to those of human\nmemory. This work may shed light on how a human brain learns.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 01:14:19 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Cao", "Zhenfeng", ""]]}, {"id": "1903.03512", "submitter": "Hrishikesh Ganu", "authors": "Hrishikesh Ganu, Mithun Ghosh, Shashi Roshan", "title": "AgentBuddy: A Contextual Bandit based Decision Support System for\n  Customer Support Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this short paper, we present early insights from a Decision Support System\nfor Customer Support Agents (CSAs) serving customers of a leading accounting\nsoftware. The system is under development and is designed to provide\nsuggestions to CSAs to make them more productive. A unique aspect of the\nsolution is the use of bandit algorithms to create a tractable\nhuman-in-the-loop system that can learn from CSAs in an online fashion. In\naddition to discussing the ML aspects, we also bring out important insights we\ngleaned from early feedback from CSAs. These insights motivate our future work\nand also might be of wider interest to ML practitioners.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 19:13:04 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Ganu", "Hrishikesh", ""], ["Ghosh", "Mithun", ""], ["Roshan", "Shashi", ""]]}, {"id": "1903.03515", "submitter": "Naveen Sundar Govindarajulu", "authors": "Selmer Bringsjord and Naveen Sundar Govindarajulu", "title": "Learning $\\textit{Ex Nihilo}$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces, philosophically and to a degree formally, the novel\nconcept of learning $\\textit{ex nihilo}$, intended (obviously) to be analogous\nto the concept of creation $\\textit{ex nihilo}$. Learning $\\textit{ex nihilo}$\nis an agent's learning \"from nothing,\" by the suitable employment of schemata\nfor deductive and inductive reasoning. This reasoning must be in\nmachine-verifiable accord with a formal proof/argument theory in a\n$\\textit{cognitive calculus}$ (i.e., roughly, an intensional higher-order\nmulti-operator quantified logic), and this reasoning is applied to percepts\nreceived by the agent, in the context of both some prior knowledge, and some\nprior and current interests. Learning $\\textit{ex nihilo}$ is a challenge to\ncontemporary forms of ML, indeed a severe one, but the challenge is offered in\nthe spirt of seeking to stimulate attempts, on the part of non-logicist ML\nresearchers and engineers, to collaborate with those in possession of\nlearning-$\\textit{ex nihilo}$ frameworks, and eventually attempts to integrate\ndirectly with such frameworks at the implementation level. Such integration\nwill require, among other things, the symbiotic interoperation of\nstate-of-the-art automated reasoners and high-expressivity planners, with\nstatistical/connectionist ML technology.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 05:06:09 GMT"}, {"version": "v2", "created": "Sun, 21 Apr 2019 06:30:47 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Bringsjord", "Selmer", ""], ["Govindarajulu", "Naveen Sundar", ""]]}, {"id": "1903.03536", "submitter": "Martin Wistuba", "authors": "Martin Wistuba, Tejaswini Pedapati", "title": "Inductive Transfer for Neural Architecture Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advent of automated neural network architecture search led to\nseveral methods that outperform state-of-the-art human-designed architectures.\nHowever, these approaches are computationally expensive, in extreme cases\nconsuming GPU years. We propose two novel methods which aim to expedite this\noptimization problem by transferring knowledge acquired from previous tasks to\nnew ones. First, we propose a novel neural architecture selection method which\nemploys this knowledge to identify strong and weak characteristics of neural\narchitectures across datasets. Thus, these characteristics do not need to be\nrediscovered in every search, a strong weakness of current state-of-the-art\nsearches. Second, we propose a method for learning curve extrapolation to\ndetermine if a training process can be terminated early. In contrast to\nexisting work, we propose to learn from learning curves of architectures\ntrained on other datasets to improve the prediction accuracy for novel\ndatasets. On five different image classification benchmarks, we empirically\ndemonstrate that both of our orthogonal contributions independently lead to an\nacceleration, without any significant loss in accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 16:27:32 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Wistuba", "Martin", ""], ["Pedapati", "Tejaswini", ""]]}, {"id": "1903.03557", "submitter": "Mohamed El Yafrani", "authors": "Mohamed El Yafrani", "title": "A study of problems with multiple interdependent components - Part I", "comments": "Ph.D. thesis (Chapters 1 and 2) Contributors: Bela\\\"id Ahiod,\n  Mohammad Reza Bonyadi Update 20190318: definition 5 correction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognising that real-world optimisation problems have multiple\ninterdependent components can be quite easy. However, providing a generic and\nformal model for dependencies between components can be a tricky task. In fact,\na PMIC can be considered simply as a single optimisation problem and the\ndependencies between components could be investigated by studying the\ndecomposability of the problem and the correlations between the sub-problems.\nIn this work, we attempt to define PMICs by reasoning from a reverse\nperspective. Instead of considering a decomposable problem, we model multiple\nproblems (the components) and define how these components could be connected.\nIn this document, we introduce notions related to problems with mutliple\ninterndependent components. We start by introducing realistic examples from\nlogistics and supply chain management to illustrate the composite nature and\ndependencies in these problems. Afterwards, we provide our attempt to formalise\nand classify dependency in multi-component problems.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 19:45:39 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 09:31:03 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Yafrani", "Mohamed El", ""]]}, {"id": "1903.03591", "submitter": "Justin Lin", "authors": "Justin Lin, Roberto Calandra, and Sergey Levine", "title": "Learning to Identify Object Instances by Touch: Tactile Recognition via\n  Multimodal Matching", "comments": "6 pages; accepted to IEEE International Conference on Robotics and\n  Automation 2019 (ICRA 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of the literature on robotic perception focuses on the visual modality.\nVision provides a global observation of a scene, making it broadly useful.\nHowever, in the domain of robotic manipulation, vision alone can sometimes\nprove inadequate: in the presence of occlusions or poor lighting, visual object\nidentification might be difficult. The sense of touch can provide robots with\nan alternative mechanism for recognizing objects. In this paper, we study the\nproblem of touch-based instance recognition. We propose a novel framing of the\nproblem as multi-modal recognition: the goal of our system is to recognize,\ngiven a visual and tactile observation, whether or not these observations\ncorrespond to the same object. To our knowledge, our work is the first to\naddress this type of multi-modal instance recognition problem on such a\nlarge-scale with our analysis spanning 98 different objects. We employ a robot\nequipped with two GelSight touch sensors, one on each finger, and a\nself-supervised, autonomous data collection procedure to collect a dataset of\ntactile observations and images. Our experimental results show that it is\npossible to accurately recognize object instances by touch alone, including\ninstances of novel objects that were never seen during training. Our learned\nmodel outperforms other methods on this complex task, including that of human\nvolunteers.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 18:18:16 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Lin", "Justin", ""], ["Calandra", "Roberto", ""], ["Levine", "Sergey", ""]]}, {"id": "1903.03592", "submitter": "Guillaume Escamocher", "authors": "Guillaume Escamocher, Barry O'Sullivan, Steven David Prestwich", "title": "Generating Difficult SAT Instances by Preventing Triangles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When creating benchmarks for SAT solvers, we need SAT instances that are easy\nto build but hard to solve. A recent development in the search for such methods\nhas led to the Balanced SAT algorithm, which can create k-SAT instances with m\nclauses of high difficulty, for arbitrary k and m. In this paper we introduce\nthe No-Triangle SAT algorithm, a SAT instance generator based on the cluster\ncoefficient graph statistic. We empirically compare the two algorithms by\nfixing the arity and the number of variables, but varying the number of\nclauses. The hardest instances that we find are produced by No-Triangle SAT.\nFurthermore, difficult instances from No-Triangle SAT have a different number\nof clauses than difficult instances from Balanced SAT, potentially allowing a\ncombination of the two methods to find hard SAT instances for a larger array of\nparameters.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 18:21:46 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Escamocher", "Guillaume", ""], ["O'Sullivan", "Barry", ""], ["Prestwich", "Steven David", ""]]}, {"id": "1903.03614", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang", "title": "Gradient Descent based Optimization Algorithms for Deep Learning Models\n  Training", "comments": "arXiv admin note: text overlap with arXiv:1805.07500", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aim at providing an introduction to the gradient descent\nbased optimization algorithms for learning deep neural network models. Deep\nlearning models involving multiple nonlinear projection layers are very\nchallenging to train. Nowadays, most of the deep learning model training still\nrelies on the back propagation algorithm actually. In back propagation, the\nmodel variables will be updated iteratively until convergence with gradient\ndescent based optimization algorithms. Besides the conventional vanilla\ngradient descent algorithm, many gradient descent variants have also been\nproposed in recent years to improve the learning performance, including\nMomentum, Adagrad, Adam, Gadam, etc., which will all be introduced in this\npaper respectively.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 12:59:47 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Zhang", "Jiawei", ""]]}, {"id": "1903.03674", "submitter": "Ruiyang Xu", "authors": "Ruiyang Xu and Karl Lieberherr", "title": "Learning Self-Game-Play Agents for Combinatorial Optimization Problems", "comments": "Accepted as an Extended Abstract in AAMAS'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in reinforcement learning (RL) using self-game-play has shown\nremarkable performance on several board games (e.g., Chess and Go) as well as\nvideo games (e.g., Atari games and Dota2). It is plausible to consider that RL,\nstarting from zero knowledge, might be able to gradually approximate a winning\nstrategy after a certain amount of training. In this paper, we explore neural\nMonte-Carlo-Tree-Search (neural MCTS), an RL algorithm which has been applied\nsuccessfully by DeepMind to play Go and Chess at a super-human level. We try to\nleverage the computational power of neural MCTS to solve a class of\ncombinatorial optimization problems. Following the idea of Hintikka's\nGame-Theoretical Semantics, we propose the Zermelo Gamification (ZG) to\ntransform specific combinatorial optimization problems into Zermelo games whose\nwinning strategies correspond to the solutions of the original optimization\nproblem. The ZG also provides a specially designed neural MCTS. We use a\ncombinatorial planning problem for which the ground-truth policy is efficiently\ncomputable to demonstrate that ZG is promising.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 21:38:33 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 00:40:17 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Xu", "Ruiyang", ""], ["Lieberherr", "Karl", ""]]}, {"id": "1903.03698", "submitter": "Vitchyr H. Pong", "authors": "Vitchyr H. Pong, Murtaza Dalal, Steven Lin, Ashvin Nair, Shikhar Bahl,\n  Sergey Levine", "title": "Skew-Fit: State-Covering Self-Supervised Reinforcement Learning", "comments": "ICML 2020. 8 pages, 8 figures; 9 pages appendix (6 additional\n  figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous agents that must exhibit flexible and broad capabilities will need\nto be equipped with large repertoires of skills. Defining each skill with a\nmanually-designed reward function limits this repertoire and imposes a manual\nengineering burden. Self-supervised agents that set their own goals can\nautomate this process, but designing appropriate goal setting objectives can be\ndifficult, and often involves heuristic design decisions. In this paper, we\npropose a formal exploration objective for goal-reaching policies that\nmaximizes state coverage. We show that this objective is equivalent to\nmaximizing goal reaching performance together with the entropy of the goal\ndistribution, where goals correspond to full state observations. To instantiate\nthis principle, we present an algorithm called Skew-Fit for learning a\nmaximum-entropy goal distributions. We prove that, under regularity conditions,\nSkew-Fit converges to a uniform distribution over the set of valid states, even\nwhen we do not know this set beforehand. Our experiments show that combining\nSkew-Fit for learning goal distributions with existing goal-reaching methods\noutperforms a variety of prior methods on open-sourced visual goal-reaching\ntasks. Moreover, we demonstrate that Skew-Fit enables a real-world robot to\nlearn to open a door, entirely from scratch, from pixels, and without any\nmanually-designed reward function.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 23:32:17 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 15:30:20 GMT"}, {"version": "v3", "created": "Sun, 9 Feb 2020 20:24:12 GMT"}, {"version": "v4", "created": "Tue, 4 Aug 2020 04:07:27 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Pong", "Vitchyr H.", ""], ["Dalal", "Murtaza", ""], ["Lin", "Steven", ""], ["Nair", "Ashvin", ""], ["Bahl", "Shikhar", ""], ["Levine", "Sergey", ""]]}, {"id": "1903.03714", "submitter": "Xiang Ren", "authors": "Weizhi Ma, Min Zhang, Yue Cao, Woojeong, Jin, Chenyang Wang, Yiqun\n  Liu, Shaoping Ma, Xiang Ren", "title": "Jointly Learning Explainable Rules for Recommendation with Knowledge\n  Graph", "comments": "10 pages, plus 1-page references; accepted at The Web Conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainability and effectiveness are two key aspects for building recommender\nsystems. Prior efforts mostly focus on incorporating side information to\nachieve better recommendation performance. However, these methods have some\nweaknesses: (1) prediction of neural network-based embedding methods are hard\nto explain and debug; (2) symbolic, graph-based approaches (e.g., meta\npath-based models) require manual efforts and domain knowledge to define\npatterns and rules, and ignore the item association types (e.g. substitutable\nand complementary). In this paper, we propose a novel joint learning framework\nto integrate \\textit{induction of explainable rules from knowledge graph} with\n\\textit{construction of a rule-guided neural recommendation model}. The\nframework encourages two modules to complement each other in generating\neffective and explainable recommendation: 1) inductive rules, mined from\nitem-centric knowledge graphs, summarize common multi-hop relational patterns\nfor inferring different item associations and provide human-readable\nexplanation for model prediction; 2) recommendation module can be augmented by\ninduced rules and thus have better generalization ability dealing with the\ncold-start issue. Extensive experiments\\footnote{Code and data can be found at:\n\\url{https://github.com/THUIR/RuleRec}} show that our proposed method has\nachieved significant improvements in item recommendation over baselines on\nreal-world datasets. Our model demonstrates robust performance over \"noisy\"\nitem knowledge graphs, generated by linking item names to related entities.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 01:06:04 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Ma", "Weizhi", ""], ["Zhang", "Min", ""], ["Cao", "Yue", ""], ["Woojeong", "", ""], ["Jin", "", ""], ["Wang", "Chenyang", ""], ["Liu", "Yiqun", ""], ["Ma", "Shaoping", ""], ["Ren", "Xiang", ""]]}, {"id": "1903.03772", "submitter": "Pengwei Wang", "authors": "Pengwei Wang, Dejing Dou, Fangzhao Wu, Nisansa de Silva, Lianwen Jin", "title": "Logic Rules Powered Knowledge Graph Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large scale knowledge graph embedding has attracted much attention from both\nacademia and industry in the field of Artificial Intelligence. However, most\nexisting methods concentrate solely on fact triples contained in the given\nknowledge graph. Inspired by the fact that logic rules can provide a flexible\nand declarative language for expressing rich background knowledge, it is\nnatural to integrate logic rules into knowledge graph embedding, to transfer\nhuman knowledge to entity and relation embedding, and strengthen the learning\nprocess. In this paper, we propose a novel logic rule-enhanced method which can\nbe easily integrated with any translation based knowledge graph embedding\nmodel, such as TransE . We first introduce a method to automatically mine the\nlogic rules and corresponding confidences from the triples. And then, to put\nboth triples and mined logic rules within the same semantic space, all triples\nin the knowledge graph are represented as first-order logic. Finally, we define\nseveral operations on the first-order logic and minimize a global loss over\nboth of the mined logic rules and the transformed first-order logics. We\nconduct extensive experiments for link prediction and triple classification on\nthree datasets: WN18, FB166, and FB15K. Experiments show that the rule-enhanced\nmethod can significantly improve the performance of several baselines. The\nhighlight of our model is that the filtered Hits@1, which is a pivotal\nevaluation in the knowledge inference task, has a significant improvement (up\nto 700% improvement).\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 10:01:12 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Wang", "Pengwei", ""], ["Dou", "Dejing", ""], ["Wu", "Fangzhao", ""], ["de Silva", "Nisansa", ""], ["Jin", "Lianwen", ""]]}, {"id": "1903.03804", "submitter": "Dingwu Tan", "authors": "Mingming Lu, Dingwu Tan, Naixue Xiong, Zailiang Chen and Haifeng Li", "title": "Program Classification Using Gated Graph Attention Neural Network for\n  Online Programming Service", "comments": "12 pages, 27 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The online programing services, such as Github,TopCoder, and EduCoder, have\npromoted a lot of social interactions among the service users. However, the\nexisting social interactions is rather limited and inefficient due to the rapid\nincreasing of source-code repositories, which is difficult to explore manually.\nThe emergence of source-code mining provides a promising way to analyze those\nsource codes, so that those source codes can be relatively easy to understand\nand share among those service users. Among all the source-code mining\nattempts,program classification lays a foundation for various tasks related to\nsource-code understanding, because it is impossible for a machine to understand\na computer program if it cannot classify the program correctly. Although\nnumerous machine learning models, such as the Natural Language Processing (NLP)\nbased models and the Abstract Syntax Tree (AST) based models, have been\nproposed to classify computer programs based on their corresponding source\ncodes, the existing works cannot fully characterize the source codes from the\nperspective of both the syntax and semantic information. To address this\nproblem, we proposed a Graph Neural Network (GNN) based model, which integrates\ndata flow and function call information to the AST,and applies an improved GNN\nmodel to the integrated graph, so as to achieve the state-of-art program\nclassification accuracy. The experiment results have shown that the proposed\nwork can classify programs with accuracy over 97%.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 13:47:05 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Lu", "Mingming", ""], ["Tan", "Dingwu", ""], ["Xiong", "Naixue", ""], ["Chen", "Zailiang", ""], ["Li", "Haifeng", ""]]}, {"id": "1903.03825", "submitter": "Vikas Verma", "authors": "Vikas Verma, Kenji Kawaguchi, Alex Lamb, Juho Kannala, Yoshua Bengio,\n  David Lopez-Paz", "title": "Interpolation Consistency Training for Semi-Supervised Learning", "comments": "Extended version of IJCAI 2019 paper. Semi-supervised Learning, Deep\n  Learning, Neural Networks. All the previous results are unchanged; we added\n  new theoretical and empirical results", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Interpolation Consistency Training (ICT), a simple and\ncomputation efficient algorithm for training Deep Neural Networks in the\nsemi-supervised learning paradigm. ICT encourages the prediction at an\ninterpolation of unlabeled points to be consistent with the interpolation of\nthe predictions at those points. In classification problems, ICT moves the\ndecision boundary to low-density regions of the data distribution. Our\nexperiments show that ICT achieves state-of-the-art performance when applied to\nstandard neural network architectures on the CIFAR-10 and SVHN benchmark\ndatasets. Our theoretical analysis shows that ICT corresponds to a certain type\nof data-adaptive regularization with unlabeled points which reduces overfitting\nto labeled points under high confidence values.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 16:39:22 GMT"}, {"version": "v2", "created": "Sat, 11 May 2019 17:46:54 GMT"}, {"version": "v3", "created": "Sun, 19 May 2019 05:00:06 GMT"}, {"version": "v4", "created": "Tue, 29 Dec 2020 15:31:56 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Verma", "Vikas", ""], ["Kawaguchi", "Kenji", ""], ["Lamb", "Alex", ""], ["Kannala", "Juho", ""], ["Bengio", "Yoshua", ""], ["Lopez-Paz", "David", ""]]}, {"id": "1903.03877", "submitter": "Smitha Milli", "authors": "Smitha Milli, Anca D. Dragan", "title": "Literal or Pedagogic Human? Analyzing Human Model Misspecification in\n  Objective Learning", "comments": "Published at UAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is incredibly easy for a system designer to misspecify the objective for\nan autonomous system (\"robot''), thus motivating the desire to have the robot\nlearn the objective from human behavior instead. Recent work has suggested that\npeople have an interest in the robot performing well, and will thus behave\npedagogically, choosing actions that are informative to the robot. In turn,\nrobots benefit from interpreting the behavior by accounting for this pedagogy.\nIn this work, we focus on misspecification: we argue that robots might not know\nwhether people are being pedagogic or literal and that it is important to ask\nwhich assumption is safer to make. We cast objective learning into the more\ngeneral form of a common-payoff game between the robot and human, and prove\nthat in any such game literal interpretation is more robust to\nmisspecification. Experiments with human data support our theoretical results\nand point to the sensitivity of the pedagogic assumption.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 21:58:46 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2019 03:26:48 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Milli", "Smitha", ""], ["Dragan", "Anca D.", ""]]}, {"id": "1903.03893", "submitter": "Bin Wang", "authors": "Bin Wang, Yanan Sun, Bing Xue, Mengjie Zhang", "title": "A Hybrid GA-PSO Method for Evolving Architecture and Short Connections\n  of Deep Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image classification is a difficult machine learning task, where\nConvolutional Neural Networks (CNNs) have been applied for over 20 years in\norder to solve the problem. In recent years, instead of the traditional way of\nonly connecting the current layer with its next layer, shortcut connections\nhave been proposed to connect the current layer with its forward layers apart\nfrom its next layer, which has been proved to be able to facilitate the\ntraining process of deep CNNs. However, there are various ways to build the\nshortcut connections, it is hard to manually design the best shortcut\nconnections when solving a particular problem, especially given the design of\nthe network architecture is already very challenging.\n  In this paper, a hybrid evolutionary computation (EC) method is proposed to\n\\textit{automatically} evolve both the architecture of deep CNNs and the\nshortcut connections. Three major contributions of this work are: Firstly, a\nnew encoding strategy is proposed to encode a CNN, where the architecture and\nthe shortcut connections are encoded separately; Secondly, a hybrid two-level\nEC method, which combines particle swarm optimisation and genetic algorithms,\nis developed to search for the optimal CNNs; Lastly, an adjustable learning\nrate is introduced for the fitness evaluations, which provides a better\nlearning rate for the training process given a fixed number of epochs. The\nproposed algorithm is evaluated on three widely used benchmark datasets of\nimage classification and compared with 12 peer Non-EC based competitors and one\nEC based competitor. The experimental results demonstrate that the proposed\nmethod outperforms all of the peer competitors in terms of classification\naccuracy.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 00:51:19 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Wang", "Bin", ""], ["Sun", "Yanan", ""], ["Xue", "Bing", ""], ["Zhang", "Mengjie", ""]]}, {"id": "1903.03906", "submitter": "Xuhui Fan", "authors": "Xuhui Fan and Bin Li and Scott Anthony Sisson", "title": "Rectangular Bounding Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic partition models divide a multi-dimensional space into a number of\nrectangular regions, such that the data within each region exhibit certain\ntypes of homogeneity. Due to the nature of their partition strategy, existing\npartition models may create many unnecessary divisions in sparse regions when\ntrying to describe data in dense regions. To avoid this problem we introduce a\nnew parsimonious partition model -- the Rectangular Bounding Process (RBP) --\nto efficiently partition multi-dimensional spaces, by employing a bounding\nstrategy to enclose data points within rectangular bounding boxes. Unlike\nexisting approaches, the RBP possesses several attractive theoretical\nproperties that make it a powerful nonparametric partition prior on a\nhypercube. In particular, the RBP is self-consistent and as such can be\ndirectly extended from a finite hypercube to infinite (unbounded) space. We\napply the RBP to regression trees and relational models as a flexible partition\nprior. The experimental results validate the merit of the RBP {in rich yet\nparsimonious expressiveness} compared to the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 02:52:32 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Fan", "Xuhui", ""], ["Li", "Bin", ""], ["Sisson", "Scott Anthony", ""]]}, {"id": "1903.03920", "submitter": "Pooyan Jamshidi", "authors": "Pooyan Jamshidi, Javier C\\'amara, Bradley Schmerl, Christian\n  K\\\"astner, David Garlan", "title": "Machine Learning Meets Quantitative Planning: Enabling Self-Adaptation\n  in Autonomous Robots", "comments": "14th International Symposium on Software Engineering for Adaptive and\n  Self-Managing Systems (SEAMS 2019 )", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern cyber-physical systems (e.g., robotics systems) are typically composed\nof physical and software components, the characteristics of which are likely to\nchange over time. Assumptions about parts of the system made at design time may\nnot hold at run time, especially when a system is deployed for long periods\n(e.g., over decades). Self-adaptation is designed to find reconfigurations of\nsystems to handle such run-time inconsistencies. Planners can be used to find\nand enact optimal reconfigurations in such an evolving context. However, for\nsystems that are highly configurable, such planning becomes intractable due to\nthe size of the adaptation space. To overcome this challenge, in this paper we\nexplore an approach that (a) uses machine learning to find Pareto-optimal\nconfigurations without needing to explore every configuration and (b) restricts\nthe search space to such configurations to make planning tractable. We explore\nthis in the context of robot missions that need to consider task timeliness and\nenergy consumption. An independent evaluation shows that our approach results\nin high-quality adaptation plans in uncertain and adversarial environments.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 04:24:49 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Jamshidi", "Pooyan", ""], ["C\u00e1mara", "Javier", ""], ["Schmerl", "Bradley", ""], ["K\u00e4stner", "Christian", ""], ["Garlan", "David", ""]]}, {"id": "1903.03948", "submitter": "Edward Balaban", "authors": "Edward Balaban, Stephen B. Johnson, Mykel J. Kochenderfer", "title": "Rethinking System Health Management", "comments": "Published in the proceedings of the 2018 AAAI Fall Symposium on\n  Integrating Planning, Diagnosis, and Causal Reasoning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Health management of complex dynamic systems has traditionally evolved\nseparately from automated control, planning, and scheduling (generally referred\nto in the paper as decision making). A goal of Integrated System Health\nManagement has been to enable coordination between system health management and\ndecision making, although successful practical implementations have remained\nlimited. This paper proposes that, rather than being treated as connected, yet\ndistinct entities, system health management and decision making should be\nunified in their formulations. Enabled by advances in modeling and computing,\nwe argue that the unified approach will increase a system's operational\neffectiveness and may also lead to a lower overall system complexity. We\noverview the prevalent system health management methodology and illustrate its\nlimitations through numerical examples. We then describe the proposed\nunification approach and show how it accommodates the typical system health\nmanagement concepts.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 07:59:37 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Balaban", "Edward", ""], ["Johnson", "Stephen B.", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1903.03980", "submitter": "Jesse Hoey", "authors": "Moojan Ghafurian and Neil Budnarain and Jesse Hoey", "title": "Improving Humanness of Virtual Agents and Users' Cooperation through\n  Emotions", "comments": null, "journal-ref": null, "doi": "10.1109/TAFFC.2021.3096831", "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze the performance of an agent developed according to\na well-accepted appraisal theory of human emotion with respect to how it\nmodulates play in the context of a social dilemma. We ask if the agent will be\ncapable of generating interactions that are considered to be more human than\nmachine-like. We conduct an experiment with 117 participants and show how\nparticipants rate our agent on dimensions of human-uniqueness (which separates\nhumans from animals) and human-nature (which separates humans from machines).\nWe show that our appraisal theoretic agent is perceived to be more human-like\nthan baseline models, by significantly improving both human-nature and\nhuman-uniqueness aspects of the intelligent agent. We also show that perception\nof humanness positively affects enjoyment and cooperation in the social\ndilemma.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 12:37:15 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Ghafurian", "Moojan", ""], ["Budnarain", "Neil", ""], ["Hoey", "Jesse", ""]]}, {"id": "1903.03985", "submitter": "Beatrice Alex", "authors": "Philip John Gorinski, Honghan Wu, Claire Grover, Richard Tobin, Conn\n  Talbot, Heather Whalley, Cathie Sudlow, William Whiteley, Beatrice Alex", "title": "Named Entity Recognition for Electronic Health Records: A Comparison of\n  Rule-based and Machine Learning Approaches", "comments": "8 pages, presented at HealTAC 2019, Cardiff, 24-25/04/2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates multiple approaches to Named Entity Recognition (NER)\nfor text in Electronic Health Record (EHR) data. In particular, we look into\nthe application of (i) rule-based, (ii) deep learning and (iii) transfer\nlearning systems for the task of NER on brain imaging reports with a focus on\nrecords from patients with stroke. We explore the strengths and weaknesses of\neach approach, develop rules and train on a common dataset, and evaluate each\nsystem's performance on common test sets of Scottish radiology reports from two\nsources (brain imaging reports in ESS -- Edinburgh Stroke Study data collected\nby NHS Lothian as well as radiology reports created in NHS Tayside). Our\ncomparison shows that a hand-crafted system is the most accurate way to\nautomatically label EHR, but machine learning approaches can provide a feasible\nalternative where resources for a manual system are not readily available.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 13:16:37 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 15:55:53 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Gorinski", "Philip John", ""], ["Wu", "Honghan", ""], ["Grover", "Claire", ""], ["Tobin", "Richard", ""], ["Talbot", "Conn", ""], ["Whalley", "Heather", ""], ["Sudlow", "Cathie", ""], ["Whiteley", "William", ""], ["Alex", "Beatrice", ""]]}, {"id": "1903.03993", "submitter": "Massimiliano de Leoni", "authors": "Massimiliano de Leoni, Safa Dundar", "title": "From Low-Level Events to Activities -- A Session-Based Approach\n  (Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process-Mining techniques aim to use event data about past executions to gain\ninsight into how processes are executed. While these techniques are proven to\nbe very valuable, they are less successful to reach their goal if the process\nis flexible and, hence, events can potentially occur in any order. Furthermore,\ninformation systems can record events at very low level, which do not match the\nhigh-level concepts known at business level. Without abstracting sequences of\nevents to high-level concepts, the results of applying process mining (e.g.,\ndiscovered models) easily become very complex and difficult to interpret, which\nultimately means that they are of little use. A large body of research exists\non event abstraction but typically a large amount of domain knowledge is\nrequired to be fed in, which is often not readily available. Other abstraction\ntechniques are unsupervised, which give lower accuracy. This paper puts forward\na technique that requires limited domain knowledge that can be easily provided.\nTraces are divided in sessions, and each session is abstracted as one single\nhigh-level activity execution. The abstraction is based on a combination of\nautomatic clustering and visualization methods. The technique was assessed on\ntwo case studies that evidently exhibits a large amount of behavior. The\nresults clearly illustrate the benefits of the abstraction to convey knowledge\nto stakeholders.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 14:01:49 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 15:45:24 GMT"}, {"version": "v3", "created": "Mon, 3 Jun 2019 12:39:36 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["de Leoni", "Massimiliano", ""], ["Dundar", "Safa", ""]]}, {"id": "1903.03995", "submitter": "Honghan Wu", "authors": "Honghan Wu, Karen Hodgson, Sue Dyson, Katherine I. Morley, Zina M.\n  Ibrahim, Ehtesham Iqbal, Robert Stewart, Richard JB Dobson, Cathie Sudlow", "title": "Efficiently Reusing Natural Language Processing Models for\n  Phenotype-Mention Identification in Free-text Electronic Medical Records:\n  Methodology Study", "comments": null, "journal-ref": null, "doi": "10.2196/14782", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Many efforts have been put into the use of automated approaches,\nsuch as natural language processing (NLP), to mine or extract data from\nfree-text medical records to construct comprehensive patient profiles for\ndelivering better health-care. Reusing NLP models in new settings, however,\nremains cumbersome - requiring validation and/or retraining on new data\niteratively to achieve convergent results.\n  Objective: The aim of this work is to minimize the effort involved in reusing\nNLP models on free-text medical records.\n  Methods: We formally define and analyse the model adaptation problem in\nphenotype-mention identification tasks. We identify \"duplicate waste\" and\n\"imbalance waste\", which collectively impede efficient model reuse. We propose\na phenotype embedding based approach to minimize these sources of waste without\nthe need for labelled data from new settings.\n  Results: We conduct experiments on data from a large mental health registry\nto reuse NLP models in four phenotype-mention identification tasks. The\nproposed approach can choose the best model for a new task, identifying up to\n76% (duplicate waste), i.e. phenotype mentions without the need for validation\nand model retraining, and with very good performance (93-97% accuracy). It can\nalso provide guidance for validating and retraining the selected model for\nnovel language patterns in new tasks, saving around 80% (imbalance waste), i.e.\nthe effort required in \"blind\" model-adaptation approaches.\n  Conclusions: Adapting pre-trained NLP models for new tasks can be more\nefficient and effective if the language pattern landscapes of old settings and\nnew settings can be made explicit and comparable. Our experiments show that the\nphenotype-mention embedding approach is an effective way to model language\npatterns for phenotype-mention identification tasks and that its use can guide\nefficient NLP model reuse.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 14:05:08 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 14:26:51 GMT"}, {"version": "v3", "created": "Wed, 23 Oct 2019 21:32:15 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Wu", "Honghan", ""], ["Hodgson", "Karen", ""], ["Dyson", "Sue", ""], ["Morley", "Katherine I.", ""], ["Ibrahim", "Zina M.", ""], ["Iqbal", "Ehtesham", ""], ["Stewart", "Robert", ""], ["Dobson", "Richard JB", ""], ["Sudlow", "Cathie", ""]]}, {"id": "1903.04039", "submitter": "Florent Capelli", "authors": "Florent Capelli", "title": "Knowledge compilation languages as proof systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study proof systems in the sense of Cook-Reckhow for\nproblems that are higher in the polynomial hierarchy than coNP, in particular,\n#SAT and maxSAT. We start by explaining how the notion of Cook-Reckhow proof\nsystems can be apply to these problems and show how one can twist existing\nlanguages in knowledge compilation such as decision DNNF so that they can be\nseen as proof systems for problems such as #SAT and maxSAT.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 18:33:35 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Capelli", "Florent", ""]]}, {"id": "1903.04051", "submitter": "Hongkai Wen", "authors": "Man Luo, Hongkai Wen, Yi Luo, Bowen Du, Konstantin Klemmer, Hongming\n  Zhu", "title": "Demand Prediction for Electric Vehicle Sharing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electric Vehicle (EV) sharing systems have recently experienced unprecedented\ngrowth across the globe. Many car sharing service providers as well as\nautomobile manufacturers are entering this competition by expanding both their\nEV fleets and renting/returning station networks, aiming to seize a share of\nthe market and bring car sharing to the zero emissions level. During their fast\nexpansion, one fundamental determinant for success is the capability of\ndynamically predicting the demand of stations. In this paper we propose a novel\ndemand prediction approach, which is able to model the dynamics of the system\nand predict demand accordingly. We use a local temporal encoding process to\nhandle the available historical data at individual stations, and a spatial\nencoding process to take correlations between stations into account with graph\nconvolutional neural networks. The encoded features are fed to a prediction\nnetwork, which forecasts both the long-term expected demand of the stations. We\nevaluate the proposed approach on real-world data collected from a major EV\nsharing platform. Experimental results demonstrate that our approach\nsignificantly outperforms the state of the art.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 20:03:43 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 17:05:50 GMT"}, {"version": "v3", "created": "Fri, 10 May 2019 21:12:19 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Luo", "Man", ""], ["Wen", "Hongkai", ""], ["Luo", "Yi", ""], ["Du", "Bowen", ""], ["Klemmer", "Konstantin", ""], ["Zhu", "Hongming", ""]]}, {"id": "1903.04084", "submitter": "Yang Zheng", "authors": "Yang Zheng, Izzat H. Izzat, John H.L. Hansen", "title": "Exploring OpenStreetMap Availability for Driving Environment\n  Understanding", "comments": "12 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the great achievement of artificial intelligence, vehicle technologies\nhave advanced significantly from human centric driving towards fully automated\ndriving. An intelligent vehicle should be able to understand the driver's\nperception of the environment as well as controlling behavior of the vehicle.\nSince high digital map information has been available to provide rich\nenvironmental context about static roads, buildings and traffic\ninfrastructures, it would be worthwhile to explore map data capability for\ndriving task understanding. Alternative to commercial used maps, the\nOpenStreetMap (OSM) data is a free open dataset, which makes it unique for the\nexploration research. This study is focused on two tasks that leverage OSM for\ndriving environment understanding. First, driving scenario attributes are\nretrieved from OSM elements, which are combined with vehicle dynamic signals\nfor the driving event recognition. Utilizing steering angle changes and based\non a Bi-directional Recurrent Neural Network (Bi-RNN), a driving sequence is\nsegmented and classified as lane-keeping, lane-change-left, lane-change-right,\nturn-left, and turn-right events. Second, for autonomous driving perception,\nOSM data can be used to render virtual street views, represented as prior\nknowledge to fuse with vision/laser systems for road semantic segmentation.\nFive different types of road masks are generated from OSM, images, and Lidar\npoints, and fused to characterize the drivable space at the driver's\nperspective. An alternative data-driven approach is based on a Fully\nConvolutional Network (FCN), OSM availability for deep learning methods are\ndiscussed to reveal potential usage on compensating street view images and\nautomatic road semantic annotation.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 00:43:13 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Zheng", "Yang", ""], ["Izzat", "Izzat H.", ""], ["Hansen", "John H. L.", ""]]}, {"id": "1903.04101", "submitter": "Chun Kai Ling", "authors": "Chun Kai Ling, Fei Fang, J. Zico Kolter", "title": "Large Scale Learning of Agent Rationality in Two-Player Zero-Sum Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent advances in solving large, zero-sum extensive form games,\nthere is a growing interest in the inverse problem of inferring underlying game\nparameters given only access to agent actions. Although a recent work provides\na powerful differentiable end-to-end learning frameworks which embed a game\nsolver within a deep-learning framework, allowing unknown game parameters to be\nlearned via backpropagation, this framework faces significant limitations when\napplied to boundedly rational human agents and large scale problems, leading to\npoor practicality. In this paper, we address these limitations and propose a\nframework that is applicable for more practical settings. First, seeking to\nlearn the rationality of human agents in complex two-player zero-sum games, we\ndraw upon well-known ideas in decision theory to obtain a concise and\ninterpretable agent behavior model, and derive solvers and gradients for\nend-to-end learning. Second, to scale up to large, real-world scenarios, we\npropose an efficient first-order primal-dual method which exploits the\nstructure of extensive-form games, yielding significantly faster computation\nfor both game solving and gradient computation. When tested on randomly\ngenerated games, we report speedups of orders of magnitude over previous\napproaches. We also demonstrate the effectiveness of our model on both\nreal-world one-player settings and synthetic data.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 02:15:02 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Ling", "Chun Kai", ""], ["Fang", "Fei", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1903.04102", "submitter": "Meir Friedenberg", "authors": "Meir Friedenberg, Joseph Y. Halpern", "title": "Blameworthiness in Multi-Agent Settings", "comments": "Appears in AAAI-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a formal definition of blameworthiness in settings where multiple\nagents can collaborate to avoid a negative outcome. We first provide a method\nfor ascribing blameworthiness to groups relative to an epistemic state (a\ndistribution over causal models that describe how the outcome might arise). We\nthen show how we can go from an ascription of blameworthiness for groups to an\nascription of blameworthiness for individuals using a standard notion from\ncooperative game theory, the Shapley value. We believe that getting a good\nnotion of blameworthiness in a group setting will be critical for designing\nautonomous agents that behave in a moral manner.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 02:26:30 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Friedenberg", "Meir", ""], ["Halpern", "Joseph Y.", ""]]}, {"id": "1903.04110", "submitter": "Xiaoxiao Guo", "authors": "Xiaoxiao Guo, Shiyu Chang, Mo Yu, Gerald Tesauro, Murray Campbell", "title": "Hybrid Reinforcement Learning with Expert State Sequences", "comments": "AAAI 2019; https://github.com/XiaoxiaoGuo/tensor4rl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing imitation learning approaches often require that the complete\ndemonstration data, including sequences of actions and states, are available.\nIn this paper, we consider a more realistic and difficult scenario where a\nreinforcement learning agent only has access to the state sequences of an\nexpert, while the expert actions are unobserved. We propose a novel\ntensor-based model to infer the unobserved actions of the expert state\nsequences. The policy of the agent is then optimized via a hybrid objective\ncombining reinforcement learning and imitation learning. We evaluated our\nhybrid approach on an illustrative domain and Atari games. The empirical\nresults show that (1) the agents are able to leverage state expert sequences to\nlearn faster than pure reinforcement learning baselines, (2) our tensor-based\naction inference model is advantageous compared to standard deep neural\nnetworks in inferring expert actions, and (3) the hybrid policy optimization\nobjective is robust against noise in expert state sequences.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 03:28:13 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Guo", "Xiaoxiao", ""], ["Chang", "Shiyu", ""], ["Yu", "Mo", ""], ["Tesauro", "Gerald", ""], ["Campbell", "Murray", ""]]}, {"id": "1903.04120", "submitter": "Pravendra Singh", "authors": "Pravendra Singh, Vinay Kumar Verma, Piyush Rai, Vinay P. Namboodiri", "title": "HetConv: Heterogeneous Kernel-Based Convolutions for Deep CNNs", "comments": "Accepted in CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel deep learning architecture in which the convolution\noperation leverages heterogeneous kernels. The proposed HetConv (Heterogeneous\nKernel-Based Convolution) reduces the computation (FLOPs) and the number of\nparameters as compared to standard convolution operation while still\nmaintaining representational efficiency. To show the effectiveness of our\nproposed convolution, we present extensive experimental results on the standard\nconvolutional neural network (CNN) architectures such as VGG \\cite{vgg2014very}\nand ResNet \\cite{resnet}. We find that after replacing the standard\nconvolutional filters in these architectures with our proposed HetConv filters,\nwe achieve 3X to 8X FLOPs based improvement in speed while still maintaining\n(and sometimes improving) the accuracy. We also compare our proposed\nconvolutions with group/depth wise convolutions and show that it achieves more\nFLOPs reduction with significantly higher accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 04:20:38 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 09:52:55 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Singh", "Pravendra", ""], ["Verma", "Vinay Kumar", ""], ["Rai", "Piyush", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "1903.04128", "submitter": "Stephen Tian", "authors": "Stephen Tian, Frederik Ebert, Dinesh Jayaraman, Mayur Mudigonda,\n  Chelsea Finn, Roberto Calandra, Sergey Levine", "title": "Manipulation by Feel: Touch-Based Control with Deep Predictive Models", "comments": "Accepted to ICRA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Touch sensing is widely acknowledged to be important for dexterous robotic\nmanipulation, but exploiting tactile sensing for continuous, non-prehensile\nmanipulation is challenging. General purpose control techniques that are able\nto effectively leverage tactile sensing as well as accurate physics models of\ncontacts and forces remain largely elusive, and it is unclear how to even\nspecify a desired behavior in terms of tactile percepts. In this paper, we take\na step towards addressing these issues by combining high-resolution tactile\nsensing with data-driven modeling using deep neural network dynamics models. We\npropose deep tactile MPC, a framework for learning to perform tactile servoing\nfrom raw tactile sensor inputs, without manual supervision. We show that this\nmethod enables a robot equipped with a GelSight-style tactile sensor to\nmanipulate a ball, analog stick, and 20-sided die, learning from unsupervised\nautonomous interaction and then using the learned tactile predictive model to\nreposition each object to user-specified configurations, indicated by a goal\ntactile reading. Videos, visualizations and the code are available here:\nhttps://sites.google.com/view/deeptactilempc\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 05:14:34 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Tian", "Stephen", ""], ["Ebert", "Frederik", ""], ["Jayaraman", "Dinesh", ""], ["Mudigonda", "Mayur", ""], ["Finn", "Chelsea", ""], ["Calandra", "Roberto", ""], ["Levine", "Sergey", ""]]}, {"id": "1903.04181", "submitter": "Fabien Gandon", "authors": "Fabien Gandon (Laboratoire I3S - SPARKS, WIMMICS, CRISAM), Franck\n  Michel (WIMMICS), Olivier Corby (WIMMICS), Michel Buffa (WIMMICS), Andrea\n  Tettamanzi (WIMMICS), Catherine Faron Zucker (WIMMICS), Elena Cabrio\n  (WIMMICS), Serena Villata (WIMMICS)", "title": "Graph Data on the Web: extend the pivot, don't reinvent the wheel", "comments": "W3C Workshop on Web Standardization for Graph Data - Creating\n  Bridges: RDF, Property Graph and SQL, Mar 2019, Berlin, France. 2019,\n  https://www.w3.org/Data/events/data-ws-2019/index.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is a collective position paper from the Wimmics research team,\nexpressing our vision of how Web graph data technologies should evolve in the\nfuture in order to ensure a high-level of interoperability between the many\ntypes of applications that produce and consume graph data. Wimmics stands for\nWeb-Instrumented Man-Machine Interactions, Communities, and Semantics. We are a\njoint research team between INRIA Sophia Antipolis-M{\\'e}diterran{\\'e}e and I3S\n(CNRS and Universit{\\'e} C{\\^o}te d'Azur). Our challenge is to bridge formal\nsemantics and social semantics on the web. Our research areas are\ngraph-oriented knowledge representation, reasoning and operationalization to\nmodel and support actors, actions and interactions in web-based epistemic\ncommunities. The application of our research is supporting and fostering\ninteractions in online communities and management of their resources. In this\nposition paper, we emphasize the need to extend the semantic Web standard stack\nto address and fulfill new graph data needs, as well as the importance of\nremaining compatible with existing recommendations, in particular the RDF\nstack, to avoid the painful duplication of models, languages, frameworks, etc.\nThe following sections group motivations for different directions of work and\ncollect reasons for the creation of a working group on RDF 2.0 and other\nrecommendations of the RDF family.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 09:09:06 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Gandon", "Fabien", "", "Laboratoire I3S - SPARKS, WIMMICS, CRISAM"], ["Michel", "Franck", "", "WIMMICS"], ["Corby", "Olivier", "", "WIMMICS"], ["Buffa", "Michel", "", "WIMMICS"], ["Tettamanzi", "Andrea", "", "WIMMICS"], ["Zucker", "Catherine Faron", "", "WIMMICS"], ["Cabrio", "Elena", "", "WIMMICS"], ["Villata", "Serena", "", "WIMMICS"]]}, {"id": "1903.04193", "submitter": "Denis Steckelmacher", "authors": "Denis Steckelmacher, H\\'el\\`ene Plisnier, Diederik M. Roijers, Ann\n  Now\\'e", "title": "Sample-Efficient Model-Free Reinforcement Learning with Off-Policy\n  Critics", "comments": "Accepted at the European Conference on Machine Learning 2019 (ECML)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value-based reinforcement-learning algorithms provide state-of-the-art\nresults in model-free discrete-action settings, and tend to outperform\nactor-critic algorithms. We argue that actor-critic algorithms are limited by\ntheir need for an on-policy critic. We propose Bootstrapped Dual Policy\nIteration (BDPI), a novel model-free reinforcement-learning algorithm for\ncontinuous states and discrete actions, with an actor and several off-policy\ncritics. Off-policy critics are compatible with experience replay, ensuring\nhigh sample-efficiency, without the need for off-policy corrections. The actor,\nby slowly imitating the average greedy policy of the critics, leads to\nhigh-quality and state-specific exploration, which we compare to Thompson\nsampling. Because the actor and critics are fully decoupled, BDPI is remarkably\nstable, and unusually robust to its hyper-parameters. BDPI is significantly\nmore sample-efficient than Bootstrapped DQN, PPO, and ACKTR, on discrete,\ncontinuous and pixel-based tasks. Source code:\nhttps://github.com/vub-ai-lab/bdpi.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 09:59:58 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 13:49:50 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Steckelmacher", "Denis", ""], ["Plisnier", "H\u00e9l\u00e8ne", ""], ["Roijers", "Diederik M.", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "1903.04235", "submitter": "Zhao Kang", "authors": "Zhao Kang, Yiwei Lu, Yuanzhang Su, Changsheng Li, Zenglin Xu", "title": "Similarity Learning via Kernel Preserving Embedding", "comments": "Published in AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data similarity is a key concept in many data-driven applications. Many\nalgorithms are sensitive to similarity measures. To tackle this fundamental\nproblem, automatically learning of similarity information from data via\nself-expression has been developed and successfully applied in various models,\nsuch as low-rank representation, sparse subspace learning, semi-supervised\nlearning. However, it just tries to reconstruct the original data and some\nvaluable information, e.g., the manifold structure, is largely ignored. In this\npaper, we argue that it is beneficial to preserve the overall relations when we\nextract similarity information. Specifically, we propose a novel similarity\nlearning framework by minimizing the reconstruction error of kernel matrices,\nrather than the reconstruction error of original data adopted by existing work.\nTaking the clustering task as an example to evaluate our method, we observe\nconsiderable improvements compared to other state-of-the-art methods. More\nimportantly, our proposed framework is very general and provides a novel and\nfundamental building block for many other similarity-based tasks. Besides, our\nproposed kernel preserving opens up a large number of possibilities to embed\nhigh-dimensional data into low-dimensional space.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 11:58:40 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Kang", "Zhao", ""], ["Lu", "Yiwei", ""], ["Su", "Yuanzhang", ""], ["Li", "Changsheng", ""], ["Xu", "Zenglin", ""]]}, {"id": "1903.04278", "submitter": "Hsu-Chieh Hu", "authors": "Hsu-Chieh Hu, Stephen F. Smith", "title": "Coping with Large Traffic Volumes in Schedule-Driven Traffic Signal\n  Control", "comments": "ICAPS 2017. Twenty-Seventh International Conference on Automated\n  Planning and Scheduling. arXiv admin note: text overlap with arXiv:1903.02589", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in decentralized, schedule-driven traffic control has\ndemonstrated the ability to significantly improve traffic flow efficiency in\ncomplex urban road networks. However, in situations where vehicle volumes\nincrease to the point that the physical capacity of a road network reaches or\nexceeds saturation, it has been observed that the effectiveness of a\nschedule-driven approach begins to degrade, leading to progressively higher\nnetwork congestion. In essence, the traffic control problem becomes less of a\nscheduling problem and more of a queue management problem in this circumstance.\nIn this paper we propose a composite approach to real-time traffic control that\nuses sensed information on queue lengths to influence scheduling decisions and\ngracefully shift the signal control strategy to queue management in high\nvolume/high congestion settings. Specifically, queue-length information is used\nto establish weights for the sensed vehicle clusters that must be scheduled\nthrough a given intersection at any point, and hence bias the wait time\nminimization calculation. To compute these weights, we develop a model in which\nsuccessive movement phases are viewed as different states of an Ising model,\nand parameters quantify strength of interactions. To ensure scalability, queue\ninformation is only exchanged between direct neighbors and the asynchronous\nnature of local intersection scheduling is preserved. We demonstrate the\npotential of the approach through microscopic traffic simulation of a\nreal-world road network, showing a 60% reduction in average wait times over the\nbaseline schedule-driven approach in heavy traffic scenarios. We also report\ninitial field test results, which show the ability to reduce queues during\nheavy traffic periods.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 19:42:36 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Hu", "Hsu-Chieh", ""], ["Smith", "Stephen F.", ""]]}, {"id": "1903.04300", "submitter": "Arthur Queffelec", "authors": "Tristan Charrier, Arthur Queffelec, Ocan Sankur and Fran\\c{c}ois\n  Schwarzentruber", "title": "Reachability and Coverage Planning for Connected Agents: Extended\n  Version", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the increasing appeal of robots in information-gathering\nmissions, we study multi-agent path planning problems in which the agents must\nremain interconnected. We model an area by a topological graph specifying the\nmovement and the connectivity constraints of the agents. We study the\ntheoretical complexity of the reachability and the coverage problems of a fleet\nof connected agents on various classes of topological graphs. We establish the\ncomplexity of these problems on known classes, and introduce a new class called\nsight-moveable graphs which admit efficient algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 13:52:57 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Charrier", "Tristan", ""], ["Queffelec", "Arthur", ""], ["Sankur", "Ocan", ""], ["Schwarzentruber", "Fran\u00e7ois", ""]]}, {"id": "1903.04311", "submitter": "Clement Romac", "authors": "Cl\\'ement Romac, Vincent B\\'eraud", "title": "Deep Recurrent Q-Learning vs Deep Q-Learning on a simple Partially\n  Observable Markov Decision Process with Minecraft", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Q-Learning has been successfully applied to a wide variety of tasks in\nthe past several years. However, the architecture of the vanilla Deep Q-Network\nis not suited to deal with partially observable environments such as 3D video\ngames. For this, recurrent layers have been added to the Deep Q-Network in\norder to allow it to handle past dependencies. We here use Minecraft for its\ncustomization advantages and design two very simple missions that can be frames\nas Partially Observable Markov Decision Process. We compare on these missions\nthe Deep Q-Network and the Deep Recurrent Q-Network in order to see if the\nlatter, which is trickier and longer to train, is always the best architecture\nwhen the agent has to deal with partial observability.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 14:11:20 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 07:11:13 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Romac", "Cl\u00e9ment", ""], ["B\u00e9raud", "Vincent", ""]]}, {"id": "1903.04407", "submitter": "Pravendra Singh", "authors": "Pravendra Singh, Pratik Mazumder, Vinay P. Namboodiri", "title": "Accuracy Booster: Performance Boosting using Feature Map Re-calibration", "comments": "IEEE Winter Conference on Applications of Computer Vision (WACV),\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolution Neural Networks (CNN) have been extremely successful in solving\nintensive computer vision tasks. The convolutional filters used in CNNs have\nplayed a major role in this success, by extracting useful features from the\ninputs. Recently researchers have tried to boost the performance of CNNs by\nre-calibrating the feature maps produced by these filters, e.g.,\nSqueeze-and-Excitation Networks (SENets). These approaches have achieved better\nperformance by Exciting up the important channels or feature maps while\ndiminishing the rest. However, in the process, architectural complexity has\nincreased. We propose an architectural block that introduces much lower\ncomplexity than the existing methods of CNN performance boosting while\nperforming significantly better than them. We carry out experiments on the\nCIFAR, ImageNet and MS-COCO datasets, and show that the proposed block can\nchallenge the state-of-the-art results. Our method boosts the ResNet-50\narchitecture to perform comparably to the ResNet-152 architecture, which is a\nthree times deeper network, on classification. We also show experimentally that\nour method is not limited to classification but also generalizes well to other\ntasks such as object detection.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 16:16:03 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 10:44:44 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Singh", "Pravendra", ""], ["Mazumder", "Pratik", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "1903.04411", "submitter": "Zhewei Huang", "authors": "Zhewei Huang, Wen Heng, Shuchang Zhou", "title": "Learning to Paint With Model-based Deep Reinforcement Learning", "comments": "Accepted to ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to teach machines to paint like human painters, who can use a\nsmall number of strokes to create fantastic paintings. By employing a neural\nrenderer in model-based Deep Reinforcement Learning (DRL), our agents learn to\ndetermine the position and color of each stroke and make long-term plans to\ndecompose texture-rich images into strokes. Experiments demonstrate that\nexcellent visual effects can be achieved using hundreds of strokes. The\ntraining process does not require the experience of human painters or stroke\ntracking data. The code is available at\nhttps://github.com/hzwer/ICCV2019-LearningToPaint.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 16:21:46 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 20:36:19 GMT"}, {"version": "v3", "created": "Fri, 16 Aug 2019 08:02:02 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Huang", "Zhewei", ""], ["Heng", "Wen", ""], ["Zhou", "Shuchang", ""]]}, {"id": "1903.04413", "submitter": "Alexandre Coninx", "authors": "Leni K. Le Goff, Oussama Yaakoubi, Alexandre Coninx and Stephane\n  Doncieux", "title": "Building an Affordances Map with Interactive Perception", "comments": "14 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots need to understand their environment to perform their task. If it is\npossible to pre-program a visual scene analysis process in closed environments,\nrobots operating in an open environment would benefit from the ability to learn\nit through their interaction with their environment. This ability furthermore\nopens the way to the acquisition of affordances maps in which the action\ncapabilities of the robot structure its visual scene understanding. We propose\nan approach to build such affordances maps by relying on an interactive\nperception approach and an online classification. In the proposed formalization\nof affordances, actions and effects are related to visual features, not\nobjects, and they can be combined. We have tested the approach on three action\nprimitives and on a real PR2 robot.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 16:24:04 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Goff", "Leni K. Le", ""], ["Yaakoubi", "Oussama", ""], ["Coninx", "Alexandre", ""], ["Doncieux", "Stephane", ""]]}, {"id": "1903.04421", "submitter": "Rob Brisk", "authors": "Rob Brisk, Raymond R Bond. Dewar D Finlay, James McLaughlin, Alicja\n  Piadlo, Stephen J Leslie, David E Gossman, Ian B A Menown and David J\n  McEneaney", "title": "Augmenting expert detection of early coronary artery occlusion from 12\n  lead electrocardiograms using deep learning", "comments": "Our attempts to produce what we considered to be an acceptable level\n  of explainability from our algorithm have not yielded a satisfactory account\n  of its internal logic and we do not feel this is acceptable from a clinical\n  application. We will publish a fuller account of our work on this issue and\n  its implications on the validation of clinical deep learning algorithms in\n  the near future", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.AI q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early diagnosis of acute coronary artery occlusion based on electrocardiogram\n(ECG) findings is essential for prompt delivery of primary percutaneous\ncoronary intervention. Current ST elevation (STE) criteria are specific but\ninsensitive. Consequently, it is likely that many patients are missing out on\npotentially life-saving treatment. Experts combining non-specific ECG changes\nwith STE detect ischaemia with higher sensitivity, but at the cost of\nspecificity. We show that a deep learning model can detect ischaemia caused by\nacute coronary artery occlusion with a better balance of sensitivity and\nspecificity than STE criteria, existing computerised analysers or expert\ncardiologists.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 16:33:10 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 09:16:26 GMT"}, {"version": "v3", "created": "Wed, 20 Mar 2019 13:19:45 GMT"}, {"version": "v4", "created": "Mon, 18 Nov 2019 10:15:13 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Brisk", "Rob", ""], ["Finlay", "Raymond R Bond. Dewar D", ""], ["McLaughlin", "James", ""], ["Piadlo", "Alicja", ""], ["Leslie", "Stephen J", ""], ["Gossman", "David E", ""], ["Menown", "Ian B A", ""], ["McEneaney", "David J", ""]]}, {"id": "1903.04442", "submitter": "Bo Fu", "authors": "Patrick O'Driscoll, Jaehoon Lee and Bo Fu", "title": "Physics Enhanced Artificial Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose that intelligently combining models from the domains of Artificial\nIntelligence or Machine Learning with Physical and Expert models will yield a\nmore \"trustworthy\" model than any one model from a single domain, given a\ncomplex and narrow enough problem. Based on mean-variance portfolio theory and\nbias-variance trade-off analysis, we prove combining models from various\ndomains produces a model that has lower risk, increasing user trust. We call\nsuch combined models - physics enhanced artificial intelligence (PEAI), and\nsuggest use cases for PEAI.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 17:03:19 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["O'Driscoll", "Patrick", ""], ["Lee", "Jaehoon", ""], ["Fu", "Bo", ""]]}, {"id": "1903.04448", "submitter": "Judith Fan", "authors": "Judith Fan, Robert Hawkins, Mike Wu, Noah Goodman", "title": "Pragmatic inference and visual abstraction enable contextual flexibility\n  during visual communication", "comments": "29 pages; 5 figures; submitted draft of manuscript", "journal-ref": null, "doi": "10.1007/s42113-019-00058-7", "report-no": null, "categories": "cs.OH cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual modes of communication are ubiquitous in modern life --- from maps to\ndata plots to political cartoons. Here we investigate drawing, the most basic\nform of visual communication. Participants were paired in an online environment\nto play a drawing-based reference game. On each trial, both participants were\nshown the same four objects, but in different locations. The sketcher's goal\nwas to draw one of these objects so that the viewer could select it from the\narray. On `close' trials, objects belonged to the same basic-level category,\nwhereas on `far' trials objects belonged to different categories. We found that\npeople exploited shared information to efficiently communicate about the target\nobject: on far trials, sketchers achieved high recognition accuracy while\napplying fewer strokes, using less ink, and spending less time on their\ndrawings than on close trials. We hypothesized that humans succeed in this task\nby recruiting two core faculties: visual abstraction, the ability to perceive\nthe correspondence between an object and a drawing of it; and pragmatic\ninference, the ability to judge what information would help a viewer\ndistinguish the target from distractors. To evaluate this hypothesis, we\ndeveloped a computational model of the sketcher that embodied both faculties,\ninstantiated as a deep convolutional neural network nested within a\nprobabilistic program. We found that this model fit human data well and\noutperformed lesioned variants. Together, this work provides the first\nalgorithmically explicit theory of how visual perception and social cognition\njointly support contextual flexibility in visual communication.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 17:18:16 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2019 01:06:20 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Fan", "Judith", ""], ["Hawkins", "Robert", ""], ["Wu", "Mike", ""], ["Goodman", "Noah", ""]]}, {"id": "1903.04538", "submitter": "Richard Galvez", "authors": "Richard Galvez, David F. Fouhey, Meng Jin, Alexandre Szenicer,\n  Andr\\'es Mu\\~noz-Jaramillo, Mark C. M. Cheung, Paul J. Wright, Monica G.\n  Bobra, Yang Liu, James Mason, Rajat Thomas", "title": "A Machine Learning Dataset Prepared From the NASA Solar Dynamics\n  Observatory Mission", "comments": "Accepted to The Astrophysical Journal Supplement Series; 11 pages, 8\n  figures", "journal-ref": null, "doi": "10.3847/1538-4365/ab1005", "report-no": null, "categories": "astro-ph.SR cs.AI cs.DB cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we present a curated dataset from the NASA Solar Dynamics\nObservatory (SDO) mission in a format suitable for machine learning research.\nBeginning from level 1 scientific products we have processed various\ninstrumental corrections, downsampled to manageable spatial and temporal\nresolutions, and synchronized observations spatially and temporally. We\nillustrate the use of this dataset with two example applications: forecasting\nfuture EVE irradiance from present EVE irradiance and translating HMI\nobservations into AIA observations. For each application we provide metrics and\nbaselines for future model comparison. We anticipate this curated dataset will\nfacilitate machine learning research in heliophysics and the physical sciences\ngenerally, increasing the scientific return of the SDO mission. This work is a\ndirect result of the 2018 NASA Frontier Development Laboratory Program. Please\nsee the appendix for access to the dataset.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 18:50:48 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Galvez", "Richard", ""], ["Fouhey", "David F.", ""], ["Jin", "Meng", ""], ["Szenicer", "Alexandre", ""], ["Mu\u00f1oz-Jaramillo", "Andr\u00e9s", ""], ["Cheung", "Mark C. M.", ""], ["Wright", "Paul J.", ""], ["Bobra", "Monica G.", ""], ["Liu", "Yang", ""], ["Mason", "James", ""], ["Thomas", "Rajat", ""]]}, {"id": "1903.04672", "submitter": "Steven Holtzen", "authors": "Steven Holtzen and Todd Millstein and Guy Van den Broeck", "title": "Generating and Sampling Orbits for Lifted Probabilistic Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key goal in the design of probabilistic inference algorithms is identifying\nand exploiting properties of the distribution that make inference tractable.\nLifted inference algorithms identify symmetry as a property that enables\nefficient inference and seek to scale with the degree of symmetry of a\nprobability model. A limitation of existing exact lifted inference techniques\nis that they do not apply to non-relational representations like factor graphs.\nIn this work we provide the first example of an exact lifted inference\nalgorithm for arbitrary discrete factor graphs. In addition we describe a\nlifted Markov-Chain Monte-Carlo algorithm that provably mixes rapidly in the\ndegree of symmetry of the distribution.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 00:15:46 GMT"}, {"version": "v2", "created": "Thu, 14 Mar 2019 15:46:52 GMT"}, {"version": "v3", "created": "Sun, 30 Jun 2019 23:23:21 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Holtzen", "Steven", ""], ["Millstein", "Todd", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "1903.04714", "submitter": "Michael Teng", "authors": "Michael Teng, Tuan Anh Le, Adam Scibior, Frank Wood", "title": "Imitation Learning of Factored Multi-agent Reactive Models", "comments": "incorporated into another paper with different motivations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply recent advances in deep generative modeling to the task of imitation\nlearning from biological agents. Specifically, we apply variations of the\nvariational recurrent neural network model to a multi-agent setting where we\nlearn policies of individual uncoordinated agents acting based on their\nperceptual inputs and their hidden belief state. We learn stochastic policies\nfor these agents directly from observational data, without constructing a\nreward function. An inference network learned jointly with the policy allows\nfor efficient inference over the agent's belief state given a sequence of its\ncurrent perceptual inputs and the prior actions it performed, which lets us\nextrapolate observed sequences of behavior into the future while maintaining\nuncertainty estimates over future trajectories. We test our approach on a\ndataset of flies interacting in a 2D environment, where we demonstrate better\npredictive performance than existing approaches which learn deterministic\npolicies with recurrent neural networks. We further show that the uncertainty\nestimates over future trajectories we obtain are well calibrated, which makes\nthem useful for a variety of downstream processing tasks.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 03:50:27 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 21:13:23 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Teng", "Michael", ""], ["Le", "Tuan Anh", ""], ["Scibior", "Adam", ""], ["Wood", "Frank", ""]]}, {"id": "1903.04750", "submitter": "Wen Zhang", "authors": "Wen Zhang, Bibek Paudel, Wei Zhang, Abraham Bernstein and Huajun Chen", "title": "Interaction Embeddings for Prediction and Explanation in Knowledge\n  Graphs", "comments": "This paper is accepted by WSDM2019", "journal-ref": null, "doi": "10.1145/3289600.3291014", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph embedding aims to learn distributed representations for\nentities and relations, and is proven to be effective in many applications.\nCrossover interactions --- bi-directional effects between entities and\nrelations --- help select related information when predicting a new triple, but\nhaven't been formally discussed before. In this paper, we propose CrossE, a\nnovel knowledge graph embedding which explicitly simulates crossover\ninteractions. It not only learns one general embedding for each entity and\nrelation as most previous methods do, but also generates multiple triple\nspecific embeddings for both of them, named interaction embeddings. We evaluate\nembeddings on typical link prediction tasks and find that CrossE achieves\nstate-of-the-art results on complex and more challenging datasets. Furthermore,\nwe evaluate embeddings from a new perspective --- giving explanations for\npredicted triples, which is important for real applications. In this work, an\nexplanation for a triple is regarded as a reliable closed-path between the head\nand the tail entity. Compared to other baselines, we show experimentally that\nCrossE, benefiting from interaction embeddings, is more capable of generating\nreliable explanations to support its predictions.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 07:12:46 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Zhang", "Wen", ""], ["Paudel", "Bibek", ""], ["Zhang", "Wei", ""], ["Bernstein", "Abraham", ""], ["Chen", "Huajun", ""]]}, {"id": "1903.04940", "submitter": "Rafael Pe\\~naloza", "authors": "Fabrizio M. Maggi, Marco Montali and Rafael Pe\\~naloza", "title": "Temporal Logics Over Finite Traces with Uncertainty (Technical Report)", "comments": "Extended version of paper accepted at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal logics over finite traces have recently seen wide application in a\nnumber of areas, from business process modelling, monitoring, and mining to\nplanning and decision making. However, real-life dynamic systems contain a\ndegree of uncertainty which cannot be handled with classical logics. We thus\npropose a new probabilistic temporal logic over finite traces using\nsuperposition semantics, where all possible evolutions are possible, until\nobserved. We study the properties of the logic and provide automata-based\nmechanisms for deriving probabilistic inferences from its formulas. We then\nstudy a fragment of the logic with better computational properties. Notably,\nformulas in this fragment can be discovered from event log data using\noff-the-shelf existing declarative process discovery techniques.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 14:17:44 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 15:38:40 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Maggi", "Fabrizio M.", ""], ["Montali", "Marco", ""], ["Pe\u00f1aloza", "Rafael", ""]]}, {"id": "1903.04959", "submitter": "Haotian Fu", "authors": "Haotian Fu, Hongyao Tang, Jianye Hao, Zihan Lei, Yingfeng Chen,\n  Changjie Fan", "title": "Deep Multi-Agent Reinforcement Learning with Discrete-Continuous Hybrid\n  Action Spaces", "comments": null, "journal-ref": "IJCAI 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) has been applied to address a variety of\ncooperative multi-agent problems with either discrete action spaces or\ncontinuous action spaces. However, to the best of our knowledge, no previous\nwork has ever succeeded in applying DRL to multi-agent problems with\ndiscrete-continuous hybrid (or parameterized) action spaces which is very\ncommon in practice. Our work fills this gap by proposing two novel algorithms:\nDeep Multi-Agent Parameterized Q-Networks (Deep MAPQN) and Deep Multi-Agent\nHierarchical Hybrid Q-Networks (Deep MAHHQN). We follow the centralized\ntraining but decentralized execution paradigm: different levels of\ncommunication between different agents are used to facilitate the training\nprocess, while each agent executes its policy independently based on local\nobservations during execution. Our empirical results on several challenging\ntasks (simulated RoboCup Soccer and game Ghost Story) show that both Deep MAPQN\nand Deep MAHHQN are effective and significantly outperform existing independent\ndeep parameterized Q-learning method.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 14:40:32 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Fu", "Haotian", ""], ["Tang", "Hongyao", ""], ["Hao", "Jianye", ""], ["Lei", "Zihan", ""], ["Chen", "Yingfeng", ""], ["Fan", "Changjie", ""]]}, {"id": "1903.04966", "submitter": "Jin-Kao Hao", "authors": "Zequn Wei and Jin-Kao Hao", "title": "Iterated two-phase local search for the Set-Union Knapsack Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Set-union Knapsack Problem (SUKP) is a generalization of the popular 0-1\nknapsack problem. Given a set of weighted elements and a set of items with\nprofits where each item is composed of a subset of elements, the SUKP involves\npacking a subset of items in a capacity-constrained knapsack such that the\ntotal profit of the selected items is maximized while their weights do not\nexceed the knapsack capacity. In this work, we present an effective iterated\ntwo-phase local search algorithm for this NP-hard combinatorial optimization\nproblem. The proposed algorithm iterates through two search phases: a local\noptima exploration phase that alternates between a variable neighborhood\ndescent search and a tabu search to explore local optimal solutions, and a\nlocal optima escaping phase to drive the search to unexplored regions. We show\nthe competitiveness of the algorithm compared to the state-of-the-art methods\nin the literature. Specifically, the algorithm discovers 18 improved best\nresults (new lower bounds) for the 30 benchmark instances and matches the\nbest-known results for the 12 remaining instances. We also report the first\ncomputational results with the general CPLEX solver, including 6 proven optimal\nsolutions. Finally, we investigate the effectiveness of the key ingredients of\nthe algorithm on its performance.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 14:48:24 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 09:46:30 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Wei", "Zequn", ""], ["Hao", "Jin-Kao", ""]]}, {"id": "1903.04991", "submitter": "Andrzej Banburski", "authors": "Andrzej Banburski, Qianli Liao, Brando Miranda, Lorenzo Rosasco,\n  Fernanda De La Torre, Jack Hidary and Tomaso Poggio", "title": "Theory III: Dynamics and Generalization in Deep Networks", "comments": "47 pages, 11 figures. This replaces previous versions of Theory III,\n  that appeared on Arxiv [arXiv:1806.11379, arXiv:1801.00173] or on the CBMM\n  site. v5: Changes throughout the paper to the presentation and tightening\n  some of the statements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key to generalization is controlling the complexity of the network.\nHowever, there is no obvious control of complexity -- such as an explicit\nregularization term -- in the training of deep networks for classification. We\nwill show that a classical form of norm control -- but kind of hidden -- is\npresent in deep networks trained with gradient descent techniques on\nexponential-type losses. In particular, gradient descent induces a dynamics of\nthe normalized weights which converge for $t \\to \\infty$ to an equilibrium\nwhich corresponds to a minimum norm (or maximum margin) solution. For\nsufficiently large but finite $\\rho$ -- and thus finite $t$ -- the dynamics\nconverges to one of several margin maximizers, with the margin monotonically\nincreasing towards a limit stationary point of the flow. In the usual case of\nstochastic gradient descent, most of the stationary points are likely to be\nconvex minima corresponding to a constrained minimizer -- the network with\nnormalized weights-- which corresponds to vanishing regularization. The\nsolution has zero generalization gap, for fixed architecture, asymptotically\nfor $N \\to \\infty$, where $N$ is the number of training examples. Our approach\nextends some of the original results of Srebro from linear networks to deep\nnetworks and provides a new perspective on the implicit bias of gradient\ndescent. We believe that the elusive complexity control we describe is\nresponsible for the puzzling empirical finding of good predictive performance\nby deep networks, despite overparametrization.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 15:24:26 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 22:38:08 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 02:02:40 GMT"}, {"version": "v4", "created": "Wed, 3 Jul 2019 22:59:20 GMT"}, {"version": "v5", "created": "Sat, 11 Apr 2020 00:21:50 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Banburski", "Andrzej", ""], ["Liao", "Qianli", ""], ["Miranda", "Brando", ""], ["Rosasco", "Lorenzo", ""], ["De La Torre", "Fernanda", ""], ["Hidary", "Jack", ""], ["Poggio", "Tomaso", ""]]}, {"id": "1903.05084", "submitter": "Julian Theis", "authors": "Julian Theis and Houshang Darabi", "title": "Decay Replay Mining to Predict Next Process Events", "comments": "Revised manuscript. Github repository added", "journal-ref": "IEEE Access, vol. 7, pp. 119787-119803, 2019", "doi": "10.1109/ACCESS.2019.2937085", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In complex processes, various events can happen in different sequences. The\nprediction of the next event given an a-priori process state is of importance\nin such processes. Recent methods have proposed deep learning techniques such\nas recurrent neural networks, developed on raw event logs, to predict the next\nevent from a process state. However, such deep learning models by themselves\nlack a clear representation of the process states. At the same time, recent\nmethods have neglected the time feature of event instances. In this paper, we\ntake advantage of Petri nets as a powerful tool in modeling complex process\nbehaviors considering time as an elemental variable. We propose an approach\nwhich starts from a Petri net process model constructed by a process mining\nalgorithm. We enhance the Petri net model with time decay functions to create\ncontinuous process state samples. Finally, we use these samples in combination\nwith discrete token movement counters and Petri net markings to train a deep\nlearning model that predicts the next event. We demonstrate significant\nperformance improvements and outperform the state-of-the-art methods on nine\nreal-world benchmark event logs.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 14:53:10 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 15:04:55 GMT"}, {"version": "v3", "created": "Mon, 26 Aug 2019 20:54:32 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Theis", "Julian", ""], ["Darabi", "Houshang", ""]]}, {"id": "1903.05134", "submitter": "Jiahui Yu", "authors": "Jiahui Yu, Thomas Huang", "title": "Universally Slimmable Networks and Improved Training Techniques", "comments": "Accepted in ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Slimmable networks are a family of neural networks that can instantly adjust\nthe runtime width. The width can be chosen from a predefined widths set to\nadaptively optimize accuracy-efficiency trade-offs at runtime. In this work, we\npropose a systematic approach to train universally slimmable networks\n(US-Nets), extending slimmable networks to execute at arbitrary width, and\ngeneralizing to networks both with and without batch normalization layers. We\nfurther propose two improved training techniques for US-Nets, named the\nsandwich rule and inplace distillation, to enhance training process and boost\ntesting accuracy. We show improved performance of universally slimmable\nMobileNet v1 and MobileNet v2 on ImageNet classification task, compared with\nindividually trained ones and 4-switch slimmable network baselines. We also\nevaluate the proposed US-Nets and improved training techniques on tasks of\nimage super-resolution and deep reinforcement learning. Extensive ablation\nexperiments on these representative tasks demonstrate the effectiveness of our\nproposed methods. Our discovery opens up the possibility to directly evaluate\nFLOPs-Accuracy spectrum of network architectures. Code and models are available\nat: https://github.com/JiahuiYu/slimmable_networks\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 18:36:02 GMT"}, {"version": "v2", "created": "Sun, 20 Oct 2019 19:52:57 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Yu", "Jiahui", ""], ["Huang", "Thomas", ""]]}, {"id": "1903.05136", "submitter": "Zhijian Liu", "authors": "Zhenjia Xu, Zhijian Liu, Chen Sun, Kevin Murphy, William T. Freeman,\n  Joshua B. Tenenbaum, Jiajun Wu", "title": "Unsupervised Discovery of Parts, Structure, and Dynamics", "comments": "ICLR 2019. The first two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans easily recognize object parts and their hierarchical structure by\nwatching how they move; they can then predict how each part moves in the\nfuture. In this paper, we propose a novel formulation that simultaneously\nlearns a hierarchical, disentangled object representation and a dynamics model\nfor object parts from unlabeled videos. Our Parts, Structure, and Dynamics\n(PSD) model learns to, first, recognize the object parts via a layered image\nrepresentation; second, predict hierarchy via a structural descriptor that\ncomposes low-level concepts into a hierarchical structure; and third, model the\nsystem dynamics by predicting the future. Experiments on multiple real and\nsynthetic datasets demonstrate that our PSD model works well on all three\ntasks: segmenting object parts, building their hierarchical structure, and\ncapturing their motion distributions.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 18:39:10 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Xu", "Zhenjia", ""], ["Liu", "Zhijian", ""], ["Sun", "Chen", ""], ["Murphy", "Kevin", ""], ["Freeman", "William T.", ""], ["Tenenbaum", "Joshua B.", ""], ["Wu", "Jiajun", ""]]}, {"id": "1903.05153", "submitter": "Vijil Chenthamarakshan", "authors": "Tian Gao, Jie Chen, Vijil Chenthamarakshan, Michael Witbrock", "title": "A Sequential Set Generation Method for Predicting Set-Valued Outputs", "comments": "Published at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a general machine learning setting where the output is a set of\nlabels or sequences. This output set is unordered and its size varies with the\ninput. Whereas multi-label classification methods seem a natural first resort,\nthey are not readily applicable to set-valued outputs because of the growth\nrate of the output space; and because conventional sequence generation doesn't\nreflect sets' order-free nature. In this paper, we propose a unified\nframework--sequential set generation (SSG)--that can handle output sets of\nlabels and sequences. SSG is a meta-algorithm that leverages any probabilistic\nlearning method for label or sequence prediction, but employs a proper\nregularization such that a new label or sequence is generated repeatedly until\nthe full set is produced. Though SSG is sequential in nature, it does not\npenalize the ordering of the appearance of the set elements and can be applied\nto a variety of set output problems, such as a set of classification labels or\nsequences. We perform experiments with both benchmark and synthetic data sets\nand demonstrate SSG's strong performance over baseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 19:06:18 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Gao", "Tian", ""], ["Chen", "Jie", ""], ["Chenthamarakshan", "Vijil", ""], ["Witbrock", "Michael", ""]]}, {"id": "1903.05168", "submitter": "Ryan Lowe T.", "authors": "Ryan Lowe and Jakob Foerster and Y-Lan Boureau and Joelle Pineau and\n  Yann Dauphin", "title": "On the Pitfalls of Measuring Emergent Communication", "comments": "AAMAS 2019. 13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How do we know if communication is emerging in a multi-agent system? The vast\nmajority of recent papers on emergent communication show that adding a\ncommunication channel leads to an increase in reward or task success. This is a\nuseful indicator, but provides only a coarse measure of the agent's learned\ncommunication abilities. As we move towards more complex environments, it\nbecomes imperative to have a set of finer tools that allow qualitative and\nquantitative insights into the emergence of communication. This may be\nespecially useful to allow humans to monitor agents' behaviour, whether for\nfault detection, assessing performance, or even building trust. In this paper,\nwe examine a few intuitive existing metrics for measuring communication, and\nshow that they can be misleading. Specifically, by training deep reinforcement\nlearning agents to play simple matrix games augmented with a communication\nchannel, we find a scenario where agents appear to communicate (their messages\nprovide information about their subsequent action), and yet the messages do not\nimpact the environment or other agent in any way. We explain this phenomenon\nusing ablation studies and by visualizing the representations of the learned\npolicies. We also survey some commonly used metrics for measuring emergent\ncommunication, and provide recommendations as to when these metrics should be\nused.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 19:33:49 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Lowe", "Ryan", ""], ["Foerster", "Jakob", ""], ["Boureau", "Y-Lan", ""], ["Pineau", "Joelle", ""], ["Dauphin", "Yann", ""]]}, {"id": "1903.05174", "submitter": "Claudio Gallicchio", "authors": "Claudio Gallicchio and Alessio Micheli", "title": "Richness of Deep Echo State Network Dynamics", "comments": "Preprint of the paper accepted at IWANN 2019", "journal-ref": null, "doi": "10.1007/978-3-030-20521-8_40", "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reservoir Computing (RC) is a popular methodology for the efficient design of\nRecurrent Neural Networks (RNNs). Recently, the advantages of the RC approach\nhave been extended to the context of multi-layered RNNs, with the introduction\nof the Deep Echo State Network (DeepESN) model. In this paper, we study the\nquality of state dynamics in progressively higher layers of DeepESNs, using\ntools from the areas of information theory and numerical analysis. Our\nexperimental results on RC benchmark datasets reveal the fundamental role\nplayed by the strength of inter-reservoir connections to increasingly enrich\nthe representations developed in higher layers. Our analysis also gives\ninteresting insights into the possibility of effective exploitation of training\nalgorithms based on stochastic gradient descent in the RC field.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 19:39:36 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 15:49:55 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Gallicchio", "Claudio", ""], ["Micheli", "Alessio", ""]]}, {"id": "1903.05284", "submitter": "Yunhao Tang", "authors": "Yunhao Tang, Mingzhang Yin, Mingyuan Zhou", "title": "Augment-Reinforce-Merge Policy Gradient for Binary Stochastic Policy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the high variance of policy gradients, on-policy optimization\nalgorithms are plagued with low sample efficiency. In this work, we propose\nAugment-Reinforce-Merge (ARM) policy gradient estimator as an unbiased\nlow-variance alternative to previous baseline estimators on tasks with binary\naction space, inspired by the recent ARM gradient estimator for discrete random\nvariable models. We show that the ARM policy gradient estimator achieves\nvariance reduction with theoretical guarantees, and leads to significantly more\nstable and faster convergence of policies parameterized by neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 01:43:50 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Tang", "Yunhao", ""], ["Yin", "Mingzhang", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "1903.05334", "submitter": "Zhe Zeng Miss", "authors": "Zhe Zeng, Guy Van den Broeck", "title": "Efficient Search-Based Weighted Model Integration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weighted model integration (WMI) extends Weighted model counting (WMC) to the\nintegration of functions over mixed discrete-continuous domains. It has shown\ntremendous promise for solving inference problems in graphical models and\nprobabilistic programming. Yet, state-of-the-art tools for WMI are limited in\nterms of performance and ignore the independence structure that is crucial to\nimproving efficiency. To address this limitation, we propose an efficient model\nintegration algorithm for theories with tree primal graphs. We exploit the\nsparse graph structure by using search to performing integration. Our algorithm\ngreatly improves the computational efficiency on such problems and exploits\ncontext-specific independence between variables. Experimental results show\ndramatic speedups compared to existing WMI solvers on problems with tree-shaped\ndependencies.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 06:46:03 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 14:26:38 GMT"}, {"version": "v3", "created": "Mon, 9 Sep 2019 21:58:55 GMT"}, {"version": "v4", "created": "Wed, 20 Nov 2019 00:17:53 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Zeng", "Zhe", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "1903.05382", "submitter": "Lior Rokach", "authors": "Eran Fainman, Bracha Shapira, Lior Rokach, Yisroel Mirsky", "title": "Online Budgeted Learning for Classifier Induction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world machine learning applications, there is a cost associated with\nsampling of different features. Budgeted learning can be used to select which\nfeature-values to acquire from each instance in a dataset, such that the best\nmodel is induced under a given constraint. However, this approach is not\npossible in the domain of online learning since one may not retroactively\nacquire feature-values from past instances. In online learning, the challenge\nis to find the optimum set of features to be acquired from each instance upon\narrival from a data stream. In this paper we introduce the issue of online\nbudgeted learning and describe a general framework for addressing this\nchallenge. We propose two types of feature value acquisition policies based on\nthe multi-armed bandit problem: random and adaptive. Adaptive policies perform\nonline adjustments according to new information coming from a data stream,\nwhile random policies are not sensitive to the information that arrives from\nthe data stream. Our comparative study on five real-world datasets indicates\nthat adaptive policies outperform random policies for most budget limitations\nand datasets. Furthermore, we found that in some cases adaptive policies\nachieve near-optimal results.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 09:51:33 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Fainman", "Eran", ""], ["Shapira", "Bracha", ""], ["Rokach", "Lior", ""], ["Mirsky", "Yisroel", ""]]}, {"id": "1903.05485", "submitter": "Ye Liu", "authors": "Ye Liu, Hui Li, Alberto Garcia-Duran, Mathias Niepert, Daniel\n  Onoro-Rubio, David S. Rosenblum", "title": "MMKG: Multi-Modal Knowledge Graphs", "comments": "ESWC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present MMKG, a collection of three knowledge graphs that contain both\nnumerical features and (links to) images for all entities as well as entity\nalignments between pairs of KGs. Therefore, multi-relational link prediction\nand entity matching communities can benefit from this resource. We believe this\ndata set has the potential to facilitate the development of novel multi-modal\nlearning approaches for knowledge graphs.We validate the utility ofMMKG in the\nsameAs link prediction task with an extensive set of experiments. These\nexperiments show that the task at hand benefits from learning of multiple\nfeature types.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 13:48:32 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Liu", "Ye", ""], ["Li", "Hui", ""], ["Garcia-Duran", "Alberto", ""], ["Niepert", "Mathias", ""], ["Onoro-Rubio", "Daniel", ""], ["Rosenblum", "David S.", ""]]}, {"id": "1903.05501", "submitter": "Hiroshi Kuwajima", "authors": "Hiroshi Kuwajima, Masayuki Tanaka, Masatoshi Okutomi", "title": "Improving Transparency of Deep Neural Inference Process", "comments": "11 pages, 14 figures, 1 table. This is a pre-print of an article\n  accepted in \"Progress in Artificial Intelligence\" on 26 Feb 2019. The final\n  authenticated version will be available online soon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning techniques are rapidly advanced recently, and becoming a\nnecessity component for widespread systems. However, the inference process of\ndeep learning is black-box, and not very suitable to safety-critical systems\nwhich must exhibit high transparency. In this paper, to address this black-box\nlimitation, we develop a simple analysis method which consists of 1) structural\nfeature analysis: lists of the features contributing to inference process, 2)\nlinguistic feature analysis: lists of the natural language labels describing\nthe visual attributes for each feature contributing to inference process, and\n3) consistency analysis: measuring consistency among input data, inference\n(label), and the result of our structural and linguistic feature analysis. Our\nanalysis is simplified to reflect the actual inference process for high\ntransparency, whereas it does not include any additional black-box mechanisms\nsuch as LSTM for highly human readable results. We conduct experiments and\ndiscuss the results of our analysis qualitatively and quantitatively, and come\nto believe that our work improves the transparency of neural networks.\nEvaluated through 12,800 human tasks, 75% workers answer that input data and\nresult of our feature analysis are consistent, and 70% workers answer that\ninference (label) and result of our feature analysis are consistent. In\naddition to the evaluation of the proposed analysis, we find that our analysis\nalso provide suggestions, or possible next actions such as expanding neural\nnetwork complexity or collecting training data to improve a neural network.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 14:11:44 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Kuwajima", "Hiroshi", ""], ["Tanaka", "Masayuki", ""], ["Okutomi", "Masatoshi", ""]]}, {"id": "1903.05517", "submitter": "Claudio Zito", "authors": "Claudio Zito and Valerio Ortenzi and Maxime Adjigble and Marek Kopicki\n  and Rustam Stolkin and Jeremy L. Wyatt", "title": "Hypothesis-based Belief Planning for Dexterous Grasping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Belief space planning is a viable alternative to formalise partially\nobservable control problems and, in the recent years, its application to robot\nmanipulation problems has grown. However, this planning approach was tried\nsuccessfully only on simplified control problems. In this paper, we apply\nbelief space planning to the problem of planning dexterous reach-to-grasp\ntrajectories under object pose uncertainty. In our framework, the robot\nperceives the object to be grasped on-the-fly as a point cloud and compute a\nfull 6D, non-Gaussian distribution over the object's pose (our belief space).\nThe system has no limitations on the geometry of the object, i.e., non-convex\nobjects can be represented, nor assumes that the point cloud is a complete\nrepresentation of the object. A plan in the belief space is then created to\nreach and grasp the object, such that the information value of expected\ncontacts along the trajectory is maximised to compensate for the pose\nuncertainty. If an unexpected contact occurs when performing the action, such\ninformation is used to refine the pose distribution and triggers a re-planning.\nExperimental results show that our planner (IR3ne) improves grasp reliability\nand compensates for the pose uncertainty such that it doubles the proportion of\ngrasps that succeed on a first attempt.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 14:46:28 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Zito", "Claudio", ""], ["Ortenzi", "Valerio", ""], ["Adjigble", "Maxime", ""], ["Kopicki", "Marek", ""], ["Stolkin", "Rustam", ""], ["Wyatt", "Jeremy L.", ""]]}, {"id": "1903.05543", "submitter": "James Thorne", "authors": "James Thorne and Andreas Vlachos", "title": "Adversarial attacks against Fact Extraction and VERification", "comments": "Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a baseline for the second iteration of the Fact\nExtraction and VERification shared task (FEVER2.0) which explores the\nresilience of systems through adversarial evaluation. We present a collection\nof simple adversarial attacks against systems that participated in the first\nFEVER shared task. FEVER modeled the assessment of truthfulness of written\nclaims as a joint information retrieval and natural language inference task\nusing evidence from Wikipedia. A large number of participants made use of deep\nneural networks in their submissions to the shared task. The extent as to\nwhether such models understand language has been the subject of a number of\nrecent investigations and discussion in literature. In this paper, we present a\nsimple method of generating entailment-preserving and entailment-altering\nperturbations of instances by common patterns within the training data. We find\nthat a number of systems are greatly affected with absolute losses in\nclassification accuracy of up to $29\\%$ on the newly perturbed instances. Using\nthese newly generated instances, we construct a sample submission for the\nFEVER2.0 shared task. Addressing these types of attacks will aid in building\nmore robust fact-checking models, as well as suggest directions to expand the\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 15:29:22 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Thorne", "James", ""], ["Vlachos", "Andreas", ""]]}, {"id": "1903.05614", "submitter": "Marc Lanctot", "authors": "Edward Lockhart, Marc Lanctot, Julien P\\'erolat, Jean-Baptiste\n  Lespiau, Dustin Morrill, Finbarr Timbers, Karl Tuyls", "title": "Computing Approximate Equilibria in Sequential Adversarial Games by\n  Exploitability Descent", "comments": "IJCAI 2019, 11 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present exploitability descent, a new algorithm to compute\napproximate equilibria in two-player zero-sum extensive-form games with\nimperfect information, by direct policy optimization against worst-case\nopponents. We prove that when following this optimization, the exploitability\nof a player's strategy converges asymptotically to zero, and hence when both\nplayers employ this optimization, the joint policies converge to a Nash\nequilibrium. Unlike fictitious play (XFP) and counterfactual regret\nminimization (CFR), our convergence result pertains to the policies being\noptimized rather than the average policies. Our experiments demonstrate\nconvergence rates comparable to XFP and CFR in four benchmark games in the\ntabular case. Using function approximation, we find that our algorithm\noutperforms the tabular version in two of the games, which, to the best of our\nknowledge, is the first such result in imperfect information games among this\nclass of algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 17:27:04 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 15:14:51 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 22:49:42 GMT"}, {"version": "v4", "created": "Fri, 12 Jun 2020 04:41:23 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Lockhart", "Edward", ""], ["Lanctot", "Marc", ""], ["P\u00e9rolat", "Julien", ""], ["Lespiau", "Jean-Baptiste", ""], ["Morrill", "Dustin", ""], ["Timbers", "Finbarr", ""], ["Tuyls", "Karl", ""]]}, {"id": "1903.05696", "submitter": "Aaron Hertzmann", "authors": "Aaron Hertzmann", "title": "Aesthetics of Neural Network Art", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a way to understand neural network artworks as\njuxtapositions of natural image cues. It is hypothesized that images with\nunusual combinations of realistic visual cues are interesting, and, neural\nmodels trained to model natural images are well-suited to creating interesting\nimages. Art using neural models produces new images similar to those of natural\nimages, but with weird and intriguing variations. This analysis is applied to\nneural art based on Generative Adversarial Networks, image stylization, Deep\nDreams, and Perception Engines.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 19:45:54 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 17:58:15 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Hertzmann", "Aaron", ""]]}, {"id": "1903.05720", "submitter": "Arjun Akula", "authors": "Arjun R Akula, Sinisa Todorovic, Joyce Y Chai, Song-Chun Zhu", "title": "Natural Language Interaction with Explainable AI Models", "comments": null, "journal-ref": "CVPR 2019 Workshop on Explainable AI", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an explainable AI (XAI) system that provides explanations\nfor its predictions. The system consists of two key components -- namely, the\nprediction And-Or graph (AOG) model for recognizing and localizing concepts of\ninterest in input data, and the XAI model for providing explanations to the\nuser about the AOG's predictions. In this work, we focus on the XAI model\nspecified to interact with the user in natural language, whereas the AOG's\npredictions are considered given and represented by the corresponding parse\ngraphs (pg's) of the AOG. Our XAI model takes pg's as input and provides\nanswers to the user's questions using the following types of reasoning: direct\nevidence (e.g., detection scores), part-based inference (e.g., detected parts\nprovide evidence for the concept asked), and other evidences from\nspatio-temporal context (e.g., constraints from the spatio-temporal surround).\nWe identify several correlations between user's questions and the XAI answers\nusing Youtube Action dataset.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 21:29:13 GMT"}, {"version": "v2", "created": "Sun, 7 Jul 2019 07:52:59 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Akula", "Arjun R", ""], ["Todorovic", "Sinisa", ""], ["Chai", "Joyce Y", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1903.05726", "submitter": "Guanyang Wang", "authors": "Guanyang Wang", "title": "A Multi-armed Bandit MCMC, with applications in sampling from doubly\n  intractable posterior", "comments": "24 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.AI physics.data-an stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov chain Monte Carlo (MCMC) algorithms are widely used to sample from\ncomplicated distributions, especially to sample from the posterior distribution\nin Bayesian inference. However, MCMC is not directly applicable when facing the\ndoubly intractable problem. In this paper, we discussed and compared two\nexisting solutions -- Pseudo-marginal Monte Carlo and Exchange Algorithm. This\npaper also proposes a novel algorithm: Multi-armed Bandit MCMC (MABMC), which\nchooses between two (or more) randomized acceptance ratios in each step. MABMC\ncould be applied directly to incorporate Pseudo-marginal Monte Carlo and\nExchange algorithm, with higher average acceptance probability.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 21:38:48 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 20:39:01 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Wang", "Guanyang", ""]]}, {"id": "1903.05757", "submitter": "Xiaofeng Gao", "authors": "Xiaofeng Gao, Ran Gong, Tianmin Shu, Xu Xie, Shu Wang, Song-Chun Zhu", "title": "VRKitchen: an Interactive 3D Virtual Environment for Task-oriented\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main challenges of advancing task-oriented learning such as visual\ntask planning and reinforcement learning is the lack of realistic and\nstandardized environments for training and testing AI agents. Previously,\nresearchers often relied on ad-hoc lab environments. There have been recent\nadvances in virtual systems built with 3D physics engines and photo-realistic\nrendering for indoor and outdoor environments, but the embodied agents in those\nsystems can only conduct simple interactions with the world (e.g., walking\naround, moving objects, etc.). Most of the existing systems also do not allow\nhuman participation in their simulated environments. In this work, we design\nand implement a virtual reality (VR) system, VRKitchen, with integrated\nfunctions which i) enable embodied agents powered by modern AI methods (e.g.,\nplanning, reinforcement learning, etc.) to perform complex tasks involving a\nwide range of fine-grained object manipulations in a realistic environment, and\nii) allow human teachers to perform demonstrations to train agents (i.e.,\nlearning from demonstration). We also provide standardized evaluation\nbenchmarks and data collection tools to facilitate a broad use in research on\ntask-oriented learning and beyond.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 23:31:21 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Gao", "Xiaofeng", ""], ["Gong", "Ran", ""], ["Shu", "Tianmin", ""], ["Xie", "Xu", ""], ["Wang", "Shu", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1903.05766", "submitter": "Raunak Bhattacharyya", "authors": "Raunak P. Bhattacharyya, Derek J. Phillips, Changliu Liu, Jayesh K.\n  Gupta, Katherine Driggs-Campbell, Mykel J. Kochenderfer", "title": "Simulating Emergent Properties of Human Driving Behavior Using\n  Multi-Agent Reward Augmented Imitation Learning", "comments": "Accepted for publication at ICRA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in multi-agent imitation learning have shown promising\nresults for modeling the behavior of human drivers. However, it is challenging\nto capture emergent traffic behaviors that are observed in real-world datasets.\nSuch behaviors arise due to the many local interactions between agents that are\nnot commonly accounted for in imitation learning. This paper proposes Reward\nAugmented Imitation Learning (RAIL), which integrates reward augmentation into\nthe multi-agent imitation learning framework and allows the designer to specify\nprior knowledge in a principled fashion. We prove that convergence guarantees\nfor the imitation learning process are preserved under the application of\nreward augmentation. This method is validated in a driving scenario, where an\nentire traffic scene is controlled by driving policies learned using our\nproposed algorithm. Further, we demonstrate improved performance in comparison\nto traditional imitation learning algorithms both in terms of the local actions\nof a single agent and the behavior of emergent properties in complex,\nmulti-agent settings.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 00:02:03 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Bhattacharyya", "Raunak P.", ""], ["Phillips", "Derek J.", ""], ["Liu", "Changliu", ""], ["Gupta", "Jayesh K.", ""], ["Driggs-Campbell", "Katherine", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1903.05881", "submitter": "Yasunori Ozaki", "authors": "Yasunori Ozaki, Tatsuya Ishihara, Narimune Matsumura, Tadashi Nunobiki", "title": "Can User-Centered Reinforcement Learning Allow a Robot to Attract\n  Passersby without Causing Discomfort?", "comments": "Accepted to The 2019 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The aim of our study was to develop a method by which a social robot can\ngreet passersby and get their attention without causing them to suffer\ndiscomfort.A number of customer services have recently come to be provided by\nsocial robots rather than people, including, serving as receptionists, guides,\nand exhibitors. Robot exhibitors, for example, can explain products being\npromoted by the robot owners. However, a sudden greeting by a robot can startle\npassersby and cause discomfort to passersby.Social robots should thus adapt\ntheir mannerisms to the situation they face regarding passersby.We developed a\nmethod for meeting this requirement on the basis of the results of related\nwork. Our proposed method, user-centered reinforcement learning, enables robots\nto greet passersby and get their attention without causing them to suffer\ndiscomfort (p<0.01) .The results of an experiment in the field, an office\nentrance, demonstrated that our method meets this requirement.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 09:51:04 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 03:52:52 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Ozaki", "Yasunori", ""], ["Ishihara", "Tatsuya", ""], ["Matsumura", "Narimune", ""], ["Nunobiki", "Tadashi", ""]]}, {"id": "1903.05926", "submitter": "Ling Pan", "authors": "Ling Pan, Qingpeng Cai, Qi Meng, Wei Chen, Longbo Huang, Tie-Yan Liu", "title": "Reinforcement Learning with Dynamic Boltzmann Softmax Updates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value function estimation is an important task in reinforcement learning,\ni.e., prediction. The Boltzmann softmax operator is a natural value estimator\nand can provide several benefits. However, it does not satisfy the\nnon-expansion property, and its direct use may fail to converge even in value\niteration. In this paper, we propose to update the value function with dynamic\nBoltzmann softmax (DBS) operator, which has good convergence property in the\nsetting of planning and learning. Experimental results on GridWorld show that\nthe DBS operator enables better estimation of the value function, which\nrectifies the convergence issue of the softmax operator. Finally, we propose\nthe DBS-DQN algorithm by applying dynamic Boltzmann softmax updates in deep\nQ-network, which outperforms DQN substantially in 40 out of 49 Atari games.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 11:54:13 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 01:32:58 GMT"}, {"version": "v3", "created": "Tue, 30 Jul 2019 03:40:05 GMT"}, {"version": "v4", "created": "Sun, 8 Sep 2019 07:41:39 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Pan", "Ling", ""], ["Cai", "Qingpeng", ""], ["Meng", "Qi", ""], ["Chen", "Wei", ""], ["Huang", "Longbo", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1903.05937", "submitter": "Luciano Serafini", "authors": "Luciano Serafini, Paolo Traverso", "title": "Incremental Learning of Discrete Planning Domains from Continuous\n  Perceptions", "comments": "Corrected lines 12 and 19 of algorithm 1: ALP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for learning discrete deterministic planning domains.\nIn this framework, an agent learns the domain by observing the action effects\nthrough continuous features that describe the state of the environment after\nthe execution of each action. Besides, the agent learns its perception\nfunction, i.e., a probabilistic mapping between state variables and sensor data\nrepresented as a vector of continuous random variables called perception\nvariables. We define an algorithm that updates the planning domain and the\nperception function by (i) introducing new states, either by extending the\npossible values of state variables, or by weakening their constraints; (ii)\nadapts the perception function to fit the observed data (iii) adapts the\ntransition function on the basis of the executed actions and the effects\nobserved via the perception function. The framework is able to deal with\nexogenous events that happen in the environment.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 12:17:33 GMT"}, {"version": "v2", "created": "Fri, 19 Apr 2019 09:39:27 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Serafini", "Luciano", ""], ["Traverso", "Paolo", ""]]}, {"id": "1903.06015", "submitter": "Vahid Mokhtari", "authors": "Vahid Mokhtari, Luis Seabra Lopes, Armando Pinho and Roman Manevich", "title": "Computing the Scope of Applicability for Acquired Task Knowledge in\n  Experience-Based Planning Domains", "comments": "8 pages, conference paper. arXiv admin note: text overlap with\n  arXiv:1902.10770", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experience-based planning domains have been proposed to improve problem\nsolving by learning from experience. They rely on acquiring and using task\nknowledge, i.e., activity schemata, for generating solutions to problem\ninstances in a class of tasks. Using Three-Valued Logic Analysis (TVLA), we\nextend previous work to generate a set of conditions that determine the scope\nof applicability of an activity schema. The inferred scope is a bounded\nrepresentation of a set of problems of potentially unbounded size, in the form\nof a 3-valued logical structure, which is used to automatically find an\napplicable activity schema for solving task problems. We validate this work in\ntwo classical planning domains.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 09:05:47 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Mokhtari", "Vahid", ""], ["Lopes", "Luis Seabra", ""], ["Pinho", "Armando", ""], ["Manevich", "Roman", ""]]}, {"id": "1903.06047", "submitter": "Matthew Gombolay", "authors": "Rohan Paleja and Matthew Gombolay", "title": "Inferring Personalized Bayesian Embeddings for Learning from\n  Heterogeneous Demonstration", "comments": "8 Pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For assistive robots and virtual agents to achieve ubiquity, machines will\nneed to anticipate the needs of their human counterparts. The field of Learning\nfrom Demonstration (LfD) has sought to enable machines to infer predictive\nmodels of human behavior for autonomous robot control. However, humans exhibit\nheterogeneity in decision-making, which traditional LfD approaches fail to\ncapture. To overcome this challenge, we propose a Bayesian LfD framework to\ninfer an integrated representation of all human task demonstrators by inferring\nhuman-specific embeddings, thereby distilling their unique characteristics. We\nvalidate our approach is able to outperform state-of-the-art techniques on both\nsynthetic and real-world data sets.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 14:32:55 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Paleja", "Rohan", ""], ["Gombolay", "Matthew", ""]]}, {"id": "1903.06151", "submitter": "Jan Scholten", "authors": "Jan Scholten, Daan Wout, Carlos Celemin and Jens Kober", "title": "Deep Reinforcement Learning with Feedback-based Exploration", "comments": "6 pages", "journal-ref": null, "doi": "10.1109/CDC40024.2019.9029503", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning has enabled the control of increasingly complex\nand high-dimensional problems. However, the need of vast amounts of data before\nreasonable performance is attained prevents its widespread application. We\nemploy binary corrective feedback as a general and intuitive manner to\nincorporate human intuition and domain knowledge in model-free machine\nlearning. The uncertainty in the policy and the corrective feedback is combined\ndirectly in the action space as probabilistic conditional exploration. As a\nresult, the greatest part of the otherwise ignorant learning process can be\navoided. We demonstrate the proposed method, Predictive Probabilistic Merging\nof Policies (PPMP), in combination with DDPG. In experiments on continuous\ncontrol problems of the OpenAI Gym, we achieve drastic improvements in sample\nefficiency, final performance, and robustness to erroneous feedback, both for\nhuman and synthetic feedback. Additionally, we show solutions beyond the\ndemonstrated knowledge.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 17:52:46 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Scholten", "Jan", ""], ["Wout", "Daan", ""], ["Celemin", "Carlos", ""], ["Kober", "Jens", ""]]}, {"id": "1903.06187", "submitter": "Aditya Modi", "authors": "Aditya Modi, Ambuj Tewari", "title": "No-regret Exploration in Contextual Reinforcement Learning", "comments": "Accepted to UAI 2020. PMLR proceedings, volume 124", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the recently proposed reinforcement learning (RL) framework of\nContextual Markov Decision Processes (CMDP), where the agent interacts with a\n(potentially adversarial) sequence of episodic tabular MDPs. In addition, a\ncontext vector determining the MDP parameters is available to the agent at the\nstart of each episode, thereby allowing it to learn a context-dependent\nnear-optimal policy. In this paper, we propose a no-regret online RL algorithm\nin the setting where the MDP parameters are obtained from the context using\ngeneralized linear mappings (GLMs). We propose and analyze optimistic and\nrandomized exploration methods which make (time and space) efficient online\nupdates. The GLM based model subsumes previous work in this area and also\nimproves previous known bounds in the special case where the contextual mapping\nis linear. In addition, we demonstrate a generic template to derive confidence\nsets using an online learning oracle and give a lower bound for the setting.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 18:02:09 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 21:30:26 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 20:02:00 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Modi", "Aditya", ""], ["Tewari", "Ambuj", ""]]}, {"id": "1903.06278", "submitter": "Risto Kojcev", "authors": "Nestor Gonzalez Lopez, Yue Leire Erro Nuin, Elias Barba Moral, Lander\n  Usategui San Juan, Alejandro Solano Rueda, V\\'ictor Mayoral Vilches and Risto\n  Kojcev", "title": "gym-gazebo2, a toolkit for reinforcement learning using ROS 2 and Gazebo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an upgraded, real world application oriented version of\ngym-gazebo, the Robot Operating System (ROS) and Gazebo based Reinforcement\nLearning (RL) toolkit, which complies with OpenAI Gym. The content discusses\nthe new ROS 2 based software architecture and summarizes the results obtained\nusing Proximal Policy Optimization (PPO). Ultimately, the output of this work\npresents a benchmarking system for robotics that allows different techniques\nand algorithms to be compared using the same virtual conditions. We have\nevaluated environments with different levels of complexity of the Modular\nArticulated Robotic Arm (MARA), reaching accuracies in the millimeter scale.\nThe converged results show the feasibility and usefulness of the gym-gazebo 2\ntoolkit, its potential and applicability in industrial use cases, using modular\nrobots.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 22:05:20 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 05:32:11 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Lopez", "Nestor Gonzalez", ""], ["Nuin", "Yue Leire Erro", ""], ["Moral", "Elias Barba", ""], ["Juan", "Lander Usategui San", ""], ["Rueda", "Alejandro Solano", ""], ["Vilches", "V\u00edctor Mayoral", ""], ["Kojcev", "Risto", ""]]}, {"id": "1903.06281", "submitter": "Peter Eckersley", "authors": "Sky Croeser and Peter Eckersley", "title": "Theories of Parenting and their Application to Artificial Intelligence", "comments": null, "journal-ref": "Also in Proc. AI, Ethics and Society 2019", "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As machine learning (ML) systems have advanced, they have acquired more power\nover humans' lives, and questions about what values are embedded in them have\nbecome more complex and fraught. It is conceivable that in the coming decades,\nhumans may succeed in creating artificial general intelligence (AGI) that\nthinks and acts with an open-endedness and autonomy comparable to that of\nhumans. The implications would be profound for our species; they are now widely\ndebated not just in science fiction and speculative research agendas but\nincreasingly in serious technical and policy conversations.\n  Much work is underway to try to weave ethics into advancing ML research. We\nthink it useful to add the lens of parenting to these efforts, and specifically\nradical, queer theories of parenting that consciously set out to nurture agents\nwhose experiences, objectives and understanding of the world will necessarily\nbe very different from their parents'. We propose a spectrum of principles\nwhich might underpin such an effort; some are relevant to current ML research,\nwhile others will become more important if AGI becomes more likely. These\nprinciples may encourage new thinking about the development, design, training,\nand release into the world of increasingly autonomous agents.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 22:13:14 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Croeser", "Sky", ""], ["Eckersley", "Peter", ""]]}, {"id": "1903.06282", "submitter": "Risto Kojcev", "authors": "Yue Leire Erro Nuin, Nestor Gonzalez Lopez, Elias Barba Moral, Lander\n  Usategui San Juan, Alejandro Solano Rueda, V\\'ictor Mayoral Vilches and Risto\n  Kojcev", "title": "ROS2Learn: a reinforcement learning framework for ROS 2", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel framework for Deep Reinforcement Learning (DRL) in modular\nrobotics to train a robot directly from joint states, using traditional robotic\ntools. We use an state-of-the-art implementation of the Proximal Policy\nOptimization, Trust Region Policy Optimization and Actor-Critic\nKronecker-Factored Trust Region algorithms to learn policies in four different\nModular Articulated Robotic Arm (MARA) environments. We support this process\nusing a framework that communicates with typical tools used in robotics, such\nas Gazebo and Robot Operating System 2 (ROS 2). We evaluate several algorithms\nin modular robots with an empirical study in simulation.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 22:13:23 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 05:27:29 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Nuin", "Yue Leire Erro", ""], ["Lopez", "Nestor Gonzalez", ""], ["Moral", "Elias Barba", ""], ["Juan", "Lander Usategui San", ""], ["Rueda", "Alejandro Solano", ""], ["Vilches", "V\u00edctor Mayoral", ""], ["Kojcev", "Risto", ""]]}, {"id": "1903.06309", "submitter": "Xingyu Lin", "authors": "Xingyu Lin, Pengsheng Guo, Carlos Florensa, David Held", "title": "Adaptive Variance for Changing Sparse-Reward Environments", "comments": "Accepted as a conference at International Conference on Robotics and\n  Automation(ICRA) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots that are trained to perform a task in a fixed environment often fail\nwhen facing unexpected changes to the environment due to a lack of exploration.\nWe propose a principled way to adapt the policy for better exploration in\nchanging sparse-reward environments. Unlike previous works which explicitly\nmodel environmental changes, we analyze the relationship between the value\nfunction and the optimal exploration for a Gaussian-parameterized policy and\nshow that our theory leads to an effective strategy for adjusting the variance\nof the policy, enabling fast adapt to changes in a variety of sparse-reward\nenvironments.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 00:40:59 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 20:25:48 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Lin", "Xingyu", ""], ["Guo", "Pengsheng", ""], ["Florensa", "Carlos", ""], ["Held", "David", ""]]}, {"id": "1903.06320", "submitter": "Hideaki Hata", "authors": "Yoshiharu Ikutani, Nishanth Koganti, Hideaki Hata, Takatomi Kubo,\n  Kenichi Matsumoto", "title": "Toward Imitating Visual Attention of Experts in Software Development\n  Tasks", "comments": "4 pages, EMIP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expert programmers' eye-movements during source code reading are valuable\nsources that are considered to be associated with their domain expertise. We\nadvocate a vision of new intelligent systems incorporating expertise of experts\nfor software development tasks, such as issue localization, comment generation,\nand code generation. We present a conceptual framework of neural autonomous\nagents based on imitation learning (IL), which enables agents to mimic the\nvisual attention of an expert via his/her eye movement. In this framework, an\nautonomous agent is constructed as a context-based attention model that\nconsists of encoder/decoder network and trained with state-action sequences\ngenerated by an experts' demonstration. Challenges to implement an IL-based\nautonomous agent specialized for software development task are discussed in\nthis paper.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 01:51:16 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Ikutani", "Yoshiharu", ""], ["Koganti", "Nishanth", ""], ["Hata", "Hideaki", ""], ["Kubo", "Takatomi", ""], ["Matsumoto", "Kenichi", ""]]}, {"id": "1903.06418", "submitter": "Mehrdad Zakershahrak", "authors": "Mehrdad Zakershahrak, Ze Gong, Nikhillesh Sadassivam and Yu Zhang", "title": "Online Explanation Generation for Human-Robot Teaming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As AI becomes an integral part of our lives, the development of explainable\nAI, embodied in the decision-making process of an AI or robotic agent, becomes\nimperative. For a robotic teammate, the ability to generate explanations to\njustify its behavior is one of the key requirements of explainable agency.\nPrior work on explanation generation has been focused on supporting the\nrationale behind the robot's decision or behavior. These approaches, however,\nfail to consider the mental demand for understanding the received explanation.\nIn other words, the human teammate is expected to understand an explanation no\nmatter how much information is presented. In this work, we argue that\nexplanations, especially those of a complex nature, should be made in an online\nfashion during the execution, which helps spread out the information to be\nexplained and thus reduce the mental workload of humans in highly cognitive\ndemanding tasks. However, a challenge here is that the different parts of an\nexplanation may be dependent on each other, which must be taken into account\nwhen generating online explanations. To this end, a general formulation of\nonline explanation generation is presented with three variations satisfying\ndifferent \"online\" properties. The new explanation generation methods are based\non a model reconciliation setting introduced in our prior work. We evaluated\nour methods both with human subjects in a simulated rover domain, using NASA\nTask Load Index (TLX), and synthetically with ten different problems across two\nstandard IPC domains. Results strongly suggest that our methods generate\nexplanations that are perceived as less cognitively demanding and much\npreferred over the baselines and are computationally efficient.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 09:09:53 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 01:14:46 GMT"}, {"version": "v3", "created": "Sun, 4 Aug 2019 00:42:18 GMT"}, {"version": "v4", "created": "Tue, 6 Aug 2019 08:00:27 GMT"}, {"version": "v5", "created": "Mon, 16 Sep 2019 05:31:34 GMT"}, {"version": "v6", "created": "Mon, 31 Aug 2020 17:04:51 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Zakershahrak", "Mehrdad", ""], ["Gong", "Ze", ""], ["Sadassivam", "Nikhillesh", ""], ["Zhang", "Yu", ""]]}, {"id": "1903.06445", "submitter": "Desmond Ong", "authors": "Desmond C. Ong, Harold Soh, Jamil Zaki, Noah D. Goodman", "title": "Applying Probabilistic Programming to Affective Computing", "comments": "Accepted by IEEE Transactions on Affective Computing. 12 pages, 6\n  figures", "journal-ref": null, "doi": "10.1109/TAFFC.2019.2905211", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Affective Computing is a rapidly growing field spurred by advancements in\nartificial intelligence, but often, held back by the inability to translate\npsychological theories of emotion into tractable computational models. To\naddress this, we propose a probabilistic programming approach to affective\ncomputing, which models psychological-grounded theories as generative models of\nemotion, and implements them as stochastic, executable computer programs. We\nfirst review probabilistic approaches that integrate reasoning about emotions\nwith reasoning about other latent mental states (e.g., beliefs, desires) in\ncontext. Recently-developed probabilistic programming languages offer several\nkey desidarata over previous approaches, such as: (i) flexibility in\nrepresenting emotions and emotional processes; (ii) modularity and\ncompositionality; (iii) integration with deep learning libraries that\nfacilitate efficient inference and learning from large, naturalistic data; and\n(iv) ease of adoption. Furthermore, using a probabilistic programming framework\nallows a standardized platform for theory-building and experimentation:\nCompeting theories (e.g., of appraisal or other emotional processes) can be\neasily compared via modular substitution of code followed by model comparison.\nTo jumpstart adoption, we illustrate our points with executable code that\nresearchers can easily modify for their own models. We end with a discussion of\napplications and future directions of the probabilistic programming approach.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 10:33:53 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Ong", "Desmond C.", ""], ["Soh", "Harold", ""], ["Zaki", "Jamil", ""], ["Goodman", "Noah D.", ""]]}, {"id": "1903.06592", "submitter": "Samir Wadhwania", "authors": "Samir Wadhwania, Dong-Ki Kim, Shayegan Omidshafiei, and Jonathan P.\n  How", "title": "Policy Distillation and Value Matching in Multiagent Reinforcement\n  Learning", "comments": "Submitted as a conference paper to IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiagent reinforcement learning algorithms (MARL) have been demonstrated on\ncomplex tasks that require the coordination of a team of multiple agents to\ncomplete. Existing works have focused on sharing information between agents via\ncentralized critics to stabilize learning or through communication to increase\nperformance, but do not generally look at how information can be shared between\nagents to address the curse of dimensionality in MARL. We posit that a\nmultiagent problem can be decomposed into a multi-task problem where each agent\nexplores a subset of the state space instead of exploring the entire state\nspace. This paper introduces a multiagent actor-critic algorithm and method for\ncombining knowledge from homogeneous agents through distillation and\nvalue-matching that outperforms policy distillation alone and allows further\nlearning in both discrete and continuous action spaces.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 15:13:02 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Wadhwania", "Samir", ""], ["Kim", "Dong-Ki", ""], ["Omidshafiei", "Shayegan", ""], ["How", "Jonathan P.", ""]]}, {"id": "1903.06669", "submitter": "Lily Xu", "authors": "Lily Xu, Shahrzad Gholami, Sara Mc Carthy, Bistra Dilkina, Andrew\n  Plumptre, Milind Tambe, Rohit Singh, Mustapha Nsubuga, Joshua Mabonga,\n  Margaret Driciru, Fred Wanyama, Aggrey Rwetsiba, Tom Okello, Eric Enyel", "title": "Stay Ahead of Poachers: Illegal Wildlife Poaching Prediction and Patrol\n  Planning Under Uncertainty with Field Test Evaluations", "comments": "12 pages, 11 figures. Short paper published in ICDE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Illegal wildlife poaching threatens ecosystems and drives endangered species\ntoward extinction. However, efforts for wildlife protection are constrained by\nthe limited resources of law enforcement agencies. To help combat poaching, the\nProtection Assistant for Wildlife Security (PAWS) is a machine learning\npipeline that has been developed as a data-driven approach to identify areas at\nhigh risk of poaching throughout protected areas and compute optimal patrol\nroutes. In this paper, we take an end-to-end approach to the data-to-deployment\npipeline for anti-poaching. In doing so, we address challenges including\nextreme class imbalance (up to 1:200), bias, and uncertainty in wildlife\npoaching data to enhance PAWS, and we apply our methodology to three national\nparks with diverse characteristics. (i) We use Gaussian processes to quantify\npredictive uncertainty, which we exploit to improve robustness of our\nprescribed patrols and increase detection of snares by an average of 30%. We\nevaluate our approach on real-world historical poaching data from Murchison\nFalls and Queen Elizabeth National Parks in Uganda and, for the first time,\nSrepok Wildlife Sanctuary in Cambodia. (ii) We present the results of\nlarge-scale field tests conducted in Murchison Falls and Srepok Wildlife\nSanctuary which confirm that the predictive power of PAWS extends promisingly\nto multiple parks. This paper is part of an effort to expand PAWS to 800 parks\naround the world through integration with SMART conservation software.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 08:26:07 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 04:11:38 GMT"}, {"version": "v3", "created": "Wed, 6 Nov 2019 03:06:34 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Xu", "Lily", ""], ["Gholami", "Shahrzad", ""], ["Carthy", "Sara Mc", ""], ["Dilkina", "Bistra", ""], ["Plumptre", "Andrew", ""], ["Tambe", "Milind", ""], ["Singh", "Rohit", ""], ["Nsubuga", "Mustapha", ""], ["Mabonga", "Joshua", ""], ["Driciru", "Margaret", ""], ["Wanyama", "Fred", ""], ["Rwetsiba", "Aggrey", ""], ["Okello", "Tom", ""], ["Enyel", "Eric", ""]]}, {"id": "1903.06694", "submitter": "Kirthevasan Kandasamy", "authors": "Kirthevasan Kandasamy, Karun Raju Vysyaraju, Willie Neiswanger,\n  Biswajit Paria, Christopher R. Collins, Jeff Schneider, Barnabas Poczos, Eric\n  P. Xing", "title": "Tuning Hyperparameters without Grad Students: Scalable and Robust\n  Bayesian Optimisation with Dragonfly", "comments": "Journal of Machine Learning Research 2020, Special Issue on Bayesian\n  Optimization", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Optimisation (BO) refers to a suite of techniques for global\noptimisation of expensive black box functions, which use introspective Bayesian\nmodels of the function to efficiently search for the optimum. While BO has been\napplied successfully in many applications, modern optimisation tasks usher in\nnew challenges where conventional methods fail spectacularly. In this work, we\npresent Dragonfly, an open source Python library for scalable and robust BO.\nDragonfly incorporates multiple recently developed methods that allow BO to be\napplied in challenging real world settings; these include better methods for\nhandling higher dimensional domains, methods for handling multi-fidelity\nevaluations when cheap approximations of an expensive function are available,\nmethods for optimising over structured combinatorial spaces, such as the space\nof neural network architectures, and methods for handling parallel evaluations.\nAdditionally, we develop new methodological improvements in BO for selecting\nthe Bayesian model, selecting the acquisition function, and optimising over\ncomplex domains with different variable types and additional constraints. We\ncompare Dragonfly to a suite of other packages and algorithms for global\noptimisation and demonstrate that when the above methods are integrated, they\nenable significant improvements in the performance of BO. The Dragonfly library\nis available at dragonfly.github.io.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 17:45:39 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 18:09:41 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Kandasamy", "Kirthevasan", ""], ["Vysyaraju", "Karun Raju", ""], ["Neiswanger", "Willie", ""], ["Paria", "Biswajit", ""], ["Collins", "Christopher R.", ""], ["Schneider", "Jeff", ""], ["Poczos", "Barnabas", ""], ["Xing", "Eric P.", ""]]}, {"id": "1903.06847", "submitter": "Matthew Gombolay", "authors": "Esmaeil Seraj and Andrew Silva and Matthew Gombolay", "title": "Safe Coordination of Human-Robot Firefighting Teams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wildfires are destructive and inflict massive, irreversible harm to victims'\nlives and natural resources. Researchers have proposed commissioning unmanned\naerial vehicles (UAVs) to provide firefighters with real-time tracking\ninformation; yet, these UAVs are not able to reason about a fire's track,\nincluding current location, measurement, and uncertainty, as well as\npropagation. We propose a model-predictive, probabilistically safe distributed\ncontrol algorithm for human-robot collaboration in wildfire fighting. The\nproposed algorithm overcomes the limitations of prior work by explicitly\nestimating the latent fire propagation dynamics to enable intelligent,\ntime-extended coordination of the UAVs in support of on-the-ground human\nfirefighters. We derive a novel, analytical bound that enables UAVs to\ndistribute their resources and provides a probabilistic guarantee of the\nhumans' safety while preserving the UAVs' ability to cover an entire fire.\n", "versions": [{"version": "v1", "created": "Sat, 16 Mar 2019 00:14:34 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Seraj", "Esmaeil", ""], ["Silva", "Andrew", ""], ["Gombolay", "Matthew", ""]]}, {"id": "1903.07008", "submitter": "Rodrigo Canaan", "authors": "Rodrigo Canaan, Christoph Salge, Julian Togelius, Andy Nealen", "title": "Leveling the Playing Field -- Fairness in AI Versus Human Game\n  Benchmarks", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From the beginning if the history of AI, there has been interest in games as\na platform of research. As the field developed, human-level competence in\ncomplex games became a target researchers worked to reach. Only relatively\nrecently has this target been finally met for traditional tabletop games such\nas Backgammon, Chess and Go. Current research focus has shifted to electronic\ngames, which provide unique challenges. As is often the case with AI research,\nthese results are liable to be exaggerated or misrepresented by either authors\nor third parties. The extent to which these games benchmark consist of fair\ncompetition between human and AI is also a matter of debate. In this work, we\nreview the statements made by authors and third parties in the general media\nand academic circle about these game benchmark results and discuss factors that\ncan impact the perception of fairness in the contest between humans and\nmachines\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 00:42:26 GMT"}, {"version": "v2", "created": "Sun, 24 Mar 2019 17:52:49 GMT"}, {"version": "v3", "created": "Sun, 14 Apr 2019 01:20:16 GMT"}, {"version": "v4", "created": "Thu, 29 Aug 2019 16:52:14 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Canaan", "Rodrigo", ""], ["Salge", "Christoph", ""], ["Togelius", "Julian", ""], ["Nealen", "Andy", ""]]}, {"id": "1903.07021", "submitter": "Adam Poulsen", "authors": "Adam Poulsen, Michael Anderson, Susan L. Anderson, Ben Byford, Fabio\n  Fossa, Erica L. Neely, Alejandro Rosas, Alan Winfield", "title": "Responses to a Critique of Artificial Moral Agents", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of machine ethics is concerned with the question of how to embed\nethical behaviors, or a means to determine ethical behaviors, into artificial\nintelligence (AI) systems. The goal is to produce artificial moral agents\n(AMAs) that are either implicitly ethical (designed to avoid unethical\nconsequences) or explicitly ethical (designed to behave ethically). Van\nWynsberghe and Robbins' (2018) paper Critiquing the Reasons for Making\nArtificial Moral Agents critically addresses the reasons offered by machine\nethicists for pursuing AMA research; this paper, co-authored by machine\nethicists and commentators, aims to contribute to the machine ethics\nconversation by responding to that critique. The reasons for developing AMAs\ndiscussed in van Wynsberghe and Robbins (2018) are: it is inevitable that they\nwill be developed; the prevention of harm; the necessity for public trust; the\nprevention of immoral use; such machines are better moral reasoners than\nhumans, and building these machines would lead to a better understanding of\nhuman morality. In this paper, each co-author addresses those reasons in turn.\nIn so doing, this paper demonstrates that the reasons critiqued are not shared\nby all co-authors; each machine ethicist has their own reasons for researching\nAMAs. But while we express a diverse range of views on each of the six reasons\nin van Wynsberghe and Robbins' critique, we nevertheless share the opinion that\nthe scientific study of AMAs has considerable value.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 03:18:24 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Poulsen", "Adam", ""], ["Anderson", "Michael", ""], ["Anderson", "Susan L.", ""], ["Byford", "Ben", ""], ["Fossa", "Fabio", ""], ["Neely", "Erica L.", ""], ["Rosas", "Alejandro", ""], ["Winfield", "Alan", ""]]}, {"id": "1903.07091", "submitter": "Naveen Arivazhagan", "authors": "Naveen Arivazhagan, Ankur Bapna, Orhan Firat, Roee Aharoni, Melvin\n  Johnson, Wolfgang Macherey", "title": "The Missing Ingredient in Zero-Shot Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual Neural Machine Translation (NMT) models are capable of\ntranslating between multiple source and target languages. Despite various\napproaches to train such models, they have difficulty with zero-shot\ntranslation: translating between language pairs that were not together seen\nduring training. In this paper we first diagnose why state-of-the-art\nmultilingual NMT models that rely purely on parameter sharing, fail to\ngeneralize to unseen language pairs. We then propose auxiliary losses on the\nNMT encoder that impose representational invariance across languages. Our\nsimple approach vastly improves zero-shot translation quality without\nregressing on supervised directions. For the first time, on WMT14\nEnglish-FrenchGerman, we achieve zero-shot performance that is on par with\npivoting. We also demonstrate the easy scalability of our approach to multiple\nlanguages on the IWSLT 2017 shared task.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 14:01:53 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Arivazhagan", "Naveen", ""], ["Bapna", "Ankur", ""], ["Firat", "Orhan", ""], ["Aharoni", "Roee", ""], ["Johnson", "Melvin", ""], ["Macherey", "Wolfgang", ""]]}, {"id": "1903.07107", "submitter": "Souma Chowdhury", "authors": "Amir Behjat and Sharat Chidambaran and Souma Chowdhury", "title": "Adaptive Genomic Evolution of Neural Network Topologies (AGENT) for\n  State-to-Action Mapping in Autonomous Agents", "comments": "Accepted for presentation in (and publication in the proceedings of)\n  the 2019 IEEE International Conference on Robotics and Automation (ICRA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroevolution is a process of training neural networks (NN) through an\nevolutionary algorithm, usually to serve as a state-to-action mapping model in\ncontrol or reinforcement learning-type problems. This paper builds on the Neuro\nEvolution of Augmented Topologies (NEAT) formalism that allows designing\ntopology and weight evolving NNs. Fundamental advancements are made to the\nneuroevolution process to address premature stagnation and convergence issues,\ncentral among which is the incorporation of automated mechanisms to control the\npopulation diversity and average fitness improvement within the neuroevolution\nprocess. Insights into the performance and efficiency of the new algorithm is\nobtained by evaluating it on three benchmark problems from the Open AI platform\nand an Unmanned Aerial Vehicle (UAV) collision avoidance problem.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 15:34:11 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Behjat", "Amir", ""], ["Chidambaran", "Sharat", ""], ["Chowdhury", "Souma", ""]]}, {"id": "1903.07157", "submitter": "Jiaxiao Zheng", "authors": "Jiaxiao Zheng and Gustavo de Veciana", "title": "Modeling and Optimization of Human-machine Interaction Processes via the\n  Maximum Entropy Principle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a data-driven framework to enable the modeling and optimization of\nhuman-machine interaction processes, e.g., systems aimed at assisting humans in\ndecision-making or learning, work-load allocation, and interactive advertising.\nThis is a challenging problem for several reasons. First, humans' behavior is\nhard to model or infer, as it may reflect biases, long term memory, and\nsensitivity to sequencing, i.e., transience and exponential complexity in the\nlength of the interaction. Second, due to the interactive nature of such\nprocesses, the machine policy used to engage with a human may bias possible\ndata-driven inferences. Finally, in choosing machine policies that optimize\ninteraction rewards, one must, on the one hand, avoid being overly sensitive to\nerror/variability in the estimated human model, and on the other, being overly\ndeterministic/predictable which may result in poor human 'engagement' in the\ninteraction. To meet these challenges, we propose a robust approach, based on\nthe maximum entropy principle, which iteratively estimates human behavior and\noptimizes the machine policy--Alternating Entropy-Reward Ascent (AREA)\nalgorithm. We characterize AREA, in terms of its space and time complexity and\nconvergence. We also provide an initial validation based on synthetic data\ngenerated by an established noisy nonlinear model for human decision-making.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 20:14:04 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Zheng", "Jiaxiao", ""], ["de Veciana", "Gustavo", ""]]}, {"id": "1903.07198", "submitter": "Sarath Sreedharan", "authors": "Sarath Sreedharan, Alberto Olmo, Aditya Prasad Mishra and Subbarao\n  Kambhampati", "title": "Model-Free Model Reconciliation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing agents capable of explaining complex sequential decisions remain a\nsignificant open problem in automated decision-making. Recently, there has been\na lot of interest in developing approaches for generating such explanations for\nvarious decision-making paradigms. One such approach has been the idea of {\\em\nexplanation as model-reconciliation}. The framework hypothesizes that one of\nthe common reasons for the user's confusion could be the mismatch between the\nuser's model of the task and the one used by the system to generate the\ndecisions. While this is a general framework, most works that have been\nexplicitly built on this explanatory philosophy have focused on settings where\nthe model of user's knowledge is available in a declarative form. Our goal in\nthis paper is to adapt the model reconciliation approach to the cases where\nsuch user models are no longer explicitly provided. We present a simple and\neasy to learn labeling model that can help an explainer decide what information\ncould help achieve model reconciliation between the user and the agent.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 23:30:52 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Sreedharan", "Sarath", ""], ["Olmo", "Alberto", ""], ["Mishra", "Aditya Prasad", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1903.07260", "submitter": "Yaoting Huang", "authors": "Yaoting Huang, Boyu Chen, Wenlian Lu, Zhong-Xiao Jin, Ren Zheng", "title": "Intelligent Solution System towards Parts Logistics Optimization", "comments": "WCGO 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the complication of the presented problem, intelligent algorithms show\ngreat power to solve the parts logistics optimization problem related to the\nvehicle routing problem (VRP). However, most of the existing research to VRP\nare incomprehensive and failed to solve a real-work parts logistics problem.\n  In this work, towards SAIC logistics problem, we propose a systematic\nsolution to this 2-Dimensional Loading Capacitated Multi-Depot Heterogeneous\nVRP with Time Windows by integrating diverse types of intelligent algorithms,\nincluding, a heuristic algorithm to initialize feasible logistics planning\nschemes by imitating manual planning, the core Tabu Search algorithm for global\noptimization, accelerated by a novel bundle technique, heuristically algorithms\nfor routing, packing and queuing associated, and a heuristic post-optimization\nprocess to promote the optimal solution.\n  Based on these algorithms, the SAIC Motor has successfully established an\nintelligent management system to give a systematic solution for the parts\nlogistics planning, superior than manual planning in its performance,\ncustomizability and expandability.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 05:43:03 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Huang", "Yaoting", ""], ["Chen", "Boyu", ""], ["Lu", "Wenlian", ""], ["Jin", "Zhong-Xiao", ""], ["Zheng", "Ren", ""]]}, {"id": "1903.07269", "submitter": "Sarath Sreedharan", "authors": "Sarath Sreedharan, Tathagata Chakraborti, Christian Muise, Subbarao\n  Kambhampati", "title": "Expectation-Aware Planning: A Unifying Framework for Synthesizing and\n  Executing Self-Explaining Plans for Human-Aware Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a new planning formalism called Expectation-Aware\nplanning for decision making with humans in the loop where the human's\nexpectations about an agent may differ from the agent's own model. We show how\nthis formulation allows agents to not only leverage existing strategies for\nhandling model differences but can also exhibit novel behaviors that are\ngenerated through the combination of these different strategies. Our\nformulation also reveals a deep connection to existing approaches in epistemic\nplanning. Specifically, we show how we can leverage classical planning\ncompilations for epistemic planning to solve Expectation-Aware planning\nproblems. To the best of our knowledge, the proposed formulation is the first\ncomplete solution to decision-making in the presence of diverging user\nexpectations that is amenable to a classical planning compilation while\nsuccessfully combining previous works on explanation and explicability. We\nempirically show how our approach provides a computational advantage over\nexisting approximate approaches that unnecessarily try to search in the space\nof models while also failing to facilitate the full gamut of behaviors enabled\nby our framework.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 06:41:18 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 19:49:51 GMT"}, {"version": "v3", "created": "Mon, 11 Nov 2019 02:48:11 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Sreedharan", "Sarath", ""], ["Chakraborti", "Tathagata", ""], ["Muise", "Christian", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1903.07291", "submitter": "Ming-Yu Liu", "authors": "Taesung Park, Ming-Yu Liu, Ting-Chun Wang, Jun-Yan Zhu", "title": "Semantic Image Synthesis with Spatially-Adaptive Normalization", "comments": "Accepted as a CVPR 2019 oral paper", "journal-ref": "CVPR 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose spatially-adaptive normalization, a simple but effective layer for\nsynthesizing photorealistic images given an input semantic layout. Previous\nmethods directly feed the semantic layout as input to the deep network, which\nis then processed through stacks of convolution, normalization, and\nnonlinearity layers. We show that this is suboptimal as the normalization\nlayers tend to ``wash away'' semantic information. To address the issue, we\npropose using the input layout for modulating the activations in normalization\nlayers through a spatially-adaptive, learned transformation. Experiments on\nseveral challenging datasets demonstrate the advantage of the proposed method\nover existing approaches, regarding both visual fidelity and alignment with\ninput layouts. Finally, our model allows user control over both semantic and\nstyle. Code is available at https://github.com/NVlabs/SPADE .\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 08:12:23 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 15:41:27 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Park", "Taesung", ""], ["Liu", "Ming-Yu", ""], ["Wang", "Ting-Chun", ""], ["Zhu", "Jun-Yan", ""]]}, {"id": "1903.07299", "submitter": "Daniele Grattarola", "authors": "Daniele Zambon, Daniele Grattarola, Lorenzo Livi, Cesare Alippi", "title": "Autoregressive Models for Sequences of Graphs", "comments": "International Joint Conference on Neural Networks (IJCNN) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an autoregressive (AR) model for sequences of graphs,\nwhich generalises traditional AR models. A first novelty consists in\nformalising the AR model for a very general family of graphs, characterised by\na variable topology, and attributes associated with nodes and edges. A graph\nneural network (GNN) is also proposed to learn the AR function associated with\nthe graph-generating process (GGP), and subsequently predict the next graph in\na sequence. The proposed method is compared with four baselines on synthetic\nGGPs, denoting a significantly better performance on all considered problems.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 08:37:13 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Zambon", "Daniele", ""], ["Grattarola", "Daniele", ""], ["Livi", "Lorenzo", ""], ["Alippi", "Cesare", ""]]}, {"id": "1903.07400", "submitter": "Jingwei Zhang", "authors": "Jingwei Zhang, Niklas Wetzel, Nicolai Dorka, Joschka Boedecker and\n  Wolfram Burgard", "title": "Scheduled Intrinsic Drive: A Hierarchical Take on Intrinsically\n  Motivated Exploration", "comments": "A video of our experimental results can be found at\n  https://youtu.be/b0MbY3lUlEI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration in sparse reward reinforcement learning remains an open\nchallenge. Many state-of-the-art methods use intrinsic motivation to complement\nthe sparse extrinsic reward signal, giving the agent more opportunities to\nreceive feedback during exploration. Commonly these signals are added as bonus\nrewards, which results in a mixture policy that neither conducts exploration\nnor task fulfillment resolutely. In this paper, we instead learn separate\nintrinsic and extrinsic task policies and schedule between these different\ndrives to accelerate exploration and stabilize learning. Moreover, we introduce\na new type of intrinsic reward denoted as successor feature control (SFC),\nwhich is general and not task-specific. It takes into account statistics over\ncomplete trajectories and thus differs from previous methods that only use\nlocal information to evaluate intrinsic motivation. We evaluate our proposed\nscheduled intrinsic drive (SID) agent using three different environments with\npure visual inputs: VizDoom, DeepMind Lab and DeepMind Control Suite. The\nresults show a substantially improved exploration efficiency with SFC and the\nhierarchical usage of the intrinsic drives. A video of our experimental results\ncan be found at https://youtu.be/b0MbY3lUlEI.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 12:52:57 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 15:41:14 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Zhang", "Jingwei", ""], ["Wetzel", "Niklas", ""], ["Dorka", "Nicolai", ""], ["Boedecker", "Joschka", ""], ["Burgard", "Wolfram", ""]]}, {"id": "1903.07424", "submitter": "Yang Chen Mr", "authors": "Yang Chen, Xiaoyan Sun, Yaochu Jin", "title": "Communication-Efficient Federated Deep Learning with Asynchronous Model\n  Update and Temporally Weighted Aggregation", "comments": null, "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems, 2019", "doi": "10.1109/TNNLS.2019.2953131", "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning obtains a central model on the server by aggregating\nmodels trained locally on clients. As a result, federated learning does not\nrequire clients to upload their data to the server, thereby preserving the data\nprivacy of the clients. One challenge in federated learning is to reduce the\nclient-server communication since the end devices typically have very limited\ncommunication bandwidth. This paper presents an enhanced federated learning\ntechnique by proposing a synchronous learning strategy on the clients and a\ntemporally weighted aggregation of the local models on the server. In the\nasynchronous learning strategy, different layers of the deep neural networks\nare categorized into shallow and deeps layers and the parameters of the deep\nlayers are updated less frequently than those of the shallow layers.\nFurthermore, a temporally weighted aggregation strategy is introduced on the\nserver to make use of the previously trained local models, thereby enhancing\nthe accuracy and convergence of the central model. The proposed algorithm is\nempirically on two datasets with different deep neural networks. Our results\ndemonstrate that the proposed asynchronous federated deep learning outperforms\nthe baseline algorithm both in terms of communication cost and model accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 13:27:42 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Chen", "Yang", ""], ["Sun", "Xiaoyan", ""], ["Jin", "Yaochu", ""]]}, {"id": "1903.07456", "submitter": "Carlos Gershenson", "authors": "Carlos Gershenson, Vito Trianni, Justin Werfel, Hiroki Sayama", "title": "Self-Organization and Artificial Life", "comments": "24 pages, 1 figure, 1 table arXiv admin note: substantial text\n  overlap with arXiv:1804.01144", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO cs.AI cs.RO q-bio.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-organization can be broadly defined as the ability of a system to\ndisplay ordered spatio-temporal patterns solely as the result of the\ninteractions among the system components. Processes of this kind characterize\nboth living and artificial systems, making self-organization a concept that is\nat the basis of several disciplines, from physics to biology and engineering.\nPlaced at the frontiers between disciplines, Artificial Life (ALife) has\nheavily borrowed concepts and tools from the study of self-organization,\nproviding mechanistic interpretations of life-like phenomena as well as useful\nconstructivist approaches to artificial system design. Despite its broad usage\nwithin ALife, the concept of self-organization has been often excessively\nstretched or misinterpreted, calling for a clarification that could help with\ntracing the borders between what can and cannot be considered\nself-organization. In this review, we discuss the fundamental aspects of\nself-organization and list the main usages within three primary ALife domains,\nnamely \"soft\" (mathematical/computational modeling), \"hard\" (physical robots),\nand \"wet\" (chemical/biological systems) ALife. We also provide a classification\nto locate this research. Finally, we discuss the usefulness of\nself-organization and related concepts within ALife studies, point to\nperspectives and challenges for future research, and list open questions. We\nhope that this work will motivate discussions related to self-organization in\nALife and related fields.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 21:26:43 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 13:37:19 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Gershenson", "Carlos", ""], ["Trianni", "Vito", ""], ["Werfel", "Justin", ""], ["Sayama", "Hiroki", ""]]}, {"id": "1903.07534", "submitter": "Francesco Giannini", "authors": "Giuseppe Marra, Francesco Giannini, Michelangelo Diligenti and Marco\n  Gori", "title": "LYRICS: a General Interface Layer to Integrate Logic Inference and Deep\n  Learning", "comments": "To appear in proceedings of ECML PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of the amazing results obtained by deep learning in many\napplications, a real intelligent behavior of an agent acting in a complex\nenvironment is likely to require some kind of higher-level symbolic inference.\nTherefore, there is a clear need for the definition of a general and tight\nintegration between low-level tasks, processing sensorial data that can be\neffectively elaborated using deep learning techniques, and the logic reasoning\nthat allows humans to take decisions in complex environments. This paper\npresents LYRICS, a generic interface layer for AI, which is implemented in\nTersorFlow (TF). LYRICS provides an input language that allows to define\narbitrary First Order Logic (FOL) background knowledge. The predicates and\nfunctions of the FOL knowledge can be bound to any TF computational graph, and\nthe formulas are converted into a set of real-valued constraints, which\nparticipate to the overall optimization problem. This allows to learn the\nweights of the learners, under the constraints imposed by the prior knowledge.\nThe framework is extremely general as it imposes no restrictions in terms of\nwhich models or knowledge can be integrated. In this paper, we show the\ngenerality of the approach showing some use cases of the presented language,\nincluding model checking, supervised learning and collective classification.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 16:23:00 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 15:32:33 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Marra", "Giuseppe", ""], ["Giannini", "Francesco", ""], ["Diligenti", "Michelangelo", ""], ["Gori", "Marco", ""]]}, {"id": "1903.07557", "submitter": "Xiuqin Shang", "authors": "Xiuqin Shang and Dayong Shen and Fei-Yue Wang and Timo R. Nyberg", "title": "A Heuristic Algorithm for the Fabric Spreading and Cutting Problem in\n  Apparel Factories", "comments": "accepted by IEEE/CAA Journal of Automatica Sinica", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the fabric spreading and cutting problem in apparel factories. For\nthe sake of saving the material costs, the cutting requirement should be met\nexactly without producing additional garment components. For reducing the\nproduction costs, the number of lays that corresponds to the frequency of using\nthe cutting beds should be minimized. We propose an iterated greedy algorithm\nfor solving the fabric spreading and cutting problem. This algorithm contains a\nconstructive procedure and an improving loop. Firstly the constructive\nprocedure creates a set of lays in sequence, and then the improving loop tries\nto pick each lay from the lay set and rearrange the remaining lays into a\nsmaller lay set. The improving loop will run until it cannot obtain any small\nlay set or the time limit is due. The experiment results on 500 cases shows\nthat the proposed algorithm is effective and efficient.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 07:51:27 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Shang", "Xiuqin", ""], ["Shen", "Dayong", ""], ["Wang", "Fei-Yue", ""], ["Nyberg", "Timo R.", ""]]}, {"id": "1903.07593", "submitter": "Allan Jabri", "authors": "Xiaolong Wang, Allan Jabri, Alexei A. Efros", "title": "Learning Correspondence from the Cycle-Consistency of Time", "comments": "CVPR 2019 Oral. Project page: http://ajabri.github.io/timecycle", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a self-supervised method for learning visual correspondence from\nunlabeled video. The main idea is to use cycle-consistency in time as free\nsupervisory signal for learning visual representations from scratch. At\ntraining time, our model learns a feature map representation to be useful for\nperforming cycle-consistent tracking. At test time, we use the acquired\nrepresentation to find nearest neighbors across space and time. We demonstrate\nthe generalizability of the representation -- without finetuning -- across a\nrange of visual correspondence tasks, including video object segmentation,\nkeypoint tracking, and optical flow. Our approach outperforms previous\nself-supervised methods and performs competitively with strongly supervised\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 17:36:00 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 05:56:01 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Wang", "Xiaolong", ""], ["Jabri", "Allan", ""], ["Efros", "Alexei A.", ""]]}, {"id": "1903.07676", "submitter": "Ye Yu", "authors": "Ye Yu, Yingmin Li, Shuai Che, Niraj K. Jha, and Weifeng Zhang", "title": "Software-defined Design Space Exploration for an Efficient DNN\n  Accelerator Architecture", "comments": null, "journal-ref": null, "doi": "10.1109/TC.2020.2983694", "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been shown to outperform conventional\nmachine learning algorithms across a wide range of applications, e.g., image\nrecognition, object detection, robotics, and natural language processing.\nHowever, the high computational complexity of DNNs often necessitates extremely\nfast and efficient hardware. The problem gets worse as the size of neural\nnetworks grows exponentially. As a result, customized hardware accelerators\nhave been developed to accelerate DNN processing without sacrificing model\naccuracy. However, previous accelerator design studies have not fully\nconsidered the characteristics of the target applications, which may lead to\nsub-optimal architecture designs. On the other hand, new DNN models have been\ndeveloped for better accuracy, but their compatibility with the underlying\nhardware accelerator is often overlooked. In this article, we propose an\napplication-driven framework for architectural design space exploration of DNN\naccelerators. This framework is based on a hardware analytical model of\nindividual DNN operations. It models the accelerator design task as a\nmulti-dimensional optimization problem. We demonstrate that it can be\nefficaciously used in application-driven accelerator architecture design. Given\na target DNN, the framework can generate efficient accelerator design solutions\nwith optimized performance and area. Furthermore, we explore the opportunity to\nuse the framework for accelerator configuration optimization under simultaneous\ndiverse DNN applications. The framework is also capable of improving neural\nnetwork models to best fit the underlying hardware resources.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 19:03:50 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 20:44:29 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Yu", "Ye", ""], ["Li", "Yingmin", ""], ["Che", "Shuai", ""], ["Jha", "Niraj K.", ""], ["Zhang", "Weifeng", ""]]}, {"id": "1903.07765", "submitter": "Yao Hengshuai", "authors": "Borislav Mavrin, Hengshuai Yao, Linglong Kong", "title": "Deep Reinforcement Learning with Decorrelation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning an effective representation for high-dimensional data is a\nchallenging problem in reinforcement learning (RL). Deep reinforcement learning\n(DRL) such as Deep Q networks (DQN) achieves remarkable success in computer\ngames by learning deeply encoded representation from convolution networks. In\nthis paper, we propose a simple yet very effective method for representation\nlearning with DRL algorithms. Our key insight is that features learned by DRL\nalgorithms are highly correlated, which interferes with learning. By adding a\nregularized loss that penalizes correlation in latent features (with only\nslight computation), we decorrelate features represented by deep neural\nnetworks incrementally. On 49 Atari games, with the same regularization factor,\nour decorrelation algorithms perform $70\\%$ in terms of human-normalized\nscores, which is $40\\%$ better than DQN. In particular, ours performs better\nthan DQN on 39 games with 4 close ties and lost only slightly on $6$ games.\nEmpirical results also show that the decorrelation method applies to Quantile\nRegression DQN (QR-DQN) and significantly boosts performance. Further\nexperiments on the losing games show that our decorelation algorithms can win\nover DQN and QR-DQN with a fined tuned regularization factor.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 23:35:23 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 17:18:07 GMT"}, {"version": "v3", "created": "Wed, 8 May 2019 22:06:55 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Mavrin", "Borislav", ""], ["Yao", "Hengshuai", ""], ["Kong", "Linglong", ""]]}, {"id": "1903.07766", "submitter": "Devi Parikh", "authors": "X. Alice Li and Devi Parikh", "title": "Lemotif: An Affective Visual Journal Using Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Lemotif, an integrated natural language processing and image\ngeneration system that uses machine learning to (1) parse a text-based input\njournal entry describing the user's day for salient themes and emotions and (2)\nvisualize the detected themes and emotions in creative and appealing image\nmotifs. Synthesizing approaches from artificial intelligence and psychology,\nLemotif acts as an affective visual journal, encouraging users to regularly\nwrite and reflect on their daily experiences through visual reinforcement. By\nmaking patterns in emotions and their sources more apparent, Lemotif aims to\nhelp users better understand their emotional lives, identify opportunities for\naction, and track the effectiveness of behavioral changes over time. We verify\nvia human studies that prospective users prefer motifs generated by Lemotif\nover corresponding baselines, find the motifs representative of their journal\nentries, and think they would be more likely to journal regularly using a\nLemotif-based app.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 23:35:31 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 16:21:41 GMT"}, {"version": "v3", "created": "Wed, 1 Apr 2020 16:48:35 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Li", "X. Alice", ""], ["Parikh", "Devi", ""]]}, {"id": "1903.07826", "submitter": "Yong Liu Stephen", "authors": "Yong Liu, Yinan Zhang, Qiong Wu, Chunyan Miao, Lizhen Cui, Binqiang\n  Zhao, Yin Zhao, Lu Guan", "title": "Diversity-Promoting Deep Reinforcement Learning for Interactive\n  Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive recommendation that models the explicit interactions between\nusers and the recommender system has attracted a lot of research attentions in\nrecent years. Most previous interactive recommendation systems only focus on\noptimizing recommendation accuracy while overlooking other important aspects of\nrecommendation quality, such as the diversity of recommendation results. In\nthis paper, we propose a novel recommendation model, named\n\\underline{D}iversity-promoting \\underline{D}eep \\underline{R}einforcement\n\\underline{L}earning (D$^2$RL), which encourages the diversity of\nrecommendation results in interaction recommendations. More specifically, we\nadopt a Determinantal Point Process (DPP) model to generate diverse, while\nrelevant item recommendations. A personalized DPP kernel matrix is maintained\nfor each user, which is constructed from two parts: a fixed similarity matrix\ncapturing item-item similarity, and the relevance of items dynamically learnt\nthrough an actor-critic reinforcement learning framework. We performed\nextensive offline experiments as well as simulated online experiments with real\nworld datasets to demonstrate the effectiveness of the proposed model.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 04:38:05 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Liu", "Yong", ""], ["Zhang", "Yinan", ""], ["Wu", "Qiong", ""], ["Miao", "Chunyan", ""], ["Cui", "Lizhen", ""], ["Zhao", "Binqiang", ""], ["Zhao", "Yin", ""], ["Guan", "Lu", ""]]}, {"id": "1903.07837", "submitter": "Ryuta Arisaka", "authors": "Ryuta Arisaka", "title": "Turing-Completeness of Dynamics in Abstract Persuasion Argumentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract Persuasion Argumentation (APA) is a dynamic argumentation formalism\nthat extends Dung argumentation with persuasion relations. In this work, we\nshow through two-counter Minsky machine encoding that APA dynamics is\nTuring-complete.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 05:09:42 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Arisaka", "Ryuta", ""]]}, {"id": "1903.07860", "submitter": "Guangneng Hu", "authors": "Guangneng Hu", "title": "Personalized Neural Embeddings for Collaborative Filtering with Text", "comments": "NAACL 2019 short papers, oral presentation", "journal-ref": "NAACL 2019", "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering (CF) is a core technique for recommender systems.\nTraditional CF approaches exploit user-item relations (e.g., clicks, likes, and\nviews) only and hence they suffer from the data sparsity issue. Items are\nusually associated with unstructured text such as article abstracts and product\nreviews. We develop a Personalized Neural Embedding (PNE) framework to exploit\nboth interactions and words seamlessly. We learn such embeddings of users,\nitems, and words jointly, and predict user preferences on items based on these\nlearned representations. PNE estimates the probability that a user will like an\nitem by two terms---behavior factors and semantic factors. On two real-world\ndatasets, PNE shows better performance than four state-of-the-art baselines in\nterms of three metrics. We also show that PNE learns meaningful word embeddings\nby visualization.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 07:05:59 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Hu", "Guangneng", ""]]}, {"id": "1903.07940", "submitter": "Yuhui Wang", "authors": "Yuhui Wang, Hao He, Chao Wen, Xiaoyang Tan", "title": "Truly Proximal Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proximal policy optimization (PPO) is one of the most successful deep\nreinforcement-learning methods, achieving state-of-the-art performance across a\nwide range of challenging tasks. However, its optimization behavior is still\nfar from being fully understood. In this paper, we show that PPO could neither\nstrictly restrict the likelihood ratio as it attempts to do nor enforce a\nwell-defined trust region constraint, which means that it may still suffer from\nthe risk of performance instability. To address this issue, we present an\nenhanced PPO method, named Truly PPO. Two critical improvements are made in our\nmethod: 1) it adopts a new clipping function to support a rollback behavior to\nrestrict the difference between the new policy and the old one; 2) the\ntriggering condition for clipping is replaced with a trust region-based one,\nsuch that optimizing the resulted surrogate objective function provides\nguaranteed monotonic improvement of the ultimate policy performance. It seems,\nby adhering more truly to making the algorithm proximal - confining the policy\nwithin the trust region, the new algorithm improves the original PPO on both\nsample efficiency and performance.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 11:18:29 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 03:59:49 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Wang", "Yuhui", ""], ["He", "Hao", ""], ["Wen", "Chao", ""], ["Tan", "Xiaoyang", ""]]}, {"id": "1903.08066", "submitter": "Sambhav R. Jain", "authors": "Sambhav R. Jain, Albert Gural, Michael Wu, Chris H. Dick", "title": "Trained Quantization Thresholds for Accurate and Efficient Fixed-Point\n  Inference of Deep Neural Networks", "comments": "Link to Conference (Oral & Poster) Schedule -\n  https://mlsys.org/Conferences/2020/ScheduleMultitrack?event=1431", "journal-ref": "Proceedings of the 3rd Machine Learning and Systems (MLSys)\n  Conference, Austin, TX, USA, 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method of training quantization thresholds (TQT) for uniform\nsymmetric quantizers using standard backpropagation and gradient descent.\nContrary to prior work, we show that a careful analysis of the straight-through\nestimator for threshold gradients allows for a natural range-precision\ntrade-off leading to better optima. Our quantizers are constrained to use\npower-of-2 scale-factors and per-tensor scaling of weights and activations to\nmake it amenable for hardware implementations. We present analytical support\nfor the general robustness of our methods and empirically validate them on\nvarious CNNs for ImageNet classification. We are able to achieve\nnear-floating-point accuracy on traditionally difficult networks such as\nMobileNets with less than 5 epochs of quantized (8-bit) retraining. Finally, we\npresent Graffitist, a framework that enables automatic quantization of\nTensorFlow graphs for TQT (available at https://github.com/Xilinx/graffitist ).\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 15:50:24 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 06:24:16 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 18:21:29 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Jain", "Sambhav R.", ""], ["Gural", "Albert", ""], ["Wu", "Michael", ""], ["Dick", "Chris H.", ""]]}, {"id": "1903.08129", "submitter": "Hui Wang", "authors": "Hui Wang, Michael Emmerich, Mike Preuss, Aske Plaat", "title": "Hyper-Parameter Sweep on AlphaZero General", "comments": "19 pages 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since AlphaGo and AlphaGo Zero have achieved breakground successes in the\ngame of Go, the programs have been generalized to solve other tasks.\nSubsequently, AlphaZero was developed to play Go, Chess and Shogi. In the\nliterature, the algorithms are explained well. However, AlphaZero contains many\nparameters, and for neither AlphaGo, AlphaGo Zero nor AlphaZero, there is\nsufficient discussion about how to set parameter values in these algorithms.\nTherefore, in this paper, we choose 12 parameters in AlphaZero and evaluate how\nthese parameters contribute to training. We focus on three objectives~(training\nloss, time cost and playing strength). For each parameter, we train 3 models\nusing 3 different values~(minimum value, default value, maximum value). We use\nthe game of play 6$\\times$6 Othello, on the AlphaZeroGeneral open source\nre-implementation of AlphaZero. Overall, experimental results show that\ndifferent values can lead to different training results, proving the importance\nof such a parameter sweep. We categorize these 12 parameters into\ntime-sensitive parameters and time-friendly parameters. Moreover, through\nmulti-objective analysis, this paper provides an insightful basis for further\nhyper-parameter optimization.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 17:38:46 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Wang", "Hui", ""], ["Emmerich", "Michael", ""], ["Preuss", "Mike", ""], ["Plaat", "Aske", ""]]}, {"id": "1903.08218", "submitter": "Sarath Sreedharan", "authors": "Sarath Sreedharan, Siddharth Srivastava, David Smith, Subbarao\n  Kambhampati", "title": "Why Couldn't You do that? Explaining Unsolvability of Classical Planning\n  Problems in the Presence of Plan Advice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable planning is widely accepted as a prerequisite for autonomous\nagents to successfully work with humans. While there has been a lot of research\non generating explanations of solutions to planning problems, explaining the\nabsence of solutions remains an open and under-studied problem, even though\nsuch situations can be the hardest to understand or debug. In this paper, we\nshow that hierarchical abstractions can be used to efficiently generate reasons\nfor unsolvability of planning problems. In contrast to related work on\ncomputing certificates of unsolvability, we show that these methods can\ngenerate compact, human-understandable reasons for unsolvability. Empirical\nanalysis and user studies show the validity of our methods as well as their\ncomputational efficacy on a number of benchmark planning domains.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 19:08:32 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Sreedharan", "Sarath", ""], ["Srivastava", "Siddharth", ""], ["Smith", "David", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1903.08254", "submitter": "Kate Rakelly", "authors": "Kate Rakelly, Aurick Zhou, Deirdre Quillen, Chelsea Finn, Sergey\n  Levine", "title": "Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic\n  Context Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning algorithms require large amounts of experience to\nlearn an individual task. While in principle meta-reinforcement learning\n(meta-RL) algorithms enable agents to learn new skills from small amounts of\nexperience, several major challenges preclude their practicality. Current\nmethods rely heavily on on-policy experience, limiting their sample efficiency.\nThe also lack mechanisms to reason about task uncertainty when adapting to new\ntasks, limiting their effectiveness in sparse reward problems. In this paper,\nwe address these challenges by developing an off-policy meta-RL algorithm that\ndisentangles task inference and control. In our approach, we perform online\nprobabilistic filtering of latent task variables to infer how to solve a new\ntask from small amounts of experience. This probabilistic interpretation\nenables posterior sampling for structured and efficient exploration. We\ndemonstrate how to integrate these task variables with off-policy RL algorithms\nto achieve both meta-training and adaptation efficiency. Our method outperforms\nprior algorithms in sample efficiency by 20-100X as well as in asymptotic\nperformance on several meta-RL benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 20:51:04 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Rakelly", "Kate", ""], ["Zhou", "Aurick", ""], ["Quillen", "Deirdre", ""], ["Finn", "Chelsea", ""], ["Levine", "Sergey", ""]]}, {"id": "1903.08309", "submitter": "Chris Paxton", "authors": "Chris Paxton, Yonatan Bisk, Jesse Thomason, Arunkumar Byravan, Dieter\n  Fox", "title": "Prospection: Interpretable Plans From Language By Predicting the Future", "comments": "Accepted to ICRA 2019; extended version with appendix containing\n  additional results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-level human instructions often correspond to behaviors with multiple\nimplicit steps. In order for robots to be useful in the real world, they must\nbe able to to reason over both motions and intermediate goals implied by human\ninstructions. In this work, we propose a framework for learning representations\nthat convert from a natural-language command to a sequence of intermediate\ngoals for execution on a robot. A key feature of this framework is prospection,\ntraining an agent not just to correctly execute the prescribed command, but to\npredict a horizon of consequences of an action before taking it. We demonstrate\nthe fidelity of plans generated by our framework when interpreting real,\ncrowd-sourced natural language commands for a robot in simulated scenes.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 01:52:37 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Paxton", "Chris", ""], ["Bisk", "Yonatan", ""], ["Thomason", "Jesse", ""], ["Byravan", "Arunkumar", ""], ["Fox", "Dieter", ""]]}, {"id": "1903.08322", "submitter": "Tushant Jha", "authors": "Tushant Jha, Yair Zick", "title": "A Learning Framework for Distribution-Based Game-Theoretic Solution\n  Concepts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past few years have seen several works on learning economic solutions\nfrom data; these include optimal auction design, function optimization, stable\npayoffs in cooperative games and more. In this work, we provide a unified\nlearning-theoretic methodology for modeling such problems, and establish tools\nfor determining whether a given economic solution concept can be learned from\ndata. Our learning theoretic framework generalizes a notion of function space\ndimension -- the graph dimension -- adapting it to the solution concept\nlearning domain. We identify sufficient conditions for the PAC learnability of\nsolution concepts, and show that results in existing works can be immediately\nderived using our methodology. Finally, we apply our methods in other economic\ndomains, yielding a novel notion of PAC competitive equilibrium and PAC\nCondorcet winners.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 02:39:50 GMT"}, {"version": "v2", "created": "Sun, 16 Jun 2019 23:20:32 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Jha", "Tushant", ""], ["Zick", "Yair", ""]]}, {"id": "1903.08329", "submitter": "Shahin Shahrampour", "authors": "Shahin Shahrampour, Soheil Kolouri", "title": "On Sampling Random Features From Empirical Leverage Scores:\n  Implementation and Theoretical Guarantees", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random features provide a practical framework for large-scale kernel\napproximation and supervised learning. It has been shown that data-dependent\nsampling of random features using leverage scores can significantly reduce the\nnumber of features required to achieve optimal learning bounds. Leverage scores\nintroduce an optimized distribution for features based on an\ninfinite-dimensional integral operator (depending on input distribution), which\nis impractical to sample from. Focusing on empirical leverage scores in this\npaper, we establish an out-of-sample performance bound, revealing an\ninteresting trade-off between the approximated kernel and the eigenvalue decay\nof another kernel in the domain of random features defined based on data\ndistribution. Our experiments verify that the empirical algorithm consistently\noutperforms vanilla Monte Carlo sampling, and with a minor modification the\nmethod is even competitive to supervised data-dependent kernel learning,\nwithout using the output (label) information.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 03:41:01 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Shahrampour", "Shahin", ""], ["Kolouri", "Soheil", ""]]}, {"id": "1903.08389", "submitter": "Christina Lioma Assoc. Prof", "authors": "Dongsheng Wang, Quichi Li, Lucas Chaves Lima, Jakob grue Simonsen,\n  Christina Lioma", "title": "Contextual Compositionality Detection with External Knowledge Bases\n  andWord Embeddings", "comments": "WWW '19 Companion, May 13-17, 2019, San Francisco, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When the meaning of a phrase cannot be inferred from the individual meanings\nof its words (e.g., hot dog), that phrase is said to be non-compositional.\nAutomatic compositionality detection in multi-word phrases is critical in any\napplication of semantic processing, such as search engines; failing to detect\nnon-compositional phrases can hurt system effectiveness notably. Existing\nresearch treats phrases as either compositional or non-compositional in a\ndeterministic manner. In this paper, we operationalize the viewpoint that\ncompositionality is contextual rather than deterministic, i.e., that whether a\nphrase is compositional or non-compositional depends on its context. For\nexample, the phrase `green card' is compositional when referring to a green\ncolored card, whereas it is non-compositional when meaning permanent residence\nauthorization. We address the challenge of detecting this type of contextual\ncompositionality as follows: given a multi-word phrase, we enrich the word\nembedding representing its semantics with evidence about its global context\n(terms it often collocates with) as well as its local context (narratives where\nthat phrase is used, which we call usage scenarios). We further extend this\nrepresentation with information extracted from external knowledge bases. The\nresulting representation incorporates both localized context and more general\nusage of the phrase and allows to detect its compositionality in a\nnon-deterministic and contextual way. Empirical evaluation of our model on a\ndataset of phrase compositionality, manually collected by crowdsourcing\ncontextual compositionality assessments, shows that our model outperforms\nstate-of-the-art baselines notably on detecting phrase compositionality.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 08:53:05 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Wang", "Dongsheng", ""], ["Li", "Quichi", ""], ["Lima", "Lucas Chaves", ""], ["Simonsen", "Jakob grue", ""], ["Lioma", "Christina", ""]]}, {"id": "1903.08412", "submitter": "Sumanta Das Dr", "authors": "Sumanta Kumar Das", "title": "Modeling Intelligent Decision Making Command And Control Agents: An\n  Application to Air Defense", "comments": null, "journal-ref": "IEEE Intelligent system, sept/oct 2014", "doi": "10.1109/MIS.2013.71", "report-no": null, "categories": "cs.AI stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper is a half-way between the agent technology and the mathematical\nreasoning to model tactical decision making tasks. These models are applied to\nair defense (AD) domain for command and control (C2). It also addresses the\nissues related to evaluation of agents. The agents are designed and implemented\nusing the agent-programming paradigm. The agents are deployed in an air combat\nsimulated environment for performing the tasks of C2 like electronic counter\ncounter measures, threat assessment, and weapon allocation. The simulated AD\nsystem runs without any human intervention, and represents state-of-the-art\nmodel for C2 autonomy. The use of agents as autonomous decision making entities\nis particularly useful in view of futuristic network centric warfare.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 09:52:17 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Das", "Sumanta Kumar", ""]]}, {"id": "1903.08428", "submitter": "Nils Jansen", "authors": "Steven Carr, Nils Jansen, Ralf Wimmer, Alexandru C. Serban, Bernd\n  Becker, Ufuk Topcu", "title": "Counterexample-Guided Strategy Improvement for POMDPs Using Recurrent\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study strategy synthesis for partially observable Markov decision\nprocesses (POMDPs). The particular problem is to determine strategies that\nprovably adhere to (probabilistic) temporal logic constraints. This problem is\ncomputationally intractable and theoretically hard. We propose a novel method\nthat combines techniques from machine learning and formal verification. First,\nwe train a recurrent neural network (RNN) to encode POMDP strategies. The RNN\naccounts for memory-based decisions without the need to expand the full belief\nspace of a POMDP. Secondly, we restrict the RNN-based strategy to represent a\nfinite-memory strategy and implement it on a specific POMDP. For the resulting\nfinite Markov chain, efficient formal verification techniques provide provable\nguarantees against temporal logic specifications. If the specification is not\nsatisfied, counterexamples supply diagnostic information. We use this\ninformation to improve the strategy by iteratively training the RNN. Numerical\nexperiments show that the proposed method elevates the state of the art in\nPOMDP solving by up to three orders of magnitude in terms of solving times and\nmodel sizes.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 10:40:54 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 13:24:02 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Carr", "Steven", ""], ["Jansen", "Nils", ""], ["Wimmer", "Ralf", ""], ["Serban", "Alexandru C.", ""], ["Becker", "Bernd", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1903.08452", "submitter": "Jerry Lonlac", "authors": "Jerry Lonlac, Sa\\\"idd Jabbour, Engelbert Mephu Nguifo, Lakhdar Sa\\\"is,\n  Badran Raddaoui", "title": "Extracting Frequent Gradual Patterns Using Constraints Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a constraint-based modeling approach for the\nproblem of discovering frequent gradual patterns in a numerical dataset. This\nSAT-based declarative approach offers an additional possibility to benefit from\nthe recent progress in satisfiability testing and to exploit the efficiency of\nmodern SAT solvers for enumerating all frequent gradual patterns in a numerical\ndataset. Our approach can easily be extended with extra constraints, such as\ntemporal constraints in order to extract more specific patterns in a broad\nrange of gradual patterns mining applications. We show the practical\nfeasibility of our SAT model by running experiments on two real world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 11:33:02 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Lonlac", "Jerry", ""], ["Jabbour", "Sa\u00efdd", ""], ["Nguifo", "Engelbert Mephu", ""], ["Sa\u00efs", "Lakhdar", ""], ["Raddaoui", "Badran", ""]]}, {"id": "1903.08495", "submitter": "Elena Stamm", "authors": "Andreas Christ, Franz Quint (eds.)", "title": "Artificial Intelligence : from Research to Application ; the Upper-Rhine\n  Artificial Intelligence Symposium (UR-AI 2019)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The TriRhenaTech alliance universities and their partners presented their\ncompetences in the field of artificial intelligence and their cross-border\ncooperations with the industry at the tri-national conference 'Artificial\nIntelligence : from Research to Application' on March 13th, 2019 in Offenburg.\nThe TriRhenaTech alliance is a network of universities in the Upper Rhine\nTrinational Metropolitan Region comprising of the German universities of\napplied sciences in Furtwangen, Kaiserslautern, Karlsruhe, and Offenburg, the\nBaden-Wuerttemberg Cooperative State University Loerrach, the French university\nnetwork Alsace Tech (comprised of 14 'grandes \\'ecoles' in the fields of\nengineering, architecture and management) and the University of Applied\nSciences and Arts Northwestern Switzerland. The alliance's common goal is to\nreinforce the transfer of knowledge, research, and technology, as well as the\ncross-border mobility of students.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 13:18:15 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Christ", "Andreas", "", "eds."], ["Quint", "Franz", "", "eds."]]}, {"id": "1903.08523", "submitter": "Aaron Sterling", "authors": "Aaron Sterling", "title": "Ontology of Card Sleights", "comments": "8 pages. Preprint. Final version appeared in ICSC 2019. Copyright of\n  final version is held by IEEE", "journal-ref": "IEEE 14th International Conference on Semantic Computing (ICSC),\n  February 2019, pp. 263-270", "doi": "10.1109/ICOSC.2019.8665514", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a machine-readable movement writing for sleight-of-hand moves with\ncards -- a \"Labanotation of card magic.\" This scheme of movement writing\ncontains 440 categories of motion, and appears to taxonomize all card sleights\nthat have appeared in over 1500 publications. The movement writing is\naxiomatized in $\\mathcal{SROIQ}$(D) Description Logic, and collected formally\nas an Ontology of Card Sleights, a computational ontology that extends the\nBasic Formal Ontology and the Information Artifact Ontology. The Ontology of\nCard Sleights is implemented in OWL DL, a Description Logic fragment of the Web\nOntology Language. While ontologies have historically been used to classify at\na less granular level, the algorithmic nature of card tricks allows us to\ntranscribe a performer's actions step by step. We conclude by discussing design\ncriteria we have used to ensure the ontology can be accessed and modified with\na simple click-and-drag interface. This may allow database searches and\nperformance transcriptions by users with card magic knowledge, but no ontology\nbackground.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 14:35:16 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Sterling", "Aaron", ""]]}, {"id": "1903.08606", "submitter": "Yao Hengshuai", "authors": "Nazmus Sakib, Hengshuai Yao, Hong Zhang, Shangling Jui", "title": "Single-step Options for Adversary Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we use reinforcement learning for safety driving in adversary\nsettings. In our work, the knowledge in state-of-art planning methods is reused\nby single-step options whose action suggestions are compared in parallel with\nprimitive actions. We show two advantages by doing so. First, training this\nreinforcement learning agent is easier and faster than training the\nprimitive-action agent. Second, our new agent outperforms the primitive-action\nreinforcement learning agent, human testers as well as the state-of-art\nplanning methods that our agent queries as skill options.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 16:39:28 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 18:56:07 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Sakib", "Nazmus", ""], ["Yao", "Hengshuai", ""], ["Zhang", "Hong", ""], ["Jui", "Shangling", ""]]}, {"id": "1903.08671", "submitter": "Rahaf Aljundi", "authors": "Rahaf Aljundi, Min Lin, Baptiste Goujaud and Yoshua Bengio", "title": "Gradient based sample selection for online continual learning", "comments": "Neurips 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A continual learning agent learns online with a non-stationary and\nnever-ending stream of data. The key to such learning process is to overcome\nthe catastrophic forgetting of previously seen data, which is a well known\nproblem of neural networks. To prevent forgetting, a replay buffer is usually\nemployed to store the previous data for the purpose of rehearsal. Previous\nworks often depend on task boundary and i.i.d. assumptions to properly select\nsamples for the replay buffer. In this work, we formulate sample selection as a\nconstraint reduction problem based on the constrained optimization view of\ncontinual learning. The goal is to select a fixed subset of constraints that\nbest approximate the feasible region defined by the original constraints. We\nshow that it is equivalent to maximizing the diversity of samples in the replay\nbuffer with parameters gradient as the feature. We further develop a greedy\nalternative that is cheap and efficient. The advantage of the proposed method\nis demonstrated by comparing to other alternatives under the continual learning\nsetting. Further comparisons are made against state of the art methods that\nrely on task boundaries which show comparable or even better results for our\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 18:01:55 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 13:20:35 GMT"}, {"version": "v3", "created": "Mon, 24 Jun 2019 09:00:19 GMT"}, {"version": "v4", "created": "Tue, 16 Jul 2019 15:52:08 GMT"}, {"version": "v5", "created": "Thu, 31 Oct 2019 14:45:47 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Aljundi", "Rahaf", ""], ["Lin", "Min", ""], ["Goujaud", "Baptiste", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1903.08693", "submitter": "Constantinos Chamzas", "authors": "Constantinos Chamzas, Anshumali Shrivastava, Lydia E. Kavraki", "title": "Using Local Experiences for Global Motion Planning", "comments": "6 pages, to appear in International Conference on Robotics and\n  Automation (ICRA), 2019", "journal-ref": "ICRA, 2019, 8606--8612", "doi": "10.1109/ICRA.2019.8794317", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sampling-based planners are effective in many real-world applications such as\nrobotics manipulation, navigation, and even protein modeling. However, it is\noften challenging to generate a collision-free path in environments where key\nareas are hard to sample. In the absence of any prior information,\nsampling-based planners are forced to explore uniformly or heuristically, which\ncan lead to degraded performance. One way to improve performance is to use\nprior knowledge of environments to adapt the sampling strategy to the problem\nat hand. In this work, we decompose the workspace into local primitives,\nmemorizing local experiences by these primitives in the form of local samplers,\nand store them in a database. We synthesize an efficient global sampler by\nretrieving local experiences relevant to the given situation. Our method\ntransfers knowledge effectively between diverse environments that share local\nprimitives and speeds up the performance dramatically. Our results show, in\nterms of solution time, an improvement of multiple orders of magnitude in two\ntraditionally challenging high-dimensional problems compared to\nstate-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 18:47:36 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Chamzas", "Constantinos", ""], ["Shrivastava", "Anshumali", ""], ["Kavraki", "Lydia E.", ""]]}, {"id": "1903.08738", "submitter": "Hoang M. Le", "authors": "Hoang M. Le, Cameron Voloshin, Yisong Yue", "title": "Batch Policy Learning under Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When learning policies for real-world domains, two important questions arise:\n(i) how to efficiently use pre-collected off-policy, non-optimal behavior data;\nand (ii) how to mediate among different competing objectives and constraints.\nWe thus study the problem of batch policy learning under multiple constraints,\nand offer a systematic solution. We first propose a flexible meta-algorithm\nthat admits any batch reinforcement learning and online learning procedure as\nsubroutines. We then present a specific algorithmic instantiation and provide\nperformance guarantees for the main objective and all constraints. To certify\nconstraint satisfaction, we propose a new and simple method for off-policy\npolicy evaluation (OPE) and derive PAC-style bounds. Our algorithm achieves\nstrong empirical results in different domains, including in a challenging\nproblem of simulated car driving subject to multiple constraints such as lane\nkeeping and smooth driving. We also show experimentally that our OPE method\noutperforms other popular OPE techniques on a standalone basis, especially in a\nhigh-dimensional setting.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 21:01:22 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Le", "Hoang M.", ""], ["Voloshin", "Cameron", ""], ["Yue", "Yisong", ""]]}, {"id": "1903.08772", "submitter": "Jaroslav Vitku", "authors": "Jaroslav V\\'itk\\r{u}, Petr Dluho\\v{s}, Joseph Davidson, Mat\\v{e}j\n  Nikl, Simon Andersson, P\\v{r}emysl Pa\\v{s}ka, Jan \\v{S}inkora, Petr\n  Hlubu\\v{c}ek, Martin Str\\'ansk\\'y, Martin Hyben, Martin Poliak, Jan\n  Feyereisl, Marek Rosa", "title": "ToyArchitecture: Unsupervised Learning of Interpretable Models of the\n  World", "comments": "Revision: changed the pdftitle", "journal-ref": null, "doi": "10.1371/journal.pone.0230432", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Research in Artificial Intelligence (AI) has focused mostly on two extremes:\neither on small improvements in narrow AI domains, or on universal theoretical\nframeworks which are usually uncomputable, incompatible with theories of\nbiological intelligence, or lack practical implementations. The goal of this\nwork is to combine the main advantages of the two: to follow a big picture\nview, while providing a particular theory and its implementation. In contrast\nwith purely theoretical approaches, the resulting architecture should be usable\nin realistic settings, but also form the core of a framework containing all the\nbasic mechanisms, into which it should be easier to integrate additional\nrequired functionality.\n  In this paper, we present a novel, purposely simple, and interpretable\nhierarchical architecture which combines multiple different mechanisms into one\nsystem: unsupervised learning of a model of the world, learning the influence\nof one's own actions on the world, model-based reinforcement learning,\nhierarchical planning and plan execution, and symbolic/sub-symbolic integration\nin general. The learned model is stored in the form of hierarchical\nrepresentations with the following properties: 1) they are increasingly more\nabstract, but can retain details when needed, and 2) they are easy to\nmanipulate in their local and symbolic-like form, thus also allowing one to\nobserve the learning process at each level of abstraction. On all levels of the\nsystem, the representation of the data can be interpreted in both a symbolic\nand a sub-symbolic manner. This enables the architecture to learn efficiently\nusing sub-symbolic methods and to employ symbolic inference.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 23:07:12 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 21:47:29 GMT"}, {"version": "v3", "created": "Wed, 9 Sep 2020 07:54:19 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["V\u00edtk\u016f", "Jaroslav", ""], ["Dluho\u0161", "Petr", ""], ["Davidson", "Joseph", ""], ["Nikl", "Mat\u011bj", ""], ["Andersson", "Simon", ""], ["Pa\u0161ka", "P\u0159emysl", ""], ["\u0160inkora", "Jan", ""], ["Hlubu\u010dek", "Petr", ""], ["Str\u00e1nsk\u00fd", "Martin", ""], ["Hyben", "Martin", ""], ["Poliak", "Martin", ""], ["Feyereisl", "Jan", ""], ["Rosa", "Marek", ""]]}, {"id": "1903.08816", "submitter": "Haozhen Zhao", "authors": "Christian J. Mahoney, Nathaniel Huber-Fliflet, Katie Jensen, Haozhen\n  Zhao, Robert Neary, Shi Ye", "title": "Empirical Evaluations of Seed Set Selection Strategies for Predictive\n  Coding", "comments": "2018 IEEE International Conference on Big Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training documents have a significant impact on the performance of predictive\nmodels in the legal domain. Yet, there is limited research that explores the\neffectiveness of the training document selection strategy - in particular, the\nstrategy used to select the seed set, or the set of documents an attorney\nreviews first to establish an initial model. Since there is limited research on\nthis important component of predictive coding, the authors of this paper set\nout to identify strategies that consistently perform well. Our research\ndemonstrated that the seed set selection strategy can have a significant impact\non the precision of a predictive model. Enabling attorneys with the results of\nthis study will allow them to initiate the most effective predictive modeling\nprocess to comb through the terabytes of data typically present in modern\nlitigation. This study used documents from four actual legal cases to evaluate\neight different seed set selection strategies. Attorneys can use the results\ncontained within this paper to enhance their approach to predictive coding.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 03:04:30 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Mahoney", "Christian J.", ""], ["Huber-Fliflet", "Nathaniel", ""], ["Jensen", "Katie", ""], ["Zhao", "Haozhen", ""], ["Neary", "Robert", ""], ["Ye", "Shi", ""]]}, {"id": "1903.08894", "submitter": "Joshua Achiam", "authors": "Joshua Achiam, Ethan Knight, Pieter Abbeel", "title": "Towards Characterizing Divergence in Deep Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Q-Learning (DQL), a family of temporal difference algorithms for\ncontrol, employs three techniques collectively known as the `deadly triad' in\nreinforcement learning: bootstrapping, off-policy learning, and function\napproximation. Prior work has demonstrated that together these can lead to\ndivergence in Q-learning algorithms, but the conditions under which divergence\noccurs are not well-understood. In this note, we give a simple analysis based\non a linear approximation to the Q-value updates, which we believe provides\ninsight into divergence under the deadly triad. The central point in our\nanalysis is to consider when the leading order approximation to the deep-Q\nupdate is or is not a contraction in the sup norm. Based on this analysis, we\ndevelop an algorithm which permits stable deep Q-learning for continuous\ncontrol without any of the tricks conventionally used (such as target networks,\nadaptive gradient optimizers, or using multiple Q functions). We demonstrate\nthat our algorithm performs above or near state-of-the-art on standard MuJoCo\nbenchmarks from the OpenAI Gym.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 09:42:41 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Achiam", "Joshua", ""], ["Knight", "Ethan", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1903.08942", "submitter": "Dennis Soemers", "authors": "Dennis J. N. J. Soemers, \\'Eric Piette and Cameron Browne", "title": "Biasing MCTS with Features for General Games", "comments": "Accepted at IEEE CEC 2019, Special Session on Games. Copyright of\n  final version held by IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes using a linear function approximator, rather than a deep\nneural network (DNN), to bias a Monte Carlo tree search (MCTS) player for\ngeneral games. This is unlikely to match the potential raw playing strength of\nDNNs, but has advantages in terms of generality, interpretability and resources\n(time and hardware) required for training. Features describing local patterns\nare used as inputs. The features are formulated in such a way that they are\neasily interpretable and applicable to a wide range of general games, and might\nencode simple local strategies. We gradually create new features during the\nsame self-play training process used to learn feature weights. We evaluate the\nplaying strength of an MCTS player biased by learnt features against a standard\nupper confidence bounds for trees (UCT) player in multiple different board\ngames, and demonstrate significantly improved playing strength in the majority\nof them after a small number of self-play training games.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 12:09:27 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Soemers", "Dennis J. N. J.", ""], ["Piette", "\u00c9ric", ""], ["Browne", "Cameron", ""]]}, {"id": "1903.08948", "submitter": "Wen Zhang", "authors": "Wen Zhang, Bibek Paudel, Liang Wang, Jiaoyan Chen, Hai Zhu, Wei Zhang,\n  Abraham Bernstein and Huajun Chen", "title": "Iteratively Learning Embeddings and Rules for Knowledge Graph Reasoning", "comments": "This paper is accepted by WWW'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning is essential for the development of large knowledge graphs,\nespecially for completion, which aims to infer new triples based on existing\nones. Both rules and embeddings can be used for knowledge graph reasoning and\nthey have their own advantages and difficulties. Rule-based reasoning is\naccurate and explainable but rule learning with searching over the graph always\nsuffers from efficiency due to huge search space. Embedding-based reasoning is\nmore scalable and efficient as the reasoning is conducted via computation\nbetween embeddings, but it has difficulty learning good representations for\nsparse entities because a good embedding relies heavily on data richness. Based\non this observation, in this paper we explore how embedding and rule learning\ncan be combined together and complement each other's difficulties with their\nadvantages. We propose a novel framework IterE iteratively learning embeddings\nand rules, in which rules are learned from embeddings with proper pruning\nstrategy and embeddings are learned from existing triples and new triples\ninferred by rules. Evaluations on embedding qualities of IterE show that rules\nhelp improve the quality of sparse entity embeddings and their link prediction\nresults. We also evaluate the efficiency of rule learning and quality of rules\nfrom IterE compared with AMIE+, showing that IterE is capable of generating\nhigh quality rules more efficiently. Experiments show that iteratively learning\nembeddings and rules benefit each other during learning and prediction.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 12:26:44 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Zhang", "Wen", ""], ["Paudel", "Bibek", ""], ["Wang", "Liang", ""], ["Chen", "Jiaoyan", ""], ["Zhu", "Hai", ""], ["Zhang", "Wei", ""], ["Bernstein", "Abraham", ""], ["Chen", "Huajun", ""]]}, {"id": "1903.08960", "submitter": "Lukas Hoyer", "authors": "Lukas Hoyer, Patrick Kesper, Anna Khoreva and Volker Fischer", "title": "Short-Term Prediction and Multi-Camera Fusion on Semantic Grids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An environment representation (ER) is a substantial part of every autonomous\nsystem. It introduces a common interface between perception and other system\ncomponents, such as decision making, and allows downstream algorithms to deal\nwith abstracted data without knowledge of the used sensor. In this work, we\npropose and evaluate a novel architecture that generates an egocentric,\ngrid-based, predictive, and semantically-interpretable ER. In particular, we\nprovide a proof of concept for the spatio-temporal fusion of multiple camera\nsequences and short-term prediction in such an ER. Our design utilizes a strong\nsemantic segmentation network together with depth and egomotion estimates to\nfirst extract semantic information from multiple camera streams and then\ntransform these separately into egocentric temporally-aligned bird's-eye view\ngrids. A deep encoder-decoder network is trained to fuse a stack of these grids\ninto a unified semantic grid representation and to predict the dynamics of its\nsurrounding. We evaluate this representation on real-world sequences of the\nCityscapes dataset and show that our architecture can make accurate predictions\nin complex sensor fusion scenarios and significantly outperforms a model-driven\nbaseline in a category-based evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 12:49:31 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 18:31:06 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Hoyer", "Lukas", ""], ["Kesper", "Patrick", ""], ["Khoreva", "Anna", ""], ["Fischer", "Volker", ""]]}, {"id": "1903.09012", "submitter": "Umberto Straccia", "authors": "Faranak Sobhani and Umberto Straccia", "title": "Towards a Forensic Event Ontology to Assist Video Surveillance-based\n  Vandalism Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection and representation of events is a critical element in automated\nsurveillance systems. We present here an ontology for representing complex\nsemantic events to assist video surveillance-based vandalism detection. The\nontology contains the definition of a rich and articulated event vocabulary\nthat is aimed at aiding forensic analysis to objectively identify and represent\ncomplex events. Our ontology has then been applied in the context of London\nRiots, which took place in 2011. We report also on the experiments conducted to\nsupport the classification of complex criminal events from video data.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 14:03:59 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Sobhani", "Faranak", ""], ["Straccia", "Umberto", ""]]}, {"id": "1903.09025", "submitter": "Maali Mnasri", "authors": "Maali Mnasri", "title": "Recent advances in conversational NLP : Towards the standardization of\n  Chatbot building", "comments": "8 pages with references, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue systems have become recently essential in our life. Their use is\ngetting more and more fluid and easy throughout the time. This boils down to\nthe improvements made in NLP and AI fields. In this paper, we try to provide an\noverview to the current state of the art of dialogue systems, their categories\nand the different approaches to build them. We end up with a discussion that\ncompares all the techniques and analyzes the strengths and weaknesses of each.\nFinally, we present an opinion piece suggesting to orientate the research\ntowards the standardization of dialogue systems building.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 14:30:55 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Mnasri", "Maali", ""]]}, {"id": "1903.09035", "submitter": "Marie-El\\'eonore Kessaci", "authors": "Lucien Mousin, Marie-El\\'eonore Kessaci, Clarisse Dhaenens", "title": "Exploiting Promising Sub-Sequences of Jobs to solve the No-Wait Flowshop\n  Scheduling Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The no-wait flowshop scheduling problem is a variant of the classical\npermutation flowshop problem, with the additional constraint that jobs have to\nbe processed by the successive machines without waiting time. To efficiently\naddress this NP-hard combinatorial optimization problem we conduct an analysis\nof the structure of good quality solutions. This analysis shows that the\nNo-Wait specificity gives them a common structure: they share identical\nsub-sequences of jobs, we call super-jobs. After a discussion on the way to\nidentify these super-jobs, we propose IG-SJ, an algorithm that exploits\nsuper-jobs within the state-of-the-art algorithm for the classical permutation\nflowshop, the well-known Iterated Greedy (IG) algorithm. An iterative approach\nof IG-SJ is also proposed. Experiments are conducted on Taillard's instances.\nThe experimental results show that exploiting super-jobs is successful since\nIG-SJ is able to find 64 new best solutions.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 14:48:00 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Mousin", "Lucien", ""], ["Kessaci", "Marie-El\u00e9onore", ""], ["Dhaenens", "Clarisse", ""]]}, {"id": "1903.09097", "submitter": "Lukas Folle", "authors": "Lukas Folle, Sulaiman Vesal, Nishant Ravikumar, Andreas Maier", "title": "Dilated deeply supervised networks for hippocampus segmentation in MRI", "comments": "BVM 2019 conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tissue loss in the hippocampi has been heavily correlated with the\nprogression of Alzheimer's Disease (AD). The shape and structure of the\nhippocampus are important factors in terms of early AD diagnosis and prognosis\nby clinicians. However, manual segmentation of such subcortical structures in\nMR studies is a challenging and subjective task. In this paper, we investigate\nvariants of the well known 3D U-Net, a type of convolution neural network (CNN)\nfor semantic segmentation tasks. We propose an alternative form of the 3D\nU-Net, which uses dilated convolutions and deep supervision to incorporate\nmulti-scale information into the model. The proposed method is evaluated on the\ntask of hippocampus head and body segmentation in an MRI dataset, provided as\npart of the MICCAI 2018 segmentation decathlon challenge. The experimental\nresults show that our approach outperforms other conventional methods in terms\nof different segmentation accuracy metrics.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 15:14:27 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Folle", "Lukas", ""], ["Vesal", "Sulaiman", ""], ["Ravikumar", "Nishant", ""], ["Maier", "Andreas", ""]]}, {"id": "1903.09171", "submitter": "Unai Garciarena", "authors": "Unai Garciarena, Alexander Mendiburu, and Roberto Santana", "title": "Towards automatic construction of multi-network models for heterogeneous\n  multi-task learning", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning, as it is understood nowadays, consists of using one\nsingle model to carry out several similar tasks. From classifying hand-written\ncharacters of different alphabets to figuring out how to play several Atari\ngames using reinforcement learning, multi-task models have been able to widen\ntheir performance range across different tasks, although these tasks are\nusually of a similar nature. In this work, we attempt to widen this range even\nfurther, by including heterogeneous tasks in a single learning procedure. To do\nso, we firstly formally define a multi-network model, identifying the necessary\ncomponents and characteristics to allow different adaptations of said model\ndepending on the tasks it is required to fulfill. Secondly, employing the\nformal definition as a starting point, we develop an illustrative model example\nconsisting of three different tasks (classification, regression and data\nsampling). The performance of this model implementation is then analyzed,\nshowing its capabilities. Motivated by the results of the analysis, we\nenumerate a set of open challenges and future research lines over which the\nfull potential of the proposed model definition can be exploited.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 18:07:02 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Garciarena", "Unai", ""], ["Mendiburu", "Alexander", ""], ["Santana", "Roberto", ""]]}, {"id": "1903.09243", "submitter": "Matthew Walter", "authors": "Siddharth Patki and Andrea F. Daniele and Matthew R. Walter and Thomas\n  M. Howard", "title": "Inferring Compact Representations for Efficient Natural Language\n  Understanding of Robot Instructions", "comments": "Accepted to ICRA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The speed and accuracy with which robots are able to interpret natural\nlanguage is fundamental to realizing effective human-robot interaction. A great\ndeal of attention has been paid to developing models and approximate inference\nalgorithms that improve the efficiency of language understanding. However,\nexisting methods still attempt to reason over a representation of the\nenvironment that is flat and unnecessarily detailed, which limits scalability.\nAn open problem is then to develop methods capable of producing the most\ncompact environment model sufficient for accurate and efficient natural\nlanguage understanding. We propose a model that leverages environment-related\ninformation encoded within instructions to identify the subset of observations\nand perceptual classifiers necessary to perceive a succinct,\ninstruction-specific environment representation. The framework uses three\nprobabilistic graphical models trained from a corpus of annotated instructions\nto infer salient scene semantics, perceptual classifiers, and grounded symbols.\nExperimental results on two robots operating in different environments\ndemonstrate that by exploiting the content and the structure of the\ninstructions, our method learns compact environment representations that\nsignificantly improve the efficiency of natural language symbol grounding.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 21:38:20 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Patki", "Siddharth", ""], ["Daniele", "Andrea F.", ""], ["Walter", "Matthew R.", ""], ["Howard", "Thomas M.", ""]]}, {"id": "1903.09245", "submitter": "Soheil Khorram", "authors": "Soheil Khorram, Melvin G McInnis, Emily Mower Provost", "title": "Trainable Time Warping: Aligning Time-Series in the Continuous-Time\n  Domain", "comments": "ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  DTW calculates the similarity or alignment between two signals, subject to\ntemporal warping. However, its computational complexity grows exponentially\nwith the number of time-series. Although there have been algorithms developed\nthat are linear in the number of time-series, they are generally quadratic in\ntime-series length. The exception is generalized time warping (GTW), which has\nlinear computational cost. Yet, it can only identify simple time warping\nfunctions. There is a need for a new fast, high-quality multisequence alignment\nalgorithm. We introduce trainable time warping (TTW), whose complexity is\nlinear in both the number and the length of time-series. TTW performs alignment\nin the continuous-time domain using a sinc convolutional kernel and a\ngradient-based optimization technique. We compare TTW and GTW on 85 UCR\ndatasets in time-series averaging and classification. TTW outperforms GTW on\n67.1% of the datasets for the averaging tasks, and 61.2% of the datasets for\nthe classification tasks.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 21:42:19 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Khorram", "Soheil", ""], ["McInnis", "Melvin G", ""], ["Provost", "Emily Mower", ""]]}, {"id": "1903.09255", "submitter": "Yan Zhang", "authors": "Yan Zhang, Michael M. Zavlanos", "title": "Distributed off-Policy Actor-Critic Reinforcement Learning with Policy\n  Consensus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a distributed off-policy actor critic method to\nsolve multi-agent reinforcement learning problems. Specifically, we assume that\nall agents keep local estimates of the global optimal policy parameter and\nupdate their local value function estimates independently. Then, we introduce\nan additional consensus step to let all the agents asymptotically achieve\nagreement on the global optimal policy function. The convergence analysis of\nthe proposed algorithm is provided and the effectiveness of the proposed\nalgorithm is validated using a distributed resource allocation example.\nCompared to relevant distributed actor critic methods, here the agents do not\nshare information about their local tasks, but instead they coordinate to\nestimate the global policy function.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 22:04:16 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Zhang", "Yan", ""], ["Zavlanos", "Michael M.", ""]]}, {"id": "1903.09297", "submitter": "Hussein Abbass A", "authors": "Alexander Gee and Hussein Abbass", "title": "Transparent Machine Education of Neural Networks for Swarm Shepherding\n  Using Curriculum Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Swarm control is a difficult problem due to the need to guide a large number\nof agents simultaneously. We cast the problem as a shepherding problem, similar\nto biological dogs guiding a group of sheep towards a goal. The shepherd needs\nto deal with complex and dynamic environments and make decisions in order to\ndirect the swarm from one location to another. In this paper, we design a novel\ncurriculum to teach an artificial intelligence empowered agent to shepherd in\nthe presence of the large state space associated with the shepherding problem\nand in a transparent manner. The results show that a properly designed\ncurriculum could indeed enhance the speed of learning and the complexity of\nlearnt behaviours.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 00:04:04 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Gee", "Alexander", ""], ["Abbass", "Hussein", ""]]}, {"id": "1903.09328", "submitter": "Bharat Prakash", "authors": "Bharat Prakash, Mohit Khatwani, Nicholas Waytowich, Tinoosh Mohsenin", "title": "Improving Safety in Reinforcement Learning Using Model-Based\n  Architectures and Human Intervention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in AI and Reinforcement learning has shown great success in\nsolving complex problems with high dimensional state spaces. However, most of\nthese successes have been primarily in simulated environments where failure is\nof little or no consequence. Most real-world applications, however, require\ntraining solutions that are safe to operate as catastrophic failures are\ninadmissible especially when there is human interaction involved. Currently,\nSafe RL systems use human oversight during training and exploration in order to\nmake sure the RL agent does not go into a catastrophic state. These methods\nrequire a large amount of human labor and it is very difficult to scale up. We\npresent a hybrid method for reducing the human intervention time by combining\nmodel-based approaches and training a supervised learner to improve sample\nefficiency while also ensuring safety. We evaluate these methods on various\ngrid-world environments using both standard and visual representations and show\nthat our approach achieves better performance in terms of sample efficiency,\nnumber of catastrophic states reached as well as overall task performance\ncompared to traditional model-free approaches\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 02:48:21 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Prakash", "Bharat", ""], ["Khatwani", "Mohit", ""], ["Waytowich", "Nicholas", ""], ["Mohsenin", "Tinoosh", ""]]}, {"id": "1903.09333", "submitter": "Gene Louis Kim", "authors": "Gene Louis Kim and Lenhart Schubert", "title": "A Type-coherent, Expressive Representation as an Initial Step to\n  Language Understanding", "comments": "Accepted for publication at The 13th International Conference on\n  Computational Semantics (IWCS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing interest in tasks involving language understanding by the NLP\ncommunity has led to the need for effective semantic parsing and inference.\nModern NLP systems use semantic representations that do not quite fulfill the\nnuanced needs for language understanding: adequately modeling language\nsemantics, enabling general inferences, and being accurately recoverable. This\ndocument describes underspecified logical forms (ULF) for Episodic Logic (EL),\nwhich is an initial form for a semantic representation that balances these\nneeds. ULFs fully resolve the semantic type structure while leaving issues such\nas quantifier scope, word sense, and anaphora unresolved; they provide a\nstarting point for further resolution into EL, and enable certain structural\ninferences without further resolution. This document also presents preliminary\nresults of creating a hand-annotated corpus of ULFs for the purpose of training\na precise ULF parser, showing a three-person pairwise interannotator agreement\nof 0.88 on confident annotations. We hypothesize that a divide-and-conquer\napproach to semantic parsing starting with derivation of ULFs will lead to\nsemantic analyses that do justice to subtle aspects of linguistic meaning, and\nwill enable construction of more accurate semantic parsers.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 03:06:36 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2019 21:58:38 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Kim", "Gene Louis", ""], ["Schubert", "Lenhart", ""]]}, {"id": "1903.09343", "submitter": "Xuhui Fan", "authors": "Xuhui Fan, Bin Li, Scott Anthony Sisson", "title": "The Binary Space Partitioning-Tree Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Mondrian process represents an elegant and powerful approach for space\npartition modelling. However, as it restricts the partitions to be\naxis-aligned, its modelling flexibility is limited. In this work, we propose a\nself-consistent Binary Space Partitioning (BSP)-Tree process to generalize the\nMondrian process. The BSP-Tree process is an almost surely right continuous\nMarkov jump process that allows uniformly distributed oblique cuts in a\ntwo-dimensional convex polygon. The BSP-Tree process can also be extended using\na non-uniform probability measure to generate direction differentiated cuts.\nThe process is also self-consistent, maintaining distributional invariance\nunder a restricted subdomain. We use Conditional-Sequential Monte Carlo for\ninference using the tree structure as the high-dimensional variable. The\nBSP-Tree process's performance on synthetic data partitioning and relational\nmodelling demonstrates clear inferential improvements over the standard\nMondrian process and other related methods.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 03:38:00 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Fan", "Xuhui", ""], ["Li", "Bin", ""], ["Sisson", "Scott Anthony", ""]]}, {"id": "1903.09348", "submitter": "Xuhui Fan", "authors": "Xuhui Fan, Bin Li, Scott Anthony Sisson", "title": "Binary Space Partitioning Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Binary Space Partitioning~(BSP)-Tree process is proposed to produce\nflexible 2-D partition structures which are originally used as a Bayesian\nnonparametric prior for relational modelling. It can hardly be applied to other\nlearning tasks such as regression trees because extending the BSP-Tree process\nto a higher dimensional space is nontrivial. This paper is the first attempt to\nextend the BSP-Tree process to a d-dimensional (d>2) space. We propose to\ngenerate a cutting hyperplane, which is assumed to be parallel to d-2\ndimensions, to cut each node in the d-dimensional BSP-tree. By designing a\nsubtle strategy to sample two free dimensions from d dimensions, the extended\nBSP-Tree process can inherit the essential self-consistency property from the\noriginal version. Based on the extended BSP-Tree process, an ensemble model,\nwhich is named the BSP-Forest, is further developed for regression tasks.\nThanks to the retained self-consistency property, we can thus significantly\nreduce the geometric calculations in the inference stage. Compared to its\ncounterpart, the Mondrian Forest, the BSP-Forest can achieve similar\nperformance with fewer cuts due to its flexibility. The BSP-Forest also\noutperforms other (Bayesian) regression forests on a number of real-world data\nsets.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 03:48:48 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Fan", "Xuhui", ""], ["Li", "Bin", ""], ["Sisson", "Scott Anthony", ""]]}, {"id": "1903.09354", "submitter": "Marcell Vazquez-Chanlatte", "authors": "Marcell Vazquez-Chanlatte, Markus N. Rabe, Sanjit A. Seshia", "title": "A Model Counter's Guide to Probabilistic Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we systematize the modeling of probabilistic systems for the\npurpose of analyzing them with model counting techniques. Starting from\nunbiased coin flips, we show how to model biased coins, correlated coins, and\ndistributions over finite sets. From there, we continue with modeling\nsequential systems, such as Markov chains, and revisit the relationship between\nweighted and unweighted model counting. Thereby, this work provides a\nconceptual framework for deriving #SAT encodings for probabilistic inference.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 04:37:36 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Vazquez-Chanlatte", "Marcell", ""], ["Rabe", "Markus N.", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "1903.09366", "submitter": "Masanori Yamada", "authors": "Heecheol Kim, Masanori Yamada, Kosuke Miyoshi, Hiroshi Yamakawa", "title": "Macro Action Reinforcement Learning with Sequence Disentanglement using\n  Variational Autoencoder", "comments": "First and second authors equally contributed to this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One problem in the application of reinforcement learning to real-world\nproblems is the curse of dimensionality on the action space. Macro actions, a\nsequence of primitive actions, have been studied to diminish the dimensionality\nof the action space with regard to the time axis. However, previous studies\nrelied on humans defining macro actions or assumed macro actions as repetitions\nof the same primitive actions. We present Factorized Macro Action Reinforcement\nLearning (FaMARL) which autonomously learns disentangled factor representation\nof a sequence of actions to generate macro actions that can be directly applied\nto general reinforcement learning algorithms. FaMARL exhibits higher scores\nthan other reinforcement learning algorithms on environments that require an\nextensive amount of search.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 05:54:27 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 01:46:52 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Kim", "Heecheol", ""], ["Yamada", "Masanori", ""], ["Miyoshi", "Kosuke", ""], ["Yamakawa", "Hiroshi", ""]]}, {"id": "1903.09374", "submitter": "Dongyang Zhao", "authors": "Dongyang Zhao, Liang Zhang, Bo Zhang, Lizhou Zheng, Yongjun Bao,\n  Weipeng Yan", "title": "Deep Hierarchical Reinforcement Learning Based Recommendations via\n  Multi-goals Abstraction", "comments": "submitted to SIGKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recommender system is an important form of intelligent application, which\nassists users to alleviate from information redundancy. Among the metrics used\nto evaluate a recommender system, the metric of conversion has become more and\nmore important. The majority of existing recommender systems perform poorly on\nthe metric of conversion due to its extremely sparse feedback signal. To tackle\nthis challenge, we propose a deep hierarchical reinforcement learning based\nrecommendation framework, which consists of two components, i.e., high-level\nagent and low-level agent. The high-level agent catches long-term sparse\nconversion signals, and automatically sets abstract goals for low-level agent,\nwhile the low-level agent follows the abstract goals and interacts with\nreal-time environment. To solve the inherent problem in hierarchical\nreinforcement learning, we propose a novel deep hierarchical reinforcement\nlearning algorithm via multi-goals abstraction (HRL-MG). Our proposed algorithm\ncontains three characteristics: 1) the high-level agent generates multiple\ngoals to guide the low-level agent in different stages, which reduces the\ndifficulty of approaching high-level goals; 2) different goals share the same\nstate encoder parameters, which increases the update frequency of the\nhigh-level agent and thus accelerates the convergence of our proposed\nalgorithm; 3) an appreciate benefit assignment function is designed to allocate\nrewards in each goal so as to coordinate different goals in a consistent\ndirection. We evaluate our proposed algorithm based on a real-world e-commerce\ndataset and validate its effectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 06:43:49 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Zhao", "Dongyang", ""], ["Zhang", "Liang", ""], ["Zhang", "Bo", ""], ["Zheng", "Lizhou", ""], ["Bao", "Yongjun", ""], ["Yan", "Weipeng", ""]]}, {"id": "1903.09415", "submitter": "Raphael Volz", "authors": "Maximilian Auer, Kai Osswald, Raphael Volz, Joerg Woidasky", "title": "Artificial intelligence-based process for metal scrap sorting", "comments": "8 pages, 3 figures, 1 table, peer-reviewed, accepted and presented", "journal-ref": "Bockreis, A. et al. (Hrsg.): 9. Wissenschaftskongress Abfall- und\n  Ressourcenwirtschaft. Innsbruck University Press, 2019, ISBN\n  978-3-903187-48-1, S. 17-22", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning offers remarkable benefits for improving workplaces and\nworking conditions amongst others in the recycling industry. Here e.g.\nhand-sorting of medium value scrap is labor intensive and requires experienced\nand skilled workers. On the one hand, they have to be highly concentrated for\nmaking proper readings and analyses of the material, but on the other hand,\nthis work is monotonous. Therefore, a machine learning approach is proposed for\na quick and reliable automated identification of alloys in the recycling\nindustry, while the mere scrap handling is regarded to be left in the hands of\nthe workers. To this end, a set of twelve tool and high-speed steels from the\nfield were selected to be identified by their spectrum induced by electric\narcs. For data acquisition, the optical emission spectrometer Thorlabs CCS 100\nwas used. Spectra have been post-processed to be fed into the supervised\nmachine learning algorithm. The development of the machine learning software is\nconducted according to the steps of the VDI 2221 standard method. For\nprogramming Python 3 as well as the python-library sklearn were used. By\nsystematic parameter variation, the appropriate machine learning algorithm was\nselected and validated. Subsequent validation steps showed that the automated\nidentification process using a machine learning approach and the optical\nemission spectrometry is applicable, reaching a maximum F1 score of 96.9 %.\nThis performance is as good as the performance of a highly trained worker using\nvisual grinding spark identification. The tests were based on a self-generated\nset of 600 spectra per single alloy (7,200 spectra in total) which were\nproduced using an industry workshop device.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 09:28:03 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Auer", "Maximilian", ""], ["Osswald", "Kai", ""], ["Volz", "Raphael", ""], ["Woidasky", "Joerg", ""]]}, {"id": "1903.09475", "submitter": "Andrei Arusoaie", "authors": "Andrei Arusoaie, Ionut Pistol", "title": "Using SMT Solvers to Validate Models for AI Problems", "comments": "8 pages,1 table, technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence problems, ranging form planning/scheduling up to game\ncontrol, include an essential crucial step: describing a model which accurately\ndefines the problem's required data, requirements, allowed transitions and\nestablished goals. The ways in which a model can fail are numerous and often\nlead to a failure of search strategies to provide a quick, optimal, or even any\nsolution. This paper proposes using SMT (Satisfiability Modulo Theories)\nsolvers, such as Z3, to check the validity of a model. We propose two tests:\nchecking whether a final(goal) state exists in the model's described problem\nspace and checking whether the transitions described can provide a path from\nthe identified initial states to any the goal states (meaning a solution has\nbeen found). The advantage of using an SMT solver for AI model checking is that\nthey substitute actual search strategies and they work over an abstract\nrepresentation of the model, that is, a set of logical formulas. Reasoning at\nan abstract level is not as expensive as exploring the entire solution space.\nSMT solvers use efficient decision procedures which provide proofs for the\nlogical formulas corresponding to the AI model. A recent addition to Z3 allowed\nus to describe sequences of transitions as a recursive function, thus we can\ncheck if a solution can be found in the defined model.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 12:45:23 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Arusoaie", "Andrei", ""], ["Pistol", "Ionut", ""]]}, {"id": "1903.09516", "submitter": "Kristian Kersting", "authors": "Kristian Kersting and Jan Peters and Constantin Rothkopf", "title": "Was ist eine Professur fuer Kuenstliche Intelligenz?", "comments": "in German", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Federal Government of Germany aims to boost the research in the field of\nArtificial Intelligence (AI). For instance, 100 new professorships are said to\nbe established. However, the white paper of the government does not answer what\nan AI professorship is at all. In order to give colleagues, politicians, and\ncitizens an idea, we present a view that is often followed when appointing\nprofessors for AI at German and international universities. We hope that it\nwill help to establish a guideline with internationally accepted measures and\nthus make the public debate more informed.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2019 14:35:11 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Kersting", "Kristian", ""], ["Peters", "Jan", ""], ["Rothkopf", "Constantin", ""]]}, {"id": "1903.09518", "submitter": "Arthur Gaudron", "authors": "Gaudron Arthur (CAOR)", "title": "Trial of an AI: Empowering people to explore law and science challenges", "comments": null, "journal-ref": "IFIM's International Journal on Law & Regulation of Artificial\n  Intelligence & Robotics, 2019, 1 (1)", "doi": null, "report-no": null, "categories": "cs.OH cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence represents many things: a new market to conquer or a\nquality label for tech companies, a threat for traditional industries, a menace\nfor democracy, or a blessing for our busy everyday life. The press abounds in\nexamples illustrating these aspects, but one should draw not hasty and\npremature conclusions. The first successes in AI have been a surprise for\nsociety at large-including researchers in the field. Today, after the initial\nstupefaction, we have examples of the system reactions: traditional companies\nare heavily investing in AI, social platforms are monitored during elections,\ndata collection is more and more regulated, etc. The resilience of an\norganization (i.e. its capacity to resist to a shock) relies deeply on the\nperception of its environment. Future problems have to be anticipated, while\nunforeseen events occurring have to be quickly identified in order to be\nmitigated as fast as possible. The author states that this clear perception\nstarts with a common definition of AI in terms of capacities and limits. AI\npractitioners should make notions and concepts accessible to the general public\nand the impacted fields (e.g. industries, law, education). It is a truism that\nonly law experts would have the potential to estimate IA impacts on judicial\nsystem. However, questions remain on how to connect different kind of expertise\nand what is the appropriate level of detail required for the knowledge\nexchanges. And the same consideration is true for dissemination towards\nsociety. Ultimately, society will live with decisions made by the \"experts\". It\nsounds wise to involve society in the decision process rather than risking to\npay consequences later. Therefore, society also needs the key concepts to\nunderstand AI impact on their life. This was the purpose of the trial of an IA\nthat took place in October 2018 at the Court of Appeal of Paris: gathering\nexperts from various fields to expose challenges in law and science towards a\ngeneral public.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 07:22:29 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Arthur", "Gaudron", "", "CAOR"]]}, {"id": "1903.09542", "submitter": "Manuel Baltieri Mr", "authors": "Manuel Baltieri and Christopher L. Buckley", "title": "Nonmodular architectures of cognitive systems based on active inference", "comments": "Accepted at IJCNN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In psychology and neuroscience it is common to describe cognitive systems as\ninput/output devices where perceptual and motor functions are implemented in a\npurely feedforward, open-loop fashion. On this view, perception and action are\noften seen as encapsulated modules with limited interaction between them. While\nembodied and enactive approaches to cognitive science have challenged the\nidealisation of the brain as an input/output device, we argue that even the\nmore recent attempts to model systems using closed-loop architectures still\nheavily rely on a strong separation between motor and perceptual functions.\nPreviously, we have suggested that the mainstream notion of modularity strongly\nresonates with the separation principle of control theory. In this work we\npresent a minimal model of a sensorimotor loop implementing an architecture\nbased on the separation principle. We link this to popular formulations of\nperception and action in the cognitive sciences, and show its limitations when,\nfor instance, external forces are not modelled by an agent. These forces can be\nseen as variables that an agent cannot directly control, i.e., a perturbation\nfrom the environment or an interference caused by other agents. As an\nalternative approach inspired by embodied cognitive science, we then propose a\nnonmodular architecture based on the active inference framework. We demonstrate\nthe robustness of this architecture to unknown external inputs and show that\nthe mechanism with which this is achieved in linear models is equivalent to\nintegral control.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 15:00:25 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Baltieri", "Manuel", ""], ["Buckley", "Christopher L.", ""]]}, {"id": "1903.09569", "submitter": "Li Zhang", "authors": "Li Zhang, Wei Wang, Shijian Li, Gang Pan", "title": "Monte Carlo Neural Fictitious Self-Play: Approach to Approximate Nash\n  equilibrium of Imperfect-Information Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers on artificial intelligence have achieved human-level intelligence\nin large-scale perfect-information games, but it is still a challenge to\nachieve (nearly) optimal results (in other words, an approximate Nash\nEquilibrium) in large-scale imperfect-information games (i.e. war games,\nfootball coach or business strategies). Neural Fictitious Self Play (NFSP) is\nan effective algorithm for learning approximate Nash equilibrium of\nimperfect-information games from self-play without prior domain knowledge.\nHowever, it relies on Deep Q-Network, which is off-line and is hard to converge\nin online games with changing opponent strategy, so it can't approach\napproximate Nash equilibrium in games with large search scale and deep search\ndepth. In this paper, we propose Monte Carlo Neural Fictitious Self Play\n(MC-NFSP), an algorithm combines Monte Carlo tree search with NFSP, which\ngreatly improves the performance on large-scale zero-sum imperfect-information\ngames. Experimentally, we demonstrate that the proposed Monte Carlo Neural\nFictitious Self Play can converge to approximate Nash equilibrium in games with\nlarge-scale search depth while the Neural Fictitious Self Play can't.\nFurthermore, we develop Asynchronous Neural Fictitious Self Play (ANFSP). It\nuse asynchronous and parallel architecture to collect game experience. In\nexperiments, we show that parallel actor-learners have a further accelerated\nand stabilizing effect on training.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 15:58:35 GMT"}, {"version": "v2", "created": "Sat, 6 Apr 2019 09:12:25 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Zhang", "Li", ""], ["Wang", "Wei", ""], ["Li", "Shijian", ""], ["Pan", "Gang", ""]]}, {"id": "1903.09604", "submitter": "Christopher Solinas", "authors": "Christopher Solinas, Douglas Rebstock, Michael Buro", "title": "Improving Search with Supervised Learning in Trick-Based Card Games", "comments": "Accepted for publication at AAAI-19", "journal-ref": "Vol 33 (2019): Proceedings of the Thirty-Third AAAI Conference on\n  Artificial Intelligence, Pages 1158-1165", "doi": "10.1609/aaai.v33i01.33011158", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In trick-taking card games, a two-step process of state sampling and\nevaluation is widely used to approximate move values. While the evaluation\ncomponent is vital, the accuracy of move value estimates is also fundamentally\nlinked to how well the sampling distribution corresponds the true distribution.\nDespite this, recent work in trick-taking card game AI has mainly focused on\nimproving evaluation algorithms with limited work on improving sampling. In\nthis paper, we focus on the effect of sampling on the strength of a player and\npropose a novel method of sampling more realistic states given move history. In\nparticular, we use predictions about locations of individual cards made by a\ndeep neural network --- trained on data from human gameplay - in order to\nsample likely worlds for evaluation. This technique, used in conjunction with\nPerfect Information Monte Carlo (PIMC) search, provides a substantial increase\nin cardplay strength in the popular trick-taking card game of Skat.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 17:00:50 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Solinas", "Christopher", ""], ["Rebstock", "Douglas", ""], ["Buro", "Michael", ""]]}, {"id": "1903.09708", "submitter": "Andrew Anderson", "authors": "Andrew Anderson, Jonathan Dodge, Amrita Sadarangani, Zoe Juozapaitis,\n  Evan Newman, Jed Irvine, Souti Chattopadhyay, Alan Fern, Margaret Burnett", "title": "Explaining Reinforcement Learning to Mere Mortals: An Empirical Study", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a user study to investigate the impact of explanations on\nnon-experts' understanding of reinforcement learning (RL) agents. We\ninvestigate both a common RL visualization, saliency maps (the focus of\nattention), and a more recent explanation type, reward-decomposition bars\n(predictions of future types of rewards). We designed a 124 participant,\nfour-treatment experiment to compare participants' mental models of an RL agent\nin a simple Real-Time Strategy (RTS) game. Our results show that the\ncombination of both saliency and reward bars were needed to achieve a\nstatistically significant improvement in mental model score over the control.\nIn addition, our qualitative analysis of the data reveals a number of effects\nfor further study.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 20:56:55 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 19:47:07 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Anderson", "Andrew", ""], ["Dodge", "Jonathan", ""], ["Sadarangani", "Amrita", ""], ["Juozapaitis", "Zoe", ""], ["Newman", "Evan", ""], ["Irvine", "Jed", ""], ["Chattopadhyay", "Souti", ""], ["Fern", "Alan", ""], ["Burnett", "Margaret", ""]]}, {"id": "1903.09709", "submitter": "Matthew Guzdial", "authors": "Matthew Guzdial and Mark Riedl", "title": "An Interaction Framework for Studying Co-Creative AI", "comments": "6 pages, 2 figures, Human-Centered Machine Learning Perspectives\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has been applied to a number of creative, design-oriented\ntasks. However, it remains unclear how to best empower human users with these\nmachine learning approaches, particularly those users without technical\nexpertise. In this paper we propose a general framework for turn-based\ninteraction between human users and AI agents designed to support human\ncreativity, called {co-creative systems}. The framework can be used to better\nunderstand the space of possible designs of co-creative systems and reveal\nfuture research directions. We demonstrate how to apply this framework in\nconjunction with a pair of recent human subject studies, comparing between the\nfour human-AI systems employed in these studies and generating hypotheses\ntowards future studies.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 20:57:05 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Guzdial", "Matthew", ""], ["Riedl", "Mark", ""]]}, {"id": "1903.09731", "submitter": "Gilmer Valdes", "authors": "E.D. Gennatas, J.H. Friedman, L.H. Ungar, R. Pirracchio, E. Eaton, L.\n  Reichman, Y. Interian, C.B. Simone, A. Auerbach, E. Delgado, M.J. Van der\n  Laan, T.D. Solberg, G. Valdes", "title": "Expert-Augmented Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning is proving invaluable across disciplines. However, its\nsuccess is often limited by the quality and quantity of available data, while\nits adoption by the level of trust that models afford users. Human vs. machine\nperformance is commonly compared empirically to decide whether a certain task\nshould be performed by a computer or an expert. In reality, the optimal\nlearning strategy may involve combining the complementary strengths of man and\nmachine. Here we present Expert-Augmented Machine Learning (EAML), an automated\nmethod that guides the extraction of expert knowledge and its integration into\nmachine-learned models. We use a large dataset of intensive care patient data\nto predict mortality and show that we can extract expert knowledge using an\nonline platform, help reveal hidden confounders, improve generalizability on a\ndifferent population and learn using less data. EAML presents a novel framework\nfor high performance and dependable machine learning in critical applications.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 23:32:22 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 21:22:36 GMT"}, {"version": "v3", "created": "Tue, 5 Jan 2021 20:27:43 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Gennatas", "E. D.", ""], ["Friedman", "J. H.", ""], ["Ungar", "L. H.", ""], ["Pirracchio", "R.", ""], ["Eaton", "E.", ""], ["Reichman", "L.", ""], ["Interian", "Y.", ""], ["Simone", "C. B.", ""], ["Auerbach", "A.", ""], ["Delgado", "E.", ""], ["Van der Laan", "M. J.", ""], ["Solberg", "T. D.", ""], ["Valdes", "G.", ""]]}, {"id": "1903.09820", "submitter": "Pavel Surynek", "authors": "Pavel Surynek", "title": "Multi-agent Path Finding with Continuous Time Viewed Through\n  Satisfiability Modulo Theories (SMT)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses a variant of multi-agent path finding (MAPF) in\ncontinuous space and time. We present a new solving approach based on\nsatisfiability modulo theories (SMT) to obtain makespan optimal solutions. The\nstandard MAPF is a task of navigating agents in an undirected graph from given\nstarting vertices to given goal vertices so that agents do not collide with\neach other in vertices of the graph. In the continuous version\n(MAPF$^\\mathcal{R}$) agents move in an $n$-dimensional Euclidean space along\nstraight lines that interconnect predefined positions. For simplicity, we work\nwith circular omni-directional agents having constant velocities in the 2D\nplane. As agents can have different sizes and move smoothly along lines, a\nnon-colliding movement along certain lines with small agents can result in a\ncollision if the same movement is performed with larger agents. Our SMT-based\napproach for MAPF$^\\mathcal{R}$ called SMT-CBS$^\\mathcal{R}$ reformulates the\nConflict-based Search (CBS) algorithm in terms of SMT concepts. We suggest lazy\ngeneration of decision variables and constraints. Each time a new conflict is\ndiscovered, the underlying encoding is extended with new variables and\nconstraints to eliminate the conflict. We compared SMT-CBS$^\\mathcal{R}$ and\nadaptations of CBS for the continuous variant of MAPF experimentally.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2019 13:27:32 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Surynek", "Pavel", ""]]}, {"id": "1903.09850", "submitter": "Marcello Balduccini", "authors": "Marcello Balduccini and Emily LeBlanc", "title": "Action-Centered Information Retrieval", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": "Theory and Practice of Logic Programming 20 (2020) 249-272", "doi": "10.1017/S1471068419000097", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information Retrieval (IR) aims at retrieving documents that are most\nrelevant to a query provided by a user. Traditional techniques rely mostly on\nsyntactic methods. In some cases, however, links at a deeper semantic level\nmust be considered. In this paper, we explore a type of IR task in which\ndocuments describe sequences of events, and queries are about the state of the\nworld after such events. In this context, successfully matching documents and\nquery requires considering the events' possibly implicit, uncertain effects and\nside-effects. We begin by analyzing the problem, then propose an action\nlanguage based formalization, and finally automate the corresponding IR task\nusing Answer Set Programming.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2019 17:34:25 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Balduccini", "Marcello", ""], ["LeBlanc", "Emily", ""]]}, {"id": "1903.09876", "submitter": "Hao Tang", "authors": "Hao Tang, Daniel R. Kim, Xiaohui Xie", "title": "Automated pulmonary nodule detection using 3D deep convolutional neural\n  networks", "comments": "2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early detection of pulmonary nodules in computed tomography (CT) images is\nessential for successful outcomes among lung cancer patients. Much attention\nhas been given to deep convolutional neural network (DCNN)-based approaches to\nthis task, but models have relied at least partly on 2D or 2.5D components for\ninherently 3D data. In this paper, we introduce a novel DCNN approach,\nconsisting of two stages, that is fully three-dimensional end-to-end and\nutilizes the state-of-the-art in object detection. First, nodule candidates are\nidentified with a U-Net-inspired 3D Faster R-CNN trained using online hard\nnegative mining. Second, false positive reduction is performed by 3D DCNN\nclassifiers trained on difficult examples produced during candidate screening.\nFinally, we introduce a method to ensemble models from both stages via\nconsensus to give the final predictions. By using this framework, we ranked\nfirst of 2887 teams in Season One of Alibaba's 2017 TianChi AI Competition for\nHealthcare.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2019 20:20:15 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Tang", "Hao", ""], ["Kim", "Daniel R.", ""], ["Xie", "Xiaohui", ""]]}, {"id": "1903.09879", "submitter": "Hao Tang", "authors": "Hao Tang, Chupeng Zhang, Xiaohui Xie", "title": "Automatic Pulmonary Lobe Segmentation Using Deep Learning", "comments": "2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Pulmonary lobe segmentation is an important task for pulmonary disease\nrelated Computer Aided Diagnosis systems (CADs). Classical methods for lobe\nsegmentation rely on successful detection of fissures and other anatomical\ninformation such as the location of blood vessels and airways. With the success\nof deep learning in recent years, Deep Convolutional Neural Network (DCNN) has\nbeen widely applied to analyze medical images like Computed Tomography (CT) and\nMagnetic Resonance Imaging (MRI), which, however, requires a large number of\nground truth annotations. In this work, we release our manually labeled 50 CT\nscans which are randomly chosen from the LUNA16 dataset and explore the use of\ndeep learning on this task. We propose pre-processing CT image by cropping\nregion that is covered by the convex hull of the lungs in order to mitigate the\ninfluence of noise from outside the lungs. Moreover, we design a hybrid loss\nfunction with dice loss to tackle extreme class imbalance issue and focal loss\nto force model to focus on voxels that are hard to be discriminated. To\nvalidate the robustness and performance of our proposed framework trained with\na small number of training examples, we further tested our model on CT scans\nfrom an independent dataset. Experimental results show the robustness of the\nproposed approach, which consistently improves performance across different\ndatasets by a maximum of $5.87\\%$ as compared to a baseline model.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2019 20:31:45 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 18:04:51 GMT"}, {"version": "v3", "created": "Wed, 10 Apr 2019 06:41:19 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Tang", "Hao", ""], ["Zhang", "Chupeng", ""], ["Xie", "Xiaohui", ""]]}, {"id": "1903.09880", "submitter": "Hao Tang", "authors": "Hao Tang, Xingwei Liu, Xiaohui Xie", "title": "An End-to-end Framework For Integrated Pulmonary Nodule Detection and\n  False Positive Reduction", "comments": "2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Pulmonary nodule detection using low-dose Computed Tomography (CT) is often\nthe first step in lung disease screening and diagnosis. Recently, algorithms\nbased on deep convolutional neural nets have shown great promise for automated\nnodule detection. Most of the existing deep learning nodule detection systems\nare constructed in two steps: a) nodule candidates screening and b) false\npositive reduction, using two different models trained separately. Although it\nis commonly adopted, the two-step approach not only imposes significant\nresource overhead on training two independent deep learning models, but also is\nsub-optimal because it prevents cross-talk between the two. In this work, we\npresent an end-to-end framework for nodule detection, integrating nodule\ncandidate screening and false positive reduction into one model, trained\njointly. We demonstrate that the end-to-end system improves the performance by\n3.88\\% over the two-step approach, while at the same time reducing model\ncomplexity by one third and cutting inference time by 3.6 fold. Code will be\nmade publicly available.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2019 20:38:51 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Tang", "Hao", ""], ["Liu", "Xingwei", ""], ["Xie", "Xiaohui", ""]]}, {"id": "1903.09900", "submitter": "Andrew Hundt", "authors": "Andrew Hundt, Varun Jain, Gregory D. Hager", "title": "sharpDARTS: Faster and More Accurate Differentiable Architecture Search", "comments": "9 pages, 6 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) has been a source of dramatic improvements\nin neural network design, with recent results meeting or exceeding the\nperformance of hand-tuned architectures. However, our understanding of how to\nrepresent the search space for neural net architectures and how to search that\nspace efficiently are both still in their infancy.\n  We have performed an in-depth analysis to identify limitations in a widely\nused search space and a recent architecture search method, Differentiable\nArchitecture Search (DARTS). These findings led us to introduce novel network\nblocks with a more general, balanced, and consistent design; a better-optimized\nCosine Power Annealing learning rate schedule; and other improvements. Our\nresulting sharpDARTS search is 50% faster with a 20-30% relative improvement in\nfinal model error on CIFAR-10 when compared to DARTS. Our best single model run\nhas 1.93% (1.98+/-0.07) validation error on CIFAR-10 and 5.5% error (5.8+/-0.3)\non the recently released CIFAR-10.1 test set. To our knowledge, both are state\nof the art for models of similar size. This model also generalizes\ncompetitively to ImageNet at 25.1% top-1 (7.8% top-5) error.\n  We found improvements for existing search spaces but does DARTS generalize to\nnew domains? We propose Differentiable Hyperparameter Grid Search and the\nHyperCuboid search space, which are representations designed to leverage DARTS\nfor more general parameter optimization. Here we find that DARTS fails to\ngeneralize when compared against a human's one shot choice of models. We look\nback to the DARTS and sharpDARTS search spaces to understand why, and an\nablation study reveals an unusual generalization gap. We finally propose Max-W\nregularization to solve this problem, which proves significantly better than\nthe handmade design. Code will be made available.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2019 23:20:44 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Hundt", "Andrew", ""], ["Jain", "Varun", ""], ["Hager", "Gregory D.", ""]]}, {"id": "1903.09922", "submitter": "Nao Takano", "authors": "Nao Takano and Gita Alaghband", "title": "SRGAN: Training Dataset Matters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) in supervised settings can generate\nphoto-realistic corresponding output from low-definition input (SRGAN). Using\nthe architecture presented in the SRGAN original paper [2], we explore how\nselecting a dataset affects the outcome by using three different datasets to\nsee that SRGAN fundamentally learns objects, with their shape, color, and\ntexture, and redraws them in the output rather than merely attempting to\nsharpen edges. This is further underscored with our demonstration that once the\nnetwork learns the images of the dataset, it can generate a photo-like image\nwith even a slight hint of what it might look like for the original from a very\nblurry edged sketch. Given a set of inference images, the network trained with\nthe same dataset results in a better outcome over the one trained with\narbitrary set of images, and we report its significance numerically with\nFrechet Inception Distance score [22].\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 04:28:58 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Takano", "Nao", ""], ["Alaghband", "Gita", ""]]}, {"id": "1903.09942", "submitter": "Andrei Damian I", "authors": "Laurentiu Piciu, Andrei Damian, Nicolae Tapus, Andrei\n  Simion-Constantinescu, Bogdan Dumitrescu", "title": "Deep recommender engine based on efficient product embeddings neural\n  pipeline", "comments": "2018 17th RoEduNet Conference: Networking in Education and Research\n  (RoEduNet)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Predictive analytics systems are currently one of the most important areas of\nresearch and development within the Artificial Intelligence domain and\nparticularly in Machine Learning. One of the \"holy grails\" of predictive\nanalytics is the research and development of the \"perfect\" recommendation\nsystem. In our paper, we propose an advanced pipeline model for the multi-task\nobjective of determining product complementarity, similarity and sales\nprediction using deep neural models applied to big-data sequential transaction\nsystems. Our highly parallelized hybrid model pipeline consists of both\nunsupervised and supervised models, used for the objectives of generating\nsemantic product embeddings and predicting sales, respectively. Our\nexperimentation and benchmarking processes have been done using pharma industry\nretail real-life transactional Big-Data streams.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 08:11:58 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 13:39:33 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Piciu", "Laurentiu", ""], ["Damian", "Andrei", ""], ["Tapus", "Nicolae", ""], ["Simion-Constantinescu", "Andrei", ""], ["Dumitrescu", "Bogdan", ""]]}, {"id": "1903.10012", "submitter": "Maria Perez-Ortiz", "authors": "Maria Perez-Ortiz, Pedro A. Gutierrez, Peter Tino, Carlos\n  Casanova-Mateo, Sancho Salcedo-Sanz", "title": "A mixture of experts model for predicting persistent weather patterns", "comments": "Published in IEEE International Joint Conference on Neural Networks\n  (IJCNN) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weather and atmospheric patterns are often persistent. The simplest weather\nforecasting method is the so-called persistence model, which assumes that the\nfuture state of a system will be similar (or equal) to the present state.\nMachine learning (ML) models are widely used in different weather forecasting\napplications, but they need to be compared to the persistence model to analyse\nwhether they provide a competitive solution to the problem at hand. In this\npaper, we devise a new model for predicting low-visibility in airports using\nthe concepts of mixture of experts. Visibility level is coded as two different\nordered categorical variables: cloud height and runway visual height. The\nunderlying system in this application is stagnant approximately in 90% of the\ncases, and standard ML models fail to improve on the performance of the\npersistence model. Because of this, instead of trying to simply beat the\npersistence model using ML, we use this persistence as a baseline and learn an\nordinal neural network model that refines its results by focusing on learning\nweather fluctuations. The results show that the proposal outperforms\npersistence and other ordinal autoregressive models, especially for longer time\nhorizon predictions and for the runway visual height variable.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 16:17:07 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Perez-Ortiz", "Maria", ""], ["Gutierrez", "Pedro A.", ""], ["Tino", "Peter", ""], ["Casanova-Mateo", "Carlos", ""], ["Salcedo-Sanz", "Sancho", ""]]}, {"id": "1903.10022", "submitter": "Maria Perez-Ortiz", "authors": "Maria Perez-Ortiz, Peter Tino, Rafal Mantiuk, Cesar Hervas-Martinez", "title": "Exploiting Synthetically Generated Data with Semi-Supervised Learning\n  for Small and Imbalanced Datasets", "comments": "Published in the Thirty-Third AAAI Conference on Artificial\n  Intelligence, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation is rapidly gaining attention in machine learning. Synthetic\ndata can be generated by simple transformations or through the data\ndistribution. In the latter case, the main challenge is to estimate the label\nassociated to new synthetic patterns. This paper studies the effect of\ngenerating synthetic data by convex combination of patterns and the use of\nthese as unsupervised information in a semi-supervised learning framework with\nsupport vector machines, avoiding thus the need to label synthetic examples. We\nperform experiments on a total of 53 binary classification datasets. Our\nresults show that this type of data over-sampling supports the well-known\ncluster assumption in semi-supervised learning, showing outstanding results for\nsmall high-dimensional datasets and imbalanced learning problems.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 17:09:28 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Perez-Ortiz", "Maria", ""], ["Tino", "Peter", ""], ["Mantiuk", "Rafal", ""], ["Hervas-Martinez", "Cesar", ""]]}, {"id": "1903.10145", "submitter": "Chunyuan Li", "authors": "Hao Fu, Chunyuan Li, Xiaodong Liu, Jianfeng Gao, Asli Celikyilmaz,\n  Lawrence Carin", "title": "Cyclical Annealing Schedule: A Simple Approach to Mitigating KL\n  Vanishing", "comments": "Published in NAACL 2019; The first two authors contribute equally;\n  Code: https://github.com/haofuml/cyclical_annealing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAEs) with an auto-regressive decoder have been\napplied for many natural language processing (NLP) tasks. The VAE objective\nconsists of two terms, (i) reconstruction and (ii) KL regularization, balanced\nby a weighting hyper-parameter \\beta. One notorious training difficulty is that\nthe KL term tends to vanish. In this paper we study scheduling schemes for\n\\beta, and show that KL vanishing is caused by the lack of good latent codes in\ntraining the decoder at the beginning of optimization. To remedy this, we\npropose a cyclical annealing schedule, which repeats the process of increasing\n\\beta multiple times. This new procedure allows the progressive learning of\nmore meaningful latent codes, by leveraging the informative representations of\nprevious cycles as warm re-starts. The effectiveness of cyclical annealing is\nvalidated on a broad range of NLP tasks, including language modeling, dialog\nresponse generation and unsupervised language pre-training.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 06:28:24 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 06:50:06 GMT"}, {"version": "v3", "created": "Mon, 10 Jun 2019 21:43:02 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Fu", "Hao", ""], ["Li", "Chunyuan", ""], ["Liu", "Xiaodong", ""], ["Gao", "Jianfeng", ""], ["Celikyilmaz", "Asli", ""], ["Carin", "Lawrence", ""]]}, {"id": "1903.10187", "submitter": "Christoph Benzm\\\"uller", "authors": "Christoph Benzm\\\"uller, Xavier Parent, Leendert van der Torre", "title": "Designing Normative Theories for Ethical and Legal Reasoning: LogiKEy\n  Framework, Methodology, and Tool Support", "comments": "50 pages; 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A framework and methodology---termed LogiKEy---for the design and engineering\nof ethical reasoners, normative theories and deontic logics is presented. The\noverall motivation is the development of suitable means for the control and\ngovernance of intelligent autonomous systems. LogiKEy's unifying formal\nframework is based on semantical embeddings of deontic logics, logic\ncombinations and ethico-legal domain theories in expressive classic\nhigher-order logic (HOL). This meta-logical approach enables the provision of\npowerful tool support in LogiKEy: off-the-shelf theorem provers and model\nfinders for HOL are assisting the LogiKEy designer of ethical intelligent\nagents to flexibly experiment with underlying logics and their combinations,\nwith ethico-legal domain theories, and with concrete examples---all at the same\ntime. Continuous improvements of these off-the-shelf provers, without further\nado, leverage the reasoning performance in LogiKEy. Case studies, in which the\nLogiKEy framework and methodology has been applied and tested, give evidence\nthat HOL's undecidability often does not hinder efficient experimentation.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 09:01:27 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2019 13:05:11 GMT"}, {"version": "v3", "created": "Fri, 9 Aug 2019 09:46:18 GMT"}, {"version": "v4", "created": "Sun, 18 Aug 2019 06:29:46 GMT"}, {"version": "v5", "created": "Fri, 27 Mar 2020 12:24:57 GMT"}, {"version": "v6", "created": "Sun, 24 May 2020 09:21:53 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Benzm\u00fcller", "Christoph", ""], ["Parent", "Xavier", ""], ["van der Torre", "Leendert", ""]]}, {"id": "1903.10245", "submitter": "Zheng-Yu Niu", "authors": "Zhibin Liu, Zheng-Yu Niu, Hua Wu, Haifeng Wang", "title": "Knowledge Aware Conversation Generation with Explainable Reasoning over\n  Augmented Graphs", "comments": "Accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two types of knowledge, triples from knowledge graphs and texts from\ndocuments, have been studied for knowledge aware open-domain conversation\ngeneration, in which graph paths can narrow down vertex candidates for\nknowledge selection decision, and texts can provide rich information for\nresponse generation. Fusion of a knowledge graph and texts might yield mutually\nreinforcing advantages, but there is less study on that. To address this\nchallenge, we propose a knowledge aware chatting machine with three components,\nan augmented knowledge graph with both triples and texts, knowledge selector,\nand knowledge aware response generator. For knowledge selection on the graph,\nwe formulate it as a problem of multi-hop graph reasoning to effectively\ncapture conversation flow, which is more explainable and flexible in comparison\nwith previous work. To fully leverage long text information that differentiates\nour graph from others, we improve a state of the art reasoning algorithm with\nmachine reading comprehension technology. We demonstrate the effectiveness of\nour system on two datasets in comparison with state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 11:23:17 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2019 10:12:48 GMT"}, {"version": "v3", "created": "Fri, 19 Apr 2019 02:24:09 GMT"}, {"version": "v4", "created": "Tue, 3 Sep 2019 04:36:06 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Liu", "Zhibin", ""], ["Niu", "Zheng-Yu", ""], ["Wu", "Hua", ""], ["Wang", "Haifeng", ""]]}, {"id": "1903.10246", "submitter": "Pierre-Yves Oudeyer", "authors": "Pierre-Yves Oudeyer, George Kachergis, William Schueller", "title": "Computational and Robotic Models of Early Language Development: A Review", "comments": "to appear in International Handbook on Language Development, ed. J.\n  Horst and J. von Koss Torkildsen, Routledge", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review computational and robotics models of early language learning and\ndevelopment. We first explain why and how these models are used to understand\nbetter how children learn language. We argue that they provide concrete\ntheories of language learning as a complex dynamic system, complementing\ntraditional methods in psychology and linguistics. We review different modeling\nformalisms, grounded in techniques from machine learning and artificial\nintelligence such as Bayesian and neural network approaches. We then discuss\ntheir role in understanding several key mechanisms of language development:\ncross-situational statistical learning, embodiment, situated social\ninteraction, intrinsically motivated learning, and cultural evolution. We\nconclude by discussing future challenges for research, including modeling of\nlarge-scale empirical data about language acquisition in real-world\nenvironments.\n  Keywords: Early language learning, Computational and robotic models, machine\nlearning, development, embodiment, social interaction, intrinsic motivation,\nself-organization, dynamical systems, complexity.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 11:28:36 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Oudeyer", "Pierre-Yves", ""], ["Kachergis", "George", ""], ["Schueller", "William", ""]]}, {"id": "1903.10325", "submitter": "Gary Merrill", "authors": "Gary H. Merrill", "title": "Ontology, Ontologies, and Science", "comments": null, "journal-ref": "Topoi 30 (2011) 71-83", "doi": "10.1007/s11245-011-9091-x", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Philosophers frequently struggle with the relation of metaphysics to the\neveryday world, with its practical value, and with its relation to empirical\nscience. This paper distinguishes several different models of the relation\nbetween philosophical ontology and applied (scientific) ontology that have been\nadvanced in the history of philosophy. Adoption of a strong participation model\nfor the philosophical ontologist in science is urged, and requirements and\nconsequences of the participation model are explored. This approach provides\nboth a principled view and justification of the role of the philosophical\nontologist in contemporary empirical science as well as guidelines for\nintegrating philosophers and philosophical contributions into the practice of\nscience.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 19:05:25 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Merrill", "Gary H.", ""]]}, {"id": "1903.10404", "submitter": "Bharat Prakash", "authors": "Bharat Prakash, Mark Horton, Nicholas R. Waytowich, William David\n  Hairston, Tim Oates, Tinoosh Mohsenin", "title": "On the use of Deep Autoencoders for Efficient Embedded Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In autonomous embedded systems, it is often vital to reduce the amount of\nactions taken in the real world and energy required to learn a policy. Training\nreinforcement learning agents from high dimensional image representations can\nbe very expensive and time consuming. Autoencoders are deep neural network used\nto compress high dimensional data such as pixelated images into small latent\nrepresentations. This compression model is vital to efficiently learn policies,\nespecially when learning on embedded systems. We have implemented this model on\nthe NVIDIA Jetson TX2 embedded GPU, and evaluated the power consumption,\nthroughput, and energy consumption of the autoencoders for various CPU/GPU core\ncombinations, frequencies, and model parameters. Additionally, we have shown\nthe reconstructions generated by the autoencoder to analyze the quality of the\ngenerated compressed representation and also the performance of the\nreinforcement learning agent. Finally, we have presented an assessment of the\nviability of training these models on embedded systems and their usefulness in\ndeveloping autonomous policies. Using autoencoders, we were able to achieve 4-5\n$\\times$ improved performance compared to a baseline RL agent with a\nconvolutional feature extractor, while using less than 2W of power.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 15:38:37 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Prakash", "Bharat", ""], ["Horton", "Mark", ""], ["Waytowich", "Nicholas R.", ""], ["Hairston", "William David", ""], ["Oates", "Tim", ""], ["Mohsenin", "Tinoosh", ""]]}, {"id": "1903.10410", "submitter": "Sidney Pontes-Filho", "authors": "Sidney Pontes-Filho and Stefano Nichele", "title": "A Conceptual Bio-Inspired Framework for the Evolution of Artificial\n  General Intelligence", "comments": "7 pages, 2 figures, accepted to \"The 3rd Special Session on\n  Biologically Inspired Parallel and Distributed Computing, Algorithms and\n  Solutions\" (BICAS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a conceptual bio-inspired parallel and distributed learning\nframework for the emergence of general intelligence is proposed, where agents\nevolve through environmental rewards and learn throughout their lifetime\nwithout supervision, i.e., self-learning through embodiment. The chosen control\nmechanism for agents is a biologically plausible neuron model based on spiking\nneural networks. Network topologies become more complex through evolution,\ni.e., the topology is not fixed, while the synaptic weights of the networks\ncannot be inherited, i.e., newborn brains are not trained and have no innate\nknowledge of the environment. What is subject to the evolutionary process is\nthe network topology, the type of neurons, and the type of learning. This\nprocess ensures that controllers that are passed through the generations have\nthe intrinsic ability to learn and adapt during their lifetime in mutable\nenvironments. We envision that the described approach may lead to the emergence\nof the simplest form of artificial general intelligence.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 15:49:07 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 08:22:46 GMT"}, {"version": "v3", "created": "Thu, 25 Apr 2019 15:52:45 GMT"}, {"version": "v4", "created": "Tue, 22 Sep 2020 08:49:57 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Pontes-Filho", "Sidney", ""], ["Nichele", "Stefano", ""]]}, {"id": "1903.10545", "submitter": "Ahmad Beirami", "authors": "Yunqi Zhao, Igor Borovikov, Fernando de Mesentier Silva, Ahmad\n  Beirami, Jason Rupert, Caedmon Somers, Jesse Harder, John Kolen, Jervis\n  Pinto, Reza Pourabolghasem, James Pestrak, Harold Chaput, Mohsen Sardari,\n  Long Lin, Sundeep Narravula, Navid Aghdaie, Kazi Zaman", "title": "Winning Isn't Everything: Enhancing Game Development with Intelligent\n  Agents", "comments": "Accepted to IEEE Trans. Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there have been several high-profile achievements of agents\nlearning to play games against humans and beat them. In this paper, we study\nthe problem of training intelligent agents in service of game development.\nUnlike the agents built to \"beat the game\", our agents aim to produce\nhuman-like behavior to help with game evaluation and balancing. We discuss two\nfundamental metrics based on which we measure the human-likeness of agents,\nnamely skill and style, which are multi-faceted concepts with practical\nimplications outlined in this paper. We report four case studies in which the\nstyle and skill requirements inform the choice of algorithms and metrics used\nto train agents; ranging from A* search to state-of-the-art deep reinforcement\nlearning. We, further, show that the learning potential of state-of-the-art\ndeep RL models does not seamlessly transfer from the benchmark environments to\ntarget ones without heavily tuning their hyperparameters, leading to linear\nscaling of the engineering efforts and computational cost with the number of\ntarget domains.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 18:39:04 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 00:19:51 GMT"}, {"version": "v3", "created": "Thu, 30 Jan 2020 04:37:58 GMT"}, {"version": "v4", "created": "Sat, 25 Apr 2020 18:36:10 GMT"}, {"version": "v5", "created": "Tue, 28 Apr 2020 03:29:36 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Zhao", "Yunqi", ""], ["Borovikov", "Igor", ""], ["Silva", "Fernando de Mesentier", ""], ["Beirami", "Ahmad", ""], ["Rupert", "Jason", ""], ["Somers", "Caedmon", ""], ["Harder", "Jesse", ""], ["Kolen", "John", ""], ["Pinto", "Jervis", ""], ["Pourabolghasem", "Reza", ""], ["Pestrak", "James", ""], ["Chaput", "Harold", ""], ["Sardari", "Mohsen", ""], ["Lin", "Long", ""], ["Narravula", "Sundeep", ""], ["Aghdaie", "Navid", ""], ["Zaman", "Kazi", ""]]}, {"id": "1903.10559", "submitter": "Luis A. Pineda", "authors": "Luis A. Pineda", "title": "The Mode of Computing", "comments": "35 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Turing Machine is the paradigmatic case of computing machines, but there\nare others, such as Artificial Neural Networks, Table Computing,\nRelational-Indeterminate Computing and diverse forms of analogical computing,\neach of which based on a particular underlying intuition of the phenomenon of\ncomputing. This variety can be captured in terms of system levels,\nre-interpreting and generalizing Newell's hierarchy, which includes the\nknowledge level at the top and the symbol level immediately below it. In this\nre-interpretation the knowledge level consists of human knowledge and the\nsymbol level is generalized into a new level that here is called The Mode of\nComputing. Natural computing performed by the brains of humans and non-human\nanimals with a developed enough neural system should be understood in terms of\na hierarchy of system levels too. By analogy from standard computing machinery\nthere must be a system level above the neural circuitry levels and directly\nbelow the knowledge level that is named here The mode of Natural Computing. A\ncentral question for Cognition is the characterization of this mode. The Mode\nof Computing provides a novel perspective on the phenomena of computing,\ninterpreting, the representational and non-representational views of cognition,\nand consciousness.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 19:25:16 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 17:20:01 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Pineda", "Luis A.", ""]]}, {"id": "1903.10572", "submitter": "Dongrui Wu", "authors": "Dongrui Wu and Chin-Teng Lin and Jian Huang and Zhigang Zeng", "title": "On the Functional Equivalence of TSK Fuzzy Systems to Neural Networks,\n  Mixture of Experts, CART, and Stacking Ensemble Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzy systems have achieved great success in numerous applications. However,\nthere are still many challenges in designing an optimal fuzzy system, e.g., how\nto efficiently optimize its parameters, how to balance the trade-off between\ncooperations and competitions among the rules, how to overcome the curse of\ndimensionality, how to increase its generalization ability, etc. Literature has\nshown that by making appropriate connections between fuzzy systems and other\nmachine learning approaches, good practices from other domains may be used to\nimprove the fuzzy systems, and vice versa. This paper gives an overview on the\nfunctional equivalence between Takagi-Sugeno-Kang fuzzy systems and four\nclassic machine learning approaches -- neural networks, mixture of experts,\nclassification and regression trees, and stacking ensemble regression -- for\nregression problems. We also point out some promising new research directions,\ninspired by the functional equivalence, that could lead to solutions to the\naforementioned problems. To our knowledge, this is so far the most\ncomprehensive overview on the connections between fuzzy systems and other\npopular machine learning approaches, and hopefully will stimulate more\nhybridization between different machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 19:52:17 GMT"}, {"version": "v2", "created": "Sat, 13 Jul 2019 17:18:14 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Wu", "Dongrui", ""], ["Lin", "Chin-Teng", ""], ["Huang", "Jian", ""], ["Zeng", "Zhigang", ""]]}, {"id": "1903.10605", "submitter": "Riley Simmons-Edler", "authors": "Riley Simmons-Edler, Ben Eisner, Eric Mitchell, Sebastian Seung,\n  Daniel Lee", "title": "Q-Learning for Continuous Actions with Cross-Entropy Guided Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-Policy reinforcement learning (RL) is an important class of methods for\nmany problem domains, such as robotics, where the cost of collecting data is\nhigh and on-policy methods are consequently intractable. Standard methods for\napplying Q-learning to continuous-valued action domains involve iteratively\nsampling the Q-function to find a good action (e.g. via hill-climbing), or by\nlearning a policy network at the same time as the Q-function (e.g. DDPG). Both\napproaches make tradeoffs between stability, speed, and accuracy. We propose a\nnovel approach, called Cross-Entropy Guided Policies, or CGP, that draws\ninspiration from both classes of techniques. CGP aims to combine the stability\nand performance of iterative sampling policies with the low computational cost\nof a policy network. Our approach trains the Q-function using iterative\nsampling with the Cross-Entropy Method (CEM), while training a policy network\nto imitate CEM's sampling behavior. We demonstrate that our method is more\nstable to train than state of the art policy network methods, while preserving\nequivalent inference time compute costs, and achieving competitive total reward\non standard benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 21:46:58 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2019 21:52:02 GMT"}, {"version": "v3", "created": "Mon, 1 Jul 2019 21:03:09 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Simmons-Edler", "Riley", ""], ["Eisner", "Ben", ""], ["Mitchell", "Eric", ""], ["Seung", "Sebastian", ""], ["Lee", "Daniel", ""]]}, {"id": "1903.10630", "submitter": "Budhaditya Deb", "authors": "Budhaditya Deb and Peter Bailey and Milad Shokouhi", "title": "Diversifying Reply Suggestions using a Matching-Conditional Variational\n  Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of diversifying automated reply suggestions for a\ncommercial instant-messaging (IM) system (Skype). Our conversation model is a\nstandard matching based information retrieval architecture, which consists of\ntwo parallel encoders to project messages and replies into a common feature\nrepresentation. During inference, we select replies from a fixed response set\nusing nearest neighbors in the feature space. To diversify responses, we\nformulate the model as a generative latent variable model with Conditional\nVariational Auto-Encoder (M-CVAE). We propose a constrained-sampling approach\nto make the variational inference in M-CVAE efficient for our production\nsystem. In offline experiments, M-CVAE consistently increased diversity by\n~30-40% without significant impact on relevance. This translated to a 5% gain\nin click-rate in our online production system.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 23:12:56 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Deb", "Budhaditya", ""], ["Bailey", "Peter", ""], ["Shokouhi", "Milad", ""]]}, {"id": "1903.10654", "submitter": "Akifumi Wachi", "authors": "Akifumi Wachi", "title": "Failure-Scenario Maker for Rule-Based Agent using Multi-agent\n  Adversarial Reinforcement Learning and its Application to Autonomous Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the problem of adversarial reinforcement learning for multi-agent\ndomains including a rule-based agent. Rule-based algorithms are required in\nsafety-critical applications for them to work properly in a wide range of\nsituations. Hence, every effort is made to find failure scenarios during the\ndevelopment phase. However, as the software becomes complicated, finding\nfailure cases becomes difficult. Especially in multi-agent domains, such as\nautonomous driving environments, it is much harder to find useful failure\nscenarios that help us improve the algorithm. We propose a method for\nefficiently finding failure scenarios; this method trains the adversarial\nagents using multi-agent reinforcement learning such that the tested rule-based\nagent fails. We demonstrate the effectiveness of our proposed method using a\nsimple environment and autonomous driving simulator.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 02:15:59 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 06:39:52 GMT"}, {"version": "v3", "created": "Sat, 25 May 2019 01:00:19 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Wachi", "Akifumi", ""]]}, {"id": "1903.10716", "submitter": "Cunxiang Wang", "authors": "Cunxiang Wang, Feiliang Ren, Zhichao Lin, Chenxv Zhao, Tian Xie and\n  Yue Zhang", "title": "Domain Representation for Knowledge Graph Embedding", "comments": "Acceptted by NLPCC2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding entities and relations into a continuous multi-dimensional vector\nspace have become the dominant method for knowledge graph embedding in\nrepresentation learning. However, most existing models ignore to represent\nhierarchical knowledge, such as the similarities and dissimilarities of\nentities in one domain. We proposed to learn a Domain Representations over\nexisting knowledge graph embedding models, such that entities that have similar\nattributes are organized into the same domain. Such hierarchical knowledge of\ndomains can give further evidence in link prediction. Experimental results show\nthat domain embeddings give a significant improvement over the most recent\nstate-of-art baseline knowledge graph embedding models.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 07:44:39 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 13:35:14 GMT"}, {"version": "v3", "created": "Thu, 16 May 2019 08:36:37 GMT"}, {"version": "v4", "created": "Wed, 11 Sep 2019 12:58:44 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Wang", "Cunxiang", ""], ["Ren", "Feiliang", ""], ["Lin", "Zhichao", ""], ["Zhao", "Chenxv", ""], ["Xie", "Tian", ""], ["Zhang", "Yue", ""]]}, {"id": "1903.10862", "submitter": "Dongrui Wu", "authors": "Dongrui Wu and Feifei Liu and Chengyu Liu", "title": "Active Stacking for Heart Rate Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heart rate estimation from electrocardiogram signals is very important for\nthe early detection of cardiovascular diseases. However, due to large\nindividual differences and varying electrocardiogram signal quality, there does\nnot exist a single reliable estimation algorithm that works well on all\nsubjects. Every algorithm may break down on certain subjects, resulting in a\nsignificant estimation error. Ensemble regression, which aggregates the outputs\nof multiple base estimators for more reliable and stable estimates, can be used\nto remedy this problem. Moreover, active learning can be used to optimally\nselect a few trials from a new subject to label, based on which a stacking\nensemble regression model can be trained to aggregate the base estimators. This\npaper proposes four active stacking approaches, and demonstrates that they all\nsignificantly outperform three common unsupervised ensemble regression\napproaches, and a supervised stacking approach which randomly selects some\ntrials to label. Remarkably, our active stacking approaches only need three or\nfour labeled trials from each subject to achieve an average root mean squared\nestimation error below three beats per minute, making them very convenient for\nreal-world applications. To our knowledge, this is the first research on active\nstacking, and its application to heart rate estimation.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 13:26:34 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Wu", "Dongrui", ""], ["Liu", "Feifei", ""], ["Liu", "Chengyu", ""]]}, {"id": "1903.10920", "submitter": "Amir Rosenfeld", "authors": "Amir Rosenfeld, Richard Zemel, John K. Tsotsos", "title": "High-Level Perceptual Similarity is Enabled by Learning Diverse Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting human perceptual similarity is a challenging subject of ongoing\nresearch. The visual process underlying this aspect of human vision is thought\nto employ multiple different levels of visual analysis (shapes, objects,\ntexture, layout, color, etc). In this paper, we postulate that the perception\nof image similarity is not an explicitly learned capability, but rather one\nthat is a byproduct of learning others. This claim is supported by leveraging\nrepresentations learned from a diverse set of visual tasks and using them\njointly to predict perceptual similarity. This is done via simple feature\nconcatenation, without any further learning. Nevertheless, experiments\nperformed on the challenging Totally-Looks-Like (TLL) benchmark significantly\nsurpass recent baselines, closing much of the reported gap towards prediction\nof human perceptual similarity. We provide an analysis of these results and\ndiscuss them in a broader context of emergent visual capabilities and their\nimplications on the course of machine-vision research.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 14:32:02 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Rosenfeld", "Amir", ""], ["Zemel", "Richard", ""], ["Tsotsos", "John K.", ""]]}, {"id": "1903.10951", "submitter": "Dongrui Wu", "authors": "Dongrui Wu and Ye Yuan and Yihua Tan", "title": "Optimize TSK Fuzzy Systems for Regression Problems: Mini-Batch Gradient\n  Descent with Regularization, DropRule and AdaBound (MBGD-RDA)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Takagi-Sugeno-Kang (TSK) fuzzy systems are very useful machine learning\nmodels for regression problems. However, to our knowledge, there has not\nexisted an efficient and effective training algorithm that ensures their\ngeneralization performance, and also enables them to deal with big data.\nInspired by the connections between TSK fuzzy systems and neural networks, we\nextend three powerful neural network optimization techniques, i.e., mini-batch\ngradient descent, regularization, and AdaBound, to TSK fuzzy systems, and also\npropose three novel techniques (DropRule, DropMF, and DropMembership)\nspecifically for training TSK fuzzy systems. Our final algorithm, mini-batch\ngradient descent with regularization, DropRule and AdaBound (MBGD-RDA), can\nachieve fast convergence in training TSK fuzzy systems, and also superior\ngeneralization performance in testing. It can be used for training TSK fuzzy\nsystems on datasets of any size; however, it is particularly useful for big\ndatasets, on which currently no other efficient training algorithms exist.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 15:16:24 GMT"}, {"version": "v2", "created": "Sat, 11 May 2019 11:37:38 GMT"}, {"version": "v3", "created": "Tue, 17 Sep 2019 01:45:17 GMT"}, {"version": "v4", "created": "Sun, 1 Dec 2019 04:58:47 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Wu", "Dongrui", ""], ["Yuan", "Ye", ""], ["Tan", "Yihua", ""]]}, {"id": "1903.10983", "submitter": "Benjamin Doerr", "authors": "Benjamin Doerr", "title": "A Tight Runtime Analysis for the cGA on Jump Functions---EDAs Can Cross\n  Fitness Valleys at No Extra Cost", "comments": "25 pages, full version of a paper to appear at GECCO 2019", "journal-ref": null, "doi": "10.1145/3321707.3321747", "report-no": null, "categories": "cs.NE cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the compact genetic algorithm (cGA) with hypothetical\npopulation size $\\mu = \\Omega(\\sqrt n \\log n) \\cap \\text{poly}(n)$ with high\nprobability finds the optimum of any $n$-dimensional jump function with jump\nsize $k < \\frac 1 {20} \\ln n$ in $O(\\mu \\sqrt n)$ iterations. Since it is known\nthat the cGA with high probability needs at least $\\Omega(\\mu \\sqrt n + n \\log\nn)$ iterations to optimize the unimodal OneMax function, our result shows that\nthe cGA in contrast to most classic evolutionary algorithms here is able to\ncross moderate-sized valleys of low fitness at no extra cost.\n  Our runtime guarantee improves over the recent upper bound $O(\\mu n^{1.5}\n\\log n)$ valid for $\\mu = \\Omega(n^{3.5+\\varepsilon})$ of Hasen\\\"ohrl and\nSutton (GECCO 2018). For the best choice of the hypothetical population size,\nthis result gives a runtime guarantee of $O(n^{5+\\varepsilon})$, whereas ours\ngives $O(n \\log n)$.\n  We also provide a simple general method based on parallel runs that, under\nmild conditions, (i)~overcomes the need to specify a suitable population size,\nbut gives a performance close to the one stemming from the best-possible\npopulation size, and (ii)~transforms EDAs with high-probability performance\nguarantees into EDAs with similar bounds on the expected runtime.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 16:12:02 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Doerr", "Benjamin", ""]]}, {"id": "1903.11137", "submitter": "Ilia Shumailov", "authors": "Ilia Shumailov, Laurent Simon, Jeff Yan, Ross Anderson", "title": "Hearing your touch: A new acoustic side channel on smartphones", "comments": "Paper built on the MPhil thesis of Ilia Shumailov. 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present the first acoustic side-channel attack that recovers what users\ntype on the virtual keyboard of their touch-screen smartphone or tablet. When a\nuser taps the screen with a finger, the tap generates a sound wave that\npropagates on the screen surface and in the air. We found the device's\nmicrophone(s) can recover this wave and \"hear\" the finger's touch, and the\nwave's distortions are characteristic of the tap's location on the screen.\nHence, by recording audio through the built-in microphone(s), a malicious app\ncan infer text as the user enters it on their device. We evaluate the\neffectiveness of the attack with 45 participants in a real-world environment on\nan Android tablet and an Android smartphone. For the tablet, we recover 61% of\n200 4-digit PIN-codes within 20 attempts, even if the model is not trained with\nthe victim's data. For the smartphone, we recover 9 words of size 7--13 letters\nwith 50 attempts in a common side-channel attack benchmark. Our results suggest\nthat it not always sufficient to rely on isolation mechanisms such as TrustZone\nto protect user input. We propose and discuss hardware, operating-system and\napplication-level mechanisms to block this attack more effectively. Mobile\ndevices may need a richer capability model, a more user-friendly notification\nsystem for sensor usage and a more thorough evaluation of the information\nleaked by the underlying hardware.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 20:06:26 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Shumailov", "Ilia", ""], ["Simon", "Laurent", ""], ["Yan", "Jeff", ""], ["Anderson", "Ross", ""]]}, {"id": "1903.11174", "submitter": "Rogerio Bonatti", "authors": "Wenshan Wang, Aayush Ahuja, Yanfu Zhang, Rogerio Bonatti, Sebastian\n  Scherer", "title": "Improved Generalization of Heading Direction Estimation for Aerial\n  Filming Using Semi-supervised Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the task of Autonomous aerial filming of a moving actor (e.g. a person or\na vehicle), it is crucial to have a good heading direction estimation for the\nactor from the visual input. However, the models obtained in other similar\ntasks, such as pedestrian collision risk analysis and human-robot interaction,\nare very difficult to generalize to the aerial filming task, because of the\ndifference in data distributions. Towards improving generalization with less\namount of labeled data, this paper presents a semi-supervised algorithm for\nheading direction estimation problem. We utilize temporal continuity as the\nunsupervised signal to regularize the model and achieve better generalization\nability. This semi-supervised algorithm is applied to both training and testing\nphases, which increases the testing performance by a large margin. We show that\nby leveraging unlabeled sequences, the amount of labeled data required can be\nsignificantly reduced. We also discuss several important details on improving\nthe performance by balancing labeled and unlabeled loss, and making good\ncombinations. Experimental results show that our approach robustly outputs the\nheading direction for different types of actor. The aesthetic value of the\nvideo is also improved in the aerial filming task.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 22:05:05 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Wang", "Wenshan", ""], ["Ahuja", "Aayush", ""], ["Zhang", "Yanfu", ""], ["Bonatti", "Rogerio", ""], ["Scherer", "Sebastian", ""]]}, {"id": "1903.11239", "submitter": "Andy Zeng", "authors": "Andy Zeng, Shuran Song, Johnny Lee, Alberto Rodriguez, Thomas\n  Funkhouser", "title": "TossingBot: Learning to Throw Arbitrary Objects with Residual Physics", "comments": "Summary Video: https://youtu.be/f5Zn2Up2RjQ Project webpage:\n  https://tossingbot.cs.princeton.edu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate whether a robot arm can learn to pick and throw arbitrary\nobjects into selected boxes quickly and accurately. Throwing has the potential\nto increase the physical reachability and picking speed of a robot arm.\nHowever, precisely throwing arbitrary objects in unstructured settings presents\nmany challenges: from acquiring reliable pre-throw conditions (e.g. initial\npose of object in manipulator) to handling varying object-centric properties\n(e.g. mass distribution, friction, shape) and dynamics (e.g. aerodynamics). In\nthis work, we propose an end-to-end formulation that jointly learns to infer\ncontrol parameters for grasping and throwing motion primitives from visual\nobservations (images of arbitrary objects in a bin) through trial and error.\nWithin this formulation, we investigate the synergies between grasping and\nthrowing (i.e., learning grasps that enable more accurate throws) and between\nsimulation and deep learning (i.e., using deep networks to predict residuals on\ntop of control parameters predicted by a physics simulator). The resulting\nsystem, TossingBot, is able to grasp and throw arbitrary objects into boxes\nlocated outside its maximum reach range at 500+ mean picks per hour (600+\ngrasps per hour with 85% throwing accuracy); and generalizes to new objects and\ntarget locations. Videos are available at https://tossingbot.cs.princeton.edu\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 04:04:28 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 19:16:12 GMT"}, {"version": "v3", "created": "Sat, 30 May 2020 15:59:12 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Zeng", "Andy", ""], ["Song", "Shuran", ""], ["Lee", "Johnny", ""], ["Rodriguez", "Alberto", ""], ["Funkhouser", "Thomas", ""]]}, {"id": "1903.11241", "submitter": "Neil Lawrence", "authors": "Neil D. Lawrence", "title": "Data Science and Digital Systems: The 3Ds of Machine Learning Systems\n  Design", "comments": "Paper presented at the Stu Hunter Research Conference held at the\n  Villa Porro Pirelli in Induno Olona, Italy, from Sunday February 17th to\n  Wednesday February 20th, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning solutions, in particular those based on deep learning\nmethods, form an underpinning of the current revolution in \"artificial\nintelligence\" that has dominated popular press headlines and is having a\nsignificant influence on the wider tech agenda. Here we give an overview of the\n3Ds of ML systems design: Data, Design and Deployment. By considering the 3Ds\nwe can move towards \\emph{data first} design.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 13:27:37 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Lawrence", "Neil D.", ""]]}, {"id": "1903.11253", "submitter": "Qun Liu", "authors": "Qun Liu, Supratik Mukhopadhyay, Yimin Zhu, Ravindra Gudishala, Sanaz\n  Saeidi, Alimire Nabijiang", "title": "Improving Route Choice Models by Incorporating Contextual Factors via\n  Knowledge Distillation", "comments": "Paper was accepted at the 2019 International Joint Conference on\n  Neural Networks (IJCNN 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Route Choice Models predict the route choices of travelers traversing an\nurban area. Most of the route choice models link route characteristics of\nalternative routes to those chosen by the drivers. The models play an important\nrole in prediction of traffic levels on different routes and thus assist in\ndevelopment of efficient traffic management strategies that result in\nminimizing traffic delay and maximizing effective utilization of transport\nsystem. High fidelity route choice models are required to predict traffic\nlevels with higher accuracy. Existing route choice models do not take into\naccount dynamic contextual conditions such as the occurrence of an accident,\nthe socio-cultural and economic background of drivers, other human behaviors,\nthe dynamic personal risk level, etc. As a result, they can only make\npredictions at an aggregate level and for a fixed set of contextual factors.\nFor higher fidelity, it is highly desirable to use a model that captures\nsignificance of subjective or contextual factors in route choice. This paper\npresents a novel approach for developing high-fidelity route choice models with\nincreased predictive power by augmenting existing aggregate level baseline\nmodels with information on drivers' responses to contextual factors obtained\nfrom Stated Choice Experiments carried out in an Immersive Virtual Environment\nthrough the use of knowledge distillation.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 05:18:21 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Liu", "Qun", ""], ["Mukhopadhyay", "Supratik", ""], ["Zhu", "Yimin", ""], ["Gudishala", "Ravindra", ""], ["Saeidi", "Sanaz", ""], ["Nabijiang", "Alimire", ""]]}, {"id": "1903.11277", "submitter": "Masataro Asai", "authors": "Masataro Asai, Hiroshi Kajino", "title": "Towards Stable Symbol Grounding with Zero-Suppressed State AutoEncoder", "comments": "Accepted in 29th International Conference of Automated Planning and\n  Scheduling (ICAPS-2019), Planning and Learning track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While classical planning has been an active branch of AI, its applicability\nis limited to the tasks precisely modeled by humans. Fully automated high-level\nagents should be instead able to find a symbolic representation of an unknown\nenvironment without supervision, otherwise it exhibits the knowledge\nacquisition bottleneck. Meanwhile, Latplan (Asai and Fukunaga 2018) partially\nresolves the bottleneck with a neural network called State AutoEncoder (SAE).\nSAE obtains the propositional representation of the image-based puzzle domains\nwith unsupervised learning, generates a state space and performs classical\nplanning. In this paper, we identify the problematic, stochastic behavior of\nthe SAE-produced propositions as a new sub-problem of symbol grounding problem,\nthe symbol stability problem. Informally, symbols are stable when their\nreferents (e.g. propositional values) do not change against small perturbation\nof the observation, and unstable symbols are harmful for symbolic reasoning. We\nanalyze the problem in Latplan both formally and empirically, and propose\n\"Zero-Suppressed SAE\", an enhancement that stabilizes the propositions using\nthe idea of closed-world assumption as a prior for NN optimization. We show\nthat it finds the more stable propositions and the more compact\nrepresentations, resulting in an improved success rate of Latplan. It is robust\nagainst various hyperparameters and eases the tuning effort, and also provides\na weight pruning capability as a side effect.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 07:46:02 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Asai", "Masataro", ""], ["Kajino", "Hiroshi", ""]]}, {"id": "1903.11314", "submitter": "Ruben Mayer", "authors": "Ruben Mayer and Hans-Arno Jacobsen", "title": "Scalable Deep Learning on Distributed Infrastructures: Challenges,\n  Techniques and Tools", "comments": "accepted at ACM Computing Surveys, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL) has had an immense success in the recent past, leading to\nstate-of-the-art results in various domains such as image recognition and\nnatural language processing. One of the reasons for this success is the\nincreasing size of DL models and the proliferation of vast amounts of training\ndata being available. To keep on improving the performance of DL, increasing\nthe scalability of DL systems is necessary. In this survey, we perform a broad\nand thorough investigation on challenges, techniques and tools for scalable DL\non distributed infrastructures. This incorporates infrastructures for DL,\nmethods for parallel DL training, multi-tenant resource scheduling and the\nmanagement of training and model data. Further, we analyze and compare 11\ncurrent open-source DL frameworks and tools and investigate which of the\ntechniques are commonly implemented in practice. Finally, we highlight future\nresearch trends in DL systems that deserve further research.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 09:46:52 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 08:51:24 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Mayer", "Ruben", ""], ["Jacobsen", "Hans-Arno", ""]]}, {"id": "1903.11329", "submitter": "Shangtong Zhang", "authors": "Shangtong Zhang, Wendelin Boehmer, Shimon Whiteson", "title": "Generalized Off-Policy Actor-Critic", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new objective, the counterfactual objective, unifying existing\nobjectives for off-policy policy gradient algorithms in the continuing\nreinforcement learning (RL) setting. Compared to the commonly used excursion\nobjective, which can be misleading about the performance of the target policy\nwhen deployed, our new objective better predicts such performance. We prove the\nGeneralized Off-Policy Policy Gradient Theorem to compute the policy gradient\nof the counterfactual objective and use an emphatic approach to get an unbiased\nsample from this policy gradient, yielding the Generalized Off-Policy\nActor-Critic (Geoff-PAC) algorithm. We demonstrate the merits of Geoff-PAC over\nexisting algorithms in Mujoco robot simulation tasks, the first empirical\nsuccess of emphatic algorithms in prevailing deep RL benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 10:17:13 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 10:45:48 GMT"}, {"version": "v3", "created": "Mon, 10 Jun 2019 23:26:22 GMT"}, {"version": "v4", "created": "Mon, 17 Jun 2019 20:55:53 GMT"}, {"version": "v5", "created": "Fri, 13 Sep 2019 15:32:03 GMT"}, {"version": "v6", "created": "Mon, 16 Sep 2019 20:41:03 GMT"}, {"version": "v7", "created": "Mon, 14 Oct 2019 20:22:42 GMT"}, {"version": "v8", "created": "Mon, 28 Oct 2019 09:58:44 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Zhang", "Shangtong", ""], ["Boehmer", "Wendelin", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1903.11341", "submitter": "Nikita Dvornik", "authors": "Nikita Dvornik, Cordelia Schmid, Julien Mairal", "title": "Diversity with Cooperation: Ensemble Methods for Few-Shot Classification", "comments": "Added experiments for different network architectures across\n  different input image resolutions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot classification consists of learning a predictive model that is able\nto effectively adapt to a new class, given only a few annotated samples. To\nsolve this challenging problem, meta-learning has become a popular paradigm\nthat advocates the ability to \"learn to adapt\". Recent works have shown,\nhowever, that simple learning strategies without meta-learning could be\ncompetitive. In this paper, we go a step further and show that by addressing\nthe fundamental high-variance issue of few-shot learning classifiers, it is\npossible to significantly outperform current meta-learning techniques. Our\napproach consists of designing an ensemble of deep networks to leverage the\nvariance of the classifiers, and introducing new strategies to encourage the\nnetworks to cooperate, while encouraging prediction diversity. Evaluation is\nconducted on the mini-ImageNet and CUB datasets, where we show that even a\nsingle network obtained by distillation yields state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 10:53:22 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 09:34:59 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Dvornik", "Nikita", ""], ["Schmid", "Cordelia", ""], ["Mairal", "Julien", ""]]}, {"id": "1903.11367", "submitter": "Yang Gao", "authors": "Yang Gao, Steffen Eger, Ilia Kuznetsov, Iryna Gurevych, Yusuke Miyao", "title": "Does My Rebuttal Matter? Insights from a Major NLP Conference", "comments": "Accepted to NAACL-HLT 2019. Main paper plus supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer review is a core element of the scientific process, particularly in\nconference-centered fields such as ML and NLP. However, only few studies have\nevaluated its properties empirically. Aiming to fill this gap, we present a\ncorpus that contains over 4k reviews and 1.2k author responses from ACL-2018.\nWe quantitatively and qualitatively assess the corpus. This includes a pilot\nstudy on paper weaknesses given by reviewers and on quality of author\nresponses. We then focus on the role of the rebuttal phase, and propose a novel\ntask to predict after-rebuttal (i.e., final) scores from initial reviews and\nauthor responses. Although author responses do have a marginal (and\nstatistically significant) influence on the final scores, especially for\nborderline papers, our results suggest that a reviewer's final score is largely\ndetermined by her initial score and the distance to the other reviewers'\ninitial scores. In this context, we discuss the conformity bias inherent to\npeer reviewing, a bias that has largely been overlooked in previous research.\nWe hope our analyses will help better assess the usefulness of the rebuttal\nphase in NLP conferences.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 12:00:20 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2019 08:40:05 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Gao", "Yang", ""], ["Eger", "Steffen", ""], ["Kuznetsov", "Ilia", ""], ["Gurevych", "Iryna", ""], ["Miyao", "Yusuke", ""]]}, {"id": "1903.11406", "submitter": "Hung Nghiep Tran", "authors": "Hung Nghiep Tran, Atsuhiro Takasu", "title": "Analyzing Knowledge Graph Embedding Methods from a Multi-Embedding\n  Interaction Perspective", "comments": "DSI4 at EDBT/ICDT 2019. Source code is available on github at\n  https://github.com/tranhungnghiep/AnalyzingKGEmbeddings", "journal-ref": "Data Science for Industry 4.0 at EDBT/ICDT 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge graph is a popular format for representing knowledge, with many\napplications to semantic search engines, question-answering systems, and\nrecommender systems. Real-world knowledge graphs are usually incomplete, so\nknowledge graph embedding methods, such as Canonical decomposition/Parallel\nfactorization (CP), DistMult, and ComplEx, have been proposed to address this\nissue. These methods represent entities and relations as embedding vectors in\nsemantic space and predict the links between them. The embedding vectors\nthemselves contain rich semantic information and can be used in other\napplications such as data analysis. However, mechanisms in these models and the\nembedding vectors themselves vary greatly, making it difficult to understand\nand compare them. Given this lack of understanding, we risk using them\nineffectively or incorrectly, particularly for complicated models, such as CP,\nwith two role-based embedding vectors, or the state-of-the-art ComplEx model,\nwith complex-valued embedding vectors. In this paper, we propose a\nmulti-embedding interaction mechanism as a new approach to uniting and\ngeneralizing these models. We derive them theoretically via this mechanism and\nprovide empirical analyses and comparisons between them. We also propose a new\nmulti-embedding model based on quaternion algebra and show that it achieves\npromising results using popular benchmarks. Source code is available on github\nat https://github.com/tranhungnghiep/AnalyzingKGEmbeddings\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 13:09:16 GMT"}, {"version": "v2", "created": "Sat, 19 Oct 2019 04:34:16 GMT"}, {"version": "v3", "created": "Thu, 14 May 2020 19:58:51 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Tran", "Hung Nghiep", ""], ["Takasu", "Atsuhiro", ""]]}, {"id": "1903.11421", "submitter": "Richard Jiang", "authors": "Ziping Jiang, Paul L. Chazot, M. Emre Celebi, Danny Crookes and\n  Richard Jiang", "title": "Social Behavioral Phenotyping of Drosophila with a2D-3D Hybrid CNN\n  Framework", "comments": null, "journal-ref": "IEEE Access 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.ET cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Behavioural phenotyping of Drosophila is an important means in biological and\nmedical research to identify genetic, pathologic or psychologic impact on\nanimal behaviour.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 13:41:17 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Jiang", "Ziping", ""], ["Chazot", "Paul L.", ""], ["Celebi", "M. Emre", ""], ["Crookes", "Danny", ""], ["Jiang", "Richard", ""]]}, {"id": "1903.11524", "submitter": "Dmytro Korenkevych", "authors": "Dmytro Korenkevych, A. Rupam Mahmood, Gautham Vasan, James Bergstra", "title": "Autoregressive Policies for Continuous Control Deep Reinforcement\n  Learning", "comments": "Submitted to 28th International Joint Conference on Artificial\n  Intelligence (IJCAI 2019). Video: https://youtu.be/NCpyXBNqNmw Code:\n  https://github.com/dkorenkevych/arp", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning algorithms rely on exploration to discover new\nbehaviors, which is typically achieved by following a stochastic policy. In\ncontinuous control tasks, policies with a Gaussian distribution have been\nwidely adopted. Gaussian exploration however does not result in smooth\ntrajectories that generally correspond to safe and rewarding behaviors in\npractical tasks. In addition, Gaussian policies do not result in an effective\nexploration of an environment and become increasingly inefficient as the action\nrate increases. This contributes to a low sample efficiency often observed in\nlearning continuous control tasks. We introduce a family of stationary\nautoregressive (AR) stochastic processes to facilitate exploration in\ncontinuous control domains. We show that proposed processes possess two\ndesirable features: subsequent process observations are temporally coherent\nwith continuously adjustable degree of coherence, and the process stationary\ndistribution is standard normal. We derive an autoregressive policy (ARP) that\nimplements such processes maintaining the standard agent-environment interface.\nWe show how ARPs can be easily used with the existing off-the-shelf learning\nalgorithms. Empirically we demonstrate that using ARPs results in improved\nexploration and sample efficiency in both simulated and real world domains,\nand, furthermore, provides smooth exploration trajectories that enable safe\noperation of robotic hardware.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 16:22:48 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Korenkevych", "Dmytro", ""], ["Mahmood", "A. Rupam", ""], ["Vasan", "Gautham", ""], ["Bergstra", "James", ""]]}, {"id": "1903.11570", "submitter": "No\\'e Tits", "authors": "No\\'e Tits, Fengna Wang, Kevin El Haddad, Vincent Pagel, Thierry\n  Dutoit", "title": "Visualization and Interpretation of Latent Spaces for Controlling\n  Expressive Speech Synthesis through Audio Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of Text-to-Speech has experienced huge improvements last years\nbenefiting from deep learning techniques. Producing realistic speech becomes\npossible now. As a consequence, the research on the control of the\nexpressiveness, allowing to generate speech in different styles or manners, has\nattracted increasing attention lately. Systems able to control style have been\ndeveloped and show impressive results. However the control parameters often\nconsist of latent variables and remain complex to interpret. In this paper, we\nanalyze and compare different latent spaces and obtain an interpretation of\ntheir influence on expressive speech. This will enable the possibility to build\ncontrollable speech synthesis systems with an understandable behaviour.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 17:33:33 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Tits", "No\u00e9", ""], ["Wang", "Fengna", ""], ["Haddad", "Kevin El", ""], ["Pagel", "Vincent", ""], ["Dutoit", "Thierry", ""]]}, {"id": "1903.11593", "submitter": "Stephen Baek", "authors": "Stephen Baek, Yusen He, Bryan G. Allen, John M. Buatti, Brian J.\n  Smith, Ling Tong, Zhiyu Sun, Jia Wu, Maximilian Diehn, Billy W. Loo, Kristin\n  A. Plichta, Steven N. Seyedin, Maggie Gannon, Katherine R. Cabel, Yusung Kim,\n  Xiaodong Wu", "title": "Deep segmentation networks predict survival of non-small cell lung\n  cancer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-small-cell lung cancer (NSCLC) represents approximately 80-85% of lung\ncancer diagnoses and is the leading cause of cancer-related death worldwide.\nRecent studies indicate that image-based radiomics features from positron\nemission tomography-computed tomography (PET/CT) images have predictive power\non NSCLC outcomes. To this end, easily calculated functional features such as\nthe maximum and the mean of standard uptake value (SUV) and total lesion\nglycolysis (TLG) are most commonly used for NSCLC prognostication, but their\nprognostic value remains controversial. Meanwhile, convolutional neural\nnetworks (CNN) are rapidly emerging as a new premise for cancer image analysis,\nwith significantly enhanced predictive power compared to other hand-crafted\nradiomics features. Here we show that CNN trained to perform the tumor\nsegmentation task, with no other information than physician contours, identify\na rich set of survival-related image features with remarkable prognostic value.\nIn a retrospective study on 96 NSCLC patients before stereotactic-body\nradiotherapy (SBRT), we found that the CNN segmentation algorithm (U-Net)\ntrained for tumor segmentation in PET/CT images, contained features having\nstrong correlation with 2- and 5-year overall and disease-specific survivals.\nThe U-net algorithm has not seen any other clinical information (e.g. survival,\nage, smoking history) than the images and the corresponding tumor contours\nprovided by physicians. Furthermore, through visualization of the U-Net, we\nalso found convincing evidence that the regions of progression appear to match\nwith the regions where the U-Net features identified patterns that predicted\nhigher likelihood of death. We anticipate our findings will be a starting point\nfor more sophisticated non-intrusive patient specific cancer prognosis\ndetermination.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 19:55:44 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 22:42:56 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Baek", "Stephen", ""], ["He", "Yusen", ""], ["Allen", "Bryan G.", ""], ["Buatti", "John M.", ""], ["Smith", "Brian J.", ""], ["Tong", "Ling", ""], ["Sun", "Zhiyu", ""], ["Wu", "Jia", ""], ["Diehn", "Maximilian", ""], ["Loo", "Billy W.", ""], ["Plichta", "Kristin A.", ""], ["Seyedin", "Steven N.", ""], ["Gannon", "Maggie", ""], ["Cabel", "Katherine R.", ""], ["Kim", "Yusung", ""], ["Wu", "Xiaodong", ""]]}, {"id": "1903.11621", "submitter": "Xin-She Yang", "authors": "Nunzia Palmieri, Xin-She Yang, Floriano De Rango, Amilcare Francesco\n  Santamaria", "title": "Self-adaptive decision-making mechanisms to balance the execution of\n  multiple tasks for a multi-robots team", "comments": "40 pages", "journal-ref": "Neurocomputing, vol. 306, 17-36 (2018)", "doi": "10.1016/j.neucom.2018.03.038", "report-no": null, "categories": "cs.RO cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses the coordination problem of multiple robots with the goal\nof finding specific hazardous targets in an unknown area and dealing with them\ncooperatively. The desired behaviour for the robotic system entails multiple\nrequirements, which may also be conflicting. The paper presents the problem as\na constrained bi-objective optimization problem in which mobile robots must\nperform two specific tasks of exploration and at same time cooperation and\ncoordination for disarming the hazardous targets. These objectives are opposed\ngoals, in which one may be favored, but only at the expense of the other.\nTherefore, a good trade-off must be found. For this purpose, a nature-inspired\napproach and an analytical mathematical model to solve this problem considering\na single equivalent weighted objective function are presented. The results of\nproposed coordination model, simulated in a two dimensional terrain, are showed\nin order to assess the behaviour of the proposed solution to tackle this\nproblem. We have analyzed the performance of the approach and the influence of\nthe weights of the objective function under different conditions: static and\ndynamic. In this latter situation, the robots may fail under the stringent\nlimited budget of energy or for hazardous events. The paper concludes with a\ncritical discussion of the experimental results.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 18:01:59 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Palmieri", "Nunzia", ""], ["Yang", "Xin-She", ""], ["De Rango", "Floriano", ""], ["Santamaria", "Amilcare Francesco", ""]]}, {"id": "1903.11626", "submitter": "Junghoon Seo", "authors": "Beomsu Kim, Junghoon Seo, Taegyun Jeon", "title": "Bridging Adversarial Robustness and Gradient Interpretability", "comments": "Accepted at the 2019 ICLR Workshop on Safe Machine Learning:\n  Specification, Robustness, and Assurance (SafeML 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is a training scheme designed to counter adversarial\nattacks by augmenting the training dataset with adversarial examples.\nSurprisingly, several studies have observed that loss gradients from\nadversarially trained DNNs are visually more interpretable than those from\nstandard DNNs. Although this phenomenon is interesting, there are only few\nworks that have offered an explanation. In this paper, we attempted to bridge\nthis gap between adversarial robustness and gradient interpretability. To this\nend, we identified that loss gradients from adversarially trained DNNs align\nbetter with human perception because adversarial training restricts gradients\ncloser to the image manifold. We then demonstrated that adversarial training\ncauses loss gradients to be quantitatively meaningful. Finally, we showed that\nunder the adversarial training framework, there exists an empirical trade-off\nbetween test accuracy and loss gradient interpretability and proposed two\npotential approaches to resolving this trade-off.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 18:06:06 GMT"}, {"version": "v2", "created": "Fri, 19 Apr 2019 07:35:00 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Kim", "Beomsu", ""], ["Seo", "Junghoon", ""], ["Jeon", "Taegyun", ""]]}, {"id": "1903.11678", "submitter": "Ahmed Khalifa", "authors": "Debosmita Bhaumik, Ahmed Khalifa, Michael Cerny Green, Julian Togelius", "title": "Tree Search vs Optimization Approaches for Map Generation", "comments": "10 pages, 9 figures, published at AIIDE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search-based procedural content generation uses stochastic global\noptimization algorithms to search for game content. However, standard tree\nsearch algorithms can be competitive with evolution on some optimization\nproblems. We investigate the applicability of several tree search methods to\nlevel generation and compare them systematically with several optimization\nalgorithms, including evolutionary algorithms. We compare them on three\ndifferent game level generation problems: Binary, Zelda, and Sokoban. We\nintroduce two new representations that can help tree search algorithms deal\nwith the large branching factor of the generation problem. We find that in\ngeneral, optimization algorithms clearly outperform tree search algorithms, but\ngiven the right problem representation certain tree search algorithms perform\nsimilarly to optimization algorithms, and in one particular problem, we see\nsurprisingly strong results from MCTS.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 19:53:29 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 22:00:00 GMT"}, {"version": "v3", "created": "Thu, 13 Aug 2020 02:34:56 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Bhaumik", "Debosmita", ""], ["Khalifa", "Ahmed", ""], ["Green", "Michael Cerny", ""], ["Togelius", "Julian", ""]]}, {"id": "1903.11690", "submitter": "Emanuel Laude", "authors": "Emanuel Laude and Tao Wu and Daniel Cremers", "title": "Optimization of Inf-Convolution Regularized Nonconvex Composite Problems", "comments": "Accepted as a Conference Paper to International Conference on\n  Artificial Intelligence and Statistics (AISTATS) 2019, Naha", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider nonconvex composite problems that involve\ninf-convolution with a Legendre function, which gives rise to an anisotropic\ngeneralization of the proximal mapping and Moreau-envelope. In a convex setting\nsuch problems can be solved via alternating minimization of a splitting\nformulation, where the consensus constraint is penalized with a Legendre\nfunction. In contrast, for nonconvex models it is in general unclear that this\napproach yields stationary points to the infimal convolution problem. To this\nend we analytically investigate local regularity properties of the\nMoreau-envelope function under prox-regularity, which allows us to establish\nthe equivalence between stationary points of the splitting model and the\noriginal inf-convolution model. We apply our theory to characterize stationary\npoints of the penalty objective, which is minimized by the elastic averaging\nSGD (EASGD) method for distributed training. Numerically, we demonstrate the\npractical relevance of the proposed approach on the important task of\ndistributed training of deep neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 20:37:17 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Laude", "Emanuel", ""], ["Wu", "Tao", ""], ["Cremers", "Daniel", ""]]}, {"id": "1903.11701", "submitter": "Debasmit Das", "authors": "Debasmit Das and C. S. George Lee", "title": "Zero-shot Image Recognition Using Relational Matching, Adaptation and\n  Calibration", "comments": "International Joint Conference on Neural Networks (IJCNN) 2019.\n  Copyright 2019 IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-shot learning (ZSL) for image classification focuses on recognizing\nnovel categories that have no labeled data available for training. The learning\nis generally carried out with the help of mid-level semantic descriptors\nassociated with each class. This semantic-descriptor space is generally shared\nby both seen and unseen categories. However, ZSL suffers from hubness, domain\ndiscrepancy and biased-ness towards seen classes. To tackle these problems, we\npropose a three-step approach to zero-shot learning. Firstly, a mapping is\nlearned from the semantic-descriptor space to the image-feature space. This\nmapping learns to minimize both one-to-one and pairwise distances between\nsemantic embeddings and the image features of the corresponding classes.\nSecondly, we propose test-time domain adaptation to adapt the semantic\nembedding of the unseen classes to the test data. This is achieved by finding\ncorrespondences between the semantic descriptors and the image features.\nThirdly, we propose scaled calibration on the classification scores of the seen\nclasses. This is necessary because the ZSL model is biased towards seen classes\nas the unseen classes are not used in the training. Finally, to validate the\nproposed three-step approach, we performed experiments on four benchmark\ndatasets where the proposed method outperformed previous results. We also\nstudied and analyzed the performance of each component of our proposed ZSL\nframework.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 21:07:00 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Das", "Debasmit", ""], ["Lee", "C. S. George", ""]]}, {"id": "1903.11723", "submitter": "Abdur Rakib", "authors": "Abba Lawan and Abdur Rakib", "title": "The Semantic Web Rule Language Expressiveness Extensions-A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Semantic Web Rule Language (SWRL) is a direct extension of OWL 2 DL with\na subset of RuleML, and it is designed to be the rule language of the Semantic\nWeb. This paper explores the state-of-the-art of SWRL's expressiveness\nextensions proposed over time. As a motivation, the effectiveness of the\nSWRL/OWL combination in modeling domain facts is discussed while some of the\ncommon expressive limitations of the combination are also highlighted. The\npaper then classifies and presents the relevant language extensions of the SWRL\nand their added expressive powers to the original SWRL definition. Furthermore,\nit provides a comparative analysis of the syntax and semantics of the proposed\nextensions. In conclusion, the decidability requirement and usability of each\nexpressiveness extension are evaluated towards an efficient inclusion into the\nOWL ontologies.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 23:03:48 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Lawan", "Abba", ""], ["Rakib", "Abdur", ""]]}, {"id": "1903.11728", "submitter": "Jiahui Yu", "authors": "Jiahui Yu, Thomas Huang", "title": "AutoSlim: Towards One-Shot Architecture Search for Channel Numbers", "comments": "tech report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how to set channel numbers in a neural network to achieve better\naccuracy under constrained resources (e.g., FLOPs, latency, memory footprint or\nmodel size). A simple and one-shot solution, named AutoSlim, is presented.\nInstead of training many network samples and searching with reinforcement\nlearning, we train a single slimmable network to approximate the network\naccuracy of different channel configurations. We then iteratively evaluate the\ntrained slimmable model and greedily slim the layer with minimal accuracy drop.\nBy this single pass, we can obtain the optimized channel configurations under\ndifferent resource constraints. We present experiments with MobileNet v1,\nMobileNet v2, ResNet-50 and RL-searched MNasNet on ImageNet classification. We\nshow significant improvements over their default channel configurations. We\nalso achieve better accuracy than recent channel pruning methods and neural\narchitecture search methods.\n  Notably, by setting optimized channel numbers, our AutoSlim-MobileNet-v2 at\n305M FLOPs achieves 74.2% top-1 accuracy, 2.4% better than default MobileNet-v2\n(301M FLOPs), and even 0.2% better than RL-searched MNasNet (317M FLOPs). Our\nAutoSlim-ResNet-50 at 570M FLOPs, without depthwise convolutions, achieves 1.3%\nbetter accuracy than MobileNet-v1 (569M FLOPs). Code and models will be\navailable at: https://github.com/JiahuiYu/slimmable_networks\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 23:17:28 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 03:19:54 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Yu", "Jiahui", ""], ["Huang", "Thomas", ""]]}, {"id": "1903.11774", "submitter": "Quan Vuong", "authors": "Quan Vuong, Sharad Vikram, Hao Su, Sicun Gao, Henrik I. Christensen", "title": "How to pick the domain randomization parameters for sim-to-real transfer\n  of reinforcement learning policies?", "comments": "2-page extended abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, reinforcement learning (RL) algorithms have demonstrated remarkable\nsuccess in learning complicated behaviors from minimally processed input.\nHowever, most of this success is limited to simulation. While there are\npromising successes in applying RL algorithms directly on real systems, their\nperformance on more complex systems remains bottle-necked by the relative data\ninefficiency of RL algorithms. Domain randomization is a promising direction of\nresearch that has demonstrated impressive results using RL algorithms to\ncontrol real robots. At a high level, domain randomization works by training a\npolicy on a distribution of environmental conditions in simulation. If the\nenvironments are diverse enough, then the policy trained on this distribution\nwill plausibly generalize to the real world. A human-specified design choice in\ndomain randomization is the form and parameters of the distribution of\nsimulated environments. It is unclear how to the best pick the form and\nparameters of this distribution and prior work uses hand-tuned distributions.\nThis extended abstract demonstrates that the choice of the distribution plays a\nmajor role in the performance of the trained policies in the real world and\nthat the parameter of this distribution can be optimized to maximize the\nperformance of the trained policies in the real world\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 03:24:44 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Vuong", "Quan", ""], ["Vikram", "Sharad", ""], ["Su", "Hao", ""], ["Gao", "Sicun", ""], ["Christensen", "Henrik I.", ""]]}, {"id": "1903.11777", "submitter": "Guang Hu", "authors": "Guang Hu, Tim Miller and Nir Lipovetzky", "title": "What you get is what you see: Decomposing Epistemic Planning using\n  Functional STRIPS", "comments": "20 pages, 3 figures, 4 experiments, journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epistemic planning --- planning with knowledge and belief --- is essential in\nmany multi-agent and human-agent interaction domains. Most state-of-the-art\nepistemic planners solve this problem by compiling to propositional classical\nplanning, for example, generating all possible knowledge atoms, or compiling\nepistemic formula to normal forms. However, these methods become\ncomputationally infeasible as problems grow. In this paper, we decompose\nepistemic planning by delegating reasoning about epistemic formula to an\nexternal solver. We do this by modelling the problem using \\emph{functional\nSTRIPS}, which is more expressive than standard STRIPS and supports the use of\nexternal, black-box functions within action models. Exploiting recent work that\ndemonstrates the relationship between what an agent `sees' and what it knows,\nwe allow modellers to provide new implementations of externals functions. These\ndefine what agents see in their environment, allowing new epistemic logics to\nbe defined without changing the planner. As a result, it increases the\ncapability and flexibility of the epistemic model itself, and avoids the\nexponential pre-compilation step. We ran evaluations on well-known epistemic\nplanning benchmarks to compare with an existing state-of-the-art planner, and\non new scenarios based on different external functions. The results show that\nour planner scales significantly better than the state-of-the-art planner\nagainst which we compared, and can express problems more succinctly.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 03:34:45 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 06:11:43 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Hu", "Guang", ""], ["Miller", "Tim", ""], ["Lipovetzky", "Nir", ""]]}, {"id": "1903.11857", "submitter": "Lianmeng Jiao", "authors": "Lianmeng Jiao and Xiaojiao Geng", "title": "Analysis and Extension of the Evidential Reasoning Algorithm for\n  Multiple Attribute Decision Analysis with Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multiple attribute decision analysis (MADA) problems, one often needs to\ndeal with assessment information with uncertainty. The evidential reasoning\napproach is one of the most effective methods to deal with such MADA problems.\nAs kernel of the evidential reasoning approach, an original evidential\nreasoning (ER) algorithm was firstly proposed by Yang et al, and later they\nmodified the ER algorithm in order to satisfy the proposed four synthesis\naxioms with which a rational aggregation process needs to satisfy. However, up\nto present, the essential difference of the two ER algorithms as well as the\nrationality of the synthesis axioms are still unclear. In this paper, we\nanalyze the ER algorithms in Dempster-Shafer theory (DST) framework and prove\nthat the original ER algorithm follows the reliability discounting and\ncombination scheme, while the modified one follows the importance discounting\nand combination scheme. Further we reveal that the four synthesis axioms are\nnot valid criteria to check the rationality of one attribute aggregation\nalgorithm. Based on these new findings, an extended ER algorithm is proposed to\ntake into account both the reliability and importance of different attributes,\nwhich provides a more general attribute aggregation scheme for MADA with\nuncertainty. A motorcycle performance assessment problem is examined to\nillustrate the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 09:37:50 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Jiao", "Lianmeng", ""], ["Geng", "Xiaojiao", ""]]}, {"id": "1903.11916", "submitter": "Yang Liu", "authors": "Yang Liu", "title": "Intelligent Processing in Vehicular Ad hoc Networks: a Survey", "comments": "11pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The intelligent Processing technique is more and more attractive to\nresearchers due to its ability to deal with key problems in Vehicular Ad hoc\nnetworks. However, several problems in applying intelligent processing\ntechnologies in VANETs remain open. The existing applications are\ncomprehensively reviewed and discussed, and classified into different\ncategories in this paper. Their strategies, advantages/disadvantages, and\nperformances are elaborated. By generalizing different tactics in various\napplications related to different scenarios of VANETs and evaluating their\nperformances, several promising directions for future research have been\nsuggested.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 12:33:07 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Liu", "Yang", ""]]}, {"id": "1903.11971", "submitter": "Xin-She Yang", "authors": "Si Chen, Guo-Hua Peng, Xing-Shi He, Xin-She Yang", "title": "The Global Convergence Analysis of the Bat Algorithm Using a Markovian\n  Framework and Dynamical System Theory", "comments": "17 pages, 3 figures", "journal-ref": "Expert Systems with Applications, vol. 114, 173--182 (2018)", "doi": "10.1016/j.eswa.2018.07.036", "report-no": null, "categories": "math.OC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bat algorithm (BA) has been shown to be effective to solve a wider range\nof optimization problems. However, there is not much theoretical analysis\nconcerning its convergence and stability. In order to prove the convergence of\nthe bat algorithm, we have built a Markov model for the algorithm and proved\nthat the state sequence of the bat population forms a finite homogeneous Markov\nchain, satisfying the global convergence criteria. Then, we prove that the bat\nalgorithm can have global convergence. In addition, in order to enhance the\nconvergence performance of the algorithm, we have designed an updated model\nusing the dynamical system theory in terms of a dynamic matrix, and the\nparameter ranges for the algorithm stability are then obtained. We then use\nsome benchmark functions to demonstrate that BA can indeed achieve global\noptimality efficiently for these functions.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 14:33:37 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Chen", "Si", ""], ["Peng", "Guo-Hua", ""], ["He", "Xing-Shi", ""], ["Yang", "Xin-She", ""]]}, {"id": "1903.12071", "submitter": "Ariel Rosenfeld", "authors": "Ariel Rosenfeld, David Benrimoh, Caitrin Armstrong, Nykan Mirchi,\n  Timothe Langlois-Therrien, Colleen Rollins, Myriam Tanguay-Sela, Joseph\n  Mehltretter, Robert Fratila, Sonia Israel, Emily Snook, Kelly Perlman, Akiva\n  Kleinerman, Bechara Saab, Mark Thoburn, Cheryl Gabbay and Amit\n  Yaniv-Rosenfeld", "title": "Big Data Analytics and AI in Mental Healthcare", "comments": "Chapter in the \"Big Data in Healthcare\" book (Elsevier) [exp. 2019]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mental health conditions cause a great deal of distress or impairment;\ndepression alone will affect 11% of the world's population. The application of\nArtificial Intelligence (AI) and big-data technologies to mental health has\ngreat potential for personalizing treatment selection, prognosticating,\nmonitoring for relapse, detecting and helping to prevent mental health\nconditions before they reach clinical-level symptomatology, and even delivering\nsome treatments. However, unlike similar applications in other fields of\nmedicine, there are several unique challenges in mental health applications\nwhich currently pose barriers towards the implementation of these technologies.\nSpecifically, there are very few widely used or validated biomarkers in mental\nhealth, leading to a heavy reliance on patient and clinician derived\nquestionnaire data as well as interpretation of new signals such as digital\nphenotyping. In addition, diagnosis also lacks the same objective 'gold\nstandard' as in other conditions such as oncology, where clinicians and\nresearchers can often rely on pathological analysis for confirmation of\ndiagnosis. In this chapter we discuss the major opportunities, limitations and\ntechniques used for improving mental healthcare through AI and big-data. We\nexplore both the computational, clinical and ethical considerations and best\npractices as well as lay out the major researcher directions for the near\nfuture.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 20:47:29 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Rosenfeld", "Ariel", ""], ["Benrimoh", "David", ""], ["Armstrong", "Caitrin", ""], ["Mirchi", "Nykan", ""], ["Langlois-Therrien", "Timothe", ""], ["Rollins", "Colleen", ""], ["Tanguay-Sela", "Myriam", ""], ["Mehltretter", "Joseph", ""], ["Fratila", "Robert", ""], ["Israel", "Sonia", ""], ["Snook", "Emily", ""], ["Perlman", "Kelly", ""], ["Kleinerman", "Akiva", ""], ["Saab", "Bechara", ""], ["Thoburn", "Mark", ""], ["Gabbay", "Cheryl", ""], ["Yaniv-Rosenfeld", "Amit", ""]]}, {"id": "1903.12073", "submitter": "Vishakha Metre VaM", "authors": "Vishakha A Metre, Mr Pramod B Deshmukh", "title": "Scope of Research on Particle Swarm Optimization Based Data Clustering", "comments": "7 pages, 6 figures, 1 table, published with International Journal of\n  Computer Science Trends and Technology (IJCST)", "journal-ref": "IJCST V6(6): Page(87-93) Nov-Dec 2018. ISSN: 2347-8578", "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization is nothing but a mathematical technique which finds maxima or\nminima of any function of concern in some realistic region. Different\noptimization techniques are proposed which are competing for the best solution.\nParticle Swarm Optimization (PSO) is a new, advanced, and most powerful\noptimization methodology that performs empirically well on several optimization\nproblems. It is the extensively used Swarm Intelligence (SI) inspired\noptimization algorithm used for finding the global optimal solution in a\nmultifaceted search region. Data clustering is one of the challenging real\nworld applications that invite the eminent research works in variety of fields.\nApplicability of different PSO variants to data clustering is studied in the\nliterature, and the analyzed research work shows that, PSO variants give poor\nresults for multidimensional data. This paper describes the different\nchallenges associated with multidimensional data clustering and scope of\nresearch on optimizing the clustering problems using PSO. We also propose a\nstrategy to use hybrid PSO variant for clustering multidimensional numerical,\ntext and image data.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 17:05:28 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Metre", "Vishakha A", ""], ["Deshmukh", "Mr Pramod B", ""]]}, {"id": "1903.12101", "submitter": "Ashwinkumar Ganesan", "authors": "Ashwinkumar Ganesan, Pooja Parameshwarappa, Akshay Peshave, Zhiyuan\n  Chen, Tim Oates", "title": "Extending Signature-based Intrusion Detection Systems WithBayesian\n  Abductive Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolving cybersecurity threats are a persistent challenge for\nsystemadministrators and security experts as new malwares are continu-ally\nreleased. Attackers may look for vulnerabilities in commercialproducts or\nexecute sophisticated reconnaissance campaigns tounderstand a targets network\nand gather information on securityproducts like firewalls and intrusion\ndetection / prevention systems(network or host-based). Many new attacks tend to\nbe modificationsof existing ones. In such a scenario, rule-based systems fail\nto detectthe attack, even though there are minor differences in conditions\n/attributes between rules to identify the new and existing attack. Todetect\nthese differences the IDS must be able to isolate the subset ofconditions that\nare true and predict the likely conditions (differentfrom the original) that\nmust be observed. In this paper, we proposeaprobabilistic abductive\nreasoningapproach that augments an exist-ing rule-based IDS (snort [29]) to\ndetect these evolved attacks by (a)Predicting rule conditions that are likely\nto occur (based on existingrules) and (b) able to generate new snort rules when\nprovided withseed rule (i.e. a starting rule) to reduce the burden on experts\ntoconstantly update them. We demonstrate the effectiveness of theapproach by\ngenerating new rules from the snort 2012 rules set andtesting it on the MACCDC\n2012 dataset [6].\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 16:38:09 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Ganesan", "Ashwinkumar", ""], ["Parameshwarappa", "Pooja", ""], ["Peshave", "Akshay", ""], ["Chen", "Zhiyuan", ""], ["Oates", "Tim", ""]]}, {"id": "1903.12220", "submitter": "Maithra Raghu", "authors": "Maithra Raghu, Katy Blumer, Greg Corrado, Jon Kleinberg, Ziad\n  Obermeyer, Sendhil Mullainathan", "title": "The Algorithmic Automation Problem: Prediction, Triage, and Human Effort", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a wide array of areas, algorithms are matching and surpassing the\nperformance of human experts, leading to consideration of the roles of human\njudgment and algorithmic prediction in these domains. The discussion around\nthese developments, however, has implicitly equated the specific task of\nprediction with the general task of automation. We argue here that automation\nis broader than just a comparison of human versus algorithmic performance on a\ntask; it also involves the decision of which instances of the task to give to\nthe algorithm in the first place. We develop a general framework that poses\nthis latter decision as an optimization problem, and we show how basic\nheuristics for this optimization problem can lead to performance gains even on\nheavily-studied applications of AI in medicine. Our framework also serves to\nhighlight how effective automation depends crucially on estimating both\nalgorithmic and human error on an instance-by-instance basis, and our results\nshow how improvements in these error estimation problems can yield significant\ngains for automation as well.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 18:53:58 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Raghu", "Maithra", ""], ["Blumer", "Katy", ""], ["Corrado", "Greg", ""], ["Kleinberg", "Jon", ""], ["Obermeyer", "Ziad", ""], ["Mullainathan", "Sendhil", ""]]}, {"id": "1903.12287", "submitter": "Adam Lerer", "authors": "Adam Lerer, Ledell Wu, Jiajun Shen, Timothee Lacroix, Luca Wehrstedt,\n  Abhijit Bose, Alex Peysakhovich", "title": "PyTorch-BigGraph: A Large-scale Graph Embedding System", "comments": null, "journal-ref": "Proceedings of The Conference on Systems and Machine Learning,\n  2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embedding methods produce unsupervised node features from graphs that\ncan then be used for a variety of machine learning tasks. Modern graphs,\nparticularly in industrial applications, contain billions of nodes and\ntrillions of edges, which exceeds the capability of existing embedding systems.\nWe present PyTorch-BigGraph (PBG), an embedding system that incorporates\nseveral modifications to traditional multi-relation embedding systems that\nallow it to scale to graphs with billions of nodes and trillions of edges. PBG\nuses graph partitioning to train arbitrarily large embeddings on either a\nsingle machine or in a distributed environment. We demonstrate comparable\nperformance with existing embedding systems on common benchmarks, while\nallowing for scaling to arbitrarily large graphs and parallelization on\nmultiple machines. We train and evaluate embeddings on several large social\nnetwork graphs as well as the full Freebase dataset, which contains over 100\nmillion nodes and 2 billion edges.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 21:51:09 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 16:48:00 GMT"}, {"version": "v3", "created": "Tue, 9 Apr 2019 15:41:25 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Lerer", "Adam", ""], ["Wu", "Ledell", ""], ["Shen", "Jiajun", ""], ["Lacroix", "Timothee", ""], ["Wehrstedt", "Luca", ""], ["Bose", "Abhijit", ""], ["Peysakhovich", "Alex", ""]]}, {"id": "1903.12302", "submitter": "Ferenc Balint-Benczedi", "authors": "Ferenc Balint-Benczedi, Michael Beetz", "title": "Amortized Object and Scene Perception for Long-term Robot Manipulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile robots, performing long-term manipulation activities in human\nenvironments, have to perceive a wide variety of objects possessing very\ndifferent visual characteristics and need to reliably keep track of these\nthroughout the execution of a task. In order to be efficient, robot perception\ncapabilities need to go beyond what is currently perceivable and should be able\nto answer queries about both current and past scenes. In this paper we\ninvestigate a perception system for long-term robot manipulation that keeps\ntrack of the changing environment and builds a representation of the perceived\nworld. Specifically we introduce an amortized component that spreads perception\ntasks throughout the execution cycle. The resulting query driven perception\nsystem asynchronously integrates results from logged images into a symbolic and\nnumeric (what we call sub-symbolic) representation that forms the perceptual\nbelief state of the robot.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 23:36:47 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Balint-Benczedi", "Ferenc", ""], ["Beetz", "Michael", ""]]}, {"id": "1903.12314", "submitter": "Zhe Gan", "authors": "Linjie Li, Zhe Gan, Yu Cheng, Jingjing Liu", "title": "Relation-Aware Graph Attention Network for Visual Question Answering", "comments": "To appear in ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to answer semantically-complicated questions about an image, a\nVisual Question Answering (VQA) model needs to fully understand the visual\nscene in the image, especially the interactive dynamics between different\nobjects. We propose a Relation-aware Graph Attention Network (ReGAT), which\nencodes each image into a graph and models multi-type inter-object relations\nvia a graph attention mechanism, to learn question-adaptive relation\nrepresentations. Two types of visual object relations are explored: (i)\nExplicit Relations that represent geometric positions and semantic interactions\nbetween objects; and (ii) Implicit Relations that capture the hidden dynamics\nbetween image regions. Experiments demonstrate that ReGAT outperforms prior\nstate-of-the-art approaches on both VQA 2.0 and VQA-CP v2 datasets. We further\nshow that ReGAT is compatible to existing VQA architectures, and can be used as\na generic relation encoder to boost the model performance for VQA.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 01:24:19 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2019 03:59:32 GMT"}, {"version": "v3", "created": "Wed, 9 Oct 2019 18:34:49 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Li", "Linjie", ""], ["Gan", "Zhe", ""], ["Cheng", "Yu", ""], ["Liu", "Jingjing", ""]]}, {"id": "1903.12354", "submitter": "Ivan Vankov", "authors": "Ivan Vankov, Jeffrey Bowers", "title": "Training neural networks to encode symbols enables combinatorial\n  generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combinatorial generalization - the ability to understand and produce novel\ncombinations of already familiar elements - is considered to be a core capacity\nof the human mind and a major challenge to neural network models. A significant\nbody of research suggests that conventional neural networks can't solve this\nproblem unless they are endowed with mechanisms specifically engineered for the\npurpose of representing symbols. In this paper we introduce a novel way of\nrepresenting symbolic structures in connectionist terms - the vectors approach\nto representing symbols (VARS), which allows training standard neural\narchitectures to encode symbolic knowledge explicitly at their output layers.\nIn two simulations, we show that neural networks not only can learn to produce\nVARS representations, but in doing so they achieve combinatorial generalization\nin their symbolic and non-symbolic output. This adds to other recent work that\nhas shown improved combinatorial generalization under specific training\nconditions, and raises the question of whether specific mechanisms or training\nroutines are needed to support symbolic processing.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 05:02:51 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 08:40:06 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Vankov", "Ivan", ""], ["Bowers", "Jeffrey", ""]]}, {"id": "1903.12355", "submitter": "Chengxu Zhuang", "authors": "Chengxu Zhuang, Alex Lin Zhai, Daniel Yamins", "title": "Local Aggregation for Unsupervised Learning of Visual Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised approaches to learning in neural networks are of substantial\ninterest for furthering artificial intelligence, both because they would enable\nthe training of networks without the need for large numbers of expensive\nannotations, and because they would be better models of the kind of\ngeneral-purpose learning deployed by humans. However, unsupervised networks\nhave long lagged behind the performance of their supervised counterparts,\nespecially in the domain of large-scale visual recognition. Recent developments\nin training deep convolutional embeddings to maximize non-parametric instance\nseparation and clustering objectives have shown promise in closing this gap.\nHere, we describe a method that trains an embedding function to maximize a\nmetric of local aggregation, causing similar data instances to move together in\nthe embedding space, while allowing dissimilar instances to separate. This\naggregation metric is dynamic, allowing soft clusters of different scales to\nemerge. We evaluate our procedure on several large-scale visual recognition\ndatasets, achieving state-of-the-art unsupervised transfer learning performance\non object recognition in ImageNet, scene recognition in Places 205, and object\ndetection in PASCAL VOC.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 05:05:41 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 06:37:42 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Zhuang", "Chengxu", ""], ["Zhai", "Alex Lin", ""], ["Yamins", "Daniel", ""]]}, {"id": "1903.12356", "submitter": "Dekun Wu", "authors": "Dekun Wu, Nana Nosirova, Hui Jiang, Mingbin Xu", "title": "A General FOFE-net Framework for Simple and Effective Question Answering\n  over Knowledge Bases", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering over knowledge base (KB-QA) has recently become a popular\nresearch topic in NLP. One popular way to solve the KB-QA problem is to make\nuse of a pipeline of several NLP modules, including entity discovery and\nlinking (EDL) and relation detection. Recent success on KB-QA task usually\ninvolves complex network structures with sophisticated heuristics. Inspired by\na previous work that builds a strong KB-QA baseline, we propose a simple but\ngeneral neural model composed of fixed-size ordinally forgetting encoding\n(FOFE) and deep neural networks, called FOFE-net to solve KB-QA problem at\ndifferent stages. For evaluation, we use two popular KB-QA datasets,\nSimpleQuestions and WebQSP, and a newly created dataset, FreebaseQA. The\nexperimental results show that FOFE-net performs well on KB-QA subtasks, entity\ndiscovery and linking (EDL) and relation detection, and in turn pushing overall\nKB-QA system to achieve strong results on all datasets.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 05:15:58 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Wu", "Dekun", ""], ["Nosirova", "Nana", ""], ["Jiang", "Hui", ""], ["Xu", "Mingbin", ""]]}, {"id": "1903.12363", "submitter": "Xiaohui Zhao Ph.D.", "authors": "Xiaohui Zhao, Endi Niu, Zhuo Wu, and Xiaoguang Wang", "title": "CUTIE: Learning to Understand Documents with Convolutional Universal\n  Text Information Extractor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting key information from documents, such as receipts or invoices, and\npreserving the interested texts to structured data is crucial in the\ndocument-intensive streamline processes of office automation in areas that\nincludes but not limited to accounting, financial, and taxation areas. To avoid\ndesigning expert rules for each specific type of document, some published works\nattempt to tackle the problem by learning a model to explore the semantic\ncontext in text sequences based on the Named Entity Recognition (NER) method in\nthe NLP field. In this paper, we propose to harness the effective information\nfrom both semantic meaning and spatial distribution of texts in documents.\nSpecifically, our proposed model, Convolutional Universal Text Information\nExtractor (CUTIE), applies convolutional neural networks on gridded texts where\ntexts are embedded as features with semantical connotations. We further explore\nthe effect of employing different structures of convolutional neural network\nand propose a fast and portable structure. We demonstrate the effectiveness of\nthe proposed method on a dataset with up to $4,484$ labelled receipts, without\nany pre-training or post-processing, achieving state of the art performance\nthat is much better than the NER based methods in terms of either speed and\naccuracy. Experimental results also demonstrate that the proposed CUTIE model\nbeing able to achieve good performance with a much smaller amount of training\ndata.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 06:23:06 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 05:50:09 GMT"}, {"version": "v3", "created": "Fri, 24 May 2019 03:42:21 GMT"}, {"version": "v4", "created": "Thu, 20 Jun 2019 01:56:57 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Zhao", "Xiaohui", ""], ["Niu", "Endi", ""], ["Wu", "Zhuo", ""], ["Wang", "Xiaoguang", ""]]}, {"id": "1903.12394", "submitter": "Laura von Rueden", "authors": "Laura von Rueden, Sebastian Mayer, Katharina Beckh, Bogdan Georgiev,\n  Sven Giesselbach, Raoul Heese, Birgit Kirsch, Julius Pfrommer, Annika Pick,\n  Rajkumar Ramamurthy, Michal Walczak, Jochen Garcke, Christian Bauckhage,\n  Jannis Schuecker", "title": "Informed Machine Learning -- A Taxonomy and Survey of Integrating\n  Knowledge into Learning Systems", "comments": "Accepted at IEEE Transactions on Knowledge and Data Engineering:\n  https://ieeexplore.ieee.org/document/9429985", "journal-ref": null, "doi": "10.1109/TKDE.2021.3079836", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite its great success, machine learning can have its limits when dealing\nwith insufficient training data. A potential solution is the additional\nintegration of prior knowledge into the training process which leads to the\nnotion of informed machine learning. In this paper, we present a structured\noverview of various approaches in this field. We provide a definition and\npropose a concept for informed machine learning which illustrates its building\nblocks and distinguishes it from conventional machine learning. We introduce a\ntaxonomy that serves as a classification framework for informed machine\nlearning approaches. It considers the source of knowledge, its representation,\nand its integration into the machine learning pipeline. Based on this taxonomy,\nwe survey related research and describe how different knowledge representations\nsuch as algebraic equations, logic rules, or simulation results can be used in\nlearning systems. This evaluation of numerous papers on the basis of our\ntaxonomy uncovers key methods in the field of informed machine learning.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 08:37:40 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 21:10:43 GMT"}, {"version": "v3", "created": "Fri, 28 May 2021 07:34:41 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["von Rueden", "Laura", ""], ["Mayer", "Sebastian", ""], ["Beckh", "Katharina", ""], ["Georgiev", "Bogdan", ""], ["Giesselbach", "Sven", ""], ["Heese", "Raoul", ""], ["Kirsch", "Birgit", ""], ["Pfrommer", "Julius", ""], ["Pick", "Annika", ""], ["Ramamurthy", "Rajkumar", ""], ["Walczak", "Michal", ""], ["Garcke", "Jochen", ""], ["Bauckhage", "Christian", ""], ["Schuecker", "Jannis", ""]]}, {"id": "1903.12402", "submitter": "EPTCS", "authors": "Pedro Quaresma (University of Coimbra, Portugal), Walther Neuper (Graz\n  University of Technology, Austria)", "title": "Proceedings 7th International Workshop on Theorem proving components for\n  Educational software", "comments": null, "journal-ref": "EPTCS 290, 2019", "doi": "10.4204/EPTCS.290", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 7th International Workshop on Theorem proving components for Educational\nsoftware (ThEdu'18) was held in Oxford, United Kingdom, on 18 July 2018. It was\nassociated to the conference, Federated Logic Conference 2018 (FLoC2018).\n  The major aim of the ThEdu workshop series was to link developers interested\nin adapting Computer Theorem Proving (TP) to the needs of education and to\ninform mathematicians and mathematics educators about TP's potential for\neducational software. Topics of interest include: methods of automated\ndeduction applied to checking students' input; methods of automated deduction\napplied to prove post-conditions for particular problem solutions; combinations\nof deduction and computation enabling systems to propose next steps; automated\nprovers specific for dynamic geometry systems; proof and proving in mathematics\neducation.\n  ThEdu'18 was a vibrant workshop, with one invited talk and six contributions.\nIt triggered the post-proceedings at hand.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 09:01:07 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Quaresma", "Pedro", "", "University of Coimbra, Portugal"], ["Neuper", "Walther", "", "Graz\n  University of Technology, Austria"]]}, {"id": "1903.12411", "submitter": "Cedric Buron", "authors": "C\\'edric Buron, Zahia Guessoum (SMA), Sylvain Ductor (UECE)", "title": "MCTS-based Automated Negotiation Agent (Extended Abstract)", "comments": null, "journal-ref": "AAMAS 2019, May 2019, Montreal, Canada", "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new Negotiating Agent for automated negotiation on\ncontinuous domains and without considering a specified deadline. The agent\nbidding strategy relies on Monte Carlo Tree Search, which is a trendy method\nsince it has been used with success on games with high branching factor such as\nGo. It uses two opponent modeling techniques for its bidding strategy and its\nutility: Gaussian process regression and Bayesian learning. Evaluation is done\nby confronting the existing agents that are able to negotiate in such context:\nRandom Walker, Tit-for-tat and Nice Tit-for-Tat. None of those agents succeeds\nin beating our agent; moreover the modular and adaptive nature of our approach\nis a huge advantage when it comes to optimize it in specific applicative\ncontexts.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 09:21:53 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Buron", "C\u00e9dric", "", "SMA"], ["Guessoum", "Zahia", "", "SMA"], ["Ductor", "Sylvain", "", "UECE"]]}, {"id": "1903.12467", "submitter": "Daniel Bauer", "authors": "Daniel Bauer, Lars Kuhnert, Lutz Eckstein", "title": "Deep, spatially coherent Occupancy Maps based on Radar Measurements", "comments": "Submitted for Automotive Meets Electronics 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One essential step to realize modern driver assistance technology is the\naccurate knowledge about the location of static objects in the environment. In\nthis work, we use artificial neural networks to predict the occupation state of\na whole scene in an end-to-end manner. This stands in contrast to the\ntraditional approach of accumulating each detection's influence on the\noccupancy state and allows to learn spatial priors which can be used to\ninterpolate the environment's occupancy state. We show that these priors make\nour method suitable to predict dense occupancy estimations from sparse, highly\nuncertain inputs, as given by automotive radars, even for complex urban\nscenarios. Furthermore, we demonstrate that these estimations can be used for\nlarge-scale mapping applications.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 12:26:07 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Bauer", "Daniel", ""], ["Kuhnert", "Lars", ""], ["Eckstein", "Lutz", ""]]}, {"id": "1903.12508", "submitter": "Simon Lucas", "authors": "Simon M. Lucas, Alexander Dockhorn, Vanessa Volz, Chris Bamford,\n  Raluca D. Gaina, Ivan Bravi, Diego Perez-Liebana, Sanaz Mostaghim, Rudolf\n  Kruse", "title": "A Local Approach to Forward Model Learning: Results on the Game of Life\n  Game", "comments": "Submitted to IEEE Conference on Games 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the effect of learning a forward model on the\nperformance of a statistical forward planning agent. We transform Conway's Game\nof Life simulation into a single-player game where the objective can be either\nto preserve as much life as possible or to extinguish all life as quickly as\npossible.\n  In order to learn the forward model of the game, we formulate the problem in\na novel way that learns the local cell transition function by creating a set of\nsupervised training data and predicting the next state of each cell in the grid\nbased on its current state and immediate neighbours. Using this method we are\nable to harvest sufficient data to learn perfect forward models by observing\nonly a few complete state transitions, using either a look-up table, a decision\ntree or a neural network.\n  In contrast, learning the complete state transition function is a much harder\ntask and our initial efforts to do this using deep convolutional auto-encoders\nwere less successful.\n  We also investigate the effects of imperfect learned models on prediction\nerrors and game-playing performance, and show that even models with significant\nerrors can provide good performance.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 13:17:15 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Lucas", "Simon M.", ""], ["Dockhorn", "Alexander", ""], ["Volz", "Vanessa", ""], ["Bamford", "Chris", ""], ["Gaina", "Raluca D.", ""], ["Bravi", "Ivan", ""], ["Perez-Liebana", "Diego", ""], ["Mostaghim", "Sanaz", ""], ["Kruse", "Rudolf", ""]]}, {"id": "1903.12510", "submitter": "Richard Taupe", "authors": "Richard Taupe, Antonius Weinzierl, Gerhard Friedrich", "title": "Degrees of Laziness in Grounding: Effects of Lazy-Grounding Strategies\n  on ASP Solving", "comments": null, "journal-ref": "In: Logic Programming and Nonmonotonic Reasoning. LPNMR 2019.\n  Lecture Notes in Computer Science, vol 11481. Springer, Cham", "doi": "10.1007/978-3-030-20528-7_22", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The traditional ground-and-solve approach to Answer Set Programming (ASP)\nsuffers from the grounding bottleneck, which makes large-scale problem\ninstances unsolvable. Lazy grounding is an alternative approach that\ninterleaves grounding with solving and thus uses space more efficiently. The\nlimited view on the search space in lazy grounding poses unique challenges,\nhowever, and can have adverse effects on solving performance. In this paper we\npresent a novel characterization of degrees of laziness in grounding for ASP,\ni.e. of compromises between lazily grounding as little as possible and the\ntraditional full grounding upfront. We investigate how these degrees of\nlaziness compare to each other formally as well as, by means of an experimental\nanalysis using a number of benchmarks, in terms of their effects on solving\nperformance. Our contributions are the introduction of a range of novel lazy\ngrounding strategies, a formal account on their relationships and their\ncorrectness, and an investigation of their effects on solving performance.\nExperiments show that our approach performs significantly better than\nstate-of-the-art lazy grounding in many cases.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 13:22:33 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 06:18:16 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Taupe", "Richard", ""], ["Weinzierl", "Antonius", ""], ["Friedrich", "Gerhard", ""]]}, {"id": "1903.12517", "submitter": "Chen Jingye", "authors": "Jieneng Chen, Jingye Chen, Ruiming Zhang, Xiaobin Hu", "title": "Towards Brain-inspired System: Deep Recurrent Reinforcement Learning for\n  Simulated Self-driving Agent", "comments": "8 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An effective way to achieve intelligence is to simulate various intelligent\nbehaviors in the human brain. In recent years, bio-inspired learning methods\nhave emerged, and they are different from the classical mathematical\nprogramming principle. In the perspective of brain inspiration, reinforcement\nlearning has gained additional interest in solving decision-making tasks as\nincreasing neuroscientific research demonstrates that significant links exist\nbetween reinforcement learning and specific neural substrates. Because of the\ntremendous research that focuses on human brains and reinforcement learning,\nscientists have investigated how robots can autonomously tackle complex tasks\nin the form of a self-driving agent control in a human-like way. In this study,\nwe propose an end-to-end architecture using novel deep-Q-network architecture\nin conjunction with a recurrence to resolve the problem in the field of\nsimulated self-driving. The main contribution of this study is that we trained\nthe driving agent using a brain-inspired trial-and-error technique, which was\nin line with the real world situation. Besides, there are three innovations in\nthe proposed learning network: raw screen outputs are the only information\nwhich the driving agent can rely on, a weighted layer that enhances the\ndifferences of the lengthy episode, and a modified replay mechanism that\novercomes the problem of sparsity and accelerates learning. The proposed\nnetwork was trained and tested under a third-partied OpenAI Gym environment.\nAfter training for several episodes, the resulting driving agent performed\nadvanced behaviors in the given scene. We hope that in the future, the proposed\nbrain-inspired learning system would inspire practicable self-driving control\nsolutions.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 13:31:44 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Chen", "Jieneng", ""], ["Chen", "Jingye", ""], ["Zhang", "Ruiming", ""], ["Hu", "Xiaobin", ""]]}, {"id": "1903.12519", "submitter": "Matthew Mirman", "authors": "Matthew Mirman, Gagandeep Singh, Martin Vechev", "title": "A Provable Defense for Deep Residual Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a training system, which can provably defend significantly larger\nneural networks than previously possible, including ResNet-34 and DenseNet-100.\nOur approach is based on differentiable abstract interpretation and introduces\ntwo novel concepts: (i) abstract layers for fine-tuning the precision and\nscalability of the abstraction, (ii) a flexible domain specific language (DSL)\nfor describing training objectives that combine abstract and concrete losses\nwith arbitrary specifications. Our training method is implemented in the DiffAI\nsystem.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 13:35:31 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 14:50:42 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Mirman", "Matthew", ""], ["Singh", "Gagandeep", ""], ["Vechev", "Martin", ""]]}, {"id": "1903.12549", "submitter": "Alireza Koochali", "authors": "Alireza Koochali, Peter Schichtel, Sheraz Ahmed and Andreas Dengel", "title": "Probabilistic Forecasting of Sensory Data with Generative Adversarial\n  Networks - ForGAN", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2019.2915544", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series forecasting is one of the challenging problems for humankind.\nTraditional forecasting methods using mean regression models have severe\nshortcomings in reflecting real-world fluctuations. While new probabilistic\nmethods rush to rescue, they fight with technical difficulties like quantile\ncrossing or selecting a prior distribution. To meld the different strengths of\nthese fields while avoiding their weaknesses as well as to push the boundary of\nthe state-of-the-art, we introduce ForGAN - one step ahead probabilistic\nforecasting with generative adversarial networks. ForGAN utilizes the power of\nthe conditional generative adversarial network to learn the data generating\ndistribution and compute probabilistic forecasts from it. We argue how to\nevaluate ForGAN in opposition to regression methods. To investigate\nprobabilistic forecasting of ForGAN, we create a new dataset and demonstrate\nour method abilities on it. This dataset will be made publicly available for\ncomparison. Furthermore, we test ForGAN on two publicly available datasets,\nnamely Mackey-Glass dataset and Internet traffic dataset (A5M) where the\nimpressive performance of ForGAN demonstrate its high capability in forecasting\nfuture values.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 14:39:00 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Koochali", "Alireza", ""], ["Schichtel", "Peter", ""], ["Ahmed", "Sheraz", ""], ["Dengel", "Andreas", ""]]}, {"id": "1903.12564", "submitter": "Changhee Han", "authors": "Changhee Han, Leonardo Rundo, Ryosuke Araki, Yujiro Furukawa,\n  Giancarlo Mauri, Hideki Nakayama, Hideaki Hayashi", "title": "Infinite Brain MR Images: PGGAN-based Data Augmentation for Tumor\n  Detection", "comments": "13 pages, 6 figures, Accepted to Neural Approaches to Dynamics of\n  Signal Exchanges as a Springer book chapter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the lack of available annotated medical images, accurate\ncomputer-assisted diagnosis requires intensive Data Augmentation (DA)\ntechniques, such as geometric/intensity transformations of original images;\nhowever, those transformed images intrinsically have a similar distribution to\nthe original ones, leading to limited performance improvement. To fill the data\nlack in the real image distribution, we synthesize brain contrast-enhanced\nMagnetic Resonance (MR) images---realistic but completely different from the\noriginal ones---using Generative Adversarial Networks (GANs). This study\nexploits Progressive Growing of GANs (PGGANs), a multi-stage generative\ntraining method, to generate original-sized 256 X 256 MR images for\nConvolutional Neural Network-based brain tumor detection, which is challenging\nvia conventional GANs; difficulties arise due to unstable GAN training with\nhigh resolution and a variety of tumors in size, location, shape, and contrast.\nOur preliminary results show that this novel PGGAN-based DA method can achieve\npromising performance improvement, when combined with classical DA, in tumor\ndetection and also in other medical imaging tasks.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 15:16:15 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Han", "Changhee", ""], ["Rundo", "Leonardo", ""], ["Araki", "Ryosuke", ""], ["Furukawa", "Yujiro", ""], ["Mauri", "Giancarlo", ""], ["Nakayama", "Hideki", ""], ["Hayashi", "Hideaki", ""]]}, {"id": "1903.12571", "submitter": "Changhee Han", "authors": "Leonardo Rundo, Changhee Han, Jin Zhang, Ryuichiro Hataya, Yudai\n  Nagano, Carmelo Militello, Claudio Ferretti, Marco S. Nobile, Andrea\n  Tangherloni, Maria Carla Gilardi, Salvatore Vitabile, Hideki Nakayama,\n  Giancarlo Mauri", "title": "CNN-based Prostate Zonal Segmentation on T2-weighted MR Images: A\n  Cross-dataset Study", "comments": "12 pages, 3 figures, Accepted to Neural Approaches to Dynamics of\n  Signal Exchanges as a Springer book chapter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prostate cancer is the most common cancer among US men. However, prostate\nimaging is still challenging despite the advances in multi-parametric Magnetic\nResonance Imaging (MRI), which provides both morphologic and functional\ninformation pertaining to the pathological regions. Along with whole prostate\ngland segmentation, distinguishing between the Central Gland (CG) and\nPeripheral Zone (PZ) can guide towards differential diagnosis, since the\nfrequency and severity of tumors differ in these regions; however, their\nboundary is often weak and fuzzy. This work presents a preliminary study on\nDeep Learning to automatically delineate the CG and PZ, aiming at evaluating\nthe generalization ability of Convolutional Neural Networks (CNNs) on two\nmulti-centric MRI prostate datasets. Especially, we compared three CNN-based\narchitectures: SegNet, U-Net, and pix2pix. In such a context, the segmentation\nperformances achieved with/without pre-training were compared in 4-fold\ncross-validation. In general, U-Net outperforms the other methods, especially\nwhen training and testing are performed on multiple datasets.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 15:30:38 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Rundo", "Leonardo", ""], ["Han", "Changhee", ""], ["Zhang", "Jin", ""], ["Hataya", "Ryuichiro", ""], ["Nagano", "Yudai", ""], ["Militello", "Carmelo", ""], ["Ferretti", "Claudio", ""], ["Nobile", "Marco S.", ""], ["Tangherloni", "Andrea", ""], ["Gilardi", "Maria Carla", ""], ["Vitabile", "Salvatore", ""], ["Nakayama", "Hideki", ""], ["Mauri", "Giancarlo", ""]]}, {"id": "1903.12577", "submitter": "Sebastijan Dumancic", "authors": "Sebastijan Dumancic, Tias Guns, Wannes Meert, Hendrik Blockeel", "title": "Learning Relational Representations with Auto-encoding Logic Programs", "comments": "8 pages,4 figures, paper + supplement, published at IJCAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods capable of handling relational data have proliferated\nover the last years. In contrast to traditional relational learning methods\nthat leverage first-order logic for representing such data, these deep learning\nmethods aim at re-representing symbolic relational data in Euclidean spaces.\nThey offer better scalability, but can only numerically approximate relational\nstructures and are less flexible in terms of reasoning tasks supported. This\npaper introduces a novel framework for relational representation learning that\ncombines the best of both worlds. This framework, inspired by the auto-encoding\nprinciple, uses first-order logic as a data representation language, and the\nmapping between the original and latent representation is done by means of\nlogic programs instead of neural networks. We show how learning can be cast as\na constraint optimisation problem for which existing solvers can be used. The\nuse of logic as a representation language makes the proposed framework more\naccurate (as the representation is exact, rather than approximate), more\nflexible, and more interpretable than deep learning methods. We experimentally\nshow that these latent representations are indeed beneficial in relational\nlearning tasks.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 15:38:02 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 16:32:33 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Dumancic", "Sebastijan", ""], ["Guns", "Tias", ""], ["Meert", "Wannes", ""], ["Blockeel", "Hendrik", ""]]}]