[{"id": "1407.0481", "submitter": "Konstantinos Kotis", "authors": "Konstantinos Kotis, Iraklis Athanasakis, George Vouros", "title": "Semantic Integration & Single-Site Opening of Multiple Governmental Data\n  Sources", "comments": "21 pages, 7 figures, live demo at\n  http://www.samos.gr/apps/s3-ai/eGovTicketApp.xhtml", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In many cases, government data is still \"locked\" in several \"data silos\",\neven within the boundaries of a single (inter-)national public organization\nwith disparate and distributed organizational units and departments spread\nacross multiple sites. Opening data and enabling its unified querying from a\nsingle site in an efficient and effective way is a semantic application\nintegration and open government data challenge. This paper describes how NARA\nis using Semantic Web technology to implement an application integration\napproach within the boundaries of its organization via opening and querying\nmultiple governmental data sources from a single site. The generic approach\nproposed, namely S3-AI, provides support to answering unified,\nontology-mediated, federated queries to data produced and exploited by\ndisparate applications, while these are being located in different\norganizational sites. S3-AI preserves ownership, autonomy and independency of\napplications and data. The paper extensively demonstrates S3-AI, using the D2RQ\nand Fuseki technologies, for addressing the needs of a governmental \"IT\nhelpdesk support\" case.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jul 2014 08:40:41 GMT"}], "update_date": "2014-07-03", "authors_parsed": [["Kotis", "Konstantinos", ""], ["Athanasakis", "Iraklis", ""], ["Vouros", "George", ""]]}, {"id": "1407.0787", "submitter": "Henk van Elst", "authors": "Ekaterina Svetlova (Universit\\\"at Konstanz, Karlshochschule\n  International University), Henk van Elst (Karlshochschule International\n  University)", "title": "Decision-theoretic approaches to non-knowledge in economics", "comments": "13 pages, LaTeX2e, hyperlinked references. To appear in \"Routledge\n  International Handbook of Ignorance Studies,\" edited by Matthias Gro{\\ss} and\n  Linsey McGoey (London: Routledge), due to be published in February 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review two strands of conceptual approaches to the formal representation\nof a decision maker's non-knowledge at the initial stage of a static\none-person, one-shot decision problem in economic theory. One focuses on\nrepresentations of non-knowledge in terms of probability measures over sets of\nmutually exclusive and exhaustive consequence-relevant states of Nature, the\nother deals with unawareness of potentially important events by means of sets\nof states that are less complete than the full set of consequence-relevant\nstates of Nature. We supplement our review with a brief discussion of\nunresolved matters in both approaches.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jul 2014 05:42:53 GMT"}], "update_date": "2014-07-04", "authors_parsed": [["Svetlova", "Ekaterina", "", "Universit\u00e4t Konstanz, Karlshochschule\n  International University"], ["van Elst", "Henk", "", "Karlshochschule International\n  University"]]}, {"id": "1407.1041", "submitter": "Florentin Smarandache", "authors": "Florentin Smarandache", "title": "n-Valued Refined Neutrosophic Logic and Its Applications to Physics", "comments": "9 pages", "journal-ref": "Progress in Physics, 143-146, Vol. 4, 2013", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a short history of logics: from particular cases of\n2-symbol or numerical valued logic to the general case of n-symbol or numerical\nvalued logic. We show generalizations of 2-valued Boolean logic to fuzzy logic,\nalso from the Kleene and Lukasiewicz 3-symbol valued logics or Belnap 4-symbol\nvalued logic to the most general n-symbol or numerical valued refined\nneutrosophic logic. Two classes of neutrosophic norm (n-norm) and neutrosophic\nconorm (n-conorm) are defined. Examples of applications of neutrosophic logic\nto physics are listed in the last section. Similar generalizations can be done\nfor n-Valued Refined Neutrosophic Set, and respectively n- Valued Refined\nNeutrosopjhic Probability.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jul 2014 15:25:52 GMT"}], "update_date": "2014-07-07", "authors_parsed": [["Smarandache", "Florentin", ""]]}, {"id": "1407.1339", "submitter": "Tejas Kulkarni", "authors": "Tejas D. Kulkarni and Vikash K. Mansinghka and Pushmeet Kohli and\n  Joshua B. Tenenbaum", "title": "Inverse Graphics with Probabilistic CAD Models", "comments": "For correspondence, contact tejask@mit.edu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Recently, multiple formulations of vision problems as probabilistic\ninversions of generative models based on computer graphics have been proposed.\nHowever, applications to 3D perception from natural images have focused on\nlow-dimensional latent scenes, due to challenges in both modeling and\ninference. Accounting for the enormous variability in 3D object shape and 2D\nappearance via realistic generative models seems intractable, as does inverting\neven simple versions of the many-to-many computations that link 3D scenes to 2D\nimages. This paper proposes and evaluates an approach that addresses key\naspects of both these challenges. We show that it is possible to solve\nchallenging, real-world 3D vision problems by approximate inference in\ngenerative models for images based on rendering the outputs of probabilistic\nCAD (PCAD) programs. Our PCAD object geometry priors generate deformable 3D\nmeshes corresponding to plausible objects and apply affine transformations to\nplace them in a scene. Image likelihoods are based on similarity in a feature\nspace based on standard mid-level image representations from the vision\nliterature. Our inference algorithm integrates single-site and locally blocked\nMetropolis-Hastings proposals, Hamiltonian Monte Carlo and discriminative\ndata-driven proposals learned from training data generated from our models. We\napply this approach to 3D human pose estimation and object shape reconstruction\nfrom single images, achieving quantitative and qualitative performance\nimprovements over state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jul 2014 23:03:25 GMT"}], "update_date": "2014-07-08", "authors_parsed": [["Kulkarni", "Tejas D.", ""], ["Mansinghka", "Vikash K.", ""], ["Kohli", "Pushmeet", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1407.1408", "submitter": "Roni Khardon", "authors": "Benjamin J. Hescott and Roni Khardon", "title": "The Complexity of Reasoning with FODD and GFODD", "comments": "A short version of this paper appears in AAAI 2014. Version 2\n  includes a reorganization and some expanded proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work introduced Generalized First Order Decision Diagrams (GFODD) as a\nknowledge representation that is useful in mechanizing decision theoretic\nplanning in relational domains. GFODDs generalize function-free first order\nlogic and include numerical values and numerical generalizations of existential\nand universal quantification. Previous work presented heuristic inference\nalgorithms for GFODDs and implemented these heuristics in systems for decision\ntheoretic planning. In this paper, we study the complexity of the computational\nproblems addressed by such implementations. In particular, we study the\nevaluation problem, the satisfiability problem, and the equivalence problem for\nGFODDs under the assumption that the size of the intended model is given with\nthe problem, a restriction that guarantees decidability. Our results provide a\ncomplete characterization placing these problems within the polynomial\nhierarchy. The same characterization applies to the corresponding restriction\nof problems in first order logic, giving an interesting new avenue for\nefficient inference when the number of objects is bounded. Our results show\nthat for $\\Sigma_k$ formulas, and for corresponding GFODDs, evaluation and\nsatisfiability are $\\Sigma_k^p$ complete, and equivalence is $\\Pi_{k+1}^p$\ncomplete. For $\\Pi_k$ formulas evaluation is $\\Pi_k^p$ complete, satisfiability\nis one level higher and is $\\Sigma_{k+1}^p$ complete, and equivalence is\n$\\Pi_{k+1}^p$ complete.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jul 2014 14:11:46 GMT"}, {"version": "v2", "created": "Fri, 20 Feb 2015 17:10:55 GMT"}], "update_date": "2015-02-23", "authors_parsed": [["Hescott", "Benjamin J.", ""], ["Khardon", "Roni", ""]]}, {"id": "1407.1474", "submitter": "Kaveh Bakhtiyari", "authors": "Kaveh Bakhtiyari and Hafizah Husain", "title": "Fuzzy Model on Human Emotions Recognition", "comments": "12th WSEAS International Conference on Applications of Computer\n  Engineering (ACE '13), Cambridge, MA, USA, 30 Jan. - 1 Feb. 2013 ISBN:\n  978-1-61804-156-2, Pages 77-82", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses a fuzzy model for multi-level human emotions recognition\nby computer systems through keyboard keystrokes, mouse and touchscreen\ninteractions. This model can also be used to detect the other possible emotions\nat the time of recognition. Accuracy measurements of human emotions by the\nfuzzy model are discussed through two methods; the first is accuracy analysis\nand the second is false positive rate analysis. This fuzzy model detects more\nemotions, but on the other hand, for some of emotions, a lower accuracy was\nobtained with the comparison with the non-fuzzy human emotions detection\nmethods. This system was trained and tested by Support Vector Machine (SVM) to\nrecognize the users' emotions. Overall, this model represents a closer\nsimilarity between human brain detection of emotions and computer systems.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jul 2014 09:38:21 GMT"}], "update_date": "2014-08-05", "authors_parsed": [["Bakhtiyari", "Kaveh", ""], ["Husain", "Hafizah", ""]]}, {"id": "1407.1584", "submitter": "Hadi Hosseini", "authors": "Hadi Hosseini, Jesse Hoey, Robin Cohen", "title": "A Coordinated MDP Approach to Multi-Agent Planning for Resource\n  Allocation, with Applications to Healthcare", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a novel approach to scalable multiagent resource\nallocation in dynamic settings. We propose an approximate solution in which\neach resource consumer is represented by an independent MDP-based agent that\nmodels expected utility using an average model of its expected access to\nresources given only limited information about all other agents. A global\nauction-based mechanism is proposed for allocations based on expected regret.\nWe assume truthful bidding and a cooperative coordination mechanism, as we are\nconsidering healthcare scenarios. We illustrate the performance of our\ncoordinated MDP approach against a Monte-Carlo based planning algorithm\nintended for large-scale applications, as well as other approaches suitable for\nallocating medical resources. The evaluations show that the global utility\nvalue across all consumer agents is closer to optimal when using our algorithms\nunder certain time constraints, with low computational cost. As such, we offer\na promising approach for addressing complex resource allocation problems that\narise in healthcare settings.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jul 2014 05:07:59 GMT"}], "update_date": "2014-07-08", "authors_parsed": [["Hosseini", "Hadi", ""], ["Hoey", "Jesse", ""], ["Cohen", "Robin", ""]]}, {"id": "1407.1933", "submitter": "Adam Saulwick", "authors": "Adam Saulwick", "title": "Lexpresso: a Controlled Natural Language", "comments": "12 pages, 2 figures, 4th Workshop on Controlled Natural Language 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an overview of `Lexpresso', a Controlled Natural Language\ndeveloped at the Defence Science & Technology Organisation as a bidirectional\nnatural language interface to a high-level information fusion system. The paper\ndescribes Lexpresso's main features including lexical coverage, expressiveness\nand range of linguistic syntactic and semantic structures. It also touches on\nits tight integration with a formal semantic formalism and tentatively\nclassifies it against the PENS system.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jul 2014 02:53:29 GMT"}], "update_date": "2014-07-09", "authors_parsed": [["Saulwick", "Adam", ""]]}, {"id": "1407.2002", "submitter": "Simon Walk", "authors": "Simon Walk, Philipp Singer, Markus Strohmaier, Tania Tudorache, Mark\n  A. Musen and Natalya F. Noy", "title": "Discovering Beaten Paths in Collaborative Ontology-Engineering Projects\n  using Markov Chains", "comments": "Published in the Journal of Biomedical Informatics", "journal-ref": null, "doi": "10.1016/j.jbi.2014.06.004", "report-no": null, "categories": "cs.SI cs.AI cs.DL physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biomedical taxonomies, thesauri and ontologies in the form of the\nInternational Classification of Diseases (ICD) as a taxonomy or the National\nCancer Institute Thesaurus as an OWL-based ontology, play a critical role in\nacquiring, representing and processing information about human health. With\nincreasing adoption and relevance, biomedical ontologies have also\nsignificantly increased in size. For example, the 11th revision of the ICD,\nwhich is currently under active development by the WHO contains nearly 50,000\nclasses representing a vast variety of different diseases and causes of death.\nThis evolution in terms of size was accompanied by an evolution in the way\nontologies are engineered. Because no single individual has the expertise to\ndevelop such large-scale ontologies, ontology-engineering projects have evolved\nfrom small-scale efforts involving just a few domain experts to large-scale\nprojects that require effective collaboration between dozens or even hundreds\nof experts, practitioners and other stakeholders. Understanding how these\nstakeholders collaborate will enable us to improve editing environments that\nsupport such collaborations. We uncover how large ontology-engineering\nprojects, such as the ICD in its 11th revision, unfold by analyzing usage logs\nof five different biomedical ontology-engineering projects of varying sizes and\nscopes using Markov chains. We discover intriguing interaction patterns (e.g.,\nwhich properties users subsequently change) that suggest that large\ncollaborative ontology-engineering projects are governed by a few general\nprinciples that determine and drive development. From our analysis, we identify\ncommonalities and differences between different projects that have implications\nfor project managers, ontology editors, developers and contributors working on\ncollaborative ontology-engineering projects and tools in the biomedical domain.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jul 2014 09:08:25 GMT"}, {"version": "v2", "created": "Mon, 29 Feb 2016 10:20:17 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Walk", "Simon", ""], ["Singer", "Philipp", ""], ["Strohmaier", "Markus", ""], ["Tudorache", "Tania", ""], ["Musen", "Mark A.", ""], ["Noy", "Natalya F.", ""]]}, {"id": "1407.2483", "submitter": "Shyam Visweswaran", "authors": "Shyam Visweswaran and Gregory F. Cooper", "title": "Counting Markov Blanket Structures", "comments": "5 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Learning Markov blanket (MB) structures has proven useful in performing\nfeature selection, learning Bayesian networks (BNs), and discovering causal\nrelationships. We present a formula for efficiently determining the number of\nMB structures given a target variable and a set of other variables. As\nexpected, the number of MB structures grows exponentially. However, we show\nquantitatively that there are many fewer MB structures that contain the target\nvariable than there are BN structures that contain it. In particular, the ratio\nof BN structures to MB structures appears to increase exponentially in the\nnumber of variables.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jul 2014 14:02:01 GMT"}, {"version": "v2", "created": "Sat, 12 Jul 2014 17:23:57 GMT"}], "update_date": "2014-07-15", "authors_parsed": [["Visweswaran", "Shyam", ""], ["Cooper", "Gregory F.", ""]]}, {"id": "1407.2506", "submitter": "Ming Xu", "authors": "Ming Xu, Jianping Wu, Yiman Du, Haohan Wang, Geqi Qi, Kezhen Hu,\n  Yunpeng Xiao", "title": "Discovery of Important Crossroads in Road Network using Massive Taxi\n  Trajectories", "comments": null, "journal-ref": null, "doi": "10.1109/TITS.2018.2817282", "report-no": null, "categories": "cs.AI cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major problem in road network analysis is discovery of important\ncrossroads, which can provide useful information for transport planning.\nHowever, none of existing approaches addresses the problem of identifying\nnetwork-wide important crossroads in real road network. In this paper, we\npropose a novel data-driven based approach named CRRank to rank important\ncrossroads. Our key innovation is that we model the trip network reflecting\nreal travel demands with a tripartite graph, instead of solely analysis on the\ntopology of road network. To compute the importance scores of crossroads\naccurately, we propose a HITS-like ranking algorithm, in which a procedure of\nscore propagation on our tripartite graph is performed. We conduct experiments\non CRRank using a real-world dataset of taxi trajectories. Experiments verify\nthe utility of CRRank.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jul 2014 14:46:58 GMT"}, {"version": "v2", "created": "Thu, 10 Jul 2014 17:11:24 GMT"}, {"version": "v3", "created": "Thu, 17 Jul 2014 13:51:57 GMT"}, {"version": "v4", "created": "Thu, 7 Aug 2014 13:48:46 GMT"}, {"version": "v5", "created": "Wed, 10 Sep 2014 12:47:19 GMT"}, {"version": "v6", "created": "Fri, 18 Sep 2015 17:27:43 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Xu", "Ming", ""], ["Wu", "Jianping", ""], ["Du", "Yiman", ""], ["Wang", "Haohan", ""], ["Qi", "Geqi", ""], ["Hu", "Kezhen", ""], ["Xiao", "Yunpeng", ""]]}, {"id": "1407.2646", "submitter": "Yura Perov N", "authors": "Yura N. Perov, Frank D. Wood", "title": "Learning Probabilistic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a technique for generalising from data in which models are\nsamplers represented as program text. We establish encouraging empirical\nresults that suggest that Markov chain Monte Carlo probabilistic programming\ninference techniques coupled with higher-order probabilistic programming\nlanguages are now sufficiently powerful to enable successful inference of this\nkind in nontrivial domains. We also introduce a new notion of probabilistic\nprogram compilation and show how the same machinery might be used in the future\nto compile probabilistic programs for efficient reusable predictive inference.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jul 2014 22:06:18 GMT"}], "update_date": "2014-07-11", "authors_parsed": [["Perov", "Yura N.", ""], ["Wood", "Frank D.", ""]]}, {"id": "1407.2676", "submitter": "Peter Frazier", "authors": "Ilya O. Ryzhov and Peter I. Frazier and Warren B. Powell", "title": "A New Optimal Stepsize For Approximate Dynamic Programming", "comments": "Matlab files are included with the paper source", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate dynamic programming (ADP) has proven itself in a wide range of\napplications spanning large-scale transportation problems, health care, revenue\nmanagement, and energy systems. The design of effective ADP algorithms has many\ndimensions, but one crucial factor is the stepsize rule used to update a value\nfunction approximation. Many operations research applications are\ncomputationally intensive, and it is important to obtain good results quickly.\nFurthermore, the most popular stepsize formulas use tunable parameters and can\nproduce very poor results if tuned improperly. We derive a new stepsize rule\nthat optimizes the prediction error in order to improve the short-term\nperformance of an ADP algorithm. With only one, relatively insensitive tunable\nparameter, the new rule adapts to the level of noise in the problem and\nproduces faster convergence in numerical experiments.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jul 2014 02:34:15 GMT"}, {"version": "v2", "created": "Mon, 14 Jul 2014 00:24:14 GMT"}], "update_date": "2014-07-15", "authors_parsed": [["Ryzhov", "Ilya O.", ""], ["Frazier", "Peter I.", ""], ["Powell", "Warren B.", ""]]}, {"id": "1407.2776", "submitter": "Seyed-Mahdi Khaligh-Razavi", "authors": "Seyed-Mahdi Khaligh-Razavi", "title": "What you need to know about the state-of-the-art computational models of\n  object-vision: A tour through the models", "comments": "36 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models of object vision have been of great interest in computer vision and\nvisual neuroscience. During the last decades, several models have been\ndeveloped to extract visual features from images for object recognition tasks.\nSome of these were inspired by the hierarchical structure of primate visual\nsystem, and some others were engineered models. The models are varied in\nseveral aspects: models that are trained by supervision, models trained without\nsupervision, and models (e.g. feature extractors) that are fully hard-wired and\ndo not need training. Some of the models come with a deep hierarchical\nstructure consisting of several layers, and some others are shallow and come\nwith only one or two layers of processing. More recently, new models have been\ndeveloped that are not hand-tuned but trained using millions of images, through\nwhich they learn how to extract informative task-related features. Here I will\nsurvey all these different models and provide the reader with an intuitive, as\nwell as a more detailed, understanding of the underlying computations in each\nof the models.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jul 2014 13:15:18 GMT"}], "update_date": "2014-07-11", "authors_parsed": [["Khaligh-Razavi", "Seyed-Mahdi", ""]]}, {"id": "1407.2845", "submitter": "Emilio Ferrara", "authors": "Santa Agreste, Pasquale De Meo, Emilio Ferrara, Domenico Ursino", "title": "XML Matchers: approaches and challenges", "comments": "34 pages, 8 tables, 7 figures", "journal-ref": "Knowledge-based systems 66: 190-209, 2014", "doi": "10.1016/j.knosys.2014.04.044", "report-no": null, "categories": "cs.DB cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Schema Matching, i.e. the process of discovering semantic correspondences\nbetween concepts adopted in different data source schemas, has been a key topic\nin Database and Artificial Intelligence research areas for many years. In the\npast, it was largely investigated especially for classical database models\n(e.g., E/R schemas, relational databases, etc.). However, in the latest years,\nthe widespread adoption of XML in the most disparate application fields pushed\na growing number of researchers to design XML-specific Schema Matching\napproaches, called XML Matchers, aiming at finding semantic matchings between\nconcepts defined in DTDs and XSDs. XML Matchers do not just take well-known\ntechniques originally designed for other data models and apply them on\nDTDs/XSDs, but they exploit specific XML features (e.g., the hierarchical\nstructure of a DTD/XSD) to improve the performance of the Schema Matching\nprocess. The design of XML Matchers is currently a well-established research\narea. The main goal of this paper is to provide a detailed description and\nclassification of XML Matchers. We first describe to what extent the\nspecificities of DTDs/XSDs impact on the Schema Matching task. Then we\nintroduce a template, called XML Matcher Template, that describes the main\ncomponents of an XML Matcher, their role and behavior. We illustrate how each\nof these components has been implemented in some popular XML Matchers. We\nconsider our XML Matcher Template as the baseline for objectively comparing\napproaches that, at first glance, might appear as unrelated. The introduction\nof this template can be useful in the design of future XML Matchers. Finally,\nwe analyze commercial tools implementing XML Matchers and introduce two\nchallenging issues strictly related to this topic, namely XML source clustering\nand uncertainty management in XML Matchers.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jul 2014 16:14:11 GMT"}], "update_date": "2014-07-11", "authors_parsed": [["Agreste", "Santa", ""], ["De Meo", "Pasquale", ""], ["Ferrara", "Emilio", ""], ["Ursino", "Domenico", ""]]}, {"id": "1407.2873", "submitter": "Sergey Kulikov", "authors": "Sergey Kulikov", "title": "Possibilities of technologization of philosophical knowledge", "comments": "6 pages, in Russian, conference \"Constraction of Man\" (Russia, Tomsk,\n  2011, April 26-29)", "journal-ref": null, "doi": "10.13140/2.1.3036.7521", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Article purpose is the analysis of a question of possibility of\ntechnologization of philosophical knowledge. We understand the organization of\ncognitive activity which is guided by the set of methods guaranteed bringing to\nsuccessful (i.e. to precisely corresponding set parameters) to applied results\nas technologization. Transformation of sense of philosophy allows revealing\npossibilities of its technologization. The leading role in this process is\nplayed by philosophy of science which creates conditions for such\ntransformation. At the same time there is justified an appeal to branch\ncombination theory of the directions of scientific knowledge and partial\nrefusal of understanding of philosophy as synthetic knowledge in which the main\ntask is permission, instead of generation of paradoxes.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jul 2014 17:38:13 GMT"}], "update_date": "2015-02-09", "authors_parsed": [["Kulikov", "Sergey", ""]]}, {"id": "1407.2987", "submitter": "Eren Golge", "authors": "Eren Golge and Pinar Duygulu", "title": "FAME: Face Association through Model Evolution", "comments": "Draft version of the study", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We attack the problem of learning face models for public faces from\nweakly-labelled images collected from web through querying a name. The data is\nvery noisy even after face detection, with several irrelevant faces\ncorresponding to other people. We propose a novel method, Face Association\nthrough Model Evolution (FAME), that is able to prune the data in an iterative\nway, for the face models associated to a name to evolve. The idea is based on\ncapturing discriminativeness and representativeness of each instance and\neliminating the outliers. The final models are used to classify faces on novel\ndatasets with possibly different characteristics. On benchmark datasets, our\nresults are comparable to or better than state-of-the-art studies for the task\nof face identification.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jul 2014 23:52:44 GMT"}], "update_date": "2014-07-14", "authors_parsed": [["Golge", "Eren", ""], ["Duygulu", "Pinar", ""]]}, {"id": "1407.3130", "submitter": "Toby Walsh", "authors": "Toby Walsh", "title": "Allocation in Practice", "comments": "To appear in Proc. of 37th edition of the German Conference on\n  Artificial Intelligence (KI 2014), Springer LNCS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How do we allocate scarcere sources? How do we fairly allocate costs? These\nare two pressing challenges facing society today. I discuss two recent projects\nat NICTA concerning resource and cost allocation. In the first, we have been\nworking with FoodBank Local, a social startup working in collaboration with\nfood bank charities around the world to optimise the logistics of collecting\nand distributing donated food. Before we can distribute this food, we must\ndecide how to allocate it to different charities and food kitchens. This gives\nrise to a fair division problem with several new dimensions, rarely considered\nin the literature. In the second, we have been looking at cost allocation\nwithin the distribution network of a large multinational company. This also has\nseveral new dimensions rarely considered in the literature.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jul 2014 12:17:09 GMT"}, {"version": "v2", "created": "Wed, 16 Jul 2014 05:30:30 GMT"}], "update_date": "2014-07-17", "authors_parsed": [["Walsh", "Toby", ""]]}, {"id": "1407.3208", "submitter": "Brian Ruttenberg", "authors": "Brian E. Ruttenberg and Avi Pfeffer", "title": "Decision-Making with Complex Data Structures using Probabilistic\n  Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing decision-theoretic reasoning frameworks such as decision networks\nuse simple data structures and processes. However, decisions are often made\nbased on complex data structures, such as social networks and protein\nsequences, and rich processes involving those structures. We present a\nframework for representing decision problems with complex data structures using\nprobabilistic programming, allowing probabilistic models to be created with\nprogramming language constructs such as data structures and control flow. We\nprovide a way to use arbitrary data types with minimal effort from the user,\nand an approximate decision-making algorithm that is effective even when the\ninformation space is very large or infinite. Experimental results show our\nalgorithm working on problems with very large information spaces.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jul 2014 16:20:15 GMT"}], "update_date": "2014-07-14", "authors_parsed": [["Ruttenberg", "Brian E.", ""], ["Pfeffer", "Avi", ""]]}, {"id": "1407.3211", "submitter": "Faruk Karaaslan", "authors": "Faruk Karaaslan", "title": "Possibility neutrosophic soft sets with applications in decision making\n  and similarity measure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, concept of possibility neutrosophic soft set and its\noperations are defined, and their properties are studied. An application of\nthis theory in decision making is investigated. Also a similarity measure of\ntwo possibility neutrosophic soft sets is introduced and discussed. Finally an\napplication of this similarity measure is given to select suitable person for\nposition in a firm.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jul 2014 22:36:56 GMT"}], "update_date": "2014-07-14", "authors_parsed": [["Karaaslan", "Faruk", ""]]}, {"id": "1407.3247", "submitter": "Nicholas Mattei", "authors": "Haris Aziz, Serge Gaspers, Joachim Gudmundsson, Simon Mackenzie,\n  Nicholas Mattei and Toby Walsh", "title": "Computational Aspects of Multi-Winner Approval Voting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study computational aspects of three prominent voting rules that use\napproval ballots to elect multiple winners. These rules are satisfaction\napproval voting, proportional approval voting, and reweighted approval voting.\nWe first show that computing the winner for proportional approval voting is\nNP-hard, closing a long standing open problem. As none of the rules are\nstrategyproof, even for dichotomous preferences, we study various strategic\naspects of the rules. In particular, we examine the computational complexity of\ncomputing a best response for both a single agent and a group of agents. In\nmany settings, we show that it is NP-hard for an agent or agents to compute how\nbest to vote given a fixed set of approval ballots from the other agents.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jul 2014 18:40:22 GMT"}], "update_date": "2014-07-14", "authors_parsed": [["Aziz", "Haris", ""], ["Gaspers", "Serge", ""], ["Gudmundsson", "Joachim", ""], ["Mackenzie", "Simon", ""], ["Mattei", "Nicholas", ""], ["Walsh", "Toby", ""]]}, {"id": "1407.3269", "submitter": "Sakyasingha Dasgupta", "authors": "Guanjiao Ren, Weihai Chen, Sakyasingha Dasgupta, Christoph\n  Kolodziejski, Florentin W\\\"org\\\"otter, Poramate Manoonpong", "title": "Multiple chaotic central pattern generators with learning for legged\n  locomotion and malfunction compensation", "comments": "48 pages, 16 figures, Information Sciences 2014", "journal-ref": null, "doi": "10.1016/j.ins.2014.05.001", "report-no": null, "categories": "cs.AI cs.LG cs.NE cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  An originally chaotic system can be controlled into various periodic\ndynamics. When it is implemented into a legged robot's locomotion control as a\ncentral pattern generator (CPG), sophisticated gait patterns arise so that the\nrobot can perform various walking behaviors. However, such a single chaotic CPG\ncontroller has difficulties dealing with leg malfunction. Specifically, in the\nscenarios presented here, its movement permanently deviates from the desired\ntrajectory. To address this problem, we extend the single chaotic CPG to\nmultiple CPGs with learning. The learning mechanism is based on a simulated\nannealing algorithm. In a normal situation, the CPGs synchronize and their\ndynamics are identical. With leg malfunction or disability, the CPGs lose\nsynchronization leading to independent dynamics. In this case, the learning\nmechanism is applied to automatically adjust the remaining legs' oscillation\nfrequencies so that the robot adapts its locomotion to deal with the\nmalfunction. As a consequence, the trajectory produced by the multiple chaotic\nCPGs resembles the original trajectory far better than the one produced by only\na single CPG. The performance of the system is evaluated first in a physical\nsimulation of a quadruped as well as a hexapod robot and finally in a real\nsix-legged walking machine called AMOSII. The experimental results presented\nhere reveal that using multiple CPGs with learning is an effective approach for\nadaptive locomotion generation where, for instance, different body parts have\nto perform independent movements for malfunction compensation.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jul 2014 14:21:22 GMT"}], "update_date": "2014-09-02", "authors_parsed": [["Ren", "Guanjiao", ""], ["Chen", "Weihai", ""], ["Dasgupta", "Sakyasingha", ""], ["Kolodziejski", "Christoph", ""], ["W\u00f6rg\u00f6tter", "Florentin", ""], ["Manoonpong", "Poramate", ""]]}, {"id": "1407.3341", "submitter": "Marcus Hutter", "authors": "Marcus Hutter", "title": "Extreme State Aggregation Beyond MDPs", "comments": "28 LaTeX pages. 8 Theorems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a Reinforcement Learning setup where an agent interacts with an\nenvironment in observation-reward-action cycles without any (esp.\\ MDP)\nassumptions on the environment. State aggregation and more generally feature\nreinforcement learning is concerned with mapping histories/raw-states to\nreduced/aggregated states. The idea behind both is that the resulting reduced\nprocess (approximately) forms a small stationary finite-state MDP, which can\nthen be efficiently solved or learnt. We considerably generalize existing\naggregation results by showing that even if the reduced process is not an MDP,\nthe (q-)value functions and (optimal) policies of an associated MDP with same\nstate-space size solve the original problem, as long as the solution can\napproximately be represented as a function of the reduced states. This implies\nan upper bound on the required state space size that holds uniformly for all RL\nproblems. It may also explain why RL algorithms designed for MDPs sometimes\nperform well beyond MDPs.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jul 2014 04:10:43 GMT"}], "update_date": "2014-07-15", "authors_parsed": [["Hutter", "Marcus", ""]]}, {"id": "1407.3501", "submitter": "Jean-Baptiste Mouret", "authors": "Antoine Cully, Jeff Clune, Danesh Tarapore, Jean-Baptiste Mouret", "title": "Robots that can adapt like animals", "comments": null, "journal-ref": null, "doi": "10.1038/nature14422", "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As robots leave the controlled environments of factories to autonomously\nfunction in more complex, natural environments, they will have to respond to\nthe inevitable fact that they will become damaged. However, while animals can\nquickly adapt to a wide variety of injuries, current robots cannot \"think\noutside the box\" to find a compensatory behavior when damaged: they are limited\nto their pre-specified self-sensing abilities, can diagnose only anticipated\nfailure modes, and require a pre-programmed contingency plan for every type of\npotential damage, an impracticality for complex robots. Here we introduce an\nintelligent trial and error algorithm that allows robots to adapt to damage in\nless than two minutes, without requiring self-diagnosis or pre-specified\ncontingency plans. Before deployment, a robot exploits a novel algorithm to\ncreate a detailed map of the space of high-performing behaviors: This map\nrepresents the robot's intuitions about what behaviors it can perform and their\nvalue. If the robot is damaged, it uses these intuitions to guide a\ntrial-and-error learning algorithm that conducts intelligent experiments to\nrapidly discover a compensatory behavior that works in spite of the damage.\nExperiments reveal successful adaptations for a legged robot injured in five\ndifferent ways, including damaged, broken, and missing legs, and for a robotic\narm with joints broken in 14 different ways. This new technique will enable\nmore robust, effective, autonomous robots, and suggests principles that animals\nmay use to adapt to injury.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jul 2014 19:06:08 GMT"}, {"version": "v2", "created": "Wed, 23 Jul 2014 16:08:20 GMT"}, {"version": "v3", "created": "Mon, 18 Aug 2014 14:07:53 GMT"}, {"version": "v4", "created": "Wed, 27 May 2015 22:43:04 GMT"}], "update_date": "2015-05-29", "authors_parsed": [["Cully", "Antoine", ""], ["Clune", "Jeff", ""], ["Tarapore", "Danesh", ""], ["Mouret", "Jean-Baptiste", ""]]}, {"id": "1407.3512", "submitter": "Radhakrishnan Delhibabu", "authors": "Radhakrishnan Delhibabu and Andreas Behrend", "title": "A New Rational Algorithm for View Updating in Relational Databases", "comments": "arXiv admin note: substantial text overlap with arXiv:1301.5154", "journal-ref": null, "doi": "10.1007/s10489-014-0579-0", "report-no": null, "categories": "cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The dynamics of belief and knowledge is one of the major components of any\nautonomous system that should be able to incorporate new pieces of information.\nIn order to apply the rationality result of belief dynamics theory to various\npractical problems, it should be generalized in two respects: first it should\nallow a certain part of belief to be declared as immutable; and second, the\nbelief state need not be deductively closed. Such a generalization of belief\ndynamics, referred to as base dynamics, is presented in this paper, along with\nthe concept of a generalized revision algorithm for knowledge bases (Horn or\nHorn logic with stratified negation). We show that knowledge base dynamics has\nan interesting connection with kernel change via hitting set and abduction. In\nthis paper, we show how techniques from disjunctive logic programming can be\nused for efficient (deductive) database updates. The key idea is to transform\nthe given database together with the update request into a disjunctive\n(datalog) logic program and apply disjunctive techniques (such as minimal model\nreasoning) to solve the original update problem. The approach extends and\nintegrates standard techniques for efficient query answering and integrity\nchecking. The generation of a hitting set is carried out through a hyper\ntableaux calculus and magic set that is focused on the goal of minimality.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jul 2014 23:08:09 GMT"}], "update_date": "2014-11-11", "authors_parsed": [["Delhibabu", "Radhakrishnan", ""], ["Behrend", "Andreas", ""]]}, {"id": "1407.3832", "submitter": "Rob Miller", "authors": "Irene-Anna Diakidoy, Antonis Kakas, Loizos Michael and Rob Miller", "title": "Non-Monotonic Reasoning and Story Comprehension", "comments": null, "journal-ref": "Proceedings of the 15th International Workshop on Non-Monotonic\n  Reasoning (NMR 2014), Vienna, 1719 July, 2014", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a Reasoning about Actions and Change framework integrated\nwith Default Reasoning, suitable as a Knowledge Representation and Reasoning\nframework for Story Comprehension. The proposed framework, which is guided\nstrongly by existing knowhow from the Psychology of Reading and Comprehension,\nis based on the theory of argumentation from AI. It uses argumentation to\ncapture appropriate solutions to the frame, ramification and qualification\nproblems and generalizations of these problems required for text comprehension.\nIn this first part of the study the work concentrates on the central problem of\nintegration (or elaboration) of the explicit information from the narrative in\nthe text with the implicit (in the readers mind) common sense world knowledge\npertaining to the topic(s) of the story given in the text. We also report on\nour empirical efforts to gather background common sense world knowledge used by\nhumans when reading a story and to evaluate, through a prototype system, the\nability of our approach to capture both the majority and the variability of\nunderstanding of a story by the human readers in the experiments.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jul 2014 21:55:10 GMT"}], "update_date": "2014-07-16", "authors_parsed": [["Diakidoy", "Irene-Anna", ""], ["Kakas", "Antonis", ""], ["Michael", "Loizos", ""], ["Miller", "Rob", ""]]}, {"id": "1407.3836", "submitter": "David Toth", "authors": "David Toth", "title": "Imparo is complete by inverse subsumption", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Inverse subsumption for complete explanatory induction Yamamoto et al.\ninvestigate which inductive logic programming systems can learn a correct\nhypothesis $H$ by using the inverse subsumption instead of inverse entailment.\nWe prove that inductive logic programming system Imparo is complete by inverse\nsubsumption for learning a correct definite hypothesis $H$ wrt the definite\nbackground theory $B$ and ground atomic examples $E$, by establishing that\nthere exists a connected theory $T$ for $B$ and $E$ such that $H$ subsumes $T$.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jul 2014 22:21:22 GMT"}], "update_date": "2014-07-16", "authors_parsed": [["Toth", "David", ""]]}, {"id": "1407.3896", "submitter": "Tjitze Rienstra", "authors": "Richard Booth, Dov Gabbay, Souhila Kaci, Tjitze Rienstra, Leendert van\n  der Torre", "title": "Abduction and Dialogical Proof in Argumentation and Logic Programming", "comments": "Appears in the Proceedings of the 15th International Workshop on\n  Non-Monotonic Reasoning (NMR 2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a model of abduction in abstract argumentation, where changes to\nan argumentation framework act as hypotheses to explain the support of an\nobservation. We present dialogical proof theories for the main decision\nproblems (i.e., finding hypothe- ses that explain skeptical/credulous support)\nand we show that our model can be instantiated on the basis of abductive logic\nprograms.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jul 2014 07:18:32 GMT"}], "update_date": "2014-07-16", "authors_parsed": [["Booth", "Richard", ""], ["Gabbay", "Dov", ""], ["Kaci", "Souhila", ""], ["Rienstra", "Tjitze", ""], ["van der Torre", "Leendert", ""]]}, {"id": "1407.3926", "submitter": "Anton\\'in Ku\\v{c}era", "authors": "Miroslav Klimos, Antonin Kucera", "title": "Strategy Synthesis for General Deductive Games Based on SAT Solving", "comments": "A preliminary version submitted to a conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general framework for modelling and solving deductive games,\nwhere one player selects a secret code and the other player strives to discover\nthis code using a minimal number of allowed experiments that reveal some\npartial information about the code. The framework is implemented in a software\ntool Cobra, and its functionality is demonstrated by producing new results\nabout existing deductive games.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jul 2014 10:07:49 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2015 13:12:06 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Klimos", "Miroslav", ""], ["Kucera", "Antonin", ""]]}, {"id": "1407.4139", "submitter": "Pedro Alejandro Ortega", "authors": "Pedro A. Ortega", "title": "Subjectivity, Bayesianism, and Causality", "comments": "21 pages, 21 figures. Submitted to Special Issue of Pattern\n  Recognition Letters on \"Philosophical aspects of pattern recognition\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian probability theory is one of the most successful frameworks to model\nreasoning under uncertainty. Its defining property is the interpretation of\nprobabilities as degrees of belief in propositions about the state of the world\nrelative to an inquiring subject. This essay examines the notion of\nsubjectivity by drawing parallels between Lacanian theory and Bayesian\nprobability theory, and concludes that the latter must be enriched with causal\ninterventions to model agency. The central contribution of this work is an\nabstract model of the subject that accommodates causal interventions in a\nmeasure-theoretic formalisation. This formalisation is obtained through a\ngame-theoretic Ansatz based on modelling the inside and outside of the subject\nas an extensive-form game with imperfect information between two players.\nFinally, I illustrate the expressiveness of this model with an example of\ncausal induction.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jul 2014 20:16:10 GMT"}, {"version": "v2", "created": "Tue, 16 Sep 2014 03:51:42 GMT"}, {"version": "v3", "created": "Mon, 16 Feb 2015 21:27:16 GMT"}, {"version": "v4", "created": "Fri, 24 Apr 2015 19:59:32 GMT"}], "update_date": "2015-04-27", "authors_parsed": [["Ortega", "Pedro A.", ""]]}, {"id": "1407.4234", "submitter": "Emil Weydert", "authors": "Emil Weydert", "title": "A Plausibility Semantics for Abstract Argumentation Frameworks", "comments": "Proceedings of the 15th International Workshop on Non-Monotonic\n  Reasoning (NMR 2014). This is an improved and extended version of the\n  author's ECSQARU 2013 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and investigate a simple ranking-measure-based extension semantics\nfor abstract argumentation frameworks based on their generic instantiation by\ndefault knowledge bases and the ranking construction semantics for default\nreasoning. In this context, we consider the path from structured to logical to\nshallow semantic instantiations. The resulting well-justified JZ-extension\nsemantics diverges from more traditional approaches.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jul 2014 08:53:36 GMT"}], "update_date": "2014-07-17", "authors_parsed": [["Weydert", "Emil", ""]]}, {"id": "1407.4360", "submitter": "Rosangela Cintra", "authors": "Rosangela S. Cintra and Haroldo F. de Campos Velho", "title": "Data Assimilation by Artificial Neural Networks for an Atmospheric\n  General Circulation Model: Conventional Observation", "comments": "17 pages, 16 figures, monthly weather review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an approach for employing artificial neural networks (NN)\nto emulate an ensemble Kalman filter (EnKF) as a method of data assimilation.\nThe assimilation methods are tested in the Simplified Parameterizations\nPrimitivE-Equation Dynamics (SPEEDY) model, an atmospheric general circulation\nmodel (AGCM), using synthetic observational data simulating localization of\nballoon soundings. For the data assimilation scheme, the supervised NN, the\nmultilayer perceptrons (MLP-NN), is applied. The MLP-NN are able to emulate the\nanalysis from the local ensemble transform Kalman filter (LETKF). After the\ntraining process, the method using the MLP-NN is seen as a function of data\nassimilation. The NN were trained with data from first three months of 1982,\n1983, and 1984. A hind-casting experiment for the 1985 data assimilation cycle\nusing MLP-NN were performed with synthetic observations for January 1985. The\nnumerical results demonstrate the effectiveness of the NN technique for\natmospheric data assimilation. The results of the NN analyses are very close to\nthe results from the LETKF analyses, the differences of the monthly average of\nabsolute temperature analyses is of order 0.02. The simulations show that the\nmajor advantage of using the MLP-NN is better computational performance, since\nthe analyses have similar quality. The CPU-time cycle assimilation with MLP-NN\nis 90 times faster than cycle assimilation with LETKF for the numerical\nexperiment.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jul 2014 16:04:08 GMT"}], "update_date": "2014-07-17", "authors_parsed": [["Cintra", "Rosangela S.", ""], ["Velho", "Haroldo F. de Campos", ""]]}, {"id": "1407.4364", "submitter": "Muhammad Marwan Muhammad Fuad", "authors": "Muhammad Marwan Muhammad Fuad", "title": "One-Step or Two-Step Optimization and the Overfitting Phenomenon: A Case\n  Study on Time Series Classification", "comments": null, "journal-ref": "Proceedings of the 6th International Conference on Agents and\n  Artificial Intelligence -6 - 8 March, 2014", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the last few decades, optimization has been developing at a fast rate.\nBio-inspired optimization algorithms are metaheuristics inspired by nature.\nThese algorithms have been applied to solve different problems in engineering,\neconomics, and other domains. Bio-inspired algorithms have also been applied in\ndifferent branches of information technology such as networking and software\nengineering. Time series data mining is a field of information technology that\nhas its share of these applications too. In previous works we showed how\nbio-inspired algorithms such as the genetic algorithms and differential\nevolution can be used to find the locations of the breakpoints used in the\nsymbolic aggregate approximation of time series representation, and in another\nwork we showed how we can utilize the particle swarm optimization, one of the\nfamous bio-inspired algorithms, to set weights to the different segments in the\nsymbolic aggregate approximation representation. In this paper we present, in\ntwo different approaches, a new meta optimization process that produces optimal\nlocations of the breakpoints in addition to optimal weights of the segments.\nThe experiments of time series classification task that we conducted show an\ninteresting example of how the overfitting phenomenon, a frequently encountered\nproblem in data mining which happens when the model overfits the training set,\ncan interfere in the optimization process and hide the superior performance of\nan optimization algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jul 2014 16:12:16 GMT"}], "update_date": "2014-07-17", "authors_parsed": [["Fuad", "Muhammad Marwan Muhammad", ""]]}, {"id": "1407.4490", "submitter": "Shalini Ghosh", "authors": "Shalini Ghosh, Patrick Lincoln, Christian Petersen, Alfonso Valdes", "title": "Virus Detection in Multiplexed Nanowire Arrays using Hidden Semi-Markov\n  models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the problem of real-time detection of viruses\ndocking to nanowires, especially when multiple viruses dock to the same\nnano-wire. The task becomes more complicated when there is an array of\nnanowires coated with different antibodies, where different viruses can dock to\neach coated nanowire at different binding strengths. We model the array\nresponse to a viral agent as a pattern of conductance change over nanowires\nwith known modifier --- this representation permits analysis of the output of\nsuch an array via belief network (Bayes) methods, as well as novel generative\nmodels like the Hidden Semi-Markov Model (HSMM).\n", "versions": [{"version": "v1", "created": "Wed, 16 Jul 2014 20:33:11 GMT"}], "update_date": "2014-07-18", "authors_parsed": [["Ghosh", "Shalini", ""], ["Lincoln", "Patrick", ""], ["Petersen", "Christian", ""], ["Valdes", "Alfonso", ""]]}, {"id": "1407.4709", "submitter": "Vadim Bulitko", "authors": "Vadim Bulitko", "title": "Flow for Meta Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The psychological state of flow has been linked to optimizing human\nperformance. A key condition of flow emergence is a match between the human\nabilities and complexity of the task. We propose a simple computational model\nof flow for Artificial Intelligence (AI) agents. The model factors the standard\nagent-environment state into a self-reflective set of the agent's abilities and\na socially learned set of the environmental complexity. Maximizing the flow\nserves as a meta control for the agent. We show how to apply the meta-control\npolicy to a broad class of AI control policies and illustrate our approach with\na specific implementation. Results in a synthetic testbed are promising and\nopen interesting directions for future work.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jul 2014 15:31:03 GMT"}], "update_date": "2014-07-18", "authors_parsed": [["Bulitko", "Vadim", ""]]}, {"id": "1407.4832", "submitter": "Ernesto Diaz-Aviles", "authors": "Bernat Coma-Puig and Ernesto Diaz-Aviles and Wolfgang Nejdl", "title": "Collaborative Filtering Ensemble for Personalized Name Recommendation", "comments": "Top-N recommendation; personalized ranking; given name recommendation", "journal-ref": "Proceedings of the ECML PKDD Discovery Challenge - Recommending\n  Given Names. Co-located with ECML PKDD 2013. Prague, Czech Republic,\n  September 27, 2013", "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Out of thousands of names to choose from, picking the right one for your\nchild is a daunting task. In this work, our objective is to help parents making\nan informed decision while choosing a name for their baby. We follow a\nrecommender system approach and combine, in an ensemble, the individual\nrankings produced by simple collaborative filtering algorithms in order to\nproduce a personalized list of names that meets the individual parents' taste.\nOur experiments were conducted using real-world data collected from the query\nlogs of 'nameling' (nameling.net), an online portal for searching and exploring\nnames, which corresponds to the dataset released in the context of the ECML\nPKDD Discover Challenge 2013. Our approach is intuitive, easy to implement, and\nfeatures fast training and prediction steps.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jul 2014 12:07:36 GMT"}], "update_date": "2014-07-21", "authors_parsed": [["Coma-Puig", "Bernat", ""], ["Diaz-Aviles", "Ernesto", ""], ["Nejdl", "Wolfgang", ""]]}, {"id": "1407.4833", "submitter": "Nikita Zhiltsov", "authors": "Olga Nevzorova, Nikita Zhiltsov, Alexander Kirillovich, and Evgeny\n  Lipachev", "title": "$OntoMath^{PRO}$ Ontology: A Linked Data Hub for Mathematics", "comments": "15 pages, 6 images, 1 table, Knowledge Engineering and the Semantic\n  Web - 5th International Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an ontology of mathematical knowledge concepts that\ncovers a wide range of the fields of mathematics and introduces a balanced\nrepresentation between comprehensive and sensible models. We demonstrate the\napplications of this representation in information extraction, semantic search,\nand education. We argue that the ontology can be a core of future integration\nof math-aware data sets in the Web of Data and, therefore, provide mappings\nonto relevant datasets, such as DBpedia and ScienceWISE.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jul 2014 20:36:36 GMT"}, {"version": "v2", "created": "Mon, 11 Aug 2014 06:54:16 GMT"}], "update_date": "2014-08-12", "authors_parsed": [["Nevzorova", "Olga", ""], ["Zhiltsov", "Nikita", ""], ["Kirillovich", "Alexander", ""], ["Lipachev", "Evgeny", ""]]}, {"id": "1407.4863", "submitter": "GamalAbd El-Nasser A. Said", "authors": "Gamal Abd El-Nasser A. Said, Abeer M. Mahmoud and El-Sayed M.\n  El-Horbaty", "title": "A Comparative Study of Meta-heuristic Algorithms for Solving Quadratic\n  Assignment Problem", "comments": "6 pages, 3 figures", "journal-ref": "(IJACSA) International Journal of Advanced Computer Science and\n  Applications,Vol. 5 No. 1, 2014", "doi": "10.14569/IJACSA.2014.050101", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quadratic Assignment Problem (QAP) is an NP-hard combinatorial optimization\nproblem, therefore, solving the QAP requires applying one or more of the\nmeta-heuristic algorithms. This paper presents a comparative study between\nMeta-heuristic algorithms: Genetic Algorithm, Tabu Search, and Simulated\nannealing for solving a real-life (QAP) and analyze their performance in terms\nof both runtime efficiency and solution quality. The results show that Genetic\nAlgorithm has a better solution quality while Tabu Search has a faster\nexecution time in comparison with other Meta-heuristic algorithms for solving\nQAP.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jul 2014 01:08:27 GMT"}], "update_date": "2014-07-21", "authors_parsed": [["Said", "Gamal Abd El-Nasser A.", ""], ["Mahmoud", "Abeer M.", ""], ["El-Horbaty", "El-Sayed M.", ""]]}, {"id": "1407.5212", "submitter": "Kandarp Khandwala", "authors": "Kandarp Khandwala, Rudra Sharma, Snehal Rao", "title": "Context Aware Dynamic Traffic Signal Optimization", "comments": null, "journal-ref": "International Journal of Computer Applications 100(13):24-28,\n  August 2014", "doi": "10.5120/17586-8253", "report-no": "17586-8253", "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional urban traffic control systems have been based on historical\ntraffic data. Later advancements made use of detectors, which enabled the\ngathering of real time traffic data, in order to reorganize and calibrate\ntraffic signalization programs. Further evolvement provided the ability to\nforecast traffic conditions, in order to develop traffic signalization programs\nand strategies precomputed and applied at the most appropriate time frame for\nthe optimal control of the current traffic conditions. We, propose the next\ngeneration of traffic control systems based on principles of Artificial\nIntelligence and Context Awareness. Most of the existing algorithms use average\nwaiting time or length of the queue to assess an algorithms performance.\nHowever, a low average waiting time may come at the cost of delaying other\nvehicles indefinitely. In our algorithm, besides the vehicle queue, we use\nfairness also as an important performance metric to assess an algorithms\nperformance.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jul 2014 18:15:54 GMT"}], "update_date": "2014-09-22", "authors_parsed": [["Khandwala", "Kandarp", ""], ["Sharma", "Rudra", ""], ["Rao", "Snehal", ""]]}, {"id": "1407.5358", "submitter": "Andr\\'e Barreto", "authors": "Andr\\'e M. S. Barreto, Doina Precup, and Joelle Pineau", "title": "Practical Kernel-Based Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel-based reinforcement learning (KBRL) stands out among reinforcement\nlearning algorithms for its strong theoretical guarantees. By casting the\nlearning problem as a local kernel approximation, KBRL provides a way of\ncomputing a decision policy which is statistically consistent and converges to\na unique solution. Unfortunately, the model constructed by KBRL grows with the\nnumber of sample transitions, resulting in a computational cost that precludes\nits application to large-scale or on-line domains. In this paper we introduce\nan algorithm that turns KBRL into a practical reinforcement learning tool.\nKernel-based stochastic factorization (KBSF) builds on a simple idea: when a\ntransition matrix is represented as the product of two stochastic matrices, one\ncan swap the factors of the multiplication to obtain another transition matrix,\npotentially much smaller, which retains some fundamental properties of its\nprecursor. KBSF exploits such an insight to compress the information contained\nin KBRL's model into an approximator of fixed size. This makes it possible to\nbuild an approximation that takes into account both the difficulty of the\nproblem and the associated computational cost. KBSF's computational complexity\nis linear in the number of sample transitions, which is the best one can do\nwithout discarding data. Moreover, the algorithm's simple mechanics allow for a\nfully incremental implementation that makes the amount of memory used\nindependent of the number of sample transitions. The result is a kernel-based\nreinforcement learning algorithm that can be applied to large-scale problems in\nboth off-line and on-line regimes. We derive upper bounds for the distance\nbetween the value functions computed by KBRL and KBSF using the same data. We\nalso illustrate the potential of our algorithm in an extensive empirical study\nin which KBSF is applied to difficult tasks based on real-world data.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jul 2014 01:20:45 GMT"}], "update_date": "2014-07-22", "authors_parsed": [["Barreto", "Andr\u00e9 M. S.", ""], ["Precup", "Doina", ""], ["Pineau", "Joelle", ""]]}, {"id": "1407.5380", "submitter": "Dongmo Zhang", "authors": "Dongmo Zhang and Michael Thielsher", "title": "Representing and Reasoning about Game Strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  As a contribution to the challenge of building game-playing AI systems, we\ndevelop and analyse a formal language for representing and reasoning about\nstrategies. Our logical language builds on the existing general Game\nDescription Language (GDL) and extends it by a standard modality for linear\ntime along with two dual connectives to express preferences when combining\nstrategies. The semantics of the language is provided by a standard\nstate-transition model. As such, problems that require reasoning about games\ncan be solved by the standard methods for reasoning about actions and change.\nWe also endow the language with a specific semantics by which strategy formulas\nare understood as move recommendations for a player. To illustrate how our\nformalism supports automated reasoning about strategies, we demonstrate two\nexample methods of implementation\\/: first, we formalise the semantic\ninterpretation of our language in conjunction with game rules and strategy\nrules in the Situation Calculus; second, we show how the reasoning problem can\nbe solved with Answer Set Programming.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jul 2014 06:15:27 GMT"}], "update_date": "2014-07-22", "authors_parsed": [["Zhang", "Dongmo", ""], ["Thielsher", "Michael", ""]]}, {"id": "1407.5397", "submitter": "EPTCS", "authors": "Susmit Jha (Strategic CAD Labs, Intel), Sanjit A. Seshia (EECS, UC\n  Berkeley)", "title": "Are There Good Mistakes? A Theoretical Analysis of CEGIS", "comments": "In Proceedings SYNT 2014, arXiv:1407.4937", "journal-ref": "EPTCS 157, 2014, pp. 84-99", "doi": "10.4204/EPTCS.157.10", "report-no": null, "categories": "cs.LO cs.AI cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterexample-guided inductive synthesis CEGIS is used to synthesize\nprograms from a candidate space of programs. The technique is guaranteed to\nterminate and synthesize the correct program if the space of candidate programs\nis finite. But the technique may or may not terminate with the correct program\nif the candidate space of programs is infinite. In this paper, we perform a\ntheoretical analysis of counterexample-guided inductive synthesis technique. We\ninvestigate whether the set of candidate spaces for which the correct program\ncan be synthesized using CEGIS depends on the counterexamples used in inductive\nsynthesis, that is, whether there are good mistakes which would increase the\nsynthesis power. We investigate whether the use of minimal counterexamples\ninstead of arbitrary counterexamples expands the set of candidate spaces of\nprograms for which inductive synthesis can successfully synthesize a correct\nprogram. We consider two kinds of counterexamples: minimal counterexamples and\nhistory bounded counterexamples. The history bounded counterexample used in any\niteration of CEGIS is bounded by the examples used in previous iterations of\ninductive synthesis. We examine the relative change in power of inductive\nsynthesis in both cases. We show that the synthesis technique using minimal\ncounterexamples MinCEGIS has the same synthesis power as CEGIS but the\nsynthesis technique using history bounded counterexamples HCEGIS has different\npower than that of CEGIS, but none dominates the other.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jul 2014 07:28:49 GMT"}], "update_date": "2014-07-22", "authors_parsed": [["Jha", "Susmit", "", "Strategic CAD Labs, Intel"], ["Seshia", "Sanjit A.", "", "EECS, UC\n  Berkeley"]]}, {"id": "1407.5574", "submitter": "Sandeep Kumar", "authors": "Sandeep Kumar, Vivek Kumar Sharma, Rajani Kumari", "title": "A Novel Hybrid Crossover based Artificial Bee Colony Algorithm for\n  Optimization Problem", "comments": null, "journal-ref": null, "doi": "10.5120/14136-2266", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial bee colony (ABC) algorithm has proved its importance in solving a\nnumber of problems including engineering optimization problems. ABC algorithm\nis one of the most popular and youngest member of the family of population\nbased nature inspired meta-heuristic swarm intelligence method. ABC has been\nproved its superiority over some other Nature Inspired Algorithms (NIA) when\napplied for both benchmark functions and real world problems. The performance\nof search process of ABC depends on a random value which tries to balance\nexploration and exploitation phase. In order to increase the performance it is\nrequired to balance the exploration of search space and exploitation of optimal\nsolution of the ABC. This paper outlines a new hybrid of ABC algorithm with\nGenetic Algorithm. The proposed method integrates crossover operation from\nGenetic Algorithm (GA) with original ABC algorithm. The proposed method is\nnamed as Crossover based ABC (CbABC). The CbABC strengthens the exploitation\nphase of ABC as crossover enhances exploration of search space. The CbABC\ntested over four standard benchmark functions and a popular continuous\noptimization problem.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jul 2014 17:13:43 GMT"}], "update_date": "2014-07-23", "authors_parsed": [["Kumar", "Sandeep", ""], ["Sharma", "Vivek Kumar", ""], ["Kumari", "Rajani", ""]]}, {"id": "1407.5656", "submitter": "Khalifeh AlJadda", "authors": "Khalifeh AlJadda, Mohammed Korayem, Camilo Ortiz, Trey Grainger, John\n  A. Miller, William S. York", "title": "PGMHD: A Scalable Probabilistic Graphical Model for Massive Hierarchical\n  Data Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the big data era, scalability has become a crucial requirement for any\nuseful computational model. Probabilistic graphical models are very useful for\nmining and discovering data insights, but they are not scalable enough to be\nsuitable for big data problems. Bayesian Networks particularly demonstrate this\nlimitation when their data is represented using few random variables while each\nrandom variable has a massive set of values. With hierarchical data - data that\nis arranged in a treelike structure with several levels - one would expect to\nsee hundreds of thousands or millions of values distributed over even just a\nsmall number of levels. When modeling this kind of hierarchical data across\nlarge data sets, Bayesian networks become infeasible for representing the\nprobability distributions for the following reasons: i) Each level represents a\nsingle random variable with hundreds of thousands of values, ii) The number of\nlevels is usually small, so there are also few random variables, and iii) The\nstructure of the network is predefined since the dependency is modeled top-down\nfrom each parent to each of its child nodes, so the network would contain a\nsingle linear path for the random variables from each parent to each child\nnode. In this paper we present a scalable probabilistic graphical model to\novercome these limitations for massive hierarchical data. We believe the\nproposed model will lead to an easily-scalable, more readable, and expressive\nimplementation for problems that require probabilistic-based solutions for\nmassive amounts of hierarchical data. We successfully applied this model to\nsolve two different challenging probabilistic-based problems on massive\nhierarchical data sets for different domains, namely, bioinformatics and latent\nsemantic discovery over search logs.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jul 2014 20:26:32 GMT"}, {"version": "v2", "created": "Tue, 19 Aug 2014 21:06:27 GMT"}], "update_date": "2014-08-21", "authors_parsed": [["AlJadda", "Khalifeh", ""], ["Korayem", "Mohammed", ""], ["Ortiz", "Camilo", ""], ["Grainger", "Trey", ""], ["Miller", "John A.", ""], ["York", "William S.", ""]]}, {"id": "1407.5754", "submitter": "Truyen Tran", "authors": "Truyen Tran, Dinh Phung, Svetha Venkatesh", "title": "Tree-based iterated local search for Markov random fields with\n  applications in image analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \\emph{maximum a posteriori} (MAP) assignment for general structure Markov\nrandom fields (MRFs) is computationally intractable. In this paper, we exploit\ntree-based methods to efficiently address this problem. Our novel method, named\nTree-based Iterated Local Search (T-ILS) takes advantage of the tractability of\ntree-structures embedded within MRFs to derive strong local search in an ILS\nframework. The method efficiently explores exponentially large neighborhood and\ndoes so with limited memory without any requirement on the cost functions. We\nevaluate the T-ILS in a simulation of Ising model and two real-world problems\nin computer vision: stereo matching, image denoising. Experimental results\ndemonstrate that our methods are competitive against state-of-the-art rivals\nwith a significant computational gain.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jul 2014 06:43:41 GMT"}], "update_date": "2014-07-23", "authors_parsed": [["Tran", "Truyen", ""], ["Phung", "Dinh", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1407.6090", "submitter": "arXiv Admin", "authors": "Jyoti Chaturvedi, Anubha Parashar, Amrita A Manjrekar, Vinay S Bhaskar", "title": "Social and Business Intelligence Analysis Using PSO", "comments": "This article has been withdrawn by arXiv administrators due to\n  disputed authorship", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to elaborate swarm intelligence for business\nintelligence decision making and the business rules management improvement.\n.The swarm optimization, which is highly influenced by the behavior of\ncreature, performs in group. The Spatial data is defined as data that is\nrepresented by 2D or 3D images. SQL Server supports only 2D images till now. As\nwe know that location is an essential part of any organizational data as well\nas business data enterprises maintain customer address lists, own property,\nship goods from and to warehouses, manage transport flows among their\nworkforce, and perform many other activities. By means to say a lot of spatial\ndata is used and processed by enterprises, organizations and other bodies in\norder to make the things more visible and self descriptive. From the\nexperiments, we found that PSO is can facilitate the intelligence in social and\nbusiness behavior.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jul 2014 02:14:48 GMT"}, {"version": "v2", "created": "Thu, 25 Aug 2016 16:24:39 GMT"}], "update_date": "2016-08-26", "authors_parsed": [["Chaturvedi", "Jyoti", ""], ["Parashar", "Anubha", ""], ["Manjrekar", "Amrita A", ""], ["Bhaskar", "Vinay S", ""]]}, {"id": "1407.6166", "submitter": "Evgeniy Vodolazskiy", "authors": "Michail Schlesinger, Boris Flach, Evgeniy Vodolazskiy", "title": "M-best solutions for a class of fuzzy constraint satisfaction problems", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article considers one of the possible generalizations of constraint\nsatisfaction problems where relations are replaced by multivalued membership\nfunctions. In this case operations of disjunction and conjunction are replaced\nby maximum and minimum, and consistency of a solution becomes multivalued\nrather than binary. The article studies the problem of finding d most\nadmissible solutions for a given d. A tractable subclass of these problems is\ndefined by the concepts of invariants and polymorphisms similar to the classic\nconstraint satisfaction approach. These concepts are adapted in two ways.\nFirstly, the correspondence of \"invariant-polymorphism\" is generalized to\n(min,max) semirings. Secondly, we consider non-uniform polymorphisms, where\neach variable has its own operator, in contrast to the case of one operator\ncommon for all variables. The article describes an algorithm that finds $d$\nmost admissible solutions in polynomial time, provided that the problem is\ninvariant with respect to some non-uniform majority operator. It is essential\nthat this operator needs not to be known for the algorithm to work. Moreover,\neven a guarantee for the existence of such an operator is not necessary. The\nalgorithm either finds the solution or discards the problem. The latter is\npossible only if the problem has no majority polymorphism.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jul 2014 10:48:09 GMT"}], "update_date": "2014-07-24", "authors_parsed": [["Schlesinger", "Michail", ""], ["Flach", "Boris", ""], ["Vodolazskiy", "Evgeniy", ""]]}, {"id": "1407.6315", "submitter": "Deepak Kumar", "authors": "Deepak Kumar, A G Ramakrishnan", "title": "Quadratically constrained quadratic programming for classification using\n  particle swarms and applications", "comments": "17 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle swarm optimization is used in several combinatorial optimization\nproblems. In this work, particle swarms are used to solve quadratic programming\nproblems with quadratic constraints. The approach of particle swarms is an\nexample for interior point methods in optimization as an iterative technique.\nThis approach is novel and deals with classification problems without the use\nof a traditional classifier. Our method determines the optimal hyperplane or\nclassification boundary for a data set. In a binary classification problem, we\nconstrain each class as a cluster, which is enclosed by an ellipsoid. The\nestimation of the optimal hyperplane between the two clusters is posed as a\nquadratically constrained quadratic problem. The optimization problem is solved\nin distributed format using modified particle swarms. Our method has the\nadvantage of using the direction towards optimal solution rather than searching\nthe entire feasible region. Our results on the Iris, Pima, Wine, and Thyroid\ndatasets show that the proposed method works better than a neural network and\nthe performance is close to that of SVM.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jul 2014 18:04:23 GMT"}], "update_date": "2014-07-24", "authors_parsed": [["Kumar", "Deepak", ""], ["Ramakrishnan", "A G", ""]]}, {"id": "1407.6513", "submitter": "Amir Hesam Salavati", "authors": "Amin Karbasi, Amir Hesam Salavati, Amin Shokrollahi", "title": "Convolutional Neural Associative Memories: Massive Capacity with Noise\n  Tolerance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of a neural associative memory is to retrieve a set of previously\nmemorized patterns from their noisy versions using a network of neurons. An\nideal network should have the ability to 1) learn a set of patterns as they\narrive, 2) retrieve the correct patterns from noisy queries, and 3) maximize\nthe pattern retrieval capacity while maintaining the reliability in responding\nto queries. The majority of work on neural associative memories has focused on\ndesigning networks capable of memorizing any set of randomly chosen patterns at\nthe expense of limiting the retrieval capacity. In this paper, we show that if\nwe target memorizing only those patterns that have inherent redundancy (i.e.,\nbelong to a subspace), we can obtain all the aforementioned properties. This is\nin sharp contrast with the previous work that could only improve one or two\naspects at the expense of the third. More specifically, we propose framework\nbased on a convolutional neural network along with an iterative algorithm that\nlearns the redundancy among the patterns. The resulting network has a retrieval\ncapacity that is exponential in the size of the network. Moreover, the\nasymptotic error correction performance of our network is linear in the size of\nthe patterns. We then ex- tend our approach to deal with patterns lie\napproximately in a subspace. This extension allows us to memorize datasets\ncontaining natural patterns (e.g., images). Finally, we report experimental\nresults on both synthetic and real datasets to support our claims.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jul 2014 10:06:24 GMT"}], "update_date": "2014-07-25", "authors_parsed": [["Karbasi", "Amin", ""], ["Salavati", "Amir Hesam", ""], ["Shokrollahi", "Amin", ""]]}, {"id": "1407.6699", "submitter": "Eduardo Vega-Fuentes", "authors": "Eduardo Vega-Fuentes, Juan Manuel Cerezo-Sanchez, Sonia Leon-del\n  Rosario and Aurelio Vega-Martinez", "title": "Fuzzy inference system for integrated VVC in isolated power systems", "comments": "arXiv admin note: substantial text overlap with arXiv:1401.1632", "journal-ref": "International Journal of Artificial Intelligence & Aplications,\n  (IJAIA), January 2014, Volume 5, Number 1, pp 91-106", "doi": "10.5121/ijaia.2014.5107", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a fuzzy inference system for integrated volt/var control\n(VVC) in distribution substations. The purpose is go forward to automation\ndistribution applying conservation voltage reduction (CVR) in isolated power\nsystems where control capabilities are limited. A fuzzy controller has been\ndesigned. Working as an on-line tool, it has been tested under real conditions\nand it has managed the operation during a whole day in a distribution\nsubstation. Within the limits of control capabilities of the system, the\ncontroller maintained successfully an acceptable voltage profile, power factor\nvalues over 0,98 and it has ostensibly improved the performance given by an\noptimal power flow based automation system. CVR savings during the test are\nevaluated and the aim to integrate it in the VVC is presented.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2014 12:30:47 GMT"}], "update_date": "2014-07-25", "authors_parsed": [["Vega-Fuentes", "Eduardo", ""], ["Cerezo-Sanchez", "Juan Manuel", ""], ["Rosario", "Sonia Leon-del", ""], ["Vega-Martinez", "Aurelio", ""]]}, {"id": "1407.6885", "submitter": "Marie-Laure Mugnier", "authors": "Jean-Francois Baget, Fabien Garreau, Marie-Laure Mugnier, Swan Rocher", "title": "Extending Acyclicity Notions for Existential Rules (\\emph{long version})", "comments": "This report contains a revised version (July 2014) of the paper that\n  will appear in the proceedings of ECAI 2014 and an appendix with proofs that\n  could not be included in the paper for space restriction reasons", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existential rules have been proposed for representing ontological knowledge,\nspecifically in the context of Ontology-Based Query Answering. Entailment with\nexistential rules is undecidable. We focus in this paper on conditions that\nensure the termination of a breadth-first forward chaining algorithm known as\nthe chase. First, we propose a new tool that allows to extend existing\nacyclicity conditions ensuring chase termination, while keeping good complexity\nproperties. Second, we consider the extension to existential rules with\nnonmonotonic negation under stable model semantics and further extend\nacyclicity results obtained in the positive case.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jul 2014 13:27:34 GMT"}], "update_date": "2014-07-28", "authors_parsed": [["Baget", "Jean-Francois", ""], ["Garreau", "Fabien", ""], ["Mugnier", "Marie-Laure", ""], ["Rocher", "Swan", ""]]}, {"id": "1407.7008", "submitter": "Lorenzo Livi", "authors": "Enrico De Santis, Lorenzo Livi, Alireza Sadeghian, Antonello Rizzi", "title": "Modeling and Recognition of Smart Grid Faults by a Combined Approach of\n  Dissimilarity Learning and One-Class Classification", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2015.05.112", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting faults in electrical power grids is of paramount importance, either\nfrom the electricity operator and consumer viewpoints. Modern electric power\ngrids (smart grids) are equipped with smart sensors that allow to gather\nreal-time information regarding the physical status of all the component\nelements belonging to the whole infrastructure (e.g., cables and related\ninsulation, transformers, breakers and so on). In real-world smart grid\nsystems, usually, additional information that are related to the operational\nstatus of the grid itself are collected such as meteorological information.\nDesigning a suitable recognition (discrimination) model of faults in a\nreal-world smart grid system is hence a challenging task. This follows from the\nheterogeneity of the information that actually determine a typical fault\ncondition. The second point is that, for synthesizing a recognition model, in\npractice only the conditions of observed faults are usually meaningful.\nTherefore, a suitable recognition model should be synthesized by making use of\nthe observed fault conditions only. In this paper, we deal with the problem of\nmodeling and recognizing faults in a real-world smart grid system, which\nsupplies the entire city of Rome, Italy. Recognition of faults is addressed by\nfollowing a combined approach of multiple dissimilarity measures customization\nand one-class classification techniques. We provide here an in-depth study\nrelated to the available data and to the models synthesized by the proposed\none-class classifier. We offer also a comprehensive analysis of the fault\nrecognition results by exploiting a fuzzy set based reliability decision rule.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jul 2014 19:15:25 GMT"}, {"version": "v2", "created": "Wed, 17 Dec 2014 15:46:26 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["De Santis", "Enrico", ""], ["Livi", "Lorenzo", ""], ["Sadeghian", "Alireza", ""], ["Rizzi", "Antonello", ""]]}, {"id": "1407.7138", "submitter": "Lorenzo Livi", "authors": "Lorenzo Livi, Alireza Sadeghian", "title": "Data granulation by the principles of uncertainty", "comments": "16 pages, 9 figures, 52 references", "journal-ref": null, "doi": "10.1016/j.patrec.2015.04.008", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researches in granular modeling produced a variety of mathematical models,\nsuch as intervals, (higher-order) fuzzy sets, rough sets, and shadowed sets,\nwhich are all suitable to characterize the so-called information granules.\nModeling of the input data uncertainty is recognized as a crucial aspect in\ninformation granulation. Moreover, the uncertainty is a well-studied concept in\nmany mathematical settings, such as those of probability theory, fuzzy set\ntheory, and possibility theory. This fact suggests that an appropriate\nquantification of the uncertainty expressed by the information granule model\ncould be used to define an invariant property, to be exploited in practical\nsituations of information granulation. In this perspective, a procedure of\ninformation granulation is effective if the uncertainty conveyed by the\nsynthesized information granule is in a monotonically increasing relation with\nthe uncertainty of the input data. In this paper, we present a data granulation\nframework that elaborates over the principles of uncertainty introduced by\nKlir. Being the uncertainty a mesoscopic descriptor of systems and data, it is\npossible to apply such principles regardless of the input data type and the\nspecific mathematical setting adopted for the information granules. The\nproposed framework is conceived (i) to offer a guideline for the synthesis of\ninformation granules and (ii) to build a groundwork to compare and\nquantitatively judge over different data granulation procedures. To provide a\nsuitable case study, we introduce a new data granulation technique based on the\nminimum sum of distances, which is designed to generate type-2 fuzzy sets. We\nanalyze the procedure by performing different experiments on two distinct data\ntypes: feature vectors and labeled graphs. Results show that the uncertainty of\nthe input data is suitably conveyed by the generated type-2 fuzzy set models.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jul 2014 16:03:13 GMT"}, {"version": "v2", "created": "Mon, 15 Sep 2014 14:42:35 GMT"}, {"version": "v3", "created": "Sun, 11 Jan 2015 18:57:41 GMT"}, {"version": "v4", "created": "Mon, 2 Mar 2015 13:46:50 GMT"}], "update_date": "2015-04-30", "authors_parsed": [["Livi", "Lorenzo", ""], ["Sadeghian", "Alireza", ""]]}, {"id": "1407.7180", "submitter": "Joseph Y. Halpern", "authors": "Joseph Y. Halpern", "title": "Defining Relative Likelihood in Partially-Ordered Preferential\n  Structures", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-299-306", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Starting with a likelihood or preference order on worlds, we extend it to a\nlikelihood ordering on sets of worlds in a natural way, and examine the\nresulting logic. Lewis (1973) earlier considered such a notion of relative\nlikelihood in the context of studying counterfactuals, but he assumed a total\npreference order on worlds. Complications arise when examining partial orders\nthat are not present for total orders. There are subtleties involving the exact\napproach to lifting the order on worlds to an order on sets of worlds. In\naddition, the axiomatization of the logic of relative likelihood in the case of\npartial orders gives insight into the connection between relative likelihood\nand default reasoning.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jul 2014 05:16:18 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Halpern", "Joseph Y.", ""]]}, {"id": "1407.7182", "submitter": "Joseph Y. Halpern", "authors": "Joseph Y. Halpern", "title": "Conditional Plausibility Measures and Bayesian Networks", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-247-255", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general notion of algebraic conditional plausibility measures is defined.\nProbability measures, ranking functions, possibility measures, and (under the\nappropriate definitions) sets of probability measures can all be viewed as\ndefining algebraic conditional plausibility measures. It is shown that the\ntechnology of Bayesian networks can be applied to algebraic conditional\nplausibility measures.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jul 2014 05:24:44 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Halpern", "Joseph Y.", ""]]}, {"id": "1407.7183", "submitter": "Peter D Grunwald", "authors": "Peter D. Grunwald, Joseph Y. Halpern", "title": "Updating Probabilities", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-187-196", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As examples such as the Monty Hall puzzle show, applying conditioning to\nupdate a probability distribution on a ``naive space', which does not take into\naccount the protocol used, can often lead to counterintuitive results. Here we\nexamine why. A criterion known as CAR (coarsening at random) in the statistical\nliterature characterizes when ``naive' conditioning in a naive space works. We\nshow that the CAR condition holds rather infrequently. We then consider more\ngeneralized notions of update such as Jeffrey conditioning and minimizing\nrelative entropy (MRE). We give a generalization of the CAR condition that\ncharacterizes when Jeffrey conditioning leads to appropriate answers, but show\nthat there are no such conditions for MRE. This generalizes and interconnects\nprevious results obtained in the literature on CAR and MRE.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jul 2014 05:25:17 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Grunwald", "Peter D.", ""], ["Halpern", "Joseph Y.", ""]]}, {"id": "1407.7184", "submitter": "Joseph Y. Halpern", "authors": "Joseph Y. Halpern, Riccardo Pucella", "title": "Reasoning about Expectation", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-207-215", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expectation is a central notion in probability theory. The notion of\nexpectation also makes sense for other notions of uncertainty. We introduce a\npropositional logic for reasoning about expectation, where the semantics\ndepends on the underlying representation of uncertainty. We give sound and\ncomplete axiomatizations for the logic in the case that the underlying\nrepresentation is (a) probability, (b) sets of probability measures, (c) belief\nfunctions, and (d) possibility measures. We show that this logic is more\nexpressive than the corresponding logic for reasoning about likelihood in the\ncase of sets of probability measures, but equi-expressive in the case of\nprobability, belief, and possibility. Finally, we show that satisfiability for\nthese logics is NP-complete, no harder than satisfiability for propositional\nlogic.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jul 2014 05:25:25 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Halpern", "Joseph Y.", ""], ["Pucella", "Riccardo", ""]]}, {"id": "1407.7185", "submitter": "Joseph Y. Halpern", "authors": "Joseph Y. Halpern, Riccardo Pucella", "title": "A Logic for Reasoning about Evidence", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-297-304", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a logic for reasoning about evidence, that essentially views\nevidence as a function from prior beliefs (before making an observation) to\nposterior beliefs (after making the observation). We provide a sound and\ncomplete axiomatization for the logic, and consider the complexity of the\ndecision problem. Although the reasoning in the logic is mainly propositional,\nwe allow variables representing numbers and quantification over them. This\nexpressive power seems necessary to capture important properties of evidence\n", "versions": [{"version": "v1", "created": "Sun, 27 Jul 2014 05:25:52 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Halpern", "Joseph Y.", ""], ["Pucella", "Riccardo", ""]]}, {"id": "1407.7188", "submitter": "Peter D Grunwald", "authors": "Peter D. Grunwald, Joseph Y. Halpern", "title": "When Ignorance is Bliss", "comments": "Appears in Proceedings of the Twentieth Conference on Uncertainty in\n  Artificial Intelligence (UAI2004)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2004-PG-226-234", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is commonly-accepted wisdom that more information is better, and that\ninformation should never be ignored. Here we argue, using both a Bayesian and a\nnon-Bayesian analysis, that in some situations you are better off ignoring\ninformation if your uncertainty is represented by a set of probability\nmeasures. These include situations in which the information is relevant for the\nprediction task at hand. In the non-Bayesian analysis, we show how ignoring\ninformation avoids dilation, the phenomenon that additional pieces of\ninformation sometimes lead to an increase in uncertainty. In the Bayesian\nanalysis, we show that for small sample sizes and certain prediction tasks, the\nBayesian posterior based on a noninformative prior yields worse predictions\nthan simply ignoring the given information.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jul 2014 05:34:39 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Grunwald", "Peter D.", ""], ["Halpern", "Joseph Y.", ""]]}, {"id": "1407.7189", "submitter": "Joseph Y. Halpern", "authors": "Joseph Y. Halpern, Riccardo Pucella", "title": "Evidence with Uncertain Likelihoods", "comments": "Appears in Proceedings of the Twenty-First Conference on Uncertainty\n  in Artificial Intelligence (UAI2005)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2005-PG-243-250", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An agent often has a number of hypotheses, and must choose among them based\non observations, or outcomes of experiments. Each of these observations can be\nviewed as providing evidence for or against various hypotheses. All the\nattempts to formalize this intuition up to now have assumed that associated\nwith each hypothesis h there is a likelihood function {\\mu}h, which is a\nprobability measure that intuitively describes how likely each observation is,\nconditional on h being the correct hypothesis. We consider an extension of this\nframework where there is uncertainty as to which of a number of likelihood\nfunctions is appropriate, and discuss how one formal approach to defining\nevidence, which views evidence as a function from priors to posteriors, can be\ngeneralized to accommodate this uncertainty.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jul 2014 05:35:44 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Halpern", "Joseph Y.", ""], ["Pucella", "Riccardo", ""]]}, {"id": "1407.7190", "submitter": "Peter D Grunwald", "authors": "Peter D. Grunwald, Joseph Y. Halpern", "title": "A Game-Theoretic Analysis of Updating Sets of Probabilities", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-240-247", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider how an agent should update her uncertainty when it is represented\nby a set P of probability distributions and the agent observes that a random\nvariable X takes on value x, given that the agent makes decisions using the\nminimax criterion, perhaps the best-studied and most commonly-used criterion in\nthe literature. We adopt a game-theoretic framework, where the agent plays\nagainst a bookie, who chooses some distribution from P. We consider two\nreasonable games that differ in what the bookie knows when he makes his choice.\nAnomalies that have been observed before, like time inconsistency, can be\nunderstood as arising because different games are being played, against bookies\nwith different information. We characterize the important special cases in\nwhich the optimal decision rules according to the minimax criterion amount to\neither conditioning or simply ignoring the information. Finally, we consider\nthe relationship between conditioning and calibration when uncertainty is\ndescribed by sets of probabilities.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jul 2014 05:37:10 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Grunwald", "Peter D.", ""], ["Halpern", "Joseph Y.", ""]]}, {"id": "1407.7191", "submitter": "Joseph Y. Halpern", "authors": "Joseph Y. Halpern, Nan Rong, Ashutosh Saxena", "title": "MDPs with Unawareness", "comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2010-PG-228-235", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov decision processes (MDPs) are widely used for modeling decision-making\nproblems in robotics, automated control, and economics. Traditional MDPs assume\nthat the decision maker (DM) knows all states and actions. However, this may\nnot be true in many situations of interest. We define a new framework, MDPs\nwith unawareness (MDPUs) to deal with the possibilities that a DM may not be\naware of all possible actions. We provide a complete characterization of when a\nDM can learn to play near-optimally in an MDPU, and give an algorithm that\nlearns to play near-optimally when it is possible to do so, as efficiently as\npossible. In particular, we characterize when a near-optimal solution can be\nfound in polynomial time.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jul 2014 05:37:48 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Halpern", "Joseph Y.", ""], ["Rong", "Nan", ""], ["Saxena", "Ashutosh", ""]]}, {"id": "1407.7211", "submitter": "Jo\\~ao Pedro Pedroso", "authors": "Jo\\~ao Pedro Pedroso", "title": "An evolutionary solver for linear integer programming", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce an evolutionary algorithm for the solution of\nlinear integer programs. The strategy is based on the separation of the\nvariables into the integer subset and the continuous subset; the integer\nvariables are fixed by the evolutionary system, and the continuous ones are\ndetermined in function of them, by a linear program solver.\n  We report results obtained for some standard benchmark problems, and compare\nthem with those obtained by branch-and-bound. The performance of the\nevolutionary algorithm is promising. Good feasible solutions were generally\nobtained, and in some of the difficult benchmark tests it outperformed\nbranch-and-bound.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jul 2014 11:45:21 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Pedroso", "Jo\u00e3o Pedro", ""]]}, {"id": "1407.7281", "submitter": "Eric J. Horvitz", "authors": "Eric J. Horvitz, David Heckerman", "title": "Modular Belief Updates and Confusion about Measures of Certainty in\n  Artificial Intelligence Research", "comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1985-PG-283-286", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last decade, there has been growing interest in the use or measures\nor change in belief for reasoning with uncertainty in artificial intelligence\nresearch. An important characteristic of several methodologies that reason with\nchanges in belief or belief updates, is a property that we term modularity. We\ncall updates that satisfy this property modular updates. Whereas probabilistic\nmeasures of belief update - which satisfy the modularity property were first\ndiscovered in the nineteenth century, knowledge and discussion of these\nquantities remains obscure in artificial intelligence research. We define\nmodular updates and discuss their inappropriate use in two influential expert\nsystems.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jul 2014 20:37:36 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Horvitz", "Eric J.", ""], ["Heckerman", "David", ""]]}, {"id": "1407.7417", "submitter": "Nabarun Mondal Mr", "authors": "Nabarun Mondal, Partha P. Ghosh", "title": "'Almost Sure' Chaotic Properties of Machine Learning Methods", "comments": "10 pages : to be submitted to Theoretical Computer Science. arXiv\n  admin note: text overlap with arXiv:1111.4949", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been demonstrated earlier that universal computation is 'almost\nsurely' chaotic. Machine learning is a form of computational fixed point\niteration, iterating over the computable function space. We showcase some\nproperties of this iteration, and establish in general that the iteration is\n'almost surely' of chaotic nature. This theory explains the observation in the\ncounter intuitive properties of deep learning methods. This paper demonstrates\nthat these properties are going to be universal to any learning method.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jul 2014 13:44:25 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Mondal", "Nabarun", ""], ["Ghosh", "Partha P.", ""]]}, {"id": "1407.7933", "submitter": "EPTCS", "authors": "Steffen Ziegert (University of Paderborn)", "title": "Graph Transformation Planning via Abstraction", "comments": "In Proceedings GRAPHITE 2014, arXiv:1407.7671", "journal-ref": "EPTCS 159, 2014, pp. 71-83", "doi": "10.4204/EPTCS.159.7", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern software systems increasingly incorporate self-* behavior to adapt to\nchanges in the environment at runtime. Such adaptations often involve\nreconfiguring the software architecture of the system. Many systems also need\nto manage their architecture themselves, i.e., they need a planning component\nto autonomously decide which reconfigurations to execute to reach a desired\ntarget configuration. For the specification of reconfigurations, we employ\ngraph transformations systems (GTS) due to the close relation of graphs and UML\nobject diagrams. We solve the resulting planning problems with a planning\nsystem that works directly on a GTS. It features a domain-independent heuristic\nthat uses the solution length of an abstraction of the original problem as an\nestimate. Finally, we provide experimental results on two different domains,\nwhich confirm that our heuristic performs better than another\ndomain-independent heuristic which resembles heuristics employed in related\nwork.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jul 2014 03:23:24 GMT"}], "update_date": "2014-07-31", "authors_parsed": [["Ziegert", "Steffen", "", "University of Paderborn"]]}, {"id": "1407.7934", "submitter": "EPTCS", "authors": "Valerio Senni, Michele Stawowy (IMT Institute for Advanced Studies)", "title": "Backwards State-space Reduction for Planning in Dynamic Knowledge Bases", "comments": "In Proceedings GRAPHITE 2014, arXiv:1407.7671", "journal-ref": "EPTCS 159, 2014, pp. 84-99", "doi": "10.4204/EPTCS.159.8", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the problem of planning in rich domains, where\nknowledge representation is a key aspect for managing the complexity and size\nof the planning domain. We follow the approach of Description Logic (DL) based\nDynamic Knowledge Bases, where a state of the world is represented concisely by\na (possibly changing) ABox and a (fixed) TBox containing the axioms, and\nactions that allow to change the content of the ABox. The plan goal is given in\nterms of satisfaction of a DL query. In this paper we start from a traditional\nforward planning algorithm and we propose a much more efficient variant by\ncombining backward and forward search. In particular, we propose a Backward\nState-space Reduction technique that consists in two phases: first, an Abstract\nPlanning Graph P is created by using the Abstract Backward Planning Algorithm\n(ABP), then the abstract planning graph P is instantiated into a corresponding\nplanning graph P by using the Forward Plan Instantiation Algorithm (FPI). The\nadvantage is that in the preliminary ABP phase we produce a symbolic plan that\nis a pattern to direct the search of the concrete plan. This can be seen as a\nkind of informed search where the preliminary backward phase is useful to\ndiscover properties of the state-space that can be used to direct the\nsubsequent forward phase. We evaluate the effectiveness of our ABP+FPI\nalgorithm in the reduction of the explored planning domain by comparing it to a\nstandard forward planning algorithm and applying both of them to a concrete\nbusiness case study.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jul 2014 03:28:15 GMT"}], "update_date": "2014-07-31", "authors_parsed": [["Senni", "Valerio", "", "IMT Institute for Advanced Studies"], ["Stawowy", "Michele", "", "IMT Institute for Advanced Studies"]]}, {"id": "1407.8033", "submitter": "Lorenzo Livi", "authors": "Lorenzo Livi, Alessandro Giuliani, Alireza Sadeghian", "title": "Characterization of graphs for protein structure modeling and\n  recognition of solubility", "comments": "To appear in Current Bioinformatics, Bentham Science", "journal-ref": null, "doi": "10.2174/1574893611666151109175216", "report-no": null, "categories": "physics.data-an cs.AI q-bio.BM q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the relations among structural, topological, and\nchemical properties of the E.Coli proteome from the vantage point of the\nsolubility/aggregation propensity of proteins. Each E.Coli protein is initially\nrepresented according to its known folded 3D shape. This step consists in\nrepresenting the available E.Coli proteins in terms of graphs. We first analyze\nthose graphs by considering pure topological characterizations, i.e., by\nanalyzing the mass fractal dimension and the distribution underlying both\nshortest paths and vertex degrees. Results confirm the general architectural\nprinciples of proteins. Successively, we focus on the statistical properties of\na representation of such graphs in terms of vectors composed of several\nnumerical features, which we extracted from their structural representation. We\nfound that protein size is the main discriminator for the solubility, while\nhowever there are other factors that help explaining the solubility degree. We\nfinally analyze such data through a novel one-class classifier, with the aim of\ndiscriminating among very and poorly soluble proteins. Results are encouraging\nand consolidate the potential of pattern recognition techniques when employed\nto describe complex biological systems.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jul 2014 13:22:19 GMT"}, {"version": "v2", "created": "Wed, 20 Aug 2014 19:42:39 GMT"}, {"version": "v3", "created": "Thu, 21 Aug 2014 13:01:08 GMT"}, {"version": "v4", "created": "Sun, 11 Jan 2015 15:31:16 GMT"}, {"version": "v5", "created": "Wed, 23 Sep 2015 18:21:55 GMT"}], "update_date": "2015-11-17", "authors_parsed": [["Livi", "Lorenzo", ""], ["Giuliani", "Alessandro", ""], ["Sadeghian", "Alireza", ""]]}, {"id": "1407.8134", "submitter": "Rossano Schifanella", "authors": "Luca Maria Aiello, Martina Deplano, Rossano Schifanella, Giancarlo\n  Ruffo", "title": "People are Strange when you're a Stranger: Impact and Influence of Bots\n  on Social Networks", "comments": "10 pages, 9 figures, Proceedings of the 6th International AAAI\n  Conference on Weblogs and Social Media, Dublin, IR, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bots are, for many Web and social media users, the source of many dangerous\nattacks or the carrier of unwanted messages, such as spam. Nevertheless,\ncrawlers and software agents are a precious tool for analysts, and they are\ncontinuously executed to collect data or to test distributed applications.\nHowever, no one knows which is the real potential of a bot whose purpose is to\ncontrol a community, to manipulate consensus, or to influence user behavior. It\nis commonly believed that the better an agent simulates human behavior in a\nsocial network, the more it can succeed to generate an impact in that\ncommunity. We contribute to shed light on this issue through an online social\nexperiment aimed to study to what extent a bot with no trust, no profile, and\nno aims to reproduce human behavior, can become popular and influential in a\nsocial media. Results show that a basic social probing activity can be used to\nacquire social relevance on the network and that the so-acquired popularity can\nbe effectively leveraged to drive users in their social connectivity choices.\nWe also register that our bot activity unveiled hidden social polarization\npatterns in the community and triggered an emotional response of individuals\nthat brings to light subtle privacy hazards perceived by the user base.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jul 2014 17:29:38 GMT"}], "update_date": "2014-07-31", "authors_parsed": [["Aiello", "Luca Maria", ""], ["Deplano", "Martina", ""], ["Schifanella", "Rossano", ""], ["Ruffo", "Giancarlo", ""]]}, {"id": "1407.8151", "submitter": "Fabio Cuzzolin", "authors": "Fabio Cuzzolin", "title": "Consistent transformations of belief functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consistent belief functions represent collections of coherent or\nnon-contradictory pieces of evidence, but most of all they are the counterparts\nof consistent knowledge bases in belief calculus. The use of consistent\ntransformations cs[.] in a reasoning process to guarantee coherence can\ntherefore be desirable, and generalizes similar techniques in classical logic.\nTransformations can be obtained by minimizing an appropriate distance measure\nbetween the original belief function and the collection of consistent ones. We\nfocus here on the case in which distances are measured using classical Lp\nnorms, in both the \"mass space\" and the \"belief space\" representation of belief\nfunctions. While mass consistent approximations reassign the mass not focussed\non a chosen element of the frame either to the whole frame or to all supersets\nof the element on an equal basis, approximations in the belief space do\ndistinguish these focal elements according to the \"focussed consistent\ntransformation\" principle. The different approximations are interpreted and\ncompared, with the help of examples.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jul 2014 18:25:31 GMT"}], "update_date": "2014-07-31", "authors_parsed": [["Cuzzolin", "Fabio", ""]]}, {"id": "1407.8161", "submitter": "Miroslav Dud\\'ik", "authors": "Miroslav Dud\\'ik and Rafael Frongillo and Jennifer Wortman Vaughan", "title": "Market Making with Decreasing Utility for Information", "comments": null, "journal-ref": "M. Dudik, R. Frongillo, and J. Wortman Vaughan. Market Making with\n  Decreasing Utility for Information. In Proceedings of the 30th Conference on\n  Uncertainty in Artificial Intelligence, pages 152-161, 2014", "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study information elicitation in cost-function-based combinatorial\nprediction markets when the market maker's utility for information decreases\nover time. In the sudden revelation setting, it is known that some piece of\ninformation will be revealed to traders, and the market maker wishes to prevent\nguaranteed profits for trading on the sure information. In the gradual decrease\nsetting, the market maker's utility for (partial) information decreases\ncontinuously over time. We design adaptive cost functions for both settings\nwhich: (1) preserve the information previously gathered in the market; (2)\neliminate (or diminish) rewards to traders for the publicly revealed\ninformation; (3) leave the reward structure unaffected for other information;\nand (4) maintain the market maker's worst-case loss. Our constructions utilize\nmixed Bregman divergence, which matches our notion of utility for information.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jul 2014 19:09:45 GMT"}], "update_date": "2014-07-31", "authors_parsed": [["Dud\u00edk", "Miroslav", ""], ["Frongillo", "Rafael", ""], ["Vaughan", "Jennifer Wortman", ""]]}, {"id": "1407.8392", "submitter": "Gagan Sidhu", "authors": "Gagan Sidhu, Brian Caffo", "title": "MONEYBaRL: Exploiting pitcher decision-making using Reinforcement\n  Learning", "comments": "Published in at http://dx.doi.org/10.1214/13-AOAS712 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 2, 926-955", "doi": "10.1214/13-AOAS712", "report-no": "IMS-AOAS-AOAS712", "categories": "cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This manuscript uses machine learning techniques to exploit baseball\npitchers' decision making, so-called \"Baseball IQ,\" by modeling the at-bat\ninformation, pitch selection and counts, as a Markov Decision Process (MDP).\nEach state of the MDP models the pitcher's current pitch selection in a\nMarkovian fashion, conditional on the information immediately prior to making\nthe current pitch. This includes the count prior to the previous pitch, his\nensuing pitch selection, the batter's ensuing action and the result of the\npitch.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jul 2014 12:49:52 GMT"}], "update_date": "2014-08-01", "authors_parsed": [["Sidhu", "Gagan", ""], ["Caffo", "Brian", ""]]}]